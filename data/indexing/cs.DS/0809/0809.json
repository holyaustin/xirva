[{"id": "0809.0188", "submitter": "Marek Karpinski", "authors": "Piotr Berman, Bhaskar DasGupta and Marek Karpinski", "title": "Approximating Transitivity in Directed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of computing a minimum equivalent digraph (also known as\nthe problem of computing a strong transitive reduction) and its maximum\nobjective function variant, with two types of extensions. First, we allow to\ndeclare a set $D\\subset E$ and require that a valid solution $A$ satisfies\n$D\\subset A$ (it is sometimes called transitive reduction problem). In the\nsecond extension (called $p$-ary transitive reduction), we have integer edge\nlabeling and we view two paths as equivalent if they have the same beginning,\nending and the sum of labels modulo $p$. A solution $A\\subseteq E$ is valid if\nit gives an equivalent path for every original path. For all problems we\nestablish the following: polynomial time minimization of $|A|$ within ratio\n1.5, maximization of $|E-A|$ within ratio 2, MAX-SNP hardness even of the\nlength of simple cycles is limited to 5. Furthermore, we believe that the\ncombinatorial technique behind the approximation algorithm for the minimization\nversion might be of interest to other graph connectivity problems as well.\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2008 08:58:32 GMT"}], "update_date": "2008-09-02", "authors_parsed": [["Berman", "Piotr", ""], ["DasGupta", "Bhaskar", ""], ["Karpinski", "Marek", ""]]}, {"id": "0809.0400", "submitter": "Xuan Cai", "authors": "Xuan Cai", "title": "Canonical Coin Systems for Change-Making Problems", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Change-Making Problem is to represent a given value with the fewest coins\nunder a given coin system. As a variation of the knapsack problem, it is known\nto be NP-hard. Nevertheless, in most real money systems, the greedy algorithm\nyields optimal solutions. In this paper, we study what type of coin systems\nthat guarantee the optimality of the greedy algorithm. We provide new proofs\nfor a sufficient and necessary condition for the so-called \\emph{canonical}\ncoin systems with four or five types of coins, and a sufficient condition for\nnon-canonical coin systems, respectively. Moreover, we present an $O(m^2)$\nalgorithm that decides whether a tight coin system is canonical.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2008 11:04:19 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2009 16:12:55 GMT"}], "update_date": "2009-03-21", "authors_parsed": [["Cai", "Xuan", ""]]}, {"id": "0809.0460", "submitter": "Shipra Agrawal", "authors": "Shipra Agrawal, Amin Saberi, Yinyu Ye", "title": "Stochastic Combinatorial Optimization under Probabilistic Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present approximation algorithms for combinatorial\noptimization problems under probabilistic constraints. Specifically, we focus\non stochastic variants of two important combinatorial optimization problems:\nthe k-center problem and the set cover problem, with uncertainty characterized\nby a probability distribution over set of points or elements to be covered. We\nconsider these problems under adaptive and non-adaptive settings, and present\nefficient approximation algorithms for the case when underlying distribution is\na product distribution. In contrast to the expected cost model prevalent in\nstochastic optimization literature, our problem definitions support\nrestrictions on the probability distributions of the total costs, via\nincorporating constraints that bound the probability with which the incurred\ncosts may exceed a given threshold.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2008 16:07:42 GMT"}], "update_date": "2008-09-03", "authors_parsed": [["Agrawal", "Shipra", ""], ["Saberi", "Amin", ""], ["Ye", "Yinyu", ""]]}, {"id": "0809.0949", "submitter": "Michael Baer", "authors": "Michael B. Baer", "title": "Efficient Implementation of the Generalized Tunstall Code Generation\n  Algorithm", "comments": "5 pages, 5 figures, accepted to ISIT 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method is presented for constructing a Tunstall code that is linear time in\nthe number of output items. This is an improvement on the state of the art for\nnon-Bernoulli sources, including Markov sources, which require a (suboptimal)\ngeneralization of Tunstall's algorithm proposed by Savari and analytically\nexamined by Tabus and Rissanen. In general, if n is the total number of output\nleaves across all Tunstall trees, s is the number of trees (states), and D is\nthe number of leaves of each internal node, then this method takes O((1+(log\ns)/D) n) time and O(n) space.\n", "versions": [{"version": "v1", "created": "Fri, 5 Sep 2008 05:14:10 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2009 19:58:44 GMT"}, {"version": "v3", "created": "Fri, 8 May 2009 00:10:57 GMT"}], "update_date": "2009-05-08", "authors_parsed": [["Baer", "Michael B.", ""]]}, {"id": "0809.1171", "submitter": "Cheng-Wei Luo", "authors": "Cheng-Wei Luo, Hsiao-Fei Liu, Peng-An Chen, and Kun-Mao Chao", "title": "Minkowski Sum Selection and Finding", "comments": "23 pages, 10 figures, accepted by ISAAC 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the \\textsc{Minkowski Sum Selection} problem with linear objective\nfunctions, we obtain the following results: (1) optimal $O(n\\log n)$ time\nalgorithms for $\\lambda=1$; (2) $O(n\\log^2 n)$ time deterministic algorithms\nand expected $O(n\\log n)$ time randomized algorithms for any fixed $\\lambda>1$.\nFor the \\textsc{Minkowski Sum Finding} problem with linear objective functions\nor objective functions of the form\n  $f(x,y)=\\frac{by}{ax}$, we construct optimal $O(n\\log n)$ time algorithms for\nany fixed $\\lambda\\geq 1$.\n", "versions": [{"version": "v1", "created": "Sat, 6 Sep 2008 14:31:49 GMT"}], "update_date": "2008-09-09", "authors_parsed": [["Luo", "Cheng-Wei", ""], ["Liu", "Hsiao-Fei", ""], ["Chen", "Peng-An", ""], ["Chao", "Kun-Mao", ""]]}, {"id": "0809.1681", "submitter": "Rafael Laufer", "authors": "Rafael Laufer and Leonard Kleinrock", "title": "Multirate Anypath Routing in Wireless Mesh Networks", "comments": "13 pages, 8 figures", "journal-ref": "IEEE INFOCOM 2009", "doi": "10.1109/INFCOM.2009.5061904", "report-no": "UCLA-CSD-TR080025", "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new routing paradigm that generalizes\nopportunistic routing in wireless mesh networks. In multirate anypath routing,\neach node uses both a set of next hops and a selected transmission rate to\nreach a destination. Using this rate, a packet is broadcast to the nodes in the\nset and one of them forwards the packet on to the destination. To date, there\nis no theory capable of jointly optimizing both the set of next hops and the\ntransmission rate used by each node. We bridge this gap by introducing a\npolynomial-time algorithm to this problem and provide the proof of its\noptimality. The proposed algorithm runs in the same running time as regular\nshortest-path algorithms and is therefore suitable for deployment in link-state\nrouting protocols. We conducted experiments in a 802.11b testbed network, and\nour results show that multirate anypath routing performs on average 80% and up\nto 6.4 times better than anypath routing with a fixed rate of 11 Mbps. If the\nrate is fixed at 1 Mbps instead, performance improves by up to one order of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2008 21:49:04 GMT"}], "update_date": "2010-11-01", "authors_parsed": [["Laufer", "Rafael", ""], ["Kleinrock", "Leonard", ""]]}, {"id": "0809.1715", "submitter": "Bodo Manthey", "authors": "Bodo Manthey and Heiko R\\\"oglin", "title": "Improved Smoothed Analysis of the k-Means Method", "comments": "To be presented at the 20th ACM-SIAM Symposium on Discrete Algorithms\n  (SODA 2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-means method is a widely used clustering algorithm. One of its\ndistinguished features is its speed in practice. Its worst-case running-time,\nhowever, is exponential, leaving a gap between practical and theoretical\nperformance. Arthur and Vassilvitskii (FOCS 2006) aimed at closing this gap,\nand they proved a bound of $\\poly(n^k, \\sigma^{-1})$ on the smoothed\nrunning-time of the k-means method, where n is the number of data points and\n$\\sigma$ is the standard deviation of the Gaussian perturbation. This bound,\nthough better than the worst-case bound, is still much larger than the\nrunning-time observed in practice.\n  We improve the smoothed analysis of the k-means method by showing two upper\nbounds on the expected running-time of k-means. First, we prove that the\nexpected running-time is bounded by a polynomial in $n^{\\sqrt k}$ and\n$\\sigma^{-1}$. Second, we prove an upper bound of $k^{kd} \\cdot \\poly(n,\n\\sigma^{-1})$, where d is the dimension of the data space. The polynomial is\nindependent of k and d, and we obtain a polynomial bound for the expected\nrunning-time for $k, d \\in O(\\sqrt{\\log n/\\log \\log n})$.\n  Finally, we show that k-means runs in smoothed polynomial time for\none-dimensional instances.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2008 07:00:38 GMT"}], "update_date": "2008-09-11", "authors_parsed": [["Manthey", "Bodo", ""], ["R\u00f6glin", "Heiko", ""]]}, {"id": "0809.1810", "submitter": "Felipe Cruz", "authors": "Felipe A. Cruz, L. A. Barba", "title": "Characterization of the errors of the FMM in particle simulations", "comments": "34 pages, 38 images", "journal-ref": "Int. J. Num. Meth. Engrg., 79(13):1577-1604 (2009)", "doi": "10.1002/nme.2611", "report-no": null, "categories": "cs.DS physics.comp-ph", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The Fast Multipole Method (FMM) offers an acceleration for pairwise\ninteraction calculation, known as $N$-body problems, from $\\mathcal{O}(N^2)$ to\n$\\mathcal{O}(N)$ with $N$ particles. This has brought dramatic increase in the\ncapability of particle simulations in many application areas, such as\nelectrostatics, particle formulations of fluid mechanics, and others. Although\nthe literature on the subject provides theoretical error bounds for the FMM\napproximation, there are not many reports of the measured errors in a suite of\ncomputational experiments. We have performed such an experimental\ninvestigation, and summarized the results of about 1000 calculations using the\nFMM algorithm, to characterize the accuracy of the method in relation with the\ndifferent parameters available to the user. In addition to the more standard\ndiagnostic of the maximum error, we supply illustrations of the spatial\ndistribution of the errors, which offers visual evidence of all the\ncontributing factors to the overall approximation accuracy: multipole\nexpansion, local expansion, hierarchical spatial decomposition (interaction\nlists, local domain, far domain). This presentation is a contribution to any\nresearcher wishing to incorporate the FMM acceleration to their application\ncode, as it aids in understanding where accuracy is gained or compromised.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2008 15:06:08 GMT"}], "update_date": "2011-09-21", "authors_parsed": [["Cruz", "Felipe A.", ""], ["Barba", "L. A.", ""]]}, {"id": "0809.1895", "submitter": "Benjamin Birnbaum", "authors": "Yossi Azar, Benjamin Birnbaum, Anna R. Karlin, and C. Thach Nguyen", "title": "Thinking Twice about Second-Price Ad Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has addressed the algorithmic problem of allocating advertisement\nspace for keywords in sponsored search auctions so as to maximize revenue, most\nof which assume that pricing is done via a first-price auction. This does not\nrealistically model the Generalized Second Price (GSP) auction used in\npractice, in which bidders pay the next-highest bid for keywords that they are\nallocated. Towards the goal of more realistically modeling these auctions, we\nintroduce the Second-Price Ad Auctions problem, in which bidders' payments are\ndetermined by the GSP mechanism. We show that the complexity of the\nSecond-Price Ad Auctions problem is quite different than that of the more\nstudied First-Price Ad Auctions problem. First, unlike the first-price variant,\nfor which small constant-factor approximations are known, it is NP-hard to\napproximate the Second-Price Ad Auctions problem to any non-trivial factor,\neven when the bids are small compared to the budgets. Second, this discrepancy\nextends even to the 0-1 special case that we call the Second-Price Matching\nproblem (2PM). Offline 2PM is APX-hard, and for online 2PM there is no\ndeterministic algorithm achieving a non-trivial competitive ratio and no\nrandomized algorithm achieving a competitive ratio better than 2. This\ncontrasts with the results for the analogous special case in the first-price\nmodel, the standard bipartite matching problem, which is solvable in polynomial\ntime and which has deterministic and randomized online algorithms achieving\nbetter competitive ratios. On the positive side, we provide a 2-approximation\nfor offline 2PM and a 5.083-competitive randomized algorithm for online 2PM.\nThe latter result makes use of a new generalization of a result on the\nperformance of the \"Ranking\" algorithm for online bipartite matching.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2008 23:33:47 GMT"}], "update_date": "2008-09-12", "authors_parsed": [["Azar", "Yossi", ""], ["Birnbaum", "Benjamin", ""], ["Karlin", "Anna R.", ""], ["Nguyen", "C. Thach", ""]]}, {"id": "0809.1902", "submitter": "Manor Mendel", "authors": "Manor Mendel, Chaya Schwob", "title": "Fast C-K-R Partitions of Sparse Graphs", "comments": "15 pages, title changed, a small error in the running time was fixed.\n  Many errors in English were eliminated", "journal-ref": "Chicago J. Theoretical Comp. Sci., 2009(2), 2009", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present fast algorithms for constructing probabilistic embeddings and\napproximate distance oracles in sparse graphs. The main ingredient is a fast\nalgorithm for sampling the probabilistic partitions of Calinescu, Karloff, and\nRabani in sparse graphs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2008 02:10:29 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2009 02:47:44 GMT"}], "update_date": "2009-09-09", "authors_parsed": [["Mendel", "Manor", ""], ["Schwob", "Chaya", ""]]}, {"id": "0809.1906", "submitter": "Shiva Kintali", "authors": "Shiva Kintali", "title": "Betweenness Centrality : Algorithms and Lower Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most fundamental problems in large scale network analysis is to\ndetermine the importance of a particular node in a network. Betweenness\ncentrality is the most widely used metric to measure the importance of a node\nin a network. In this paper, we present a randomized parallel algorithm and an\nalgebraic method for computing betweenness centrality of all nodes in a\nnetwork. We prove that any path-comparison based algorithm cannot compute\nbetweenness in less than O(nm) time.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2008 02:49:07 GMT"}, {"version": "v2", "created": "Sun, 19 Oct 2008 04:24:21 GMT"}], "update_date": "2008-10-19", "authors_parsed": [["Kintali", "Shiva", ""]]}, {"id": "0809.2075", "submitter": "Jittat Fakcharoenphol", "authors": "Jittat Fakcharoenphol, Boonserm Kijsirikul", "title": "Low congestion online routing and an improved mistake bound for online\n  prediction of graph labeling", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show a connection between a certain online low-congestion\nrouting problem and an online prediction of graph labeling. More specifically,\nwe prove that if there exists a routing scheme that guarantees a congestion of\n$\\alpha$ on any edge, there exists an online prediction algorithm with mistake\nbound $\\alpha$ times the cut size, which is the size of the cut induced by the\nlabel partitioning of graph vertices. With previous known bound of $O(\\log n)$\nfor $\\alpha$ for the routing problem on trees with $n$ vertices, we obtain an\nimproved prediction algorithm for graphs with high effective resistance.\n  In contrast to previous approaches that move the graph problem into problems\nin vector space using graph Laplacian and rely on the analysis of the\nperceptron algorithm, our proof are purely combinatorial. Further more, our\napproach directly generalizes to the case where labels are not binary.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2008 19:32:49 GMT"}, {"version": "v2", "created": "Fri, 12 Sep 2008 07:02:37 GMT"}], "update_date": "2008-09-12", "authors_parsed": [["Fakcharoenphol", "Jittat", ""], ["Kijsirikul", "Boonserm", ""]]}, {"id": "0809.2097", "submitter": "Hsiao-Fei Liu", "authors": "Hsiao-Fei Liu, Peng-An Chen, and Kun-Mao Chao", "title": "Algorithms for Locating Constrained Optimal Intervals", "comments": "An earlier version of the second part of this work appeared in\n  Proceedings of the 18th International Symposium on Algorithms and\n  Computation, Japan, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we obtain the following new results.\n  1. Given a sequence $D=((h_1,s_1), (h_2,s_2) ..., (h_n,s_n))$ of number\npairs, where $s_i>0$ for all $i$, and a number $L_h$, we propose an O(n)-time\nalgorithm for finding an index interval $[i,j]$ that maximizes\n$\\frac{\\sum_{k=i}^{j} h_k}{\\sum_{k=i}^{j} s_k}$ subject to $\\sum_{k=i}^{j} h_k\n\\geq L_h$.\n  2. Given a sequence $D=((h_1,s_1), (h_2,s_2) ..., (h_n,s_n))$ of number\npairs, where $s_i=1$ for all $i$, and an integer $L_s$ with $1\\leq L_s\\leq n$,\nwe propose an $O(n\\frac{T(L_s^{1/2})}{L_s^{1/2}})$-time algorithm for finding\nan index interval $[i,j]$ that maximizes $\\frac{\\sum_{k=i}^{j}\nh_k}{\\sqrt{\\sum_{k=i}^{j} s_k}}$ subject to $\\sum_{k=i}^{j} s_k \\geq L_s$,\nwhere $T(n')$ is the time required to solve the all-pairs shortest paths\nproblem on a graph of $n'$ nodes. By the latest result of Chan \\cite{Chan},\n$T(n')=O(n'^3 \\frac{(\\log\\log n')^3}{(\\log n')^2})$, so our algorithm runs in\nsubquadratic time $O(nL_s\\frac{(\\log\\log L_s)^3}{(\\log L_s)^2})$.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2008 20:12:08 GMT"}], "update_date": "2008-09-15", "authors_parsed": [["Liu", "Hsiao-Fei", ""], ["Chen", "Peng-An", ""], ["Chao", "Kun-Mao", ""]]}, {"id": "0809.2489", "submitter": "Petteri Kaski", "authors": "Andreas Bj\\\"orklund, Thore Husfeldt, Petteri Kaski, Mikko Koivisto", "title": "The fast intersection transform with applications to counting paths", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for evaluating a linear ``intersection transform'' of\na function defined on the lattice of subsets of an $n$-element set. In\nparticular, the algorithm constructs an arithmetic circuit for evaluating the\ntransform in ``down-closure time'' relative to the support of the function and\nthe evaluation domain. As an application, we develop an algorithm that, given\nas input a digraph with $n$ vertices and bounded integer weights at the edges,\ncounts paths by weight and given length $0\\leq\\ell\\leq n-1$ in time\n$O^*(\\exp(n\\cdot H(\\ell/(2n))))$, where $H(p)=-p\\log p-(1-p)\\log(1-p)$, and the\nnotation $O^*(\\cdot)$ suppresses a factor polynomial in $n$.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2008 11:15:05 GMT"}], "update_date": "2008-09-16", "authors_parsed": [["Bj\u00f6rklund", "Andreas", ""], ["Husfeldt", "Thore", ""], ["Kaski", "Petteri", ""], ["Koivisto", "Mikko", ""]]}, {"id": "0809.2554", "submitter": "Kanat Tangwongsan", "authors": "Anupam Gupta and Kanat Tangwongsan", "title": "Simpler Analyses of Local Search Algorithms for Facility Location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study local search algorithms for metric instances of facility location\nproblems: the uncapacitated facility location problem (UFL), as well as\nuncapacitated versions of the $k$-median, $k$-center and $k$-means problems.\nAll these problems admit natural local search heuristics: for example, in the\nUFL problem the natural moves are to open a new facility, close an existing\nfacility, and to swap a closed facility for an open one; in $k$-medians, we are\nallowed only swap moves. The local-search algorithm for $k$-median was analyzed\nby Arya et al. (SIAM J. Comput. 33(3):544-562, 2004), who used a clever\n``coupling'' argument to show that local optima had cost at most constant times\nthe global optimum. They also used this argument to show that the local search\nalgorithm for UFL was 3-approximation; their techniques have since been applied\nto other facility location problems.\n  In this paper, we give a proof of the $k$-median result which avoids this\ncoupling argument. These arguments can be used in other settings where the Arya\net al. arguments have been used. We also show that for the problem of opening\n$k$ facilities $F$ to minimize the objective function $\\Phi_p(F) = \\big(\\sum_{j\n\\in V} d(j, F)^p\\big)^{1/p}$, the natural swap-based local-search algorithm is\na $\\Theta(p)$-approximation. This implies constant-factor approximations for\n$k$-medians (when $p=1$), and $k$-means (when $p = 2$), and an $O(\\log\nn)$-approximation algorithm for the $k$-center problem (which is essentially $p\n= \\log n$).\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2008 15:42:47 GMT"}], "update_date": "2008-09-16", "authors_parsed": [["Gupta", "Anupam", ""], ["Tangwongsan", "Kanat", ""]]}, {"id": "0809.2858", "submitter": "Christophe Paul", "authors": "Stephane Bessy and Christophe Paul and Anthony Perez", "title": "Polynomial kernels for 3-leaf power graph modification problems", "comments": "Submitted", "journal-ref": null, "doi": "10.1007/978-3-642-10217-2_10", "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph G=(V,E) is a 3-leaf power iff there exists a tree T whose leaves are\nV and such that (u,v) is an edge iff u and v are at distance at most 3 in T.\nThe 3-leaf power graph edge modification problems, i.e. edition (also known as\nthe closest 3-leaf power), completion and edge-deletion, are FTP when\nparameterized by the size of the edge set modification. However polynomial\nkernel was known for none of these three problems. For each of them, we provide\ncubic kernels that can be computed in linear time for each of these problems.\nWe thereby answer an open problem first mentioned by Dom, Guo, Huffner and\nNiedermeier (2005).\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2008 06:16:37 GMT"}, {"version": "v2", "created": "Wed, 17 Sep 2008 20:10:57 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Bessy", "Stephane", ""], ["Paul", "Christophe", ""], ["Perez", "Anthony", ""]]}, {"id": "0809.2957", "submitter": "Sergi Elizalde", "authors": "Sergi Elizalde, Peter Winkler", "title": "Sorting by Placement and Shift", "comments": "13 pages, 4 figures, Proceedings of SODA 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sorting situations where the final destination of each item is known, it\nis natural to repeatedly choose items and place them where they belong,\nallowing the intervening items to shift by one to make room. (In fact, a\nspecial case of this algorithm is commonly used to hand-sort files.) However,\nit is not obvious that this algorithm necessarily terminates.\n  We show that in fact the algorithm terminates after at most $2^{n-1}-1$ steps\nin the worst case (confirming a conjecture of L. Larson), and that there are\nsuper-exponentially many permutations for which this exact bound can be\nachieved. The proof involves a curious symmetrical binary representation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2008 16:29:38 GMT"}], "update_date": "2008-09-18", "authors_parsed": [["Elizalde", "Sergi", ""], ["Winkler", "Peter", ""]]}, {"id": "0809.2970", "submitter": "Raphael Yuster", "authors": "Raphael Yuster", "title": "Single source shortest paths in $H$-minor free graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for the Single Source Shortest Paths (SSSP) problem\nin \\emph{$H$-minor free} graphs. For every fixed $H$, if $G$ is a graph with\n$n$ vertices having integer edge lengths and $s$ is a designated source vertex\nof $G$, the algorithm runs in $\\tilde{O}(n^{\\sqrt{11.5}-2} \\log L) \\le\nO(n^{1.392} \\log L)$ time, where $L$ is the absolute value of the smallest edge\nlength. The algorithm computes shortest paths and the distances from $s$ to all\nvertices of the graph, or else provides a certificate that $G$ is not $H$-minor\nfree. Our result improves an earlier $O(n^{1.5} \\log L)$ time algorithm for\nthis problem, which follows from a general SSSP algorithm of Goldberg.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2008 17:51:09 GMT"}], "update_date": "2008-09-18", "authors_parsed": [["Yuster", "Raphael", ""]]}, {"id": "0809.3232", "submitter": "Daniel A. Spielman", "authors": "Daniel A. Spielman, Shang-Hua Teng", "title": "A Local Clustering Algorithm for Massive Graphs and its Application to\n  Nearly-Linear Time Graph Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the design of local algorithms for massive graphs. A local algorithm\nis one that finds a solution containing or near a given vertex without looking\nat the whole graph. We present a local clustering algorithm. Our algorithm\nfinds a good cluster--a subset of vertices whose internal connections are\nsignificantly richer than its external connections--near a given vertex. The\nrunning time of our algorithm, when it finds a non-empty local cluster, is\nnearly linear in the size of the cluster it outputs.\n  Our clustering algorithm could be a useful primitive for handling massive\ngraphs, such as social networks and web-graphs. As an application of this\nclustering algorithm, we present a partitioning algorithm that finds an\napproximate sparsest cut with nearly optimal balance. Our algorithm takes time\nnearly linear in the number edges of the graph.\n  Using the partitioning algorithm of this paper, we have designed a\nnearly-linear time algorithm for constructing spectral sparsifiers of graphs,\nwhich we in turn use in a nearly-linear time algorithm for solving linear\nsystems in symmetric, diagonally-dominant matrices. The linear system solver\nalso leads to a nearly linear-time algorithm for approximating the\nsecond-smallest eigenvalue and corresponding eigenvector of the Laplacian\nmatrix of a graph. These other results are presented in two companion papers.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2008 19:20:07 GMT"}], "update_date": "2008-09-19", "authors_parsed": [["Spielman", "Daniel A.", ""], ["Teng", "Shang-Hua", ""]]}, {"id": "0809.3527", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Angela Andreica, Romulus Andreica", "title": "Inferring Company Structure from Limited Available Information", "comments": "Some of the algorithmic techniques presented in this paper were used\n  as part of the solutions for some of the tasks proposed in several\n  programming contests in which the first author participated (see the related\n  materials for several such tasks and their solutions)", "journal-ref": "International Symposium on Social Development and Economic\n  Performance, Satu Mare : Romania (2008)", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present several algorithmic techniques for inferring the\nstructure of a company when only a limited amount of information is available.\nWe consider problems with two types of inputs: the number of pairs of employees\nwith a given property and restricted information about the hierarchical\nstructure of the company. We provide dynamic programming and greedy algorithms\nfor these problems.\n", "versions": [{"version": "v1", "created": "Sat, 20 Sep 2008 20:05:21 GMT"}, {"version": "v2", "created": "Sun, 23 Dec 2012 06:56:16 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Andreica", "Angela", ""], ["Andreica", "Romulus", ""]]}, {"id": "0809.3528", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Cristina Teodora Andreica, Madalina Ecaterina\n  Andreica", "title": "Locating Restricted Facilities on Binary Maps", "comments": "The algorithmic techniques presented in this paper were used by the\n  first author in the implementation of solutions to various algorithmic\n  contest tasks (see the attached zip archive for some examples)", "journal-ref": "International Symposium on Social Development and Economic\n  Performance, Satu Mare : Romania (2008)", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider several facility location problems with\napplications to cost and social welfare optimization, when the area map is\nencoded as a binary (0,1) mxn matrix. We present algorithmic solutions for all\nthe problems. Some cases are too particular to be used in practical situations,\nbut they are at least a starting point for more generic solutions.\n", "versions": [{"version": "v1", "created": "Sat, 20 Sep 2008 20:06:34 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2013 07:48:10 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Andreica", "Cristina Teodora", ""], ["Andreica", "Madalina Ecaterina", ""]]}, {"id": "0809.3577", "submitter": "Philippe Robert", "authors": "Han\\`ene Mohamed, Philippe Robert", "title": "Dynamic tree algorithms", "comments": "Published in at http://dx.doi.org/10.1214/09-AAP617 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 1, 26-51", "doi": "10.1214/09-AAP617", "report-no": "IMS-AAP-AAP617", "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a general tree algorithm processing a random flow of arrivals\nis analyzed. Capetanakis--Tsybakov--Mikhailov's protocol in the context of\ncommunication networks with random access is an example of such an algorithm.\nIn computer science, this corresponds to a trie structure with a dynamic input.\nMathematically, it is related to a stopped branching process with exogeneous\narrivals (immigration). Under quite general assumptions on the distribution of\nthe number of arrivals and on the branching procedure, it is shown that there\nexists a positive constant $\\lambda_c$ so that if the arrival rate is smaller\nthan $\\lambda_c$, then the algorithm is stable under the flow of requests, that\nis, that the total size of an associated tree is integrable. At the same time,\na gap in the earlier proofs of stability in the literature is fixed. When the\narrivals are Poisson, an explicit characterization of $\\lambda_c$ is given.\nUnder the stability condition, the asymptotic behavior of the average size of a\ntree starting with a large number of individuals is analyzed. The results are\nobtained with the help of a probabilistic rewriting of the functional equations\ndescribing the dynamics of the system. The proofs use extensively this\nstochastic background throughout the paper. In this analysis, two basic limit\ntheorems play a key role: the renewal theorem and the convergence to\nequilibrium of an auto-regressive process with a moving average.\n", "versions": [{"version": "v1", "created": "Sun, 21 Sep 2008 11:46:05 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2010 13:51:20 GMT"}], "update_date": "2010-01-13", "authors_parsed": [["Mohamed", "Han\u00e8ne", ""], ["Robert", "Philippe", ""]]}, {"id": "0809.3646", "submitter": "Petr Golovach", "authors": "Fedor V. Fomin, Petr A. Golovach and Dimitrios M. Thilikos", "title": "Approximating acyclicity parameters of sparse hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notions of hypertree width and generalized hypertree width were\nintroduced by Gottlob, Leone, and Scarcello in order to extend the concept of\nhypergraph acyclicity. These notions were further generalized by Grohe and\nMarx, who introduced the fractional hypertree width of a hypergraph. All these\nwidth parameters on hypergraphs are useful for extending tractability of many\nproblems in database theory and artificial intelligence. In this paper, we\nstudy the approximability of (generalized, fractional) hyper treewidth of\nsparse hypergraphs where the criterion of sparsity reflects the sparsity of\ntheir incidence graphs. Our first step is to prove that the (generalized,\nfractional) hypertree width of a hypergraph H is constant-factor sandwiched by\nthe treewidth of its incidence graph, when the incidence graph belongs to some\napex-minor-free graph class. This determines the combinatorial borderline above\nwhich the notion of (generalized, fractional) hypertree width becomes\nessentially more general than treewidth, justifying that way its functionality\nas a hypergraph acyclicity measure. While for more general sparse families of\nhypergraphs treewidth of incidence graphs and all hypertree width parameters\nmay differ arbitrarily, there are sparse families where a constant factor\napproximation algorithm is possible. In particular, we give a constant factor\napproximation polynomial time algorithm for (generalized, fractional) hypertree\nwidth on hypergraphs whose incidence graphs belong to some H-minor-free graph\nclass.\n", "versions": [{"version": "v1", "created": "Mon, 22 Sep 2008 08:17:22 GMT"}], "update_date": "2008-09-23", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "0809.4398", "submitter": "Philipp Schuetz", "authors": "Philipp Schuetz, Amedeo Caflisch", "title": "Multistep greedy algorithm identifies community structure in real-world\n  and computer-generated networks", "comments": "17 pages, 2 figures", "journal-ref": "Phys. Rev. E 78, 026112 (2008)", "doi": "10.1103/PhysRevE.78.026112", "report-no": null, "categories": "cs.DS cond-mat.dis-nn physics.soc-ph q-bio.MN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently introduced a multistep extension of the greedy algorithm for\nmodularity optimization. The extension is based on the idea that merging l\npairs of communities (l>1) at each iteration prevents premature condensation\ninto few large communities. Here, an empirical formula is presented for the\nchoice of the step width l that generates partitions with (close to) optimal\nmodularity for 17 real-world and 1100 computer-generated networks. Furthermore,\nan in-depth analysis of the communities of two real-world networks (the\nmetabolic network of the bacterium E. coli and the graph of coappearing words\nin the titles of papers coauthored by Martin Karplus) provides evidence that\nthe partition obtained by the multistep greedy algorithm is superior to the one\ngenerated by the original greedy algorithm not only with respect to modularity\nbut also according to objective criteria. In other words, the multistep\nextension of the greedy algorithm reduces the danger of getting trapped in\nlocal optima of modularity and generates more reasonable partitions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2008 13:46:30 GMT"}], "update_date": "2008-09-26", "authors_parsed": [["Schuetz", "Philipp", ""], ["Caflisch", "Amedeo", ""]]}, {"id": "0809.4577", "submitter": "Jiajin Yu", "authors": "Mordecai Golin, Xiaoming Xu and Jiajin Yu", "title": "A Generic Top-Down Dynamic-Programming Approach to Prefix-Free Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a probability distribution over a set of n words to be transmitted, the\nHuffman Coding problem is to find a minimal-cost prefix free code for\ntransmitting those words. The basic Huffman coding problem can be solved in O(n\nlog n) time but variations are more difficult. One of the standard techniques\nfor solving these variations utilizes a top-down dynamic programming approach.\nIn this paper we show that this approach is amenable to dynamic programming\nspeedup techniques, permitting a speedup of an order of magnitude for many\nalgorithms in the literature for such variations as mixed radix, reserved\nlength and one-ended coding. These speedups are immediate implications of a\ngeneral structural property that permits batching together the calculation of\nmany DP entries.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2008 09:42:04 GMT"}], "update_date": "2008-09-29", "authors_parsed": [["Golin", "Mordecai", ""], ["Xu", "Xiaoming", ""], ["Yu", "Jiajin", ""]]}, {"id": "0809.4743", "submitter": "Boris Ryabko", "authors": "Boris Ryabko", "title": "The Imaginary Sliding Window As a New Data Structure for Adaptive\n  Algorithms", "comments": "Published in: Problems of information transmission,1996,v.32,#2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scheme of the sliding window is known in Information Theory, Computer\nScience, the problem of predicting and in stastistics. Let a source with\nunknown statistics generate some word $... x_{-1}x_{0}x_{1}x_{2}...$ in some\nalphabet $A$. For every moment $t, t=... $ $-1, 0, 1, ...$, one stores the word\n(\"window\") $ x_{t-w} x_{t-w+1}... x_{t-1}$ where $w$,$w \\geq 1$, is called\n\"window length\". In the theory of universal coding, the code of the $x_{t}$\ndepends on source ststistics estimated by the window, in the problem of\npredicting, each letter $x_{t}$ is predicted using information of the window,\netc. After that the letter $x_{t}$ is included in the window on the right,\nwhile $x_{t-w}$ is removed from the window. It is the sliding window scheme.\nThis scheme has two merits: it allows one i) to estimate the source statistics\nquite precisely and ii) to adapt the code in case of a change in the source'\nstatistics. However this scheme has a defect, namely, the necessity to store\nthe window (i.e. the word $x_{t-w}... x_{t-1})$ which needs a large memory size\nfor large $w$. A new scheme named \"the Imaginary Sliding Window (ISW)\" is\nconstructed. The gist of this scheme is that not the last element $x_{t-w}$ but\nrather a random one is removed from the window. This allows one to retain both\nmerits of the sliding window as well as the possibility of not storing the\nwindow and thus significantly decreasing the memory size.\n", "versions": [{"version": "v1", "created": "Sat, 27 Sep 2008 07:42:44 GMT"}], "update_date": "2008-09-30", "authors_parsed": [["Ryabko", "Boris", ""]]}, {"id": "0809.4794", "submitter": "Adam Smith", "authors": "Adam Smith", "title": "Efficient, Differentially Private Point Estimators", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a recent notion of privacy for statistical databases\nthat provides rigorous, meaningful confidentiality guarantees, even in the\npresence of an attacker with access to arbitrary side information.\n  We show that for a large class of parametric probability models, one can\nconstruct a differentially private estimator whose distribution converges to\nthat of the maximum likelihood estimator. In particular, it is efficient and\nasymptotically unbiased. This result provides (further) compelling evidence\nthat rigorous notions of privacy in statistical databases can be consistent\nwith statistically valid inference.\n", "versions": [{"version": "v1", "created": "Sat, 27 Sep 2008 19:57:34 GMT"}], "update_date": "2008-09-30", "authors_parsed": [["Smith", "Adam", ""]]}, {"id": "0809.4882", "submitter": "Aleksandrs Slivkins", "authors": "Robert Kleinberg, Aleksandrs Slivkins and Eli Upfal", "title": "Multi-Armed Bandits in Metric Spaces", "comments": "16 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-armed bandit problem, an online algorithm chooses from a set of\nstrategies in a sequence of trials so as to maximize the total payoff of the\nchosen strategies. While the performance of bandit algorithms with a small\nfinite strategy set is quite well understood, bandit problems with large\nstrategy sets are still a topic of very active investigation, motivated by\npractical applications such as online auctions and web advertisement. The goal\nof such research is to identify broad and natural classes of strategy sets and\npayoff functions which enable the design of efficient solutions. In this work\nwe study a very general setting for the multi-armed bandit problem in which the\nstrategies form a metric space, and the payoff function satisfies a Lipschitz\ncondition with respect to the metric. We refer to this problem as the\n\"Lipschitz MAB problem\". We present a complete solution for the multi-armed\nproblem in this setting. That is, for every metric space (L,X) we define an\nisometry invariant which bounds from below the performance of Lipschitz MAB\nalgorithms for X, and we present an algorithm which comes arbitrarily close to\nmeeting this bound. Furthermore, our technique gives even better results for\nbenign payoff functions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Sep 2008 01:58:13 GMT"}], "update_date": "2008-09-30", "authors_parsed": [["Kleinberg", "Robert", ""], ["Slivkins", "Aleksandrs", ""], ["Upfal", "Eli", ""]]}]