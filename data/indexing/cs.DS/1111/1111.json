[{"id": "1111.0194", "submitter": "Sebastian U. Stich", "authors": "Sebastian U. Stich and Christian L. M\\\"uller and Bernd G\\\"artner", "title": "Optimization of Convex Functions with Random Pursuit", "comments": "35 pages, 5 figures, 8 algorithms, 21 tables, submitted to journal\n  The appendix contains additional supporting online material, not contained in\n  the journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider unconstrained randomized optimization of convex objective\nfunctions. We analyze the Random Pursuit algorithm, which iteratively computes\nan approximate solution to the optimization problem by repeated optimization\nover a randomly chosen one-dimensional subspace. This randomized method only\nuses zeroth-order information about the objective function and does not need\nany problem-specific parametrization. We prove convergence and give convergence\nrates for smooth objectives assuming that the one-dimensional optimization can\nbe solved exactly or approximately by an oracle. A convenient property of\nRandom Pursuit is its invariance under strictly monotone transformations of the\nobjective function. It thus enjoys identical convergence behavior on a wider\nfunction class. To support the theoretical results we present extensive\nnumerical performance results of Random Pursuit, two gradient-free algorithms\nrecently proposed by Nesterov, and a classical adaptive step-size random search\nscheme. We also present an accelerated heuristic version of the Random Pursuit\nalgorithm which significantly improves standard Random Pursuit on all numerical\nbenchmark problems. A general comparison of the experimental results reveals\nthat (i) standard Random Pursuit is effective on strongly convex functions with\nmoderate condition number, and (ii) the accelerated scheme is comparable to\nNesterov's fast gradient method and outperforms adaptive step-size strategies.\n  The appendix contains additional supporting online material.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2011 13:08:15 GMT"}, {"version": "v2", "created": "Thu, 24 May 2012 19:00:09 GMT"}], "update_date": "2012-05-25", "authors_parsed": [["Stich", "Sebastian U.", ""], ["M\u00fcller", "Christian L.", ""], ["G\u00e4rtner", "Bernd", ""]]}, {"id": "1111.0253", "submitter": "Ankur Moitra", "authors": "Noga Alon, Ankur Moitra, Benny Sudakov", "title": "Nearly Complete Graphs Decomposable into Large Induced Matchings and\n  their Applications", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two constructions of (very) dense graphs which are edge disjoint\nunions of large {\\em induced} matchings. The first construction exhibits graphs\non $N$ vertices with ${N \\choose 2}-o(N^2)$ edges, which can be decomposed into\npairwise disjoint induced matchings, each of size $N^{1-o(1)}$. The second\nconstruction provides a covering of all edges of the complete graph $K_N$ by\ntwo graphs, each being the edge disjoint union of at most $N^{2-\\delta}$\ninduced matchings, where $\\delta > 0.058$. This disproves (in a strong form) a\nconjecture of Meshulam, substantially improves a result of Birk, Linial and\nMeshulam on communicating over a shared channel, and (slightly) extends the\nanalysis of H{\\aa}stad and Wigderson of the graph test of Samorodnitsky and\nTrevisan for linearity. Additionally, our constructions settle a combinatorial\nquestion of Vempala regarding a candidate rounding scheme for the directed\nSteiner tree problem.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2011 17:38:12 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2011 01:45:46 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Alon", "Noga", ""], ["Moitra", "Ankur", ""], ["Sudakov", "Benny", ""]]}, {"id": "1111.0321", "submitter": "Yoann Dieudonn\\'e", "authors": "Yoann Dieudonn\\'e and Andrzej Pelc", "title": "Anonymous Meeting in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A team consisting of an unknown number of mobile agents, starting from\ndifferent nodes of an unknown network, possibly at different times, have to\nmeet at the same node. Agents are anonymous (identical), execute the same\ndeterministic algorithm and move in synchronous rounds along links of the\nnetwork. Which configurations are gatherable and how to gather all of them\ndeterministically by the same algorithm?\n  We give a complete solution of this gathering problem in arbitrary networks.\nWe characterize all gatherable configurations and give two universal\ndeterministic gathering algorithms, i.e., algorithms that gather all gatherable\nconfigurations. The first algorithm works under the assumption that an upper\nbound n on the size of the network is known. In this case our algorithm\nguarantees gathering with detection, i.e., the existence of a round for any\ngatherable configuration, such that all agents are at the same node and all\ndeclare that gathering is accomplished. If no upper bound on the size of the\nnetwork is known, we show that a universal algorithm for gathering with\ndetection does not exist. Hence, for this harder scenario, we construct a\nsecond universal gathering algorithm, which guarantees that, for any gatherable\nconfiguration, all agents eventually get to one node and stop, although they\ncannot tell if gathering is over. The time of the first algorithm is polynomial\nin the upper bound n on the size of the network, and the time of the second\nalgorithm is polynomial in the (unknown) size itself.\n  Our results have an important consequence for the leader election problem for\nanonymous agents in arbitrary graphs. For anonymous agents in graphs, leader\nelection turns out to be equivalent to gathering with detection. Hence, as a\nby-product, we obtain a complete solution of the leader election problem for\nanonymous agents in arbitrary graphs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2011 21:18:10 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2012 19:44:25 GMT"}, {"version": "v3", "created": "Sun, 13 Mar 2016 09:49:08 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Dieudonn\u00e9", "Yoann", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1111.0376", "submitter": "Christina Boucher", "authors": "Christina Boucher and Christine Lo and Daniel Lokshtanov", "title": "Outlier Detection for DNA Fragment Assembly", "comments": "29 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $n$ length-$\\ell$ strings $S =\\{s_1, ..., s_n\\}$ over a constant size\nalphabet $\\Sigma$ together with parameters $d$ and $k$, the objective in the\n{\\em Consensus String with Outliers} problem is to find a subset $S^*$ of $S$\nof size $n-k$ and a string $s$ such that $\\sum_{s_i \\in S^*} d(s_i, s) \\leq d$.\nHere $d(x, y)$ denotes the Hamming distance between the two strings $x$ and\n$y$. We prove\n  1. a variant of {\\em Consensus String with Outliers} where the number of\noutliers $k$ is fixed and the objective is to minimize the total distance\n$\\sum_{s_i \\in S^*} d(s_i, s)$ admits a simple PTAS. (ii) Under the natural\nassumption that the number of outliers $k$ is small, the PTAS for the distance\nminimization version of {\\em Consensus String with Outliers} performs well. In\nparticular, as long as $k\\leq cn$ for a fixed constant $c < 1$, the algorithm\nprovides a $(1+\\epsilon)$-approximate solution in time\n$f(1/\\epsilon)(n\\ell)^{O(1)}$ and thus, is an EPTAS.\n  2. In order to improve the PTAS for {\\em Consensus String with Outliers} to\nan EPTAS, the assumption that $k$ is small is necessary. Specifically, when $k$\nis allowed to be arbitrary the {\\em Consensus String with Outliers} problem\ndoes not admit an EPTAS unless FPT=W[1]. This hardness result holds even for\nbinary alphabets.\n  3. The decision version of {\\em Consensus String with Outliers} is fixed\nparameter tractable when parameterized by $\\frac{d}{n-k}$. and thus, also when\nparameterized by just $d$.\n  To the best of our knowledge, {\\em Consensus String with Outliers} is the\nfirst problem that admits a PTAS, and is fixed parameter tractable when\nparameterized by the value of the objective function but does not admit an\nEPTAS under plausible complexity assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 03:13:55 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2011 00:33:48 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Boucher", "Christina", ""], ["Lo", "Christine", ""], ["Lokshtanov", "Daniel", ""]]}, {"id": "1111.0434", "submitter": "Laurent Bulteau", "authors": "Laurent Bulteau, Guillaume Fertin, Irena Rusu", "title": "Pancake Flipping is Hard", "comments": "Corrected references", "journal-ref": null, "doi": "10.1007/978-3-642-32589-2_24", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pancake Flipping is the problem of sorting a stack of pancakes of different\nsizes (that is, a permutation), when the only allowed operation is to insert a\nspatula anywhere in the stack and to flip the pancakes above it (that is, to\nperform a prefix reversal). In the burnt variant, one side of each pancake is\nmarked as burnt, and it is required to finish with all pancakes having the\nburnt side down. Computing the optimal scenario for any stack of pancakes and\ndetermining the worst-case stack for any stack size have been challenges over\nmore than three decades. Beyond being an intriguing combinatorial problem in\nitself, it also yields applications, e.g. in parallel computing and\ncomputational biology. In this paper, we show that the Pancake Flipping\nproblem, in its original (unburnt) variant, is NP-hard, thus answering the\nlong-standing question of its computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 09:30:20 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2011 09:53:22 GMT"}], "update_date": "2012-09-05", "authors_parsed": [["Bulteau", "Laurent", ""], ["Fertin", "Guillaume", ""], ["Rusu", "Irena", ""]]}, {"id": "1111.0499", "submitter": "Rafael Grimson Dr.", "authors": "Rafael Grimson, Joos Heintz, Bart Kuijpers", "title": "Evaluating geometric queries using few arithmetic operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\cp:=(P_1,...,P_s)$ be a given family of $n$-variate polynomials with\ninteger coefficients and suppose that the degrees and logarithmic heights of\nthese polynomials are bounded by $d$ and $h$, respectively. Suppose furthermore\nthat for each $1\\leq i\\leq s$ the polynomial $P_i$ can be evaluated using $L$\narithmetic operations (additions, subtractions, multiplications and the\nconstants 0 and 1). Assume that the family $\\cp$ is in a suitable sense\n\\emph{generic}. We construct a database $\\cal D$, supported by an algebraic\ncomputation tree, such that for each $x\\in [0,1]^n$ the query for the signs of\n$P_1(x),...,P_s(x)$ can be answered using $h d^{\\cO(n^2)}$ comparisons and $nL$\narithmetic operations between real numbers. The arithmetic-geometric tools\ndeveloped for the construction of $\\cal D$ are then employed to exhibit example\nclasses of systems of $n$ polynomial equations in $n$ unknowns whose\nconsistency may be checked using only few arithmetic operations, admitting\nhowever an exponential number of comparisons.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2011 17:57:20 GMT"}], "update_date": "2011-11-03", "authors_parsed": [["Grimson", "Rafael", ""], ["Heintz", "Joos", ""], ["Kuijpers", "Bart", ""]]}, {"id": "1111.0567", "submitter": "Sivakumar Rathinam", "authors": "Jungyun Bae and Sivakumar Rathinam", "title": "A Primal Dual Algorithm for a Heterogeneous Traveling Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.RO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surveillance applications require a collection of heterogeneous vehicles to\nvisit a set of targets. In this article, we consider a fundamental routing\nproblem that arises in these applications involving two vehicles. Specifically,\nwe consider a routing problem where there are two heterogeneous vehicles that\nstart from distinct initial locations, and a set of targets. The objective is\nto find a tour for each vehicle such that each of the targets is visited at\nleast once by a vehicle and the sum of the distances traveled by the vehicles\nis a minimum. We present a primal-dual algorithm for a variant of this routing\nproblem that provides an approximation ratio of 2.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 17:25:02 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2013 06:06:32 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Bae", "Jungyun", ""], ["Rathinam", "Sivakumar", ""]]}, {"id": "1111.0570", "submitter": "Marcin Pilipczuk", "authors": "Marek Cygan and Stefan Kratsch and Marcin Pilipczuk and Micha{\\l}\n  Pilipczuk and Magnus Wahlstr\\\"om", "title": "Clique cover and graph separation: New incompressibility results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of kernelization studies polynomial-time preprocessing routines for\nhard problems in the framework of parameterized complexity. Although a\nframework for proving kernelization lower bounds has been discovered in 2008\nand successfully applied multiple times over the last three years, establishing\nkernelization complexity of many important problems remains open. In this paper\nwe show that, unless NP is a subset of coNP/poly and the polynomial hierarchy\ncollapses up to its third level, the following parameterized problems do not\nadmit a polynomial-time preprocessing algorithm that reduces the size of an\ninstance to polynomial in the parameter:\n  - EDGE CLIQUE COVER, parameterized by the number of cliques,\n  - DIRECTED EDGE/VERTEX MULTIWAY CUT, parameterized by the size of the cutset,\neven in the case of two terminals,\n  - EDGE/VERTEX MULTICUT, parameterized by the size of the cutset, and\n  - k-WAY CUT, parameterized by the size of the cutset.\n  The existence of a polynomial kernelization for EDGE CLIQUE COVER was a\nseasoned veteran in open problem sessions. Furthermore, our results complement\nvery recent developments in designing parameterized algorithms for cut problems\nby Marx and Razgon [STOC'11], Bousquet et al. [STOC'11], Kawarabayashi and\nThorup [FOCS'11] and Chitnis et al. [SODA'12].\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 17:28:08 GMT"}], "update_date": "2011-11-03", "authors_parsed": [["Cygan", "Marek", ""], ["Kratsch", "Stefan", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""], ["Wahlstr\u00f6m", "Magnus", ""]]}, {"id": "1111.0623", "submitter": "Moritz Hardt", "authors": "Moritz Hardt and Aaron Roth", "title": "Beating Randomized Response on Incoherent Matrices", "comments": null, "journal-ref": null, "doi": "10.1145/2213977.2214088", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing accurate low rank approximations of large matrices is a fundamental\ndata mining task. In many applications however the matrix contains sensitive\ninformation about individuals. In such case we would like to release a low rank\napproximation that satisfies a strong privacy guarantee such as differential\nprivacy. Unfortunately, to date the best known algorithm for this task that\nsatisfies differential privacy is based on naive input perturbation or\nrandomized response: Each entry of the matrix is perturbed independently by a\nsufficiently large random noise variable, a low rank approximation is then\ncomputed on the resulting matrix.\n  We give (the first) significant improvements in accuracy over randomized\nresponse under the natural and necessary assumption that the matrix has low\ncoherence. Our algorithm is also very efficient and finds a constant rank\napproximation of an m x n matrix in time O(mn). Note that even generating the\nnoise matrix required for randomized response already requires time O(mn).\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 19:49:50 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Hardt", "Moritz", ""], ["Roth", "Aaron", ""]]}, {"id": "1111.0627", "submitter": "EPTCS", "authors": "Ji\\v{r}\\'i Barnat, Petr Bauch, Lubo\\v{s} Brim, Milan \\v{C}e\\v{s}ka", "title": "Computing Optimal Cycle Mean in Parallel on CUDA", "comments": "In Proceedings PDMC 2011, arXiv:1111.0064", "journal-ref": "EPTCS 72, 2011, pp. 68-83", "doi": "10.4204/EPTCS.72.8", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation of optimal cycle mean in a directed weighted graph has many\napplications in program analysis, performance verification in particular. In\nthis paper we propose a data-parallel algorithmic solution to the problem and\nshow how the computation of optimal cycle mean can be efficiently accelerated\nby means of CUDA technology. We show how the problem of computation of optimal\ncycle mean is decomposed into a sequence of data-parallel graph computation\nprimitives and show how these primitives can be implemented and optimized for\nCUDA computation. Finally, we report a fivefold experimental speed up on graphs\nrepresenting models of distributed systems when compared to best sequential\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 03:04:48 GMT"}], "update_date": "2011-11-04", "authors_parsed": [["Barnat", "Ji\u0159\u00ed", ""], ["Bauch", "Petr", ""], ["Brim", "Lubo\u0161", ""], ["\u010ce\u0161ka", "Milan", ""]]}, {"id": "1111.0753", "submitter": "Sourav Dutta", "authors": "Sourav Dutta, Souvik Bhattacherjee and Ankur Narang", "title": "Towards \"Intelligent Compression\" in Streams: A Biased Reservoir\n  Sampling based Bloom Filter Approach", "comments": "11 pages, 8 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": "IBM TechReport RI11015", "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosion of information stored world-wide,data intensive computing\nhas become a central area of research.Efficient management and processing of\nthis massively exponential amount of data from diverse sources,such as\ntelecommunication call data records,online transaction records,etc.,has become\na necessity.Removing redundancy from such huge(multi-billion records) datasets\nresulting in resource and compute efficiency for downstream processing\nconstitutes an important area of study. \"Intelligent compression\" or\ndeduplication in streaming scenarios,for precise identification and elimination\nof duplicates from the unbounded datastream is a greater challenge given the\nrealtime nature of data arrival.Stable Bloom Filters(SBF) address this problem\nto a certain extent.However,SBF suffers from a high false negative rate(FNR)\nand slow convergence rate,thereby rendering it inefficient for applications\nwith low FNR tolerance.In this paper, we present a novel Reservoir Sampling\nbased Bloom Filter,(RSBF) data structure,based on the combined concepts of\nreservoir sampling and Bloom filters for approximate detection of duplicates in\ndata streams.Using detailed theoretical analysis we prove analytical bounds on\nits false positive rate(FPR),false negative rate(FNR) and convergence rates\nwith low memory requirements.We show that RSBF offers the currently lowest FN\nand convergence rates,and are better than those of SBF while using the same\nmemory.Using empirical analysis on real-world datasets(3 million records) and\nsynthetic datasets with around 1 billion records,we demonstrate upto 2x\nimprovement in FNR with better convergence rates as compared to SBF,while\nexhibiting comparable FPR.To the best of our knowledge,this is the first\nattempt to integrate reservoir sampling method with Bloom filters for\ndeduplication in streaming scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 08:45:44 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Dutta", "Sourav", ""], ["Bhattacherjee", "Souvik", ""], ["Narang", "Ankur", ""]]}, {"id": "1111.0762", "submitter": "Sourav Dutta", "authors": "Ankur Narang, Sourav Dutta and Souvik Bhattacherjee", "title": "Multidimensional Balanced Allocation for Multiple Choice & (1 + Beta)\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": "RI11018", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allocation of balls into bins is a well studied abstraction for load\nbalancing problems.The literature hosts numerous results for sequential(single\ndimensional) allocation case when m balls are thrown into n bins. In this paper\nwe study the symmetric multiple choice process for both unweighted and weighted\nballs as well as for both multidimensional and scalar models.Additionally,we\npresent the results on bounds on gap for (1+beta) choice process with\nmultidimensional balls and bins. We show that for the symmetric d choice\nprocess and with m=O(n), the upper bound on the gap is O(lnln(n)) w.h.p.This\nupper bound on the gap is within D=f factor of the lower bound. This is the\nfirst such tight result.For the general case of m>>n the expected gap is\nbounded by O(lnln(n)).For variable f and non-uniform distribution of the\npopulated dimensions,we obtain the upper bound on the expected gap as\nO(log(n)).\n  Further,for the multiple round parallel balls and bins,we show that the gap\nis also bounded by O(loglog(n)) for m=O(n).The same bound holds for the\nexpected gap when m>>n. Our analysis also has strong implications in the\nsequential scalar case.For the weighted balls and bins and general case m>>n,we\nshow that the upper bound on the expected gap is O(log(n)) which improves upon\nthe best prior bound of n^c.Moreover,we show that for the (1 + beta) choice\nprocess and m=O(n) the upper bound(assuming uniform distribution of f populated\ndimensions over D total dimensions) on the gap is O(log(n)/beta),which is\nwithin D=f factor of the lower bound.For fixed f with non-uniform distribution\nand for random f with Binomial distribution the expected gap remains\nO(log(n)/beta) independent of the total number of balls thrown. This is the\nfirst such tight result for (1 +beta) paradigm with multidimensional balls and\nbins.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 09:14:41 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2011 09:59:17 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Narang", "Ankur", ""], ["Dutta", "Sourav", ""], ["Bhattacherjee", "Souvik", ""]]}, {"id": "1111.0773", "submitter": "Matthias Hellwig", "authors": "Susanne Albers and Matthias Hellwig", "title": "On the Value of Job Migration in Online Makespan Minimization", "comments": "Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Makespan minimization on identical parallel machines is a classical\nscheduling problem. We consider the online scenario where a sequence of $n$\njobs has to be scheduled non-preemptively on $m$ machines so as to minimize the\nmaximum completion time of any job. The best competitive ratio that can be\nachieved by deterministic online algorithms is in the range $[1.88,1.9201]$.\nCurrently no randomized online algorithm with a smaller competitiveness is\nknown, for general $m$.\n  In this paper we explore the power of job migration, i.e.\\ an online\nscheduler is allowed to perform a limited number of job reassignments.\nMigration is a common technique used in theory and practice to balance load in\nparallel processing environments. As our main result we settle the performance\nthat can be achieved by deterministic online algorithms. We develop an\nalgorithm that is $\\alpha_m$-competitive, for any $m\\geq 2$, where $\\alpha_m$\nis the solution of a certain equation. For $m=2$, $\\alpha_2 = 4/3$ and\n$\\lim_{m\\rightarrow \\infty} \\alpha_m = W_{-1}(-1/e^2)/(1+ W_{-1}(-1/e^2))\n\\approx 1.4659$. Here $W_{-1}$ is the lower branch of the Lambert $W$ function.\nFor $m\\geq 11$, the algorithm uses at most $7m$ migration operations. For\nsmaller $m$, $8m$ to $10m$ operations may be performed. We complement this\nresult by a matching lower bound: No online algorithm that uses $o(n)$ job\nmigrations can achieve a competitive ratio smaller than $\\alpha_m$. We finally\ntrade performance for migrations. We give a family of algorithms that is\n$c$-competitive, for any $5/3\\leq c \\leq 2$. For $c= 5/3$, the strategy uses at\nmost $4m$ job migrations. For $c=1.75$, at most $2.5m$ migrations are used.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 10:27:20 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2012 17:13:31 GMT"}], "update_date": "2012-03-09", "authors_parsed": [["Albers", "Susanne", ""], ["Hellwig", "Matthias", ""]]}, {"id": "1111.0801", "submitter": "Sourav Dutta", "authors": "Sourav Dutta, Souvik Bhattacherjee and Ankur Narang", "title": "Perfectly Balanced Allocation With Estimated Average Using Expected\n  Constant Retries", "comments": null, "journal-ref": null, "doi": null, "report-no": "RI11023", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balanced allocation of online balls-into-bins has long been an active area of\nresearch for efficient load balancing and hashing applications.There exists a\nlarge number of results in this domain for different settings, such as parallel\nallocations~\\cite{parallel}, multi-dimensional allocations~\\cite{multi},\nweighted balls~\\cite{weight} etc. For sequential multi-choice allocation, where\n$m$ balls are thrown into $n$ bins with each ball choosing $d$ (constant) bins\nindependently uniformly at random, the maximum load of a bin is $O(\\log \\log n)\n+ m/n$ with high probability~\\cite{heavily_load}. This offers the current best\nknown allocation scheme. However, for $d = \\Theta(\\log n)$, the gap reduces to\n$O(1)$~\\cite{soda08}.A similar constant gap bound has been established for\nparallel allocations with $O(\\log ^*n)$ communication rounds~\\cite{lenzen}.\n  In this paper we propose a novel multi-choice allocation algorithm,\n\\emph{Improved D-choice with Estimated Average} ($IDEA$) achieving a constant\ngap with a high probability for the sequential single-dimensional online\nallocation problem with constant $d$. We achieve a maximum load of $\\lceil m/n\n\\rceil$ with high probability for constant $d$ choice scheme with\n\\emph{expected} constant number of retries or rounds per ball. We also show\nthat the bound holds even for an arbitrary large number of balls, $m>>n$.\nFurther, we generalize this result to (i)~the weighted case, where balls have\nweights drawn from an arbitrary weight distribution with finite variance,\n(ii)~multi-dimensional setting, where balls have $D$ dimensions with $f$\nrandomly and uniformly chosen filled dimension for $m=n$, and (iii)~the\nparallel case, where $n$ balls arrive and are placed parallely in the bins. We\nshow that the gap in these case is also a constant w.h.p. (independent of $m$)\nfor constant value of $d$ with expected constant number of retries per ball.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 11:26:28 GMT"}, {"version": "v2", "created": "Sun, 27 Nov 2011 21:25:36 GMT"}, {"version": "v3", "created": "Thu, 29 Dec 2011 11:33:49 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Dutta", "Sourav", ""], ["Bhattacherjee", "Souvik", ""], ["Narang", "Ankur", ""]]}, {"id": "1111.0867", "submitter": "Ton Kloks", "authors": "Ton Kloks, Sheung-Hung Poon, Feng-Ren Tsai and Yue-Li Wang", "title": "The black-and-white coloring problem on distance hereditary graphs and\n  strongly chordal graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph G and integers b and w. The black-and-white coloring problem\nasks if there exist disjoint sets of vertices B and W with |B|=b and |W|=w such\nthat no vertex in B is adjacent to any vertex in W. In this paper we show that\nthe problem is polynomial when restricted to cographs, distance-hereditary\ngraphs, interval graphs and strongly chordal graphs. We show that the problem\nis NP-complete on splitgraphs.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 15:01:07 GMT"}], "update_date": "2011-11-07", "authors_parsed": [["Kloks", "Ton", ""], ["Poon", "Sheung-Hung", ""], ["Tsai", "Feng-Ren", ""], ["Wang", "Yue-Li", ""]]}, {"id": "1111.0897", "submitter": "Liu Yang", "authors": "Maria-Florina Balcan and Eric Blais and Avrim Blum and Liu Yang", "title": "Active Property Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the motivations for property testing of boolean functions is the idea\nthat testing can serve as a preprocessing step before learning. However, in\nmost machine learning applications, it is not possible to request for labels of\nfictitious examples constructed by the algorithm. Instead, the dominant query\nparadigm in applied machine learning, called active learning, is one where the\nalgorithm may query for labels, but only on points in a given polynomial-sized\n(unlabeled) sample, drawn from some underlying distribution D. In this work, we\nbring this well-studied model in learning to the domain of testing.\n  We show that for a number of important properties, testing can still yield\nsubstantial benefits in this setting. This includes testing unions of\nintervals, testing linear separators, and testing various assumptions used in\nsemi-supervised learning. In addition to these specific results, we also\ndevelop a general notion of the testing dimension of a given property with\nrespect to a given distribution. We show this dimension characterizes (up to\nconstant factors) the intrinsic number of label requests needed to test that\nproperty. We develop such notions for both the active and passive testing\nmodels. We then use these dimensions to prove a number of lower bounds,\nincluding for linear separators and the class of dictator functions.\n  Our results show that testing can be a powerful tool in realistic models for\nlearning, and further that active testing exhibits an interesting and rich\nstructure. Our work in addition brings together tools from a range of areas\nincluding U-statistics, noise-sensitivity, self-correction, and spectral\nanalysis of random matrices, and develops new tools that may be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 16:06:35 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2012 17:48:41 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Blais", "Eric", ""], ["Blum", "Avrim", ""], ["Yang", "Liu", ""]]}, {"id": "1111.0934", "submitter": "Marcus Ritt", "authors": "Marcus Ritt and Alysson M. Costa", "title": "Improved integer programming models for simple assembly line balancing\n  and related problems", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stronger formulation of the precedence constraints and the\nstation limits for the simple assembly line balancing problem. The linear\nrelaxation of the improved integer program theoretically dominates all previous\nformulations using impulse variables, and produces solutions of significantly\nbetter quality in practice. The improved formulation can be used to strengthen\nrelated problems with similar restrictions. We demonstrate their effectiveness\non the U-shaped assembly line balancing problem and on the bin packing problem\nwith precedence constraints.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 18:01:57 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2015 19:56:19 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Ritt", "Marcus", ""], ["Costa", "Alysson M.", ""]]}, {"id": "1111.0952", "submitter": "Ankur Moitra", "authors": "Sanjeev Arora, Rong Ge, Ravi Kannan, Ankur Moitra", "title": "Computing a Nonnegative Matrix Factorization -- Provably", "comments": "29 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Nonnegative Matrix Factorization (NMF) problem we are given an $n\n\\times m$ nonnegative matrix $M$ and an integer $r > 0$. Our goal is to express\n$M$ as $A W$ where $A$ and $W$ are nonnegative matrices of size $n \\times r$\nand $r \\times m$ respectively. In some applications, it makes sense to ask\ninstead for the product $AW$ to approximate $M$ -- i.e. (approximately)\nminimize $\\norm{M - AW}_F$ where $\\norm{}_F$ denotes the Frobenius norm; we\nrefer to this as Approximate NMF. This problem has a rich history spanning\nquantum mechanics, probability theory, data analysis, polyhedral combinatorics,\ncommunication complexity, demography, chemometrics, etc. In the past decade NMF\nhas become enormously popular in machine learning, where $A$ and $W$ are\ncomputed using a variety of local search heuristics. Vavasis proved that this\nproblem is NP-complete. We initiate a study of when this problem is solvable in\npolynomial time:\n  1. We give a polynomial-time algorithm for exact and approximate NMF for\nevery constant $r$. Indeed NMF is most interesting in applications precisely\nwhen $r$ is small.\n  2. We complement this with a hardness result, that if exact NMF can be solved\nin time $(nm)^{o(r)}$, 3-SAT has a sub-exponential time algorithm. This rules\nout substantial improvements to the above algorithm.\n  3. We give an algorithm that runs in time polynomial in $n$, $m$ and $r$\nunder the separablity condition identified by Donoho and Stodden in 2003. The\nalgorithm may be practical since it is simple and noise tolerant (under benign\nassumptions). Separability is believed to hold in many practical settings.\n  To the best of our knowledge, this last result is the first example of a\npolynomial-time algorithm that provably works under a non-trivial condition on\nthe input and we believe that this will be an interesting and important\ndirection for future work.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 19:15:56 GMT"}], "update_date": "2011-11-04", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Kannan", "Ravi", ""], ["Moitra", "Ankur", ""]]}, {"id": "1111.0965", "submitter": "Anand Louis", "authors": "Anand Louis, Prasad Raghavendra, Prasad Tetali, Santosh Vempala", "title": "Many Sparse Cuts via Higher Eigenvalues", "comments": null, "journal-ref": null, "doi": "10.1145/2213977.2214079", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cheeger's fundamental inequality states that any edge-weighted graph has a\nvertex subset $S$ such that its expansion (a.k.a. conductance) is bounded as\nfollows: \\[ \\phi(S) \\defeq \\frac{w(S,\\bar{S})}{\\min \\set{w(S), w(\\bar{S})}}\n\\leq 2\\sqrt{\\lambda_2} \\] where $w$ is the total edge weight of a subset or a\ncut and $\\lambda_2$ is the second smallest eigenvalue of the normalized\nLaplacian of the graph. Here we prove the following natural generalization: for\nany integer $k \\in [n]$, there exist $ck$ disjoint subsets $S_1, ..., S_{ck}$,\nsuch that \\[ \\max_i \\phi(S_i) \\leq C \\sqrt{\\lambda_{k} \\log k} \\] where\n$\\lambda_i$ is the $i^{th}$ smallest eigenvalue of the normalized Laplacian and\n$c<1,C>0$ are suitable absolute constants. Our proof is via a polynomial-time\nalgorithm to find such subsets, consisting of a spectral projection and a\nrandomized rounding. As a consequence, we get the same upper bound for the\nsmall set expansion problem, namely for any $k$, there is a subset $S$ whose\nweight is at most a $\\bigO(1/k)$ fraction of the total weight and $\\phi(S) \\le\nC \\sqrt{\\lambda_k \\log k}$. Both results are the best possible up to constant\nfactors.\n  The underlying algorithmic problem, namely finding $k$ subsets such that the\nmaximum expansion is minimized, besides extending sparse cuts to more than one\nsubset, appears to be a natural clustering problem in its own right.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 19:57:26 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Louis", "Anand", ""], ["Raghavendra", "Prasad", ""], ["Tetali", "Prasad", ""], ["Vempala", "Santosh", ""]]}, {"id": "1111.1055", "submitter": "James Lee", "authors": "James R. Lee and Shayan Oveis Gharan and Luca Trevisan", "title": "Multi-way spectral partitioning and higher-order Cheeger inequalities", "comments": "Misc. edits, added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.DS math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic fact in spectral graph theory is that the number of connected\ncomponents in an undirected graph is equal to the multiplicity of the\neigenvalue zero in the Laplacian matrix of the graph. In particular, the graph\nis disconnected if and only if there are at least two eigenvalues equal to\nzero. Cheeger's inequality and its variants provide an approximate version of\nthe latter fact; they state that a graph has a sparse cut if and only if there\nare at least two eigenvalues that are close to zero.\n  It has been conjectured that an analogous characterization holds for higher\nmultiplicities, i.e., there are $k$ eigenvalues close to zero if and only if\nthe vertex set can be partitioned into $k$ subsets, each defining a sparse cut.\nWe resolve this conjecture. Our result provides a theoretical justification for\nclustering algorithms that use the bottom $k$ eigenvectors to embed the\nvertices into $\\mathbb R^k$, and then apply geometric considerations to the\nembedding.\n  We also show that these techniques yield a nearly optimal tradeoff between\nthe expansion of sets of size $\\approx n/k$, and the $k$th smallest eigenvalue\nof the normalized Laplacian matrix, denoted $\\lambda_k$. In particular, we show\nthat in every graph there is a set of size at most $2n/k$ which has expansion\nat most $O(\\sqrt{\\lambda_k \\log k})$. This bound is tight, up to constant\nfactors, for the \"noisy hypercube\" graphs.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2011 06:57:56 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2011 01:19:49 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2012 09:48:48 GMT"}, {"version": "v4", "created": "Sat, 26 Jan 2013 11:17:37 GMT"}, {"version": "v5", "created": "Mon, 27 Jan 2014 05:00:04 GMT"}, {"version": "v6", "created": "Fri, 21 Nov 2014 17:28:58 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["Lee", "James R.", ""], ["Gharan", "Shayan Oveis", ""], ["Trevisan", "Luca", ""]]}, {"id": "1111.1086", "submitter": "Aman Chadha Mr.", "authors": "Aman Chadha, Divya Jyoti and M. G. Bhatia", "title": "Design and Simulation of an 8-bit Dedicated Processor for calculating\n  the Sine and Cosine of an Angle using the CORDIC Algorithm", "comments": "CORDIC, VHDL, dedicated processor, datapath, finite state machine", "journal-ref": "Proceedings of the 2011 IEEE International Conference on\n  Computational Intelligence and Computing Research (ICCIC); IEEE Xplore:\n  CFB1120J-ART; ISBN: 978-1-61284-694-1; Print Version: CFB1120J-PRT; ISBN:\n  978-1-61284-766-5", "doi": null, "report-no": null, "categories": "cs.AR cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design and simulation of an 8-bit dedicated\nprocessor for calculating the Sine and Cosine of an Angle using CORDIC\nAlgorithm (COordinate Rotation DIgital Computer), a simple and efficient\nalgorithm to calculate hyperbolic and trigonometric functions. We have proposed\na dedicated processor system, modeled by writing appropriate programs in VHDL,\nfor calculating the Sine and Cosine of an angle. System simulation was carried\nout using ModelSim 6.3f and Xilinx ISE Design Suite 12.3. A maximum frequency\nof 81.353 MHz was reached with a minimum period of 12.292 ns. 126 (3%) slices\nwere used. This paper attempts to survey the existing CORDIC algorithm with an\neye towards implementation in Field Programmable Gate Arrays (FPGAs). A brief\ndescription of the theory behind the algorithm and the derivation of the Sine\nand Cosine of an angle using the CORDIC algorithm has been presented. The\nsystem can be implemented using Spartan3 XC3S400 with Xilinx ISE 12.3 and VHDL.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2011 10:27:24 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Chadha", "Aman", ""], ["Jyoti", "Divya", ""], ["Bhatia", "M. G.", ""]]}, {"id": "1111.1109", "submitter": "D\\'aniel Marx", "authors": "Martin Grohe and D\\'aniel Marx", "title": "Structure Theorem and Isomorphism Test for Graphs with Excluded\n  Topological Subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the structure theorem of Robertson and Seymour for graphs\nexcluding a fixed graph $H$ as a minor to graphs excluding $H$ as a topological\nsubgraph. We prove that for a fixed $H$, every graph excluding $H$ as a\ntopological subgraph has a tree decomposition where each part is either \"almost\nembeddable\" to a fixed surface or has bounded degree with the exception of a\nbounded number of vertices. Furthermore, we prove that such a decomposition is\ncomputable by an algorithm that is fixed-parameter tractable with parameter\n$|H|$.\n  We present two algorithmic applications of our structure theorem. To\nillustrate the mechanics of a \"typical\" application of the structure theorem,\nwe show that on graphs excluding $H$ as a topological subgraph, Partial\nDominating Set (find $k$ vertices whose closed neighborhood has maximum size)\ncan be solved in time $f(H,k)\\cdot n^{O(1)}$ time. More significantly, we show\nthat on graphs excluding $H$ as a topological subgraph, Graph Isomorphism can\nbe solved in time $n^{f(H)}$. This result unifies and generalizes two\npreviously known important polynomial-time solvable cases of Graph Isomorphism:\nbounded-degree graphs and $H$-minor free graphs. The proof of this result needs\na generalization of our structure theorem to the context of invariant treelike\ndecomposition.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2011 12:27:52 GMT"}, {"version": "v2", "created": "Thu, 13 Nov 2014 11:12:24 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Grohe", "Martin", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "1111.1355", "submitter": "Travis Gagie", "authors": "Travis Gagie and Juha K\\\"arkk\\\"ainen and Yakov Nekrich and Simon J.\n  Puglisi", "title": "A Compressed Self-Index for Genomic Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in DNA sequencing technology will soon result in databases of\nthousands of genomes. Within a species, individuals' genomes are almost exact\ncopies of each other; e.g., any two human genomes are 99.9% the same. Relative\nLempel-Ziv (RLZ) compression takes advantage of this property: it stores the\nfirst genome uncompressed or as an FM-index, then compresses the other genomes\nwith a variant of LZ77 that copies phrases only from the first genome. RLZ\nachieves good compression and supports fast random access; in this paper we\nshow how to support fast search as well, thus obtaining an efficient compressed\nself-index.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2011 21:53:33 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Gagie", "Travis", ""], ["K\u00e4rkk\u00e4inen", "Juha", ""], ["Nekrich", "Yakov", ""], ["Puglisi", "Simon J.", ""]]}, {"id": "1111.1464", "submitter": "Charl Ras", "authors": "Marcus N. Brazil, Charl J. Ras, Konrad J. Swanepoel, Doreen A. Thomas", "title": "Generalised k-Steiner Tree Problems in Normed Planes", "comments": null, "journal-ref": "Algorithmica: Volume 71, Issue 1 (2015), Page 66-86", "doi": "10.1007/s00453-013-9780-5", "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 1-Steiner tree problem, the problem of constructing a Steiner minimum\ntree containing at most one Steiner point, has been solved in the Euclidean\nplane by Georgakopoulos and Papadimitriou using plane subdivisions called\noriented Dirichlet cell partitions. Their algorithm produces an optimal\nsolution within $O(n^2)$ time. In this paper we generalise their approach in\norder to solve the $k$-Steiner tree problem, in which the Steiner minimum tree\nmay contain up to $k$ Steiner points for a given constant $k$. We also extend\ntheir approach further to encompass other normed planes, and to solve a much\nwider class of problems, including the $k$-bottleneck Steiner tree problem and\nother generalised $k$-Steiner tree problems. We show that, for any fixed $k$,\nsuch problems can be solved in $O(n^{2k})$ time.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 01:11:57 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2013 04:40:16 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Brazil", "Marcus N.", ""], ["Ras", "Charl J.", ""], ["Swanepoel", "Konrad J.", ""], ["Thomas", "Doreen A.", ""]]}, {"id": "1111.1491", "submitter": "Sushant Sachdeva", "authors": "Lorenzo Orecchia, Sushant Sachdeva, Nisheeth K. Vishnoi", "title": "Approximating the Exponential, the Lanczos Method and an\n  \\tilde{O}(m)-Time Spectral Algorithm for Balanced Separator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.CA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a novel spectral approximation algorithm for the balanced separator\nproblem that, given a graph G, a constant balance b \\in (0,1/2], and a\nparameter \\gamma, either finds an \\Omega(b)-balanced cut of conductance\nO(\\sqrt(\\gamma)) in G, or outputs a certificate that all b-balanced cuts in G\nhave conductance at least \\gamma, and runs in time \\tilde{O}(m). This settles\nthe question of designing asymptotically optimal spectral algorithms for\nbalanced separator. Our algorithm relies on a variant of the heat kernel random\nwalk and requires, as a subroutine, an algorithm to compute \\exp(-L)v where L\nis the Laplacian of a graph related to G and v is a vector. Algorithms for\ncomputing the matrix-exponential-vector product efficiently comprise our next\nset of results. Our main result here is a new algorithm which computes a good\napproximation to \\exp(-A)v for a class of PSD matrices A and a given vector u,\nin time roughly \\tilde{O}(m_A), where m_A is the number of non-zero entries of\nA. This uses, in a non-trivial way, the result of Spielman and Teng on\ninverting SDD matrices in \\tilde{O}(m_A) time. Finally, we prove e^{-x} can be\nuniformly approximated up to a small additive error, in a non-negative interval\n[a,b] with a polynomial of degree roughly \\sqrt{b-a}. While this result is of\nindependent interest in approximation theory, we show that, via the Lanczos\nmethod from numerical analysis, it yields a simple algorithm to compute\n\\exp(-A)v for PSD matrices that runs in time roughly O(t_A \\sqrt{||A||}), where\nt_A is the time required for computation of the vector Aw for given vector w.\nAs an application, we obtain a simple and practical algorithm, with output\nconductance O(\\sqrt(\\gamma)), for balanced separator that runs in time\n\\tilde{O}(m/\\sqrt(\\gamma)). This latter algorithm matches the running time, but\nimproves on the approximation guarantee of the algorithm by Andersen and Peres.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 05:24:34 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Orecchia", "Lorenzo", ""], ["Sachdeva", "Sushant", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1111.1492", "submitter": "Taisuke Izumi", "authors": "Taisuke Izumi and Samia Souissi and Yoshiaki Katayama and Nobuhiro\n  Inuzuka and Xavier D\\'efago and Koichi Wada and Masafumi Yamashita", "title": "The Gathering Problem for Two Oblivious Robots with Unreliable Compasses", "comments": "23 pages, 10 figures, to appear at SIAM Journal on Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymous mobile robots are often classified into synchronous,\nsemi-synchronous and asynchronous robots when discussing the pattern formation\nproblem. For semi-synchronous robots, all patterns formable with memory are\nalso formable without memory, with the single exception of forming a point\n(i.e., the gathering) by two robots. However, the gathering problem for two\nsemi-synchronous robots without memory is trivially solvable when their local\ncoordinate systems are consistent, and the impossibility proof essentially uses\nthe inconsistencies in their coordinate systems. Motivated by this, this paper\ninvestigates the magnitude of consistency between the local coordinate systems\nnecessary and sufficient to solve the gathering problem for two oblivious\nrobots under semi-synchronous and asynchronous models. To discuss the magnitude\nof consistency, we assume that each robot is equipped with an unreliable\ncompass, the bearings of which may deviate from an absolute reference\ndirection, and that the local coordinate system of each robot is determined by\nits compass. We consider two families of unreliable compasses, namely,static\ncompasses with constant bearings, and dynamic compasses the bearings of which\ncan change arbitrarily.\n  For each of the combinations of robot and compass models, we establish the\ncondition on deviation \\phi that allows an algorithm to solve the gathering\nproblem, where the deviation is measured by the largest angle formed between\nthe x-axis of a compass and the reference direction of the global coordinate\nsystem: \\phi < \\pi/2 for semi-synchronous and asynchronous robots with static\ncompasses, \\phi < \\pi/4 for semi-synchronous robots with dynamic compasses, and\n\\phi < \\pi/6 for asynchronous robots with dynamic compasses. Except for\nasynchronous robots with dynamic compasses, these sufficient conditions are\nalso necessary.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 06:00:11 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Izumi", "Taisuke", ""], ["Souissi", "Samia", ""], ["Katayama", "Yoshiaki", ""], ["Inuzuka", "Nobuhiro", ""], ["D\u00e9fago", "Xavier", ""], ["Wada", "Koichi", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1111.1546", "submitter": "Heiko R\\\"oglin", "authors": "Tobias Brunsch, Heiko R\\\"oglin", "title": "Improved Smoothed Analysis of Multiobjective Optimization", "comments": "to appear in JACM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several new results about smoothed analysis of multiobjective\noptimization problems. Motivated by the discrepancy between worst-case analysis\nand practical experience, this line of research has gained a lot of attention\nin the last decade. We consider problems in which d linear and one arbitrary\nobjective function are to be optimized over a subset S of {0,1}^n of feasible\nsolutions. We improve the previously best known bound for the smoothed number\nof Pareto-optimal solutions to O(n^{2d} phi^d), where phi denotes the\nperturbation parameter. Additionally, we show that for any constant c the c-th\nmoment of the smoothed number of Pareto-optimal solutions is bounded by\nO((n^{2d} phi^d)^c). This improves the previously best known bounds\nsignificantly. Furthermore, we address the criticism that the perturbations in\nsmoothed analysis destroy the zero-structure of problems by showing that the\nsmoothed number of Pareto-optimal solutions remains polynomially bounded even\nfor zero-preserving perturbations. This broadens the class of problems captured\nby smoothed analysis and it has consequences for non-linear objective\nfunctions. One corollary of our result is that the smoothed number of\nPareto-optimal solutions is polynomially bounded for polynomial objective\nfunctions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 11:28:33 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2015 09:35:14 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Brunsch", "Tobias", ""], ["R\u00f6glin", "Heiko", ""]]}, {"id": "1111.1665", "submitter": "Stefan Langerman", "authors": "Prosenjit Bose and S\\'ebastien Collette and Rolf Fagerberg and Stefan\n  Langerman", "title": "De-amortizing Binary Search Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general method for de-amortizing essentially any Binary Search\nTree (BST) algorithm. In particular, by transforming Splay Trees, our method\nproduces a BST that has the same asymptotic cost as Splay Trees on any access\nsequence while performing each search in O(log n) worst case time. By\ntransforming Multi-Splay Trees, we obtain a BST that is O(log log n)\ncompetitive, satisfies the scanning theorem, the static optimality theorem, the\nstatic finger theorem, the working set theorem, and performs each search in\nO(log n) worst case time. Moreover, we prove that if there is a dynamically\noptimal BST algorithm, then there is a dynamically optimal BST algorithm that\nanswers every search in O(log n) worst case time.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 18:16:59 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Bose", "Prosenjit", ""], ["Collette", "S\u00e9bastien", ""], ["Fagerberg", "Rolf", ""], ["Langerman", "Stefan", ""]]}, {"id": "1111.1672", "submitter": "Lehilton Pedrosa", "authors": "Cristina G. Fernandes, Lu\\'is A. A. Meira, Fl\\'avio K. Miyazawa,\n  Lehilton L. C. Pedrosa", "title": "A Systematic Approach to Bound Factor-Revealing LPs and its Application\n  to the Metric and Squared Metric Facility Location Problems", "comments": "Additional variants with powers of metrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A systematic technique to bound factor-revealing linear programs is\npresented. We show how to derive a family of upper bound factor-revealing\nprograms (UPFRP), and show that each such program can be solved by a computer\nto bound the approximation factor of an associated algorithm. Obtaining an\nUPFRP is straightforward, and can be used as an alternative to analytical\nproofs, that are usually very long and tedious. We apply this technique to the\nMetric Facility Location Problem (MFLP) and to a generalization where the\ndistance function is a squared metric. We call this generalization the Squared\nMetric Facility Location Problem (SMFLP) and prove that there is no\napproximation factor better than 2.04, assuming P $\\neq$ NP. Then, we analyze\nthe best known algorithms for the MFLP based on primal-dual and LP-rounding\ntechniques when they are applied to the SMFLP. We prove very tight bounds for\nthese algorithms, and show that the LP-rounding algorithm achieves a ratio of\n2.04, and therefore has the best factor for the SMFLP. We use UPFRPs in the\ndual-fitting analysis of the primal-dual algorithms for both the SMFLP and the\nMFLP, improving some of the previous analysis for the MFLP.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 18:37:12 GMT"}, {"version": "v2", "created": "Wed, 29 Feb 2012 19:37:50 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2013 17:31:49 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Fernandes", "Cristina G.", ""], ["Meira", "Lu\u00eds A. A.", ""], ["Miyazawa", "Fl\u00e1vio K.", ""], ["Pedrosa", "Lehilton L. C.", ""]]}, {"id": "1111.1713", "submitter": "Daniel Reichman", "authors": "Simon Korman, Daniel Reichman and Gilad Tsur", "title": "Tight Approximation of Image Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the {\\em image matching} problem for two grayscale\n$n \\times n$ images, $M_1$ and $M_2$ (where pixel values range from 0 to 1).\nOur goal is to find an affine transformation $T$ that maps pixels from $M_1$ to\npixels in $M_2$ so that the differences over pixels $p$ between $M_1(p)$ and\n$M_2(T(p))$ is minimized. Our focus here is on sublinear algorithms that give\nan approximate result for this problem, that is, we wish to perform this task\nwhile querying as few pixels from both images as possible, and give a\ntransformation that comes close to minimizing the difference.\n  We give an algorithm for the image matching problem that returns a\ntransformation $T$ which minimizes the sum of differences (normalized by $n^2$)\nup to an additive error of $\\epsilon$ and performs $\\tilde{O}(n/\\epsilon^2)$\nqueries. We give a corresponding lower bound of $\\Omega(n)$ queries showing\nthat this is the best possible result in the general case (with respect to $n$\nand up to low order terms).\n  In addition, we give a significantly better algorithm for a natural family of\nimages, namely, smooth images. We consider an image smooth when the total\ndifference between neighboring pixels is O(n). For such images we provide an\napproximation of the distance between the images to within an additive error of\n$\\epsilon$ using a number of queries depending polynomially on $1/\\epsilon$ and\nnot on $n$. To do this we first consider the image matching problem for 2 and\n3-dimensional {\\em binary} images, and then reduce the grayscale image matching\nproblem to the 3-dimensional binary case.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 18:37:42 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Korman", "Simon", ""], ["Reichman", "Daniel", ""], ["Tsur", "Gilad", ""]]}, {"id": "1111.1750", "submitter": "Kanat Tangwongsan", "authors": "Guy E. Blelloch, Anupam Gupta, Ioannis Koutis, Gary L. Miller, Richard\n  Peng, Kanat Tangwongsan", "title": "Near Linear-Work Parallel SDD Solvers, Low-Diameter Decomposition, and\n  Low-Stretch Subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design and analysis of a near linear-work parallel algorithm\nfor solving symmetric diagonally dominant (SDD) linear systems. On input of a\nSDD $n$-by-$n$ matrix $A$ with $m$ non-zero entries and a vector $b$, our\nalgorithm computes a vector $\\tilde{x}$ such that $\\norm[A]{\\tilde{x} - A^+b}\n\\leq \\vareps \\cdot \\norm[A]{A^+b}$ in $O(m\\log^{O(1)}{n}\\log{\\frac1\\epsilon})$\nwork and $O(m^{1/3+\\theta}\\log \\frac1\\epsilon)$ depth for any fixed $\\theta >\n0$.\n  The algorithm relies on a parallel algorithm for generating low-stretch\nspanning trees or spanning subgraphs. To this end, we first develop a parallel\ndecomposition algorithm that in polylogarithmic depth and $\\otilde(|E|)$ work,\npartitions a graph into components with polylogarithmic diameter such that only\na small fraction of the original edges are between the components. This can be\nused to generate low-stretch spanning trees with average stretch\n$O(n^{\\alpha})$ in $O(n^{1+\\alpha})$ work and $O(n^{\\alpha})$ depth.\nAlternatively, it can be used to generate spanning subgraphs with\npolylogarithmic average stretch in $\\otilde(|E|)$ work and polylogarithmic\ndepth. We apply this subgraph construction to derive a parallel linear system\nsolver. By using this solver in known applications, our results imply improved\nparallel randomized algorithms for several problems, including single-source\nshortest paths, maximum flow, minimum-cost flow, and approximate maximum flow.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 21:17:09 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Blelloch", "Guy E.", ""], ["Gupta", "Anupam", ""], ["Koutis", "Ioannis", ""], ["Miller", "Gary L.", ""], ["Peng", "Richard", ""], ["Tangwongsan", "Kanat", ""]]}, {"id": "1111.1797", "submitter": "Shipra Agrawal", "authors": "Shipra Agrawal, Navin Goyal", "title": "Analysis of Thompson Sampling for the multi-armed bandit problem", "comments": "This version corrects some minor errors, and reorganizes some content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit problem is a popular model for studying\nexploration/exploitation trade-off in sequential decision problems. Many\nalgorithms are now available for this well-studied problem. One of the earliest\nalgorithms, given by W. R. Thompson, dates back to 1933. This algorithm,\nreferred to as Thompson Sampling, is a natural Bayesian algorithm. The basic\nidea is to choose an arm to play according to its probability of being the best\narm. Thompson Sampling algorithm has experimentally been shown to be close to\noptimal. In addition, it is efficient to implement and exhibits several\ndesirable properties such as small regret for delayed feedback. However,\ntheoretical understanding of this algorithm was quite limited. In this paper,\nfor the first time, we show that Thompson Sampling algorithm achieves\nlogarithmic expected regret for the multi-armed bandit problem. More precisely,\nfor the two-armed bandit problem, the expected regret in time $T$ is\n$O(\\frac{\\ln T}{\\Delta} + \\frac{1}{\\Delta^3})$. And, for the $N$-armed bandit\nproblem, the expected regret in time $T$ is $O([(\\sum_{i=2}^N\n\\frac{1}{\\Delta_i^2})^2] \\ln T)$. Our bounds are optimal but for the dependence\non $\\Delta_i$ and the constant factors in big-Oh.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2011 04:27:01 GMT"}, {"version": "v2", "created": "Tue, 27 Dec 2011 08:27:25 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2012 10:43:05 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Agrawal", "Shipra", ""], ["Goyal", "Navin", ""]]}, {"id": "1111.2105", "submitter": "Charl Ras", "authors": "Marcus Brazil, Charl Ras, Doreen Thomas", "title": "An exact algorithm for the bottleneck 2-connected $k$-Steiner network\n  problem in $L_p$ planes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first exact polynomial time algorithm for constructing optimal\ngeometric bottleneck 2-connected Steiner networks containing at most $k$\nSteiner points, where $k>2$ is a constant. Given a set of $n$ vertices embedded\nin an $L_p$ plane, the objective of the problem is to find a 2-connected\nnetwork, spanning the given vertices and at most $k$ additional vertices, such\nthat the length of the longest edge is minimised. In contrast to the discrete\nversion of this problem the additional vertices may be located anywhere in the\nplane. The problem is motivated by the modelling of relay-augmentation for the\noptimisation of energy consumption in wireless ad hoc networks. Our algorithm\nemploys Voronoi diagrams and properties of block-cut-vertex decompositions of\ngraphs to find an optimal solution in $O(n^k\\log^{\\frac{5k}{2}}n)$ steps when\n$1<p<\\infty$ and in $O(n^2\\log^{\\frac{7k}{2}+1}n)$ steps when\n$p\\in\\{1,\\infty\\}$.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 05:25:04 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2013 01:56:31 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2013 00:45:43 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Brazil", "Marcus", ""], ["Ras", "Charl", ""], ["Thomas", "Doreen", ""]]}, {"id": "1111.2109", "submitter": "Charl Ras", "authors": "Marcus Brazil, Charl Ras, Doreen Thomas", "title": "A Flow-dependent Quadratic Steiner Tree Problem in the Euclidean Plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a flow-dependent version of the quadratic Steiner tree problem\nin the plane. An instance of the problem on a set of embedded sources and a\nsink asks for a directed tree $T$ spanning these nodes and a bounded number of\nSteiner points, such that $\\displaystyle\\sum_{e \\in E(T)}f(e)|e|^2$ is a\nminimum, where $f(e)$ is the flow on edge $e$. The edges are uncapacitated and\nthe flows are determined additively, i.e., the flow on an edge leaving a node\n$u$ will be the sum of the flows on all edges entering $u$. Our motivation for\nstudying this problem is its utility as a model for relay augmentation of\nwireless sensor networks. In these scenarios one seeks to optimise power\nconsumption -- which is predominantly due to communication and, in free space,\nis proportional to the square of transmission distance -- in the network by\nintroducing additional relays. We prove several geometric and combinatorial\nresults on the structure of optimal and locally optimal solution-trees (under\nvarious strategies for bounding the number of Steiner points) and describe a\ngeometric linear-time algorithm for constructing such trees with known\ntopologies.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 06:00:16 GMT"}], "update_date": "2011-11-11", "authors_parsed": [["Brazil", "Marcus", ""], ["Ras", "Charl", ""], ["Thomas", "Doreen", ""]]}, {"id": "1111.2111", "submitter": "Song Liu Mr", "authors": "Song Liu, Peter Flach, Nello Cristianini", "title": "Generic Multiplicative Methods for Implementing Machine Learning\n  Algorithms on MapReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a generic model for multiplicative algorithms\nwhich is suitable for the MapReduce parallel programming paradigm. We implement\nthree typical machine learning algorithms to demonstrate how similarity\ncomparison, gradient descent, power method and other classic learning\ntechniques fit this model well. Two versions of large-scale matrix\nmultiplication are discussed in this paper, and different methods are developed\nfor both cases with regard to their unique computational characteristics and\nproblem settings. In contrast to earlier research, we focus on fundamental\nlinear algebra techniques that establish a generic approach for a range of\nalgorithms, rather than specific ways of scaling up algorithms one at a time.\nExperiments show promising results when evaluated on both speedup and accuracy.\nCompared with a standard implementation with computational complexity $O(m^3)$\nin the worst case, the large-scale matrix multiplication experiments prove our\ndesign is considerably more efficient and maintains a good speedup as the\nnumber of cores increases. Algorithm-specific experiments also produce\nencouraging results on runtime performance.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 06:39:17 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2011 02:08:47 GMT"}], "update_date": "2011-12-05", "authors_parsed": [["Liu", "Song", ""], ["Flach", "Peter", ""], ["Cristianini", "Nello", ""]]}, {"id": "1111.2195", "submitter": "Stefan Kratsch", "authors": "Stefan Kratsch and Magnus Wahlstr\\\"om", "title": "Representative sets and irrelevant vertices: New tools for kernelization", "comments": "30 pages. To appear in FOCS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of a polynomial kernel for Odd Cycle Transversal was a\nnotorious open problem in parameterized complexity. Recently, this was settled\nby the present authors (Kratsch and Wahlstr\\\"om, SODA 2012), with a randomized\npolynomial kernel for the problem, using matroid theory to encode flow\nquestions over a set of terminals in size polynomial in the number of\nterminals.\n  In the current work we further establish the usefulness of matroid theory to\nkernelization by showing applications of a result on representative sets due to\nLov\\'asz (Combinatorial Surveys 1977) and Marx (TCS 2009). We show how\nrepresentative sets can be used to give a polynomial kernel for the elusive\nAlmost 2-SAT problem. We further apply the representative sets tool to the\nproblem of finding irrelevant vertices in graph cut problems, i.e., vertices\nwhich can be made undeletable without affecting the status of the problem. This\ngives the first significant progress towards a polynomial kernel for the\nMultiway Cut problem; in particular, we get a kernel of O(k^{s+1}) vertices for\nMultiway Cut instances with at most s terminals. Both these kernelization\nresults have significant spin-off effects, producing the first polynomial\nkernels for a range of related problems.\n  More generally, the irrelevant vertex results have implications for covering\nmin-cuts in graphs. For a directed graph G=(V,E) and sets S, T \\subseteq V, let\nr be the size of a minimum (S,T)-vertex cut (which may intersect S and T). We\ncan find a set Z \\subseteq V of size O(|S|*|T|*r) which contains a minimum\n(A,B)-vertex cut for every A \\subseteq S, B \\subseteq T. Similarly, for an\nundirected graph G=(V,E), a set of terminals X \\subseteq V, and a constant s,\nwe can find a set Z\\subseteq V of size O(|X|^{s+1}) which contains a minimum\nmultiway cut for any partition of X into at most s pairwise disjoint subsets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 12:55:42 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2012 12:00:40 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Kratsch", "Stefan", ""], ["Wahlstr\u00f6m", "Magnus", ""]]}, {"id": "1111.2228", "submitter": "Francesco Silvestri", "authors": "Andrea Pietracaprina, Geppino Pucci, Matteo Riondato, Francesco\n  Silvestri, Eli Upfal", "title": "Space-Round Tradeoffs for MapReduce Computations", "comments": null, "journal-ref": "Final version in Proc. of the 26th ACM international conference on\n  Supercomputing, pages 235-244, 2012", "doi": "10.1145/2304576.2304607", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores fundamental modeling and algorithmic issues arising in the\nwell-established MapReduce framework. First, we formally specify a\ncomputational model for MapReduce which captures the functional flavor of the\nparadigm by allowing for a flexible use of parallelism. Indeed, the model\ndiverges from a traditional processor-centric view by featuring parameters\nwhich embody only global and local memory constraints, thus favoring a more\ndata-centric view. Second, we apply the model to the fundamental computation\ntask of matrix multiplication presenting upper and lower bounds for both dense\nand sparse matrix multiplication, which highlight interesting tradeoffs between\nspace and round complexity. Finally, building on the matrix multiplication\nresults, we derive further space-round tradeoffs on matrix inversion and\nmatching.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 15:13:40 GMT"}], "update_date": "2013-06-13", "authors_parsed": [["Pietracaprina", "Andrea", ""], ["Pucci", "Geppino", ""], ["Riondato", "Matteo", ""], ["Silvestri", "Francesco", ""], ["Upfal", "Eli", ""]]}, {"id": "1111.2527", "submitter": "Taha Sochi", "authors": "Taha Sochi", "title": "Testing the Connectivity of Networks", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": "10.4304/jnw.9.2.239-243", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we discuss general strategies and computer algorithms to test\nthe connectivity of unstructured networks which consist of a number of segments\nconnected through randomly distributed nodes.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2011 17:28:20 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Sochi", "Taha", ""]]}, {"id": "1111.2621", "submitter": "Gonzalo Navarro", "authors": "Djamal Belazzougui and Gonzalo Navarro", "title": "Optimal Lower and Upper Bounds for Representing Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence representations supporting queries $access$, $select$ and $rank$ are\nat the core of many data structures. There is a considerable gap between the\nvarious upper bounds and the few lower bounds known for such representations,\nand how they relate to the space used. In this article we prove a strong lower\nbound for $rank$, which holds for rather permissive assumptions on the space\nused, and give matching upper bounds that require only a compressed\nrepresentation of the sequence. Within this compressed space, operations\n$access$ and $select$ can be solved in constant or almost-constant time, which\nis optimal for large alphabets. Our new upper bounds dominate all of the\nprevious work in the time/space map.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2011 21:51:27 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2013 16:51:05 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Belazzougui", "Djamal", ""], ["Navarro", "Gonzalo", ""]]}, {"id": "1111.2693", "submitter": "Nicolas Nicolaou", "authors": "Chryssis Georgiou and Nicolas C. Nicolaou", "title": "On the Practicality of Atomic MWMR Register Implementations", "comments": "18 pages, 14 figures, 3 tables, Technical Report, Full Version of an\n  Article appearing in the Proceedings of the 10th International Symposium on\n  Parallel and Distributed Processing with Applications (ISPA 2012), Leganes,\n  Madrid, July 2012", "journal-ref": null, "doi": null, "report-no": "UCY-CS-TR-11-08", "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-writer/multiple-reader (MWMR) atomic register implementations\nprovide precise consistency guarantees, in the asynchronous, crash-prone,\nmessage passing environment. Fast MWMR atomic register implementations were\nfirst introduced in Englert et al. 2009. Fastness is measured in terms of the\nnumber of single round read and write operations that does not sacrifice\ncorrectness. In Georgiou et al. 2011 was shown, however, that decreasing the\ncommunication cost is not enough in these implementations. In particular,\nconsidering that the performance is measured in terms of the latency of read\nand write operations due to both (a) communication delays and (b)local\ncomputation, they introduced two new algorithms that traded communication for\nreducing computation. As computation is still part of the algorithms, someone\nmay wonder: What is the trade-off between communication and local computation\nin real-time systems?\n  In this work we conduct an experimental performance evaluation of four MWMR\natomic register implementations: SFW from Englert et al. 2009, APRX-SFW and\nCWFR from Georgiou at al. 2011, and the generalization of the traditional\nalgorithm of Attiya et al. 1996 in the MWMR environment, which we call SIMPLE.\nWe implement and evaluate the algorithms on NS2, a single-processor simulator,\nand on PlanetLab, a planetary-scale real-time network platform. Our comparison\nprovides an empirical answer to the above question and demonstrates the\npracticality of atomic MWMR register implementations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2011 09:50:01 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2012 13:51:10 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Georgiou", "Chryssis", ""], ["Nicolaou", "Nicolas C.", ""]]}, {"id": "1111.2885", "submitter": "Pranav Dandekar", "authors": "Pranav Dandekar and Nadia Fawaz and Stratis Ioannidis", "title": "Privacy Auctions for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a market for private data in which a data analyst publicly releases\na statistic over a database of private information. Individuals that own the\ndata incur a cost for their loss of privacy proportional to the differential\nprivacy guarantee given by the analyst at the time of the release. The analyst\nincentivizes individuals by compensating them, giving rise to a \\emph{privacy\nauction}. Motivated by recommender systems, the statistic we consider is a\nlinear predictor function with publicly known weights. The statistic can be\nviewed as a prediction of the unknown data of a new individual, based on the\ndata of individuals in the database. We formalize the trade-off between privacy\nand accuracy in this setting, and show that a simple class of estimates\nachieves an order-optimal trade-off. It thus suffices to focus on auction\nmechanisms that output such estimates. We use this observation to design a\ntruthful, individually rational, proportional-purchase mechanism under a fixed\nbudget constraint. We show that our mechanism is 5-approximate in terms of\naccuracy compared to the optimal mechanism, and that no truthful mechanism can\nachieve a $2-\\varepsilon$ approximation, for any $\\varepsilon > 0$.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2011 23:37:57 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2012 22:49:41 GMT"}], "update_date": "2012-10-01", "authors_parsed": [["Dandekar", "Pranav", ""], ["Fawaz", "Nadia", ""], ["Ioannidis", "Stratis", ""]]}, {"id": "1111.2942", "submitter": "Nirman Kumar", "authors": "Sariel Har-Peled and Nirman Kumar", "title": "Down the Rabbit Hole: Robust Proximity Search and Density Estimation in\n  Sublinear Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a set of $n$ points in $\\Re^d$, and parameters $k$ and $\\eps$, we present\na data structure that answers $(1+\\eps,k)$-\\ANN queries in logarithmic time.\nSurprisingly, the space used by the data-structure is $\\Otilde (n /k)$; that\nis, the space used is sublinear in the input size if $k$ is sufficiently large.\nOur approach provides a novel way to summarize geometric data, such that\nmeaningful proximity queries on the data can be carried out using this sketch.\nUsing this, we provide a sublinear space data-structure that can estimate the\ndensity of a point set under various measures, including:\n  \\begin{inparaenum}[(i)]\n  \\item sum of distances of $k$ closest points to the query point, and\n  \\item sum of squared distances of $k$ closest points to the query point.\n  \\end{inparaenum}\n  Our approach generalizes to other distance based estimation of densities of\nsimilar flavor. We also study the problem of approximating some of these\nquantities when using sampling. In particular, we show that a sample of size\n$\\Otilde (n /k)$ is sufficient, in some restricted cases, to estimate the above\nquantities. Remarkably, the sample size has only linear dependency on the\ndimension.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2011 17:18:12 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2012 21:43:13 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2013 19:03:06 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Har-Peled", "Sariel", ""], ["Kumar", "Nirman", ""]]}, {"id": "1111.3097", "submitter": "Damien Woods", "authors": "David Doty, Jack H. Lutz, Matthew J. Patitz, Robert T. Schweller,\n  Scott M. Summers, Damien Woods", "title": "The tile assembly model is intrinsically universal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the abstract Tile Assembly Model (aTAM) of nanoscale\nself-assembly is intrinsically universal. This means that there is a single\ntile assembly system U that, with proper initialization, simulates any tile\nassembly system T. The simulation is \"intrinsic\" in the sense that the\nself-assembly process carried out by U is exactly that carried out by T, with\neach tile of T represented by an m x m \"supertile\" of U. Our construction works\nfor the full aTAM at any temperature, and it faithfully simulates the\ndeterministic or nondeterministic behavior of each T.\n  Our construction succeeds by solving an analog of the cell differentiation\nproblem in developmental biology: Each supertile of U, starting with those in\nthe seed assembly, carries the \"genome\" of the simulated system T. At each\nlocation of a potential supertile in the self-assembly of U, a decision is made\nwhether and how to express this genome, i.e., whether to generate a supertile\nand, if so, which tile of T it will represent. This decision must be achieved\nusing asynchronous communication under incomplete information, but it achieves\nthe correct global outcome(s).\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2011 05:16:46 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2012 09:32:09 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Doty", "David", ""], ["Lutz", "Jack H.", ""], ["Patitz", "Matthew J.", ""], ["Schweller", "Robert T.", ""], ["Summers", "Scott M.", ""], ["Woods", "Damien", ""]]}, {"id": "1111.3114", "submitter": "Ashwin Ganesan", "authors": "Ashwin Ganesan", "title": "Diameter of Cayley graphs of permutation groups generated by\n  transposition trees", "comments": "This is an extension of arXiv:1106.5353", "journal-ref": "Journal of Combinatorial Mathematics and Combinatorial Computing,\n  vol. 84, pp. 29-40, February 2013", "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\Gamma$ be a Cayley graph of the permutation group generated by a\ntransposition tree $T$ on $n$ vertices. In an oft-cited paper\n\\cite{Akers:Krishnamurthy:1989} (see also \\cite{Hahn:Sabidussi:1997}), it is\nshown that the diameter of the Cayley graph $\\Gamma$ is bounded as\n$$\\diam(\\Gamma) \\le \\max_{\\pi \\in S_n}{c(\\pi)-n+\\sum_{i=1}^n\n\\dist_T(i,\\pi(i))},$$ where the maximization is over all permutations $\\pi$,\n$c(\\pi)$ denotes the number of cycles in $\\pi$, and $\\dist_T$ is the distance\nfunction in $T$. In this work, we first assess the performance (the sharpness\nand strictness) of this upper bound. We show that the upper bound is sharp for\nall trees of maximum diameter and also for all trees of minimum diameter, and\nwe exhibit some families of trees for which the bound is strict. We then show\nthat for every $n$, there exists a tree on $n$ vertices, such that the\ndifference between the upper bound and the true diameter value is at least\n$n-4$.\n  Observe that evaluating this upper bound requires on the order of $n!$ (times\na polynomial) computations. We provide an algorithm that obtains an estimate of\nthe diameter, but which requires only on the order of (polynomial in) $n$\ncomputations; furthermore, the value obtained by our algorithm is less than or\nequal to the previously known diameter upper bound. This result is possible\nbecause our algorithm works directly with the transposition tree on $n$\nvertices and does not require examining any of the permutations (only the proof\nrequires examining the permutations). For all families of trees examined so\nfar, the value $\\beta$ computed by our algorithm happens to also be an upper\nbound on the diameter, i.e.\n  $$\\diam(\\Gamma) \\le \\beta \\le \\max_{\\pi \\in S_n}{c(\\pi)-n+\\sum_{i=1}^n\n\\dist_T(i,\\pi(i))}.$$\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2011 07:07:51 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2011 15:38:03 GMT"}, {"version": "v3", "created": "Wed, 21 Dec 2011 12:41:05 GMT"}], "update_date": "2015-12-11", "authors_parsed": [["Ganesan", "Ashwin", ""]]}, {"id": "1111.3244", "submitter": "Artur Je\\.z", "authors": "Artur Je\\.z", "title": "Faster fully compressed pattern matching by recompression", "comments": "Full version, submitted to a journal as is. Overall improvements over\n  the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a fully compressed pattern matching problem is studied. The\ncompression is represented by straight-line programs (SLPs), i.e. a\ncontext-free grammars generating exactly one string; the term fully means that\nboth the pattern and the text are given in the compressed form. The problem is\napproached using a recently developed technique of local recompression: the\nSLPs are refactored, so that substrings of the pattern and text are encoded in\nboth SLPs in the same way. To this end, the SLPs are locally decompressed and\nthen recompressed in a uniform way.\n  This technique yields an O((n+m)log M) algorithm for compressed pattern\nmatching, assuming that M fits in O(1) machine words, where n (m) is the size\nof the compressed representation of the text (pattern, respectively), while M\nis the size of the decompressed pattern. If only m+n fits in O(1) machine\nwords, the running time increases to O((n+m)log M log(n+m)). The previous best\nalgorithm due to Lifshits had O(n^2m) running time.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2011 15:26:56 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2012 19:18:18 GMT"}, {"version": "v3", "created": "Thu, 10 May 2012 14:17:37 GMT"}, {"version": "v4", "created": "Tue, 25 Jun 2013 15:23:56 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Je\u017c", "Artur", ""]]}, {"id": "1111.3270", "submitter": "Mehdi Kaytoue", "authors": "Mehdi Kaytoue (DCC - UFMG), Sergei O. Kuznetsov, Juraj Macko, Wagner\n  Meira (DCC - UFMG), Amedeo Napoli (INRIA Lorraine - LORIA)", "title": "Mining Biclusters of Similar Values with Triadic Concept Analysis", "comments": "Concept Lattices and their Applications (CLA) (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering numerical data became a popular data-mining task in the\nbeginning of 2000's, especially for analysing gene expression data. A bicluster\nreflects a strong association between a subset of objects and a subset of\nattributes in a numerical object/attribute data-table. So called biclusters of\nsimilar values can be thought as maximal sub-tables with close values. Only few\nmethods address a complete, correct and non redundant enumeration of such\npatterns, which is a well-known intractable problem, while no formal framework\nexists. In this paper, we introduce important links between biclustering and\nformal concept analysis. More specifically, we originally show that Triadic\nConcept Analysis (TCA), provides a nice mathematical framework for\nbiclustering. Interestingly, existing algorithms of TCA, that usually apply on\nbinary data, can be used (directly or with slight modifications) after a\npreprocessing step for extracting maximal biclusters of similar values.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2011 16:22:33 GMT"}], "update_date": "2011-11-15", "authors_parsed": [["Kaytoue", "Mehdi", "", "DCC - UFMG"], ["Kuznetsov", "Sergei O.", "", "DCC - UFMG"], ["Macko", "Juraj", "", "DCC - UFMG"], ["Meira", "Wagner", "", "DCC - UFMG"], ["Napoli", "Amedeo", "", "INRIA Lorraine - LORIA"]]}, {"id": "1111.3297", "submitter": "Zolt\\'an K\\'asa", "authors": "A. J\\'arai, E. Vatai", "title": "Cache optimized linear sieve", "comments": null, "journal-ref": "Acta Univ. Sapientiae, Inform. 3,2 (2011) 205--223", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sieving is essential in different number theoretical algorithms. Sieving with\nlarge primes violates locality of memory access, thus degrading performance.\nOur suggestion on how to tackle this problem is to use cyclic data structures\nin combination with in-place bucket-sort. We present our results on the\nimplementation of the sieve of Eratosthenes, using these ideas, which show that\nthis approach is more robust and less affected by slow memory.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2011 17:31:29 GMT"}], "update_date": "2011-11-15", "authors_parsed": [["J\u00e1rai", "A.", ""], ["Vatai", "E.", ""]]}, {"id": "1111.3304", "submitter": "Mihai Cucuringu", "authors": "Mihai Cucuringu, Amit Singer, David Cowburn", "title": "Eigenvector Synchronization, Graph Rigidity and the Molecule Problem", "comments": "49 pages, 8 figures", "journal-ref": "Information and inference : a journal of the IMA 2012, 1, 21", "doi": "10.1093/imaiai/ias002", "report-no": null, "categories": "cs.CE cs.DS math.CO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph realization problem has received a great deal of attention in\nrecent years, due to its importance in applications such as wireless sensor\nnetworks and structural biology. In this paper, we extend on previous work and\npropose the 3D-ASAP algorithm, for the graph realization problem in\n$\\mathbb{R}^3$, given a sparse and noisy set of distance measurements. 3D-ASAP\nis a divide and conquer, non-incremental and non-iterative algorithm, which\nintegrates local distance information into a global structure determination.\nOur approach starts with identifying, for every node, a subgraph of its 1-hop\nneighborhood graph, which can be accurately embedded in its own coordinate\nsystem. In the noise-free case, the computed coordinates of the sensors in each\npatch must agree with their global positioning up to some unknown rigid motion,\nthat is, up to translation, rotation and possibly reflection. In other words,\nto every patch there corresponds an element of the Euclidean group Euc(3) of\nrigid transformations in $\\mathbb{R}^3$, and the goal is to estimate the group\nelements that will properly align all the patches in a globally consistent way.\nFurthermore, 3D-ASAP successfully incorporates information specific to the\nmolecule problem in structural biology, in particular information on known\nsubstructures and their orientation. In addition, we also propose 3D-SP-ASAP, a\nfaster version of 3D-ASAP, which uses a spectral partitioning algorithm as a\npreprocessing step for dividing the initial graph into smaller subgraphs. Our\nextensive numerical simulations show that 3D-ASAP and 3D-SP-ASAP are very\nrobust to high levels of noise in the measured distances and to sparse\nconnectivity in the measurement graph, and compare favorably to similar\nstate-of-the art localization algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 17:38:16 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2012 01:13:29 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2012 02:24:58 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Cucuringu", "Mihai", ""], ["Singer", "Amit", ""], ["Cowburn", "David", ""]]}, {"id": "1111.3398", "submitter": "Christoph Durr", "authors": "Evripidis Bampis, Christoph D\\\"urr, Fadi Kacem and Ioannis Milis", "title": "Speed scaling with power down scheduling for agreeable deadlines", "comments": null, "journal-ref": null, "doi": "10.1016/j.suscom.2012.10.003", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of scheduling on a single processor a given set of n\njobs. Each job j has a workload w_j and a release time r_j. The processor can\nvary its speed and hibernate to reduce energy consumption. In a schedule\nminimizing overall consumed energy, it might be that some jobs complete\narbitrarily far from their release time. So in order to guarantee some quality\nof service, we would like to impose a deadline d_j=r_j+F for every job j, where\nF is a guarantee on the *flow time*. We provide an O(n^3) algorithm for the\nmore general case of *agreeable deadlines*, where jobs have release times and\ndeadlines and can be ordered such that for every i<j, both r_i<=r_j and\nd_i<=d_j.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2011 00:28:24 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2012 22:32:14 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Bampis", "Evripidis", ""], ["D\u00fcrr", "Christoph", ""], ["Kacem", "Fadi", ""], ["Milis", "Ioannis", ""]]}, {"id": "1111.3548", "submitter": "Francisco Soulignac", "authors": "Francisco J. Soulignac", "title": "Fully dynamic recognition of proper circular-arc graphs", "comments": "60 pages, 15 figures", "journal-ref": null, "doi": "10.1007/s00453-013-9835-7", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fully dynamic algorithm for the recognition of proper\ncircular-arc (PCA) graphs. The allowed operations on the graph involve the\ninsertion and removal of vertices (together with its incident edges) or edges.\nEdge operations cost O(log n) time, where n is the number of vertices of the\ngraph, while vertex operations cost O(log n + d) time, where d is the degree of\nthe modified vertex. We also show incremental and decremental algorithms that\nwork in O(1) time per inserted or removed edge. As part of our algorithm, fully\ndynamic connectivity and co-connectivity algorithms that work in O(log n) time\nper operation are obtained. Also, an O(\\Delta) time algorithm for determining\nif a PCA representation corresponds to a co-bipartite graph is provided, where\n\\Delta\\ is the maximum among the degrees of the vertices. When the graph is\nco-bipartite, a co-bipartition of each of its co-components is obtained within\nthe same amount of time.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2011 15:06:54 GMT"}], "update_date": "2014-08-18", "authors_parsed": [["Soulignac", "Francisco J.", ""]]}, {"id": "1111.3584", "submitter": "Matias Korman", "authors": "Luis Barba, Matias Korman, Stefan Langerman and Rodrigo I. Silveira", "title": "Computing a visibility polygon using few variables", "comments": "11 pages. Full version of paper in Proceedings of ISAAC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several algorithms for computing the visibility polygon of a\nsimple polygon $P$ from a viewpoint inside the polygon, when the polygon\nresides in read-only memory and only few working variables can be used. The\nfirst algorithm uses a constant number of variables, and outputs the vertices\nof the visibility polygon in $O(n\\Rout)$ time, where $\\Rout$ denotes the number\nof reflex vertices of $P$ that are part of the output. The next two algorithms\nuse $O(\\log \\Rin)$ variables, and output the visibility polygon in $O(n\\log\n\\Rin)$ randomized expected time or $O(n\\log^2 \\Rin)$ deterministic time, where\n$\\Rin$ is the number of reflex vertices of $P$.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2011 17:10:52 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2013 13:03:32 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Barba", "Luis", ""], ["Korman", "Matias", ""], ["Langerman", "Stefan", ""], ["Silveira", "Rodrigo I.", ""]]}, {"id": "1111.3663", "submitter": "Zolt\\'an K\\'asa", "authors": "C. P\\u{a}tca\\c{s}", "title": "The debts' clearing problem: a new approach", "comments": null, "journal-ref": "Acta Univ. Sapientia Inform. 3,2 (2011) 192--204", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The debts' clearing problem is about clearing all the debts in a group of $n$\nentities (e.g. persons, companies) using a minimal number of money transaction\noperations. In our previous works we studied the problem, gave a dynamic\nprogramming solution solving it and proved that it is NP-hard. In this paper we\nadapt the problem to dynamic graphs and give a data structure to solve it.\nBased on this data structure we develop a new algorithm, that improves our\nprevious one for the static version of the problem.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2011 21:35:48 GMT"}], "update_date": "2011-11-17", "authors_parsed": [["P\u0103tca\u015f", "C.", ""]]}, {"id": "1111.3668", "submitter": "Zolt\\'an K\\'asa", "authors": "T. Herendi, R. Major", "title": "Modular exponentiation of matrices on FPGA-s", "comments": null, "journal-ref": "Acta Univ. Sapientiae, Inform. 3, 2 (2011) 172--191", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an efficient FPGA implementation for the exponentiation of large\nmatrices. The research is related to an algorithm for constructing uniformly\ndistributed linear recurring sequences. The design utilizes the special\nproperties of both the FPGA and the used matrices to achieve a very significant\nspeedup compared to traditional architectures.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2011 21:47:03 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Herendi", "T.", ""], ["Major", "R.", ""]]}, {"id": "1111.3670", "submitter": "Zolt\\'an K\\'asa", "authors": "G. Farkas, G. Kall\\'os, G. Kiss", "title": "Large primes in generalized Pascal triangles", "comments": null, "journal-ref": "Acta Univ. Sapientiae, Inform. 3, 2 (2011) 158--171", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, after presenting the results of the generalization of Pascal\ntriangle (using powers of base numbers), we examine some properties of the\n112-based triangle, most of all regarding to prime numbers. Additionally, an\neffective implementation of ECPP method is presented which enables Magma\ncomputer algebra system to prove the primality of numbers with more than 1000\ndecimal digits.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2011 21:54:54 GMT"}], "update_date": "2011-11-17", "authors_parsed": [["Farkas", "G.", ""], ["Kall\u00f3s", "G.", ""], ["Kiss", "G.", ""]]}, {"id": "1111.4299", "submitter": "Monaldo Mastrolilli", "authors": "Monaldo Mastrolilli", "title": "The Feedback Arc Set Problem with Triangle Inequality is a Vertex Cover\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the (precedence constrained) Minimum Feedback Arc Set problem\nwith triangle inequalities on the weights, which finds important applications\nin problems of ranking with inconsistent information. We present a surprising\nstructural insight showing that the problem is a special case of the minimum\nvertex cover in hypergraphs with edges of size at most 3. This result leads to\ncombinatorial approximation algorithms for the problem and opens the road to\nstudying the problem as a vertex cover problem.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 08:32:45 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2011 15:54:59 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Mastrolilli", "Monaldo", ""]]}, {"id": "1111.4395", "submitter": "Daniel Valenzuela", "authors": "Gonzalo Navarro and Daniel Valenzuela", "title": "Practical Top-K Document Retrieval in Reduced Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supporting top-k document retrieval queries on general text databases, that\nis, finding the k documents where a given pattern occurs most frequently, has\nbecome a topic of interest with practical applications. While the problem has\nbeen solved in optimal time and linear space, the actual space usage is a\nserious concern. In this paper we study various reduced-space structures that\nsupport top-k retrieval and propose new alternatives. Our experimental results\nshow that our novel algorithms and data structures dominate almost all the\nspace/time tradeoff.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 15:30:49 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Navarro", "Gonzalo", ""], ["Valenzuela", "Daniel", ""]]}, {"id": "1111.4649", "submitter": "Karthekeyan Chandrasekaran", "authors": "Karthekeyan Chandrasekaran and Santosh Vempala", "title": "Integer Feasibility of Random Polytopes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study integer programming instances over polytopes P(A,b)={x:Ax<=b} where\nthe constraint matrix A is random, i.e., its entries are i.i.d. Gaussian or,\nmore generally, its rows are i.i.d. from a spherically symmetric distribution.\nThe radius of the largest inscribed ball is closely related to the existence of\ninteger points in the polytope. We show that for m=2^O(sqrt{n}), there exist\nconstants c_0 < c_1 such that with high probability, random polytopes are\ninteger feasible if the radius of the largest ball contained in the polytope is\nat least c_1sqrt{log(m/n)}; and integer infeasible if the largest ball\ncontained in the polytope is centered at (1/2,...,1/2) and has radius at most\nc_0sqrt{log(m/n)}. Thus, random polytopes transition from having no integer\npoints to being integer feasible within a constant factor increase in the\nradius of the largest inscribed ball. We show integer feasibility via a\nrandomized polynomial-time algorithm for finding an integer point in the\npolytope.\n  Our main tool is a simple new connection between integer feasibility and\nlinear discrepancy. We extend a recent algorithm for finding low-discrepancy\nsolutions (Lovett-Meka, FOCS '12) to give a constructive upper bound on the\nlinear discrepancy of random matrices. By our connection between discrepancy\nand integer feasibility, this upper bound on linear discrepancy translates to\nthe radius lower bound that guarantees integer feasibility of random polytopes.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2011 16:53:55 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2011 20:36:44 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2013 20:13:57 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Chandrasekaran", "Karthekeyan", ""], ["Vempala", "Santosh", ""]]}, {"id": "1111.4766", "submitter": "Chinmoy Dutta", "authors": "Costas Busch and Chinmoy Dutta and Jaikumar Radhakrishnan and Rajmohan\n  Rajaraman and Srivathsan Srinivasagopalan", "title": "On Strong Graph Partitions and Universal Steiner Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of constructing universal Steiner trees for undirected\ngraphs. Given a graph $G$ and a root node $r$, we seek a single spanning tree\n$T$ of minimum {\\em stretch}, where the stretch of $T$ is defined to be the\nmaximum ratio, over all terminal sets $X$, of the cost of the minimal sub-tree\n$T_X$ of $T$ that connects $X$ to $r$ to the cost of an optimal Steiner tree\nconnecting $X$ to $r$ in $G$. Universal Steiner trees (USTs) are important for\ndata aggregation problems where computing the Steiner tree from scratch for\nevery input instance of terminals is costly, as for example in low energy\nsensor network applications.\n  We provide a polynomial time \\ust\\ construction for general graphs with\n$2^{O(\\sqrt{\\log n})}$-stretch. We also give a polynomial time\n$\\polylog(n)$-stretch construction for minor-free graphs. One basic building\nblock of our algorithms is a hierarchy of graph partitions, each of which\nguarantees small strong diameter for each cluster and bounded neighbourhood\nintersections for each node. We show close connections between the problems of\nconstructing USTs and building such graph partitions. Our construction of\npartition hierarchies for general graphs is based on an iterative cluster\nmerging procedure, while the one for minor-free graphs is based on a separator\ntheorem for such graphs and the solution to a cluster aggregation problem that\nmay be of independent interest even for general graphs. To our knowledge, this\nis the first subpolynomial-stretch ($o(n^\\epsilon)$ for any $\\epsilon > 0$) UST\nconstruction for general graphs, and the first polylogarithmic-stretch UST\nconstruction for minor-free graphs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 06:03:45 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2011 20:32:13 GMT"}, {"version": "v3", "created": "Wed, 7 Dec 2011 17:11:18 GMT"}, {"version": "v4", "created": "Wed, 22 Aug 2012 21:57:08 GMT"}, {"version": "v5", "created": "Sun, 1 Mar 2015 18:54:30 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Busch", "Costas", ""], ["Dutta", "Chinmoy", ""], ["Radhakrishnan", "Jaikumar", ""], ["Rajaraman", "Rajmohan", ""], ["Srinivasagopalan", "Srivathsan", ""]]}, {"id": "1111.4841", "submitter": "Isaac  P\\'erez Castillo", "authors": "Francesc Font-Clos, Francesco Alessandro Massucci, and Isaac P\\'erez\n  Castillo", "title": "A weighted message-passing algorithm to estimate volume-related\n  properties of random polytopes", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cond-mat.dis-nn math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we introduce a novel message-passing algorithm for a class of\nproblems which can be mathematically understood as estimating volume-related\nproperties of random polytopes. Unlike the usual approach consisting in\napproximating the real-valued cavity marginal distributions by a few\nparameters, we propose a weighted message-passing algorithm to deal with the\nentire function. Various alternatives of how to implement our approach are\ndiscussed and numerical results for random polytopes are compared with results\nusing the Hit-and-Run algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 11:57:05 GMT"}], "update_date": "2011-11-23", "authors_parsed": [["Font-Clos", "Francesc", ""], ["Massucci", "Francesco Alessandro", ""], ["Castillo", "Isaac P\u00e9rez", ""]]}, {"id": "1111.4937", "submitter": "Xin He", "authors": "Bryan Dawei He", "title": "A Simple Optimal Binary Representation of Mosaic Floorplans and Baxter\n  Permutations", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A \"floorplan\" is a rectangle subdivided into smaller rectangular sections by\nhorizontal and vertical line segments. Each section in the floorplan is called\na \"block\". Two floorplans are considered equivalent if and only if there is a\none-to-one correspondence between the blocks in the two floorplans such that\nthe relative position relationship of the blocks in one floorplan is the same\nas the relative position relationship of the corresponding blocks in another\nfloorplan. The objects of \"Mosaic floorplans\" are the same as floorplans, but\nan alternative definition of equivalence is used. Two mosaic floorplans are\nconsidered equivalent if and only if they can be converted to each other by\nsliding the line segments that divide the blocks.\n  Mosaic floorplans are widely used in VLSI circuit design. An important\nproblem in this area is to find short binary string representations of the set\nof n-block mosaic floorplans. The best known representation is the\n\"Quarter-State Sequence\" which uses 4n bits. This paper introduces a simple\nbinary representation of n-block mosaic floorplan using 3n-3 bits. It has been\nshown that any binary representation of n-block mosaic floorplans must use at\nleast (3n-o(n)) bits. Therefore, the representation presented in this paper is\noptimal (up to an additive lower order term).\n  \"Baxter permutations\" are a set of permutations defined by prohibited\nsubsequences. Baxter permutations have been shown to have one-to-one\ncorrespondences to many interesting objects in the so-called \"Baxter\ncombinatorial family\". In particular, there exists a simple one-to-one\ncorrespondence between mosaic floorplans and Baxter permutations. As a result,\nthe methods introduced in this paper also lead to an optimal binary\nrepresentation of Baxter permutations and all objects in the Baxter\ncombinatorial family.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 17:11:39 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2011 20:14:16 GMT"}], "update_date": "2011-11-23", "authors_parsed": [["He", "Bryan Dawei", ""]]}, {"id": "1111.5200", "submitter": "Pradipta Mitra", "authors": "Magnus M. Halldorsson and Pradipta Mitra", "title": "Wireless Capacity and Admission Control in Cognitive Radio", "comments": "to appear in INFOCOM 2012, 16 pages, 4 fgures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give algorithms with constant-factor performance guarantees for several\ncapacity and throughput problems in the SINR model. The algorithms are all\nbased on a novel LP formulation for capacity problems. First, we give a new\nconstant-factor approximation algorithm for selecting the maximum subset of\nlinks that can be scheduled simultaneously, under any non-decreasing and\nsublinear power assignment. For the case of uniform power, we extend this to\nthe case of variable QoS requirements and link-dependent noise terms. Second,\nwe approximate a problem related to cognitive radio: find a maximum set of\nlinks that can be simultaneously scheduled without affecting a given set of\npreviously assigned links. Finally, we obtain constant-factor approximation of\nweighted capacity under linear power assignment.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 14:08:44 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2012 13:09:16 GMT"}], "update_date": "2012-01-20", "authors_parsed": [["Halldorsson", "Magnus M.", ""], ["Mitra", "Pradipta", ""]]}, {"id": "1111.5220", "submitter": "Giuseppe Ottaviano", "authors": "Roberto Grossi, Giuseppe Ottaviano", "title": "Fast Compressed Tries through Path Decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tries are popular data structures for storing a set of strings, where common\nprefixes are represented by common root-to-node paths. Over fifty years of\nusage have produced many variants and implementations to overcome some of their\nlimitations. We explore new succinct representations of path-decomposed tries\nand experimentally evaluate the corresponding reduction in space usage and\nmemory latency, comparing with the state of the art. We study two cases of\napplications: (1) a compressed dictionary for (compressed) strings, and (2) a\nmonotone minimal perfect hash for strings that preserves their lexicographic\norder.\n  For (1), we obtain data structures that outperform other state-of-the-art\ncompressed dictionaries in space efficiency, while obtaining predictable query\ntimes that are competitive with data structures preferred by the practitioners.\nIn (2), our tries perform several times faster than other trie-based monotone\nperfect hash functions, while occupying nearly the same space.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 15:28:03 GMT"}, {"version": "v2", "created": "Sat, 3 Dec 2011 14:42:26 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Grossi", "Roberto", ""], ["Ottaviano", "Giuseppe", ""]]}, {"id": "1111.5305", "submitter": "Neal E. Young", "authors": "Arman Yousefi and Neal E. Young", "title": "On a Linear Program for Minimum-Weight Triangulation", "comments": "To appear in SICOMP. Extended abstract appeared in SODA 2012", "journal-ref": "SIAM Journal on Computing 43(1):25-51(2014)", "doi": "10.1137/120887928", "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimum-weight triangulation (MWT) is NP-hard. It has a polynomial-time\nconstant-factor approximation algorithm, and a variety of effective polynomial-\ntime heuristics that, for many instances, can find the exact MWT. Linear\nprograms (LPs) for MWT are well-studied, but previously no connection was known\nbetween any LP and any approximation algorithm or heuristic for MWT. Here we\nshow the first such connections: for an LP formulation due to Dantzig et al.\n(1985): (i) the integrality gap is bounded by a constant; (ii) given any\ninstance, if the aforementioned heuristics find the MWT, then so does the LP.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 19:49:25 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2013 18:31:36 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Yousefi", "Arman", ""], ["Young", "Neal E.", ""]]}, {"id": "1111.5357", "submitter": "Hermann Gruber", "authors": "Hermann Gruber", "title": "Digraph Complexity Measures and Applications in Formal Language Theory", "comments": "19 pages, 1 figure", "journal-ref": "Discrete Mathematics & Theoretical Computer Science,\n  14(2):189-204, 2012", "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate structural complexity measures on digraphs, in particular the\ncycle rank. This concept is intimately related to a classical topic in formal\nlanguage theory, namely the star height of regular languages. We explore this\nconnection, and obtain several new algorithmic insights regarding both cycle\nrank and star height. Among other results, we show that computing the cycle\nrank is NP-complete, even for sparse digraphs of maximum outdegree 2.\nNotwithstanding, we provide both a polynomial-time approximation algorithm and\nan exponential-time exact algorithm for this problem. The former algorithm\nyields an O((log n)^(3/2))- approximation in polynomial time, whereas the\nlatter yields the optimum solution, and runs in time and space O*(1.9129^n) on\ndigraphs of maximum outdegree at most two. Regarding the star height problem,\nwe identify a subclass of the regular languages for which we can precisely\ndetermine the computational complexity of the star height problem. Namely, the\nstar height problem for bideterministic languages is NP-complete, and this\nholds already for binary alphabets. Then we translate the algorithmic results\nconcerning cycle rank to the bideterministic star height problem, thus giving a\npolynomial-time approximation as well as a reasonably fast exact exponential\nalgorithm for bideterministic star height.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 22:38:55 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Gruber", "Hermann", ""]]}, {"id": "1111.5382", "submitter": "Zoltan Toroczkai", "authors": "Maria Ercsey-Ravasz, Ryan Lichtenwalter, Nitesh V. Chawla and Zoltan\n  Toroczkai", "title": "Range-limited Centrality Measures in Complex Networks", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present a range-limited approach to centrality measures in both\nnon-weighted and weighted directed complex networks. We introduce an efficient\nmethod that generates for every node and every edge its betweenness centrality\nbased on shortest paths of lengths not longer than $\\ell = 1,...,L$ in case of\nnon-weighted networks, and for weighted networks the corresponding quantities\nbased on minimum weight paths with path weights not larger than $w_{\\ell}=\\ell\n\\Delta$, $\\ell=1,2...,L=R/\\Delta$. These measures provide a systematic\ndescription on the positioning importance of a node (edge) with respect to its\nnetwork neighborhoods 1-step out, 2-steps out, etc. up to including the whole\nnetwork. We show that range-limited centralities obey universal scaling laws\nfor large non-weighted networks. As the computation of traditional centrality\nmeasures is costly, this scaling behavior can be exploited to efficiently\nestimate centralities of nodes and edges for all ranges, including the\ntraditional ones. The scaling behavior can also be exploited to show that the\nranking top-list of nodes (edges) based on their range-limited centralities\nquickly freezes as function of the range, and hence the diameter-range top-list\ncan be efficiently predicted. We also show how to estimate the typical largest\nnode-to-node distance for a network of $N$ nodes, exploiting the aforementioned\nscaling behavior. These observations are illustrated on model networks and on a\nlarge social network inferred from cell-phone trace logs ($\\sim 5.5\\times 10^6$\nnodes and $\\sim 2.7\\times 10^7$ edges). Finally, we apply these concepts to\nefficiently detect the vulnerability backbone of a network (defined as the\nsmallest percolating cluster of the highest betweenness nodes and edges) and\nillustrate the importance of weight-based centrality measures in weighted\nnetworks in detecting such backbones.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 01:23:44 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Ercsey-Ravasz", "Maria", ""], ["Lichtenwalter", "Ryan", ""], ["Chawla", "Nitesh V.", ""], ["Toroczkai", "Zoltan", ""]]}, {"id": "1111.5386", "submitter": "Jiangwei Pan", "authors": "Ho-Leung Chan, Tak-Wah Lam, Lap-Kei Lee, Jiangwei Pan, Hing-Fung Ting,\n  Qin Zhang", "title": "Edit Distance to Monotonicity in Sliding Windows", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream of items each associated with a numerical value, its edit\ndistance to monotonicity is the minimum number of items to remove so that the\nremaining items are non-decreasing with respect to the numerical value. The\nspace complexity of estimating the edit distance to monotonicity of a data\nstream is becoming well-understood over the past few years. Motivated by\napplications on network quality monitoring, we extend the study to estimating\nthe edit distance to monotonicity of a sliding window covering the $w$ most\nrecent items in the stream for any $w \\ge 1$. We give a deterministic algorithm\nwhich can return an estimate within a factor of $(4+\\eps)$ using\n$O(\\frac{1}{\\eps^2} \\log^2(\\eps w))$ space.\n  We also extend the study in two directions. First, we consider a stream where\neach item is associated with a value from a partial ordered set. We give a\nrandomized $(4+\\epsilon)$-approximate algorithm using $O(\\frac{1}{\\epsilon^2}\n\\log \\epsilon^2 w \\log w)$ space. Second, we consider an out-of-order stream\nwhere each item is associated with a creation time and a numerical value, and\nitems may be out of order with respect to their creation times. The goal is to\nestimate the edit distance to monotonicity with respect to the numerical value\nof items arranged in the order of creation times. We show that any randomized\nconstant-approximate algorithm requires linear space.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 02:08:09 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Chan", "Ho-Leung", ""], ["Lam", "Tak-Wah", ""], ["Lee", "Lap-Kei", ""], ["Pan", "Jiangwei", ""], ["Ting", "Hing-Fung", ""], ["Zhang", "Qin", ""]]}, {"id": "1111.5414", "submitter": "Michael Bannister", "authors": "Michael J. Bannister and David Eppstein", "title": "Randomized Speedup of the Bellman-Ford Algorithm", "comments": "12 Pages, 6 Figures, ANALCO 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a variant of the Bellman-Ford algorithm for single-source\nshortest paths in graphs with negative edges but no negative cycles that\nrandomly permutes the vertices and uses this randomized order to process the\nvertices within each pass of the algorithm. The modification reduces the\nworst-case expected number of relaxation steps of the algorithm, compared to\nthe previously-best variant by Yen (1970), by a factor of 2/3 with high\nprobability. We also use our high probability bound to add negative cycle\ndetection to the randomized algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 06:45:33 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Bannister", "Michael J.", ""], ["Eppstein", "David", ""]]}, {"id": "1111.5442", "submitter": "Richard Schmied", "authors": "Marek Karpinski and Richard Schmied", "title": "Improved Lower Bounds for the Shortest Superstring and Related Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation hardness of the Shortest Superstring, the Maximal\nCompression and the Maximum Asymmetric Traveling Salesperson (MAX-ATSP)\nproblem. We introduce a new reduction method that produces strongly restricted\ninstances of the Shortest Superstring problem, in which the maximal orbit size\nis eight (with no character appearing more than eight times) and all given\nstrings having length four. Based on this reduction method, we are able to\nimprove the best up to now known approximation lower bound for the Shortest\nSuperstring problem and the Maximal Compression problem by an order of\nmagnitude. The results imply also an improved approximation lower bound for the\nMAX-ATSP problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 10:00:50 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2012 12:42:27 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2012 19:44:15 GMT"}], "update_date": "2012-08-28", "authors_parsed": [["Karpinski", "Marek", ""], ["Schmied", "Richard", ""]]}, {"id": "1111.5473", "submitter": "Thomas Rothvoss", "authors": "Thomas Rothvo{\\ss}", "title": "Directed Steiner Tree and the Lasserre Hierarchy", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal for the Directed Steiner Tree problem is to find a minimum cost tree\nin a directed graph G=(V,E) that connects all terminals X to a given root r. It\nis well known that modulo a logarithmic factor it suffices to consider acyclic\ngraphs where the nodes are arranged in L <= log |X| levels. Unfortunately the\nnatural LP formulation has a |X|^(1/2) integrality gap already for 5 levels. We\nshow that for every L, the O(L)-round Lasserre Strengthening of this LP has\nintegrality gap O(L log |X|). This provides a polynomial time\n|X|^{epsilon}-approximation and a O(log^3 |X|) approximation in O(n^{log |X|)\ntime, matching the best known approximation guarantee obtained by a greedy\nalgorithm of Charikar et al.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 12:21:33 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2012 22:50:52 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["Rothvo\u00df", "Thomas", ""]]}, {"id": "1111.5528", "submitter": "Guillaume Aupy", "authors": "Guillaume Aupy, Anne Benoit and Yves Robert", "title": "Energy-aware scheduling under reliability and makespan constraints", "comments": "22 pages. A 10 pages version should appear in HiPC'12", "journal-ref": null, "doi": null, "report-no": "Inria Research Report 7757", "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a task graph mapped on a set of homogeneous processors. We aim at\nminimizing the energy consumption while enforcing two constraints: a prescribed\nbound on the execution time (or makespan), and a reliability threshold. Dynamic\nvoltage and frequency scaling (DVFS) is an approach frequently used to reduce\nthe energy consumption of a schedule, but slowing down the execution of a task\nto save energy is decreasing the reliability of the execution. In this work, to\nimprove the reliability of a schedule while reducing the energy consumption, we\nallow for the re-execution of some tasks. We assess the complexity of the\ntri-criteria scheduling problem (makespan, reliability, energy) of deciding\nwhich task to re-execute, and at which speed each execution of a task should be\ndone, with two different speed models: either processors can have arbitrary\nspeeds (continuous model), or a processor can run at a finite number of\ndifferent speeds and change its speed during a computation (VDD model). We\npropose several novel tri-criteria scheduling heuristics under the continuous\nspeed model, and we evaluate them through a set of simulations. The two best\nheuristics turn out to be very efficient and complementary.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 15:42:57 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2012 12:06:15 GMT"}], "update_date": "2012-08-03", "authors_parsed": [["Aupy", "Guillaume", ""], ["Benoit", "Anne", ""], ["Robert", "Yves", ""]]}, {"id": "1111.5548", "submitter": "Milan Tasi\\'c", "authors": "Milan B. Tasi\\'c, Predrag S. Stanimirovi\\'c and Selver H. Pepi\\'c", "title": "Computation of generalized inverses using Php/MySql environment", "comments": "International Journal of Computer Mathematics, Volume 88, Issue 11,\n  2011", "journal-ref": null, "doi": "10.1080/00207160.2010.541453", "report-no": null, "categories": "cs.DB cs.DS math.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The main aim of this paper is to develop a client/server-based model for\ncomputing the weighted Moore-Penrose inverse using the partitioning method as\nwell as for storage of generated results. The web application is developed in\nthe PHP/MySQL environment. The source code is open and free for testing by\nusing a web browser. Influence of different matrix representations and storage\nsystems on the computational time is investigated. The CPU time for searching\nthe previously stored pseudo-inverses is compared with the CPU time spent for\nnew computation of the same inverses.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 16:47:10 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Tasi\u0107", "Milan B.", ""], ["Stanimirovi\u0107", "Predrag S.", ""], ["Pepi\u0107", "Selver H.", ""]]}, {"id": "1111.5572", "submitter": "Matei Zaharia", "authors": "Matei Zaharia, William J. Bolosky, Kristal Curtis, Armando Fox, David\n  Patterson, Scott Shenker, Ion Stoica, Richard M. Karp, Taylor Sittler", "title": "Faster and More Accurate Sequence Alignment with SNAP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Scalable Nucleotide Alignment Program (SNAP), a new short and\nlong read aligner that is both more accurate (i.e., aligns more reads with\nfewer errors) and 10-100x faster than state-of-the-art tools such as BWA.\nUnlike recent aligners based on the Burrows-Wheeler transform, SNAP uses a\nsimple hash index of short seed sequences from the genome, similar to BLAST's.\nHowever, SNAP greatly reduces the number and cost of local alignment checks\nperformed through several measures: it uses longer seeds to reduce the false\npositive locations considered, leverages larger memory capacities to speed\nindex lookup, and excludes most candidate locations without fully computing\ntheir edit distance to the read. The result is an algorithm that scales well\nfor reads from one hundred to thousands of bases long and provides a rich error\nmodel that can match classes of mutations (e.g., longer indels) that today's\nfast aligners ignore. We calculate that SNAP can align a dataset with 30x\ncoverage of a human genome in less than an hour for a cost of $2 on Amazon EC2,\nwith higher accuracy than BWA. Finally, we describe ongoing work to further\nimprove SNAP.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 17:46:03 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Zaharia", "Matei", ""], ["Bolosky", "William J.", ""], ["Curtis", "Kristal", ""], ["Fox", "Armando", ""], ["Patterson", "David", ""], ["Shenker", "Scott", ""], ["Stoica", "Ion", ""], ["Karp", "Richard M.", ""], ["Sittler", "Taylor", ""]]}, {"id": "1111.5872", "submitter": "Cedric Chauve", "authors": "Ahmad Mahmoody-Ghaidary and Cedric Chauve and Ladislav Stacho", "title": "Tractability results for the Double-Cut-and-Join circular median problem", "comments": "12 pages, 6 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The circular median problem in the Double-Cut-and-Join (DCJ) distance asks to\nfind, for three given genomes, a fourth circular genome that minimizes the sum\nof the mutual distances with the three other ones. This problem has been shown\nto be NP-complete. We show here that, if the number of vertices of degree 3 in\nthe breakpoint graph of the three input genomes is fixed, then the problem is\ntractable\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2011 23:53:48 GMT"}], "update_date": "2011-11-28", "authors_parsed": [["Mahmoody-Ghaidary", "Ahmad", ""], ["Chauve", "Cedric", ""], ["Stacho", "Ladislav", ""]]}, {"id": "1111.5893", "submitter": "R Inkulu", "authors": "Rajasekhar Inkulu, Sanjiv Kapoor", "title": "ANN queries: covering Voronoi diagram with hyperboxes", "comments": "This paper has been withdrawn by the authors. Not interesting to have\n  it around", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $S$ of $n$ points in $d$-dimensional Euclidean metric space $X$\nand a small positive real number $\\epsilon$, we present an algorithm to\npreprocess $S$ and answer queries that require finding a set $S' \\subseteq S$\nof $\\epsilon$-approximate nearest neighbors (ANNs) to a given query point $q\n\\in X$. The following are the characteristics of points belonging to set $S'$:\n  - $\\forall s \\in S'$, $\\exists$ a point $p \\in X$ such that $|pq| \\le\n\\epsilon$ and the nearest neighbor of $p$ is $s$, and\n  - $\\exists$ a $s' \\in S'$ such that $s'$ is a nearest neighbor of $q$.\n  During the preprocessing phase, from the Voronoi diagram of $S$ we construct\na set of box trees of size $O(4^d\\frac{V}{\\delta}(\\frac{\\pi}{\\epsilon})^{d-1})$\nwhich facilitate in querying ANNs of any input query point in $O(\\frac{1}{d}lg\n\\frac{V}{\\delta} + (\\frac{\\pi}{\\epsilon})^{d-1})$ time. Here $\\delta$ equals to\n$(\\frac{\\epsilon}{2\\sqrt{d}})^d$, and $V$ is the volume of a large bounding box\nthat contains all the points of set $S$. The average case cardinality of $S'$\nis shown to rely on $S$ and $\\epsilon$.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2011 05:23:06 GMT"}, {"version": "v2", "created": "Mon, 16 Jun 2014 21:14:32 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Inkulu", "Rajasekhar", ""], ["Kapoor", "Sanjiv", ""]]}, {"id": "1111.6224", "submitter": "Hsien-Kuei Hwang", "authors": "Hsien-Kuei Hwang, Tsung-Hsi Tsai, Wei-Mei Chen", "title": "Threshold phenomena in k-dominant skylines of random samples", "comments": "38 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skylines emerged as a useful notion in database queries for selecting\nrepresentative groups in multivariate data samples for further decision making,\nmulti-objective optimization or data processing, and the $k$-dominant skylines\nwere naturally introduced to resolve the abundance of skylines when the\ndimensionality grows or when the coordinates are negatively correlated. We\nprove in this paper that the expected number of $k$-dominant skylines is\nasymptotically zero for large samples when $1\\le k\\le d-1$ under two reasonable\n(continuous) probability assumptions of the input points, $d$ being the\n(finite) dimensionality, in contrast to the asymptotic unboundedness when\n$k=d$. In addition to such an asymptotic zero-infinity property, we also\nestablish a sharp threshold phenomenon for the expected ($d-1$)-dominant\nskylines when the dimensionality is allowed to grow with $n$. Several related\nissues such as the dominant cycle structures and numerical aspects, are also\nbriefly studied.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2011 04:36:53 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Hwang", "Hsien-Kuei", ""], ["Tsai", "Tsung-Hsi", ""], ["Chen", "Wei-Mei", ""]]}, {"id": "1111.6321", "submitter": "Kamen Lozev", "authors": "Kamen Lozev", "title": "Shape and Trajectory Tracking of Moving Obstacles", "comments": "22 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents new methods and algorithms for tracking the shape and\ntrajectory of moving reflecting obstacles with broken rays, or rays reflecting\nat an obstacle. While in tomography the focus of the reconstruction method is\nto recover the velocity structure of the domain, the shape and trajectory\nreconstruction procedure directly finds the shape and trajectory of the\nobstacle. The physical signal carrier for this innovative method are ultrasonic\nbeams. When the speed of sound is constant, the rays are straight line segments\nand the shape and trajectory of moving objects will be reconstructed with\nmethods based on the travel time equation and ellipsoid geometry. For variable\nspeed of sound, we start with the eikonal equation and a system of differential\nequations that has its origins in acoustics and seismology. In this case, the\nrays are curves that are not necessarily straight line segments and we develop\nalgorithms for shape and trajectory tracking based on the numerical solution of\nthese equations. We present methods and algorithms for shape and trajectory\ntracking of moving obstacles with reflected rays when the location of the\nreceiver of the reflected ray is not known in advance. The shape and trajectory\ntracking method is very efficient because it is not necessary for the reflected\nsignal to traverse the whole domain or the same path back to the transmitter.\nIt could be received close to the point of reflection or far away from the\ntransmitter. This optimizes the energy spent by transmitters for tracking the\nobject, reduces signal attenuation and improves image resolution. It is a safe\nand secure method. We also present algorithms for tracking the shape and\ntrajectory of absorbing obstacles. The new methods and algorithms for shape and\ntrajectory tracking enable new applications and an application to one-hop\nInternet routing is presented.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 00:10:06 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Lozev", "Kamen", ""]]}, {"id": "1111.6519", "submitter": "Dzmitry Sledneu", "authors": "Andrzej Lingas, Dzmitry Sledneu", "title": "A Combinatorial Algorithm for All-Pairs Shortest Paths in Directed\n  Vertex-Weighted Graphs with Applications to Disc Graphs", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-27660-6_31", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing all-pairs shortest paths in a directed\ngraph with real weights assigned to vertices.\n  For an $n\\times n$ 0-1 matrix $C,$ let $K_{C}$ be the complete weighted graph\non the rows of $C$ where the weight of an edge between two rows is equal to\ntheir Hamming distance. Let $MWT(C)$ be the weight of a minimum weight spanning\ntree of $K_{C}.$\n  We show that the all-pairs shortest path problem for a directed graph $G$ on\n$n$ vertices with nonnegative real weights and adjacency matrix $A_G$ can be\nsolved by a combinatorial randomized algorithm in time\n$$\\widetilde{O}(n^{2}\\sqrt {n + \\min\\{MWT(A_G), MWT(A_G^t)\\}})$$\n  As a corollary, we conclude that the transitive closure of a directed graph\n$G$ can be computed by a combinatorial randomized algorithm in the\naforementioned time. $\\widetilde{O}(n^{2}\\sqrt {n + \\min\\{MWT(A_G),\nMWT(A_G^t)\\}})$\n  We also conclude that the all-pairs shortest path problem for uniform disk\ngraphs, with nonnegative real vertex weights, induced by point sets of bounded\ndensity within a unit square can be solved in time $\\widetilde{O}(n^{2.75})$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 17:14:26 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Lingas", "Andrzej", ""], ["Sledneu", "Dzmitry", ""]]}, {"id": "1111.6685", "submitter": "Hong-Gwa Yeh", "authors": "Chun-Ying Chiang, Liang-Hao Huang, Bo-Jr Li, Jiaojiao Wu, Hong-Gwa Yeh", "title": "Some Results on the Target Set Selection Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a fundamental problem in the area of viral\nmarketing, called T{\\scriptsize ARGET} S{\\scriptsize ET} S{\\scriptsize\nELECTION} problem. We study the problem when the underlying graph is a\nblock-cactus graph, a chordal graph or a Hamming graph. We show that if $G$ is\na block-cactus graph, then the T{\\scriptsize ARGET} S{\\scriptsize ET}\nS{\\scriptsize ELECTION} problem can be solved in linear time, which generalizes\nChen's result \\cite{chen2009} for trees, and the time complexity is much better\nthan the algorithm in \\cite{treewidth} (for bounded treewidth graphs) when\nrestricted to block-cactus graphs. We show that if the underlying graph $G$ is\na chordal graph with thresholds $\\theta(v)\\leq 2$ for each vertex $v$ in $G$,\nthen the problem can be solved in linear time. For a Hamming graph $G$ having\nthresholds $\\theta(v)=2$ for each vertex $v$ of $G$, we precisely determine an\noptimal target set $S$ for $(G,\\theta)$. These results partially answer an open\nproblem raised by Dreyer and Roberts \\cite{Dreyer2009}.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 04:22:33 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Chiang", "Chun-Ying", ""], ["Huang", "Liang-Hao", ""], ["Li", "Bo-Jr", ""], ["Wu", "Jiaojiao", ""], ["Yeh", "Hong-Gwa", ""]]}, {"id": "1111.6698", "submitter": "Shi Li", "authors": "Mohammad Taghi Hajiaghayi, Shi Li", "title": "On the Integrality Gap of the Directed-Component Relaxation for Steiner\n  Tree", "comments": "This paper has been withdrawn due to a crucial error in Lemma 4. In\n  Lemma 4, additional property for $\\{Y'_j\\}$ is needed to guarantee that the\n  family of distributions exists. However, we can not guarantee the condition\n  for every iteration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we show that the integrality gap of the $k$-Directed-Component-\nRelaxation($k$-DCR) LP for the Steiner tree problem, introduced by Byrka,\nGrandoni, Rothvob and Sanita (STOC 2010), is at most $\\ln(4)<1.39$. The proof\nis constructive: we can efficiently find a Steiner tree whose cost is at most\n$\\ln(4)$ times the cost of the optimal fractional $k$-restricted Steiner tree\ngiven by the $k$-DCR LP.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 05:29:28 GMT"}, {"version": "v2", "created": "Sat, 3 Dec 2011 03:32:29 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Hajiaghayi", "Mohammad Taghi", ""], ["Li", "Shi", ""]]}, {"id": "1111.6745", "submitter": "Andreas Emil Feldmann", "authors": "Andreas Emil Feldmann", "title": "Fast Balanced Partitioning is Hard, Even on Grids and Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two kinds of approximation algorithms exist for the k-BALANCED PARTITIONING\nproblem: those that are fast but compute unsatisfying approximation ratios, and\nthose that guarantee high quality ratios but are slow. In this paper we prove\nthat this tradeoff between runtime and solution quality is necessary. For the\nproblem a minimum number of edges in a graph need to be found that, when cut,\npartition the vertices into k equal-sized sets. We develop a reduction\nframework which identifies some necessary conditions on the considered graph\nclass in order to prove the hardness of the problem. We focus on two\ncombinatorially simple but very different classes, namely trees and solid grid\ngraphs. The latter are finite connected subgraphs of the infinite 2D grid\nwithout holes. First we use the framework to show that for solid grid graphs it\nis NP-hard to approximate the optimum number of cut edges within any satisfying\nratio. Then we consider solutions in which the sets may deviate from being\nequal-sized. Our framework is used on grids and trees to prove that no fully\npolynomial time algorithm exists that computes solutions in which the sets are\narbitrarily close to equal-sized. This is true even if the number of edges cut\nis allowed to increase the more stringent the limit on the set sizes is. These\nare the first bicriteria inapproximability results for the problem.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 10:07:18 GMT"}, {"version": "v2", "created": "Mon, 13 Feb 2012 12:12:55 GMT"}, {"version": "v3", "created": "Fri, 24 Feb 2012 10:46:39 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2013 17:28:43 GMT"}, {"version": "v5", "created": "Tue, 29 Jan 2013 02:09:41 GMT"}, {"version": "v6", "created": "Fri, 26 Apr 2019 11:23:19 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Feldmann", "Andreas Emil", ""]]}, {"id": "1111.6842", "submitter": "Aaron Roth", "authors": "Avrim Blum and Aaron Roth", "title": "Fast Private Data Release Algorithms for Sparse Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of accurately answering large classes of statistical\nqueries while preserving differential privacy. Previous approaches to this\nproblem have either been very general but have not had run-time polynomial in\nthe size of the database, have applied only to very limited classes of queries,\nor have relaxed the notion of worst-case error guarantees. In this paper we\nconsider the large class of sparse queries, which take non-zero values on only\npolynomially many universe elements. We give efficient query release algorithms\nfor this class, in both the interactive and the non-interactive setting. Our\nalgorithms also achieve better accuracy bounds than previous general techniques\ndo when applied to sparse queries: our bounds are independent of the universe\nsize. In fact, even the runtime of our interactive mechanism is independent of\nthe universe size, and so can be implemented in the \"infinite universe\" model\nin which no finite universe need be specified by the data curator.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 15:23:08 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Blum", "Avrim", ""], ["Roth", "Aaron", ""]]}, {"id": "1111.6937", "submitter": "Matteo Riondato", "authors": "Matteo Riondato and Eli Upfal", "title": "Efficient Discovery of Association Rules and Frequent Itemsets through\n  Sampling with Tight Performance Guarantees", "comments": "19 pages, 7 figures. A shorter version of this paper appeared in the\n  proceedings of ECML PKDD 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tasks of extracting (top-$K$) Frequent Itemsets (FI's) and Association\nRules (AR's) are fundamental primitives in data mining and database\napplications. Exact algorithms for these problems exist and are widely used,\nbut their running time is hindered by the need of scanning the entire dataset,\npossibly multiple times. High quality approximations of FI's and AR's are\nsufficient for most practical uses, and a number of recent works explored the\napplication of sampling for fast discovery of approximate solutions to the\nproblems. However, these works do not provide satisfactory performance\nguarantees on the quality of the approximation, due to the difficulty of\nbounding the probability of under- or over-sampling any one of an unknown\nnumber of frequent itemsets. In this work we circumvent this issue by applying\nthe statistical concept of \\emph{Vapnik-Chervonenkis (VC) dimension} to develop\na novel technique for providing tight bounds on the sample size that guarantees\napproximation within user-specified parameters. Our technique applies both to\nabsolute and to relative approximations of (top-$K$) FI's and AR's. The\nresulting sample size is linearly dependent on the VC-dimension of a range\nspace associated with the dataset to be mined. The main theoretical\ncontribution of this work is a proof that the VC-dimension of this range space\nis upper bounded by an easy-to-compute characteristic quantity of the dataset\nwhich we call \\emph{d-index}, and is the maximum integer $d$ such that the\ndataset contains at least $d$ transactions of length at least $d$ such that no\none of them is a superset of or equal to another. We show that this bound is\nstrict for a large class of datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 19:11:50 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2011 14:45:50 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2012 02:39:09 GMT"}, {"version": "v4", "created": "Thu, 21 Jun 2012 12:56:59 GMT"}, {"version": "v5", "created": "Mon, 10 Dec 2012 20:07:02 GMT"}, {"version": "v6", "created": "Fri, 22 Feb 2013 14:32:31 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Riondato", "Matteo", ""], ["Upfal", "Eli", ""]]}, {"id": "1111.6990", "submitter": "Kyle Fox", "authors": "Kyle Fox", "title": "Shortest Non-trivial Cycles in Directed and Undirected Surface Graphs", "comments": "Accepted to SODA 2013. Updated for reviewer comments, to include new\n  results for undirected graphs, and to include new title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G be a graph embedded on a surface of genus g with b boundary cycles. We\ndescribe algorithms to compute multiple types of non-trivial cycles in G, using\ndifferent techniques depending on whether or not G is an undirected graph. If G\nis undirected, then we give an algorithm to compute a shortest non-separating\ncycle in 2^O(g) n log log n time. Similar algorithms are given to compute a\nshortest non-contractible or non-null-homologous cycle in 2^O(g+b) n log log n\ntime. Our algorithms for undirected G combine an algorithm of Kutz with known\ntechniques for efficiently enumerating homotopy classes of curves that may be\nshortest non-trivial cycles.\n  Our main technical contributions in this work arise from assuming G is a\ndirected graph with possibly asymmetric edge weights. For this case, we give an\nalgorithm to compute a shortest non-contractible cycle in G in O((g^3 + g b)n\nlog n) time. In order to achieve this time bound, we use a restriction of the\ninfinite cyclic cover that may be useful in other contexts. We also describe an\nalgorithm to compute a shortest non-null-homologous cycle in G in O((g^2 + g\nb)n log n) time, extending a known algorithm of Erickson to compute a shortest\nnon-separating cycle. In both the undirected and directed cases, our algorithms\nimprove the best time bounds known for many values of g and b.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 21:24:21 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2011 20:42:03 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2012 15:50:06 GMT"}], "update_date": "2012-09-20", "authors_parsed": [["Fox", "Kyle", ""]]}, {"id": "1111.7064", "submitter": "Yitong Yin", "authors": "Liang Li, Pinyan Lu, Yitong Yin", "title": "Correlation Decay up to Uniqueness in Spin Systems", "comments": "This new version has corrected an error in Lemma 21 in Appendix A in\n  the original version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a complete characterization of the two-state anti-ferromagnetic spin\nsystems which are of strong spatial mixing on general graphs. We show that a\ntwo-state anti-ferromagnetic spin system is of strong spatial mixing on all\ngraphs of maximum degree at most $\\Delta$ if and only if the system has a\nunique Gibbs measure on infinite regular trees of degree up to $\\Delta$, where\n$\\Delta$ can be either bounded or unbounded. As a consequence, there exists an\nFPTAS for the partition function of a two-state anti-ferromagnetic spin system\non graphs of maximum degree at most $\\Delta$ when the uniqueness condition is\nsatisfied on infinite regular trees of degree up to $\\Delta$. In particular, an\nFPTAS exists for arbitrary graphs if the uniqueness is satisfied on all\ninfinite regular trees. This covers as special cases all previous algorithmic\nresults for two-state anti-ferromagnetic systems on general-structure graphs.\n  Combining with the FPRAS for two-state ferromagnetic spin systems of\nJerrum-Sinclair and Goldberg-Jerrum-Paterson, and the hardness results of\nSly-Sun and independently of Galanis-Stefankovic-Vigoda, this gives a complete\nclassification, except at the phase transition boundary, of the approximability\nof all two-state spin systems, on either degree-bounded families of graphs or\nfamily of all graphs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 06:56:09 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2012 22:13:40 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 12:55:19 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Li", "Liang", ""], ["Lu", "Pinyan", ""], ["Yin", "Yitong", ""]]}, {"id": "1111.7280", "submitter": "Rico Zenklusen", "authors": "Michel X. Goemans, Neil Olver, Thomas Rothvoss, Rico Zenklusen", "title": "Matroids and Integrality Gaps for Hypergraphic Steiner Tree Relaxations", "comments": "Corrects an issue at the end of Section 3. Various other minor\n  improvements to the exposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Until recently, LP relaxations have played a limited role in the design of\napproximation algorithms for the Steiner tree problem. In 2010, Byrka et al.\npresented a ln(4)+epsilon approximation based on a hypergraphic LP relaxation,\nbut surprisingly, their analysis does not provide a matching bound on the\nintegrality gap.\n  We take a fresh look at hypergraphic LP relaxations for the Steiner tree\nproblem - one that heavily exploits methods and results from the theory of\nmatroids and submodular functions - which leads to stronger integrality gaps,\nfaster algorithms, and a variety of structural insights of independent\ninterest. More precisely, we present a deterministic ln(4)+epsilon\napproximation that compares against the LP value and therefore proves a\nmatching ln(4) upper bound on the integrality gap.\n  Similarly to Byrka et al., we iteratively fix one component and update the LP\nsolution. However, whereas they solve an LP at every iteration after\ncontracting a component, we show how feasibility can be maintained by a greedy\nprocedure on a well-chosen matroid. Apart from avoiding the expensive step of\nsolving a hypergraphic LP at each iteration, our algorithm can be analyzed\nusing a simple potential function. This gives an easy means to determine\nstronger approximation guarantees and integrality gaps when considering\nrestricted graph topologies. In particular, this readily leads to a 73/60 bound\non the integrality gap for quasi-bipartite graphs.\n  For the case of quasi-bipartite graphs, we present a simple algorithm to\ntransform an optimal solution to the bidirected cut relaxation to an optimal\nsolution of the hypergraphic relaxation, leading to a fast 73/60 approximation\nfor quasi-bipartite graphs. Furthermore, we show how the separation problem of\nthe hypergraphic relaxation can be solved by computing maximum flows, providing\na fast independence oracle for our matroids.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 19:27:12 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2011 20:52:10 GMT"}], "update_date": "2011-12-15", "authors_parsed": [["Goemans", "Michel X.", ""], ["Olver", "Neil", ""], ["Rothvoss", "Thomas", ""], ["Zenklusen", "Rico", ""]]}]