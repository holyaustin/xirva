[{"id": "0804.0149", "submitter": "Fabien Mathieu", "authors": "Bruno Gaume (IRIT), Fabien Mathieu (FT R&D, INRIA Rocquencourt)", "title": "From Random Graph to Small World by Wandering", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6489", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous studies show that most known real-world complex networks share\nsimilar properties in their connectivity and degree distribution. They are\ncalled small worlds. This article gives a method to turn random graphs into\nSmall World graphs by the dint of random walks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2008 11:59:43 GMT"}, {"version": "v2", "created": "Wed, 2 Apr 2008 08:12:38 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Gaume", "Bruno", "", "IRIT"], ["Mathieu", "Fabien", "", "FT R&D, INRIA Rocquencourt"]]}, {"id": "0804.0277", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez", "title": "Mapping Semantic Networks to Undirected Networks", "comments": null, "journal-ref": "International Journal of Applied Mathematics and Computer\n  Sciences, volume 5, issue 1, pages 39-42, ISSN:2070-3902, LA-UR-07-5287, 2009", "doi": null, "report-no": "LAUR-07-5287", "categories": "cs.DS", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  There exists an injective, information-preserving function that maps a\nsemantic network (i.e a directed labeled network) to a directed network (i.e. a\ndirected unlabeled network). The edge label in the semantic network is\nrepresented as a topological feature of the directed network. Also, there\nexists an injective function that maps a directed network to an undirected\nnetwork (i.e. an undirected unlabeled network). The edge directionality in the\ndirected network is represented as a topological feature of the undirected\nnetwork. Through function composition, there exists an injective function that\nmaps a semantic network to an undirected network. Thus, aside from space\nconstraints, the semantic network construct does not have any modeling\nfunctionality that is not possible with either a directed or undirected network\nrepresentation. Two proofs of this idea will be presented. The first is a proof\nof the aforementioned function composition concept. The second is a simpler\nproof involving an undirected binary encoding of a semantic network.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2008 01:19:55 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Rodriguez", "Marko A.", ""]]}, {"id": "0804.0362", "submitter": "Lenka Zdeborova", "authors": "John Ardelius, Lenka Zdeborov\\'a", "title": "Exhaustive enumeration unveils clustering and freezing in random 3-SAT", "comments": "4 pages, 3 figures", "journal-ref": "Phys. Rev. E 78, 040101(R) (2008)", "doi": "10.1103/PhysRevE.78.040101", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study geometrical properties of the complete set of solutions of the\nrandom 3-satisfiability problem. We show that even for moderate system sizes\nthe number of clusters corresponds surprisingly well with the theoretic\nasymptotic prediction. We locate the freezing transition in the space of\nsolutions which has been conjectured to be relevant in explaining the onset of\ncomputational hardness in random constraint satisfaction problems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2008 14:32:44 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2008 09:31:46 GMT"}], "update_date": "2008-10-02", "authors_parsed": [["Ardelius", "John", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "0804.0570", "submitter": "Daniel Raible", "authors": "Jianer Chen, Henning Fernau, Dan Ning, Daniel Raible, Jianxin Wang", "title": "A Parameterized Perspective on $P_2$-Packings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  }We study (vertex-disjoint) $P_2$-packings in graphs under a parameterized\nperspective. Starting from a maximal $P_2$-packing $\\p$ of size $j$ we use\nextremal arguments for determining how many vertices of $\\p$ appear in some\n$P_2$-packing of size $(j+1)$. We basically can 'reuse' $2.5j$ vertices. We\nalso present a kernelization algorithm that gives a kernel of size bounded by\n$7k$. With these two results we build an algorithm which constructs a\n$P_2$-packing of size $k$ in time $\\Oh^*(2.482^{3k})$.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2008 14:36:19 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Chen", "Jianer", ""], ["Fernau", "Henning", ""], ["Ning", "Dan", ""], ["Raible", "Daniel", ""], ["Wang", "Jianxin", ""]]}, {"id": "0804.0577", "submitter": "Oskar Sandberg", "authors": "Oskar Sandberg", "title": "Decentralized Search with Random Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A decentralized search algorithm is a method of routing on a random graph\nthat uses only limited, local, information about the realization of the graph.\nIn some random graph models it is possible to define such algorithms which\nproduce short paths when routing from any vertex to any other, while for others\nit is not.\n  We consider random graphs with random costs assigned to the edges. In this\nsituation, we use the methods of stochastic dynamic programming to create a\ndecentralized search method which attempts to minimize the total cost, rather\nthan the number of steps, of each path. We show that it succeeds in doing so\namong all decentralized search algorithms which monotonically approach the\ndestination. Our algorithm depends on knowing the expected cost of routing from\nevery vertex to any other, but we show that this may be calculated iteratively,\nand in practice can be easily estimated from the cost of previous routes and\ncompressed into a small routing table. The methods applied here can also be\napplied directly in other situations, such as efficient searching in graphs\nwith varying vertex degrees.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2008 15:32:29 GMT"}], "update_date": "2008-04-04", "authors_parsed": [["Sandberg", "Oskar", ""]]}, {"id": "0804.0722", "submitter": "Daniel Karapetyan", "authors": "Gregory Gutin, Daniel Karapetyan", "title": "A Memetic Algorithm for the Generalized Traveling Salesman Problem", "comments": "15 pages, to appear in Natural Computing, Springer, available online:\n  http://www.springerlink.com/content/5v4568l492272865/?p=e1779dd02e4d4cbfa49d0d27b19b929f&pi=13", "journal-ref": "Natural Computing 9(1) (2010) 47-60", "doi": "10.1007/s11047-009-9111-6", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized traveling salesman problem (GTSP) is an extension of the\nwell-known traveling salesman problem. In GTSP, we are given a partition of\ncities into groups and we are required to find a minimum length tour that\nincludes exactly one city from each group. The recent studies on this subject\nconsider different variations of a memetic algorithm approach to the GTSP. The\naim of this paper is to present a new memetic algorithm for GTSP with a\npowerful local search procedure. The experiments show that the proposed\nalgorithm clearly outperforms all of the known heuristics with respect to both\nsolution quality and running time. While the other memetic algorithms were\ndesigned only for the symmetric GTSP, our algorithm can solve both symmetric\nand asymmetric instances.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 13:21:40 GMT"}, {"version": "v2", "created": "Tue, 11 Nov 2008 23:58:20 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2009 22:13:27 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Gutin", "Gregory", ""], ["Karapetyan", "Daniel", ""]]}, {"id": "0804.0735", "submitter": "Daniel Karapetyan", "authors": "Gregory Gutin and Daniel Karapetyan", "title": "Generalized Traveling Salesman Problem Reduction Algorithms", "comments": "To appear in Algorithmic Operations Research", "journal-ref": "Algorithmic Operations Research 4 (2009) 144-154", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized traveling salesman problem (GTSP) is an extension of the\nwell-known traveling salesman problem. In GTSP, we are given a partition of\ncities into groups and we are required to find a minimum length tour that\nincludes exactly one city from each group. The aim of this paper is to present\na problem reduction algorithm that deletes redundant vertices and edges,\npreserving the optimal solution. The algorithm's running time is O(N^3) in the\nworst case, but it is significantly faster in practice. The algorithm has\nreduced the problem size by 15-20% on average in our experiments and this has\ndecreased the solution time by 10-60% for each of the considered solvers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 13:36:19 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2009 17:36:47 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Gutin", "Gregory", ""], ["Karapetyan", "Daniel", ""]]}, {"id": "0804.0743", "submitter": "Fabien Mathieu", "authors": "Laurent Viennot (INRIA Rocquencourt), Yacine Boufkhad (INRIA\n  Rocquencourt, LIAFA), Fabien Mathieu (INRIA Rocquencourt, FT R&D), Fabien De\n  Montgolfier (INRIA Rocquencourt, LIAFA), Diego Perino (INRIA Rocquencourt, FT\n  R&D)", "title": "Scalable Distributed Video-on-Demand: Theoretical Bounds and Practical\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6496", "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a distributed system where n nodes called boxes store a large set\nof videos and collaborate to serve simultaneously n videos or less. We explore\nunder which conditions such a system can be scalable while serving any sequence\nof demands. We model this problem through a combination of two algorithms: a\nvideo allocation algorithm and a connection scheduling algorithm. The latter\nplays against an adversary that incrementally proposes video requests.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 14:08:49 GMT"}, {"version": "v2", "created": "Tue, 8 Apr 2008 07:16:36 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Viennot", "Laurent", "", "INRIA Rocquencourt"], ["Boufkhad", "Yacine", "", "INRIA\n  Rocquencourt, LIAFA"], ["Mathieu", "Fabien", "", "INRIA Rocquencourt, FT R&D"], ["De Montgolfier", "Fabien", "", "INRIA Rocquencourt, LIAFA"], ["Perino", "Diego", "", "INRIA Rocquencourt, FT\n  R&D"]]}, {"id": "0804.0936", "submitter": "Shripad Thite", "authors": "Mark de Berg and Shripad Thite", "title": "Cache-Oblivious Selection in Sorted X+Y Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let X[0..n-1] and Y[0..m-1] be two sorted arrays, and define the mxn matrix A\nby A[j][i]=X[i]+Y[j]. Frederickson and Johnson gave an efficient algorithm for\nselecting the k-th smallest element from A. We show how to make this algorithm\nIO-efficient. Our cache-oblivious algorithm performs O((m+n)/B) IOs, where B is\nthe block size of memory transfers.\n", "versions": [{"version": "v1", "created": "Sun, 6 Apr 2008 22:31:04 GMT"}], "update_date": "2008-04-08", "authors_parsed": [["de Berg", "Mark", ""], ["Thite", "Shripad", ""]]}, {"id": "0804.0940", "submitter": "Shripad Thite", "authors": "Shripad Thite", "title": "Optimum Binary Search Trees on the Hierarchical Memory Model", "comments": "M.S. thesis; Department of Computer Science, University of Illinois\n  at Urbana-Champaign; CSL Technical Report UILU-ENG-00-2215 ACT-142; November\n  2000", "journal-ref": null, "doi": null, "report-no": "UILU-ENG-00-2215 ACT-142", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hierarchical Memory Model (HMM) of computation is similar to the standard\nRandom Access Machine (RAM) model except that the HMM has a non-uniform memory\norganized in a hierarchy of levels numbered 1 through h. The cost of accessing\na memory location increases with the level number, and accesses to memory\nlocations belonging to the same level cost the same. Formally, the cost of a\nsingle access to the memory location at address a is given by m(a), where m: N\n-> N is the memory cost function, and the h distinct values of m model the\ndifferent levels of the memory hierarchy.\n  We study the problem of constructing and storing a binary search tree (BST)\nof minimum cost, over a set of keys, with probabilities for successful and\nunsuccessful searches, on the HMM with an arbitrary number of memory levels,\nand for the special case h=2.\n  While the problem of constructing optimum binary search trees has been well\nstudied for the standard RAM model, the additional parameter m for the HMM\nincreases the combinatorial complexity of the problem. We present two dynamic\nprogramming algorithms to construct optimum BSTs bottom-up. These algorithms\nrun efficiently under some natural assumptions about the memory hierarchy. We\nalso give an efficient algorithm to construct a BST that is close to optimum,\nby modifying a well-known linear-time approximation algorithm for the RAM\nmodel. We conjecture that the problem of constructing an optimum BST for the\nHMM with an arbitrary memory cost function m is NP-complete.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 00:06:08 GMT"}], "update_date": "2008-04-08", "authors_parsed": [["Thite", "Shripad", ""]]}, {"id": "0804.1115", "submitter": "Oskar Sandberg", "authors": "Olof Mogren, Oskar Sandberg, Vilhelm Verendel and Devdatt Dubhashi", "title": "Adaptive Dynamics of Realistic Small-World Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuing in the steps of Jon Kleinberg's and others celebrated work on\ndecentralized search in small-world networks, we conduct an experimental\nanalysis of a dynamic algorithm that produces small-world networks. We find\nthat the algorithm adapts robustly to a wide variety of situations in realistic\ngeographic networks with synthetic test data and with real world data, even\nwhen vertices are uneven and non-homogeneously distributed.\n  We investigate the same algorithm in the case where some vertices are more\npopular destinations for searches than others, for example obeying power-laws.\nWe find that the algorithm adapts and adjusts the networks according to the\ndistributions, leading to improved performance. The ability of the dynamic\nprocess to adapt and create small worlds in such diverse settings suggests a\npossible mechanism by which such networks appear in nature.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 19:39:59 GMT"}], "update_date": "2008-04-08", "authors_parsed": [["Mogren", "Olof", ""], ["Sandberg", "Oskar", ""], ["Verendel", "Vilhelm", ""], ["Dubhashi", "Devdatt", ""]]}, {"id": "0804.1170", "submitter": "Daniel \\v{S}tefankovi\\v{c}", "authors": "Satyaki Mahalanabis, Daniel Stefankovic", "title": "Approximating L1-distances between mixture distributions using random\n  projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing L1-distances between every pair\nofcprobability densities from a given family. We point out that the technique\nof Cauchy random projections (Indyk'06) in this context turns into stochastic\nintegrals with respect to Cauchy motion.\n  For piecewise-linear densities these integrals can be sampled from if one can\nsample from the stochastic integral of the function x->(1,x). We give an\nexplicit density function for this stochastic integral and present an efficient\nsampling algorithm. As a consequence we obtain an efficient algorithm to\napproximate the L1-distances with a small relative error.\n  For piecewise-polynomial densities we show how to approximately sample from\nthe distributions resulting from the stochastic integrals. This also results in\nan efficient algorithm to approximate the L1-distances, although our inability\nto get exact samples worsens the dependence on the parameters.\n", "versions": [{"version": "v1", "created": "Tue, 8 Apr 2008 02:11:13 GMT"}], "update_date": "2008-04-09", "authors_parsed": [["Mahalanabis", "Satyaki", ""], ["Stefankovic", "Daniel", ""]]}, {"id": "0804.1409", "submitter": "Murat Ali Bayir Mr.", "authors": "Murat Ali Bayir, Ismail Hakki Toroslu, Ahmet Cosar, Guven Fidan", "title": "Discovering More Accurate Frequent Web Usage Patterns", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web usage mining is a type of web mining, which exploits data mining\ntechniques to discover valuable information from navigation behavior of World\nWide Web users. As in classical data mining, data preparation and pattern\ndiscovery are the main issues in web usage mining. The first phase of web usage\nmining is the data processing phase, which includes the session reconstruction\noperation from server logs. Session reconstruction success directly affects the\nquality of the frequent patterns discovered in the next phase. In reactive web\nusage mining techniques, the source data is web server logs and the topology of\nthe web pages served by the web server domain. Other kinds of information\ncollected during the interactive browsing of web site by user, such as cookies\nor web logs containing similar information, are not used. The next phase of web\nusage mining is discovering frequent user navigation patterns. In this phase,\npattern discovery methods are applied on the reconstructed sessions obtained in\nthe first phase in order to discover frequent user patterns. In this paper, we\npropose a frequent web usage pattern discovery method that can be applied after\nsession reconstruction phase. In order to compare accuracy performance of\nsession reconstruction phase and pattern discovery phase, we have used an agent\nsimulator, which models behavior of web users and generates web user navigation\nas well as the log data kept by the web server.\n", "versions": [{"version": "v1", "created": "Wed, 9 Apr 2008 05:46:26 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Bayir", "Murat Ali", ""], ["Toroslu", "Ismail Hakki", ""], ["Cosar", "Ahmet", ""], ["Fidan", "Guven", ""]]}, {"id": "0804.1724", "submitter": "Sudipto Guha", "authors": "Sudipto Guha and Kamesh Munagala and Saswati Sarkar", "title": "Information Acquisition and Exploitation in Multichannel Wireless\n  Networks", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wireless system with multiple channels is considered, where each channel\nhas several transmission states. A user learns about the instantaneous state of\nan available channel by transmitting a control packet in it. Since probing all\nchannels consumes significant energy and time, a user needs to determine what\nand how much information it needs to acquire about the instantaneous states of\nthe available channels so that it can maximize its transmission rate. This\nmotivates the study of the trade-off between the cost of information\nacquisition and its value towards improving the transmission rate.\n  A simple model is presented for studying this information acquisition and\nexploitation trade-off when the channels are multi-state, with different\ndistributions and information acquisition costs. The objective is to maximize a\nutility function which depends on both the cost and value of information.\nSolution techniques are presented for computing near-optimal policies with\nsuccinct representation in polynomial time. These policies provably achieve at\nleast a fixed constant factor of the optimal utility on any problem instance,\nand in addition, have natural characterizations. The techniques are based on\nexploiting the structure of the optimal policy, and use of Lagrangean\nrelaxations which simplify the space of approximately optimal solutions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2008 14:53:30 GMT"}], "update_date": "2008-04-11", "authors_parsed": [["Guha", "Sudipto", ""], ["Munagala", "Kamesh", ""], ["Sarkar", "Saswati", ""]]}, {"id": "0804.1845", "submitter": "Ely Porat", "authors": "Ely Porat", "title": "An Optimal Bloom Filter Replacement Based on Matrix Solving", "comments": "A lectureon this paper will be available in Google video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a method for holding a dictionary data structure, which maps keys\nto values, in the spirit of Bloom Filters. The space requirements of the\ndictionary we suggest are much smaller than those of a hashtable. We allow\nstoring n keys, each mapped to value which is a string of k bits. Our suggested\nmethod requires nk + o(n) bits space to store the dictionary, and O(n) time to\nproduce the data structure, and allows answering a membership query in O(1)\nmemory probes. The dictionary size does not depend on the size of the keys.\nHowever, reducing the space requirements of the data structure comes at a\ncertain cost. Our dictionary has a small probability of a one sided error. When\nattempting to obtain the value for a key that is stored in the dictionary we\nalways get the correct answer. However, when testing for membership of an\nelement that is not stored in the dictionary, we may get an incorrect answer,\nand when requesting the value of such an element we may get a certain random\nvalue. Our method is based on solving equations in GF(2^k) and using several\nhash functions. Another significant advantage of our suggested method is that\nwe do not require using sophisticated hash functions. We only require pairwise\nindependent hash functions. We also suggest a data structure that requires only\nnk bits space, has O(n2) preprocessing time, and has a O(log n) query time.\nHowever, this data structures requires a uniform hash functions. In order\nreplace a Bloom Filter of n elements with an error proability of 2^{-k}, we\nrequire nk + o(n) memory bits, O(1) query time, O(n) preprocessing time, and\nonly pairwise independent hash function. Even the most advanced previously\nknown Bloom Filter would require nk+O(n) space, and a uniform hash functions,\nso our method is significantly less space consuming especially when k is small.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2008 11:24:04 GMT"}], "update_date": "2008-04-14", "authors_parsed": [["Porat", "Ely", ""]]}, {"id": "0804.1888", "submitter": "Latorre", "authors": "Frank Verstraete, J. Ignacio Cirac, Jose I. Latorre", "title": "Quantum circuits for strongly correlated quantum systems", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevA.79.032316", "report-no": null, "categories": "quant-ph cond-mat.str-el cs.DS hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, we have witnessed an explosion of experimental tools by\nwhich quantum systems can be manipulated in a controlled and coherent way. One\nof the most important goals now is to build quantum simulators, which would\nopen up the possibility of exciting experiments probing various theories in\nregimes that are not achievable under normal lab circumstances. Here we present\na novel approach to gain detailed control on the quantum simulation of strongly\ncorrelated quantum many-body systems by constructing the explicit quantum\ncircuits that diagonalize their dynamics. We show that the exact quantum\ncircuits underlying some of the most relevant many-body Hamiltonians only need\na finite amount of local gates. As a particularly simple instance, the full\ndynamics of a one-dimensional Quantum Ising model in a transverse field with\nfour spins is shown to be reproduced using a quantum circuit of only six local\ngates. This opens up the possibility of experimentally producing strongly\ncorrelated states, their time evolution at zero time and even thermal\nsuperpositions at zero temperature. Our method also allows to uncover the exact\ncircuits corresponding to models that exhibit topological order and to\nstabilizer states.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2008 12:52:44 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Verstraete", "Frank", ""], ["Cirac", "J. Ignacio", ""], ["Latorre", "Jose I.", ""]]}, {"id": "0804.2032", "submitter": "Frederic Dorn Harald", "authors": "Paul Bonsma and Frederic Dorn", "title": "Tight Bounds and Faster Algorithms for Directed Max-Leaf Problems", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An out-tree $T$ of a directed graph $D$ is a rooted tree subgraph with all\narcs directed outwards from the root. An out-branching is a spanning out-tree.\nBy $l(D)$ and $l_s(D)$ we denote the maximum number of leaves over all\nout-trees and out-branchings of $D$, respectively.\n  We give fixed parameter tractable algorithms for deciding whether $l_s(D)\\geq\nk$ and whether $l(D)\\geq k$ for a digraph $D$ on $n$ vertices, both with time\ncomplexity $2^{O(k\\log k)} \\cdot n^{O(1)}$. This improves on previous\nalgorithms with complexity $2^{O(k^3\\log k)} \\cdot n^{O(1)}$ and $2^{O(k\\log^2\nk)} \\cdot n^{O(1)}$, respectively.\n  To obtain the complexity bound in the case of out-branchings, we prove that\nwhen all arcs of $D$ are part of at least one out-branching, $l_s(D)\\geq\nl(D)/3$. The second bound we prove in this paper states that for strongly\nconnected digraphs $D$ with minimum in-degree 3, $l_s(D)\\geq \\Theta(\\sqrt{n})$,\nwhere previously $l_s(D)\\geq \\Theta(\\sqrt[3]{n})$ was the best known bound.\nThis bound is tight, and also holds for the larger class of digraphs with\nminimum in-degree 3 in which every arc is part of at least one out-branching.\n", "versions": [{"version": "v1", "created": "Sat, 12 Apr 2008 20:50:59 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Bonsma", "Paul", ""], ["Dorn", "Frederic", ""]]}, {"id": "0804.2097", "submitter": "Tim Roughgarden", "authors": "Jason D. Hartline and Tim Roughgarden", "title": "Optimal Mechansim Design and Money Burning", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mechanism design is now a standard tool in computer science for aligning the\nincentives of self-interested agents with the objectives of a system designer.\nThere is, however, a fundamental disconnect between the traditional application\ndomains of mechanism design (such as auctions) and those arising in computer\nscience (such as networks): while monetary transfers (i.e., payments) are\nessential for most of the known positive results in mechanism design, they are\nundesirable or even technologically infeasible in many computer systems.\nClassical impossibility results imply that the reach of mechanisms without\ntransfers is severely limited.\n  Computer systems typically do have the ability to reduce service\nquality--routing systems can drop or delay traffic, scheduling protocols can\ndelay the release of jobs, and computational payment schemes can require\ncomputational payments from users (e.g., in spam-fighting systems). Service\ndegradation is tantamount to requiring that users burn money}, and such\n``payments'' can be used to influence the preferences of the agents at a cost\nof degrading the social surplus.\n  We develop a framework for the design and analysis of money-burning\nmechanisms to maximize the residual surplus--the total value of the chosen\noutcome minus the payments required.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2008 04:32:45 GMT"}], "update_date": "2008-04-15", "authors_parsed": [["Hartline", "Jason D.", ""], ["Roughgarden", "Tim", ""]]}, {"id": "0804.2112", "submitter": "Shai  Gutner", "authors": "Yossi Azar, Iftah Gamzu and Shai Gutner", "title": "Truthful Unsplittable Flow for Large Capacity Networks", "comments": null, "journal-ref": "Proc. of 19th SPAA (2007), 320-329", "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus our attention on the large capacities unsplittable\nflow problem in a game theoretic setting. In this setting, there are selfish\nagents, which control some of the requests characteristics, and may be\ndishonest about them. It is worth noting that in game theoretic settings many\nstandard techniques, such as randomized rounding, violate certain monotonicity\nproperties, which are imperative for truthfulness, and therefore cannot be\nemployed. In light of this state of affairs, we design a monotone deterministic\nalgorithm, which is based on a primal-dual machinery, which attains an\napproximation ratio of $\\frac{e}{e-1}$, up to a disparity of $\\epsilon$ away.\nThis implies an improvement on the current best truthful mechanism, as well as\nan improvement on the current best combinatorial algorithm for the problem\nunder consideration. Surprisingly, we demonstrate that any algorithm in the\nfamily of reasonable iterative path minimizing algorithms, cannot yield a\nbetter approximation ratio. Consequently, it follows that in order to achieve a\nmonotone PTAS, if exists, one would have to exert different techniques. We also\nconsider the large capacities \\textit{single-minded multi-unit combinatorial\nauction problem}. This problem is closely related to the unsplittable flow\nproblem since one can formulate it as a special case of the integer linear\nprogram of the unsplittable flow problem. Accordingly, we obtain a comparable\nperformance guarantee by refining the algorithm suggested for the unsplittable\nflow problem.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2008 08:03:30 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Azar", "Yossi", ""], ["Gamzu", "Iftah", ""], ["Gutner", "Shai", ""]]}, {"id": "0804.2288", "submitter": "Shipra Agrawal", "authors": "Shipra Agrawal, Zizhuo Wang, Yinyu Ye", "title": "Parimutuel Betting on Permutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on a permutation betting market under parimutuel call auction model\nwhere traders bet on the final ranking of n candidates. We present a\nProportional Betting mechanism for this market. Our mechanism allows the\ntraders to bet on any subset of the n x n 'candidate-rank' pairs, and rewards\nthem proportionally to the number of pairs that appear in the final outcome. We\nshow that market organizer's decision problem for this mechanism can be\nformulated as a convex program of polynomial size. More importantly, the\nformulation yields a set of n x n unique marginal prices that are sufficient to\nprice the bets in this mechanism, and are computable in polynomial-time. The\nmarginal prices reflect the traders' beliefs about the marginal distributions\nover outcomes. We also propose techniques to compute the joint distribution\nover n! permutations from these marginal distributions. We show that using a\nmaximum entropy criterion, we can obtain a concise parametric form (with only n\nx n parameters) for the joint distribution which is defined over an\nexponentially large state space. We then present an approximation algorithm for\ncomputing the parameters of this distribution. In fact, the algorithm addresses\nthe generic problem of finding the maximum entropy distribution over\npermutations that has a given mean, and may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2008 00:20:17 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Agrawal", "Shipra", ""], ["Wang", "Zizhuo", ""], ["Ye", "Yinyu", ""]]}, {"id": "0804.2699", "submitter": "Dennis Huo", "authors": "Ian Christopher, Dennis Huo, and Bryan Jacobs", "title": "A Critique of a Polynomial-time SAT Solver Devised by Sergey Gubin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper refutes the validity of the polynomial-time algorithm for solving\nsatisfiability proposed by Sergey Gubin. Gubin introduces the algorithm using\n3-SAT and eventually expands it to accept a broad range of forms of the Boolean\nsatisfiability problem. Because 3-SAT is NP-complete, the algorithm would have\nimplied P = NP, had it been correct. Additionally, this paper refutes the\ncorrectness of his polynomial-time reduction of SAT to 2-SAT.\n", "versions": [{"version": "v1", "created": "Wed, 16 Apr 2008 23:00:51 GMT"}], "update_date": "2008-04-18", "authors_parsed": [["Christopher", "Ian", ""], ["Huo", "Dennis", ""], ["Jacobs", "Bryan", ""]]}, {"id": "0804.3028", "submitter": "Saket Saurabh", "authors": "Michael Fellows, Fedor Fomin, Daniel Lokshtanov, Elena Losievskaja,\n  Frances A. Rosamond and Saket Saurabh", "title": "Parameterized Low-distortion Embeddings - Graph metrics into lines and\n  trees", "comments": "19 pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the issue of low-distortion embedding of metric spaces into the\nline, and more generally, into the shortest path metric of trees, from the\nparameterized complexity perspective.Let $M=M(G)$ be the shortest path metric\nof an edge weighted graph $G=(V,E)$ on $n$ vertices. We describe algorithms for\nthe problem of finding a low distortion non-contracting embedding of $M$ into\nline and tree metrics.\n  We give an $O(nd^4(2d+1)^{2d})$ time algorithm that for an unweighted graph\nmetric $M$ and integer $d$ either constructs an embedding of $M$ into the line\nwith distortion at most $d$, or concludes that no such embedding exists. We\nfind the result surprising, because the considered problem bears a strong\nresemblance to the notoriously hard Bandwidth Minimization problem which does\nnot admit any FPT algorithm unless an unlikely collapse of parameterized\ncomplexity classes occurs.\n  We show that our algorithm can also be applied to construct small distortion\nembeddings of weighted graph metrics. The running time of our algorithm is\n$O(n(dW)^4(2d+1)^{2dW})$ where $W$ is the largest edge weight of the input\ngraph. We also show that deciding whether a weighted graph metric $M(G)$ with\nmaximum weight $W < |V(G)|$ can be embedded into the line with distortion at\nmost $d$ is NP-Complete for every fixed rational $d \\geq 2$. This rules out any\npossibility of an algorithm with running time $O((nW)^{h(d)})$ where $h$ is a\nfunction of $d$ alone.\n  We generalize the result on embedding into the line by proving that for any\ntree $T$ with maximum degree $\\Delta$, embedding of $M$ into a shortest path\nmetric of $T$ is FPT, parameterized by $(\\Delta,d)$.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2008 14:39:41 GMT"}], "update_date": "2008-04-21", "authors_parsed": [["Fellows", "Michael", ""], ["Fomin", "Fedor", ""], ["Lokshtanov", "Daniel", ""], ["Losievskaja", "Elena", ""], ["Rosamond", "Frances A.", ""], ["Saurabh", "Saket", ""]]}, {"id": "0804.3615", "submitter": "Jarek Duda", "authors": "Jarek Duda", "title": "Combinatorial invariants for graph isomorphism problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presented approach in polynomial time calculates large number of invariants\nfor each vertex, which won't change with graph isomorphism and should fully\ndetermine the graph. For example numbers of closed paths of length k for given\nstarting vertex, what can be though as the diagonal terms of k-th power of the\nadjacency matrix. For k=2 we would get degree of verities invariant, higher\ndescribes local topology deeper. Now if two graphs are isomorphic, they have\nthe same set of such vectors of invariants - we can sort theses vectors\nlexicographically and compare them. If they agree, permutations from sorting\nallow to reconstruct the isomorphism. I'm presenting arguments that these\ninvariants should fully determine the graph, but unfortunately I can't prove it\nin this moment. This approach can give hope, that maybe P=NP - instead of\nchecking all instances, we should make arithmetics on these large numbers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Apr 2008 22:16:46 GMT"}, {"version": "v2", "created": "Wed, 23 Apr 2008 21:54:08 GMT"}, {"version": "v3", "created": "Fri, 9 May 2008 07:09:06 GMT"}, {"version": "v4", "created": "Mon, 19 May 2008 14:20:36 GMT"}], "update_date": "2008-05-19", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "0804.3860", "submitter": "Hsiao-Fei Liu", "authors": "Hsiao-Fei Liu and Kun-Mao Chao", "title": "An $\\tilde{O}(n^{2.5})$-Time Algorithm for Online Topological Ordering", "comments": "Better results have been proposed in the following paper: Haeupler,\n  Kavitha, Mathew, Sen, Tarjan: Faster Algorithms for Incremental Topological\n  Ordering. ICALP (1) 2008: 421-433", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an $\\tilde{O}(n^{2.5})$-time algorithm for maintaining the\ntopological order of a directed acyclic graph with $n$ vertices while inserting\n$m$ edges.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2008 09:40:20 GMT"}, {"version": "v2", "created": "Sat, 23 Aug 2008 07:10:20 GMT"}], "update_date": "2008-08-23", "authors_parsed": [["Liu", "Hsiao-Fei", ""], ["Chao", "Kun-Mao", ""]]}, {"id": "0804.3902", "submitter": "Tiziana Calamoneri", "authors": "Tiziana Calamoneri, Andrea E.F. Clementi, Angelo Monti, Gianluca\n  Rossi, Riccardo Silvestri", "title": "Minimum-energy broadcast in random-grid ad-hoc networks: approximation\n  and distributed algorithms", "comments": "13 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Min Energy broadcast problem consists in assigning transmission ranges to\nthe nodes of an ad-hoc network in order to guarantee a directed spanning tree\nfrom a given source node and, at the same time, to minimize the energy\nconsumption (i.e. the energy cost) yielded by the range assignment. Min energy\nbroadcast is known to be NP-hard.\n  We consider random-grid networks where nodes are chosen independently at\nrandom from the $n$ points of a $\\sqrt n \\times \\sqrt n$ square grid in the\nplane. The probability of the existence of a node at a given point of the grid\ndoes depend on that point, that is, the probability distribution can be\nnon-uniform.\n  By using information-theoretic arguments, we prove a lower bound\n$(1-\\epsilon) \\frac n{\\pi}$ on the energy cost of any feasible solution for\nthis problem. Then, we provide an efficient solution of energy cost not larger\nthan $1.1204 \\frac n{\\pi}$.\n  Finally, we present a fully-distributed protocol that constructs a broadcast\nrange assignment of energy cost not larger than $8n$,thus still yielding\nconstant approximation. The energy load is well balanced and, at the same time,\nthe work complexity (i.e. the energy due to all message transmissions of the\nprotocol) is asymptotically optimal. The completion time of the protocol is\nonly an $O(\\log n)$ factor slower than the optimum. The approximation quality\nof our distributed solution is also experimentally evaluated.\n  All bounds hold with probability at least $1-1/n^{\\Theta(1)}$.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2008 11:17:57 GMT"}], "update_date": "2008-04-25", "authors_parsed": [["Calamoneri", "Tiziana", ""], ["Clementi", "Andrea E. F.", ""], ["Monti", "Angelo", ""], ["Rossi", "Gianluca", ""], ["Silvestri", "Riccardo", ""]]}, {"id": "0804.3947", "submitter": "Peter Sanders", "authors": "Peter Sanders", "title": "Time Dependent Contraction Hierarchies -- Basic Algorithmic Ideas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contraction hierarchies are a simple hierarchical routing technique that has\nproved extremely efficient for static road networks. We explain how to\ngeneralize them to networks with time-dependent edge weights. This is the first\nhierarchical speedup technique for time-dependent routing that allows\nbidirectional query algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2008 15:24:08 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Sanders", "Peter", ""]]}, {"id": "0804.4039", "submitter": "Ioannis Chatzigiannakis", "authors": "Ioannis Chatzigiannakis, Georgios Giannoulis and Paul G. Spirakis", "title": "Energy and Time Efficient Scheduling of Tasks with Dependencies on\n  Asymmetric Multiprocessors", "comments": null, "journal-ref": null, "doi": null, "report-no": "RACTI-RU1-2008-10", "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the problem of scheduling tasks with dependencies in\nmultiprocessor architectures where processors have different speeds. We present\nthe preemptive algorithm \"Save-Energy\" that given a schedule of tasks it post\nprocesses it to improve the energy efficiency without any deterioration of the\nmakespan. In terms of time efficiency, we show that preemptive scheduling in an\nasymmetric system can achieve the same or better optimal makespan than in a\nsymmetric system. Motivited by real multiprocessor systems, we investigate\narchitectures that exhibit limited asymmetry: there are two essentially\ndifferent speeds. Interestingly, this special case has not been studied in the\nfield of parallel computing and scheduling theory; only the general case was\nstudied where processors have $K$ essentially different speeds. We present the\nnon-preemptive algorithm ``Remnants'' that achieves almost optimal makespan. We\nprovide a refined analysis of a recent scheduling method. Based on this\nanalysis, we specialize the scheduling policy and provide an algorithm of $(3 +\no(1))$ expected approximation factor. Note that this improves the previous best\nfactor (6 for two speeds). We believe that our work will convince researchers\nto revisit this well studied scheduling problem for these simple, yet\nrealistic, asymmetric multiprocessor architectures.\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2008 03:16:21 GMT"}, {"version": "v2", "created": "Fri, 6 Jun 2008 14:21:18 GMT"}], "update_date": "2008-06-09", "authors_parsed": [["Chatzigiannakis", "Ioannis", ""], ["Giannoulis", "Georgios", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "0804.4138", "submitter": "Jelani Nelson", "authors": "Nicholas J. A. Harvey, Jelani Nelson, Krzysztof Onak", "title": "Sketching and Streaming Entropy via Approximation Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conclude a sequence of work by giving near-optimal sketching and streaming\nalgorithms for estimating Shannon entropy in the most general streaming model,\nwith arbitrary insertions and deletions. This improves on prior results that\nobtain suboptimal space bounds in the general model, and near-optimal bounds in\nthe insertion-only model without sketching. Our high-level approach is simple:\nwe give algorithms to estimate Renyi and Tsallis entropy, and use them to\nextrapolate an estimate of Shannon entropy. The accuracy of our estimates is\nproven using approximation theory arguments and extremal properties of\nChebyshev polynomials, a technique which may be useful for other problems. Our\nwork also yields the best-known and near-optimal additive approximations for\nentropy, and hence also for conditional entropy and mutual information.\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2008 16:04:20 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Harvey", "Nicholas J. A.", ""], ["Nelson", "Jelani", ""], ["Onak", "Krzysztof", ""]]}, {"id": "0804.4666", "submitter": "Anna Gilbert", "authors": "R. Berinde, A. C. Gilbert, P. Indyk, H. Karloff, M. J. Strauss", "title": "Combining geometry and combinatorics: A unified approach to sparse\n  signal recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two main algorithmic approaches to sparse signal recovery:\ngeometric and combinatorial. The geometric approach starts with a geometric\nconstraint on the measurement matrix and then uses linear programming to decode\ninformation about the signal from its measurements. The combinatorial approach\nconstructs the measurement matrix and a combinatorial decoding algorithm to\nmatch. We present a unified approach to these two classes of sparse signal\nrecovery algorithms.\n  The unifying elements are the adjacency matrices of high-quality unbalanced\nexpanders. We generalize the notion of Restricted Isometry Property (RIP),\ncrucial to compressed sensing results for signal recovery, from the Euclidean\nnorm to the l_p norm for p about 1, and then show that unbalanced expanders are\nessentially equivalent to RIP-p matrices.\n  From known deterministic constructions for such matrices, we obtain new\ndeterministic measurement matrix constructions and algorithms for signal\nrecovery which, compared to previous deterministic algorithms, are superior in\neither the number of measurements or in noise tolerance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Apr 2008 18:24:14 GMT"}], "update_date": "2008-04-30", "authors_parsed": [["Berinde", "R.", ""], ["Gilbert", "A. C.", ""], ["Indyk", "P.", ""], ["Karloff", "H.", ""], ["Strauss", "M. J.", ""]]}, {"id": "0804.4744", "submitter": "V. Arvind", "authors": "V. Arvind and Pushkar S. Joglekar", "title": "Lattice Problems, Gauge Functions and Parameterized Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a k-dimensional subspace M\\subseteq \\R^n and a full rank integer\nlattice L\\subseteq \\R^n, the \\emph{subspace avoiding problem} SAP is to find a\nshortest vector in L\\setminus M. Treating k as a parameter, we obtain new\nparameterized approximation and exact algorithms for SAP based on the AKS\nsieving technique. More precisely, we give a randomized\n$(1+\\epsilon)$-approximation algorithm for parameterized SAP that runs in time\n2^{O(n)}.(1/\\epsilon)^k, where the parameter k is the dimension of the subspace\nM. Thus, we obtain a 2^{O(n)} time algorithm for \\epsilon=2^{-O(n/k)}. We also\ngive a 2^{O(n+k\\log k)} exact algorithm for the parameterized SAP for any\n\\ell_p norm.\n  Several of our algorithms work for all gauge functions as metric with some\nnatural restrictions, in particular for all \\ell_p norms. We also prove an\n\\Omega(2^n) lower bound on the query complexity of AKS sieving based exact\nalgorithms for SVP that accesses the gauge function as oracle.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2008 06:39:21 GMT"}], "update_date": "2008-05-01", "authors_parsed": [["Arvind", "V.", ""], ["Joglekar", "Pushkar S.", ""]]}, {"id": "0804.4819", "submitter": "Jukka Suomela", "authors": "Michael A. Bender, S\\'andor P. Fekete, Alexander Kr\\\"oller, Vincenzo\n  Liberatore, Joseph S. B. Mitchell, Valentin Polishchuk, Jukka Suomela", "title": "The Minimum Backlog Problem", "comments": "1+16 pages, 3 figures", "journal-ref": "Theoretical Computer Science 605 (2015), 51-61", "doi": "10.1016/j.tcs.2015.08.027", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minimum backlog problem (MBP). This online problem arises, e.g.,\nin the context of sensor networks. We focus on two main variants of MBP.\n  The discrete MBP is a 2-person game played on a graph $G=(V,E)$. The player\nis initially located at a vertex of the graph. In each time step, the adversary\npours a total of one unit of water into cups that are located on the vertices\nof the graph, arbitrarily distributing the water among the cups. The player\nthen moves from her current vertex to an adjacent vertex and empties the cup at\nthat vertex. The player's objective is to minimize the backlog, i.e., the\nmaximum amount of water in any cup at any time.\n  The geometric MBP is a continuous-time version of the MBP: the cups are\npoints in the two-dimensional plane, the adversary pours water continuously at\na constant rate, and the player moves in the plane with unit speed. Again, the\nplayer's objective is to minimize the backlog.\n  We show that the competitive ratio of any algorithm for the MBP has a lower\nbound of $\\Omega(D)$, where $D$ is the diameter of the graph (for the discrete\nMBP) or the diameter of the point set (for the geometric MBP). Therefore we\nfocus on determining a strategy for the player that guarantees a uniform upper\nbound on the absolute value of the backlog.\n  For the absolute value of the backlog there is a trivial lower bound of\n$\\Omega(D)$, and the deamortization analysis of Dietz and Sleator gives an\nupper bound of $O(D\\log N)$ for $N$ cups. Our main result is a tight upper\nbound for the geometric MBP: we show that there is a strategy for the player\nthat guarantees a backlog of $O(D)$, independently of the number of cups.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2008 13:13:12 GMT"}, {"version": "v2", "created": "Tue, 22 Mar 2016 20:54:15 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Bender", "Michael A.", ""], ["Fekete", "S\u00e1ndor P.", ""], ["Kr\u00f6ller", "Alexander", ""], ["Liberatore", "Vincenzo", ""], ["Mitchell", "Joseph S. B.", ""], ["Polishchuk", "Valentin", ""], ["Suomela", "Jukka", ""]]}, {"id": "0804.4881", "submitter": "Adolfo Piperno", "authors": "Adolfo Piperno", "title": "Search Space Contraction in Canonical Labeling of Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The individualization-refinement paradigm for computing a canonical labeling\nand the automorphism group of a graph is investigated. A new algorithmic design\naimed at reducing the size of the associated search space is introduced, and a\nnew tool, named \"Traces\", is presented, together with experimental results and\ncomparisons with existing software, such as McKay's \"nauty\". It is shown that\nthe approach presented here leads to a huge reduction in the search space,\nthereby making computation feasible for several classes of graphs which are\nhard for all the main canonical labeling tools in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2008 18:28:13 GMT"}, {"version": "v2", "created": "Wed, 26 Jan 2011 15:52:11 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Piperno", "Adolfo", ""]]}]