[{"id": "1302.0072", "submitter": "Shoshana Marcus", "authors": "Shoshana Marcus, Dina Sokol", "title": "Dynamic 2D Dictionary Matching in Small Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dictionary matching problem preprocesses a set of patterns and finds all\noccurrences of each of the patterns in a text when it is provided. We focus on\nthe dynamic setting, in which patterns can be inserted to and removed from the\ndictionary, without reprocessing the entire dictionary. This article presents\nthe first algorithm that performs \\emph{dynamic} dictionary matching on\ntwo-dimensional data within small space. The time complexity of our algorithm\nis almost linear. The only slowdown is incurred by querying the compressed\nself-index that replaces the dictionary. The dictionary is updated in time\nproportional to the size of the pattern that is being inserted to or removed\nfrom the dictionary. Our algorithm is suitable for rectangular patterns that\nare of uniform size in one dimension.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2013 04:14:08 GMT"}], "update_date": "2013-02-04", "authors_parsed": [["Marcus", "Shoshana", ""], ["Sokol", "Dina", ""]]}, {"id": "1302.0264", "submitter": "Mohsen Ghaffari", "authors": "Mohsen Ghaffari, Bernhard Haeupler, Majid Khabbazian", "title": "A Bound on the Throughput of Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the well-studied radio network model: a synchronous model with a\ngraph G=(V,E) with |V|=n where in each round, each node either transmits a\npacket, with length B=Omega(log n) bits, or listens. Each node receives a\npacket iff it is listening and exactly one of its neighbors is transmitting. We\nconsider the problem of k-message broadcast, where k messages, each with\nTheta(B) bits, are placed in an arbitrary nodes of the graph and the goal is to\ndeliver all messages to all the nodes. We present a simple proof showing that\nthere exist a radio network with radius 2 where for any k, broadcasting k\nmessages requires at least Omega(k log n) rounds. That is, in this network,\nregardless of the algorithm, the maximum achievable broadcast throughput is\nO(1/log n).\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2013 20:03:24 GMT"}], "update_date": "2013-02-04", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Haeupler", "Bernhard", ""], ["Khabbazian", "Majid", ""]]}, {"id": "1302.0304", "submitter": "Vida Dujmovic", "authors": "Vida Dujmovic", "title": "Graph Layouts via Layered Separators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A k-queue layout of a graph consists of a total order of the vertices, and a\npartition of the edges into k sets such that no two edges that are in the same\nset are nested with respect to the vertex ordering. A k-track layout of a graph\nconsists of a vertex k-colouring, and a total order of each vertex colour\nclass, such that between each pair of colour classes no two edges cross. The\nqueue-number (track-number) of a graph G, is the minimum k such that G has a\nk-queue (k-track) layout.\n  This paper proves that every n-vertex planar graph has track number and queue\nnumber at most O(log n). This improves the result of Di Battista, Frati and\nPach [Foundations of Computer Science, (FOCS '10), pp. 365--374] who proved the\nfirst sub-polynomial bounds on the queue number and track number of planar\ngraphs. Specifically, they obtained O(log^2 n) queue number and O(log^8 n)\ntrack number bounds for planar graphs.\n  The result also implies that every planar graph has a 3D crossing-free grid\ndrawing in O(n log n) volume. The proof uses a non-standard type of graph\nseparators.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2013 22:13:42 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Dujmovic", "Vida", ""]]}, {"id": "1302.0418", "submitter": "Tom Gur", "authors": "Tom Gur, Ran Raz", "title": "Arthur-Merlin Streaming Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the power of Arthur-Merlin probabilistic proof systems in the data\nstream model. We show a canonical $\\mathcal{AM}$ streaming algorithm for a wide\nclass of data stream problems. The algorithm offers a tradeoff between the\nlength of the proof and the space complexity that is needed to verify it.\n  As an application, we give an $\\mathcal{AM}$ streaming algorithm for the\n\\emph{Distinct Elements} problem. Given a data stream of length $m$ over\nalphabet of size $n$, the algorithm uses $\\tilde O(s)$ space and a proof of\nsize $\\tilde O(w)$, for every $s,w$ such that $s \\cdot w \\ge n$ (where $\\tilde\nO$ hides a $\\polylog(m,n)$ factor). We also prove a lower bound, showing that\nevery $\\mathcal{MA}$ streaming algorithm for the \\emph{Distinct Elements}\nproblem that uses $s$ bits of space and a proof of size $w$, satisfies $s \\cdot\nw = \\Omega(n)$.\n  As a part of the proof of the lower bound for the \\emph{Distinct Elements}\nproblem, we show a new lower bound of $\\Omega(\\sqrt n)$ on the $\\mathcal{MA}$\ncommunication complexity of the \\emph{Gap Hamming Distance} problem, and prove\nits tightness.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2013 19:26:50 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Gur", "Tom", ""], ["Raz", "Ran", ""]]}, {"id": "1302.0792", "submitter": "Edith Cohen", "authors": "Edith Cohen, Avinatan Hassidim, Haim Kaplan, Yishay Mansour, Danny\n  Raz, Yoav Tzur", "title": "Probe Scheduling for Efficient Detection of Silent Failures", "comments": "23 Pages, 3 figures, A partial version (without some of the proofs)\n  Performance Evaluation 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most discovery systems for silent failures work in two phases: a continuous\nmonitoring phase that detects presence of failures through probe packets and a\nlocalization phase that pinpoints the faulty element(s). This separation is\nimportant because localization requires significantly more resources than\ndetection and should be initiated only when a fault is present.\n  We focus on improving the efficiency of the detection phase, where the goal\nis to balance the overhead with the cost associated with longer failure\ndetection times. We formulate a general model which unifies the treatment of\nprobe scheduling mechanisms, stochastic or deterministic, and different cost\nobjectives - minimizing average detection time (SUM) or worst-case detection\ntime (MAX).\n  We then focus on two classes of schedules. {\\em Memoryless schedules} -- a\nsubclass of stochastic schedules which is simple and suitable for distributed\ndeployment. We show that the optimal memorlyess schedulers can be efficiently\ncomputed by convex programs (for SUM objectives) or linear programs (for MAX\nobjectives), and surprisingly perhaps, are guaranteed to have expected\ndetection times that are not too far off the (NP hard) stochastic optima. {\\em\nDeterministic schedules} allow us to bound the maximum (rather than expected)\ncost of undetected faults, but like stochastic schedules, are NP hard to\noptimize. We develop novel efficient deterministic schedulers with provable\napproximation ratios.\n  An extensive simulation study on real networks, demonstrates significant\nperformance gains of our memoryless and deterministic schedulers over previous\napproaches. Our unified treatment also facilitates a clear comparison between\ndifferent objectives and scheduling mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2013 18:43:50 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2013 06:51:12 GMT"}, {"version": "v3", "created": "Thu, 19 Jun 2014 08:52:07 GMT"}], "update_date": "2014-06-20", "authors_parsed": [["Cohen", "Edith", ""], ["Hassidim", "Avinatan", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""], ["Raz", "Danny", ""], ["Tzur", "Yoav", ""]]}, {"id": "1302.0892", "submitter": "Mark Braverman", "authors": "Mark Braverman, Gal Oshri", "title": "Search using queries on indistinguishable items", "comments": "A version of this paper was presented in STACS'13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of determining a set S of k indistinguishable\nintegers in the range [1,n]. The algorithm is allowed to query an integer $q\\in\n[1,n]$, and receive a response comparing this integer to an integer randomly\nchosen from S. The algorithm has no control over which element of S the query q\nis compared to. We show tight bounds for this problem. In particular, we show\nthat in the natural regime where $k\\le n$, the optimal number of queries to\nattain $n^{-\\Omega(1)}$ error probability is $\\Theta(k^3 \\log n)$. In the\nregime where $k>n$, the optimal number of queries is $\\Theta(n^2 k \\log n)$.\n  Our main technical tools include the use of information theory to derive the\nlower bounds, and the application of noisy binary search in the spirit of\nFeige, Raghavan, Peleg, and Upfal (1994). In particular, our lower bound\ntechnique is likely to be applicable in other situations that involve search\nunder uncertainty.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2013 22:34:59 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Braverman", "Mark", ""], ["Oshri", "Gal", ""]]}, {"id": "1302.1064", "submitter": "Dominik Kempa", "authors": "Juha K\\\"arkk\\\"ainen and Dominik Kempa and Simon J. Puglisi", "title": "Lightweight Lempel-Ziv Parsing", "comments": "12 pages", "journal-ref": null, "doi": "10.1007/978-3-642-38527-8_14", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach to LZ77 factorization that uses O(n/d) words of\nworking space and O(dn) time for any d >= 1 (for polylogarithmic alphabet\nsizes). We also describe carefully engineered implementations of alternative\napproaches to lightweight LZ77 factorization. Extensive experiments show that\nthe new algorithm is superior in most cases, particularly at the lowest memory\nlevels and for highly repetitive data. As a part of the algorithm, we describe\nnew methods for computing matching statistics which may be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 15:34:53 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2013 10:15:05 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["K\u00e4rkk\u00e4inen", "Juha", ""], ["Kempa", "Dominik", ""], ["Puglisi", "Simon J.", ""]]}, {"id": "1302.1232", "submitter": "N. Raj Rao", "authors": "Raj Rao Nadakuditi", "title": "When are the most informative components for inference also the\n  principal components?", "comments": "Submitted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.IT cs.LG math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Which components of the singular value decomposition of a signal-plus-noise\ndata matrix are most informative for the inferential task of detecting or\nestimating an embedded low-rank signal matrix? Principal component analysis\nascribes greater importance to the components that capture the greatest\nvariation, i.e., the singular vectors associated with the largest singular\nvalues. This choice is often justified by invoking the Eckart-Young theorem\neven though that work addresses the problem of how to best represent a\nsignal-plus-noise matrix using a low-rank approximation and not how to\nbest_infer_ the underlying low-rank signal component.\n  Here we take a first-principles approach in which we start with a\nsignal-plus-noise data matrix and show how the spectrum of the noise-only\ncomponent governs whether the principal or the middle components of the\nsingular value decomposition of the data matrix will be the informative\ncomponents for inference. Simply put, if the noise spectrum is supported on a\nconnected interval, in a sense we make precise, then the use of the principal\ncomponents is justified. When the noise spectrum is supported on multiple\nintervals, then the middle components might be more informative than the\nprincipal components.\n  The end result is a proper justification of the use of principal components\nin the setting where the noise matrix is i.i.d. Gaussian and the identification\nof scenarios, generically involving heterogeneous noise models such as mixtures\nof Gaussians, where the middle components might be more informative than the\nprincipal components so that they may be exploited to extract additional\nprocessing gain. Our results show how the blind use of principal components can\nlead to suboptimal or even faulty inference because of phase transitions that\nseparate a regime where the principal components are informative from a regime\nwhere they are uninformative.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 23:20:45 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Nadakuditi", "Raj Rao", ""]]}, {"id": "1302.1400", "submitter": "Abdesslem Layeb", "authors": "Abdesslem Layeb, Amira Boudra, Wissem Korichi, Salim Chikhi", "title": "A new greedy randomized adaptive search procedure for multiobjective RNA\n  structural alignment", "comments": null, "journal-ref": "International Journal in Foundations of Computer Science &\n  Technology (IJFCST), Vol. 3, No.1,pp. 9-24, January 2013", "doi": "10.5121/ijfcst.2013.3102", "report-no": null, "categories": "cs.DS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RNA secondary structures prediction is one of the main issues in\nbioinformatics. It seeks to elucidate structural conserved regions within a set\nof RNA sequences. Unfortunately, finding an accurate conserved structure is a\nvery hard task to do. Within the present study, the prediction problem is\nconsidered as a multiobjective optimization process in which the structural\nconservation and the sensitivity of the multiple alignment are optimized. The\nproposed method called GRASPMORSA is based on an aggregate function and GRASP\nprocedure. The initial solutions are obtained by using a random progressive\nlocal/ global algorithm, and then they are refined by an iterative realignment.\nExperiments within a large scale of data have shown the efficacy and\neffectiveness of the proposed method and its capacity to reach good quality\nsolutions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:13:03 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Layeb", "Abdesslem", ""], ["Boudra", "Amira", ""], ["Korichi", "Wissem", ""], ["Chikhi", "Salim", ""]]}, {"id": "1302.1515", "submitter": "Ankur Moitra", "authors": "Ankur Moitra, Michael Saks", "title": "A Polynomial Time Algorithm for Lossy Population Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a polynomial time algorithm for the lossy population recovery\nproblem. In this problem, the goal is to approximately learn an unknown\ndistribution on binary strings of length $n$ from lossy samples: for some\nparameter $\\mu$ each coordinate of the sample is preserved with probability\n$\\mu$ and otherwise is replaced by a `?'. The running time and number of\nsamples needed for our algorithm is polynomial in $n$ and $1/\\varepsilon$ for\neach fixed $\\mu>0$. This improves on algorithm of Wigderson and Yehudayoff that\nruns in quasi-polynomial time for any $\\mu > 0$ and the polynomial time\nalgorithm of Dvir et al which was shown to work for $\\mu \\gtrapprox 0.30$ by\nBatman et al. In fact, our algorithm also works in the more general framework\nof Batman et al. in which there is no a priori bound on the size of the support\nof the distribution. The algorithm we analyze is implicit in previous work; our\nmain contribution is to analyze the algorithm by showing (via linear\nprogramming duality and connections to complex analysis) that a certain matrix\nassociated with the problem has a robust local inverse even though its\ncondition number is exponentially small. A corollary of our result is the first\npolynomial time algorithm for learning DNFs in the restriction access model of\nDvir et al.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 20:53:35 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2013 15:21:41 GMT"}], "update_date": "2013-07-11", "authors_parsed": [["Moitra", "Ankur", ""], ["Saks", "Michael", ""]]}, {"id": "1302.1669", "submitter": "Serge Gaspers", "authors": "Serge Gaspers and Victor Naroditskiy and Nina Narodytska and Toby\n  Walsh", "title": "Possible and Necessary Winner Problem in Social Polls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networks are increasingly being used to conduct polls. We introduce a\nsimple model of such social polling. We suppose agents vote sequentially, but\nthe order in which agents choose to vote is not necessarily fixed. We also\nsuppose that an agent's vote is influenced by the votes of their friends who\nhave already voted. Despite its simplicity, this model provides useful insights\ninto a number of areas including social polling, sequential voting, and\nmanipulation. We prove that the number of candidates and the network structure\naffect the computational complexity of computing which candidate necessarily or\npossibly can win in such a social poll. For social networks with bounded\ntreewidth and a bounded number of candidates, we provide polynomial algorithms\nfor both problems. In other cases, we prove that computing which candidates\nnecessarily or possibly win are computationally intractable.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 08:20:29 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Gaspers", "Serge", ""], ["Naroditskiy", "Victor", ""], ["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1302.1948", "submitter": "Sanjoy Dasgupta", "authors": "Sanjoy Dasgupta and Kaushik Sinha", "title": "Randomized partition trees for exact nearest neighbor search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-d tree was one of the first spatial data structures proposed for\nnearest neighbor search. Its efficacy is diminished in high-dimensional spaces,\nbut several variants, with randomization and overlapping cells, have proved to\nbe successful in practice. We analyze three such schemes. We show that the\nprobability that they fail to find the nearest neighbor, for any data set and\nany query point, is directly related to a simple potential function that\ncaptures the difficulty of the point configuration. We then bound this\npotential function in two situations of interest: the first, when data come\nfrom a doubling measure, and the second, when the data are documents from a\ntopic model.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2013 05:40:38 GMT"}], "update_date": "2013-02-11", "authors_parsed": [["Dasgupta", "Sanjoy", ""], ["Sinha", "Kaushik", ""]]}, {"id": "1302.2127", "submitter": "Sina Sadeghian  S", "authors": "Jochen K\\\"onemann, Sina Sadeghian and Laura Sanit\\`a", "title": "An LMP O(log n)-Approximation Algorithm for Node Weighted Prize\n  Collecting Steiner Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the node-weighted prize-collecting Steiner tree problem (NW-PCST) we are\ngiven an undirected graph $G=(V,E)$, non-negative costs $c(v)$ and penalties\n$\\pi(v)$ for each $v \\in V$. The goal is to find a tree $T$ that minimizes the\ntotal cost of the vertices spanned by $T$ plus the total penalty of vertices\nnot in $T$. This problem is well-known to be set-cover hard to approximate.\nMoss and Rabani (STOC'01) presented a primal-dual\nLagrangean-multiplier-preserving $O(\\ln |V|)$-approximation algorithm for this\nproblem. We show a serious problem with the algorithm, and present a new,\nfundamentally different primal-dual method achieving the same performance\nguarantee. Our algorithm introduces several novel features to the primal-dual\nmethod that may be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2013 19:41:06 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2013 06:41:49 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2013 17:58:09 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["K\u00f6nemann", "Jochen", ""], ["Sadeghian", "Sina", ""], ["Sanit\u00e0", "Laura", ""]]}, {"id": "1302.2137", "submitter": "Edith Cohen", "authors": "Edith Cohen and Graham Cormode and Nick Duffield and Carsten Lund", "title": "On the Tradeoff between Stability and Fit", "comments": "24 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computing, as in many aspects of life, changes incur cost. Many\noptimization problems are formulated as a one-time instance starting from\nscratch. However, a common case that arises is when we already have a set of\nprior assignments, and must decide how to respond to a new set of constraints,\ngiven that each change from the current assignment comes at a price. That is,\nwe would like to maximize the fitness or efficiency of our system, but we need\nto balance it with the changeout cost from the previous state.\n  We provide a precise formulation for this tradeoff and analyze the resulting\n{\\em stable extensions} of some fundamental problems in measurement and\nanalytics. Our main technical contribution is a stable extension of PPS\n(probability proportional to size) weighted random sampling, with applications\nto monitoring and anomaly detection problems. We also provide a general\nframework that applies to top-$k$, minimum spanning tree, and assignment. In\nboth cases, we are able to provide exact solutions, and discuss efficient\nincremental algorithms that can find new solutions as the input changes.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2013 20:16:46 GMT"}], "update_date": "2013-02-11", "authors_parsed": [["Cohen", "Edith", ""], ["Cormode", "Graham", ""], ["Duffield", "Nick", ""], ["Lund", "Carsten", ""]]}, {"id": "1302.2184", "submitter": "Glencora Borradaile", "authors": "Glencora Borradaile and Philip Klein", "title": "The two-edge connectivity survivable-network design problem in planar\n  graphs", "comments": "Updated from original conference version (ICALP '08). To appear:\n  Transactions on Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following problem: given a graph with edge costs and a subset Q\nof vertices, find a minimum-cost subgraph in which there are two edge-disjoint\npaths connecting every pair of vertices in Q. The problem is a\nfailure-resilient analog of the Steiner tree problem arising, for example, in\ntelecommunications applications. We study a more general mixed-connectivity\nformulation, also employed in telecommunications optimization. Given a number\n(or requirement) r(v) in {0, 1, 2} for each vertex v in the graph, find a\nminimum-cost subgraph in which there are min{r(u), r(v)} edge-disjoint u-to-v\npaths for every pair u, v of vertices.\n  We address the problem in planar graphs, considering a popular relaxation in\nwhich the solution is allowed to use multiple copies of the input-graph edges\n(paying separately for each copy). The problem is max SNP-hard in general\ngraphs and strongly NP-hard in planar graphs. We give the first polynomial-time\napproximation scheme in planar graphs. The running time is O(n log n).\n  Under the additional restriction that the requirements are only non-zero for\nvertices on the boundary of a single face of a planar graph, we give a\npolynomial-time algorithm to find the optimal solution.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2013 00:09:51 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2015 18:21:56 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Borradaile", "Glencora", ""], ["Klein", "Philip", ""]]}, {"id": "1302.2426", "submitter": "Jean Cardinal", "authors": "Andrei Asinowski, Jean Cardinal, Nathann Cohen, S\\'ebastien Collette,\n  Thomas Hackl, Michael Hoffmann, Kolja Knauer, Stefan Langerman, Micha{\\l}\n  Laso\\'n, Piotr Micek, G\\\"unter Rote, Torsten Ueckerdt", "title": "Coloring Hypergraphs Induced by Dynamic Point Sets and Bottomless\n  Rectangles", "comments": "A preliminary version was presented by a subset of the authors to the\n  European Workshop on Computational Geometry, held in Assisi (Italy) on March\n  19-21, 2012", "journal-ref": "In: Algorithms and Data Structures Symposium-WADS 2013, August\n  2013, Editors: Frank Dehne, Roberto Solis-Oba, and J\\\"org-R\\\"udiger Sack,\n  Lecture Notes in Computer Science, 8037, Springer-Verlag, 2013, pp. 73-84", "doi": "10.1007/978-3-642-40104-6_7", "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a coloring problem on dynamic, one-dimensional point sets: points\nappearing and disappearing on a line at given times. We wish to color them with\nk colors so that at any time, any sequence of p(k) consecutive points, for some\nfunction p, contains at least one point of each color.\n  We prove that no such function p(k) exists in general. However, in the\nrestricted case in which points appear gradually, but never disappear, we give\na coloring algorithm guaranteeing the property at any time with p(k)=3k-2. This\ncan be interpreted as coloring point sets in R^2 with k colors such that any\nbottomless rectangle containing at least 3k-2 points contains at least one\npoint of each color. Here a bottomless rectangle is an axis-aligned rectangle\nwhose bottom edge is below the lowest point of the set. For this problem, we\nalso prove a lower bound p(k)>ck, where c>1.67. Hence for every k there exists\na point set, every k-coloring of which is such that there exists a bottomless\nrectangle containing ck points and missing at least one of the k colors.\n  Chen et al. (2009) proved that no such function $p(k)$ exists in the case of\ngeneral axis-aligned rectangles. Our result also complements recent results\nfrom Keszegh and Palvolgyi on cover-decomposability of octants (2011, 2012).\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2013 09:40:23 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Asinowski", "Andrei", ""], ["Cardinal", "Jean", ""], ["Cohen", "Nathann", ""], ["Collette", "S\u00e9bastien", ""], ["Hackl", "Thomas", ""], ["Hoffmann", "Michael", ""], ["Knauer", "Kolja", ""], ["Langerman", "Stefan", ""], ["Laso\u0144", "Micha\u0142", ""], ["Micek", "Piotr", ""], ["Rote", "G\u00fcnter", ""], ["Ueckerdt", "Torsten", ""]]}, {"id": "1302.2551", "submitter": "Marcin Mucha", "authors": "Marcin Mucha and Maxim Sviridenko", "title": "No-Wait Flowshop Scheduling is as Hard as Asymmetric Traveling Salesman\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the classical no-wait flowshop scheduling problem with\nmakespan objective (F|no-wait|C_max in the standard three-field notation). This\nproblem is well-known to be a special case of the asymmetric traveling salesman\nproblem (ATSP) and as such has an approximation algorithm with logarithmic\nperformance guarantee. In this work we show a reverse connection, we show that\nany polynomial time \\alpha-approximation algorithm for the no-wait flowshop\nscheduling problem with makespan objective implies the existence of a\npolynomial-time \\alpha(1+\\epsilon)-approximation algorithm for the ATSP, for\nany \\epsilon>0. This in turn implies that all non-approximability results for\nthe ATSP (current or future) will carry over to its special case. In\nparticular, it follows that no-wait flowshop problem is APX-hard, which is the\nfirst non-approximability result for this problem.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2013 17:44:20 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2013 14:59:01 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2013 16:16:47 GMT"}], "update_date": "2013-04-26", "authors_parsed": [["Mucha", "Marcin", ""], ["Sviridenko", "Maxim", ""]]}, {"id": "1302.2698", "submitter": "Mohammadreza Jooyandeh", "authors": "Mohammadreza Jooyandeh, Brendan D. McKay, Patric R. J.\n  \\\"Osterg{\\aa}rd, Ville H. Pettersson, Carol T. Zamfirescu", "title": "Planar Hypohamiltonian Graphs on 40 Vertices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is hypohamiltonian if it is not Hamiltonian, but the deletion of any\nsingle vertex gives a Hamiltonian graph. Until now, the smallest known planar\nhypohamiltonian graph had 42 vertices, a result due to Araya and Wiener. That\nresult is here improved upon by 25 planar hypohamiltonian graphs of order 40,\nwhich are found through computer-aided generation of certain families of planar\ngraphs with girth 4 and a fixed number of 4-faces. It is further shown that\nplanar hypohamiltonian graphs exist for all orders greater than or equal to 42.\nIf Hamiltonian cycles are replaced by Hamiltonian paths throughout the\ndefinition of hypohamiltonian graphs, we get the definition of hypotraceable\ngraphs. It is shown that there is a planar hypotraceable graph of order 154 and\nof all orders greater than or equal to 156. We also show that the smallest\nhypohamiltonian planar graph of girth 5 has 45 vertices.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 04:30:16 GMT"}, {"version": "v2", "created": "Mon, 29 Sep 2014 00:00:21 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2015 01:28:15 GMT"}, {"version": "v4", "created": "Sun, 6 Dec 2015 20:25:15 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Jooyandeh", "Mohammadreza", ""], ["McKay", "Brendan D.", ""], ["\u00d6sterg\u00e5rd", "Patric R. J.", ""], ["Pettersson", "Ville H.", ""], ["Zamfirescu", "Carol T.", ""]]}, {"id": "1302.2752", "submitter": "Aryeh Kontorovich", "authors": "Lee-Ad Gottlieb, Aryeh Kontorovich, Robert Krauthgamer", "title": "Adaptive Metric Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adaptive data-dependent dimensionality reduction in the context of\nsupervised learning in general metric spaces. Our main statistical contribution\nis a generalization bound for Lipschitz functions in metric spaces that are\ndoubling, or nearly doubling. On the algorithmic front, we describe an analogue\nof PCA for metric spaces: namely an efficient procedure that approximates the\ndata's intrinsic dimension, which is often much lower than the ambient\ndimension. Our approach thus leverages the dual benefits of low dimensionality:\n(1) more efficient algorithms, e.g., for proximity search, and (2) more\noptimistic generalization bounds.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 10:20:21 GMT"}, {"version": "v2", "created": "Sun, 12 May 2013 14:58:17 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2015 12:18:55 GMT"}], "update_date": "2015-03-26", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kontorovich", "Aryeh", ""], ["Krauthgamer", "Robert", ""]]}, {"id": "1302.2757", "submitter": "Daniel Cederman", "authors": "Daniel Cederman and Anders Gidenstam and Phuong Ha and H{\\aa}kan\n  Sundell and Marina Papatriantafilou and Philippas Tsigas", "title": "Lock-free Concurrent Data Structures", "comments": "To appear in \"Programming Multi-core and Many-core Computing\n  Systems\", eds. S. Pllana and F. Xhafa, Wiley Series on Parallel and\n  Distributed Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent data structures are the data sharing side of parallel programming.\nData structures give the means to the program to store data, but also provide\noperations to the program to access and manipulate these data. These operations\nare implemented through algorithms that have to be efficient. In the sequential\nsetting, data structures are crucially important for the performance of the\nrespective computation. In the parallel programming setting, their importance\nbecomes more crucial because of the increased use of data and resource sharing\nfor utilizing parallelism.\n  The first and main goal of this chapter is to provide a sufficient background\nand intuition to help the interested reader to navigate in the complex research\narea of lock-free data structures. The second goal is to offer the programmer\nfamiliarity to the subject that will allow her to use truly concurrent methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 11:08:26 GMT"}], "update_date": "2013-02-13", "authors_parsed": [["Cederman", "Daniel", ""], ["Gidenstam", "Anders", ""], ["Ha", "Phuong", ""], ["Sundell", "H\u00e5kan", ""], ["Papatriantafilou", "Marina", ""], ["Tsigas", "Philippas", ""]]}, {"id": "1302.2787", "submitter": "Igor Shinkar", "authors": "Itai Benjamini, Igor Shinkar, Gilad Tsur", "title": "Acquaintance Time of a Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.SI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define the following parameter of connected graphs. For a given graph $G$\nwe place one agent in each vertex of $G$. Every pair of agents sharing a common\nedge is declared to be acquainted. In each round we choose some matching of $G$\n(not necessarily a maximal matching), and for each edge in the matching the\nagents on this edge swap places. After the swap, again, every pair of agents\nsharing a common edge become acquainted, and the process continues. We define\nthe \\emph{acquaintance time} of a graph $G$, denoted by $AC(G)$, to be the\nminimal number of rounds required until every two agents are acquainted.\n  We first study the acquaintance time for some natural families of graphs\nincluding the path, expanders, the binary tree, and the complete bipartite\ngraph. We also show that for all positive integers $n$ and $k \\leq n^{1.5}$\nthere exists an $n$-vertex graph $G$ such that $AC(G) =\\Theta(k)$. We also\nprove that for all $n$-vertex connected graphs $G$ we have $AC(G) =\nO\\left(\\frac{n^2}{\\log(n)/\\log\\log(n)}\\right)$, improving the $O(n^2)$ trivial\nupper bound achieved by sequentially letting each agent perform depth-first\nsearch along a spanning tree of $G$.\n  Studying the computational complexity of this problem, we prove that for any\nconstant $t \\geq 1$ the problem of deciding that a given graph $G$ has $AC(G)\n\\leq t$ or $AC(G) \\geq 2t$ is $\\mathcal{NP}$-complete. That is, $AC(G)$ is\n$\\mathcal{NP}$-hard to approximate within multiplicative factor of 2, as well\nas within any additive constant factor.\n  On the algorithmic side, we give a deterministic algorithm that given a graph\n$G$ with $AC(G)=1$ finds a ${\\lceil n/c\\rceil}$-rounds strategy for\nacquaintance in time $n^{c+O(1)}$. We also design a randomized polynomial time\nalgorithm that given a graph $G$ with $AC(G)=1$ finds with high probability an\n$O(\\log(n))$-rounds strategy for acquaintance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 13:34:52 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2013 07:28:02 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2013 14:34:30 GMT"}, {"version": "v4", "created": "Thu, 13 Mar 2014 12:51:04 GMT"}], "update_date": "2014-03-14", "authors_parsed": [["Benjamini", "Itai", ""], ["Shinkar", "Igor", ""], ["Tsur", "Gilad", ""]]}, {"id": "1302.2788", "submitter": "Dariusz Dereniowski", "authors": "Dariusz Dereniowski, Wieslaw Kubiak, Yori Zwols", "title": "Minimum length path decompositions", "comments": "Work presented at the 5th Workshop on GRAph Searching, Theory and\n  Applications (GRASTA 2012), Banff International Research Station, Banff, AB,\n  Canada", "journal-ref": "Journal of Computer and System Sciences 81 (2015) 1715-1747", "doi": "10.1016/j.jcss.2015.06.011", "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a bi-criteria generalization of the pathwidth problem, where, for\ngiven integers $k,l$ and a graph $G$, we ask whether there exists a path\ndecomposition $\\cP$ of $G$ such that the width of $\\cP$ is at most $k$ and the\nnumber of bags in $\\cP$, i.e., the \\emph{length} of $\\cP$, is at most $l$.\n  We provide a complete complexity classification of the problem in terms of\n$k$ and $l$ for general graphs. Contrary to the original pathwidth problem,\nwhich is fixed-parameter tractable with respect to $k$, we prove that the\ngeneralized problem is NP-complete for any fixed $k\\geq 4$, and is also\nNP-complete for any fixed $l\\geq 2$. On the other hand, we give a\npolynomial-time algorithm that, for any (possibly disconnected) graph $G$ and\nintegers $k\\leq 3$ and $l>0$, constructs a path decomposition of width at most\n$k$ and length at most $l$, if any exists.\n  As a by-product, we obtain an almost complete classification of the problem\nin terms of $k$ and $l$ for connected graphs. Namely, the problem is\nNP-complete for any fixed $k\\geq 5$ and it is polynomial-time for any $k\\leq\n3$. This leaves open the case $k=4$ for connected graphs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 13:38:58 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Dereniowski", "Dariusz", ""], ["Kubiak", "Wieslaw", ""], ["Zwols", "Yori", ""]]}, {"id": "1302.2805", "submitter": "Tobias Moemke", "authors": "Dennis Komm, Rastislav Kr\\'alovi\\v{c}, Richard Kr\\'alovi\\v{c} and\n  Tobias M\\\"omke", "title": "Randomized online computation with high probability guarantees", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relationship between the competitive ratio and the tail\ndistribution of randomized online minimization problems. To this end, we define\na broad class of online problems that includes some of the well-studied\nproblems like paging, k-server and metrical task systems on finite metrics, and\nshow that for these problems it is possible to obtain, given an algorithm with\nconstant expected competitive ratio, another algorithm that achieves the same\nsolution quality up to an arbitrarily small constant error a with high\nprobability; the \"high probability\" statement is in terms of the optimal cost.\nFurthermore, we show that our assumptions are tight in the sense that removing\nany of them allows for a counterexample to the theorem. In addition, there are\nexamples of other problems not covered by our definition, where similar high\nprobability results can be obtained.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 14:29:05 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Komm", "Dennis", ""], ["Kr\u00e1lovi\u010d", "Rastislav", ""], ["Kr\u00e1lovi\u010d", "Richard", ""], ["M\u00f6mke", "Tobias", ""]]}, {"id": "1302.3033", "submitter": "Chih-Hua Tai", "authors": "Chih-Hua Tai, Philip S. Yu, De-Nian Yang and Ming-Syan Chen", "title": "Structural Diversity for Resisting Community Identification in Published\n  Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an increasing number of social networking data is published and shared for\ncommercial and research purposes, privacy issues about the individuals in\nsocial networks have become serious concerns. Vertex identification, which\nidentifies a particular user from a network based on background knowledge such\nas vertex degree, is one of the most important problems that has been\naddressed. In reality, however, each individual in a social network is inclined\nto be associated with not only a vertex identity but also a community identity,\nwhich can represent the personal privacy information sensitive to the public,\nsuch as political party affiliation. This paper first addresses the new privacy\nissue, referred to as community identification, by showing that the community\nidentity of a victim can still be inferred even though the social network is\nprotected by existing anonymity schemes. For this problem, we then propose the\nconcept of \\textit{structural diversity} to provide the anonymity of the\ncommunity identities. The $k$-Structural Diversity Anonymization ($k$-SDA) is\nto ensure sufficient vertices with the same vertex degree in at least $k$\ncommunities in a social network. We propose an Integer Programming formulation\nto find optimal solutions to $k$-SDA and also devise scalable heuristics to\nsolve large-scale instances of $k$-SDA from different perspectives. The\nperformance studies on real data sets from various perspectives demonstrate the\npractical utility of the proposed privacy scheme and our anonymization\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 09:55:52 GMT"}], "update_date": "2013-02-14", "authors_parsed": [["Tai", "Chih-Hua", ""], ["Yu", "Philip S.", ""], ["Yang", "De-Nian", ""], ["Chen", "Ming-Syan", ""]]}, {"id": "1302.3035", "submitter": "Bj\\\"orn Hlava", "authors": "Bj\\\"orn Hlava", "title": "Yet another approach to the Maximum Flow", "comments": "preprint. uploaded to make sure, that this idea will not be stolen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I introduce a new approach to the maximum flow problem by a simple algorithm\nwith a slightly better runtime. This approach is based on sorting arcs insight\nof vertices on a residual graph. This new approach leads to an O(mn^0.5) time\nbound for a network with n vertices and m arcs.\n  Category: Algorithms, Graph Theory and maximum flows\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 10:06:17 GMT"}], "update_date": "2013-02-14", "authors_parsed": [["Hlava", "Bj\u00f6rn", ""]]}, {"id": "1302.3145", "submitter": "Zachary Friggstad", "authors": "Zachary Friggstad, Anupam Gupta, and Mohit Singh", "title": "An Improved Integrality Gap for Asymmetric TSP Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Asymmetric Traveling Salesperson Path Problem (ATSPP) is one where, given\nan asymmetric metric space $(V,d)$ with specified vertices s and t, the goal is\nto find an s-t path of minimum length that passes through all the vertices in\nV.\n  This problem is closely related to the Asymmetric TSP (ATSP), which seeks to\nfind a tour (instead of an $s-t$ path) visiting all the nodes: for ATSP, a\n$\\rho$-approximation guarantee implies an $O(\\rho)$-approximation for ATSPP.\nHowever, no such connection is known for the integrality gaps of the linear\nprogramming relaxations for these problems: the current-best approximation\nalgorithm for ATSPP is $O(\\log n/\\log\\log n)$, whereas the best bound on the\nintegrality gap of the natural LP relaxation (the subtour elimination LP) for\nATSPP is $O(\\log n)$.\n  In this paper, we close this gap, and improve the current best bound on the\nintegrality gap from $O(\\log n)$ to $O(\\log n/\\log\\log n)$. The resulting\nalgorithm uses the structure of narrow $s$-$t$ cuts in the LP solution to\nconstruct a (random) tree spanning tree that can be cheaply augmented to\ncontain an Eulerian $s$-$t$ walk.\n  We also build on a result of Oveis Gharan and Saberi and show a strong form\nof Goddyn's conjecture about thin spanning trees implies the integrality gap of\nthe subtour elimination LP relaxation for ATSPP is bounded by a constant.\nFinally, we give a simpler family of instances showing the integrality gap of\nthis LP is at least 2.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 15:49:23 GMT"}, {"version": "v2", "created": "Tue, 6 Jan 2015 18:15:34 GMT"}], "update_date": "2015-01-07", "authors_parsed": [["Friggstad", "Zachary", ""], ["Gupta", "Anupam", ""], ["Singh", "Mohit", ""]]}, {"id": "1302.3347", "submitter": "Johannes Fischer", "authors": "Johannes Fischer and Pawel Gawrychowski", "title": "Alphabet-Dependent String Searching with Wexponential Search Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely assumed that $O(m+\\lg \\sigma)$ is the best one can do for\nfinding a pattern of length $m$ in a compacted trie storing strings over an\nalphabet of size $\\sigma$, if one insists on linear-size data structures and\ndeterministic worst-case running times [Cole et al., ICALP'06]. In this\narticle, we first show that a rather straightforward combination of well-known\nideas yields $O(m+\\lg\\lg \\sigma)$ deterministic worst-case searching time for\nstatic tries.\n  Then we move on to dynamic tries, where we achieve a worst-case bound of\n$O(m+\\frac{\\lg^{2}\\lg\\sigma}{\\lg\\lg\\lg\\sigma})$ per query or update, which\nshould again be compared to the previously known $O(m+\\lg\\sigma)$ deterministic\nworst-case bounds [Cole et al., ICALP'06], and to the alphabet\n\\emph{in}dependent $O(m+\\sqrt{\\lg n/\\lg\\lg n})$ deterministic worst-case bounds\n[Andersson and Thorup, SODA'01], where $n$ is the number of nodes in the trie.\nThe basis of our update procedure is a weighted variant of exponential search\ntrees which, while simple, might be of independent interest.\n  As one particular application, the above bounds (static and dynamic) apply to\nsuffix trees. There, an update corresponds to pre- or appending a letter to the\ntext, and an additional goal is to do the updates quicker than rematching\nentire suffixes. We show how to do this in $O(\\lg\\lg n +\n\\frac{\\lg^{2}\\lg\\sigma}{\\lg\\lg\\lg\\sigma})$ time, which improves the previously\nknown $O(\\lg n)$ bound [Amir et al., SPIRE'05].\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 09:29:09 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Fischer", "Johannes", ""], ["Gawrychowski", "Pawel", ""]]}, {"id": "1302.3404", "submitter": "Alexandru Popa Dr.", "authors": "Tommi Larjomaa and Alexandru Popa", "title": "The min-max edge q-coloring problem", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and study a new problem named \\emph{min-max edge\n$q$-coloring} which is motivated by applications in wireless mesh networks. The\ninput of the problem consists of an undirected graph and an integer $q$. The\ngoal is to color the edges of the graph with as many colors as possible such\nthat: (a) any vertex is incident to at most $q$ different colors, and (b) the\nmaximum size of a color group (i.e. set of edges identically colored) is\nminimized. We show the following results: 1. Min-max edge $q$-coloring is\nNP-hard, for any $q \\ge 2$. 2. A polynomial time exact algorithm for min-max\nedge $q$-coloring on trees. 3. Exact formulas of the optimal solution for\ncliques and almost tight bounds for bicliques and hypergraphs. 4. A non-trivial\nlower bound of the optimal solution with respect to the average degree of the\ngraph. 5. An approximation algorithm for planar graphs.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 14:07:55 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Larjomaa", "Tommi", ""], ["Popa", "Alexandru", ""]]}, {"id": "1302.3417", "submitter": "Reut Levi", "authors": "Reut Levi and Dana Ron", "title": "A Quasi-Polynomial Time Partition Oracle for Graphs with an Excluded\n  Minor", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problem of testing planarity and related properties, we\nstudy the problem of designing efficient {\\em partition oracles}. A {\\em\npartition oracle} is a procedure that, given access to the incidence lists\nrepresentation of a bounded-degree graph $G= (V,E)$ and a parameter $\\eps$,\nwhen queried on a vertex $v\\in V$, returns the part (subset of vertices) which\n$v$ belongs to in a partition of all graph vertices. The partition should be\nsuch that all parts are small, each part is connected, and if the graph has\ncertain properties, the total number of edges between parts is at most $\\eps\n|V|$. In this work we give a partition oracle for graphs with excluded minors\nwhose query complexity is quasi-polynomial in $1/\\eps$, thus improving on the\nresult of Hassidim et al. ({\\em Proceedings of FOCS 2009}) who gave a partition\noracle with query complexity exponential in $1/\\eps$. This improvement implies\ncorresponding improvements in the complexity of testing planarity and other\nproperties that are characterized by excluded minors as well as sublinear-time\napproximation algorithms that work under the promise that the graph has an\nexcluded minor.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 14:51:29 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Levi", "Reut", ""], ["Ron", "Dana", ""]]}, {"id": "1302.3437", "submitter": "P\\'eter    L. Erd\\H{o}s", "authors": "Alberto Apostolico, P\\'eter L. Erd\\H{o}s, Istv\\'an Mikl\\'os, Johannes\n  Siemons", "title": "Modulated String Searching", "comments": "10 pages", "journal-ref": null, "doi": "10.1016/j.tcs.2013.10.013", "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his 1987 paper entitled \"Generalized String Matching\", Abrahamson\nintroduced {\\em pattern matching with character classes} and provided the first\nefficient algorithm to solve it. The best known solution to date is due to\nLinhart and Shamir (2009).\n  Another broad yet comparatively less studied class of string matching\nproblems is that of numerical string searching, such as, e.g., the `less-than'\nor $L_1$-norm string searching. The best known solutions for problems in this\nclass are based on FFT convolution after some suitable re-encoding.\n  The present paper introduces {\\em modulated string searching} as a unified\nframework for string matching problems where the numerical conditions can be\ncombined with some Boolean/numerical decision conditions on the character\nclasses. One example problem in this class is the {\\em locally bounded\n$L_1$-norm} matching problem on character classes: here the \"match\" between a\ncharacter at some position in the text and a set of characters at some position\nin the pattern is assessed based on the smallest $L_1$ distance between the\ntext character and one of those pattern characters. The two positions \"match\"\nif the (absolute value of the) difference between the two characters does not\nexceed a predefined constant. The pattern has an occurrence in an alignment\nwith the text if the sum of all such differences does not exceed a second\npredefined constant value. This problem requires a pointwise evaluation of the\nquality of each match and has no known solution based on the previously\nmentioned algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 15:44:49 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2013 16:45:40 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Apostolico", "Alberto", ""], ["Erd\u0151s", "P\u00e9ter L.", ""], ["Mikl\u00f3s", "Istv\u00e1n", ""], ["Siemons", "Johannes", ""]]}, {"id": "1302.3481", "submitter": "Artur Je\\.z", "authors": "Artur Je\\.z", "title": "One-variable word equations in linear time", "comments": "submitted to a journal, general overhaul over the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider word equations with one variable (and arbitrary\nmany appearances of it). A recent technique of recompression, which is\napplicable to general word equations, is shown to be suitable also in this\ncase. While in general case it is non-deterministic, it determinises in case of\none variable and the obtained running time is O(n + #_X log n), where #_X is\nthe number of appearances of the variable in the equation. This matches the\npreviously-best algorithm due to D\\k{a}browski and Plandowski. Then, using a\ncouple of heuristics as well as more detailed time analysis the running time is\nlowered to O(n) in RAM model. Unfortunately no new properties of solutions are\nshown.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 17:24:36 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2014 16:15:16 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Je\u017c", "Artur", ""]]}, {"id": "1302.3494", "submitter": "Stefan Kratsch", "authors": "Stefan Kratsch", "title": "On Polynomial Kernels for Sparse Integer Linear Programs", "comments": "To appear in STACS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integer linear programs (ILPs) are a widely applied framework for dealing\nwith combinatorial problems that arise in practice. It is known, e.g., by the\nsuccess of CPLEX, that preprocessing and simplification can greatly speed up\nthe process of optimizing an ILP. The present work seeks to further the\ntheoretical understanding of preprocessing for ILPs by initiating a rigorous\nstudy within the framework of parameterized complexity and kernelization.\n  A famous result of Lenstra (Mathematics of Operations Research, 1983) shows\nthat feasibility of any ILP with n variables and m constraints can be decided\nin time O(c^{n^3} m^c'). Thus, by a folklore argument, any such ILP admits a\nkernelization to an equivalent instance of size O(c^{n^3}). It is known, that\nunless NP \\subseteq coNP/poly and the polynomial hierarchy collapses, no\nkernelization with size bound polynomial in n is possible. However, this lower\nbound only applies for the case when constraints may include an arbitrary\nnumber of variables since it follows from lower bounds for Satisfiability and\nHitting Set, whose bounded arity variants admit polynomial kernelizations.\n  We consider the feasibility problem for ILPs Ax<= b where A is an\nr-row-sparse matrix parameterized by the number of variables. We show that the\nkernelizability of this problem depends strongly on the range of the variables.\nIf the range is unbounded then this problem does not admit a polynomial\nkernelization unless NP \\subseteq coNP/poly. If, on the other hand, the range\nof each variable is polynomially bounded in n then we do get a polynomial\nkernelization. Additionally, this holds also for the more general case when the\nmaximum range d is an additional parameter, i.e., the size obtained is\npolynomial in n+d.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 18:01:10 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2013 19:23:05 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Kratsch", "Stefan", ""]]}, {"id": "1302.3496", "submitter": "Stefan Kratsch", "authors": "Stefan Kratsch", "title": "On Polynomial Kernels for Integer Linear Programs: Covering, Packing and\n  Feasibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the existence of polynomial kernels for the problem of deciding\nfeasibility of integer linear programs (ILPs), and for finding good solutions\nfor covering and packing ILPs. Our main results are as follows: First, we show\nthat the ILP Feasibility problem admits no polynomial kernelization when\nparameterized by both the number of variables and the number of constraints,\nunless NP \\subseteq coNP/poly. This extends to the restricted cases of bounded\nvariable degree and bounded number of variables per constraint, and to covering\nand packing ILPs. Second, we give a polynomial kernelization for the Cover ILP\nproblem, asking for a solution to Ax >= b with c^Tx <= k, parameterized by k,\nwhen A is row-sparse; this generalizes a known polynomial kernelization for the\nspecial case with 0/1-variables and coefficients (d-Hitting Set).\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 18:02:04 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2013 18:05:12 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Kratsch", "Stefan", ""]]}, {"id": "1302.3518", "submitter": "Nissim Halabi", "authors": "Guy Even and Nissim Halabi", "title": "Analysis of the Min-Sum Algorithm for Packing and Covering Problems via\n  Linear Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DM cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message-passing algorithms based on belief-propagation (BP) are successfully\nused in many applications including decoding error correcting codes and solving\nconstraint satisfaction and inference problems. BP-based algorithms operate\nover graph representations, called factor graphs, that are used to model the\ninput. Although in many cases BP-based algorithms exhibit impressive empirical\nresults, not much has been proved when the factor graphs have cycles.\n  This work deals with packing and covering integer programs in which the\nconstraint matrix is zero-one, the constraint vector is integral, and the\nvariables are subject to box constraints. We study the performance of the\nmin-sum algorithm when applied to the corresponding factor graph models of\npacking and covering LPs.\n  We compare the solutions computed by the min-sum algorithm for packing and\ncovering problems to the optimal solutions of the corresponding linear\nprogramming (LP) relaxations. In particular, we prove that if the LP has an\noptimal fractional solution, then for each fractional component, the min-sum\nalgorithm either computes multiple solutions or the solution oscillates below\nand above the fraction. This implies that the min-sum algorithm computes the\noptimal integral solution only if the LP has a unique optimal solution that is\nintegral.\n  The converse is not true in general. For a special case of packing and\ncovering problems, we prove that if the LP has a unique optimal solution that\nis integral and on the boundary of the box constraints, then the min-sum\nalgorithm computes the optimal solution in pseudo-polynomial time.\n  Our results unify and extend recent results for the maximum weight matching\nproblem by [Sanghavi et al.,'2011] and [Bayati et al., 2011] and for the\nmaximum weight independent set problem [Sanghavi et al.'2009].\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 19:31:23 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2013 16:48:13 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Even", "Guy", ""], ["Halabi", "Nissim", ""]]}, {"id": "1302.3558", "submitter": "Ann Becker", "authors": "Ann Becker, Dan Geiger", "title": "A Sufficiently Fast Algorithm for Finding Close to Optimal Junction\n  Trees", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-81-89", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm is developed for finding a close to optimal junction tree of a\ngiven graph G. The algorithm has a worst case complexity O(c^k n^a) where a and\nc are constants, n is the number of vertices, and k is the size of the largest\nclique in a junction tree of G in which this size is minimized. The algorithm\nguarantees that the logarithm of the size of the state space of the heaviest\nclique in the junction tree produced is less than a constant factor off the\noptimal value. When k = O(log n), our algorithm yields a polynomial inference\nalgorithm for Bayesian networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:12 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Becker", "Ann", ""], ["Geiger", "Dan", ""]]}, {"id": "1302.3672", "submitter": "Jiun-Jie Wang", "authors": "Jiun-Jie Wang", "title": "A Polynomial Time Algorithm for Finding Area-Universal Rectangular\n  Layouts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rectangular layout $\\mathcal{L}$ is a rectangle partitioned into disjoint\nsmaller rectangles so that no four smaller rectangles meet at the same point.\nRectangular layouts were originally used as floorplans in VLSI design to\nrepresent VLSI chip layouts. More recently, they are used in graph drawing as\nrectangular cartograms. In these applications, an area $a(r)$ is assigned to\neach rectangle $r$, and the actual area of $r$ in $\\mathcal{L}$ is required to\nbe $a(r)$. Moreover, some applications require that we use combinatorially\nequivalent rectangular layouts to represent multiple area assignment functions.\n$\\mathcal{L}$ is called {\\em area-universal} if any area assignment to its\nrectangles can be realized by a layout that is combinatorially equivalent to\n$\\mathcal{L}$.\n  A basic question in this area is to determine if a given plane graph $G$ has\nan area-universal rectangular layout or not. A fixed-parameter-tractable\nalgorithm for solving this problem was obtained in \\cite{EMSV12}. Their\nalgorithm takes $O(2^{O(K^2)}n^{O(1)})$ time (where $K$ is the maximum number\nof degree 4 vertices in any minimal separation component), which is exponential\ntime in general case. It is an open problem to find a true polynomial time\nalgorithm for solving this problem. In this paper, we describe such a\npolynomial time algorithm.\n  This paper has been revised for many versions. For previous versions,\nreferrers who are familiar with area-universal rectangular layouts always have\nthe same doubt for the correctness of our algorithm. They doubt that our\nalgorithm will give a wrong output which combine two \\emph{conflicting} REL\ntogether.\n  In the current version, we realize this critical issue for the previous\nalgorithm and we will provide two subsections 5.3 and 5.4 to solve this issue.\n(A backtracking algorithm to detect wrong outputs.)\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 04:29:16 GMT"}, {"version": "v2", "created": "Mon, 5 May 2014 22:24:30 GMT"}, {"version": "v3", "created": "Sun, 18 May 2014 19:48:27 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2015 00:53:32 GMT"}, {"version": "v5", "created": "Wed, 30 Dec 2015 09:12:32 GMT"}, {"version": "v6", "created": "Thu, 2 Jun 2016 00:44:43 GMT"}, {"version": "v7", "created": "Thu, 15 Sep 2016 22:56:32 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Wang", "Jiun-Jie", ""]]}, {"id": "1302.3720", "submitter": "Guillaume Aupy", "authors": "Guillaume Aupy and Anne Benoit and Rami Melhem and Paul Renaud-Goud\n  and Yves Robert", "title": "Energy-aware checkpointing of divisible tasks with soft or hard\n  deadlines", "comments": "This work was supported by ANR Rescue", "journal-ref": null, "doi": null, "report-no": "INRIA RR-8238", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim at minimizing the energy consumption when executing a\ndivisible workload under a bound on the total execution time, while resilience\nis provided through checkpointing. We discuss several variants of this\nmulti-criteria problem. Given the workload, we need to decide how many chunks\nto use, what are the sizes of these chunks, and at which speed each chunk is\nexecuted. Furthermore, since a failure may occur during the execution of a\nchunk, we also need to decide at which speed a chunk should be re-executed in\nthe event of a failure. The goal is to minimize the expectation of the total\nenergy consumption, while enforcing a deadline on the execution time, that\nshould be met either in expectation (soft deadline), or in the worst case (hard\ndeadline). For each problem instance, we propose either an exact solution, or a\nfunction that can be optimized numerically. The different models are then\ncompared through an extensive set of experiments.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 10:42:53 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Aupy", "Guillaume", ""], ["Benoit", "Anne", ""], ["Melhem", "Rami", ""], ["Renaud-Goud", "Paul", ""], ["Robert", "Yves", ""]]}, {"id": "1302.3726", "submitter": "Aaron Potechin", "authors": "Aaron Potechin", "title": "Improved upper and lower bound techniques for monotone switching\n  networks for directed connectivity", "comments": "48 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the monotone space of complexity of directed\nconnectivity for a large class of input graphs $G$ using the switching network\nmodel. The upper and lower bounds we obtain are a significant generalization of\nprevious results and the proofs involve several completely new techniques and\nideas.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 11:04:14 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2013 01:18:24 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Potechin", "Aaron", ""]]}, {"id": "1302.3763", "submitter": "Marek Cygan", "authors": "Marek Cygan and Marcin Pilipczuk", "title": "Faster exponential-time algorithms in graphs of bounded average degree", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first show that the Traveling Salesman Problem in an n-vertex graph with\naverage degree bounded by d can be solved in O*(2^{(1-\\eps_d)n}) time and\nexponential space for a constant \\eps_d depending only on d, where the\nO*-notation suppresses factors polynomial in the input size. Thus, we\ngeneralize the recent results of Bjorklund et al. [TALG 2012] on graphs of\nbounded degree.\n  Then, we move to the problem of counting perfect matchings in a graph. We\nfirst present a simple algorithm for counting perfect matchings in an n-vertex\ngraph in O*(2^{n/2}) time and polynomial space; our algorithm matches the\ncomplexity bounds of the algorithm of Bjorklund [SODA 2012], but relies on\ninclusion-exclusion principle instead of algebraic transformations. Building\nupon this result, we show that the number of perfect matchings in an n-vertex\ngraph with average degree bounded by d can be computed in\nO*(2^{(1-\\eps_{2d})n/2}) time and exponential space, where \\eps_{2d} is the\nconstant obtained by us for the Traveling Salesman Problem in graphs of average\ndegree at most 2d.\n  Moreover we obtain a simple algorithm that counts the number of perfect\nmatchings in an n-vertex bipartite graph of average degree at most d in\nO*(2^{(1-1/(3.55d))n/2}) time, improving and simplifying the recent result of\nIzumi and Wadayama [FOCS 2012].\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 14:41:00 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Cygan", "Marek", ""], ["Pilipczuk", "Marcin", ""]]}, {"id": "1302.3889", "submitter": "Mohammad Mahdi Karbasioun", "authors": "Mohammad M. Karbasioun, Gennady Shaikhet, Evangelos Kranakis, Ioannis\n  Lambadaris", "title": "Power Strip Packing of Malleable Demands in Smart Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of supplying electricity to a set of $\\mathcal{N}$\ncustomers in a smart-grid framework. Each customer requires a certain amount of\nelectrical energy which has to be supplied during the time interval $[0,1]$. We\nassume that each demand has to be supplied without interruption, with possible\nduration between $\\ell$ and $r$, which are given system parameters ($\\ell\\le\nr$). At each moment of time, the power of the grid is the sum of all the\nconsumption rates for the demands being supplied at that moment. Our goal is to\nfind an assignment that minimizes the {\\it power peak} - maximal power over\n$[0,1]$ - while satisfying all the demands. To do this first we find the lower\nbound of optimal power peak. We show that the problem depends on whether or not\nthe pair $\\ell, r$ belongs to a \"good\" region $\\mathcal{G}$. If it does - then\nan optimal assignment almost perfectly \"fills\" the rectangle $time \\times power\n= [0,1] \\times [0, A]$ with $A$ being the sum of all the energy demands - thus\nachieving an optimal power peak $A$. Conversely, if $\\ell, r$ do not belong to\n$\\mathcal{G}$, we identify the lower bound $\\bar{A} >A$ on the optimal value of\npower peak and introduce a simple linear time algorithm that almost perfectly\narranges all the demands in a rectangle $[0, A /\\bar{A}] \\times [0, \\bar{A}]$\nand show that it is asymptotically optimal.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 21:12:30 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Karbasioun", "Mohammad M.", ""], ["Shaikhet", "Gennady", ""], ["Kranakis", "Evangelos", ""], ["Lambadaris", "Ioannis", ""]]}, {"id": "1302.3946", "submitter": "Lin Chen", "authors": "Lin Chen, Deshi Ye, Guochuan Zhang", "title": "Approximating the optimal competitive ratio for an ancient online\n  scheduling problem", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical online scheduling problem P||C_{max} in which jobs\nare released over list and provide a nearly optimal online algorithm. More\nprecisely, an online algorithm whose competitive ratio is at most (1+\\epsilon)\ntimes that of an optimal online algorithm could be achieved in polynomial time,\nwhere m, the number of machines, is a part of the input. It substantially\nimproves upon the previous results by almost closing the gap between the\ncurrently best known lower bound of 1.88 (Rudin, Ph.D thesis, 2001) and the\nbest known upper bound of 1.92 (Fleischer, Wahl, Journal of Scheduling, 2000).\nIt has been known by folklore that an online problem could be viewed as a game\nbetween an adversary and the online player. Our approach extensively explores\nsuch a structure and builds up a completely new framework to show that, for the\nonline over list scheduling problem, given any \\epsilon>0, there exists a\nuniform threshold K which is polynomial in m such that if the competitive ratio\nof an online algorithm is \\rho<=2, then there exists a list of at most K jobs\nto enforce the online algorithm to achieve a competitive ratio of at least\n\\rho-O(\\epsilon). Our approach is substantially different from that of Gunther\net al. (Gunther et al., SODA 2013), in which an approximation scheme for online\nover time scheduling problems is given, where the number of machines is fixed.\nOur method could also be extended to several related online over list\nscheduling models.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2013 08:32:11 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Chen", "Lin", ""], ["Ye", "Deshi", ""], ["Zhang", "Guochuan", ""]]}, {"id": "1302.4016", "submitter": "Yakov Nekrich", "authors": "Gregory Kucherov, Yakov Nekrich", "title": "Full-fledged Real-Time Indexing for Constant Size Alphabets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a data structure that supports pattern matching\nqueries on a dynamically arriving text over an alphabet ofconstant size. Each\nnew symbol can be prepended to $T$ in O(1) worst-case time. At any moment, we\ncan report all occurrences of a pattern $P$ in the current text in $O(|P|+k)$\ntime, where $|P|$ is the length of $P$ and $k$ is the number of occurrences.\nThis resolves, under assumption of constant-size alphabet, a long-standing open\nproblem of existence of a real-time indexing method for string matching (see\n\\cite{AmirN08}).\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2013 00:01:20 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2013 09:24:14 GMT"}, {"version": "v3", "created": "Sat, 6 Jul 2013 20:34:41 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Kucherov", "Gregory", ""], ["Nekrich", "Yakov", ""]]}, {"id": "1302.4064", "submitter": "Jinil Kim", "authors": "Jinil Kim, Peter Eades, Rudolf Fleischer, Seok-Hee Hong, Costas S.\n  Iliopoulos, Kunsoo Park, Simon J. Puglisi, Takeshi Tokuyama", "title": "Order Preserving Matching", "comments": "15 pages; submitted to Theoretical Computer Science, 5 Dec 2012;\n  presented at Theo Murphy International Scientific Meeting of the Royal\n  Society on Storage and Indexing of Massive Data, 7 Feb 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new string matching problem called order-preserving matching\non numeric strings where a pattern matches a text if the text contains a\nsubstring whose relative orders coincide with those of the pattern.\nOrder-preserving matching is applicable to many scenarios such as stock price\nanalysis and musical melody matching in which the order relations should be\nmatched instead of the strings themselves. Solving order-preserving matching\nhas to do with representations of order relations of a numeric string. We\ndefine prefix representation and nearest neighbor representation, which lead to\nefficient algorithms for order-preserving matching. We present efficient\nalgorithms for single and multiple pattern cases. For the single pattern case,\nwe give an O(n log m) time algorithm and optimize it further to obtain O(n + m\nlog m) time. For the multiple pattern case, we give an O(n log m) time\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2013 13:06:42 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Kim", "Jinil", ""], ["Eades", "Peter", ""], ["Fleischer", "Rudolf", ""], ["Hong", "Seok-Hee", ""], ["Iliopoulos", "Costas S.", ""], ["Park", "Kunsoo", ""], ["Puglisi", "Simon J.", ""], ["Tokuyama", "Takeshi", ""]]}, {"id": "1302.4213", "submitter": "Kim-Manuel Klein", "authors": "Klaus Jansen and Kim-Manuel Klein", "title": "A Robust AFPTAS for Online Bin Packing with Polynomial Migration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop general LP and ILP techniques to find an approximate\nsolution with improved objective value close to an existing solution. The task\nof improving an approximate solution is closely related to a classical theorem\nof Cook et al. in the sensitivity analysis for LPs and ILPs. This result is\noften applied in designing robust algorithms for online problems. We apply our\nnew techniques to the online bin packing problem, where it is allowed to\nreassign a certain number of items, measured by the migration factor. The\nmigration factor is defined by the total size of reassigned items divided by\nthe size of the arriving item. We obtain a robust asymptotic fully polynomial\ntime approximation scheme (AFPTAS) for the online bin packing problem with\nmigration factor bounded by a polynomial in $\\frac{1}{\\epsilon}$. This answers\nan open question stated by Epstein and Levin in the affirmative. As a byproduct\nwe prove an approximate variant of the sensitivity theorem by Cook at el. for\nlinear programs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 10:23:00 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Jansen", "Klaus", ""], ["Klein", "Kim-Manuel", ""]]}, {"id": "1302.4216", "submitter": "Adrian  Neumann", "authors": "Karl Bringmann, Benjamin Doerr, Adrian Neumann, Jakub Sliacan", "title": "Online Checkpointing with Improved Worst-Case Guarantees", "comments": "25 pages, 5 figures. ICALP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online checkpointing problem, the task is to continuously maintain a\nset of k checkpoints that allow to rewind an ongoing computation faster than by\na full restart. The only operation allowed is to replace an old checkpoint by\nthe current state. Our aim are checkpoint placement strategies that minimize\nrewinding cost, i.e., such that at all times T when requested to rewind to some\ntime t <= T the number of computation steps that need to be redone to get to t\nfrom a checkpoint before t is as small as possible. In particular, we want that\nthe closest checkpoint earlier than t is not further away from t than q_k times\nthe ideal distance T / (k+1), where q_k is a small constant.\n  Improving over earlier work showing 1 + 1/k <= q_k <= 2, we show that q_k can\nbe chosen asymptotically less than 2. We present algorithms with asymptotic\ndiscrepancy q_k <= 1.59 + o(1) valid for all k and q_k <= ln(4) + o(1) <= 1.39\n+ o(1) valid for k being a power of two. Experiments indicate the uniform bound\np_k <= 1.7 for all k. For small k, we show how to use a linear programming\napproach to compute good checkpointing algorithms. This gives discrepancies of\nless than 1.55 for all k < 60.\n  We prove the first lower bound that is asymptotically more than one, namely\nq_k >= 1.30 - o(1). We also show that optimal algorithms (yielding the infimum\ndiscrepancy) exist for all k.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 10:36:08 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2013 10:10:13 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Bringmann", "Karl", ""], ["Doerr", "Benjamin", ""], ["Neumann", "Adrian", ""], ["Sliacan", "Jakub", ""]]}, {"id": "1302.4347", "submitter": "Justin Ward", "authors": "Maxim Sviridenko and Justin Ward", "title": "Large Neighborhood Local Search for the Maximum Set Packing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the classical maximum set packing problem where set\ncardinality is upper bounded by $k$. We show how to design a variant of a\npolynomial-time local search algorithm with performance guarantee $(k+2)/3$.\nThis local search algorithm is a special case of a more general procedure that\nallows to swap up to $\\Theta(\\log n)$ elements per iteration. We also design\nproblem instances with locality gap $k/3$ even for a wide class of exponential\ntime local search procedures, which can swap up to $cn$ elements for a constant\n$c$. This shows that our analysis of this class of algorithms is almost tight.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 16:48:00 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Sviridenko", "Maxim", ""], ["Ward", "Justin", ""]]}, {"id": "1302.4391", "submitter": "Mohammadreza Ghodsi", "authors": "Mohammadreza Ghodsi", "title": "Constructing a genome assembly that has the maximum likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate genome assembly problem as an optimization problem in which the\nobjective function is the likelihood of the assembly given the reads.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 19:14:38 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2013 15:43:10 GMT"}, {"version": "v3", "created": "Thu, 7 Apr 2016 06:14:03 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Ghodsi", "Mohammadreza", ""]]}, {"id": "1302.4426", "submitter": "Fatemeh Rajabi-Alni", "authors": "Fatemeh Rajabi-Alni", "title": "A new algorithm for Many to Many Matching with Demands and Capacities", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let A={a_1,a_2,...,a_s} and {b_1,b_2,...,b_t} with s+r=n, the many to many\npoint matching with demands and capacities matches each point a_i in A to at\nleast alpha_i and at most alpha_i points in B, and each point b_j in B to at\nleast beta_j and at most beta_j points in A for all 1 <= i <= s and 1 <= j <=\nt. In this paper, we present an O(n^4) time and O(n) space algorithm for this\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 20:54:05 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Rajabi-Alni", "Fatemeh", ""]]}, {"id": "1302.4536", "submitter": "C. Seshadhri", "authors": "Deeparnab Chakrabarty and C. Seshadhri", "title": "A o(n) monotonicity tester for Boolean functions over the hypercube", "comments": "Journal version, with discussion on directed isoperimetry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Boolean function $f:\\{0,1\\}^n \\mapsto \\{0,1\\}$ is said to be $\\eps$-far\nfrom monotone if $f$ needs to be modified in at least $\\eps$-fraction of the\npoints to make it monotone. We design a randomized tester that is given oracle\naccess to $f$ and an input parameter $\\eps>0$, and has the following guarantee:\nIt outputs {\\sf Yes} if the function is monotonically non-decreasing, and\noutputs {\\sf No} with probability $>2/3$, if the function is $\\eps$-far from\nmonotone. This non-adaptive, one-sided tester makes\n$O(n^{7/8}\\eps^{-3/2}\\ln(1/\\eps))$ queries to the oracle.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 08:05:14 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2013 05:30:10 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2014 23:26:02 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Chakrabarty", "Deeparnab", ""], ["Seshadhri", "C.", ""]]}, {"id": "1302.4544", "submitter": "Danupon Nanongkai", "authors": "Atish Das Sarma, Danupon Nanongkai, Gopal Pandurangan, Prasad Tetali", "title": "Distributed Random Walks", "comments": "Preprint of an article to appear in Journal of the ACM in February\n  2013. The official journal version has several gramatical corrections.\n  Preliminary versions of this paper appeared in PODC 2009 and PODC 2010. arXiv\n  admin note: substantial text overlap with arXiv:0911.3195, arXiv:1205.5525", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing random walks in networks is a fundamental primitive that has found\napplications in many areas of computer science, including distributed\ncomputing. In this paper, we focus on the problem of sampling random walks\nefficiently in a distributed network and its applications. Given bandwidth\nconstraints, the goal is to minimize the number of rounds required to obtain\nrandom walk samples.\n  All previous algorithms that compute a random walk sample of length $\\ell$ as\na subroutine always do so naively, i.e., in $O(\\ell)$ rounds. The main\ncontribution of this paper is a fast distributed algorithm for performing\nrandom walks. We present a sublinear time distributed algorithm for performing\nrandom walks whose time complexity is sublinear in the length of the walk. Our\nalgorithm performs a random walk of length $\\ell$ in $\\tilde{O}(\\sqrt{\\ell D})$\nrounds ($\\tilde{O}$ hides $\\polylog{n}$ factors where $n$ is the number of\nnodes in the network) with high probability on an undirected network, where $D$\nis the diameter of the network. For small diameter graphs, this is a\nsignificant improvement over the naive $O(\\ell)$ bound. Furthermore, our\nalgorithm is optimal within a poly-logarithmic factor as there exists a\nmatching lower bound [Nanongkai et al. PODC 2011]. We further extend our\nalgorithms to efficiently perform $k$ independent random walks in\n$\\tilde{O}(\\sqrt{k\\ell D} + k)$ rounds. We also show that our algorithm can be\napplied to speedup the more general Metropolis-Hastings sampling.\n  Our random walk algorithms can be used to speed up distributed algorithms in\napplications that use random walks as a subroutine, such as computing a random\nspanning tree and estimating mixing time and related parameters. Our algorithm\nis fully decentralized and can serve as a building block in the design of\ntopologically-aware networks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 08:36:18 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Sarma", "Atish Das", ""], ["Nanongkai", "Danupon", ""], ["Pandurangan", "Gopal", ""], ["Tetali", "Prasad", ""]]}, {"id": "1302.4546", "submitter": "Rong-Hua Li", "authors": "Rong-Hua Li and Jeffrey Xu Yu and Xin Huang and Hong Cheng", "title": "Random-walk domination in large graphs: problem definitions and fast\n  solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and formulate two types of random-walk domination problems in\ngraphs motivated by a number of applications in practice (e.g., item-placement\nproblem in online social network, Ads-placement problem in advertisement\nnetworks, and resource-placement problem in P2P networks). Specifically, given\na graph $G$, the goal of the first type of random-walk domination problem is to\ntarget $k$ nodes such that the total hitting time of an $L$-length random walk\nstarting from the remaining nodes to the targeted nodes is minimal. The second\ntype of random-walk domination problem is to find $k$ nodes to maximize the\nexpected number of nodes that hit any one targeted node through an $L$-length\nrandom walk. We prove that these problems are two special instances of the\nsubmodular set function maximization with cardinality constraint problem. To\nsolve them effectively, we propose a dynamic-programming (DP) based greedy\nalgorithm which is with near-optimal performance guarantee. The DP-based greedy\nalgorithm, however, is not very efficient due to the expensive marginal gain\nevaluation. To further speed up the algorithm, we propose an approximate greedy\nalgorithm with linear time complexity w.r.t.\\ the graph size and also with\nnear-optimal performance guarantee. The approximate greedy algorithm is based\non a carefully designed random-walk sampling and sample-materialization\ntechniques. Extensive experiments demonstrate the effectiveness, efficiency and\nscalability of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 09:09:20 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Li", "Rong-Hua", ""], ["Yu", "Jeffrey Xu", ""], ["Huang", "Xin", ""], ["Cheng", "Hong", ""]]}, {"id": "1302.4587", "submitter": "Christian Schulz", "authors": "Marcel Birn, Vitaly Osipov, Peter Sanders, Christian Schulz, Nodari\n  Sitchinava", "title": "Efficient Parallel and External Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a simple algorithm for computing a matching on a graph runs in a\nlogarithmic number of phases incurring work linear in the input size. The\nalgorithm can be adapted to provide efficient algorithms in several models of\ncomputation, such as PRAM, External Memory, MapReduce and distributed memory\nmodels. Our CREW PRAM algorithm is the first O(log^2 n) time, linear work\nalgorithm. Our experimental results indicate the algorithm's high speed and\nefficiency combined with good solution quality.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 12:13:10 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2014 16:09:09 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Birn", "Marcel", ""], ["Osipov", "Vitaly", ""], ["Sanders", "Peter", ""], ["Schulz", "Christian", ""], ["Sitchinava", "Nodari", ""]]}, {"id": "1302.4609", "submitter": "G\\'abor Tardos", "authors": "L. Csirmaz, G. Tardos", "title": "Optimal information rate of secret sharing schemes on trees", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information rate for an access structure is the reciprocal of the load of\nthe optimal secret sharing scheme for this structure. We determine this value\nfor all trees: it is 1/(2-1/c), where c is the size of the largest core of the\ntree. A subset of the vertices of a tree is a core if it induces a connected\nsubgraph and for each vertex in the subset one finds a neighbor outside the\nsubset. Our result follows from a lower and an upper bound on the information\nrate that applies for any graph and happen to coincide for trees because of a\ncorrespondence between the size of the largest core and a quantity related to a\nfractional cover of the tree with stars.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 13:53:52 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Csirmaz", "L.", ""], ["Tardos", "G.", ""]]}, {"id": "1302.4619", "submitter": "Dmitry Lande", "authors": "D.V. Lande, A.A.Snarskii", "title": "Compactified Horizontal Visibility Graph for the Language Network", "comments": "9 pages, 3 figures, 2 appendix tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A compactified horizontal visibility graph for the language network is\nproposed. It was found that the networks constructed in such way are scale\nfree, and have a property that among the nodes with largest degrees there are\nwords that determine not only a text structure communication, but also its\ninformational structure.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 14:32:17 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Lande", "D. V.", ""], ["Snarskii", "A. A.", ""]]}, {"id": "1302.4713", "submitter": "Aaron Roth", "authors": "Shaddin Dughmi and Nicole Immorlica and Aaron Roth", "title": "Constrained Signaling in Auction Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of an auctioneer who faces the task of selling a good\n(drawn from a known distribution) to a set of buyers, when the auctioneer does\nnot have the capacity to describe to the buyers the exact identity of the good\nthat he is selling. Instead, he must come up with a constrained signalling\nscheme: a (non injective) mapping from goods to signals, that satisfies the\nconstraints of his setting. For example, the auctioneer may be able to\ncommunicate only a bounded length message for each good, or he might be legally\nconstrained in how he can advertise the item being sold. Each candidate\nsignaling scheme induces an incomplete-information game among the buyers, and\nthe goal of the auctioneer is to choose the signaling scheme and accompanying\nauction format that optimizes welfare. In this paper, we use techniques from\nsubmodular function maximization and no-regret learning to give algorithms for\ncomputing constrained signaling schemes for a variety of constrained signaling\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 19:15:02 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2014 21:20:45 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Dughmi", "Shaddin", ""], ["Immorlica", "Nicole", ""], ["Roth", "Aaron", ""]]}, {"id": "1302.4870", "submitter": "Shaheena Sultana", "authors": "Shaheena Sultana and Md. Saidur Rahman and Arpita Roy and Suraiya\n  Tairin", "title": "Bar 1-Visibility Drawings of 1-Planar Graphs", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bar 1-visibility drawing of a graph $G$ is a drawing of $G$ where each\nvertex is drawn as a horizontal line segment called a bar, each edge is drawn\nas a vertical line segment where the vertical line segment representing an edge\nmust connect the horizontal line segments representing the end vertices and a\nvertical line segment corresponding to an edge intersects at most one bar which\nis not an end point of the edge. A graph $G$ is bar 1-visible if $G$ has a bar\n1-visibility drawing. A graph $G$ is 1-planar if $G$ has a drawing in a\n2-dimensional plane such that an edge crosses at most one other edge. In this\npaper we give linear-time algorithms to find bar 1-visibility drawings of\ndiagonal grid graphs and maximal outer 1-planar graphs. We also show that\nrecursive quadrangle 1-planar graphs and pseudo double wheel 1-planar graphs\nare bar 1-visible graphs.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 11:00:29 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Sultana", "Shaheena", ""], ["Rahman", "Md. Saidur", ""], ["Roy", "Arpita", ""], ["Tairin", "Suraiya", ""]]}, {"id": "1302.5121", "submitter": "Robin Thomas", "authors": "Zdenek Dvorak, Ken-ichi Kawarabayashi and Robin Thomas", "title": "Three-coloring triangle-free planar graphs in linear time", "comments": "22 pages", "journal-ref": "ACM Transactions on Algorithms 7 (2011), Article 41", "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grotzsch's theorem states that every triangle-free planar graph is\n3-colorable. Several relatively simple proofs of this fact were provided by\nThomassen and other authors. It is easy to convert these proofs into\nquadratic-time algorithms to find a 3-coloring, but it is not clear how to find\nsuch a coloring in linear time (Kowalik used a nontrivial data structure to\nconstruct an O(n log n) algorithm).\n  We design a linear-time algorithm to find a 3-coloring of a given\ntriangle-free planar graph. The algorithm avoids using any complex data\nstructures, which makes it easy to implement. As a by-product we give a yet\nsimpler proof of Grotzsch's theorem.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 21:13:06 GMT"}], "update_date": "2013-02-22", "authors_parsed": [["Dvorak", "Zdenek", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Thomas", "Robin", ""]]}, {"id": "1302.5127", "submitter": "Mikkel Thorup", "authors": "Mikkel Thorup", "title": "On the k-Independence Required by Linear Probing and Minwise\n  Independence", "comments": "Short preliminary version appeared at ICALP'10. Version 3 fixes typos\n  from first and second version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that linear probing requires 5-independent hash functions for\nexpected constant-time performance, matching an upper bound of [Pagh et al.\nSTOC'07]. More precisely, we construct a 4-independent hash functions yielding\nexpected logarithmic search time.\n  For (1+{\\epsilon})-approximate minwise independence, we show that \\Omega(log\n1/{\\epsilon})-independent hash functions are required, matching an upper bound\nof [Indyk, SODA'99].\n  We also show that the very fast 2-independent multiply-shift scheme of\nDietzfelbinger [STACS'96] fails badly in both applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 21:25:32 GMT"}, {"version": "v2", "created": "Tue, 9 Dec 2014 15:33:49 GMT"}, {"version": "v3", "created": "Wed, 24 Dec 2014 10:40:13 GMT"}], "update_date": "2014-12-25", "authors_parsed": [["Thorup", "Mikkel", ""]]}, {"id": "1302.5366", "submitter": "Rameshwar Pratap", "authors": "Sourav Chakraborty, Akshay Kamath, and Rameshwar Pratap", "title": "Testing Uniformity of Stationary Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random walk on a directed graph gives a Markov chain on the vertices of the\ngraph. An important question that arises often in the context of Markov chain\nis whether the uniform distribution on the vertices of the graph is a\nstationary distribution of the Markov chain. Stationary distribution of a\nMarkov chain is a global property of the graph. In this paper, we prove that\nfor a regular directed graph whether the uniform distribution on the vertices\nof the graph is a stationary distribution, depends on a local property of the\ngraph, namely if (u,v) is an directed edge then outdegree(u) is equal to\nindegree(v).\n  This result also has an application to the problem of testing whether a given\ndistribution is uniform or \"far\" from being uniform. This is a well studied\nproblem in property testing and statistics. If the distribution is the\nstationary distribution of the lazy random walk on a directed graph and the\ngraph is given as an input, then how many bits of the input graph do one need\nto query in order to decide whether the distribution is uniform or \"far\" from\nit? This is a problem of graph property testing and we consider this problem in\nthe orientation model (introduced by Halevy et al.). We reduce this problem to\ntest (in the orientation model) whether a directed graph is Eulerian. And using\nresult of Fischer et al. on query complexity of testing (in the orientation\nmodel) whether a graph is Eulerian, we obtain bounds on the query complexity\nfor testing whether the stationary distribution is uniform.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 18:26:40 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2013 10:05:21 GMT"}, {"version": "v3", "created": "Thu, 10 Mar 2016 17:00:22 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["Chakraborty", "Sourav", ""], ["Kamath", "Akshay", ""], ["Pratap", "Rameshwar", ""]]}, {"id": "1302.5382", "submitter": "Mehdi Saeedi", "authors": "Afshin Abdollahi, Mehdi Saeedi, Massoud Pedram", "title": "Reversible Logic Synthesis by Quantum Rotation Gates", "comments": "19 pages, 17 figures", "journal-ref": "A. Abdollahi, M. Saeedi, and M. Pedram, \"Reversible Logic\n  Synthesis by Quantum Rotation Gates,\" Quantum Information and Computation,\n  Vol. 13, No. 9-10, 2013", "doi": null, "report-no": null, "categories": "cs.ET cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rotation-based synthesis framework for reversible logic is proposed. We\ndevelop a canonical representation based on binary decision diagrams and\nintroduce operators to manipulate the developed representation model.\nFurthermore, a recursive functional bi-decomposition approach is proposed to\nautomatically synthesize a given function. While Boolean reversible logic is\nparticularly addressed, our framework constructs intermediate quantum states\nthat may be in superposition, hence we combine techniques from reversible\nBoolean logic and quantum computation. The proposed approach results in\nquadratic gate count for multiple-control Toffoli gates without ancillae,\nlinear depth for quantum carry-ripple adder, and quasilinear size for quantum\nmultiplexer.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 19:33:18 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2013 19:05:09 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Abdollahi", "Afshin", ""], ["Saeedi", "Mehdi", ""], ["Pedram", "Massoud", ""]]}, {"id": "1302.5401", "submitter": "Parter Merav", "authors": "Merav Parter and David Peleg", "title": "Sparse Fault-Tolerant BFS Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of designing a sparse {\\em fault-tolerant}\nBFS tree, or {\\em FT-BFS tree} for short, namely, a sparse subgraph $T$ of the\ngiven network $G$ such that subsequent to the failure of a single edge or\nvertex, the surviving part $T'$ of $T$ still contains a BFS spanning tree for\n(the surviving part of) $G$. Our main results are as follows. We present an\nalgorithm that for every $n$-vertex graph $G$ and source node $s$ constructs a\n(single edge failure) FT-BFS tree rooted at $s$ with $O(n \\cdot\n\\min\\{\\Depth(s), \\sqrt{n}\\})$ edges, where $\\Depth(s)$ is the depth of the BFS\ntree rooted at $s$. This result is complemented by a matching lower bound,\nshowing that there exist $n$-vertex graphs with a source node $s$ for which any\nedge (or vertex) FT-BFS tree rooted at $s$ has $\\Omega(n^{3/2})$ edges. We then\nconsider {\\em fault-tolerant multi-source BFS trees}, or {\\em FT-MBFS trees}\nfor short, aiming to provide (following a failure) a BFS tree rooted at each\nsource $s\\in S$ for some subset of sources $S\\subseteq V$. Again, tight bounds\nare provided, showing that there exists a poly-time algorithm that for every\n$n$-vertex graph and source set $S \\subseteq V$ of size $\\sigma$ constructs a\n(single failure) FT-MBFS tree $T^*(S)$ from each source $s_i \\in S$, with\n$O(\\sqrt{\\sigma} \\cdot n^{3/2})$ edges, and on the other hand there exist\n$n$-vertex graphs with source sets $S \\subseteq V$ of cardinality $\\sigma$, on\nwhich any FT-MBFS tree from $S$ has $\\Omega(\\sqrt{\\sigma}\\cdot n^{3/2})$ edges.\nFinally, we propose an $O(\\log n)$ approximation algorithm for constructing\nFT-BFS and FT-MBFS structures. The latter is complemented by a hardness result\nstating that there exists no $\\Omega(\\log n)$ approximation algorithm for these\nproblems under standard complexity assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 20:19:31 GMT"}], "update_date": "2013-02-22", "authors_parsed": [["Parter", "Merav", ""], ["Peleg", "David", ""]]}, {"id": "1302.5445", "submitter": "Viswanath Nagarajan", "authors": "Anupam Gupta and Viswanath Nagarajan and Vijay V. Vazirani", "title": "Thrifty Algorithms for Multistage Robust Optimization", "comments": "20 pages, full version of IPCO 2013 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of multi-stage robust covering problems, where additional\ninformation is revealed about the problem instance in each stage, but the cost\nof taking actions increases. The dilemma for the decision-maker is whether to\nwait for additional information and risk the inflation, or to take early\nactions to hedge against rising costs. We study the \"k-robust\" uncertainty\nmodel: in each stage i = 0, 1,...,T, the algorithm is shown some subset of size\nk_i that completely contains the eventual demands to be covered; here k_1 > k_2\n>...> k_T which ensures increasing information over time. The goal is to\nminimize the cost incurred in the worst-case possible sequence of revelations.\n  For the multistage k-robust set cover problem, we give an O(log m + log\nn)-approximation algorithm, nearly matching the \\Omega(log n + log m/loglog m)\nhardness of approximation even for T=2 stages. Moreover, our algorithm has a\nuseful \"thrifty\" property: it takes actions on just two stages. We show similar\nthrifty algorithms for multi-stage k-robust Steiner tree, Steiner forest, and\nminimum-cut. For these problems our approximation guarantees are O(min{T, log\nn, log L_{max}), where L_{max} is the maximum inflation over all the stages. We\nconjecture that these problems also admit O(1)-approximate thrifty algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 22:34:33 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Gupta", "Anupam", ""], ["Nagarajan", "Viswanath", ""], ["Vazirani", "Vijay V.", ""]]}, {"id": "1302.5611", "submitter": "Dennis Luxen", "authors": "Julian Arz, Dennis Luxen, Peter Sanders", "title": "Transit Node Routing Reconsidered", "comments": "19 pages, submitted to SEA'2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transit Node Routing (TNR) is a fast and exact distance oracle for road\nnetworks. We show several new results for TNR. First, we give a surprisingly\nsimple implementation fully based on Contraction Hierarchies that speeds up\npreprocessing by an order of magnitude approaching the time for just finding a\nCH (which alone has two orders of magnitude larger query time). We also develop\na very effective purely graph theoretical locality filter without any\ncompromise in query times. Finally, we show that a specialization to the online\nmany-to-one (or one-to-many) shortest path further speeds up query time by an\norder of magnitude. This variant even has better query time than the fastest\nknown previous methods which need much more space.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2013 14:43:06 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Arz", "Julian", ""], ["Luxen", "Dennis", ""], ["Sanders", "Peter", ""]]}, {"id": "1302.5820", "submitter": "Songjian Lu", "authors": "Songjian Lu and Xinghua Lu", "title": "An exact algorithm with the time complexity of $O^*(1.299^m)$ for the\n  weighed mutually exclusive set cover problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, we will introduce an exact algorithm with a time complexity of\n$O^*(1.299^m)$ for the {\\sc weighted mutually exclusive set cover} problem,\nwhere $m$ is the number of subsets in the problem. This problem has important\napplications in recognizing mutation genes that cause different cancer\ndiseases.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2013 15:55:48 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Lu", "Songjian", ""], ["Lu", "Xinghua", ""]]}, {"id": "1302.5843", "submitter": "Andrew Lucas", "authors": "Andrew Lucas", "title": "Ising formulations of many NP problems", "comments": "27 pages; v2: substantial revision to intro/conclusion, many more\n  references; v3: substantial revision and extension, to-be-published version", "journal-ref": "Frontiers in Physics 2, 5 (2014)", "doi": "10.3389/fphy.2014.00005", "report-no": null, "categories": "cond-mat.stat-mech cs.CC cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide Ising formulations for many NP-complete and NP-hard problems,\nincluding all of Karp's 21 NP-complete problems. This collects and extends\nmappings to the Ising model from partitioning, covering and satisfiability. In\neach case, the required number of spins is at most cubic in the size of the\nproblem. This work may be useful in designing adiabatic quantum optimization\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2013 20:45:26 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2013 22:26:44 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2014 16:20:55 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Lucas", "Andrew", ""]]}, {"id": "1302.5851", "submitter": "Matthew Felice Pace", "authors": "Matthew Felice Pace and Alexander Tiskin", "title": "Parallel Suffix Array Construction by Accelerated Sampling", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deterministic BSP algorithm for constructing the suffix array of a given\nstring is presented, based on a technique which we call accelerated sampling.\nIt runs in optimal O(n/p) local computation and communication, and requires a\nnear optimal O(log log p) synchronisation steps. The algorithm provides an\nimprovement over the synchronisation costs of existing algorithms, and\nreinforces the importance of the sampling technique.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2013 22:39:03 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Pace", "Matthew Felice", ""], ["Tiskin", "Alexander", ""]]}, {"id": "1302.5871", "submitter": "S Kapoor Sanjiv Kapoor", "authors": "S. Kapoor and M. Sarwat", "title": "The Budgeted Transportation Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a transportation problem with sets of sources and sinks. There are\nprofits and prices on the edges. The goal is to maximize the profit while\nmeeting the following constraints; the total flow going out of a source must\nnot exceed its capacity and the total price of the incoming flow on a sink must\nnot exceed its budget. This problem is closely related to the generalized flow\nproblem.\n  We propose an auction based primal dual approximation algorithm to solve the\nproblem. The complexity is $O(\\epsilon^{-1}(n^2+ n\\log{m})m\\log U)$ where $n$\nis the number of sources, $m$ is the number of sinks, $U$ is the ratio of the\nmaximum profit/price to the minimum profit/price.\n  We also show how to generalize the scheme to solve a more general version of\nthe problem, where there are edge capacities and/or the profit function is\nconcave and piece-wise linear. The complexity of the algorithm depends on the\nnumber of linear segments, termed ${\\cal L}$, of the profit function.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2013 05:08:27 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Kapoor", "S.", ""], ["Sarwat", "M.", ""]]}, {"id": "1302.5913", "submitter": "Viswanath Nagarajan", "authors": "Anupam Gupta and Viswanath Nagarajan", "title": "A Stochastic Probing Problem with Applications", "comments": "20 pages, full version of IPCO 2013 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a general stochastic probing problem defined on a universe V, where\neach element e in V is \"active\" independently with probability p_e. Elements\nhave weights {w_e} and the goal is to maximize the weight of a chosen subset S\nof active elements. However, we are given only the p_e values-- to determine\nwhether or not an element e is active, our algorithm must probe e. If element e\nis probed and happens to be active, then e must irrevocably be added to the\nchosen set S; if e is not active then it is not included in S. Moreover, the\nfollowing conditions must hold in every random instantiation: (1) the set Q of\nprobed elements satisfy an \"outer\" packing constraint, and (2) the set S of\nchosen elements satisfy an \"inner\" packing constraint.\n  The kinds of packing constraints we consider are intersections of matroids\nand knapsacks. Our results provide a simple and unified view of results in\nstochastic matching and Bayesian mechanism design, and can also handle more\ngeneral constraints. As an application, we obtain the first polynomial-time\n$\\Omega(1/k)$-approximate \"Sequential Posted Price Mechanism\" under k-matroid\nintersection feasibility constraints.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2013 14:48:37 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Gupta", "Anupam", ""], ["Nagarajan", "Viswanath", ""]]}, {"id": "1302.6005", "submitter": "Shantanav Chakraborty", "authors": "Shantanav Chakraborty, and Satyabrata Adhikari", "title": "Non-classical Correlations in the Quantum Search Algorithm", "comments": "7 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entanglement lies at the heart of quantum mechanics and has no classical\nanalogue. It is central to the speed up achieved by quantum algorithms over\ntheir classical counterparts. The Grover's search algorithm is one such\nalgorithm which enables us to achieve a quadratic speed up over any known\nclassical algorithm that searches for an element in an unstructured database.\nHere, we analyse and quantify the effects of entanglement in the generalized\nversion of this algorithm for two qubits. By 'generalized', it is meant that\nthe use of any arbitrary single qubit unitary gate is permitted to create\nsuperposed states. Our analysis has been firstly on a noise free environment\nand secondly in the presence of noise. In the absence of noise, we establish a\nrelation between the concurrence and the amplitude of the final state thereby\nshowing the explicit effects of entanglement on the same. Moreover, the effects\nof noisy channels, namely amplitude and phase damping channels are studied. We\ninvestigate the amount of quantum correlation in the states obtained after the\nphase inversion stage of the algorithm followed by interaction of those states\nwith the noisy environment. The quantum correlations are quantified by\ngeometric discord. It has been revealed that the states generated after the\neffect of amplitude damping on the phase inverted states of the quantum search\nalgorithm possess non-zero quantum correlation even when entanglement is\nabsent. However, this is absent in the phase damping scenario.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2013 06:48:15 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Chakraborty", "Shantanav", ""], ["Adhikari", "Satyabrata", ""]]}, {"id": "1302.6220", "submitter": "C. Seshadhri", "authors": "C. Seshadhri, Ali Pinar, Nurcan Durak, and Tamara G. Kolda", "title": "Directed closure measures for networks with reciprocity", "comments": "Updated version; new results on expected directed closures for\n  reciprocal configuration model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of triangles in graphs is a standard tool in network analysis,\nleading to measures such as the \\emph{transitivity}, i.e., the fraction of\npaths of length $2$ that participate in triangles. Real-world networks are\noften directed, and it can be difficult to \"measure\" this network structure\nmeaningfully. We propose a collection of \\emph{directed closure values} for\nmeasuring triangles in directed graphs in a way that is analogous to\ntransitivity in an undirected graph. Our study of these values reveals much\ninformation about directed triadic closure. For instance, we immediately see\nthat reciprocal edges have a high propensity to participate in triangles. We\nalso observe striking similarities between the triadic closure patterns of\ndifferent web and social networks. We perform mathematical and empirical\nanalysis showing that directed configuration models that preserve reciprocity\ncannot capture the triadic closure patterns of real networks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2013 20:42:42 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2013 19:28:55 GMT"}, {"version": "v3", "created": "Thu, 24 Apr 2014 00:24:10 GMT"}], "update_date": "2014-04-25", "authors_parsed": [["Seshadhri", "C.", ""], ["Pinar", "Ali", ""], ["Durak", "Nurcan", ""], ["Kolda", "Tamara G.", ""]]}, {"id": "1302.6256", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi, David F. Gleich, Assefaw H. Gebremedhin, Md. Mostofa\n  Ali Patwary", "title": "Parallel Maximum Clique Algorithms with Applications to Network Analysis\n  and Storage", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC cs.DM cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast, parallel maximum clique algorithm for large sparse graphs\nthat is designed to exploit characteristics of social and information networks.\nThe method exhibits a roughly linear runtime scaling over real-world networks\nranging from 1000 to 100 million nodes. In a test on a social network with 1.8\nbillion edges, the algorithm finds the largest clique in about 20 minutes. Our\nmethod employs a branch and bound strategy with novel and aggressive pruning\ntechniques. For instance, we use the core number of a vertex in combination\nwith a good heuristic clique finder to efficiently remove the vast majority of\nthe search space. In addition, we parallelize the exploration of the search\ntree. During the search, processes immediately communicate changes to upper and\nlower bounds on the size of maximum clique, which occasionally results in a\nsuper-linear speedup because vertices with large search spaces can be pruned by\nother processes. We apply the algorithm to two problems: to compute temporal\nstrong components and to compress graphs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2013 21:16:13 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2013 02:00:15 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Rossi", "Ryan A.", ""], ["Gleich", "David F.", ""], ["Gebremedhin", "Assefaw H.", ""], ["Patwary", "Md. Mostofa Ali", ""]]}, {"id": "1302.6336", "submitter": "EPTCS", "authors": "Manfred Schmidt-Schauss", "title": "Linear Compressed Pattern Matching for Polynomial Rewriting (Extended\n  Abstract)", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 29-40", "doi": "10.4204/EPTCS.110.5", "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an extended abstract of an analysis of term rewriting where the\nterms in the rewrite rules as well as the term to be rewritten are compressed\nby a singleton tree grammar (STG). This form of compression is more general\nthan node sharing or representing terms as dags since also partial trees\n(contexts) can be shared in the compression. In the first part efficient but\ncomplex algorithms for detecting applicability of a rewrite rule under\nSTG-compression are constructed and analyzed. The second part applies these\nresults to term rewriting sequences.\n  The main result for submatching is that finding a redex of a left-linear rule\ncan be performed in polynomial time under STG-compression.\n  The main implications for rewriting and (single-position or parallel)\nrewriting steps are: (i) under STG-compression, n rewriting steps can be\nperformed in nondeterministic polynomial time. (ii) under STG-compression and\nfor left-linear rewrite rules a sequence of n rewriting steps can be performed\nin polynomial time, and (iii) for compressed rewrite rules where the left hand\nsides are either DAG-compressed or ground and STG-compressed, and an\nSTG-compressed target term, n rewriting steps can be performed in polynomial\ntime.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:22 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Schmidt-Schauss", "Manfred", ""]]}, {"id": "1302.6482", "submitter": "Ji\\v{r}\\'i Matou\\v{s}ek", "authors": "Jiri Matousek", "title": "Near-optimal separators in string graphs", "comments": "4 pages; minor corrections and updates compared to version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G be a string graph (an intersection graph of continuous arcs in the\nplane) with m edges. Fox and Pach proved that G has a separator consisting of\nO(m^{3/4}\\sqrt{log m})$ vertices, and they conjectured that the bound of\nO(\\sqrt m) actually holds. We obtain separators with O(\\sqrt m \\log m)\nvertices.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 16:29:16 GMT"}, {"version": "v2", "created": "Mon, 6 May 2013 16:44:53 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Matousek", "Jiri", ""]]}, {"id": "1302.6641", "submitter": "John Iacono", "authors": "John Iacono", "title": "Why some heaps support constant-amortized-time decrease-key operations,\n  and others do not", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lower bound is presented which shows that a class of heap algorithms in the\npointer model with only heap pointers must spend Omega(log log n / log log log\nn) amortized time on the decrease-key operation (given O(log n) amortized-time\nextract-min). Intuitively, this bound shows the key to having O(1)-time\ndecrease-key is the ability to sort O(log n) items in O(log n) time; Fibonacci\nheaps [M.L. Fredman and R. E. Tarjan. J. ACM 34(3):596-615 (1987)] do this\nthrough the use of bucket sort. Our lower bound also holds no matter how much\ndata is augmented; this is in contrast to the lower bound of Fredman [J. ACM\n46(4):473-501 (1999)] who showed a tradeoff between the number of augmented\nbits and the amortized cost of decrease-key. A new heap data structure, the\nsort heap, is presented. This heap is a simplification of the heap of Elmasry\n[SODA 2009: 471-476] and shares with it a O(log log n) amortized-time\ndecrease-key, but with a straightforward implementation such that our lower\nbound holds. Thus a natural model is presented for a pointer-based heap such\nthat the amortized runtime of a self-adjusting structure and amortized lower\nasymptotic bounds for decrease-key differ by but a O(log log log n) factor.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 01:52:21 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2013 22:12:24 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2013 18:50:20 GMT"}], "update_date": "2013-07-17", "authors_parsed": [["Iacono", "John", ""]]}, {"id": "1302.6653", "submitter": "David Wagner", "authors": "David P. Wagner", "title": "The Unified Segment Tree and its Application to the Rectangle\n  Intersection Problem", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a variation on the multidimensional segment tree,\nformed by unifying different interpretations of the dimensionalities of the\ndata structure. We give some new definitions to previously well-defined\nconcepts that arise naturally in this variation, and we show some properties\nconcerning the relationships between the nodes, and the regions those nodes\nrepresent. We think these properties will enable the data to be utilized in new\nsituations, beyond those previously studied. As an example, we show that the\ndata structure can be used to solve the Rectangle Intersection Problem in a\nmore straightforward and natural way than had be done in the past.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 03:15:56 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Wagner", "David P.", ""]]}, {"id": "1302.6666", "submitter": "Yan Huang", "authors": "Yan Huang, Ruoming Jin, Favyen Bastani, Xiaoyang Sean Wang", "title": "Large Scale Real-time Ridesharing with Service Guarantee on Road\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The mean occupancy rates of personal vehicle trips in the United States is\nonly 1.6 persons per vehicle mile. Urban traffic gridlock is a familiar scene.\nRidesharing has the potential to solve many environmental, congestion, and\nenergy problems. In this paper, we introduce the problem of large scale\nreal-time ridesharing with service guarantee on road networks. Servers and trip\nrequests are dynamically matched while waiting time and service time\nconstraints of trips are satisfied. We first propose two basic algorithms: a\nbranch-and-bound algorithm and an integer programing algorithm. However, these\nalgorithm structures do not adapt well to the dynamic nature of the ridesharing\nproblem. Thus, we then propose a kinetic tree algorithm capable of better\nscheduling dynamic requests and adjusting routes on-the-fly. We perform\nexperiments on a large real taxi dataset from Shanghai. The results show that\nthe kinetic tree algorithm is faster than other algorithms in response time.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 05:41:49 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Huang", "Yan", ""], ["Jin", "Ruoming", ""], ["Bastani", "Favyen", ""], ["Wang", "Xiaoyang Sean", ""]]}, {"id": "1302.6787", "submitter": "Ann Becker", "authors": "Ann Becker, Dan Geiger", "title": "Approximation Algorithms for the Loop Cutset Problem", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-60-68", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to find a small loop curser in a Bayesian network. Finding such a\nloop cutset is the first step in the method of conditioning for inference. Our\nalgorithm for finding a loop cutset, called MGA, finds a loop cutset which is\nguaranteed in the worst case to contain less than twice the number of variables\ncontained in a minimum loop cutset. We test MGA on randomly generated graphs\nand find that the average ratio between the number of instances associated with\nthe algorithms' output and the number of instances associated with a minimum\nsolution is 1.22.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:14:02 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Becker", "Ann", ""], ["Geiger", "Dan", ""]]}, {"id": "1302.6863", "submitter": "Jan Obdr\\v{z}\\'alek", "authors": "Jakub Gajarsk\\'y, Petr Hlin\\v{e}n\\'y, Jan Obdr\\v{z}\\'alek, Sebastian\n  Ordyniak, Felix Reidl, Peter Rossmanith, Fernando S\\'anchez Villaamil,\n  Somnath Sikdar", "title": "Kernelization Using Structural Parameters on Sparse Graph Classes", "comments": "A preliminary version appeared as an extended abstract in the\n  proceedings of ESA 2013, and one section in the proceedings of IPEC 2014.\n  Changes from the previous version: inclusion of the IPEC 2014 results; much\n  stronger conclusion for the case of nowhere dense graph classes; inclusion of\n  some additional problems in the framework, e.g., of the branchwidth problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-theorems for polynomial (linear) kernels have been the subject of\nintensive research in parameterized complexity. Heretofore, meta-theorems for\nlinear kernels exist on graphs of bounded genus, $H$-minor-free graphs, and\n$H$-topological-minor-free graphs. To the best of our knowledge, no\nmeta-theorems for polynomial kernels are known for any larger sparse graph\nclasses; e.g., for classes of bounded expansion or for nowhere dense ones. In\nthis paper we prove such meta-theorems for the two latter cases. More\nspecifically, we show that graph problems that have finite integer index (FII)\nhave linear kernels on graphs of bounded expansion when parameterized by the\nsize of a modulator to constant-treedepth graphs. For nowhere dense graph\nclasses, our result yields almost-linear kernels. While our parameter may seem\nrather strong, we argue that a linear kernelization result on graphs of bounded\nexpansion with a weaker parameter (than treedepth modulator) would fail to\ninclude some of the problems covered by our framework. Moreover, we only\nrequire the problems to have FII on graphs of constant treedepth. This allows\nus to prove linear kernels for problems such as Longest Path/Cycle, Exact\n$s,t$-Path, Treewidth, and Pathwidth, which do not have FII on general graphs\n(and the first two not even on bounded treewidth graphs).\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:49:43 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2013 09:05:41 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2015 15:33:32 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Gajarsk\u00fd", "Jakub", ""], ["Hlin\u011bn\u00fd", "Petr", ""], ["Obdr\u017e\u00e1lek", "Jan", ""], ["Ordyniak", "Sebastian", ""], ["Reidl", "Felix", ""], ["Rossmanith", "Peter", ""], ["Villaamil", "Fernando S\u00e1nchez", ""], ["Sikdar", "Somnath", ""]]}, {"id": "1302.6900", "submitter": "Manuel Schmitt", "authors": "Manuel Schmitt and Rolf Wanka", "title": "Exploiting Independent Subformulas: A Faster Approximation Scheme for\n  #k-SAT", "comments": "Improves: arXiv:1107.2001", "journal-ref": "Information Processing Letters 113 (2013) 337-344", "doi": "10.1016/j.ipl.2013.02.013", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improvement on Thurley's recent randomized approximation scheme\nfor #k-SAT where the task is to count the number of satisfying truth\nassignments of a Boolean function {\\Phi} given as an n-variable k-CNF. We\nintroduce a novel way to identify independent substructures of {\\Phi} and can\ntherefore reduce the size of the search space considerably. Our randomized\nalgorithm works for any k. For #3-SAT, it runs in time\nO(\\epsilon^{-2}*1.51426^n), for #4-SAT, it runs in time\nO(\\epsilon^{-2}*1.60816^n), with error bound \\epsilon.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 16:19:18 GMT"}, {"version": "v2", "created": "Thu, 5 Jun 2014 10:29:05 GMT"}], "update_date": "2014-06-06", "authors_parsed": [["Schmitt", "Manuel", ""], ["Wanka", "Rolf", ""]]}, {"id": "1302.6914", "submitter": "John Howat", "authors": "John Howat and John Iacono and Pat Morin", "title": "The Fresh-Finger Property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unified property roughly states that searching for an element is fast\nwhen the current access is close to a recent access. Here, \"close\" refers to\nrank distance measured among all elements stored by the dictionary. We show\nthat distance need not be measured this way: in fact, it is only necessary to\nconsider a small working-set of elements to measure this rank distance. This\nresults in a data structure with access time that is an improvement upon those\noffered by the unified property for many query sequences.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 16:40:11 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Howat", "John", ""], ["Iacono", "John", ""], ["Morin", "Pat", ""]]}, {"id": "1302.7014", "submitter": "Justin Thaler", "authors": "Jiayang Jiang, Michael Mitzenmacher, Justin Thaler", "title": "Parallel Peeling Algorithms", "comments": "Appears in SPAA 2014. Minor typo corrections relative to previous\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of several algorithms and data structures can be framed as a\npeeling process on a random hypergraph: vertices with degree less than k are\nremoved until there are no vertices of degree less than k left. The remaining\nhypergraph is known as the k-core. In this paper, we analyze parallel peeling\nprocesses, where in each round, all vertices of degree less than k are removed.\nIt is known that, below a specific edge density threshold, the k-core is empty\nwith high probability. We show that, with high probability, below this\nthreshold, only (log log n)/log(k-1)(r-1) + O(1) rounds of peeling are needed\nto obtain the empty k-core for r-uniform hypergraphs. Interestingly, we show\nthat above this threshold, Omega(log n) rounds of peeling are required to find\nthe non-empty k-core. Since most algorithms and data structures aim to peel to\nan empty k-core, this asymmetry appears fortunate. We verify the theoretical\nresults both with simulation and with a parallel implementation using graphics\nprocessing units (GPUs). Our implementation provides insights into how to\nstructure parallel peeling algorithms for efficiency in practice.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 22:03:08 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2013 01:02:04 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2014 19:43:02 GMT"}, {"version": "v4", "created": "Tue, 17 Jun 2014 17:56:29 GMT"}, {"version": "v5", "created": "Fri, 1 Aug 2014 15:30:18 GMT"}], "update_date": "2014-08-04", "authors_parsed": [["Jiang", "Jiayang", ""], ["Mitzenmacher", "Michael", ""], ["Thaler", "Justin", ""]]}, {"id": "1302.7262", "submitter": "Vinicius Gusmao Pereira de Sa", "authors": "Lucila M. S. Bento, Davidson Boccardo, Raphael C. S. Machado,\n  Vin\\'icius G. Pereira de S\\'a, Jayme L. Szwarcfiter", "title": "Towards a provably resilient scheme for graph-based watermarking", "comments": "44 pages, 6 figures. An extended abstract of this paper was published\n  in Proceedings of the 39th International Workshop on Graph Theoretic Concepts\n  in Computer Science (WG 2013), Lecture Notes in Computer Science 8165 (2013),\n  50-63", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital watermarks have been considered a promising way to fight software\npiracy. Graph-based watermarking schemes encode authorship/ownership data as\ncontrol-flow graph of dummy code. In 2012, Chroni and Nikolopoulos developed an\ningenious such scheme which was claimed to withstand attacks in the form of a\nsingle edge removal. We extend the work of those authors in various aspects.\nFirst, we give a formal characterization of the class of graphs generated by\ntheir encoding function. Then, we formulate a linear-time algorithm which\nrecovers from ill-intentioned removals of $k \\leq 2$ edges, therefore proving\ntheir claim. Furthermore, we provide a simpler decoding function and an\nalgorithm to restore watermarks with an arbitrary number of missing edges\nwhenever at all possible. By disclosing and improving upon the resilience of\nChroni and Nikolopoulos's watermark, our results reinforce the interest in\nregarding it as a possible solution to numerous applications.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 17:15:44 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2013 15:09:04 GMT"}, {"version": "v3", "created": "Sun, 14 Apr 2013 05:01:51 GMT"}, {"version": "v4", "created": "Wed, 28 Aug 2013 19:06:06 GMT"}, {"version": "v5", "created": "Fri, 27 Dec 2013 04:33:04 GMT"}, {"version": "v6", "created": "Sat, 4 Jan 2014 15:03:28 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Bento", "Lucila M. S.", ""], ["Boccardo", "Davidson", ""], ["Machado", "Raphael C. S.", ""], ["de S\u00e1", "Vin\u00edcius G. Pereira", ""], ["Szwarcfiter", "Jayme L.", ""]]}, {"id": "1302.7270", "submitter": "Glencora Borradaile", "authors": "Glencora Borradaile and Philip Klein and Claire Mathieu", "title": "A polynomial-time approximation scheme for Euclidean Steiner forest", "comments": "This version is more recent than that appearing in the FOCS\n  proceedings. The partition step has been corrected and the overall\n  presentation has been clarified and formalized. This paper has been accepted\n  to TALG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a randomized O(n polylog n)-time approximation scheme for the Steiner\nforest problem in the Euclidean plane. For every fixed eps > 0 and given n\nterminals in the plane with connection requests between some pairs of\nterminals, our scheme finds a (1 + eps)-approximation to the minimum-length\nforest that connects every requested pair of terminals.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 18:08:25 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2014 16:37:22 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Borradaile", "Glencora", ""], ["Klein", "Philip", ""], ["Mathieu", "Claire", ""]]}, {"id": "1302.7278", "submitter": "Gregory Kucherov", "authors": "Kamil Salikhov, Gustavo Sacomoto, and Gregory Kucherov", "title": "Using cascading Bloom filters to improve the memory usage for de Brujin\n  graphs", "comments": "12 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  De Brujin graphs are widely used in bioinformatics for processing\nnext-generation sequencing data. Due to a very large size of NGS datasets, it\nis essential to represent de Bruijn graphs compactly, and several approaches to\nthis problem have been proposed recently. In this work, we show how to reduce\nthe memory required by the algorithm of [3] that represents de Brujin graphs\nusing Bloom filters. Our method requires 30% to 40% less memory with respect to\nthe method of [3], with insignificant impact to construction time. At the same\ntime, our experiments showed a better query time compared to [3]. This is, to\nour knowledge, the best practical representation for de Bruijn graphs.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 18:35:21 GMT"}, {"version": "v2", "created": "Tue, 21 May 2013 15:25:19 GMT"}], "update_date": "2013-05-22", "authors_parsed": [["Salikhov", "Kamil", ""], ["Sacomoto", "Gustavo", ""], ["Kucherov", "Gregory", ""]]}, {"id": "1302.7316", "submitter": "Stacey Jeffery", "authors": "Andrew M. Childs and Stacey Jeffery and Robin Kothari and Frederic\n  Magniez", "title": "A Time-Efficient Quantum Walk for 3-Distinctness Using Nested Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension to the quantum walk search framework that facilitates\nquantum walks with nested updates. We apply it to give a quantum walk algorithm\nfor 3-Distinctness with query complexity ~O(n^{5/7}), matching the best known\nupper bound (obtained via learning graphs) up to log factors. Furthermore, our\nalgorithm has time complexity ~O(n^{5/7}), improving the previous ~O(n^{3/4}).\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 20:54:56 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Childs", "Andrew M.", ""], ["Jeffery", "Stacey", ""], ["Kothari", "Robin", ""], ["Magniez", "Frederic", ""]]}]