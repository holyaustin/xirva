[{"id": "1301.0068", "submitter": "Guy Bresler", "authors": "Guy Bresler, Ma'ayan Bresler, David Tse", "title": "Optimal Assembly for High Throughput Shotgun Sequencing", "comments": "26 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.DS cs.IT math.IT q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for the design of optimal assembly algorithms for\nshotgun sequencing under the criterion of complete reconstruction. We derive a\nlower bound on the read length and the coverage depth required for\nreconstruction in terms of the repeat statistics of the genome. Building on\nearlier works, we design a de Brujin graph based assembly algorithm which can\nachieve very close to the lower bound for repeat statistics of a wide range of\nsequenced genomes, including the GAGE datasets. The results are based on a set\nof necessary and sufficient conditions on the DNA sequence and the reads for\nreconstruction. The conditions can be viewed as the shotgun sequencing analogue\nof Ukkonen-Pevzner's necessary and sufficient conditions for Sequencing by\nHybridization.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 08:52:44 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2013 03:51:20 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2013 17:41:09 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Bresler", "Guy", ""], ["Bresler", "Ma'ayan", ""], ["Tse", "David", ""]]}, {"id": "1301.0103", "submitter": "Shoshana Marcus", "authors": "Shoshana Marcus and Dina Sokol", "title": "2D Lyndon Words and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Lyndon word is a primitive string which is lexicographically smallest among\ncyclic permutations of its characters. Lyndon words are used for constructing\nbases in free Lie algebras, constructing de Bruijn sequences, finding the\nlexicographically smallest or largest substring in a string, and succinct\nsuffix-prefix matching of highly periodic strings. In this paper, we extend the\nconcept of the Lyndon word to two dimensions. We introduce the 2D Lyndon word\nand use it to capture 2D horizontal periodicity of a matrix in which each row\nis highly periodic, and to efficiently solve 2D horizontal suffix-prefix\nmatching among a set of patterns. This yields a succinct and efficient\nalgorithm for 2D dictionary matching.\n  We present several algorithms that compute the 2D Lyndon word that represents\na matrix. The final algorithm achieves linear time complexity even when the\nleast common multiple of the periods of the rows is exponential in the matrix\nwidth.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 16:24:46 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Marcus", "Shoshana", ""], ["Sokol", "Dina", ""]]}, {"id": "1301.0114", "submitter": "Paul Tarau", "authors": "Paul Tarau", "title": "Tree-based Arithmetic and Compressed Representations of Giant Numbers", "comments": "UNPUBLISHED DRAFT, 26 pages, 2 figures, literate Haskell code\n  included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DM cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we do arithmetic in a completely different way, with a radically\ndifferent data structure? Could this approach provide practical benefits, like\noperations on giant numbers while having an average performance similar to\ntraditional bitstring representations?\n  While answering these questions positively, our tree based representation\ndescribed in this paper comes with a few extra benefits: it compresses giant\nnumbers such that, for instance, the largest known prime number as well as its\nrelated perfect number are represented as trees of small sizes. The same also\napplies to Fermat numbers and important computations like exponentiation of two\nbecome constant time operations.\n  At the same time, succinct representations of sparse sets, multisets and\nsequences become possible through bijections to our tree-represented natural\nnumbers.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 18:29:39 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Tarau", "Paul", ""]]}, {"id": "1301.0123", "submitter": "Ashish Chiplunkar", "authors": "Ashish Chiplunkar, Sundar Vishwanathan", "title": "On Randomized Memoryless Algorithms for the Weighted $k$-server Problem", "comments": "Published at the 54th Annual IEEE Symposium on Foundations of\n  Computer Science (FOCS 2013)", "journal-ref": null, "doi": "10.1109/FOCS.2013.10", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weighted $k$-server problem is a generalization of the $k$-server problem\nin which the cost of moving a server of weight $\\beta_i$ through a distance $d$\nis $\\beta_i\\cdot d$. The weighted server problem on uniform spaces models\ncaching where caches have different write costs. We prove tight bounds on the\nperformance of randomized memoryless algorithms for this problem on uniform\nmetric spaces. We prove that there is an $\\alpha_k$-competitive memoryless\nalgorithm for this problem, where $\\alpha_k=\\alpha_{k-1}^2+3\\alpha_{k-1}+1$;\n$\\alpha_1=1$. On the other hand we also prove that no randomized memoryless\nalgorithm can have competitive ratio better than $\\alpha_k$.\n  To prove the upper bound of $\\alpha_k$ we develop a framework to bound from\nabove the competitive ratio of any randomized memoryless algorithm for this\nproblem. The key technical contribution is a method for working with potential\nfunctions defined implicitly as the solution of a linear system. The result is\nrobust in the sense that a small change in the probabilities used by the\nalgorithm results in a small change in the upper bound on the competitive\nratio. The above result has two important implications. Firstly this yields an\n$\\alpha_k$-competitive memoryless algorithm for the weighted $k$-server problem\non uniform spaces. This is the first competitive algorithm for $k>2$ which is\nmemoryless. Secondly, this helps us prove that the Harmonic algorithm, which\nchooses probabilities in inverse proportion to weights, has a competitive ratio\nof $k\\alpha_k$.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 19:11:25 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2013 19:41:15 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2013 13:25:03 GMT"}, {"version": "v4", "created": "Tue, 17 Dec 2013 17:06:21 GMT"}, {"version": "v5", "created": "Thu, 29 May 2014 09:54:03 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Chiplunkar", "Ashish", ""], ["Vishwanathan", "Sundar", ""]]}, {"id": "1301.0181", "submitter": "Fatih Kocan", "authors": "Fatih Kocan", "title": "A nonenumerative algorithm to find the k longest (shortest) paths in a\n  DAG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel and efficient algorithm to find the k\nlongest (shortest) paths between sources and sinks in a directed acyclic graph\n(DAG). The algorithm does not enumerate paths therefore it is especially useful\nfor very large k values. It is based on the Valued-Sum-of-Product (VSOP) tool,\nwhich is an extension of Zero-suppressed Binary Decision Diagrams (ZBDDs). We\nassessed the performance of this algorithm with a DAG model of a path-intensive\ncombinational circuit, viz. c6288, that has \\sim10^{20} paths. We found that it\ntook about 64 minutes to compute all paths in this DAG along with their\nlengths.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 07:25:14 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Kocan", "Fatih", ""]]}, {"id": "1301.0583", "submitter": "Omid Madani", "authors": "Omid Madani", "title": "Polynomial Value Iteration Algorithms for Detrerminstic MDPs", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-311-318", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value iteration is a commonly used and empirically competitive method in\nsolving many Markov decision process problems. However, it is known that value\niteration has only pseudo-polynomial complexity in general. We establish a\nsomewhat surprising polynomial bound for value iteration on deterministic\nMarkov decision (DMDP) problems. We show that the basic value iteration\nprocedure converges to the highest average reward cycle on a DMDP problem in\nheta(n^2) iterations, or heta(mn^2) total time, where n denotes the number of\nstates, and m the number of edges. We give two extensions of value iteration\nthat solve the DMDP in heta(mn) time. We explore the analysis of policy\niteration algorithms and report on an empirical study of value iteration\nshowing that its convergence is much faster on random sparse graphs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:15 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Madani", "Omid", ""]]}, {"id": "1301.0587", "submitter": "Ramgopal Mettu", "authors": "Ramgopal Mettu, Greg Plaxton", "title": "Optimal Time Bounds for Approximate Clustering", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-344-351", "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental problem in unsupervised learning, and has been\nstudied widely both as a problem of learning mixture models and as an\noptimization problem. In this paper, we study clustering with respect the\nemph{k-median} objective function, a natural formulation of clustering in which\nwe attempt to minimize the average distance to cluster centers. One of the main\ncontributions of this paper is a simple but powerful sampling technique that we\ncall emph{successive sampling} that could be of independent interest. We show\nthat our sampling procedure can rapidly identify a small set of points (of size\njust O(klog{n/k})) that summarize the input points for the purpose of\nclustering. Using successive sampling, we develop an algorithm for the k-median\nproblem that runs in O(nk) time for a wide range of values of k and is\nguaranteed, with high probability, to return a solution with cost at most a\nconstant factor times optimal. We also establish a lower bound of Omega(nk) on\nany randomized constant-factor approximation algorithm for the k-median problem\nthat succeeds with even a negligible (say 1/100) probability. Thus we establish\na tight time bound of Theta(nk) for the k-median problem for a wide range of\nvalues of k. The best previous upper bound for the problem was O(nk), where the\nO-notation hides polylogarithmic factors in n and k. The best previous lower\nbound of O(nk) applied only to deterministic k-median algorithms. While we\nfocus our presentation on the k-median objective, all our upper bounds are\nvalid for the k-means objective as well. In this context our algorithm compares\nfavorably to the widely used k-means heuristic, which requires O(nk) time for\njust one iteration and provides no useful approximation guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:31 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Mettu", "Ramgopal", ""], ["Plaxton", "Greg", ""]]}, {"id": "1301.0722", "submitter": "Stefan Gerdjikov", "authors": "Stefan Gerdjikov, Stoyan Mihov, Petar Mitankin, Klaus U. Schulz", "title": "Good parts first - a new algorithm for approximate search in lexica and\n  string databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new efficient method for approximate search in electronic\nlexica. Given an input string (the pattern) and a similarity threshold, the\nalgorithm retrieves all entries of the lexicon that are sufficiently similar to\nthe pattern. Search is organized in subsearches that always start with an exact\npartial match where a substring of the input pattern is aligned with a\nsubstring of a lexicon word. Afterwards this partial match is extended stepwise\nto larger substrings. For aligning further parts of the pattern with\ncorresponding parts of lexicon entries, more errors are tolerated at each\nsubsequent step. For supporting this alignment order, which may start at any\npart of the pattern, the lexicon is represented as a structure that enables\nimmediate access to any substring of a lexicon word and permits the extension\nof such substrings in both directions. Experimental evaluations of the\napproximate search procedure are given that show significant efficiency\nimprovements compared to existing techniques. Since the technique can be used\nfor large error bounds it offers interesting possibilities for approximate\nsearch in special collections of \"long\" strings, such as phrases, sentences, or\nbook ti\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 13:45:35 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 10:53:17 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Gerdjikov", "Stefan", ""], ["Mihov", "Stoyan", ""], ["Mitankin", "Petar", ""], ["Schulz", "Klaus U.", ""]]}, {"id": "1301.0745", "submitter": "Hongyu Liang", "authors": "Danny Z. Chen and Jian Li and Hongyu Liang and Haitao Wang", "title": "Matroid and Knapsack Center Problems", "comments": "A preliminary version of this paper is accepted to IPCO 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classic $k$-center problem, we are given a metric graph, and the\nobjective is to open $k$ nodes as centers such that the maximum distance from\nany vertex to its closest center is minimized. In this paper, we consider two\nimportant generalizations of $k$-center, the matroid center problem and the\nknapsack center problem. Both problems are motivated by recent content\ndistribution network applications. Our contributions can be summarized as\nfollows:\n  1. We consider the matroid center problem in which the centers are required\nto form an independent set of a given matroid. We show this problem is NP-hard\neven on a line. We present a 3-approximation algorithm for the problem on\ngeneral metrics. We also consider the outlier version of the problem where a\ngiven number of vertices can be excluded as the outliers from the solution. We\npresent a 7-approximation for the outlier version.\n  2. We consider the (multi-)knapsack center problem in which the centers are\nrequired to satisfy one (or more) knapsack constraint(s). It is known that the\nknapsack center problem with a single knapsack constraint admits a\n3-approximation. However, when there are at least two knapsack constraints, we\nshow this problem is not approximable at all. To complement the hardness\nresult, we present a polynomial time algorithm that gives a 3-approximate\nsolution such that one knapsack constraint is satisfied and the others may be\nviolated by at most a factor of $1+\\epsilon$. We also obtain a 3-approximation\nfor the outlier version that may violate the knapsack constraint by\n$1+\\epsilon$.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 15:17:06 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2013 19:32:31 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Chen", "Danny Z.", ""], ["Li", "Jian", ""], ["Liang", "Hongyu", ""], ["Wang", "Haitao", ""]]}, {"id": "1301.0763", "submitter": "Lorenzo Pasquini", "authors": "Lorenzo Pasquini", "title": "Improved QFT algorithm for power-of-two FFT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that it is possible to improve the computational cost, the\nmemory requirements and the accuracy of Quick Fourier Transform (QFT) algorithm\nfor power-of-two FFT (Fast Fourier Transform) just introducing a slight\nmodification in this algorithm. The new algorithm requires the same number of\nadditions and multiplications of split-radix 3add/3mul, one of the most\nappreciated FFT algorithms appeared in the literature, but employing only half\nof the trigonometric constants. These results can elevate the QFT approach to\nthe level of most used FFT procedures. A new quite general way to describe FFT\nalgorithms, based on signal types and on a particular notation, is also\nproposed and used, highligting its advantages.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 16:25:56 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Pasquini", "Lorenzo", ""]]}, {"id": "1301.0793", "submitter": "Benjmain Moseley", "authors": "Benjamin Moseley, Kirk Pruhs, and Cliff Stein", "title": "The Complexity of Scheduling for p-norms of Flow and Stretch", "comments": "Conference version accepted to IPCO 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider computing optimal k-norm preemptive schedules of jobs that arrive\nover time. In particular, we show that computing the optimal k-norm of flow\nschedule, is strongly NP-hard for k in (0, 1) and integers k in (1, infinity).\nFurther we show that computing the optimal k-norm of stretch schedule, is\nstrongly NP-hard for k in (0, 1) and integers k in (1, infinity).\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 18:24:40 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Moseley", "Benjamin", ""], ["Pruhs", "Kirk", ""], ["Stein", "Cliff", ""]]}, {"id": "1301.0820", "submitter": "Raghu Meka", "authors": "Adam Klivans and Raghu Meka", "title": "Moment-Matching Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new framework for proving the existence of low-degree, polynomial\napproximators for Boolean functions with respect to broad classes of\nnon-product distributions. Our proofs use techniques related to the classical\nmoment problem and deviate significantly from known Fourier-based methods,\nwhich require the underlying distribution to have some product structure.\n  Our main application is the first polynomial-time algorithm for agnostically\nlearning any function of a constant number of halfspaces with respect to any\nlog-concave distribution (for any constant accuracy parameter). This result was\nnot known even for the case of learning the intersection of two halfspaces\nwithout noise. Additionally, we show that in the \"smoothed-analysis\" setting,\nthe above results hold with respect to distributions that have sub-exponential\ntails, a property satisfied by many natural and well-studied distributions in\nmachine learning.\n  Given that our algorithms can be implemented using Support Vector Machines\n(SVMs) with a polynomial kernel, these results give a rigorous theoretical\nexplanation as to why many kernel methods work so well in practice.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 20:43:46 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Klivans", "Adam", ""], ["Meka", "Raghu", ""]]}, {"id": "1301.0834", "submitter": "Fahad Saeed", "authors": "Fahad Saeed and Trairak Pisitkun and Mark A. Knepper and Jason D.\n  Hoffert", "title": "An Efficient Algorithm for Clustering of Large-Scale Mass Spectrometry\n  Data", "comments": "4 pages, 4 figures, Bioinformatics and Biomedicine (BIBM), 2012 IEEE\n  International Conference on", "journal-ref": "IEEE Proceedings publications 2012", "doi": "10.1109/BIBM.2012.6392738", "report-no": null, "categories": "cs.DS q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-throughput spectrometers are capable of producing data sets containing\nthousands of spectra for a single biological sample. These data sets contain a\nsubstantial amount of redundancy from peptides that may get selected multiple\ntimes in a LC-MS/MS experiment. In this paper, we present an efficient\nalgorithm, CAMS (Clustering Algorithm for Mass Spectra) for clustering mass\nspectrometry data which increases both the sensitivity and confidence of\nspectral assignment. CAMS utilizes a novel metric, called F-set, that allows\naccurate identification of the spectra that are similar. A graph theoretic\nframework is defined that allows the use of F-set metric efficiently for\naccurate cluster identifications. The accuracy of the algorithm is tested on\nreal HCD and CID data sets with varying amounts of peptides. Our experiments\nshow that the proposed algorithm is able to cluster spectra with very high\naccuracy in a reasonable amount of time for large spectral data sets. Thus, the\nalgorithm is able to decrease the computational time by compressing the data\nsets while increasing the throughput of the data by interpreting low S/N\nspectra.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 21:09:18 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Saeed", "Fahad", ""], ["Pisitkun", "Trairak", ""], ["Knepper", "Mark A.", ""], ["Hoffert", "Jason D.", ""]]}, {"id": "1301.0902", "submitter": "Meghana Nasre Ms.", "authors": "Meghana Nasre", "title": "Popular Matchings -- structure and cheating strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the cheating strategies for the popular matchings problem. The\npopular matchings problem can be defined as follows: Let G = (A U P, E) be a\nbipartite graph where A denotes a set of agents, P denotes a set of posts and\nthe edges in E are ranked. Each agent ranks a subset of posts in an order of\npreference, possibly involving ties. A matching M is popular if there exists no\nmatching M' such that the number of agents that prefer M' to M exceeds the\nnumber of agents that prefer M to M'. Consider a centralized market where\nagents submit their preferences and a central authority matches agents to posts\naccording to the notion of popularity. Since a popular matching need not be\nunique, we assume that the central authority chooses an arbitrary popular\nmatching. Let a1 be the sole manipulative agent who is aware of the true\npreference lists of all other agents. The goal of a1 is to falsify her\npreference list to get better always, that is, to improve the set of posts that\nshe gets matched to as opposed to what she got when she was truthful. We show\nthat the optimal cheating strategy for a single agent to get better always can\nbe computed in O(\\sqrt{n}m) time when preference lists are allowed to contain\nties and in O(m+n) time when preference lists are all strict. Here n = |A| +\n|P| and m = |E|.\n  To compute the cheating strategies, we develop a switching graph\ncharacterization of the popular matchings problem involving ties. The switching\ngraph characterization was studied for the case of strict lists by McDermid and\nIrving (J. Comb. Optim. 2011) and it was open for the case of ties. The\nswitching graph characterization for the case of ties is of independent\ninterest and answers a part of the open questions posed by McDermid and Irving.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2013 13:24:58 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Nasre", "Meghana", ""]]}, {"id": "1301.0955", "submitter": "Erwan Le Martelot", "authors": "Erwan Le Martelot and Chris Hankin", "title": "Fast Multi-Scale Community Detection based on Local Criteria within a\n  Multi-Threaded Algorithm", "comments": "arXiv admin note: text overlap with arXiv:1204.1002", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many systems can be described using graphs, or networks. Detecting\ncommunities in these networks can provide information about the underlying\nstructure and functioning of the original systems. Yet this detection is a\ncomplex task and a large amount of work was dedicated to it in the past decade.\nOne important feature is that communities can be found at several scales, or\nlevels of resolution, indicating several levels of organisations. Therefore\nsolutions to the community structure may not be unique. Also networks tend to\nbe large and hence require efficient processing. In this work, we present a new\nalgorithm for the fast detection of communities across scales using a local\ncriterion. We exploit the local aspect of the criterion to enable parallel\ncomputation and improve the algorithm's efficiency further. The algorithm is\ntested against large generated multi-scale networks and experiments demonstrate\nits efficiency and accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2013 23:44:55 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2013 16:42:21 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Martelot", "Erwan Le", ""], ["Hankin", "Chris", ""]]}, {"id": "1301.0977", "submitter": "Hilmi Yildirim", "authors": "Hilmi Yildirim, Vineet Chaoji and Mohammed J. Zaki", "title": "DAGGER: A Scalable Index for Reachability Queries in Large Dynamic\n  Graphs", "comments": "11 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ubiquity of large-scale graph data in a variety of application\ndomains, querying them effectively is a challenge. In particular, reachability\nqueries are becoming increasingly important, especially for containment,\nsubsumption, and connectivity checks. Whereas many methods have been proposed\nfor static graph reachability, many real-world graphs are constantly evolving,\nwhich calls for dynamic indexing. In this paper, we present a fully dynamic\nreachability index over dynamic graphs. Our method, called DAGGER, is a\nlight-weight index based on interval labeling, that scales to million node\ngraphs and beyond. Our extensive experimental evaluation on real-world and\nsynthetic graphs confirms its effectiveness over baseline methods.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2013 06:12:42 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Yildirim", "Hilmi", ""], ["Chaoji", "Vineet", ""], ["Zaki", "Mohammed J.", ""]]}, {"id": "1301.0995", "submitter": "Hongyu Liang", "authors": "Hongyu Liang and Tiancheng Lou and Haisheng Tan and Yuexuan Wang and\n  Dongxiao Yu", "title": "On the Complexity of Connectivity in Cognitive Radio Networks Through\n  Spectrum Assignment", "comments": "A preliminary version of this paper appeared in ALGOSENSORS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive Radio Networks (CRNs) are considered as a promising solution to the\nspectrum shortage problem in wireless communication. In this paper, we initiate\nthe first systematic study on the algorithmic complexity of the connectivity\nproblem in CRNs through spectrum assignments. We model the network of secondary\nusers (SUs) as a potential graph, where two nodes having an edge between them\nare connected as long as they choose a common available channel. In the general\ncase, where the potential graph is arbitrary and the SUs may have different\nnumber of antennae, we prove that it is NP-complete to determine whether the\nnetwork is connectable even if there are only two channels. For the special\ncase where the number of channels is constant and all the SUs have the same\nnumber of antennae, which is more than one but less than the number of\nchannels, the problem is also NP-complete. For the special cases in which the\npotential graph is complete, a tree, or a graph with bounded treewidth, we\nprove the problem is NP-complete and fixed-parameter tractable (FPT) when\nparameterized by the number of channels. Exact algorithms are also derived to\ndetermine the connectability of a given cognitive radio network.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2013 11:44:35 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Liang", "Hongyu", ""], ["Lou", "Tiancheng", ""], ["Tan", "Haisheng", ""], ["Wang", "Yuexuan", ""], ["Yu", "Dongxiao", ""]]}, {"id": "1301.1218", "submitter": "Matteo Riondato", "authors": "Matteo Riondato and Fabio Vandin", "title": "Finding the True Frequent Itemsets", "comments": "13 pages, Extended version of work appeared in SIAM International\n  Conference on Data Mining, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequent Itemsets (FIs) mining is a fundamental primitive in data mining. It\nrequires to identify all itemsets appearing in at least a fraction $\\theta$ of\na transactional dataset $\\mathcal{D}$. Often though, the ultimate goal of\nmining $\\mathcal{D}$ is not an analysis of the dataset \\emph{per se}, but the\nunderstanding of the underlying process that generated it. Specifically, in\nmany applications $\\mathcal{D}$ is a collection of samples obtained from an\nunknown probability distribution $\\pi$ on transactions, and by extracting the\nFIs in $\\mathcal{D}$ one attempts to infer itemsets that are frequently (i.e.,\nwith probability at least $\\theta$) generated by $\\pi$, which we call the True\nFrequent Itemsets (TFIs). Due to the inherently stochastic nature of the\ngenerative process, the set of FIs is only a rough approximation of the set of\nTFIs, as it often contains a huge number of \\emph{false positives}, i.e.,\nspurious itemsets that are not among the TFIs. In this work we design and\nanalyze an algorithm to identify a threshold $\\hat{\\theta}$ such that the\ncollection of itemsets with frequency at least $\\hat{\\theta}$ in $\\mathcal{D}$\ncontains only TFIs with probability at least $1-\\delta$, for some\nuser-specified $\\delta$. Our method uses results from statistical learning\ntheory involving the (empirical) VC-dimension of the problem at hand. This\nallows us to identify almost all the TFIs without including any false positive.\nWe also experimentally compare our method with the direct mining of\n$\\mathcal{D}$ at frequency $\\theta$ and with techniques based on widely-used\nstandard bounds (i.e., the Chernoff bounds) of the binomial distribution, and\nshow that our algorithm outperforms these methods and achieves even better\nresults than what is guaranteed by the theoretical analysis.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 15:04:43 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2013 12:54:12 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2014 16:38:44 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Riondato", "Matteo", ""], ["Vandin", "Fabio", ""]]}, {"id": "1301.1517", "submitter": "Magnus Wahlstr\\\"om", "authors": "Magnus Wahlstr\\\"om", "title": "Abusing the Tutte Matrix: An Algebraic Instance Compression for the\n  K-set-cycle Problem", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algebraic, determinant-based algorithm for the K-Cycle problem,\ni.e., the problem of finding a cycle through a set of specified elements. Our\napproach gives a simple FPT algorithm for the problem, matching the\n$O^*(2^{|K|})$ running time of the algorithm of Bj\\\"orklund et al. (SODA,\n2012). Furthermore, our approach is open for treatment by classical algebraic\ntools (e.g., Gaussian elimination), and we show that it leads to a polynomial\ncompression of the problem, i.e., a polynomial-time reduction of the $K$-Cycle\nproblem into an algebraic problem with coding size $O(|K|^3)$. This is\nsurprising, as several related problems (e.g., k-Cycle and the Disjoint Paths\nproblem) are known not to admit such a reduction unless the polynomial\nhierarchy collapses. Furthermore, despite the result, we are not aware of any\nwitness for the K-Cycle problem of size polynomial in $|K|+\\log n$, which seems\n(for now) to separate the notions of polynomial compression and polynomial\nkernelization (as a polynomial kernelization for a problem in NP necessarily\nimplies a small witness).\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 12:48:52 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Wahlstr\u00f6m", "Magnus", ""]]}, {"id": "1301.1547", "submitter": "Bruno Bauwens", "authors": "Bruno Bauwens, Anton Makhlin, Nikolay Vereshchagin, Marius Zimand", "title": "Short lists with short programs in short time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a machine $U$, a $c$-short program for $x$ is a string $p$ such that\n$U(p)=x$ and the length of $p$ is bounded by $c$ + (the length of a shortest\nprogram for $x$). We show that for any standard Turing machine, it is possible\nto compute in polynomial time on input $x$ a list of polynomial size guaranteed\nto contain a O$(\\log |x|)$-short program for $x$. We also show that there\nexists a computable function that maps every $x$ to a list of size $|x|^2$\ncontaining a O$(1)$-short program for $x$. This is essentially optimal because\nwe prove that for each such function there is a $c$ and infinitely many $x$ for\nwhich the list has size at least $c|x|^2$. Finally we show that for some\nstandard machines, computable functions generating lists with $0$-short\nprograms, must have infinitely often list sizes proportional to $2^{|x|}$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 14:41:49 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2013 11:45:29 GMT"}, {"version": "v3", "created": "Thu, 30 Mar 2017 15:33:31 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Bauwens", "Bruno", ""], ["Makhlin", "Anton", ""], ["Vereshchagin", "Nikolay", ""], ["Zimand", "Marius", ""]]}, {"id": "1301.1751", "submitter": "Hongyu Liang", "authors": "Hongyu Liang and Hao Yuan", "title": "On the Complexity of $t$-Closeness Anonymization and Related Problems", "comments": "An extended abstract to appear in DASFAA 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important issue in releasing individual data is to protect the sensitive\ninformation from being leaked and maliciously utilized. Famous privacy\npreserving principles that aim to ensure both data privacy and data integrity,\nsuch as $k$-anonymity and $l$-diversity, have been extensively studied both\ntheoretically and empirically. Nonetheless, these widely-adopted principles are\nstill insufficient to prevent attribute disclosure if the attacker has partial\nknowledge about the overall sensitive data distribution. The $t$-closeness\nprinciple has been proposed to fix this, which also has the benefit of\nsupporting numerical sensitive attributes. However, in contrast to\n$k$-anonymity and $l$-diversity, the theoretical aspect of $t$-closeness has\nnot been well investigated.\n  We initiate the first systematic theoretical study on the $t$-closeness\nprinciple under the commonly-used attribute suppression model. We prove that\nfor every constant $t$ such that $0\\leq t<1$, it is NP-hard to find an optimal\n$t$-closeness generalization of a given table. The proof consists of several\nreductions each of which works for different values of $t$, which together\ncover the full range. To complement this negative result, we also provide exact\nand fixed-parameter algorithms. Finally, we answer some open questions\nregarding the complexity of $k$-anonymity and $l$-diversity left in the\nliterature.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 04:34:03 GMT"}], "update_date": "2013-01-10", "authors_parsed": [["Liang", "Hongyu", ""], ["Yuan", "Hao", ""]]}, {"id": "1301.1999", "submitter": "Marek Cygan", "authors": "Marek Cygan and Fabrizio Grandoni and Telikepalli Kavitha", "title": "On Pairwise Spanners", "comments": "Full version of STACS 2013 paper; 13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected $n$-node unweighted graph $G = (V, E)$, a spanner with\nstretch function $f(\\cdot)$ is a subgraph $H\\subseteq G$ such that, if two\nnodes are at distance $d$ in $G$, then they are at distance at most $f(d)$ in\n$H$. Spanners are very well studied in the literature. The typical goal is to\nconstruct the sparsest possible spanner for a given stretch function.\n  In this paper we study pairwise spanners, where we require to approximate the\n$u$-$v$ distance only for pairs $(u,v)$ in a given set $\\cP \\subseteq V\\times\nV$. Such $\\cP$-spanners were studied before [Coppersmith,Elkin'05] only in the\nspecial case that $f(\\cdot)$ is the identity function, i.e. distances between\nrelevant pairs must be preserved exactly (a.k.a. pairwise preservers).\n  Here we present pairwise spanners which are at the same time sparser than the\nbest known preservers (on the same $\\cP$) and of the best known spanners (with\nthe same $f(\\cdot)$). In more detail, for arbitrary $\\cP$, we show that there\nexists a $\\mathcal{P}$-spanner of size $O(n(|\\cP|\\log n)^{1/4})$ with\n$f(d)=d+4\\log n$. Alternatively, for any $\\eps>0$, there exists a $\\cP$-spanner\nof size $O(n|\\cP|^{1/4}\\sqrt{\\frac{\\log n}{\\eps}})$ with $f(d)=(1+\\eps)d+4$. We\nalso consider the relevant special case that there is a critical set of nodes\n$S\\subseteq V$, and we wish to approximate either the distances within nodes in\n$S$ or from nodes in $S$ to any other node. We show that there exists an\n$(S\\times S)$-spanner of size $O(n\\sqrt{|S|})$ with $f(d)=d+2$, and an\n$(S\\times V)$-spanner of size $O(n\\sqrt{|S|\\log n})$ with $f(d)=d+2\\log n$. All\nthe mentioned pairwise spanners can be constructed in polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 22:30:04 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Cygan", "Marek", ""], ["Grandoni", "Fabrizio", ""], ["Kavitha", "Telikepalli", ""]]}, {"id": "1301.2046", "submitter": "A. Emre Cetin", "authors": "A. Emre Cetin", "title": "In-situ associative permuting", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The technique of in-situ associative permuting is introduced which is an\nassociation of in-situ permuting and in-situ inverting. It is suitable for\nassociatively permutable permutations of {1,2,...,n} where the elements that\nwill be inverted are negative and stored in order relative to each other\naccording to their absolute values.\n  Let K[1...n] be an array of n integer keys each in the range [1,n], and it is\nallowed to modify the keys in the range [-n,n]. If the integer keys are\nrearranged such that one of each distinct key having the value i is moved to\nthe i'th position of K, then the resulting arrangement (will be denoted by K^P)\ncan be transformed in-situ into associatively permutable permutation pi^P using\nonly logn additional bits. The associatively permutable permutation pi^P not\nonly stores the ranks of the keys of K^P but also uniquely represents K^P.\nRestoring the keys from pi^P is not considered. However, in-situ associative\npermuting pi^P in O(n) time using logn additional bits rearranges the elements\nof pi^P in order, as well as lets to restore the keys of K^P in O(n) further\ntime using the inverses of the negative ranks. This means that an array of n\ninteger keys each in the range [1,n] can be sorted using only logn bits of\nadditional space.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 08:08:48 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Cetin", "A. Emre", ""]]}, {"id": "1301.2253", "submitter": "Eyal Amir", "authors": "Eyal Amir", "title": "Efficient Approximation for Triangulation of Minimum Treewidth", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-7-15", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present four novel approximation algorithms for finding triangulation of\nminimum treewidth. Two of the algorithms improve on the running times of\nalgorithms by Robertson and Seymour, and Becker and Geiger that approximate the\noptimum by factors of 4 and 3 2/3, respectively. A third algorithm is faster\nthan those but gives an approximation factor of 4 1/2. The last algorithm is\nyet faster, producing factor-O(lg/k) approximations in polynomial time. Finding\ntriangulations of minimum treewidth for graphs is central to many problems in\ncomputer science. Real-world problems in artificial intelligence, VLSI design\nand databases are efficiently solvable if we have an efficient approximation\nalgorithm for them. We report on experimental results confirming the\neffectiveness of our algorithms for large graphs associated with real-world\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:23 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Amir", "Eyal", ""]]}, {"id": "1301.2256", "submitter": "Hans L. Bodlaender", "authors": "Hans L. Bodlaender, Arie M.C.A. Koster, Frank van den Eijkhof, Linda\n  C. van der Gaag", "title": "Pre-processing for Triangulation of Probabilistic Networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-32-39", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The currently most efficient algorithm for inference with a probabilistic\nnetwork builds upon a triangulation of a network's graph. In this paper, we\nshow that pre-processing can help in finding good triangulations\nforprobabilistic networks, that is, triangulations with a minimal maximum\nclique size. We provide a set of rules for stepwise reducing a graph, without\nlosing optimality. This reduction allows us to solve the triangulation problem\non a smaller graph. From the smaller graph's triangulation, a triangulation of\nthe original graph is obtained by reversing the reduction steps. Our\nexperimental results show that the graphs of some well-known real-life\nprobabilistic networks can be triangulated optimally just by preprocessing; for\nother networks, huge reductions in their graph's size are obtained.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:22:36 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Koster", "Arie M. C. A.", ""], ["Eijkhof", "Frank van den", ""], ["van der Gaag", "Linda C.", ""]]}, {"id": "1301.2267", "submitter": "Amol Deshpande", "authors": "Amol Deshpande, Minos Garofalakis, Michael I. Jordan", "title": "Efficient Stepwise Selection in Decomposable Models", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-128-135", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an efficient way of performing stepwise selection\nin the class of decomposable models. The main contribution of the paper is a\nsimple characterization of the edges that canbe added to a decomposable model\nwhile keeping the resulting model decomposable and an efficient algorithm for\nenumerating all such edges for a given model in essentially O(1) time per edge.\nWe also discuss how backward selection can be performed efficiently using our\ndata structures.We also analyze the complexity of the complete stepwise\nselection procedure, including the complexity of choosing which of the eligible\ndges to add to (or delete from) the current model, with the aim ofminimizing\nthe Kullback-Leibler distance of the resulting model from the saturated model\nfor the data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:22 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Deshpande", "Amol", ""], ["Garofalakis", "Minos", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.2277", "submitter": "Milos Hauskrecht", "authors": "Milos Hauskrecht, Eli Upfal", "title": "A Clustering Approach to Solving Large Stochastic Matching Problems", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-219-226", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we focus on efficient heuristics for solving a class of\nstochastic planning problems that arise in a variety of business, investment,\nand industrial applications. The problem is best described in terms of future\nbuy and sell contracts. By buying less reliable, but less expensive, buy\n(supply) contracts, a company or a trader can cover a position of more reliable\nand more expensive sell contracts. The goal is to maximize the expected net\ngain (profit) by constructing a dose to optimum portfolio out of the available\nbuy and sell contracts. This stochastic planning problem can be formulated as a\ntwo-stage stochastic linear programming problem with recourse. However, this\nformalization leads to solutions that are exponential in the number of possible\nfailure combinations. Thus, this approach is not feasible for large scale\nproblems. In this work we investigate heuristic approximation techniques\nalleviating the efficiency problem. We primarily focus on the clustering\napproach and devise heuristics for finding clusterings leading to good\napproximations. We illustrate the quality and feasibility of the approach\nthrough experimental data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:06 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Hauskrecht", "Milos", ""], ["Upfal", "Eli", ""]]}, {"id": "1301.2342", "submitter": "Jingjin Yu", "authors": "Jingjin Yu", "title": "A Linear Time Algorithm for the Feasibility of Pebble Motion on Graphs", "comments": "Added reference to an earlier linear result on pebble motion on\n  graphs by Goraly and Hassin", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a connected, undirected, simple graph $G = (V, E)$ and $p \\le |V|$\npebbles labeled $1,..., p$, a configuration of these $p$ pebbles is an\ninjective map assigning the pebbles to vertices of $G$. Let $S$ and $D$ be two\nsuch configurations. From a configuration, pebbles can move on $G$ as follows:\nIn each step, at most one pebble may move from the vertex it currently occupies\nto an adjacent unoccupied vertex, yielding a new configuration. A natural\nquestion in this setting is the following: Is configuration $D$ reachable from\n$S$ and if so, how? We show that the feasibility of this problem can be decided\nin time $O(|V| + |E|)$.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 21:53:51 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2013 05:48:45 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Yu", "Jingjin", ""]]}, {"id": "1301.2390", "submitter": "Shashank Mehta", "authors": "Shashank K Mehta and Pawan Aurora", "title": "Completely Positive formulation of the Graph Isomorphism Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two graphs $G_1$ and $G_2$ on $n$ vertices each, we define a graph $G$\non vertex set $V_1\\times V_2$ and the edge set as the union of edges of\n$G_1\\times \\bar{G_2}$, $\\bar{G_1}\\times G_2$, $\\{(v,u'),(v,u\"))(|u',u\"\\in\nV_2\\}$ for each $v\\in V_1$, and $\\{((u',v),(u\",v))|u',u\"\\in V_1\\}$ for each\n$v\\in V_2$. We consider the completely-positive Lov\\'asz $\\vartheta$ function,\ni.e., $cp\\vartheta$ function for $G$. We show that the function evaluates to\n$n$ whenever $G_1$ and $G_2$ are isomorphic and to less than $n-1/(4n^4)$ when\nnon-isomorphic. Hence this function provides a test for graph isomorphism. We\nalso provide some geometric insight into the feasible region of the completely\npositive program.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 05:30:45 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Mehta", "Shashank K", ""], ["Aurora", "Pawan", ""]]}, {"id": "1301.2495", "submitter": "Reut Levi", "authors": "Akashnil Dutta, Reut Levi, Dana Ron, Ronitt Rubinfeld", "title": "A simple online competitive adaptation of Lempel-Ziv compression with\n  efficient random access support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple adaptation of the Lempel Ziv 78' (LZ78) compression\nscheme ({\\em IEEE Transactions on Information Theory, 1978}) that supports\nefficient random access to the input string. Namely, given query access to the\ncompressed string, it is possible to efficiently recover any symbol of the\ninput string. The compression algorithm is given as input a parameter $\\eps\n>0$, and with very high probability increases the length of the compressed\nstring by at most a factor of $(1+\\eps)$. The access time is $O(\\log n +\n1/\\eps^2)$ in expectation, and $O(\\log n/\\eps^2)$ with high probability. The\nscheme relies on sparse transitive-closure spanners. Any (consecutive)\nsubstring of the input string can be retrieved at an additional additive cost\nin the running time of the length of the substring. We also formally establish\nthe necessity of modifying LZ78 so as to allow efficient random access.\nSpecifically, we construct a family of strings for which $\\Omega(n/\\log n)$\nqueries to the LZ78-compressed string are required in order to recover a single\nsymbol in the input string. The main benefit of the proposed scheme is that it\npreserves the online nature and simplicity of LZ78, and that for {\\em every}\ninput string, the length of the compressed string is only a small factor larger\nthan that obtained by running LZ78.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 13:44:27 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Dutta", "Akashnil", ""], ["Levi", "Reut", ""], ["Ron", "Dana", ""], ["Rubinfeld", "Ronitt", ""]]}, {"id": "1301.2506", "submitter": "Yngve Villanger", "authors": "Jan Arne Telle and Yngve Villanger", "title": "Connecting Terminals and 2-Disjoint Connected Subgraphs", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G=(V,E)$ and a set of terminal vertices $T$ we say that a\nsuperset $S$ of $T$ is $T$-connecting if $S$ induces a connected graph, and $S$\nis minimal if no strict subset of $S$ is $T$-connecting. In this paper we prove\nthat there are at most ${|V \\setminus T| \\choose |T|-2} \\cdot 3^{\\frac{|V\n\\setminus T|}{3}}$ minimal $T$-connecting sets when $|T| \\leq n/3$ and that\nthese can be enumerated within a polynomial factor of this bound. This\ngeneralizes the algorithm for enumerating all induced paths between a pair of\nvertices, corresponding to the case $|T|=2$. We apply our enumeration algorithm\nto solve the {\\sc 2-Disjoint Connected Subgraphs} problem in time\n$O^*(1.7804^n)$, improving on the recent $O^*(1.933^n)$ algorithm of Cygan et\nal. 2012 LATIN paper.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 14:27:13 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Telle", "Jan Arne", ""], ["Villanger", "Yngve", ""]]}, {"id": "1301.2626", "submitter": "Damien Woods", "authors": "Damien Woods, Ho-Lin Chen, Scott Goodfriend, Nadine Dabby, Erik\n  Winfree, Peng Yin", "title": "Active Self-Assembly of Algorithmic Shapes and Patterns in\n  Polylogarithmic Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a computational model for studying the complexity of\nself-assembled structures with active molecular components. Our model captures\nnotions of growth and movement ubiquitous in biological systems. The model is\ninspired by biology's fantastic ability to assemble biomolecules that form\nsystems with complicated structure and dynamics, from molecular motors that\nwalk on rigid tracks and proteins that dynamically alter the structure of the\ncell during mitosis, to embryonic development where large-scale complicated\norganisms efficiently grow from a single cell. Using this active self-assembly\nmodel, we show how to efficiently self-assemble shapes and patterns from simple\nmonomers. For example, we show how to grow a line of monomers in time and\nnumber of monomer states that is merely logarithmic in the length of the line.\n  Our main results show how to grow arbitrary connected two-dimensional\ngeometric shapes and patterns in expected time that is polylogarithmic in the\nsize of the shape, plus roughly the time required to run a Turing machine\ndeciding whether or not a given pixel is in the shape. We do this while keeping\nthe number of monomer types logarithmic in shape size, plus those monomers\nrequired by the Kolmogorov complexity of the shape or pattern. This work thus\nhighlights the efficiency advantages of active self-assembly over passive\nself-assembly and motivates experimental effort to construct general-purpose\nactive molecular self-assembly systems.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 23:01:15 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Woods", "Damien", ""], ["Chen", "Ho-Lin", ""], ["Goodfriend", "Scott", ""], ["Dabby", "Nadine", ""], ["Winfree", "Erik", ""], ["Yin", "Peng", ""]]}, {"id": "1301.2707", "submitter": "Sou-Cheng Choi", "authors": "Sou-Cheng T. Choi and Michael A. Saunders", "title": "ALGORITHM 937: MINRES-QLP for Singular Symmetric and Hermitian Linear\n  Equations and Least-Squares Problems", "comments": "14 pages and 1 figure", "journal-ref": null, "doi": "10.1145/2527267", "report-no": null, "categories": "cs.MS cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe algorithm MINRES-QLP and its FORTRAN 90 implementation for\nsolving symmetric or Hermitian linear systems or least-squares problems. If the\nsystem is singular, MINRES-QLP computes the unique minimum-length solution\n(also known as the pseudoinverse solution), which generally eludes MINRES. In\nall cases, it overcomes a potential instability in the original MINRES\nalgorithm. A positive-definite preconditioner may be supplied. Our FORTRAN 90\nimplementation illustrates a design pattern that allows users to make problem\ndata known to the solver but hidden and secure from other program units. In\nparticular, we circumvent the need for reverse communication. While we focus\nhere on a FORTRAN 90 implementation, we also provide and maintain MATLAB\nversions of MINRES and MINRES-QLP.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 19:00:15 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2015 00:44:56 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Choi", "Sou-Cheng T.", ""], ["Saunders", "Michael A.", ""]]}, {"id": "1301.2734", "submitter": "Fabio D'Andreagiovanni", "authors": "Christina B\\\"using and Fabio D'Andreagiovanni", "title": "Robust Optimization under Multi-band Uncertainty - Part I: Theory", "comments": "Modifications w.r.t. version 1: Section 4 revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical single-band uncertainty model introduced by Bertsimas and Sim\nhas represented a breakthrough in the development of tractable robust\ncounterparts of Linear Programs. However, adopting a single deviation band may\nbe too limitative in practice: in many real-world problems, observed deviations\nindeed present asymmetric distributions over asymmetric ranges, so that getting\na higher modeling resolution by partitioning the band into multiple sub-bands\nis advisable. The critical aim of our work is to close the knowledge gap on the\nadoption of multi-band uncertainty in Robust Optimization: a general definition\nand intensive theoretical study of a multi-band model are actually still\nmissing. Our new developments have been also strongly inspired and encouraged\nby our industrial partners, interested in getting a better modeling of\narbitrary shaped distributions, built on historical data about the uncertainty\naffecting the considered real-world problems.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 23:26:30 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2013 12:16:02 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2013 11:28:43 GMT"}], "update_date": "2013-03-15", "authors_parsed": [["B\u00fcsing", "Christina", ""], ["D'Andreagiovanni", "Fabio", ""]]}, {"id": "1301.2875", "submitter": "Alexandre Maurer", "authors": "Alexandre Maurer (LIP6, LINCS), S\\'ebastien Tixeuil (LIP6, LINCS, IUF)", "title": "On Byzantine Broadcast in Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reliably broadcasting information in a multihop\nasynchronous network in the presence of Byzantine failures: some nodes may\nexhibit unpredictable malicious behavior. We focus on completely decentralized\nsolutions. Few Byzantine-robust algorithms exist for loosely connected\nnetworks. A recent solution guarantees reliable broadcast on a torus when D >\n4, D being the minimal distance between two Byzantine nodes. In this paper, we\ngeneralize this result to 4-connected planar graphs. We show that reliable\nbroadcast can be guaranteed when D > Z, Z being the maximal number of edges per\npolygon. We also show that this bound on D is a lower bound for this class of\ngraphs. Our solution has the same time complexity as a simple broadcast. This\nis also the first solution where the memory required increases linearly\n(instead of exponentially) with the size of transmitted information. Important\ndisclaimer: these results have NOT yet been published in an international\nconference or journal. This is just a technical report presenting intermediary\nand incomplete results. A generalized version of these results may be under\nsubmission.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 07:44:22 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2013 07:35:36 GMT"}, {"version": "v3", "created": "Sat, 9 Feb 2013 11:14:16 GMT"}, {"version": "v4", "created": "Sat, 7 Dec 2013 19:12:38 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Maurer", "Alexandre", "", "LIP6, LINCS"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, LINCS, IUF"]]}, {"id": "1301.3093", "submitter": "Dmitriy Nuriyev", "authors": "Dmitriy Nuriyev", "title": "A DP Approach to Hamiltonian Path Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Dynamic Programming based polynomial worst case time and space algorithm is\ndescribed for computing Hamiltonian Path of a directed graph. Complexity\nconstructive proofs along with a tested C++ implementation are provided as\nwell. The result is obtained via the use of original colored hypergraph\nstructures in order to maintain and update the necessary DP states.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 18:46:00 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2013 15:44:57 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Nuriyev", "Dmitriy", ""]]}, {"id": "1301.3210", "submitter": "Mehdi Saeedi", "authors": "Igor L. Markov, Mehdi Saeedi", "title": "Faster Quantum Number Factoring via Circuit Synthesis", "comments": "4 pages, 2 figures, 1 table", "journal-ref": "Phys. Rev. A, 87: 012310 (2013)", "doi": "10.1103/PhysRevA.87.012310", "report-no": null, "categories": "quant-ph cs.DS cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major obstacle to implementing Shor's quantum number-factoring algorithm is\nthe large size of modular-exponentiation circuits. We reduce this bottleneck by\ncustomizing reversible circuits for modular multiplication to individual runs\nof Shor's algorithm. Our circuit-synthesis procedure exploits spectral\nproperties of multiplication operators and constructs optimized circuits from\nthe traces of the execution of an appropriate GCD algorithm. Empirically, gate\ncounts are reduced by 4-5 times, and circuit latency is reduced by larger\nfactors.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 03:15:21 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Markov", "Igor L.", ""], ["Saeedi", "Mehdi", ""]]}, {"id": "1301.3252", "submitter": "Mong-Jen Kao", "authors": "Mong-Jen Kao, Der-Tsai Lee, and Dorothea Wagner", "title": "Approximating Metrics by Tree Metrics of Small Distance-Weighted Average\n  Stretch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of how well a tree metric is able to preserve the sum of\npairwise distances of an arbitrary metric. This problem is closely related to\nlow-stretch metric embeddings and is interesting by its own flavor from the\nline of research proposed in the literature.\n  As the structure of a tree imposes great constraints on the pairwise\ndistances, any embedding of a metric into a tree metric is known to have\nmaximum pairwise stretch of $\\Omega(\\log n)$. We show, however, from the\nperspective of average performance, there exist tree metrics which preserve the\nsum of pairwise distances of the given metric up to a small constant factor,\nfor which we also show to be no worse than twice what we can possibly expect.\nThe approach we use to tackle this problem is more direct compared to a\nprevious result of [4], and also leads to a provably better guarantee. Second,\nwhen the given metric is extracted from a Euclidean point set of finite\ndimension $d$, we show that there exist spanning trees of the given point set\nsuch that the sum of pairwise distances is preserved up to a constant which\ndepends only on $d$. Both of our proofs are constructive. The main ingredient\nin our result is a special point-set decomposition which relates two\nseemingly-unrelated quantities.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 07:52:43 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Kao", "Mong-Jen", ""], ["Lee", "Der-Tsai", ""], ["Wagner", "Dorothea", ""]]}, {"id": "1301.3388", "submitter": "Olle Liljenzin", "authors": "Olle Liljenzin", "title": "Confluently Persistent Sets and Maps", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordered sets and maps play important roles as index structures in relational\ndata models. When a shared index in a multi-user system is modified\nconcurrently, the current state of the index will diverge into multiple\nversions containing the local modifications performed in each work flow. The\nconfluent persistence problem arises when versions should be melded in commit\nand refresh operations so that modifications performed by different users\nbecome merged.\n  Confluently Persistent Sets and Maps are functional binary search trees that\nsupport efficient set operations both when operands are disjoint and when they\nare overlapping. Treap properties with hash values as priorities are maintained\nand with hash-consing of nodes a unique representation is provided.\nNon-destructive set merge algorithms that skip inspection of equal subtrees and\na conflict detecting meld algorithm based on set merges are presented. The meld\nalgorithm is used in commit and refresh operations. With m modifications in one\nflow and n items in total, the expected cost of the operations is O(m\nlog(n/m)).\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 12:49:13 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Liljenzin", "Olle", ""]]}, {"id": "1301.3402", "submitter": "Jason Crampton", "authors": "Jason Crampton and Gregory Gutin", "title": "Constraint Expressions and Workflow Satisfiability", "comments": "arXiv admin note: text overlap with arXiv:1205.0852; to appear in\n  Proceedings of SACMAT 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A workflow specification defines a set of steps and the order in which those\nsteps must be executed. Security requirements and business rules may impose\nconstraints on which users are permitted to perform those steps. A workflow\nspecification is said to be satisfiable if there exists an assignment of\nauthorized users to workflow steps that satisfies all the constraints. An\nalgorithm for determining whether such an assignment exists is important, both\nas a static analysis tool for workflow specifications, and for the construction\nof run-time reference monitors for workflow management systems. We develop new\nmethods for determining workflow satisfiability based on the concept of\nconstraint expressions, which were introduced recently by Khan and Fong. These\nmethods are surprising versatile, enabling us to develop algorithms for, and\ndetermine the complexity of, a number of different problems related to workflow\nsatisfiability.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2013 13:56:40 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2013 08:14:34 GMT"}], "update_date": "2013-03-14", "authors_parsed": [["Crampton", "Jason", ""], ["Gutin", "Gregory", ""]]}, {"id": "1301.3451", "submitter": "Fanghu Dong", "authors": "Fanghu Dong", "title": "Eigenstructure of Maximum Likelihood from Counts Data", "comments": "The current article contains premature results which is refined in\n  another published articles. I want to withdraw it in order to reduce the\n  confusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DS math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MLE (Maximum Likelihood Estimate) for a multinomial model is proportional\nto the data. We call such estimate an eigenestimate and the relationship of it\nto the data as the eigenstructure. When the multinomial model is generalized to\ndeal with data arise from incomplete or censored categorical counts, we would\nnaturally look for this eigenstructure between MLE and data. The paper finds\nthe algebraic representation of the eigenstructure (put as Eqn (2.1)), with\nwhich the intuition is visualized geometrically (Figures 2.2 and 4.3) and\nelaborated in a theory (Section 4). The eigenestimate constructed from the\neigenstructure must be a stationary point of the likelihood, a result proved in\nTheorem 4.42. On the bridge between the algebraic definition of Eqn (2.1) and\nthe Proof of Theorem 4.42, we have exploited an elementary inequality (Lemma\n3.1) that governs the primitive cases, defined the thick objects of fragment\nand slice which can be assembled like mechanical parts (Definition 4.1), proved\na few intermediary results that help build up the intuition (Section 4),\nconjectured the universal existence of an eigenestimate (Conjecture 4.32),\nestablished a criterion for boundary regularity (Criterion 4.37), and paved way\n(the Trivial Slicing Algorithm (TSA)) for the derivation of the Weaver\nalgorithms (Section 5) that finds the eigenestimate by using it to reconstruct\nthe observed counts through the eigenstructure, the reconstruction is iterative\nbut derivative-free and matrix-inversion-free. As new addition to the current\nbody of algorithmic methods, the Weaver algorithms craftily tighten threads\nthat are weaved on a rectangular grid (Figure 2.3), and is one incarnation of\nthe TSA. Finally, we put our method in the context of some existing methods\n(Section 6). Softwares are pseudocoded and put online. Visit\nhttp://hku.hk/jdong/eigenstruct2013a.html for demonstrations and download.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 18:50:42 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2015 13:27:06 GMT"}, {"version": "v3", "created": "Mon, 1 Jan 2018 03:46:45 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Dong", "Fanghu", ""]]}, {"id": "1301.3471", "submitter": "Fatemeh Rajabi-Alni", "authors": "Fatemeh Rajabi-Alni, Alireza Bagheri", "title": "Embedding a balanced binary tree on a bounded point set", "comments": "21 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected planar graph G with n vertices and a set S of n points\ninside a simple polygon P, a point-set embedding of G on S is a planar drawing\nof G such that each vertex is mapped to a distinct point of S and the edges are\npolygonal chains surrounded by P. A special case of the embedding problem is\nthat in which G is a balanced binary tree. In this paper, we present a new\nalgorithm for embedding an n-vertex balanced binary tree BBT on a set S of n\npoints bounded by a simple m-gon P in O(m^2 + n(log n)^2 + mn) time with at\nmost O(m) bends per edge.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 20:06:36 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2013 02:44:31 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Rajabi-Alni", "Fatemeh", ""], ["Bagheri", "Alireza", ""]]}, {"id": "1301.3482", "submitter": "Fatemeh Rajabi-Alni", "authors": "Fatemeh Rajabi-Alni, Alireza Bagheri", "title": "Many to Many Matching with Demands and Capacities", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let A and B be two finite sets of points with total cardinality n, the many\nto many point matching with demands and capacities matches each point ai in A\nto at least alpha'i and at most alphai points in B, and each point bj in B to\nat least betaj and at most beta'j points in A for all 1 <= i <= s and 1 <= j <=\nt. In this paper, we present an upper bound for this problem using our new\npolynomial time algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 20:43:38 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Rajabi-Alni", "Fatemeh", ""], ["Bagheri", "Alireza", ""]]}, {"id": "1301.3488", "submitter": "Mathieu Raffinot", "authors": "Djamal Belazzougui, Roman Kolpakov, Mathieu Raffinot", "title": "Various improvements to text fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let s = s_1 .. s_n be a text (or sequence) on a finite alphabet \\Sigma of\nsize \\sigma. A fingerprint in s is the set of distinct characters appearing in\none of its substrings. The problem considered here is to compute the set {\\cal\nF} of all fingerprints of all substrings of s in order to answer efficiently\ncertain questions on this set. A substring s_i .. s_j is a maximal location for\na fingerprint f in F (denoted by <i,j>) if the alphabet of s_i .. s_j is f and\ns_{i-1}, s_{j+1}, if defined, are not in f. The set of maximal locations ins is\n{\\cal L} (it is easy to see that |{\\cal L}| \\leq n \\sigma). Two maximal\nlocations <i,j> and <k,l> such that s_i .. s_j = s_k .. s_l are named {\\em\ncopies}, and the quotient set of {\\cal L} according to the copy relation is\ndenoted by {\\cal L}_C. We present new exact and approximate efficient\nalgorithms and data structures for the following three problems: (1) to compute\n{\\cal F}; (2) given f as a set of distinct characters in \\Sigma, to answer if f\nrepresents a fingerprint in {\\cal F}; (3) given f, to find all maximal\nlocations of f in s.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 20:59:43 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Belazzougui", "Djamal", ""], ["Kolpakov", "Roman", ""], ["Raffinot", "Mathieu", ""]]}, {"id": "1301.3509", "submitter": "Vahideh Manshadi", "authors": "Itai Ashlagi and Patrick Jaillet and Vahideh H. Manshadi", "title": "Kidney Exchange in Dynamic Sparse Heterogenous Pools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current kidney exchange pools are of moderate size and thin, as they consist\nof many highly sensitized patients. Creating a thicker pool can be done by\nwaiting for many pairs to arrive. We analyze a simple class of matching\nalgorithms that search periodically for allocations. We find that if only 2-way\ncycles are conducted, in order to gain a significant amount of matches over the\nonline scenario (matching each time a new incompatible pair joins the pool) the\nwaiting period should be \"very long\". If 3-way cycles are also allowed we find\nregimes in which waiting for a short period also increases the number of\nmatches considerably. Finally, a significant increase of matches can be\nobtained by using even one non-simultaneous chain while still matching in an\nonline fashion. Our theoretical findings and data-driven computational\nexperiments lead to policy recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 21:51:58 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2013 14:11:47 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Ashlagi", "Itai", ""], ["Jaillet", "Patrick", ""], ["Manshadi", "Vahideh H.", ""]]}, {"id": "1301.3771", "submitter": "Shinnosuke Seki", "authors": "Shinnosuke Seki", "title": "Combinatorial Optimization in Pattern Assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern self-assembly tile set synthesis (PATS) is a combinatorial\noptimization problem which aim at minimizing a rectilinear tile assembly system\n(RTAS) that uniquely self-assembles a given rectangular pattern, and is known\nto be NP-hard. PATS gets practically meaningful when it is parameterized by a\nconstant c such that any given pattern is guaranteed to contain at most c\ncolors (c-PATS). We first investigate simple patterns and properties of minimum\nRTASs for them. Then based on them, we design a 59-colored pattern to which\n3SAT is reduced, and prove that 59-PATS is NP-hard.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 18:02:07 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Seki", "Shinnosuke", ""]]}, {"id": "1301.3780", "submitter": "Joshua Brakensiek", "authors": "Joshua Brakensiek and Aaron Potechin", "title": "Bounds on the Size of Sound Monotone Switching Networks Accepting\n  Permutation Sets of Directed Trees", "comments": "32 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove almost tight bounds on the size of sound monotone\nswitching networks accepting permutations sets of directed trees. This roughly\ncorresponds to proving almost tight bounds bounds on the monotone memory\nefficiency of the directed ST-connectivity problem for the special case in\nwhich the input graph is guaranteed to have no path from s to t or be\nisomorphic to a specific directed tree.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 18:11:40 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Brakensiek", "Joshua", ""], ["Potechin", "Aaron", ""]]}, {"id": "1301.3871", "submitter": "Pedro Larra\\~naga", "authors": "Pedro Larra\\~naga, Ramon Etxeberria, Jose A. Lozano, Jose M. Pena", "title": "Combinatorial Optimization by Learning and Simulation of Bayesian\n  Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-343-352", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how the Bayesian network paradigm can be used in order to\nsolve combinatorial optimization problems. To do it some methods of structure\nlearning from data and simulation of Bayesian networks are inserted inside\nEstimation of Distribution Algorithms (EDA). EDA are a new tool for\nevolutionary computation in which populations of individuals are created by\nestimation and simulation of the joint probability distribution of the selected\nindividuals. We propose new approaches to EDA for combinatorial optimization\nbased on the theory of probabilistic graphical models. Experimental results are\nalso presented.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:14 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Larra\u00f1aga", "Pedro", ""], ["Etxeberria", "Ramon", ""], ["Lozano", "Jose A.", ""], ["Pena", "Jose M.", ""]]}, {"id": "1301.3877", "submitter": "Andrew Moore", "authors": "Andrew Moore", "title": "The Anchors Hierachy: Using the triangle inequality to survive high\n  dimensional data", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-397-405", "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about metric data structures in high-dimensional or\nnon-Euclidean space that permit cached sufficient statistics accelerations of\nlearning algorithms.\n  It has recently been shown that for less than about 10 dimensions, decorating\nkd-trees with additional \"cached sufficient statistics\" such as first and\nsecond moments and contingency tables can provide satisfying acceleration for a\nvery wide range of statistical learning tasks such as kernel regression,\nlocally weighted regression, k-means clustering, mixture modeling and Bayes Net\nlearning.\n  In this paper, we begin by defining the anchors hierarchy - a fast data\nstructure and algorithm for localizing data based only on a\ntriangle-inequality-obeying distance metric. We show how this, in its own\nright, gives a fast and effective clustering of data. But more importantly we\nshow how it can produce a well-balanced structure similar to a Ball-Tree\n(Omohundro, 1991) or a kind of metric tree (Uhlmann, 1991; Ciaccia, Patella, &\nZezula, 1997) in a way that is neither \"top-down\" nor \"bottom-up\" but instead\n\"middle-out\". We then show how this structure, decorated with cached sufficient\nstatistics, allows a wide variety of statistical learning algorithms to be\naccelerated even in thousands of dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:38 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Moore", "Andrew", ""]]}, {"id": "1301.3946", "submitter": "Hoyt Koepke", "authors": "Hoyt Koepke and Elizabeth Thompson", "title": "Efficient Identification of Equivalences in Dynamic Graphs and Pedigree\n  Structures", "comments": "Code for paper available at\n  http://www.stat.washington.edu/~hoytak/code/hashreduce", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.QM stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for designing test and query functions for complex\nstructures that vary across a given parameter such as genetic marker position.\nThe operations we are interested in include equality testing, set operations,\nisolating unique states, duplication counting, or finding equivalence classes\nunder identifiability constraints. A motivating application is locating\nequivalence classes in identity-by-descent (IBD) graphs, graph structures in\npedigree analysis that change over genetic marker location. The nodes of these\ngraphs are unlabeled and identified only by their connecting edges, a\nconstraint easily handled by our approach. The general framework introduced is\npowerful enough to build a range of testing functions for IBD graphs, dynamic\npopulations, and other structures using a minimal set of operations. The\ntheoretical and algorithmic properties of our approach are analyzed and proved.\nComputational results on several simulations demonstrate the effectiveness of\nour approach.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 23:11:14 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2013 21:41:35 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2013 21:15:43 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Koepke", "Hoyt", ""], ["Thompson", "Elizabeth", ""]]}, {"id": "1301.3996", "submitter": "Alexandre Maurer", "authors": "Alexandre Maurer (LIP6, LINCS), S\\'ebastien Tixeuil (LIP6, LINCS, IUF)", "title": "Parameterizable Byzantine Broadcast in Loosely Connected Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reliably broadcasting information in a multihop\nasynchronous network, despite the presence of Byzantine failures: some nodes\nare malicious and behave arbitrarly. We focus on non-cryptographic solutions.\nMost existing approaches give conditions for perfect reliable broadcast (all\ncorrect nodes deliver the good information), but require a highly connected\nnetwork. A probabilistic approach was recently proposed for loosely connected\nnetworks: the Byzantine failures are randomly distributed, and the correct\nnodes deliver the good information with high probability. A first solution\nrequire the nodes to initially know their position on the network, which may be\ndifficult or impossible in self-organizing or dynamic networks. A second\nsolution relaxed this hypothesis but has much weaker Byzantine tolerance\nguarantees. In this paper, we propose a parameterizable broadcast protocol that\ndoes not require nodes to have any knowledge about the network. We give a\ndeterministic technique to compute a set of nodes that always deliver authentic\ninformation, for a given set of Byzantine failures. Then, we use this technique\nto experimentally evaluate our protocol, and show that it significantely\noutperforms previous solutions with the same hypotheses. Important disclaimer:\nthese results have NOT yet been published in an international conference or\njournal. This is just a technical report presenting intermediary and incomplete\nresults. A generalized version of these results may be under submission.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 07:09:15 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2013 07:36:54 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Maurer", "Alexandre", "", "LIP6, LINCS"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, LINCS, IUF"]]}, {"id": "1301.4010", "submitter": "Thomas Rothvoss", "authors": "Thomas Rothvoss", "title": "Approximating Bin Packing within O(log OPT * log log OPT) bins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For bin packing, the input consists of n items with sizes s_1,...,s_n in\n[0,1] which have to be assigned to a minimum number of bins of size 1. The\nseminal Karmarkar-Karp algorithm from '82 produces a solution with at most OPT\n+ O(log^2 OPT) bins.\n  We provide the first improvement in now 3 decades and show that one can find\na solution of cost OPT + O(log OPT * log log OPT) in polynomial time. This is\nachieved by rounding a fractional solution to the Gilmore-Gomory LP relaxation\nusing the Entropy Method from discrepancy theory. The result is constructive\nvia algorithms of Bansal and Lovett-Meka.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 08:49:14 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2013 23:51:21 GMT"}, {"version": "v3", "created": "Mon, 10 Mar 2014 19:10:25 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Rothvoss", "Thomas", ""]]}, {"id": "1301.4096", "submitter": "Anton Eremeev", "authors": "Benjamin Doerr, Anton Eremeev, Frank Neumann, Madeleine Theile,\n  Christian Thyssen", "title": "Evolutionary Algorithms and Dynamic Programming", "comments": "This is an updated version of journal publication where few misprints\n  are fixed", "journal-ref": "Theoretical Computer Science, Vol. 412, Issue 43, 2011,\n  P.6020-6035", "doi": "10.1016/j.tcs.2011.07.024", "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been proven that evolutionary algorithms produce good\nresults for a wide range of combinatorial optimization problems. Some of the\nconsidered problems are tackled by evolutionary algorithms that use a\nrepresentation which enables them to construct solutions in a dynamic\nprogramming fashion. We take a general approach and relate the construction of\nsuch algorithms to the development of algorithms using dynamic programming\ntechniques. Thereby, we give general guidelines on how to develop evolutionary\nalgorithms that have the additional ability of carrying out dynamic programming\nsteps. Finally, we show that for a wide class of the so-called DP-benevolent\nproblems (which are known to admit FPTAS) there exists a fully polynomial-time\nrandomized approximation scheme based on an evolutionary algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 13:50:25 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Doerr", "Benjamin", ""], ["Eremeev", "Anton", ""], ["Neumann", "Frank", ""], ["Theile", "Madeleine", ""], ["Thyssen", "Christian", ""]]}, {"id": "1301.4131", "submitter": "Xibo Jin", "authors": "Xibo Jin, Fa Zhang, Ying Song, Liya Fan and Zhiyong Liu", "title": "Energy-Efficient Scheduling with Time and Processors Eligibility\n  Restrictions", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While previous work on energy-efficient algorithms focused on assumption that\ntasks can be assigned to any processor, we initially study the problem of task\nscheduling on restricted parallel processors. The objective is to minimize the\noverall energy consumption while speed scaling (SS) method is used to reduce\nenergy consumption under the execution time constraint (Makespan $C_{max}$). In\nthis work, we discuss the speed setting in the continuous model that processors\ncan run at arbitrary speed in $[s_{min},s_{max}]$. The energy-efficient\nscheduling problem, involving task assignment and speed scaling, is inherently\ncomplicated as it is proved to be NP-Complete. We formulate the problem as an\nInteger Programming (IP) problem. Specifically, we devise a polynomial time\noptimal scheduling algorithm for the case tasks have a uniform size. Our\nalgorithm runs in $O(mn^3logn)$ time, where $m$ is the number of processors and\n$n$ is the number of tasks. We then present a polynomial time algorithm that\nachieves an approximation factor of $2^{\\alpha-1}(2-\\frac{1}{m^{\\alpha}})$\n($\\alpha$ is the power parameter) when the tasks have arbitrary size work.\nExperimental results demonstrate that our algorithm could provide an efficient\nscheduling for the problem of task scheduling on restricted parallel\nprocessors.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 15:48:55 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2013 01:56:35 GMT"}, {"version": "v3", "created": "Sat, 14 Sep 2013 09:10:53 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Jin", "Xibo", ""], ["Zhang", "Fa", ""], ["Song", "Ying", ""], ["Fan", "Liya", ""], ["Liu", "Zhiyong", ""]]}, {"id": "1301.4478", "submitter": "Chaitanya Swamy", "authors": "Sara Ahmadian, Zachary Friggstad, and Chaitanya Swamy", "title": "Local-Search based Approximation Algorithms for Mobile Facility Location\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the {\\em mobile facility location} (\\mfl) problem. We are given a\nset of facilities and clients located in a common metric space. The goal is to\nmove each facility from its initial location to a destination and assign each\nclient to the destination of some facility so as to minimize the sum of the\nmovement-costs of the facilities and the client-assignment costs. This\nabstracts facility-location settings where one has the flexibility of moving\nfacilities from their current locations to other destinations so as to serve\nclients more efficiently by reducing their assignment costs.\n  We give the first {\\em local-search based} approximation algorithm for this\nproblem and achieve the best-known approximation guarantee. Our main result is\n$(3+\\epsilon)$-approximation for this problem for any constant $\\epsilon>0$\nusing local search. The previous best guarantee was an 8-approximation\nalgorithm based on LP-rounding. Our guarantee {\\em matches} the best-known\napproximation guarantee for the $k$-median problem. Since there is an\napproximation-preserving reduction from the $k$-median problem to \\mfl, any\nimprovement of our result would imply an analogous improvement for the\n$k$-median problem. Furthermore, {\\em our analysis is tight} (up to $o(1)$\nfactors) since the tight example for the local-search based 3-approximation\nalgorithm for $k$-median can be easily adapted to show that our local-search\nalgorithm has a tight approximation ratio of 3. One of the chief novelties of\nthe analysis is that in order to generate a suitable collection of local-search\nmoves whose resulting inequalities yield the desired bound on the cost of a\nlocal-optimum, we define a tree-like structure that (loosely speaking)\nfunctions as a \"recursion tree\", using which we spawn off local-search moves by\nexploring this tree to a constant depth.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 20:05:12 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["Ahmadian", "Sara", ""], ["Friggstad", "Zachary", ""], ["Swamy", "Chaitanya", ""]]}, {"id": "1301.4529", "submitter": "Andrew Mastin", "authors": "Andrew Mastin, Patrick Jaillet", "title": "Average-Case Performance of Rollout Algorithms for Knapsack Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rollout algorithms have demonstrated excellent performance on a variety of\ndynamic and discrete optimization problems. Interpreted as an approximate\ndynamic programming algorithm, a rollout algorithm estimates the value-to-go at\neach decision stage by simulating future events while following a greedy\npolicy, referred to as the base policy. While in many cases rollout algorithms\nare guaranteed to perform as well as their base policies, there have been few\ntheoretical results showing additional improvement in performance. In this\npaper we perform a probabilistic analysis of the subset sum problem and\nknapsack problem, giving theoretical evidence that rollout algorithms perform\nstrictly better than their base policies. Using a stochastic model from the\nexisting literature, we analyze two rollout methods that we refer to as the\nconsecutive rollout and exhaustive rollout, both of which employ a simple\ngreedy base policy. For the subset sum problem, we prove that after only a\nsingle iteration of the rollout algorithm, both methods yield at least a 30%\nreduction in the expected gap between the solution value and capacity, relative\nto the base policy. Analogous results are shown for the knapsack problem.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2013 03:58:34 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2013 23:51:31 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2013 19:09:09 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Mastin", "Andrew", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1301.4728", "submitter": "Charl Ras", "authors": "Marcus Brazil, Charl Ras, Doreen Thomas", "title": "Relay Augmentation for Lifetime Extension of Wireless Sensor Networks", "comments": null, "journal-ref": "IET Wireless Sensor Systems. 3:145-152. 2013", "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel relay augmentation strategy for extending the lifetime of\na certain class of wireless sensor networks. In this class sensors are located\nat fixed and pre-determined positions and all communication takes place via\nmulti-hop paths in a fixed routing tree rooted at the base station. It is\nassumed that no accumulation of data takes place along the communication paths\nand that there is no restriction on where additional relays may be located.\nUnder these assumptions the optimal extension of network lifetime is modelled\nas the Euclidean $k$-bottleneck Steiner tree problem. Only two approximation\nalgorithms for this NP-hard problem exist in the literature: a minimum spanning\ntree heuristic (MSTH) with performance ratio 2, and a probabilistic 3-regular\nhypergraph heuristic (3RHH) with performance ratio $\\sqrt{3}+\\epsilon$. We\npresent a new iterative heuristic that incorporates MSTH and show via\nsimulation that our algorithm performs better than MSTH in extending lifetime,\nand outperforms 3RHH in terms of efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 02:05:49 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Brazil", "Marcus", ""], ["Ras", "Charl", ""], ["Thomas", "Doreen", ""]]}, {"id": "1301.4769", "submitter": "Claudio Gentile", "authors": "Nicolo Cesa-Bianchi, Claudio Gentile, Fabio Vitale, Giovanni Zappella", "title": "A Correlation Clustering Approach to Link Classification in Signed\n  Networks -- Full Version --", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by social balance theory, we develop a theory of link\nclassification in signed networks using the correlation clustering index as\nmeasure of label regularity. We derive learning bounds in terms of correlation\nclustering within three fundamental transductive learning settings: online,\nbatch and active. Our main algorithmic contribution is in the active setting,\nwhere we introduce a new family of efficient link classifiers based on covering\nthe input graph with small circuits. These are the first active algorithms for\nlink classification with mistake bounds that hold for arbitrary signed\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 07:28:44 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2013 17:44:24 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Cesa-Bianchi", "Nicolo", ""], ["Gentile", "Claudio", ""], ["Vitale", "Fabio", ""], ["Zappella", "Giovanni", ""]]}, {"id": "1301.4952", "submitter": "Djamal Belazzougui", "authors": "Djamal Belazzougui, Adeline Pierrot, Mathieu Raffinot, St\\'ephane\n  Vialette", "title": "Single and multiple consecutive permutation motif search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $t$ be a permutation (that shall play the role of the {\\em text}) on\n$[n]$ and a pattern $p$ be a sequence of $m$ distinct integer(s) of $[n]$,\n$m\\leq n$. The pattern $p$ occurs in $t$ in position $i$ if and only if $p_1...\np_m$ is order-isomorphic to $t_i... t_{i+m-1}$, that is, for all $1 \\leq k<\n\\ell \\leq m$, $p_k>p_\\ell$ if and only if $t_{i+k-1}>t_{i+\\ell-1}$. Searching\nfor a pattern $p$ in a text $t$ consists in identifying all occurrences of $p$\nin $t$. We first present a forward automaton which allows us to search for $p$\nin $t$ in $O(m^2\\log \\log m +n)$ time. We then introduce a Morris-Pratt\nautomaton representation of the forward automaton which allows us to reduce\nthis complexity to $O(m\\log \\log m +n)$ at the price of an additional amortized\nconstant term by integer of the text. Both automata occupy $O(m)$ space. We\nthen extend the problem to search for a set of patterns and exhibit a specific\nAho-Corasick like algorithm. Next we present a sub-linear average case search\nalgorithm running in $O(\\frac{m\\log m}{\\log\\log m}+\\frac{n\\log m}{m\\log\\log\nm})$ time, that we eventually prove to be optimal on average.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 18:33:06 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2013 20:00:55 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Belazzougui", "Djamal", ""], ["Pierrot", "Adeline", ""], ["Raffinot", "Mathieu", ""], ["Vialette", "St\u00e9phane", ""]]}, {"id": "1301.5070", "submitter": "Longkun Guo l", "authors": "Longkun Guo, Hong Shen and Kewen Liao", "title": "Improved Approximation Algorithms for Computing k Disjoint Paths Subject\n  to Two Constraints", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given graph $G$ with positive integral cost and delay on edges,\ndistinct vertices $s$ and $t$, cost bound $C\\in Z^{+}$ and delay bound $D\\in\nZ^{+}$, the $k$ bi-constraint path ($k$BCP) problem is to compute $k$ disjoint\n$st$-paths subject to $C$ and $D$. This problem is known NP-hard, even when\n$k=1$ \\cite{garey1979computers}. This paper first gives a simple approximation\nalgorithm with factor-$(2,2)$, i.e. the algorithm computes a solution with\ndelay and cost bounded by $2*D$ and $2*C$ respectively. Later, a novel improved\napproximation algorithm with ratio\n$(1+\\beta,\\,\\max\\{2,\\,1+\\ln\\frac{1}{\\beta}\\})$ is developed by constructing\ninteresting auxiliary graphs and employing the cycle cancellation method. As a\nconsequence, we can obtain a factor-$(1.369,\\,2)$ approximation algorithm by\nsetting $1+\\ln\\frac{1}{\\beta}=2$ and a factor-$(1.567,\\,1.567)$ algorithm by\nsetting $1+\\beta=1+\\ln\\frac{1}{\\beta}$. Besides, by setting $\\beta=0$, an\napproximation algorithm with ratio $(1,\\, O(\\ln n))$, i.e. an algorithm with\nonly a single factor ratio $O(\\ln n)$ on cost, can be immediately obtained. To\nthe best of our knowledge, this is the first non-trivial approximation\nalgorithm for the $k$BCP problem that strictly obeys the delay constraint.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 04:52:06 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2013 13:24:04 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Guo", "Longkun", ""], ["Shen", "Hong", ""], ["Liao", "Kewen", ""]]}, {"id": "1301.5293", "submitter": "Jonathan Sorenson", "authors": "Eric Bach, Jonathan Sorenson", "title": "Approximately counting semismooth integers", "comments": "To appear in ISSAC 2013, Boston MA", "journal-ref": null, "doi": "10.1145/2465506.2465933", "report-no": null, "categories": "cs.DS math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An integer $n$ is $(y,z)$-semismooth if $n=pm$ where $m$ is an integer with\nall prime divisors $\\le y$ and $p$ is 1 or a prime $\\le z$. arge quantities of\nsemismooth integers are utilized in modern integer factoring algorithms, such\nas the number field sieve, that incorporate the so-called large prime variant.\nThus, it is useful for factoring practitioners to be able to estimate the value\nof $\\Psi(x,y,z)$, the number of $(y,z)$-semismooth integers up to $x$, so that\nthey can better set algorithm parameters and minimize running times, which\ncould be weeks or months on a cluster supercomputer. In this paper, we explore\nseveral algorithms to approximate $\\Psi(x,y,z)$ using a generalization of\nBuchstab's identity with numeric integration.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 19:44:57 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2013 16:51:25 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Bach", "Eric", ""], ["Sorenson", "Jonathan", ""]]}, {"id": "1301.5468", "submitter": "Sebastiano Vigna", "authors": "Sebastiano Vigna", "title": "Broadword Implementation of Parenthesis Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue the line of research started in \"Broadword Implementation of\nRank/Select Queries\" proposing broadword (a.k.a. SWAR, \"SIMD Within A\nRegister\") algorithms for finding matching closed parentheses and the k-th far\nclosed parenthesis. Our algorithms work in time O(log w) on a word of w bits,\nand contain no branch and no test instruction. On 64-bit (and wider)\narchitectures, these algorithms make it possible to avoid costly tabulations,\nwhile providing a very significant speedup with respect to for-loop\nimplementations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 11:15:11 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2013 09:46:13 GMT"}], "update_date": "2013-01-25", "authors_parsed": [["Vigna", "Sebastiano", ""]]}, {"id": "1301.5584", "submitter": "Shayan Oveis Gharan", "authors": "Tsz Chiu Kwok and Lap Chi Lau and Yin Tat Lee and Shayan Oveis Gharan\n  and Luca Trevisan", "title": "Improved Cheeger's Inequality: Analysis of Spectral Partitioning\n  Algorithms through Higher Order Spectral Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let \\phi(G) be the minimum conductance of an undirected graph G, and let\n0=\\lambda_1 <= \\lambda_2 <=... <= \\lambda_n <= 2 be the eigenvalues of the\nnormalized Laplacian matrix of G. We prove that for any graph G and any k >= 2,\n  \\phi(G) = O(k) \\lambda_2 / \\sqrt{\\lambda_k}, and this performance guarantee\nis achieved by the spectral partitioning algorithm. This improves Cheeger's\ninequality, and the bound is optimal up to a constant factor for any k. Our\nresult shows that the spectral partitioning algorithm is a constant factor\napproximation algorithm for finding a sparse cut if \\lambda_k$ is a constant\nfor some constant k. This provides some theoretical justification to its\nempirical performance in image segmentation and clustering problems. We extend\nthe analysis to other graph partitioning problems, including multi-way\npartition, balanced separator, and maximum cut.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 17:49:05 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Kwok", "Tsz Chiu", ""], ["Lau", "Lap Chi", ""], ["Lee", "Yin Tat", ""], ["Gharan", "Shayan Oveis", ""], ["Trevisan", "Luca", ""]]}, {"id": "1301.5842", "submitter": "Artur Je\\.z", "authors": "Artur Je\\.z", "title": "Approximation of grammar-based compression via recompression", "comments": "22 pages, some many small improvements, to be submited to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a simple linear-time algorithm constructing a\ncontext-free grammar of size O(g log(N/g)) for the input string, where N is the\nsize of the input string and g the size of the optimal grammar generating this\nstring. The algorithm works for arbitrary size alphabets, but the running time\nis linear assuming that the alphabet \\Sigma of the input string can be\nidentified with numbers from {1, ..., N^c} for some constant c. Otherwise,\nadditional cost of O(n log|\\Sigma|) is needed.\n  Algorithms with such approximation guarantees and running time are known, the\nnovelty of this paper is a particular simplicity of the algorithm as well as\nthe analysis of the algorithm, which uses a general technique of recompression\nrecently introduced by the author. Furthermore, contrary to the previous\nresults, this work does not use the LZ representation of the input string in\nthe construction, nor in the analysis.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 17:03:41 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2013 14:27:45 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2013 09:42:13 GMT"}], "update_date": "2013-11-08", "authors_parsed": [["Je\u017c", "Artur", ""]]}, {"id": "1301.5844", "submitter": "Paul Goldberg", "authors": "Leslie Ann Goldberg, Paul W. Goldberg, Piotr Krysta and Carmine Ventre", "title": "Ranking Games that have Competitiveness-based Strategies", "comments": "21 pages; preliminary version in ACM-EC 2010; accepted for\n  publication in Theoretical Computer Science", "journal-ref": "TCS 476 24-37 (2013)", "doi": "10.1016/j.tcs.2013.01.013", "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extensive literature in economics and social science addresses contests,\nin which players compete to outperform each other on some measurable criterion,\noften referred to as a player's score, or output. Players incur costs that are\nan increasing function of score, but receive prizes for obtaining higher score\nthan their competitors. In this paper we study finite games that are\ndiscretized contests, and the problems of computing exact and approximate Nash\nequilibria. Our motivation is the worst-case hardness of Nash equilibrium\ncomputation, and the resulting interest in important classes of games that\nadmit polynomial-time algorithms. For games that have a tie-breaking rule for\nplayers' scores, we present a polynomial-time algorithm for computing an exact\nequilibrium in the 2-player case, and for multiple players, a characterization\nof Nash equilibria that shows an interesting parallel between these games and\nunrestricted 2-player games in normal form. When ties are allowed, via a\nreduction from these games to a subclass of anonymous games, we give\napproximation schemes for two special cases: constant-sized set of strategies,\nand constant number of players.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 17:08:45 GMT"}], "update_date": "2013-08-01", "authors_parsed": [["Goldberg", "Leslie Ann", ""], ["Goldberg", "Paul W.", ""], ["Krysta", "Piotr", ""], ["Ventre", "Carmine", ""]]}, {"id": "1301.5896", "submitter": "Ioannis Katsikarelis", "authors": "Ioannis Katsikarelis", "title": "Computing bounded-width tree and branch decompositions of k-outerplanar\n  graphs", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By a well known result the treewidth of k-outerplanar graphs is at most 3k-1.\nThis paper gives, besides a rigorous proof of this fact, an algorithmic\nimplementation of the proof, i.e. it is shown that, given a k-outerplanar graph\nG, a tree decomposition of G of width at most 3k-1 can be found in O(kn) time\nand space. Similarly, a branch decomposition of a k-outerplanar graph of width\nat most 2k+1 can be also obtained in O(kn) time, the algorithm for which is\nalso analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 20:54:38 GMT"}], "update_date": "2013-01-25", "authors_parsed": [["Katsikarelis", "Ioannis", ""]]}, {"id": "1301.5953", "submitter": "Daniel Paulusma", "authors": "Hajo Broersma, Ji\\v{r}\\'i Fiala, Petr A. Golovach, Tom\\'a\\v{s} Kaiser,\n  Dani\\\"el Paulusma, Andrzej Proskurowski", "title": "Linear-Time Algorithms for Scattering Number and Hamilton-Connectivity\n  of Interval Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hung and Chang showed that for all k>=1 an interval graph has a path cover of\nsize at most k if and only if its scattering number is at most k. They also\nshowed that an interval graph has a Hamilton cycle if and only if its\nscattering number is at most 0. We complete this characterization by proving\nthat for all k<=-1 an interval graph is -(k+1)-Hamilton-connected if and only\nif its scattering number is at most k. We also give an O(m+n) time algorithm\nfor computing the scattering number of an interval graph with n vertices an m\nedges, which improves the O(n^4) time bound of Kratsch, Kloks and M\\\"uller. As\na consequence of our two results the maximum k for which an interval graph is\nk-Hamilton-connected can be computed in O(m+n) time.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 02:24:26 GMT"}], "update_date": "2013-01-28", "authors_parsed": [["Broersma", "Hajo", ""], ["Fiala", "Ji\u0159\u00ed", ""], ["Golovach", "Petr A.", ""], ["Kaiser", "Tom\u00e1\u0161", ""], ["Paulusma", "Dani\u00ebl", ""], ["Proskurowski", "Andrzej", ""]]}, {"id": "1301.6127", "submitter": "Oren Weimann", "authors": "Travis Gagie and Danny Hermelin and Gad M. Landau and Oren Weimann", "title": "Binary Jumbled Pattern Matching on Trees and Tree-Like Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary jumbled pattern matching asks to preprocess a binary string $S$ in\norder to answer queries $(i,j)$ which ask for a substring of $S$ that is of\nlength $i$ and has exactly $j$ 1-bits. This problem naturally generalizes to\nvertex-labeled trees and graphs by replacing \"substring\" with \"connected\nsubgraph\". In this paper, we give an $O(n^2 / \\log^2 n)$-time solution for\ntrees, matching the currently best bound for (the simpler problem of) strings.\nWe also give an $\\Oh{g^{2 / 3} n^{4 / 3}/(\\log n)^{4/3}}$-time solution for\nstrings that are compressed by a grammar of size $g$. This solution improves\nthe known bounds when the string is compressible under many popular compression\nschemes. Finally, we prove that the problem is fixed-parameter tractable with\nrespect to the treewidth $w$ of the graph, thus improving the previous best\n$n^{O(w)}$ algorithm [ICALP'07].\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 19:06:06 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2013 22:22:50 GMT"}, {"version": "v3", "created": "Sat, 28 Jun 2014 12:24:53 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Gagie", "Travis", ""], ["Hermelin", "Danny", ""], ["Landau", "Gad M.", ""], ["Weimann", "Oren", ""]]}, {"id": "1301.6268", "submitter": "Ofer Zeitouni", "authors": "Mark Rudelson, Ofer Zeitouni", "title": "Singular values of Gaussian matrices and permanent estimators", "comments": "small revision, no major changes. Changed terminology to \"broadly\n  connected\". Corrected error in probability estimate in statement of theorems\n  1.4 and 1.5", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present estimates on the small singular values of a class of matrices with\nindependent Gaussian entries and inhomogeneous variance profile, satisfying a\nbroad-connectedness condition. Using these estimates and concentration of\nmeasure for the spectrum of Gaussian matrices with independent entries, we\nprove that for a large class of graphs satisfying an appropriate expansion\nproperty, the Barvinok--Godsil-Gutman estimator for the permanent achieves\nsub-exponential errors with high probability.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2013 16:27:33 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2013 05:52:45 GMT"}, {"version": "v3", "created": "Fri, 29 Aug 2014 19:51:48 GMT"}], "update_date": "2014-09-01", "authors_parsed": [["Rudelson", "Mark", ""], ["Zeitouni", "Ofer", ""]]}, {"id": "1301.6299", "submitter": "David Adjiashvili", "authors": "David Adjiashvili", "title": "Fault-Tolerant Shortest Paths - Beyond the Uniform Failure Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overwhelming majority of survivable (fault-tolerant) network design\nmodels assume a uniform scenario set. Such a scenario set assumes that every\nsubset of the network resources (edges or vertices) of a given cardinality $k$\ncomprises a scenario. While this approach yields problems with clean\ncombinatorial structure and good algorithms, it often fails to capture the true\nnature of the scenario set coming from applications.\n  One natural refinement of the uniform model is obtained by partitioning the\nset of resources into faulty and secure resources. The scenario set contains\nevery subset of at most $k$ faulty resources. This work studies the\nFault-Tolerant Path (FTP) problem, the counterpart of the Shortest Path problem\nin this failure model. We present complexity results alongside exact and\napproximation algorithms for FTP. We emphasize the vast increase in the\ncomplexity of the problem with respect to its uniform analogue, the\nEdge-Disjoint Paths problem.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2013 23:51:15 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Adjiashvili", "David", ""]]}, {"id": "1301.6428", "submitter": "Shoshana Marcus", "authors": "Shoshana Marcus Dina Sokol", "title": "Engineering Small Space Dictionary Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dictionary matching problem is to locate occurrences of any pattern among\na set of patterns in a given text. Massive data sets abound and at the same\ntime, there are many settings in which working space is extremely limited. We\nintroduce dictionary matching software for the space-constrained environment\nwhose running time is close to linear. We use the compressed suffix tree as the\nunderlying data structure of our algorithm, thus, the working space of our\nalgorithm is proportional to the optimal compression of the dictionary. We also\ncontribute a succinct tool for performing constant-time lowest marked ancestor\nqueries on a tree that is succinctly encoded as a sequence of balanced\nparentheses, with linear time preprocessing of the tree. This tool should be\nuseful in many other applications. Our source code is available at\nhttp://www.sci.brooklyn.cuny.edu/~sokol/dictmatch.html\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 02:25:33 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Sokol", "Shoshana Marcus Dina", ""]]}, {"id": "1301.6447", "submitter": "Aleksandar Nikolov", "authors": "Nadia Fawaz, S. Muthukrishnan, Aleksandar Nikolov", "title": "Nearly Optimal Private Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study computing the convolution of a private input $x$ with a public input\n$h$, while satisfying the guarantees of $(\\epsilon, \\delta)$-differential\nprivacy. Convolution is a fundamental operation, intimately related to Fourier\nTransforms. In our setting, the private input may represent a time series of\nsensitive events or a histogram of a database of confidential personal\ninformation. Convolution then captures important primitives including linear\nfiltering, which is an essential tool in time series analysis, and aggregation\nqueries on projections of the data.\n  We give a nearly optimal algorithm for computing convolutions while\nsatisfying $(\\epsilon, \\delta)$-differential privacy. Surprisingly, we follow\nthe simple strategy of adding independent Laplacian noise to each Fourier\ncoefficient and bounding the privacy loss using the composition theorem of\nDwork, Rothblum, and Vadhan. We derive a closed form expression for the optimal\nnoise to add to each Fourier coefficient using convex programming duality. Our\nalgorithm is very efficient -- it is essentially no more computationally\nexpensive than a Fast Fourier Transform.\n  To prove near optimality, we use the recent discrepancy lowerbounds of\nMuthukrishnan and Nikolov and derive a spectral lower bound using a\ncharacterization of discrepancy in terms of determinants.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 04:48:33 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Fawaz", "Nadia", ""], ["Muthukrishnan", "S.", ""], ["Nikolov", "Aleksandar", ""]]}, {"id": "1301.6628", "submitter": "Aaron Sidford", "authors": "Jonathan A. Kelner, Lorenzo Orecchia, Aaron Sidford, Zeyuan Allen Zhu", "title": "A Simple, Combinatorial Algorithm for Solving SDD Systems in\n  Nearly-Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a simple combinatorial algorithm that solves\nsymmetric diagonally dominant (SDD) linear systems in nearly-linear time. It\nuses very little of the machinery that previously appeared to be necessary for\na such an algorithm. It does not require recursive preconditioning, spectral\nsparsification, or even the Chebyshev Method or Conjugate Gradient. After\nconstructing a \"nice\" spanning tree of a graph associated with the linear\nsystem, the entire algorithm consists of the repeated application of a simple\n(non-recursive) update rule, which it implements using a lightweight data\nstructure. The algorithm is numerically stable and can be implemented without\nthe increased bit-precision required by previous solvers. As such, the\nalgorithm has the fastest known running time under the standard unit-cost RAM\nmodel. We hope that the simplicity of the algorithm and the insights yielded by\nits analysis will be useful in both theory and practice.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 18:06:21 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Kelner", "Jonathan A.", ""], ["Orecchia", "Lorenzo", ""], ["Sidford", "Aaron", ""], ["Zhu", "Zeyuan Allen", ""]]}, {"id": "1301.6916", "submitter": "Vincent Gripon", "authors": "Vincent Gripon and Michael Rabbat", "title": "Reconstructing a Graph from Path Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of inferring the structure of a network from\nindirect observations. Each observation (a \"trace\") is the unordered set of\nnodes which are activated along a path through the network. Since a trace does\nnot convey information about the order of nodes within the path, there are many\nfeasible orders for each trace observed, and thus the problem of inferring the\nnetwork from traces is, in general, illposed. We propose and analyze an\nalgorithm which inserts edges by ordering each trace into a path according to\nwhich pairs of nodes in the path co-occur most frequently in the observations.\nWhen all traces involve exactly 3 nodes, we derive necessary and sufficient\nconditions for the reconstruction algorithm to exactly recover the graph.\nFinally, for a family of random graphs, we present expressions for\nreconstruction error probabilities (false discoveries and missed detections).\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 13:13:02 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Gripon", "Vincent", ""], ["Rabbat", "Michael", ""]]}, {"id": "1301.7119", "submitter": "Yoann Dieudonn\\'e", "authors": "Yoann Dieudonn\\'e, Andrzej Pelc, Vincent Villain", "title": "How to Meet Asynchronously at Polynomial Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two mobile agents starting at different nodes of an unknown network have to\nmeet. This task is known in the literature as rendezvous. Each agent has a\ndifferent label which is a positive integer known to it, but unknown to the\nother agent. Agents move in an asynchronous way: the speed of agents may vary\nand is controlled by an adversary. The cost of a rendezvous algorithm is the\ntotal number of edge traversals by both agents until their meeting. The only\nprevious deterministic algorithm solving this problem has cost exponential in\nthe size of the graph and in the larger label. In this paper we present a\ndeterministic rendezvous algorithm with cost polynomial in the size of the\ngraph and in the length of the smaller label. Hence we decrease the cost\nexponentially in the size of the graph and doubly exponentially in the labels\nof agents. As an application of our rendezvous algorithm we solve several\nfundamental problems involving teams of unknown size larger than 1 of labeled\nagents moving asynchronously in unknown networks. Among them are the following\nproblems: team size, in which every agent has to find the total number of\nagents, leader election, in which all agents have to output the label of a\nsingle agent, perfect renaming in which all agents have to adopt new different\nlabels from the set {1, . . . , k}, where k is the number of agents, and\ngossiping, in which each agent has initially a piece of information (value) and\nall agents have to output all the values. Using our rendezvous algorithm we\nsolve all these problems at cost polynomial in the size of the graph and in the\nsmallest length of all labels of participating agents.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 01:25:48 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2015 15:36:59 GMT"}], "update_date": "2015-04-24", "authors_parsed": [["Dieudonn\u00e9", "Yoann", ""], ["Pelc", "Andrzej", ""], ["Villain", "Vincent", ""]]}, {"id": "1301.7134", "submitter": "Yi Wang", "authors": "Peng Guo, Wenming Chen, Yi Wang", "title": "A general variable neighborhood search for single-machine total\n  tardiness scheduling problem with step-deteriorating jobs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study a single-machine scheduling problem of minimizing\nthe total tardiness for a set of independent jobs. The processing time of a job\nis modeled as a step function of its starting time and a specific deteriorating\ndate. A mixed integer programming model was applied to the problem and\nvalidated. Since the problem is known to be NP-hard, we proposed a heuristic\nnamed simple weighted search procedure (SWSP) and a general variable\nneighborhood search algorithm (GVNS).\n  A perturbation procedure with 3-opt is embedded within the GVNS process in\norder to explore broader spaces. Extensive numerical experiments are carried\nout on some randomly generated test instances so as to investigate the\nperformance of the proposed algorithms. By comparing to the results of the\nCPLEX optimization solver, the heuristic SWSP and the standard variable\nneighborhood search, it is shown that the proposed GVNS algorithm can provide\nbetter solutions within a reasonable running time.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 03:12:50 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2013 01:52:11 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Guo", "Peng", ""], ["Chen", "Wenming", ""], ["Wang", "Yi", ""]]}, {"id": "1301.7183", "submitter": "Xiaodong Wang", "authors": "Lei Wang, Xiaodong Wang, Yingjie Wu, and Daxin Zhu", "title": "A Dynamic Programming Solution to a Generalized LCS Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a generalized longest common subsequence problem,\nthe string-excluding constrained LCS problem. For the two input sequences $X$\nand $Y$ of lengths $n$ and $m$, and a constraint string $P$ of length $r$, the\nproblem is to find a common subsequence $Z$ of $X$ and $Y$ excluding $P$ as a\nsubstring and the length of $Z$ is maximized. The problem and its solution were\nfirst proposed by Chen and Chao\\cite{1}, but we found that their algorithm can\nnot solve the problem correctly. A new dynamic programming solution for the\nSTR-EC-LCS problem is then presented in this paper. The correctness of the new\nalgorithm is proved. The time complexity of the new algorithm is $O(nmr)$.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 10:03:10 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Wang", "Lei", ""], ["Wang", "Xiaodong", ""], ["Wu", "Yingjie", ""], ["Zhu", "Daxin", ""]]}, {"id": "1301.7250", "submitter": "Andreas Bjorklund", "authors": "Andreas Bj\\\"orklund and Thore Husfeldt", "title": "The Parity of Directed Hamiltonian Cycles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deterministic algorithm that given any directed graph on n\nvertices computes the parity of its number of Hamiltonian cycles in O(1.619^n)\ntime and polynomial space. For bipartite graphs, we give a 1.5^n poly(n)\nexpected time algorithm. Our algorithms are based on a new combinatorial\nformula for the number of Hamiltonian cycles modulo a positive integer.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 14:57:48 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2013 14:32:17 GMT"}], "update_date": "2013-08-09", "authors_parsed": [["Bj\u00f6rklund", "Andreas", ""], ["Husfeldt", "Thore", ""]]}, {"id": "1301.7314", "submitter": "Micha{\\l} Pilipczuk", "authors": "Fedor V. Fomin and Micha{\\l} Pilipczuk", "title": "Subexponential parameterized algorithm for computing the cutwidth of a\n  semi-complete digraph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cutwidth of a digraph is a width measure introduced by Chudnovsky, Fradkin,\nand Seymour [4] in connection with development of a structural theory for\ntournaments, or more generally, for semi-complete digraphs. In this paper we\nprovide an algorithm with running time 2^{O(\\sqrt{k log k})} * n^{O(1)} that\ntests whether the cutwidth of a given n-vertex semi-complete digraph is at most\nk, improving upon the currently fastest algorithm of the second author [18]\nthat works in 2^{O(k)} * n^2 time. As a byproduct, we obtain a new algorithm\nfor Feedback Arc Set in tournaments (FAST) with running time 2^{c\\sqrt{k}} *\nn^{O(1)}, where c = 2\\pi / \\sqrt(3)*\\ln(2) <= 5.24, that is simpler than the\nalgorithms of Feige [9] and of Karpinski and Schudy[16], both also working in\n2^{O(\\sqrt{k})} * n^{O(1)} time. Our techniques can be applied also to other\nlayout problems on semi-complete digraphs. We show that the Optimal Linear\nArrangement problem, a close relative of Feedback Arc Set, can be solved in\n2^{O(k^{1/3} \\sqrt{\\log k})} * n^{O(1)} time, where k is the target cost of the\nordering.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 18:11:30 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1301.7462", "submitter": "Christine Rizkallah", "authors": "Eyad Alkassar and Sascha B\\\"ohme and Kurt Mehlhorn and Christine\n  Rizkallah", "title": "A Framework for the Verification of Certifying Computations", "comments": "A preliminary version appeared under the title \"Verification of\n  Certifying Computations\" in CAV 2011, LCNS Vol 6806, pages 67 - 82. This\n  paper is currently under review in the Journal of Automated Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal verification of complex algorithms is challenging. Verifying their\nimplementations goes beyond the state of the art of current automatic\nverification tools and usually involves intricate mathematical theorems.\nCertifying algorithms compute in addition to each output a witness certifying\nthat the output is correct. A checker for such a witness is usually much\nsimpler than the original algorithm - yet it is all the user has to trust. The\nverification of checkers is feasible with current tools and leads to\ncomputations that can be completely trusted. We describe a framework to\nseamlessly verify certifying computations. We use the automatic verifier VCC\nfor establishing the correctness of the checker and the interactive theorem\nprover Isabelle/HOL for high-level mathematical properties of algorithms. We\ndemonstrate the effectiveness of our approach by presenting the verification of\ntypical examples of the industrial-level and widespread algorithmic library\nLEDA.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 23:02:36 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Alkassar", "Eyad", ""], ["B\u00f6hme", "Sascha", ""], ["Mehlhorn", "Kurt", ""], ["Rizkallah", "Christine", ""]]}, {"id": "1301.7512", "submitter": "Haitao Wang", "authors": "Danny Z. Chen, Jian Li, and Haitao Wang", "title": "Efficient Algorithms for One-Dimensional k-Center Problems", "comments": "13 pages, 3 figures. Thanks to Amir Tamir, discussions on previous\n  work are updated in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding k centers for n weighted points on a real\nline. This (weighted) k-center problem was solved in O(n log n) time previously\nby using Cole's parametric search and other complicated approaches. In this\npaper, we present an easier O(n log n) time algorithm that avoids the\nparametric search, and in certain special cases our algorithm solves the\nproblem in O(n) time. In addition, our techniques involve developing\ninteresting data structures for processing queries that find a lowest point in\nthe common intersection of a certain subset of half-planes. This subproblem is\ninteresting in its own right and our solution for it may find other\napplications as well.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 04:40:10 GMT"}, {"version": "v2", "created": "Thu, 6 Mar 2014 05:12:43 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Chen", "Danny Z.", ""], ["Li", "Jian", ""], ["Wang", "Haitao", ""]]}]