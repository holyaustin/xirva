[{"id": "1304.0053", "submitter": "Niall Murphy", "authors": "Turlough Neary, Damien Woods, Niall Murphy, Rainer Glaschick", "title": "Wang's B machines are efficiently universal, as is Hasenjaeger's small\n  universal electromechanical toy", "comments": "18 pages, 1 figure, 1 table, Conference: Turing in context II -\n  History and Philosophy of Computing, 2012", "journal-ref": "Journal of Complexity, Volume 30, Issue 5, October 2014, pages\n  634-646", "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the 1960's Gisbert Hasenjaeger built Turing Machines from\nelectromechanical relays and uniselectors. Recently, Glaschick reverse\nengineered the program of one of these machines and found that it is a\nuniversal Turing machine. In fact, its program uses only four states and two\nsymbols, making it a very small universal Turing machine. (The machine has\nthree tapes and a number of other features that are important to keep in mind\nwhen comparing it to other small universal machines.) Hasenjaeger's machine\nsimulates Hao Wang's B machines, which were proved universal by Wang.\nUnfortunately, Wang's original simulation algorithm suffers from an exponential\nslowdown when simulating Turing machines. Hence, via this simulation,\nHasenjaeger's machine also has an exponential slowdown when simulating Turing\nmachines. In this work, we give a new efficient simulation algorithm for Wang's\nB machines by showing that they simulate Turing machines with only a polynomial\nslowdown. As a second result, we find that Hasenjaeger's machine also\nefficiently simulates Turing machines in polynomial time. Thus, Hasenjaeger's\nmachine is both small and fast. In another application of our result, we show\nthat Hooper's small universal Turing machine simulates Turing machines in\npolynomial time, an exponential improvement.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2013 00:34:31 GMT"}, {"version": "v2", "created": "Tue, 5 Aug 2014 18:34:14 GMT"}], "update_date": "2014-08-06", "authors_parsed": [["Neary", "Turlough", ""], ["Woods", "Damien", ""], ["Murphy", "Niall", ""], ["Glaschick", "Rainer", ""]]}, {"id": "1304.0084", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Jakub {\\L}\\k{a}cki", "title": "Faster Algorithms for Markov Decision Processes with Low Treewidth", "comments": "Conference version will appear in CAV 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two core algorithmic problems for probabilistic verification: the\nmaximal end-component decomposition and the almost-sure reachability set\ncomputation for Markov decision processes (MDPs). For MDPs with treewidth $k$,\nwe present two improved static algorithms for both the problems that run in\ntime $O(n \\cdot k^{2.38} \\cdot 2^k)$ and $O(m \\cdot \\log n \\cdot k)$,\nrespectively, where $n$ is the number of states and $m$ is the number of edges,\nsignificantly improving the previous known $O(n\\cdot k \\cdot \\sqrt{n\\cdot k})$\nbound for low treewidth. We also present decremental algorithms for both\nproblems for MDPs with constant treewidth that run in amortized logarithmic\ntime, which is a huge improvement over the previously known algorithms that\nrequire amortized linear time.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2013 10:17:14 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2013 12:09:19 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["\u0141\u0105cki", "Jakub", ""]]}, {"id": "1304.0378", "submitter": "Manoj Gupta", "authors": "Manoj Gupta and Richard Peng", "title": "Fully Dynamic $(1+\\epsilon)$-Approximate Matchings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first data structures that maintain near optimal maximum\ncardinality and maximum weighted matchings on sparse graphs in sublinear time\nper update. Our main result is a data structure that maintains a $(1+\\epsilon)$\napproximation of maximum matching under edge insertions/deletions in worst case\n$O(\\sqrt{m}\\epsilon^{-2})$ time per update. This improves the 3/2 approximation\ngiven in [Neiman,Solomon,STOC 2013] which runs in similar time. The result is\nbased on two ideas. The first is to re-run a static algorithm after a chosen\nnumber of updates to ensure approximation guarantees. The second is to\njudiciously trim the graph to a smaller equivalent one whenever possible.\n  We also study extensions of our approach to the weighted setting, and combine\nit with known frameworks to obtain arbitrary approximation ratios. For a\nconstant $\\epsilon$ and for graphs with edge weights between 1 and N, we design\nan algorithm that maintains an $(1+\\epsilon)$-approximate maximum weighted\nmatching in $O(\\sqrt{m} \\log N)$ time per update. The only previous result for\nmaintaining weighted matchings on dynamic graphs has an approximation ratio of\n4.9108, and was shown in [Anand,Baswana,Gupta,Sen, FSTTCS 2012, arXiv 2012].\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2013 15:29:21 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2013 18:55:31 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Gupta", "Manoj", ""], ["Peng", "Richard", ""]]}, {"id": "1304.0419", "submitter": "Mahashweta Das", "authors": "Mahashweta Das, Gautam Das, Vagelis Hristidis", "title": "Top-K Product Design Based on Collaborative Tagging Data", "comments": "The conference version appeared under the title \"Leveraging\n  collaborative tagging for web item design\" in SIGKDD 2011, pages 538-546", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use and popularity of collaborative content sites (e.g., IMDB,\nAmazon, Yelp, etc.) has created rich resources for users to consult in order to\nmake purchasing decisions on various products such as movies, e-commerce\nproducts, restaurants, etc. Products with desirable tags (e.g., modern,\nreliable, etc.) have higher chances of being selected by prospective customers.\nThis creates an opportunity for product designers to design better products\nthat are likely to attract desirable tags when published. In this paper, we\ninvestigate how to mine collaborative tagging data to decide the attribute\nvalues of new products and to return the top-k products that are likely to\nattract the maximum number of desirable tags when published. Given a training\nset of existing products with their features and user-submitted tags, we first\nbuild a Naive Bayes Classifier for each tag. We show that the problem of is\nNP-complete even if simple Naive Bayes Classifiers are used for tag prediction.\nWe present a suite of algorithms for solving this problem: (a) an exact two\ntier algorithm(based on top-k querying techniques), which performs much better\nthan the naive brute-force algorithm and works well for moderate problem\ninstances, and (b) a set of approximation algorithms for larger problem\ninstances: a novel polynomial-time approximation algorithm with provable error\nbound and a practical hill-climbing heuristic. We conduct detailed experiments\non synthetic and real data crawled from the web to evaluate the efficiency and\nquality of our proposed algorithms, as well as show how product designers can\nbenefit by leveraging collaborative tagging information.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2013 19:09:38 GMT"}], "update_date": "2013-04-02", "authors_parsed": [["Das", "Mahashweta", ""], ["Das", "Gautam", ""], ["Hristidis", "Vagelis", ""]]}, {"id": "1304.0494", "submitter": "Kaarthik Sundar", "authors": "Kaarthik Sundar and Sivakumar Rathinam", "title": "Algorithms for Routing an Unmanned Aerial Vehicle in the presence of\n  Refueling Depots", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a single Unmanned Aerial Vehicle (UAV) routing problem where\nthere are multiple depots and the vehicle is allowed to refuel at any depot.\nThe objective of the problem is to find a path for the UAV such that each\ntarget is visited at least once by the vehicle, the fuel constraint is never\nviolated along the path for the UAV, and the total fuel required by the UAV is\na minimum. We develop an approximation algorithm for the problem, and propose\nfast construction and improvement heuristics to solve the same. Computational\nresults show that solutions whose costs are on an average within 1.4% of the\noptimum can be obtained relatively fast for the problem involving 5 depots and\n25 targets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2013 23:04:27 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Sundar", "Kaarthik", ""], ["Rathinam", "Sivakumar", ""]]}, {"id": "1304.0528", "submitter": "Ver\\'onica  Becher", "authors": "Veronica Becher and Alejandro Deymonnaz and Pablo Ariel Heiber", "title": "Efficient repeat finding via suffix arrays", "comments": "14 pages", "journal-ref": "Bioinformatics, 25(14):1746-1753, 2009", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We solve the problem of finding interspersed maximal repeats using a suffix\narray construction. As it is well known, all the functionality of suffix trees\ncan be handled by suffix arrays, gaining practicality. Our solution improves\nthe suffix tree based approaches for the repeat finding problem, being\nparticularly well suited for very large inputs. We prove the corrrectness and\ncomplexity of the algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 04:41:33 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Becher", "Veronica", ""], ["Deymonnaz", "Alejandro", ""], ["Heiber", "Pablo Ariel", ""]]}, {"id": "1304.0552", "submitter": "Pascal Maillard", "authors": "Pascal Maillard, Ofer Zeitouni", "title": "Performance of the Metropolis algorithm on a disordered tree: The\n  Einstein relation", "comments": "Published in at http://dx.doi.org/10.1214/13-AAP972 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 5, 2070-2090", "doi": "10.1214/13-AAP972", "report-no": "IMS-AAP-AAP972", "categories": "math.PR cond-mat.dis-nn cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a $d$-ary rooted tree ($d\\geq3$) where each edge $e$ is assigned an\ni.i.d. (bounded) random variable $X(e)$ of negative mean. Assign to each vertex\n$v$ the sum $S(v)$ of $X(e)$ over all edges connecting $v$ to the root, and\nassume that the maximum $S_n^*$ of $S(v)$ over all vertices $v$ at distance $n$\nfrom the root tends to infinity (necessarily, linearly) as $n$ tends to\ninfinity. We analyze the Metropolis algorithm on the tree and show that under\nthese assumptions there always exists a temperature $1/\\beta$ of the algorithm\nso that it achieves a linear (positive) growth rate in linear time. This\nconfirms a conjecture of Aldous [Algorithmica 22 (1998) 388-412]. The proof is\nobtained by establishing an Einstein relation for the Metropolis algorithm on\nthe tree.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 07:55:10 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2013 14:40:24 GMT"}, {"version": "v3", "created": "Wed, 2 Jul 2014 13:56:55 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Maillard", "Pascal", ""], ["Zeitouni", "Ofer", ""]]}, {"id": "1304.0730", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Pravesh Kothari and Jan Vondrak", "title": "Representation, Approximation and Learning of Submodular Functions Using\n  Low-rank Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of approximate representation and learning of\nsubmodular functions over the uniform distribution on the Boolean hypercube\n$\\{0,1\\}^n$. Our main result is the following structural theorem: any\nsubmodular function is $\\epsilon$-close in $\\ell_2$ to a real-valued decision\ntree (DT) of depth $O(1/\\epsilon^2)$. This immediately implies that any\nsubmodular function is $\\epsilon$-close to a function of at most\n$2^{O(1/\\epsilon^2)}$ variables and has a spectral $\\ell_1$ norm of\n$2^{O(1/\\epsilon^2)}$. It also implies the closest previous result that states\nthat submodular functions can be approximated by polynomials of degree\n$O(1/\\epsilon^2)$ (Cheraghchi et al., 2012). Our result is proved by\nconstructing an approximation of a submodular function by a DT of rank\n$4/\\epsilon^2$ and a proof that any rank-$r$ DT can be $\\epsilon$-approximated\nby a DT of depth $\\frac{5}{2}(r+\\log(1/\\epsilon))$.\n  We show that these structural results can be exploited to give an\nattribute-efficient PAC learning algorithm for submodular functions running in\ntime $\\tilde{O}(n^2) \\cdot 2^{O(1/\\epsilon^{4})}$. The best previous algorithm\nfor the problem requires $n^{O(1/\\epsilon^{2})}$ time and examples (Cheraghchi\net al., 2012) but works also in the agnostic setting. In addition, we give\nimproved learning algorithms for a number of related settings.\n  We also prove that our PAC and agnostic learning algorithms are essentially\noptimal via two lower bounds: (1) an information-theoretic lower bound of\n$2^{\\Omega(1/\\epsilon^{2/3})}$ on the complexity of learning monotone\nsubmodular functions in any reasonable model; (2) computational lower bound of\n$n^{\\Omega(1/\\epsilon^{2/3})}$ based on a reduction to learning of sparse\nparities with noise, widely-believed to be intractable. These are the first\nlower bounds for learning of submodular functions over the uniform\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 18:37:35 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Feldman", "Vitaly", ""], ["Kothari", "Pravesh", ""], ["Vondrak", "Jan", ""]]}, {"id": "1304.0810", "submitter": "Claudio Angione", "authors": "Claudio Angione, Annalisa Occhipinti, Giovanni Stracquadanio, Giuseppe\n  Nicosia", "title": "Bose-Einstein Condensation in Satisfiability Problems", "comments": null, "journal-ref": "European Journal of Operational Research, 227, 44-54 (2013)", "doi": "10.1016/j.ejor.2012.11.039", "report-no": null, "categories": "cs.DS cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the complex behavior arising in satisfiability\nproblems. We present a new statistical physics-based characterization of the\nsatisfiability problem. Specifically, we design an algorithm that is able to\nproduce graphs starting from a k-SAT instance, in order to analyze them and\nshow whether a Bose-Einstein condensation occurs. We observe that, analogously\nto complex networks, the networks of k-SAT instances follow Bose statistics and\ncan undergo Bose-Einstein condensation. In particular, k-SAT instances move\nfrom a fit-get-rich network to a winner-takes-all network as the ratio of\nclauses to variables decreases, and the phase transition of k-SAT approximates\nthe critical temperature for the Bose-Einstein condensation. Finally, we employ\nthe fitness-based classification to enhance SAT solvers (e.g., ChainSAT) and\nobtain the consistently highest performing SAT solver for CNF formulas, and\ntherefore a new class of efficient hardware and software verification tools.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 22:58:35 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Angione", "Claudio", ""], ["Occhipinti", "Annalisa", ""], ["Stracquadanio", "Giovanni", ""], ["Nicosia", "Giuseppe", ""]]}, {"id": "1304.0872", "submitter": "David Doty", "authors": "David Doty", "title": "Timing in chemical reaction networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC cs.DS q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical reaction networks (CRNs) formally model chemistry in a well-mixed\nsolution. CRNs are widely used to describe information processing occurring in\nnatural cellular regulatory networks, and with upcoming advances in synthetic\nbiology, CRNs are a promising programming language for the design of artificial\nmolecular control circuitry. Due to a formal equivalence between CRNs and a\nmodel of distributed computing known as population protocols, results transfer\nreadily between the two models.\n  We show that if a CRN respects finite density (at most O(n) additional\nmolecules can be produced from n initial molecules), then starting from any\ndense initial configuration (all molecular species initially present have\ninitial count Omega(n), where n is the initial molecular count and volume),\nthen every producible species is produced in constant time with high\nprobability.\n  This implies that no CRN obeying the stated constraints can function as a\ntimer, able to produce a molecule, but doing so only after a time that is an\nunbounded function of the input size. This has consequences regarding an open\nquestion of Angluin, Aspnes, and Eisenstat concerning the ability of population\nprotocols to perform fast, reliable leader election and to simulate arbitrary\nalgorithms from a uniform initial state.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 08:50:30 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Doty", "David", ""]]}, {"id": "1304.0917", "submitter": "Yasuo Tabei", "authors": "Yasuo Tabei, Yoshimasa Takabatake, Hiroshi Sakamoto", "title": "A Succinct Grammar Compression", "comments": "The paper is accepted to 24th Annual Symposium on Combinatorial\n  Pattern Matching (CPM2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We solve an open problem related to an optimal encoding of a straight line\nprogram (SLP), a canonical form of grammar compression deriving a single string\ndeterministically. We show that an information-theoretic lower bound for\nrepresenting an SLP with n symbols requires at least 2n+logn!+o(n) bits. We\nthen present a succinct representation of an SLP; this representation is\nasymptotically equivalent to the lower bound. The space is at most 2n log\n{rho}(1 + o(1)) bits for rho leq 2sqrt{n}, while supporting random access to\nany production rule of an SLP in O(log log n) time. In addition, we present a\nnovel dynamic data structure associating a digram with a unique symbol. Such a\ndata structure is called a naming function and has been implemented using a\nhash table that has a space-time tradeoff. Thus, the memory space is mainly\noccupied by the hash table during the development of production rules.\nAlternatively, we build a dynamic data structure for the naming function by\nleveraging the idea behind the wavelet tree. The space is strictly bounded by\n2n log n(1 + o(1)) bits, while supporting O(log n) query and update time.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 11:13:00 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2013 03:15:33 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2013 02:13:38 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Tabei", "Yasuo", ""], ["Takabatake", "Yoshimasa", ""], ["Sakamoto", "Hiroshi", ""]]}, {"id": "1304.0988", "submitter": "Sebastian Wild", "authors": "Sebastian Wild, Markus E. Nebel, Ralph Neininger", "title": "Average Case and Distributional Analysis of Dual-Pivot Quicksort", "comments": "v3 is content-wise identical to TALG version", "journal-ref": "ACM Transactions on Algorithms 11, 3, Article 22 (Jan 2015)", "doi": "10.1145/2629340", "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2009, Oracle replaced the long-serving sorting algorithm in its Java 7\nruntime library by a new dual-pivot Quicksort variant due to Vladimir\nYaroslavskiy. The decision was based on the strikingly good performance of\nYaroslavskiy's implementation in running time experiments. At that time, no\nprecise investigations of the algorithm were available to explain its superior\nperformance - on the contrary: Previous theoretical studies of other dual-pivot\nQuicksort variants even discouraged the use of two pivots. Only in 2012, two of\nthe authors gave an average case analysis of a simplified version of\nYaroslavskiy's algorithm, proving that savings in the number of comparisons are\npossible. However, Yaroslavskiy's algorithm needs more swaps, which renders the\nanalysis inconclusive.\n  To force the issue, we herein extend our analysis to the fully detailed style\nof Knuth: We determine the exact number of executed Java Bytecode instructions.\nSurprisingly, Yaroslavskiy's algorithm needs sightly more Bytecode instructions\nthan a simple implementation of classic Quicksort - contradicting observed\nrunning times. Like in Oracle's library implementation we incorporate the use\nof Insertionsort on small subproblems and show that it indeed speeds up\nYaroslavskiy's Quicksort in terms of Bytecodes; but even with optimal\nInsertionsort thresholds the new Quicksort variant needs slightly more Bytecode\ninstructions on average.\n  Finally, we show that the (suitably normalized) costs of Yaroslavskiy's\nalgorithm converge to a random variable whose distribution is characterized by\na fixed-point equation. From that, we compute variances of costs and show that\nfor large n, costs are concentrated around their mean.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 15:37:50 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2014 14:14:37 GMT"}, {"version": "v3", "created": "Fri, 13 Feb 2015 16:38:39 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Wild", "Sebastian", ""], ["Nebel", "Markus E.", ""], ["Neininger", "Ralph", ""]]}, {"id": "1304.1007", "submitter": "Jukka Suomela", "authors": "Mika G\\\"o\\\"os, Juho Hirvonen, Jukka Suomela", "title": "Linear-in-$\\Delta$ Lower Bounds in the LOCAL Model", "comments": "1 + 21 pages, 10 figures", "journal-ref": null, "doi": "10.1007/s00446-015-0245-8", "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By prior work, there is a distributed algorithm that finds a maximal\nfractional matching (maximal edge packing) in $O(\\Delta)$ rounds, where\n$\\Delta$ is the maximum degree of the graph. We show that this is optimal:\nthere is no distributed algorithm that finds a maximal fractional matching in\n$o(\\Delta)$ rounds.\n  Our work gives the first linear-in-$\\Delta$ lower bound for a natural graph\nproblem in the standard model of distributed computing---prior lower bounds for\na wide range of graph problems have been at best logarithmic in $\\Delta$.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 16:46:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["G\u00f6\u00f6s", "Mika", ""], ["Hirvonen", "Juho", ""], ["Suomela", "Jukka", ""]]}, {"id": "1304.1066", "submitter": "Qi Zhou", "authors": "Qi Zhou and Xiaoli Ma", "title": "An Improved LR-aided K-Best Algorithm for MIMO Detection", "comments": "5 pages, 4 figures, 1 table, conference", "journal-ref": "International Conference on Wireless Communications and Signal\n  Processing (WCSP) 2012", "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, lattice reduction (LR) technique has caught great attention for\nmulti-input multi-output (MIMO) receiver because of its low complexity and high\nperformance. However, when the number of antennas is large, LR-aided linear\ndetectors and successive interference cancellation (SIC) detectors still\nexhibit considerable performance gap to the optimal maximum likelihood detector\n(MLD). To enhance the performance of the LR-aided detectors, the LR-aided\nK-best algorithm was developed at the cost of the extra complexity on the order\n$\\mathcal{O}(N_t^2 K + N_t K^2)$, where $N_t$ is the number of transmit\nantennas and $K$ is the number of candidates. In this paper, we develop an\nLR-aided K-best algorithm with lower complexity by exploiting a priority queue.\nWith the aid of the priority queue, our analysis shows that the complexity of\nthe LR-aided K-best algorithm can be further reduced to $\\mathcal{O}(N_t^2 K +\nN_t K {\\rm log}_2(K))$. The low complexity of the proposed LR-aided K-best\nalgorithm allows us to perform the algorithm for large MIMO systems (e.g.,\n50x50 MIMO systems) with large candidate sizes. Simulations show that as the\nnumber of antennas increases, the error performance approaches that of AWGN\nchannel.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 19:27:52 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Zhou", "Qi", ""], ["Ma", "Xiaoli", ""]]}, {"id": "1304.1188", "submitter": "Rasmus Pagh", "authors": "Rasmus Pagh, Gil Segev, Udi Wieder", "title": "How to Approximate A Set Without Knowing Its Size In Advance", "comments": "Clarified a point in the lower bound proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamic approximate membership problem asks to represent a set S of size\nn, whose elements are provided in an on-line fashion, supporting membership\nqueries without false negatives and with a false positive rate at most epsilon.\nThat is, the membership algorithm must be correct on each x in S, and may err\nwith probability at most epsilon on each x not in S.\n  We study a well-motivated, yet insufficiently explored, variant of this\nproblem where the size n of the set is not known in advance. Existing optimal\napproximate membership data structures require that the size is known in\nadvance, but in many practical scenarios this is not a realistic assumption.\nMoreover, even if the eventual size n of the set is known in advance, it is\ndesirable to have the smallest possible space usage also when the current\nnumber of inserted elements is smaller than n. Our contribution consists of the\nfollowing results:\n  - We show a super-linear gap between the space complexity when the size is\nknown in advance and the space complexity when the size is not known in\nadvance.\n  - We show that our space lower bound is tight, and can even be matched by a\nhighly efficient data structure.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 21:07:05 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2013 04:12:45 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Pagh", "Rasmus", ""], ["Segev", "Gil", ""], ["Wieder", "Udi", ""]]}, {"id": "1304.1247", "submitter": "Xiaohui Bei", "authors": "Xiaohui Bei, Ning Chen, Shengyu Zhang", "title": "Solving Linear Programming with Constraints Unknown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the value of input information in solving linear programming? The\ncelebrated ellipsoid algorithm tells us that the full information of input\nconstraints is not necessary; the algorithm works as long as there exists an\noracle that, on a proposed candidate solution, returns a violation in the\nformat of a separating hyperplane. Can linear programming still be efficiently\nsolved if the returned violation is in other formats?\n  We study this question in a trial-and-error framework: there is an oracle\nthat, upon a proposed solution, returns the index of a violated constraint\n(with the content of the constraint still hidden). When more than one\nconstraint is violated, two variants in the model are investigated. (1) The\noracle returns the index of a \"most violated\" constraint, measured by the\nEuclidean distance of the proposed solution and the half-spaces defined by the\nconstraints. In this case, the LP can be efficiently solved. (2) The oracle\nreturns the index of an arbitrary (i.e., worst-case) violated constraint. In\nthis case, we give an algorithm with running time exponential in the number of\nvariables. We then show that the exponential dependence on n is unfortunately\nnecessary even for the query complexity. These results put together shed light\non the amount of information that one needs in order to solve a linear program\nefficiently.\n  The proofs of the results employ a variety of geometric techniques, including\nMcMullen's Upper Bound Theorem, the weighted spherical Voronoi diagram, and the\nfurthest Voronoi diagram. In addition, we give an alternative proof to a\nconjecture of L\\'aszl\\'o Fejes T\\'oth on bounding the number of disconnected\ncomponents formed by the union of m convex bodies in R^n. Our proof, inspired\nby the Gauss-Bonnet Theorem in global differential geometry, is independent of\nthe known and reveals more clear insights into the problem and the bound.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 05:32:33 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2013 08:54:51 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Bei", "Xiaohui", ""], ["Chen", "Ning", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1304.1359", "submitter": "He Sun", "authors": "Zeyu Guo and He Sun", "title": "Randomness-Efficient Rumor Spreading", "comments": "This paper has been withdrawn by the author since a more general\n  result is recently posted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the classical rumor spreading problem, which is used to spread\ninformation in an unknown network with $n$ nodes. We present the first protocol\nfor any expander graph $G$ with $n$ nodes and minimum degree $\\Theta(n)$ such\nthat, the protocol informs every node in $O(\\log n)$ rounds with high\nprobability, and uses $O(\\log n\\log\\log n)$ random bits in total. The runtime\nof our protocol is tight, and the randomness requirement of $O(\\log n\\log\\log\nn)$ random bits almost matches the lower bound of $\\Omega(\\log n)$ random bits.\nWe further study rumor spreading protocols for more general graphs, and for\nseveral graph topologies our protocols are as fast as the classical protocol\nand use $\\tilde{O}(\\log n)$ random bits in total, in contrast to $O(n\\log^2n)$\nrandom bits used in the well-known rumor spreading push protocol. These results\ntogether give us almost full understanding of the randomness requirement for\nthis basic epidemic process.\n  Our protocols rely on a novel reduction between rumor spreading processes and\nbranching programs, and this reduction provides a general framework to\nderandomize these complex and distributed epidemic processes. Interestingly,\none cannot simply apply PRGs for branching programs as rumor spreading process\nis not characterized by small-space computation. Our protocols require the\ncomposition of several pseudorandom objects, e.g. pseudorandom generators, and\npairwise independent generators. Besides designing rumor spreading protocols,\nthe techniques developed here may have applications in studying the randomness\ncomplexity of distributed algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 13:22:47 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2013 17:15:29 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Guo", "Zeyu", ""], ["Sun", "He", ""]]}, {"id": "1304.1424", "submitter": "Marek Cygan", "authors": "Marek Cygan", "title": "Improved approximation for 3-dimensional matching via bounded pathwidth\n  local search", "comments": "To appear in proceedings of FOCS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most natural optimization problems is the k-Set Packing problem,\nwhere given a family of sets of size at most k one should select a maximum size\nsubfamily of pairwise disjoint sets. A special case of 3-Set Packing is the\nwell known 3-Dimensional Matching problem. Both problems belong to the Karp`s\nlist of 21 NP-complete problems. The best known polynomial time approximation\nratio for k-Set Packing is (k + eps)/2 and goes back to the work of Hurkens and\nSchrijver [SIDMA`89], which gives (1.5 + eps)-approximation for 3-Dimensional\nMatching. Those results are obtained by a simple local search algorithm, that\nuses constant size swaps.\n  The main result of the paper is a new approach to local search for k-Set\nPacking where only a special type of swaps is considered, which we call swaps\nof bounded pathwidth. We show that for a fixed value of k one can search the\nspace of r-size swaps of constant pathwidth in c^r poly(|F|) time. Moreover we\npresent an analysis proving that a local search maximum with respect to O(log\n|F|)-size swaps of constant pathwidth yields a polynomial time (k + 1 +\neps)/3-approximation algorithm, improving the best known approximation ratio\nfor k-Set Packing. In particular we improve the approximation ratio for\n3-Dimensional Matching from 3/2 + eps to 4/3 + eps.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 16:34:44 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2013 10:05:33 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Cygan", "Marek", ""]]}, {"id": "1304.1449", "submitter": "Lior Kamma", "authors": "Lior Kamma, Robert Krauthgamer, Huy L. Nguyen", "title": "Cutting corners cheaply, or how to remove Steiner points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our main result is that the Steiner Point Removal (SPR) problem can always be\nsolved with polylogarithmic distortion, which answers in the affirmative a\nquestion posed by Chan, Xia, Konjevod, and Richa (2006). Specifically, we prove\nthat for every edge-weighted graph $G = (V,E,w)$ and a subset of terminals $T\n\\subseteq V$, there is a graph $G'=(T,E',w')$ that is isomorphic to a minor of\n$G$, such that for every two terminals $u,v\\in T$, the shortest-path distances\nbetween them in $G$ and in $G'$ satisfy $d_{G,w}(u,v) \\le d_{G',w'}(u,v) \\le\nO(\\log^5|T|) \\cdot d_{G,w}(u,v)$. Our existence proof actually gives a\nrandomized polynomial-time algorithm. Our proof features a new variant of\nmetric decomposition. It is well-known that every $n$-point metric space\n$(X,d)$ admits a $\\beta$-separating decomposition for $\\beta=O(\\log n)$, which\nroughly means for every desired diameter bound $\\Delta>0$ there is a randomized\npartitioning of $X$, which satisfies the following separation requirement: for\nevery $x,y \\in X$, the probability they lie in different clusters of the\npartition is at most $\\beta\\,d(x,y)/\\Delta$. We introduce an additional\nrequirement, which is the following tail bound: for every shortest-path $P$ of\nlength $d(P) \\leq \\Delta/\\beta$, the number of clusters of the partition that\nmeet the path $P$, denoted $Z_P$, satisfies $\\Pr[Z_P > t] \\le 2e^{-\\Omega(t)}$\nfor all $t>0$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 17:55:24 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2015 14:42:02 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Kamma", "Lior", ""], ["Krauthgamer", "Robert", ""], ["Nguyen", "Huy L.", ""]]}, {"id": "1304.1458", "submitter": "Dan Vilenchik", "authors": "Vladimir Braverman and Rafail Ostrovsky and Dan Vilenchik", "title": "How Hard is Counting Triangles in the Streaming Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of (approximately) counting the number of triangles in a graph is\none of the basic problems in graph theory. In this paper we study the problem\nin the streaming model. We study the amount of memory required by a randomized\nalgorithm to solve this problem. In case the algorithm is allowed one pass over\nthe stream, we present a best possible lower bound of $\\Omega(m)$ for graphs\n$G$ with $m$ edges on $n$ vertices. If a constant number of passes is allowed,\nwe show a lower bound of $\\Omega(m/T)$, $T$ the number of triangles. We match,\nin some sense, this lower bound with a 2-pass $O(m/T^{1/3})$-memory algorithm\nthat solves the problem of distinguishing graphs with no triangles from graphs\nwith at least $T$ triangles. We present a new graph parameter $\\rho(G)$ -- the\ntriangle density, and conjecture that the space complexity of the triangles\nproblem is $\\Omega(m/\\rho(G))$. We match this by a second algorithm that solves\nthe distinguishing problem using $O(m/\\rho(G))$-memory.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 18:30:28 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Braverman", "Vladimir", ""], ["Ostrovsky", "Rafail", ""], ["Vilenchik", "Dan", ""]]}, {"id": "1304.1467", "submitter": "Reza Bosagh Zadeh", "authors": "Reza Bosagh Zadeh, Gunnar Carlsson", "title": "Dimension Independent Matrix Square using MapReduce", "comments": "arXiv admin note: text overlap with arXiv:1206.2082", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute the singular values of an $m \\times n$ sparse matrix $A$ in a\ndistributed setting, without communication dependence on $m$, which is useful\nfor very large $m$. In particular, we give a simple nonadaptive sampling scheme\nwhere the singular values of $A$ are estimated within relative error with\nconstant probability. Our proven bounds focus on the MapReduce framework, which\nhas become the de facto tool for handling such large matrices that cannot be\nstored or even streamed through a single machine.\n  On the way, we give a general method to compute $A^TA$. We preserve singular\nvalues of $A^TA$ with $\\epsilon$ relative error with shuffle size\n$O(n^2/\\epsilon^2)$ and reduce-key complexity $O(n/\\epsilon^2)$. We further\nshow that if only specific entries of $A^TA$ are required and $A$ has\nnonnegative entries, then we can reduce the shuffle size to $O(n \\log(n) / s)$\nand reduce-key complexity to $O(\\log(n)/s)$, where $s$ is the minimum cosine\nsimilarity for the entries being estimated. All of our bounds are independent\nof $m$, the larger dimension. We provide open-source implementations in Spark\nand Scalding, along with experiments in an industrial setting.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 18:59:46 GMT"}, {"version": "v2", "created": "Wed, 1 May 2013 04:49:14 GMT"}, {"version": "v3", "created": "Wed, 22 Oct 2014 23:58:58 GMT"}, {"version": "v4", "created": "Thu, 24 Mar 2016 22:43:09 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Zadeh", "Reza Bosagh", ""], ["Carlsson", "Gunnar", ""]]}, {"id": "1304.1577", "submitter": "Chandra Chekuri", "authors": "Chandra Chekuri and Julia Chuzhoy", "title": "Large-Treewidth Graph Decompositions and Applications", "comments": "An extended abstract of the paper is to appear in Proceedings of ACM\n  STOC, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Treewidth is a graph parameter that plays a fundamental role in several\nstructural and algorithmic results. We study the problem of decomposing a given\ngraph $G$ into node-disjoint subgraphs, where each subgraph has sufficiently\nlarge treewidth. We prove two theorems on the tradeoff between the number of\nthe desired subgraphs $h$, and the desired lower bound $r$ on the treewidth of\neach subgraph. The theorems assert that, given a graph $G$ with treewidth $k$,\na decomposition with parameters $h,r$ is feasible whenever $hr^2 \\le\nk/\\polylog(k)$, or $h^3r \\le k/\\polylog(k)$ holds. We then show a framework for\nusing these theorems to bypass the well-known Grid-Minor Theorem of Robertson\nand Seymour in some applications. In particular, this leads to substantially\nimproved parameters in some Erdos-Posa-type results, and faster algorithms for\na class of fixed-parameter tractable problems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 22:42:11 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Chekuri", "Chandra", ""], ["Chuzhoy", "Julia", ""]]}, {"id": "1304.1590", "submitter": "Mong-Jen Kao", "authors": "Jian-Jia Chen, Mong-Jen Kao, D.T. Lee, Ignaz Rutter, and Dorothea\n  Wagner", "title": "Online Power-Managing Strategy with Hard Real-Time Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online dynamic power management that provides hard\nreal-time guarantees. In this problem, each of the given jobs is associated\nwith an arrival time, a deadline, and an execution time, and the objective is\nto decide a schedule of the jobs as well as a sequence of state transitions on\nthe processors so as to minimize the total energy consumption.\n  In this paper, we examine the problem complexity and provide online\nstrategies to achieve energy-efficiency. First, we show that the competitive\nfactor of any online algorithm for this problem is at least 2.06. Then we\npresent an online algorithm which gives a 4-competitive schedule. When the\nexecution times of the jobs are unit, we show that the competitive factor\nimproves to 3.59. At the end, the algorithm is generalized to allow a trade-off\nbetween the number of processors we use and the energy-efficiency of the\nresulting schedule.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 00:58:19 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2013 02:37:18 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Chen", "Jian-Jia", ""], ["Kao", "Mong-Jen", ""], ["Lee", "D. T.", ""], ["Rutter", "Ignaz", ""], ["Wagner", "Dorothea", ""]]}, {"id": "1304.1810", "submitter": "Anastasios Sidiropoulos", "authors": "Jeff Erickson and Anastasios Sidiropoulos", "title": "A near-optimal approximation algorithm for Asymmetric TSP on embedded\n  graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a near-optimal polynomial-time approximation algorithm for the\nasymmetric traveling salesman problem for graphs of bounded orientable or\nnon-orientable genus. Our algorithm achieves an approximation factor of O(f(g))\non graphs with genus g, where f(n) is the best approximation factor achievable\nin polynomial time on arbitrary n-vertex graphs. In particular, the\nO(log(n)/loglog(n))-approximation algorithm for general graphs by Asadpour et\nal. [SODA 2010] immediately implies an O(log(g)/loglog(g))-approximation\nalgorithm for genus-g graphs. Our result improves the\nO(sqrt(g)*log(g))-approximation algorithm of Oveis Gharan and Saberi [SODA\n2011], which applies only to graphs with orientable genus g; ours is the first\napproximation algorithm for graphs with bounded non-orientable genus.\n  Moreover, using recent progress on approximating the genus of a graph, our\nO(log(g) / loglog(g))-approximation can be implemented even without an\nembedding when the input graph has bounded degree. In contrast, the\nO(sqrt(g)*log(g))-approximation algorithm of Oveis Gharan and Saberi requires a\ngenus-g embedding as part of the input.\n  Finally, our techniques lead to a O(1)-approximation algorithm for ATSP on\ngraphs of genus g, with running time 2^O(g)*n^O(1).\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 20:06:28 GMT"}, {"version": "v2", "created": "Fri, 10 May 2013 21:48:37 GMT"}], "update_date": "2013-05-14", "authors_parsed": [["Erickson", "Jeff", ""], ["Sidiropoulos", "Anastasios", ""]]}, {"id": "1304.1881", "submitter": "J\\'er\\'emie Lumbroso", "authors": "Olivier Bodini and J\\'er\\'emie Lumbroso and Nicolas Rolin", "title": "Analytic Samplers and the Combinatorial Rejection Method", "comments": "accepted at ANALCO 2015, 11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann samplers, introduced by Duchon et al. in 2001, make it possible to\nuniformly draw approximate size objects from any class which can be specified\nthrough the symbolic method. This, through by evaluating the associated\ngenerating functions to obtain the correct branching probabilities.\n  But these samplers require generating functions, in particular in the\nneighborhood of their sunglarity, which is a complex problem; they also require\npicking an appropriate tuning value to best control the size of generated\nobjects. Although Pivoteau~\\etal have brought a sweeping question to the first\nquestion, with the introduction of their Newton oracle, questions remain.\n  By adapting the rejection method, a classical tool from the random, we show\nhow to obtain a variant of the Boltzmann sampler framework, which is tolerant\nof approximation, even large ones. Our goal for this is twofold: this allows\nfor exact sampling with approximate values; but this also allows much more\nflexibility in tuning samplers. For the class of simple trees, we will try to\nshow how this could be used to more easily calibrate samplers.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2013 11:48:33 GMT"}, {"version": "v2", "created": "Mon, 8 Sep 2014 18:17:33 GMT"}, {"version": "v3", "created": "Thu, 13 Nov 2014 02:09:58 GMT"}], "update_date": "2014-11-14", "authors_parsed": [["Bodini", "Olivier", ""], ["Lumbroso", "J\u00e9r\u00e9mie", ""], ["Rolin", "Nicolas", ""]]}, {"id": "1304.1916", "submitter": "J\\'er\\'emie Lumbroso", "authors": "J\\'er\\'emie Lumbroso", "title": "Optimal Discrete Uniform Generation from Coin Flips, and Applications", "comments": "first draft, 22 pages, 5 figures, C code implementation of algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces an algorithm to draw random discrete uniform\nvariables within a given range of size n from a source of random bits. The\nalgorithm aims to be simple to implement and optimal both with regards to the\namount of random bits consumed, and from a computational perspective---allowing\nfor faster and more efficient Monte-Carlo simulations in computational physics\nand biology. I also provide a detailed analysis of the number of bits that are\nspent per variate, and offer some extensions and applications, in particular to\nthe optimal random generation of permutations.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2013 17:38:04 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Lumbroso", "J\u00e9r\u00e9mie", ""]]}, {"id": "1304.2060", "submitter": "Shayan Oveis Gharan", "authors": "Shayan Oveis Gharan and Luca Trevisan", "title": "Improved ARV Rounding in Small-set Expanders and Graphs of Bounded\n  Threshold Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a structure theorem for the feasible solutions of the\nArora-Rao-Vazirani SDP relaxation on low threshold rank graphs and on small-set\nexpanders. We show that if G is a graph of bounded threshold rank or a\nsmall-set expander, then an optimal solution of the Arora-Rao-Vazirani\nrelaxation (or of any stronger version of it) can be almost entirely covered by\na small number of balls of bounded radius.\n  Then, we show that, if k is the number of balls, a solution of this form can\nbe rounded with an approximation factor of O(sqrt {log k}) in the case of the\nArora-Rao-Vazirani relaxation, and with a constant-factor approximation in the\ncase of the k-th round of the Sherali-Adams hierarchy starting at the\nArora-Rao-Vazirani relaxation.\n  The structure theorem and the rounding scheme combine to prove the following\nresult, where G=(V,E) is a graph of expansion \\phi(G), \\lambda_k is the k-th\nsmallest eigenvalue of the normalized Laplacian of G, and \\phi_k(G) =\n\\min_{disjoint S_1,...,S_k} \\max_{1 <= i <= k} \\phi(S_i) is the largest\nexpansion of any k disjoint subsets of V: if either \\lambda_k >> log^{2.5} k\n\\cdot phi(G) or \\phi_{k} (G) >> log k \\cdot sqrt{log n}\\cdot loglog n\\cdot\n\\phi(G), then the Arora-Rao-Vazirani relaxation can be rounded in polynomial\ntime with an approximation ratio O(sqrt{log k}).\n  Stronger approximation guarantees are achievable in time exponential in k via\nrelaxations in the Lasserre hierarchy. Guruswami and Sinop [GS13] and Arora, Ge\nand Sinop [AGS13] prove that 1+eps approximation is achievable in time 2^{O(k)}\npoly(n) if either \\lambda_k > \\phi(G)/ poly(eps), or if SSE_{n/k} > sqrt{log k\nlog n} \\cdot \\phi(G)/ poly(eps), where SSE_s is the minimal expansion of sets\nof size at most s.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2013 21:07:08 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2013 04:56:41 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Gharan", "Shayan Oveis", ""], ["Trevisan", "Luca", ""]]}, {"id": "1304.2077", "submitter": "Jonah Sherman", "authors": "Jonah Sherman", "title": "Nearly Maximum Flows in Nearly Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach to the maximum flow problem in undirected,\ncapacitated graphs using $\\alpha$-\\emph{congestion-approximators}:\neasy-to-compute functions that approximate the congestion required to route\nsingle-commodity demands in a graph to within a factor of $\\alpha$. Our\nalgorithm maintains an arbitrary flow that may have some residual excess and\ndeficits, while taking steps to minimize a potential function measuring the\ncongestion of the current flow plus an over-estimate of the congestion required\nto route the residual demand. Since the residual term over-estimates, the\ndescent process gradually moves the contribution to our potential function from\nthe residual term to the congestion term, eventually achieving a flow routing\nthe desired demands with nearly minimal congestion after\n$\\tilde{O}(\\alpha\\eps^{-2}\\log^2 n)$ iterations. Our approach is similar in\nspirit to that used by Spielman and Teng (STOC 2004) for solving Laplacian\nsystems, and we summarize our approach as trying to do for $\\ell_\\infty$-flows\nwhat they do for $\\ell_2$-flows.\n  Together with a nearly linear time construction of a\n$n^{o(1)}$-congestion-approximator, we obtain $1+\\eps$-optimal single-commodity\nflows undirected graphs in time $m^{1+o(1)}\\eps^{-2}$, yielding the fastest\nknown algorithm for that problem. Our requirements of a congestion-approximator\nare quite low, suggesting even faster and simpler algorithms for certain\nclasses of graphs. For example, an $\\alpha$-competitive oblivious routing tree\nmeets our definition, \\emph{even without knowing how to route the tree back in\nthe graph}. For graphs of conductance $\\phi$, a trivial\n$\\phi^{-1}$-congestion-approximator gives an extremely simple algorithm for\nfinding $1+\\eps$-optimal-flows in time $\\tilde{O}(m\\phi^{-1})$.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2013 23:42:35 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Sherman", "Jonah", ""]]}, {"id": "1304.2079", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Pravesh Kothari", "title": "Learning Coverage Functions and Private Release of Marginals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximating and learning coverage functions. A\nfunction $c: 2^{[n]} \\rightarrow \\mathbf{R}^{+}$ is a coverage function, if\nthere exists a universe $U$ with non-negative weights $w(u)$ for each $u \\in U$\nand subsets $A_1, A_2, \\ldots, A_n$ of $U$ such that $c(S) = \\sum_{u \\in\n\\cup_{i \\in S} A_i} w(u)$. Alternatively, coverage functions can be described\nas non-negative linear combinations of monotone disjunctions. They are a\nnatural subclass of submodular functions and arise in a number of applications.\n  We give an algorithm that for any $\\gamma,\\delta>0$, given random and uniform\nexamples of an unknown coverage function $c$, finds a function $h$ that\napproximates $c$ within factor $1+\\gamma$ on all but $\\delta$-fraction of the\npoints in time $poly(n,1/\\gamma,1/\\delta)$. This is the first fully-polynomial\nalgorithm for learning an interesting class of functions in the demanding PMAC\nmodel of Balcan and Harvey (2011). Our algorithms are based on several new\nstructural properties of coverage functions. Using the results in (Feldman and\nKothari, 2014), we also show that coverage functions are learnable agnostically\nwith excess $\\ell_1$-error $\\epsilon$ over all product and symmetric\ndistributions in time $n^{\\log(1/\\epsilon)}$. In contrast, we show that,\nwithout assumptions on the distribution, learning coverage functions is at\nleast as hard as learning polynomial-size disjoint DNF formulas, a class of\nfunctions for which the best known algorithm runs in time\n$2^{\\tilde{O}(n^{1/3})}$ (Klivans and Servedio, 2004).\n  As an application of our learning results, we give simple\ndifferentially-private algorithms for releasing monotone conjunction counting\nqueries with low average error. In particular, for any $k \\leq n$, we obtain\nprivate release of $k$-way marginals with average error $\\bar{\\alpha}$ in time\n$n^{O(\\log(1/\\bar{\\alpha}))}$.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2013 00:06:26 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2013 23:42:11 GMT"}, {"version": "v3", "created": "Wed, 28 May 2014 00:38:46 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Feldman", "Vitaly", ""], ["Kothari", "Pravesh", ""]]}, {"id": "1304.2110", "submitter": "M.M.A. Hashem", "authors": "Md. Mizanur Rahman, Md. Shahadat Hossain, Md. Rakib Hasan and M.M.A.\n  Hashem", "title": "An Improved GEF Fast Addition Algorithm", "comments": null, "journal-ref": "Procs. of the 3rd International Conference on Electrical and\n  Computer Engineering (ICECE 2004), pp. 613-616, Dhaka, Bangladesh, December\n  28-30, (2004)", "doi": null, "report-no": null, "categories": "cs.DS cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an improved GEF fast addition algorithm is proposed. The\nproposed algorithm reduces time and memory space. In this algorithm, carry is\ncalculated on the basis of arrival timing of the operand's bits without\noverhead of sorting. Intermediate terms are generated from the most significant\nbit and the carry is generated from the least significant bit using the\nfunctions of efficient operators. This algorithm shows better performance for\nuse in the fastest computational devices of the near future.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2013 06:22:59 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Rahman", "Md. Mizanur", ""], ["Hossain", "Md. Shahadat", ""], ["Hasan", "Md. Rakib", ""], ["Hashem", "M. M. A.", ""]]}, {"id": "1304.2112", "submitter": "M.M.A. Hashem", "authors": "Md. Nazrul Islam, M.M.A. Hashem and A. M. Moshiur Rahman", "title": "A Probabilistic Algorithm for Reducing Broadcast Redundancy in Ad Hoc\n  Wireless Networks", "comments": null, "journal-ref": "Procs. of the 8th International Conference on Computer &\n  Information Technology (ICCIT 2005), pp. 752-757, Dhaka, Bangladesh, December\n  28-30, (2005)", "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a wired network, a packet can be transmitted to a specified destination\nonly, no broadcasting required. But in ad hoc wireless network a packet\ntransmitted by a node can reach all neighbors due to broadcasting. This\nbroadcasting introduces unnecessary retransmissions of same message. Therefore,\nthe total number of transmissions (forward nodes) is generally used as the cost\ncriterion for broadcasting. The problem of finding the minimum number of\nforward nodes is NP-complete. In this paper, the goal is to reduce the number\nof forward nodes which will reduce redundant transmission as a result. Thus\nsome of approximation approaches are analyzed, especially dominant pruning and\ntotal dominant pruning which use 2-hop neighborhood information and a new\napproach: Probability based algorithm is proposed with a view to minimizing\nnumber of forward nodes. Simulation results of applying this algorithm shows\nperformance improvements with compared to dominant pruning and total dominant\npruning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2013 06:35:33 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Islam", "Md. Nazrul", ""], ["Hashem", "M. M. A.", ""], ["Rahman", "A. M. Moshiur", ""]]}, {"id": "1304.2144", "submitter": "Xuejun Huangfu", "authors": "Jianbin Huang, Xuejun Huangfu, Heli Sun, Hong Cheng and Qinbao Song", "title": "Backward Path Growth for Efficient Mobile Sequential Recommendation", "comments": "28 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of mobile sequential recommendation is presented to suggest a\nroute connecting some pick-up points for a taxi driver so that he/she is more\nlikely to get passengers with less travel cost. Essentially, a key challenge of\nthis problem is its high computational complexity. In this paper, we propose a\ndynamical programming based method to solve this problem. Our method consists\nof two separate stages: an offline pre-processing stage and an online search\nstage. The offline stage pre-computes optimal potential sequence candidates\nfrom a set of pick-up points, and the online stage selects the optimal driving\nroute based on the pre-computed sequences with the current position of an empty\ntaxi. Specifically, for the offline pre-computation, a backward incremental\nsequence generation algorithm is proposed based on the iterative property of\nthe cost function. Simultaneously, an incremental pruning policy is adopted in\nthe process of sequence generation to reduce the search space of the potential\nsequences effectively. In addition, a batch pruning algorithm can also be\napplied to the generated potential sequences to remove the non-optimal ones of\na certain length. Since the pruning effect continuously increases with the\nincrease of the sequence length, our method can search the optimal driving\nroute efficiently in the remaining potential sequence candidates. Experimental\nresults on real and synthetic data sets show that the pruning percentage of our\nmethod is significantly improved compared to the state-of-the-art methods,\nwhich makes our method can be used to handle the problem of mobile sequential\nrecommendation with more pick-up points and to search the optimal driving\nroutes in arbitrary length ranges.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2013 09:35:46 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Huang", "Jianbin", ""], ["Huangfu", "Xuejun", ""], ["Sun", "Heli", ""], ["Cheng", "Hong", ""], ["Song", "Qinbao", ""]]}, {"id": "1304.2338", "submitter": "Aaron Sidford", "authors": "Jonathan A. Kelner, Yin Tat Lee, Lorenzo Orecchia, Aaron Sidford", "title": "An Almost-Linear-Time Algorithm for Approximate Max Flow in Undirected\n  Graphs, and its Multicommodity Generalizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new framework for approximately solving flow\nproblems in capacitated, undirected graphs and apply it to provide\nasymptotically faster algorithms for the maximum $s$-$t$ flow and maximum\nconcurrent multicommodity flow problems. For graphs with $n$ vertices and $m$\nedges, it allows us to find an $\\epsilon$-approximate maximum $s$-$t$ flow in\ntime $O(m^{1+o(1)}\\epsilon^{-2})$, improving on the previous best bound of\n$\\tilde{O}(mn^{1/3} poly(1/\\epsilon))$. Applying the same framework in the\nmulticommodity setting solves a maximum concurrent multicommodity flow problem\nwith $k$ commodities in $O(m^{1+o(1)}\\epsilon^{-2}k^2)$ time, improving on the\nexisting bound of $\\tilde{O}(m^{4/3} poly(k,\\epsilon^{-1})$.\n  Our algorithms utilize several new technical tools that we believe may be of\nindependent interest:\n  - We give a non-Euclidean generalization of gradient descent and provide\nbounds on its performance. Using this, we show how to reduce approximate\nmaximum flow and maximum concurrent flow to the efficient construction of\noblivious routings with a low competitive ratio.\n  - We define and provide an efficient construction of a new type of flow\nsparsifier. In addition to providing the standard properties of a cut\nsparsifier our construction allows for flows in the sparse graph to be routed\n(very efficiently) in the original graph with low congestion.\n  - We give the first almost-linear-time construction of an\n$O(m^{o(1)})$-competitive oblivious routing scheme. No previous such algorithm\nran in time better than $\\tilde{{\\Omega}}(mn)$.\n  We also note that independently Jonah Sherman produced an almost linear time\nalgorithm for maximum flow and we thank him for coordinating submissions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2013 20:06:45 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2013 17:41:00 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Kelner", "Jonathan A.", ""], ["Lee", "Yin Tat", ""], ["Orecchia", "Lorenzo", ""], ["Sidford", "Aaron", ""]]}, {"id": "1304.2416", "submitter": "Anastasios Sidiropoulos", "authors": "Chandra Chekuri and Anastasios Sidiropoulos", "title": "Approximation algorithms for Euler genus and related problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euler genus of a graph is a fundamental and well-studied parameter in\ngraph theory and topology. Computing it has been shown to be NP-hard by\n[Thomassen '89 & '93], and it is known to be fixed-parameter tractable.\nHowever, the approximability of the Euler genus is wide open. While the\nexistence of an O(1)-approximation is not ruled out, only an\nO(sqrt(n))-approximation [Chen, Kanchi, Kanevsky '97] is known even in bounded\ndegree graphs. In this paper we give a polynomial-time algorithm which on input\na bounded-degree graph of Euler genus g, computes a drawing into a surface of\nEuler genus poly(g, log(n)). Combined with the upper bound from [Chen, Kanchi,\nKanevsky '97], our result also implies a O(n^(1/2 - alpha))-approximation, for\nsome constant alpha>0.\n  Using our algorithm for approximating the Euler genus as a subroutine, we\nobtain, in a unified fashion, algorithms with approximation ratios of the form\npoly(OPT, log(n)) for several related problems on bounded degree graphs. These\ninclude the problems of orientable genus, crossing number, and planar edge and\nvertex deletion problems. Our algorithm and proof of correctness for the\ncrossing number problem is simpler compared to the long and difficult proof in\nthe recent breakthrough by [Chuzhoy 2011], while essentially obtaining a\nqualitatively similar result. For planar edge and vertex deletion problems our\nresults are the first to obtain a bound of form poly(OPT, log(n)).\n  We also highlight some further applications of our results in the design of\nalgorithms for graphs with small genus. Many such algorithms require that a\ndrawing of the graph is given as part of the input. Our results imply that in\nseveral interesting cases, we can implement such algorithms even when the\ndrawing is unknown.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2013 20:37:36 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2013 06:19:06 GMT"}], "update_date": "2013-11-04", "authors_parsed": [["Chekuri", "Chandra", ""], ["Sidiropoulos", "Anastasios", ""]]}, {"id": "1304.2576", "submitter": "Xiaokui Xiao", "authors": "Andy Diwen Zhu, Hui Ma, Xiaokui Xiao, Siqiang Luo, Youze Tang,\n  Shuigeng Zhou", "title": "Shortest Path and Distance Queries on Road Networks: Towards Bridging\n  Theory and Practice", "comments": "to appear in SIGMOD 2013. Table 1 updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two locations $s$ and $t$ in a road network, a distance query returns\nthe minimum network distance from $s$ to $t$, while a shortest path query\ncomputes the actual route that achieves the minimum distance. These two types\nof queries find important applications in practice, and a plethora of solutions\nhave been proposed in past few decades. The existing solutions, however, are\noptimized for either practical or asymptotic performance, but not both. In\nparticular, the techniques with enhanced practical efficiency are mostly\nheuristic-based, and they offer unattractive worst-case guarantees in terms of\nspace and time. On the other hand, the methods that are worst-case efficient\noften entail prohibitive preprocessing or space overheads, which render them\ninapplicable for the large road networks (with millions of nodes) commonly used\nin modern map applications.\n  This paper presents {\\em Arterial Hierarchy (AH)}, an index structure that\nnarrows the gap between theory and practice in answering shortest path and\ndistance queries on road networks. On the theoretical side, we show that, under\na realistic assumption, AH answers any distance query in $\\tilde{O}(\\log \\r)$\ntime, where $\\r = d_{max}/d_{min}$, and $d_{max}$ (resp.\\ $d_{min}$) is the\nlargest (resp.\\ smallest) $L_\\infty$ distance between any two nodes in the road\nnetwork. In addition, any shortest path query can be answered in $\\tilde{O}(k +\n\\log \\r)$ time, where $k$ is the number of nodes on the shortest path. On the\npractical side, we experimentally evaluate AH on a large set of real road\nnetworks with up to twenty million nodes, and we demonstrate that (i) AH\noutperforms the state of the art in terms of query time, and (ii) its space and\npre-computation overheads are moderate.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2013 13:14:38 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2013 13:38:37 GMT"}], "update_date": "2013-04-25", "authors_parsed": [["Zhu", "Andy Diwen", ""], ["Ma", "Hui", ""], ["Xiao", "Xiaokui", ""], ["Luo", "Siqiang", ""], ["Tang", "Youze", ""], ["Zhou", "Shuigeng", ""]]}, {"id": "1304.2641", "submitter": "Jin-Kao Hao", "authors": "Yan Jin, Jin-Kao Hao and Jean-Philippe Hamiez", "title": "A memetic algorithm for the minimum sum coloring problem", "comments": "Submitted manuscript", "journal-ref": "Computers & Operations Research 43(3): 318-327, 2014", "doi": "10.1016/j.cor.2013.09.019", "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected graph $G$, the Minimum Sum Coloring problem (MSCP) is to\nfind a legal assignment of colors (represented by natural numbers) to each\nvertex of $G$ such that the total sum of the colors assigned to the vertices is\nminimized. This paper presents a memetic algorithm for MSCP based on a tabu\nsearch procedure with two neighborhoods and a multi-parent crossover operator.\nExperiments on a set of 77 well-known DIMACS and COLOR 2002-2004 benchmark\ninstances show that the proposed algorithm achieves highly competitive results\nin comparison with five state-of-the-art algorithms. In particular, the\nproposed algorithm can improve the best known results for 17 instances. We also\nprovide upper bounds for 18 additional instances for the first time.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2013 15:54:53 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Jin", "Yan", ""], ["Hao", "Jin-Kao", ""], ["Hamiez", "Jean-Philippe", ""]]}, {"id": "1304.2881", "submitter": "\\\"Omer Demirel", "authors": "\\\"Omer Demirel and Ivo F. Sbalzarini", "title": "Balanced offline allocation of weighted balls into bins", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a sorting-based greedy algorithm called SortedGreedy[m] for\napproximately solving the offline version of the d-choice weighted\nballs-into-bins problem where the number of choices for each ball is equal to\nthe number of bins. We assume the ball weights to be non-negative. We compare\nthe performance of the sorting-based algorithm with a naive algorithm called\nGreedy[m]. We show that by sorting the input data according to the weights we\nare able to achieve an order of magnitude smaller gap (the weight difference\nbetween the heaviest and the lightest bin) for small problems (<= 4000 balls),\nand at least two orders of magnitude smaller gap for larger problems. In\npractice, SortedGreedy[m] runs almost as fast as Greedy[m]. This makes\nsorting-based algorithms favorable for solving offline weighted balls-into-bins\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2013 09:08:34 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Demirel", "\u00d6mer", ""], ["Sbalzarini", "Ivo F.", ""]]}, {"id": "1304.2983", "submitter": "Hyung-Chan An", "authors": "Hyung-Chan An, Aditya Bhaskara, Ola Svensson", "title": "Centrality of Trees for Capacitated k-Center", "comments": "21 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a large discrepancy in our understanding of uncapacitated and\ncapacitated versions of network location problems. This is perhaps best\nillustrated by the classical k-center problem: there is a simple tight\n2-approximation algorithm for the uncapacitated version whereas the first\nconstant factor approximation algorithm for the general version with capacities\nwas only recently obtained by using an intricate rounding algorithm that\nachieves an approximation guarantee in the hundreds.\n  Our paper aims to bridge this discrepancy. For the capacitated k-center\nproblem, we give a simple algorithm with a clean analysis that allows us to\nprove an approximation guarantee of 9. It uses the standard LP relaxation and\ncomes close to settling the integrality gap (after necessary preprocessing),\nwhich is narrowed down to either 7, 8 or 9. The algorithm proceeds by first\nreducing to special tree instances, and then solves such instances optimally.\nOur concept of tree instances is quite versatile, and applies to natural\nvariants of the capacitated k-center problem for which we also obtain improved\nalgorithms. Finally, we give evidence to show that more powerful preprocessing\ncould lead to better algorithms, by giving an approximation algorithm that\nbeats the integrality gap for instances where all non-zero capacities are\nuniform.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2013 14:50:12 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["An", "Hyung-Chan", ""], ["Bhaskara", "Aditya", ""], ["Svensson", "Ola", ""]]}, {"id": "1304.3145", "submitter": "Yongjie Yang", "authors": "Yongjie Yang and Jiong Guo", "title": "Exact Algorithms for Weighted and Unweighted Borda Manipulation Problems", "comments": "9 pages, 3 figures, a short version appears in AAMAS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both weighted and unweighted Borda manipulation problems have been proved\n$\\mathcal{NP}$-hard. However, there is no exact combinatorial algorithm known\nfor these problems. In this paper, we initiate the study of exact combinatorial\nalgorithms for both weighted and unweighted Borda manipulation problems. More\nprecisely, we propose $O^*((m\\cdot 2^m)^{t+1})$time and\n$O^*(t^{2m})$time\\footnote{$O^*()$ is the $O()$ notation with suppressed\nfactors polynomial in the size of the input.} combinatorial algorithms for\nweighted and unweighted Borda manipulation problems, respectively, where $t$ is\nthe number of manipulators and $m$ is the number of candidates. Thus, for $t=2$\nwe solve one of the open problems posted by Betzler et al. [IJCAI 2011]. As a\nbyproduct of our results, we show that the {{unweighted Borda manipulation}}\nproblem admits an algorithm of running time $O^*(2^{9m^2\\log{m}})$, based on an\ninteger linear programming technique. Finally, we study the {{unweighted Borda\nmanipulation}} problem under single-peaked elections and present\npolynomial-time algorithms for the problem in the case of two manipulators, in\ncontrast to the $\\mathcal{NP}$-hardness of this case in general settings.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2013 21:05:08 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Yang", "Yongjie", ""], ["Guo", "Jiong", ""]]}, {"id": "1304.3162", "submitter": "Santosh Vempala", "authors": "Ravindran Kannan and Santosh Vempala and David Woodruff", "title": "Principal Component Analysis and Higher Correlations for Distributed\n  Data", "comments": "rewritten with focus on two main results (distributed PCA,\n  higher-order moments and correlations) in the arbitrary partition model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider algorithmic problems in the setting in which the input data has\nbeen partitioned arbitrarily on many servers. The goal is to compute a function\nof all the data, and the bottleneck is the communication used by the algorithm.\nWe present algorithms for two illustrative problems on massive data sets: (1)\ncomputing a low-rank approximation of a matrix $A=A^1 + A^2 + \\ldots + A^s$,\nwith matrix $A^t$ stored on server $t$ and (2) computing a function of a vector\n$a_1 + a_2 + \\ldots + a_s$, where server $t$ has the vector $a_t$; this\nincludes the well-studied special case of computing frequency moments and\nseparable functions, as well as higher-order correlations such as the number of\nsubgraphs of a specified type occurring in a graph. For both problems we give\nalgorithms with nearly optimal communication, and in particular the only\ndependence on $n$, the size of the data, is in the number of bits needed to\nrepresent indices and words ($O(\\log n)$).\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2013 23:05:01 GMT"}, {"version": "v2", "created": "Mon, 20 May 2013 09:51:00 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2013 13:54:22 GMT"}, {"version": "v4", "created": "Sun, 29 Jun 2014 13:42:24 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Kannan", "Ravindran", ""], ["Vempala", "Santosh", ""], ["Woodruff", "David", ""]]}, {"id": "1304.3172", "submitter": "Toshiya Itoh", "authors": "Toshiya Itoh and Seiji Yoshimoto", "title": "Buffer Management of Multi-Queue QoS Switches with Class Segregation", "comments": "12 pages, 2 tables, 2 figures. arXiv admin note: substantial text\n  overlap with arXiv:1109.6060", "journal-ref": null, "doi": "10.1016/j.tcs.2015.04.010", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on buffer management of multi-queue QoS switches in\nwhich packets of different values are segregated in different queues. Our model\nconsists of $m$ queues and $m$ packet values $0 < v_{1} < v_{2} < ... < v_{m}$.\nRecently, Al-Bawani and Souza [IPL 113(4), pp.145-150, 2013] presented an\nonline algorithm GREEDY for buffer management of multi-queue QoS switches with\nclass segregation and showed thatif $m$ queues have the same size, then the\ncompetitive ratio of GREEDY is $1+r$, where $r=\\max_{1 \\leq i \\leq m-1}\nv_{i}/v_{i+1}$. In this paper, we precisely analyze the behavior of GREEDY and\nshow that it is $(1+r)$-competitive for the case that $m$ queues do not\nnecessarily have the same size.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2013 00:49:18 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 09:24:20 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2013 03:39:00 GMT"}, {"version": "v4", "created": "Fri, 3 May 2013 02:23:44 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Itoh", "Toshiya", ""], ["Yoshimoto", "Seiji", ""]]}, {"id": "1304.3365", "submitter": "Ali Sinop", "authors": "Sanjeev Arora and Rong Ge and Ali Kemal Sinop", "title": "Towards a better approximation for sparsest cut?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new $(1+\\epsilon)$-approximation for sparsest cut problem on graphs\nwhere small sets expand significantly more than the sparsest cut (sets of size\n$n/r$ expand by a factor $\\sqrt{\\log n\\log r}$ bigger, for some small $r$; this\ncondition holds for many natural graph families). We give two different\nalgorithms. One involves Guruswami-Sinop rounding on the level-$r$ Lasserre\nrelaxation. The other is combinatorial and involves a new notion called {\\em\nSmall Set Expander Flows} (inspired by the {\\em expander flows} of ARV) which\nwe show exists in the input graph. Both algorithms run in time $2^{O(r)}\n\\mathrm{poly}(n)$. We also show similar approximation algorithms in graphs with\ngenus $g$ with an analogous local expansion condition. This is the first\nalgorithm we know of that achieves $(1+\\epsilon)$-approximation on such general\nfamily of graphs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2013 16:51:07 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Sinop", "Ali Kemal", ""]]}, {"id": "1304.3541", "submitter": "Ramin Maazallahi", "authors": "Ramin Maazallahi and Aliakbar Niknafs", "title": "A modified dna computing approach to tackle the exponential solution\n  space of the graph coloring problem", "comments": "7 pages, 3 figures, 1 table, International Journal in Foundations of\n  Computer Science & Technology (IJFCST), Vol. 3, No.2, March 2013", "journal-ref": "International Journal in Foundations of Computer Science &\n  Technology (IJFCST), Vol. 3, No.2, March 2013", "doi": "10.5121/ijfcst.2013.3201", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although it has been evidenced that DNA computing is able to solve the graph\ncoloring problem in a polynomial time complexity, but the exponential solution\nspace is still a restrictive factor in applying this technique for solving\nreally large problems. In this paper a modified DNA computing approach based on\nAdleman-Lipton model is proposed which tackles the mentioned restriction by\ncoloring the vertices one by one. In each step, it expands the DNA strands\nencoding promising solutions and discards those which encode infeasible ones. A\nsample graph is colored by simulating the proposed approach and shows a notable\nreduction in the number of DNA strands used.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2013 05:34:44 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Maazallahi", "Ramin", ""], ["Niknafs", "Aliakbar", ""]]}, {"id": "1304.3604", "submitter": "Ilya Razenshteyn", "authors": "Piotr Indyk, Ilya Razenshteyn", "title": "On Model-Based RIP-1 Matrices", "comments": "Version 3 corrects a few errors present in the earlier version. In\n  particular, it states and proves correct upper and lower bounds for the\n  number of rows in RIP-1 matrices for the block-sparse model. The bounds are\n  of the form k log_b n, not k log_k n as stated in the earlier version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Restricted Isometry Property (RIP) is a fundamental property of a matrix\nenabling sparse recovery. Informally, an m x n matrix satisfies RIP of order k\nin the l_p norm if ||Ax||_p \\approx ||x||_p for any vector x that is k-sparse,\ni.e., that has at most k non-zeros. The minimal number of rows m necessary for\nthe property to hold has been extensively investigated, and tight bounds are\nknown. Motivated by signal processing models, a recent work of Baraniuk et al\nhas generalized this notion to the case where the support of x must belong to a\ngiven model, i.e., a given family of supports. This more general notion is much\nless understood, especially for norms other than l_2. In this paper we present\ntight bounds for the model-based RIP property in the l_1 norm. Our bounds hold\nfor the two most frequently investigated models: tree-sparsity and\nblock-sparsity. We also show implications of our results to sparse recovery\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2013 11:05:51 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2013 19:03:01 GMT"}, {"version": "v3", "created": "Sat, 26 Apr 2014 03:16:31 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Indyk", "Piotr", ""], ["Razenshteyn", "Ilya", ""]]}, {"id": "1304.3653", "submitter": "Binhai Zhu", "authors": "Iyad Kanj, Guohui Lin, Tian Liu, Weitian Tong, Ge Xia, Jinhui Xu,\n  Boting Yang, Fenghui Zhang, Peng Zhang, Binhai Zhu", "title": "Algorithms for Cut Problems on Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the {\\sc multicut on trees} and the {\\sc generalized multiway Cut on\ntrees} problems. For the {\\sc multicut on trees} problem, we present a\nparameterized algorithm that runs in time $O^{*}(\\rho^k)$, where $\\rho =\n\\sqrt{\\sqrt{2} + 1} \\approx 1.555$ is the positive root of the polynomial\n$x^4-2x^2-1$. This improves the current-best algorithm of Chen et al. that runs\nin time $O^{*}(1.619^k)$. For the {\\sc generalized multiway cut on trees}\nproblem, we show that this problem is solvable in polynomial time if the number\nof terminal sets is fixed; this answers an open question posed in a recent\npaper by Liu and Zhang. By reducing the {\\sc generalized multiway cut on trees}\nproblem to the {\\sc multicut on trees} problem, our results give a\nparameterized algorithm that solves the {\\sc generalized multiway cut on trees}\nproblem in time $O^{*}(\\rho^k)$, where $\\rho = \\sqrt{\\sqrt{2} + 1} \\approx\n1.555$ time.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2013 14:57:47 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Kanj", "Iyad", ""], ["Lin", "Guohui", ""], ["Liu", "Tian", ""], ["Tong", "Weitian", ""], ["Xia", "Ge", ""], ["Xu", "Jinhui", ""], ["Yang", "Boting", ""], ["Zhang", "Fenghui", ""], ["Zhang", "Peng", ""], ["Zhu", "Binhai", ""]]}, {"id": "1304.3754", "submitter": "Jonathan Ullman", "authors": "Karthekeyan Chandrasekaran, Justin Thaler, Jonathan Ullman, Andrew Wan", "title": "Faster Private Release of Marginals on Small Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of answering \\emph{$k$-way marginal} queries on a\ndatabase $D \\in (\\{0,1\\}^d)^n$, while preserving differential privacy. The\nanswer to a $k$-way marginal query is the fraction of the database's records $x\n\\in \\{0,1\\}^d$ with a given value in each of a given set of up to $k$ columns.\nMarginal queries enable a rich class of statistical analyses on a dataset, and\ndesigning efficient algorithms for privately answering marginal queries has\nbeen identified as an important open problem in private data analysis.\n  For any $k$, we give a differentially private online algorithm that runs in\ntime $$ \\min{\\exp(d^{1-\\Omega(1/\\sqrt{k})}), \\exp(d / \\log^{.99} d)\\} $$ per\nquery and answers any (possibly superpolynomially long and adaptively chosen)\nsequence of $k$-way marginal queries up to error at most $\\pm .01$ on every\nquery, provided $n \\gtrsim d^{.51} $. To the best of our knowledge, this is the\nfirst algorithm capable of privately answering marginal queries with a\nnon-trivial worst-case accuracy guarantee on a database of size $\\poly(d, k)$\nin time $\\exp(o(d))$.\n  Our algorithms are a variant of the private multiplicative weights algorithm\n(Hardt and Rothblum, FOCS '10), but using a different low-weight representation\nof the database. We derive our low-weight representation using approximations\nto the OR function by low-degree polynomials with coefficients of bounded\n$L_1$-norm. We also prove a strong limitation on our approach that is of\nindependent approximation-theoretic interest. Specifically, we show that for\nany $k = o(\\log d)$, any polynomial with coefficients of $L_1$-norm $poly(d)$\nthat pointwise approximates the $d$-variate OR function on all inputs of\nHamming weight at most $k$ must have degree $d^{1-O(1/\\sqrt{k})}$.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 00:37:17 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2013 00:41:55 GMT"}], "update_date": "2013-09-04", "authors_parsed": [["Chandrasekaran", "Karthekeyan", ""], ["Thaler", "Justin", ""], ["Ullman", "Jonathan", ""], ["Wan", "Andrew", ""]]}, {"id": "1304.3763", "submitter": "M.M.A. Hashem", "authors": "Md. Rakib Hassan, Md. Kamrul Hasan and M.M.A. Hashem", "title": "An Improved ACS Algorithm for the Solutions of Larger TSP Problems", "comments": null, "journal-ref": "Procs. of the 3rd International Conference on Electrical,\n  Electronics and Computer Engineering (ICEECE 2003), pp. 201-206, Dhaka,\n  Bangladesh, December 22-24, (2003)", "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving large traveling salesman problem (TSP) in an efficient way is a\nchallenging area for the researchers of computer science. This paper presents a\nmodified version of the ant colony system (ACS) algorithm called Red-Black Ant\nColony System (RB-ACS) for the solutions of TSP which is the most prominent\nmember of the combinatorial optimization problem. RB-ACS uses the concept of\nant colony system together with the parallel search of genetic algorithm for\nobtaining the optimal solutions quickly. In this paper, it is shown that the\nproposed RB-ACS algorithm yields significantly better performance than the\nexisting best-known algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 02:30:23 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Hassan", "Md. Rakib", ""], ["Hasan", "Md. Kamrul", ""], ["Hashem", "M. M. A.", ""]]}, {"id": "1304.3812", "submitter": "Justin Thaler", "authors": "Justin Thaler", "title": "Time-Optimal Interactive Proofs for Circuit Evaluation", "comments": "This version corrects a confusing typographical error in Section 7.\n  We are grateful to Michael Walfish for identifying the error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers have been working toward the development of practical\ngeneral-purpose protocols for verifiable computation. These protocols enable a\ncomputationally weak verifier to offload computations to a powerful but\nuntrusted prover, while providing the verifier with a guarantee that the prover\nperformed the computations correctly. Despite substantial progress, existing\nimplementations are not yet practical. The main bottleneck is typically the\nextra effort required by the prover to return an answer with a guarantee of\ncorrectness, compared to returning an answer with no guarantee.\n  We describe a refinement of a powerful interactive proof protocol originally\ndue to Goldwasser, Kalai, and Rothblum. Cormode, Mitzenmacher, and Thaler show\nhow to implement the prover in this protocol in time O(S log S), where S is the\nsize of an arithmetic circuit computing the function of interest. Our\nrefinements apply to circuits whose wiring pattern is sufficiently \"regular\";\nfor these circuits, we bring the runtime of the prover down to O(S). That is,\nour prover can evaluate the circuit with a guarantee of correctness, with only\na constant-factor blowup in work compared to evaluating the circuit with no\nguarantee.\n  We argue that our refinements capture a large class of circuits, and prove\nsome theorems formalizing this. Experimentally, our refinements yield a 200x\nspeedup for the prover over the implementation of Cormode et al., and our\nprover is less than 10x slower than a C++ program that simply evaluates the\ncircuit. Along the way, we describe a special-purpose protocol for matrix\nmultiplication that is of interest in its own right.\n  Our final contribution is a protocol targeted at general data parallel\ncomputation. Compared to prior work, this protocol can more efficiently verify\ncomplicated computations as long as that computation is applied independently\nto many pieces of data.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 14:47:09 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2013 20:30:31 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2013 18:23:12 GMT"}, {"version": "v4", "created": "Wed, 8 Feb 2017 18:57:37 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Thaler", "Justin", ""]]}, {"id": "1304.3816", "submitter": "Justin Thaler", "authors": "Amit Chakrabarti and Graham Cormode and Navin Goyal and Justin Thaler", "title": "Annotations for Sparse Data Streams", "comments": "29 pages, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by cloud computing, a number of recent works have studied annotated\ndata streams and variants thereof. In this setting, a computationally weak\nverifier (cloud user), lacking the resources to store and manipulate his\nmassive input locally, accesses a powerful but untrusted prover (cloud\nservice). The verifier must work within the restrictive data streaming\nparadigm. The prover, who can annotate the data stream as it is read, must not\njust supply the answer but also convince the verifier of its correctness.\nIdeally, both the amount of annotation and the space used by the verifier\nshould be sublinear in the relevant input size parameters.\n  A rich theory of such algorithms -- which we call schemes -- has emerged.\nPrior work has shown how to leverage the prover's power to efficiently solve\nproblems that have no non-trivial standard data stream algorithms. However,\nwhile optimal schemes are now known for several basic problems, such optimality\nholds only for streams whose length is commensurate with the size of the data\nuniverse. In contrast, many real-world datasets are relatively sparse,\nincluding graphs that contain only O(n^2) edges, and IP traffic streams that\ncontain much fewer than the total number of possible IP addresses, 2^128 in\nIPv6.\n  We design the first schemes that allow both the annotation and the space\nusage to be sublinear in the total number of stream updates rather than the\nsize of the data universe. We solve significant problems, including variations\nof INDEX, SET-DISJOINTNESS, and FREQUENCY-MOMENTS, plus several natural\nproblems on graphs. On the other hand, we give a new lower bound that, for the\nfirst time, rules out smooth tradeoffs between annotation and space usage for a\nspecific problem. Our technique brings out new nuances in Merlin-Arthur\ncommunication complexity models, and provides a separation between online\nversions of the MA and AMA models.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 15:17:28 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Chakrabarti", "Amit", ""], ["Cormode", "Graham", ""], ["Goyal", "Navin", ""], ["Thaler", "Justin", ""]]}, {"id": "1304.3868", "submitter": "Siddharth Barman", "authors": "Siddharth Barman, Shuchi Chawla and Seeun Umboh", "title": "Network Design with Coverage Costs", "comments": "Updated version with additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study network design with a cost structure motivated by redundancy in data\ntraffic. We are given a graph, g groups of terminals, and a universe of data\npackets. Each group of terminals desires a subset of the packets from its\nrespective source. The cost of routing traffic on any edge in the network is\nproportional to the total size of the distinct packets that the edge carries.\nOur goal is to find a minimum cost routing. We focus on two settings. In the\nfirst, the collection of packet sets desired by source-sink pairs is laminar.\nFor this setting, we present a primal-dual based 2-approximation, improving\nupon a logarithmic approximation due to Barman and Chawla (2012). In the second\nsetting, packet sets can have non-trivial intersection. We focus on the case\nwhere each packet is desired by either a single terminal group or by all of the\ngroups, and the graph is unweighted. For this setting we present an O(log\ng)-approximation.\n  Our approximation for the second setting is based on a novel spanner-type\nconstruction in unweighted graphs that, given a collection of g vertex subsets,\nfinds a subgraph of cost only a constant factor more than the minimum spanning\ntree of the graph, such that every subset in the collection has a Steiner tree\nin the subgraph of cost at most O(log g) that of its minimum Steiner tree in\nthe original graph. We call such a subgraph a group spanner.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2013 01:11:32 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2013 20:31:45 GMT"}], "update_date": "2013-07-31", "authors_parsed": [["Barman", "Siddharth", ""], ["Chawla", "Shuchi", ""], ["Umboh", "Seeun", ""]]}, {"id": "1304.3935", "submitter": "David J. Rosenbaum", "authors": "David J. Rosenbaum", "title": "Bidirectional Collision Detection and Faster Deterministic Isomorphism\n  Testing", "comments": "18 pages. v1 shows the results. v2 makes minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce bidirectional collision detection --- a new\nalgorithmic tool that applies to the collision problems that arise in many\nisomorphism problems. For the group isomorphism problem, we show that\nbidirectional collision detection yields a deterministic n^((1 / 2) log n +\nO(1)) time algorithm whereas previously the n^(log n + O(1))\ngenerator-enumeration algorithm was the best result for several decades. For\nthe hard special case of solvable groups, we combine bidirectional collision\ndetection with methods from the author's previous work to obtain a\ndeterministic square-root speedup over the best previous algorithm. We also\nshow a deterministic square-root speedup over the best previous algorithm for\ntesting isomorphism of rings. We can even apply bidirectional collision\ndetection to the graph isomorphism problem to obtain a deterministic T^(1 /\nsqrt(2)) speedup over the best previous deterministic algorithm. Although the\nspace requirements for our algorithms are greater than those for previous\ndeterministic isomorphism tests, we show time-space tradeoffs that interpolate\nbetween the resource requirements of our algorithms and previous work.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2013 19:21:14 GMT"}, {"version": "v2", "created": "Thu, 16 May 2013 04:37:28 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Rosenbaum", "David J.", ""]]}, {"id": "1304.4073", "submitter": "Long Wan", "authors": "Long Wan", "title": "Simultaneous approximation for scheduling problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Motivated by the problem to approximate all feasible schedules by one\nschedule in a given scheduling environment, we introduce in this paper the\nconcepts of strong simultaneous approximation ratio (SAR) and weak simultaneous\napproximation ratio (WAR). Then we study the two parameters under various\nscheduling environments, such as, non-preemptive, preemptive or fractional\nscheduling on identical, related or unrelated machines.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2013 12:47:42 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Wan", "Long", ""]]}, {"id": "1304.4207", "submitter": "Marek Cygan", "authors": "Marek Cygan, D\\'aniel Marx, Marcin Pilipczuk, Micha{\\l} Pilipczuk", "title": "The planar directed k-Vertex-Disjoint Paths problem is fixed-parameter\n  tractable", "comments": "110 pages, 43 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph G and k pairs of vertices (s_1,t_1), ..., (s_k,t_k), the\nk-Vertex-Disjoint Paths problem asks for pairwise vertex-disjoint paths P_1,\n..., P_k such that P_i goes from s_i to t_i. Schrijver [SICOMP'94] proved that\nthe k-Vertex-Disjoint Paths problem on planar directed graphs can be solved in\ntime n^{O(k)}. We give an algorithm with running time 2^{2^{O(k^2)}} n^{O(1)}\nfor the problem, that is, we show the fixed-parameter tractability of the\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2013 19:15:18 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Cygan", "Marek", ""], ["Marx", "D\u00e1niel", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1304.4243", "submitter": "Samira Daruki Samira Daruki", "authors": "Amirali Abdullah, Samira Daruki, Jeff M. Phillips", "title": "Range Counting Coresets for Uncertain Data", "comments": "17 pages, 3 figures, 29th Annual ACM Symposium on Computational\n  Geometry (SoCG)- June 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study coresets for various types of range counting queries on uncertain\ndata. In our model each uncertain point has a probability density describing\nits location, sometimes defined as k distinct locations. Our goal is to\nconstruct a subset of the uncertain points, including their locational\nuncertainty, so that range counting queries can be answered by just examining\nthis subset. We study three distinct types of queries. RE queries return the\nexpected number of points in a query range. RC queries return the number of\npoints in the range with probability at least a threshold. RQ queries returns\nthe probability that fewer than some threshold fraction of the points are in\nthe range. In both RC and RQ coresets the threshold is provided as part of the\nquery. And for each type of query we provide coreset constructions with\napproximation-size tradeoffs. We show that random sampling can be used to\nconstruct each type of coreset, and we also provide significantly improved\nbounds using discrepancy-based approaches on axis-aligned range queries.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2013 20:00:38 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Abdullah", "Amirali", ""], ["Daruki", "Samira", ""], ["Phillips", "Jeff M.", ""]]}, {"id": "1304.4280", "submitter": "Shreyas Balakuntala", "authors": "Rishi Ranjan Singh, Shreyas Balakuntala, Sudarshan Iyengar", "title": "Navigability on Networks: A Graph Theoretic Perspective", "comments": "This paper has been withdrawn by the author due to an error in\n  equation 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human navigation has been of interest to psychologists and cognitive\nscientists since the past few decades. It was in the recent past that a study\nof human navigational strategies was initiated with a network analytic\napproach, instigated mainly by Milgrams small world experiment. We brief the\nwork in this direction and provide answers to the algorithmic questions raised\nby the previous study. It is noted that humans have a tendency to navigate\nusing centers of the network - such paths are called the\ncenter-strategic-paths. We show that the problem of finding a\ncenter-strategic-path is an easy one. We provide a polynomial time algorithm to\nfind a center-strategic-path between a given pair of nodes. We apply our\nfinding in empirically checking the navigability on synthetic networks and\nanalyze few special types of graphs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2013 22:16:23 GMT"}, {"version": "v2", "created": "Tue, 7 May 2013 05:36:44 GMT"}], "update_date": "2013-05-08", "authors_parsed": [["Singh", "Rishi Ranjan", ""], ["Balakuntala", "Shreyas", ""], ["Iyengar", "Sudarshan", ""]]}, {"id": "1304.4321", "submitter": "Venkatesan Guruswami", "authors": "Venkatesan Guruswami, Patrick Xia", "title": "Polar Codes: Speed of polarization and polynomial gap to capacity", "comments": "26 pages; Submitted to IEEE Transactions on Information Theory (Full\n  version of conference paper appearing in FOCS'13)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that, for all binary-input symmetric memoryless channels, polar\ncodes enable reliable communication at rates within $\\epsilon > 0$ of the\nShannon capacity with a block length, construction complexity, and decoding\ncomplexity all bounded by a {\\em polynomial} in $1/\\epsilon$. Polar coding\ngives the {\\em first known explicit construction} with rigorous proofs of all\nthese properties; previous constructions were not known to achieve capacity\nwith less than $\\exp(1/\\epsilon)$ decoding complexity except for erasure\nchannels.\n  We establish the capacity-achieving property of polar codes via a direct\nanalysis of the underlying martingale of conditional entropies, without relying\non the martingale convergence theorem. This step gives rough polarization\n(noise levels $\\approx \\epsilon$ for the \"good\" channels), which can then be\nadequately amplified by tracking the decay of the channel Bhattacharyya\nparameters. Our effective bounds imply that polar codes can have block length\n(and encoding/decoding complexity) bounded by a polynomial in $1/\\epsilon$. The\ngenerator matrix of such polar codes can be constructed in polynomial time by\nalgorithmically computing an adequate approximation of the polarization\nprocess.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 03:33:21 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2013 18:30:48 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Xia", "Patrick", ""]]}, {"id": "1304.4327", "submitter": "Ryan Curtin", "authors": "Ryan R. Curtin, William B. March, Parikshit Ram, David V. Anderson,\n  Alexander G. Gray, and Charles L. Isbell Jr", "title": "Tree-Independent Dual-Tree Algorithms", "comments": "accepted in ICML 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual-tree algorithms are a widely used class of branch-and-bound algorithms.\nUnfortunately, developing dual-tree algorithms for use with different trees and\nproblems is often complex and burdensome. We introduce a four-part logical\nsplit: the tree, the traversal, the point-to-point base case, and the pruning\nrule. We provide a meta-algorithm which allows development of dual-tree\nalgorithms in a tree-independent manner and easy extension to entirely new\ntypes of trees. Representations are provided for five common algorithms; for\nk-nearest neighbor search, this leads to a novel, tighter pruning bound. The\nmeta-algorithm also allows straightforward extensions to massively parallel\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 04:04:42 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Curtin", "Ryan R.", ""], ["March", "William B.", ""], ["Ram", "Parikshit", ""], ["Anderson", "David V.", ""], ["Gray", "Alexander G.", ""], ["Isbell", "Charles L.", "Jr"]]}, {"id": "1304.4371", "submitter": "Joel Lang", "authors": "Joel Lang and James Henderson", "title": "Efficient Computation of Mean Truncated Hitting Times on Very Large\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown the effectiveness of random walk hitting times as a\nmeasure of dissimilarity in a variety of graph-based learning problems such as\ncollaborative filtering, query suggestion or finding paraphrases. However,\napplication of hitting times has been limited to small datasets because of\ncomputational restrictions. This paper develops a new approximation algorithm\nwith which hitting times can be computed on very large, disk-resident graphs,\nmaking their application possible to problems which were previously out of\nreach. This will potentially benefit a range of large-scale problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 09:11:16 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Lang", "Joel", ""], ["Henderson", "James", ""]]}, {"id": "1304.4517", "submitter": "David Lawlor", "authors": "Andrew Christlieb, David Lawlor, Yang Wang", "title": "A Multiscale Sub-linear Time Fourier Algorithm for Noisy Data", "comments": "28 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the recent sparse Fourier transform algorithm of (Lawlor,\nChristlieb, and Wang, 2013) to the noisy setting, in which a signal of\nbandwidth N is given as a superposition of k << N frequencies and additive\nnoise. We present two such extensions, the second of which exhibits a novel\nform of error-correction in its frequency estimation not unlike that of the\nbeta-encoders in analog-to-digital conversion (Daubechies et al, 2006). The\nalgorithm runs in time O(k log(k) log(N/k)) on average, provided the noise is\nnot overwhelming. The error-correction property allows the algorithm to\noutperform FFTW, a highly optimized software package for computing the full\ndiscrete Fourier transform, over a wide range of sparsity and noise values, and\nis to the best of our knowledge novel in the sparse Fourier transform context.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 16:49:43 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2013 18:21:48 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Christlieb", "Andrew", ""], ["Lawlor", "David", ""], ["Wang", "Yang", ""]]}, {"id": "1304.4519", "submitter": "David Doty", "authors": "David Doty and Monir Hajiaghayi", "title": "Leaderless deterministic chemical reaction networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1204.4176", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC cs.DS q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper answers an open question of Chen, Doty, and Soloveichik [1], who\nshowed that a function f:N^k --> N^l is deterministically computable by a\nstochastic chemical reaction network (CRN) if and only if the graph of f is a\nsemilinear subset of N^{k+l}. That construction crucially used \"leaders\": the\nability to start in an initial configuration with constant but non-zero counts\nof species other than the k species X_1,...,X_k representing the input to the\nfunction f. The authors asked whether deterministic CRNs without a leader\nretain the same power.\n  We answer this question affirmatively, showing that every semilinear function\nis deterministically computable by a CRN whose initial configuration contains\nonly the input species X_1,...,X_k, and zero counts of every other species. We\nshow that this CRN completes in expected time O(n), where n is the total number\nof input molecules. This time bound is slower than the O(log^5 n) achieved in\n[1], but faster than the O(n log n) achieved by the direct construction of [1]\n(Theorem 4.1 in the latest online version of [1]), since the fast construction\nof that paper (Theorem 4.4) relied heavily on the use of a fast, error-prone\nCRN that computes arbitrary computable functions, and which crucially uses a\nleader.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 17:04:10 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Doty", "David", ""], ["Hajiaghayi", "Monir", ""]]}, {"id": "1304.4553", "submitter": "Mohsen Ghaffari", "authors": "Keren Censor-Hillel, Mohsen Ghaffari, Fabian Kuhn", "title": "A New Perspective on Vertex Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge connectivity and vertex connectivity are two fundamental concepts in\ngraph theory. Although by now there is a good understanding of the structure of\ngraphs based on their edge connectivity, our knowledge in the case of vertex\nconnectivity is much more limited. An essential tool in capturing edge\nconnectivity are edge-disjoint spanning trees. The famous results of Tutte and\nNash-Williams show that a graph with edge connectivity $\\lambda$ contains\n$\\floor{\\lambda/2}$ edge-disjoint spanning trees.\n  We present connected dominating set (CDS) partition and packing as tools that\nare analogous to edge-disjoint spanning trees and that help us to better grasp\nthe structure of graphs based on their vertex connectivity. The objective of\nthe CDS partition problem is to partition the nodes of a graph into as many\nconnected dominating sets as possible. The CDS packing problem is the\ncorresponding fractional relaxation, where CDSs are allowed to overlap as long\nas this is compensated by assigning appropriate weights. CDS partition and CDS\npacking can be viewed as the counterparts of the well-studied edge-disjoint\nspanning trees, focusing on vertex disjointedness rather than edge\ndisjointness.\n  We constructively show that every $k$-vertex-connected graph with $n$ nodes\nhas a CDS packing of size $\\Omega(k/\\log n)$ and a CDS partition of size\n$\\Omega(k/\\log^5 n)$. We prove that the $\\Omega(k/\\log n)$ CDS packing bound is\nexistentially optimal.\n  Using CDS packing, we show that if vertices of a $k$-vertex-connected graph\nare independently sampled with probability $p$, then the graph induced by the\nsampled vertices has vertex connectivity $\\tilde{\\Omega}(kp^2)$. Moreover,\nusing our $\\Omega(k/\\log n)$ CDS packing, we get a store-and-forward broadcast\nalgorithm with optimal throughput in the networking model where in each round,\neach node can send one bounded-size message to all its neighbors.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 19:00:48 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Ghaffari", "Mohsen", ""], ["Kuhn", "Fabian", ""]]}, {"id": "1304.4613", "submitter": "Ye Wang", "authors": "Bing-Rong Lin, Ye Wang, Shantanu Rane", "title": "On the Benefits of Sampling in Privacy Preserving Statistical Analysis\n  on Distributed Databases", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem where mutually untrusting curators possess portions of\na vertically partitioned database containing information about a set of\nindividuals. The goal is to enable an authorized party to obtain aggregate\n(statistical) information from the database while protecting the privacy of the\nindividuals, which we formalize using Differential Privacy. This process can be\nfacilitated by an untrusted server that provides storage and processing\nservices but should not learn anything about the database. This work describes\na data release mechanism that employs Post Randomization (PRAM), encryption and\nrandom sampling to maintain privacy, while allowing the authorized party to\nconduct an accurate statistical analysis of the data. Encryption ensures that\nthe storage server obtains no information about the database, while PRAM and\nsampling ensures individual privacy is maintained against the authorized party.\nWe characterize how much the composition of random sampling with PRAM increases\nthe differential privacy of system compared to using PRAM alone. We also\nanalyze the statistical utility of our system, by bounding the estimation error\n- the expected l2-norm error between the true empirical distribution and the\nestimated distribution - as a function of the number of samples, PRAM noise,\nand other system parameters. Our analysis shows a tradeoff between increasing\nPRAM noise versus decreasing the number of samples to maintain a desired level\nof privacy, and we determine the optimal number of samples that balances this\ntradeoff and maximizes the utility. In experimental simulations with the UCI\n\"Adult Data Set\" and with synthetically generated data, we confirm that the\ntheoretically predicted optimal number of samples indeed achieves close to the\nminimal empirical error, and that our analytical error bounds match well with\nthe empirical results.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 20:28:32 GMT"}], "update_date": "2013-04-18", "authors_parsed": [["Lin", "Bing-Rong", ""], ["Wang", "Ye", ""], ["Rane", "Shantanu", ""]]}, {"id": "1304.4626", "submitter": "Saket Saurabh", "authors": "Fedor V. Fomin and Daniel Lokshtanov and Fahad Panolan and Saket\n  Saurabh", "title": "Efficient Computation of Representative Sets with Applications in\n  Parameterized and Exact Algorithms", "comments": "61 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give two algorithms computing representative families of linear and\nuniform matroids and demonstrate how to use representative families for\ndesigning single-exponential parameterized and exact exponential time\nalgorithms. The applications of our approach include\n  - LONGEST DIRECTED CYCLE\n  - MINIMUM EQUIVALENT GRAPH (MEG)\n  - Algorithms on graphs of bounded treewidth\n  -k-PATH, k-TREE, and more generally, k-SUBGRAPH ISOMORPHISM, where the\nk-vertex pattern graph is of constant treewidth.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 21:16:34 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2013 21:28:10 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2013 01:08:39 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2016 18:36:55 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Lokshtanov", "Daniel", ""], ["Panolan", "Fahad", ""], ["Saurabh", "Saket", ""]]}, {"id": "1304.4633", "submitter": "Brendan Juba", "authors": "Brendan Juba", "title": "PAC Quasi-automatizability of Resolution over Restricted Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider principled alternatives to unsupervised learning in data mining\nby situating the learning task in the context of the subsequent analysis task.\nSpecifically, we consider a query-answering (hypothesis-testing) task: In the\ncombined task, we decide whether an input query formula is satisfied over a\nbackground distribution by using input examples directly, rather than invoking\na two-stage process in which (i) rules over the distribution are learned by an\nunsupervised learning algorithm and (ii) a reasoning algorithm decides whether\nor not the query formula follows from the learned rules. In a previous work\n(2013), we observed that the learning task could satisfy numerous desirable\ncriteria in this combined context -- effectively matching what could be\nachieved by agnostic learning of CNFs from partial information -- that are not\nknown to be achievable directly. In this work, we show that likewise, there are\nreasoning tasks that are achievable in such a combined context that are not\nknown to be achievable directly (and indeed, have been seriously conjectured to\nbe impossible, cf. (Alekhnovich and Razborov, 2008)). Namely, we test for a\nresolution proof of the query formula of a given size in quasipolynomial time\n(that is, \"quasi-automatizing\" resolution). The learning setting we consider is\na partial-information, restricted-distribution setting that generalizes\nlearning parities over the uniform distribution from partial information,\nanother task that is known not to be achievable directly in various models (cf.\n(Ben-David and Dichterman, 1998) and (Michael, 2010)).\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 22:10:26 GMT"}], "update_date": "2013-04-18", "authors_parsed": [["Juba", "Brendan", ""]]}, {"id": "1304.4636", "submitter": "Qin Zhang", "authors": "David P. Woodruff and Qin Zhang", "title": "When Distributed Computation is Communication Expensive", "comments": "A few minor modifications are made. The new version also has a more\n  appropriate title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a number of fundamental statistical and graph problems in the\nmessage-passing model, where we have $k$ machines (sites), each holding a piece\nof data, and the machines want to jointly solve a problem defined on the union\nof the $k$ data sets. The communication is point-to-point, and the goal is to\nminimize the total communication among the $k$ machines. This model captures\nall point-to-point distributed computational models with respect to minimizing\ncommunication costs. Our analysis shows that exact computation of many\nstatistical and graph problems in this distributed setting requires a\nprohibitively large amount of communication, and often one cannot improve upon\nthe communication of the simple protocol in which all machines send their data\nto a centralized server. Thus, in order to obtain protocols that are\ncommunication-efficient, one has to allow approximation, or investigate the\ndistribution or layout of the data sets.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 22:14:12 GMT"}, {"version": "v2", "created": "Wed, 1 May 2013 19:58:42 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2013 17:13:46 GMT"}], "update_date": "2013-07-29", "authors_parsed": [["Woodruff", "David P.", ""], ["Zhang", "Qin", ""]]}, {"id": "1304.4658", "submitter": "Peter Lofgren", "authors": "Peter Lofgren, Ashish Goel", "title": "Personalized PageRank to a Target Node", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalalized PageRank uses random walks to determine the importance or\nauthority of nodes in a graph from the point of view of a given source node.\nMuch past work has considered how to compute personalized PageRank from a given\nsource node to other nodes. In this work we consider the problem of computing\npersonalized PageRanks to a given target node from all source nodes. This\nproblem can be interpreted as finding who supports the target or who is\ninterested in the target.\n  We present an efficient algorithm for computing personalized PageRank to a\ngiven target up to any given accuracy. We give a simple analysis of our\nalgorithm's running time in both the average case and the parameterized\nworst-case. We show that for any graph with $n$ nodes and $m$ edges, if the\ntarget node is randomly chosen and the teleport probability $\\alpha$ is given,\nthe algorithm will compute a result with $\\epsilon$ error in time\n$O\\left(\\frac{1}{\\alpha \\epsilon} \\left(\\frac{m}{n} + \\log(n)\\right)\\right)$.\nThis is much faster than the previously proposed method of computing\npersonalized PageRank separately from every source node, and it is comparable\nto the cost of computing personalized PageRank from a single source. We present\nresults from experiments on the Twitter graph which show that the constant\nfactors in our running time analysis are small and our algorithm is efficient\nin practice.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 00:49:25 GMT"}, {"version": "v2", "created": "Fri, 11 Apr 2014 22:49:33 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Lofgren", "Peter", ""], ["Goel", "Ashish", ""]]}, {"id": "1304.4661", "submitter": "Takuya Akiba", "authors": "Takuya Akiba, Yoichi Iwata, and Yuichi Yoshida", "title": "Fast Exact Shortest-Path Distance Queries on Large Networks by Pruned\n  Landmark Labeling", "comments": "To appear in SIGMOD 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new exact method for shortest-path distance queries on\nlarge-scale networks. Our method precomputes distance labels for vertices by\nperforming a breadth-first search from every vertex. Seemingly too obvious and\ntoo inefficient at first glance, the key ingredient introduced here is pruning\nduring breadth-first searches. While we can still answer the correct distance\nfor any pair of vertices from the labels, it surprisingly reduces the search\nspace and sizes of labels. Moreover, we show that we can perform 32 or 64\nbreadth-first searches simultaneously exploiting bitwise operations. We\nexperimentally demonstrate that the combination of these two techniques is\nefficient and robust on various kinds of large-scale real-world networks. In\nparticular, our method can handle social networks and web graphs with hundreds\nof millions of edges, which are two orders of magnitude larger than the limits\nof previous exact methods, with comparable query time to those of previous\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 01:11:12 GMT"}], "update_date": "2013-04-18", "authors_parsed": [["Akiba", "Takuya", ""], ["Iwata", "Yoichi", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "1304.4680", "submitter": "Tianbao Yang", "authors": "Rong Jin, Tianbao Yang, Shenghuo Zhu", "title": "A New Analysis of Compressive Sensing by Stochastic Proximal Gradient\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript, we analyze the sparse signal recovery (compressive\nsensing) problem from the perspective of convex optimization by stochastic\nproximal gradient descent. This view allows us to significantly simplify the\nrecovery analysis of compressive sensing. More importantly, it leads to an\nefficient optimization algorithm for solving the regularized optimization\nproblem related to the sparse recovery problem. Compared to the existing\napproaches, there are two advantages of the proposed algorithm. First, it\nenjoys a geometric convergence rate and therefore is computationally efficient.\nSecond, it guarantees that the support set of any intermediate solution\ngenerated by the proposed algorithm is concentrated on the support set of the\noptimal solution.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 04:15:43 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 03:58:50 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Jin", "Rong", ""], ["Yang", "Tianbao", ""], ["Zhu", "Shenghuo", ""]]}, {"id": "1304.4948", "submitter": "Ankit Sharma", "authors": "Nikhil R. Devanur and Shaddin Dughmi and Roy Schwartz and Ankit Sharma\n  and Mohit Singh", "title": "On the Approximation of Submodular Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions are a fundamental object of study in combinatorial\noptimization, economics, machine learning, etc. and exhibit a rich\ncombinatorial structure. Many subclasses of submodular functions have also been\nwell studied and these subclasses widely vary in their complexity. Our\nmotivation is to understand the relative complexity of these classes of\nfunctions. Towards this, we consider the question of how well can one class of\nsubmodular functions be approximated by another (simpler) class of submodular\nfunctions. Such approximations naturally allow algorithms designed for the\nsimpler class to be applied to the bigger class of functions. We prove both\nupper and lower bounds on such approximations.\n  Our main results are:\n  1. General submodular functions can be approximated by cut functions of\ndirected graphs to a factor of $n^2/4$, which is tight.\n  2. General symmetric submodular functions$^{1}$ can be approximated by cut\nfunctions of undirected graphs to a factor of $n-1$, which is tight up to a\nconstant.\n  3. Budgeted additive functions can be approximated by coverage functions to a\nfactor of $e/(e-1)$, which is tight.\n  Here $n$ is the size of the ground set on which the submodular function is\ndefined.\n  We also observe that prior works imply that monotone submodular functions can\nbe approximated by coverage functions with a factor between $O(\\sqrt{n} \\log\nn)$ and $\\Omega(n^{1/3} /\\log^2 n) $.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 20:02:32 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Devanur", "Nikhil R.", ""], ["Dughmi", "Shaddin", ""], ["Schwartz", "Roy", ""], ["Sharma", "Ankit", ""], ["Singh", "Mohit", ""]]}, {"id": "1304.5051", "submitter": "Arnab Bhattacharya", "authors": "Shubhadip Mitra, Partha Dutta, Arnab Bhattacharya", "title": "Constraint Satisfaction over Generalized Staircase Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key research interests in the area of Constraint Satisfaction\nProblem (CSP) is to identify tractable classes of constraints and develop\nefficient solutions for them. In this paper, we introduce generalized staircase\n(GS) constraints which is an important generalization of one such tractable\nclass found in the literature, namely, staircase constraints. GS constraints\nare of two kinds, down staircase (DS) and up staircase (US). We first examine\nseveral properties of GS constraints, and then show that arc consistency is\nsufficient to determine a solution to a CSP over DS constraints. Further, we\npropose an optimal O(cd) time and space algorithm to compute arc consistency\nfor GS constraints where c is the number of constraints and d is the size of\nthe largest domain. Next, observing that arc consistency is not necessary for\nsolving a DSCSP, we propose a more efficient algorithm for solving it. With\nregard to US constraints, arc consistency is not known to be sufficient to\ndetermine a solution, and therefore, methods such as path consistency or\nvariable elimination are required. Since arc consistency acts as a subroutine\nfor these existing methods, replacing it by our optimal O(cd) arc consistency\nalgorithm produces a more efficient method for solving a USCSP.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2013 08:42:22 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Mitra", "Shubhadip", ""], ["Dutta", "Partha", ""], ["Bhattacharya", "Arnab", ""]]}, {"id": "1304.5140", "submitter": "Irena Rusu Ph.D.", "authors": "Irena Rusu", "title": "MinMax-Profiles: A Unifying View of Common Intervals, Nested Common\n  Intervals and Conserved Intervals of K Permutations", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common intervals of K permutations over the same set of n elements were\nfirstly investigated by T. Uno and M.Yagiura (Algorithmica, 26:290:309, 2000),\nwho proposed an efficient algorithm to find common intervals when K=2. Several\nparticular classes of intervals have been defined since then, e.g. conserved\nintervals and nested common intervals, with applications mainly in genome\ncomparison. Each such class, including common intervals, led to the development\nof a specific algorithmic approach for K=2, and - except for nested common\nintervals - for its extension to an arbitrary K.\n  In this paper, we propose a common and efficient algorithmic framework for\nfinding different types of common intervals in a set P of K permutations, with\narbitrary K. Our generic algorithm is based on a global representation of the\ninformation stored in P, called the MinMax-profile of P, and an efficient data\nstructure, called an LR-stack, that we introduce here. We show that common\nintervals (and their subclasses of irreducible common intervals and same-sign\ncommon intervals), nested common intervals (and their subclass of maximal\nnested common intervals) as well as conserved intervals (and their subclass of\nirreducible conserved intervals) may be obtained by appropriately setting the\nparameters of our algorithm in each case. All the resulting algorithms run in\nO(Kn+N)-time and need O(n) additional space, where N is the number of\nsolutions. The algorithms for nested common intervals and maximal nested common\nintervals are new for K>2, in the sense that no other algorithm has been given\nso far to solve the problem with the same complexity, or better. The other\nalgorithms are as efficient as the best known algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2013 14:09:17 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 10:16:17 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Rusu", "Irena", ""]]}, {"id": "1304.5264", "submitter": "C. Seshadhri", "authors": "Deeparnab Chakrabarty, C. Seshadhri", "title": "An optimal lower bound for monotonicity testing over hypergrids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For positive integers $n, d$, consider the hypergrid $[n]^d$ with the\ncoordinate-wise product partial ordering denoted by $\\prec$. A function $f:\n[n]^d \\mapsto \\mathbb{N}$ is monotone if $\\forall x \\prec y$, $f(x) \\leq f(y)$.\nA function $f$ is $\\eps$-far from monotone if at least an $\\eps$-fraction of\nvalues must be changed to make $f$ monotone. Given a parameter $\\eps$, a\n\\emph{monotonicity tester} must distinguish with high probability a monotone\nfunction from one that is $\\eps$-far.\n  We prove that any (adaptive, two-sided) monotonicity tester for functions\n$f:[n]^d \\mapsto \\mathbb{N}$ must make $\\Omega(\\eps^{-1}d\\log n - \\eps^{-1}\\log\n\\eps^{-1})$ queries. Recent upper bounds show the existence of $O(\\eps^{-1}d\n\\log n)$ query monotonicity testers for hypergrids. This closes the question of\nmonotonicity testing for hypergrids over arbitrary ranges. The previous best\nlower bound for general hypergrids was a non-adaptive bound of $\\Omega(d \\log\nn)$.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2013 21:48:43 GMT"}], "update_date": "2013-04-22", "authors_parsed": [["Chakrabarty", "Deeparnab", ""], ["Seshadhri", "C.", ""]]}, {"id": "1304.5373", "submitter": "Patrick Hagge Cording", "authors": "Philip Bille, Patrick Hagge Cording, Inge Li G{\\o}rtz", "title": "Compact q-gram Profiling of Compressed Strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the q-gram profile of a string \\str of\nsize $N$ compressed by a context-free grammar with $n$ production rules. We\npresent an algorithm that runs in $O(N-\\alpha)$ expected time and uses\n$O(n+q+\\kq)$ space, where $N-\\alpha\\leq qn$ is the exact number of characters\ndecompressed by the algorithm and $\\kq\\leq N-\\alpha$ is the number of distinct\nq-grams in $\\str$. This simultaneously matches the current best known time\nbound and improves the best known space bound. Our space bound is\nasymptotically optimal in the sense that any algorithm storing the grammar and\nthe q-gram profile must use $\\Omega(n+q+\\kq)$ space. To achieve this we\nintroduce the q-gram graph that space-efficiently captures the structure of a\nstring with respect to its q-grams, and show how to construct it from a\ngrammar.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 11:11:36 GMT"}, {"version": "v2", "created": "Fri, 6 Jun 2014 13:40:56 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Bille", "Philip", ""], ["Cording", "Patrick Hagge", ""], ["G\u00f8rtz", "Inge Li", ""]]}, {"id": "1304.5498", "submitter": "Stefan Szeider", "authors": "Marijn J. H. Heule, Stefan Szeider", "title": "A SAT Approach to Clique-Width", "comments": "proofs in section 3 updated, results remain unchanged", "journal-ref": "Proceedings of SAT 2013, LNCS 7962, pp. 318-334, 2013", "doi": "10.1007/978-3-642-39071-5_24", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clique-width is a graph invariant that has been widely studied in\ncombinatorics and computer science. However, computing the clique-width of a\ngraph is an intricate problem, the exact clique-width is not known even for\nvery small graphs. We present a new method for computing the clique-width of\ngraphs based on an encoding to propositional satisfiability (SAT) which is then\nevaluated by a SAT solver. Our encoding is based on a reformulation of\nclique-width in terms of partitions that utilizes an efficient encoding of\ncardinality constraints. Our SAT-based method is the first to discover the\nexact clique-width of various small graphs, including famous graphs from the\nliterature as well as random graphs of various density. With our method we\ndetermined the smallest graphs that require a small pre-described clique-width.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 18:23:16 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2013 13:15:26 GMT"}], "update_date": "2013-09-30", "authors_parsed": [["Heule", "Marijn J. H.", ""], ["Szeider", "Stefan", ""]]}, {"id": "1304.5518", "submitter": "Sebastian Ordyniak", "authors": "Neeldhara Misra, Sebastian Ordyniak, Venkatesh Raman, Stefan Szeider", "title": "Upper and Lower Bounds for Weak Backdoor Set Detection", "comments": "A short version will appear in the proceedings of the 16th\n  International Conference on Theory and Applications of Satisfiability Testing", "journal-ref": "Proceedings of SAT 2013, LNCS 7962, pp. 394-402, 2013", "doi": "10.1007/978-3-642-39071-5_29", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain upper and lower bounds for running times of exponential time\nalgorithms for the detection of weak backdoor sets of 3CNF formulas,\nconsidering various base classes. These results include (omitting polynomial\nfactors), (i) a 4.54^k algorithm to detect whether there is a weak backdoor set\nof at most k variables into the class of Horn formulas; (ii) a 2.27^k algorithm\nto detect whether there is a weak backdoor set of at most k variables into the\nclass of Krom formulas. These bounds improve an earlier known bound of 6^k. We\nalso prove a 2^k lower bound for these problems, subject to the Strong\nExponential Time Hypothesis.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 19:50:04 GMT"}, {"version": "v2", "created": "Fri, 3 May 2013 09:48:02 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Misra", "Neeldhara", ""], ["Ordyniak", "Sebastian", ""], ["Raman", "Venkatesh", ""], ["Szeider", "Stefan", ""]]}, {"id": "1304.5560", "submitter": "Travis Gagie", "authors": "Ferdinando Cicalese, Travis Gagie, Emanuele Giaquinta, Eduardo Sany\n  Laber, Zsuzsanna Lipt\\'ak, Romeo Rizzi and Alexandru I. Tomescu", "title": "Indexes for Jumbled Pattern Matching in Strings, Trees and Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider how to index strings, trees and graphs for jumbled pattern\nmatching when we are asked to return a match if one exists. For example, we\nshow how, given a tree containing two colours, we can build a quadratic-space\nindex with which we can find a match in time proportional to the size of the\nmatch. We also show how we need only linear space if we are content with\napproximate matches.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 22:50:32 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Cicalese", "Ferdinando", ""], ["Gagie", "Travis", ""], ["Giaquinta", "Emanuele", ""], ["Laber", "Eduardo Sany", ""], ["Lipt\u00e1k", "Zsuzsanna", ""], ["Rizzi", "Romeo", ""], ["Tomescu", "Alexandru I.", ""]]}, {"id": "1304.5591", "submitter": "Michael Bannister", "authors": "Michael J. Bannister and Sergio Cabello and David Eppstein", "title": "Parameterized Complexity of 1-Planarity", "comments": "WADS 2013", "journal-ref": "J. Graph Algorithms and Applications 22 (1): 23-49, 2018", "doi": "10.7155/jgaa.00457", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding a 1-planar drawing for a general graph,\nwhere a 1-planar drawing is a drawing in which each edge participates in at\nmost one crossing. Since this problem is known to be NP-hard we investigate the\nparameterized complexity of the problem with respect to the vertex cover\nnumber, tree-depth, and cyclomatic number. For these parameters we construct\nfixed-parameter tractable algorithms. However, the problem remains NP-complete\nfor graphs of bounded bandwidth, pathwidth, or treewidth.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2013 06:14:31 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Bannister", "Michael J.", ""], ["Cabello", "Sergio", ""], ["Eppstein", "David", ""]]}, {"id": "1304.5625", "submitter": "Matthias Hellwig", "authors": "Susanne Albers and Matthias Hellwig", "title": "Online Makespan Minimization with Parallel Schedules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online makespan minimization a sequence of jobs $\\sigma = J_1,..., J_n$\nhas to be scheduled on $m$ identical parallel machines so as to minimize the\nmaximum completion time of any job. We investigate the problem with an\nessentially new model of resource augmentation. Here, an online algorithm is\nallowed to build several schedules in parallel while processing $\\sigma$. At\nthe end of the scheduling process the best schedule is selected. This model can\nbe viewed as providing an online algorithm with extra space, which is invested\nto maintain multiple solutions. The setting is of particular interest in\nparallel processing environments where each processor can maintain a single or\na small set of solutions.\n  We develop a $(4/3+\\eps)$-competitive algorithm, for any $0<\\eps\\leq 1$, that\nuses a number of $1/\\eps^{O(\\log (1/\\eps))}$ schedules. We also give a\n$(1+\\eps)$-competitive algorithm, for any $0<\\eps\\leq 1$, that builds a\npolynomial number of $(m/\\eps)^{O(\\log (1/\\eps) / \\eps)}$ schedules. This value\ndepends on $m$ but is independent of the input $\\sigma$. The performance\nguarantees are nearly best possible. We show that any algorithm that achieves a\ncompetitiveness smaller than 4/3 must construct $\\Omega(m)$ schedules. Our\nalgorithms make use of novel guessing schemes that (1) predict the optimum\nmakespan of a job sequence $\\sigma$ to within a factor of $1+\\eps$ and (2)\nguess the job processing times and their frequencies in $\\sigma$. In (2) we\nhave to sparsify the universe of all guesses so as to reduce the number of\nschedules to a constant.\n  The competitive ratios achieved using parallel schedules are considerably\nsmaller than those in the standard problem without resource augmentation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2013 11:45:03 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Albers", "Susanne", ""], ["Hellwig", "Matthias", ""]]}, {"id": "1304.5633", "submitter": "Vahagn Poghosyan", "authors": "V.H. Hovnanyan, H.E. Nahapetyan, Su.S. Poghosyan and V.S. Poghosyan", "title": "Tighter Upper Bounds for the Minimum Number of Calls and Rigorous\n  Minimal Time in Fault-Tolerant Gossip Schemes", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gossip problem (telephone problem) is an information dissemination\nproblem in which each of $n$ nodes of a communication network has a unique\npiece of information that must be transmitted to all the other nodes using\ntwo-way communications (telephone calls) between the pairs of nodes. During a\ncall between the given two nodes, they exchange the whole information known to\nthem at that moment. In this paper we investigate the $k$-fault-tolerant gossip\nproblem, which is a generalization of the gossip problem, where at most $k$\narbitrary faults of calls are allowed. The problem is to find the minimal\nnumber of calls $\\tau(n,k)$ needed to guarantee the $k$-fault-tolerance. We\nconstruct two classes of $k$-fault-tolerant gossip schemes (sequences of calls)\nand found two upper bounds of $\\tau(n,k)$, which improve the previously known\nresults. The first upper bound for general even $n$ is $\\tau(n,k) \\leq 1/2 n\n\\lceil\\log_2 n\\rceil + 1/2 n k$. This result is used to obtain the upper bound\nfor general odd $n$. From the expressions for the second upper bound it follows\nthat $\\tau(n,k) \\leq 2/3 n k + O(n)$ for large $n$. Assuming that the calls can\ntake place simultaneously, it is also of interest to find $k$-fault-tolerant\ngossip schemes, which can spread the full information in minimal time. For even\n$n$ we showed that the minimal time is $T(n,k)=\\lceil\\log_2 n\\rceil + k$.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2013 14:30:01 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Hovnanyan", "V. H.", ""], ["Nahapetyan", "H. E.", ""], ["Poghosyan", "Su. S.", ""], ["Poghosyan", "V. S.", ""]]}, {"id": "1304.5702", "submitter": "Philip Bille", "authors": "Philip Bille, Inge Li Goertz, Gad M. Landau, and Oren Weimann", "title": "Tree Compression with Top Trees", "comments": "An extended abstract of this paper appeared at the 40th International\n  Colloquium on Automata, Languages and Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new compression scheme for labeled trees based on top trees.\nOur compression scheme is the first to simultaneously take advantage of\ninternal repeats in the tree (as opposed to the classical DAG compression that\nonly exploits rooted subtree repeats) while also supporting fast navigational\nqueries directly on the compressed representation. We show that the new\ncompression scheme achieves close to optimal worst-case compression, can\ncompress exponentially better than DAG compression, is never much worse than\nDAG compression, and supports navigational queries in logarithmic time.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 07:38:50 GMT"}, {"version": "v2", "created": "Sun, 11 May 2014 08:19:41 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Bille", "Philip", ""], ["Goertz", "Inge Li", ""], ["Landau", "Gad M.", ""], ["Weimann", "Oren", ""]]}, {"id": "1304.5714", "submitter": "Szabolcs Iv\\'an", "authors": "Szabolcs Ivan, Judit Nagy-Gyorgy", "title": "On the structure and syntactic complexity of generalized definite\n  languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a forbidden pattern characterization for the class of generalized\ndefinite languages, show that the corresponding problem is NL-complete and can\nbe solved in quadratic time. We also show that their syntactic complexity\ncoincides with that of the definite languages and give an upper bound of n! for\nthis measure.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 09:44:30 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Ivan", "Szabolcs", ""], ["Nagy-Gyorgy", "Judit", ""]]}, {"id": "1304.5719", "submitter": "Jukka Suomela", "authors": "Danny Dolev, Keijo Heljanko, Matti J\\\"arvisalo, Janne H. Korhonen,\n  Christoph Lenzen, Joel Rybicki, Jukka Suomela, Siert Wieringa", "title": "Synchronous Counting and Computational Algorithm Design", "comments": "35 pages, extended and revised version", "journal-ref": null, "doi": "10.1016/j.jcss.2015.09.002", "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a complete communication network on $n$ nodes, each of which is a\nstate machine. In synchronous 2-counting, the nodes receive a common clock\npulse and they have to agree on which pulses are \"odd\" and which are \"even\". We\nrequire that the solution is self-stabilising (reaching the correct operation\nfrom any initial state) and it tolerates $f$ Byzantine failures (nodes that\nsend arbitrary misinformation). Prior algorithms are expensive to implement in\nhardware: they require a source of random bits or a large number of states.\n  This work consists of two parts. In the first part, we use computational\ntechniques (often known as synthesis) to construct very compact deterministic\nalgorithms for the first non-trivial case of $f = 1$. While no algorithm exists\nfor $n < 4$, we show that as few as 3 states per node are sufficient for all\nvalues $n \\ge 4$. Moreover, the problem cannot be solved with only 2 states per\nnode for $n = 4$, but there is a 2-state solution for all values $n \\ge 6$.\n  In the second part, we develop and compare two different approaches for\nsynthesising synchronous counting algorithms. Both approaches are based on\ncasting the synthesis problem as a propositional satisfiability (SAT) problem\nand employing modern SAT-solvers. The difference lies in how to solve the SAT\nproblem: either in a direct fashion, or incrementally within a counter-example\nguided abstraction refinement loop. Empirical results suggest that the former\ntechnique is more efficient if we want to synthesise time-optimal algorithms,\nwhile the latter technique discovers non-optimal algorithms more quickly.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 10:58:03 GMT"}, {"version": "v2", "created": "Mon, 5 Jan 2015 10:40:27 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dolev", "Danny", ""], ["Heljanko", "Keijo", ""], ["J\u00e4rvisalo", "Matti", ""], ["Korhonen", "Janne H.", ""], ["Lenzen", "Christoph", ""], ["Rybicki", "Joel", ""], ["Suomela", "Jukka", ""], ["Wieringa", "Siert", ""]]}, {"id": "1304.5746", "submitter": "Petr Golovach", "authors": "Fedor V. Fomin and Petr A. Golovach", "title": "Long Circuits and Large Euler Subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An undirected graph is Eulerian if it is connected and all its vertices are\nof even degree. Similarly, a directed graph is Eulerian, if for each vertex its\nin-degree is equal to its out-degree. It is well known that Eulerian graphs can\nbe recognized in polynomial time while the problems of finding a maximum\nEulerian subgraph or a maximum induced Eulerian subgraph are NP-hard. In this\npaper, we study the parameterized complexity of the following Euler subgraph\nproblems:\n  - Large Euler Subgraph: For a given graph G and integer parameter k, does G\ncontain an induced Eulerian subgraph with at least k vertices?\n  - Long Circuit: For a given graph G and integer parameter k, does G contain\nan Eulerian subgraph with at least k edges?\n  Our main algorithmic result is that Large Euler Subgraph is fixed parameter\ntractable (FPT) on undirected graphs. We find this a bit surprising because the\nproblem of finding an induced Eulerian subgraph with exactly k vertices is\nknown to be W[1]-hard. The complexity of the problem changes drastically on\ndirected graphs. On directed graphs we obtained the following complexity\ndichotomy: Large Euler Subgraph is NP-hard for every fixed k>3 and is solvable\nin polynomial time for k<=3. For Long Circuit, we prove that the problem is FPT\non directed and undirected graphs.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 15:04:59 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""]]}, {"id": "1304.5773", "submitter": "Frank Gaitan", "authors": "Frank Gaitan and Lane Clark", "title": "Graph isomorphism and adiabatic quantum computing", "comments": "22 pages; 18 figures; and 6 tables; version to appear in Physical\n  Review A", "journal-ref": "Phys. Rev. A vol. 89, 022342 (2014)", "doi": "10.1103/PhysRevA.89.022342", "report-no": null, "categories": "quant-ph cs.DS math-ph math.CO math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Graph Isomorphism problem two N-vertex graphs G and G' are given and\nthe task is to determine whether there exists a permutation of the vertices of\nG that preserves adjacency and transforms G into G'. If yes, then G and G' are\nsaid to be isomorphic; otherwise they are non-isomorphic. The GI problem is an\nimportant problem in computer science and is thought to be of comparable\ndifficulty to integer factorization. In this paper we present a quantum\nalgorithm that solves arbitrary instances of GI and can also determine all\nautomorphisms of a given graph. We show how the GI problem can be converted to\na combinatorial optimization problem that can be solved using adiabatic quantum\nevolution. We numerically simulate the algorithm's quantum dynamics and show\nthat it correctly: (i) distinguishes non-isomorphic graphs; (ii) recognizes\nisomorphic graphs; and (iii) finds all automorphisms of a given graph G. We\nthen discuss the GI quantum algorithm's experimental implementation, and close\nby showing how it can be leveraged to give a quantum algorithm that solves\narbitrary instances of the NP-Complete Sub-Graph Isomorphism problem.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 18:09:17 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2014 20:01:59 GMT"}], "update_date": "2014-03-03", "authors_parsed": [["Gaitan", "Frank", ""], ["Clark", "Lane", ""]]}, {"id": "1304.5799", "submitter": "Yvonne-Anne Pignolet", "authors": "Yvonne-Anne Pignolet, Stefan Schmid, Gilles Tredan", "title": "Request Complexity of VNet Topology Extraction: Dictionary-Based Attacks", "comments": "full version of paper at NETYS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network virtualization paradigm envisions an Internet where arbitrary\nvirtual networks (VNets) can be specified and embedded over a shared substrate\n(e.g., the physical infrastructure). As VNets can be requested at short notice\nand for a desired time period only, the paradigm enables a flexible service\ndeployment and an efficient resource utilization.\n  This paper investigates the security implications of such an architecture. We\nconsider a simple model where an attacker seeks to extract secret information\nabout the substrate topology, by issuing repeated VNet embedding requests. We\npresent a general framework that exploits basic properties of the VNet\nembedding relation to infer the entire topology. Our framework is based on a\ngraph motif dictionary applicable for various graph classes. Moreover, we\nprovide upper bounds on the request complexity, the number of requests needed\nby the attacker to succeed.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 20:53:23 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Pignolet", "Yvonne-Anne", ""], ["Schmid", "Stefan", ""], ["Tredan", "Gilles", ""]]}, {"id": "1304.5849", "submitter": "Marcin Kami\\'nski", "authors": "Jaroslaw Blasiok and Marcin Kaminski", "title": "Chain minors are FPT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two finite posets P and Q, P is a chain minor of Q if there exists a\npartial function f from the elements of Q to the elements of P such that for\nevery chain in P there is a chain C_Q in Q with the property that f restricted\nto C_Q is an isomorphism of chains. We give an algorithm to decide whether a\nposet P is a chain minor of o poset Q that runs in time O(|Q| log |Q|) for\nevery fixed poset P. This solves an open problem from the monograph by Downey\nand Fellows [Parameterized Complexity, 1999] who asked whether the problem was\nfixed parameter tractable.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 06:22:34 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Blasiok", "Jaroslaw", ""], ["Kaminski", "Marcin", ""]]}, {"id": "1304.5870", "submitter": "Petr Golovach", "authors": "Rajesh Chitnis, Fedor V. Fomin and Petr A. Golovach", "title": "Parameterized Complexity of the Anchored k-Core Problem for Directed\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bhawalkar, Kleinberg, Lewi, Roughgarden, and Sharma [ICALP 2012] introduced\nthe Anchored k-Core problem, where the task is for a given graph G and integers\nb, k, and p to find an induced subgraph H with at least p vertices (the core)\nsuch that all but at most b vertices (called anchors) of H are of degree at\nleast k. In this paper, we extend the notion of k-core to directed graphs and\nprovide a number of new algorithmic and complexity results for the directed\nversion of the problem. We show that\n  - The decision version of the problem is NP-complete for every k>=1 even if\nthe input graph is restricted to be a planar directed acyclic graph of maximum\ndegree at most k+2.\n  - The problem is fixed parameter tractable (FPT) parameterized by the size of\nthe core p for k=1, and W[1]-hard for k>=2.\n  - When the maximum degree of the graph is at most \\Delta, the problem is FPT\nparameterized by p+\\Delta if k>= \\Delta/2.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 08:43:19 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2013 08:42:08 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Chitnis", "Rajesh", ""], ["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""]]}, {"id": "1304.5872", "submitter": "Eylon Yogev", "authors": "Moni Naor and Eylon Yogev", "title": "Sliding Bloom Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bloom filter is a method for reducing the space (memory) required for\nrepresenting a set by allowing a small error probability. In this paper we\nconsider a \\emph{Sliding Bloom Filter}: a data structure that, given a stream\nof elements, supports membership queries of the set of the last $n$ elements (a\nsliding window), while allowing a small error probability. We formally define\nthe data structure and its relevant parameters and analyze the time and memory\nrequirements needed to achieve them. We give a low space construction that runs\nin O(1) time per update with high probability (that is, for all sequences with\nhigh probability all operations take constant time) and provide an almost\nmatching lower bound on the space that shows that our construction has the best\npossible space consumption up to an additive lower order term.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 08:51:25 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2013 17:28:02 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2013 07:25:35 GMT"}, {"version": "v4", "created": "Sun, 22 Sep 2013 09:25:51 GMT"}, {"version": "v5", "created": "Mon, 7 Oct 2013 09:10:33 GMT"}, {"version": "v6", "created": "Wed, 9 Oct 2013 12:28:39 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Naor", "Moni", ""], ["Yogev", "Eylon", ""]]}, {"id": "1304.5876", "submitter": "Jin-Kao Hao", "authors": "Yang Wang, Jin-Kao Hao, Fred Glover, Zhipeng L\\\"u", "title": "Solving the minimum sum coloring problem via binary quadratic\n  programming", "comments": "Short pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, binary quadratic programming (BQP) has been successively\napplied to solve several combinatorial optimization problems. We consider in\nthis paper a study of using the BQP model to solve the minimum sum coloring\nproblem (MSCP). For this purpose, we recast the MSCP with a quadratic model\nwhich is then solved via a recently proposed Path Relinking (PR) algorithm\ndesigned for the general BQP. Based on a set of MSCP benchmark instances, we\ninvestigate the performance of this solution approach compared with existing\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 08:56:11 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Wang", "Yang", ""], ["Hao", "Jin-Kao", ""], ["Glover", "Fred", ""], ["L\u00fc", "Zhipeng", ""]]}, {"id": "1304.5934", "submitter": "Bugra Caskurlu", "authors": "Bugra Caskurlu, K. Subramani", "title": "On Partial Vertex Cover on Bipartite Graphs and Trees", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the Vertex Cover problem is in P on bipartite graphs,\nhowever; the computational complexity of the Partial Vertex Cover problem on\nbipartite graphs is open. In this paper, we first show that the Partial Vertex\nCover problem is NP-hard on bipartite graphs. We then identify an interesting\nspecial case of bipartite graphs, for which the Partial Vertex Cover problem\ncan be solved in polynomial-time. We also show that the set of acyclic\nbipartite graphs, i.e., forests, and the set of bipartite graph where the\ndegree of each vertex is at most 3 fall into that special case. Therefore, we\nprove that the Partial Vertex Cover problem is in P on trees, and it is also in\nP on the set of bipartite graphs where the degree of each vertex is at most 3.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 12:59:20 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Caskurlu", "Bugra", ""], ["Subramani", "K.", ""]]}, {"id": "1304.5942", "submitter": "Eranda Cela", "authors": "Eranda Cela and Rostislav Stanek", "title": "Heuristics for the data arrangement problem on regular trees", "comments": "34 pages, 16 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data arrangement problem on regular trees (DAPT) consists in assigning\nthe vertices of a given graph G to the leaves of a d-regular tree T such that\nthe sum of the pairwise distances of all pairs of leaves in T which correspond\nto edges of G is minimised. Luczak and Noble [6] have shown that this problem\nis NP-hard for every fixed d larger than or equal to 2. In this paper we\npropose construction and local search heuristics for the DAPT and introduce a\nlower bound for this problem. The analysis of the performance of the heuristics\nis based on two considerations: a) the quality of the solutions produced by the\nheuristics as compared to the respective lower bounds b) for a special class of\ninstances with known optimal solution we evaluate the gap between the optimal\nvalue of the objective function and the objective function value attained by\nthe heuristic solution, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 13:18:18 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Cela", "Eranda", ""], ["Stanek", "Rostislav", ""]]}, {"id": "1304.5971", "submitter": "Sandor P. Fekete", "authors": "S\\'andor P. Fekete, Nils Schweer, Jan-Marc Reinhardt", "title": "A Competitive Strategy for Distance-Aware Online Shape Allocation", "comments": "15 pages, 9 figures, 3 tables; extended abstract version appears in\n  WALCOM 2013, LNCS 7748, pp. 41-52", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following online allocation problem: Given a unit square S,\nand a sequence of numbers n_i between 0 and 1, with partial sum bounded by 1;\nat each step i, select a region C_i of previously unassigned area n_i in S. The\nobjective is to make these regions compact in a distance-aware sense: minimize\nthe maximum (normalized) average Manhattan distance between points from the\nsame set C_i. Related location problems have received a considerable amount of\nattention; in particular, the problem of determining the \"optimal shape of a\ncity\", i.e., allocating a single n_i has been studied. We present an online\nstrategy, based on an analysis of space-filling curves; for continuous shapes,\nwe prove a factor of 1.8092, and 1.7848 for discrete point sets.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 14:49:39 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Fekete", "S\u00e1ndor P.", ""], ["Schweer", "Nils", ""], ["Reinhardt", "Jan-Marc", ""]]}, {"id": "1304.5973", "submitter": "Ilya Razenshteyn", "authors": "Andrew V. Goldberg, Ilya Razenshteyn, Ruslan Savchenko", "title": "Separating Hierarchical and General Hub Labelings", "comments": "11 pages, minor corrections, MFCS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of distance oracles, a labeling algorithm computes vertex\nlabels during preprocessing. An $s,t$ query computes the corresponding distance\nfrom the labels of $s$ and $t$ only, without looking at the input graph. Hub\nlabels is a class of labels that has been extensively studied. Performance of\nthe hub label query depends on the label size. Hierarchical labels are a\nnatural special kind of hub labels. These labels are related to other problems\nand can be computed more efficiently. This brings up a natural question of the\nquality of hierarchical labels. We show that there is a gap: optimal\nhierarchical labels can be polynomially bigger than the general hub labels. To\nprove this result, we give tight upper and lower bounds on the size of\nhierarchical and general labels for hypercubes.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 15:06:41 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2013 05:16:53 GMT"}, {"version": "v3", "created": "Sun, 23 Jun 2013 03:16:08 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Goldberg", "Andrew V.", ""], ["Razenshteyn", "Ilya", ""], ["Savchenko", "Ruslan", ""]]}, {"id": "1304.5991", "submitter": "Shalabh Vidyarthi", "authors": "Shalabh Vidyarthi and Kaushal K Shukla", "title": "Approximation Algorithms for Vehicle Routing Problems with Stochastic\n  Demands on Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the vehicle routing problem with stochastic demands (VRPSD) on\ntree structured networks with a single depot. The problem we are concerned with\nin this paper is to find a set of tours for the vehicle with minimum expected\nlength. Every tour begins at the depot, visits a subset of customers and\nreturns to the depot without violating the capacity constraint. Randomized\napproximation algorithm achieving approximation guarantees of 2 for\nsplit-delivery VRPSD, and 3 for un-split delivery VRPSD are obtained.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 15:48:41 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Vidyarthi", "Shalabh", ""], ["Shukla", "Kaushal K", ""]]}, {"id": "1304.6007", "submitter": "Enoch Peserico", "authors": "Enoch Peserico", "title": "Paging with dynamic memory capacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.OS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalization of the classic paging problem that allows the\namount of available memory to vary over time - capturing a fundamental property\nof many modern computing realities, from cloud computing to multi-core and\nenergy-optimized processors. It turns out that good performance in the\n\"classic\" case provides no performance guarantees when memory capacity\nfluctuates: roughly speaking, moving from static to dynamic capacity can mean\nthe difference between optimality within a factor 2 in space and time, and\nsuboptimality by an arbitrarily large factor. More precisely, adopting the\ncompetitive analysis framework, we show that some online paging algorithms,\ndespite having an optimal (h,k)-competitive ratio when capacity remains\nconstant, are not (3,k)-competitive for any arbitrarily large k in the presence\nof minimal capacity fluctuations. In this light it is surprising that several\nclassic paging algorithms perform remarkably well even if memory capacity\nchanges adversarially - even without taking those changes into explicit\naccount! In particular, we prove that LFD still achieves the minimum number of\nfaults, and that several classic online algorithms such as LRU have a \"dynamic\"\n(h,k)-competitive ratio that is the best one can achieve without knowledge of\nfuture page requests, even if one had perfect knowledge of future capacity\nfluctuations (an exact characterization of this ratio shows it is almost,\nalbeit not quite, equal to the \"classic\" ratio k/(k-h+1)). In other words, with\ncareful management, knowing/predicting future memory resources appears far less\ncrucial to performance than knowing/predicting future data accesses.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 16:23:24 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Peserico", "Enoch", ""]]}, {"id": "1304.6023", "submitter": "Gonzalo Navarro", "authors": "Gonzalo Navarro", "title": "Spaces, Trees and Colors: The Algorithmic Landscape of Document\n  Retrieval on Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document retrieval is one of the best established information retrieval\nactivities since the sixties, pervading all search engines. Its aim is to\nobtain, from a collection of text documents, those most relevant to a pattern\nquery. Current technology is mostly oriented to \"natural language\" text\ncollections, where inverted indices are the preferred solution. As successful\nas this paradigm has been, it fails to properly handle some East Asian\nlanguages and other scenarios where the \"natural language\" assumptions do not\nhold. In this survey we cover the recent research in extending the document\nretrieval techniques to a broader class of sequence collections, which has\napplications bioinformatics, data and Web mining, chemoinformatics, software\nengineering, multimedia information retrieval, and many others. We focus on the\nalgorithmic aspects of the techniques, uncovering a rich world of relations\nbetween document retrieval challenges and fundamental problems on trees,\nstrings, range queries, discrete geometry, and others.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 17:12:43 GMT"}, {"version": "v2", "created": "Fri, 10 May 2013 05:52:04 GMT"}, {"version": "v3", "created": "Tue, 14 May 2013 05:04:06 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2013 23:11:49 GMT"}, {"version": "v5", "created": "Fri, 27 Sep 2013 21:35:29 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Navarro", "Gonzalo", ""]]}, {"id": "1304.6174", "submitter": "Nicholas Mattei", "authors": "Nicholas Mattei, Nina Narodytska, and Toby Walsh", "title": "How Hard Is It to Control an Election by Breaking Ties?", "comments": "Revised and expanded version including longer proofs and additional\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of controlling the result of an\nelection by breaking ties strategically. This problem is equivalent to the\nproblem of deciding the winner of an election under parallel universes\ntie-breaking. When the chair of the election is only asked to break ties to\nchoose between one of the co-winners, the problem is trivially easy. However,\nin multi-round elections, we prove that it can be NP-hard for the chair to\ncompute how to break ties to ensure a given result. Additionally, we show that\nthe form of the tie-breaking function can increase the opportunities for\ncontrol. Indeed, we prove that it can be NP-hard to control an election by\nbreaking ties even with a two-stage voting rule.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 05:58:29 GMT"}, {"version": "v2", "created": "Thu, 29 May 2014 04:48:08 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Mattei", "Nicholas", ""], ["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1304.6188", "submitter": "Christoph D\\\"urr", "authors": "Nikhil Bansal and Christoph D\\\"urr and Nguyen Kim Thang and \\'Oscar C.\n  V\\'asquez", "title": "The local-global conjecture for scheduling with non-linear cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical scheduling problem on a single machine, on which we\nneed to schedule sequentially $n$ given jobs. Every job $j$ has a processing\ntime $p_j$ and a priority weight $w_j$, and for a given schedule a completion\ntime $C_j$. In this paper we consider the problem of minimizing the objective\nvalue $\\sum_j w_j C_j^\\beta$ for some fixed constant $\\beta>0$. This\nnon-linearity is motivated for example by the learning effect of a machine\nimproving its efficiency over time, or by the speed scaling model. For\n$\\beta=1$, the well-known Smith's rule that orders job in the non-increasing\norder of $w_j/p_j$ give the optimum schedule. However, for $\\beta \\neq 1$, the\ncomplexity status of this problem is open. Among other things, a key issue here\nis that the ordering between a pair of jobs is not well-defined, and might\ndepend on where the jobs lie in the schedule and also on the jobs between them.\nWe investigate this question systematically and substantially generalize the\npreviously known results in this direction. These results lead to interesting\nnew dominance properties among schedules which lead to huge speed up in exact\nalgorithms for the problem. An experimental study evaluates the impact of these\nproperties on the exact algorithm A*.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 07:29:55 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2013 16:02:36 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2013 11:44:38 GMT"}, {"version": "v4", "created": "Mon, 16 Feb 2015 17:05:44 GMT"}, {"version": "v5", "created": "Mon, 21 Dec 2015 09:50:29 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Bansal", "Nikhil", ""], ["D\u00fcrr", "Christoph", ""], ["Thang", "Nguyen Kim", ""], ["V\u00e1squez", "\u00d3scar C.", ""]]}, {"id": "1304.6189", "submitter": "Janne H. Korhonen", "authors": "Fedor V. Fomin, Petr A. Golovach, Janne H. Korhonen", "title": "On the parameterized complexity of cutting a few vertices from a graph", "comments": null, "journal-ref": "38th International Symposium on Mathematical Foundations of\n  Computer Science (MFCS 2013), pages 421-432", "doi": "10.1007/978-3-642-40313-2_38", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of separating a small set of vertices\nfrom a graph by a small vertex-separator. That is, given a graph $G$ and\nintegers $k$, $t$, the task is to find a vertex set $X$ with $|X| \\le k$ and\n$|N(X)| \\le t$. We show that\n  - the problem is fixed-parameter tractable (FPT) when parameterized by $t$\nbut W[1]-hard when parameterized by $k$, and\n  - a terminal variant of the problem, where $X$ must contain a given vertex\n$s$, is W[1]-hard when parameterized either by $k$ or by $t$ alone, but is FPT\nwhen parameterized by $k + t$.\n  We also show that if we consider edge cuts instead of vertex cuts, the\nterminal variant is NP-hard.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 07:38:34 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2013 13:32:40 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Korhonen", "Janne H.", ""]]}, {"id": "1304.6232", "submitter": "Atri Rudra", "authors": "Anna C. Gilbert, Hung Q. Ngo, Ely Porat, Atri Rudra and Martin J.\n  Strauss", "title": "L2/L2-foreach sparse recovery with low risk", "comments": "1 figure, extended abstract to appear in ICALP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the \"foreach\" sparse recovery problem with failure\nprobability $p$. The goal of which is to design a distribution over $m \\times\nN$ matrices $\\Phi$ and a decoding algorithm $\\algo$ such that for every\n$\\vx\\in\\R^N$, we have the following error guarantee with probability at least\n$1-p$ \\[\\|\\vx-\\algo(\\Phi\\vx)\\|_2\\le C\\|\\vx-\\vx_k\\|_2,\\] where $C$ is a constant\n(ideally arbitrarily close to 1) and $\\vx_k$ is the best $k$-sparse\napproximation of $\\vx$.\n  Much of the sparse recovery or compressive sensing literature has focused on\nthe case of either $p = 0$ or $p = \\Omega(1)$. We initiate the study of this\nproblem for the entire range of failure probability. Our two main results are\nas follows: \\begin{enumerate} \\item We prove a lower bound on $m$, the number\nmeasurements, of $\\Omega(k\\log(n/k)+\\log(1/p))$ for $2^{-\\Theta(N)}\\le p <1$.\nCohen, Dahmen, and DeVore \\cite{CDD2007:NearOptimall2l2} prove that this bound\nis tight. \\item We prove nearly matching upper bounds for \\textit{sub-linear}\ntime decoding. Previous such results addressed only $p = \\Omega(1)$.\n\\end{enumerate}\n  Our results and techniques lead to the following corollaries: (i) the first\never sub-linear time decoding $\\lolo$ \"forall\" sparse recovery system that\nrequires a $\\log^{\\gamma}{N}$ extra factor (for some $\\gamma<1$) over the\noptimal $O(k\\log(N/k))$ number of measurements, and (ii) extensions of Gilbert\net al. \\cite{GHRSW12:SimpleSignals} results for information-theoretically\nbounded adversaries.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 11:00:45 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Gilbert", "Anna C.", ""], ["Ngo", "Hung Q.", ""], ["Porat", "Ely", ""], ["Rudra", "Atri", ""], ["Strauss", "Martin J.", ""]]}, {"id": "1304.6321", "submitter": "Daniel Lokshtanov", "authors": "Hans Bodlaender, P{\\aa}l G. Drange, Markus S. Dregi, Fedor V. Fomin,\n  Daniel Lokshtanov, Micha{\\l} Pilipczuk", "title": "A O(c^k n) 5-Approximation Algorithm for Treewidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm that for an input n-vertex graph G and integer k>0, in\ntime 2^[O(k)]n either outputs that the treewidth of G is larger than k, or\ngives a tree decomposition of G of width at most 5k+4. This is the first\nalgorithm providing a constant factor approximation for treewidth which runs in\ntime single-exponential in k and linear in n. Treewidth based computations are\nsubroutines of numerous algorithms. Our algorithm can be used to speed up many\nsuch algorithms to work in time which is single-exponential in the treewidth\nand linear in the input size.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 15:29:55 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Bodlaender", "Hans", ""], ["Drange", "P\u00e5l G.", ""], ["Dregi", "Markus S.", ""], ["Fomin", "Fedor V.", ""], ["Lokshtanov", "Daniel", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1304.6358", "submitter": "Peter Terlecky", "authors": "Amotz Bar-Noy, Dror Rawitz, Peter Terlecky", "title": "Maximizing Barrier Coverage Lifetime with Mobile Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor networks are ubiquitously used for detection and tracking and as a\nresult covering is one of the main tasks of such networks. We study the problem\nof maximizing the coverage lifetime of a barrier by mobile sensors with limited\nbattery powers, where the coverage lifetime is the time until there is a\nbreakdown in coverage due to the death of a sensor. Sensors are first deployed\nand then coverage commences. Energy is consumed in proportion to the distance\ntraveled for mobility, while for coverage, energy is consumed in direct\nproportion to the radius of the sensor raised to a constant exponent. We study\ntwo variants which are distinguished by whether the sensing radii are given as\npart of the input or can be optimized, the fixed radii problem and the variable\nradii problem. We design parametric search algorithms for both problems for the\ncase where the final order of the sensors is predetermined and for the case\nwhere sensors are initially located at barrier endpoints. In contrast, we show\nthat the variable radii problem is strongly NP-hard and provide hardness of\napproximation results for fixed radii for the case where all the sensors are\ninitially co-located at an internal point of the barrier.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 17:31:18 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Bar-Noy", "Amotz", ""], ["Rawitz", "Dror", ""], ["Terlecky", "Peter", ""]]}, {"id": "1304.6393", "submitter": "Mostafa Haghir Chehreghani", "authors": "Mostafa Haghir Chehreghani", "title": "Efficient Algorithms for Approximate Triangle Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting the number of triangles in a graph has many important applications\nin network analysis. Several frequently computed metrics like the clustering\ncoefficient and the transitivity ratio need to count the number of triangles in\nthe network. Furthermore, triangles are one of the most important graph classes\nconsidered in network mining. In this paper, we present a new randomized\nalgorithm for approximate triangle counting. The algorithm can be adopted with\ndifferent sampling methods and give effective triangle counting methods. In\nparticular, we present two sampling methods, called the \\textit{$q$-optimal\nsampling} and the \\textit{edge sampling}, which respectively give $O(sm)$ and\n$O(sn)$ time algorithms with nice error bounds ($m$ and $n$ are respectively\nthe number of edges and vertices in the graph and $s$ is the number of\nsamples). Among others, we show, for example, that if an upper bound\n$\\widetilde{\\Delta^e}$ is known for the number of triangles incident to every\nedge, the proposed method provides an $1\\pm \\epsilon$ approximation which runs\nin $O( \\frac{\\widetilde{\\Delta^e} n \\log n}{\\widehat{\\Delta^e} \\epsilon^2} )$\ntime, where $\\widehat{\\Delta^e}$ is the average number of triangles incident to\nan edge. Finally we show that the algorithm can be adopted with streams. Then\nit, for example, will perform 2 passes over the data (if the size of the graph\nis known, otherwise it needs 3 passes) and will use $O(sn)$ space.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 19:55:18 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Chehreghani", "Mostafa Haghir", ""]]}, {"id": "1304.6420", "submitter": "Rajesh Chitnis", "authors": "Rajesh Chitnis, Fedor V. Fomin, Petr A. Golovach", "title": "Preventing Unraveling in Social Networks Gets Harder", "comments": "To appear in AAAI 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of users in social networks is often observed to be affected by\nthe actions of their friends. Bhawalkar et al. \\cite{bhawalkar-icalp}\nintroduced a formal mathematical model for user engagement in social networks\nwhere each individual derives a benefit proportional to the number of its\nfriends which are engaged. Given a threshold degree $k$ the equilibrium for\nthis model is a maximal subgraph whose minimum degree is $\\geq k$. However the\ndropping out of individuals with degrees less than $k$ might lead to a\ncascading effect of iterated withdrawals such that the size of equilibrium\nsubgraph becomes very small. To overcome this some special vertices called\n\"anchors\" are introduced: these vertices need not have large degree. Bhawalkar\net al. \\cite{bhawalkar-icalp} considered the \\textsc{Anchored $k$-Core}\nproblem: Given a graph $G$ and integers $b, k$ and $p$ do there exist a set of\nvertices $B\\subseteq H\\subseteq V(G)$ such that $|B|\\leq b, |H|\\geq p$ and\nevery vertex $v\\in H\\setminus B$ has degree at least $k$ is the induced\nsubgraph $G[H]$. They showed that the problem is NP-hard for $k\\geq 2$ and gave\nsome inapproximability and fixed-parameter intractability results. In this\npaper we give improved hardness results for this problem. In particular we show\nthat the \\textsc{Anchored $k$-Core} problem is W[1]-hard parameterized by $p$,\neven for $k=3$. This improves the result of Bhawalkar et al.\n\\cite{bhawalkar-icalp} (who show W[2]-hardness parameterized by $b$) as our\nparameter is always bigger since $p\\geq b$. Then we answer a question of\nBhawalkar et al. \\cite{bhawalkar-icalp} by showing that the \\textsc{Anchored\n$k$-Core} problem remains NP-hard on planar graphs for all $k\\geq 3$, even if\nthe maximum degree of the graph is $k+2$. Finally we show that the problem is\nFPT on planar graphs parameterized by $b$ for all $k\\geq 7$.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 20:44:07 GMT"}], "update_date": "2013-04-25", "authors_parsed": [["Chitnis", "Rajesh", ""], ["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""]]}, {"id": "1304.6475", "submitter": "Haim Avron", "authors": "Haim Avron, Alex Druinsky, Anshul Gupta", "title": "Revisiting Asynchronous Linear Solvers: Provable Convergence Rate\n  Through Randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous methods for solving systems of linear equations have been\nresearched since Chazan and Miranker's pioneering 1969 paper on chaotic\nrelaxation. The underlying idea of asynchronous methods is to avoid processor\nidle time by allowing the processors to continue to make progress even if not\nall progress made by other processors has been communicated to them.\n  Historically, the applicability of asynchronous methods for solving linear\nequations was limited to certain restricted classes of matrices, such as\ndiagonally dominant matrices. Furthermore, analysis of these methods focused on\nproving convergence in the limit. Comparison of the asynchronous convergence\nrate with its synchronous counterpart and its scaling with the number of\nprocessors were seldom studied, and are still not well understood.\n  In this paper, we propose a randomized shared-memory asynchronous method for\ngeneral symmetric positive definite matrices. We rigorously analyze the\nconvergence rate and prove that it is linear, and is close to that of the\nmethod's synchronous counterpart if the processor count is not excessive\nrelative to the size and sparsity of the matrix. We also present an algorithm\nfor unsymmetric systems and overdetermined least-squares. Our work presents a\nsignificant improvement in the applicability of asynchronous linear solvers as\nwell as in their convergence analysis, and suggests randomization as a key\nparadigm to serve as a foundation for asynchronous methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 03:18:53 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2013 20:19:45 GMT"}, {"version": "v3", "created": "Wed, 2 Jul 2014 20:43:04 GMT"}, {"version": "v4", "created": "Fri, 18 Jul 2014 20:08:45 GMT"}, {"version": "v5", "created": "Fri, 6 Mar 2015 21:17:17 GMT"}, {"version": "v6", "created": "Tue, 14 Jul 2015 20:35:14 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Avron", "Haim", ""], ["Druinsky", "Alex", ""], ["Gupta", "Anshul", ""]]}, {"id": "1304.6588", "submitter": "Hang Zhou", "authors": "Claire Mathieu and Hang Zhou", "title": "Graph Reconstruction via Distance Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of reconstructing a hidden graph given access to a\ndistance oracle. We design randomized algorithms for the following problems:\nreconstruction of a degree bounded graph with query complexity\n$\\tilde{O}(n^{3/2})$; reconstruction of a degree bounded outerplanar graph with\nquery complexity $\\tilde{O}(n)$; and near-optimal approximate reconstruction of\na general graph.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 13:57:03 GMT"}], "update_date": "2013-04-25", "authors_parsed": [["Mathieu", "Claire", ""], ["Zhou", "Hang", ""]]}, {"id": "1304.6593", "submitter": "L\\'aszl\\'o V\\'egh", "authors": "D\\'aniel Marx and L\\'aszl\\'o A. V\\'egh", "title": "Fixed-parameter algorithms for minimum cost edge-connectivity\n  augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider connectivity-augmentation problems in a setting where each\npotential new edge has a nonnegative cost associated with it, and the task is\nto achieve a certain connectivity target with at most p new edges of minimum\ntotal cost. The main result is that the minimum cost augmentation of\nedge-connectivity from k-1 to k with at most p new edges is fixed-parameter\ntractable parameterized by p and admits a polynomial kernel. We also prove the\nfixed-parameter tractability of increasing edge-connectivity from 0 to 2, and\nincreasing node-connectivity from 1 to 2.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 14:06:47 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2013 09:20:28 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Marx", "D\u00e1niel", ""], ["V\u00e9gh", "L\u00e1szl\u00f3 A.", ""]]}, {"id": "1304.6707", "submitter": "Rastislav \\v{S}r\\'amek", "authors": "Mat\\'u\\v{s} Mihal\\'ak and Rastislav \\v{S}r\\'amek and Peter Widmayer", "title": "Counting approximately-shortest paths in directed acyclic graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a directed acyclic graph with positive edge-weights, two vertices s and\nt, and a threshold-weight L, we present a fully-polynomial time\napproximation-scheme for the problem of counting the s-t paths of length at\nmost L. We extend the algorithm for the case of two (or more) instances of the\nsame problem. That is, given two graphs that have the same vertices and edges\nand differ only in edge-weights, and given two threshold-weights L_1 and L_2,\nwe show how to approximately count the s-t paths that have length at most L_1\nin the first graph and length at most L_2 in the second graph. We believe that\nour algorithms should find application in counting approximate solutions of\nrelated optimization problems, where finding an (optimum) solution can be\nreduced to the computation of a shortest path in a purpose-built auxiliary\ngraph.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 19:46:23 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2013 13:41:42 GMT"}], "update_date": "2013-10-14", "authors_parsed": [["Mihal\u00e1k", "Mat\u00fa\u0161", ""], ["\u0160r\u00e1mek", "Rastislav", ""], ["Widmayer", "Peter", ""]]}, {"id": "1304.6740", "submitter": "Piotr Sankowski", "authors": "Harold N. Gabow and Piotr Sankowski", "title": "Algebraic Algorithms for b-Matching, Shortest Undirected Paths, and\n  f-Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G=(V,E) be a graph with f:V\\to Z_+ a function assigning degree bounds to\nvertices. We present the first efficient algebraic algorithm to find an\nf-factor. The time is \\tilde{O}(f(V)^{\\omega}). More generally for graphs with\nintegral edge weights of maximum absolute value W we find a maximum weight\nf-factor in time \\tilde{O}(Wf(V)^{\\omega}). (The algorithms are randomized,\ncorrect with high probability and Las Vegas; the time bound is worst-case.) We\nalso present three specializations of these algorithms: For maximum weight\nperfect f-matching the algorithm is considerably simpler (and almost identical\nto its special case of ordinary weighted matching). For the single-source\nshortest-path problem in undirected graphs with conservative edge weights, we\npresent a generalization of the shortest-path tree, and we compute it in\n\\tilde{O(Wn^{\\omega}) time. For bipartite graphs, we improve the known\ncomplexity bounds for vertex capacitated max-flow and min-cost max-flow on a\nsubclass of graphs.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 20:26:13 GMT"}], "update_date": "2013-04-26", "authors_parsed": [["Gabow", "Harold N.", ""], ["Sankowski", "Piotr", ""]]}, {"id": "1304.6800", "submitter": "Richard Schmied", "authors": "Marek Karpinski and Richard Schmied", "title": "Approximation Hardness of Graphic TSP on Cubic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove explicit approximation hardness results for the Graphic TSP on cubic\nand subcubic graphs as well as the new inapproximability bounds for the\ncorresponding instances of the (1,2)-TSP. The proof technique uses new modular\nconstructions of simulating gadgets for the restricted cubic and subcubic\ninstances. The modular constructions used in the paper could be also of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 05:07:16 GMT"}, {"version": "v2", "created": "Tue, 14 May 2013 17:20:50 GMT"}], "update_date": "2013-05-15", "authors_parsed": [["Karpinski", "Marek", ""], ["Schmied", "Richard", ""]]}, {"id": "1304.6832", "submitter": "Son Hoang Dau", "authors": "Son Hoang Dau and Yeow Meng Chee", "title": "Polynomial Time Algorithm for Min-Ranks of Graphs with Simple Tree\n  Structures", "comments": "Accepted by Algorithmica, 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The min-rank of a graph was introduced by Haemers (1978) to bound the Shannon\ncapacity of a graph. This parameter of a graph has recently gained much more\nattention from the research community after the work of Bar-Yossef et al.\n(2006). In their paper, it was shown that the min-rank of a graph G\ncharacterizes the optimal scalar linear solution of an instance of the Index\nCoding with Side Information (ICSI) problem described by the graph G. It was\nshown by Peeters (1996) that computing the min-rank of a general graph is an\nNP-hard problem. There are very few known families of graphs whose min-ranks\ncan be found in polynomial time. In this work, we introduce a new family of\ngraphs with efficiently computed min-ranks. Specifically, we establish a\npolynomial time dynamic programming algorithm to compute the min-ranks of\ngraphs having simple tree structures. Intuitively, such graphs are obtained by\ngluing together, in a tree-like structure, any set of graphs for which the\nmin-ranks can be determined in polynomial time. A polynomial time algorithm to\nrecognize such graphs is also proposed.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 08:41:22 GMT"}], "update_date": "2016-11-26", "authors_parsed": [["Dau", "Son Hoang", ""], ["Chee", "Yeow Meng", ""]]}, {"id": "1304.6897", "submitter": "John Iacono", "authors": "Prosenjit Bose and Karim Dou\\\"ieb and John Iacono and Stefan Langerman", "title": "The Power and Limitations of Static Binary Search Trees with Lazy Finger", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A static binary search tree where every search starts from where the previous\none ends (lazy finger) is considered. Such a search method is more powerful\nthan that of the classic optimal static trees, where every search starts from\nthe root (root finger), and less powerful than when rotations are\nallowed---where finding the best rotation based tree is the topic of the\ndynamic optimality conjecture of Sleator and Tarjan. The runtime of the classic\nroot-finger tree can be expressed in terms of the entropy of the distribution\nof the searches, but we show that this is not the case for the optimal lazy\nfinger tree. A non-entropy based asymptotically-tight expression for the\nruntime of the optimal lazy finger trees is derived, and a dynamic\nprogramming-based method is presented to compute the optimal tree.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 12:46:53 GMT"}], "update_date": "2013-04-26", "authors_parsed": [["Bose", "Prosenjit", ""], ["Dou\u00efeb", "Karim", ""], ["Iacono", "John", ""], ["Langerman", "Stefan", ""]]}, {"id": "1304.6906", "submitter": "Christian Konrad", "authors": "Christian Konrad, Adi Ros\\'en", "title": "Approximating Semi-Matchings in Streaming and in Two-Party Communication", "comments": "This is the long version including all proves of the ICALP 2013 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the communication complexity and streaming complexity of\napproximating unweighted semi-matchings. A semi-matching in a bipartite graph G\n= (A, B, E), with n = |A|, is a subset of edges S that matches all A vertices\nto B vertices with the goal usually being to do this as fairly as possible.\nWhile the term 'semi-matching' was coined in 2003 by Harvey et al. [WADS 2003],\nthe problem had already previously been studied in the scheduling literature\nunder different names.\n  We present a deterministic one-pass streaming algorithm that for any 0 <=\n\\epsilon <= 1 uses space O(n^{1+\\epsilon}) and computes an\nO(n^{(1-\\epsilon)/2})-approximation to the semi-matching problem. Furthermore,\nwith O(log n) passes it is possible to compute an O(log n)-approximation with\nspace O(n).\n  In the one-way two-party communication setting, we show that for every\n\\epsilon > 0, deterministic communication protocols for computing an\nO(n^{1/((1+\\epsilon)c + 1)})-approximation require a message of size more than\ncn bits. We present two deterministic protocols communicating n and 2n edges\nthat compute an O(sqrt(n)) and an O(n^{1/3})-approximation respectively.\n  Finally, we improve on results of Harvey et al. [Journal of Algorithms 2006]\nand prove new links between semi-matchings and matchings. While it was known\nthat an optimal semi-matching contains a maximum matching, we show that there\nis a hierarchical decomposition of an optimal semi-matching into maximum\nmatchings. A similar result holds for semi-matchings that do not admit\nlength-two degree-minimizing paths.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 13:34:46 GMT"}], "update_date": "2013-04-26", "authors_parsed": [["Konrad", "Christian", ""], ["Ros\u00e9n", "Adi", ""]]}, {"id": "1304.6937", "submitter": "Ghaith Hiary", "authors": "Andrew R. Booker, Ghaith A. Hiary, Jon P. Keating", "title": "Detecting squarefree numbers", "comments": "31 pages, 3 figures, latest version", "journal-ref": "Duke Math. J. 164, no. 2 (2015), 235-275", "doi": "10.1215/00127094-2856619", "report-no": null, "categories": "math.NT cs.DS math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm, based on the explicit formula for $L$-functions and\nconditional on GRH, for proving that a given integer is squarefree with little\nor no knowledge of its factorization. We analyze the algorithm both\ntheoretically and practically, and use it to prove that several RSA challenge\nnumbers are not squarefull.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 15:29:44 GMT"}, {"version": "v2", "created": "Mon, 5 Jan 2015 05:14:58 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Booker", "Andrew R.", ""], ["Hiary", "Ghaith A.", ""], ["Keating", "Jon P.", ""]]}, {"id": "1304.7055", "submitter": "Zhihan Gao", "authors": "Zhihan Gao", "title": "An LP-based 3/2-approximation algorithm for the graphic s-t path TSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We design a new LP-based algorithm for the graphic $s$-$t$ path Traveling\nSalesman Problem (TSP), which achieves the best approximation factor of 1.5.\nThe algorithm is based on the idea of narrow cuts due to An, Kleinberg, and\nShmoys. It partly answers an open question of Seb\\H{o}.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2013 02:28:22 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Gao", "Zhihan", ""]]}, {"id": "1304.7061", "submitter": "Hideo Bannai", "authors": "Tomohiro I, Yuto Nakashima, Shunsuke Inenaga, Hideo Bannai and\n  Masayuki Takeda", "title": "Efficient Lyndon factorization of grammar compressed text", "comments": "CPM 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for computing the Lyndon factorization of a string\nthat is given in grammar compressed form, namely, a Straight Line Program\n(SLP). The algorithm runs in $O(n^4 + mn^3h)$ time and $O(n^2)$ space, where\n$m$ is the size of the Lyndon factorization, $n$ is the size of the SLP, and\n$h$ is the height of the derivation tree of the SLP. Since the length of the\ndecompressed string can be exponentially large w.r.t. $n, m$ and $h$, our\nresult is the first polynomial time solution when the string is given as SLP.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2013 04:04:54 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["I", "Tomohiro", ""], ["Nakashima", "Yuto", ""], ["Inenaga", "Shunsuke", ""], ["Bannai", "Hideo", ""], ["Takeda", "Masayuki", ""]]}, {"id": "1304.7067", "submitter": "Hideo Bannai", "authors": "Tomohiro I, Wataru Matsubara, Kouji Shimohira, Shunsuke Inenaga, Hideo\n  Bannai, Masayuki Takeda, Kazuyuki Narisawa and Ayumi Shinohara", "title": "Detecting regularities on grammar-compressed strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We solve the problems of detecting and counting various forms of regularities\nin a string represented as a Straight Line Program (SLP). Given an SLP of size\n$n$ that represents a string $s$ of length $N$, our algorithm compute all runs\nand squares in $s$ in $O(n^3h)$ time and $O(n^2)$ space, where $h$ is the\nheight of the derivation tree of the SLP. We also show an algorithm to compute\nall gapped-palindromes in $O(n^3h + gnh\\log N)$ time and $O(n^2)$ space, where\n$g$ is the length of the gap. The key technique of the above solution also\nallows us to compute the periods and covers of the string in $O(n^2 h)$ time\nand $O(nh(n+\\log^2 N))$ time, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2013 04:55:07 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["I", "Tomohiro", ""], ["Matsubara", "Wataru", ""], ["Shimohira", "Kouji", ""], ["Inenaga", "Shunsuke", ""], ["Bannai", "Hideo", ""], ["Takeda", "Masayuki", ""], ["Narisawa", "Kazuyuki", ""], ["Shinohara", "Ayumi", ""]]}, {"id": "1304.7121", "submitter": "Jordi Arjona Aroca", "authors": "Jordi Arjona Aroca, Antonio Fernandez Anta, Miguel A. Mosteiro,\n  Christopher Thraves and Lin Wang", "title": "Power-efficient Assignment of Virtual Machines to Physical Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by current trends in cloud computing, we study a version of the\ngeneralized assignment problem where a set of virtual processors has to be\nimplemented by a set of identical processors. For literature consistency, we\nsay that a set of virtual machines (VMs) is assigned to a set of physical\nmachines (PMs). The optimization criteria is to minimize the power consumed by\nall the PMs. We term the problem Virtual Machine Assignment (VMA). Crucial\ndifferences with previous work include a variable number of PMs, that each VM\nmust be assigned to exactly one PM (i.e., VMs cannot be implemented\nfractionally), and a minimum power consumption for each active PM. Such\ninfrastructure may be strictly constrained in the number of PMs or in the PMs'\ncapacity, depending on how costly (in terms of power consumption) is to add a\nnew PM to the system or to heavily load some of the existing PMs. Low usage or\nample budget yields models where PM capacity and/or the number of PMs may be\nassumed unbounded for all practical purposes. We study 4 VMA problems depending\non whether the capacity or the number of PMs is bounded or not. Specifically,\nwe study hardness and online competitiveness for a variety of cases. To the\nbest of our knowledge, this is the first comprehensive study of the VMA problem\nfor this cost function.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2013 10:58:16 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2013 21:02:45 GMT"}, {"version": "v3", "created": "Tue, 10 Jun 2014 08:55:55 GMT"}], "update_date": "2014-06-11", "authors_parsed": [["Aroca", "Jordi Arjona", ""], ["Anta", "Antonio Fernandez", ""], ["Mosteiro", "Miguel A.", ""], ["Thraves", "Christopher", ""], ["Wang", "Lin", ""]]}, {"id": "1304.7235", "submitter": "Tobias Brunsch", "authors": "Tobias Brunsch and Heiko R\\\"oglin", "title": "Finding Short Paths on Polytopes by the Shadow Vertex Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the shadow vertex algorithm can be used to compute a short path\nbetween a given pair of vertices of a polytope P = {x : Ax \\leq b} along the\nedges of P, where A \\in R^{m \\times n} is a real-valued matrix. Both, the\nlength of the path and the running time of the algorithm, are polynomial in m,\nn, and a parameter 1/delta that is a measure for the flatness of the vertices\nof P. For integer matrices A \\in Z^{m \\times n} we show a connection between\ndelta and the largest absolute value Delta of any sub-determinant of A,\nyielding a bound of O(Delta^4 m n^4) for the length of the computed path. This\nbound is expressed in the same parameter Delta as the recent non-constructive\nbound of O(Delta^2 n^4 \\log (n Delta)) by Bonifas et al.\n  For the special case of totally unimodular matrices, the length of the\ncomputed path simplifies to O(m n^4), which significantly improves the\npreviously best known constructive bound of O(m^{16} n^3 \\log^3(mn)) by Dyer\nand Frieze.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2013 17:24:53 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Brunsch", "Tobias", ""], ["R\u00f6glin", "Heiko", ""]]}, {"id": "1304.7355", "submitter": "Filip Proborszcz", "authors": "Filip Proborszcz", "title": "Web graph compression with fast access", "comments": "MSc thesis, May 2012, advisors: Szymon Grabowski, Wojciech Bieniecki;\n  65 pages, 16 figures, 6 tables, 5 code snippets, source code available at:\n  http://sourceforge.net/projects/webgraphcompres/files/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years studying the content of the World Wide Web became a very\nimportant yet rather difficult task. There is a need for a compression\ntechnique that would allow a web graph representation to be put into the memory\nwhile maintaining random access time competitive to the time needed to access\nuncompressed web graph on a hard drive.\n  There are already available techniques that accomplish this task, but there\nis still room for improvements and this thesis attempts to prove it. It\nincludes a comparison of two methods contained in state of art of this field\n(BV and k2partitioned) to two already implemented algorithms (rewritten,\nhowever, in C++ programming language to maximize speed and resource management\nefficiency), which are LM and 2D, and introduces the new variant of the latter\none, called 2D stripes.\n  This thesis serves as well as a proof of concept. The final considerations\nshow positive and negative aspects of all presented methods, expose the\nfeasibility of the new variant as well as indicate future direction for\ndevelopment.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2013 10:51:34 GMT"}, {"version": "v2", "created": "Wed, 1 May 2013 10:28:49 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Proborszcz", "Filip", ""]]}, {"id": "1304.7373", "submitter": "Gunjan Kumar", "authors": "Gunjan Kumar, Saswata Shannigrahi", "title": "NP-Hardness of Speed Scaling with a Sleep State", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.tcs.2015.06.012", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modern processor can dynamically set it's speed while it's active, and can\nmake a transition to sleep state when required. When the processor is operating\nat a speed $s$, the energy consumed per unit time is given by a convex power\nfunction $P(s)$ having the property that $P(0) > 0$ and $P\"(s) > 0$ for all\nvalues of $s$. Moreover, $C > 0$ units of energy is required to make a\ntransition from the sleep state to the active state. The jobs are specified by\ntheir arrival time, deadline and the processing volume.\n  We consider a scheduling problem, called speed scaling with sleep state,\nwhere each job has to be scheduled within their arrival time and deadline, and\nthe goal is to minimize the total energy consumption required to process these\njobs. Albers et. al. proved the NP-hardness of this problem by reducing an\ninstance of an NP-hard partition problem to an instance of this scheduling\nproblem. The instance of this scheduling problem consists of the arrival time,\nthe deadline and the processing volume for each of the jobs, in addition to $P$\nand $C$. Since $P$ and $C$ depend on the instance of the partition problem,\nthis proof of the NP-hardness of the speed scaling with sleep state problem\ndoesn't remain valid when $P$ and $C$ are fixed. In this paper, we prove that\nthe speed scaling with sleep state problem remains NP-hard for any fixed\npositive number $C$ and convex $P$ satisfying $P(0) > 0$ and $P\"(s) > 0$ for\nall values of $s$.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2013 14:18:42 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kumar", "Gunjan", ""], ["Shannigrahi", "Saswata", ""]]}, {"id": "1304.7403", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "Improved Approximation Algorithms for the Min-Max Selecting Items\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a simple deterministic $O(\\log K / \\log\\log K)$ approximation\nalgorithm for the Min-Max Selecting Items problem, where $K$ is the number of\nscenarios. While our main goal is simplicity, this result also improves over\nthe previous best approximation ratio of $O(\\log K)$ due to Kasperski, Kurpisz,\nand Zieli\\'nski (Information Processing Letters (2013)). Despite using the\nmethod of pessimistic estimators, the algorithm has a polynomial runtime also\nin the RAM model of computation. We also show that the LP formulation for this\nproblem by Kasperski and Zieli\\'nski (Annals of Operations Research (2009)),\nwhich is the basis for the previous work and ours, has an integrality gap of at\nleast $\\Omega(\\log K / \\log\\log K)$.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2013 19:56:34 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "1304.7456", "submitter": "He Sun", "authors": "He Sun", "title": "Counting Hypergraphs in Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first streaming algorithm for counting an arbitrary hypergraph\n$H$ of constant size in a massive hypergraph $G$. Our algorithm can handle both\nedge-insertions and edge-deletions, and is applicable for the distributed\nsetting. Moreover, our approach provides the first family of graph polynomials\nfor the hypergraph counting problem. Because of the close relationship between\nhypergraphs and set systems, our approach may have applications in studying\nsimilar problems.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2013 11:24:40 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Sun", "He", ""]]}, {"id": "1304.7505", "submitter": "Ramanujan M. S.", "authors": "M. S. Ramanujan and Saket Saurabh", "title": "Linear Time Parameterized Algorithms via Skew-Symmetric Multicuts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A skew-symmetric graph $(D=(V,A),\\sigma)$ is a directed graph $D$ with an\ninvolution $\\sigma$ on the set of vertices and arcs. In this paper, we\nintroduce a separation problem, $d$-Skew-Symmetric Multicut, where we are given\na skew-symmetric graph $D$, a family of $\\cal T$ of $d$-sized subsets of\nvertices and an integer $k$. The objective is to decide if there is a set\n$X\\subseteq A$ of $k$ arcs such that every set $J$ in the family has a vertex\n$v$ such that $v$ and $\\sigma(v)$ are in different connected components of\n$D'=(V,A\\setminus (X\\cup \\sigma(X))$. In this paper, we give an algorithm for\nthis problem which runs in time $O((4d)^{k}(m+n+\\ell))$, where $m$ is the\nnumber of arcs in the graph, $n$ the number of vertices and $\\ell$ the length\nof the family given in the input.\n  Using our algorithm, we show that Almost 2-SAT has an algorithm with running\ntime $O(4^kk^4\\ell)$ and we obtain algorithms for {\\sc Odd Cycle Transversal}\nand {\\sc Edge Bipartization} which run in time $O(4^kk^4(m+n))$ and\n$O(4^kk^5(m+n))$ respectively. This resolves an open problem posed by Reed,\nSmith and Vetta [Operations Research Letters, 2003] and improves upon the\nearlier almost linear time algorithm of Kawarabayashi and Reed [SODA, 2010].\n  We also show that Deletion q-Horn Backdoor Set Detection is a special case of\n3-Skew-Symmetric Multicut, giving us an algorithm for Deletion q-Horn Backdoor\nSet Detection which runs in time $O(12^kk^5\\ell)$. This gives the first\nfixed-parameter tractable algorithm for this problem answering a question posed\nin a paper by a superset of the authors [STACS, 2013]. Using this result, we\nget an algorithm for Satisfiability which runs in time $O(12^kk^5\\ell)$ where\n$k$ is the size of the smallest q-Horn deletion backdoor set, with $\\ell$ being\nthe length of the input formula.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2013 19:23:40 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Ramanujan", "M. S.", ""], ["Saurabh", "Saket", ""]]}, {"id": "1304.7512", "submitter": "Anastasios Sidiropoulos", "authors": "Anastasios Sidiropoulos", "title": "Non-positive curvature, and the planar embedding conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The planar embedding conjecture asserts that any planar metric admits an\nembedding into L_1 with constant distortion. This is a well-known open problem\nwith important algorithmic implications, and has received a lot of attention\nover the past two decades. Despite significant efforts, it has been verified\nonly for some very restricted cases, while the general problem remains elusive.\n  In this paper we make progress towards resolving this conjecture. We show\nthat every planar metric of non-positive curvature admits a constant-distortion\nembedding into L_1. This confirms the planar embedding conjecture for the case\nof non-positively curved metrics.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2013 19:57:06 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Sidiropoulos", "Anastasios", ""]]}, {"id": "1304.7530", "submitter": "Vahid Liaghat", "authors": "MohammadHossein Bateni, MohammadTaghi Hajiaghayi, Vahid Liaghat", "title": "Improved Approximation Algorithms for (Budgeted) Node-weighted Steiner\n  Problems", "comments": "To appear in ICALP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moss and Rabani[12] study constrained node-weighted Steiner tree problems\nwith two independent weight values associated with each node, namely, cost and\nprize (or penalty). They give an O(log n)-approximation algorithm for the\nprize-collecting node-weighted Steiner tree problem (PCST). They use the\nalgorithm for PCST to obtain a bicriteria (2, O(log n))-approximation algorithm\nfor the Budgeted node-weighted Steiner tree problem. Their solution may cost up\nto twice the budget, but collects a factor Omega(1/log n) of the optimal prize.\nWe improve these results from at least two aspects.\n  Our first main result is a primal-dual O(log h)-approximation algorithm for a\nmore general problem, prize-collecting node-weighted Steiner forest, where we\nhave (h) demands each requesting the connectivity of a pair of vertices. Our\nalgorithm can be seen as a greedy algorithm which reduces the number of demands\nby choosing a structure with minimum cost-to-reduction ratio. This natural\nstyle of argument (also used by Klein and Ravi[10] and Guha et al.[8]) leads to\na much simpler algorithm than that of Moss and Rabani[12] for PCST.\n  Our second main contribution is for the Budgeted node-weighted Steiner tree\nproblem, which is also an improvement to [12] and [8]. In the unrooted case, we\nimprove upon an O(log^2(n))-approximation of [8], and present an O(log\nn)-approximation algorithm without any budget violation. For the rooted case,\nwhere a specified vertex has to appear in the solution tree, we improve the\nbicriteria result of [12] to a bicriteria approximation ratio of (1+eps, O(log\nn)/(eps^2)) for any positive (possibly subconstant) (eps). That is, for any\npermissible budget violation (1+eps), we present an algorithm achieving a\ntradeoff in the guarantee for prize. Indeed, we show that this is almost tight\nfor the natural linear-programming relaxation used by us as well as in [12].\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2013 22:34:20 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Bateni", "MohammadHossein", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Liaghat", "Vahid", ""]]}, {"id": "1304.7558", "submitter": "Amir Abboud", "authors": "Amir Abboud and Kevin Lewi", "title": "Exact Weight Subgraphs and the k-Sum Conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Exact-Weight-H problem of finding a (not necessarily induced)\nsubgraph H of weight 0 in an edge-weighted graph G. We show that for every H,\nthe complexity of this problem is strongly related to that of the infamous\nk-Sum problem. In particular, we show that under the k-Sum Conjecture, we can\nachieve tight upper and lower bounds for the Exact-Weight-H problem for various\nsubgraphs H such as matching, star, path, and cycle. One interesting\nconsequence is that improving on the O(n^3) upper bound for Exact-Weight-4-Path\nor Exact-Weight-5-Path will imply improved algorithms for 3-Sum, 5-Sum,\nAll-Pairs Shortest Paths and other fundamental problems. This is in sharp\ncontrast to the minimum-weight and (unweighted) detection versions, which can\nbe solved easily in time O(n^2). We also show that a faster algorithm for any\nof the following three problems would yield faster algorithms for the others:\n3-Sum, Exact-Weight-3-Matching, and Exact-Weight-3-Star.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 03:38:47 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Abboud", "Amir", ""], ["Lewi", "Kevin", ""]]}, {"id": "1304.7571", "submitter": "Zeev Nutov", "authors": "Nachshon Cohen and Zeev Nutov", "title": "Approximating {0,1,2}-Survivable Networks with Minimum Number of Steiner\n  Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider low connectivity variants of the Survivable Network with Minimum\nNumber of Steiner Points (SN-MSP) problem: given a finite set $R$ of terminals\nin a metric space (M,d), a subset $B \\subseteq R$ of \"unstable\" terminals, and\nconnectivity requirements {r_{uv}: u,v \\in R}, find a minimum size set $S\n\\subseteq M$ of additional points such that the unit-disc graph of $R \\cup S$\ncontains $r_{uv}$ pairwise internally edge-disjoint and $(B \\cup S)$-disjoint\n$uv$-paths for all $u,v \\in R$. The case when $r_{uv}=1$ for all $u,v \\in R$ is\nthe {\\sf Steiner Tree with Minimum Number of Steiner Points} (ST-MSP) problem,\nand the case $r_{uv} \\in \\{0,1\\}$ is the {\\sf Steiner Forest with Minimum\nNumber of Steiner Points} (SF-MSP) problem. Let $\\Delta$ be the maximum number\nof points in a unit ball such that the distance between any two of them is\nlarger than 1. It is known that $\\Delta=5$ in $\\mathbb{R}^2$ The previous known\napproximation ratio for {\\sf ST-MSP} was $\\lfloor (\\Delta+1)/2\n\\rfloor+1+\\epsilon$ in an arbitrary normed space \\cite{NY}, and $2.5+\\epsilon$\nin the Euclidean space $\\mathbb{R}^2$ \\cite{cheng2008relay}. Our approximation\nratio for ST-MSP is $1+\\ln(\\Delta-1)+\\epsilon$ in an arbitrary normed space,\nwhich in $\\mathbb{R}^2$ reduces to $1+\\ln 4+\\epsilon < 2.3863 +\\epsilon$. For\nSN-MSP with $r_{uv} \\in \\{0,1,2\\}$, we give a simple $\\Delta$-approximation\nalgorithm. In particular, for SF-MSP, this improves the previous ratio\n$2\\Delta$.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 06:35:44 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Cohen", "Nachshon", ""], ["Nutov", "Zeev", ""]]}, {"id": "1304.7577", "submitter": "Preyas Popat", "authors": "Rina Panigrahy and Preyas Popat", "title": "Optimal amortized regret in every interval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the classical problem of predicting the next bit in a sequence of\nbits. A standard performance measure is {\\em regret} (loss in payoff) with\nrespect to a set of experts. For example if we measure performance with respect\nto two constant experts one that always predicts 0's and another that always\npredicts 1's it is well known that one can get regret $O(\\sqrt T)$ with respect\nto the best expert by using, say, the weighted majority algorithm. But this\nalgorithm does not provide performance guarantee in any interval. There are\nother algorithms that ensure regret $O(\\sqrt {x \\log T})$ in any interval of\nlength $x$. In this paper we show a randomized algorithm that in an amortized\nsense gets a regret of $O(\\sqrt x)$ for any interval when the sequence is\npartitioned into intervals arbitrarily. We empirically estimated the constant\nin the $O()$ for $T$ upto 2000 and found it to be small -- around 2.1. We also\nexperimentally evaluate the efficacy of this algorithm in predicting high\nfrequency stock data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 07:17:31 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Panigrahy", "Rina", ""], ["Popat", "Preyas", ""]]}, {"id": "1304.7604", "submitter": "\\\"Ozg\\\"ur  \\\"Ozkan", "authors": "Erik D. Demaine and John Iacono and Stefan Langerman and \\\"Ozg\\\"ur\n  \\\"Ozkan", "title": "Combining Binary Search Trees", "comments": "12 pages, 2 figures, ICALP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general transformation for combining a constant number of binary\nsearch tree data structures (BSTs) into a single BST whose running time is\nwithin a constant factor of the minimum of any \"well-behaved\" bound on the\nrunning time of the given BSTs, for any online access sequence.\n  (A BST has a well behaved bound with $f(n)$ overhead if it spends at most\n\\bigoh{f(n)} time per access and its bound satisfies a weak sense of closure\nunder subsequences.) In particular, we obtain a BST data structure that is\n\\bigoh{\\log\\log n} competitive, satisfies the working set bound (and thus\nsatisfies the static finger bound and the static optimality bound), satisfies\nthe dynamic finger bound, satisfies the unified bound with an additive\n\\bigoh{\\log\\log n} factor, and performs each access in worst-case \\bigoh{\\log\nn} time.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 09:52:14 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Demaine", "Erik D.", ""], ["Iacono", "John", ""], ["Langerman", "Stefan", ""], ["\u00d6zkan", "\u00d6zg\u00fcr", ""]]}, {"id": "1304.7632", "submitter": "Rastislav \\v{S}r\\'amek", "authors": "Barbara Geissmann and Rastislav \\v{S}r\\'amek", "title": "Counting small cuts in a graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minimum cut problem in the presence of uncertainty and show how\nto apply a novel robust optimization approach, which aims to exploit the\nsimilarity in subsequent graph measurements or similar graph instances, without\nposing any assumptions on the way they have been obtained. With experiments we\nshow that the approach works well when compared to other approaches that are\nalso oblivious towards the relationship between the input datasets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 12:08:32 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Geissmann", "Barbara", ""], ["\u0160r\u00e1mek", "Rastislav", ""]]}, {"id": "1304.7687", "submitter": "Moti Medina", "authors": "Guy Even and Moti Medina", "title": "A Nonmonotone Analysis with the Primal-Dual Approach: online routing of\n  virtual circuits with unknown durations", "comments": "To appear in SIROCCO 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question of whether the primal-dual approach for the design\nand analysis of online algorithms can be applied to nonmonotone problems. We\nprovide a positive answer by presenting a primal-dual analysis to the online\nalgorithm of Awerbuch et al.[AAPW01] for routing virtual circuits with unknown\ndurations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 15:36:35 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2013 17:05:20 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Even", "Guy", ""], ["Medina", "Moti", ""]]}, {"id": "1304.7693", "submitter": "Konstantinos Georgiou", "authors": "Jurek Czyzowicz and Leszek Gasieniec and Konstantinos Georgiou and\n  Evangelos Kranakis and Fraser MacQuarrie", "title": "The Beachcombers' Problem: Walking and Searching with Mobile Robots", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study a new problem concerning the exploration of a\ngeometric domain by mobile robots. Consider a line segment $[0,I]$ and a set of\n$n$ mobile robots $r_1,r_2,..., r_n$ placed at one of its endpoints. Each robot\nhas a {\\em searching speed} $s_i$ and a {\\em walking speed} $w_i$, where $s_i\n<w_i$. We assume that each robot is aware of the number of robots of the\ncollection and their corresponding speeds. At each time moment a robot $r_i$\neither walks along a portion of the segment not exceeding its walking speed\n$w_i$ or searches a portion of the segment with the speed not exceeding $s_i$.\nA search of segment $[0,I]$ is completed at the time when each of its points\nhave been searched by at least one of the $n$ robots. We want to develop {\\em\nmobility schedules} (algorithms) for the robots which complete the search of\nthe segment as fast as possible. More exactly we want to maximize the {\\em\nspeed} of the mobility schedule (equal to the ratio of the segment length\nversus the time of the completion of the schedule).\n  We analyze first the offline scenario when the robots know the length of the\nsegment that is to be searched. We give an algorithm producing a mobility\nschedule for arbitrary walking and searching speeds and prove its optimality.\nThen we propose an online algorithm, when the robots do not know in advance the\nactual length of the segment to be searched. The speed $S$ of such algorithm is\ndefined as $S = \\inf_{I_L} S(I_L)$ where $S(I_L)$ denotes the speed of\nsearching of segment $I_L=[0,L]$. We prove that the proposed online algorithm\nis 2-competitive. The competitive ratio is shown to be better in the case when\nthe robots' walking speeds are all the same.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 15:48:52 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Czyzowicz", "Jurek", ""], ["Gasieniec", "Leszek", ""], ["Georgiou", "Konstantinos", ""], ["Kranakis", "Evangelos", ""], ["MacQuarrie", "Fraser", ""]]}, {"id": "1304.7793", "submitter": "Guillaume Aupy", "authors": "Guillaume Aupy, Manu Shantharam, Anne Benoit, Yves Robert and Padma\n  Raghavan", "title": "Co-Scheduling Algorithms for High-Throughput Workload Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": "INRIA RR-8293", "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates co-scheduling algorithms for processing a set of\nparallel applications. Instead of executing each application one by one, using\na maximum degree of parallelism for each of them, we aim at scheduling several\napplications concurrently. We partition the original application set into a\nseries of packs, which are executed one by one. A pack comprises several\napplications, each of them with an assigned number of processors, with the\nconstraint that the total number of processors assigned within a pack does not\nexceed the maximum number of available processors. The objective is to\ndetermine a partition into packs, and an assignment of processors to\napplications, that minimize the sum of the execution times of the packs. We\nthoroughly study the complexity of this optimization problem, and propose\nseveral heuristics that exhibit very good performance on a variety of\nworkloads, whose application execution times model profiles of parallel\nscientific codes. We show that co-scheduling leads to to faster workload\ncompletion time and to faster response times on average (hence increasing\nsystem throughput and saving energy), for significant benefits over traditional\nscheduling from both the user and system perspectives.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 20:22:27 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Aupy", "Guillaume", ""], ["Shantharam", "Manu", ""], ["Benoit", "Anne", ""], ["Robert", "Yves", ""], ["Raghavan", "Padma", ""]]}, {"id": "1304.7804", "submitter": "David Doty", "authors": "David Doty", "title": "Producibility in hierarchical self-assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three results are shown on producibility in the hierarchical model of tile\nself-assembly. It is shown that a simple greedy polynomial-time strategy\ndecides whether an assembly A is producible. The algorithm can be optimized to\nuse O(|A| log^2 |A|) time. Cannon, Demaine, Demaine, Eisenstat, Patitz,\nSchweller, Summers, and Winslow showed that the problem of deciding if an\nassembly A is the unique producible terminal assembly of a tile system T can be\nsolved in O(|A|^2 |T| + |A| |T|^2) time for the special case of noncooperative\n\"temperature 1\" systems. It is shown that this can be improved to O(|A| |T| log\n|T|) time. Finally, it is shown that if two assemblies are producible, and if\nthey can be overlapped consistently -- i.e., if the positions that they share\nhave the same tile type in each assembly -- then their union is also\nproducible.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 21:02:51 GMT"}, {"version": "v2", "created": "Wed, 1 May 2013 07:56:03 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Doty", "David", ""]]}, {"id": "1304.7863", "submitter": "EPTCS", "authors": "David S. Hardin (Rockwell Collins), Samuel S. Hardin (Iowa State\n  University)", "title": "ACL2 Meets the GPU: Formalizing a CUDA-based Parallelizable All-Pairs\n  Shortest Path Algorithm in ACL2", "comments": "In Proceedings ACL2 2013, arXiv:1304.7123", "journal-ref": "EPTCS 114, 2013, pp. 127-142", "doi": "10.4204/EPTCS.114.10", "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Graphics Processing Units (GPUs) have gained in capability and GPU\ndevelopment environments have matured, developers are increasingly turning to\nthe GPU to off-load the main host CPU of numerically-intensive, parallelizable\ncomputations. Modern GPUs feature hundreds of cores, and offer programming\nniceties such as double-precision floating point, and even limited recursion.\nThis shift from CPU to GPU, however, raises the question: how do we know that\nthese new GPU-based algorithms are correct?\n  In order to explore this new verification frontier, we formalized a\nparallelizable all-pairs shortest path (APSP) algorithm for weighted graphs,\noriginally coded in NVIDIA's CUDA language, in ACL2. The ACL2 specification is\nwritten using a single-threaded object (stobj) and tail recursion, as the\nstobj/tail recursion combination yields the most straightforward translation\nfrom imperative programming languages, as well as efficient, scalable\nexecutable specifications within ACL2 itself. The ACL2 version of the APSP\nalgorithm can process millions of vertices and edges with little to no garbage\ngeneration, and executes at one-sixth the speed of a host-based version of APSP\ncoded in C- a very respectable result for a theorem prover.\n  In addition to formalizing the APSP algorithm (which uses Dijkstra's shortest\npath algorithm at its core), we have also provided capability that the original\nAPSP code lacked, namely shortest path recovery. Path recovery is accomplished\nusing a secondary ACL2 stobj implementing a LIFO stack, which is proven\ncorrect. To conclude the experiment, we ported the ACL2 version of the APSP\nkernels back to C, resulting in a less than 5% slowdown, and also performed a\npartial back-port to CUDA, which, surprisingly, yielded a slight performance\nincrease.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 04:15:02 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Hardin", "David S.", "", "Rockwell Collins"], ["Hardin", "Samuel S.", "", "Iowa State\n  University"]]}, {"id": "1304.7959", "submitter": "Gerth St{\\o}lting Brodal", "authors": "Gerth St{\\o}lting Brodal and Kasper Green Larsen", "title": "Optimal Planar Orthogonal Skyline Counting Queries", "comments": "Full version of paper appearing in the proceedings of the 14th\n  Scandinavian Symposium and Workshops on Algorithm Theory, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The skyline of a set of points in the plane is the subset of maximal points,\nwhere a point $(x,y)$ is maximal if no other point $(x',y')$ satisfies $x'\\ge\nx$ and $y'\\ge Y$. We consider the problem of preprocessing a set $P$ of $n$\npoints into a space efficient static data structure supporting orthogonal\nskyline counting queries, i.e. given a query rectangle $R$ to report the size\nof the skyline of $P$ intersected with $R$. We present a data structure for\nstoring n points with integer coordinates having query time $O(\\lg n/\\lg\\lg n)$\nand space usage $O(n)$. The model of computation is a unit cost RAM with\nlogarithmic word size. We prove that these bounds are the best possible by\npresenting a lower bound in the cell probe model with logarithmic word size:\nSpace usage $n\\lg^{O(1)} n$ implies worst case query time $\\Omega(\\lg n/\\lg\\lg\nn)$.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 11:43:28 GMT"}, {"version": "v2", "created": "Thu, 24 Apr 2014 21:40:39 GMT"}], "update_date": "2014-04-28", "authors_parsed": [["Brodal", "Gerth St\u00f8lting", ""], ["Larsen", "Kasper Green", ""]]}, {"id": "1304.8016", "submitter": "Lukas Barth", "authors": "Lukas Barth, Stephen Kobourov, Sergey Pupyrev, Torsten Ueckerdt", "title": "On Semantic Word Cloud Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of computing semantic-preserving word clouds in which\nsemantically related words are close to each other. While several heuristic\napproaches have been described in the literature, we formalize the underlying\ngeometric algorithm problem: Word Rectangle Adjacency Contact (WRAC). In this\nmodel each word is associated with rectangle with fixed dimensions, and the\ngoal is to represent semantically related words by ensuring that the two\ncorresponding rectangles touch. We design and analyze efficient polynomial-time\nalgorithms for some variants of the WRAC problem, show that several general\nvariants are NP-hard, and describe a number of approximation algorithms.\nFinally, we experimentally demonstrate that our theoretically-sound algorithms\noutperform the early heuristics.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 22:14:18 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Barth", "Lukas", ""], ["Kobourov", "Stephen", ""], ["Pupyrev", "Sergey", ""], ["Ueckerdt", "Torsten", ""]]}, {"id": "1304.8026", "submitter": "Marzieh Parandehgheibi", "authors": "Marzieh Parandehgheibi, Hyang-Won Lee and Eytan Modiano", "title": "Survivable Paths in Multilayer Networks", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider protection problems in multilayer networks. In single-layer\nnetworks, a pair of disjoint paths can be used to provide protection for a\nsource-destination pair. However, this approach cannot be directly applied to\nlayered networks where disjoint paths may not always exist. In this paper, we\ntake a new approach which is based on finding a set of paths that may not be\ndisjoint but together will survive any single physical link failure. First, we\nconsider the problem of finding the minimum number of survivable paths. In\nparticular, we focus on two versions of this problem: one where the length of a\npath is restricted, and the other where the number of paths sharing a fiber is\nrestricted. We prove that in general, finding the minimum survivable path set\nis NP-hard, whereas both of the restricted versions of the problem can be\nsolved in polynomial time. We formulate the problem as Integer Linear Programs\n(ILPs), and use these formulations to develop heuristics and approximation\nalgorithms. Next, we consider the problem of finding a set of survivable paths\nthat uses the minimum number of fibers. We show that this problem is NP-hard in\ngeneral, and develop heuristics and approximation algorithms with provable\napproximation bounds. Finally, we present simulation results comparing the\ndifferent algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 15:15:29 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Parandehgheibi", "Marzieh", ""], ["Lee", "Hyang-Won", ""], ["Modiano", "Eytan", ""]]}, {"id": "1304.8087", "submitter": "Aravindan Vijayaraghavan", "authors": "Aditya Bhaskara, Moses Charikar, Aravindan Vijayaraghavan", "title": "Uniqueness of Tensor Decompositions with Applications to Polynomial\n  Identifiability", "comments": "51 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a robust version of the celebrated result of Kruskal on the\nuniqueness of tensor decompositions: we prove that given a tensor whose\ndecomposition satisfies a robust form of Kruskal's rank condition, it is\npossible to approximately recover the decomposition if the tensor is known up\nto a sufficiently small (inverse polynomial) error.\n  Kruskal's theorem has found many applications in proving the identifiability\nof parameters for various latent variable models and mixture models such as\nHidden Markov models, topic models etc. Our robust version immediately implies\nidentifiability using only polynomially many samples in many of these settings.\nThis polynomial identifiability is an essential first step towards efficient\nlearning algorithms for these models.\n  Recently, algorithms based on tensor decompositions have been used to\nestimate the parameters of various hidden variable models efficiently in\nspecial cases as long as they satisfy certain \"non-degeneracy\" properties. Our\nmethods give a way to go beyond this non-degeneracy barrier, and establish\npolynomial identifiability of the parameters under much milder conditions.\nGiven the importance of Kruskal's theorem in the tensor literature, we expect\nthat this robust version will have several applications beyond the settings we\nexplore in this work.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 17:35:37 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Bhaskara", "Aditya", ""], ["Charikar", "Moses", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1304.8108", "submitter": "Mohit Singh", "authors": "Mohit Singh, Nisheeth K. Vishnoi", "title": "Entropy, Optimization and Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of computing max-entropy distributions\nover a discrete set of objects subject to observed marginals. Interest in such\ndistributions arises due to their applicability in areas such as statistical\nphysics, economics, biology, information theory, machine learning,\ncombinatorics and, more recently, approximation algorithms. A key difficulty in\ncomputing max-entropy distributions has been to show that they have\npolynomially-sized descriptions. We show that such descriptions exist under\ngeneral conditions. Subsequently, we show how algorithms for (approximately)\ncounting the underlying discrete set can be translated into efficient\nalgorithms to (approximately) compute max-entropy distributions. In the reverse\ndirection, we show how access to algorithms that compute max-entropy\ndistributions can be used to count, which establishes an equivalence between\ncounting and computing max-entropy distributions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 18:39:26 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Singh", "Mohit", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1304.8132", "submitter": "Zeyuan Allen Zhu", "authors": "Zeyuan Allen Zhu and Silvio Lattanzi and Vahab Mirrokni", "title": "Local Graph Clustering Beyond Cheeger's Inequality", "comments": "An extended abstract of this paper has appeared in the proceedings of\n  the 30th International Conference on Machine Learning (ICML 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications of large-scale graph clustering, we study\nrandom-walk-based LOCAL algorithms whose running times depend only on the size\nof the output cluster, rather than the entire graph. All previously known such\nalgorithms guarantee an output conductance of $\\tilde{O}(\\sqrt{\\phi(A)})$ when\nthe target set $A$ has conductance $\\phi(A)\\in[0,1]$. In this paper, we improve\nit to $$\\tilde{O}\\bigg( \\min\\Big\\{\\sqrt{\\phi(A)},\n\\frac{\\phi(A)}{\\sqrt{\\mathsf{Conn}(A)}} \\Big\\} \\bigg)\\enspace, $$ where the\ninternal connectivity parameter $\\mathsf{Conn}(A) \\in [0,1]$ is defined as the\nreciprocal of the mixing time of the random walk over the induced subgraph on\n$A$.\n  For instance, using $\\mathsf{Conn}(A) = \\Omega(\\lambda(A) / \\log n)$ where\n$\\lambda$ is the second eigenvalue of the Laplacian of the induced subgraph on\n$A$, our conductance guarantee can be as good as\n$\\tilde{O}(\\phi(A)/\\sqrt{\\lambda(A)})$. This builds an interesting connection\nto the recent advance of the so-called improved Cheeger's Inequality [KKL+13],\nwhich says that global spectral algorithms can provide a conductance guarantee\nof $O(\\phi_{\\mathsf{opt}}/\\sqrt{\\lambda_3})$ instead of\n$O(\\sqrt{\\phi_{\\mathsf{opt}}})$.\n  In addition, we provide theoretical guarantee on the clustering accuracy (in\nterms of precision and recall) of the output set. We also prove that our\nanalysis is tight, and perform empirical evaluation to support our theory on\nboth synthetic and real data.\n  It is worth noting that, our analysis outperforms prior work when the cluster\nis well-connected. In fact, the better it is well-connected inside, the more\nsignificant improvement (both in terms of conductance and accuracy) we can\nobtain. Our results shed light on why in practice some random-walk-based\nalgorithms perform better than its previous theory, and help guide future\nresearch about local clustering.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 19:57:36 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2013 18:25:15 GMT"}], "update_date": "2013-11-08", "authors_parsed": [["Zhu", "Zeyuan Allen", ""], ["Lattanzi", "Silvio", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1304.8135", "submitter": "Shay Solomon", "authors": "Shay Solomon", "title": "From Hierarchical Partitions to Hierarchical Covers: Optimal\n  Fault-Tolerant Spanners for Doubling Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we devise an optimal construction of fault-tolerant spanners\nfor doubling metrics. Specifically, for any $n$-point doubling metric, any\n$\\eps > 0$, and any integer $0 \\le k \\le n-2$, our construction provides a\n$k$-fault-tolerant $(1+\\eps)$-spanner with optimal degree $O(k)$ within optimal\ntime $O(n \\log n + k n)$.\n  We then strengthen this result to provide near-optimal (up to a factor of\n$\\log k$) guarantees on the diameter and weight of our spanners, namely,\ndiameter $O(\\log n)$ and weight $O(k^2 + k \\log n) \\cdot \\omega(MST)$, while\npreserving the optimal guarantees on the degree $O(k)$ and the running time\n$O(n \\log n + k n)$.\n  Our result settles several fundamental open questions in this area,\nculminating a long line of research that started with the STOC'95 paper of Arya\net al.\\ and the STOC'98 paper of Levcopoulos et al.\n  On the way to this result we develop a new technique for constructing\nspanners in doubling metrics. Our spanner construction is based on a novel\n\\emph{hierarchical cover} of the metric, whereas most previous constructions of\nspanners for doubling and Euclidean metrics (such as the net-tree spanner) are\nbased on \\emph{hierarchical partitions} of the metric. We demonstrate the power\nof hierarchical covers in the context of geometric spanners by improving the\nstate-of-the-art results in this area.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 19:58:41 GMT"}, {"version": "v2", "created": "Wed, 8 May 2013 19:52:23 GMT"}], "update_date": "2013-05-09", "authors_parsed": [["Solomon", "Shay", ""]]}]