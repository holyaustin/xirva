[{"id": "1306.0155", "submitter": "Aleksandrs Slivkins", "authors": "Aleksandrs Slivkins", "title": "Dynamic Ad Allocation: Bandits with Budgets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an application of multi-armed bandits to internet advertising\n(specifically, to dynamic ad allocation in the pay-per-click model, with\nuncertainty on the click probabilities). We focus on an important practical\nissue that advertisers are constrained in how much money they can spend on\ntheir ad campaigns. This issue has not been considered in the prior work on\nbandit-based approaches for ad allocation, to the best of our knowledge.\n  We define a simple, stylized model where an algorithm picks one ad to display\nin each round, and each ad has a \\emph{budget}: the maximal amount of money\nthat can be spent on this ad. This model admits a natural variant of UCB1, a\nwell-known algorithm for multi-armed bandits with stochastic rewards. We derive\nstrong provable guarantees for this algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2013 22:00:03 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Slivkins", "Aleksandrs", ""]]}, {"id": "1306.0207", "submitter": "John Iacono", "authors": "John Iacono", "title": "In pursuit of the dynamic optimality conjecture", "comments": "Preliminary version of paper to appear in the Conference on Space\n  Efficient Data Structures, Streams and Algorithms to be held in August 2013\n  in honor of Ian Munro's 66th birthday", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1985, Sleator and Tarjan introduced the splay tree, a self-adjusting\nbinary search tree algorithm. Splay trees were conjectured to perform within a\nconstant factor as any offline rotation-based search tree algorithm on every\nsufficiently long sequence---any binary search tree algorithm that has this\nproperty is said to be dynamically optimal. However, currently neither splay\ntrees nor any other tree algorithm is known to be dynamically optimal. Here we\nsurvey the progress that has been made in the almost thirty years since the\nconjecture was first formulated, and present a binary search tree algorithm\nthat is dynamically optimal if any binary search tree algorithm is dynamically\noptimal.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2013 13:05:41 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Iacono", "John", ""]]}, {"id": "1306.0406", "submitter": "Moshe Lewenstein", "authors": "Amihood Amir and Gianni Franceschini and Roberto Grossi and Tsvi\n  Kopelowitz and Moshe Lewenstein and Noa Lewenstein", "title": "Managing Unbounded-Length Keys in Comparison-Driven Data Structures with\n  Applications to On-Line Indexing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a general technique for optimally transforming any\ndynamic data structure that operates on atomic and indivisible keys by\nconstant-time comparisons, into a data structure that handles unbounded-length\nkeys whose comparison cost is not a constant. Examples of these keys are\nstrings, multi-dimensional points, multiple-precision numbers, multi-key data\n(e.g.~records), XML paths, URL addresses, etc. The technique is more general\nthan what has been done in previous work as no particular exploitation of the\nunderlying structure of is required. The only requirement is that the insertion\nof a key must identify its predecessor or its successor.\n  Using the proposed technique, online suffix tree can be constructed in worst\ncase time $O(\\log n)$ per input symbol (as opposed to amortized $O(\\log n)$\ntime per symbol, achieved by previously known algorithms). To our knowledge,\nour algorithm is the first that achieves $O(\\log n)$ worst case time per input\nsymbol. Searching for a pattern of length $m$ in the resulting suffix tree\ntakes $O(\\min(m\\log |\\Sigma|, m + \\log n) + tocc)$ time, where $tocc$ is the\nnumber of occurrences of the pattern. The paper also describes more\napplications and show how to obtain alternative methods for dealing with suffix\nsorting, dynamic lowest common ancestors and order maintenance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 13:53:29 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Amir", "Amihood", ""], ["Franceschini", "Gianni", ""], ["Grossi", "Roberto", ""], ["Kopelowitz", "Tsvi", ""], ["Lewenstein", "Moshe", ""], ["Lewenstein", "Noa", ""]]}, {"id": "1306.0615", "submitter": "Moshe Lewenstein", "authors": "Moshe Lewenstein", "title": "Orthogonal Range Searching for Text Indexing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text indexing, the problem in which one desires to preprocess a (usually\nlarge) text for future (shorter) queries, has been researched ever since the\nsuffix tree was invented in the early 70's. With textual data continuing to\nincrease and with changes in the way it is accessed, new data structures and\nnew algorithmic methods are continuously required. Therefore, text indexing is\nof utmost importance and is a very active research domain.\n  Orthogonal range searching, classically associated with the computational\ngeometry community, is one of the tools that has increasingly become important\nfor various text indexing applications. Initially, in the mid 90's there were a\ncouple of results recognizing this connection. In the last few years we have\nseen an increase in use of this method and are reaching a deeper understanding\nof the range searching uses for text indexing.\n  In this monograph we survey some of these results.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 22:37:43 GMT"}], "update_date": "2017-01-08", "authors_parsed": [["Lewenstein", "Moshe", ""]]}, {"id": "1306.0771", "submitter": "Kim S. Larsen", "authors": "Joan Boyar, Kim S. Larsen, Abyayananda Maiti", "title": "The Frequent Items Problem in Online Streaming under Various Performance\n  Measures", "comments": "IMADA-preprint-cs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we strengthen the competitive analysis results obtained for a\nfundamental online streaming problem, the Frequent Items Problem. Additionally,\nwe contribute with a more detailed analysis of this problem, using alternative\nperformance measures, supplementing the insight gained from competitive\nanalysis. The results also contribute to the general study of performance\nmeasures for online algorithms. It has long been known that competitive\nanalysis suffers from drawbacks in certain situations, and many alternative\nmeasures have been proposed. However, more systematic comparative studies of\nperformance measures have been initiated recently, and we continue this work,\nusing competitive analysis, relative interval analysis, and relative worst\norder analysis on the Frequent Items Problem.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2013 13:05:35 GMT"}], "update_date": "2013-06-05", "authors_parsed": [["Boyar", "Joan", ""], ["Larsen", "Kim S.", ""], ["Maiti", "Abyayananda", ""]]}, {"id": "1306.1128", "submitter": "Paul Tarau", "authors": "Paul Tarau", "title": "Arithmetic Algorithms for Hereditarily Binary Natural Numbers", "comments": "unpublished draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study some essential arithmetic properties of a new tree-based number\nrepresentation, {\\em hereditarily binary numbers}, defined by applying\nrecursively run-length encoding of bijective base-2 digits.\n  Our representation expresses giant numbers like the largest known prime\nnumber and its related perfect number as well as the largest known Woodall,\nCullen, Proth, Sophie Germain and twin primes as trees of small sizes.\n  More importantly, our number representation supports novel algorithms that,\nin the best case, collapse the complexity of various computations by\nsuper-exponential factors and in the worse case are within a constant factor of\ntheir traditional counterparts.\n  As a result, it opens the door to a new world, where arithmetic operations\nare limited by the structural complexity of their operands, rather than their\nbitsizes.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 14:56:04 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Tarau", "Paul", ""]]}, {"id": "1306.1149", "submitter": "Will Ma", "authors": "Will Ma", "title": "Improvements and Generalizations of Stochastic Knapsack and Multi-Armed\n  Bandit Approximation Algorithms: Full Version", "comments": "38 pages, full version of conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-armed bandit problem with arms which are Markov chains\nwith rewards. In the finite-horizon setting, the celebrated Gittins indices do\nnot apply, and the exact solution is intractable. We provide approximation\nalgorithms for a more general model which includes Markov decision processes\nand non-unit transition times. When preemption is allowed, we provide a\n(1/2-eps)-approximation, along with an example showing this is tight. When\npreemption isn't allowed, we provide a 1/12-approximation, which improves to a\n4/27-approximation when transition times are unity. Our model encompasses the\nMarkovian Bandits model of Gupta et al, the Stochastic Knapsack model of Dean,\nGoemans, and Vondrak, and the Budgeted Learning model of Guha and Munagala, and\nour algorithms improve existing results in all three areas. In our analysis, we\nencounter and overcome to our knowledge a novel obstacle - an algorithm that\nprovably exists via polyhedral arguments, but cannot be found in polynomial\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 15:32:48 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2013 17:14:06 GMT"}, {"version": "v3", "created": "Sun, 7 Jul 2013 19:10:46 GMT"}, {"version": "v4", "created": "Tue, 13 Sep 2016 00:31:50 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Ma", "Will", ""]]}, {"id": "1306.1153", "submitter": "Xiaokui Xiao", "authors": "Andy Diwen Zhu, Xiaokui Xiao, Sibo Wang, Wenqing Lin", "title": "Efficient Single-Source Shortest Path and Distance Queries on Large\n  Graphs", "comments": "To appear in KDD 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates two types of graph queries: {\\em single source\ndistance (SSD)} queries and {\\em single source shortest path (SSSP)} queries.\nGiven a node $v$ in a graph $G$, an SSD query from $v$ asks for the distance\nfrom $v$ to any other node in $G$, while an SSSP query retrieves the shortest\npath from $v$ to any other node. These two types of queries are fundamental\nbuilding blocks of numerous graph algorithms, and they find important\napplications in graph analysis, especially in the computation of graph\nmeasures. Most of the existing solutions for SSD and SSSP queries, however,\nrequire that the input graph fits in the main memory, which renders them\ninapplicable for the massive disk-resident graphs commonly used in web and\nsocial applications. The only exceptions are a few techniques that are designed\nto be I/O efficient, but they all focus on undirected and/or unweighted graphs,\nand they only offer sub-optimal query efficiency.\n  To address the deficiency of existing work, this paper presents {\\em\nHighways-on-Disk (HoD)}, a disk-based index that supports both SSD and SSSP\nqueries on directed and weighted graphs. The key idea of HoD is to augment the\ninput graph with a set of auxiliary edges, and exploit them during query\nprocessing to reduce I/O and computation costs. We experimentally evaluate HoD\non both directed and undirected real-world graphs with up to billions of nodes\nand edges, and we demonstrate that HoD significantly outperforms alternative\nsolutions in terms of query efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 15:46:33 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Zhu", "Andy Diwen", ""], ["Xiao", "Xiaokui", ""], ["Wang", "Sibo", ""], ["Lin", "Wenqing", ""]]}, {"id": "1306.1161", "submitter": "Martin Roetteler", "authors": "Martin Roetteler, Rainer Steinwandt", "title": "A quantum circuit to find discrete logarithms on ordinary binary\n  elliptic curves in depth O(log^2 n)", "comments": "13 pages, 5 figures; title change and other minor changes. Accepted\n  for publication in Quantum Information and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving over an earlier construction by Kaye and Zalka, Maslov et al.\ndescribe an implementation of Shor's algorithm which can solve the discrete\nlogarithm problem on binary elliptic curves in quadratic depth O(n^2). In this\npaper we show that discrete logarithms on such curves can be found with a\nquantum circuit of depth O(log^2 n). As technical tools we introduce quantum\ncircuits for GF(2^n) multiplication in depth O(log n) and for GF(2^n) inversion\nin depth O(log^2 n).\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 16:15:34 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2013 00:16:01 GMT"}], "update_date": "2013-11-15", "authors_parsed": [["Roetteler", "Martin", ""], ["Steinwandt", "Rainer", ""]]}, {"id": "1306.1167", "submitter": "Jinwoo Shin", "authors": "Sungsoo Ahn, Michael Chertkov, Andrew E. Gelfand, Sejun Park, Jinwoo\n  Shin", "title": "A Graphical Transformation for Belief Propagation: Maximum Weight\n  Matchings and Odd-Sized Cycles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Maximum Weight Matching (MWM) problem for general graphs through\nthe max-product Belief Propagation (BP) and related Linear Programming (LP).\nThe BP approach provides distributed heuristics for finding the Maximum A\nPosteriori (MAP) assignment in a joint probability distribution represented by\na Graphical Model (GM) and respective LPs can be considered as continuous\nrelaxations of the discrete MAP problem. It was recently shown that a BP\nalgorithm converges to the correct MWM assignment under a simple GM formulation\nof MAP/MWM as long as the corresponding LP relaxation is tight. First, under\nthe motivation for forcing the tightness condition, we consider a new GM\nformulation of MWM, say C-GM, using non-intersecting odd-sized cycles in the\ngraph: the new corresponding LP relaxation, say C-LP, becomes tight for more\nMWM instances. However, the tightness of C-LP now does not guarantee such\nconvergence and correctness of the new BP on C-GM. To address the issue, we\nintroduce a novel graph transformation applied to C-GM, which results in\nanother GM formulation of MWM, and prove that the respective BP on it converges\nto the correct MAP/MWM assignment as long as C-LP is tight. Finally, we also\nshow that C-LP always has half-integral solutions, which leads to an efficient\nBP-based MWM heuristic consisting of making sequential, `cutting plane',\nmodifications to the underlying GM. Our experiments show that this BP-based\ncutting plane heuristic performs as well as that based on traditional LP\nsolvers.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 16:46:34 GMT"}, {"version": "v2", "created": "Mon, 1 Jan 2018 04:55:56 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Ahn", "Sungsoo", ""], ["Chertkov", "Michael", ""], ["Gelfand", "Andrew E.", ""], ["Park", "Sejun", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1306.1202", "submitter": "Sanjeeb Dash", "authors": "Sanjeeb Dash", "title": "A note on QUBO instances defined on Chimera graphs", "comments": "Version 1 discussed computational results with random QUBO instances.\n  McGeoch and Wang made an error in describing the instances they used; they\n  did not use random QUBO instances but rather random Ising Model instances\n  with fields (mapped to QUBO instances). The current version of the note\n  reports on tests with the precise instances used by McGeoch and Wang", "journal-ref": "Optima 98, 2015, 2-6", "doi": null, "report-no": null, "categories": "math.OC cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  McGeoch and Wang (2013) recently obtained optimal or near-optimal solutions\nto some quadratic unconstrained boolean optimization (QUBO) problem instances\nusing a 439 qubit D-Wave Two quantum computing system in much less time than\nwith the IBM ILOG CPLEX mixed-integer quadratic programming (MIQP) solver. The\nproblems studied by McGeoch and Wang are defined on subgraphs -- with up to 439\nnodes -- of Chimera graphs. We observe that after a standard reformulation of\nthe QUBO problem as a mixed-integer linear program (MILP), the specific\ninstances used by McGeoch and Wang can be solved to optimality with the CPLEX\nMILP solver in much less time than the time reported in McGeoch and Wang for\nthe CPLEX MIQP solver. However, the solution time is still more than the time\ntaken by the D-Wave computer in the McGeoch-Wang tests.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 18:42:50 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2013 15:54:02 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["Dash", "Sanjeeb", ""]]}, {"id": "1306.1265", "submitter": "Constantinos Daskalakis", "authors": "Constantinos Daskalakis and Christos Papadimitriou", "title": "Sparse Covers for Sums of Indicators", "comments": "PTRF, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For all $n, \\epsilon >0$, we show that the set of Poisson Binomial\ndistributions on $n$ variables admits a proper $\\epsilon$-cover in total\nvariation distance of size $n^2+n \\cdot (1/\\epsilon)^{O(\\log^2 (1/\\epsilon))}$,\nwhich can also be computed in polynomial time. We discuss the implications of\nour construction for approximation algorithms and the computation of\napproximate Nash equilibria in anonymous games.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 23:16:31 GMT"}, {"version": "v2", "created": "Sat, 5 Jul 2014 18:18:18 GMT"}, {"version": "v3", "created": "Wed, 1 Oct 2014 22:16:02 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Papadimitriou", "Christos", ""]]}, {"id": "1306.1345", "submitter": "Mamadou Moustapha Kant\\'e", "authors": "Binh-Minh Bui-Xuan and Mamadou Moustapha Kant\\'e and Vincent Limouzy", "title": "A Note on Graphs of Linear Rank-Width 1", "comments": "9 pages, 2 figures. Not to be published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that a connected graph has linear rank-width 1 if and only if it is\na distance-hereditary graph and its split decomposition tree is a path. An\nimmediate consequence is that one can decide in linear time whether a graph has\nlinear rank-width at most 1, and give an obstruction if not. Other immediate\nconsequences are several characterisations of graphs of linear rank-width 1. In\nparticular a connected graph has linear rank-width 1 if and only if it is\nlocally equivalent to a caterpillar if and only if it is a vertex-minor of a\npath [O-joung Kwon and Sang-il Oum, Graphs of small rank-width are pivot-minors\nof graphs of small tree-width, arxiv:1203.3606] if and only if it does not\ncontain the co-K_2 graph, the Net graph and the 5-cycle graph as vertex-minors\n[Isolde Adler, Arthur M. Farley and Andrzej Proskurowski, Obstructions for\nlinear rank-width at most 1, arxiv:1106.2533].\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 09:12:31 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2014 11:38:27 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Bui-Xuan", "Binh-Minh", ""], ["Kant\u00e9", "Mamadou Moustapha", ""], ["Limouzy", "Vincent", ""]]}, {"id": "1306.1366", "submitter": "Giovanna Rosone", "authors": "Sabrina Mantaci, Antonio Restivo, Giovanna Rosone, Marinella Sciortino", "title": "Sorting suffixes of a text via its Lyndon Factorization", "comments": "Submitted to the Prague Stringology Conference 2013 (PSC 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of sorting the suffixes of a text plays a fundamental role in\nText Algorithms. They are used for instance in the constructions of the\nBurrows-Wheeler transform and the suffix array, widely used in several fields\nof Computer Science. For this reason, several recent researches have been\ndevoted to finding new strategies to obtain effective methods for such a\nsorting. In this paper we introduce a new methodology in which an important\nrole is played by the Lyndon factorization, so that the local suffixes inside\nfactors detected by this factorization keep their mutual order when extended to\nthe suffixes of the whole word. This property suggests a versatile technique\nthat easily can be adapted to different implementative scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 10:27:22 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Mantaci", "Sabrina", ""], ["Restivo", "Antonio", ""], ["Rosone", "Giovanna", ""], ["Sciortino", "Marinella", ""]]}, {"id": "1306.1402", "submitter": "Martin Hoefer", "authors": "Martin Hoefer, Thomas Sauerwald", "title": "Threshold Load Balancing in Networks", "comments": "20 pages, brief announcement in PODC 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study probabilistic protocols for concurrent threshold-based load\nbalancing in networks. There are n resources or machines represented by nodes\nin an undirected graph and m >> n users that try to find an acceptable resource\nby moving along the edges of the graph. Users accept a resource if the load is\nbelow a threshold. Such thresholds have an intuitive meaning, e.g., as\ndeadlines in a machine scheduling scenario, and they allow the design of\nprotocols under strong locality constraints. When migration is partly\ncontrolled by resources and partly by users, our protocols obtain rapid\nconvergence to a balanced state, in which all users are satisfied. We show that\nconvergence is achieved in a number of rounds that is only logarithmic in m and\npolynomial in structural properties of the graph. Even when migration is fully\ncontrolled by users, we obtain similar results for convergence to approximately\nbalanced states. If we slightly adjust the migration probabilities in our\nprotocol, we can also obtain fast convergence to balanced states.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 13:08:52 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Hoefer", "Martin", ""], ["Sauerwald", "Thomas", ""]]}, {"id": "1306.1547", "submitter": "Ilya Razenshteyn", "authors": "Alexandr Andoni, Piotr Indyk, Huy L. Nguyen, Ilya Razenshteyn", "title": "Beyond Locality-Sensitive Hashing", "comments": "17 pages, many corrections, added some intuition for the main\n  ingredients, Section 4 has been rewritten completely; to appear at ACM-SIAM\n  Symposium on Discrete Algorithms (SODA 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new data structure for the c-approximate near neighbor problem\n(ANN) in the Euclidean space. For n points in R^d, our algorithm achieves\nO(n^{\\rho} + d log n) query time and O(n^{1 + \\rho} + d log n) space, where\n\\rho <= 7/(8c^2) + O(1 / c^3) + o(1). This is the first improvement over the\nresult by Andoni and Indyk (FOCS 2006) and the first data structure that\nbypasses a locality-sensitive hashing lower bound proved by O'Donnell, Wu and\nZhou (ICS 2011). By a standard reduction we obtain a data structure for the\nHamming space and \\ell_1 norm with \\rho <= 7/(8c) + O(1/c^{3/2}) + o(1), which\nis the first improvement over the result of Indyk and Motwani (STOC 1998).\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 20:33:41 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2013 17:54:54 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2013 19:48:23 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Andoni", "Alexandr", ""], ["Indyk", "Piotr", ""], ["Nguyen", "Huy L.", ""], ["Razenshteyn", "Ilya", ""]]}, {"id": "1306.1716", "submitter": "Alexander Petukhov", "authors": "Alexander Petukhov and Inna Kozlov", "title": "Fast greedy algorithm for subspace clustering from corrupted and\n  incomplete data", "comments": "arXiv admin note: substantial text overlap with arXiv:1304.4282", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the Fast Greedy Sparse Subspace Clustering (FGSSC) algorithm\nproviding an efficient method for clustering data belonging to a few\nlow-dimensional linear or affine subspaces. The main difference of our\nalgorithm from predecessors is its ability to work with noisy data having a\nhigh rate of erasures (missed entries with the known coordinates) and errors\n(corrupted entries with unknown coordinates). We discuss here how to implement\nthe fast version of the greedy algorithm with the maximum efficiency whose\ngreedy strategy is incorporated into iterations of the basic algorithm.\n  We provide numerical evidences that, in the subspace clustering capability,\nthe fast greedy algorithm outperforms not only the existing state-of-the art\nSSC algorithm taken by the authors as a basic algorithm but also the recent\nGSSC algorithm. At the same time, its computational cost is only slightly\nhigher than the cost of SSC.\n  The numerical evidence of the algorithm significant advantage is presented\nfor a few synthetic models as well as for the Extended Yale B dataset of facial\nimages. In particular, the face recognition misclassification rate turned out\nto be 6-20 times lower than for the SSC algorithm. We provide also the\nnumerical evidence that the FGSSC algorithm is able to perform clustering of\ncorrupted data efficiently even when the sum of subspace dimensions\nsignificantly exceeds the dimension of the ambient space.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2013 13:14:50 GMT"}], "update_date": "2013-06-10", "authors_parsed": [["Petukhov", "Alexander", ""], ["Kozlov", "Inna", ""]]}, {"id": "1306.2043", "submitter": "Zhiqing Wei", "authors": "Zhiqing Wei", "title": "A Raindrop Algorithm for Searching The Global Optimal Solution in\n  Non-linear Programming", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply the random walk model in designing a raindrop\nalgorithm to find the global optimal solution of a non-linear programming\nproblem. The raindrop algorithm does not require the information of the first\nor second order derivatives of the object function. Hence it is a direct\nmethod. We investigate the properties of raindrop algorithm. Besides, we apply\nthe raindrop algorithm to solve a non-linear optimization problem, where the\nobject function is highly irregular (neither convex nor concave). And the\nglobal optimal solution can be found with small number of iterations.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2013 17:36:38 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Wei", "Zhiqing", ""]]}, {"id": "1306.2053", "submitter": "Sergey Pupyrev", "authors": "Md. Jawaherul Alam and Stephen G. Kobourov and Sergey Pupyrev and\n  Jakson Toeniskoetter", "title": "Happy Edges: Threshold-Coloring of Regular Lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a graph coloring problem motivated by a fun Sudoku-style puzzle.\nGiven a bipartition of the edges of a graph into {\\em near} and {\\em far} sets\nand an integer threshold $t$, a {\\em threshold-coloring} of the graph is an\nassignment of integers to the vertices so that endpoints of near edges differ\nby $t$ or less, while endpoints of far edges differ by more than $t$. We study\nthreshold-coloring of tilings of the plane by regular polygons, known as\nArchimedean lattices, and their duals, the Laves lattices. We prove that some\nare threshold-colorable with constant number of colors for any edge labeling,\nsome require an unbounded number of colors for specific labelings, and some are\nnot threshold-colorable.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2013 19:23:58 GMT"}, {"version": "v2", "created": "Wed, 5 Mar 2014 23:01:14 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Alam", "Md. Jawaherul", ""], ["Kobourov", "Stephen G.", ""], ["Pupyrev", "Sergey", ""], ["Toeniskoetter", "Jakson", ""]]}, {"id": "1306.2079", "submitter": "Martin Fink", "authors": "Martin Fink and Sergey Pupyrev", "title": "Metro-Line Crossing Minimization: Hardness, Approximations, and\n  Tractable Cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crossing minimization is one of the central problems in graph drawing.\nRecently, there has been an increased interest in the problem of minimizing\ncrossings between paths in drawings of graphs. This is the metro-line crossing\nminimization problem (MLCM): Given an embedded graph and a set L of simple\npaths, called lines, order the lines on each edge so that the total number of\ncrossings is minimized. So far, the complexity of MLCM has been an open\nproblem. In contrast, the problem variant in which line ends must be placed in\noutermost position on their edges (MLCM-P) is known to be NP-hard. Our main\nresults answer two open questions: (i) We show that MLCM is NP-hard. (ii) We\ngive an $O(\\sqrt{\\log |L|})$-approximation algorithm for MLCM-P.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 00:48:53 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2013 07:51:36 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2013 17:17:50 GMT"}], "update_date": "2013-06-19", "authors_parsed": [["Fink", "Martin", ""], ["Pupyrev", "Sergey", ""]]}, {"id": "1306.2083", "submitter": "Aaron Roth", "authors": "Mallesh Pai and Aaron Roth", "title": "Privacy and Mechanism Design", "comments": "This survey appears in SIGecom Exchanges 12.1, 2013", "journal-ref": "SIGecom Exchanges 12.1, 2013", "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a survey of recent work at the intersection of mechanism design\nand privacy. The connection is a natural one, but its study has been\njump-started in recent years by the advent of differential privacy, which\nprovides a rigorous, quantitative way of reasoning about the costs that an\nagent might experience because of the loss of his privacy. Here, we survey\nseveral facets of this study, and differential privacy plays a role in more\nthan one way. Of course, it provides us a basis for modeling agent costs for\nprivacy, which is essential if we are to attempt mechanism design in a setting\nin which agents have preferences for privacy. It also provides a toolkit for\ncontrolling those costs. However, perhaps more surprisingly, it provides a\npowerful toolkit for controlling the stability of mechanisms in general, which\nyields a set of tools for designing novel mechanisms even in economic settings\ncompletely unrelated to privacy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 01:41:38 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Pai", "Mallesh", ""], ["Roth", "Aaron", ""]]}, {"id": "1306.2187", "submitter": "Stefan Hoffmann", "authors": "Stefan Hoffmann, Egon Wanke", "title": "Metric Dimension for Gabriel Unit Disk Graphs is NP-Complete", "comments": "A brief announcement of this result has been published in the\n  proceedings of ALGOSENSORS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that finding a minimal number of landmark nodes for a unique virtual\naddressing by hop-distances in wireless ad-hoc sensor networks is NP-complete\neven if the networks are unit disk graphs that contain only Gabriel edges. This\nproblem is equivalent to Metric Dimension for Gabriel unit disk graphs. The\nGabriel edges of a unit disc graph induce a planar O(\\sqrt{n}) distance and an\noptimal energy spanner. This is one of the most interesting restrictions of\nMetric Dimension in the context of wireless multi-hop networks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 12:55:16 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Hoffmann", "Stefan", ""], ["Wanke", "Egon", ""]]}, {"id": "1306.2217", "submitter": "Edouard Bonnet", "authors": "Edouard Bonnet, Bruno Escoffier, Vangelis Th. Paschos and Emeric\n  Tourniaire", "title": "Multi-parameter complexity analysis for constrained size graph problems:\n  using greediness for parameterization", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of a broad class of problems called\n\"local graph partitioning problems\" that includes the classical fixed\ncardinality problems as max k-vertex cover, k-densest subgraph, etc. By\ndeveloping a technique \"greediness-for-parameterization\", we obtain fixed\nparameter algorithms with respect to a pair of parameters k, the size of the\nsolution (but not its value) and \\Delta, the maximum degree of the input graph.\nIn particular, greediness-for-parameterization improves asymptotic running\ntimes for these problems upon random separation (that is a special case of\ncolor coding) and is more intuitive and simple. Then, we show how these results\ncan be easily extended for getting standard-parameterization results (i.e.,\nwith parameter the value of the optimal solution) for a well known local graph\npartitioning problem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 14:48:11 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Bonnet", "Edouard", ""], ["Escoffier", "Bruno", ""], ["Paschos", "Vangelis Th.", ""], ["Tourniaire", "Emeric", ""]]}, {"id": "1306.2483", "submitter": "Emanuele Giaquinta", "authors": "Emanuele Giaquinta, Kimmo Fredriksson, Szymon Grabowski, Alexandru I.\n  Tomescu, Esko Ukkonen", "title": "Motif matching using gapped patterns", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2014.06.032", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new algorithms for the problem of multiple string matching of\ngapped patterns, where a gapped pattern is a sequence of strings such that\nthere is a gap of fixed length between each two consecutive strings. The\nproblem has applications in the discovery of transcription factor binding sites\nin DNA sequences when using generalized versions of the Position Weight Matrix\nmodel to describe transcription factor specificities. In these models a motif\ncan be matched as a set of gapped patterns with unit-length keywords. The\nexisting algorithms for matching a set of gapped patterns are worst-case\nefficient but not practical, or vice versa, in this particular case. The novel\nalgorithms that we present are based on dynamic programming and\nbit-parallelism, and lie in a middle-ground among the existing algorithms. In\nfact, their time complexity is close to the best existing bound and, yet, they\nare also practical. We also provide experimental results which show that the\npresented algorithms are fast in practice, and preferable if all the strings in\nthe patterns have unit-length.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 10:42:56 GMT"}, {"version": "v2", "created": "Mon, 7 Jul 2014 14:03:33 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Giaquinta", "Emanuele", ""], ["Fredriksson", "Kimmo", ""], ["Grabowski", "Szymon", ""], ["Tomescu", "Alexandru I.", ""], ["Ukkonen", "Esko", ""]]}, {"id": "1306.2547", "submitter": "Aryeh Kontorovich", "authors": "Lee-Ad Gottlieb and Aryeh Kontorovich and Robert Krauthgamer", "title": "Efficient Classification for Metric Data", "comments": "This is the full version of an extended abstract that appeared in\n  Proceedings of the 23rd COLT, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in large-margin classification of data residing in general\nmetric spaces (rather than Hilbert spaces) enable classification under various\nnatural metrics, such as string edit and earthmover distance. A general\nframework developed for this purpose by von Luxburg and Bousquet [JMLR, 2004]\nleft open the questions of computational efficiency and of providing direct\nbounds on generalization error.\n  We design a new algorithm for classification in general metric spaces, whose\nruntime and accuracy depend on the doubling dimension of the data points, and\ncan thus achieve superior classification performance in many common scenarios.\nThe algorithmic core of our approach is an approximate (rather than exact)\nsolution to the classical problems of Lipschitz extension and of Nearest\nNeighbor Search. The algorithm's generalization performance is guaranteed via\nthe fat-shattering dimension of Lipschitz classifiers, and we present\nexperimental evidence of its superiority to some common kernel methods. As a\nby-product, we offer a new perspective on the nearest neighbor classifier,\nwhich yields significantly sharper risk asymptotics than the classic analysis\nof Cover and Hart [IEEE Trans. Info. Theory, 1967].\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 15:00:35 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2014 19:56:43 GMT"}, {"version": "v3", "created": "Thu, 10 Jul 2014 21:33:44 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kontorovich", "Aryeh", ""], ["Krauthgamer", "Robert", ""]]}, {"id": "1306.2552", "submitter": "Francesco Silvestri", "authors": "Andrea Pietracaprina and Geppino Pucci and Francesco Silvestri and\n  Fabio Vandin", "title": "Space-Efficient Parallel Algorithms for Combinatorial Search Problems", "comments": "Extended version of the paper in the Proc. of 38th International\n  Symposium on Mathematical Foundations of Computer Science (MFCS)", "journal-ref": null, "doi": "10.4230/LIPIcs.STACS.2014.627", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present space-efficient parallel strategies for two fundamental\ncombinatorial search problems, namely, backtrack search and branch-and-bound,\nboth involving the visit of an $n$-node tree of height $h$ under the assumption\nthat a node can be accessed only through its father or its children. For both\nproblems we propose efficient algorithms that run on a $p$-processor\ndistributed-memory machine. For backtrack search, we give a deterministic\nalgorithm running in $O(n/p+h\\log p)$ time, and a Las Vegas algorithm requiring\noptimal $O(n/p+h)$ time, with high probability. Building on the backtrack\nsearch algorithm, we also derive a Las Vegas algorithm for branch-and-bound\nwhich runs in $O((n/p+h\\log p \\log n)h\\log^2 n)$ time, with high probability. A\nremarkable feature of our algorithms is the use of only constant space per\nprocessor, which constitutes a significant improvement upon previous algorithms\nwhose space requirements per processor depend on the (possibly huge) tree to be\nexplored.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 15:29:17 GMT"}, {"version": "v2", "created": "Wed, 26 Mar 2014 13:17:39 GMT"}], "update_date": "2014-03-27", "authors_parsed": [["Pietracaprina", "Andrea", ""], ["Pucci", "Geppino", ""], ["Silvestri", "Francesco", ""], ["Vandin", "Fabio", ""]]}, {"id": "1306.2578", "submitter": "Yixin Cao", "authors": "Yixin Cao", "title": "A note on small cuts for a terminal", "comments": "Results already known (http://dx.doi.org/10.1016/j.ic.2012.10.016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G = (V,E)$ and a terminal $s\\in V$, a cut $X$ for $s$ is a\nvertex set that contains $s$. We look for a cut that is small in two senses,\ni.e., there are no more than $k$ vertices in $X$ and no more than $t$ edges\nleaving $X$. Answering a question asked by Fomin et al. (arXiv:1304.6189), we\nshow the problem is fixed-parameter tractable parameterized by either $k$ or\n$t$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 16:45:10 GMT"}, {"version": "v2", "created": "Tue, 4 Mar 2014 22:46:27 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Cao", "Yixin", ""]]}, {"id": "1306.2815", "submitter": "Casper Kejlberg-Rasmussen", "authors": "Casper Kejlberg-Rasmussen and Yufei Tao and Konstantinos Tsakalidis\n  and Kostas Tsichlas and Jeonghun Yoon", "title": "I/O-Efficient Planar Range Skyline and Attrition Priority Queues", "comments": "Appeared at PODS 2013, New York, 19 pages, 10 figures. arXiv admin\n  note: text overlap with arXiv:1208.4511, arXiv:1207.2341", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the planar range skyline reporting problem, we store a set P of n 2D\npoints in a structure such that, given a query rectangle Q = [a_1, a_2] x [b_1,\nb_2], the maxima (a.k.a. skyline) of P \\cap Q can be reported efficiently. The\nquery is 3-sided if an edge of Q is grounded, giving rise to two variants:\ntop-open (b_2 = \\infty) and left-open (a_1 = -\\infty) queries.\n  All our results are in external memory under the O(n/B) space budget, for\nboth the static and dynamic settings:\n  * For static P, we give structures that answer top-open queries in O(log_B n\n+ k/B), O(loglog_B U + k/B), and O(1 + k/B) I/Os when the universe is R^2, a U\nx U grid, and a rank space grid [O(n)]^2, respectively (where k is the number\nof reported points). The query complexity is optimal in all cases.\n  * We show that the left-open case is harder, such that any linear-size\nstructure must incur \\Omega((n/B)^e + k/B) I/Os for a query. We show that this\ncase is as difficult as the general 4-sided queries, for which we give a static\nstructure with the optimal query cost O((n/B)^e + k/B).\n  * We give a dynamic structure that supports top-open queries in O(log_2B^e\n(n/B) + k/B^1-e) I/Os, and updates in O(log_2B^e (n/B)) I/Os, for any e\nsatisfying 0 \\le e \\le 1. This leads to a dynamic structure for 4-sided queries\nwith optimal query cost O((n/B)^e + k/B), and amortized update cost O(log\n(n/B)).\n  As a contribution of independent interest, we propose an I/O-efficient\nversion of the fundamental structure priority queue with attrition (PQA). Our\nPQA supports FindMin, DeleteMin, and InsertAndAttrite all in O(1) worst case\nI/Os, and O(1/B) amortized I/Os per operation.\n  We also add the new CatenateAndAttrite operation that catenates two PQAs in\nO(1) worst case and O(1/B) amortized I/Os. This operation is a non-trivial\nextension to the classic PQA of Sundar, even in internal memory.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 13:05:49 GMT"}], "update_date": "2013-06-13", "authors_parsed": [["Kejlberg-Rasmussen", "Casper", ""], ["Tao", "Yufei", ""], ["Tsakalidis", "Konstantinos", ""], ["Tsichlas", "Kostas", ""], ["Yoon", "Jeonghun", ""]]}, {"id": "1306.2931", "submitter": "Neeldhara Misra", "authors": "Prachi Goyal, Vikram Kamat and Neeldhara Misra", "title": "On the Parameterized Complexity of the Maximum Edge Coloring Problem", "comments": "18 pages, 2 figures, accepted at MFCS 2013. arXiv admin note: text\n  overlap with arXiv:1009.0806 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the parameterized complexity of the following edge coloring\nproblem motivated by the problem of channel assignment in wireless networks.\nFor an integer q>1 and a graph G, the goal is to find a coloring of the edges\nof G with the maximum number of colors such that every vertex of the graph sees\nat most q colors. This problem is NP-hard for q>1, and has been well-studied\nfrom the point of view of approximation. Our main focus is the case when q=2,\nwhich is already theoretically intricate and practically relevant. We show\nfixed-parameter tractable algorithms for both the standard and the dual\nparameter, and for the latter problem, the result is based on a linear vertex\nkernel.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 19:29:03 GMT"}], "update_date": "2013-06-13", "authors_parsed": [["Goyal", "Prachi", ""], ["Kamat", "Vikram", ""], ["Misra", "Neeldhara", ""]]}, {"id": "1306.2978", "submitter": "Ignaz Rutter", "authors": "Alexander Koch and Marcus Krug and Ignaz Rutter", "title": "Graphs with Plane Outside-Obstacle Representations", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An \\emph{obstacle representation} of a graph consists of a set of polygonal\nobstacles and a distinct point for each vertex such that two points see each\nother if and only if the corresponding vertices are adjacent. Obstacle\nrepresentations are a recent generalization of classical polygon--vertex\nvisibility graphs, for which the characterization and recognition problems are\nlong-standing open questions.\n  In this paper, we study \\emph{plane outside-obstacle representations}, where\nall obstacles lie in the unbounded face of the representation and no two\nvisibility segments cross. We give a combinatorial characterization of the\nbiconnected graphs that admit such a representation. Based on this\ncharacterization, we present a simple linear-time recognition algorithm for\nthese graphs. As a side result, we show that the plane vertex--polygon\nvisibility graphs are exactly the maximal outerplanar graphs and that every\nchordal outerplanar graph has an outside-obstacle representation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 21:10:53 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Koch", "Alexander", ""], ["Krug", "Marcus", ""], ["Rutter", "Ignaz", ""]]}, {"id": "1306.2988", "submitter": "Gagan Goel", "authors": "Gagan Goel and Pushkar Tripathi", "title": "Matching with our Eyes Closed", "comments": "This paper has been withdrawn by the authors. The result claiming a\n  factor 0.56 algorithm is invalid because of a crucial bug in Claim 2 which\n  was brought to our attention by Matthias Poloczek, Frans Schalekamp, and Anke\n  van Zuylen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by an application in kidney exchange, we study the following\nquery-commit problem: we are given the set of vertices of a non-bipartite graph\nG. The set of edges in this graph are not known ahead of time. We can query any\npair of vertices to determine if they are adjacent. If the queried edge exists,\nwe are committed to match the two endpoints. Our objective is to maximize the\nsize of the matching.\n  This restriction in the amount of information available to the algorithm\nconstraints us to implement myopic, greedy-like algorithms. A simple\ndeterministic greedy algorithm achieves a factor 1/2 which is tight for\ndeterministic algorithms. An important open question in this direction is to\ngive a randomized greedy algorithm that has a significantly better\napproximation factor. This question was first asked almost 20 years ago by Dyer\nand Frieze [9] where they showed that a natural randomized strategy of picking\nedges uniformly at random doesn't help and has an approximation factor of 1/2 +\no(1). They left it as an open question to devise a better randomized greedy\nalgorithm. In subsequent work, Aronson, Dyer, Frieze, and Suen [2] gave a\ndifferent randomized greedy algorithm and showed that it attains a factor 0.5 +\nepsilon where epsilon is 0.0000025.\n  In this paper we propose and analyze a new randomized greedy algorithm for\nfinding a large matching in a general graph and use it to solve the query\ncommit problem mentioned above. We show that our algorithm attains a factor of\nat least 0.56, a significant improvement over 0.50000025. We also show that no\nrandomized algorithm can have an approximation factor better than 0.7916 for\nthe query commit problem. For another large and interesting class of randomized\nalgorithms that we call vertex-iterative algorithms, we show that no\nvertex-iterative algorithm can have an approximation factor better than 0.75.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 23:07:27 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2013 01:08:36 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Goel", "Gagan", ""], ["Tripathi", "Pushkar", ""]]}, {"id": "1306.3000", "submitter": "Pawe{\\l} Pszona", "authors": "Michael T. Goodrich, Pawe{\\l} Pszona", "title": "Cole's Parametric Search Technique Made Practical", "comments": "12 pages, 4 figures. To appear at the 25th Canadian Conference on\n  Computational Geometry (CCCG 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric search has been widely used in geometric algorithms. Cole's\nimprovement provides a way of saving a logarithmic factor in the running time\nover what is achievable using the standard method. Unfortunately, this\nimprovement comes at the expense of making an already complicated algorithm\neven more complex; hence, this technique has been mostly of theoretical\ninterest. In this paper, we provide an algorithm engineering framework that\nallows for the same asymptotic complexity to be achieved probabilistically in a\nway that is both simple and practical (i.e., suitable for actual\nimplementation). The main idea of our approach is to show that a variant of\nquicksort, known as boxsort, can be used to drive comparisons, instead of using\na sorting network, like the complicated AKS network, or an EREW parallel\nsorting algorithm, like the fairly intricate parallel mergesort algorithm. This\nresults in a randomized optimization algorithm with a running time matching\nthat of using Cole's method, with high probability, while also being practical.\nWe show how this results in practical implementations of some geometric\nalgorithms utilizing parametric searching and provide experimental results that\nprove practicality of the method.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 00:44:58 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Goodrich", "Michael T.", ""], ["Pszona", "Pawe\u0142", ""]]}, {"id": "1306.3030", "submitter": "Bodo Manthey", "authors": "Karl Bringmann, Christian Engels, Bodo Manthey and B.V. Raghavendra\n  Rao", "title": "Random Shortest Paths: Non-Euclidean Instances for Metric Optimization\n  Problems", "comments": "To appear in Algorithmica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic analysis for metric optimization problems has mostly been\nconducted on random Euclidean instances, but little is known about metric\ninstances drawn from distributions other than the Euclidean. This motivates our\nstudy of random metric instances for optimization problems obtained as follows:\nEvery edge of a complete graph gets a weight drawn independently at random. The\ndistance between two nodes is then the length of a shortest path (with respect\nto the weights drawn) that connects these nodes.\n  We prove structural properties of the random shortest path metrics generated\nin this way. Our main structural contribution is the construction of a good\nclustering. Then we apply these findings to analyze the approximation ratios of\nheuristics for matching, the traveling salesman problem (TSP), and the k-median\nproblem, as well as the running-time of the 2-opt heuristic for the TSP. The\nbounds that we obtain are considerably better than the respective worst-case\nbounds. This suggests that random shortest path metrics are easy instances,\nsimilar to random Euclidean instances, albeit for completely different\nstructural reasons.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 06:16:41 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2013 05:19:37 GMT"}, {"version": "v3", "created": "Fri, 23 May 2014 09:12:25 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Bringmann", "Karl", ""], ["Engels", "Christian", ""], ["Manthey", "Bodo", ""], ["Rao", "B. V. Raghavendra", ""]]}, {"id": "1306.3119", "submitter": "Kanstantsin Pashkovich", "authors": "Samuel Fiorini and Kanstantsin Pashkovich", "title": "Uncapacitated Flow-based Extended Formulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extended formulation of a polytope is a linear description of this\npolytope using extra variables besides the variables in which the polytope is\ndefined. The interest of extended formulations is due to the fact that many\ninteresting polytopes have extended formulations with a lot fewer inequalities\nthan any linear description in the original space. This motivates the\ndevelopment of methods for, on the one hand, constructing extended formulations\nand, on the other hand, proving lower bounds on the sizes of extended\nformulations.\n  Network flows are a central paradigm in discrete optimization, and are widely\nused to design extended formulations. We prove exponential lower bounds on the\nsizes of uncapacitated flow-based extended formulations of several polytopes,\nsuch as the (bipartite and non-bipartite) perfect matching polytope and TSP\npolytope. We also give new examples of flow-based extended formulations, e.g.,\nfor 0/1-polytopes defined from regular languages. Finally, we state a few open\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 14:27:42 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Fiorini", "Samuel", ""], ["Pashkovich", "Kanstantsin", ""]]}, {"id": "1306.3181", "submitter": "Yixin Cao", "authors": "Yixin Cao", "title": "An Efficient Branching Algorithm for Interval Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the \\emph{{interval completion}} problem, which asks for the\ninsertion of a set of at most $k$ edges to make a graph of $n$ vertices into an\ninterval graph. We focus on chordal graphs with no small obstructions, where\nevery remaining obstruction is known to have a shallow property. From such a\nshallow obstruction we single out a subset 6 or 7 vertices, called the frame,\nand 5 missed edges in the subgraph induced by the frame. We show that if none\nof these edges is inserted, then the frame cannot be altered at all, and the\nwhole obstruction is also fixed, by and large, in the sense that their related\npositions in an interval representation of the objective interval graph have a\nspecific pattern. We propose a simple bounded search process, which effectively\ntransforms a given graph to a graph with the structural property that all\nobstructions are shallow and have fixed frames. Then we fill in polynomial time\nall obstructions that have been previously left in indecision. These efforts\ntogether deliver a simple parameterized algorithm of time $6^k\\cdot n^{O(1)}$\nfor the problem, significantly improving the only known parameterized algorithm\nof time $k^{2k}\\cdot n^{O(1)}$.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 18:22:43 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Cao", "Yixin", ""]]}, {"id": "1306.3284", "submitter": "Edith Cohen", "authors": "Edith Cohen", "title": "All-Distances Sketches, Revisited: HIP Estimators for Massive Graphs\n  Analysis", "comments": "16 pages, 3 figures, extended version of a PODS 2014 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph datasets with billions of edges, such as social and Web graphs, are\nprevalent, and scalable computation is critical. All-distances sketches (ADS)\n[Cohen 1997], are a powerful tool for scalable approximation of statistics.\n  The sketch is a small size sample of the distance relation of a node which\nemphasizes closer nodes. Sketches for all nodes are computed using a nearly\nlinear computation and estimators are applied to sketches of nodes to estimate\ntheir properties.\n  We provide, for the first time, a unified exposition of ADS algorithms and\napplications. We present the Historic Inverse Probability (HIP) estimators\nwhich are applied to the ADS of a node to estimate a large natural class of\nstatistics. For the important special cases of neighborhood cardinalities (the\nnumber of nodes within some query distance) and closeness centralities, HIP\nestimators have at most half the variance of previous estimators and we show\nthat this is essentially optimal. Moreover, HIP obtains a polynomial\nimprovement for more general statistics and the estimators are simple,\nflexible, unbiased, and elegant.\n  For approximate distinct counting on data streams, HIP outperforms the\noriginal estimators for the HyperLogLog MinHash sketches (Flajolet et al.\n2007), obtaining significantly improved estimation quality for this\nstate-of-the-art practical algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2013 03:33:05 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2013 12:01:34 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2013 00:54:09 GMT"}, {"version": "v4", "created": "Wed, 11 Dec 2013 05:36:59 GMT"}, {"version": "v5", "created": "Wed, 23 Apr 2014 23:09:46 GMT"}, {"version": "v6", "created": "Wed, 5 Nov 2014 06:11:04 GMT"}, {"version": "v7", "created": "Sat, 17 Jan 2015 07:55:41 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Cohen", "Edith", ""]]}, {"id": "1306.3482", "submitter": "Joseph Simons", "authors": "David Eppstein and Michael T. Goodrich and Joseph A. Simons", "title": "Set-Difference Range Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of performing set-difference range queries, where\nanswers to queries are set-theoretic symmetric differences between sets of\nitems in two geometric ranges. We describe a general framework for answering\nsuch queries based on a novel use of data-streaming sketches we call signed\nsymmetric-difference sketches. We show that such sketches can be realized using\ninvertible Bloom filters (IBFs), which can be composed, differenced, and\nsearched so as to solve set-difference range queries in a wide range of\nscenarios.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2013 18:50:47 GMT"}], "update_date": "2013-06-17", "authors_parsed": [["Eppstein", "David", ""], ["Goodrich", "Michael T.", ""], ["Simons", "Joseph A.", ""]]}, {"id": "1306.3525", "submitter": "Sudipto Guha", "authors": "Sudipto Guha and Kamesh Munagala", "title": "Approximation Algorithms for Bayesian Multi-Armed Bandit Problems", "comments": "arXiv admin note: text overlap with arXiv:1011.1161", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider several finite-horizon Bayesian multi-armed bandit\nproblems with side constraints which are computationally intractable (NP-Hard)\nand for which no optimal (or near optimal) algorithms are known to exist with\nsub-exponential running time. All of these problems violate the standard\nexchange property, which assumes that the reward from the play of an arm is not\ncontingent upon when the arm is played. Not only are index policies suboptimal\nin these contexts, there has been little analysis of such policies in these\nproblem settings. We show that if we consider near-optimal policies, in the\nsense of approximation algorithms, then there exists (near) index policies.\nConceptually, if we can find policies that satisfy an approximate version of\nthe exchange property, namely, that the reward from the play of an arm depends\non when the arm is played to within a constant factor, then we have an avenue\ntowards solving these problems. However such an approximate version of the\nidling bandit property does not hold on a per-play basis and are shown to hold\nin a global sense. Clearly, such a property is not necessarily true of\narbitrary single arm policies and finding such single arm policies is\nnontrivial. We show that by restricting the state spaces of arms we can find\nsingle arm policies and that these single arm policies can be combined into\nglobal (near) index policies where the approximate version of the exchange\nproperty is true in expectation. The number of different bandit problems that\ncan be addressed by this technique already demonstrate its wide applicability.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2013 22:24:29 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2013 19:16:47 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Guha", "Sudipto", ""], ["Munagala", "Kamesh", ""]]}, {"id": "1306.3538", "submitter": "Yushi Uno", "authors": "Yoshio Okamoto, Yuichi Tatsu and Yushi Uno", "title": "Exact and fixed-parameter algorithms for metro-line crossing\n  minimization problems", "comments": "19 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A metro-line crossing minimization problem is to draw multiple lines on an\nunderlying graph that models stations and rail tracks so that the number of\ncrossings of lines becomes minimum. It has several variations by adding\nrestrictions on how lines are drawn. Among those, there is one with a\nrestriction that line terminals have to be drawn at a verge of a station, and\nit is known to be NP-hard even when underlying graphs are paths. This paper\nstudies the problem in this setting, and propose new exact algorithms. We first\nshow that a problem to decide if lines can be drawn without crossings is solved\nin polynomial time, and propose a fast exponential algorithm to solve a\ncrossing minimization problem. We then propose a fixed-parameter algorithm with\nrespect to the multiplicity of lines, which implies that the problem is FPT.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2013 01:41:52 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Okamoto", "Yoshio", ""], ["Tatsu", "Yuichi", ""], ["Uno", "Yushi", ""]]}, {"id": "1306.3566", "submitter": "Marcin Pilipczuk", "authors": "Tomasz Kociumaka and Marcin Pilipczuk", "title": "Faster deterministic Feedback Vertex Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two new deterministic algorithms for the Feedback Vertex Set\nproblem parameterized by the solution size. We begin with a simple algorithm,\nwhich runs in O*((2 + \\phi)^k) time, where \\phi < 1.619 is the golden ratio. It\nalready surpasses the previously fastest O*((1+2sqrt(2))^k)-time deterministic\nalgorithm due to Cao et al. [SWAT 2010]. In our developments we follow the\napproach of Cao et al., however, thanks to a new reduction rule, we obtain not\nonly better dependency on the parameter in the running time, but also a\nsolution with simple analysis and only a single branching rule. Then, we\npresent a modification of the algorithm which, using a more involved set of\nbranching rules, achieves O*(3.592^k) running time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2013 11:36:20 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Kociumaka", "Tomasz", ""], ["Pilipczuk", "Marcin", ""]]}, {"id": "1306.3601", "submitter": "Huy Nguyen", "authors": "Huy L. Nguyen", "title": "Approximate Nearest Neighbor Search in $\\ell_p$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new locality sensitive hashing (LSH) algorithm for\n$c$-approximate nearest neighbor search in $\\ell_p$ with $1<p<2$. For a\ndatabase of $n$ points in $\\ell_p$, we achieve $O(dn^{\\rho})$ query time and\n$O(dn+n^{1+\\rho})$ space, where $\\rho \\le O((\\ln c)^2/c^p)$. This improves upon\nthe previous best upper bound $\\rho\\le 1/c$ by Datar et al. (SOCG 2004), and is\nclose to the lower bound $\\rho \\ge 1/c^p$ by O'Donnell, Wu and Zhou (ITCS\n2011). The proof is a simple generalization of the LSH scheme for $\\ell_2$ by\nAndoni and Indyk (FOCS 2006).\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2013 19:40:18 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Nguyen", "Huy L.", ""]]}, {"id": "1306.3602", "submitter": "Shenshi Chen", "authors": "Shenshi Chen and Zhixiang Chen", "title": "Faster Deterministic Algorithms for Packing, Matching and $t$-Dominating\n  Set Problems", "comments": "ISAAC13 Submission. arXiv admin note: substantial text overlap with\n  arXiv:1303.0478", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we devise three deterministic algorithms for solving the\n$m$-set $k$-packing, $m$-dimensional $k$-matching, and $t$-dominating set\nproblems in time $O^*(5.44^{mk})$, $O^*(5.44^{(m-1)k})$ and $O^*(5.44^{t})$,\nrespectively. Although recently there has been remarkable progress on\nrandomized solutions to those problems, our bounds make good improvements on\nthe best known bounds for deterministic solutions to those problems.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2013 19:48:52 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Chen", "Shenshi", ""], ["Chen", "Zhixiang", ""]]}, {"id": "1306.3649", "submitter": "Gregory Gutin", "authors": "David Cohen, Jason Crampton, Andrei Gagarin, Gregory Gutin, Mark Jones", "title": "Iterative Plan Construction for the Workflow Satisfiability Problem", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research 51 (2014), pp.555-577", "doi": "10.1613/jair.4435", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\emph{Workflow Satisfiability Problem (WSP)} is a problem of practical\ninterest that arises whenever tasks need to be performed by authorized users,\nsubject to constraints defined by business rules. We are required to decide\nwhether there exists a \\emph{plan} -- an assignment of tasks to authorized\nusers -- such that all constraints are satisfied. Several bespoke algorithms\nhave been constructed for solving the WSP, optimised to deal with constraints\n(business rules) of particular types.\n  It is natural to see the WSP as a subclass of the {\\em Constraint\nSatisfaction Problem (CSP)} in which the variables are tasks and the domain is\nthe set of users. What makes the WSP distinctive as a CSP is that we can assume\nthat the number of tasks is very small compared to the number of users. This is\nin sharp contrast with traditional CSP models where the domain is small and the\nnumber of variables is very large. As such, it is appropriate to ask for which\nconstraint languages the WSP is fixed-parameter tractable (FPT), parameterized\nby the number of tasks. We have identified a new FPT constraint language,\nuser-independent constraint, that includes many of the constraints of interest\nin business processing systems. We are also able to prove that the union of FPT\nlanguages remains FPT if they satisfy a simple compatibility condition.\n  In this paper we present our generic algorithm, in which plans are grouped\ninto equivalence classes, each class being associated with a \\emph{pattern}. We\ndemonstrate that our generic algorithm has running time $O^*(2^{k\\log k})$,\nwhere $k$ is the number of tasks, for the language of user-independent\nconstraints. We also show that there is no algorithm of running time\n$O^*(2^{o(k\\log k)})$ for user-independent constraints unless the Exponential\nTime Hypothesis fails.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2013 10:45:32 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2013 08:33:05 GMT"}, {"version": "v3", "created": "Thu, 8 May 2014 09:08:03 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Cohen", "David", ""], ["Crampton", "Jason", ""], ["Gagarin", "Andrei", ""], ["Gutin", "Gregory", ""], ["Jones", "Mark", ""]]}, {"id": "1306.3727", "submitter": "Lin Chen", "authors": "Lin Chen, Deshi Ye, Guochuan Zhang", "title": "A note on scheduling with low rank processing times", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical minimum makespan scheduling problem, where the\nprocessing time of job $j$ on machine $i$ is $p_{ij}$, and the matrix\n$P=(p_{ij})_{m\\times n}$ is of a low rank. It is proved in (Bhaskara et al.,\nSODA 2013) that rank 7 scheduling is NP-hard to approximate to a factor of\n$3/2-\\epsilon$, and rank 4 scheduling is APX-hard (NP-hard to approximate\nwithin a factor of $1.03-\\epsilon$). We improve this result by showing that\nrank 4 scheduling is already NP-hard to approximate within a factor of\n$3/2-\\epsilon$, and meanwhile rank 3 scheduling is APX-hard.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 02:19:11 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Chen", "Lin", ""], ["Ye", "Deshi", ""], ["Zhang", "Guochuan", ""]]}, {"id": "1306.3739", "submitter": "Reza Khani", "authors": "MohammadTaghi Hajiaghayi, Rohit Khandekar, M. Reza Khani, Guy Kortsarz", "title": "Approximation Algorithms for Movement Repairmen", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the {\\em Movement Repairmen (MR)} problem we are given a metric space $(V,\nd)$ along with a set $R$ of $k$ repairmen $r_1, r_2, ..., r_k$ with their start\ndepots $s_1, s_2, ..., s_k \\in V$ and speeds $v_1, v_2, ..., v_k \\geq 0$\nrespectively and a set $C$ of $m$ clients $c_1, c_2, ..., c_m$ having start\nlocations $s'_1, s'_2, ..., s'_m \\in V$ and speeds $v'_1, v'_2, ..., v'_m \\geq\n0$ respectively. If $t$ is the earliest time a client $c_j$ is collocated with\nany repairman (say, $r_i$) at a node $u$, we say that the client is served by\n$r_i$ at $u$ and that its latency is $t$. The objective in the (\\smr{}) problem\nis to plan the movements for all repairmen and clients to minimize the sum\n(average) of the clients latencies. The motivation for this problem comes, for\nexample, from Amazon Locker Delivery \\cite{amazon} and USPS gopost\n\\cite{gopost}. We give the first $O(\\log n)$-approximation algorithm for the\n\\smr{} problem.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 05:21:58 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2013 04:13:40 GMT"}], "update_date": "2013-06-19", "authors_parsed": [["Hajiaghayi", "MohammadTaghi", ""], ["Khandekar", "Rohit", ""], ["Khani", "M. Reza", ""], ["Kortsarz", "Guy", ""]]}, {"id": "1306.3772", "submitter": "Sarel Cohen", "authors": "Sarel Cohen, Amos Fiat, Moshik Hershcovitch, Haim Kaplan", "title": "Minimal Indices for Successor Search", "comments": "28 pages, full version, extended abstract submitted to MFCS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new successor data structure which improves upon the index size of\nthe P\\v{a}tra\\c{s}cu-Thorup data structures, reducing the index size from $O(n\nw^{4/5})$ bits to $O(n \\log w)$ bits, with optimal probe complexity.\nAlternatively, our new data structure can be viewed as matching the space\ncomplexity of the (probe-suboptimal) $z$-fast trie of Belazzougui et al. Thus,\nwe get the best of both approaches with respect to both probe count and index\nsize. The penalty we pay is an extra $O(\\log w)$ inter-register operations. Our\ndata structure can also be used to solve the weak prefix search problem, the\nindex size of $O(n \\log w)$ bits is known to be optimal for any such data\nstructure.\n  The technical contributions include highly efficient single word indices,\nwith out-degree $w/\\log w$ (compared to the $w^{1/5}$ out-degree of fusion tree\nbased indices). To construct such high efficiency single word indices we device\nhighly efficient bit selectors which, we believe, are of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 08:47:05 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Cohen", "Sarel", ""], ["Fiat", "Amos", ""], ["Hershcovitch", "Moshik", ""], ["Kaplan", "Haim", ""]]}, {"id": "1306.3797", "submitter": "Luca Ferrari", "authors": "Luca Ferrari", "title": "Greedy algorithms and poset matroids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the matroid-theoretic approach to greedy algorithms to the\nsetting of poset matroids, in the sense of Barnabei, Nicoletti and Pezzoli\n(1998) [BNP]. We illustrate our result by providing a generalization of Kruskal\nalgorithm (which finds a minimum spanning subtree of a weighted graph) to\nabstract simplicial complexes.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 10:12:27 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Ferrari", "Luca", ""]]}, {"id": "1306.3819", "submitter": "Sebastian Wild", "authors": "Sebastian Wild and Markus E. Nebel and Hosam Mahmoud", "title": "Analysis of Quickselect under Yaroslavskiy's Dual-Pivoting Algorithm", "comments": "full version with appendices; otherwise identical to Algorithmica\n  version", "journal-ref": null, "doi": "10.1007/s00453-014-9953-x", "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is excitement within the algorithms community about a new partitioning\nmethod introduced by Yaroslavskiy. This algorithm renders Quicksort slightly\nfaster than the case when it runs under classic partitioning methods. We show\nthat this improved performance in Quicksort is not sustained in Quickselect; a\nvariant of Quicksort for finding order statistics. We investigate the number of\ncomparisons made by Quickselect to find a key with a randomly selected rank\nunder Yaroslavskiy's algorithm. This grand averaging is a smoothing operator\nover all individual distributions for specific fixed order statistics. We give\nthe exact grand average. The grand distribution of the number of comparison\n(when suitably scaled) is given as the fixed-point solution of a distributional\nequation of a contraction in the Zolotarev metric space. Our investigation\nshows that Quickselect under older partitioning methods slightly outperforms\nQuickselect under Yaroslavskiy's algorithm, for an order statistic of a random\nrank. Similar results are obtained for extremal order statistics, where again\nwe find the exact average, and the distribution for the number of comparisons\n(when suitably scaled). Both limiting distributions are of perpetuities (a sum\nof products of independent mixed continuous random variables).\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 11:44:54 GMT"}, {"version": "v2", "created": "Fri, 18 Jul 2014 12:04:56 GMT"}, {"version": "v3", "created": "Sat, 15 Nov 2014 13:54:05 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Wild", "Sebastian", ""], ["Nebel", "Markus E.", ""], ["Mahmoud", "Hosam", ""]]}, {"id": "1306.3857", "submitter": "Archontia C. Giannopoulou", "authors": "Fedor V. Fomin, Archontia C. Giannopoulou and Micha{\\l} Pilipczuk", "title": "Computing Tree-depth Faster Than $2^{n}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A connected graph has tree-depth at most $k$ if it is a subgraph of the\nclosure of a rooted tree whose height is at most $k$. We give an algorithm\nwhich for a given $n$-vertex graph $G$, in time $\\mathcal{O}(1.9602^n)$\ncomputes the tree-depth of $G$. Our algorithm is based on combinatorial results\nrevealing the structure of minimal rooted trees whose closures contain $G$.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 13:48:44 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Giannopoulou", "Archontia C.", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1306.3877", "submitter": "Marcin Pilipczuk", "authors": "Anudhyan Boral and Marek Cygan and Tomasz Kociumaka and Marcin\n  Pilipczuk", "title": "Fast branching algorithm for Cluster Vertex Deletion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the family of clustering problems, we are given a set of objects (vertices\nof the graph), together with some observed pairwise similarities (edges). The\ngoal is to identify clusters of similar objects by slightly modifying the graph\nto obtain a cluster graph (disjoint union of cliques). Hueffner et al. [Theory\nComput. Syst. 2010] initiated the parameterized study of Cluster Vertex\nDeletion, where the allowed modification is vertex deletion, and presented an\nelegant O(2^k * k^9 + n * m)-time fixed-parameter algorithm, parameterized by\nthe solution size. In our work, we pick up this line of research and present an\nO(1.9102^k * (n + m))-time branching algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 14:43:35 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Boral", "Anudhyan", ""], ["Cygan", "Marek", ""], ["Kociumaka", "Tomasz", ""], ["Pilipczuk", "Marcin", ""]]}, {"id": "1306.4037", "submitter": "Travis Gagie", "authors": "H. Ferrada, T. Gagie, T. Hirvola and S. J. Puglisi", "title": "Hybrid Indexes for Repetitive Datasets", "comments": null, "journal-ref": null, "doi": "10.1098/rsta.2013.0137", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in DNA sequencing mean databases of thousands of human genomes will\nsoon be commonplace. In this paper we introduce a simple technique for reducing\nthe size of conventional indexes on such highly repetitive texts. Given upper\nbounds on pattern lengths and edit distances, we preprocess the text with LZ77\nto obtain a filtered text, for which we store a conventional index. Later,\ngiven a query, we find all matches in the filtered text, then use their\npositions and the structure of the LZ77 parse to find all matches in the\noriginal text. Our experiments show this also significantly reduces query\ntimes.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 22:48:15 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Ferrada", "H.", ""], ["Gagie", "T.", ""], ["Hirvola", "T.", ""], ["Puglisi", "S. J.", ""]]}, {"id": "1306.4111", "submitter": "Lukasz Kowalik", "authors": "Andreas Bj\\\"orklund and Petteri Kaski and {\\L}ukasz Kowalik", "title": "Counting thin subgraphs via packings faster than meet-in-the-middle time", "comments": "Journal version, 26 pages. Compared to the SODA'14 version, it\n  contains some new results: a) improved algorithms for counting t-tuples of\n  disjoint s-sets for the special cases of s = 2, 3, 4 and b) new hardness\n  arguments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vassilevska and Williams (STOC 2009) showed how to count simple paths on $k$\nvertices and matchings on $k/2$ edges in an $n$-vertex graph in time\n$n^{k/2+O(1)}$. In the same year, two different algorithms with the same\nruntime were given by Koutis and Williams~(ICALP 2009), and Bj\\\"orklund\n\\emph{et al.} (ESA 2009), via $n^{st/2+O(1)}$-time algorithms for counting\n$t$-tuples of pairwise disjoint sets drawn from a given family of $s$-sized\nsubsets of an $n$-element universe. Shortly afterwards, Alon and Gutner (TALG\n2010) showed that these problems have $\\Omega(n^{\\lfloor st/2\\rfloor})$ and\n$\\Omega(n^{\\lfloor k/2\\rfloor})$ lower bounds when counting by color coding.\n  Here we show that one can do better, namely, we show that the\n\"meet-in-the-middle\" exponent $st/2$ can be beaten and give an algorithm that\ncounts in time $n^{0.45470382 st + O(1)}$ for $t$ a multiple of three. This\nimplies algorithms for counting occurrences of a fixed subgraph on $k$ vertices\nand pathwidth $p\\ll k$ in an $n$-vertex graph in $n^{0.45470382k+2p+O(1)}$\ntime, improving on the three mentioned algorithms for paths and matchings, and\ncircumventing the color-coding lower bound. We also give improved bounds for\ncounting $t$-tuples of disjoint $s$-sets for $s=2,3,4$.\n  Our algorithms use fast matrix multiplication. We show an argument that this\nis necessary to go below the meet-in-the-middle barrier.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 09:10:41 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2015 16:05:13 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Bj\u00f6rklund", "Andreas", ""], ["Kaski", "Petteri", ""], ["Kowalik", "\u0141ukasz", ""]]}, {"id": "1306.4151", "submitter": "Elchanan Mossel", "authors": "Elchanan Mossel and Anupam Prakash and Gregory Valiant", "title": "Computation in anonymous networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify and investigate a computational model arising in molecular\ncomputing, social computing and sensor network. The model is made of of\nmultiple agents who are computationally limited and posses no global\ninformation. The agents may represent nodes in a social network, sensors, or\nmolecules in a molecular computer. Assuming that each agent is in one of $k$\nstates, we say that {\\em the system computes} $f:[k]^{n} \\to [k]$ if all agents\neventually converge to the correct value of $f$. We present number of general\nresults characterizing the computational power of the mode. We further present\nprotocols for computing the plurality function with $O(\\log k)$ memory and for\napproximately counting the number of nodes of a given color with $O(\\log \\log\nn)$ memory, where $n$ is the number of agents in the networks. These results\nare tight.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 11:37:39 GMT"}], "update_date": "2013-06-19", "authors_parsed": [["Mossel", "Elchanan", ""], ["Prakash", "Anupam", ""], ["Valiant", "Gregory", ""]]}, {"id": "1306.4207", "submitter": "Ragesh Jaiswal", "authors": "Ragesh Jaiswal and Prachi Jain and Saumya Yadav", "title": "A bad 2-dimensional instance for k-means++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-means++ seeding algorithm is one of the most popular algorithms that is\nused for finding the initial $k$ centers when using the k-means heuristic. The\nalgorithm is a simple sampling procedure and can be described as follows:\n{quote} Pick the first center randomly from among the given points. For $i >\n1$, pick a point to be the $i^{th}$ center with probability proportional to the\nsquare of the Euclidean distance of this point to the previously $(i-1)$ chosen\ncenters. {quote} The k-means++ seeding algorithm is not only simple and fast\nbut gives an $O(\\log{k})$ approximation in expectation as shown by Arthur and\nVassilvitskii \\cite{av07}. There are datasets \\cite{av07,adk09} on which this\nseeding algorithm gives an approximation factor $\\Omega(\\log{k})$ in\nexpectation. However, it is not clear from these results if the algorithm\nachieves good approximation factor with reasonably large probability (say\n$1/poly(k)$). Brunsch and R\\\"{o}glin \\cite{br11} gave a dataset where the\nk-means++ seeding algorithm achieves an approximation ratio of $(2/3 -\n\\epsilon)\\cdot \\log{k}$ only with probability that is exponentially small in\n$k$. However, this and all other known {\\em lower-bound examples}\n\\cite{av07,adk09} are high dimensional. So, an open problem is to understand\nthe behavior of the algorithm on low dimensional datasets. In this work, we\ngive a simple two dimensional dataset on which the seeding algorithm achieves\nan approximation ratio $c$ (for some universal constant $c$) only with\nprobability exponentially small in $k$. This is the first step towards solving\nopen problems posed by Mahajan et al \\cite{mnv12} and by Brunsch and R\\\"{o}glin\n\\cite{br11}.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 14:22:12 GMT"}], "update_date": "2013-06-19", "authors_parsed": [["Jaiswal", "Ragesh", ""], ["Jain", "Prachi", ""], ["Yadav", "Saumya", ""]]}, {"id": "1306.4287", "submitter": "Venkatesh Raman", "authors": "Moshe Lewenstein, J. Ian Munro and Venkatesh Raman", "title": "Succinct data structures for representing equivalence classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a partition of an n element set into equivalence classes, we consider\ntime-space tradeoffs for representing it to support the query that asks whether\ntwo given elements are in the same equivalence class. This has various\napplications including for testing whether two vertices are in the same\ncomponent in an undirected graph or in the same strongly connected component in\na directed graph.\n  We consider the problem in several models.\n  -- Concerning labeling schemes where we assign labels to elements and the\nquery is to be answered just by examining the labels of the queried elements\n(without any extra space): if each vertex is required to have a unique label,\nthen we show that a label space of (\\sum_{i=1}^n \\lfloor {n \\over i} \\rfloor)\nis necessary and sufficient. In other words, \\lg n + \\lg \\lg n + O(1) bits of\nspace are necessary and sufficient for representing each of the labels. This\nslightly strengthens the known lower bound and is in contrast to the known\nnecessary and sufficient bound of \\lceil \\lg n \\rceil for the label length, if\neach vertex need not get a unique label.\n  --Concerning succinct data structures for the problem when the n elements are\nto be uniquely assigned labels from label set {1, 2, ...n}, we first show that\n\\Theta(\\sqrt n) bits are necessary and sufficient to represent the equivalence\nclass information. This space includes the space for implicitly encoding the\nvertex labels. We can support the query in such a structure in O(\\lg n) time in\nthe standard word RAM model. We then develop structures resulting in one where\nthe queries can be supported in constant time using O({\\sqrt n} \\lg n) bits of\nspace. We also develop space efficient structures where union operation along\nwith the equivalence query can be answered fast.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 18:31:27 GMT"}], "update_date": "2013-06-19", "authors_parsed": [["Lewenstein", "Moshe", ""], ["Munro", "J. Ian", ""], ["Raman", "Venkatesh", ""]]}, {"id": "1306.4353", "submitter": "Ashok Rajaraman", "authors": "Cedric Chauve, Murray Patterson, Ashok Rajaraman", "title": "Hypergraph covering problems motivated by genome assembly questions", "comments": "13 pages+3 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Consecutive-Ones Property (C1P) is a classical concept in discrete\nmathematics that has been used in several genomics applications, from physical\nmapping of contemporary genomes to the assembly of ancient genomes. A common\nissue in genome assembly concerns repeats, genomic sequences that appear in\nseveral locations of a genome. Handling repeats leads to a variant of the C1P,\nthe C1P with multiplicity (mC1P), that can also be seen as the problem of\ncovering edges of hypergraphs by linear and circular walks. In the present\nwork, we describe variants of the mC1P that address specific issues of genome\nassembly, and polynomial time or fixed-parameter algorithms to solve them.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 21:01:08 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2013 19:23:01 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Chauve", "Cedric", ""], ["Patterson", "Murray", ""], ["Rajaraman", "Ashok", ""]]}, {"id": "1306.4384", "submitter": "Anand Louis", "authors": "Anand Louis, Konstantin Makarychev", "title": "Approximation Algorithm for Sparsest k-Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G$, the sparsest-cut problem asks to find the set of vertices\n$S$ which has the least expansion defined as $$\\phi_G(S) :=\n\\frac{w(E(S,\\bar{S}))}{\\min \\set{w(S), w(\\bar{S})}}, $$ where $w$ is the total\nedge weight of a subset. Here we study the natural generalization of this\nproblem: given an integer $k$, compute a $k$-partition $\\set{P_1, \\ldots, P_k}$\nof the vertex set so as to minimize $$ \\phi_k(\\set{P_1, \\ldots, P_k}) := \\max_i\n\\phi_G(P_i). $$ Our main result is a polynomial time bi-criteria approximation\nalgorithm which outputs a $(1 - \\e)k$-partition of the vertex set such that\neach piece has expansion at most $O_{\\varepsilon}(\\sqrt{\\log n \\log k})$ times\n$OPT$. We also study balanced versions of this problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 23:00:35 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2013 01:38:18 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Louis", "Anand", ""], ["Makarychev", "Konstantin", ""]]}, {"id": "1306.4521", "submitter": "Deepak Ajwani", "authors": "Deepak Ajwani and Nodari Sitchinava", "title": "Empirical Evaluation of the Parallel Distribution Sweeping Framework on\n  Multicore Architectures", "comments": "Longer version of ESA'13 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we perform an empirical evaluation of the Parallel External\nMemory (PEM) model in the context of geometric problems. In particular, we\nimplement the parallel distribution sweeping framework of Ajwani, Sitchinava\nand Zeh to solve batched 1-dimensional stabbing max problem. While modern\nprocessors consist of sophisticated memory systems (multiple levels of caches,\nset associativity, TLB, prefetching), we empirically show that algorithms\ndesigned in simple models, that focus on minimizing the I/O transfers between\nshared memory and single level cache, can lead to efficient software on current\nmulticore architectures. Our implementation exhibits significantly fewer\naccesses to slow DRAM and, therefore, outperforms traditional approaches based\non plane sweep and two-way divide and conquer.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 12:41:37 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Ajwani", "Deepak", ""], ["Sitchinava", "Nodari", ""]]}, {"id": "1306.4627", "submitter": "Tirtharaj Dash", "authors": "Tirtharaj Dash and Tanistha Nayak", "title": "Parallel Algorithm for Longest Common Subsequence in a String", "comments": "appeared in: Proceedings of National Conference on Artificial\n  Intelligence, Robotics and Embedded Systems (AIRES) - 2012, Andhra\n  University, Visakhapatnam (29-30 June, 2012), pp. 66-69", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the area of Pattern Recognition and Matching, finding a Longest Common\nSubsequence plays an important role. In this paper, we have proposed one\nalgorithm based on parallel computation. We have used OpenMP API package as\nmiddleware to send the data to different processors. We have tested our\nalgorithm in a system having four processors and 2 GB physical memory. The best\nresult showed that the parallel algorithm increases the performance (speed of\ncomputation) by 3.22.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 17:45:32 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Dash", "Tirtharaj", ""], ["Nayak", "Tanistha", ""]]}, {"id": "1306.4664", "submitter": "Michael Huber", "authors": "Michael Huber", "title": "Efficient Two-Stage Group Testing Algorithms for Genetic Screening", "comments": "14 pages; to appear in \"Algorithmica\". Part of this work has been\n  presented at the ICALP 2011 Group Testing Workshop; arXiv:1106.3680", "journal-ref": null, "doi": "10.1007/s00453-013-9791-2", "report-no": null, "categories": "cs.DS math.CO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient two-stage group testing algorithms that are particularly suited for\nrapid and less-expensive DNA library screening and other large scale biological\ngroup testing efforts are investigated in this paper. The main focus is on\nnovel combinatorial constructions in order to minimize the number of individual\ntests at the second stage of a two-stage disjunctive testing procedure.\nBuilding on recent work by Levenshtein (2003) and Tonchev (2008), several new\ninfinite classes of such combinatorial designs are presented.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 19:51:05 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Huber", "Michael", ""]]}, {"id": "1306.4919", "submitter": "Kevin Buchin", "authors": "Sander P. A. Alewijnse, Quirijn W. Bouts, Alex P. ten Brink, Kevin\n  Buchin", "title": "Computing the Greedy Spanner in Linear Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The greedy spanner is a high-quality spanner: its total weight, edge count\nand maximal degree are asymptotically optimal and in practice significantly\nbetter than for any other spanner with reasonable construction time.\nUnfortunately, all known algorithms that compute the greedy spanner of n points\nuse Omega(n^2) space, which is impractical on large instances. To the best of\nour knowledge, the largest instance for which the greedy spanner was computed\nso far has about 13,000 vertices.\n  We present a O(n)-space algorithm that computes the same spanner for points\nin R^d running in O(n^2 log^2 n) time for any fixed stretch factor and\ndimension. We discuss and evaluate a number of optimizations to its running\ntime, which allowed us to compute the greedy spanner on a graph with a million\nvertices. To our knowledge, this is also the first algorithm for the greedy\nspanner with a near-quadratic running time guarantee that has actually been\nimplemented.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 15:51:45 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Alewijnse", "Sander P. A.", ""], ["Bouts", "Quirijn W.", ""], ["Brink", "Alex P. ten", ""], ["Buchin", "Kevin", ""]]}, {"id": "1306.5003", "submitter": "Shai Vardi", "authors": "Yishay Mansour and Shai Vardi", "title": "A Local Computation Approximation Scheme to Maximum Matching", "comments": "Appears in Approx 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a polylogarithmic local computation matching algorithm which\nguarantees a $(1-\\eps)$-approximation to the maximum matching in graphs of\nbounded degree.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 21:31:14 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Mansour", "Yishay", ""], ["Vardi", "Shai", ""]]}, {"id": "1306.5029", "submitter": "Yakov Nekrich", "authors": "Yakov Nekrich and Jeffrey Scott Vitter", "title": "Optimal Color Range Reporting in One Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Color (or categorical) range reporting is a variant of the orthogonal range\nreporting problem in which every point in the input is assigned a \\emph{color}.\nWhile the answer to an orthogonal point reporting query contains all points in\nthe query range $Q$, the answer to a color reporting query contains only\ndistinct colors of points in $Q$. In this paper we describe an O(N)-space data\nstructure that answers one-dimensional color reporting queries in optimal\n$O(k+1)$ time, where $k$ is the number of colors in the answer and $N$ is the\nnumber of points in the data structure. Our result can be also dynamized and\nextended to the external memory model.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2013 01:35:36 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Nekrich", "Yakov", ""], ["Vitter", "Jeffrey Scott", ""]]}, {"id": "1306.5041", "submitter": "Hirotaka Ono", "authors": "Toshimasa Ishii, Hirotaka Ono, Yushi Uno", "title": "(Total) Vector Domination for Graphs with Bounded Branchwidth", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G=(V,E)$ of order $n$ and an $n$-dimensional non-negative\nvector $d=(d(1),d(2),\\ldots,d(n))$, called demand vector, the vector domination\n(resp., total vector domination) is the problem of finding a minimum\n$S\\subseteq V$ such that every vertex $v$ in $V\\setminus S$ (resp., in $V$) has\nat least $d(v)$ neighbors in $S$. The (total) vector domination is a\ngeneralization of many dominating set type problems, e.g., the dominating set\nproblem, the $k$-tuple dominating set problem (this $k$ is different from the\nsolution size), and so on, and its approximability and inapproximability have\nbeen studied under this general framework. In this paper, we show that a\n(total) vector domination of graphs with bounded branchwidth can be solved in\npolynomial time. This implies that the problem is polynomially solvable also\nfor graphs with bounded treewidth. Consequently, the (total) vector domination\nproblem for a planar graph is subexponential fixed-parameter tractable with\nrespectto $k$, where $k$ is the size of solution.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2013 03:46:54 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2013 05:57:49 GMT"}, {"version": "v3", "created": "Sat, 28 Sep 2013 03:36:20 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Ishii", "Toshimasa", ""], ["Ono", "Hirotaka", ""], ["Uno", "Yushi", ""]]}, {"id": "1306.5076", "submitter": "Volker Weichert", "authors": "Nodari Sitchinava, Volker Weichert", "title": "Bank Conflict Free Comparison-based Sorting On GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a framework for designing algorithms in shared\nmemory of GPUs without incurring memory bank conflicts. Using our framework we\ndevelop the first comparison-based shared memory sorting algorithm that incurs\nno bank conflicts. It can be used as a subroutine for GPU sorting algorithms to\nreplace current use of sorting networks in shared memory. Using our bank\nconflict free shared memory sorting subroutine as a black box, we design\nBCFMergesort, an algorithm for merging sorted streams of data that are larger\nthan shared memory. Our algorithm performs all accesses to global memory in\ncoalesced manner and incurs no bank conflicts during the merge.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2013 08:57:39 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2016 05:32:00 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Sitchinava", "Nodari", ""], ["Weichert", "Volker", ""]]}, {"id": "1306.5166", "submitter": "Peter Hegarty", "authors": "Peter Hegarty, Anders Martinsson, Dmitry Zhelezov", "title": "A variant of the multi-agent rendezvous problem", "comments": "18 pages, 3 figures. None of the authors has any previous experience\n  in this area of research (multi-agent systems), hence we welcome any feedback\n  from specialists", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CG cs.DS cs.RO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical multi-agent rendezvous problem asks for a deterministic\nalgorithm by which $n$ points scattered in a plane can move about at constant\nspeed and merge at a single point, assuming each point can use only the\nlocations of the others it sees when making decisions and that the visibility\ngraph as a whole is connected. In time complexity analyses of such algorithms,\nonly the number of rounds of computation required are usually considered, not\nthe amount of computation done per round. In this paper, we consider\n$\\Omega(n^2 \\log n)$ points distributed independently and uniformly at random\nin a disc of radius $n$ and, assuming each point can not only see but also, in\nprinciple, communicate with others within unit distance, seek a randomised\nmerging algorithm which asymptotically almost surely (a.a.s.) runs in time\nO(n), in other words in time linear in the radius of the disc rather than in\nthe number of points. Under a precise set of assumptions concerning the\ncommunication capabilities of neighboring points, we describe an algorithm\nwhich a.a.s. runs in time O(n) provided the number of points is $o(n^3)$.\nSeveral questions are posed for future work.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2013 15:15:22 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Hegarty", "Peter", ""], ["Martinsson", "Anders", ""], ["Zhelezov", "Dmitry", ""]]}, {"id": "1306.5391", "submitter": "Anna Harutyunyan", "authors": "Glencora Borradaile and Anna Harutyunyan", "title": "Boundary-to-boundary flows in planar graphs", "comments": "In Proc. IWOCA, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an iterative algorithm for finding the maximum flow between a set of\nsources and sinks that lie on the boundary of a planar graph. Our algorithm\nuses only O(n) queries to simple data structures, achieving an O(n log n)\nrunning time that we expect to be practical given the use of simple primitives.\nThe only existing algorithm for this problem uses divide and conquer and, in\norder to achieve an O(n log n) running time, requires the use of the\n(complicated) linear-time shortest-paths algorithm for planar graphs.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2013 09:45:51 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Borradaile", "Glencora", ""], ["Harutyunyan", "Anna", ""]]}, {"id": "1306.5434", "submitter": "Manor Mendel", "authors": "Manor Mendel and Assaf Naor", "title": "Expanders with respect to Hadamard spaces and random graphs", "comments": "incorporated Referees' comments", "journal-ref": "Duke Math. J. 164, no. 8 (2015), 1471-1548", "doi": "10.1215/00127094-3119525", "report-no": null, "categories": "math.MG cs.DS math.CO math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that there exists a sequence of 3-regular graphs\n$\\{G_n\\}_{n=1}^\\infty$ and a Hadamard space $X$ such that\n$\\{G_n\\}_{n=1}^\\infty$ forms an expander sequence with respect to $X$, yet\nrandom regular graphs are not expanders with respect to $X$. This answers a\nquestion of \\cite{NS11}. $\\{G_n\\}_{n=1}^\\infty$ are also shown to be expanders\nwith respect to random regular graphs, yielding a deterministic sublinear time\nconstant factor approximation algorithm for computing the average squared\ndistance in subsets of a random graph. The proof uses the Euclidean cone over a\nrandom graph, an auxiliary continuous geometric object that allows for the\nimplementation of martingale methods.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2013 16:29:21 GMT"}, {"version": "v2", "created": "Fri, 18 Jul 2014 06:03:25 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Mendel", "Manor", ""], ["Naor", "Assaf", ""]]}, {"id": "1306.5571", "submitter": "Robert Ganian", "authors": "Robert Ganian, Jan Obdr\\v{z}\\'alek", "title": "Expanding the expressive power of Monadic Second-Order logic on\n  restricted graph classes", "comments": "Accepted for IWOCA 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine integer linear programming and recent advances in Monadic\nSecond-Order model checking to obtain two new algorithmic meta-theorems for\ngraphs of bounded vertex-cover. The first shows that cardMSO1, an extension of\nthe well-known Monadic Second-Order logic by the addition of cardinality\nconstraints, can be solved in FPT time parameterized by vertex cover. The\nsecond meta-theorem shows that the MSO partitioning problems introduced by Rao\ncan also be solved in FPT time with the same parameter. The significance of our\ncontribution stems from the fact that these formalisms can describe problems\nwhich are W[1]-hard and even NP-hard on graphs of bounded tree-width.\nAdditionally, our algorithms have only an elementary dependence on the\nparameter and formula. We also show that both results are easily extended from\nvertex cover to neighborhood diversity.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 10:53:00 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Ganian", "Robert", ""], ["Obdr\u017e\u00e1lek", "Jan", ""]]}, {"id": "1306.5720", "submitter": "Lev Reyzin", "authors": "Shelby Heinecke and Will Perkins and Lev Reyzin", "title": "On the Resilience of Bipartite Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by problems modeling the spread of infections in networks, in this\npaper we explore which bipartite graphs are most resilient to widespread\ninfections under various parameter settings. Namely, we study bipartite\nnetworks with a requirement of a minimum degree $d$ on one side under an\nindependent infection, independent transmission model. We completely\ncharacterize the optimal graphs in the case $d=1$, which already produces\nnon-trivial behavior, and we give extremal results for the more general cases.\nWe show that in the case $d=2$, surprisingly, the optimally resilient set of\ngraphs includes a graph that is not one of the two \"extremes\" found in the case\n$d=1$.\n  Then, we briefly examine the case where we force a connectivity requirement\ninstead of a one-sided degree requirement and again, we find that the set of\nthe most resilient graphs contains more than the two \"extremes.\" We also show\nthat determining the subgraph of an arbitrary bipartite graph most resilient to\ninfection is NP-hard for any one-sided minimal degree $d \\ge 1$.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 19:37:45 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 19:35:10 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Heinecke", "Shelby", ""], ["Perkins", "Will", ""], ["Reyzin", "Lev", ""]]}, {"id": "1306.5815", "submitter": "Tong-Wook Shinn", "authors": "Tong-Wook Shinn, Tadao Takaoka", "title": "Some Extensions of the All Pairs Bottleneck Paths Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the well known bottleneck paths problem in two directions for\ndirected unweighted (unit edge cost) graphs with positive real edge capacities.\nFirstly we narrow the problem domain and compute the bottleneck of the entire\nnetwork in $O(n^{\\omega}\\log{n})$ time, where $O(n^{\\omega})$ is the time taken\nto multiply two $n$-by-$n$ matrices over ring. Secondly we enlarge the domain\nand compute the shortest paths for all possible flow amounts. We present a\ncombinatorial algorithm to solve the Single Source Shortest Paths for All Flows\n(SSSP-AF) problem in $O(mn)$ worst case time, followed by an algorithm to solve\nthe All Pairs Shortest Paths for All Flows (APSP-AF) problem in\n$O(\\sqrt{d}n^{(\\omega+9)/4})$ time, where $d$ is the number of distinct edge\ncapacities. We also discuss real life applications for these new problems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 00:01:07 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Shinn", "Tong-Wook", ""], ["Takaoka", "Tadao", ""]]}, {"id": "1306.5825", "submitter": "Ying Xiao", "authors": "Navin Goyal, Santosh Vempala and Ying Xiao", "title": "Fourier PCA and Robust Tensor Decomposition", "comments": "Extensively revised; details added; minor errors corrected;\n  exposition improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fourier PCA is Principal Component Analysis of a matrix obtained from higher\norder derivatives of the logarithm of the Fourier transform of a\ndistribution.We make this method algorithmic by developing a tensor\ndecomposition method for a pair of tensors sharing the same vectors in rank-$1$\ndecompositions. Our main application is the first provably polynomial-time\nalgorithm for underdetermined ICA, i.e., learning an $n \\times m$ matrix $A$\nfrom observations $y=Ax$ where $x$ is drawn from an unknown product\ndistribution with arbitrary non-Gaussian components. The number of component\ndistributions $m$ can be arbitrarily higher than the dimension $n$ and the\ncolumns of $A$ only need to satisfy a natural and efficiently verifiable\nnondegeneracy condition. As a second application, we give an alternative\nalgorithm for learning mixtures of spherical Gaussians with linearly\nindependent means. These results also hold in the presence of Gaussian noise.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 01:44:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2013 05:58:50 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2013 00:58:34 GMT"}, {"version": "v4", "created": "Fri, 30 May 2014 04:39:23 GMT"}, {"version": "v5", "created": "Fri, 27 Jun 2014 20:37:17 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Goyal", "Navin", ""], ["Vempala", "Santosh", ""], ["Xiao", "Ying", ""]]}, {"id": "1306.5829", "submitter": "Ben Cousins", "authors": "Ben Cousins and Santosh Vempala", "title": "A Cubic Algorithm for Computing Gaussian Volume", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.FA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present randomized algorithms for sampling the standard Gaussian\ndistribution restricted to a convex set and for estimating the Gaussian measure\nof a convex set, in the general membership oracle model. The complexity of\nintegration is $O^*(n^3)$ while the complexity of sampling is $O^*(n^3)$ for\nthe first sample and $O^*(n^2)$ for every subsequent sample. These bounds\nimprove on the corresponding state-of-the-art by a factor of $n$. Our\nimprovement comes from several aspects: better isoperimetry, smoother\nannealing, avoiding transformation to isotropic position and the use of the\n\"speedy walk\" in the analysis.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 02:04:58 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2013 05:35:52 GMT"}], "update_date": "2013-07-12", "authors_parsed": [["Cousins", "Ben", ""], ["Vempala", "Santosh", ""]]}, {"id": "1306.6193", "submitter": "Vasanth Sena pesari", "authors": "P. Vasanth Sena", "title": "An Optimal Heuristic for Sum of All Prime Numbers Logic for Large Inputs\n  using RAPTOR", "comments": "7 pages, 7 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An optimal heuristic logic is an effective method for finding the sum of all\nprime numbers up to a given number. This paper presents different approaches,\nnamely, general method and optimal method which facilitate to compare the\nresults and draw the optimal solution. The method adopted is to know the number\nof symbols evaluated in each logic, construct better approaches based on\nheuristics, proposals and implementations of human sequential development using\nRapid algorithmic prototyping tool for ordered reasoning (RAPTOR). In\ntraditional approach, task is complex in point of time and space; however, this\nmethod reduces these prime factors by applying simple mathematical theorems and\nheuristics. This model effectively works with large numeric inputs. It has been\ntested on RAPTOR with flow charts, results indicates that algorithms are fast,\neffective and scalable.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2013 10:18:48 GMT"}], "update_date": "2013-06-27", "authors_parsed": [["Sena", "P. Vasanth", ""]]}, {"id": "1306.6295", "submitter": "Yihong Wu", "authors": "Alexandr Andoni and Huy L. Nguyen and Yury Polyanskiy and Yihong Wu", "title": "Tight Lower Bound for Linear Sketches of Moments", "comments": "In Proceedings of the 40th International Colloquium on Automata,\n  Languages and Programming (ICALP), Riga, Latvia, July 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating frequency moments of a data stream has attracted a\nlot of attention since the onset of streaming algorithms [AMS99]. While the\nspace complexity for approximately computing the $p^{\\rm th}$ moment, for\n$p\\in(0,2]$ has been settled [KNW10], for $p>2$ the exact complexity remains\nopen. For $p>2$ the current best algorithm uses $O(n^{1-2/p}\\log n)$ words of\nspace [AKO11,BO10], whereas the lower bound is of $\\Omega(n^{1-2/p})$ [BJKS04].\n  In this paper, we show a tight lower bound of $\\Omega(n^{1-2/p}\\log n)$ words\nfor the class of algorithms based on linear sketches, which store only a sketch\n$Ax$ of input vector $x$ and some (possibly randomized) matrix $A$. We note\nthat all known algorithms for this problem are linear sketches.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2013 17:19:54 GMT"}], "update_date": "2013-06-27", "authors_parsed": [["Andoni", "Alexandr", ""], ["Nguyen", "Huy L.", ""], ["Polyanskiy", "Yury", ""], ["Wu", "Yihong", ""]]}, {"id": "1306.6593", "submitter": "Marcin Pilipczuk", "authors": "Marcin Pilipczuk, Micha{\\l} Pilipczuk, Piotr Sankowski and Erik Jan\n  van Leeuwen", "title": "Network Sparsification for Steiner Problems on Planar and Bounded-Genus\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose polynomial-time algorithms that sparsify planar and bounded-genus\ngraphs while preserving optimal or near-optimal solutions to Steiner problems.\nOur main contribution is a polynomial-time algorithm that, given an unweighted\ngraph $G$ embedded on a surface of genus $g$ and a designated face $f$ bounded\nby a simple cycle of length $k$, uncovers a set $F \\subseteq E(G)$ of size\npolynomial in $g$ and $k$ that contains an optimal Steiner tree for any set of\nterminals that is a subset of the vertices of $f$.\n  We apply this general theorem to prove that: * given an unweighted graph $G$\nembedded on a surface of genus $g$ and a terminal set $S \\subseteq V(G)$, one\ncan in polynomial time find a set $F \\subseteq E(G)$ that contains an optimal\nSteiner tree $T$ for $S$ and that has size polynomial in $g$ and $|E(T)|$; * an\nanalogous result holds for an optimal Steiner forest for a set $S$ of terminal\npairs; * given an unweighted planar graph $G$ and a terminal set $S \\subseteq\nV(G)$, one can in polynomial time find a set $F \\subseteq E(G)$ that contains\nan optimal (edge) multiway cut $C$ separating $S$ and that has size polynomial\nin $|C|$.\n  In the language of parameterized complexity, these results imply the first\npolynomial kernels for Steiner Tree and Steiner Forest on planar and\nbounded-genus graphs (parameterized by the size of the tree and forest,\nrespectively) and for (Edge) Multiway Cut on planar graphs (parameterized by\nthe size of the cutset). Additionally, we obtain a weighted variant of our main\ncontribution.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2013 18:19:19 GMT"}, {"version": "v2", "created": "Thu, 3 Apr 2014 09:46:08 GMT"}, {"version": "v3", "created": "Fri, 24 Jun 2016 10:28:52 GMT"}, {"version": "v4", "created": "Tue, 11 Jul 2017 07:58:08 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""], ["Sankowski", "Piotr", ""], ["van Leeuwen", "Erik Jan", ""]]}, {"id": "1306.6710", "submitter": "Trent Rogers", "authors": "Erik D. Demaine, Matthew J. Patitz, Trent A. Rogers, Robert T.\n  Schweller, Scott M. Summers, and Damien Woods", "title": "The two-handed tile assembly model is not intrinsically universal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-studied Two-Handed Tile Assembly Model (2HAM) is a model of tile\nassembly in which pairs of large assemblies can bind, or self-assemble,\ntogether. In order to bind, two assemblies must have matching glues that can\nsimultaneously touch each other, and stick together with strength that is at\nleast the temperature $\\tau$, where $\\tau$ is some fixed positive integer. We\nask whether the 2HAM is intrinsically universal, in other words we ask: is\nthere a single universal 2HAM tile set $U$ which can be used to simulate any\ninstance of the model? Our main result is a negative answer to this question.\nWe show that for all $\\tau' < \\tau$, each temperature-$\\tau'$ 2HAM tile system\ndoes not simulate at least one temperature-$\\tau$ 2HAM tile system. This\nimpossibility result proves that the 2HAM is not intrinsically universal, in\nstark contrast to the simpler (single-tile addition only) abstract Tile\nAssembly Model which is intrinsically universal (\"The tile assembly model is\nintrinsically universal\", FOCS 2012). However, on the positive side, we prove\nthat, for every fixed temperature $\\tau \\geq 2$, temperature-$\\tau$ 2HAM tile\nsystems are indeed intrinsically universal: in other words, for each $\\tau$\nthere is a single universal 2HAM tile set $U$ that, when appropriately\ninitialized, is capable of simulating the behavior of any temperature-$\\tau$\n2HAM tile system. As a corollary of these results we find an infinite set of\ninfinite hierarchies of 2HAM systems with strictly increasing simulation power\nwithin each hierarchy. Finally, we show that for each $\\tau$, there is a\ntemperature-$\\tau$ 2HAM system that simultaneously simulates all\ntemperature-$\\tau$ 2HAM systems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 04:06:31 GMT"}, {"version": "v2", "created": "Wed, 20 Aug 2014 20:46:09 GMT"}], "update_date": "2014-08-22", "authors_parsed": [["Demaine", "Erik D.", ""], ["Patitz", "Matthew J.", ""], ["Rogers", "Trent A.", ""], ["Schweller", "Robert T.", ""], ["Summers", "Scott M.", ""], ["Woods", "Damien", ""]]}, {"id": "1306.6728", "submitter": "Yahav Nussbaum", "authors": "Haim Kaplan and Yahav Nussbaum", "title": "Min-Cost Flow Duality in Planar Networks", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the min-cost flow problem in planar networks. We start\nwith the min-cost flow problem and apply two transformations, one is based on\ngeometric duality of planar graphs and the other on linear programming duality.\nThe result is a min-cost flow problem in a related planar network whose balance\nconstraints are defined by the costs of the original problem and whose costs\nare defined by the capacities of the original problem. We use this\ntransformation to show an O(n log^2 n) time algorithm for the min-cost flow\nproblem in an n-vertex outerplanar network.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 06:36:55 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Kaplan", "Haim", ""], ["Nussbaum", "Yahav", ""]]}, {"id": "1306.6943", "submitter": "Rishi Saket", "authors": "Rishi Saket", "title": "A PTAS for the Classical Ising Spin Glass Problem on the Chimera Graph\n  Structure", "comments": "6 pages, corrected PTAS running time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a polynomial time approximation scheme (PTAS) for the minimum\nvalue of the classical Ising Hamiltonian with linear terms on the Chimera graph\nstructure as defined in the recent work of McGeoch and Wang. The result follows\nfrom a direct application of the techniques used by Bansal, Bravyi and Terhal\nwho gave a PTAS for the same problem on planar and, in particular, grid graphs.\nWe also show that on Chimera graphs, the trivial lower bound is within a\nconstant factor of the optimum.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 20:00:25 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2013 14:12:45 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Saket", "Rishi", ""]]}]