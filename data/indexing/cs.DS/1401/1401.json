[{"id": "1401.0042", "submitter": "Grigory Yaroslavtsev", "authors": "Alexandr Andoni, Aleksandar Nikolov, Krzysztof Onak, Grigory\n  Yaroslavtsev", "title": "Parallel Algorithms for Geometric Graph Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give algorithms for geometric graph problems in the modern parallel models\ninspired by MapReduce. For example, for the Minimum Spanning Tree (MST) problem\nover a set of points in the two-dimensional space, our algorithm computes a\n$(1+\\epsilon)$-approximate MST. Our algorithms work in a constant number of\nrounds of communication, while using total space and communication proportional\nto the size of the data (linear space and near linear time algorithms). In\ncontrast, for general graphs, achieving the same result for MST (or even\nconnectivity) remains a challenging open problem, despite drawing significant\nattention in recent years.\n  We develop a general algorithmic framework that, besides MST, also applies to\nEarth-Mover Distance (EMD) and the transportation cost problem. Our algorithmic\nframework has implications beyond the MapReduce model. For example it yields a\nnew algorithm for computing EMD cost in the plane in near-linear time,\n$n^{1+o_\\epsilon(1)}$. We note that while recently Sharathkumar and Agarwal\ndeveloped a near-linear time algorithm for $(1+\\epsilon)$-approximating EMD,\nour algorithm is fundamentally different, and, for example, also solves the\ntransportation (cost) problem, raised as an open question in their work.\nFurthermore, our algorithm immediately gives a $(1+\\epsilon)$-approximation\nalgorithm with $n^{\\delta}$ space in the streaming-with-sorting model with\n$1/\\delta^{O(1)}$ passes. As such, it is tempting to conjecture that the\nparallel models may also constitute a concrete playground in the quest for\nefficient algorithms for EMD (and other similar problems) in the vanilla\nstreaming model, a well-known open problem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 22:34:56 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2014 05:57:47 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Andoni", "Alexandr", ""], ["Nikolov", "Aleksandar", ""], ["Onak", "Krzysztof", ""], ["Yaroslavtsev", "Grigory", ""]]}, {"id": "1401.0085", "submitter": "Yin Tat Lee", "authors": "Yin Tat Lee", "title": "Probabilistic Spectral Sparsification In Sublinear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a variant of spectral sparsification, called\nprobabilistic $(\\varepsilon,\\delta)$-spectral sparsification. Roughly speaking,\nit preserves the cut value of any cut $(S,S^{c})$ with an $1\\pm\\varepsilon$\nmultiplicative error and a $\\delta\\left|S\\right|$ additive error. We show how\nto produce a probabilistic $(\\varepsilon,\\delta)$-spectral sparsifier with\n$O(n\\log n/\\varepsilon^{2})$ edges in time $\\tilde{O}(n/\\varepsilon^{2}\\delta)$\ntime for unweighted undirected graph. This gives fastest known sub-linear time\nalgorithms for different cut problems on unweighted undirected graph such as\n  - An $\\tilde{O}(n/OPT+n^{3/2+t})$ time $O(\\sqrt{\\log n/t})$-approximation\nalgorithm for the sparsest cut problem and the balanced separator problem.\n  - A $n^{1+o(1)}/\\varepsilon^{4}$ time approximation minimum s-t cut algorithm\nwith an $\\varepsilon n$ additive error.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 03:58:45 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Lee", "Yin Tat", ""]]}, {"id": "1401.0119", "submitter": "Oshri Naparstek", "authors": "Oshri Naparstek and Amir Leshem", "title": "Expected time complexity of the auction algorithm and the push relabel\n  algorithm for maximal bipartite matching on random graphs", "comments": null, "journal-ref": "Random Structures and Algorithms, volume 48 pages 384-395, 2016", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the expected time complexity of the auction\nalgorithm for the matching problem on random bipartite graphs. We prove that\nthe expected time complexity of the auction algorithm for bipartite matching is\n$O\\left(\\frac{N\\log^2(N)}{\\log\\left(Np\\right)}\\right)$ on sequential machines.\nThis is equivalent to other augmenting path algorithms such as the HK\nalgorithm. Furthermore, we show that the algorithm can be implemented on\nparallel machines with $O(\\log(N))$ processors and shared memory with an\nexpected time complexity of $O(N\\log(N))$.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 09:41:59 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Naparstek", "Oshri", ""], ["Leshem", "Amir", ""]]}, {"id": "1401.0163", "submitter": "Jakub Radoszewski", "authors": "Tomasz Kociumaka, Jakub Radoszewski, Wojciech Rytter, Solon P. Pissis,\n  Tomasz Wale\\'n", "title": "Fast Algorithm for Partial Covers in Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A factor $u$ of a word $w$ is a cover of $w$ if every position in $w$ lies\nwithin some occurrence of $u$ in $w$. A word $w$ covered by $u$ thus\ngeneralizes the idea of a repetition, that is, a word composed of exact\nconcatenations of $u$. In this article we introduce a new notion of\n$\\alpha$-partial cover, which can be viewed as a relaxed variant of cover, that\nis, a factor covering at least $\\alpha$ positions in $w$. We develop a data\nstructure of $O(n)$ size (where $n=|w|$) that can be constructed in $O(n\\log\nn)$ time which we apply to compute all shortest $\\alpha$-partial covers for a\ngiven $\\alpha$. We also employ it for an $O(n\\log n)$-time algorithm computing\na shortest $\\alpha$-partial cover for each $\\alpha=1,2,\\ldots,n$.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 15:56:30 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Kociumaka", "Tomasz", ""], ["Radoszewski", "Jakub", ""], ["Rytter", "Wojciech", ""], ["Pissis", "Solon P.", ""], ["Wale\u0144", "Tomasz", ""]]}, {"id": "1401.0201", "submitter": "Ping Li", "authors": "Ping Li, Cun-Hui Zhang, Tong Zhang", "title": "Sparse Recovery with Very Sparse Compressed Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (sparse signal recovery) often encounters nonnegative data\n(e.g., images). Recently we developed the methodology of using (dense)\nCompressed Counting for recovering nonnegative K-sparse signals. In this paper,\nwe adopt very sparse Compressed Counting for nonnegative signal recovery. Our\ndesign matrix is sampled from a maximally-skewed p-stable distribution (0<p<1),\nand we sparsify the design matrix so that on average (1-g)-fraction of the\nentries become zero. The idea is related to very sparse stable random\nprojections (Li et al 2006 and Li 2007), the prior work for estimating summary\nstatistics of the data.\n  In our theoretical analysis, we show that, when p->0, it suffices to use M=\nK/(1-exp(-gK) log N measurements, so that all coordinates can be recovered in\none scan of the coordinates. If g = 1 (i.e., dense design), then M = K log N.\nIf g= 1/K or 2/K (i.e., very sparse design), then M = 1.58K log N or M = 1.16K\nlog N. This means the design matrix can be indeed very sparse at only a minor\ninflation of the sample complexity.\n  Interestingly, as p->1, the required number of measurements is essentially M\n= 2.7K log N, provided g= 1/K. It turns out that this result is a general\nworst-case bound.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 18:17:09 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Li", "Ping", ""], ["Zhang", "Cun-Hui", ""], ["Zhang", "Tong", ""]]}, {"id": "1401.0224", "submitter": "Nathan Lindzey", "authors": "Nathan Lindzey and Ross M. McConnell", "title": "Linear-Time Algorithms for Finding Tucker Submatrices and\n  Lekkerkerker-Boland Subgraphs", "comments": "A preliminary version of this work appeared in WG13: 39th\n  International Workshop on Graph-Theoretic Concepts in Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lekkerkerker and Boland characterized the minimal forbidden induced subgraphs\nfor the class of interval graphs. We give a linear-time algorithm to find one\nin any graph that is not an interval graph. Tucker characterized the minimal\nforbidden submatrices of binary matrices that do not have the consecutive-ones\nproperty. We give a linear-time algorithm to find one in any binary matrix that\ndoes not have the consecutive-ones property.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 21:56:04 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Lindzey", "Nathan", ""], ["McConnell", "Ross M.", ""]]}, {"id": "1401.0247", "submitter": "Yingyu Liang", "authors": "Maria-Florina Balcan, Yingyu Liang, Pramod Gupta", "title": "Robust Hierarchical Clustering", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most widely used techniques for data clustering is agglomerative\nclustering. Such algorithms have been long used across many different fields\nranging from computational biology to social sciences to computer vision in\npart because their output is easy to interpret. Unfortunately, it is well\nknown, however, that many of the classic agglomerative clustering algorithms\nare not robust to noise. In this paper we propose and analyze a new robust\nalgorithm for bottom-up agglomerative clustering. We show that our algorithm\ncan be used to cluster accurately in cases where the data satisfies a number of\nnatural properties and where the traditional agglomerative algorithms fail. We\nalso show how to adapt our algorithm to the inductive setting where our given\ndata is only a small random sample of the entire data set. Experimental\nevaluations on synthetic and real world data sets show that our algorithm\nachieves better performance than other hierarchical algorithms in the presence\nof noise.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2014 04:16:21 GMT"}, {"version": "v2", "created": "Sun, 13 Jul 2014 01:51:05 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Liang", "Yingyu", ""], ["Gupta", "Pramod", ""]]}, {"id": "1401.0379", "submitter": "Pierre Lescanne", "authors": "Katarzyna Grygiel, Pierre Lescanne (LIP)", "title": "Counting Terms in the Binary Lambda Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a paper entitled Binary lambda calculus and combinatory logic, John Tromp\npresents a simple way of encoding lambda calculus terms as binary sequences. In\nwhat follows, we study the numbers of binary strings of a given size that\nrepresent lambda terms and derive results from their generating functions,\nespecially that the number of terms of size n grows roughly like 1.963447954^n.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 07:43:54 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Grygiel", "Katarzyna", "", "LIP"], ["Lescanne", "Pierre", "", "LIP"]]}, {"id": "1401.0396", "submitter": "Marek Piotr\\'ow", "authors": "Marek Piotr\\'ow", "title": "Faster 3-Periodic Merging Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of merging two sorted sequences on a comparator\nnetwork that is used repeatedly, that is, if the output is not sorted, the\nnetwork is applied again using the output as input. The challenging task is to\nconstruct such networks of small depth. The first constructions of merging\nnetworks with a constant period were given by Kuty{\\l}owski, Lory\\'s and\nOesterdikhoff. They have given $3$-periodic network that merges two sorted\nsequences of $N$ numbers in time $12\\log N$ and a similar network of period $4$\nthat works in $5.67\\log N$. We present a new family of such networks that are\nbased on Canfield and Williamson periodic sorter. Our $3$-periodic merging\nnetworks work in time upper-bounded by $6\\log N$. The construction can be\neasily generalized to larger constant periods with decreasing running time, for\nexample, to $4$-periodic ones that work in time upper-bounded by $4\\log N$.\nMoreover, to obtain the facts we have introduced a new proof technique.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 09:24:17 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Piotr\u00f3w", "Marek", ""]]}, {"id": "1401.0417", "submitter": "Christos Boutsidis", "authors": "Christos Boutsidis, Malik Magdon-Ismail", "title": "Faster SVD-Truncated Least-Squares Regression", "comments": "2014 IEEE International Symposium on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a fast algorithm for computing the \"SVD-truncated\" regularized\nsolution to the least-squares problem: $ \\min_{\\x} \\TNorm{\\matA \\x - \\b}. $ Let\n$\\matA_k$ of rank $k$ be the best rank $k$ matrix computed via the SVD of\n$\\matA$. Then, the SVD-truncated regularized solution is: $ \\x_k =\n\\pinv{\\matA}_k \\b. $ If $\\matA$ is $m \\times n$, then, it takes $O(m n\n\\min\\{m,n\\})$ time to compute $\\x_k $ using the SVD of \\math{\\matA}. We give an\napproximation algorithm for \\math{\\x_k} which constructs a rank-\\math{k}\napproximation $\\tilde{\\matA}_{k}$ and computes $ \\tilde{\\x}_{k} =\n\\pinv{\\tilde\\matA}_{k} \\b$ in roughly $O(\\nnz(\\matA) k \\log n)$ time. Our\nalgorithm uses a randomized variant of the subspace iteration. We show that,\nwith high probability: $ \\TNorm{\\matA \\tilde{\\x}_{k} - \\b} \\approx \\TNorm{\\matA\n\\x_k - \\b}$ and $\\TNorm{\\x_k - \\tilde\\x_k} \\approx 0. $\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 11:19:11 GMT"}, {"version": "v2", "created": "Wed, 28 May 2014 19:44:50 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Boutsidis", "Christos", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1401.0432", "submitter": "G Ramakrishna", "authors": "N.S. Narayanaswamy and G. Ramakrishna", "title": "On Minimum Average Stretch Spanning Trees in Polygonal 2-trees", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A spanning tree of an unweighted graph is a minimum average stretch spanning\ntree if it minimizes the ratio of sum of the distances in the tree between the\nend vertices of the graph edges and the number of graph edges. We consider the\nproblem of computing a minimum average stretch spanning tree in polygonal\n2-trees, a super class of 2-connected outerplanar graphs. For a polygonal\n2-tree on $n$ vertices, we present an algorithm to compute a minimum average\nstretch spanning tree in $O(n \\log n)$ time. This algorithm also finds a\nminimum fundamental cycle basis in polygonal 2-trees.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 13:31:13 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 07:37:46 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Narayanaswamy", "N. S.", ""], ["Ramakrishna", "G.", ""]]}, {"id": "1401.0579", "submitter": "Tengyu Ma", "authors": "Sanjeev Arora, Aditya Bhaskara, Rong Ge, Tengyu Ma", "title": "More Algorithms for Provable Dictionary Learning", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dictionary learning, also known as sparse coding, the algorithm is given\nsamples of the form $y = Ax$ where $x\\in \\mathbb{R}^m$ is an unknown random\nsparse vector and $A$ is an unknown dictionary matrix in $\\mathbb{R}^{n\\times\nm}$ (usually $m > n$, which is the overcomplete case). The goal is to learn $A$\nand $x$. This problem has been studied in neuroscience, machine learning,\nvisions, and image processing. In practice it is solved by heuristic algorithms\nand provable algorithms seemed hard to find. Recently, provable algorithms were\nfound that work if the unknown feature vector $x$ is $\\sqrt{n}$-sparse or even\nsparser. Spielman et al. \\cite{DBLP:journals/jmlr/SpielmanWW12} did this for\ndictionaries where $m=n$; Arora et al. \\cite{AGM} gave an algorithm for\novercomplete ($m >n$) and incoherent matrices $A$; and Agarwal et al.\n\\cite{DBLP:journals/corr/AgarwalAN13} handled a similar case but with weaker\nguarantees.\n  This raised the problem of designing provable algorithms that allow sparsity\n$\\gg \\sqrt{n}$ in the hidden vector $x$. The current paper designs algorithms\nthat allow sparsity up to $n/poly(\\log n)$. It works for a class of matrices\nwhere features are individually recoverable, a new notion identified in this\npaper that may motivate further work.\n  The algorithm runs in quasipolynomial time because they use limited\nenumeration.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 02:52:17 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Arora", "Sanjeev", ""], ["Bhaskara", "Aditya", ""], ["Ge", "Rong", ""], ["Ma", "Tengyu", ""]]}, {"id": "1401.0625", "submitter": "Yakov Nekrich", "authors": "Moshe Lewenstein, Yakov Nekrich, Jeffrey Scott Vitter", "title": "Space-Efficient String Indexing for Wildcard Pattern Matching", "comments": "15 pages, extended version of the STACS paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe compressed indexes that support pattern matching\nqueries for strings with wildcards. For a constant size alphabet our data\nstructure uses $O(n\\log^{\\varepsilon}n)$ bits for any $\\varepsilon>0$ and\nreports all $\\mathrm{occ}$ occurrences of a wildcard string in $O(m+\\sigma^g\n\\cdot\\mu(n) + \\mathrm{occ})$ time, where $\\mu(n)=o(\\log\\log\\log n)$, $\\sigma$\nis the alphabet size, $m$ is the number of alphabet symbols and $g$ is the\nnumber of wildcard symbols in the query string. We also present an $O(n)$-bit\nindex with $O((m+\\sigma^g+\\mathrm{occ})\\log^{\\varepsilon}n)$ query time and an\n$O(n(\\log\\log n)^2)$-bit index with $O((m+\\sigma^g+\\mathrm{occ})\\log\\log n)$\nquery time. These are the first non-trivial data structures for this problem\nthat need $o(n\\log n)$ bits of space.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 11:08:34 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Lewenstein", "Moshe", ""], ["Nekrich", "Yakov", ""], ["Vitter", "Jeffrey Scott", ""]]}, {"id": "1401.0699", "submitter": "Yury Makarychev", "authors": "Konstantin Makarychev and Yury Makarychev", "title": "Nonuniform Graph Partitioning with Unrelated Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a bi-criteria approximation algorithm for the Minimum Nonuniform\nPartitioning problem, recently introduced by Krauthgamer, Naor, Schwartz and\nTalwar (2014). In this problem, we are given a graph $G=(V,E)$ on $n$ vertices\nand $k$ numbers $\\rho_1,\\dots, \\rho_k$. The goal is to partition the graph into\n$k$ disjoint sets $P_1,\\dots, P_k$ satisfying $|P_i|\\leq \\rho_i n$ so as to\nminimize the number of edges cut by the partition. Our algorithm has an\napproximation ratio of $O(\\sqrt{\\log n \\log k})$ for general graphs, and an\n$O(1)$ approximation for graphs with excluded minors. This is an improvement\nupon the $O(\\log n)$ algorithm of Krauthgamer, Naor, Schwartz and Talwar\n(2014). Our approximation ratio matches the best known ratio for the Minimum\n(Uniform) $k$-Partitioning problem.\n  We extend our results to the case of \"unrelated weights\" and to the case of\n\"unrelated $d$-dimensional weights\". In the former case, different vertices may\nhave different weights and the weight of a vertex may depend on the set $P_i$\nthe vertex is assigned to. In the latter case, each vertex $u$ has a\n$d$-dimensional weight $r(u,i) = (r_1(u,i), \\dots, r_d(u,i))$ if $u$ is\nassigned to $P_i$. Each set $P_i$ has a $d$-dimensional capacity $c(i) =\n(c_1(i),\\dots, c_d(i))$. The goal is to find a partition such that $\\sum_{u\\in\n{P_i}} r(u,i) \\leq c(i)$ coordinate-wise.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 19:10:51 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2014 20:44:00 GMT"}, {"version": "v3", "created": "Mon, 28 Apr 2014 16:57:03 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Makarychev", "Konstantin", ""], ["Makarychev", "Yury", ""]]}, {"id": "1401.0702", "submitter": "Massimo Cafaro", "authors": "Massimo Cafaro, Marco Pulimeno and Piergiulio Tempesta", "title": "A Parallel Space Saving Algorithm For Frequent Items and the Hurwitz\n  zeta distribution", "comments": "Accepted for publication. To appear in Information Sciences,\n  Elsevier. http://www.sciencedirect.com/science/article/pii/S002002551500657X", "journal-ref": "Information Sciences, Elsevier, Volume 329, 2016, pp. 1 - 19,\n  ISSN: 0020-0255", "doi": "10.1016/j.ins.2015.09.003", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a message-passing based parallel version of the Space Saving\nalgorithm designed to solve the $k$--majority problem. The algorithm determines\nin parallel frequent items, i.e., those whose frequency is greater than a given\nthreshold, and is therefore useful for iceberg queries and many other different\ncontexts. We apply our algorithm to the detection of frequent items in both\nreal and synthetic datasets whose probability distribution functions are a\nHurwitz and a Zipf distribution respectively. Also, we compare its parallel\nperformances and accuracy against a parallel algorithm recently proposed for\nmerging summaries derived by the Space Saving or Frequent algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 19:34:14 GMT"}, {"version": "v10", "created": "Thu, 13 Aug 2015 07:59:35 GMT"}, {"version": "v11", "created": "Thu, 3 Sep 2015 08:16:34 GMT"}, {"version": "v12", "created": "Sat, 19 Sep 2015 13:34:20 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2014 09:31:45 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2014 17:03:52 GMT"}, {"version": "v4", "created": "Mon, 19 May 2014 15:01:57 GMT"}, {"version": "v5", "created": "Tue, 7 Oct 2014 21:17:35 GMT"}, {"version": "v6", "created": "Wed, 3 Dec 2014 16:21:00 GMT"}, {"version": "v7", "created": "Mon, 15 Jun 2015 13:21:55 GMT"}, {"version": "v8", "created": "Tue, 16 Jun 2015 10:24:26 GMT"}, {"version": "v9", "created": "Sun, 2 Aug 2015 09:18:00 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Cafaro", "Massimo", ""], ["Pulimeno", "Marco", ""], ["Tempesta", "Piergiulio", ""]]}, {"id": "1401.0906", "submitter": "Paul Clarke", "authors": "P. Clarke", "title": "A Search Procedure for Cyclic Subsets", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a polynomial time algorithm for finding the set of all cyclic\nsubsets in a graph is presented. The concept of cyclic subsets has already been\nintroduced in an earlier paper. The algorithm finds cyclic subsets in a graph G\nby conjoining building block subsets of length three in V(G). We prove the\ncorrectness of this algorithm and present an asymptotic time complexity\nanalysis of the algorithm's performance.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2014 16:20:34 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Clarke", "P.", ""]]}, {"id": "1401.0921", "submitter": "Jochen Burghardt", "authors": "Jochen Burghardt", "title": "Maintaining partial sums in logarithmic time", "comments": "8 pages, 3 figues. Full version of an article in the \"Nordic Journal\n  of Computing\", including Hoare-style correctness proofs of algorithms", "journal-ref": "Nordic Journal of Computing, Vol.8, No.4, p.473-474, 2001", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data structure that allows to maintain in logarithmic time all\npartial sums of elements of a linear array during incremental changes of\nelement's values.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2014 18:04:34 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Burghardt", "Jochen", ""]]}, {"id": "1401.0936", "submitter": "Djamal Belazzougui", "authors": "Djamal Belazzougui", "title": "Linear time construction of compressed text indices in compact space", "comments": "Expanded version of a paper appeared in proceedings of STOC 2014\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the compressed suffix array and the compressed suffix tree for a\nstring of length $n$ over an integer alphabet of size $\\sigma\\leq n$ can both\nbe built in $O(n)$ (randomized) time using only $O(n\\log\\sigma)$ bits of\nworking space. The previously fastest construction algorithms that used\n$O(n\\log\\sigma)$ bits of space took times $O(n\\log\\log\\sigma)$ and\n$O(n\\log^{\\epsilon}n)$ respectively (where $\\epsilon$ is any positive constant\nsmaller than $1$). In the passing, we show that the Burrows-Wheeler transform\nof a string of length $n$ over an alphabet of size $\\sigma$ can be built in\ndeterministic $O(n)$ time and space $O(n\\log\\sigma)$. We also show that within\nthe same time and space, we can carry many sequence analysis tasks and\nconstruct some variants of the compressed suffix array and compressed suffix\ntree.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2014 20:26:13 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2015 13:56:14 GMT"}, {"version": "v3", "created": "Mon, 23 May 2016 13:54:58 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Belazzougui", "Djamal", ""]]}, {"id": "1401.1085", "submitter": "Quirijn Bouts", "authors": "Sander P. A. Alewijnse, Quirijn W. Bouts, Alex P. ten Brink, Kevin\n  Buchin", "title": "Distribution-Sensitive Construction of the Greedy Spanner", "comments": "16 pages,22 figures. Full version of the ESA 2014 publication with\n  the same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The greedy spanner is the highest quality geometric spanner (in e.g. edge\ncount and weight, both in theory and practice) known to be computable in\npolynomial time. Unfortunately, all known algorithms for computing it take\nOmega(n^2) time, limiting its applicability on large data sets.\n  We observe that for many point sets, the greedy spanner has many `short'\nedges that can be determined locally and usually quickly, and few or no `long'\nedges that can usually be determined quickly using local information and the\nwell-separated pair decomposition. We give experimental results showing large\nto massive performance increases over the state-of-the-art on nearly all tests\nand real-life data sets. On the theoretical side we prove a near-linear\nexpected time bound on uniform point sets and a near-quadratic worst-case\nbound.\n  Our bound for point sets drawn uniformly and independently at random in a\nsquare follows from a local characterization of t-spanners we give on such\npoint sets: we give a geometric property that holds with high probability on\nsuch point sets. This property implies that if an edge set on these points has\nt-paths between pairs of points `close' to each other, then it has t-paths\nbetween all pairs of points.\n  This characterization gives a O(n log^2 n log^2 log n) expected time bound on\nour greedy spanner algorithm, making it the first subquadratic time algorithm\nfor this problem on any interesting class of points. We also use this\ncharacterization to give a O((n + |E|) log^2 n log log n) expected time\nalgorithm on uniformly distributed points that determines if E is a t-spanner,\nmaking it the first subquadratic time algorithm for this problem that does not\nmake assumptions on E.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 14:04:05 GMT"}, {"version": "v2", "created": "Mon, 30 Jun 2014 13:36:29 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Alewijnse", "Sander P. A.", ""], ["Bouts", "Quirijn W.", ""], ["Brink", "Alex P. ten", ""], ["Buchin", "Kevin", ""]]}, {"id": "1401.1140", "submitter": "Axel Bacher", "authors": "Axel Bacher, Olivier Bodini, Alice Jacquot", "title": "Efficient random sampling of binary and unary-binary trees via holonomic\n  equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new uniform random sampler for binary trees with $n$ internal\nnodes consuming $2n + \\Theta(\\log(n)^2)$ random bits on average. This makes it\nquasi-optimal and out-performs the classical Remy algorithm. We also present a\nsampler for unary-binary trees with $n$ nodes taking $\\Theta(n)$ random bits on\naverage. Both are the first linear-time algorithms to be optimal up to a\nconstant.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 17:04:52 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2014 08:36:22 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Bacher", "Axel", ""], ["Bodini", "Olivier", ""], ["Jacquot", "Alice", ""]]}, {"id": "1401.1331", "submitter": "Igor Shparlinski", "authors": "Oscar Garcia-Morchon, Ronald Rietman, Igor E. Shparlinski and Ludo\n  Tolhuizen", "title": "Interpolation and Approximation of Polynomials in Finite Fields over a\n  Short Interval from Noisy Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a recently introduced HIMMO key distribution scheme, we consider\na modification of the noisy polynomial interpolation problem of recovering an\nunknown polynomial $f(X) \\in Z[X]$ from approximate values of the residues of\n$f(t)$ modulo a prime $p$ at polynomially many points $t$ taken from a short\ninterval.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 10:13:42 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Garcia-Morchon", "Oscar", ""], ["Rietman", "Ronald", ""], ["Shparlinski", "Igor E.", ""], ["Tolhuizen", "Ludo", ""]]}, {"id": "1401.1450", "submitter": "Diego Fernando C. Carri\\'on L.", "authors": "Diego Fernando C. Carri\\'on L", "title": "A Recursive Algorithmic Approach to the Finding of Permutations for the\n  Combination of Any Two Sets", "comments": "12 pages, 4 figures, originally submitted to the July 2013 Brigham\n  Young University-Idaho Research and Creative Works Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper I present a conjecture for a recursive algorithm that finds\neach permutation of combining two sets of objects (AKA the Shuffle Product).\nThis algorithm provides an efficient way to navigate this problem, as each\natomic operation yields a permutation of the union. The permutations of the\nunion of the two sets are represented as binary integers which are then\nmanipulated mathematically to find the next permutation. The routes taken to\nfind each of the permutations then form a series of associations or adjacencies\nwhich can be represented in a tree graph which appears to possess some\nproperties of a fractal.\n  This algorithm was discovered while attempting to identify every possible\nend-state of a Tic-Tac-Toe (Naughts and Crosses) board. It was found to be a\nviable and efficient solution to the problem, and now---in its more generalized\nstate---it is my belief that it may find applications among a wide range of\ntheoretical and applied sciences.\n  I hypothesize that, due to the fractal-like nature of the tree it traverses,\nthis algorithm sheds light on a more generic principle of combinatorics and as\nsuch could be further generalized to perhaps be applied to the union of any\nnumber of sets.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 17:30:05 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["L", "Diego Fernando C. Carri\u00f3n", ""]]}, {"id": "1401.1753", "submitter": "Sounak Sadhukhan", "authors": "Sounak Sadhukhan, Samar Sen Sarma", "title": "A Solution of Degree Constrained Spanning Tree Using Hybrid GA", "comments": "This paper has been withdrawn by the author due to some crucial\n  errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In real life, it is always an urge to reach our goal in minimum effort i.e.,\nit should have a minimum constrained path. The path may be shortest route in\npractical life, either physical or electronic medium. The scenario is to\nrepresents the ambiance as a graph and to find a spanning tree with custom\ndesign criteria. Here, we have chosen a minimum degree spanning tree, which can\nbe generated in real time with minimum turnaround time. The problem is\nNP-complete in nature [1, 2]. The solution approach, in general, is\napproximate. We have used a heuristic approach, namely hybrid genetic algorithm\n(GA), with motivated criteria of encoded data structures of graph. We compare\nthe experimental result with the existing approximate algorithm and the result\nis so encouraging that we are interested to use it in our future applications.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 17:05:41 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2014 17:04:59 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Sadhukhan", "Sounak", ""], ["Sarma", "Samar Sen", ""]]}, {"id": "1401.1763", "submitter": "Vladimir Braverman", "authors": "Vladimir Braverman, Jonathan Katzman, Charles Seidell, Gregory\n  Vorsanger", "title": "Approximating Large Frequency Moments with $O(n^{1-2/k})$ Bits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of approximating frequency moments in\nthe streaming model. Given a stream $D = \\{p_1,p_2,\\dots,p_m\\}$ of numbers from\n$\\{1,\\dots, n\\}$, a frequency of $i$ is defined as $f_i = |\\{j: p_j = i\\}|$.\nThe $k$-th \\emph{frequency moment} of $D$ is defined as $F_k = \\sum_{i=1}^n\nf_i^k$.\n  In this paper we give an upper bound on the space required to find a $k$-th\nfrequency moment of $O(n^{1-2/k})$ bits that matches, up to a constant factor,\nthe lower bound of Woodruff and Zhang (STOC 12) for constant $\\epsilon$ and\nconstant $k$. Our algorithm makes a single pass over the stream and works for\nany constant $k > 3$.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 18:05:26 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2014 02:31:23 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Braverman", "Vladimir", ""], ["Katzman", "Jonathan", ""], ["Seidell", "Charles", ""], ["Vorsanger", "Gregory", ""]]}, {"id": "1401.1771", "submitter": "Yang Xiang", "authors": "Yang Xiang", "title": "Simple linear algorithms for mining graph cores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batagelj and Zaversnik proposed a linear algorithm for the well-known\n$k$-core decomposition problem. However, when $k$-cores are desired for a given\n$k$, we find that a simple linear algorithm requiring no sorting works for\nmining $k$-cores. In addition, this algorithm can be extended to mine $(k_1,\nk_2,\\ldots, k_p)$-cores from $p$-partite graphs in linear time, and this mining\napproach can be efficiently implemented in a distributed computing environment\nwith a lower message complexity bound in comparison with the best known method\nof distributed $k$-core decomposition.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 18:34:38 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Xiang", "Yang", ""]]}, {"id": "1401.1872", "submitter": "Paraschos Koutris", "authors": "Paul Beame, Paraschos Koutris and Dan Suciu", "title": "Skew in Parallel Query Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of computing a conjunctive query q in parallel, using p\nof servers, on a large database. We consider algorithms with one round of\ncommunication, and study the complexity of the communication. We are especially\ninterested in the case where the data is skewed, which is a major challenge for\nscalable parallel query processing. We establish a tight connection between the\nfractional edge packings of the query and the amount of communication, in two\ncases. First, in the case when the only statistics on the database are the\ncardinalities of the input relations, and the data is skew-free, we provide\nmatching upper and lower bounds (up to a poly log p factor) expressed in terms\nof fractional edge packings of the query q. Second, in the case when the\nrelations are skewed and the heavy hitters and their frequencies are known, we\nprovide upper and lower bounds (up to a poly log p factor) expressed in terms\nof packings of residual queries obtained by specializing the query to a heavy\nhitter. All our lower bounds are expressed in the strongest form, as number of\nbits needed to be communicated between processors with unlimited computational\npower. Our results generalizes some prior results on uniform databases (where\neach relation is a matching) [4], and other lower bounds for the MapReduce\nmodel [1].\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 01:07:06 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Beame", "Paul", ""], ["Koutris", "Paraschos", ""], ["Suciu", "Dan", ""]]}, {"id": "1401.1919", "submitter": "Silu Huang", "authors": "Silu Huang, James Cheng, Huanhuan Wu", "title": "Temporal Graph Traversals: Definitions, Algorithms, and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A temporal graph is a graph in which connections between vertices are active\nat specific times, and such temporal information leads to completely new\npatterns and knowledge that are not present in a non-temporal graph. In this\npaper, we study traversal problems in a temporal graph. Graph traversals, such\nas DFS and BFS, are basic operations for processing and studying a graph. While\nboth DFS and BFS are well-known simple concepts, it is non-trivial to adopt the\nsame notions from a non-temporal graph to a temporal graph. We analyze the\ndifficulties of defining temporal graph traversals and propose new definitions\nof DFS and BFS for a temporal graph. We investigate the properties of temporal\nDFS and BFS, and propose efficient algorithms with optimal complexity. In\nparticular, we also study important applications of temporal DFS and BFS. We\nverify the efficiency and importance of our graph traversal algorithms in real\nworld temporal graphs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 08:04:53 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Huang", "Silu", ""], ["Cheng", "James", ""], ["Wu", "Huanhuan", ""]]}, {"id": "1401.2065", "submitter": "Oren Weimann", "authors": "Danny Hermelin, Gad M. Landau, Yuri Rabinovich, Oren Weimann", "title": "Binary Jumbled Pattern Matching via All-Pairs Shortest Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In binary jumbled pattern matching we wish to preprocess a binary string $S$\nin order to answer queries $(i,j)$ which ask for a substring of $S$ that is of\nsize $i$ and has exactly $j$ 1-bits. The problem naturally generalizes to\nnode-labeled trees and graphs by replacing \"substring\" with \"connected\nsubgraph\".\n  In this paper, we give an ${n^2}/{2^{\\Omega(\\log n/\\log \\log n)^{1/2}}}$ time\nsolution for both strings and trees. This odd-looking time complexity improves\nthe state of the art $O(n^2/\\log^2 n)$ solutions by more than any\npoly-logarithmic factor. It originates from the recent seminal algorithm of\nWilliams for min-plus matrix multiplication. We obtain the result by giving a\nblack box reduction from trees to strings. This is then combined with a\nreduction from strings to min-plus matrix multiplications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 16:38:21 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2014 17:54:35 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2014 11:19:30 GMT"}, {"version": "v4", "created": "Sun, 29 Jun 2014 14:18:47 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Hermelin", "Danny", ""], ["Landau", "Gad M.", ""], ["Rabinovich", "Yuri", ""], ["Weimann", "Oren", ""]]}, {"id": "1401.2071", "submitter": "Stefan Hougardy", "authors": "Stefan Hougardy and Mirko Wilde", "title": "On the Nearest Neighbor Rule for the Metric Traveling Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a very simple family of traveling salesman instances with $n$\ncities where the nearest neighbor rule may produce a tour that is $\\Theta(\\log\nn)$ times longer than an optimum solution. Our family works for the graphic,\nthe euclidean, and the rectilinear traveling salesman problem at the same time.\nIt improves the so far best known lower bound in the euclidean case and proves\nfor the first time a lower bound in the rectilinear case.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 16:52:58 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Hougardy", "Stefan", ""], ["Wilde", "Mirko", ""]]}, {"id": "1401.2165", "submitter": "Stefanie Roos", "authors": "Stefanie Roos, Thorsten Strufe", "title": "NextBestOnce: Achieving Polylog Routing despite Non-greedy Embeddings", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Overlays suffer from high message delivery delays due to insufficient\nrouting strategies. Limiting connections to device pairs that are owned by\nindividuals with a mutual trust relationship in real life, they form topologies\nrestricted to a subgraph of the social network of their users. While\ncentralized, highly successful social networking services entail a complete\nprivacy loss of their users, Social Overlays at higher performance represent an\nideal private and censorship-resistant communication substrate for the same\npurpose.\n  Routing in such restricted topologies is facilitated by embedding the social\ngraph into a metric space. Decentralized routing algorithms have up to date\nmainly been analyzed under the assumption of a perfect lattice structure.\nHowever, currently deployed embedding algorithms for privacy-preserving Social\nOverlays cannot achieve a sufficiently accurate embedding and hence\nconventional routing algorithms fail. Developing Social Overlays with\nacceptable performance hence requires better models and enhanced algorithms,\nwhich guarantee convergence in the presence of local optima with regard to the\ndistance to the target.\n  We suggest a model for Social Overlays that includes inaccurate embeddings\nand arbitrary degree distributions. We further propose NextBestOnce, a routing\nalgorithm that can achieve polylog routing length despite local optima. We\nprovide analytical bounds on the performance of NextBestOnce assuming a\nscale-free degree distribution, and furthermore show that its performance can\nbe improved by more than a constant factor when including Neighbor-of-Neighbor\ninformation in the routing decisions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 21:05:57 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Roos", "Stefanie", ""], ["Strufe", "Thorsten", ""]]}, {"id": "1401.2175", "submitter": "Graham Cormode", "authors": "Graham Cormode, Hossein Jowhari", "title": "A Second Look at Counting Triangles in Graph Streams (revised)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present improved results on the problem of counting\ntriangles in edge streamed graphs. For graphs with $m$ edges and at least $T$\ntriangles, we show that an extra look over the stream yields a two-pass\ntreaming algorithm that uses $O(\\frac{m}{\\eps^{2.5}\\sqrt{T}}\\polylog(m))$ space\nand outputs a $(1+\\eps)$ approximation of the number of triangles in the graph.\nThis improves upon the two-pass streaming tester of Braverman, Ostrovsky and\nVilenchik, ICALP 2013, which distinguishes between triangle-free graphs and\ngraphs with at least $T$ triangle using $O(\\frac{m}{T^{1/3}})$ space. Also, in\nterms of dependence on $T$, we show that more passes would not lead to a better\nspace bound. In other words, we prove there is no constant pass streaming\nalgorithm that distinguishes between triangle-free graphs from graphs with at\nleast $T$ triangles using $O(\\frac{m}{T^{1/2+\\rho}})$ space for any constant\n$\\rho \\ge 0$.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 21:37:20 GMT"}, {"version": "v2", "created": "Wed, 9 Mar 2016 13:34:39 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["Cormode", "Graham", ""], ["Jowhari", "Hossein", ""]]}, {"id": "1401.2195", "submitter": "Ching-Lueh Chang", "authors": "Ching-Lueh Chang", "title": "A lower bound for metric 1-median selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of finding a point in an n-point metric space with the\nminimum average distance to all points. We show that this problem has no\ndeterministic $o(n^2)$-query $(4-\\Omega(1))$-approximation algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 22:43:59 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Chang", "Ching-Lueh", ""]]}, {"id": "1401.2327", "submitter": "Waqas Nawaz", "authors": "Kamran Najeebullah, Kifayat Ullah Khan, Waqas Nawaz, Young-Koo Lee", "title": "BPP: Large Graph Storage for Efficient Disk Based Processing", "comments": "5 pages, Published in ICCA, 2013", "journal-ref": "Advanced Science and Technology Letters Vol.30 (ICCA 2013),\n  pp.117-121", "doi": "10.14257/astl.2013.30.25", "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing very large graphs like social networks, biological and chemical\ncompounds is a challenging task. Distributed graph processing systems process\nthe billion-scale graphs efficiently but incur overheads of efficient\npartitioning and distribution of the graph over a cluster of nodes. Distributed\nprocessing also requires cluster management and fault tolerance. In order to\novercome these problems GraphChi was proposed recently. GraphChi significantly\noutperformed all the representative distributed processing frameworks. Still,\nwe observe that GraphChi incurs some serious degradation in performance due to\n1) high number of non-sequential I/Os for processing every chunk of graph; and\n2) lack of true parallelism to process the graph. In this paper we propose a\nsimple yet powerful engine BiShard Parallel Processor (BPP) to efficiently\nprocess billions-scale graphs on a single PC. We extend the storage structure\nproposed by GraphChi and introduce a new processing model called BiShard\nParallel (BP). BP enables full CPU parallelism for processing the graph and\nsignificantly reduces the number of non-sequential I/Os required to process\nevery chunk of the graph. Our experiments on real large graphs show that our\nsolution significantly outperforms GraphChi.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 13:36:21 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Najeebullah", "Kamran", ""], ["Khan", "Kifayat Ullah", ""], ["Nawaz", "Waqas", ""], ["Lee", "Young-Koo", ""]]}, {"id": "1401.2393", "submitter": "Chiranjeev Kumar", "authors": "Chiranjeev Kumar", "title": "Approximation Algorithm Project", "comments": "Tiny project. arXiv admin note: text overlap with arXiv:1203.3097 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This application for learning APPROXIMATION ALGORITHM has been designed in\nJava which will make user comfortable in learning the very complex subject\n\"NP-Completeness\" and the solution to NP-Complete problem using approximation\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 16:30:55 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Kumar", "Chiranjeev", ""]]}, {"id": "1401.2444", "submitter": "Ryan Williams", "authors": "Ryan Williams", "title": "New algorithms and lower bounds for circuits with linear threshold gates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $ACC \\circ THR$ be the class of constant-depth circuits comprised of AND,\nOR, and MOD$m$ gates (for some constant $m > 1$), with a bottom layer of gates\ncomputing arbitrary linear threshold functions. This class of circuits can be\nseen as a \"midpoint\" between $ACC$ (where we know nontrivial lower bounds) and\ndepth-two linear threshold circuits (where nontrivial lower bounds remain\nopen).\n  We give an algorithm for evaluating an arbitrary symmetric function of\n$2^{n^{o(1)}}$ $ACC \\circ THR$ circuits of size $2^{n^{o(1)}}$, on all possible\ninputs, in $2^n \\cdot poly(n)$ time. Several consequences are derived:\n  $\\bullet$ The number of satisfying assignments to an $ACC \\circ THR$ circuit\nof subexponential size can be computed in $2^{n-n^{\\varepsilon}}$ time (where\n$\\varepsilon > 0$ depends on the depth and modulus of the circuit).\n  $\\bullet$ $NEXP$ does not have quasi-polynomial size $ACC \\circ THR$\ncircuits, nor does $NEXP$ have quasi-polynomial size $ACC \\circ SYM$ circuits.\nNontrivial size lower bounds were not known even for $AND \\circ OR \\circ THR$\ncircuits.\n  $\\bullet$ Every 0-1 integer linear program with $n$ Boolean variables and $s$\nlinear constraints is solvable in $2^{n-\\Omega(n/((\\log M)(\\log s)^{5}))}\\cdot\npoly(s,n,M)$ time with high probability, where $M$ upper bounds the bit\ncomplexity of the coefficients. (For example, 0-1 integer programs with weights\nin $[-2^{poly(n)},2^{poly(n)}]$ and $poly(n)$ constraints can be solved in\n$2^{n-\\Omega(n/\\log^6 n)}$ time.)\n  We also present an algorithm for evaluating depth-two linear threshold\ncircuits (a.k.a., $THR \\circ THR$) with exponential weights and $2^{n/24}$ size\non all $2^n$ input assignments, running in $2^n \\cdot poly(n)$ time. This is\nevidence that non-uniform lower bounds for $THR \\circ THR$ are within reach.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 20:25:33 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Williams", "Ryan", ""]]}, {"id": "1401.2454", "submitter": "Shen Chen Xu", "authors": "Michael B. Cohen, Gary L. Miller, Jakub W. Pachocki, Richard Peng,\n  Shen Chen Xu", "title": "Stretching Stretch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a generalized definition of stretch that simplifies the efficient\nconstruction of low-stretch embeddings suitable for graph algorithms. The\ngeneralization, based on discounting highly stretched edges by taking their\n$p$-th power for some $0 < p < 1$, is directly related to performances of\nexisting algorithms. This discounting of high-stretch edges allows us to treat\nmany classes of edges with coarser granularity. It leads to a two-pass approach\nthat combines bottom-up clustering and top-down decompositions to construct\nthese embeddings in $\\mathcal{O}(m\\log\\log{n})$ time. Our algorithm\nparallelizes readily and can also produce generalizations of low-stretch\nsubgraphs.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 20:58:11 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2014 03:01:30 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Cohen", "Michael B.", ""], ["Miller", "Gary L.", ""], ["Pachocki", "Jakub W.", ""], ["Peng", "Richard", ""], ["Xu", "Shen Chen", ""]]}, {"id": "1401.2514", "submitter": "Abhijit Bhattacharya", "authors": "Abhijit Bhattacharya, Akhila Rao, K. P. Naveen, P. P. Nishanth, S.V.R.\n  Anand, and Anurag Kumar", "title": "QoS Constrained Optimal Sink and Relay Placement in Planned Wireless\n  Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are given a set of sensors at given locations, a set of potential\nlocations for placing base stations (BSs, or sinks), and another set of\npotential locations for placing wireless relay nodes. There is a cost for\nplacing a BS and a cost for placing a relay. The problem we consider is to\nselect a set of BS locations, a set of relay locations, and an association of\nsensor nodes with the selected BS locations, so that number of hops in the path\nfrom each sensor to its BS is bounded by hmax, and among all such feasible\nnetworks, the cost of the selected network is the minimum. The hop count bound\nsuffices to ensure a certain probability of the data being delivered to the BS\nwithin a given maximum delay under a light traffic model. We observe that the\nproblem is NP-Hard, and is hard to even approximate within a constant factor.\nFor this problem, we propose a polynomial time approximation algorithm\n(SmartSelect) based on a relay placement algorithm proposed in our earlier\nwork, along with a modification of the greedy algorithm for weighted set cover.\nWe have analyzed the worst case approximation guarantee for this algorithm. We\nhave also proposed a polynomial time heuristic to improve upon the solution\nprovided by SmartSelect. Our numerical results demonstrate that the algorithms\nprovide good quality solutions using very little computation time in various\nrandomly generated network scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2014 08:44:47 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Bhattacharya", "Abhijit", ""], ["Rao", "Akhila", ""], ["Naveen", "K. P.", ""], ["Nishanth", "P. P.", ""], ["Anand", "S. V. R.", ""], ["Kumar", "Anurag", ""]]}, {"id": "1401.2518", "submitter": "Pooja Vyavahare", "authors": "Pooja Vyavahare and Nutan Limaye and D. Manjunath", "title": "Optimal Embedding of Functions for In-Network Computation: Complexity\n  Analysis and Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimal distributed computation of a given function of\ndistributed data. The input (data) nodes and the sink node that receives the\nfunction form a connected network that is described by an undirected weighted\nnetwork graph. The algorithm to compute the given function is described by a\nweighted directed acyclic graph and is called the computation graph. An\nembedding defines the computation communication sequence that obtains the\nfunction at the sink. Two kinds of optimal embeddings are sought, the embedding\nthat---(1)~minimizes delay in obtaining function at sink, and (2)~minimizes\ncost of one instance of computation of function. This abstraction is motivated\nby three applications---in-network computation over sensor networks, operator\nplacement in distributed databases, and module placement in distributed\ncomputing.\n  We first show that obtaining minimum-delay and minimum-cost embeddings are\nboth NP-complete problems and that cost minimization is actually MAX SNP-hard.\nNext, we consider specific forms of the computation graph for which polynomial\ntime solutions are possible. When the computation graph is a tree, a polynomial\ntime algorithm to obtain the minimum delay embedding is described. Next, for\nthe case when the function is described by a layered graph we describe an\nalgorithm that obtains the minimum cost embedding in polynomial time. This\nalgorithm can also be used to obtain an approximation for delay minimization.\nWe then consider bounded treewidth computation graphs and give an algorithm to\nobtain the minimum cost embedding in polynomial time.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2014 11:05:51 GMT"}, {"version": "v2", "created": "Wed, 27 Aug 2014 07:07:06 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2015 12:33:53 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Vyavahare", "Pooja", ""], ["Limaye", "Nutan", ""], ["Manjunath", "D.", ""]]}, {"id": "1401.2532", "submitter": "Yash Raj Shrestha", "authors": "Jiong Guo and Yash Raj Shrestha", "title": "Parameterized Complexity of Edge Interdiction Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of interdiction problems in graphs. For\nan optimization problem on graphs, one can formulate an interdiction problem as\na game consisting of two players, namely, an interdictor and an evader, who\ncompete on an objective with opposing interests. In edge interdiction problems,\nevery edge of the input graph has an interdiction cost associated with it and\nthe interdictor interdicts the graph by modifying the edges in the graph, and\nthe number of such modifications is constrained by the interdictor's budget.\nThe evader then solves the given optimization problem on the modified graph.\nThe action of the interdictor must impede the evader as much as possible. We\nfocus on edge interdiction problems related to minimum spanning tree, maximum\nmatching and shortest paths. These problems arise in different real world\nscenarios. We derive several fixed-parameter tractability and W[1]-hardness\nresults for these interdiction problems with respect to various parameters.\nNext, we show close relation between interdiction problems and partial cover\nproblems on bipartite graphs where the goal is not to cover all elements but to\nminimize/maximize the number of covered elements with specific number of sets.\nHereby, we investigate the parameterized complexity of several partial cover\nproblems on bipartite graphs.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2014 14:24:12 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Guo", "Jiong", ""], ["Shrestha", "Yash Raj", ""]]}, {"id": "1401.2538", "submitter": "Hsueh-I Lu", "authors": "Hsueh-I Lu", "title": "Linear-Time Compression of Bounded-Genus Graphs into\n  Information-Theoretically Optimal Number of Bits", "comments": "26 pages, 9 figures, accepted to SIAM Journal on Computing", "journal-ref": "SIAM Journal on Computing, 43(2):477-496, 2014", "doi": "10.1137/120879142", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $\\textit{compression scheme}$ $A$ for a class $\\mathbb{G}$ of graphs\nconsists of an encoding algorithm $\\textit{Encode}_A$ that computes a binary\nstring $\\textit{Code}_A(G)$ for any given graph $G$ in $\\mathbb{G}$ and a\ndecoding algorithm $\\textit{Decode}_A$ that recovers $G$ from\n$\\textit{Code}_A(G)$. A compression scheme $A$ for $\\mathbb{G}$ is\n$\\textit{optimal}$ if both $\\textit{Encode}_A$ and $\\textit{Decode}_A$ run in\nlinear time and the number of bits of $\\textit{Code}_A(G)$ for any $n$-node\ngraph $G$ in $\\mathbb{G}$ is information-theoretically optimal to within\nlower-order terms. Trees and plane triangulations were the only known\nnontrivial graph classes that admit optimal compression schemes. Based upon\nGoodrich's separator decomposition for planar graphs and Djidjev and\nVenkatesan's planarizers for bounded-genus graphs, we give an optimal\ncompression scheme for any hereditary (i.e., closed under taking subgraphs)\nclass $\\mathbb{G}$ under the premise that any $n$-node graph of $\\mathbb{G}$ to\nbe encoded comes with a genus-$o(\\frac{n}{\\log^2 n})$ embedding. By Mohar's\nlinear-time algorithm that embeds a bounded-genus graph on a genus-$O(1)$\nsurface, our result implies that any hereditary class of genus-$O(1)$ graphs\nadmits an optimal compression scheme. For instance, our result yields the\nfirst-known optimal compression schemes for planar graphs, plane graphs, graphs\nembedded on genus-$1$ surfaces, graphs with genus $2$ or less, $3$-colorable\ndirected plane graphs, $4$-outerplanar graphs, and forests with degree at most\n$5$. For non-hereditary graph classes, we also give a methodology for obtaining\noptimal compression schemes. From this methodology, we give the first known\noptimal compression schemes for triangulations of genus-$O(1)$ surfaces and\nfloorplans.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2014 15:01:49 GMT"}], "update_date": "2014-04-24", "authors_parsed": [["Lu", "Hsueh-I", ""]]}, {"id": "1401.2662", "submitter": "Shiva Kintali", "authors": "Shiva Kintali", "title": "Directed Width Parameters and Circumference of Digraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the directed treewidth, DAG-width and Kelly-width of a digraph\nare bounded above by its circumference plus one.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2014 19:51:29 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Kintali", "Shiva", ""]]}, {"id": "1401.2844", "submitter": "Dmitry Lande", "authors": "Yakiv O. Kalinovsky, Dmitry V. Lande, Yuliya E. Boyarinova, Iana V.\n  Khitsko", "title": "Inifnite hypercomplex number system factorization methods", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of obtaining the set of noncanonical hypercomplex number systems\nby conversion of infinite hypercomplex number system to finite hypercomplex\nnumber system depending on multiplication rules and factorization method is\ndescribed. Systems obtained by this method starting from the 3rddimension are\nnoncanonical. The obtained systems of even dimension can be re-factorized. As a\nresult of it hypercomplex number system of two times less dimension are got.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 14:22:32 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Kalinovsky", "Yakiv O.", ""], ["Lande", "Dmitry V.", ""], ["Boyarinova", "Yuliya E.", ""], ["Khitsko", "Iana V.", ""]]}, {"id": "1401.2874", "submitter": "Tomasz Kociumaka", "authors": "Tomasz Kociumaka and Marek Cygan", "title": "Constant Factor Approximation for Capacitated k-Center with Outliers", "comments": "15 pages, 3 figures, accepted to STACS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-center problem is a classic facility location problem, where given an\nedge-weighted graph $G = (V,E)$ one is to find a subset of $k$ vertices $S$,\nsuch that each vertex in $V$ is \"close\" to some vertex in $S$. The\napproximation status of this basic problem is well understood, as a simple\n2-approximation algorithm is known to be tight. Consequently different\nextensions were studied.\n  In the capacitated version of the problem each vertex is assigned a capacity,\nwhich is a strict upper bound on the number of clients a facility can serve,\nwhen located at this vertex. A constant factor approximation for the\ncapacitated $k$-center was obtained last year by Cygan, Hajiaghayi and Khuller\n[FOCS'12], which was recently improved to a 9-approximation by An, Bhaskara and\nSvensson [arXiv'13].\n  In a different generalization of the problem some clients (denoted as\noutliers) may be disregarded. Here we are additionally given an integer $p$ and\nthe goal is to serve exactly $p$ clients, which the algorithm is free to\nchoose. In 2001 Charikar et al. [SODA'01] presented a 3-approximation for the\n$k$-center problem with outliers.\n  In this paper we consider a common generalization of the two extensions\npreviously studied separately, i.e. we work with the capacitated $k$-center\nwith outliers. We present the first constant factor approximation algorithm\nwith approximation ratio of 25 even for the case of non-uniform hard\ncapacities.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 15:37:02 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Kociumaka", "Tomasz", ""], ["Cygan", "Marek", ""]]}, {"id": "1401.2912", "submitter": "Ragesh Jaiswal", "authors": "Anup Bhattacharya, Ragesh Jaiswal, Nir Ailon", "title": "A tight lower bound instance for k-means++ in constant dimension", "comments": "To appear in TAMC 2014. arXiv admin note: text overlap with\n  arXiv:1306.4207", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-means++ seeding algorithm is one of the most popular algorithms that is\nused for finding the initial $k$ centers when using the k-means heuristic. The\nalgorithm is a simple sampling procedure and can be described as follows: Pick\nthe first center randomly from the given points. For $i > 1$, pick a point to\nbe the $i^{th}$ center with probability proportional to the square of the\nEuclidean distance of this point to the closest previously $(i-1)$ chosen\ncenters.\n  The k-means++ seeding algorithm is not only simple and fast but also gives an\n$O(\\log{k})$ approximation in expectation as shown by Arthur and Vassilvitskii.\nThere are datasets on which this seeding algorithm gives an approximation\nfactor of $\\Omega(\\log{k})$ in expectation. However, it is not clear from these\nresults if the algorithm achieves good approximation factor with reasonably\nhigh probability (say $1/poly(k)$). Brunsch and R\\\"{o}glin gave a dataset where\nthe k-means++ seeding algorithm achieves an $O(\\log{k})$ approximation ratio\nwith probability that is exponentially small in $k$. However, this and all\nother known lower-bound examples are high dimensional. So, an open problem was\nto understand the behavior of the algorithm on low dimensional datasets. In\nthis work, we give a simple two dimensional dataset on which the seeding\nalgorithm achieves an $O(\\log{k})$ approximation ratio with probability\nexponentially small in $k$. This solves open problems posed by Mahajan et al.\nand by Brunsch and R\\\"{o}glin.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 16:57:57 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2014 04:06:30 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["Bhattacharya", "Anup", ""], ["Jaiswal", "Ragesh", ""], ["Ailon", "Nir", ""]]}, {"id": "1401.3172", "submitter": "Pengli Ji", "authors": "Kun He, Pengli Ji, Chumin Li", "title": "An iterative merging placement algorithm for the fixed-outline\n  floorplanning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of rectangular modules with fixed area and variable dimensions,\nand a fixed rectangular circuit. The placement of Fixed-Outline Floorplanning\nwith Soft Modules (FOFSM) aims to determine the dimensions and position of each\nmodule on the circuit. We present a two-stage Iterative Merging Placement (IMP)\nalgorithm for the FOFSM with zero deadspace constraint. The first stage\niteratively merges two modules with the least area into a composite module to\nachieve a final composite module, and builds up a slicing tree in a bottom-up\nhierarchy. The second stage recursively determines the relative relationship\n(left-right or top-bottom) of the sibling modules in the slicing tree in a\ntop-down hierarchy, and the dimensions and position of each leaf module are\ndetermined automatically. Compared with zero-dead-space (ZDS) algorithm, the\nonly algorithm guarantees a feasible layout under some condition, we prove that\nthe proposed IMP could construct a feasible layout under a more relaxed\ncondition. Besides, IMP is more scalable in handling FOFSM considering the\nwirelength or without the zero deadspace constraint.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 13:07:19 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["He", "Kun", ""], ["Ji", "Pengli", ""], ["Li", "Chumin", ""]]}, {"id": "1401.3654", "submitter": "Paulo Feofiloff", "authors": "Ernesto G. Birgin, Paulo Feofiloff, Cristina G. Fernandes, Everton L.\n  de Melo, Marcio T. I. Oshiro and D\\'ebora P. Ronconi", "title": "A MILP model for an extended version of the Flexible Job Shop Problem", "comments": "15 pages, 2 figures, 4 tables. Optimization Letters, 2013", "journal-ref": null, "doi": "10.1007/S11590-013-0669-7", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A MILP model for an extended version of the Flexible Job Shop Scheduling\nproblem is proposed. The extension allows the precedences between operations of\na job to be given by an arbitrary directed acyclic graph rather than a linear\norder. The goal is the minimization of the makespan. Theoretical and practical\nadvantages of the proposed model are discussed. Numerical experiments show the\nperformance of a commercial exact solver when applied to the proposed model.\nThe new model is also compared with a simple extension of the model described\nby \\\"Ozg\\\"uven, \\\"Ozbakir, and Yavuz (Mathematical models for job-shop\nscheduling problems with routing and process plan flexibility, Applied\nMathematical Modelling, 34:1539--1548, 2010), using instances from the\nliterature and instances inspired by real data from the printing industry.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 16:23:12 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Birgin", "Ernesto G.", ""], ["Feofiloff", "Paulo", ""], ["Fernandes", "Cristina G.", ""], ["de Melo", "Everton L.", ""], ["Oshiro", "Marcio T. I.", ""], ["Ronconi", "D\u00e9bora P.", ""]]}, {"id": "1401.3670", "submitter": "Katarzyna Paluch", "authors": "Katarzyna Paluch", "title": "Better Approximation Algorithms for Maximum Asymmetric Traveling\n  Salesman and Shortest Superstring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the maximum asymmetric traveling salesman problem (Max ATSP) we are given\na complete directed graph with nonnegative weights on the edges and we wish to\ncompute a traveling salesman tour of maximum weight. In this paper we give a\nfast combinatorial $\\frac 34$-approximation algorithm for Max ATSP. It is based\non a novel use of {\\it half-edges}, matchings and a new method of edge\ncoloring. (A {\\it half-edge} of edge $(u,v)$ is informally speaking \"either a\nhead or a tail of $(u,v)$\".) The current best approximation algorithms for Max\nATSP, achieving the approximation guarantee of $\\frac 23$, are due to Kaplan,\nLewenstein, Shafrir and Sviridenko and Elbassioni, Paluch, van Zuylen. Using a\nrecent result by Mucha, which states that an $\\alpha$-approximation algorithm\nfor Max ATSP implies a $(2+\\frac{11(1-\\alpha)}{9-2\\alpha})$-approximation\nalgorithm for the shortest superstring problem (SSP), we obtain also a $(2\n\\frac{11}{30} \\approx 2,3667)$-approximation algorithm for SSP, beating the\npreviously best known (having approximation factor equal to $2 \\frac{11}{23}\n\\approx 2,4782$.)\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 17:02:40 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Paluch", "Katarzyna", ""]]}, {"id": "1401.3685", "submitter": "Ragesh Jaiswal", "authors": "Ragesh Jaiswal, Mehul Kumar, Pulkit Yadav", "title": "Improved analysis of D2-sampling based PTAS for k-means and other\n  Clustering problems", "comments": "arXiv admin note: substantial text overlap with arXiv:1201.4206", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an improved analysis of the simple $D^2$-sampling based PTAS for the\n$k$-means clustering problem given by Jaiswal, Kumar, and Sen (Algorithmica,\n2013). The improvement on the running time is from $O\\left(nd \\cdot\n2^{\\tilde{O}(k^2/\\epsilon)}\\right)$ to $O\\left(nd \\cdot\n2^{\\tilde{O}(k/\\epsilon)}\\right)$.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 17:49:22 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Jaiswal", "Ragesh", ""], ["Kumar", "Mehul", ""], ["Yadav", "Pulkit", ""]]}, {"id": "1401.3762", "submitter": "Andrew Ju", "authors": "Andrew Ju, Patrick Healy", "title": "An Experimental Evaluation of List Coloring Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The list coloring problem is a variant of vertex coloring where a vertex may\nbe colored only a color from a prescribed set. Several applications of vertex\ncoloring are more appropriately modelled as instances of list coloring and thus\nwe argue that it is an important problem to consider. Regardless of the\nimportance of list coloring, few published algorithms exist for it. In this\npaper we review the only two existing ones we could find and propose an exact\nbranch and bound one. We conduct an experimental evaluation of the three\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 21:22:18 GMT"}, {"version": "v2", "created": "Fri, 20 Jun 2014 23:07:41 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Ju", "Andrew", ""], ["Healy", "Patrick", ""]]}, {"id": "1401.3794", "submitter": "Thibaut Vidal", "authors": "Thibaut Vidal, Nelson Maculan, Puca Huachi Vaz Penna, Luis Satoru Ochi", "title": "Large neighborhoods with implicit customer selection for vehicle routing\n  problems with profits", "comments": "Working Paper -- MIT, Revised, 34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider several Vehicle Routing Problems (VRP) with profits, which seek\nto select a subset of customers, each one being associated with a profit, and\nto design service itineraries. When the sum of profits is maximized under\ndistance constraints, the problem is usually called team orienteering problem.\nThe capacitated profitable tour problem seeks to maximize profits minus travel\ncosts under capacity constraints. Finally, in the VRP with private fleet and\ncommon carrier, some customers can be delegated to an external carrier subject\nto a cost. Three families of combined decisions must be taken: customers\nselection, assignment to vehicles, and sequencing of deliveries for each route.\n  We propose a new neighborhood search for these problems which explores an\nexponential number of solutions in pseudo polynomial time. The search is\nconducted with standard VRP neighborhoods on an \"exhaustive\" solution\nrepresentation, visiting all customers. Since visiting all customers is usually\ninfeasible or sub-optimal, an efficient \"Select\" algorithm, based on resource\nconstrained shortest paths, is repeatedly used on any new route to find the\noptimal subsequence of visits to customers. The good performance of these\nneighborhood structures is demonstrated by extensive computational experiments\nwith a local search, an iterated local search and a hybrid genetic algorithm.\nIntriguingly, even a local-improvement method to the first local optimum of\nthis neighborhood achieves an average gap of 0.09% on classic team orienteering\nbenchmark instances, rivaling with the current state-of-the-art metaheuristics.\nPromising research avenues on hybridizations with more standard routing\nneighborhoods are also open.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 23:47:21 GMT"}, {"version": "v2", "created": "Sat, 26 Jul 2014 22:03:37 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Vidal", "Thibaut", ""], ["Maculan", "Nelson", ""], ["Penna", "Puca Huachi Vaz", ""], ["Ochi", "Luis Satoru", ""]]}, {"id": "1401.3879", "submitter": "Emmanuel Hebrard", "authors": "Emmanuel Hebrard, D\\'aniel Marx, Barry O'Sullivan, Igor Razgon", "title": "Soft Constraints of Difference and Equality", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 41, pages\n  97-130, 2011", "doi": "10.1613/jair.3197", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many combinatorial problems one may need to model the diversity or\nsimilarity of assignments in a solution. For example, one may wish to maximise\nor minimise the number of distinct values in a solution. To formulate problems\nof this type, we can use soft variants of the well known AllDifferent and\nAllEqual constraints. We present a taxonomy of six soft global constraints,\ngenerated by combining the two latter ones and the two standard cost functions,\nwhich are either maximised or minimised. We characterise the complexity of\nachieving arc and bounds consistency on these constraints, resolving those\ncases for which NP-hardness was neither proven nor disproven. In particular, we\nexplore in depth the constraint ensuring that at least k pairs of variables\nhave a common value. We show that achieving arc consistency is NP-hard, however\nachieving bounds consistency can be done in polynomial time through dynamic\nprogramming. Moreover, we show that the maximum number of pairs of equal\nvariables can be approximated by a factor 1/2 with a linear time greedy\nalgorithm. Finally, we provide a fixed parameter tractable algorithm with\nrespect to the number of values appearing in more than two distinct domains.\nInterestingly, this taxonomy shows that enforcing equality is harder than\nenforcing difference.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 05:11:58 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Hebrard", "Emmanuel", ""], ["Marx", "D\u00e1niel", ""], ["O'Sullivan", "Barry", ""], ["Razgon", "Igor", ""]]}, {"id": "1401.3909", "submitter": "Richard Hoshino", "authors": "Richard Hoshino, Ken-ichi Kawarabayashi", "title": "Scheduling Bipartite Tournaments to Minimize Total Travel Distance", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 42, pages\n  91-124, 2011", "doi": "10.1613/jair.3388", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many professional sports leagues, teams from opposing leagues/conferences\ncompete against one another, playing inter-league games. This is an example of\na bipartite tournament. In this paper, we consider the problem of reducing the\ntotal travel distance of bipartite tournaments, by analyzing inter-league\nscheduling from the perspective of discrete optimization. This research has\nnatural applications to sports scheduling, especially for leagues such as the\nNational Basketball Association (NBA) where teams must travel long distances\nacross North America to play all their games, thus consuming much time, money,\nand greenhouse gas emissions. We introduce the Bipartite Traveling Tournament\nProblem (BTTP), the inter-league variant of the well-studied Traveling\nTournament Problem. We prove that the 2n-team BTTP is NP-complete, but for\nsmall values of n, a distance-optimal inter-league schedule can be generated\nfrom an algorithm based on minimum-weight 4-cycle-covers. We apply our\ntheoretical results to the 12-team Nippon Professional Baseball (NPB) league in\nJapan, producing a provably-optimal schedule requiring 42950 kilometres of\ntotal team travel, a 16% reduction compared to the actual distance traveled by\nthese teams during the 2010 NPB season. We also develop a nearly-optimal\ninter-league tournament for the 30-team NBA league, just 3.8% higher than the\ntrivial theoretical lower bound.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 05:24:01 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Hoshino", "Richard", ""], ["Kawarabayashi", "Ken-ichi", ""]]}, {"id": "1401.4245", "submitter": "Ekta Gupta", "authors": "Ekta Gupta, Kalyani and Nitin", "title": "Preserving the Basic Property of Stable Matching by Deleting a pair", "comments": "5 pages, 6 tables, 2 figures, International Conference in Distributed\n  Computing & Internet Technology (ICDCIT-2014)\n  http://www.ijcaonline.org/proceedings/icdcit2014/number1/14379-1303", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the transition of a male-pessimal matching set to\noptimal when it is a man-oriented approach by deleting a pair from matching set\nconsidering the score based approach. A descriptive explanation of the proposed\nalgorithm both in a sequential and parallel manner is given. The comparison\nbased theoretical analysis shows that the best case of the algorithm is lower\nbound of n3.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2014 05:56:23 GMT"}], "update_date": "2014-01-20", "authors_parsed": [["Gupta", "Ekta", ""], ["Kalyani", "", ""], ["Nitin", "", ""]]}, {"id": "1401.4605", "submitter": "J.H.M. Lee", "authors": "J.H.M. Lee, Ka Lun Leung", "title": "Consistency Techniques for Flow-Based Projection-Safe Global Cost\n  Functions in Weighted Constraint Satisfaction", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 43, pages\n  257-292, 2012", "doi": "10.1613/jair.3476", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many combinatorial problems deal with preferences and violations, the goal of\nwhich is to find solutions with the minimum cost. Weighted constraint\nsatisfaction is a framework for modeling such problems, which consists of a set\nof cost functions to measure the degree of violation or preferences of\ndifferent combinations of variable assignments. Typical solution methods for\nweighted constraint satisfaction problems (WCSPs) are based on branch-and-bound\nsearch, which are made practical through the use of powerful consistency\ntechniques such as AC*, FDAC*, EDAC* to deduce hidden cost information and\nvalue pruning during search. These techniques, however, are designed to be\nefficient only on binary and ternary cost functions which are represented in\ntable form. In tackling many real-life problems, high arity (or global) cost\nfunctions are required. We investigate efficient representation scheme and\nalgorithms to bring the benefits of the consistency techniques to also high\narity cost functions, which are often derived from hard global constraints from\nclassical constraint satisfaction. The literature suggests some global cost\nfunctions can be represented as flow networks, and the minimum cost flow\nalgorithm can be used to compute the minimum costs of such networks in\npolynomial time. We show that naive adoption of this flow-based algorithmic\nmethod for global cost functions can result in a stronger form of null-inverse\nconsistency. We further show how the method can be modified to handle cost\nprojections and extensions to maintain generalized versions of AC* and FDAC*\nfor cost functions with more than two variables. Similar generalization for the\nstronger EDAC* is less straightforward. We reveal the oscillation problem when\nenforcing EDAC* on cost functions sharing more than one variable. To avoid\noscillation, we propose a weak version of EDAC* and generalize it to weak\nEDGAC* for non-binary cost functions. Using various benchmarks involving the\nsoft variants of hard global constraints ALLDIFFERENT, GCC, SAME, and REGULAR,\nempirical results demonstrate that our proposal gives improvements of up to an\norder of magnitude when compared with the traditional constraint optimization\napproach, both in terms of time and pruning.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2014 21:10:22 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Lee", "J. H. M.", ""], ["Leung", "Ka Lun", ""]]}, {"id": "1401.4609", "submitter": "L\\'eon R. Planken", "authors": "L\\'eon R. Planken, Mathijs M. de Weerdt, Roman P.J. van der Krogt", "title": "Computing All-Pairs Shortest Paths by Leveraging Low Treewidth", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 43, pages\n  353-388, 2012", "doi": "10.1613/jair.3509", "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two new and efficient algorithms for computing all-pairs shortest\npaths. The algorithms operate on directed graphs with real (possibly negative)\nweights. They make use of directed path consistency along a vertex ordering d.\nBoth algorithms run in O(n^2 w_d) time, where w_d is the graph width induced by\nthis vertex ordering. For graphs of constant treewidth, this yields O(n^2)\ntime, which is optimal. On chordal graphs, the algorithms run in O(nm) time. In\naddition, we present a variant that exploits graph separators to arrive at a\nrun time of O(n w_d^2 + n^2 s_d) on general graphs, where s_d andlt= w_d is the\nsize of the largest minimal separator induced by the vertex ordering d. We show\nempirically that on both constructed and realistic benchmarks, in many cases\nthe algorithms outperform Floyd-Warshalls as well as Johnsons algorithm, which\nrepresent the current state of the art with a run time of O(n^3) and O(nm + n^2\nlog n), respectively. Our algorithms can be used for spatial and temporal\nreasoning, such as for the Simple Temporal Problem, which underlines their\nrelevance to the planning and scheduling community.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2014 21:23:48 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Planken", "L\u00e9on R.", ""], ["de Weerdt", "Mathijs M.", ""], ["van der Krogt", "Roman P. J.", ""]]}, {"id": "1401.4720", "submitter": "Bruno Grenet", "authors": "Bruno Grenet", "title": "Computing low-degree factors of lacunary polynomials: a Newton-Puiseux\n  approach", "comments": "22 pages", "journal-ref": "Proceedings of the 39th International Symposium on Symbolic and\n  Algebraic Computation (ISSAC'14), pp 224-231, ACM, 2014", "doi": "10.1145/2608628.2608649", "report-no": null, "categories": "cs.SC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for the computation of the irreducible factors of\ndegree at most $d$, with multiplicity, of multivariate lacunary polynomials\nover fields of characteristic zero. The algorithm reduces this computation to\nthe computation of irreducible factors of degree at most $d$ of univariate\nlacunary polynomials and to the factorization of low-degree multivariate\npolynomials. The reduction runs in time polynomial in the size of the input\npolynomial and in $d$. As a result, we obtain a new polynomial-time algorithm\nfor the computation of low-degree factors, with multiplicity, of multivariate\nlacunary polynomials over number fields, but our method also gives partial\nresults for other fields, such as the fields of $p$-adic numbers or for\nabsolute or approximate factorization for instance.\n  The core of our reduction uses the Newton polygon of the input polynomial,\nand its validity is based on the Newton-Puiseux expansion of roots of bivariate\npolynomials. In particular, we bound the valuation of $f(X,\\phi)$ where $f$ is\na lacunary polynomial and $\\phi$ a Puiseux series whose vanishing polynomial\nhas low degree.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2014 19:23:24 GMT"}, {"version": "v2", "created": "Tue, 24 Jun 2014 07:38:52 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Grenet", "Bruno", ""]]}, {"id": "1401.4739", "submitter": "Arash Rafiey", "authors": "Jan Manuch and Arash Rafiey", "title": "Finding minimum Tucker submatrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A binary matrix has the Consecutive Ones Property (C1P) if its columns can be\nordered in such a way that all 1s on each row are consecutive. These matrices\nare used for DNA physical mapping and ancestral genome reconstruction in\ncomputational biology on the other hand they represents a class of convex\nbipartite graphs and are of interest of algorithm graph theory researchers.\nTucker gave a forbidden submartices characterization of matrices that have C1P\nproperty in 1972. Booth and Lucker (1976) gave a first linear time recognition\nalgorithm for matrices with C1P property and then in 2002, Habib, et al. gave a\nsimpler linear time recognition algorithm. There has been substantial amount of\nworks on efficiently finding minimum size forbidden submatrix. Our algorithm is\nat least $n$ times faster than the existing algorithm where $n$ is the number\nof columns of the input matrix.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2014 21:24:33 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Manuch", "Jan", ""], ["Rafiey", "Arash", ""]]}, {"id": "1401.4931", "submitter": "Viresh Patel", "authors": "Daniela K\\\"uhn, Deryk Osthus, Viresh Patel", "title": "A domination algorithm for $\\{0,1\\}$-instances of the travelling\n  salesman problem", "comments": "29 pages (final version to appear in Random Structures and\n  Algorithms)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approximation algorithm for $\\{0,1\\}$-instances of the\ntravelling salesman problem which performs well with respect to combinatorial\ndominance. More precisely, we give a polynomial-time algorithm which has\ndomination ratio $1-n^{-1/29}$. In other words, given a\n$\\{0,1\\}$-edge-weighting of the complete graph $K_n$ on $n$ vertices, our\nalgorithm outputs a Hamilton cycle $H^*$ of $K_n$ with the following property:\nthe proportion of Hamilton cycles of $K_n$ whose weight is smaller than that of\n$H^*$ is at most $n^{-1/29}$. Our analysis is based on a martingale approach.\nPreviously, the best result in this direction was a polynomial-time algorithm\nwith domination ratio $1/2-o(1)$ for arbitrary edge-weights. We also prove a\nhardness result showing that, if the Exponential Time Hypothesis holds, there\nexists a constant $C$ such that $n^{-1/29}$ cannot be replaced by $\\exp(-(\\log\nn)^C)$ in the result above.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 15:07:35 GMT"}, {"version": "v2", "created": "Tue, 26 May 2015 10:28:30 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["K\u00fchn", "Daniela", ""], ["Osthus", "Deryk", ""], ["Patel", "Viresh", ""]]}, {"id": "1401.5014", "submitter": "Lee-Ad Gottlieb", "authors": "Lee-Ad Gottlieb and Shay Solomon", "title": "Light spanners for snowflake metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic result in the study of spanners is the existence of light\nlow-stretch spanners for Euclidean spaces. These spanners ahve arbitrary low\nstretch, and weight only a constant factor greater than that of the minimum\nspanning tree of the points (with dependence on the stretch and Euclidean\ndimention). A central open problem in this field asks whether other spaces\nadmit low weight spanners as well - for example metric space with low intrinsic\ndimension - yet only a handful of results of this type are known.\n  In this paper, we consider snowflake metric spaces of low intrinsic\ndimension. The {\\alpha}-snowflake of a metric (X,{\\delta}) is the metric\n(X,${\\delta}^{\\alpha}$) for 0<{\\alpha}<1. By utilizing an approach completely\ndifferent than those used for Euclidean spaces, we demonstrate that snowflake\nmetrics admit light spanners. Further, we show that the spanner is of diameter\nO($\\log$n), a result not possible for Euclidean spaces. As an immediate\ncorollary to our spanner, we obtain dramatic improvments in algorithms for the\ntraveling salesman problem in this setting, achieving a polynomial-time\napproximation scheme with near-linear runtime. Along the way, we show that all\n${\\ell}_p$ spaces admit light spanners, a result of interest in its own right.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 18:57:08 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Solomon", "Shay", ""]]}, {"id": "1401.5143", "submitter": "Yasuo Tabei", "authors": "Shirou Maruyama and Yasuo Tabei", "title": "Fully Online Grammar Compression in Constant Space", "comments": "This is an extended version of a proceeding accepted to Data\n  Compression Conference (DCC), 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel variants of fully online LCA (FOLCA), a fully online grammar\ncompression that builds a straight line program (SLP) and directly encodes it\ninto a succinct representation in an online manner. FOLCA enables a direct\nencoding of an SLP into a succinct representation that is asymptotically\nequivalent to an information theoretic lower bound for representing an SLP\n(Maruyama et al., SPIRE'13). The compression of FOLCA takes linear time\nproportional to the length of an input text and its working space depends only\non the size of the SLP, which enables us to apply FOLCA to large-scale\nrepetitive texts. Recent repetitive texts, however, include some noise. For\nexample, current sequencing technology has significant error rates, which\nembeds noise into genome sequences. For such noisy repetitive texts, FOLCA\nworking in the SLP size consumes a large amount of memory. We present two\nvariants of FOLCA working in constant space by leveraging the idea behind\nstream mining techniques. Experiments using 100 human genomes corresponding to\nabout 300GB from the 1000 human genomes project revealed the applicability of\nour method to large-scale, noisy repetitive texts.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 01:41:17 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2014 06:37:29 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Maruyama", "Shirou", ""], ["Tabei", "Yasuo", ""]]}, {"id": "1401.5269", "submitter": "Stephan Mertens", "authors": "Stephan Mertens", "title": "Stable Roommates Problem with Random Preferences", "comments": "14 pages, 6 figures, 4 algorithms, 1 table; Journal of Statistical\n  Mechanics: Theory and Experiment (2015) P01020", "journal-ref": null, "doi": "10.1088/1742-5468/2015/01/P01020", "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stable roommates problem with $n$ agents has worst case complexity\n$O(n^2)$ in time and space. Random instances can be solved faster and with less\nmemory, however. We introduce an algorithm that has average time and space\ncomplexity $O(n^\\frac{3}{2})$ for random instances. We use this algorithm to\nsimulate large instances of the stable roommates problem and to measure the\nprobabilty $p_n$ that a random instance of size $n$ admits a stable matching.\nOur data supports the conjecture that $p_n = \\Theta(n^{-1/4})$.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 11:16:51 GMT"}, {"version": "v2", "created": "Wed, 21 Jan 2015 11:54:09 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Mertens", "Stephan", ""]]}, {"id": "1401.5316", "submitter": "Hsin-Hao Su", "authors": "Hsin-Hao Su", "title": "A Distributed Minimum Cut Approximation Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of approximating the minimum cut in a\ndistributed message-passing model, the CONGEST model. The minimum cut problem\nhas been well-studied in the context of centralized algorithms. However, there\nwere no known non-trivial algorithms in the distributed model until the recent\nwork of Ghaffari and Kuhn. They gave algorithms for finding cuts of size\n$O(\\epsilon^{-1}\\lambda)$ and $(2+\\epsilon)\\lambda$ in\n$O(D)+\\tilde{O}(n^{1/2+\\epsilon})$ rounds and $\\tilde{O}(D+\\sqrt{n})$ rounds\nrespectively, where $\\lambda$ is the size of the minimum cut. This matches the\nlower bound they provided up to a polylogarithmic factor. Yet, no scheme that\nachieves $(1+\\epsilon)$-approximation ratio is known. We give a distributed\nalgorithm that finds a cut of size $(1+\\epsilon)\\lambda$ in\n$\\tilde{O}(D+\\sqrt{n})$ time, which is optimal up to polylogarithmic factors.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 13:39:38 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Su", "Hsin-Hao", ""]]}, {"id": "1401.5383", "submitter": "Rayan Chikhi", "authors": "Rayan Chikhi, Antoine Limasset, Shaun Jackman, Jared Simpson and Paul\n  Medvedev", "title": "On the representation of de Bruijn graphs", "comments": "Journal version (JCB). A preliminary version of this article was\n  published in the proceedings of RECOMB 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DS q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The de Bruijn graph plays an important role in bioinformatics, especially in\nthe context of de novo assembly. However, the representation of the de Bruijn\ngraph in memory is a computational bottleneck for many assemblers. Recent\npapers proposed a navigational data structure approach in order to improve\nmemory usage. We prove several theoretical space lower bounds to show the\nlimitation of these types of approaches. We further design and implement a\ngeneral data structure (DBGFM) and demonstrate its use on a human whole-genome\ndataset, achieving space usage of 1.5 GB and a 46% improvement over previous\napproaches. As part of DBGFM, we develop the notion of frequency-based\nminimizers and show how it can be used to enumerate all maximal simple paths of\nthe de Bruijn graph using only 43 MB of memory. Finally, we demonstrate that\nour approach can be integrated into an existing assembler by modifying the\nABySS software to use DBGFM.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 16:55:02 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2014 16:53:37 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2014 22:55:09 GMT"}, {"version": "v4", "created": "Mon, 6 Oct 2014 12:39:56 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Chikhi", "Rayan", ""], ["Limasset", "Antoine", ""], ["Jackman", "Shaun", ""], ["Simpson", "Jared", ""], ["Medvedev", "Paul", ""]]}, {"id": "1401.5512", "submitter": "Stefan Schneider", "authors": "Russell Impagliazzo, Shachar Lovett, Ramamohan Paturi, Stefan\n  Schneider", "title": "0-1 Integer Linear Programming with a Linear Number of Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an exact algorithm for the 0-1 Integer Linear Programming problem\nwith a linear number of constraints that improves over exhaustive search by an\nexponential factor. Specifically, our algorithm runs in time\n$2^{(1-\\text{poly}(1/c))n}$ where n is the number of variables and cn is the\nnumber of constraints. The key idea for the algorithm is a reduction to the\nVector Domination problem and a new algorithm for that subproblem.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 22:46:18 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2014 23:27:30 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Impagliazzo", "Russell", ""], ["Lovett", "Shachar", ""], ["Paturi", "Ramamohan", ""], ["Schneider", "Stefan", ""]]}, {"id": "1401.5677", "submitter": "Jianwen Li", "authors": "Jianwen Li, Geguang Pu, Lijun Zhang, Moshe Y. Vardi, Jifeng He", "title": "Fast LTL Satisfiability Checking by SAT Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satisfiability checking for Linear Temporal Logic (LTL) is a fundamental step\nin checking for possible errors in LTL assertions. Extant LTL satisfiability\ncheckers use a variety of different search procedures. With the sole exception\nof LTL satisfiability checking based on bounded model checking, which does not\nprovide a complete decision procedure, LTL satisfiability checkers have not\ntaken advantage of the remarkable progress over the past 20 years in Boolean\nsatisfiability solving. In this paper, we propose a new LTL\nsatisfiability-checking framework that is accelerated using a Boolean SAT\nsolver. Our approach is based on the variant of the \\emph{obligation-set\nmethod}, which we proposed in earlier work. We describe here heuristics that\nallow the use of a Boolean SAT solver to analyze the obligations for a given\nLTL formula. The experimental evaluation indicates that the new approach\nprovides a a significant performance advantage.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 14:10:04 GMT"}, {"version": "v2", "created": "Tue, 29 Apr 2014 11:18:19 GMT"}], "update_date": "2014-04-30", "authors_parsed": [["Li", "Jianwen", ""], ["Pu", "Geguang", ""], ["Zhang", "Lijun", ""], ["Vardi", "Moshe Y.", ""], ["He", "Jifeng", ""]]}, {"id": "1401.5707", "submitter": "Ariel Gabizon", "authors": "Ran Ben-Basat and Ariel Gabizon", "title": "Relations between automata and the simple k-path problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a directed graph on $n$ vertices. Given an integer $k<=n$, the\nSIMPLE $k$-PATH problem asks whether there exists a simple $k$-path in $G$. In\ncase $G$ is weighted, the MIN-WT SIMPLE $k$-PATH problem asks for a simple\n$k$-path in $G$ of minimal weight. The fastest currently known deterministic\nalgorithm for MIN-WT SIMPLE $k$-PATH by Fomin, Lokshtanov and Saurabh runs in\ntime $O(2.851^k\\cdot n^{O(1)}\\cdot \\log W)$ for graphs with integer weights in\nthe range $[-W,W]$. This is also the best currently known deterministic\nalgorithm for SIMPLE k-PATH- where the running time is the same without the\n$\\log W$ factor. We define $L_k(n)\\subseteq [n]^k$ to be the set of words of\nlength $k$ whose symbols are all distinct. We show that an explicit\nconstruction of a non-deterministic automaton (NFA) of size $f(k)\\cdot\nn^{O(1)}$ for $L_k(n)$ implies an algorithm of running time $O(f(k)\\cdot\nn^{O(1)}\\cdot \\log W)$ for MIN-WT SIMPLE $k$-PATH when the weights are\nnon-negative or the constructed NFA is acyclic as a directed graph. We show\nthat the algorithm of Kneis et al. and its derandomization by Chen et al. for\nSIMPLE $k$-PATH can be used to construct an acylic NFA for $L_k(n)$ of size\n$O^*(4^{k+o(k)})$.\n  We show, on the other hand, that any NFA for $L_k(n)$ must be size at least\n$2^k$. We thus propose closing this gap and determining the smallest NFA for\n$L_k(n)$ as an interesting open problem that might lead to faster algorithms\nfor MIN-WT SIMPLE $k$-PATH.\n  We use a relation between SIMPLE $k$-PATH and non-deterministic xor automata\n(NXA) to give another direction for a deterministic algorithm with running time\n$O^*(2^k)$ for SIMPLE $k$-PATH.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 15:45:57 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2014 14:47:10 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2014 22:52:38 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Ben-Basat", "Ran", ""], ["Gabizon", "Ariel", ""]]}, {"id": "1401.5814", "submitter": "Johannes Schneider", "authors": "Johannes Schneider and Michail Vlachos", "title": "On Randomly Projected Hierarchical Clustering with Guarantees", "comments": "This version contains the conference paper \"On Randomly Projected\n  Hierarchical Clustering with Guarantees'', SIAM International Conference on\n  Data Mining (SDM), 2014 and, additionally, proofs omitted in the conference\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering (HC) algorithms are generally limited to small data\ninstances due to their runtime costs. Here we mitigate this shortcoming and\nexplore fast HC algorithms based on random projections for single (SLC) and\naverage (ALC) linkage clustering as well as for the minimum spanning tree\nproblem (MST). We present a thorough adaptive analysis of our algorithms that\nimprove prior work from $O(N^2)$ by up to a factor of $N/(\\log N)^2$ for a\ndataset of $N$ points in Euclidean space. The algorithms maintain, with\narbitrary high probability, the outcome of hierarchical clustering as well as\nthe worst-case running-time guarantees. We also present parameter-free\ninstances of our algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 22:01:05 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Schneider", "Johannes", ""], ["Vlachos", "Michail", ""]]}, {"id": "1401.5820", "submitter": "David Morrison", "authors": "David R. Morrison, Edward C. Sewell, Sheldon H. Jacobson", "title": "Solving the Pricing Problem in a Branch-and-Price Algorithm for Graph\n  Coloring using Zero-Suppressed Binary Decision Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Branch-and-price algorithms combine a branch-and-bound search with an\nexponentially-sized LP formulation that must be solved via column generation.\nUnfortunately, the standard branching rules used in branch-and-bound for\ninteger programming interfere with the structure of the column generation\nroutine; therefore, most such algorithms employ alternate branching rules to\ncircumvent this difficulty. This paper shows how a zero-suppressed binary\ndecision diagram (ZDD) can be used to solve the pricing problem in a\nbranch-and-price algorithm for the graph coloring problem, even in the presence\nof constraints imposed by branching decisions. This approach facilitates a much\nmore direct solution method, and can improve convergence of the column\ngeneration subroutine.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 22:34:21 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 16:21:11 GMT"}], "update_date": "2015-07-09", "authors_parsed": [["Morrison", "David R.", ""], ["Sewell", "Edward C.", ""], ["Jacobson", "Sheldon H.", ""]]}, {"id": "1401.5842", "submitter": "Florian Zuleger", "authors": "Moritz Sinn, Florian Zuleger, Helmut Veith", "title": "A Simple and Scalable Static Analysis for Bound Analysis and Amortized\n  Complexity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first scalable bound analysis that achieves amortized\ncomplexity analysis. In contrast to earlier work, our bound analysis is not\nbased on general purpose reasoners such as abstract interpreters, software\nmodel checkers or computer algebra tools. Rather, we derive bounds directly\nfrom abstract program models, which we obtain from programs by comparatively\nsimple invariant generation and symbolic execution techniques. As a result, we\nobtain an analysis that is more predictable and more scalable than earlier\napproaches. Our experiments demonstrate that our analysis is fast and at the\nsame time able to compute bounds for challenging loops in a large real-world\nbenchmark. Technically, our approach is based on lossy vector addition systems\n(VASS). Our bound analysis first computes a lexicographic ranking function that\nproves the termination of a VASS, and then derives a bound from this ranking\nfunction. Our methodology achieves amortized analysis based on a new insight\nhow lexicographic ranking functions can be used for bound analysis.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 01:40:43 GMT"}, {"version": "v2", "created": "Mon, 2 Jun 2014 20:44:29 GMT"}], "update_date": "2014-06-04", "authors_parsed": [["Sinn", "Moritz", ""], ["Zuleger", "Florian", ""], ["Veith", "Helmut", ""]]}, {"id": "1401.5852", "submitter": "Priyankar Ghosh", "authors": "Priyankar Ghosh, Amit Sharma, P.P. Chakrabarti, Pallab Dasgupta", "title": "Algorithms for Generating Ordered Solutions for Explicit AND/OR\n  Structures", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 44, pages\n  275-333, 2012", "doi": "10.1613/jair.3576", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithms for generating alternative solutions for explicit\nacyclic AND/OR structures in non-decreasing order of cost. The proposed\nalgorithms use a best first search technique and report the solutions using an\nimplicit representation ordered by cost. In this paper, we present two versions\nof the search algorithm -- (a) an initial version of the best first search\nalgorithm, ASG, which may present one solution more than once while generating\nthe ordered solutions, and (b) another version, LASG, which avoids the\nconstruction of the duplicate solutions. The actual solutions can be\nreconstructed quickly from the implicit compact representation used. We have\napplied the methods on a few test domains, some of them are synthetic while the\nothers are based on well known problems including the search space of the 5-peg\nTower of Hanoi problem, the matrix-chain multiplication problem and the problem\nof finding secondary structure of RNA. Experimental results show the efficacy\nof the proposed algorithms over the existing approach. Our proposed algorithms\nhave potential use in various domains ranging from knowledge based frameworks\nto service composition, where the AND/OR structure is widely used for\nrepresenting problems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 02:44:07 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Ghosh", "Priyankar", ""], ["Sharma", "Amit", ""], ["Chakrabarti", "P. P.", ""], ["Dasgupta", "Pallab", ""]]}, {"id": "1401.6000", "submitter": "Raed Jaberi", "authors": "Raed Jaberi", "title": "On computing the $2$-vertex-connected components of directed graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of computing the $2$-vertex-connected\ncomponents ($2$-vccs) of directed graphs. We present two new algorithms for\nsolving this problem. The first algorithm runs in $O(mn^{2})$ time, the second\nin $O(nm)$ time. Furthermore, we show that the old algorithm of Erusalimskii\nand Svetlov runs in $O(nm^{2})$ time. In this paper, we investigate the\nrelationship between $2$-vccs and dominator trees. We also present an algorithm\nfor computing the $3$-vertex-connected components ($3$-vccs) of a directed\ngraph in $O(n^{3}m)$ time, and we show that the $k$-vertex-connected components\n($k$-vccs) of a directed graph can be computed in $O(mn^{2k-3})$ time. Finally,\nwe consider three applications of our new algorithms, which are approximation\nalgorithms for problems that are generalization of the problem of approximating\nthe smallest $2$-vertex-connected spanning subgraph of $2$-vertex-connected\ndirected graph.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 15:22:23 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Jaberi", "Raed", ""]]}, {"id": "1401.6054", "submitter": "Max Alekseyev", "authors": "Max A. Alekseyev", "title": "Computing the inverses, their power sums, and extrema for Euler's\n  totient and other multiplicative functions", "comments": null, "journal-ref": "Journal of Integer Sequences 19 (2016), Article 16.5.2", "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generic algorithm for computing the inverses of a multiplicative\nfunction under the assumption that the set of inverses is finite. More\ngenerally, our algorithm can compute certain functions of the inverses, such as\ntheir power sums (e.g., cardinality) or extrema, without direct enumeration of\nthe inverses. We illustrate our algorithm with Euler's totient function\n$\\varphi(\\cdot)$ and the $k$-th power sum of divisors $\\sigma_k(\\cdot)$. For\nexample, we can establish that the number of solutions to $\\sigma_1(x) =\n10^{1000}$ is 15,512,215,160,488,452,125,793,724,066,873,737,608,071,476, while\nit is intractable to iterate over the actual solutions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 17:03:45 GMT"}, {"version": "v2", "created": "Sat, 19 Apr 2014 00:42:49 GMT"}, {"version": "v3", "created": "Tue, 17 May 2016 14:20:06 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Alekseyev", "Max A.", ""]]}, {"id": "1401.6070", "submitter": "Adrian Dumitrescu", "authors": "Adrian Dumitrescu and Anirban Ghosh and Csaba D. T\\'oth", "title": "On Fence Patrolling by Mobile Agents", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that a fence needs to be protected (perpetually) by $k$ mobile agents\nwith maximum speeds $v_1,\\ldots,v_k$ so that no point on the fence is left\nunattended for more than a given amount of time. The problem is to determine if\nthis requirement can be met, and if so, to design a suitable patrolling\nschedule for the agents. Alternatively, one would like to find a schedule that\nminimizes the \\emph{idle time}, that is, the longest time interval during which\nsome point is not visited by any agent. We revisit this problem, introduced by\nCzyzowicz et al.(2011), and discuss several strategies for the cases where the\nfence is an open and a closed curve, respectively.\n  In particular: (i) we disprove a conjecture by Czyzowicz et al. regarding the\noptimality of their Algorithm ${\\mathcal A_2}$ for unidirectional patrolling of\na closed fence; (ii) we present an algorithm with a lower idle time for\npatrolling an open fence, improving an earlier result of Kawamura and\nKobayashi.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 17:56:52 GMT"}], "update_date": "2014-01-25", "authors_parsed": [["Dumitrescu", "Adrian", ""], ["Ghosh", "Anirban", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1401.6210", "submitter": "Pradeep Chathuranga Weeraddana", "authors": "Elisabetta Alfonsetti, Pradeep Chathuranga Weeraddana, Carlo Fischione", "title": "A Semi Distributed Approach for Min-Max Fair Car-Parking Slot Assignment\n  Problem", "comments": "14 pages, 12 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing efficient car parking mechanisms that can be potentially integrated\ninto future intelligent transportation systems is of crucial importance.\nUsually, the related design problems are combinatorial and the worst-case\ncomplexity of optimal solution approaches grows exponentially with the problem\nsizes. Therefore, such optimal approaches are not scalable and practically\nundesirable. As a result, almost all existing methods for parking slot\nassignment are simple and greedy approaches, where each car is assigned a free\nparking slot, which is closer to its destination. Moreover, no emphasis is\nplaced to optimize the social benefit of the users during the parking slot\nassignment. In this paper, the fairness as a metric for modeling the aggregate\nsocial benefit of the users is considered and a distributed algorithm based on\nLagrange duality theory is developed. The proposed algorithm is gracefully\nscalable compared to the optimal methods. In addition, it is shown that the\nproposed car parking mechanism preserves privacy in the sense that any car\ninvolved in the algorithm will not be able to discover the destination of any\nother car during the algorithm iterations. Numerical results illustrate the\nperformance of the proposed algorithm compared to the optimal assignment and a\ngreedy method. They show that our algorithm yields a good tradeoff between the\nimplementation-level simplicity and the performance. Even though the main\nemphasis in this paper resides in the car parking slot assignment problem, our\nformulation and the algorithms, in general, can also be applied or adopted in\nfair agent-target assignment problems in other application domains.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 23:00:56 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Alfonsetti", "Elisabetta", ""], ["Weeraddana", "Pradeep Chathuranga", ""], ["Fischione", "Carlo", ""]]}, {"id": "1401.6236", "submitter": "Michael Cohen", "authors": "Michael B. Cohen, Rasmus Kyng, Jakub W. Pachocki, Richard Peng, Anup\n  Rao", "title": "Preconditioning in Expectation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that preconditioners constructed by random sampling can perform well\nwithout meeting the standard requirements of iterative methods. When applied to\ngraph Laplacians, this leads to ultra-sparsifiers that in expectation behave as\nthe nearly-optimal ones given by [Kolla-Makarychev-Saberi-Teng STOC`10].\nCombining this with the recursive preconditioning framework by [Spielman-Teng\nSTOC`04] and improved embedding algorithms, this leads to algorithms that solve\nsymmetric diagonally dominant linear systems and electrical flow problems in\nexpected time close to $m\\log^{1/2}n$ .\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2014 01:37:37 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Cohen", "Michael B.", ""], ["Kyng", "Rasmus", ""], ["Pachocki", "Jakub W.", ""], ["Peng", "Richard", ""], ["Rao", "Anup", ""]]}, {"id": "1401.6346", "submitter": "Zsuzsanna Lipt\\'ak", "authors": "P\\'eter Burcsi and Gabriele Fici and Zsuzsanna Lipt\\'ak and Frank\n  Ruskey and Joe Sawada", "title": "On Combinatorial Generation of Prefix Normal Words", "comments": "12 pages, 5 figures", "journal-ref": "Combinatorial Pattern Matching 2014, LNCS 8464, 60-69", "doi": "10.1007/978-3-319-07566-2_7", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prefix normal word is a binary word with the property that no substring has\nmore 1s than the prefix of the same length. This class of words is important in\nthe context of binary jumbled pattern matching. In this paper we present an\nefficient algorithm for exhaustively listing the prefix normal words with a\nfixed length. The algorithm is based on the fact that the language of prefix\nnormal words is a bubble language, a class of binary languages with the\nproperty that, for any word w in the language, exchanging the first occurrence\nof 01 by 10 in w results in another word in the language. We prove that each\nprefix normal word is produced in O(n) amortized time, and conjecture, based on\nexperimental evidence, that the true amortized running time is O(polylog(n)).\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2014 14:30:35 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Burcsi", "P\u00e9ter", ""], ["Fici", "Gabriele", ""], ["Lipt\u00e1k", "Zsuzsanna", ""], ["Ruskey", "Frank", ""], ["Sawada", "Joe", ""]]}, {"id": "1401.6385", "submitter": "Songjian Lu", "authors": "Songjian Lu, Xinghua Lu", "title": "An exact algorithm for the weighed mutually exclusive maximum set cover\n  problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an exact algorithm with a time complexity of\n$O^*(1.325^m)$ for the {\\sc weighted mutually exclusive maximum set cover}\nproblem, where $m$ is the number of subsets in the problem. This is an NP-hard\nmotivated and abstracted from a bioinformatics problem of identifying signaling\npathways based gene mutations. Currently, this problem is addressed using\nheuristic algorithms, which cannot guarantee the performance of the solution.\nBy providing a relatively efficient exact algorithm, our approach will like\nincrease the capability of finding better solutions in the application of\ncancer research.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2014 16:00:34 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Lu", "Songjian", ""], ["Lu", "Xinghua", ""]]}, {"id": "1401.6423", "submitter": "Liu Hanlin", "authors": "Hanlin Liu", "title": "A Algorithm for the Hamilton Circuit Problem", "comments": "In this article, we try to find a algorithm for the hamilton circuit\n  problem. Unfortunately, it can not cover all cases of hamilton circuit\n  problem. So, it is a failed attempt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We proposed an algorithm that covers some cases of Hamilton Circuit Problem.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 12:56:05 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2014 04:35:33 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2014 16:59:58 GMT"}, {"version": "v4", "created": "Sat, 22 Feb 2014 16:47:04 GMT"}, {"version": "v5", "created": "Mon, 10 Mar 2014 14:27:54 GMT"}, {"version": "v6", "created": "Tue, 11 Mar 2014 05:34:46 GMT"}, {"version": "v7", "created": "Wed, 16 Apr 2014 11:12:47 GMT"}, {"version": "v8", "created": "Wed, 31 Oct 2018 10:45:21 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Liu", "Hanlin", ""]]}, {"id": "1401.6428", "submitter": "Thomas Voice", "authors": "Thomas Voice, Maria Polukarov, Nicholas R. Jennings", "title": "Coalition Structure Generation over Graphs", "comments": "arXiv admin note: text overlap with arXiv:1102.1747", "journal-ref": "Journal Of Artificial Intelligence Research, Volume 45, pages\n  165-196, 2012", "doi": "10.1613/jair.3715", "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the analysis of the computational complexity of coalition structure\ngeneration over graphs. Given an undirected graph G = (N,E) and a valuation\nfunction v : P(N) \\to R over the subsets of nodes, the problem is to find a\npartition of N into connected subsets, that maximises the sum of the components\nvalues. This problem is generally NP-complete; in particular, it is hard for a\ndefined class of valuation functions which are independent of disconnected\nmembers - that is, two nodes have no effect on each other's marginal\ncontribution to their vertex separator. Nonetheless, for all such functions we\nprovide bounds on the complexity of coalition structure generation over general\nand minor-free graphs. Our proof is constructive and yields algorithms for\nsolving corresponding instances of the problem. Furthermore, we derive linear\ntime bounds for graphs of bounded treewidth. However, as we show, the problem\nremains NP-complete for planar graphs, and hence, for any K_k minor free graphs\nwhere k \\geq 5. Moreover, a 3-SAT problem with m clauses can be represented by\na coalition structure generation problem over a planar graph with O(m^2) nodes.\nImportantly, our hardness result holds for a particular subclass of valuation\nfunctions, termed edge sum, where the value of each subset of nodes is simply\ndetermined by the sum of given weights of the edges in the induced subgraph.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 16:45:24 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Voice", "Thomas", ""], ["Polukarov", "Maria", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1401.6483", "submitter": "Hu Qin", "authors": "Zhixin Luo and Hu Qin and Wenbin Zhu and Andrew Lim", "title": "Branch-and-price-and-cut for the Split-collection Vehicle Routing\n  Problem with Time Windows and Linear Weight-related Cost", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a new vehicle routing problem that simultaneously\ninvolves time windows, split collection and linear weight-related cost, which\nis a generalization of the split delivery vehicle routing problem with time\nwindows (SDVRPTW). This problem consists of determining least-cost vehicle\nroutes to serve a set of customers while respecting the restrictions of vehicle\ncapacity and time windows. The travel cost per unit distance is a linear\nfunction of the vehicle weight and the customer demand can be fulfilled by\nmultiple vehicles. To solve this problem, we propose a exact\nbranch-and-price-and-cut algorithm, where the pricing subproblem is a\nresource-constrained elementary least-cost path problem. We first prove that at\nleast an optimal solution to the pricing subproblem is associated with an\nextreme collection pattern, and then design a tailored and novel label-setting\nalgorithm to solve it. Computational results show that our proposed algorithm\ncan handle both the SDVRPTW and our problem effectively.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2014 01:38:49 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Luo", "Zhixin", ""], ["Qin", "Hu", ""], ["Zhu", "Wenbin", ""], ["Lim", "Andrew", ""]]}, {"id": "1401.6523", "submitter": "Haris Aziz", "authors": "Haris Aziz and Serge Gaspers and Nick Mattei and Nina Narodytska and\n  Toby Walsh", "title": "Strategic aspects of the probabilistic serial rule for the allocation of\n  goods", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probabilistic serial (PS) rule is one of the most prominent randomized\nrules for the assignment problem. It is well-known for its superior fairness\nand welfare properties. However, PS is not immune to manipulative behaviour by\nthe agents. We examine computational and non-computational aspects of\nstrategising under the PS rule. Firstly, we study the computational complexity\nof an agent manipulating the PS rule. We present polynomial-time algorithms for\noptimal manipulation. Secondly, we show that expected utility best responses\ncan cycle. Thirdly, we examine the existence and computation of Nash\nequilibrium profiles under the PS rule. We show that a pure Nash equilibrium is\nguaranteed to exist under the PS rule. For two agents, we identify two\ndifferent types of preference profiles that are not only in Nash equilibrium\nbut can also be computed in linear time. Finally, we conduct experiments to\ncheck the frequency of manipulability of the PS rule under different\ncombinations of the number of agents, objects, and utility functions.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2014 12:11:09 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Aziz", "Haris", ""], ["Gaspers", "Serge", ""], ["Mattei", "Nick", ""], ["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1401.6596", "submitter": "Sadi Seker E", "authors": "Sadi Evren Seker, Oguz Altun, U\\u{g}ur Ayan and Cihan Mert", "title": "A Novel String Distance Function based on Most Frequent K Characters", "comments": null, "journal-ref": "International Journal of Machine Learning and Computation (IJMLC),\n  Issn : 2010-3700, vol.4, is.2, pp.177-183, 2014", "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study aims to publish a novel similarity metric to increase the speed of\ncomparison operations. Also the new metric is suitable for distance-based\noperations among strings. Most of the simple calculation methods, such as\nstring length are fast to calculate but does not represent the string\ncorrectly. On the other hand the methods like keeping the histogram over all\ncharacters in the string are slower but good to represent the string\ncharacteristics in some areas, like natural language. We propose a new metric,\neasy to calculate and satisfactory for string comparison. Method is built on a\nhash function, which gets a string at any size and outputs the most frequent K\ncharacters with their frequencies. The outputs are open for comparison and our\nstudies showed that the success rate is quite satisfactory for the text mining\noperations.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2014 23:40:46 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Seker", "Sadi Evren", ""], ["Altun", "Oguz", ""], ["Ayan", "U\u011fur", ""], ["Mert", "Cihan", ""]]}, {"id": "1401.6694", "submitter": "Daniel Roche", "authors": "Andrew Arnold, Daniel S. Roche", "title": "Multivariate sparse interpolation using randomized Kronecker\n  substitutions", "comments": "21 pages, 2 tables, 1 procedure. Accepted to ISSAC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.DS cs.MS", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We present new techniques for reducing a multivariate sparse polynomial to a\nunivariate polynomial. The reduction works similarly to the classical and\nwidely-used Kronecker substitution, except that we choose the degrees randomly\nbased on the number of nonzero terms in the multivariate polynomial, that is,\nits sparsity. The resulting univariate polynomial often has a significantly\nlower degree than the Kronecker substitution polynomial, at the expense of a\nsmall number of term collisions. As an application, we give a new algorithm for\nmultivariate interpolation which uses these new techniques along with any\nexisting univariate interpolation algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2014 21:37:51 GMT"}, {"version": "v2", "created": "Fri, 2 May 2014 05:01:05 GMT"}], "update_date": "2014-05-05", "authors_parsed": [["Arnold", "Andrew", ""], ["Roche", "Daniel S.", ""]]}, {"id": "1401.6697", "submitter": "Yuli Ye", "authors": "Allan Borodin, Dai Tri Man Le and Yuli Ye", "title": "Weakly Submodular Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions are well-studied in combinatorial optimization, game\ntheory and economics. The natural diminishing returns property makes them\nsuitable for many applications. We study an extension of monotone submodular\nfunctions, which we call {\\em weakly submodular functions}. Our extension\nincludes some (mildly) supermodular functions. We show that several natural\nfunctions belong to this class and relate our class to some other recent\nsubmodular function extensions.\n  We consider the optimization problem of maximizing a weakly submodular\nfunction subject to uniform and general matroid constraints. For a uniform\nmatroid constraint, the \"standard greedy algorithm\" achieves a constant\napproximation ratio where the constant (experimentally) converges to 5.95 as\nthe cardinality constraint increases. For a general matroid constraint, a\nsimple local search algorithm achieves a constant approximation ratio where the\nconstant (analytically) converges to 10.22 as the rank of the matroid\nincreases.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2014 21:48:39 GMT"}, {"version": "v2", "created": "Wed, 2 Apr 2014 03:11:01 GMT"}, {"version": "v3", "created": "Mon, 21 Jul 2014 03:22:36 GMT"}, {"version": "v4", "created": "Wed, 30 Jul 2014 16:26:22 GMT"}, {"version": "v5", "created": "Sun, 16 Nov 2014 23:46:08 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Borodin", "Allan", ""], ["Le", "Dai Tri Man", ""], ["Ye", "Yuli", ""]]}, {"id": "1401.6757", "submitter": "Tomer Koren", "authors": "Elad Hazan, Tomer Koren", "title": "A Linear-Time Algorithm for Trust Region Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental problem of maximizing a general quadratic\nfunction over an ellipsoidal domain, also known as the trust region problem. We\ngive the first provable linear-time (in the number of non-zero entries of the\ninput) algorithm for approximately solving this problem. Specifically, our\nalgorithm returns an $\\epsilon$-approximate solution in time\n$\\tilde{O}(N/\\sqrt{\\epsilon})$, where $N$ is the number of non-zero entries in\nthe input. This matches the runtime of Nesterov's accelerated gradient descent,\nsuitable for the special case in which the quadratic function is concave, and\nthe runtime of the Lanczos method which is applicable when the problem is\npurely quadratic.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 07:40:26 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Hazan", "Elad", ""], ["Koren", "Tomer", ""]]}, {"id": "1401.6961", "submitter": "Matt Challacombe", "authors": "Matt Challacombe and Nicolas Bock", "title": "An N-Body Solution to the Problem of Fock Exchange", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": "10.1063/1.4868636", "report-no": "LA-UR-14-20354", "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We report an N-Body approach to computing the Fock exchange matrix with and\nwithout permutational symmetry. The method achieves an O(N lg N) computational\ncomplexity through an embedded metric-query, allowing hierarchical application\nof direct SCF criteria. The advantages of permutational symmetry are found to\nbe 4-fold for small systems, but decreasing with increasing system size and/or\nmore permissive neglect criteria. This work sets the stage for: (1) the\nintroduction of range queries in multi-level multipole schemes for rank\nreduction, and (2) recursive task parallelism.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 18:56:47 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Challacombe", "Matt", ""], ["Bock", "Nicolas", ""]]}, {"id": "1401.6963", "submitter": "Fern Hunt Dr", "authors": "Fern Y. Hunt", "title": "Optimal Spread in Network Consensus Models", "comments": "6 pages, 4 figures. This paper replaces an earlier version. The\n  entire paper has been rewritten. In addition to the results of the previous\n  version, a normalized submodular function is introduced and is used to obtain\n  a performance ratio for our algorithm. We also provide a comparison with the\n  approximation obtained using the greedy algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In a model of network communication based on a random walk in an undirected\ngraph, what subset of nodes (subject to constraints on the set size), enable\nthe fastest spread of information? The dynamics of spread is described by a\nprocess dual to the movement from informed to uninformed nodes. In this\nsetting, an optimal set $A$ minimizes the sum of the expected first hitting\ntimes $F(A)$, of random walks that start at nodes outside the set.\n  In this paper,the problem is reformulated so that the search for solutions is\nrestricted to a class of optimal and \"near\" optimal subsets of the graph. We\nintroduce a submodular, non-decreasing rank function $\\rho$, that permits some\ncomparison between the solution obtained by the classical greedy algorithm and\none obtained by our methods. The supermodularity and non-increasing properties\nof $F$ are used to show that the rank of our solution is at least\n$(1-\\frac{1}{e})$ times the rank of the optimal set. When the solution has a\nhigher rank than the greedy solution this constant can be improved to\n$(1-\\frac{1}{e})(1+\\chi)$ where $\\chi >0$ is determined a posteriori. The\nmethod requires the evaluation of $F$ for sets of some fixed cardinality $m$,\nwhere $m$ is much smaller than the cardinality of the optimal set. When $F$ has\nforward elemental curvature $\\kappa$, we can provide a rough description of the\ntrade-off between solution quality and computational effort $m$ in terms of\n$\\kappa$.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 19:00:44 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2014 14:30:29 GMT"}, {"version": "v3", "created": "Thu, 7 May 2015 17:46:17 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2016 17:13:35 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Hunt", "Fern Y.", ""]]}, {"id": "1401.6981", "submitter": "Nicolas Kourtellis Ph.D.", "authors": "Nicolas Kourtellis, Gianmarco De Francisci Morales, Francesco Bonchi", "title": "Scalable Online Betweenness Centrality in Evolving Graphs", "comments": "15 pages, 9 Figures, accepted for publication in IEEE Transactions on\n  Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Betweenness centrality is a classic measure that quantifies the importance of\na graph element (vertex or edge) according to the fraction of shortest paths\npassing through it. This measure is notoriously expensive to compute, and the\nbest known algorithm runs in O(nm) time. The problems of efficiency and\nscalability are exacerbated in a dynamic setting, where the input is an\nevolving graph seen edge by edge, and the goal is to keep the betweenness\ncentrality up to date. In this paper we propose the first truly scalable\nalgorithm for online computation of betweenness centrality of both vertices and\nedges in an evolving graph where new edges are added and existing edges are\nremoved. Our algorithm is carefully engineered with out-of-core techniques and\ntailored for modern parallel stream processing engines that run on clusters of\nshared-nothing commodity hardware. Hence, it is amenable to real-world\ndeployment. We experiment on graphs that are two orders of magnitude larger\nthan previous studies. Our method is able to keep the betweenness centrality\nmeasures up to date online, i.e., the time to update the measures is smaller\nthan the inter-arrival time between two consecutive updates.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 19:50:47 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2015 16:22:52 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Kourtellis", "Nicolas", ""], ["Morales", "Gianmarco De Francisci", ""], ["Bonchi", "Francesco", ""]]}, {"id": "1401.7110", "submitter": "Zhengjun Cao", "authors": "Zhengjun Cao and Lihua Liu", "title": "A Fast String Matching Algorithm Based on Lowlight Characters in the\n  Pattern", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We put forth a new string matching algorithm which matches the pattern from\nneither the left nor the right end, instead a special position. Comparing with\nthe Knuth-Morris-Pratt algorithm and the Boyer-Moore algorithm, the new\nalgorithm is more flexible to pick the position for starting comparisons. The\noption really brings it a saving in cost.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 08:27:19 GMT"}], "update_date": "2014-01-29", "authors_parsed": [["Cao", "Zhengjun", ""], ["Liu", "Lihua", ""]]}, {"id": "1401.7263", "submitter": "William Bradley", "authors": "William F. Bradley", "title": "Superconcentration on a Pair of Butterflies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we concatenate two directed graphs, each isomorphic to a $d$\ndimensional butterfly (but not necessarily identical to each other). Select any\nset of $2^k$ input and $2^k$ output nodes on the resulting graph. Then there\nexist node disjoint paths from the input nodes to the output nodes. If we take\ntwo standard butterflies and permute the order of the layers, then the result\nholds on sets of any size, not just powers of two.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 17:10:24 GMT"}], "update_date": "2014-01-29", "authors_parsed": [["Bradley", "William F.", ""]]}, {"id": "1401.7284", "submitter": "Janardhan Kulkarni", "authors": "Nikhil Bansal, Janardhan Kulkarni", "title": "Minimizing Flow-Time on Unrelated Machines", "comments": "The new version fixes some typos in the previous version. The paper\n  is accepted for publication in STOC 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider some flow-time minimization problems in the unrelated machines\nsetting. In this setting, there is a set of $m$ machines and a set of $n$ jobs,\nand each job $j$ has a machine dependent processing time of $p_{ij}$ on machine\n$i$. The flow-time of a job is the total time the job spends in the system\n(completion time minus its arrival time), and is one of the most natural\nquality of service measure. We show the following two results: an\n$O(\\min(\\log^2 n,\\log n \\log P))$ approximation algorithm for minimizing the\ntotal-flow time, and an $O(\\log n)$ approximation for minimizing the maximum\nflow-time. Here $P$ is the ratio of maximum to minimum job size. These are the\nfirst known poly-logarithmic guarantees for both the problems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 18:09:20 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2015 23:01:10 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Bansal", "Nikhil", ""], ["Kulkarni", "Janardhan", ""]]}, {"id": "1401.7304", "submitter": "Rishab Nithyanand", "authors": "Rishab Nithyanand, Jonathan Toohill, Rob Johnson", "title": "How Best to Handle a Dicey Situation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the {Destructive Object Handling} (DOH) problem, which models\naspects of many real-world allocation problems, such as shipping explosive\nmunitions, scheduling processes in a cluster with fragile nodes, re-using\npasswords across multiple websites, and quarantining patients during a disease\noutbreak. In these problems, objects must be assigned to handlers, but each\nobject has a probability of destroying itself and all the other objects\nallocated to the same handler. The goal is to maximize the expected value of\nthe objects handled successfully.\n  We show that finding the optimal allocation is\n$\\mathsf{NP}$-$\\mathsf{complete}$, even if all the handlers are identical. We\npresent an FPTAS when the number of handlers is constant. We note in passing\nthat the same technique also yields a first FPTAS for the weapons-target\nallocation problem \\cite{manne_wta} with a constant number of targets. We study\nthe structure of DOH problems and find that they have a sort of phase\ntransition -- in some instances it is better to spread risk evenly among the\nhandlers, in others, one handler should be used as a ``sacrificial lamb''. We\nshow that the problem is solvable in polynomial time if the destruction\nprobabilities depend only on the handler to which an object is assigned; if all\nthe handlers are identical and the objects all have the same value; or if each\nhandler can be assigned at most one object.\n  Finally, we empirically evaluate several heuristics based on a combination of\ngreedy and genetic algorithms. The proposed heuristics return fairly high\nquality solutions to very large problem instances (upto 250 objects and 100\nhandlers) in tens of seconds.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 19:31:57 GMT"}], "update_date": "2014-01-29", "authors_parsed": [["Nithyanand", "Rishab", ""], ["Toohill", "Jonathan", ""], ["Johnson", "Rob", ""]]}, {"id": "1401.7416", "submitter": "Pandiselvam Pps", "authors": "Pandiselvam.P, Marimuthu.T and Lawrance.R", "title": "A Comparative Study on String Matching Algorithm of Biological Sequences", "comments": "Selected For International Conference on Intelligent Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  String matching algorithm plays the vital role in the Computational Biology.\nThe functional and structural relationship of the biological sequence is\ndetermined by similarities on that sequence. For that, the researcher is\nsupposed to aware of similarities on the biological sequences. Pursuing of\nsimilarity among biological sequences is an important research area of that can\nbring insight into the evolutionary and genetic relationships among the genes.\nIn this paper, we have studied different kinds of string matching algorithms\nand observed their time and space complexities. For this study, we have\nassessed the performance of algorithms tested with biological sequences.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 05:39:11 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["P", "Pandiselvam.", ""], ["T", "Marimuthu.", ""], ["R", "Lawrance.", ""]]}, {"id": "1401.7457", "submitter": "Ruibang Luo", "authors": "Chi-Man Liu, Ruibang Luo, Tak-Wah Lam", "title": "GPU-Accelerated BWT Construction for Large Collection of Short Reads", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.DC cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in DNA sequencing technology have stimulated the development of\nalgorithms and tools for processing very large collections of short strings\n(reads). Short-read alignment and assembly are among the most well-studied\nproblems. Many state-of-the-art aligners, at their core, have used the\nBurrows-Wheeler transform (BWT) as a main-memory index of a reference genome\n(typical example, NCBI human genome). Recently, BWT has also found its use in\nstring-graph assembly, for indexing the reads (i.e., raw data from DNA\nsequencers). In a typical data set, the volume of reads is tens of times of the\nsequenced genome and can be up to 100 Gigabases. Note that a reference genome\nis relatively stable and computing the index is not a frequent task. For reads,\nthe index has to computed from scratch for each given input. The ability of\nefficient BWT construction becomes a much bigger concern than before. In this\npaper, we present a practical method called CX1 for constructing the BWT of\nvery large string collections. CX1 is the first tool that can take advantage of\nthe parallelism given by a graphics processing unit (GPU, a relative cheap\ndevice providing a thousand or more primitive cores), as well as simultaneously\nthe parallelism from a multi-core CPU and more interestingly, from a cluster of\nGPU-enabled nodes. Using CX1, the BWT of a short-read collection of up to 100\nGigabases can be constructed in less than 2 hours using a machine equipped with\na quad-core CPU and a GPU, or in about 43 minutes using a cluster with 4 such\nmachines (the speedup is almost linear after excluding the first 16 minutes for\nloading the reads from the hard disk). The previously fastest tool BRC is\nmeasured to take 12 hours to process 100 Gigabases on one machine; it is\nnon-trivial how BRC can be parallelized to take advantage a cluster of\nmachines, let alone GPUs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 10:06:07 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Liu", "Chi-Man", ""], ["Luo", "Ruibang", ""], ["Lam", "Tak-Wah", ""]]}, {"id": "1401.7471", "submitter": "Massimo Cafaro", "authors": "Massimo Cafaro and Piergiuseppe Pell\\`e", "title": "Space-efficient Verifiable Secret Sharing Using Polynomial Interpolation", "comments": "Accepted for publication. To appear in IEEE Transactions on Cloud\n  Computing", "journal-ref": null, "doi": "10.1109/TCC.2015.2396072", "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preserving data confidentiality in clouds is a key issue. Secret Sharing, a\ncryptographic primitive for the distribution of a secret among a group of $n$\nparticipants designed so that only subsets of shareholders of cardinality $0 <\nt \\leq n$ are allowed to reconstruct the secret by pooling their shares, can\nhelp mitigating and minimizing the problem. A desirable feature of Secret\nSharing schemes is cheater detection, i.e. the ability to detect one or more\nmalicious shareholders trying to reconstruct the secret by obtaining legal\nshares from the other shareholders while providing them with fake shares.\nVerifiable Secret Sharing schemes solve this problem by allowing shareholders\nverifying the others' shares. We present new verification algorithms providing\narbitrary secret sharing schemes with cheater detection capabilities, and prove\ntheir space efficiency with regard to other schemes appeared in the literature.\nWe also introduce, in one of our schemes, the Exponentiating Polynomial Root\nProblem (EPRP), which is believed to be NP-Intermediate and therefore\ndifficult.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 11:03:33 GMT"}, {"version": "v2", "created": "Fri, 12 Sep 2014 10:17:42 GMT"}, {"version": "v3", "created": "Wed, 3 Dec 2014 16:33:04 GMT"}, {"version": "v4", "created": "Mon, 22 Dec 2014 16:06:31 GMT"}, {"version": "v5", "created": "Mon, 16 Feb 2015 18:01:29 GMT"}, {"version": "v6", "created": "Thu, 3 Sep 2015 08:19:26 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Cafaro", "Massimo", ""], ["Pell\u00e8", "Piergiuseppe", ""]]}, {"id": "1401.7540", "submitter": "Somnath Sikdar", "authors": "Felix Reidl, Peter Rossmanith, Fernando Sanchez Villaamil, Somnath\n  Sikdar", "title": "A Faster Parameterized Algorithm for Treedepth", "comments": "An extended abstract was published in ICALP 2014, Track A", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The width measure \\emph{treedepth}, also known as vertex ranking, centered\ncoloring and elimination tree height, is a well-established notion which has\nrecently seen a resurgence of interest. We present an algorithm which---given\nas input an $n$-vertex graph, a tree decomposition of the graph of width $w$,\nand an integer $t$---decides Treedepth, i.e. whether the treedepth of the graph\nis at most $t$, in time $2^{O(wt)} \\cdot n$. If necessary, a witness structure\nfor the treedepth can be constructed in the same running time. In conjunction\nwith previous results we provide a simple algorithm and a fast algorithm which\ndecide treedepth in time $2^{2^{O(t)}} \\cdot n$ and $2^{O(t^2)} \\cdot n$,\nrespectively, which do not require a tree decomposition as part of their input.\nThe former answers an open question posed by Ossona de Mendez and Nesetril as\nto whether deciding Treedepth admits an algorithm with a linear running time\n(for every fixed $t$) that does not rely on Courcelle's Theorem or other heavy\nmachinery. For chordal graphs we can prove a running time of $2^{O(t \\log\nt)}\\cdot n$ for the same algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 15:26:04 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2014 14:05:37 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2014 09:05:49 GMT"}, {"version": "v4", "created": "Wed, 20 Aug 2014 08:54:18 GMT"}], "update_date": "2014-08-21", "authors_parsed": [["Reidl", "Felix", ""], ["Rossmanith", "Peter", ""], ["Villaamil", "Fernando Sanchez", ""], ["Sikdar", "Somnath", ""]]}, {"id": "1401.7591", "submitter": "Luigi Laura", "authors": "Camil Demetrescu and Irene Finocchi and Giuseppe F. Italiano and Luigi\n  Laura", "title": "Experimental Evaluation of Algorithms for the Food-Selection Problem", "comments": "This paper discuss the problem of eating good food in Rome :-) This\n  is the latest version, the one that has been distributed to people\n  participants of the SEA 2013 conference. Previous versions of this paper have\n  been distributed to participants of FOCS 2004, CIAC 2006, ICTCS 2007, WEA\n  2007, WINE 2009, OPODIS 2012, and WSDM 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the result of our experiments on Algorithms for\nthe Food-Selection Problem, which is the fundamental problem first stated and\naddressed in the seminal paper \\cite{pigout}. Because the key aspect of any\nexperimental evaluation is the \\textbf{reproducibility}, we detail deeply the\nsetup of all our experiments, thus leaving to the interested eater the\nopportunity to reproduce all the results described in this paper. More\nspecifically, we describe all the answers we provided to the questions proposed\nin \\cite{pigout}: Where can I have dinner tonight? What is the typical Roman\ncuisine that I should (not) miss? Where can I find the best coffee or gelato in\ntown?\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 17:09:12 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Demetrescu", "Camil", ""], ["Finocchi", "Irene", ""], ["Italiano", "Giuseppe F.", ""], ["Laura", "Luigi", ""]]}, {"id": "1401.7594", "submitter": "Ching-Chi Lin", "authors": "Ching-Chi Lin and Hai-Lun Tu", "title": "Linear-Time Algorithms for the Paired-Domination Problem in Interval\n  Graphs and Circular-Arc Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a graph $G$, a vertex subset $S\\subseteq V(G)$ is said to be a dominating\nset of $G$ if every vertex not in $S$ is adjacent to a vertex in $S$. A\ndominating set $S$ of a graph $G$ is called a paired-dominating set if the\ninduced subgraph $G[S]$ contains a perfect matching. The paired-domination\nproblem involves finding a smallest paired-dominating set of $G$. Given an\nintersection model of an interval graph $G$ with sorted endpoints, Cheng et al.\ndesigned an $O(m+n)$-time algorithm for interval graphs and an $O(m(m+n))$-time\nalgorithm for circular-arc graphs. In this paper, to solve the\npaired-domination problem in interval graphs, we propose an $O(n)$-time\nalgorithm that searches for a minimum paired-dominating set of $G$\nincrementally in a greedy manner. Then, we extend the results to design an\nalgorithm for circular-arc graphs that also runs in $O(n)$ time.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 17:23:13 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Lin", "Ching-Chi", ""], ["Tu", "Hai-Lun", ""]]}, {"id": "1401.7616", "submitter": "Michael Mitzenmacher", "authors": "Michael Mitzenmacher", "title": "A New Approach to Analyzing Robin Hood Hashing", "comments": "19 pages, draft version. Updated from the previous version with some\n  new proofs, in particular a full proof of the log log n + O(1) maximum age\n  bound in the static setting, by converting the fluid limit argument into a\n  layered induction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robin Hood hashing is a variation on open addressing hashing designed to\nreduce the maximum search time as well as the variance in the search time for\nelements in the hash table. While the case of insertions only using Robin Hood\nhashing is well understood, the behavior with deletions has remained open. Here\nwe show that Robin Hood hashing can be analyzed under the framework of\nfinite-level finite-dimensional jump Markov chains. This framework allows us to\nre-derive some past results for the insertion-only case with some new insight,\nas well as provide a new analysis for a standard deletion model, where we\nalternate between deleting a random old key and inserting a new one. In\nparticular, we show that a simple but apparently unstudied approach for\nhandling deletions with Robin Hood hashing offers good performance even under\nhigh loads.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 18:31:36 GMT"}, {"version": "v2", "created": "Fri, 11 Jul 2014 01:27:08 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Mitzenmacher", "Michael", ""]]}, {"id": "1401.7623", "submitter": "Alex Bronstein", "authors": "Yonathan Aflalo, Alex Bronstein, Ron Kimmel", "title": "Graph matching: relax or not?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of exact and inexact matching of weighted undirected\ngraphs, in which a bijective correspondence is sought to minimize a quadratic\nweight disagreement. This computationally challenging problem is often relaxed\nas a convex quadratic program, in which the space of permutations is replaced\nby the space of doubly-stochastic matrices. However, the applicability of such\na relaxation is poorly understood. We define a broad class of friendly graphs\ncharacterized by an easily verifiable spectral property. We prove that for\nfriendly graphs, the convex relaxation is guaranteed to find the exact\nisomorphism or certify its inexistence. This result is further extended to\napproximately isomorphic graphs, for which we develop an explicit bound on the\namount of weight disagreement under which the relaxation is guaranteed to find\nthe globally optimal approximate isomorphism. We also show that in many cases,\nthe graph matching problem can be further harmlessly relaxed to a convex\nquadratic program with only n separable linear equality constraints, which is\nsubstantially more efficient than the standard relaxation involving 2n equality\nand n^2 inequality constraints. Finally, we show that our results are still\nvalid for unfriendly graphs if additional information in the form of seeds or\nattributes is allowed, with the latter satisfying an easy to verify spectral\ncharacteristic.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 18:59:06 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2014 13:41:56 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2014 21:39:57 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2014 12:51:21 GMT"}, {"version": "v5", "created": "Sun, 12 Oct 2014 22:27:57 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Aflalo", "Yonathan", ""], ["Bronstein", "Alex", ""], ["Kimmel", "Ron", ""]]}, {"id": "1401.7714", "submitter": "Francois Le Gall", "authors": "Fran\\c{c}ois Le Gall", "title": "Powers of Tensors and Fast Matrix Multiplication", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method to analyze the powers of a given trilinear form\n(a special kind of algebraic constructions also called a tensor) and obtain\nupper bounds on the asymptotic complexity of matrix multiplication. Compared\nwith existing approaches, this method is based on convex optimization, and thus\nhas polynomial-time complexity. As an application, we use this method to study\npowers of the construction given by Coppersmith and Winograd [Journal of\nSymbolic Computation, 1990] and obtain the upper bound $\\omega<2.3728639$ on\nthe exponent of square matrix multiplication, which slightly improves the best\nknown upper bound.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 01:11:22 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""]]}, {"id": "1401.7741", "submitter": "Mevlut Bulut Dr", "authors": "Mevlut Bulut", "title": "ReducedCBT and SuperCBT, Two New and Improved Complete Binary Tree\n  Structures", "comments": "12 pages research paper, contains 6 figures and a table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Between the leaves and the nodes of a complete binary tree, a separate\nparent-child-sister hierarchy is employed independent of the\nparent-child-sister hierarchy used for the rest of the tree. Two different\nversions of such a local hierarchy are introduced. The result of the first\nproposed hierarchy is a faster and smaller footprint, while the second one\nprovides the size variation functionality without a significant computational\noverhead. This novel approach brings considerable memory gains and performance\nboosts to the complete binary tree based algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 05:16:01 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Bulut", "Mevlut", ""]]}, {"id": "1401.7886", "submitter": "Arnaud Spiwack", "authors": "Guyslain Naves and Arnaud Spiwack", "title": "Balancing lists: a proof pearl", "comments": "To appear in proceedings of Interactive Theorem Proving (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Starting with an algorithm to turn lists into full trees which uses\nnon-obvious invariants and partial functions, we progressively encode the\ninvariants in the types of the data, removing most of the burden of a\ncorrectness proof.\n  The invariants are encoded using non-uniform inductive types which parallel\nnumerical representations in a style advertised by Okasaki, and a small amount\nof dependent types.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 15:40:18 GMT"}, {"version": "v2", "created": "Fri, 13 Jun 2014 12:32:39 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Naves", "Guyslain", ""], ["Spiwack", "Arnaud", ""]]}, {"id": "1401.7923", "submitter": "Marc Lelarge", "authors": "Marc Lelarge", "title": "Loopy annealing belief propagation for vertex cover and matching:\n  convergence, LP relaxation, correctness and Bethe approximation", "comments": "revised version, 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.IT math-ph math.IT math.MP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the minimum cardinality vertex cover and maximum cardinality matching\nproblems, the max-product form of belief propagation (BP) is known to perform\npoorly on general graphs. In this paper, we present an iterative loopy\nannealing BP (LABP) algorithm which is shown to converge and to solve a Linear\nProgramming relaxation of the vertex cover or matching problem on general\ngraphs. LABP finds (asymptotically) a minimum half-integral vertex cover (hence\nprovides a 2-approximation) and a maximum fractional matching on any graph. We\nalso show that LABP finds (asymptotically) a minimum size vertex cover for any\nbipartite graph and as a consequence compute the matching number of the graph.\nOur proof relies on some subtle monotonicity arguments for the local iteration.\nWe also show that the Bethe free entropy is concave and that LABP maximizes it.\nUsing loop calculus, we also give an exact (also intractable for general\ngraphs) expression of the partition function for matching in term of the LABP\nmessages which can be used to improve mean-field approximations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 16:56:12 GMT"}, {"version": "v2", "created": "Mon, 7 Jul 2014 20:47:35 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Lelarge", "Marc", ""]]}, {"id": "1401.7970", "submitter": "David Malec", "authors": "Erik D. Demaine, MohammadTaghi Hajiaghayi, Hamid Mahini, David L.\n  Malec, S. Raghavan, Anshul Sawant, Morteza Zadimoghadam", "title": "How to Influence People with Partial Incentives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the power of fractional allocations of resources to maximize\ninfluence in a network. This work extends in a natural way the well-studied\nmodel by Kempe, Kleinberg, and Tardos (2003), where a designer selects a\n(small) seed set of nodes in a social network to influence directly, this\ninfluence cascades when other nodes reach certain thresholds of neighbor\ninfluence, and the goal is to maximize the final number of influenced nodes.\nDespite extensive study from both practical and theoretical viewpoints, this\nmodel limits the designer to a binary choice for each node, with no way to\napply intermediate levels of influence. This model captures some settings\nprecisely, e.g. exposure to an idea or pathogen, but it fails to capture very\nrelevant concerns in others, for example, a manufacturer promoting a new\nproduct by distributing five \"20% off\" coupons instead of giving away one free\nproduct.\n  While fractional versions of problems tend to be easier to solve than\nintegral versions, for influence maximization, we show that the two versions\nhave essentially the same computational complexity. On the other hand, the two\nversions can have vastly different solutions: the added flexibility of\nfractional allocation can lead to significantly improved influence. Our main\ntheoretical contribution is to show how to adapt the major positive results\nfrom the integral case to the fractional case. Specifically, Mossel and Roch\n(2006) used the submodularity of influence to obtain their integral results; we\nintroduce a new notion of continuous submodularity, and use this to obtain\nmatching fractional results. We conclude that we can achieve the same greedy\n$(1-1/e-\\epsilon)$-approximation for the fractional case as the integral case.\nIn practice, we find that the fractional model performs substantially better\nthan the integral model, according to simulations on real-world social network\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 20:09:12 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Demaine", "Erik D.", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Mahini", "Hamid", ""], ["Malec", "David L.", ""], ["Raghavan", "S.", ""], ["Sawant", "Anshul", ""], ["Zadimoghadam", "Morteza", ""]]}, {"id": "1401.8071", "submitter": "Sascha Kurz", "authors": "Miriam Kie{\\ss}ling, Sascha Kurz, and J\\\"org Rambau", "title": "An exact column-generation approach for the lot-type design problem --\n  extended abstract", "comments": "4 pages, 2 tables, presented at ISCO 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a fashion discounter that supplies any of its many branches with\nan integral multiple of lots whose size assortment structure stems from a set\nof many applicable lot-types. We design a column generation algorithm for the\noptimal approximation of the branch and size dependent demand by a supply using\na bounded number of lot-types.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 06:54:57 GMT"}], "update_date": "2016-03-26", "authors_parsed": [["Kie\u00dfling", "Miriam", ""], ["Kurz", "Sascha", ""], ["Rambau", "J\u00f6rg", ""]]}, {"id": "1401.8096", "submitter": "Caterina De Bacco", "authors": "Caterina De Bacco, Silvio Franz, David Saad and Chi Ho Yeung", "title": "Shortest node-disjoint paths on random graphs", "comments": "22 pages, 14 figures", "journal-ref": "J. Stat. Mech. (2014) P07009", "doi": "10.1088/1742-5468/2014/07/P07009", "report-no": null, "categories": "cond-mat.dis-nn cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A localized method to distribute paths on random graphs is devised, aimed at\nfinding the shortest paths between given source/destination pairs while\navoiding path overlaps at nodes. We propose a method based on message-passing\ntechniques to process global information and distribute paths optimally.\nStatistical properties such as scaling with system size and number of paths,\naverage path-length and the transition to the frustrated regime are analysed.\nThe performance of the suggested algorithm is evaluated through a comparison\nagainst a greedy algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 09:34:29 GMT"}, {"version": "v2", "created": "Sun, 18 May 2014 09:30:11 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["De Bacco", "Caterina", ""], ["Franz", "Silvio", ""], ["Saad", "David", ""], ["Yeung", "Chi Ho", ""]]}, {"id": "1401.8135", "submitter": "Sascha Kurz", "authors": "Sascha Kurz", "title": "Competitive learning of monotone Boolean functions", "comments": "5 pages, 2 figures, presented at APMOD 2012", "journal-ref": "Suhl, Leena; Mitra, Gautam et al. (ed.): Applied Mathematical\n  Optimization and Modelling, APMOD 2012, DS&OR Lab, Vol. 8, Pages 416-421", "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply competitive analysis onto the problem of minimizing the number of\nqueries to an oracle to completely reconstruct a given monotone Boolean\nfunction. Besides lower and upper bounds on the competitivity we determine\noptimal deterministic online algorithms for the smallest problem instances.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 11:23:52 GMT"}], "update_date": "2014-02-03", "authors_parsed": [["Kurz", "Sascha", ""]]}, {"id": "1401.8230", "submitter": "Vadim Demchik", "authors": "Vadim Demchik and Alexey Gulov", "title": "Increasing precision of uniform pseudorandom number generators", "comments": "5 pages, 1 figure; additional description of algorithm is applied", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general method to produce uniformly distributed pseudorandom numbers with\nextended precision by combining two pseudorandom numbers with lower precision\nis proposed. In particular, this method can be used for pseudorandom number\ngeneration with extended precision on graphics processing units (GPU), where\nthe performance of single and double precision operations can vary\nsignificantly.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 20:20:18 GMT"}, {"version": "v2", "created": "Mon, 12 May 2014 12:45:45 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Demchik", "Vadim", ""], ["Gulov", "Alexey", ""]]}]