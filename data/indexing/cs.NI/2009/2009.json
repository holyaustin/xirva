[{"id": "2009.00072", "submitter": "Subhadeep Sahoo", "authors": "Subhadeep Sahoo, Xiao Han Dong, Zi Qian Liu, Joydeep Sahoo", "title": "Under Water Waste Cleaning by Mobile Edge Computing and Intelligent\n  Image Processing Based Robotic Fish", "comments": "This is an innovative project report awarded by Ericsson Innovation\n  Award 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As water pollution is a serious threat to underwater resources, i.e.,\nunderwater plants and species, we focus on protecting the resources by cleaning\nthe non-biodegradable waste from the water. The waste can be recycled for\nfurther usage. Here we design a robotic fish which mainly comprises optical\nbiosensor, camera module, piston module, and wireless transceiver. By\nexploiting the LTE and 5G network architecture, the fish stores the information\nabout the underwater waste in the nearest mobile edge computing server as well\nas in the centralized cloud server. Finally, when the fish clears the\nunderwater waste, it offloads the captured image of the located object to the\nmobile edge computing server or sometimes to the cloud server for making a\ndecision. The servers employ intelligent image processing technology and an\nadaptive learning process to make a decision. However, if the servers fail to\nmake a decision, then the fish utilizes its optical biosensor. By this scheme,\nthe time delay for clearing any water body is minimized and the waste\ncollection capacity of the fish is maximized. This technique can effectively\nhelp the government or municipal personnel for making clean water without\nmanual efforts.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 19:22:54 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Sahoo", "Subhadeep", ""], ["Dong", "Xiao Han", ""], ["Liu", "Zi Qian", ""], ["Sahoo", "Joydeep", ""]]}, {"id": "2009.00205", "submitter": "Morteza Hashemi", "authors": "Chanaka Samarathunga, Mohamed Abouelseoud, Kazuyuki Sakoda, Morteza\n  Hashemi", "title": "On the Benefits of Multi-hop Communication for Indoor 60 GHz Wireless\n  Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spectrum-rich millimeter wave (mmWave) frequencies have the potential to\nalleviate the spectrum crunch that the wireless and cellular operators are\nalready experiencing. However, compared with traditional wireless communication\nin the sub-6 GHz bands, due to small wavelengths most objects such as human\nbody, cause significant additional path losses (up to 20dB), which can entirely\nbreak the mmWave link. Also, mmwave links suffer from limited range of\ncommunication. In this paper, we resort to network layer solutions to\ndemonstrate the benefits of multi-hop routing in mitigating the blockage issue\nand extending communication range in mmWave band. To this end, we develop a\nhop-by-hop multi-path routing protocol that finds one primary and one backup\nnext-hop per destination in order to guarantee reliable and robust\ncommunication under extreme stress conditions. System-level simulations based\non the IEEE802.11ad specifications demonstrate that the proposed routing\nprotocol provides a reliable end-to-end throughput performance, while\nsatisfying the latency requirements.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 03:28:12 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 21:28:05 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Samarathunga", "Chanaka", ""], ["Abouelseoud", "Mohamed", ""], ["Sakoda", "Kazuyuki", ""], ["Hashemi", "Morteza", ""]]}, {"id": "2009.00243", "submitter": "Feng Tian", "authors": "Feng Tian, Wendi Feng, Yang Zhang and Zhi-Li Zhang", "title": "A Novel Software-based Multi-path RDMA Solutionfor Data Center Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose Virtuoso, a purely software-based multi-path RDMA\nsolution for data center networks (DCNs) to effectively utilize the rich\nmulti-path topology for load balancing and reliability. As a \"middleware\"\nlibrary operating at the user space, Virtuoso employs three innovative\nmechanisms to achieve its goal. In contrast to existing hardware-based MP-RDMA\nsolution, Virtuoso can be readily deployed in DCNs with existing RDMA NICs. It\nalso decouples path selection and load balancing mechanisms from hardware\nfeatures, allowing DCN operators and applications to make flexible decisions by\nemploying the best mechanisms (as \"plug-in\" software library modules) as\nneeded. Our experiments show that Virtuoso is capable of fully utilizing\nmultiple paths with negligible CPU overheads\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 05:33:56 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Tian", "Feng", ""], ["Feng", "Wendi", ""], ["Zhang", "Yang", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "2009.00273", "submitter": "Martin Henze", "authors": "Benedikt Klaer, \\\"Omer Sen, Dennis van der Velde, Immanuel Hacker,\n  Michael Andres, Martin Henze", "title": "Graph-based Model of Smart Grid Architectures", "comments": "6 pages, 5 figures, to be published in Proceedings of the 3rd\n  International Conference on Smart Energy Systems and Technologies (SEST)", "journal-ref": null, "doi": "10.1109/SEST48500.2020.9203113", "report-no": null, "categories": "cs.SE cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rising use of information and communication technology in smart grids\nlikewise increases the risk of failures that endanger the security of power\nsupply, e.g., due to errors in the communication configuration, faulty control\nalgorithms, or cyber-attacks. Co-simulations can be used to investigate such\neffects, but require precise modeling of the energy, communication, and\ninformation domain within an integrated smart grid infrastructure model. Given\nthe complexity and lack of detailed publicly available communication network\nmodels for smart grid scenarios, there is a need for an automated and\nsystematic approach to creating such coupled models. In this paper, we present\nan approach to automatically generate smart grid infrastructure models based on\nan arbitrary electrical distribution grid model using a generic architectural\ntemplate. We demonstrate the applicability and unique features of our approach\nalongside examples concerning network planning, co-simulation setup, and\nspecification of domain-specific intrusion detection systems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 07:32:19 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Klaer", "Benedikt", ""], ["Sen", "\u00d6mer", ""], ["van der Velde", "Dennis", ""], ["Hacker", "Immanuel", ""], ["Andres", "Michael", ""], ["Henze", "Martin", ""]]}, {"id": "2009.00377", "submitter": "Giuseppe Corrente", "authors": "Giuseppe Corrente", "title": "Performance issues in content dissemination to metropolitan mobile users", "comments": "41 pages, 11 figures", "journal-ref": "Journal of High Speed Networks, vol. 23, no. 2, pp. 149-162, 2017", "doi": "10.3233/JHS-170562", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a set of heterogeneous terminals in a urban area\nthat are interested in collecting the information originated from several\nsources. This set includes mobile nodes (pedestrian and vehicles) and fixed\nterminals. In particular, each terminal aims at retrieving the data items in a\nlimited region of interest (ROI) centered around the node position. Since data\nitems may change over time all nodes must strive for having access to the\nlatest version. The goal of the paper is to evaluate the amount of information\neach node is able to gather (coverage) resorting to simple distributed data\ncollection and sharing through local broadcast communications. We study the\ndiffusion of information updates in the whole area, evaluate the impact of\nenergy saving policies in the protocol version run by pedestrian devices, and\nthe impact of contextual awareness about location and motion of nodes in the\nforwarding policies. The study we present in this paper has been carried out\nthrough simulation. To this end we develop a discrete event simulator working\non top of mobility and radio propagation traces obtained from the UDelModels\ntools that allow to obtain realistic traces of mobility and radio propagation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 12:15:20 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Corrente", "Giuseppe", ""]]}, {"id": "2009.00413", "submitter": "Konstantinos Dovelos", "authors": "Konstantinos Dovelos and Boris Bellalta", "title": "A Scheduling Policy for Downlink OFDMA in IEEE 802.11ax with Throughput\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to meet the ever-increasing demand for high throughput in WiFi\nnetworks, the IEEE 802.11ax (11ax) standard introduces orthogonal frequency\ndivision multiple access (OFDMA). In this letter, we address the\nstation-resource unit scheduling problem in downlink OFDMA of 11ax subject to\nminimum throughput requirements. To deal with the infeasible instances of the\nconstrained problem, we propose a novel scheduling policy based on weighted\nmax-min fairness, which maximizes the minimum fraction between the achievable\nand minimum required throughputs. Thus, the proposed policy has a well-defined\nbehavior even when the throughput constraints cannot be fulfilled. Numerical\nresults showcase the merits of our approach over the popular proportional\nfairness and constrained sum-rate maximization strategies.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 13:29:41 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Dovelos", "Konstantinos", ""], ["Bellalta", "Boris", ""]]}, {"id": "2009.00454", "submitter": "Baoling Sheen", "authors": "Baoling Sheen, Jin Yang, Xianglong Feng, and Md Moin Uddin Chowdhury", "title": "A Digital Twin for Reconfigurable Intelligent Surface Assisted Wireless\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconfigurable Intelligent Surface (RIS) has emerged as one of the key\ntechnologies for 6G in recent years, which comprise a large number of low-cost\npassive elements that can smartly interact with the impinging electromagnetic\nwaves for performance enhancement. However, optimally configuring massive\nnumber of RIS elements remains a challenge. In this paper, we present a novel\ndigital-twin framework for RIS-assisted wireless networks which we name it\nEnvironment-Twin (Env-Twin). The goal of the Env-Twin framework is to enable\nautomation of optimal control at various granularities. In this paper, we\npresent one example of the Env-Twin models to learn the mapping function\nbetween the RIS configuration with measured attributes for the receiver\nlocation, and the corresponding achievable rate in an RIS-assisted wireless\nnetwork without involving explicit channel estimation or beam training\noverhead. Once learned, our Env-Twin model can be used to predict optimal RIS\nconfiguration for any new receiver locations in the same wireless network. We\nleveraged deep learning (DL) techniques to build our model and studied its\nperformance and robustness. Simulation results demonstrate that the proposed\nEnv-Twin model can recommend near-optimal RIS configurations for test receiver\nlocations which achieved close to an upper bound performance that assumes\nperfect channel knowledge. Our Env-Twin model was trained using less than 2% of\nthe total receiver locations. This promising result represents great potential\nof the proposed Env-Twin framework for developing a practical RIS solution\nwhere the panel can automatically configure itself without requesting channel\nstate information (CSI) from the wireless network infrastructure.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 14:11:56 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Sheen", "Baoling", ""], ["Yang", "Jin", ""], ["Feng", "Xianglong", ""], ["Chowdhury", "Md Moin Uddin", ""]]}, {"id": "2009.00685", "submitter": "Ekram Hossain", "authors": "Vandana Mittal, Setareh Maghsudi, and Ekram Hossain", "title": "Distributed Cooperation Under Uncertainty in Drone-Based Wireless\n  Networks: A Bayesian Coalitional Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the resource sharing problem in a drone-based wireless network. We\nconsider a distributed control setting under uncertainty (i.e. unavailability\nof full information). In particular, the drones cooperate in serving the users\nwhile pooling their spectrum and energy resources in the absence of prior\nknowledge about different system characteristics such as the amount of\navailable power at the other drones. We cast the aforementioned problem as a\nBayesian cooperative game in which the agents (drones) engage in a coalition\nformation process, where the goal is to maximize the overall transmission rate\nof the network. The drones update their beliefs using a novel technique that\ncombines the maximum likelihood estimation with Kullback-Leibler divergence. We\npropose a decision-making strategy for repeated coalition formation that\nconverges to a stable coalition structure. We analyze the performance of the\nproposed approach by both theoretical analysis and simulations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 20:39:35 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mittal", "Vandana", ""], ["Maghsudi", "Setareh", ""], ["Hossain", "Ekram", ""]]}, {"id": "2009.01176", "submitter": "Siddhartha Borkotoky", "authors": "Harishwar Reddy Bapathu, Siddhartha S. Borkotoky", "title": "The LoRa Modulation Over Rapidly-Varying Channels: Are the Higher\n  Spreading Factors Necessarily More Robust?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The chirp spread spectrum (CSS) modulation scheme is employed by the physical\nlayer of the Long Range (LoRa) communication technology. In this paper, we\nexamine the performance of CSS over time-varying channels whose gain may change\nduring the reception of a LoRa frame. This is in contrast to the usually\nemployed model in the literature, which assumes the channel gain to be constant\nthroughout a frame. Specifically, we investigate the effects of exponentially\ncorrelated Rayleigh fading on the frame-error rate of a CSS receiver in which\nthe channel gain is estimated at the beginning of each frame. Our primary\nobservation is that over rapidly-varying channels, the robustness benefits of\nthe larger spreading factors tend to disappear as the payload size grows. This\nobservation, which is contrary to the common perception that higher spreading\nfactors necessarily provide greater immunity against noise, highlights the need\nto consider channel characteristics and payload sizes in allocating the\nspreading factor for reliable and energy-efficient LoRa communications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 16:35:51 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 14:52:42 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bapathu", "Harishwar Reddy", ""], ["Borkotoky", "Siddhartha S.", ""]]}, {"id": "2009.01302", "submitter": "Mao Ye", "authors": "Mao Ye, Lin Guan, Mohammed Quddus", "title": "TDMP-Reliable Target Driven and Mobility Prediction based Routing\n  Protocol in Complex VANET", "comments": "35 pages,16 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle-to-everything (V2X) communication in the vehicular ad hoc network\n(VANET), an infrastructure-free mechanism, has emerged as a crucial component\nin the advanced Intelligent Transport System (ITS) for special information\ntransmission and inter-vehicular communications. One of the main research\nchallenges in VANET is the design and implementation of network routing\nprotocols which manage to trigger V2X communication with the reliable\nend-to-end connectivity and efficient packet transmission. The organically\nchanging nature of road transport vehicles poses a significant threat to VANET\nwith respect to the accuracy and reliability of packet delivery. Therefore, a\nposition-based routing protocol tends to be the predominant method in VANET as\nthey overcome rapid changes in vehicle movements effectively. However, existing\nrouting protocols have some limitations such as (i) inaccurate in high dynamic\nnetwork topology, (ii) defective link-state estimation (iii) poor movement\nprediction in heterogeneous road layouts. In this paper, a target-driven and\nmobility prediction (TDMP) based routing protocol is therefore developed for\nhigh-speed mobility and dynamic topology of vehicles, fluctuant traffic flow\nand diverse road layouts in VANET. The primary idea in TDMP is that the\ndestination target of a driver is included in the mobility prediction to assist\nthe implementation of the routing protocol. Compared to existing geographic\nrouting protocols which mainly greedily forward the packet to the next-hop\nbased on its current position and partial road layout, TDMP is developed to\nenhance the packet transmission with the consideration of the estimation of\ninter-vehicles link status, and the prediction of vehicle positions dynamically\nin fluctuant mobility and global road layout.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:01:51 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 14:13:54 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 14:53:10 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Ye", "Mao", ""], ["Guan", "Lin", ""], ["Quddus", "Mohammed", ""]]}, {"id": "2009.01368", "submitter": "Biswadeep Chakraborty", "authors": "Biswadeep Chakraborty, Dinil Mon Divakaran, Ido Nevat, Gareth W.\n  Peters, Mohan Gurusamy", "title": "Cost-aware Feature Selection for IoT Device Classification", "comments": "33 pages, 9 figures", "journal-ref": "Internet of Things Journal 2021", "doi": "10.1109/JIOT.2021.3051480", "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification of IoT devices into different types is of paramount\nimportance, from multiple perspectives, including security and privacy aspects.\nRecent works have explored machine learning techniques for fingerprinting (or\nclassifying) IoT devices, with promising results. However, existing works have\nassumed that the features used for building the machine learning models are\nreadily available or can be easily extracted from the network traffic; in other\nwords, they do not consider the costs associated with feature extraction. In\nthis work, we take a more realistic approach, and argue that feature extraction\nhas a cost, and the costs are different for different features. We also take a\nstep forward from the current practice of considering the misclassification\nloss as a binary value, and make a case for different losses based on the\nmisclassification performance. Thereby, and more importantly, we introduce the\nnotion of risk for IoT device classification. We define and formulate the\nproblem of cost-aware IoT device classification. This being a combinatorial\noptimization problem, we develop a novel algorithm to solve it in a fast and\neffective way using the Cross-Entropy (CE) based stochastic optimization\ntechnique. Using traffic of real devices, we demonstrate the capability of the\nCE based algorithm in selecting features with minimal risk of misclassification\nwhile keeping the cost for feature extraction within a specified limit.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 22:16:11 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 17:45:18 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 18:48:57 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Chakraborty", "Biswadeep", ""], ["Divakaran", "Dinil Mon", ""], ["Nevat", "Ido", ""], ["Peters", "Gareth W.", ""], ["Gurusamy", "Mohan", ""]]}, {"id": "2009.01497", "submitter": "Gregor Stefan Bankhamer", "authors": "Gregor Bankhamer, Robert Els\\\"asser, Stefan Schmid", "title": "Local Fast Rerouting with Low Congestion: A Randomized Approach", "comments": null, "journal-ref": null, "doi": "10.1109/ICNP.2019.8888087", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most modern communication networks include fast rerouting mechanisms,\nimplemented entirely in the data plane, to quickly recover connectivity after\nlink failures. By relying on local failure information only, these data plane\nmechanisms provide very fast reaction times, but at the same time introduce an\nalgorithmic challenge in case of multiple link failures: failover routes need\nto be robust to additional but locally unknown failures downstream.\n  This paper presents local fast rerouting algorithms which not only provide a\nhigh degree of resilience against multiple link failures, but also ensure a low\ncongestion on the resulting failover paths. We consider a randomized approach\nand focus on networks which are highly connected before the failures occur. Our\nmain contribution are three simple algorithms which come with provable\nguarantees and provide interesting resilience-load tradeoffs, significantly\noutperforming any deterministic fast rerouting algorithm with high probability.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 07:45:34 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Bankhamer", "Gregor", ""], ["Els\u00e4sser", "Robert", ""], ["Schmid", "Stefan", ""]]}, {"id": "2009.01532", "submitter": "Carlos Borrego", "authors": "Diego Freire, Sergi Robles, Carlos Borrego", "title": "Towards a Methodology for the Development of Routing Algorithms in\n  Opportunistic Networks", "comments": null, "journal-ref": "The Sixteenth International Conference on Wireless and Mobile\n  Communications ICWMC 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a methodology for the development of routing algorithms\nthat takes into consideration opportunistic networking. The proposal focus on\nthe rationale behind the methodology, and highlights its most important stages\nand components. It also discusses the importance of two core elements in the\nprocess of protocol designing: the scenario selection, based on essential\ncharacteristics, and the choice of standard evaluation metrics. As of now,\nthere has been no common methodology for developing new routing algorithms, and\nthis has led to proposals difficult to compare, to evaluate, and lacking a\nrigorous objectivity ensuring fairness. Thus, there is the urgent need to\npropose, agree, and use a common methodology for the development of routing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 09:19:51 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Freire", "Diego", ""], ["Robles", "Sergi", ""], ["Borrego", "Carlos", ""]]}, {"id": "2009.01634", "submitter": "Anirudh Paranjothi", "authors": "Anirudh Paranjothi, Mohammed Atiquzzaman, Mohammad S. Khan", "title": "Message Dissemination in Connected Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in connected vehicles based on Vehicular Ad-hoc Networks (VANETs) in\nrecent years have gained significant attention in Intelligent Transport Systems\n(ITS) in terms of disseminating messages in an efficient manner. VANET uses\nDedicated Short Range Communication (DSRC) for disseminating messages between\nvehicles and between infrastructures. Though DSRC based communications are\nviable, it is still challenging to disseminate messages in a timely manner when\nvehicles are not in the transmission range of each other. Furthermore, DSRC\ncommunication channels are heavily congested when the vehicle density increases\non the road. To address these limitations, two emerging paradigms: 1) vehicular\ncloud computing and 2) vehicular fog computing are been adopted to disseminate\nmessage between the vehicles in a connected vehicular environment. Vehicular\nfog computing uses fog nodes for the dissemination of messages among vehicles.\nAny real-world object can be formed as a fog node by acquiring the properties\nsuch as 1) network connectivity, 2) computation, and 3) storage. In this book\nchapter, we highlight the significance of message dissemination in connected\nvehicles based on techniques like DSRC, vehicular cloud computing, and\nvehicular fog computing. Our objective is to help the readers better understand\nthe fundamentals of connected vehicles and communication techniques while\ndisseminating messages between vehicles and between infrastructures.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 12:56:12 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Paranjothi", "Anirudh", ""], ["Atiquzzaman", "Mohammed", ""], ["Khan", "Mohammad S.", ""]]}, {"id": "2009.01716", "submitter": "Pablo Fondo-Ferreiro", "authors": "Pablo Fondo-Ferreiro, Felipe Gil-Casti\\~neira, Francisco Javier\n  Gonz\\'alez-Casta\\~no, David Candal-Ventureira", "title": "A Software-Defined Networking Solution for Transparent Session and\n  Service Continuity in Dynamic Multi-Access Edge Computing", "comments": "Accepted version of the article published in IEEE Transactions on\n  Network and Service Management", "journal-ref": "IEEE Transactions on Network and Service Management, vol. 18, no.\n  2, pp. 1401-1414, June 2021", "doi": "10.1109/TNSM.2020.3033071", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Access Edge Computing (MEC) will allow implementing low-latency\nservices that have been unfeasible so far. The European Telecommunications\nStandards Institute (ETSI) and the 3rd Generation Partnership Project (3GPP)\nare working towards the standardization of MEC in 5G networks and the\ncorresponding solutions for routing user traffic to applications in local area\nnetworks. Nevertheless, there are neither practical implementations for\ndynamically relocating applications from the core to a MEC host nor from one\nMEC host to another ensuring service continuity. In this paper we propose a\nsolution based on Software-Defined Networking (SDN) to create a new instance of\nthe IP anchor point to dynamically redirect User Equipment (UE) traffic to a\nnew physical location (e.g. an edge infrastructure). We also present a novel\napproach that leverages SDN to replicate the previous context of the connection\nin the new instance of the IP anchor point, thus guaranteeing Session and\nService Continuity (SSC), and compare it with alternative state replication\nstrategies. This approach can be used to implement edge services in 4G or 5G\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 14:50:16 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 13:38:12 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Fondo-Ferreiro", "Pablo", ""], ["Gil-Casti\u00f1eira", "Felipe", ""], ["Gonz\u00e1lez-Casta\u00f1o", "Francisco Javier", ""], ["Candal-Ventureira", "David", ""]]}, {"id": "2009.01880", "submitter": "Anna Maria Mandalari", "authors": "Said Jawad Saidi, Anna Maria Mandalari, Roman Kolcun, Hamed Haddadi,\n  Daniel J. Dubois, David Choffnes, Georgios Smaragdakis, Anja Feldmann", "title": "A Haystack Full of Needles: Scalable Detection of IoT Devices in the\n  Wild", "comments": "Accepted at the ACM Internet Measurement Conference 2020 (IMC'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumer Internet of Things (IoT) devices are extremely popular, providing\nusers with rich and diverse functionalities, from voice assistants to home\nappliances. These functionalities often come with significant privacy and\nsecurity risks, with notable recent large scale coordinated global attacks\ndisrupting large service providers. Thus, an important first step to address\nthese risks is to know what IoT devices are where in a network. While some\nlimited solutions exist, a key question is whether device discovery can be done\nby Internet service providers that only see sampled flow statistics. In\nparticular, it is challenging for an ISP to efficiently and effectively track\nand trace activity from IoT devices deployed by its millions of subscribers\n--all with sampled network data.\n  In this paper, we develop and evaluate a scalable methodology to accurately\ndetect and monitor IoT devices at subscriber lines with limited, highly sampled\ndata in-the-wild. Our findings indicate that millions of IoT devices are\ndetectable and identifiable within hours, both at a major ISP as well as an\nIXP, using passive, sparsely sampled network flow headers. Our methodology is\nable to detect devices from more than 77% of the studied IoT manufacturers,\nincluding popular devices such as smart speakers. While our methodology is\neffective for providing network analytics, it also highlights significant\nprivacy consequences.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 18:45:15 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 16:41:49 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 13:46:36 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Saidi", "Said Jawad", ""], ["Mandalari", "Anna Maria", ""], ["Kolcun", "Roman", ""], ["Haddadi", "Hamed", ""], ["Dubois", "Daniel J.", ""], ["Choffnes", "David", ""], ["Smaragdakis", "Georgios", ""], ["Feldmann", "Anja", ""]]}, {"id": "2009.01964", "submitter": "Mohammad Mukhtaruzzaman", "authors": "Mohammad Mukhtaruzzaman and Mohammed Atiquzzaman", "title": "Clustering in VANET: Algorithms and Challenges", "comments": null, "journal-ref": "Computers & Electrical Engineering, Volume 88, December 2020,\n  106851", "doi": "10.1016/j.compeleceng.2020.106851", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is an important concept in vehicular ad hoc network (VANET) where\nseveral vehicles join to form a group based on common features. Mobility-based\nclustering strategies are the most common in VANET clustering; however, machine\nlearning and fuzzy logic algorithms are also the basis of many VANET clustering\nalgorithms. Some VANET clustering algorithms integrate machine learning and\nfuzzy logic algorithms to make the cluster more stable and efficient. Network\nmobility (NEMO) and multi-hop-based strategies are also used for VANET\nclustering. Mobility and some other clustering strategies are presented in the\nexisting literature reviews; however, extensive study of intelligence-based,\nmobility-based, and multi-hop-based strategies still missing in the VANET\nclustering reviews. In this paper, we presented a classification of\nintelligence-based clustering algorithms, mobility-based algorithms, and\nmulti-hop-based algorithms with an analysis on the mobility metrics, evaluation\ncriteria, challenges, and future directions of machine learning, fuzzy logic,\nmobility, NEMO, and multi-hop clustering algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 00:02:10 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Mukhtaruzzaman", "Mohammad", ""], ["Atiquzzaman", "Mohammed", ""]]}, {"id": "2009.02128", "submitter": "Hannaneh Barahouei Pasandi", "authors": "Hannaneh Barahouei Pasandi, Tamer Nadeem", "title": "Towards A Learning-Based Framework for Self-Driving Design of Networking\n  Protocols", "comments": "18 Pages, Under Review. arXiv admin note: text overlap with\n  arXiv:2002.02075, arXiv:2002.03795", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networking protocols are designed through long-time and hard-work human\nefforts. Machine Learning (ML)-based solutions have been developed for\ncommunication protocol design to avoid manual efforts to tune individual\nprotocol parameters. While other proposed ML-based methods mainly focus on\ntuning individual protocol parameters (e.g., adjusting contention window), our\nmain contribution is to propose a novel Deep Reinforcement Learning (DRL)-based\nframework to systematically design and evaluate networking protocols. We\ndecouple a protocol into a set of parametric modules, each representing a main\nprotocol functionality that is used as DRL input to better understand the\ngenerated protocols design optimization and analyze them in a systematic\nfashion. As a case study, we introduce and evaluate DeepMAC a framework in\nwhich a MAC protocol is decoupled into a set of blocks across popular flavors\nof 802.11 WLANs (e.g., 802.11 b/a/g/n/ac). We are interested to see what blocks\nare selected by DeepMAC across different networking scenarios and whether\nDeepMAC is able to adapt to network dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:33:27 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Pasandi", "Hannaneh Barahouei", ""], ["Nadeem", "Tamer", ""]]}, {"id": "2009.02131", "submitter": "Wei Duan", "authors": "Wei Duan, Yancheng Ji, Yan Zhang, Guoan Zhang, Valerio Frascolla and\n  Xin Li", "title": "5G Technologies Based Remote E-Health: Architecture, Applications, and\n  Solutions", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, many countries are facing the problems of aging population,\nserious imbalance of medical resources supply and demand, as well as uneven\ngeographical distribution, resulting in a huge demand for remote e-health.\nParticularly, with invasions of COVID-19, the health of people and even social\nstability have been challenged unprecedentedly. To contribute to these urgent\nproblems, this article proposes a general architecture of the remote e-health,\nwhere the city hospital provides the technical supports and services for remote\nhospitals. Meanwhile, 5G technologies supported telemedicine is introduced to\nsatisfy the high-speed transmission of massive multimedia medical data, and\nfurther realize the sharing of medical resources. Moreover, to turn passivity\ninto initiative to prevent COVID-19, a broad area epidemic prevention and\ncontrol scheme is also investigated, especially for the remote areas. We\ndiscuss their principles and key features, and foresee the challenges,\nopportunities, and future research trends. Finally, a node value and content\npopularity based caching strategy is introduced to provide a preliminary\nsolution of the massive data storage and low-latency transmission.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 12:09:41 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Duan", "Wei", ""], ["Ji", "Yancheng", ""], ["Zhang", "Yan", ""], ["Zhang", "Guoan", ""], ["Frascolla", "Valerio", ""], ["Li", "Xin", ""]]}, {"id": "2009.02137", "submitter": "Stefan More", "authors": "Lukas Alber, Stefan More, Sebastian Ramacher", "title": "Short-Lived Forward-Secure Delegation for TLS", "comments": "This is the full version of a paper which appears in 2020 Cloud\n  Computing Security Workshop (CCSW '20), November 9, 2020, Virtual Event, USA,\n  ACM", "journal-ref": null, "doi": "10.1145/3411495.3421362", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On today's Internet, combining the end-to-end security of TLS with Content\nDelivery Networks (CDNs) while ensuring the authenticity of connections results\nin a challenging delegation problem. When CDN servers provide content, they\nhave to authenticate themselves as the origin server to establish a valid\nend-to-end TLS connection with the client. In standard TLS, the latter requires\naccess to the secret key of the server. To curb this problem, multiple\nworkarounds exist to realize a delegation of the authentication.\n  In this paper, we present a solution that renders key sharing unnecessary and\nreduces the need for workarounds. By adapting identity-based signatures to this\nsetting, our solution offers short-lived delegations. Additionally, by enabling\nforward-security, existing delegations remain valid even if the server's secret\nkey leaks. We provide an implementation of the scheme and discuss integration\ninto a TLS stack. In our evaluation, we show that an efficient implementation\nincurs less overhead than a typical network round trip. Thereby, we propose an\nalternative approach to current delegation practices on the web.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 12:28:03 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 15:12:14 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Alber", "Lukas", ""], ["More", "Stefan", ""], ["Ramacher", "Sebastian", ""]]}, {"id": "2009.02181", "submitter": "Guangxu Zhu", "authors": "Guangxu Zhu and Jie Xu and Kaibin Huang and Shuguang Cui", "title": "Over-the-Air Computing for Wireless Data Aggregation in Massive IoT", "comments": "An Introductory paper to over-the-air computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless data aggregation (WDA), referring to aggregating data distributed at\ndevices (e.g., sensors and smartphone), is a common operation in 5G-and-beyond\nmachine-type communications to support Internet-of-Things (IoT), which lays the\nfoundation for diversified applications such as distributed sensing, learning,\nand control. Conventional WDA techniques that are designed based on a\nseparated-communication-and-computation principle encounter difficulty in\naccommodating the massive access under the limited radio resource and stringent\nlatency constraints imposed by emerging applications (e.g, auto-driving). To\naddress this issue, over-the-air computation (AirComp) is being developed as a\nnew WDA solution by seamlessly integrating computation and communication. By\nexploiting the waveform superposition property of a multiple-access channel,\nAirComp turns the air into a computer for computing and communicating functions\nof distributed data at many devices, thereby allowing low-latency WDA over\nmassive devices. In view of growing interests on AirComp, this article provides\na timely overview of the technology by introducing basic principles, discussing\nadvanced techniques and applications, and identifying promising research\nopportunities.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:33:51 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 13:11:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Zhu", "Guangxu", ""], ["Xu", "Jie", ""], ["Huang", "Kaibin", ""], ["Cui", "Shuguang", ""]]}, {"id": "2009.02192", "submitter": "Jimmy Nielsen", "authors": "Igor Donevski, Jimmy Jessen Nielsen", "title": "Dynamic Standalone Drone-Mounted Small Cells", "comments": "To be published in proceedings of EuCNC'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the feasibility of Dynamic Horizontal Opportunistic\nPositioning (D-HOP) use in Drone Small Cells (DSCs), with a central analysis on\nthe impact of antenna equipment efficiency onto the optimal DSC altitude that\nhas been chosen in favor of maximizing coverage. We extend the common urban\npropagation model of an isotropic antenna to account for a directional antenna,\nmaking it dependent on the antenna's ability to fit the ideal propagation\npattern. This leads us to define a closed-form expression for calculating the\nRate improvement of D-HOP implementations that maintain constant coverage\nthrough antenna tilting. Assuming full knowledge of the uniformly distributed\nactive users' locations, three D-HOP techniques were tested: in the center of\nthe Smallest Bounding Circle (SBC); the point of Maximum Aggregated Rate (MAR);\nand the Center-Most Point (CMP) out of the two aforementioned. Through analytic\nstudy and simulation we infer that DSC D-HOP implementations are feasible when\nusing electrically small and tiltable antennas. Nonetheless, it is possible to\nachieve average per user average rate increases of up to 20-35% in low user\ndensity scenarios, or 3-5% in user-dense scenarios, even when using efficient\nantennas in a DSC that has been designed for standalone coverage.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:48:24 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Donevski", "Igor", ""], ["Nielsen", "Jimmy Jessen", ""]]}, {"id": "2009.02260", "submitter": "Pavlos Charalampidis", "authors": "Konstantinos Arakadakis, Pavlos Charalampidis, Antonis Makrogiannakis,\n  Alexandros Fragkiadakis", "title": "Firmware over-the-air programming techniques for IoT networks -- A\n  survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The devices forming the Internet-of-Things (IoT) networks need to be\nre-programmed over-the-air, so that new features are added, software bugs or\nsecurity vulnerabilities are resolved and their applications can be\nre-purposed. The limitations of IoT devices, such as installation in locations\nwith limited physical access, resource-constraint nature, large scale and high\nheterogeneity, should be taken into consideration for designing an efficient\nand reliable pipeline for over-the-air programming (OTAP). In this work, we\npresent a survey of OTAP techniques, which can be applied to IoT networks. We\nhighlight the main challenges and limitations of OTAP for IoT devices and\nanalyse the essential steps of firmware update process, along with different\napproaches and techniques that implement them. In addition, we discuss schemes\nthat focus on securing the OTAP process. Finally, we present a collection of\nstate-of-the art open-source and commercial platforms that integrate secure and\nreliable OTAP.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:41:29 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 17:29:43 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Arakadakis", "Konstantinos", ""], ["Charalampidis", "Pavlos", ""], ["Makrogiannakis", "Antonis", ""], ["Fragkiadakis", "Alexandros", ""]]}, {"id": "2009.02353", "submitter": "Gianni Antichi", "authors": "Giuseppe Siracusano, Salvator Galea, Davide Sanvito, Mohammad\n  Malekzadeh, Hamed Haddadi, Gianni Antichi, Roberto Bifulco", "title": "Running Neural Networks on the NIC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that the data plane of commodity programmable (Network\nInterface Cards) NICs can run neural network inference tasks required by packet\nmonitoring applications, with low overhead. This is particularly important as\nthe data transfer costs to the host system and dedicated machine learning\naccelerators, e.g., GPUs, can be more expensive than the processing task\nitself. We design and implement our system -- N3IC -- on two different NICs and\nwe show that it can greatly benefit three different network monitoring use\ncases that require machine learning inference as first-class-primitive. N3IC\ncan perform inference for millions of network flows per second, while\nforwarding traffic at 40Gb/s. Compared to an equivalent solution implemented on\na general purpose CPU, N3IC can provide 100x lower processing latency, with\n1.5x increase in throughput.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 18:35:58 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Siracusano", "Giuseppe", ""], ["Galea", "Salvator", ""], ["Sanvito", "Davide", ""], ["Malekzadeh", "Mohammad", ""], ["Haddadi", "Hamed", ""], ["Antichi", "Gianni", ""], ["Bifulco", "Roberto", ""]]}, {"id": "2009.02377", "submitter": "Yudi Huang", "authors": "Yudi Huang, Ting He, Nilanjan Ray Chaudhuri, Thomas La Porta", "title": "Power Grid State Estimation under General Cyber-Physical Attacks", "comments": "Assumptions clarified; proof revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective defense against cyber-physical attacks in power grid requires the\ncapability of accurate damage assessment within the attacked area. While some\nsolutions have been proposed to recover the phase angles and the link status\n(i.e., breaker status) within the attacked area, existing solutions made the\nlimiting assumption that the grid stays connected after the attack. To fill\nthis gap, we study the problem of recovering the phase angles and the link\nstatus under a general cyber-physical attack that may partition the grid into\nislands. To this end, we (i) show that the existing solutions and recovery\nconditions still hold if the post-attack power injections in the attacked area\nare known, and (ii) propose a linear programming-based algorithm that can\nperfectly recover the link status under certain conditions even if the\npost-attack power injections are unknown. Our numerical evaluations based on\nthe Polish power grid demonstrate that the proposed algorithm is highly\naccurate in localizing failed links once the phase angles are known.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:01:19 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 03:59:36 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Huang", "Yudi", ""], ["He", "Ting", ""], ["Chaudhuri", "Nilanjan Ray", ""], ["La Porta", "Thomas", ""]]}, {"id": "2009.02457", "submitter": "Daehyeok Kim", "authors": "Daehyeok Kim, Ankush Jain, Zaoxing Liu, George Amvrosiadis, Damian\n  Hazen, Bradley Settlemyer, Vyas Sekar", "title": "Unleashing In-network Computing on Scientific Workloads", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many recent efforts have shown that in-network computing can benefit various\ndatacenter applications. In this paper, we explore a relatively less-explored\ndomain which we argue can benefit from in-network computing: scientific\nworkloads in high-performance computing. By analyzing canonical examples of HPC\napplications, we observe unique opportunities and challenges for exploiting\nin-network computing to accelerate scientific workloads. In particular, we find\nthat the dynamic and demanding nature of scientific workloads is the major\nobstacle to the adoption of in-network approaches which are mostly open-loop\nand lack runtime feedback. In this paper, we present NSinC (Network-accelerated\nScIeNtific Computing), an architecture for fully unleashing the potential\nbenefits of in-network computing for scientific workloads by providing\nclosed-loop runtime feedback to in-network acceleration services. We outline\nkey challenges in realizing this vision and a preliminary design to enable\nacceleration for scientific applications.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 04:35:21 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kim", "Daehyeok", ""], ["Jain", "Ankush", ""], ["Liu", "Zaoxing", ""], ["Amvrosiadis", "George", ""], ["Hazen", "Damian", ""], ["Settlemyer", "Bradley", ""], ["Sekar", "Vyas", ""]]}, {"id": "2009.02473", "submitter": "Muhammad Usama", "authors": "Muhammad Usama, Rupendra Nath Mitra, Inaam Ilahi, Junaid Qadir, and\n  Mahesh K. Marina", "title": "Examining Machine Learning for 5G and Beyond through an Adversarial Lens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spurred by the recent advances in deep learning to harness rich information\nhidden in large volumes of data and to tackle problems that are hard to\nmodel/solve (e.g., resource allocation problems), there is currently tremendous\nexcitement in the mobile networks domain around the transformative potential of\ndata-driven AI/ML based network automation, control and analytics for 5G and\nbeyond. In this article, we present a cautionary perspective on the use of\nAI/ML in the 5G context by highlighting the adversarial dimension spanning\nmultiple types of ML (supervised/unsupervised/RL) and support this through\nthree case studies. We also discuss approaches to mitigate this adversarial ML\nrisk, offer guidelines for evaluating the robustness of ML models, and call\nattention to issues surrounding ML oriented research in 5G more generally.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 06:30:26 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Usama", "Muhammad", ""], ["Mitra", "Rupendra Nath", ""], ["Ilahi", "Inaam", ""], ["Qadir", "Junaid", ""], ["Marina", "Mahesh K.", ""]]}, {"id": "2009.02742", "submitter": "Quan-Lin Li", "authors": "Heng-Li Liu, Quan-Lin Li, Chi Zhang", "title": "Matched Queues with Matching Batch Pair (m, n)", "comments": "52 Pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2001.00946", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.AI cs.DC cs.NI math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss an interesting but challenging bilateral\nstochastically matching problem: A more general matched queue with matching\nbatch pair (m, n) and two types (i.e., types A and B) of impatient customers,\nwhere the arrivals of A- and B-customers are both Poisson processes, m\nA-customers and n B-customers are matched as a group which leaves the system\nimmediately, and the customers' impatient behavior is to guarantee the\nstability of the system. We show that this matched queue can be expressed as a\nnovel bidirectional level-dependent quasi-birth-and-death (QBD) process. Based\non this, we provide a detailed analysis for this matched queue, including the\nsystem stability, the average stationary queue lengthes, and the average\nsojourn time of any A-customer or B-customer. We believe that the methodology\nand results developed in this paper can be applicable to dealing with more\ngeneral matched queueing systems, which are widely encountered in various\npractical areas, for example, sharing economy, ridesharing platform, bilateral\nmarket, organ transplantation, taxi services, assembly systems, and so on.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 14:14:47 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 16:51:22 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 09:03:29 GMT"}, {"version": "v4", "created": "Fri, 19 Mar 2021 07:23:08 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Liu", "Heng-Li", ""], ["Li", "Quan-Lin", ""], ["Zhang", "Chi", ""]]}, {"id": "2009.02771", "submitter": "Tasneem Darwish Dr.", "authors": "Tasneem Darwish, Gunes Karabulut Kurt, Halim Yanikomeroglu, Gamini\n  Senarath, and Peiying Zhu", "title": "A Vision of Self-Evolving Network Management for Future Intelligent\n  Vertical HetNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future integrated terrestrial-aerial-satellite networks will have to exhibit\nsome unprecedented characteristics for the provision of both communications and\ncomputation services, and security for a tremendous number of devices with very\nbroad and demanding requirements across multiple networks, operators, and\necosystems. Although 3GPP introduced the concept of self-organization networks\n(SONs) in 4G and 5G documents to automate network management, even this\nprogressive concept will face several challenges as it may not be sufficiently\nagile in coping with the immense levels of complexity, heterogeneity, and\nmobility in the envisioned beyond-5G integrated networks. In the presented\nvision, we discuss how future integrated networks can be intelligently and\nautonomously managed to efficiently utilize resources, reduce operational\ncosts, and achieve the targeted Quality of Experience (QoE). We introduce the\nnovel concept of \"self-evolving networks (SENs)\" framework, which utilizes\nartificial intelligence, enabled by machine learning (ML) algorithms, to make\nfuture integrated networks fully automated and intelligently evolve with\nrespect to the provision, adaptation, optimization, and management aspects of\nnetworking, communications, computation, and infrastructure nodes' mobility. To\nenvisage the concept of SEN in future integrated networks, we use the\nIntelligent Vertical Heterogeneous Network (I-VHetNet) architecture as our\nreference. The paper discusses five prominent scenarios where SEN plays the\nmain role in providing automated network management. Numerical results provide\nan insight on how the SEN framework improves the performance of future\nintegrated networks. The paper presents the leading enablers and examines the\nchallenges associated with the application of SEN concept in future integrated\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 16:35:54 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 02:22:58 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Darwish", "Tasneem", ""], ["Kurt", "Gunes Karabulut", ""], ["Yanikomeroglu", "Halim", ""], ["Senarath", "Gamini", ""], ["Zhu", "Peiying", ""]]}, {"id": "2009.02858", "submitter": "Hessam Moeini", "authors": "Hessam Moeini, I-Ling Yen, Farokh Bastani", "title": "Summarization in Semantic Based Service Discovery in Dynamic IoT-Edge\n  Networks", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, many semantic-based routing protocols had been designed\nfor peer-to-peer systems. However, they are not suitable for IoT systems,\nmainly due to their high demands in memory and computing power which are not\navailable in many IoT devices. In this paper, we develop a semantic-based\nrouting protocol for dynamic IoT systems to facilitate dynamic IoT capability\ndiscovery and composition. Our protocol is a fully decentralized routing\nprotocol. To reduce the space requirement for routing, each node maintains a\nsummarized routing table. We design an ontology-based summarization algorithm\nto smartly group similar capabilities in the routing tables and support\nadaptive routing table compression. We also design an ontology coding scheme to\ncode keywords used in the routing tables and query messages. To complete the\nsummarization scheme, we consider the metrics for choosing the summarization\ncandidates in an overflowing routing table. Some of these metrics are novel and\nare difficult to measure, such as coverage and stability. Our solutions\nsignificantly reduce the routing table size, ensuring that the routing table\nsize can be bounded by the available memory of the IoT devices, while\nsupporting efficient IoT capability lookup. Experimental results show that our\napproach can yield significantly lower network traffic and memory requirement\nfor IoT capability lookup when compared with existing semantic-based routing\nalgorithms including a centralized solution, a DHT-based approach, a controlled\nflooding scheme, and a cache-based solution.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 02:16:33 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Moeini", "Hessam", ""], ["Yen", "I-Ling", ""], ["Bastani", "Farokh", ""]]}, {"id": "2009.02983", "submitter": "Tiegang Fan", "authors": "Fan Tiegang and Chen Junmin", "title": "A node deployment model with variable transmission distance for wireless\n  sensor networks", "comments": null, "journal-ref": "International Journal of Wireless & Mobile Networks (IJWMN) Vol.\n  12, No.4, August 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of network nodes is essential to ensure the wireless sensor\nnetwork's regular operation and affects the multiple network performance\nmetrics, such as connectivity, coverage, lifetime, and cost. This paper focuses\non the problem of minimizing network costs while meeting network requirements,\nand proposes a corona-based deployment method by using the variable\ntransmission distance sensor. Based on the analysis of node energy consumption\nand network cost, an optimization model to minimize Cost Per Unit Area is\ngiven. The transmission distances and initial energy of the sensors are\nobtained by solving the model. The optimization model is improved to ensure the\nenergy consumption balance of nodes in the same corona. Based on these\nparameters, the process of network node deployment is given. Deploying the\nnetwork through this method will greatly reduce network costs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:58:28 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Tiegang", "Fan", ""], ["Junmin", "Chen", ""]]}, {"id": "2009.03145", "submitter": "Cheng-Shang Chang", "authors": "Tzu-Hsuan Liu, Che-Hao Yu, Yi-Jheng Lin, Cheng-Shang Chang, Duan-Shin\n  Lee", "title": "ALOHA Receivers: a Network Calculus Approach for Analyzing Coded\n  Multiple Access with SIC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need to hide the complexity of the physical layer from\nperformance analysis in a layer 2 protocol, a class of abstract receivers,\ncalled Poisson receivers, was recently proposed in [1] as a probabilistic\nframework for providing differentiated services in uplink transmissions in 5G\nnetworks. In this paper, we further propose a deterministic framework of ALOHA\nreceivers that can be incorporated into the probabilistic framework of Poisson\nreceivers for analyzing coded multiple access with successive interference\ncancellation. An ALOHA receiver is characterized by a success function of the\nnumber of packets that can be successfully received. Inspired by the theory of\nnetwork calculus, we derive various algebraic properties for several operations\non success functions and use them to prove various closure properties of ALOHA\nreceivers, including (i) ALOHA receivers in tandem, (ii) cooperative ALOHA\nreceivers, (iii) ALOHA receivers with traffic multiplexing, and (iv) ALOHA\nreceivers with packet coding. By conducting extensive simulations, we show that\nour theoretical results match extremely well with the simulation results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:00:04 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Liu", "Tzu-Hsuan", ""], ["Yu", "Che-Hao", ""], ["Lin", "Yi-Jheng", ""], ["Chang", "Cheng-Shang", ""], ["Lee", "Duan-Shin", ""]]}, {"id": "2009.03164", "submitter": "Yulei Wu", "authors": "Yulei Wu, Hong-Ning Dai, Hao Wang, Kim-Kwang Raymond Choo", "title": "Blockchain-based Privacy Preservation for 5G-enabled Drone\n  Communications", "comments": "8 pages, 3 figure, accepted by IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G-enabled drones have potential applications in a variety of both military\nand civilian settings (e.g., monitoring and tracking of individuals in\ndemonstrations and/or enforcing of social / physical distancing during\npandemics such as COVID-19). Such applications generally involve the collection\nand dissemination of (massive) data from the drones to remote data centres for\nstorage and analysis, for example via 5G networks. Consequently, there are\nsecurity and privacy considerations underpinning 5G-enabled drone\ncommunications. We posit the potential of leveraging blockchain to facilitate\nprivacy preservation, and therefore in this article we will review existing\nblockchain-based solutions after introducing the architecture for 5G-enabled\ndrone communications and blockchain. We will also review existing legislation\nand data privacy regulations that need to be considered in the design of\nblockchain-based solutions, as well as identifying potential challenges and\nopen issues which will hopefully inform future research agenda.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:27:52 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Wu", "Yulei", ""], ["Dai", "Hong-Ning", ""], ["Wang", "Hao", ""], ["Choo", "Kim-Kwang Raymond", ""]]}, {"id": "2009.03433", "submitter": "Rojin Aslani", "authors": "Rojin Aslani and Mehdi Rasti", "title": "A Distributed Power Control Algorithm for Energy Efficiency Maximization\n  in Wireless Cellular Networks", "comments": "This paper has beeen published in IEEE Wireless Communications\n  Letters (Early Access) in Jul. 2020", "journal-ref": "IEEE Wireless Communications Letters (Early Access), 17 Jul. 2020", "doi": "10.1109/LWC.2020.3010156", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a distributed power control algorithm for\naddressing the global energy efficiency (GEE) maximization problem subject to\nsatisfying a minimum target SINR for all user equipments (UEs) in wireless\ncellular networks. We state the problem as a multi-objective optimization\nproblem which targets minimizing total power consumption and maximizing total\nthroughput, simultaneously, while a minimum target SINR is guaranteed for all\nUEs. We propose an iterative scheme executed in the UEs to control their\ntransmit power using individual channel state information (CSI) such that the\nGEE is maximized in a distributed manner. We prove the convergence of the\nproposed iterative algorithm to its corresponding unique fixed point also shown\nby our numerical results. Additionally, simulation results demonstrate that our\nproposed scheme outperforms other algorithms in the literature and performs\nlike the centralized algorithm executed in the base station and maximizes the\nGEE using the global CSI.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 21:30:49 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Aslani", "Rojin", ""], ["Rasti", "Mehdi", ""]]}, {"id": "2009.03458", "submitter": "Sanjay Seshan", "authors": "Sanjay Seshan", "title": "Horus: Using Sensor Fusion to Combine Infrastructure and On-board\n  Sensing to Improve Autonomous Vehicle Safety", "comments": "Presented at Intel ISEF 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies predict that demand for autonomous vehicles will increase tenfold\nbetween 2019 and 2026. However, recent high-profile accidents have\nsignificantly impacted consumer confidence in this technology. The cause for\nmany of these accidents can be traced back to the inability of these vehicles\nto correctly sense the impending danger. In response, manufacturers have been\nimproving the already extensive on-vehicle sensor packages to ensure that the\nsystem always has access to the data necessary to ensure safe navigation.\nHowever, these sensor packages only provide a view from the vehicle's\nperspective and, as a result, autonomous vehicles still require frequent human\nintervention to ensure safety.\n  To address this issue, I developed a system, called Horus, that combines\non-vehicle and infrastructure-based sensors to provide a more complete view of\nthe environment, including areas not visible from the vehicle. I built a\nsmall-scale experimental testbed as a proof of concept. My measurements of the\nimpact of sensor failures showed that even short outages (1 second) at slow\nspeeds (25 km/hr scaled velocity) prevents vehicles that rely on on-vehicle\nsensors from navigating properly. My experiments also showed that Horus\ndramatically improves driving safety and that the sensor fusion algorithm\nselected plays a significant role in the quality of the navigation. With just a\npair of infrastructure sensors, Horus could tolerate sensors that fail 40% of\nthe time and still navigate safely. These results are a promising first step\ntowards safer autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 23:52:57 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Seshan", "Sanjay", ""]]}, {"id": "2009.03575", "submitter": "Cunlai Pu", "authors": "Jiexin Wu, Cunlai Pu, Shuxin Ding, Guo Cao, and Panos M. Pardalos", "title": "NC-MOPSO: Network centrality guided multi-objective particle swarm\n  optimization for transport optimization on networks", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transport processes are universal in real-world complex networks, such as\ncommunication and transportation networks. As the increase of the traffic in\nthese complex networks, problems like traffic congestion and transport delay\nare becoming more and more serious, which call for a systematic optimization of\nthese networks. In this paper, we formulate a multi-objective optimization\nproblem (MOP) to deal with the enhancement of network capacity and efficiency\nsimultaneously, by appropriately adjusting the weights of edges in networks. To\nsolve this problem, we provide a multi-objective evolutionary algorithm (MOEA)\nbased on particle swarm optimization (PSO), namely network centrality guided\nmulti-objective PSO (NC-MOPSO). Specifically, in the framework of PSO, we\npropose a hybrid population initialization mechanism and a local search\nstrategy by employing the network centrality theory to enhance the quality of\ninitial solutions and strengthen the exploration of the search space,\nrespectively. Simulation experiments performed on network models and real\nnetworks show that our algorithm has better performance than four\nstate-of-the-art alternatives on several most-used metrics.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 08:21:56 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 14:16:22 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 11:31:22 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Wu", "Jiexin", ""], ["Pu", "Cunlai", ""], ["Ding", "Shuxin", ""], ["Cao", "Guo", ""], ["Pardalos", "Panos M.", ""]]}, {"id": "2009.03638", "submitter": "Zilong Liu", "authors": "Hamidreza Bagheri, Md Noor-A-Rahim, Zilong Liu, Haeyoung Lee, Dirk\n  Pesch, Klaus Moessner, and Pei Xiao", "title": "5G NR-V2X: Towards Connected and Cooperative Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the key features and fundamental technology\ncomponents for 5G New Radio (NR) for genuine realization of connected and\ncooperative autonomous driving. We discuss the major functionalities of\nphysical layer, Sidelink features and its resource allocation, architecture\nflexibility, security and privacy mechanisms, and precise positioning\ntechniques with an evolution path from existing cellular vehicle-to-everything\n(V2X) technology towards NR-V2X. Moreover, we envisage and highlight the\npotential of machine learning for further enhancement of various NR-V2X\nservices. Lastly, we show how 5G NR can be configured to support advanced V2X\nuse cases in autonomous driving.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 10:59:08 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Bagheri", "Hamidreza", ""], ["Noor-A-Rahim", "Md", ""], ["Liu", "Zilong", ""], ["Lee", "Haeyoung", ""], ["Pesch", "Dirk", ""], ["Moessner", "Klaus", ""], ["Xiao", "Pei", ""]]}, {"id": "2009.03640", "submitter": "Souhila Silmi", "authors": "Souhila Silmi, Zouina Doukha, Rebiha Kemcha and Samira Moussaoui", "title": "Wireless sensor networks simulators and testbeds", "comments": "19 pages 10 figures 6th International Conference on Networks and\n  Communications (NCO 2020)", "journal-ref": "9th International Conference on Advanced Information Technologies\n  and Applications ICAITA 2020, July 2020, Toronto, Canada, pages 141", "doi": "10.5121/csit.2020.100901- 10.5121/csit.2020.100921", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless sensor networks (WSNs) have emerged as one of the most promising\ntechnologies for the current era. Researchers have studied them for several\nyears ago, but more work still needed to be made since open opportunities to\nintegrate new technologies are added to this field. One challenging task is WSN\ndeployment. Yet, this is done by real deployment with testbeds platforms or by\nsimulation tools when real deployment could be costly and time-consuming. In\nthis paper, we review the implementation and evaluation process in WSNs. We\nthen describe relevant testbeds and simulation tools, and their features.\nLastly, we conduct an experimentation study using these testbeds and\nsimulations to highlight their pro and cons. As a use case, we implement a\nlocalization protocol. This work gives clarity to future-work for better\nimplementation in order to improve reliability, accuracy and time consumed.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 11:04:06 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Silmi", "Souhila", ""], ["Doukha", "Zouina", ""], ["Kemcha", "Rebiha", ""], ["Moussaoui", "Samira", ""]]}, {"id": "2009.03715", "submitter": "Amir Mirzaeinia", "authors": "Amir Mirzaeinnia, Mehdi Mirzaeinia, Abdelmounaam Rezgui", "title": "Latency and Throughput Optimization in Modern Networks: A Comprehensive\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.PF", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modern applications are highly sensitive to communication delays and\nthroughput. This paper surveys major attempts on reducing latency and\nincreasing the throughput. These methods are surveyed on different networks and\nsurroundings such as wired networks, wireless networks, application layer\ntransport control, Remote Direct Memory Access, and machine learning based\ntransport control.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:17:26 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Mirzaeinnia", "Amir", ""], ["Mirzaeinia", "Mehdi", ""], ["Rezgui", "Abdelmounaam", ""]]}, {"id": "2009.03721", "submitter": "Haixia Peng", "authors": "Haixia Peng and Xuemin Shen", "title": "DDPG-based Resource Management for MEC/UAV-Assisted Vehicular Networks", "comments": "6 pages, 4 figures, accepted by VTC_Fall 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate joint vehicle association and multi-dimensional\nresource management in a vehicular network assisted by multi-access edge\ncomputing (MEC) and unmanned aerial vehicle (UAV). To efficiently manage the\navailable spectrum, computing, and caching resources for the MEC-mounted base\nstation and UAVs, a resource optimization problem is formulated and carried out\nat a central controller. Considering the overlong solving time of the\nformulated problem and the sensitive delay requirements of vehicular\napplications, we transform the optimization problem using reinforcement\nlearning and then design a deep deterministic policy gradient (DDPG)-based\nsolution. Through training the DDPG-based resource management model offline,\noptimal vehicle association and resource allocation decisions can be obtained\nrapidly. Simulation results demonstrate that the DDPG-based resource management\nscheme can converge within 200 episodes and achieve higher\ndelay/quality-of-service satisfaction ratios than the random scheme.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 21:41:34 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Peng", "Haixia", ""], ["Shen", "Xuemin", ""]]}, {"id": "2009.03740", "submitter": "Matteo Varvello", "authors": "Matteo Varvello, Benjamin Livshits", "title": "On the Battery Consumption of Mobile Browsers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.NI eess.SP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Mobile web browsing has recently surpassed desktop browsing both in term of\npopularity and traffic. Following its desktop counterpart, the mobile browsers\necosystem has been growing from few browsers (Chrome, Firefox, and Safari) to a\nplethora of browsers, each with unique characteristics (battery friendly,\nprivacy preserving, lightweight, etc.). In this paper, we introduce a browser\nbenchmarking pipeline for Android browsers encompassing automation, in-depth\nexperimentation, and result analysis. We tested 15 Android browsers, using\nCappuccino a novel testing suite we built for third party Android applications.\nWe perform a battery-centric analysis of such browsers and show that: 1)\npopular browsers tend also to consume the most, 2) adblocking produces\nsignificant battery savings (between 20 and 40% depending on the browser), and\n3) dark mode offers an extra 10% battery savings on AMOLED screens. We exploit\nthis observation to build AttentionDim, a screen dimming mechanism driven by\nbrowser events. Via integration with the Brave browser and 10 volunteers, we\nshow potential battery savings up to 30%, on both devices with AMOLED and LCD\nscreens.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 22:01:41 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Varvello", "Matteo", ""], ["Livshits", "Benjamin", ""]]}, {"id": "2009.03741", "submitter": "Caitlyn Singam", "authors": "Caitlyn A. K. Singam", "title": "Trade-off analysis of disruption-tolerant networking protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this analysis was to simulate the performance of three\ndifferent ad-hoc protocols for disruption-tolerant networking (DTN) - i.e. the\ntransfer of information through a network of nodes in contexts prone to signal\ninterruption/signal degradation - and to perform a trade-off analysis that will\nyield a recommendation of the best course of action (COA) for a user of a\nspace-based network to employ. This is important for space-based networks in\nparticular since transmitting information over long distances - e.g. from\ndirectly from the initial node to the destination node - will result in the\nterminal signal being relatively weak, which is problematic in a high noise\n(disruption-prone) environment since it will likely result in packet\ndegradation or loss unless signal power is increased to compensate. Given that\nchanging signal power for each transmission is impractical when one's network\nis located in space, optimization of the signal route is the best means of\nensuring the transmitted signal reaches its destination rapidly and with\nmaximum fidelity. The recommended COA, as determined at the end of the\nanalysis, is one that optimizes performance in a fashion that minimizes error\nduring transmission and transmission time to the greatest extent possible. This\nanalysis takes into consideration the relative value of transmission time and\ntransmission error for a user of space-based communication systems (for\ninstance, a scientific mission - the most likely type of user for a space-based\nrelay network - would prioritize data integrity much higher than transmission\ntime since even though a longer transmission time equals greater cost, a lower\nlevel of data integrity could result in the mission's scientific objective\nbeing compromised) and provides a recommendation accordingly.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 18:54:05 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 01:14:17 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Singam", "Caitlyn A. K.", ""]]}, {"id": "2009.03743", "submitter": "Fuqiang Gu Dr", "authors": "Fuqiang Gu, Milad Ramezani, Kourosh Khoshelham, Xiaoping Zheng, Ruiqin\n  Zhou and Jianga Shang", "title": "Fast and Reliable WiFi Fingerprint Collection for Indoor Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fingerprinting is a popular indoor localization technique since it can\nutilize existing infrastructures (e.g., access points). However, its site\nsurvey process is a labor-intensive and time-consuming task, which limits the\napplication of such systems in practice. In this paper, motivated by the\navailability of advanced sensing capabilities in smartphones, we propose a fast\nand reliable fingerprint collection method to reduce the time and labor\nrequired for site survey. The proposed method uses a landmark graph-based\nmethod to automatically associate the collected fingerprints, which does not\nrequire active user participation. We will show that besides fast fingerprint\ndata collection, the proposed method results in accurate location estimate\ncompared to the state-of-the-art methods. Experimental results show that the\nproposed method is an order of magnitude faster than the manual fingerprint\ncollection method, and using the radio map generated by our method achieves a\nmuch better accuracy compared to the existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 03:51:58 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Gu", "Fuqiang", ""], ["Ramezani", "Milad", ""], ["Khoshelham", "Kourosh", ""], ["Zheng", "Xiaoping", ""], ["Zhou", "Ruiqin", ""], ["Shang", "Jianga", ""]]}, {"id": "2009.03746", "submitter": "Elham Kalantari", "authors": "Elham Kalantari, Halim Yanikomeroglu, and Abbas Yongacoglu", "title": "Wireless Networks with Cache-Enabled and Backhaul-Limited Aerial Base\n  Stations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of aerial base stations (ABSs) is a promising approach to enhance the\nagility and flexibility of future wireless networks. ABSs can improve the\ncoverage and/or capacity of a network by moving supply towards demand.\nDeploying ABSs in a network presents several challenges such as finding an\nefficient 3D-placement of ABSs that takes network objectives into account.\nAnother challenge is the limited wireless backhaul capacity of ABSs and\nconsequently, potentially higher latency incurred. Content caching is proposed\nto alleviate the backhaul congestion and decrease the latency. We consider a\nlimited backhaul capacity for ABSs due to varying position-dependent path loss\nvalues and define two groups of users (delay-tolerant and delay-sensitive) with\ndifferent data rate requirements. We study the problem of jointly determining\nbackhaul-aware 3D placement for ABSs, user-BS associations and corresponding\nbandwidth allocations while minimizing total downlink transmit power. Proposed\niterative algorithm applies a decomposition method. First, the 3D locations of\nABSs are found using semi-definite relaxation and coordinate descent methods,\nand then user-BS associations and bandwidth allocations are optimized. The\nsimulation results demonstrate the effectiveness of the proposed algorithm and\nprovide insights about the impact of traffic distribution and content caching\non transmit power and backhaul usage of ABSs.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 03:43:43 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Kalantari", "Elham", ""], ["Yanikomeroglu", "Halim", ""], ["Yongacoglu", "Abbas", ""]]}, {"id": "2009.03748", "submitter": "Jatin Sharma", "authors": "Jatin Sharma and Vishwanath Sinha", "title": "Development of Adaptive Frame Reservation Scheme and Naive Persistent\n  State Co-Located Coexistence Controller", "comments": "19 pages, Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future broadband networks need to provide high capacity at low cost with\nincreased revenue through enhanced services. WiMAX came up as one of the\nleading technologies, however, the 2.3 GHz and 2.5 GHz frequency bands\nallocated create two serious coexistence issues with the adjacent 2.4 GHz ISM\nband. First problem is to address radio interfaces that are located on two\nindependent platforms and still possess the potential for mutual interference\nowing to close proximity to each other. The Adaptive Frame Reservation Scheme\npresented here extends the CTS frame reservation signaling defined in 802.11\nspecifications to a demand based and adaptive scheme. Second issue is to\naddress the coexistence problem in multi-radio platforms where two or more\nradios are co-located, creating an even worse interference scenario. This can\nbe managed by hardware signaling that can be made available between radio\ninterfaces through OS control. The development of a smart Co-located\nCoexistence Controller is explored which continuously receives transmission,\nreception and sleep requests from attached interfaces and in return grant\npermissions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 00:56:44 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 18:46:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sharma", "Jatin", ""], ["Sinha", "Vishwanath", ""]]}, {"id": "2009.03756", "submitter": "Abdallah Moubayed", "authors": "Abdallah Moubayed and Tanveer Ahmed and Anwar Haque and Abdallah Shami", "title": "Machine Learning Towards Enabling Spectrum-as-a-Service Dynamic Sharing", "comments": "6 pages, 2 figures, Accepted and presented in 2020 IEEE Canadian\n  Conference On Electrical And Computer Engineering (CCECE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth in wireless broadband users, devices, and novel applications has\nled to a significant increase in the demand for new radio frequency spectrum.\nThis is expected to grow even further given the projection that the global\ntraffic per year will reach 4.8 zettabytes by 2022. Moreover, it is projected\nthat the number of Internet users will reach 4.8 billion and the number of\nconnected devices will be close 28.5 billion devices. However, due to the\nspectrum being mostly allocated and divided, providing more spectrum to expand\nexisting services or offer new ones has become more challenging. To address\nthis, spectrum sharing has been proposed as a potential solution to improve\nspectrum utilization efficiency. Adopting effective and efficient spectrum\nsharing mechanisms is in itself a challenging task given the multitude of\nlevels and techniques that can be integrated to enable it. To that end, this\npaper provides an overview of the different spectrum sharing levels and\ntechniques that have been proposed in the literature. Moreover, it discusses\nthe potential of adopting dynamic sharing mechanisms by offering\nSpectrum-as-a-Service architecture. Furthermore, it describes the potential\nrole of machine learning models in facilitating the automated and efficient\ndynamic sharing of the spectrum and offering Spectrum-as-a-Service.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:41:02 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Moubayed", "Abdallah", ""], ["Ahmed", "Tanveer", ""], ["Haque", "Anwar", ""], ["Shami", "Abdallah", ""]]}, {"id": "2009.03771", "submitter": "Lanfranco Zanzi", "authors": "Lanfranco Zanzi, Vincenzo Sciancalepore, Andres Garcia-Saavedra, Hans\n  D. Schotten, Xavier Costa-Perez", "title": "LACO: A Latency-Driven Network Slicing Orchestration in Beyond-5G\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TWC.2020.3027963", "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Slicing is expected to become a game changer in the upcoming 5G\nnetworks and beyond, enlarging the telecom business ecosystem through\nstill-unexplored vertical industry profits. This implies that heterogeneous\nservice level agreements (SLAs) must be guaranteed per slice given the\nmultitude of predefined requirements. In this paper, we pioneer a novel radio\nslicing orchestration solution that simultaneously provides-latency and\nthroughput guarantees in a multi-tenancy environment. Leveraging on a solid\nmathematical framework, we exploit the exploration-vs-exploitation paradigm by\nmeans of a multi-armed-bandit-based(MAB) orchestrator, LACO, that makes\nadaptive resource slicing decisions with no prior knowledge on the traffic\ndemand or channel quality statistics. As opposed to traditional MAB methods\nthat are blind to the underlying system, LACO relies on system structure\ninformation to expedite decisions. After a preliminary simulations campaign\nempirically proving the validness of our solution, we provide a robust\nimplementation of LACO using off-the-shelf equipment to fully emulate realistic\nnetwork conditions:near-optimal results within affordable computational time\nare measured when LACO is in place.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:50:39 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Zanzi", "Lanfranco", ""], ["Sciancalepore", "Vincenzo", ""], ["Garcia-Saavedra", "Andres", ""], ["Schotten", "Hans D.", ""], ["Costa-Perez", "Xavier", ""]]}, {"id": "2009.03821", "submitter": "Pratheek Upadhyaya", "authors": "Pratheek S. Upadhyaya, Vijay K. Shah, and Jeffrey H. Reed", "title": "Cross-layer Band Selection and Routing Design for Diverse Band-aware DSA\n  Networks", "comments": "To be published in the proceedings of IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As several new spectrum bands are opening up for shared use, a new paradigm\nof \\textit{Diverse Band-aware Dynamic Spectrum Access} (d-DSA) has emerged.\nd-DSA equips a secondary device with software defined radios (SDRs) and utilize\nwhitespaces (or idle channels) in \\textit{multiple bands}, including but not\nlimited to TV, LTE, Citizen Broadband Radio Service (CBRS), unlicensed ISM. In\nthis paper, we propose a decentralized, online multi-agent reinforcement\nlearning based cross-layer BAnd selection and Routing Design (BARD) for such\nd-DSA networks. BARD not only harnesses whitespaces in multiple spectrum bands,\nbut also accounts for unique electro-magnetic characteristics of those bands to\nmaximize the desired quality of service (QoS) requirements of heterogeneous\nmessage packets; while also ensuring no harmful interference to the primary\nusers in the utilized band. Our extensive experiments demonstrate that BARD\noutperforms the baseline dDSAaR algorithm in terms of message delivery ratio,\nhowever, at a relatively higher network latency, for varying number of primary\nand secondary users. Furthermore, BARD greatly outperforms its single-band DSA\nvariants in terms of both the metrics in all considered scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:33:08 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Upadhyaya", "Pratheek S.", ""], ["Shah", "Vijay K.", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "2009.03963", "submitter": "Fernando Matos PhD", "authors": "Everaldo Andrade, Aldri Santos, Paulo Maciel Jr, Fernando Matos", "title": "Analyzing Cooperative Monitoring and Dissemination of Critical Mobile\n  Events by VANETs", "comments": "This work has been submitted to the Wireless Networks (WINE) journal\n  for possible publication", "journal-ref": null, "doi": "10.1007/s11276-021-02551-z", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The treatment of mobile and simultaneous critical urban events requires\neffective actions by the appropriate authorities. Additionally it implies\ncommunication challenges in the speed and accuracy of their occurrence by the\nentities, as well as dealing with the dynamics and speed in these environments.\nCooperative solutions with shared resources that address these challenges\nbecome a real option in helping to handle these events. This paper presents an\nevaluation of dynamic monitoring and collaborative dissemination supported by\nvehicular groups. It aims to analyze the impact of multiple mobile and fixed\nevents in an urban environment on information propagation, considering barriers\nimposed by the events and the environment. Differently from other studies in\nthe literature, this work takes into account both fixed and mobile events, as\nwell as simultaneous events. NS3 results show that the evaluated system\nmonitored at least 87% and 51.5% of the time for mobile and fixed events\nrespectively, and delivered information over 77% and 50% of the time for those\nevents, with average delay remains close to 0.3s in most scenarios. The results\nalso reveal that a more continuous monitoring of the mobile events is highly\ndependent on the orientation of the vehicles. The main contribution of this\nwork consists of the performance analysis of both fixed and mobile simultaneous\nevents to support studies on how moving events impact on the dissemination and\ndelivery of real-time data, and thus encouraging the development of new data\ndissemination protocols for VANETs.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 19:21:46 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Andrade", "Everaldo", ""], ["Santos", "Aldri", ""], ["Maciel", "Paulo", "Jr"], ["Matos", "Fernando", ""]]}, {"id": "2009.03973", "submitter": "Ren\\'e S{\\o}rensen", "authors": "Ren\\'e Brandborg S{\\o}rensen, Jimmy Jessen Nielsen, Petar Popovski", "title": "Queuing with Deterministic Service Times and No Waiting Lines in Machine\n  Type Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of Machine-Type Communication (MTC) increases the relevance of\nqueuing scenarios with deterministic service times. In this letter, we present\na model for queues without waiting lines and with degenerate service time\ndistributions and show how the framework is extendable to model general service\ntime distributions. Simple bounds and a close approximation of the blocking\nprobability are derived and the results are shown to hold for simulated queues\nwith Markovian and degenerate arrival processes.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 19:51:11 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["S\u00f8rensen", "Ren\u00e9 Brandborg", ""], ["Nielsen", "Jimmy Jessen", ""], ["Popovski", "Petar", ""]]}, {"id": "2009.04175", "submitter": "Marco Giordani", "authors": "Abdelaali Chaoub, Marco Giordani, Brejesh Lall, Vimal Bhatia, Adrian\n  Kliks, Luciano Mendes, Khaled Rabie, Harri Saarnisaari, Amit Singhal, Nan\n  Zhang, Sudhir Dixit, Michele Zorzi", "title": "6G for Bridging the Digital Divide: Wireless Connectivity to Remote\n  Areas", "comments": "This paper has been accepted for publication in IEEE Wireless\n  Communications. 9 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In telecommunications, network service accessibility as a requirement is\nclosely related to equitably serving the population residing at locations that\ncan most appropriately be described as remote. Remote connectivity, however,\nwould have benefited from a more inclusive consideration in the existing\ngenerations of mobile communications. To remedy this, sustainability and its\nsocial impact are being positioned as key drivers of sixth generation's (6G)\nresearch and standardization activities. In particular, there has been a\nconscious attempt to understand the demands of remote wireless connectivity,\nwhich has led to a better understanding of the challenges that lie ahead. In\nthis perspective, this article overviews the key challenges associated with\nconstraints on network design and deployment to be addressed for providing\nbroadband connectivity to rural areas, and proposes novel approaches and\nsolutions for bridging the digital divide in those regions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 09:22:24 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 08:06:14 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chaoub", "Abdelaali", ""], ["Giordani", "Marco", ""], ["Lall", "Brejesh", ""], ["Bhatia", "Vimal", ""], ["Kliks", "Adrian", ""], ["Mendes", "Luciano", ""], ["Rabie", "Khaled", ""], ["Saarnisaari", "Harri", ""], ["Singhal", "Amit", ""], ["Zhang", "Nan", ""], ["Dixit", "Sudhir", ""], ["Zorzi", "Michele", ""]]}, {"id": "2009.04199", "submitter": "Philipp H. Kindt", "authors": "Philipp H. Kindt, Swaminathan Narayanaswamy, Marco Saur, Samarjit\n  Chakraborty", "title": "Optimizing BLE-Like Neighbor Discovery", "comments": "To appear in the IEEE Transactions on Mobile Computing (TMC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neighbor discovery (ND) protocols are used for establishing a first contact\nbetween multiple wireless devices. The energy consumption and discovery latency\nof this procedure are determined by the parametrization of the protocol. In\nmost existing protocols, reception and transmission are temporally coupled.\nSuch schemes are referred to as \\textit{slotted}, for which the problem of\nfinding optimized parametrizations has been studied thoroughly in the\nliterature. However, slotted approaches are not efficient in applications in\nwhich new devices join the network gradually and only the joining devices and a\nmaster node need to run the ND protocol simultaneously. For example, this is\ntypically the case in IoT scenarios or Bluetooth Low Energy (BLE) piconets.\nHere, protocols in which packets are transmitted with periodic intervals (PI)\ncan achieve significantly lower worst-case latencies than slotted ones. For\nthis class of protocols, optimal parameter values remain unknown. To address\nthis, we propose an optimization framework for PI-based BLE-like protocols,\nwhich translates any specified duty-cycle (and therefore energy budget) into a\nset of optimized parameter values. We show that the parametrizations resulting\nfrom one variant of our proposed scheme are optimal when one receiver discovers\none transmitter, and no other parametrization or ND protocol - neither slotted\nnor slotless - can guarantee lower discovery latencies for a given duty-cycle\nin this scenario. Since the resulting protocol utilizes the channel more\naggressively than other ND protocols, beacons will collide more frequently.\nHence, due to collisions, the rate of successful discoveries gracefully\ndecreases for larger numbers of devices discovering each other simultaneously.\nWe also propose a scheme for configuring the BLE protocol (and not just\nBLE-\\textit{like} protocols).\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 10:33:29 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Kindt", "Philipp H.", ""], ["Narayanaswamy", "Swaminathan", ""], ["Saur", "Marco", ""], ["Chakraborty", "Samarjit", ""]]}, {"id": "2009.04271", "submitter": "Jean-Baptiste Dor\\'e", "authors": "Laurent Petit, Jean-Baptiste Dore, Eric Mercier, Claude Brocheton,\n  Julien Legrand, Dimitri Ktenas", "title": "Aggregated Massive Modular Paradigm: A 6G Telecom Infrastructure Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the eve of 5G network deployment worldwide, a new boom in the mass\ndigitization of our personal and professional lifestyles is looming. 5G marks a\nstrong shift in the way in which connectivity will impact our societies and\nindustries. This shift is taking place through a combination of technologies\nthat have progressed business-as-usual with technical improvements. The future\nof 5G, already called 6G, currently belongs to the world of research, which\nmust imagine the future development of mobile digital services in 10 years. In\nthis ever more connected world, ownership of data and protection, control of\necological impact, both energetic and electromagnetic, in addition to guarantee\nan available, flexible network will be essential factors in the success of 6G.\nThis new generation of networks brings along great challenges in terms of\nmodularity, cost effectiveness and power efficiency. We present here a novel\ndisruptive deployment strategy using cost-efficient modules along with\naggregated connectivity meeting these requirements.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 12:52:21 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Petit", "Laurent", ""], ["Dore", "Jean-Baptiste", ""], ["Mercier", "Eric", ""], ["Brocheton", "Claude", ""], ["Legrand", "Julien", ""], ["Ktenas", "Dimitri", ""]]}, {"id": "2009.04315", "submitter": "Fernando Matos PhD", "authors": "Alisson Yury, Everaldo Andrade, Michele Nogueira, Aldri Santos,\n  Fernando Matos", "title": "Social-based Cooperation of Vehicles for Data Dissemination of Critical\n  Urban Events", "comments": "Accepted for presentation at the IEEE Global Communications\n  Conference (GLOBECOM) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical urban events need to be efficiently handled, for instance, through\nrapid notification. VANETs are a promising choice in supporting notification of\ninformation on arbitrary critical events. Although the dynamicity of VANETs\ncompromises the dissemination process, the connections among vehicles based on\nusers' social interests allow for optimizing message exchange and data\ndissemination. This paper introduces SOCIABLE, a robust data dissemination\nsystem for critical urban events that operates in a SIoV network. It is based\non vehicles' community with common interests and/or similar routines and\nemploys social influence of vehicles according to their network location to\nselect relay vehicles. In a comparative analysis on NS3 with the MINUET system,\nSOCIABLE achieved 36.56% less packets transmitted in a dense VANET and a\nmaximum packet delivery delay of 28ms in a sparse VANET, delivering critical\nevent data in a real-time and robust way without overloading the~network.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 14:10:22 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Yury", "Alisson", ""], ["Andrade", "Everaldo", ""], ["Nogueira", "Michele", ""], ["Santos", "Aldri", ""], ["Matos", "Fernando", ""]]}, {"id": "2009.04346", "submitter": "Joberto Martins Prof. Dr.", "authors": "Eliseu M. Oliveira and Rafael F. Reale and Joberto S. B. Martins", "title": "A Methodological Approach to Model CBR-based Systems", "comments": "pp 1-16, 3 figures", "journal-ref": "Journal of Computer and Communications, September 2020, ISSN\n  Online: 2327-5227", "doi": "10.4236/jcc.2020.89001", "report-no": null, "categories": "cs.AI cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) has been used in various areas to support system\noptimization and find solutions where the complexity makes it challenging to\nuse algorithmic and heuristics. Case-based Reasoning (CBR) is an AI technique\nintensively exploited in domains like management, medicine, design,\nconstruction, retail and smart grid. CBR is a technique for problem-solving and\ncaptures new knowledge by using past experiences. One of the main CBR\ndeployment challenges is the target system modeling process. This paper\npresents a straightforward methodological approach to model CBR-based\napplications using the concepts of abstract and concrete models. Splitting the\nmodeling process with two models facilitates the allocation of expertise\nbetween the application domain and the CBR technology. The methodological\napproach intends to facilitate the CBR modeling process and to foster CBR use\nin various areas outside computer science.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:09:56 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Oliveira", "Eliseu M.", ""], ["Reale", "Rafael F.", ""], ["Martins", "Joberto S. B.", ""]]}, {"id": "2009.04579", "submitter": "Richard Sailer", "authors": "Richard Sailer, J\\\"org H\\\"ahner", "title": "An Adaptive Flow-Aware Packet Scheduling Algorithm for Multipath\n  Tunnelling", "comments": "submitted and accepted on IEEE LCN 2019, 4 pages, 5 figures", "journal-ref": "IEEE LCN 2019", "doi": "10.1109/LCN44214.2019.8990739", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes AFMT, a packet scheduling algorithm to achieve adaptive\nflow-aware multipath tunnelling. AFMT has two unique properties. Firstly, it\nimplements robust adaptive traffic splitting for the subtunnels. Secondly, it\ndetects and schedules bursts of packets cohesively, a scheme that already\nenabled traffic splitting for load balancing with little to no packet\nreordering.\n  Several NS-3 experiments over different network topologies show that AFMT\nsuccessfully deals with changing path characteristics due to background traffic\nwhile increasing throughput and reliability.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 21:22:56 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Sailer", "Richard", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "2009.04586", "submitter": "Jatin Sharma", "authors": "Jatin Sharma, Nikhilesh Behera, Priya Venkatraman, Boon Thau Loo", "title": "RapidLearn: A General Purpose Toolkit for Autonomic Networking", "comments": "5 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Defined Networking has unfolded a new area of opportunity in\ndistributed networking and intelligent networks. There has been a great\ninterest in performing machine learning in distributed setting, exploiting the\nabstraction of SDN which makes it easier to write complex ML queries on\nstandard control plane. However, most of the research has been made towards\nspecialized problems (security, performance improvement, middlebox management\netc) and not towards a generic framework. Also, existing tools and software\nrequire specialized knowledge of the algorithm/network to operate or monitor\nthese systems. We built a generic toolkit which abstracts out the underlying\nstructure, algorithms and other intricacies and gives an intuitive way for a\ncommon user to create and deploy distributed machine learning network\napplications. Decisions are made at local level by the switches and\ncommunicated to other switches to improve upon these decisions. Finally, a\nglobal decision is taken by controller based on another algorithm (in our case\nvoting). We demonstrate efficacy of the framework through a simple DDoS\ndetection algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 21:56:26 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Sharma", "Jatin", ""], ["Behera", "Nikhilesh", ""], ["Venkatraman", "Priya", ""], ["Loo", "Boon Thau", ""]]}, {"id": "2009.04635", "submitter": "Bikramjit Singh", "authors": "Bikramjit Singh and Majid Gerami", "title": "Configured Grant for Semi-Deterministic Traffic for Ultra-Reliable and\n  Low Latency Communications", "comments": "6G Wireless Summit 2020, poster paper, 2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Configured Grant-based allocation has been adopted in New Radio 3rd\nGeneration Partnership Project Release 16. This scheme is beneficial in\nsupporting Ultra-Reliable and Low Latency Communication for industrial\ncommunication, a key Fifth Generation mobile communication usage scenario. This\nscheduling mechanism enables a user with a periodic traffic to transmit its\ndata readily and bypasses the signaling entailed to scheduling requests and\nscheduling grants; and provides low latency access. To facilitate\nultra-reliable communication, the scheduling mechanism can allow the user to\ntransmit redundant transmissions at consecutive repetition occasions in a\npre-defined period. However, for the user with semi-deterministic traffic, the\nreliability and latency performance with Configured Grant-based allocation\ndeteriorates. This can be due to, e.g., late data arrival in the buffer, and\nthe user unable to transmit its repetitions, which leads to reliability\ndegradation. To improve the Configured Grant reliability performance with\nsemi-deterministic traffic, we consider various allocation designs utilizing,\ne.g., additional unlicensed spectrum, or flexible transmission in a Configured\nGrant period, or allowing time-gaps between the repetitions, etc. These\nenhancements could be a stepping-stone for Sixth Generation Configured Grant\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 02:05:07 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Singh", "Bikramjit", ""], ["Gerami", "Majid", ""]]}, {"id": "2009.04682", "submitter": "Nagender Aneja", "authors": "Rajarshi Roy Chowdhury, Sandhya Aneja, Nagender Aneja, Emeroylariffion\n  Abas", "title": "Network Traffic Analysis based IoT Device Identification", "comments": null, "journal-ref": "International Conference on Big Data and Internet of Things\n  (BDIOT2020), August 22-24, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Device identification is the process of identifying a device on Internet\nwithout using its assigned network or other credentials. The sharp rise of\nusage in Internet of Things (IoT) devices has imposed new challenges in device\nidentification due to a wide variety of devices, protocols and control\ninterfaces. In a network, conventional IoT devices identify each other by\nutilizing IP or MAC addresses, which are prone to spoofing. Moreover, IoT\ndevices are low power devices with minimal embedded security solution. To\nmitigate the issue in IoT devices, fingerprint (DFP) for device identification\ncan be used. DFP identifies a device by using implicit identifiers, such as\nnetwork traffic (or packets), radio signal, which a device used for its\ncommunication over the network. These identifiers are closely related to the\ndevice hardware and software features. In this paper, we exploit TCP/IP packet\nheader features to create a device fingerprint utilizing device originated\nnetwork packets. We present a set of three metrics which separate some features\nfrom a packet which contribute actively for device identification. To evaluate\nour approach, we used publicly accessible two datasets. We observed the\naccuracy of device genre classification 99.37% and 83.35% of accuracy in the\nidentification of an individual device from IoT Sentinel dataset. However,\nusing UNSW dataset device type identification accuracy reached up to 97.78%.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 06:28:11 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Chowdhury", "Rajarshi Roy", ""], ["Aneja", "Sandhya", ""], ["Aneja", "Nagender", ""], ["Abas", "Emeroylariffion", ""]]}, {"id": "2009.04864", "submitter": "A. F. Isakovic", "authors": "K. Eledlebi, D. Ruta, H. Hildmann, F. Saffre, Y. Al Hammadi, and A. F.\n  Isakovic", "title": "Coverage and Energy Analysis of Mobile Sensor Nodes in Obstructed Noisy\n  Indoor Environment: A Voronoi Approach", "comments": "17 pages, 24 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid deployment of wireless sensor network (WSN) poses the challenge of\nfinding optimal locations for the network nodes, especially so in (i) unknown\nand (ii) obstacle-rich environments. This paper addresses this challenge with\nBISON (Bio-Inspired Self-Organizing Network), a variant of the Voronoi\nalgorithm. In line with the scenario challenges, BISON nodes are restricted to\n(i) locally sensed as well as (ii) noisy information on the basis of which they\nmove, avoid obstacles and connect with neighboring nodes. Performance is\nmeasured as (i) the percentage of area covered, (ii) the total distance\ntraveled by the nodes, (iii) the cumulative energy consumption and (iv) the\nuniformity of nodes distribution. Obstacle constellations and noise levels are\nstudied systematically and a collision-free recovery strategy for failing nodes\nis proposed. Results obtained from extensive simulations show the algorithm\noutperforming previously reported approaches in both, convergence speed, as\nwell as deployment cost.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:56:07 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Eledlebi", "K.", ""], ["Ruta", "D.", ""], ["Hildmann", "H.", ""], ["Saffre", "F.", ""], ["Hammadi", "Y. Al", ""], ["Isakovic", "A. F.", ""]]}, {"id": "2009.05033", "submitter": "Yusheng Xiang", "authors": "Yusheng Xiang, Bing Xu, Tianqing Su, Christine Brach, Samuel S. Mao,\n  Marcus Geimer", "title": "5G meets Construction Machines: Towards a Smart working Site", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fleet management of mobile working machines with the help of connectivity\ncan increase safety and productivity. Although in our previous study, we\nproposed a solution to use IEEE 802.11p to achieve the fleet management of\nconstruction machines, the shortcoming of WIFI may limit the usage of this\ntechnology in some cases. Alternatively, the fifth-generation mobile networks\n(5G) have shown great potential to solve the problems. Thus, as the world's\nfirst academic paper investigating 5G and construction machines' cooperation,\nwe demonstrated the scenarios where 5G can have a significant effect on the\nconstruction machines industry. Also, based on the simulation we made in\n$ns-3$, we compared the performance of 4G and 5G for the most relevant\nconstruction machines scenarios. Last but not least, we showed the feasibility\nof remote-control and self-working construction machines with the help of 5G.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:53:44 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Xiang", "Yusheng", ""], ["Xu", "Bing", ""], ["Su", "Tianqing", ""], ["Brach", "Christine", ""], ["Mao", "Samuel S.", ""], ["Geimer", "Marcus", ""]]}, {"id": "2009.05131", "submitter": "Sukhdeep Singh Dr", "authors": "Navrati Saxena, Prasham Jain, Abhishek Roy, Harman Jit Singh, Sukhdeep\n  Singh and Madhan Raj Kanagarathinam", "title": "Intelligent Ranking for Dynamic Restoration in Next Generation Wireless\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging 5G and next generation 6G wireless are likely to involve myriads of\nconnectivity, consisting of a huge number of relatively smaller cells providing\nultra-dense coverage. Guaranteeing seamless connectivity and service level\nagreements in such a dense wireless system demands efficient network management\nand fast service recovery. However, restoration of a wireless network, in terms\nof maximizing service recovery, typically requires evaluating the service\nimpact of every network element. Unfortunately, unavailability of real-time KPI\ninformation, during an outage, enforces most of the existing approaches to rely\nsignificantly on context-based manual evaluation. As a consequence, configuring\na real-time recovery of the network nodes is almost impossible, thereby\nresulting in a prolonged outage duration. In this article, we explore deep\nlearning to introduce an intelligent, proactive network recovery management\nscheme in anticipation of an eminent network outage. Our proposed method\nintroduces a novel utilization-based ranking scheme of different wireless nodes\nto minimize the service downtime and enable a fast recovery. Efficient\nprediction of network KPI (Key Performance Index), based on actual wireless\ndata demonstrates up to ~54% improvement in service outage.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 20:00:59 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Saxena", "Navrati", ""], ["Jain", "Prasham", ""], ["Roy", "Abhishek", ""], ["Singh", "Harman Jit", ""], ["Singh", "Sukhdeep", ""], ["Kanagarathinam", "Madhan Raj", ""]]}, {"id": "2009.05220", "submitter": "Hong-Ning Dai Prof.", "authors": "Yalin Liu, Hong-Ning Dai, Qubeijian Wang, Muhammad Imran, Nadra\n  Guizani", "title": "Wireless Powering Internet of Things with UAVs: Challenges and\n  Opportunities", "comments": "7 pages, 4 figures", "journal-ref": "IEEE Network, 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unmanned aerial vehicles (UAVs) have the potential to overcome the deployment\nconstraint of Internet of Things (IoT) in remote or rural area. Wirelessly\npowered communications (WPC) can address the battery limitation of IoT devices\nthrough transferring wireless power to IoT devices. The integration of UAVs and\nWPC, namely UAV-enabled Wireless Powering IoT (Ue-WPIoT) can greatly extend the\nIoT applications from cities to remote or rural areas. In this article, we\npresent a state-of-the-art overview of Ue-WPIoT by first illustrating the\nworking flow of Ue-WPIoT and discussing the challenges. We then introduce the\nenabling technologies in realizing Ue-WPIoT. Simulation results validate the\neffectiveness of the enabling technologies in Ue-WPIoT. We finally outline the\nfuture directions and open issues.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 04:02:14 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Liu", "Yalin", ""], ["Dai", "Hong-Ning", ""], ["Wang", "Qubeijian", ""], ["Imran", "Muhammad", ""], ["Guizani", "Nadra", ""]]}, {"id": "2009.05240", "submitter": "DongNyeong Heo", "authors": "DongNyeong Heo, Stanislav Lange, Hee-Gon Kim and Heeyoul Choi", "title": "Graph Neural Network based Service Function Chaining for Automatic\n  Network Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined networking (SDN) and the network function virtualization\n(NFV) led to great developments in software based control technology by\ndecreasing expenditures. Service function chaining (SFC) is an important\ntechnology to find efficient paths in network servers to process all of the\nrequested virtualized network functions (VNF). However, SFC is challenging\nsince it has to maintain high Quality of Service (QoS) even for complicated\nsituations. Although some works have been conducted for such tasks with\nhigh-level intelligent models like deep neural networks (DNNs), those\napproaches are not efficient in utilizing the topology information of networks\nand cannot be applied to networks with dynamically changing topology since\ntheir models assume that the topology is fixed. In this paper, we propose a new\nneural network architecture for SFC, which is based on graph neural network\n(GNN) considering the graph-structured properties of network topology. The\nproposed SFC model consists of an encoder and a decoder, where the encoder\nfinds the representation of the network topology, and then the decoder\nestimates probabilities of neighborhood nodes and their probabilities to\nprocess a VNF. In the experiments, our proposed architecture outperformed\nprevious performances of DNN based baseline model. Moreover, the GNN based\nmodel can be applied to a new network topology without re-designing and\nre-training.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 06:01:27 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Heo", "DongNyeong", ""], ["Lange", "Stanislav", ""], ["Kim", "Hee-Gon", ""], ["Choi", "Heeyoul", ""]]}, {"id": "2009.05394", "submitter": "Thippa Reddy Gadekallu", "authors": "Mohan Krishna Kagita, Navod Thilakarathne, Thippa Reddy Gadekallu, and\n  Praveen Kumar Reddy Maddikunta", "title": "A Review on Security and Privacy of Internet of Medical Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Medical Things (IoMT) are increasing the accuracy,\nreliability, and the production capability of electronic devices by playing a\nvery important part in the industry of healthcare. The available medical\nresources and services related to healthcare are working to get an\ninterconnection with each other by the digital healthcare system by the\ncontribution of the researchers. Sensors, wearable devices, medical devices,\nand clinical devices are all connected to form an ecosystem of the Internet of\nMedical Things. The different applications of healthcare are enabled by the\nInternet of Medical Things to reduce the healthcare costs, to attend the\nmedical responses on time and it also helps in increasing the quality of the\nmedical treatment. The healthcare industry is transformed by the Internet of\nMedical Things as it delivers targeted and personalized medical care and it\nalso seamlessly enables the communication of medical data. Devices used in the\nmedical field and their application are connected to the system of healthcare\nof Information technology with the help of the digital world.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 12:31:40 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Kagita", "Mohan Krishna", ""], ["Thilakarathne", "Navod", ""], ["Gadekallu", "Thippa Reddy", ""], ["Maddikunta", "Praveen Kumar Reddy", ""]]}, {"id": "2009.05534", "submitter": "Jonathan Ling", "authors": "Jonathan Ling and Paul Cautereels", "title": "Fast LDPC GPU Decoder for Cloud RAN", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The GPU as a digital signal processing accelerator for cloud RAN is\ninvestigated. A new design for a 5G NR low density parity check code decoder\nrunning on a GPU is presented. The algorithm is flexibly adaptable to GPU\narchitecture to achieve high resource utilization as well as low latency. It\nimproves over an existing layered design that processes additional codewords in\nparallel to increase utilization. In comparison to a decoder implemented on a\nFPGA (757K gate), the new GPU (24 core) decoder has 3X higher throughput. The\nGPU decoder exhibits 3 to 5X lower decoding power efficiency, as typical of a\ngeneral-purpose processor. Thus, GPUs may find application as cloud\naccelerators where rapid deployment and flexibility are prioritized over\ndecoding power efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:10:33 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Ling", "Jonathan", ""], ["Cautereels", "Paul", ""]]}, {"id": "2009.05682", "submitter": "Mao V. Ngo", "authors": "Mao V. Ngo, Tie Luo, Hieu T. Hoang, and Tony Q.S. Quek", "title": "Coordinated Container Migration and Base Station Handover in Mobile Edge\n  Computing", "comments": "6 pages. Accepted for presentation at the IEEE Global Communications\n  Conference (Globecom), Taipei, Taiwan, Dec. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offloading computationally intensive tasks from mobile users (MUs) to a\nvirtualized environment such as containers on a nearby edge server, can\nsignificantly reduce processing time and hence end-to-end (E2E) delay. However,\nwhen users are mobile, such containers need to be migrated to other edge\nservers located closer to the MUs to keep the E2E delay low. Meanwhile, the\nmobility of MUs necessitates handover among base stations in order to keep the\nwireless connections between MUs and base stations uninterrupted. In this\npaper, we address the joint problem of container migration and base-station\nhandover by proposing a coordinated migration-handover mechanism, with the\nobjective of achieving low E2E delay and minimizing service interruption. The\nmechanism determines the optimal destinations and time for migration and\nhandover in a coordinated manner, along with a delta checkpoint technique that\nwe propose. We implement a testbed edge computing system with our proposed\ncoordinated migration-handover mechanism, and evaluate the performance using\nreal-world applications implemented with Docker container (an\nindustry-standard). The results demonstrate that our mechanism achieves 30%-40%\nlower service downtime and 13%-22% lower E2E delay as compared to other\nmechanisms. Our work is instrumental in offering smooth user experience in\nmobile edge computing.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 23:04:33 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ngo", "Mao V.", ""], ["Luo", "Tie", ""], ["Hoang", "Hieu T.", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2009.05724", "submitter": "Andreas Festag", "authors": "Anupama Hegde and Andreas Festag", "title": "Artery-C -- An OMNeT++ Based Discrete Event Simulation Framework for\n  Cellular V2X", "comments": "12 pages", "journal-ref": null, "doi": "10.1145/3416010.3423240", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cellular Vehicle-to-X (Cellular V2X) is a communication technology that aims\nto facilitate the communication among vehicles and with the roadside\ninfrastructure. Introduced with LTE Release 14, Cellular V2X enables\ndevice-to-device communication to support road safety and traffic efficiency\napplications. We present Artery-C, a simulation framework for the performance\nevaluation of Cellular V2X protocols and V2X applications. Our simulator relies\non the simulation framework SimuLTE and substantially extends it by\nimplementing control and user planes. Besides the vehicle-to-network\ncommunication via the up-/downlink interface, it provides vehicle-to-vehicle\nand vehicle-infrastructure communication via the sidelink interface using the\nmanaged and the unmanaged mode of Cellular V2X (mode 3 and 4, respectively).\nThe simulator also implements advanced features of 5G mobile networks, such as\nvariable numerologies. For the transmission of of V2X messages, it adds a\nnon-IP interface. Artery-C integrates seamlessly into the simulation framework\nArtery, which enables the simulation of standardized V2X messages at the\nfacilities layer as well as the coupling to the mobility simulator SUMO. A\nspecific feature of Artery-C is the support of dynamic switching between all\nmodes of Cellular V2X. In order to demonstrate the capabilities of Artery-C, we\nevaluate V2X-based platooning as a representative use case and present results\nfor mode 3, mode 4 and mode switching in a highway scenario.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 04:13:55 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hegde", "Anupama", ""], ["Festag", "Andreas", ""]]}, {"id": "2009.05776", "submitter": "Amitabh Trehan", "authors": "Walter Hussak and Amitabh Trehan", "title": "Terminating cases of flooding", "comments": "Submitted for journal publication. 26 pages. Related to\n  arXiv:1907.07078, https://doi.org/10.4230/LIPIcs.STACS.2020.17, and\n  https://doi.org/10.1145/3293611.3331586", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Basic synchronous flooding proceeds in rounds. Given a finite undirected\n(network) graph $G$, a set of sources $I \\subseteq G$ initiate flooding in the\nfirst round by every node in $I$ sending the same message to all of its\nneighbours. In each subsequent round, nodes send the message to all of their\nneighbours from which they did not receive the message in the previous round.\nFlooding terminates when no node in $G$ sends a message in a round. The\nquestion of termination has not been settled - rather, non-termination is\nimplicitly assumed to be possible.\n  We show that flooding terminates on every finite graph. In the case of a\nsingle source $g_0$, flooding terminates in $e$ rounds if $G$ is bipartite and\n$j$ rounds with $e < j \\leq e+d+1$ otherwise, where $e$ and $d$ are the\neccentricity of $g_0$ and diameter of $G$ respectively. For\ncommunication/broadcast to all nodes, this is asymptotically time optimal and\nobviates the need for construction and maintenance of spanning structures. We\nextend to dynamic flooding initiated in multiple rounds with possibly multiple\nmessages. The cases where a node only sends a message to neighbours from which\nit did not receive {\\it any} message in the previous round, and where a node\nsends some highest ranked message to all neighbours from which it did not\nreceive {\\it that} message in the previous round, both terminate. All these\ncases also hold if the network graph loses edges over time. Non-terminating\ncases include asynchronous flooding, flooding where messages have fixed delays\nat edges, cases of multiple-message flooding and cases where the network graph\nacquires edges over time.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 12:05:48 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hussak", "Walter", ""], ["Trehan", "Amitabh", ""]]}, {"id": "2009.05966", "submitter": "Primal Wijesekera", "authors": "Primal Wijesekera and Chamath I. Keppitiyagama", "title": "COMONet: Community Mobile Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The density of mobile phones has increased rapidly in recent years. One\ndrawback of the current mobile telephone technology is that it forces all the\ncalls to go through cellular base stations even if the caller and the callee\nare within the radio range of each other. Hybrid cellular networks and\nUnlicensed Mobile Access (UMA) have been proposed as solutions that enable\nmobile phone users to bypass cellular base stations. However, these\ntechnologies either require special hardware or in some cases have to rely on\nthe service providers. We identified that most of the Commodity-off-the-Shelf\nmobile phones are Wi-Fi (and Bluetooth) enabled. We propose a Community Mobile\nNetwork (COMONet) which utilizes Wi-Fi (and Bluetooth) to build ad hoc network\namong mobile phone users to bypass GSM base stations whenever possible. COMONet\ndoes not depend on special noncommodity hardware and it is a software based\nsolution. COMONet monitors all the available paths over the ad hoc network and\nit transparently switches to the regular path over the service provider's GSM\nbase station if a path is not available over the ad hoc network. In COMONet the\ncaller and the callee do not have to be within the Wi-Fi or Bluetooth range of\neach other to make a call since the COMONet is capable of routing calls through\nthe other mobile nodes that are participating in the COMONet.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 09:41:56 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wijesekera", "Primal", ""], ["Keppitiyagama", "Chamath I.", ""]]}, {"id": "2009.06459", "submitter": "Jihong Park", "authors": "Chaouki Ben Issaid, Anis Elgabli, Jihong Park, Mehdi Bennis,\n  M\\'erouane Debbah", "title": "Communication Efficient Distributed Learning with Censored, Quantized,\n  and Generalized Group ADMM", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a communication-efficiently decentralized machine\nlearning framework that solves a consensus optimization problem defined over a\nnetwork of inter-connected workers. The proposed algorithm, Censored and\nQuantized Generalized GADMM (CQ-GGADMM), leverages the worker grouping and\ndecentralized learning ideas of Group Alternating Direction Method of\nMultipliers (GADMM), and pushes the frontier in communication efficiency by\nextending its applicability to generalized network topologies, while\nincorporating link censoring for negligible updates after quantization. We\ntheoretically prove that CQ-GGADMM achieves the linear convergence rate when\nthe local objective functions are strongly convex under some mild assumptions.\nNumerical simulations corroborate that CQ-GGADMM exhibits higher communication\nefficiency in terms of the number of communication rounds and transmit energy\nconsumption without compromising the accuracy and convergence speed, compared\nto the censored decentralized ADMM, and the worker grouping method of GADMM.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:18:19 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 05:37:15 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Issaid", "Chaouki Ben", ""], ["Elgabli", "Anis", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "2009.06579", "submitter": "Tugba Erpek", "authors": "Yi Shi, Yalin E. Sagduyu, Tugba Erpek", "title": "Reinforcement Learning for Dynamic Resource Optimization in 5G Radio\n  Access Network Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a reinforcement learning solution to dynamic resource\nallocation for 5G radio access network slicing. Available communication\nresources (frequency-time blocks and transmit powers) and computational\nresources (processor usage) are allocated to stochastic arrivals of network\nslice requests. Each request arrives with priority (weight), throughput,\ncomputational resource, and latency (deadline) requirements, and if feasible,\nit is served with available communication and computational resources allocated\nover its requested duration. As each decision of resource allocation makes some\nof the resources temporarily unavailable for future, the myopic solution that\ncan optimize only the current resource allocation becomes ineffective for\nnetwork slicing. Therefore, a Q-learning solution is presented to maximize the\nnetwork utility in terms of the total weight of granted network slicing\nrequests over a time horizon subject to communication and computational\nconstraints. Results show that reinforcement learning provides major\nimprovements in the 5G network utility relative to myopic, random, and first\ncome first served solutions. While reinforcement learning sustains scalable\nperformance as the number of served users increases, it can also be effectively\nused to assign resources to network slices when 5G needs to share the spectrum\nwith incumbent users that may dynamically occupy some of the frequency-time\nblocks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:10:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Shi", "Yi", ""], ["Sagduyu", "Yalin E.", ""], ["Erpek", "Tugba", ""]]}, {"id": "2009.06988", "submitter": "Maksym Planeta", "authors": "Maksym Planeta, Jan Bierbaum, Leo Sahaya Daphne Antony, Torsten\n  Hoefler, Hermann H\\\"artig", "title": "MigrOS: Transparent Operating Systems Live Migration Support for\n  Containerised RDMA-applications", "comments": "16 pages, 13 figures, 4 tables, 1 listing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Major data centre providers are introducing RDMA-based networks for their\ntenants, as well as for operating the underlying infrastructure. In comparison\nto traditional socket-based network stacks, RDMA-based networks offer higher\nthroughput, lower latency and reduced CPU overhead. However, transparent\ncheckpoint and migration operations become much more difficult. The key reason\nis that the OS is removed from the critical path of communication. As a result,\nsome of the communication state itself resides in the NIC hardware and is no\nmore under the direct control of the OS. This control includes especially the\nsupport for virtualisation of communication which is needed for live migration\nof communication partners. In this paper, we propose the basic principles\nrequired to implement a migration-capable RDMA-based network. We recommend some\nchanges at the software level and small changes at the hardware level. As a\nproof of concept, we integrate the proposed changes into SoftRoCE, an\nopen-source kernel-level implementation of the RoCE protocol. We claim that\nthese changes introduce no runtime overhead when migration does not happen.\nFinally, we develop a proof-of-concept implementation for migrating\ncontainerised applications that use RDMA-based networks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 11:15:25 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 12:21:28 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Planeta", "Maksym", ""], ["Bierbaum", "Jan", ""], ["Antony", "Leo Sahaya Daphne", ""], ["Hoefler", "Torsten", ""], ["H\u00e4rtig", "Hermann", ""]]}, {"id": "2009.07343", "submitter": "Nariman Torkzaban", "authors": "Nariman Torkzaban, John S. Baras", "title": "Trust-Aware Service Function Chain Embedding: A Path-Based Approach", "comments": "6 pages, Accepted at IEEE NFV-SDN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of network function virtualization (NFV), and\nsoftware-defined networking (SDN), the realization and implementation of\nservice function chains (SFCs) have become much easier. An SFC is an ordered\nset of interconnected virtual network functions (VNFs). NFV allows for\ndecoupling the network functions from proprietary hardware realizing a\nsoftware-based implementation of VNFs on commodity hardware and SDN decouples\nthe network control from its forwarding logic allowing for a more flexible and\nprogrammable traffic routing among the VNFs. The SFC embedding problem (i.e.\nplacement of SFCs on a shared substrate and establishing the corresponding\ntraffic routes between the VNFs), has been extensively studied in the\nliterature. In this paper, we extend a previous work on trust-aware service\nchain embedding with generalizing the role of trust by incorporating the\ntrustworthiness of the service network links and substrate network paths into\nthe SFC embedding decision process. We first introduce and formulate the\npath-based trust-aware service chain embedding problem as a mixed\ninteger-linear program (MILP), and then provide an approximate model-based on\nselecting k-shortest candidate substrate paths for hosting each virtual link,\nto reduce the complexity of the model. We validate the performance of our\nmethods through simulations and conduct a discussion on evaluating the methods\nand some operation trade-offs.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 20:29:08 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 19:24:23 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Torkzaban", "Nariman", ""], ["Baras", "John S.", ""]]}, {"id": "2009.07475", "submitter": "Lin Gao", "authors": "Zhiyuan Wang, Lin Gao, Tong Wang, Jingjing Luo", "title": "Monetizing Edge Service in Mobile Internet Ecosystem", "comments": "This is an online technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile Internet ecosystem, Mobile Users (MUs) purchase wireless data\nservices from Internet Service Provider (ISP) to access to Internet and acquire\nthe interested content services (e.g., online game) from Content Provider (CP).\nThe popularity of intelligent functions (e.g., AI and 3D modeling) increases\nthe computation-intensity of the content services, leading to a growing\ncomputation pressure for the MUs' resource-limited devices. To this end, edge\ncomputing service is emerging as a promising approach to alleviate the MUs'\ncomputation pressure while keeping their quality-of-service, via offloading\nsome computation tasks of MUs to edge (computing) servers deployed at the local\nnetwork edge. Thus, Edge Service Provider (ESP), who deploys the edge servers\nand offers the edge computing service, becomes an upcoming new stakeholder in\nthe ecosystem. In this work, we study the economic interactions of MUs, ISP,\nCP, and ESP in the new ecosystem with edge computing service, where MUs can\nacquire the computation-intensive content services (offered by CP) and offload\nsome computation tasks, together with the necessary raw input data, to edge\nservers (deployed by ESP) through ISP. We first study the MU's Joint Content\nAcquisition and Task Offloading (J-CATO) problem, which aims to maximize his\nlong-term payoff. We derive the off-line solution with crucial insights, based\non which we design an online strategy with provable performance. Then, we study\nthe ESP's edge service monetization problem. We propose a pricing policy that\ncan achieve a constant fraction of the ex-post optimal revenue with an extra\nconstant loss for the ESP. Numerical results show that the edge computing\nservice can stimulate the MUs' content acquisition and improve the payoffs of\nMUs, ISP, and CP.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 05:21:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wang", "Zhiyuan", ""], ["Gao", "Lin", ""], ["Wang", "Tong", ""], ["Luo", "Jingjing", ""]]}, {"id": "2009.07937", "submitter": "Richa Varma", "authors": "Richa Varma, Chris Melville, Claudio Pinello, Tuhin Sahai", "title": "Post Quantum Secure Command and Control of Mobile Agents : Inserting\n  quantum-resistant encryption schemes in the Secure Robot Operating System", "comments": "8 pages, 5 figures, 3 tables, Submitted to The Fourth IEEE\n  International Conference on Robotic Computing 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The secure command and control (C&C) of mobile agents arises in various\nsettings including unmanned aerial vehicles, single pilot operations in\ncommercial settings, and mobile robots to name a few. As more and more of these\napplications get integrated into aerospace and defense use cases, the security\nof the communication channel between the ground station and the mobile agent is\nof increasing importance. The development of quantum computing devices poses a\nunique threat to secure communications due to the vulnerability of asymmetric\nciphers to Shor's algorithm. Given the active development of new quantum\nresistant encryption techniques, we report the first integration of\npost-quantum secure encryption schemes with the robot operating system (ROS)\nand C&C of mobile agents, in general. We integrate these schemes in the\napplication and network layers, and study the performance of these methods by\ncomparing them to present day security schemes such as the widely used RSA\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 21:13:56 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Varma", "Richa", ""], ["Melville", "Chris", ""], ["Pinello", "Claudio", ""], ["Sahai", "Tuhin", ""]]}, {"id": "2009.08044", "submitter": "Mark Hamilton", "authors": "Mark Hamilton, Nick Gonsalves, Christina Lee, Anand Raman, Brendan\n  Walsh, Siddhartha Prasad, Dalitso Banda, Lucy Zhang, Lei Zhang, William T.\n  Freeman", "title": "Large-Scale Intelligent Microservices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.DC cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deploying Machine Learning (ML) algorithms within databases is a challenge\ndue to the varied computational footprints of modern ML algorithms and the\nmyriad of database technologies each with its own restrictive syntax. We\nintroduce an Apache Spark-based micro-service orchestration framework that\nextends database operations to include web service primitives. Our system can\norchestrate web services across hundreds of machines and takes full advantage\nof cluster, thread, and asynchronous parallelism. Using this framework, we\nprovide large scale clients for intelligent services such as speech, vision,\nsearch, anomaly detection, and text analysis. This allows users to integrate\nready-to-use intelligence into any datastore with an Apache Spark connector. To\neliminate the majority of overhead from network communication, we also\nintroduce a low-latency containerized version of our architecture. Finally, we\ndemonstrate that the services we investigate are competitive on a variety of\nbenchmarks, and present two applications of this framework to create\nintelligent search engines, and real-time auto race analytics systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 03:38:28 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 20:51:47 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Hamilton", "Mark", ""], ["Gonsalves", "Nick", ""], ["Lee", "Christina", ""], ["Raman", "Anand", ""], ["Walsh", "Brendan", ""], ["Prasad", "Siddhartha", ""], ["Banda", "Dalitso", ""], ["Zhang", "Lucy", ""], ["Zhang", "Lei", ""], ["Freeman", "William T.", ""]]}, {"id": "2009.08120", "submitter": "Kim Hammar", "authors": "Kim Hammar and Rolf Stadler", "title": "Finding Effective Security Strategies through Reinforcement Learning and\n  Self-Play", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.14128.38405", "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to automatically find security strategies for the use\ncase of intrusion prevention. Following this method, we model the interaction\nbetween an attacker and a defender as a Markov game and let attack and defense\nstrategies evolve through reinforcement learning and self-play without human\nintervention. Using a simple infrastructure configuration, we demonstrate that\neffective security strategies can emerge from self-play. This shows that\nself-play, which has been applied in other domains with great success, can be\neffective in the context of network security. Inspection of the converged\npolicies show that the emerged policies reflect common-sense knowledge and are\nsimilar to strategies of humans. Moreover, we address known challenges of\nreinforcement learning in this domain and present an approach that uses\nfunction approximation, an opponent pool, and an autoregressive policy\nrepresentation. Through evaluations we show that our method is superior to two\nbaseline methods but that policy convergence in self-play remains a challenge.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:41:27 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 16:22:54 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hammar", "Kim", ""], ["Stadler", "Rolf", ""]]}, {"id": "2009.08228", "submitter": "Abhishek  Sinha", "authors": "Debjit Paria, Abhishek Sinha", "title": "LeadCache: Regret-Optimal Caching in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a set-valued online prediction problem in the context of network\ncaching. Assume that multiple users are connected to several caches via a\nbipartite network. At any time slot, each user requests an arbitrary file\nchosen from a large catalog. A user's request at a slot is met if the requested\nfile is cached in at least one of the caches connected to the user. Our\nobjective is to predict, prefetch, and optimally distribute the files on the\ncaches to maximize the total number of cache hits in an online setting. The\nproblem is non-trivial due to the non-convex and non-smooth nature of the\nobjective function. In this paper, we propose $\\texttt{LeadCache}$ - an online\ncaching policy based on the Follow-the-Perturbed-Leader paradigm. We show that\nthe policy is regret-optimal up to a factor of $\\tilde{O}(n^{3/8}),$ where $n$\nis the number of users. We design two efficient implementations of the\n$\\texttt{LeadCache}$ policy, one based on Pipage rounding and the other based\non Madow's sampling, each of which makes precisely one call to an LP-solver per\niteration. With a Strong-Law-type assumption, we show that the total number of\nfile fetches under $\\texttt{LeadCache}$ remains almost surely finite over an\ninfinite horizon. Finally, we derive a tight regret lower bound using results\nfrom graph coloring. We conclude that the learning-based $\\texttt{LeadCache}$\npolicy decisively outperforms the known caching policies both theoretically and\nempirically.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 12:13:26 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 19:26:22 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2021 17:05:28 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Paria", "Debjit", ""], ["Sinha", "Abhishek", ""]]}, {"id": "2009.08492", "submitter": "Mujahid Sultan", "authors": "Mujahid Sultan, Dodi Imbuido, Kam Patel, James MacDonald, and Kumar\n  Ratnam", "title": "Designing knowledge plane to optimize leaf and spine data center", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few decades, data center architecture evolved from the\ntraditional client-server to access-aggregation-core architectures. Recently\nthere is a new shift in the data center architecture due to the increasing need\nfor low latency and high throughput between server-to-server communications,\nload balancing and, loop-free environment. This new architecture, known as leaf\nand spine architecture, provides low latency and minimum packet loss by\nenabling the addition and deletion of network nodes on demand. Network nodes\ncan be added or deleted from the network based on network statistics like link\nspeed, packet loss, latency, and throughput.\n  With the maturity of Open Virtual Switch (OvS) and OpenFlow based Software\nDefined Network (SDN) controllers, network automation through programmatic\nextensions has become possible based on network statistics. The separation of\nthe control plane and data plane has enabled automated management of network\nand Machine Learning (ML) can be applied to learn and optimize the network.\n  In this publication, we propose the design of an ML-based approach to gather\nnetwork statistics and build a knowledge plane. We demonstrate that this\nknowledge plane enables data center optimization using southbound APIs and SDN\ncontrollers. We describe the design components of this approach - using a\nnetwork simulator and show that it can maintain the historical patterns of\nnetwork statistics to predict future growth or decline. We also provide an\nopen-source software that can be utilized in a leaf and spine data center to\nprovide elastic capacity based on load forecasts.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 18:29:11 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Sultan", "Mujahid", ""], ["Imbuido", "Dodi", ""], ["Patel", "Kam", ""], ["MacDonald", "James", ""], ["Ratnam", "Kumar", ""]]}, {"id": "2009.08646", "submitter": "Rahim Rahmani", "authors": "Rahim Rahmani and Ramin Firouzi", "title": "Gateway Controller with Deep Sensing: Learning to be Autonomic in\n  Intelligent Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.LG cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The Internet of Things(IoT) will revolutionize the Future Internet through\nubiquitous sensing. One of the challenges of having the hundreds of billions of\ndevices that are estimated to be deployed would be rise of an enormous amount\nof data, along with the devices ability to manage. This paper presents an\napproach as a controller solution and designed specifically for autonomous\nmanagement, connectivity and data interoperability in an IoT gateway. The\napproach supports distributed IoT nodes with both management and data\ninteroperability with other cloud-based solutions. The concept further allows\ngateways to easily collect and process interoperability of data from IoT\ndevices. We demonstrated the feasibility of the approach and evaluate its\nadvantages regarding deep sensing and autonomous enabled gateway as an edge\ncomputational intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 06:22:04 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Rahmani", "Rahim", ""], ["Firouzi", "Ramin", ""]]}, {"id": "2009.09011", "submitter": "Mario Di Mauro", "authors": "Mario Di Mauro, Giovanni Galatro, Antonio Liotta", "title": "Experimental Review of Neural-based approaches for Network Intrusion\n  Management", "comments": "Early Access on IEEE Transactions on Network and Service Management", "journal-ref": null, "doi": "10.1109/TNSM.2020.3024225", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Machine Learning (ML) techniques in Intrusion Detection Systems\n(IDS) has taken a prominent role in the network security management field, due\nto the substantial number of sophisticated attacks that often pass undetected\nthrough classic IDSs. These are typically aimed at recognising attacks based on\na specific signature, or at detecting anomalous events. However, deterministic,\nrule-based methods often fail to differentiate particular (rarer) network\nconditions (as in peak traffic during specific network situations) from actual\ncyber attacks. In this paper we provide an experimental-based review of\nneural-based methods applied to intrusion detection issues. Specifically, we i)\noffer a complete view of the most prominent neural-based techniques relevant to\nintrusion detection, including deep-based approaches or weightless neural\nnetworks, which feature surprising outcomes; ii) evaluate novel datasets\n(updated w.r.t. the obsolete KDD99 set) through a designed-from-scratch\nPython-based routine; iii) perform experimental analyses including time\ncomplexity and performance (accuracy and F-measure), considering both\nsingle-class and multi-class problems, and identifying trade-offs between\nresource consumption and performance. Our evaluation quantifies the value of\nneural networks, particularly when state-of-the-art datasets are used to train\nthe models. This leads to interesting guidelines for security managers and\ncomputer network practitioners who are looking at the incorporation of\nneural-based ML into IDS.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:32:24 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Di Mauro", "Mario", ""], ["Galatro", "Giovanni", ""], ["Liotta", "Antonio", ""]]}, {"id": "2009.09035", "submitter": "Paul Schmitt", "authors": "Paul Schmitt and Barath Raghavan", "title": "Pretty Good Phone Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To receive service in today's cellular architecture, phones uniquely identify\nthemselves to towers and thus to operators. This is now a cause of major\nprivacy violations, as operators now sell and leak identity and location data\nof hundreds of millions of mobile users.\n  In this paper, we take an end-to-end perspective on the cellular architecture\nand find key points of decoupling that enable us to protect user identity and\nlocation privacy with no changes to physical infrastructure, no added latency,\nand no requirement of direct cooperation from existing operators.\n  We describe Pretty Good Phone Privacy (PGPP) and demonstrate how our modified\nbackend stack (NGC) works with real phones to provide ordinary yet\nprivacy-preserving connectivity. We explore inherent privacy and efficiency\ntradeoffs in a simulation of a large metropolitan region. We show how PGPP\nmaintains today's control overheads while significantly improving user identity\nand location privacy.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 19:27:49 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 12:47:16 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2020 19:49:34 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Schmitt", "Paul", ""], ["Raghavan", "Barath", ""]]}, {"id": "2009.09218", "submitter": "Emmanouil Koulas", "authors": "Emmanouil Koulas, Marios Anthopoulos, Sotiria Grammenou, Christos\n  Kaimakamis, Konstantinos Kousaris, Fotini-Rafailia Panavou, Orestis\n  Piskioulis, Syed Iftikhar H. Shah and Vasilios Peristeras", "title": "Misinformation and its stakeholders in Europe: a web-based analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of the internet and computational power in recent years allowed for\nthe exponential growth of misinformation phenomena. An issue that was a\nnon-issue a decade ago, became a challenge for societal cohesion. The emergence\nof this new threat has led many stakeholders, especially in Europe, to act in\norder to tackle this phenomenon. This paper provides in its first part a\nliterature review on misinformation in Europe, and in its second part a\nwebometrics analysis on the identified key stakeholders. In the results we\ndiscuss who those stakeholders are, what actions do they perform to limit\nmisinformation and whether those actions have an impact.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 12:24:53 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 22:07:08 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Koulas", "Emmanouil", ""], ["Anthopoulos", "Marios", ""], ["Grammenou", "Sotiria", ""], ["Kaimakamis", "Christos", ""], ["Kousaris", "Konstantinos", ""], ["Panavou", "Fotini-Rafailia", ""], ["Piskioulis", "Orestis", ""], ["Shah", "Syed Iftikhar H.", ""], ["Peristeras", "Vasilios", ""]]}, {"id": "2009.09284", "submitter": "Mahdi Jafari Siavoshani", "authors": "Aida Ramezani, Amirhossein Khajehpour, Mahdi Jafari Siavoshani", "title": "On Multi-Session Website Fingerprinting over TLS Handshake", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing users' Internet traffic data and activities has a certain impact on\nusers' experiences in different ways, from maintaining the quality of service\non the Internet and providing users with high-quality recommendation systems to\nanomaly detection and secure connection. Considering that the Internet is a\ncomplex network, we cannot disintegrate the packets for each activity.\nTherefore we have to have a model that can identify all the activities an\nInternet user does in a given period of time. In this paper, we propose a deep\nlearning approach to generate a multi-label classifier that can predict the\nwebsites visited by a user in a certain period. This model works by extracting\nthe server names appearing in chronological order in the TLSv1.2 and TLSv1.3\nClient Hello packets. We compare the results on the test data with a simple\nfully-connected neural network developed for the same purpose to prove that\nusing the time-sequential information improves the performance. For further\nevaluations, we test the model on a human-made dataset and a modified dataset\nto check the model's accuracy under different circumstances. Finally, our\nproposed model achieved an accuracy of 95% on the test dataset and above 90% on\nboth the modified dataset and the human-made dataset.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:18:18 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ramezani", "Aida", ""], ["Khajehpour", "Amirhossein", ""], ["Siavoshani", "Mahdi Jafari", ""]]}, {"id": "2009.09338", "submitter": "Chuan Ma", "authors": "Chuan Ma, Jun Li, Ming Ding, Long Shi, Taotao Wang, Zhu Han and H.\n  Vincent Poor", "title": "When Federated Learning Meets Blockchain: A New Distributed Learning\n  Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the explosive computing capabilities at end user equipments, as\nwell as the growing privacy concerns over sharing sensitive raw data, a new\nmachine learning paradigm, named federated learning (FL) has emerged. By\ntraining models locally at each client and aggregating learning models at a\ncentral server, FL has the capability to avoid sharing data directly, thereby\nreducing privacy leakage. However, the traditional FL framework heavily relies\non a single central server and may fall apart if such a server behaves\nmaliciously. To address this single point of failure issue, this work\ninvestigates a blockchain assisted decentralized FL (BLADE-FL) framework, which\ncan well prevent the malicious clients from poisoning the learning process, and\nfurther provides a self-motivated and reliable learning environment for\nclients. In detail, the model aggregation process is fully decentralized and\nthe tasks of training for FL and mining for blockchain are integrated into each\nparticipant. In addition, we investigate the unique issues in this framework\nand provide analytical and experimental results to shed light on possible\nsolutions.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 03:09:31 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 07:52:28 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Ma", "Chuan", ""], ["Li", "Jun", ""], ["Ding", "Ming", ""], ["Shi", "Long", ""], ["Wang", "Taotao", ""], ["Han", "Zhu", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2009.09371", "submitter": "Takayuki Nishio", "authors": "Takayuki Nishio, Ryoichi Shinkuma, Narayan B. Mandayam", "title": "Estimation of Individual Device Contributions for Incentivizing\n  Federated Learning", "comments": "Submitted to IEEE Globecom Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging technique used to train a\nmachine-learning model collaboratively using the data and computation resource\nof the mobile devices without exposing privacy-sensitive user data.\n  Appropriate incentive mechanisms that motivate the data and mobile-device\nowner to participate in FL is key to building a sustainable platform for FL.\nHowever, it is difficult to evaluate the contribution level of the\ndevices/owners to determine appropriate rewards without large computation and\ncommunication overhead.\n  This paper proposes a computation-and communication-efficient method of\nestimating a participating device's contribution level. The proposed method\nenables such estimation during a single FL training process, there by reducing\nthe need for traffic and computation overhead. The performance evaluations\nusing the MNIST dataset show that the proposed method estimates individual\nparticipants' contributions accurately with 46-49% less computation overhead\nand no communication overhead than a naive estimation method.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:03:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Nishio", "Takayuki", ""], ["Shinkuma", "Ryoichi", ""], ["Mandayam", "Narayan B.", ""]]}, {"id": "2009.09397", "submitter": "Furqan Khan", "authors": "Furqan Hameed Khan, Raja Jurdak, Marius Portmann", "title": "A Model for Reliable Uplink Transmissions in LoRaWAN", "comments": "11 pages, 8 figures", "journal-ref": "Marius (2019) 147-156", "doi": "10.1109/DCOSS.2019.00042", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long range wide area networks (LoRaWAN) technology provides a simple solution\nto enable low-cost services for low power internet-of-things (IoT) networks in\nvarious applications. The current evaluation of LoRaWAN networks relies on\nsimulations or early testing, which are typically time consuming and prevent\neffective exploration of the design space. This paper proposes an analytical\nmodel to calculate the delay and energy consumed for reliable Uplink (UL) data\ndelivery in Class A LoRaWAN. The analytical model is evaluated using a real\nnetwork test-bed as well as simulation experiments based on the ns-3 LoRaWAN\nmodule. The resulting comparison confirms that the model accurately estimates\nthe delay and energy consumed in the considered environment. The value of the\nmodel is demonstrated via its application to evaluate the impact of the number\nof end-devices and the maximum number of data frame retransmissions on delay\nand energy consumed for the confirmed UL data delivery in LoRaWAN networks. The\nmodel can be used to optimize different transmission parameters in future\nLoRaWAN networks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 09:34:02 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Khan", "Furqan Hameed", ""], ["Jurdak", "Raja", ""], ["Portmann", "Marius", ""]]}, {"id": "2009.09487", "submitter": "Simeon Babatunde", "authors": "Simeon Babatunde, Nirnay Jain, Vishwas Powar", "title": "Long Range Communication on Batteryless Devices", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Bulk of the existing Wireless Sensor Network (WSN) nodes are usually battery\npowered, stationary and mostly designed for short distance communication, with\nlittle to no consideration for constrained devices that operate solely on\nharvested energy. On many occasions, batteries and beefy super-capacitors are\nused to power these WSN, but these systems are prone to service-life\ndegradation and current-leakages. Most of the systems implementing super\ncapacitors do not account for leakages after exceeding the charge cycle\nthreshold. Frequent battery maintenance and replacement at scale is\nnon-trivial, labor-intensive and challenging task, especially on sensing nodes\ndeployed in extreme harsh environments with limited human intervention. In this\npaper, we present the technique for achieving Kilometer range communication on\nbatteryless constraint devices by harnessing the capabilities of LoRa\ntechnology.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 18:04:58 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Babatunde", "Simeon", ""], ["Jain", "Nirnay", ""], ["Powar", "Vishwas", ""]]}, {"id": "2009.09503", "submitter": "Furqan Khan", "authors": "Furqan Hameed Khan and Marius Portmann", "title": "Experimental Evaluation of LoRaWAN in NS-3", "comments": "8 pages, 11 figures", "journal-ref": "Proc. 28th Int. Telecommun. Netw. Appl. Conf. (ITNAC), pp. 1-8,\n  Nov. 2019", "doi": "10.1109/ATNAC.2018.8615313", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Range Wide Area Networks (LoRaWAN) is an open medium access control\n(MAC) layer technology devised for the long range connectivity of massive\nnumber of low power network devices. This work gives an overview of the key\naspects of LoRaWAN technology and presents results that we achieved via\nextensive evaluation of Class A LoRaWAN devices in different network settings\nusing the state-of-the-art network simulator (NS-3). At first, we focus on a\nsingle device and its mobility. We further undertook evaluations in an extended\nnetwork scenario with a changing number of devices and traffic intensity. In\nparticular, we evaluate the packet delivery ratio (PDR), uplink (UL)\nthroughput, and sub-band utilization for the confirmed and unconfirmed UL\ntransmissions in different environments. Our results give new insights for\nfuture efforts to optimize the LoRaWAN performance for different large scale\nInternet of Things (IoT) applications with low power end devices.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 19:10:09 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Khan", "Furqan Hameed", ""], ["Portmann", "Marius", ""]]}, {"id": "2009.09520", "submitter": "Shu Sun Dr.", "authors": "Shu Sun, Sungho Moon", "title": "Practical Scheduling Algorithms with Contiguous Resource Allocation for\n  Next-Generation Wireless Systems", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes three novel resource and user scheduling algorithms with\ncontiguous frequency-domain resource allocation (FDRA) for wireless\ncommunications systems. The first proposed algorithm jointly schedules users\nand resources selected adaptively from both ends of the bandwidth part (BWP),\nwhile the second and third ones apply disjoint user and resource selection with\neither single-end or dual-end BWP strategies. Distinct from existing contiguous\nFDRA approaches, the proposed ones comply with standards specifications for\nfifth-generation (5G) and beyond 5G communications, and have lower\ncomputational complexity hence are more practical. Simulation results show that\nall of the proposed algorithms can achieve near-optimal performance in terms of\nthroughput and packet loss rate for low to moderate traffic load, and the first\none can still perform relatively well even with a large number of users.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 20:32:04 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:09:56 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Sun", "Shu", ""], ["Moon", "Sungho", ""]]}, {"id": "2009.09529", "submitter": "Yuhang Ye", "authors": "Yuhang Ye, Brian Lee, Yuansong Qiao", "title": "PPTP: Price-based Path-specified Transport Protocol for Named Data\n  Network using Blockchain", "comments": "5 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serving as a potential future Internet architecture, Named Data Network (NDN)\noffers superior information-centric architectural support for mobile ad-hoc\nnetworking. Using NDN as an underlying protocol, end-user devices (e.g. IoT\ndevice and smart phone) formulate a multi-hop (mesh) network, in which certain\ndevices play a role of forwarding packets for others and/or act as gateways to\naccess the Internet. Nevertheless, an autonomous (selfish) node in an ad-hoc\nnetwork has two disincentives for forwarding packets for others: energy\nexpenditure and possible delays for its own data. This paper introduces\nPrice-based Path-specified Transport Protocol (PPT) for NDN, using blockchain\nas a payment platform to support money transfers between autonomous nodes thus\nto incentivise packet forwarding. In PPTP, routers advertise their expected\nprices for packet forwarding and consumers estimate the costs and select the\nappropriate paths for content downloading. PPTP is still an on-going project\ntherefore this paper will present the design principle and planed functions,\nand show how PPTP are related to other existing blockchain-based networking\nsolutions.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 21:38:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ye", "Yuhang", ""], ["Lee", "Brian", ""], ["Qiao", "Yuansong", ""]]}, {"id": "2009.09549", "submitter": "Babar Shahzaad", "authors": "Babar Shahzaad (1), Athman Bouguettaya (1), Sajib Mistry (2), Azadeh\n  Ghari Neiat (3) ((1) The University of Sydney, Sydney NSW 2000, Australia,\n  (2) Curtin University, Perth WA 6102, Australia, (3) Deakin University,\n  Geelong VIC 3220, Australia)", "title": "Resilient Composition of Drone Services for Delivery", "comments": "48 pages, 16 figures. This is an accepted paper and it is going to\n  appear in Future Generation Computer Systems journal Elsevier. Content may\n  change prior to final publication", "journal-ref": "Future Generation Computer Systems, 2020", "doi": "10.1016/j.future.2020.09.023", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel resilient drone service composition framework for delivery\nin dynamic weather conditions. We use a skyline approach to select an optimal\nset of candidate drone services at the source node in a skyway network. Drone\nservices are initially composed using a novel constraint-aware deterministic\nlookahead algorithm using the multi-armed bandit tree exploration. We propose a\nheuristic-based resilient service composition approach that adapts to runtime\nchanges and periodically updates the composition to meet delivery expectations.\nExperimental results prove the efficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 00:19:47 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Shahzaad", "Babar", ""], ["Bouguettaya", "Athman", ""], ["Mistry", "Sajib", ""], ["Neiat", "Azadeh Ghari", ""]]}, {"id": "2009.09619", "submitter": "Junghyun Kim", "authors": "Junghyun Kim, Thong D. Ngo, Paul S. Oh, Sean S.-C. Kwon, Changhee Han,\n  Joongheon Kim", "title": "Economic Theoretic LEO Satellite Coverage Control: An Auction-based\n  Framework", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, ultra-dense low earth orbit (LEO) satelliteconstellation over\nhigh-frequency bands has considered as one ofpromising solutions to supply\ncoverage all over the world. Givensatellite constellations, efficient beam\ncoverage schemes should beemployed at satellites to provide seamless services\nand full-viewcoverage. In LEO systems, hybrid wide and spot beam\ncoverageschemes are generally used, where the LEO provides a widebeam for large\narea coverage and additional several steering spotbeams for high speed data\naccess. In this given setting, schedulingmultiple spot beams is essentially\nrequired. In order to achievethis goal, Vickery-Clarke-Groves (VCG)\nauction-based trustfulalgorithm is proposed in this paper for scheduling\nmultiple spotbeams for more efficient seamless services and full-view coverage.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 05:37:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kim", "Junghyun", ""], ["Ngo", "Thong D.", ""], ["Oh", "Paul S.", ""], ["Kwon", "Sean S. -C.", ""], ["Han", "Changhee", ""], ["Kim", "Joongheon", ""]]}, {"id": "2009.09731", "submitter": "Ivan Bo\\v{s}kov", "authors": "Ivan Bo\\v{s}kov, Halil Yetgin, Matev\\v{z} Vu\\v{c}nik, Carolina\n  Fortuna, Mihael Mohor\\v{c}i\\v{c}", "title": "Time-to-Provision Evaluation of IoT Devices Using Automated Zero-Touch\n  Provisioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is being widely adopted in today's society,\ninterconnecting smart embedded devices that are being deployed for indoor and\noutdoor environments, such as homes, factories and hospitals. Along with the\ngrowth in the development and implementation of these IoT devices, their simple\nand rapid deployment, initial configuration and out-of-the-box operational\nprovisioning are becoming prominent challenges to be circumvented. Considering\na large number of heterogeneous devices to be deployed within next generation\nIoT networks, the amount of time needed for manual provisioning of these IoT\ndevices can significantly delay the deployment and manual provisioning may\nintroduce human-induced failures and errors. By incorporating zero-touch\nprovisioning (ZTP), multiple heterogeneous devices can be provisioned with less\neffort and without human intervention. In this paper, we propose\nsoftware-enabled access point (Soft-AP)- and Bluetooth-based ZTP solutions\nrelying only on a single mediator device and evaluate their performances using\nLOG-A-TEC testbed against manual provisioning in terms of the time required for\nprovisioning (time-to-provision, TTP). We demonstrate that on average, Soft-AP-\nand Bluetooth-based ZTP solutions outperform manual provisioning with about\n154% and 313% when compared to the expert provisioning, and with about 434% and\n880% when compared to the non-expert provisioning in terms of TTP performances,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:05:19 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 10:42:58 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Bo\u0161kov", "Ivan", ""], ["Yetgin", "Halil", ""], ["Vu\u010dnik", "Matev\u017e", ""], ["Fortuna", "Carolina", ""], ["Mohor\u010di\u010d", "Mihael", ""]]}, {"id": "2009.09736", "submitter": "Shuo Liu", "authors": "Shuo Liu (1), Qiaoling Wang (1), Junyi Zhang (1), Qinliang Lin (1),\n  Yao Liu (2), Meng Xu (1), Ray C.C. Chueng (2), Jianfei He (1) ((1) Huawei\n  Technologies Co., Ltd., (2) City University of Hong Kong)", "title": "NetReduce: RDMA-Compatible In-Network Reduction for Distributed DNN\n  Training Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present NetReduce, a novel RDMA-compatible in-network reduction\narchitecture to accelerate distributed DNN training. Compared to existing\ndesigns, NetReduce maintains a reliable connection between end-hosts in the\nEthernet and does not terminate the connection in the network. The advantage of\ndoing so is that we can fully reuse the designs of congestion control and\nreliability in RoCE. In the meanwhile, we do not need to implement a high-cost\nnetwork protocol processing stack in the switch, as IB does. The prototype\nimplemented by using FPGA is an out-of-box solution without modifying commodity\ndevices such as NICs or switches. For the coordination between the end-host and\nthe switch, NetReduce customizes the transport protocol only on the first\npacket in a data message to comply with RoCE v2. The special status monitoring\nmodule is designed to reuse the reliability mechanism of RoCE v2 for dealing\nwith packet loss. A message-level credit-based flow control algorithm is also\nproposed to fully utilize bandwidth and avoid buffer overflow. We study the\neffects of intra bandwidth on the training performance in multi-machines\nmulti-GPUs scenario and give sufficient conditions for hierarchical NetReduce\nto outperform other algorithms. We also extend the design from rack-level\naggregation to more general spine-leaf topology in the data center. NetReduce\naccelerates the training up to 1.7x and 1.5x for CNN-based CV and\ntransformer-based NLP tasks, respectively. Simulations on large-scale systems\nindicate the superior scalability of NetReduce to the state-of-the-art ring\nall-reduce.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:10:10 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Liu", "Shuo", ""], ["Wang", "Qiaoling", ""], ["Zhang", "Junyi", ""], ["Lin", "Qinliang", ""], ["Liu", "Yao", ""], ["Xu", "Meng", ""], ["Chueng", "Ray C. C.", ""], ["He", "Jianfei", ""]]}, {"id": "2009.09786", "submitter": "Marc Carrascosa", "authors": "Marc Carrascosa, Boris Bellalta", "title": "Cloud-gaming:Analysis of Google Stadia traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive, real-time, and high-quality cloud video games pose a serious\nchallenge to the Internet due to simultaneous high-throughput and low round\ntrip delay requirements. In this paper, we investigate the traffic\ncharacteristics of Stadia, the cloud-gaming solution from Google, which is\nlikely to become one of the dominant players in the gaming sector. To do that,\nwe design several experiments, and perform an extensive traffic measurement\ncampaign to obtain all required data. Our first goal is to gather a deep\nunderstanding of Stadia traffic characteristics by identifying the different\nprotocols involved for both signalling and video/audio contents, the traffic\ngeneration patterns, and the packet size and inter-packet time probability\ndistributions. Then, our second goal is to understand how different Stadia\ngames and configurations, such as the video codec and the video resolution\nselected, impact on the characteristics of the generated traffic. Finally, we\naim to evaluate the ability of Stadia to adapt to different link capacity\nconditions, including those cases where the capacity drops suddenly. Our\nresults and findings, besides illustrating the characteristics of Stadia\ntraffic, are also valuable for planning and dimensioning future networks, as\nwell as for designing new resource management strategies.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:06:53 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Carrascosa", "Marc", ""], ["Bellalta", "Boris", ""]]}, {"id": "2009.09876", "submitter": "Jean-Fran\\c{c}ois Determe", "authors": "Jean-Fran\\c{c}ois Determe and Sophia Azzagnuni and Utkarsh Singh and\n  Fran\\c{c}ois Horlin and Philippe De Doncker", "title": "Collisions of uniformly distributed identifiers with an application to\n  MAC address anonymization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of this paper consists in theoretical approximations of\nthe collision rate of $n$ random identifiers uniformly distributed in $m (> n)$\nbuckets---along with bounds on the approximation errors. A secondary\ncontribution is a decentralized anonymization system of media access control\n(MAC) addresses with a low collision rate. The main contribution supports the\nsecondary one in that it quantifies its collision rate, thereby allowing\ndesigners to minimize $m$ while attaining specific collision rates. Recent\nworks in crowd monitoring based on WiFi probe requests, for which collected MAC\naddresses should be anonymized, have inspired this research.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 13:54:40 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Determe", "Jean-Fran\u00e7ois", ""], ["Azzagnuni", "Sophia", ""], ["Singh", "Utkarsh", ""], ["Horlin", "Fran\u00e7ois", ""], ["De Doncker", "Philippe", ""]]}, {"id": "2009.09953", "submitter": "Nurul Huda Mahmood", "authors": "Nurul Huda Mahmood and Onel Alcaraz Lopez and Hirley Alves and Matti\n  Latva-aho", "title": "A Predictive Interference Management Algorithm for URLLC in Beyond 5G\n  Networks", "comments": "Nine pages, six figures, submitted to IEEE Com. Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Interference mitigation is a major design challenge in wireless\nsystems,especially in the context of ultra-reliable low-latency communication\n(URLLC) services. Conventional average-based interference management schemes\nare not suitable for URLLC as they do not accurately capture the tail\ninformation of the interference distribution. This letter proposes a novel\ninterference prediction algorithm that considers the entire interference\ndistribution instead of only the mean. The key idea is to model the\ninterference variation as a discrete state space discrete-time Markov chain.\nThe state transition probability matrix is then used to estimate the state\nevolution in time, and allocate radio resources accordingly. The proposed\nscheme is found to meet the target reliability requirements in a low-latency\nsingle-shot transmission system considering realistic system assumptions, while\nrequiring only ~25% more resources than the optimum case with perfect\ninterference knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 15:21:51 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mahmood", "Nurul Huda", ""], ["Lopez", "Onel Alcaraz", ""], ["Alves", "Hirley", ""], ["Latva-aho", "Matti", ""]]}, {"id": "2009.10021", "submitter": "Quinn Burke", "authors": "Stefan Achleitner, Quinn Burke, Patrick McDaniel, Trent Jaeger, Thomas\n  La Porta, Srikanth Krishnamurthy", "title": "MLSNet: A Policy Complying Multilevel Security Framework for Software\n  Defined Networking", "comments": null, "journal-ref": null, "doi": null, "report-no": "INSR-500-TR-0500-2019", "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring that information flowing through a network is secure from\nmanipulation and eavesdropping by unauthorized parties is an important task for\nnetwork administrators. Many cyber attacks rely on a lack of network-level\ninformation flow controls to successfully compromise a victim network. Once an\nadversary exploits an initial entry point, they can eavesdrop and move\nlaterally within the network (e.g., scan and penetrate internal nodes) to\nfurther their malicious goals. In this paper, we propose a novel multilevel\nsecurity (MLS) framework to enforce a secure inter-node information flow policy\nwithin the network and therein vastly reduce the attack surface available to an\nadversary who has penetrated it. In contrast to prior work on multilevel\nsecurity in computer networks which relied on enforcing the policy at network\nendpoints, we leverage the centralization of software-defined networks (SDNs)\nby moving the task to the controller and providing this service transparently\nto all nodes in the network. Our framework, MLSNet, formalizes the generation\nof a policy compliant network configuration (i.e., set of flow rules on the SDN\nswitches) as network optimization problems, with the objectives of (1)\nmaximizing the number of flows satisfying all security constraints and (2)\nminimizing the security cost of routing any remaining flows to guarantee\navailability. We demonstrate that MLSNet can securely route flows that satisfy\nthe security constraints (e.g., >80% of flows in a performed benchmark) and\nroute the remaining flows with a minimal security cost.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:55:32 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Achleitner", "Stefan", ""], ["Burke", "Quinn", ""], ["McDaniel", "Patrick", ""], ["Jaeger", "Trent", ""], ["La Porta", "Thomas", ""], ["Krishnamurthy", "Srikanth", ""]]}, {"id": "2009.10187", "submitter": "Suat Mercan", "authors": "Suat Mercan, Kemal Akkaya, Lisa Cain, John Thomas", "title": "Security, Privacy and Ethical Concerns of IoT Implementations in\n  Hospitality Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) has been on the rise in the last decade as it\nfinds applications in various domains. Hospitality is one of the pioneer\nsectors that has adopted this technology to create novel services such as smart\nhotel rooms, personalized services etc. Hotels, restaurants, theme parks, and\ncruise ships are some specific application areas to improve customer\nsatisfaction by creating an intense interactive environment and data collection\nwith the use of appropriate sensors and actuators. However, applying IoT\nsolutions in the hospitality environment has some unique challenges such as\neasy physical access to devices. In addition, due to the very nature of these\ndomains, the customers are at the epicenter of these IoT technologies that\nresult in a massive amount of data collection from them. Such data and its\nmanagement along with business purposes also raises new concerns regarding\nprivacy and ethical considerations. Therefore, this paper surveys and analyzes\nsecurity, privacy and ethical issues regarding the utilization of IoT devices\nby focusing on the hospitality industry specifically. We explore some exemplary\nuses, cases, potential problems and solutions in order to contribute to better\nunderstanding and guiding the business operators in this sector.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 21:46:21 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mercan", "Suat", ""], ["Akkaya", "Kemal", ""], ["Cain", "Lisa", ""], ["Thomas", "John", ""]]}, {"id": "2009.10269", "submitter": "Tra Le Ms", "authors": "Tra Huong Thi Le, Nguyen H. Tran, Yan Kyaw Tun, Minh N. H. Nguyen,\n  Shashi Raj Pandey, Zhu Han, and Choong Seon Hong", "title": "An Incentive Mechanism for Federated Learning in Wireless Cellular\n  network: An Auction Approach", "comments": null, "journal-ref": "Paper-TW-Apr-20-0557(2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a distributed learning framework that can deal\nwith the distributed issue in machine learning and still guarantee high\nlearning performance. However, it is impractical that all users will sacrifice\ntheir resources to join the FL algorithm. This motivates us to study the\nincentive mechanism design for FL. In this paper, we consider a FL system that\ninvolves one base station (BS) and multiple mobile users. The mobile users use\ntheir own data to train the local machine learning model, and then send the\ntrained models to the BS, which generates the initial model, collects local\nmodels and constructs the global model. Then, we formulate the incentive\nmechanism between the BS and mobile users as an auction game where the BS is an\nauctioneer and the mobile users are the sellers. In the proposed game, each\nmobile user submits its bids according to the minimal energy cost that the\nmobile users experiences in participating in FL. To decide winners in the\nauction and maximize social welfare, we propose the primal-dual greedy auction\nmechanism. The proposed mechanism can guarantee three economic properties,\nnamely, truthfulness, individual rationality and efficiency. Finally, numerical\nresults are shown to demonstrate the performance effectiveness of our proposed\nmechanism.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 01:50:39 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Le", "Tra Huong Thi", ""], ["Tran", "Nguyen H.", ""], ["Tun", "Yan Kyaw", ""], ["Nguyen", "Minh N. H.", ""], ["Pandey", "Shashi Raj", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2009.10601", "submitter": "Xu Chen", "authors": "Shuai Yu and Xu Chen and Zhi Zhou and Xiaowen Gong and Di Wu", "title": "When Deep Reinforcement Learning Meets Federated Learning: Intelligent\n  Multi-Timescale Resource Management for Multi-access Edge Computing in 5G\n  Ultra Dense Network", "comments": "Accepted by IEEE IoTJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-dense edge computing (UDEC) has great potential, especially in the 5G\nera, but it still faces challenges in its current solutions, such as the lack\nof: i) efficient utilization of multiple 5G resources (e.g., computation,\ncommunication, storage and service resources); ii) low overhead offloading\ndecision making and resource allocation strategies; and iii) privacy and\nsecurity protection schemes. Thus, we first propose an intelligent ultra-dense\nedge computing (I-UDEC) framework, which integrates blockchain and Artificial\nIntelligence (AI) into 5G ultra-dense edge computing networks. First, we show\nthe architecture of the framework. Then, in order to achieve real-time and low\noverhead computation offloading decisions and resource allocation strategies,\nwe design a novel two-timescale deep reinforcement learning (\\textit{2Ts-DRL})\napproach, consisting of a fast-timescale and a slow-timescale learning process,\nrespectively. The primary objective is to minimize the total offloading delay\nand network resource usage by jointly optimizing computation offloading,\nresource allocation and service caching placement. We also leverage federated\nlearning (FL) to train the \\textit{2Ts-DRL} model in a distributed manner,\naiming to protect the edge devices' data privacy. Simulation results\ncorroborate the effectiveness of both the \\textit{2Ts-DRL} and FL in the I-UDEC\nframework and prove that our proposed algorithm can reduce task execution time\nup to 31.87%.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:08:00 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Yu", "Shuai", ""], ["Chen", "Xu", ""], ["Zhou", "Zhi", ""], ["Gong", "Xiaowen", ""], ["Wu", "Di", ""]]}, {"id": "2009.10674", "submitter": "Rohit Singh Dr.", "authors": "Rohit Singh and Doug Sicker", "title": "Ultra-dense Low Data Rate (UDLD) Communication in the THz", "comments": "9 Figures; To be published at ACM NANOCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the future, with the advent of Internet of Things (IoT), wireless sensors,\nand multiple 5G killer applications, an indoor room might be filled with\n$1000$s of devices demanding low data rates. Such high-level densification and\nmobility of these devices will overwhelm the system and result in higher\ninterference, frequent outages, and lower coverage. The THz band has a massive\namount of greenfield spectrum to cater to this dense-indoor deployment.\nHowever, a limited coverage range of the THz will require networks to have more\ninfrastructure and depend on non-line-of-sight (NLOS) type communication. This\nform of communication might not be profitable for network operators and can\neven result in inefficient resource utilization for devices demanding low data\nrates. Using distributed device-to-device (D2D) communication in the THz, we\ncan cater to these Ultra-dense Low Data Rate (UDLD) type applications. D2D in\nTHz can be challenging, but with opportunistic allocation and smart learning\nalgorithms, these challenges can be mitigated. We propose a 2-Layered\ndistributed D2D model, where devices use coordinated multi-agent reinforcement\nlearning (MARL) to maximize efficiency and user coverage for dense-indoor\ndeployment. We show that densification and mobility in a network can be used to\nfurther the limited coverage range of THz devices, without the need for extra\ninfrastructure or resources.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:52:58 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Singh", "Rohit", ""], ["Sicker", "Doug", ""]]}, {"id": "2009.10798", "submitter": "Juan Felipe Botero JF Botero", "authors": "Sebasti\\'an G\\'omez Mac\\'ias and Luciano Paschoal Gaspary and Juan\n  Felipe Botero", "title": "ORACLE: Collaboration of Data and Control Planes to Detect DDoS Attacks", "comments": "6 pages, 5 figures, 5 tables, Submitted to IEEE ICC Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The possibility of programming the control and data planes, enabled by the\nSoftware-Defined Networking (SDN) paradigm, represents a fertile ground on top\nof which novel operation and management mechanisms can be fully explored, being\nDistributed Denial of Service (DDoS) attack detection based on machine learning\ntechniques the focus of this work. To carry out the detection, this paper\nproposes ORACLE: cOllaboRation of dAta and Control pLanEs to detect DDoS\nattacks, an architecture that promotes the coordination of control and data\nplanes to detect network attacks. As its first contribution, this architecture\ndelegates to the data plane the extraction and processing of traffic\ninformation collected per flow. This is done in order to ease the calculation\nand classification of the feature set used in the attack detection, as the\nneeded flow information is already processed when it arrives at the control\nplane. Besides, as the second contribution, this architecture breaks the\nlimitations to calculate some features that are not possible to implement in a\ntraditional OpenFlow-based environment. In the evaluation of ORACLE, we\nobtained up to 96% of accuracy in the testing phase, using a K-Nearest Neighbor\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:26:50 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Mac\u00edas", "Sebasti\u00e1n G\u00f3mez", ""], ["Gaspary", "Luciano Paschoal", ""], ["Botero", "Juan Felipe", ""]]}, {"id": "2009.10822", "submitter": "Jorge L\\'opez", "authors": "Jorge L\\'opez, Maxime Labonne, Claude Poletti, Dallal Belabed", "title": "Priority Flow Admission and Routing in SDN: Exact and Heuristic\n  Approaches", "comments": "As submitted to NCA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel admission and routing scheme which takes into\naccount arbitrarily assigned priorities for network flows. The presented\napproach leverages the centralized Software Defined Networking (SDN)\ncapabilities in order to do so. Exact and heuristic approaches to the stated\nPriority Flow Admission and Routing (PFAR) problem are provided. The exact\napproach which provides an optimal solution is based on Integer Linear\nProgramming (ILP). Given the potentially long running time required to find an\nexact and optimal solution, a heuristic approach is proposed; this approach is\nbased on Genetic Algorithms (GAs). In order to effectively estimate the\nperformance of the proposed approaches, a simulator that is capable of\ngenerating semi-random network topologies and flows has been developed.\nExperimental results for large problem instances (up 50 network nodes and\nthousands of network flows), show that: i) an optimal solution can be often\nfound in few seconds (even milliseconds), and ii) the heuristic approach yields\nclose-to-optimal solutions (approximately 95\\% of the optimal) in a fixed\namount of time; these experimental results demonstrate the pertinence of the\nproposed approaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 21:04:03 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["L\u00f3pez", "Jorge", ""], ["Labonne", "Maxime", ""], ["Poletti", "Claude", ""], ["Belabed", "Dallal", ""]]}, {"id": "2009.11065", "submitter": "Yuxuan Sun", "authors": "Yuxuan Sun, Wenqi Shi, Xiufeng Huang, Sheng Zhou, Zhisheng Niu", "title": "Edge Learning with Timeliness Constraints: Challenges and Solutions", "comments": "7 pages, 5 figures, accepted by IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future machine learning (ML) powered applications, such as autonomous driving\nand augmented reality, involve training and inference tasks with timeliness\nrequirements and are communication and computation intensive, which demands for\nthe edge learning framework. The real-time requirements drive us to go beyond\naccuracy for ML. In this article, we introduce the concept of timely edge\nlearning, aiming to achieve accurate training and inference while minimizing\nthe communication and computation delay. We discuss key challenges and propose\ncorresponding solutions from data, model and resource management perspectives\nto meet the timeliness requirements. Particularly, for edge training, we argue\nthat the total training delay rather than rounds should be considered, and\npropose data or model compression, and joint device scheduling and resource\nmanagement schemes for both centralized training and federated learning\nsystems. For edge inference, we explore the dependency between accuracy and\ndelay for communication and computation, and propose dynamic data compression\nand flexible pruning schemes. Two case studies show that the timeliness\nperformances, including the training accuracy under a given delay budget and\nthe completion ratio of inference tasks within deadline, are highly improved\nwith the proposed solutions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 11:38:47 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Sun", "Yuxuan", ""], ["Shi", "Wenqi", ""], ["Huang", "Xiufeng", ""], ["Zhou", "Sheng", ""], ["Niu", "Zhisheng", ""]]}, {"id": "2009.11085", "submitter": "Henrik Schi{\\o}ler", "authors": "Henrik Schioler, John Leth, Shibarchi Majumder", "title": "Markovian Performance Model for Token Bucket Filter with Fixed and\n  Varying Packet Sizes", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a token bucket mechanism serving a heterogeneous flow with a\nfocus on backlog, delay and packet loss properties. Previous models have\nconsidered the case for fixed size packets, i.e. \"one token per packet\" with\nand M/D/1 view on queuing behavior. We partition the heterogeneous flow into\nseveral packet size classes with individual Poisson arrival intensities. The\naccompanying queuing model is a \"full state\" model, i.e. buffer content is not\nreduced to a single quantity but encompasses the detailed content in terms of\npacket size classes. This yields a high model cardinality for which upper\nbounds are provided. Analytical results include class specific backlog, delay\nand loss statistics and are accompanied by results from discrete event\nsimulation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:12:15 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Schioler", "Henrik", ""], ["Leth", "John", ""], ["Majumder", "Shibarchi", ""]]}, {"id": "2009.11741", "submitter": "Victor J. Exposito Jimenez", "authors": "Wolfgang Weiss and Victor J. Exposito Jimenez and Herwig Zeiner", "title": "Dynamic Buffer Sizing for Out-of-Order Event Compensation for\n  Time-Sensitive Applications", "comments": null, "journal-ref": null, "doi": "10.1145/3410403", "report-no": null, "categories": "cs.SE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's sensor network implementations often comprise various types of nodes\nconnected with different types of networks. These and various other aspects\ninfluence the delay of transmitting data and therefore of out-of-order data\noccurrences. This turns into a crucial problem in time-sensitive applications\nwhere data must be processed promptly and decisions must be reliable.\n  In this paper, we were researching dynamic buffer sizing algorithms for\nmultiple, distributed and independent sources, which reorder event streams,\nthus enabling subsequent time-sensitive applications to work correctly. To be\nable to evaluate such algorithms, we had to record datasets first. Five novel\ndynamic buffer sizing algorithms were implemented and compared to\nstate-of-the-art approaches in this domain. The evaluation has shown that the\nuse of a dynamic time-out buffering method is preferable over a static buffer.\nThe higher the variation of the network or other influences in the environment,\nthe more necessary it becomes to use an algorithm which dynamically adapts its\nbuffer size. These algorithms are universally applicable, easy to integrate in\nexisting architectures, and particularly interesting for time-sensitive\napplications. Dynamic time-out buffering is still a trade-off between reaction\ntime and out-of-order event compensation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:05:13 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Weiss", "Wolfgang", ""], ["Jimenez", "Victor J. Exposito", ""], ["Zeiner", "Herwig", ""]]}, {"id": "2009.11805", "submitter": "Oussama Abderrahmane Dambri Mr", "authors": "Oussama Abderrahmane Dambri and Soumaya Cherkaoui", "title": "Design and Evaluation of a Receiver for Wired Nano-Communication\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a bio-inspired receiver, which detects the\nelectrons transmitted through a nanowire, then, it converts the detected\ninformation into a blue light using bioluminescence. Using light allows the\ndesigned receiver to also act as a relay for the nearest gateway\n(photo-detector). We simulate the construction of the nanowire, present its\nelectrical characteristics and calculate its maximum throughput for a better\ndesign of the receiver. The designed receiver contains two parts, a part that\ndetects the transmitted electrons, which we model by using an equivalent\ncircuit, and a part that converts the detected electrons into a blue light. We\nderive the analytical expressions of the equivalent circuit's components, and\nwe calculate the emitted photons for each electrical pulse detected. We also\npropose modulation techniques that guaranty an effective decoding of the\ninformation. We send a binary message and we follow the electron detection\nprocess of the proposed receiver until light emission and we calculate the Bit\nError Rate (BER) to evaluate the performance of the designed receiver. The\nresults of this study show that the designed receiver can accurately detect the\nelectrons sent through a conductive nanowire in wired nano-communication\nnetworks, and that it can also act as a relay for the nearest gateway.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:47:37 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Dambri", "Oussama Abderrahmane", ""], ["Cherkaoui", "Soumaya", ""]]}, {"id": "2009.11901", "submitter": "Moayad Aloqaily", "authors": "Ismaeel Al Ridhawi and Moayad Aloqaily and Yaser Jararweh", "title": "An Incentive-Based Mechanism for Volunteer Computing using Blockchain", "comments": "22 pages, 12 Figures, 1 Table. Accepted. ACM Transaction On Internet\n  Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of fast communication media both at the core and at the edge has\nresulted in unprecedented numbers of sophisticated and intelligent wireless IoT\ndevices. Tactile Internet has enabled the interaction between humans and\nmachines within their environment to achieve revolutionized solutions both on\nthe move and in real-time. Many applications such as intelligent autonomous\nself-driving, smart agriculture and industrial solutions, and self-learning\nmultimedia content filtering and sharing have become attainable through\ncooperative, distributed and decentralized systems, namely, volunteer\ncomputing. This article introduces a blockchain-enabled resource sharing and\nservice composition solution through volunteer computing. Device resource,\ncomputing, and intelligence capabilities are advertised in the environment to\nbe made discoverable and available for sharing with the aid of blockchain\ntechnology. Incentives in the form of on-demand service availability are given\nto resource and service providers to ensure fair and balanced cooperative\nresource usage. Blockchains are formed whenever a service request is initiated\nwith the aid of fog and mobile edge computing (MEC) devices to ensure secure\ncommunication and service delivery for the participants. Using both volunteer\ncomputing techniques and tactile internet architectures, we devise a fast and\nreliable service provisioning framework that relies on a reinforcement learning\ntechnique. Simulation results show that the proposed solution can achieve high\nreward distribution, increased number of blockchain formations, reduced delays,\nand balanced resource usage among participants, under the premise of high IoT\ndevice availability.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:48:22 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Ridhawi", "Ismaeel Al", ""], ["Aloqaily", "Moayad", ""], ["Jararweh", "Yaser", ""]]}, {"id": "2009.12105", "submitter": "Simon Scherrer", "authors": "Simon Scherrer, Markus Legner, Adrian Perrig, Stefan Schmid", "title": "Incentivizing Stable Path Selection in Future Internet Architectures", "comments": "38th International Symposium on Computer Performance, Modeling,\n  Measurements and Evaluation (PERFORMANCE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By delegating path control to end-hosts, future Internet architectures offer\nflexibility for path selection. However, there is a concern that the\ndistributed routing decisions by end-hosts, in particular load-adaptive\nrouting, can lead to oscillations if path selection is performed without\ncoordination or accurate load information. Prior research has addressed this\nproblem by devising path-selection policies that lead to stability. However,\nlittle is known about the viability of these policies in the Internet context,\nwhere selfish end-hosts can deviate from a prescribed policy if such a\ndeviation is beneficial fromtheir individual perspective. In order to achieve\nnetwork stability in future Internet architectures, it is essential that\nend-hosts have an incentive to adopt a stability-oriented path-selection\npolicy. In this work, we perform the first incentive analysis of the\nstability-inducing path-selection policies proposed in the literature. Building\non a game-theoretic model of end-host path selection, we show that these\npolicies are in fact incompatible with the self-interest of end-hosts, as these\nstrategies make it worthwhile to pursue an oscillatory path-selection strategy.\nTherefore, stability in networks with selfish end-hosts must be enforced by\nincentive-compatible mechanisms. We present two such mechanisms and formally\nprove their incentive compatibility.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 09:48:35 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Scherrer", "Simon", ""], ["Legner", "Markus", ""], ["Perrig", "Adrian", ""], ["Schmid", "Stefan", ""]]}, {"id": "2009.12164", "submitter": "Nattakorn Promwongsa", "authors": "N. Promwongsa, A. Ebrahimzadeh, D. Naboulsi, S. Kianpisheh, F.\n  Belqasmi, R. Glitho, N. Crespi, and O. Alfandi", "title": "A Comprehensive Survey of the Tactile Internet: State of the art and\n  Research Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet has made several giant leaps over the years, from a fixed to a\nmobile Internet, then to the Internet of Things, and now to a Tactile Internet.\nThe Tactile Internet goes far beyond data, audio and video delivery over fixed\nand mobile networks, and even beyond allowing communication and collaboration\namong things. It is expected to enable haptic communication and allow skill set\ndelivery over networks. Some examples of potential applications are\ntele-surgery, vehicle fleets, augmented reality and industrial process\nautomation. Several papers already cover many of the Tactile Internet-related\nconcepts and technologies, such as haptic codecs, applications, and supporting\ntechnologies. However, none of them offers a comprehensive survey of the\nTactile Internet, including its architectures and algorithms. Furthermore, none\nof them provides a systematic and critical review of the existing solutions. To\naddress these lacunae, we provide a comprehensive survey of the architectures\nand algorithms proposed to date for the Tactile Internet. In addition, we\ncritically review them using a well-defined set of requirements and discuss\nsome of the lessons learned as well as the most promising research directions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:45:37 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Promwongsa", "N.", ""], ["Ebrahimzadeh", "A.", ""], ["Naboulsi", "D.", ""], ["Kianpisheh", "S.", ""], ["Belqasmi", "F.", ""], ["Glitho", "R.", ""], ["Crespi", "N.", ""], ["Alfandi", "O.", ""]]}, {"id": "2009.12275", "submitter": "Thi Ha Ly Dinh", "authors": "Thi Ha Ly Dinh, Megumi Kaneko, Ellen Hidemi Fukuda, Lila Boukhatem", "title": "Energy Efficient Resource Allocation Optimization in Fog Radio Access\n  Networks with Outdated Channel Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog Radio Access Networks (F-RAN) are gaining worldwide interests for\nenabling mobile edge computing for Beyond 5G. However, to realize the future\nreal-time and delay-sensitive applications, F-RAN tailored radio resource\nallocation and interference management become necessary. This work investigates\nuser association and beamforming issues for providing energy efficient F-RANs.\nWe formulate the energy efficiency maximization problem, where the F-RAN\nspecific constraint to guarantee local edge processing is explicitly\nconsidered. To solve this intricate problem, we design an algorithm based on\nthe Augmented Lagrangian (AL) method. Then, to alleviate the computational\ncomplexity, a heuristic low-complexity strategy is developed, where the tasks\nare split in two parts: one solving for user association and Fog Access Points\n(F-AP) activation in a centralized manner at the cloud, based on global but\noutdated user Channel State Information (CSI) to account for fronthaul delays,\nand the second solving for beamforming in a distributed manner at each active\nF-AP based on perfect but local CSIs. Simulation results show that the proposed\nheuristic method achieves an appreciable performance level as compared to the\nAL-based method, while largely outperforming the energy efficiency of the\nbaseline F-RAN scheme and limiting the sum-rate degradation compared to the\noptimized sum-rate maximization algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 14:51:00 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Dinh", "Thi Ha Ly", ""], ["Kaneko", "Megumi", ""], ["Fukuda", "Ellen Hidemi", ""], ["Boukhatem", "Lila", ""]]}, {"id": "2009.12471", "submitter": "Myounggyu Won", "authors": "Navid Mohammad Imran and Myounggyu Won", "title": "Reducing Operation Cost of LPWAN Roadside Sensors Using Cross Technology\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-Power Wide-Area Network (LPWAN) is an emerging communication standard for\nInternet of Things (IoT) that has strong potential to support connectivity of a\nlarge number of roadside sensors with an extremely long communication range.\nHowever, the high operation cost to manage such a large-scale roadside sensor\nnetwork remains as a significant challenge. In this paper, we propose\nLOC-LPWAN, a novel optimization framework that is designed to reduce the\noperation cost using the cross technology communication (CTC). LOC-LPWAN allows\nroadside sensors to offload sensor data to passing vehicles that in turn\nforward the data to a LPWAN server using CTC aiming to reduce the data\nsubscription cost. LOC-LPWAN finds the optimal communication schedule between\nsensors and vehicles to maximize the throughput given an available budget of\nthe user. Furthermore, LOC-LPWAN optimizes the fairness among sensors by\nallowing sensors to transmit similar amounts of data and preventing certain\nsensors from dominating the opportunity for data transmissions. LOC-LPWAN also\nprovides an option that allows all sensor to transmit data within a specific\ndelay bound. Extensive numerical analysis performed with real-world taxi data\nconsisting of 40 vehicles with 24-hour trajectories demonstrate that LOC-LPWAN\nimproves the throughput by 72.6%, enhances the fairness by 65.7%, and reduces\nthe delay by 28.8% compared with a greedy algorithm given the same budget.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 23:20:20 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Imran", "Navid Mohammad", ""], ["Won", "Myounggyu", ""]]}, {"id": "2009.12509", "submitter": "Haoxin Wang", "authors": "Haoxin Wang, Tingting Liu, BaekGyu Kim, Chung-Wei Lin, Shinichi\n  Shiraishi, Jiang Xie and Zhu Han", "title": "Architectural Design Alternatives based on Cloud/Edge/Fog Computing for\n  Connected Vehicles", "comments": "This is a personal copy of the authors. Not for redistribution. The\n  final version of this paper is available through the IEEE Xplore Digital\n  Library, at the link: https://ieeexplore.ieee.org/document/9184917, with the\n  DOI: 10.1109/COMST.2020.3020854", "journal-ref": "IEEE Communications Surveys & Tutorials, 2020", "doi": "10.1109/COMST.2020.3020854", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As vehicles playing an increasingly important role in people's daily life,\nrequirements on safer and more comfortable driving experience have arisen.\nConnected vehicles (CVs) can provide enabling technologies to realize these\nrequirements and have attracted widespread attentions from both academia and\nindustry. These requirements ask for a well-designed computing architecture to\nsupport the Quality-of-Service (QoS) of CV applications. Computation offloading\ntechniques, such as cloud, edge, and fog computing, can help CVs process\ncomputation-intensive and large-scale computing tasks. Additionally, different\ncloud/edge/fog computing architectures are suitable for supporting different\ntypes of CV applications with highly different QoS requirements, which\ndemonstrates the importance of the computing architecture design. However, most\nof the existing surveys on cloud/edge/fog computing for CVs overlook the\ncomputing architecture design, where they (i) only focus on one specific\ncomputing architecture and (ii) lack discussions on benefits, research\nchallenges, and system requirements of different architectural alternatives. In\nthis paper, we provide a comprehensive survey on different architectural design\nalternatives based on cloud/edge/fog computing for CVs. The contributions of\nthis paper are: (i) providing a comprehensive literature survey on existing\nproposed architectural design alternatives based on cloud/edge/fog computing\nfor CVs, (ii) proposing a new classification of computing architectures based\non cloud/edge/fog computing for CVs: computation-aided and computation-enabled\narchitectures, (iii) presenting a holistic comparison among different\ncloud/edge/fog computing architectures for CVs based on functional requirements\nof CV systems, including advantages, disadvantages, and research challenges.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 02:44:26 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Wang", "Haoxin", ""], ["Liu", "Tingting", ""], ["Kim", "BaekGyu", ""], ["Lin", "Chung-Wei", ""], ["Shiraishi", "Shinichi", ""], ["Xie", "Jiang", ""], ["Han", "Zhu", ""]]}, {"id": "2009.12580", "submitter": "Mario Di Mauro", "authors": "Mario Di Mauro, Antonio Liotta", "title": "An experimental evaluation and characterization of VoIP over an LTE-A\n  network", "comments": "Data available at:\n  https://www.researchgate.net/publication/342276809_DATASETS", "journal-ref": "IEEE Transactions on Network and Service Management, vol. 17, no.\n  3, pp. 1626-1639, Sept. 2020", "doi": "10.1109/TNSM.2020.2995505", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile telecommunications are converging towards all-IP solutions. This is\nthe case of the Long Term Evolution (LTE) technology that, having no\ncircuit-switched bearer to support voice traffic, needs a dedicated VoIP\ninfrastructure, which often relies on the IP Multimedia Subsystem architecture.\nMost telecom operators implement LTE-A, an advanced version of LTE often\nmarketed as 4G+, which achieves data rate peaks of 300 Mbps. Yet, although such\nnovel technology boosts the access to advanced multimedia contents and\nservices, telco operators continue to consider the VoIP market as the major\nrevenue for their business. In this work, the authors propose a detailed\nperformance assessment of VoIP traffic by carrying out experimental trials\nacross a real LTE-A environment. The experimental campaign consists of two\nstages. First, we characterize VoIP calls between fixed and mobile terminals,\nbased on a dataset that includes more than 750,000 data-voice packets. We\nanalyze quality-of-service metrics such as round-trip time (RTT) and jitter, to\ncapture the influence of uncontrolled factors that typically appear in\nreal-world settings. In the second stage, we further consider VoIP flows across\na range of codecs, looking at the trade-offs between quality and bandwidth\nconsumption. Moreover, we propose a statistical characterization of jitter and\nRTT (representing the most critical parameters), identifying the optimal\napproximating distribution, namely the Generalized Extreme Value (GEV). The\nestimation of parameters through the Maximum Likelihood criterion, leads us to\nreveal both the short- and long-tail behaviour for jitter and RTT,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 12:22:49 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Di Mauro", "Mario", ""], ["Liotta", "Antonio", ""]]}, {"id": "2009.12657", "submitter": "Olga Vikhrova", "authors": "Olga Vikhrova, Federico Chiariotti, Beatriz Soret, Giuseppe Araniti,\n  Antonella Molinaro, Petar Popovski", "title": "Age of Information in Multi-hop Networks with Priorities", "comments": "Submitted for publication to IEEE Globecom Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Age of Information is a new metric used in real-time status update tracking\napplications. It measures at the destination the time elapsed since the\ngeneration of the last received packet. In this paper, we consider the\nco-existence of critical and noncritical status updates in a two-hop system,\nfor which the network assigns different scheduling priorities. Specifically,\nthe high priority is reserved to the packets that traverse the two nodes, as\nthey experience worse latency performance. We obtain the distribution of the\nage and its natural upper bound termed peak age. We provide tight upper and\nlower bounds for priority updates and the exact expressions for the\nnon-critical flow of packets with a general service distribution. The results\ngive fundamental insights for the design of age-sensitive multi-hop systems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 18:04:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Vikhrova", "Olga", ""], ["Chiariotti", "Federico", ""], ["Soret", "Beatriz", ""], ["Araniti", "Giuseppe", ""], ["Molinaro", "Antonella", ""], ["Popovski", "Petar", ""]]}, {"id": "2009.12754", "submitter": "Shanshan Hao", "authors": "Shanshan Hao, Renjie Liu, Zhe Weng, Deliang Chang, Congxiao Bao, Xing\n  Li", "title": "Addressless: A New Internet Server Model to Prevent Network Scanning", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0246293", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Eliminating unnecessary exposure is a principle of server security. The huge\nIPv6 address space enhances security by making scanning infeasible, however,\nwith recent advances of IPv6 scanning technologies, network scanning is again\nthreatening server security. In this paper, we propose a new model named\naddressless server, which separates the server into an entrance module and a\nmain service module, and assigns an IPv6 prefix instead of an IPv6 address to\nthe main service module. The entrance module generates a legitimate IPv6\naddress under this prefix by encrypting the client address, so that the client\ncan access the main server on a destination address that is different in each\nconnection. In this way, the model provides isolation to the main server,\nprevents network scanning, and minimizes exposure. Moreover it provides a novel\nframework that supports flexible load balancing, high-availability, and other\ndesirable features. The model is simple and does not require any modification\nto the client or the network. We implement a prototype and experiments show\nthat our model can prevent the main server from being scanned at a slight\nperformance cost.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 06:06:55 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Hao", "Shanshan", ""], ["Liu", "Renjie", ""], ["Weng", "Zhe", ""], ["Chang", "Deliang", ""], ["Bao", "Congxiao", ""], ["Li", "Xing", ""]]}, {"id": "2009.12861", "submitter": "Pamela Zave", "authors": "Pamela Zave and Jennifer Rexford and John Sonchack", "title": "The Remaining Improbable: Toward Verifiable Network Services", "comments": "6 pages with 4 figures, plus references. This paper has been reviewed\n  extensively as a conference submission. Although some reviewers have found it\n  cryptic due to its length (small) and scope (large), we are satisfied that it\n  contains no factual errors. We welcome your questions!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trustworthiness of modern networked services is too important to leave to\nchance. We need to design these services with specific properties in mind, and\nverify that the properties hold. In this paper, we argue that a compositional\nnetwork architecture, based on a notion of layering where each layer is its own\ncomplete network customized for a specific purpose, is the only plausible\napproach to making network services verifiable. Realistic examples show how to\nuse the architecture to reason about sophisticated network properties in a\nmodular way. We also describe a prototype in which the basic structures of the\narchitectural model are implemented in efficient P4 code for programmable data\nplanes, then explain how this scaffolding fits into an integrated process of\nspecification, code generation, implementation of additional network functions,\nand automated verification.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:00:45 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zave", "Pamela", ""], ["Rexford", "Jennifer", ""], ["Sonchack", "John", ""]]}, {"id": "2009.12878", "submitter": "Derya Malak", "authors": "Derya Malak and Muriel M\\'edard", "title": "Function Load Balancing over Networks", "comments": "arXiv admin note: text overlap with arXiv:1912.03531", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using networks as a means of computing can reduce the communication flow or\nthe total number of bits transmitted over the networks. In this paper, we\npropose to distribute the computation load in stationary networks, and\nformulate a flow-based delay minimization problem that jointly captures the\naspects of communications and computation. We exploit the distributed\ncompression scheme of Slepian-Wolf that is applicable under any protocol\ninformation where nodes can do compression independently using different\ncodebooks. We introduce the notion of entropic surjectivity as a measure to\ndetermine how sparse the function is and to understand the limits of functional\ncompression for computation. We leverage Little's Law for stationary systems to\nprovide a connection between surjectivity and the computation processing factor\nthat reflects the proportion of flow that requires communications. This\nconnection gives us an understanding of how much a node (in isolation) should\ncompute to communicate the desired function within the network without putting\nany assumptions on the topology. Our results suggest that to effectively\ncompute different function classes that have different entropic surjectivities,\nthe networks can be re-structured with the transition probabilities being\ntailored for functions, i.e., task-based link reservations, which can enable\nmixing versus separately processing of a diverse function classes. They also\nimply that most of the available resources are reserved for computing low\ncomplexity functions versus fewer resources for processing of high complexity\nones. We numerically evaluate our technique for search, MapReduce, and\nclassification functions, and infer how sensitive the processing factor for\neach computation task to the entropic surjectivity is.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:42:37 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Malak", "Derya", ""], ["M\u00e9dard", "Muriel", ""]]}, {"id": "2009.12879", "submitter": "Derya Malak", "authors": "Derya Malak and Muriel M\\'edard", "title": "A Distributed Computationally Aware Quantizer Design via Hyper Binning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a distributed function aware quantization scheme for distributed\nfunctional compression. We consider $2$ correlated sources $X_1$ and $X_2$ and\na destination that seeks the outcome of a continuous function $f(X_1,\\,X_2)$.\nWe develop a compression scheme called hyper binning in order to quantize $f$\nvia minimizing entropy of joint source partitioning. Hyper binning is a natural\ngeneralization of Cover's random code construction for the asymptotically\noptimal Slepian-Wolf encoding scheme that makes use of orthogonal binning. The\nkey idea behind this approach is to use linear discriminant analysis in order\nto characterize different source feature combinations. This scheme captures the\ncorrelation between the sources and function's structure as a means of\ndimensionality reduction. We investigate the performance of hyper binning for\ndifferent source distributions, and identify which classes of sources entail\nmore partitioning to achieve better function approximation. Our approach brings\nan information theory perspective to the traditional vector quantization\ntechnique from signal processing.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:42:42 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Malak", "Derya", ""], ["M\u00e9dard", "Muriel", ""]]}, {"id": "2009.12908", "submitter": "Nihal Ezgi Yuceturk", "authors": "Nihal Ezgi Yuceturk, Kutay Candan", "title": "Load Balancing and Mutisource Routing in Information-Centric-Networking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-Centric Networking is still an incomplete paradigm which\nintroduces a large variety of new topics and approaches over the traditional\nnetworking. Since it is a relatively new concept which promises for easier and\nfaster data access many aspects of it have been studied intensely in recent\nyears. Nonetheless, load balancing is one of the least focused but high\npotency, open-ended areas. The aim of this project is to present an alternative\ntechnique to load balancing in the domain of pre-suggested routing method LSCR\n(Link State Content Routing). We suggested multi-path interest and multi-source\ndata packet routing on the bases of Forwarding and Routing Tables of LSCR and\npacket routing protocol of Source Routing. We have developed a simulator\nsoftware to implement and test the multi-path routing algorithm. Multi-path\nrouting and LSCR are compared with regard to the load of the links, package\nloss, package delay and overall network performance.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 17:54:51 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Yuceturk", "Nihal Ezgi", ""], ["Candan", "Kutay", ""]]}, {"id": "2009.13012", "submitter": "Latif U. Khan", "authors": "Latif U. Khan, Walid Saad, Zhu Han, Ekram Hossain, and Choong Seon\n  Hong", "title": "Federated Learning for Internet of Things: Recent Advances, Taxonomy,\n  and Open Challenges", "comments": "This paper has been accepted for publication in IEEE Communications\n  Surveys and Tutorials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) will be ripe for the deployment of novel machine\nlearning algorithms for both network and application management. However, given\nthe presence of massively distributed and private datasets, it is challenging\nto use classical centralized learning algorithms in the IoT. To overcome this\nchallenge, federated learning can be a promising solution that enables\non-device machine learning without the need to migrate the private end-user\ndata to a central cloud. In federated learning, only learning model updates are\ntransferred between end-devices and the aggregation server. Although federated\nlearning can offer better privacy preservation than centralized machine\nlearning, it has still privacy concerns. In this paper, first, we present the\nrecent advances of federated learning towards enabling federated\nlearning-powered IoT applications. A set of metrics such as sparsification,\nrobustness, quantization, scalability, security, and privacy, is delineated in\norder to rigorously evaluate the recent advances. Second, we devise a taxonomy\nfor federated learning over IoT networks. Third, we propose two IoT use cases\nof dispersed federated learning that can offer better privacy preservation than\nfederated learning. Finally, we present several open research challenges with\ntheir possible solutions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:07:37 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 14:56:42 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Khan", "Latif U.", ""], ["Saad", "Walid", ""], ["Han", "Zhu", ""], ["Hossain", "Ekram", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2009.13048", "submitter": "Wenhao Zhan", "authors": "Wenhao Zhan, Haoyue Tang, Jintao Wang", "title": "Delay Optimal Cross-Layer Scheduling Over Markov Channels with Power\n  Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scenario where a power constrained transmitter delivers\nrandomly arriving packets to the destination over Markov time-varying channel\nand adapts different transmission power to each channel state in order to\nguarantee successful transmission. To minimize the expected average\ntransmission delay of each packet, we formulate the problem into a constrained\nMarkov decision process (CMDP). We reveal the queue-length threshold structure\nof the optimal policy, i.e., the transmitter sends packets if and only if the\nqueue length surpasses a threshold and obtain the optimal cross-layer\nscheduling strategy through linear programming (LP). Numerical results validate\nthe performance of the proposed strategy and illustrate a delay-power tradeoff\nin such scenario.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 03:43:18 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhan", "Wenhao", ""], ["Tang", "Haoyue", ""], ["Wang", "Jintao", ""]]}, {"id": "2009.13141", "submitter": "Mario Di Mauro", "authors": "Mario Di Mauro, Maurizio Longo, Fabio Postiglione", "title": "Availability Evaluation of Multi-tenant Service Function Chaining\n  Infrastructures by Multidimensional Universal Generating Function", "comments": null, "journal-ref": null, "doi": "10.1109/TSC.2018.2885748", "report-no": null, "categories": "cs.NI cs.PF stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Network Function Virtualization (NFV) paradigm has been devised as an\nenabler of next generation network infrastructures by speeding up the\nprovisioning and the composition of novel network services. The latter are\nimplemented via a chain of virtualized network functions, a process known as\nService Function Chaining. In this paper, we evaluate the availability of\nmulti-tenant SFC infrastructures, where every network function is modeled as a\nmulti-state system and is shared among different and independent tenants. To\nthis aim, we propose a Universal Generating Function (UGF) approach, suitably\nextended to handle performance vectors, that we call Multidimensional UGF. This\nnovel methodology is validated in a realistic multi-tenant telecommunication\nnetwork scenario, where the service chain is composed by the network elements\nof an IP Multimedia Subsystem implemented via NFV. A steady-state availability\nevaluation of such an exemplary system is presented and a redundancy\noptimization problem is solved, so providing the SFC infrastructure which\nminimizes deployment cost while respecting a given availability requirement.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 08:39:53 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Di Mauro", "Mario", ""], ["Longo", "Maurizio", ""], ["Postiglione", "Fabio", ""]]}, {"id": "2009.13149", "submitter": "Mario Di Mauro", "authors": "Mario Di Mauro, Antonio Liotta", "title": "Statistical Assessment of IP Multimedia Subsystem in a Softwarized\n  Environment: a Queueing Networks Approach", "comments": null, "journal-ref": null, "doi": "10.1109/TNSM.2019.2943776", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Next Generation 5G Networks can greatly benefit from the synergy between\nvirtualization paradigms, such as the Network Function Virtualization (NFV),\nand service provisioning platforms such as the IP Multimedia Subsystem (IMS).\nThe NFV concept is evolving towards a lightweight solution based on containers\nthat, by contrast to classic virtual machines, do not carry a whole operating\nsystem and result in more efficient and scalable deployments. On the other\nhand, IMS has become an integral part of the 5G core network, for instance, to\nprovide advanced services like Voice over LTE (VoLTE). In this paper we combine\nthese virtualization and service provisioning concepts, deriving a\ncontainerized IMS infrastructure, dubbed cIMS, providing its assessment through\nstatistical characterization and experimental measurements. Specifically, we:\ni) model cIMS through the queueing networks methodology to characterize the\nutilization of virtual resources under constrained conditions; ii) draw an\nextended version of the Pollaczek-Khinchin formula, which is useful to deal\nwith bulk arrivals; iii) afford an optimization problem focused at maximizing\nthe whole cIMS performance in the presence of capacity constraints, thus\nproviding new means for the service provider to manage service level agreements\n(SLAs); $iv)$ evaluate a range of cIMS scenarios, considering different queuing\ndisciplines including also multiple job classes. An experimental testbed based\non the open source platform Clearwater has been deployed to derive some\nrealistic values of key parameters (e.g. arrival and service times).\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 08:58:27 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Di Mauro", "Mario", ""], ["Liotta", "Antonio", ""]]}, {"id": "2009.13379", "submitter": "Jiujiu Chen", "authors": "Jiujiu Chen, Chunyan Feng, Caili Guo, Xu Zhu", "title": "A Content Driven Resource Allocation Scheme for Video Transmission in\n  Vehicular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing computer vision applications, lots of videos are transmitted\nfor content analysis, the way to allocate resources can affect the performance\nof video content analysis. For this purpose, the traditional resource\nallocation schemes for video transmission in vehicular networks, such as\nqualityof-service (QoS) based or quality-of-experience (QoE) based schemes, are\nno longer optimal anymore. In this paper, we propose an efficient content\ndriven resource allocation scheme for vehicles equipped with cameras under\nbandwidth constraints in order to improve the video content analysis\nperformance. The proposed resource allocation scheme is based on maximizing the\nquality-of-content (QoC), which is related to the content analysis performance.\nA QoC based assessment model is first proposed. Then, the resource allocation\nproblem is converted to a solvable convex optimization problem. Finally,\nsimulation results show the better performance of our proposed scheme than the\nexisting schemes like QoE based schemes.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:51:59 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Jiujiu", ""], ["Feng", "Chunyan", ""], ["Guo", "Caili", ""], ["Zhu", "Xu", ""]]}, {"id": "2009.13446", "submitter": "Xinyu Wu", "authors": "Xinyu Crystal Wu, T.S. Eugene Ng", "title": "DCFIT: Initial Trigger-Based PFC Deadlock Detection in the Data Plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent data center applications rely on lossless networks to achieve high\nnetwork performance. Lossless networks, however, can suffer from in-network\ndeadlocks induced by hop-by-hop flow control protocols like PFC. Once deadlocks\noccur, large parts of the network could be blocked. Existing solutions mainly\ncenter on a deadlock avoidance strategy; unfortunately, they are not foolproof.\nThus, deadlock detection is a necessary last resort. In this paper, we propose\nDCFIT, a new mechanism performed entirely in the data plane to detect and solve\ndeadlocks for arbitrary network topologies and routing protocols. Unique to\nDCFIT is the use of deadlock initial triggers, which contribute to efficient\ndeadlock detection and deadlock recurrence prevention. Preliminary results\nindicate that DCFIT can detect deadlocks quickly with minimal overhead and\nmitigate the recurrence of the same deadlocks effectively. This work does not\nraise any ethical issues.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:10:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Wu", "Xinyu Crystal", ""], ["Ng", "T. S. Eugene", ""]]}, {"id": "2009.13456", "submitter": "Mohammed Elbayoumi", "authors": "Mohammed Elbayoumi, Walaa Hamouda, Amr Youssef", "title": "Multiple-Association Supporting HTC/MTC in Limited-Backhaul Capacity\n  Ultra-Dense Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TCOMM.2021.3062649", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coexistence of Human-Type Communications (HTCs) and Machine-Type\nCommunications (MTCs) is inevitable. Ultra-Dense Networks (UDNs) will be\nefficacious in supporting both types of communications. In a UDN, a massive\nnumber of low-power and low-cost Small Cells (SCs) are deployed with density\nhigher than that of the HTC users. In such a scenario, the backhaul capacities\nconstitute an intrinsic bottleneck for the system. Hence, we propose a multiple\nassociation scheme where each HTC user associates to and activates multiple SCs\nto overcome the backhaul capacity constraints. In addition, having more active\ncells allows for more MTC devices to be supported by the network. Using tools\nfrom stochastic geometry, we formulate a novel mathematical framework\ninvestigating the performance of the limited-backhaul capacity UDN in terms of\nArea Spectral Efficiency (ASE) for both HTC and MTC and the density of\nsupported MTC devices. Extensive simulations were conducted to verify the\naccuracy of the mathematical analysis under different system parameters.\nResults show the existence of an optimum number of SCs to which an HTC user may\nconnect under backhaul capacity constraints. Besides, the proposed multiple\nassociation scheme significantly improves the performance of MTC in terms of\nboth ASE and density of supported devices.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:33:50 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Elbayoumi", "Mohammed", ""], ["Hamouda", "Walaa", ""], ["Youssef", "Amr", ""]]}, {"id": "2009.13549", "submitter": "Arun Ravindran", "authors": "Anjus George, Arun Ravindran, Mattias Mendieta, Hamed Tabkhi", "title": "Mez: A Messaging System for Latency-Sensitive Multi-Camera Machine\n  Vision at the IoT Edge", "comments": "Under review ACM Transactions on Internet of Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mez is a publish-subscribe messaging system for latency sensitive\nmulti-camera machine vision at the IoT Edge. Unlike existing messaging systems,\nMez allows applications to specify latency, and application accuracy bounds.\nMez implements a network latency controller that dynamically adjusts the video\nframe quality to satisfy latency, and application accuracy requirements.\nAdditionally, the design of Mez utilizes application domain specific features\nto provide low latency operations. Experimental evaluation on an IoT Edge\ntestbed with a pedestrian detection machine vision application indicates that\nMez is able to tolerate latency variations of up to 10x with a worst-case\nreduction of 4.2\\% in the application accuracy F1 score metric.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:01:19 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["George", "Anjus", ""], ["Ravindran", "Arun", ""], ["Mendieta", "Mattias", ""], ["Tabkhi", "Hamed", ""]]}, {"id": "2009.13640", "submitter": "Habib Mostafaei", "authors": "Habib Mostafaei, Mohammad Shojafar, Mauro Conti", "title": "TEL: Low-Latency Failover Traffic Engineering in Data Plane", "comments": null, "journal-ref": "IEEE Transactions on Network and Service Management, 2021", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern network applications demand low-latency traffic engineering in the\npresence of network failure while preserving the quality of service constraints\nlike delay and capacity. Fast Re-Route (FRR) mechanisms are widely used for\ntraffic re-routing purposes in failure scenarios. Control plane FRR typically\ncomputes the backup forwarding rules to detour the traffic in the data plane\nwhen the failure occurs. This mechanism could be computed in the data plane\nwith the emergence of programmable data planes. In this paper, we propose a\nsystem (called TEL) that contains two FRR mechanisms, namely, TEL-C and TEL-D.\nThe first one computes backup forwarding rules in the control plane, satisfying\nmax-min fair allocation. The second mechanism provides FRR in the data plane.\nBoth algorithms require minimal memory on programmable data planes and are\nwell-suited with modern line rate match-action forwarding architectures (e.g.,\nPISA). We implement both mechanisms on P4 programmable software switches (e.g.,\nBMv2 and Tofino) and measure their performance on various topologies. The\nobtained results from a datacenter topology show that our FRR mechanism can\nimprove the flow completion time up to 4.6x$-$7.3x (i.e., small flows) and\n3.1x$-$12x (i.e., large flows) compared to recirculation-based mechanisms, such\nas F10, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 21:35:20 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 12:53:41 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 15:00:28 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Mostafaei", "Habib", ""], ["Shojafar", "Mohammad", ""], ["Conti", "Mauro", ""]]}, {"id": "2009.13797", "submitter": "Paul Barford", "authors": "Shreeshrita Patnaik, Paul Barford, Dante Fratta, Bill Jensen, Neal\n  Lord, Matt Malloy, and Herb Wang", "title": "Internet Photonic Sensing: Using Internet Fiber Optics for Vibration\n  Measurement and Monitoring", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Internet Photonic Sensing (IPS), a new framework\nfor deformation and vibration measurement and monitoring based on signals that\nare available from standard fiber optic communication hardware deployed in the\nInternet. IPS is based on the hypothesis that atmospheric, seismic,\nanthropogenic and other natural activity cause vibrations in the earth that\ntrigger detectable changes in standard optical signals that transmit data\nthrough Internet fiber. We assume a simple system component model for optical\ncommunication hardware and identify two candidate signals that may reflect\ndeformation and vibrations and that can be measured through standard\ninterfaces: Optical Signal Strength (OSS) and Bit Error Rate (BER). We\ninvestigate the efficacy of IPS through a series of controlled, laboratory\nexperiments that consider how the candidate signals respond when fiber is\nsubjected to a range of stresses. We believe that IPS offers the potential to\ntransform the practice of scientific, commercial and public safety-related\nvibration monitoring applications by providing a highly-sensitive platform that\nis available at a global scale.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 06:10:32 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Patnaik", "Shreeshrita", ""], ["Barford", "Paul", ""], ["Fratta", "Dante", ""], ["Jensen", "Bill", ""], ["Lord", "Neal", ""], ["Malloy", "Matt", ""], ["Wang", "Herb", ""]]}, {"id": "2009.13864", "submitter": "Sohei Itahara", "authors": "Sohei Itahara, Takayuki Nishio, Masahiro Morikura, Koji Yamamoto", "title": "Online Trainable Wireless Link Quality Prediction System using Camera\n  Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning-based prediction of future wireless link quality is an\nemerging technique that can potentially improve the reliability of wireless\ncommunications, especially at higher frequencies (e.g., millimeter-wave and\nterahertz technologies), through predictive handover and beamforming to solve\nline-of-sight (LOS) blockage problem. In this study, a real-time online\ntrainable wireless link quality prediction system was proposed; the system was\nimplemented with commercially available laptops. The proposed system collects\ndatasets, updates a model, and infers the received power in real-time. The\nexperimental evaluation was conducted using 5 GHz Wi-Fi, where received signal\nstrength could be degraded by 10 dB when the LOS path was blocked by large\nobstacles. The experimental results demonstrate that the prediction model is\nupdated in real-time, adapts to the change in environment, and predicts the\ntime-varying Wi-Fi received power accurately.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:37:25 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Itahara", "Sohei", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""], ["Yamamoto", "Koji", ""]]}, {"id": "2009.13879", "submitter": "Naoya Yoshida", "authors": "Naoya Yoshida, Takayuki Nishio, Masahiro Morikura, and Koji Yamamoto", "title": "MAB-based Client Selection for Federated Learning with Uncertain\n  Resources in Mobile Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a client selection method for federated learning (FL)\nwhen the computation and communication resource of clients cannot be estimated;\nthe method trains a machine learning (ML) model using the rich data and\ncomputational resources of mobile clients without collecting their data in\ncentral systems. Conventional FL with client selection estimates the required\ntime for an FL round from a given clients' computation power and throughput and\ndetermines a client set to reduce time consumption in FL rounds. However, it is\ndifficult to obtain accurate resource information for all clients before the FL\nprocess is conducted because the available computation and communication\nresources change easily based on background computation tasks, background\ntraffic, bottleneck links, etc. Consequently, the FL operator must select\nclients through exploration and exploitation processes. This paper proposes a\nmulti-armed bandit (MAB)-based client selection method to solve the exploration\nand exploitation trade-off and reduce the time consumption for FL in mobile\nnetworks. The proposed method balances the selection of clients for which the\namount of resources is uncertain and those known to have a large amount of\nresources. The simulation evaluation demonstrated that the proposed scheme\nrequires less learning time than the conventional method in the resource\nfluctuating scenario.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:07:21 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Yoshida", "Naoya", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""], ["Yamamoto", "Koji", ""]]}, {"id": "2009.13922", "submitter": "Syed Muhammad Asad Zaidi", "authors": "Syed Muhammad Asad Zaidi, Marvin Manalastas, Hasan Farooq and Ali\n  Imran", "title": "Mobility Management in Emerging Ultra-Dense Cellular Networks: A Survey,\n  Outlook, and Future Research Directions", "comments": "in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3027258", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential rise in mobile traffic originating from mobile devices\nhighlights the need for making mobility management in future networks even more\nefficient and seamless than ever before. Ultra-Dense Cellular Network vision\nconsisting of cells of varying sizes with conventional and mmWave bands is\nbeing perceived as the panacea for the eminent capacity crunch. However,\nmobility challenges in an ultra-dense heterogeneous network with motley of high\nfrequency and mmWave band cells will be unprecedented due to plurality of\nhandover instances, and the resulting signaling overhead and data interruptions\nfor miscellany of devices. Similarly, issues like user tracking and cell\ndiscovery for mmWave with narrow beams need to be addressed before the\nambitious gains of emerging mobile networks can be realized. Mobility\nchallenges are further highlighted when considering the 5G deliverables of\nmulti-Gbps wireless connectivity, <1ms latency and support for devices moving\nat maximum speed of 500km/h, to name a few. Despite its significance, few\nmobility surveys exist with the majority focused on adhoc networks. This paper\nis the first to provide a comprehensive survey on the panorama of mobility\nchallenges in the emerging ultra-dense mobile networks. We not only present a\ndetailed tutorial on 5G mobility approaches and highlight key mobility risks of\nlegacy networks, but also review key findings from recent studies and highlight\nthe technical challenges and potential opportunities related to mobility from\nthe perspective of emerging ultra-dense cellular networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 10:42:05 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zaidi", "Syed Muhammad Asad", ""], ["Manalastas", "Marvin", ""], ["Farooq", "Hasan", ""], ["Imran", "Ali", ""]]}, {"id": "2009.14428", "submitter": "Miao Jin", "authors": "Xuan Li, Miao Jin", "title": "A General Framework for Charger Scheduling Optimization Problems", "comments": "arXiv admin note: text overlap with arXiv:1901.09129", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a general framework to tackle a diverse range of NP-hard\ncharger scheduling problems, optimizing the trajectory of mobile chargers to\nprolong the life of Wireless Rechargeable Sensor Network (WRSN), a system\nconsisting of sensors with rechargeable batteries and mobile chargers. Existing\nsolutions to charger scheduling problems require problem-specific design and a\ntrade-off between the solution quality and computing time. Instead, we observe\nthat instances of the same type of charger scheduling problem are solved\nrepeatedly with similar combinatorial structure but different data. We consider\nsearching an optimal charger scheduling as a trial and error process, and the\nobjective function of a charging optimization problem as reward, a scalar\nfeedback signal for each search. We propose a deep reinforcement learning-based\ncharger scheduling optimization framework. The biggest advantage of the\nframework is that a diverse range of domain-specific charger scheduling\nstrategy can be learned automatically from previous experiences. A framework\nalso simplifies the complexity of algorithm design for individual charger\nscheduling optimization problem. We pick three representative charger\nscheduling optimization problems, design algorithms based on the proposed deep\nreinforcement learning framework, implement them, and compare them with\nexisting ones. Extensive simulation results show that our algorithms based on\nthe proposed framework outperform all existing ones.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 21:13:23 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Li", "Xuan", ""], ["Jin", "Miao", ""]]}, {"id": "2009.14446", "submitter": "Nariman Torkzaban", "authors": "Anousheh Gholami, Nariman Torkzaban, John S. Baras, and Chrysa\n  Papagianni", "title": "Joint Mobility-Aware UAV Placement and Routing in Multi-Hop UAV Relaying\n  Systems", "comments": "15 Pages, Accepted at ADHOCNETS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) have been extensively utilized to provide\nwireless connectivity in rural and under-developed areas, enhance network\ncapacity and provide support for peaks or unexpected surges in user demand,\nmainly due to their fast deployment, cost-efficiency and superior communication\nperformance resulting from Line of Sight (LoS)-dominated wireless channels. In\norder to exploit the benefits of UAVs as base stations or relays in a mobile\nnetwork, a major challenge is to determine the optimal UAV placement and\nrelocation strategy with respect to the mobility and traffic patterns of the\nground network nodes. Moreover, considering that the UAVs form a multi-hop\naerial network, capacity and connectivity constraints have significant impacts\non the end-to-end network performance. To this end, we formulate the joint UAV\nplacement and routing problem as a Mixed Integer Linear Program (MILP) and\npropose an approximation that leads to a LP rounding algorithm and achieves a\nbalance between time-complexity and optimality.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:18:41 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Gholami", "Anousheh", ""], ["Torkzaban", "Nariman", ""], ["Baras", "John S.", ""], ["Papagianni", "Chrysa", ""]]}]