[{"id": "2006.00030", "submitter": "Onel Luis Alcaraz Lopez", "authors": "Onel L. A. L\\'opez and Nurul Huda Mahmood and Hirley Alves and Matti\n  Latva-aho", "title": "CSI-free vs CSI-based multi-antenna WET for massive low-power Internet\n  of Things", "comments": "16 pags, 11 figures, Accepted in IEEE TWC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Energy Transfer (WET) is a promising solution for powering massive\nInternet of Things deployments. An important question is whether the costly\nChannel State Information (CSI) acquisition procedure is necessary for optimum\nperformance. In this paper, we shed some light into this matter by evaluating\nCSI-based and CSI-free multi-antenna WET schemes in a setup with WET in the\ndownlink, and periodic or Poisson-traffic Wireless Information Transfer (WIT)\nin the uplink. When CSI is available, we show that a maximum ratio transmission\nbeamformer is close to optimum whenever the farthest node experiences at least\n3 dB of power attenuation more than the remaining devices. On the other hand,\nalthough the adopted CSI-free mechanism is not capable of providing average\nharvesting gains, it does provide greater WET/WIT diversity with lower energy\nrequirements when compared with the CSI-based scheme. Our numerical results\nevidence that the CSI-free scheme performs favorably under periodic traffic\nconditions, but it may be deficient in case of Poisson traffic, specially if\nthe setup is not optimally configured. Finally, we show the prominent\nperformance results when the uplink transmissions are periodic, while\nhighlighting the need of a minimum mean square error equalizer rather than\nzero-forcing for information decoding.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 18:38:34 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 09:29:08 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["L\u00f3pez", "Onel L. A.", ""], ["Mahmood", "Nurul Huda", ""], ["Alves", "Hirley", ""], ["Latva-aho", "Matti", ""]]}, {"id": "2006.00097", "submitter": "Liang Wang", "authors": "Liang Wang, Hyojoon Kim, Prateek Mittal, Jennifer Rexford", "title": "Programmable In-Network Obfuscation of Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in programmable switch hardware offer a fresh opportunity to\nprotect user privacy. This paper presents PINOT, a lightweight in-network\nanonymity solution that runs at line rate within the memory and processing\nconstraints of hardware switches. PINOT encrypts a client's IPv4 address with\nan efficient encryption scheme to hide the address from downstream ASes and the\ndestination server. PINOT is readily deployable, requiring no end-user software\nor cooperation from networks other than the trusted network where it runs. We\nimplement a PINOT prototype on the Barefoot Tofino switch, deploy PINOT in a\ncampus network, and present results on protecting user identity against public\nDNS, NTP, and WireGuard VPN services.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 22:11:26 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Wang", "Liang", ""], ["Kim", "Hyojoon", ""], ["Mittal", "Prateek", ""], ["Rexford", "Jennifer", ""]]}, {"id": "2006.00204", "submitter": "Mostafa Zaman Chowdhury", "authors": "Mostafa Zaman Chowdhury, Moh Khalid Hasan, Md Shahjalal, Md Tanvir\n  Hossan, Yeong Min Jang", "title": "Optical wireless hybrid networks for 5G and beyond communications", "comments": "2018 International Conference on Information and Communication\n  Technology Convergence (ICTC)", "journal-ref": null, "doi": "10.1109/ICTC.2018.8539460", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next 5 th generation (5G) and above ultra-high speed, ultra-low latency,\nand extremely high reliable communication systems will consist of heterogeneous\nnetworks. These heterogeneous networks will consist not only radio frequency\n(RF) based systems but also optical wireless based systems. Hybrid\narchitectures among different networks is an excellent approach for achieving\nthe required level of service quality. In this paper, we provide the\nopportunities bring by hybrid systems considering RF as well as optical\nwireless based communication technologies. We also discuss about the key\nresearch direction of hybrid network systems.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 07:05:27 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Chowdhury", "Mostafa Zaman", ""], ["Hasan", "Moh Khalid", ""], ["Shahjalal", "Md", ""], ["Hossan", "Md Tanvir", ""], ["Jang", "Yeong Min", ""]]}, {"id": "2006.00205", "submitter": "Mostafa Zaman Chowdhury", "authors": "Mostafa Zaman Chowdhury, Moh Khalid Hasan, Md Shahjalal, Eun Bi Shin,\n  Yeong Min Jang", "title": "Opportunities of Optical Spectrum for Future Wireless Communications", "comments": "2019 International Conference on Artificial Intelligence in\n  Information and Communication (ICAIIC)", "journal-ref": null, "doi": "10.1109/ICAIIC.2019.8668981", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The requirements in terms of service quality such as data rate, latency,\npower consumption, number of connectivity of future fifth-generation (5G)\ncommunication is very high. Moreover, in Internet of Things (IoT) requires\nmassive connectivity. Optical wireless communication (OWC) technologies such as\nvisible light communication, light fidelity, optical camera communication, and\nfree space optical communication can effectively serve for the successful\ndeployment of 5G and IoT. This paper clearly presents the contributions of OWC\nnetworks for 5G and IoT solutions.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 07:11:33 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Chowdhury", "Mostafa Zaman", ""], ["Hasan", "Moh Khalid", ""], ["Shahjalal", "Md", ""], ["Shin", "Eun Bi", ""], ["Jang", "Yeong Min", ""]]}, {"id": "2006.00310", "submitter": "Ahmed Raoof", "authors": "Ahmed Raoof, Chung-Horng Lung, Ashraf Matrawy", "title": "Introducing Network Coding to RPL: The Chained Secure Mode (CSM)", "comments": "4 pages, 6 figures, 1 table, Accepted at The 19th IEEE International\n  Symposium on Network Computing and Applications (NCA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current standard of Routing Protocol for Low Power and Lossy Networks\n(RPL) incorporates three modes of security: the Unsecured Mode (UM),\nPreinstalled Secure Mode (PSM), and the Authenticated Secure Mode (ASM). While\nthe PSM and ASM are intended to protect against external routing attacks and\nsome replay attacks (through an optional replay protection mechanism), recent\nresearch showed that RPL in PSM is still vulnerable to many routing attacks,\nboth internal and external. In this paper, we propose a novel secure mode for\nRPL, the Chained Secure Mode (CSM), based on the concept of intraflow Network\nCoding. The main goal of CSM is to enhance RPL resilience against replay\nattacks, with the ability to mitigate some of them. The security and\nperformance of a proof-of-concept prototype of CSM were evaluated and compared\nagainst RPL in UM and PSM (with and without the optional replay protection) in\nthe presence of Neighbor attack as an example. It showed that CSM has better\nperformance and more enhanced security compared to both the UM and PSM with the\nreplay protection. On the other hand, it showed a need for a proper recovery\nmechanism for the case of losing a control message.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 16:24:07 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 23:18:42 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 16:45:11 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Raoof", "Ahmed", ""], ["Lung", "Chung-Horng", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "2006.00390", "submitter": "Sourav Mondal", "authors": "Sourav Mondal, Goutam Das, and Elaine Wong", "title": "Centralized and Decentralized Non-Cooperative Load-Balancing Games among\n  Federated Cloudlets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing servers like cloudlets from different service providers\ncompensate scarce computational, memory, and energy resources of mobile\ndevices, are distributed across access networks. However, depending on the\nmobility pattern and dynamically varying computational requirements of\nassociated mobile devices, cloudlets at different parts of the network become\neither overloaded or under-loaded. Hence, load balancing among neighboring\ncloudlets appears to be an essential research problem. Nonetheless, the\nexisting load balancing frameworks are unsuitable for low-latency applications.\nThus, in this paper, we propose an economic and non-cooperative load balancing\ngame for low-latency applications among federated neighboring cloudlets from\nthe same as well as different service providers and heterogeneous classes of\njob requests. Firstly, we propose a centralized incentive mechanism to compute\nthe pure strategy Nash equilibrium load balancing strategies of the cloudlets\nunder the supervision of a neutral mediator. With this mechanism, we ensure\nthat the truthful revelation of private information to the mediator is a\nweakly-dominant strategy for all the federated cloudlets. Secondly, we propose\na continuous-action reinforcement learning automata-based algorithm, which\nallows each cloudlet to independently compute the Nash equilibrium in a\ncompletely distributed network setting. We critically study the convergence\nproperties of the designed learning algorithm, scaffolding our understanding of\nthe underlying load balancing game for faster convergence. Furthermore, through\nextensive simulations, we study the impacts of exploration and exploitation on\nlearning accuracy. This is the first study to show the effectiveness of\nreinforcement learning algorithms for load balancing games among neighboring\ncloudlets.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 00:07:56 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 21:05:10 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Mondal", "Sourav", ""], ["Das", "Goutam", ""], ["Wong", "Elaine", ""]]}, {"id": "2006.00511", "submitter": "Wei Yang Bryan Lim WYB Lim", "authors": "Wei Yang Bryan Lim, Jer Shyuan Ng, Zehui Xiong, Dusit Niyato, Cyril\n  Leung, Chunyan Miao, Qiang Yang", "title": "Incentive Mechanism Design for Resource Sharing in Collaborative Edge\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 5G and Beyond networks, Artificial Intelligence applications are expected\nto be increasingly ubiquitous. This necessitates a paradigm shift from the\ncurrent cloud-centric model training approach to the Edge Computing based\ncollaborative learning scheme known as edge learning, in which model training\nis executed at the edge of the network. In this article, we first introduce the\nprinciples and technologies of collaborative edge learning. Then, we establish\nthat a successful, scalable implementation of edge learning requires the\ncommunication, caching, computation, and learning resources (3C-L) of end\ndevices and edge servers to be leveraged jointly in an efficient manner.\nHowever, users may not consent to contribute their resources without receiving\nadequate compensation. In consideration of the heterogeneity of edge nodes,\ne.g., in terms of available computation resources, we discuss the challenges of\nincentive mechanism design to facilitate resource sharing for edge learning.\nFurthermore, we present a case study involving optimal auction design using\nDeep Learning to price fresh data contributed for edge learning. The\nperformance evaluation shows the revenue maximizing properties of our proposed\nauction over the benchmark schemes.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 12:45:06 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Lim", "Wei Yang Bryan", ""], ["Ng", "Jer Shyuan", ""], ["Xiong", "Zehui", ""], ["Niyato", "Dusit", ""], ["Leung", "Cyril", ""], ["Miao", "Chunyan", ""], ["Yang", "Qiang", ""]]}, {"id": "2006.00653", "submitter": "Nengkun Yu", "authors": "Peng Yan, and Nengkun Yu", "title": "The QQUIC Transport Protocol: Quantum assisted UDP Internet Connections", "comments": "Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum key distribution, initialized in 1984, is a commercialized secure\ncommunication method which enables two parties to produce shared random secret\nkey by the nature of quantum mechanics. We propose QQUIC (Quantum assisted\nQuick UDP Internet Connections) transport protocol, which modifies the famous\nQUIC transport protocol by employing the quantum key distribution instead of\nthe original classical algorithms in the key exchanging stage. Thanks to the\nprovable security of quantum key distribution, the security of QQUIC key does\nnot depend on computational assumptions. Maybe surprisingly, QQUIC can reduce\nthe network latency in some circumstance even comparing with QUIC. To achieve\nthis, the attached quantum connections are used as the dedicated lines for key\ngeneration.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 00:44:58 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Yan", "Peng", ""], ["Yu", "Nengkun", ""]]}, {"id": "2006.00815", "submitter": "Aunas Manzoor", "authors": "Aunas Manzoor, Kitae Kim, Shashi Raj Pandey, S. M. Ahsan Kazmi, Nguyen\n  H. Tran, Walid Saad, and Choong Seon Hong", "title": "Ruin Theory for Energy-Efficient Resource Allocation in UAV-assisted\n  Cellular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) can provide an effective solution for\nimproving the coverage, capacity, and the overall performance of terrestrial\nwireless cellular networks. In particular, UAV-assisted cellular networks can\nmeet the stringent performance requirements of the fifth generation new radio\n(5G NR) applications. In this paper, the problem of energy-efficient resource\nallocation in UAV-assisted cellular networks is studied under the reliability\nand latency constraints of 5G NR applications. The framework of ruin theory is\nemployed to allow solar-powered UAVs to capture the dynamics of harvested and\nconsumed energies. First, the surplus power of every UAV is modeled, and then\nit is used to compute the probability of ruin of the UAVs. The probability of\nruin denotes the vulnerability of draining out the power of a UAV. Next, the\nprobability of ruin is used for efficient user association with each UAV. Then,\npower allocation for 5G NR applications is performed to maximize the achievable\nnetwork rate using the water-filling approach. Simulation results demonstrate\nthat the proposed ruin-based scheme can enhance the flight duration up to 61%\nand the number of served users in a UAV flight by up to 58\\%, compared to a\nbaseline SINR-based scheme.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 09:46:23 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Manzoor", "Aunas", ""], ["Kim", "Kitae", ""], ["Pandey", "Shashi Raj", ""], ["Kazmi", "S. M. Ahsan", ""], ["Tran", "Nguyen H.", ""], ["Saad", "Walid", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2006.00876", "submitter": "Reza Malekian Ph.D.", "authors": "Nikheel Soni, Reza Malekian, Dijana Capeska Bogatinoska", "title": "Algorithms for Computing in Fog Systems: principles, algorithms, and\n  Challenges", "comments": "43rd International Convention on Information, Communication and\n  Electronic Technology, Opatija, Croatia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog computing is an architecture that is used to distribute resources such as\ncomputing, storage, and memory closer to end-user to improve applications and\nservice deployment. The idea behind fog computing is to improve cloud computing\nand IoT infrastructures by reducing compute power, network bandwidth, and\nlatency as well as storage requirements. This paper presents an overview of\nwhat fog computing is, related concepts, algorithms that are present to improve\nfog computing infrastructure as well as challenges that exist. This paper shows\nthat there is a great advantage of using fog computing to support cloud and IoT\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 12:15:53 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Soni", "Nikheel", ""], ["Malekian", "Reza", ""], ["Bogatinoska", "Dijana Capeska", ""]]}, {"id": "2006.00880", "submitter": "Krzysztof Malarski", "authors": "Jakob Thrane (1), Krzysztof Mateusz Malarski (1), Henrik Lehrmann\n  Christiansen (1) and Sarah Ruepp (1) ((1) DTU Fotonik)", "title": "Experimental Evaluation of Empirical NB-IoT Propagation Modelling in a\n  Deep-Indoor Scenario", "comments": "6 pages, 6 figures, submitted to Globecom2020 conference, Selected\n  Areas in Communications Symposium, Track on Internet of Things and Smart\n  Connected Communities", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path-loss modelling in deep-indoor scenarios is a difficult task. On one\nhand, the theoretical formulae solely dependent on transmitter-receiver\ndistance are too simple; on the other hand, discovering all significant factors\naffecting the loss of signal power in a given situation may often be\ninfeasible. In this paper, we experimentally investigate the influence of\ndeep-indoor features such as indoor depth, indoor distance and distance to the\nclosest tunnel corridor and the effect on received power using NB-IoT. We\ndescribe a measurement campaign performed in a system of long underground\ntunnels, and we analyse linear regression models involving the engineered\nfeatures. We show that the current empirical models for NB-IoT signal\nattenuation are inaccurate in a deep-indoor scenario. We observe that 1) indoor\ndistance and penetration depth do not explain the signal attenuation well and\nincrease the error of the prediction by 2-12 dB using existing models, and 2) a\npromising feature of average distance to the nearest corridor is identified.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 12:28:55 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Thrane", "Jakob", "", "DTU Fotonik"], ["Malarski", "Krzysztof Mateusz", "", "DTU Fotonik"], ["Christiansen", "Henrik Lehrmann", "", "DTU Fotonik"], ["Ruepp", "Sarah", "", "DTU Fotonik"]]}, {"id": "2006.00912", "submitter": "Shengxue He Dr.", "authors": "Shengxue He", "title": "An Approach to Avoid the Unreal High Flows on Congested Links and\n  Investigates the Evolution of Congestion over Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unreal high flows may appear on the actually congested links in the\nresult when a monotonically increasing link travel time function of flow volume\nis adopted in traffic assignment. The fixed link flow results of a static\ntraffic assignment model (TAM) make it nearly impossible to investigate and\nmake use of the actual evolution of congested zones over the network during the\npredetermined observation time period. Many methods, such as TAMs with\nside-constraints on link flow capacity and the pseudo dynamic traffic\nassignment based on day-by-day traffic, have been proposed to improve the\nreliability of the results of TAM, but cannot eliminate the problem. To resolve\nthe above problems, we first uncover the origin of problem by analyzing the\nconnection between the link travel time function and the fundamental diagram of\ntraffic flow theory. According to the above connection a mapping is formulated\nto reflect the two branches of the fundamental diagram. Then with the\nassumption that the link flow states are given, new traffic assignment models\nare presented. To resolve the obtained non-convex user equilibrium model, a\nbranch-and-bound algorithm is designed based on linearizing the nonlinear part\nof the objective function. At last, by repeatedly resolving the corresponding\ntraffic assignment model with the renewed initial flow states of links, the\nevolution of congested zones during the observation time period can be\nreproduced and investigated. The numerical examples demonstrate the\neffectiveness of the new approach.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 00:45:51 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["He", "Shengxue", ""]]}, {"id": "2006.00930", "submitter": "Andra Voicu", "authors": "Andra M. Voicu, Ljiljana Simi\\'c, and Marina Petrova", "title": "Limitations of Stochastic Geometry Modelling for Estimating the\n  Performance of CSMA Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter considers stochastic geometry modelling (SGM) for estimating the\nsignal-to-interference-and-noise ratio (SINR) and throughput of CSMA networks.\nWe show that, despite its compact mathematical formulation, SGM has serious\nlimitations in terms of both accuracy and computational efficiency. SGM often\nseverely underestimates the SINR versus ns-3 simulations, yet as it neglects\nthe sensing overhead when mapping SINR to throughput, SGM usually overestimates\nthe throughput substantially. We propose our hybrid model for CSMA, which we\nargue is a superior modelling approach due to being significantly more accurate\nand at least one order of magnitude faster to compute than SGM.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 13:26:16 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Voicu", "Andra M.", ""], ["Simi\u0107", "Ljiljana", ""], ["Petrova", "Marina", ""]]}, {"id": "2006.00944", "submitter": "Ahmed Elzanaty Dr.", "authors": "Luca Chiaraviglio and Ahmed Elzanaty and Mohamed-Slim Alouini", "title": "Health Risks Associated with 5G Exposure: A View from the Communications\n  Engineering Perspective", "comments": "45 pages, 18 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The deployment of 5G wireless communication services requires the\ninstallation of 5G next-generation Node-B Base Stations (gNBs) over the\nterritory and the wide adoption of 5G User Equipment (UE). In this context, the\npopulation is concerned about the potential health risks associated with the\nRadio Frequency (RF) emissions from 5G equipment, with several communities\nactively working toward stopping the 5G deployment. To face these concerns, in\nthis work, we analyze the health risks associated with 5G exposure by adopting\na new and comprehensive viewpoint, based on the communications engineering\nperspective. By exploiting our background, we debunk the alleged health effects\nof 5G exposure and critically review the latest works that are often referenced\nto support the health concerns from 5G. We then precisely examine the\nup-to-date metrics, regulations, and assessment of compliance procedures for 5G\nexposure, by evaluating the latest guidelines from IEEE, ICNIRP, ITU, IEC, and\nFCC, as well as the national regulations in more than 220 countries. We also\nthoroughly analyze the main health risks that are frequently associated with\nspecific 5G features (e.g., MIMO, beamforming, cell densification, adoption of\nmillimeter waves, and connection of millions of devices). Finally, we examine\nthe risk mitigation techniques based on communications engineering that can be\nimplemented to reduce the exposure from 5G gNB and UE. Overall, we argue that\nthe widely perceived health risks that are attributed to 5G are not supported\nby scientific evidence from communications engineering. In addition, we explain\nhow the solutions to minimize the health risks from 5G are already mature and\nready to be implemented. Finally, future works, e.g., aimed at evaluating\nlong-term impacts of 5G exposure, as well as innovative solutions to further\nreduce the RF emissions, are suggested.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 13:48:09 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Chiaraviglio", "Luca", ""], ["Elzanaty", "Ahmed", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2006.00992", "submitter": "Zemin Sun", "authors": "Zemin Sun, Yanheng Liu, Jian Wang, Carie Anil, and Dongpu Cao", "title": "Game Theoretic Approaches in Vehicular Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of the Internet of Things (IoT), vehicles and other intelligent\ncomponents in Intelligent Transportation System (ITS) are connected, forming\nthe Vehicular Networks (VNs) that provide efficient and secure traffic,\nubiquitous access to information, and various applications. However, as the\nnumber of connected nodes keeps increasing, it is challenging to satisfy\nvarious and large amounts of service requests with different Quality of Service\n(QoS ) and security requirements in the highly dynamic VNs. Intelligent nodes\nin VNs can compete or cooperate for limited network resources so that either an\nindividual or group objectives can be achieved. Game theory, a theoretical\nframework designed for strategic interactions among rational decision-makers\nwho faced with scarce resources, can be used to model and analyze individual or\ngroup behaviors of communication entities in VNs. This paper primarily surveys\nthe recent advantages of GT used in solving various challenges in VNs. As VNs\nand GT have been extensively investigate34d, this survey starts with a brief\nintroduction of the basic concept and classification of GT used in VNs. Then, a\ncomprehensive review of applications of GT in VNs is presented, which primarily\ncovers the aspects of QoS and security. Moreover, with the development of\nfifth-generation (5G) wireless communication, recent contributions of GT to\ndiverse emerging technologies of 5G integrated into VNs are surveyed in this\npaper. Finally, several key research challenges and possible solutions for\napplying GT in VNs are outlined.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 14:53:27 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Sun", "Zemin", ""], ["Liu", "Yanheng", ""], ["Wang", "Jian", ""], ["Anil", "Carie", ""], ["Cao", "Dongpu", ""]]}, {"id": "2006.01025", "submitter": "Nikhil Karamchandani", "authors": "Jad Hachem, Nikhil Karamchandani, Suhas Diggavi, and Sharayu Moharir", "title": "Coded Caching for Heterogeneous Wireless Networks", "comments": "To appear in \"Wireless Edge Caching: Modelling, Analysis and\n  Optimization\", Cambridge University Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter provides an overview of coded caching in the context of\nheterogeneous wireless networks. We begin by briefly describing the key idea\nbehind coded caching and then discuss in detail the impact of various aspects\nsuch as non-uniform content popularity, multiple cache access, and\ninterference.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:44:20 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hachem", "Jad", ""], ["Karamchandani", "Nikhil", ""], ["Diggavi", "Suhas", ""], ["Moharir", "Sharayu", ""]]}, {"id": "2006.01032", "submitter": "Sejin Seo", "authors": "Sejin Seo, Sang Won Choi, Sujin Kook, Seong-Lyun Kim, Seung-Woo Ko", "title": "Understanding Uncertainty of Edge Computing: New Principle and Design\n  Approach", "comments": "7 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the edge's position between the cloud and the users, and the recent\nsurge of deep neural network (DNN) applications, edge computing brings about\nuncertainties that must be understood separately. Particularly, the edge users'\nlocally specific requirements that change depending on time and location cause\na phenomenon called dataset shift, defined as the difference between the\ntraining and test datasets' representations. It renders many of the\nstate-of-the-art approaches for resolving uncertainty insufficient. Instead of\nfinding ways around it, we exploit such phenomenon by utilizing a new\nprinciple: AI model diversity, which is achieved when the user is allowed to\nopportunistically choose from multiple AI models. To utilize AI model\ndiversity, we propose Model Diversity Network (MoDNet), and provide design\nguidelines and future directions for efficient learning driven communication\nschemes.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:59:29 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Seo", "Sejin", ""], ["Choi", "Sang Won", ""], ["Kook", "Sujin", ""], ["Kim", "Seong-Lyun", ""], ["Ko", "Seung-Woo", ""]]}, {"id": "2006.01074", "submitter": "Fabian Ruffy", "authors": "Fabian Ruffy, Tao Wang, Anirudh Sivaraman", "title": "Gauntlet: Finding Bugs in Compilers for Programmable Packet Processing", "comments": null, "journal-ref": "Proceedings of the USENIX Symposium on Operating Systems Design\n  and Implementation (OSDI). November, 2020", "doi": null, "report-no": null, "categories": "cs.NI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Programmable packet-processing devices such as programmable switches and\nnetwork interface cards are becoming mainstream. These devices are configured\nin a domain-specific language such as P4, using a compiler to translate\npacket-processing programs into instructions for different targets. As networks\nwith programmable devices become widespread, it is critical that these\ncompilers be dependable.\n  This paper considers the problem of finding bugs in compilers for packet\nprocessing in the context of P4-16. We introduce domain-specific techniques to\ninduce both abnormal termination of the compiler (crash bugs) and\nmiscompilation (semantic bugs). We apply these techniques to (1) the\nopen-source P4 compiler (P4C) infrastructure, which serves as a common base for\ndifferent P4 back ends; (2) the P4 back end for the P4 reference software\nswitch; and (3) the P4 back end for the Barefoot Tofino switch.\n  Across the 3 platforms, over 8 months of bug finding, our tool Gauntlet\ndetected 96 new and distinct bugs (62 crash and 34 semantic), which we\nconfirmed with the respective compiler developers. 54 have been fixed (31 crash\nand 23 semantic); the remaining have been assigned to a developer. Our\nbug-finding efforts also led to 6 P4 specification changes. We have open\nsourced Gauntlet at p4gauntlet.github.io and it now runs within P4C's\ncontinuous integration pipeline.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 16:56:31 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 15:39:26 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Ruffy", "Fabian", ""], ["Wang", "Tao", ""], ["Sivaraman", "Anirudh", ""]]}, {"id": "2006.01104", "submitter": "Quang-Trung Luu", "authors": "Quang-Trung Luu, Sylvaine Kerboeuf, and Michel Kieffer", "title": "Uncertainty-Aware Resource Provisioning for Network Slicing", "comments": "Submitted to IEEE Transactions on Network and Service Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing allows Mobile Network Operators to split the physical\ninfrastructure into isolated virtual networks (slices), managed by Service\nProviders to accommodate customized services. The Service Function Chains\n(SFCs) belonging to a slice are usually deployed on a best-effort premise:\nnothing guarantees that network infrastructure resources will be sufficient to\nsupport a varying number of users, each with uncertain requirements. Taking the\nperspective of a network Infrastructure Provider (InP), this paper proposes a\nresource provisioning approach for slices, robust to a partly unknown number of\nusers with random usage of the slice resources. The provisioning scheme aims to\nmaximize the total earnings of the InP, while providing a probabilistic\nguarantee that the amount of provisioned network resources will meet the slice\nrequirements. Moreover, the proposed provisioning approach is performed so as\nto limit its impact on low-priority background services, which may co-exist\nwith slices in the infrastructure network. A Mixed Integer Linear Programming\nformulation of the slice resource provisioning problem is proposed. Optimal\njoint and suboptimal sequential solutions are proposed. These solutions are\ncompared to a provisioning scheme that does not account for best-effort\nservices sharing the common infrastructure network.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 17:42:40 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Luu", "Quang-Trung", ""], ["Kerboeuf", "Sylvaine", ""], ["Kieffer", "Michel", ""]]}, {"id": "2006.01235", "submitter": "Mattia Lecci", "authors": "Mattia Lecci, Michele Polese, Chiehping Lai, Jian Wang, Camillo\n  Gentile, Nada Golmie, Michele Zorzi", "title": "Quasi-Deterministic Channel Model for mmWaves: Mathematical\n  Formalization and Validation", "comments": "6 pages, 5 figures, 1 table, presented at IEEE GLOBECOM 2020. Please\n  cite it as: M. Lecci, M. Polese, C. Lai, J. Wang, C. Gentile, N. Golmie, M.\n  Zorzi, \"Quasi-Deterministic Channel Model for mmWaves: Mathematical\n  Formalization and Validation,\" IEEE Global Communications Conference\n  (GLOBECOM), Dec. 2020, Taipei, Taiwan", "journal-ref": null, "doi": "10.1109/GLOBECOM42002.2020.9322374", "report-no": null, "categories": "eess.SP cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G and beyond networks will use, for the first time ever, the millimeter wave\n(mmWave) spectrum for mobile communications. Accurate performance evaluation is\nfundamental to the design of reliable mmWave networks, with accuracy rooted in\nthe fidelity of the channel models. At mmWaves, the model must account for the\nspatial characteristics of propagation since networks will employ highly\ndirectional antennas to counter the much greater pathloss. In this regard,\nQuasi-Deterministic (QD) models are highly accurate channel models, which\ncharacterize the propagation in terms of clusters of multipath components,\ngiven by a reflected ray and multiple diffuse components of any given Computer\nAided Design (CAD) scenario. This paper introduces a detailed mathematical\nformulation for QD models at mmWaves, that can be used as a reference for their\nimplementation and development. Moreover, it compares channel instances\nobtained with an open source NIST QD model implementation against real\nmeasurements at 60 GHz, substantiating the accuracy of the model. Results show\nthat, when comparing the proposed model and deterministic rays alone with a\nmeasurement campaign, the Kolmogorov-Smirnov (KS) test of the QD model improves\nby up to 0.537.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 20:14:21 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 11:21:01 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Lecci", "Mattia", ""], ["Polese", "Michele", ""], ["Lai", "Chiehping", ""], ["Wang", "Jian", ""], ["Gentile", "Camillo", ""], ["Golmie", "Nada", ""], ["Zorzi", "Michele", ""]]}, {"id": "2006.01327", "submitter": "Raghunandan M Rao", "authors": "Raghunandan M. Rao, Vuk Marojevic, Jeffrey H. Reed", "title": "Semi-Blind Post-Equalizer SINR Estimation and Dual CSI Feedback for\n  Radar-Cellular Coexistence", "comments": "33 pages, 26 figures", "journal-ref": null, "doi": "10.1109/TVT.2020.3001911", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current cellular systems use pilot-aided statistical-channel state\ninformation (S-CSI) estimation and limited feedback schemes to aid in link\nadaptation and scheduling decisions. However, in the presence of pulsed radar\nsignals, pilot-aided S-CSI is inaccurate since interference statistics on pilot\nand non-pilot resources can be different. Moreover, the channel will be bimodal\nas a result of the periodic interference. In this paper, we propose a max-min\nheuristic to estimate the post-equalizer SINR in the case of non-pilot pulsed\nradar interference, and characterize its distribution as a function of noise\nvariance and interference power. We observe that the proposed heuristic incurs\nlow computational complexity, and is robust beyond a certain SINR threshold for\ndifferent modulation schemes, especially for QPSK. This enables us to develop a\ncomprehensive semi-blind framework to estimate the wideband SINR metric that is\ncommonly used for S-CSI quantization in 3GPP Long-Term Evolution (LTE) and New\nRadio (NR) networks. Finally, we propose dual CSI feedback for practical\nradar-cellular spectrum sharing, to enable accurate CSI acquisition in the\nbimodal channel. We demonstrate significant improvements in throughput, block\nerror rate and retransmission-induced latency for LTE-Advanced Pro when\ncompared to conventional pilot-aided S-CSI estimation and limited feedback\nschemes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 00:58:51 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Rao", "Raghunandan M.", ""], ["Marojevic", "Vuk", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "2006.01354", "submitter": "Tan N. Le", "authors": "Tan N. Le, Zhenhua Liu", "title": "Flex: Closing the Gaps between Usage and Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data centers are giant factories of Internet data and services. Worldwide\ndata centers consume energy and emit emissions more than airline industry.\nUnfortunately, most of data centers are significantly underutilized. One of the\nmajor reasons is the big gaps between the real usage and the provisioned\nresources because users tend to over-estimate their demand and data center\noperators often rely on users' requests for resource allocation. In this paper,\nwe first conduct an in-depth analysis of a Google cluster trace to unveil the\nroot causes for low utilization and highlight the great potential to improve\nit. We then developed an online resource manager Flex to maximize the cluster\nutilization while satisfying the Quality of Service (QoS). Large-scale\nevaluations based on real-world traces show that Flex admits up to 1.74x more\nrequests and 1.6x higher utilization compared to tradition schedulers while\nmaintaining the QoS.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 02:41:39 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Le", "Tan N.", ""], ["Liu", "Zhenhua", ""]]}, {"id": "2006.01371", "submitter": "Jiangbin Lyu Dr.", "authors": "Yifan Zhang, Jiangbin Lyu and Liqun Fu", "title": "Energy-Efficient Cyclical Trajectory Design for UAV-Aided Maritime Data\n  Collection in Wind", "comments": "7 pages, 9 figures. Investigated UAV-aided maritime data collection\n  in wind, with joint trajectory and communications optimization for energy\n  efficiency. Proposed new cyclical trajectory design that can handle arbitrary\n  data volume with significantly reduced computational/trajectory complexity.\n  Unveiled that the wind can be proactively utilized by our optimized\n  trajectory", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.NI cs.SY eess.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs), especially fixed-wing ones that withstand\nstrong winds, have great potential for oceanic exploration and research. This\npaper studies a UAV-aided maritime data collection system with a fixed-wing UAV\ndispatched to collect data from marine buoys. We aim to minimize the UAV's\nenergy consumption in completing the task by jointly optimizing the\ncommunication time scheduling among the buoys and the UAV's flight trajectory\nsubject to wind effect, which is a non-convex problem and difficult to solve\noptimally. Existing techniques such as the successive convex approximation\n(SCA) method provide efficient sub-optimal solutions for collecting\nsmall/moderate data volume, whereas the solution heavily relies on the\ntrajectory initialization and has not explicitly considered the wind effect,\nwhile the computational complexity and resulted trajectory complexity both\nbecome prohibitive for the task with large data volume. To this end, we propose\na new cyclical trajectory design framework that can handle arbitrary data\nvolume efficiently subject to wind effect. Specifically, the proposed UAV\ntrajectory comprises multiple cyclical laps, each responsible for collecting\nonly a subset of data and thereby significantly reducing the\ncomputational/trajectory complexity, which allows searching for better\ntrajectory initialization that fits the buoys' topology and the wind. Numerical\nresults show that the proposed cyclical scheme outperforms the benchmark\none-flight-only scheme in general. Moreover, the optimized cyclical 8-shape\ntrajectory can proactively exploit the wind and achieve lower energy\nconsumption compared with the case without wind.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 03:47:05 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Zhang", "Yifan", ""], ["Lyu", "Jiangbin", ""], ["Fu", "Liqun", ""]]}, {"id": "2006.01404", "submitter": "A S Narmadha", "authors": "A.S.Narmadha", "title": "Trust-Based Winnow Linear Multiplicative Classification For Secure\n  Multipath Routing In Manet", "comments": "28pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multipath routing in Mobile Ad Hoc Network (MANET) plays a significant\nconcern for secured data transmission by avoiding the attack nodes in the\nnetwork. In order to overcome such limitations, a Winnow Trust based Multipath\nRoute Discovery (WT-MRD) Mechanism is proposed. It constructs multiple paths\nfrom source to destination with higher security and lesser time. Initially, the\ntrust value of each node is calculated based on the node cooperative count,\ndata packet forwarding rate and packet drop rate by Neighbor Node-based Trust\nCalculation (NN-TC) Model. After calculating the trust value, the nodes are\nclassified as normal or malicious by using Winnow Linear Multiplicative\nClassification (WLMC) Algorithm. With the help of normal nodes, the WT-MRD\nMechanism finds multipath from source to destination by sending a two control\nmessage RREQ and RREP. Source node transmits a route request RREQ to the\nneighboring node for constructing the multiple route paths. After receiving the\nRREQ message, the neighboring node maintains the route table where the source\ninformation and next hop information are present. Then Route Reply (RREP)\nmessages are sent from neighboring node to source node. By this way, multiple\nroute paths from source to destination are constructed with a higher security\nlevel. Keywords: Cooperative Count, Data Packet Dropped Rate, Data Packet\nForwarded Rate, Multipath Routing, Security, Trust Value, Winnow Linear\nMultiplicative Classification\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 05:49:07 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Narmadha", "A. S.", ""]]}, {"id": "2006.01515", "submitter": "Emmanouil Fountoulakis", "authors": "Emmanouil Fountoulakis, Themistoklis Charalambous, Nikolaos Nomikos,\n  Anthony Ephremides, Nikolaos Pappas", "title": "Information Freshness and Packet Drop Rate Interplay in a Two-User\n  Multi-Access Channel", "comments": "Submitted to ITW", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we combine the two notions of timely delivery of information in\norder to study their interplay; namely, deadline-constrained packet delivery\ndue to latency constraints and freshness of information at the destination.\nMore specifically, we consider a two-user multiple access setup with random\naccess, in which user 1 is a wireless device with a queue and has external\nbursty traffic which is deadline-constrained, while user 2 monitors a sensor\nand transmits status updates to the destination. For this simple, yet\nmeaningful setup, we provide analytical expressions for the throughput and drop\nprobability of user 1, and an analytical expression for the average Age of\nInformation (AoI) of user 2 monitoring the sensor. The relations reveal that\nthere is a trade-off between the average AoI of user 2 and the drop rate of\nuser 1: the lower the average AoI, the higher the drop rate, and vice versa.\nSimulations corroborate the validity of our theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 10:56:00 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 18:00:06 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Fountoulakis", "Emmanouil", ""], ["Charalambous", "Themistoklis", ""], ["Nomikos", "Nikolaos", ""], ["Ephremides", "Anthony", ""], ["Pappas", "Nikolaos", ""]]}, {"id": "2006.01540", "submitter": "Basheer Al-Duwairi Dr.", "authors": "Basheer Al-Duwairi, Oznur Ozkasap, Ahmet Uysal, Ceren Kocaogullar and\n  Kaan Yildirim", "title": "LogDos: A Novel Logging-based DDoS Prevention Mechanism in Path\n  Identifier-Based Information Centric Networks", "comments": "submitted to Journal of Network and Computer Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Centric Networks (ICNs) have emerged in recent years as a new\nnetworking paradigm for the next-generation Internet. The primary goal of these\nnetworks is to provide effective mechanisms for content distribution and\nretrieval based on in-network content caching. The design of different ICN\narchitectures addressed many of the security issues found in the traditional\nInternet. Therefore, allowing for a secure, reliable, and scalable\ncommunication over the Internet. However, recent research studies showed that\nthese architectures are vulnerable to different types of DDoS attacks. In this\npaper, we propose a defense mechanism against distributed denial of service\nattacks (DDoS) in path-identifier based information centric networks. The\nproposed mechanism, called LogDos, performs GET Message logging based filtering\nand employs Bloom filter based logging to store incoming GET messages such that\ncorresponding content messages are verified, while filtering packets\noriginating from malicious hosts. We develop three versions of LogDos with\nvarying levels of storage overhead at LogDos-enabled router. Extensive\nsimulation experiments show that LogDos is very effective against DDoS attacks\nas it can filter more than 99.98 % of attack traffic in different attack\nscenarios while incurring acceptable storage overhead.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 11:59:55 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 11:57:10 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Al-Duwairi", "Basheer", ""], ["Ozkasap", "Oznur", ""], ["Uysal", "Ahmet", ""], ["Kocaogullar", "Ceren", ""], ["Yildirim", "Kaan", ""]]}, {"id": "2006.01553", "submitter": "Lena Mashayekhy", "authors": "Weibin Ma and Lena Mashayekhy", "title": "Truthful Computation Offloading Mechanisms for Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing (EC) is a promising paradigm providing a distributed computing\nsolution for users at the edge of the network. Preserving satisfactory quality\nof experience (QoE) for users when offloading their computation to EC is a\nnon-trivial problem. Computation offloading in EC requires jointly optimizing\naccess points (APs) allocation and edge service placement for users, which is\ncomputationally intractable due to its combinatorial nature. Moreover, users\nare self-interested, and they can misreport their preferences leading to\ninefficient resource allocation and network congestion. In this paper, we\ntackle this problem and design a novel mechanism based on algorithmic mechanism\ndesign to implement a system equilibrium. Our mechanism assigns a proper pair\nof AP and edge server along with a service price for each new joining user\nmaximizing the instant social surplus while satisfying all users' preferences\nin the EC system. Declaring true preferences is a weakly dominant strategy for\nthe users. The experimental results show that our mechanism outperforms user\nequilibrium and random selection strategies in terms of the experienced\nend-to-end latency.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 12:18:07 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ma", "Weibin", ""], ["Mashayekhy", "Lena", ""]]}, {"id": "2006.01651", "submitter": "Spyridon Mastorakis", "authors": "Spyridon Mastorakis, Tianxiang Li, Lixia Zhang", "title": "DAPES: Named Data for Off-the-Grid File Sharing with Peer-to-Peer\n  Interactions", "comments": "This paper was accepted for publication at the 40th IEEE\n  International Conference on Distributed Computing Systems (ICDCS). The\n  copyright is with the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces DAta-centric Peer-to-peer filE Sharing (DAPES), a data\nsharing protocol for scenarios with intermittent connectivity and user\nmobility. DAPES provides a set of semantically meaningful hierarchical naming\nabstractions that facilitate the exchange of file collections via local\nconnectivity. This enables peers to \"make the most\" out of the limited\nconnection time with other peers by maximizing the utility of individual\ntransmissions to provide data missing by most connected peers. DAPES runs on\ntop of Named-Data Networking (NDN) and extends NDN's data-centric network layer\nabstractions to achieve communication over multiple wireless hops through an\nadaptive hop-by-hop forwarding/suppression mechanism. We have evaluated DAPES\nthrough real-world experiments in an outdoor campus setting and extensive\nsimulations. Our results demonstrate that DAPES achieves 50-71% lower overheads\nand 15-33% lower file sharing delays compared to file sharing solutions that\nrely on IP-based mobile ad-hoc routing.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 14:27:26 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Mastorakis", "Spyridon", ""], ["Li", "Tianxiang", ""], ["Zhang", "Lixia", ""]]}, {"id": "2006.01674", "submitter": "Francesco Vatalaro", "authors": "Francesco Vatalaro and Gianfranco Ciccarella", "title": "A network paradigm for very high capacity mobile and fixed\n  telecommunications ecosystem sustainable evolution", "comments": "42 pages, 4 tables, 6 figures. v2: Revised English", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For very high capacity networks (VHC), the main objective is to improve the\nquality of the end-user experience. This implies compliance with key\nperformance indicators (KPIs) required by applications. Key performance\nindicators at the application level are throughput, download time, round trip\ntime, and video delay. They depend on the end-to-end connection between the\nserver and the end-user device. For VHC networks, Telco operators must provide\nthe required application quality. Moreover, they must meet the objectives of\neconomic sustainability. Today, Telco operators rarely achieve the above\nobjectives, mainly due to the push to increase the bit-rate of access networks\nwithout considering the end-to-end KPIs of the applications. The main\ncontribution of this paper concerns the definition of a deployment framework to\naddress performance and cost issues for VHC networks. We show three actions on\nwhich it is necessary to focus. First, limiting bit-rate through video\ncompression. Second, contain the rate of packet loss through artificial\nintelligence algorithms for line stabilization. Third, reduce latency (i.e.,\nround-trip time) with edge-cloud computing. The concerted and gradual\napplication of these measures can allow a Telco to get out of the\nultra-broadband \"trap\" of the access network, as defined in the paper. We\npropose to work on end-to-end optimization of the bandwidth utilization ratio.\nThis leads to a better performance experienced by the end-user. It also allows\na Telco operator to create new business models and obtain new revenue streams\nat a sustainable cost. To give a clear example, we describe how to realize\nmobile virtual and augmented reality, which is one of the most challenging\nfuture services.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 14:48:34 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 10:04:40 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Vatalaro", "Francesco", ""], ["Ciccarella", "Gianfranco", ""]]}, {"id": "2006.01790", "submitter": "Dimitrios Michael Manias", "authors": "Dimitrios Michael Manias, Hassan Hawilo, Manar Jammal, Abdallah Shami", "title": "Depth-Optimized Delay-Aware Tree (DO-DAT) for Virtual Network Function\n  Placement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the constant increase in demand for data connectivity, network service\nproviders are faced with the task of reducing their capital and operational\nexpenses while ensuring continual improvements to network performance. Although\nNetwork Function Virtualization (NFV) has been identified as a solution,\nseveral challenges must be addressed to ensure its feasibility. In this paper,\nwe present a machine learning-based solution to the Virtual Network Function\n(VNF) placement problem. This paper proposes the Depth-Optimized Delay-Aware\nTree (DO-DAT) model by using the particle swarm optimization technique to\noptimize decision tree hyper-parameters. Using the Evolved Packet Core (EPC) as\na use case, we evaluate the performance of the model and compare it to a\npreviously proposed model and a heuristic placement strategy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 17:18:20 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Manias", "Dimitrios Michael", ""], ["Hawilo", "Hassan", ""], ["Jammal", "Manar", ""], ["Shami", "Abdallah", ""]]}, {"id": "2006.01818", "submitter": "Haw-Minn Lu", "authors": "Haw-minn Lu, Adrian Kwong, Jose Unpingco", "title": "Securing Your Collaborative Jupyter Notebooks in the Cloud using\n  Container and Load Balancing Services", "comments": "Accepted and submitted to 19th Python in Science Conference. (SciPy\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jupyter has become the go-to platform for developing data applications but\ndata and security concerns, especially when dealing with healthcare, have\nbecome paramount for many institutions and applications dealing with sensitive\ninformation. How then can we continue to enjoy the data analysis and machine\nlearning opportunities provided by Jupyter and the Python ecosystem while\nguaranteeing auditable compliance with security and privacy concerns? We will\ndescribe the architecture and implementation of a cloud based platform based on\nJupyter that integrates with Amazon Web Services (AWS) and uses containerized\nservices without exposing the platform to the vulnerabilities present in\nKubernetes and JupyterHub. This architecture addresses the HIPAA requirements\nto ensure both security and privacy of data. The architecture uses an AWS\nservice to provide JSON Web Tokens (JWT) for authentication as well as network\ncontrol. Furthermore, our architecture enables secure collaboration and sharing\nof Jupyter notebooks. Even though our platform is focused on Jupyter notebooks\nand JupyterLab, it also supports R-Studio and bespoke applications that share\nthe same authentication mechanisms. Further, the platform can be extended to\nother cloud services other than AWS.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 17:52:32 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Lu", "Haw-minn", ""], ["Kwong", "Adrian", ""], ["Unpingco", "Jose", ""]]}, {"id": "2006.01820", "submitter": "Adnan Aijaz", "authors": "Adnan Aijaz", "title": "Private 5G: The Future of Industrial Wireless", "comments": "Accepted for publication in IEEE Industrial Electronics Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance wireless communication is crucial in digital transformation\nof industrial systems which is driven by Industry 4.0 and the Industrial\nInternet initiatives. Among the candidate industrial wireless technologies, 5G\n(cellular/mobile) holds significant potential. Operation of private\n(non-public) 5G networks in industrial environments is promising to fully\nunleash this potential. This article provides a technical overview of private\n5G networks. It introduces the concept and functional architecture of private\n5G while highlighting the key benefits and industrial use-cases. It explores\nspectrum opportunities for private 5G networks. It also discusses design\naspects of private 5G along with the key challenges. Finally, it explores the\nemerging standardization and open innovation ecosystem for private 5G.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 17:53:31 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 17:34:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Aijaz", "Adnan", ""]]}, {"id": "2006.01977", "submitter": "Vidal Attias", "authors": "Vidal Attias, Luigi Vigneri, Vassil Dimitrov", "title": "Preventing Denial of Service Attacks in IoT Networks through Verifiable\n  Delay Functions", "comments": null, "journal-ref": "GLOBECOM 2020 - 2020 IEEE Global Communications Conference, 1-6", "doi": "10.1109/GLOBECOM42002.2020.9322260", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permissionless distributed ledgers provide a promising approach to deal with\nthe Internet of Things (IoT) paradigm. Since IoT devices mostly generate data\ntransactions and micropayments, distributed ledgers that use fees to regulate\nthe network access are not an optimal choice. In this paper, we study a feeless\narchitecture developed by IOTA and designed specifically for the IoT. Due to\nthe lack of fees, malicious nodes can exploit this feature to generate an\nunbounded number of transactions and perform a denial of service attacks. We\npropose to mitigate these attacks through verifiable delay functions. These\nfunctions, which are non-parallelizable, hard to compute, and easy to verify,\nhave been formulated only recently. In our work, we design a denial of service\nprevention mechanism which addresses network heterogeneity, limited node\ncomputational capabilities, and hardware-specific implementation optimizations.\nVerifiable delay functions have mostly been studied from a theoretical point of\nview, but little has been done in tangible applications. Hence, this paper can\nbe considered as a pioneer work in the field, since it builds a bridge between\nthis theoretical mathematical framework and a real-world problem.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 23:18:45 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Attias", "Vidal", ""], ["Vigneri", "Luigi", ""], ["Dimitrov", "Vassil", ""]]}, {"id": "2006.02006", "submitter": "Chase Smith", "authors": "Chase Smith, Alex Rusnak", "title": "Proximity-based Networking: Small world overlays optimized with particle\n  swarm optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information dissemination is a fundamental and frequently occurring problem\nin large, dynamic, distributed systems. In order to solve this, there has been\nan increased interest in creating efficient overlay networks that can maintain\ndecentralized peer-to-peer networks. Within these overlay networks nodes take\nthe patterns of small world networks, whose connections are based on proximity.\nThese small-world systems can be incredibly useful in the dissemination and\nlookup of information within an internet network. The data can be efficiently\ntransferred and routing with minimal information loss through forward error\ncorrect (FEC) and the User Datagram Protocol (UDP). We propose a networking\nscheme that incorporates geographic location in chord for the organization of\npeers within each node's partitioned key space. When we combine this with a\nproximity-based neighborhood set {based on the small world structure} we can\nmimic the efficient of solutions designed to solve traditional small-world\nproblems, with the additional benefit of resilience and fault-tolerance.\nFurthermore, the routing and address book can be updated based on the\nneighborhood requirements. The flexibility of our proposed schemes enables a\nvariety of swarm models, and agents. This enables our network to as an\nunderlying networking model that can be applied to file-sharing, streaming, and\nsynchronization of networks.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 01:40:46 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 00:07:12 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Smith", "Chase", ""], ["Rusnak", "Alex", ""]]}, {"id": "2006.02040", "submitter": "Chin-Ya Huang", "authors": "Ting-Cian Bai and Chin-Ya Huang", "title": "SD-FFR: Software Defined Fast Failure Recovery Mechanism in the\n  Automatic Warehouse", "comments": "10 Pages, 15 Figures, 6 Tables, submitted to IEEE Transactions on\n  Network and Service Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rapid development of IoT technology, automatic guided vehicles\n(AGVs) interact with an industrial control system (ICS) through the wireless\nnetwork to support the freight distribution in the automated warehouse.\nHowever, the message exchange among AGVs and the ICS would experience large\npacket loss or long transmission delay, in the presence of wireless network\nlink failure and link congestion. Therefore, the performance of warehouse\nautomation would be degraded. In this paper, we propose the Software Defined\nFast Failure Recovery(SD-FFR) mechanism, aiming to improve network reliability\nand avoid link congestion caused by load unbalance. With SD-FFR, when link\nfailure occurs, the SDN controller actively detects the link failure within\nmilliseconds, and then reroutes the affected traffic flows accordingly. The\nproposed SD-FFR mechanism also takes load balance into consideration in\nselecting routing paths when a new traffic flow joins or link failure occurs in\nthe network. The evaluation results show that network performance can be time\nefficiently improved.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 04:33:03 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Bai", "Ting-Cian", ""], ["Huang", "Chin-Ya", ""]]}, {"id": "2006.02107", "submitter": "Daphne Tuncer", "authors": "Marinos Charalambides, Daphne Tuncer, Ning Wang, and George Pavlou", "title": "KCN: Knowledge Centric Networking", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of multi-domain and multi-requirement digital services requires an\nunderlying network ecosystem able to understand service-specific contexts. In\nthis work, we propose Knowledge Centric Networking (KCN), a paradigm in which\nknowledge is positioned at the center of the networking landscape. KCN enables\napproaches by which in-network knowledge generation and distribution can be\nused to support advanced network control intelligence that is essential to\nhandle complexity and uncertainty in these emerging digital services. In this\npaper, we introduce the principles of KCN and present an architecture for its\nrealization that enables in-network knowledge creation, distribution, storage\nand processing, both within a single domain/player and across potentially\nheterogeneous domains/players.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 08:56:48 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Charalambides", "Marinos", ""], ["Tuncer", "Daphne", ""], ["Wang", "Ning", ""], ["Pavlou", "George", ""]]}, {"id": "2006.02235", "submitter": "Mehmet Karaca", "authors": "Mehmet Karaca", "title": "Joint optimization of TWT mechanism and scheduling for IEEE 802.11ax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IEEE 802.11ax as the newest Wireless Local Area Networks (WLANS) standard\nbrings enormous improvements in network throughput, coverage and energy\nefficiency in densely populated areas. Unlike previous IEEE 802.11 standards\nwhere power saving mechanisms have a limited capability and flexibility,\n802.11ax comes with a different mechanism called Target Wake Time (TWT) where\nstations (STAs) wake up only after each TWT interval and different STAs can\nwake up at different time instance depending on their application requirements.\nAs an example, for a periodic data arrival occurring in IoT applications, STA\ncan wake up by following the data period and go to sleep mode for a much longer\ntime, and STAs with high traffic volume can have shorter TWT interval to wake\nup more frequency. Moreover, as multi-user transmission capability is added to\n802.11ax, multiple STAs can have the same TWT interval and wake up at the same\ntime, and hence there is a great opportunity to have collision-free\ntransmission by scheduling multiple STAs on appreciate TWT intervals to reduce\nenergy consumption and also increase network throughput. In this paper, we\ninvestigate the problem of STAs scheduling and TWT interval assignment together\nto reduce overall energy consumption of the network. We propose an algorithm\nthat dynamically selects STAs to be served and assigns them the most suitable\nTWT interval given their traffic and channel conditions. We analyze our\nalgorithm through Lyapunov optimization framework and show that our algorithm\nis arbitrarily close to the optimal performance at the price of increased queue\nsizes. Simulation results show that our algorithm consumes less power and\nsupport higher traffic compared to a benchmark algorithm that operates randomly\nfor TWT assignment.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 18:59:35 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Karaca", "Mehmet", ""]]}, {"id": "2006.02270", "submitter": "Kerim G\\\"okarslan", "authors": "Kerim G\\\"okarslan", "title": "Menes: Towards a Generic, Fully-Automated Test and Validation Platform\n  for Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major step in developing robust wireless systems is to test and validate\nthe design under a variety of circumstances. As wireless networks become more\ncomplex, it is impractical to perform testing on a real deployment. As a\nresult, the network administrators rely on network simulators or network\nemulators to validate their configurations and design. Unfortunately, network\nsimulation falls short per it requires users to model the network behavior\nanalytically. On the other hand, network emulation allows users to employ real\nnetwork applications on virtualized network devices. Despite their complex\ndesign, the existing network emulation solutions miss full-scale automation\nrather they rely on experienced users to write complex configuration scripts\nmaking testing. Therefore, the validation process is prone to human operator\nerrors. Furthermore, they require a significant amount of computational\nresources that might not be feasible for many users. Moreover, most network\nemulators focus on lower layers of the network thus requiring users to employ\ntheir own network applications to control and measure network performance. To\novercome these challenges, we propose a novel wireless network emulation\nplatform, the system, that provides users a unified, high-level configuration\ninterface for different layers of wireless networks to reduce management\ncomplexities of network emulators while having a generic, fully-automated\nplatform. Menes is a generic, full-stack, fully-automated test and validation\nplatform that empowers existing state-of-the-art emulation, virtualization, and\nnetwork applications including performance measurement tools. We then provide\nan implementation of Menes based on the EMANE with Docker. Our extensive\nevaluations show that the system requires much less computing resources,\nsignificantly decreases CAPEX and OPEX, and greatly extensible for different\nuse cases.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 13:37:38 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["G\u00f6karslan", "Kerim", ""]]}, {"id": "2006.02317", "submitter": "Milad Ganjalizadeh", "authors": "Milad Ganjalizadeh, Abdulrahman Alabbasi, Joachim Sachs, Marina\n  Petrova", "title": "Translating Cyber-Physical Control Application Requirements to Network\n  level Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical control applications impose strict requirements on the\nreliability and latency of the underlying communication system. Hence, they\nhave been mostly implemented using wired channels where the communication\nservice is highly predictable. Nevertheless, fulfilling such stringent demands\nis envisioned with the fifth generation of mobile networks (5G). The\nrequirements of such applications are often defined on the application layer.\nHowever, cyber-physical control applications can usually tolerate sparse packet\nloss, and therefore it is not at all obvious what configurations and settings\nthese application level requirements impose on the underlying wireless network.\nIn this paper, we apply the fundamental metrics from reliability literature to\nwireless communications and derive a mapping function between application level\nrequirements and network level parameters for those metrics under deterministic\narrivals. Our mapping function enables network designers to realize the\nend-to-end performance (as the target application observes it). It provides\ninsights to the network controller to either enable more reliability\nenhancement features (e.g., repetition), if the metrics are below requirements,\nor to enable features increasing network utilization, otherwise. We evaluate\nour theoretical results by realistic and detailed simulations of a factory\nautomation scenario. Our simulation results confirm the viability of the\ntheoretical framework under various burst error tolerance and load conditions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 15:03:58 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Ganjalizadeh", "Milad", ""], ["Alabbasi", "Abdulrahman", ""], ["Sachs", "Joachim", ""], ["Petrova", "Marina", ""]]}, {"id": "2006.02332", "submitter": "Juan Jos\\'e Garc\\'ia-Castro Crespo", "authors": "Juan-Jos\\'e Crespo (1), Jos\\'e L. S\\'anchez (1), Francisco J.\n  Alfaro-Cort\\'es (1), Jos\\'e Flich (2), Jos\\'e Duato (2) ((1) Universidad de\n  Castilla-La Mancha, Albacete, Spain, (2) Universitat Polit\\`ecnica de\n  Val\\`encia, Valencia, Spain.)", "title": "UPR: Deadlock-Free Dynamic Network Reconfiguration by Exploiting Channel\n  Dependency Graph Compatibility", "comments": null, "journal-ref": null, "doi": "10.1007/s11227-021-03791-8", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deadlock-free dynamic network reconfiguration process is usually studied from\nthe routing algorithm restrictions and resource reservation perspective. The\ndynamic nature yielded by the transition process from one routing function to\nanother is often managed by restricting resource usage in a static predefined\nmanner, which often limits the supported routing algorithms and/or inactive\nlink patterns, or either requires additional resources such as virtual\nchannels. Exploiting compatibility between routing functions by exploring their\nassociated Channel Dependency Graphs (CDG) can take a great benefit from the\ndynamic nature of the reconfiguration process. In this paper, we propose a new\ndynamic reconfiguration process called Upstream Progressive Reconfiguration\n(UPR). Our algorithm progressively performs dependency addition/removal in a\nper channel basis relying on the information provided by the CDG while the\nreconfiguration process takes place. This gives us the opportunity to foresee\ncompatible scenarios where both routing functions coexist, reducing the amount\nof resource drainage as well as packet injection halting.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 15:24:52 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 10:01:43 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Crespo", "Juan-Jos\u00e9", ""], ["S\u00e1nchez", "Jos\u00e9 L.", ""], ["Alfaro-Cort\u00e9s", "Francisco J.", ""], ["Flich", "Jos\u00e9", ""], ["Duato", "Jos\u00e9", ""]]}, {"id": "2006.02678", "submitter": "Yoshiaki Inoue", "authors": "Yoshiaki Inoue, Takahiro Kodama, and Tomotaka Kimura", "title": "Global Optimization of Relay Placement for Seafloor Optical Wireless\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical wireless communication is a promising technology for underwater\nbroadband access networks, which are particularly important for high-resolution\nenvironmental monitoring applications. This paper focuses on a deep sea\nmonitoring system, where an underwater optical wireless network is deployed on\nthe seafloor. We model such an optical wireless network as a general queueing\nnetwork and formulate an optimal relay placement problem, whose objective is to\nmaximize the stability region of the whole system, i.e., the supremum of the\ntraffic volume that the network is capable of accommodating. The formulated\noptimization problem is further shown to be non-convex, so that its global\noptimization is non-trivial. In this paper, we develop a global optimization\nmethod for this problem and we provide an efficient algorithm to compute an\noptimal solution. Through numerical evaluations, we show that a significant\nperformance gain can be obtained by using the derived optimal solution.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 07:50:32 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 04:14:16 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Inoue", "Yoshiaki", ""], ["Kodama", "Takahiro", ""], ["Kimura", "Tomotaka", ""]]}, {"id": "2006.02729", "submitter": "Ray-Guang Cheng", "authors": "Chieh-Chun Chen, Ray-Guang Cheng, Chung-Yin Ho, Matthieu Kanj, Bruno\n  Mongazon-Cazavet, Navid Nikaein", "title": "Prototyping of Open Source NB-IoT Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Narrowband Internet-of-Things (NB-IoT) is one of the major access\ntechnologies proposed to support massive machine type communications (mMTC)\nservices for the 5th generation (5G) mobile networks. Many emerging services\nand networking paradigms are expected to be developed on top of NB-IoT\nnetworks. This paper summarizes the steps required to build up an open source\nnarrowband Internet-of-Things (NB-IoT) network. This work is a joint research\nand development (R&D) result from industry and academic collaboration. The open\nsource NB-IoT enhanced Node B (eNB) is jointly developed by B-COM and NTUST\nbased on the well-known OpenAirInterfaceTM (OAI) open source Long-Term\nEvolution (LTE) eNB developed by EURECOM. The NB-IoT eNB is successfully\nconnected to an evolved packet core (EPC) developed by Nokia Bell Lab. We\ndemonstrate how to use commercial off-the-shelf (COTS) NB-IoT module to forward\nits sensing data to the Internet via the open source NB-IoT network.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 09:39:16 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 14:55:42 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 15:04:36 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2020 22:45:31 GMT"}, {"version": "v5", "created": "Tue, 15 Sep 2020 14:05:47 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Chen", "Chieh-Chun", ""], ["Cheng", "Ray-Guang", ""], ["Ho", "Chung-Yin", ""], ["Kanj", "Matthieu", ""], ["Mongazon-Cazavet", "Bruno", ""], ["Nikaein", "Navid", ""]]}, {"id": "2006.02859", "submitter": "Jacky Cao", "authors": "Jacky Cao, Xiang Su, Benjamin Finley, Pengyuan Zhou, Pan Hui", "title": "Evaluating Transport Protocols on 5G for Mobile Augmented Reality", "comments": "8 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Augmented Reality (MAR) mixes physical environments with\nuser-interactive virtual annotations. Immersive MAR experiences are supported\nby computation-intensive tasks which rely on offloading mechanisms to ease\ndevice workloads. However, this introduces additional network traffic which in\nturn influences the motion-to-photon latency (a determinant of user-perceived\nquality of experience). Therefore, a proper transport protocol is crucial to\nminimise transmission latency and ensure sufficient throughput to support MAR\nperformance. Relatedly, 5G, a potential MAR supporting technology, is widely\nbelieved to be smarter, faster, and more efficient than its predecessors.\nHowever, the suitability and performance of existing transport protocols in MAR\nin the 5G context has not been explored. Therefore, we present an evaluation of\npopular transport protocols, including UDP, TCP, MPEG-TS, RTP, and QUIC, with a\nMAR system on a real-world 5G testbed. We also compare with their 5G\nperformance with LTE and WiFi. Our evaluation results indicate that TCP has the\nlowest round-trip-time on 5G, with a median of $15.09\\pm0.26$ ms, while QUIC\nappears to perform better on LTE. Through an additional test with varying\nsignal quality (specifically, degrading secondary synchronisation signal\nreference signal received quality), we discover that protocol performance\nappears to be significantly impacted by signal quality.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 13:57:50 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Cao", "Jacky", ""], ["Su", "Xiang", ""], ["Finley", "Benjamin", ""], ["Zhou", "Pengyuan", ""], ["Hui", "Pan", ""]]}, {"id": "2006.02896", "submitter": "Mounir Bensalem", "authors": "\\'Italo Brasileiro, Mounir Bensalem, Andr\\'e Drummond, and Admela\n  Jukan", "title": "Jamming-Aware Control Plane in Elastic Optical Networks", "comments": "This paper is uploaded here for research community, thus it is for\n  non-commercial purposes. arXiv admin note: text overlap with arXiv:2002.02708", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical layer security is essential in optical networks. In this paper, we\nstudy a jamming-aware control plane, in which a high power jamming attack\nexists in the network. The studied control plane considers that the jammed\nconnections can be detected and avoided. We used a physical layer model, in\nwhich we embedded the additional jamming power, to evaluate different security\nin scenarios, such as a jamming-free scenario, jamming with an unaware\ncontroller, and jamming with an aware controller. The performance is analyzed\nin terms of the blocking rate and slots utilization. We analyze the impact of\njamming attacks in the least used link and in the most used link on the\nnetwork. The results demonstrates that the jamming avoidance by the control\nplane can reach performance near the not jammed scenario.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 18:41:34 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Brasileiro", "\u00cdtalo", ""], ["Bensalem", "Mounir", ""], ["Drummond", "Andr\u00e9", ""], ["Jukan", "Admela", ""]]}, {"id": "2006.02931", "submitter": "Yi Liu", "authors": "Yi Liu, Xingliang Yuan, Zehui Xiong, Jiawen Kang, Xiaofei Wang, Dusit\n  Niyato", "title": "Federated Learning for 6G Communications: Challenges, Methods, and\n  Future Directions", "comments": null, "journal-ref": null, "doi": "10.23919/JCC.2020.09.009", "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the 5G communication networks are being widely deployed worldwide, both\nindustry and academia have started to move beyond 5G and explore 6G\ncommunications. It is generally believed that 6G will be established on\nubiquitous Artificial Intelligence (AI) to achieve data-driven Machine Learning\n(ML) solutions in heterogeneous and massive-scale networks. However,\ntraditional ML techniques require centralized data collection and processing by\na central server, which is becoming a bottleneck of large-scale implementation\nin daily life due to significantly increasing privacy concerns. Federated\nlearning, as an emerging distributed AI approach with privacy preservation\nnature, is particularly attractive for various wireless applications,\nespecially being treated as one of the vital solutions to achieve ubiquitous AI\nin 6G. In this article, we first introduce the integration of 6G and federated\nlearning and provide potential federated learning applications for 6G. We then\ndescribe key technical challenges, the corresponding federated learning\nmethods, and open problems for future research on federated learning in the\ncontext of 6G communications.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:17:19 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 18:19:57 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Liu", "Yi", ""], ["Yuan", "Xingliang", ""], ["Xiong", "Zehui", ""], ["Kang", "Jiawen", ""], ["Wang", "Xiaofei", ""], ["Niyato", "Dusit", ""]]}, {"id": "2006.03042", "submitter": "Francisco Maturana", "authors": "Francisco Maturana, V. S. Chaitanya Mukka, K. V. Rashmi", "title": "Access-optimal Linear MDS Convertible Codes for All Parameters", "comments": "This is an extended version of an IEEE ISIT 2020 paper with the same\n  title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale distributed storage systems, erasure codes are used to achieve\nfault tolerance in the face of node failures. Tuning code parameters to\nobserved failure rates has been shown to significantly reduce storage cost.\nSuch tuning of redundancy requires \"code conversion\", i.e., a change in code\ndimension and length on already encoded data. Convertible codes are a new class\nof codes designed to perform such conversions efficiently. The access cost of\nconversion is the number of nodes accessed during conversion.\n  Existing literature has characterized the access cost of conversion of linear\nMDS convertible codes only for a specific and small subset of parameters. In\nthis paper, we present lower bounds on the access cost of conversion of linear\nMDS codes for all valid parameters. Furthermore, we show that these lower\nbounds are tight by presenting an explicit construction for access-optimal\nlinear MDS convertible codes for all valid parameters. En route, we show that,\none of the degrees-of-freedom in the design of convertible codes that was\ninconsequential in the previously studied parameter regimes, turns out to be\ncrucial when going beyond these regimes and adds to the challenge in the\nanalysis and code construction.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 17:51:43 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Maturana", "Francisco", ""], ["Mukka", "V. S. Chaitanya", ""], ["Rashmi", "K. V.", ""]]}, {"id": "2006.03178", "submitter": "Daniel Zhang", "authors": "Daniel Zhang, Yue Ma, X. Sharon Hu, Dong Wang", "title": "Towards Privacy-aware Task Allocation in Social Sensing based Edge\n  Computing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advance in mobile computing, Internet of Things, and ubiquitous\nwireless connectivity, social sensing based edge computing (SSEC) has emerged\nas a new computation paradigm where people and their personally owned devices\ncollect sensor measurements from the physical world and process them at the\nedge of the network. This paper focuses on a privacy-aware task allocation\nproblem where the goal is to optimize the computation task allocation in SSEC\nsystems while respecting the users' customized privacy settings. It introduces\na novel Game-theoretic Privacy-aware Task Allocation (G-PATA) framework to\nachieve the goal. G-PATA includes (i) a bottom-up game-theoretic model to\ngenerate the maximum payoffs at end devices while satisfying the end user's\nprivacy settings; (ii) a top-down incentive scheme to adjust the rewards for\nthe tasks to ensure that the task allocation decisions made by end devices meet\nthe Quality of Service (QoS) requirements of the applications. Furthermore, the\nframework incorporates an efficient load balancing and iteration reduction\ncomponent to adapt to the dynamic changes in status and privacy configurations\nof end devices. The G-PATA framework was implemented on a real-world edge\ncomputing platform that consists of heterogeneous end devices (Jetson TX1 and\nTK1 boards, and Raspberry Pi3). We compare G-PATA with state-of-the-art task\nallocation schemes through two real-world social sensing applications. The\nresults show that G-PATA significantly outperforms existing approaches under\nvarious privacy settings (our scheme achieved as much as 47% improvements in\ndelay reduction for the application and 15% more payoffs for end devices\ncompared to the baselines.).\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 00:21:27 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Zhang", "Daniel", ""], ["Ma", "Yue", ""], ["Hu", "X. Sharon", ""], ["Wang", "Dong", ""]]}, {"id": "2006.03205", "submitter": "Kallol Krishna Karmakar", "authors": "Vijay Varadharajan, Kallol Karmakar, Uday Tupakula, Michael Hitchens", "title": "Towards a Trust Aware Network Slice based End to End Services for\n  Virtualised Infrastructures", "comments": "Submitted to ESORICS 2020 (under review). 24 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future communication networks such as 5G are expected to support end-to-end\ndelivery of services for several vertical markets with diverging requirements.\nNetwork slicing is a key construct that is used to provide end to end logical\nvirtual networks running on a common virtualised infrastructure, which are\nmutually isolated. Having different network slices operating over the same 5G\ninfrastructure creates several challenges in security and trust. This paper\naddresses the fundamental issue of trust of a network slice. It presents a\ntrust model and property-based trust attestation mechanisms which can be used\nto evaluate the trust of the virtual network functions that compose the network\nslice. The proposed model helps to determine the trust of the virtual network\nfunctions as well as the properties that should be satisfied by the virtual\nplatforms (both at boot and run time) on which these network functions are\ndeployed for them to be trusted. We present a logic-based language that defines\nsimple rules for the specification of properties and the conditions under which\nthese properties are evaluated to be satisfied for trusted virtualised\nplatforms. The proposed trust model and mechanisms enable the service providers\nto determine the trustworthiness of the network services as well as the users\nto develop trustworthy applications. .\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 02:27:11 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Varadharajan", "Vijay", ""], ["Karmakar", "Kallol", ""], ["Tupakula", "Uday", ""], ["Hitchens", "Michael", ""]]}, {"id": "2006.03379", "submitter": "Nurul Halimatul Asmak Ismail", "authors": "Nurul Halimatul Asmak Ismail, Samer A. B. Awwad, Rosilah Hassan", "title": "6RLR-ABC: 6LoWPAN Routing Protocol With Local Repair Using Bio Inspired\n  Artificial Bee Colony", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": "10.5121/ijcnc.2020.12302", "report-no": null, "categories": "cs.NI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Micro-Electro-Mechanical System (MEMS) has successfully\nenabled the development of IPv6 over Low power Wireless Personal Area Network\n(6LoWPAN). This network is equipped with low-cost, low-power, lightweight and\nvaried functions devices. These devices are capable of amassing, storing,\nprocessing environmental information and conversing with neighbouring sensors.\nThese requisites pose a new and interesting challenge for the development of\nIEEE 802.15.4 together with routing protocol. In this work, 6LoWPAN Routing\nProtocol with Local Repair Using Bio Inspired Artificial Bee Colony (6RLR-ABC)\nhas been introduced. This protocol supports connection establishment between\nnodes in an energy-efficient manner while maintaining high packet delivery\nratio and throughput and minimizing average end-to-end delay. This protocol has\nbeen evaluated based on increasing generated traffic. The performance of the\ndesigned 6RLR-ABC routing protocol has been evaluated compared to 6LoWPAN\nAd-hoc On-Demand Distance Vector (LOAD) routing protocol. LOAD protocol has\nbeen chosen since it is the most relevant existed 6LoWPANrouting protocol. The\nsimulation results show that the introduced 6RLR-ABC protocol achieves lower\npacket average end-to-end delay and lower energy consumption compared to LOAD\nprotocol.Additionally,the packet delivery ratio of the designed protocol is\nmuch higher than LOAD protocol. The proposed 6RLR-ABC achieved about 39% higher\npacket delivery ratio and about 54.8% higher throughput while simultaneously\noffering lower average end-to-end delay and lower average energy consumption\nthan LOAD protocol.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 11:27:44 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Ismail", "Nurul Halimatul Asmak", ""], ["Awwad", "Samer A. B.", ""], ["Hassan", "Rosilah", ""]]}, {"id": "2006.03447", "submitter": "Fatemeh Akbarian", "authors": "Fatemeh Akbarian, Emma Fitzgerald and Maria Kihl", "title": "Synchronization in Digital Twins for Industrial Control Systems", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital twins, which are a new concept in industrial control systems (ICS),\nplay a key role in realizing the vision of a smart factory, and they can have\ndifferent effective use cases. With digital twins, we have virtual replicas of\nphysical systems so that they precisely mirror the internal behavior of the\nphysical systems. Hence, synchronization is necessary to keep the states of\ndigital twins in sync with those of their physical counterparts. Otherwise,\ntheir behavior may be different from each other, and it can lead to wrong\ndecisions about the system that can have catastrophic consequences. In this\npaper, we propose three different architectures for digital twins, and then by\ninvestigating their ability to follow the physical system's behavior, we will\ndetermine the best architecture, whose output has the lowest error compared\nwith the physical system's output.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 13:44:50 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Akbarian", "Fatemeh", ""], ["Fitzgerald", "Emma", ""], ["Kihl", "Maria", ""]]}, {"id": "2006.03554", "submitter": "Federico Terraneo", "authors": "Federico Terraneo, Federico Amedeo Izzo, Alberto Leva, William\n  Fornaciari", "title": "TDMH: a communication stack for real-time wireless mesh networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the TDMH (Time Deterministc Multi-Hop) protocol, a complete stack\nfor real-time wireless mesh networks. TDMH offers to applications a\nconnection-oriented, bounded-latency communication model. Point-to-point data\nstreams can be created and destroyed at any time. Path redundancy can be\noptionally introduced to improve reliability. TDMH exploits state-of-the-art\nlow power clock synchronisation and constructive interference flooding to build\na continuously updated graph of the network topology, onto which a centralized\nscheduler maps data streams using TDMA channel access. We realised TDMH as a\nunitary codebase, that we ran on both the OMNeT++ simulator and WandStem\nwireless nodes. As a result we can state that when built atop the IEEE 802.15.4\nphysical layer, TDMH can scale up to 100 nodes, 10 hops and beyond, despite the\nlimited available bandwidth.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:06:50 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Terraneo", "Federico", ""], ["Izzo", "Federico Amedeo", ""], ["Leva", "Alberto", ""], ["Fornaciari", "William", ""]]}, {"id": "2006.03566", "submitter": "Basheer Al-Duwairi Dr.", "authors": "Basheer Al-Duwairi, Moath Jarrah and Ahmed Shatnawi", "title": "PASSVM: A Highly Accurate Online Fast Flux Detection System", "comments": "Submitted to Journal of Network and Systems Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast Flux service networks (FFSNs) are used by adversaries to achieve a high\nresilient technique for their malicious servers while keeping them hidden from\ndirect access. In this technique, a large number of botnet machines, that are\nknown as flux agents, work as proxies to relay the traffic between end users\nand a malicious mothership server which is controlled by an adversary. Various\nmechanisms have been proposed for detecting FFSNs. Such mechanisms depend on\ncollecting a large amount of DNS traffic traces and require a considerable\namount of time to identify fast flux domains. In this paper, we propose an\nefficient AI-based online fast flux detection system that performs highly\naccurate and extremely fast detection of fast flux domains. The proposed\nsystem, called PASSVM, is based on features that are associated with DNS\nresponse messages of a given domain name. The approach relies on features that\nare stored in two local databases, in addition to features that are extracted\nfrom the response DNS messages itself. The information in the databases are\nobtained from Censys search engine and IP Geolocation service. PASSVM is\nevaluated using three types of artificial neural networks which are: Multilayer\nPerceptron (MLP), Radial Basis Function Network (RBF), and Support Vector\nMachines (SVM). Results show that SVM with RBF kernel outperformed the other\ntwo methods with an accuracy of 99.557% and a detection time of less than 18\nms.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:22:28 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Al-Duwairi", "Basheer", ""], ["Jarrah", "Moath", ""], ["Shatnawi", "Ahmed", ""]]}, {"id": "2006.03594", "submitter": "Seyyedali Hosseinalipour", "authors": "Seyyedali Hosseinalipour and Christopher G. Brinton and Vaneet\n  Aggarwal and Huaiyu Dai and Mung Chiang", "title": "From Federated to Fog Learning: Distributed Machine Learning over\n  Heterogeneous Wireless Networks", "comments": "This paper is accepted for publication in IEEE Communications\n  Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) tasks are becoming ubiquitous in today's network\napplications. Federated learning has emerged recently as a technique for\ntraining ML models at the network edge by leveraging processing capabilities\nacross the nodes that collect the data. There are several challenges with\nemploying conventional federated learning in contemporary networks, due to the\nsignificant heterogeneity in compute and communication capabilities that exist\nacross devices. To address this, we advocate a new learning paradigm called fog\nlearning which will intelligently distribute ML model training across the\ncontinuum of nodes from edge devices to cloud servers. Fog learning enhances\nfederated learning along three major dimensions: network, heterogeneity, and\nproximity. It considers a multi-layer hybrid learning framework consisting of\nheterogeneous devices with various proximities. It accounts for the topology\nstructures of the local networks among the heterogeneous nodes at each network\nlayer, orchestrating them for collaborative/cooperative learning through\ndevice-to-device (D2D) communications. This migrates from star network\ntopologies used for parameter transfers in federated learning to more\ndistributed topologies at scale. We discuss several open research directions to\nrealizing fog learning.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 05:11:18 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 21:16:51 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 14:42:05 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Hosseinalipour", "Seyyedali", ""], ["Brinton", "Christopher G.", ""], ["Aggarwal", "Vaneet", ""], ["Dai", "Huaiyu", ""], ["Chiang", "Mung", ""]]}, {"id": "2006.03675", "submitter": "Marco Spohn", "authors": "Marco Aur\\'elio Spohn", "title": "Publish, subscribe, and federate!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connecting usual things/objects to the Internet allows the monitoring and\ncontrol of such things from anywhere, which is usually referred to as the\nInternet of Things (IoT). Things communicate among themselves or with other\nentities (e.g., a server) so that information can be gathered from things\nwhilst proper actions can be taken upon them. A prominent communication\napproach adopted by many IoT applications is related to the Publish/Subscribe\n(P/S) paradigm. Any communication entity willing to provide some data announces\nits intention to a server (broker), establishing itself as a publisher for such\ndata/topic. Entities that are willing to receive any published data, register\nthemselves to the broker as subscribers. While employing just one broker might\nlead to a bottleneck and a single point of failure, when having multiple\nbrokers one could end up having difficulties with their management. This work\npresents a scalable and efficient proposal for the federation of independent\nbrokers, by allowing subscribers to get all their publications no matter to\nwhich broker publishers and subscribers are associated with.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 20:45:21 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Spohn", "Marco Aur\u00e9lio", ""]]}, {"id": "2006.03695", "submitter": "Ken St. Germain", "authors": "Ken St. Germain, Frank Kragh", "title": "Physical-Layer Authentication Using Channel State Information and\n  Machine Learning", "comments": "Submitted to 14th International Conference on Signal Processing and\n  Communication Systems (ICSPCS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong authentication in an interconnected wireless environment continues to\nbe an important, but sometimes elusive goal. Research in physical-layer\nauthentication using channel features holds promise as a technique to improve\nnetwork security for a variety of devices. We propose the use of machine\nlearning and measured multiple-input multiple-output communications channel\ninformation to make a decision on whether or not to authenticate a particular\ndevice. This work analyzes the use of received channel state information from\nthe wireless environment and demonstrates the employment of a generative\nadversarial neural network (GAN) trained with received channel data to\nauthenticate a transmitting device. We compared a variety of machine learning\ntechniques and found that the local outlier factor (LOF) algorithm reached 100%\naccuracy at lower signal to noise ratios (SNR) than other algorithms. However,\nbefore LOF reached 100%, we also show that the GAN was more accurate at lower\nSNR levels.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 21:26:01 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 16:36:00 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Germain", "Ken St.", ""], ["Kragh", "Frank", ""]]}, {"id": "2006.03720", "submitter": "Anirban Das", "authors": "Anirban Das, Andrew Leaf, Carlos A. Varela, Stacy Patterson", "title": "Skedulix: Hybrid Cloud Scheduling for Cost-Efficient Execution of\n  Serverless Applications", "comments": "10 pages, 5 figures, 2020 IEEE 13th International Conference on Cloud\n  Computing (CLOUD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for scheduling multifunction serverless applications\nover a hybrid public-private cloud. A set of serverless jobs is input as a\nbatch, and the objective is to schedule function executions over the hybrid\nplatform to minimize the cost of public cloud use, while completing all jobs by\na specified deadline. As this scheduling problem is NP-Hard, we propose a\ngreedy algorithm that dynamically determines both the order and placement of\neach function execution using predictive models of function execution time and\nnetwork latencies. We present a prototype implementation of our framework that\nuses AWS Lambda and OpenFaaS, for the public and private cloud, respectively.\nWe evaluate our prototype in live experiments using a mixture of compute and\nI/O heavy serverless applications. Our results show that our framework can\nachieve a speedup in batch processing of up to 1.92 times that of an approach\nthat uses only the private cloud, at 40.5% the cost of an approach that uses\nonly the public cloud.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 22:27:42 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Das", "Anirban", ""], ["Leaf", "Andrew", ""], ["Varela", "Carlos A.", ""], ["Patterson", "Stacy", ""]]}, {"id": "2006.03798", "submitter": "Qinwen Hu", "authors": "Qinwen Hu, Wanqing Tu", "title": "A Vehicle Transmission Scheduling Scheme for Supporting Vehicle Trust\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in advanced sensors, wireless communications and\nintelligent vehicle control technologies have enabled vehicles to detect\ntraffic anomalies on the road and then notify surrounding vehicles to improve\ntraffic safety. However, due to the high-speed movement of vehicles and the\nfrequent topological changes between vehicles, it is difficult for vehicles to\nevaluate the credibility of received messages. Quite a lot of research effort\nhas been carried out to establish various trustworthiness platforms. These\nstudies mostly focus on how to enhance the accuracy of credibility evaluation,\noverlooking that the transmission performance may affect the quality of vehicle\nmessages. In this paper, we aim to support the improvement of credibility\nevaluation in vehicle networks by enhancing the transmission experience of\nvehicles. The proposed solution utilizes the vehicle's trajectory information,\ndetection range and a roadside unit (RSU) coverage to form a controlled number\nof detection zones, which guarantees that events can be detected and reported\nwhile limiting the number of transmission vehicles. Furthermore, our scheme\ntakes account of vehicle credibility and interference ranges when selecting\nreporting vehicles, supporting the timely and reliable delivery of vehicles'\nevent reports when accidents occur. Our ns2 evaluation shows that our scheme\ncan greatly reduce delay and loss rates of vehicle messages to help existing\nstudies on accurate vehicle credibility evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 06:54:24 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Hu", "Qinwen", ""], ["Tu", "Wanqing", ""]]}, {"id": "2006.03977", "submitter": "Daniela Ganelin", "authors": "Daniela Ganelin and Isaac Chuang", "title": "IP Geolocation Underestimates Regressive Economic Patterns in MOOC Usage", "comments": null, "journal-ref": "ICETC 2019: Proceedings of the 2019 11th International Conference\n  on Education Technology and Computers October 2019", "doi": "10.1145/3369255.3369301", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive open online courses (MOOCs) promise to make rigorous higher education\naccessible to everyone, but prior research has shown that registrants tend to\ncome from backgrounds of higher socioeconomic status. We study geographically\ngranular economic patterns in about 76,000 U.S. registrations for about 600\nHarvardX and MITx courses between 2012 and 2018, identifying registrants'\nlocations using both IP geolocation and user-reported mailing addresses. By\neither metric, we find higher registration rates among postal codes with\ngreater prosperity or population density. However, we also find evidence of\nbias in IP geolocation: it makes greater errors, both geographically and\neconomically, for users from more economically distressed areas; it\ndisproportionately places users in prosperous areas; and it underestimates the\nregressive pattern in MOOC registration. Researchers should use IP geolocation\nin MOOC studies with care, and consider the possibility of similar economic\nbiases affecting its other academic, commercial, and legal uses.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 21:13:14 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ganelin", "Daniela", ""], ["Chuang", "Isaac", ""]]}, {"id": "2006.04055", "submitter": "Qiaoni Han", "authors": "Qiaoni Han, Bo Yang, Nan Song, Yuwei Li, and Ping Wei", "title": "Green Resource Allocation and Energy Management in Heterogeneous Small\n  Cell Networks Powered by Hybrid Energy", "comments": "29 pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.comcom.2020.06.002", "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In heterogeneous networks (HetNets), how to improve spectrum efficiency is a\ncrucial issue. Meanwhile increased energy consumption inspires network\noperators to deploy renewable energy sources as assistance to traditional\nelectricity. Based on above aspects, we allow base stations (BSs) to share\ntheir licensed spectrum resource with each other and adjust transmission power\nto adapt to the renewable energy level. Considering the sharing fairness among\nBSs, we formulate a multi-person bargaining problem as a stochastic\noptimization problem. We divide the optimization problem into three parts: data\nrate control, resource allocation and energy management. An online dynamic\ncontrol algorithm is proposed to control admission rate and resource allocation\nto maximize the transmission and sharing profits with the least grid energy\nconsumption. Simulation results investigate the time-varying data control and\nenergy management of BSs and demonstrate the effectiveness of the proposed\nscheme.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 06:14:54 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 11:02:20 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Han", "Qiaoni", ""], ["Yang", "Bo", ""], ["Song", "Nan", ""], ["Li", "Yuwei", ""], ["Wei", "Ping", ""]]}, {"id": "2006.04416", "submitter": "Annika Dochhan", "authors": "Annika Dochhan, Johannes K. Fischer, Bodo Lent, Achim Autenrieth,\n  Behnam Shariati, Pablo Wilke Berenguer, J\\\"org-Peter Elbers", "title": "Metro-haul Project Vertical Service Demo: Video Surveillance Real-time\n  Low-latency Object Tracking", "comments": "This work has received funding from the European Union's Horizon 2020\n  research and innovation programme under grant agreement No. 761727\n  (METRO-HAUL)", "journal-ref": "Optical Fiber Conference (OFC) 2020", "doi": "10.1364/OFC.2020.M2D.4", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the EU H2020 project METRO-HAUL use-case demonstration,\nincluding flexible allocation of storage and computing resources in different\nnetwork locations and deployment of a network slice instance through a\nprogrammable multi-layer optical network.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 08:45:25 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Dochhan", "Annika", ""], ["Fischer", "Johannes K.", ""], ["Lent", "Bodo", ""], ["Autenrieth", "Achim", ""], ["Shariati", "Behnam", ""], ["Berenguer", "Pablo Wilke", ""], ["Elbers", "J\u00f6rg-Peter", ""]]}, {"id": "2006.04595", "submitter": "Abdallah Moubayed", "authors": "Abdallah Moubayed and Abdallah Shami", "title": "Softwarization, Virtualization, & Machine Learning For Intelligent &\n  Effective V2X Communications", "comments": "14 pages, 6 figures, 3 tables, Accepted in IEEE Intelligent\n  Transportation Systems Magazine", "journal-ref": null, "doi": "10.1109/MITS.2020.3014124", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of the fifth generation (5G) mobile network system has emerged in\nrecent years as telecommunication operators and service providers look to\nupgrade their infrastructure and delivery modes to meet the growing demand.\nConcepts such as softwarization, virtualization, and machine learning will be\nkey components as innovative and flexible enablers of such networks. In\nparticular, paradigms such as software-defined networks, software-defined\nperimeter, cloud & edge computing, and network function virtualization will\nplay a major role in addressing several 5G networks' challenges, especially in\nterms of flexibility, programmability, scalability, and security. In this work,\nthe role and potential of these paradigms in the context of V2X communication\nis discussed. To do so, the paper starts off by providing an overview and\nbackground of V2X communications. Then, the paper discusses in more details the\nvarious challenges facing V2X communications and some of the previous\nliterature work done to tackle them. Furthermore, the paper describes how\nsoftwarization, virtualization, and machine learning can be adapted to tackle\nthe challenges of such networks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:43:43 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Moubayed", "Abdallah", ""], ["Shami", "Abdallah", ""]]}, {"id": "2006.04870", "submitter": "Hedongliang Liu", "authors": "Hedongliang Liu, Hengjia Wei, Sven Puchinger, Antonia Wachter-Zeh,\n  Moshe Schwartz", "title": "On the Gap between Scalar and Vector Solutions of Generalized\n  Combination Networks", "comments": "extended version of arXiv:2001.04150v2; 13 pages, 5 figures, 1 table,\n  accepted for publication in IEEE Transactions on Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2021.3065364", "report-no": null, "categories": "cs.IT cs.NI cs.SI math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study scalar-linear and vector-linear solutions of the generalized\ncombination network. We derive new upper and lower bounds on the maximum number\nof nodes in the middle layer, depending on the network parameters and the\nalphabet size. These bounds improve and extend the parameter range of known\nbounds. Using these new bounds we present a lower bound and an upper bound on\nthe gap in the alphabet size between optimal scalar-linear and optimal\nvector-linear network coding solutions. For a fixed network structure, while\nvarying the number of middle-layer nodes $r$, the asymptotic behavior of the\nupper and lower bounds shows that the gap is in $\\Theta(\\log(r))$.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 18:46:24 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 09:53:55 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 08:25:12 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Liu", "Hedongliang", ""], ["Wei", "Hengjia", ""], ["Puchinger", "Sven", ""], ["Wachter-Zeh", "Antonia", ""], ["Schwartz", "Moshe", ""]]}, {"id": "2006.05010", "submitter": "Qianyu Liu", "authors": "Qianyu Liu, Chiew Foong Kwong, Sun Wei, Sijia Zhou, Lincan Li", "title": "Reinforcement Learning-Based Joint Self-Optimisation Method for the\n  Fuzzy Logic Handover Algorithm in 5G HetNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G heterogeneous networks (HetNets) can provide higher network coverage and\nsystem capacity to the user by deploying massive small base stations (BSs)\nwithin the 4G macro system. However, the large-scale deployment of small BSs\nsignificantly increases the complexity and workload of network maintenance and\noptimisation. The current handover (HO) triggering mechanism A3 event was\ndesigned only for mobility management in the macro system. Directly\nimplementing A3 in 5G-HetNets may degrade the user mobility robustness.\nMotivated by the concept of self-organisation networks (SON), this study\ndeveloped a self-optimised triggering mechanism to enable automated network\nmaintenance and enhance user mobility robustness in 5G-HetNets. The proposed\nmethod integrates the advantages of subtractive clustering and Q-learning\nframeworks into the conventional fuzzy logic-based HO algorithm (FLHA).\nSubtractive clustering is first adopted to generate a membership function (MF)\nfor the FLHA to enable FLHA with the self-configuration feature. Subsequently,\nQ-learning is utilised to learn the optimal HO policy from the environment as\nfuzzy rules that empower the FLHA with a self-optimisation function. The FLHA\nwith SON functionality also overcomes the limitations of the conventional FLHA\nthat must rely heavily on professional experience to design. The simulation\nresults show that the proposed self-optimised FLHA can effectively generate MF\nand fuzzy rules for the FLHA. By comparing with conventional triggering\nmechanisms, the proposed approach can decrease the HO, ping-pong HO, and HO\nfailure ratios by approximately 91%, 49%, and 97.5% while improving network\nthroughput and latency by 8% and 35%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 01:52:57 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 04:31:20 GMT"}, {"version": "v3", "created": "Sat, 27 Feb 2021 07:26:07 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Liu", "Qianyu", ""], ["Kwong", "Chiew Foong", ""], ["Wei", "Sun", ""], ["Zhou", "Sijia", ""], ["Li", "Lincan", ""]]}, {"id": "2006.05019", "submitter": "Ekram Hossain", "authors": "Mohammad Salehi and Ekram Hossain", "title": "Handover Rate and Sojourn Time Analysis in Mobile Drone-Assisted\n  Cellular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve capacity and overcome some of the limitations of cellular wireless\nnetworks, drones with aerial base stations can be deployed to assist the\nterrestrial cellular wireless networks. The mobility of drones allows flexible\nnetwork reconfiguration to adapt to dynamic traffic and channel conditions.\nHowever, this is achieved at the expense of more handovers since even a static\nuser may experience a handover when the drones are mobile. In this letter, we\nprovide an exact analysis of the handover rate and sojourn time (time between\ntwo subsequent handovers) for a network of drone base stations. We also show\nthat among different speed distributions with the same mean, the handover rate\nis minimum when all drone base stations move with same speed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 02:42:58 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Salehi", "Mohammad", ""], ["Hossain", "Ekram", ""]]}, {"id": "2006.05027", "submitter": "Sanket Kalamkar", "authors": "Sanket S. Kalamkar and Fuad M. Abinader Jr. and Fran\\c{c}ois Baccelli\n  and Andrea S. Marcano Fani and and Luis G. Uzeda Garcia", "title": "Stochastic Geometry-Based Modeling and Analysis of Beam Management in 5G", "comments": "This is a work in progress. Your comments are welcome. 9 pages, 6\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam management is central in the operation of dense 5G cellular networks.\nFocusing the energy radiated to mobile terminals (MTs) by increasing the number\nof beams per cell increases signal power and decreases interference, and has\nhence the potential to bring major improvements on area spectral efficiency\n(ASE). This benefit, however, comes with unavoidable overheads that increase\nwith the number of beams and the MT speed. This paper proposes a first\nsystem-level stochastic geometry model encompassing major aspects of the beam\nmanagement problem: frequencies, antennas, and propagation; physical layer,\nwireless links, and coding; network geometry, interference, and resource\nsharing; sensing, signaling, and mobility management. This model leads to a\nsimple analytical expression for the effective ASE that the typical user gets\nin this context. This in turn allows one to find, for a wide variety of 5G\nnetwork scenarios including millimeter wave (mmWave) and sub-6 GHz, the number\nof beams per cell that offers the best global trade-off between these benefits\nand costs. We finally provide numerical results that discuss the effects of\ndifferent systemic trade-offs and performances of mmWave and sub-6 GHz 5G\ndeployments.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 03:10:05 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 15:56:28 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kalamkar", "Sanket S.", ""], ["Abinader", "Fuad M.", "Jr."], ["Baccelli", "Fran\u00e7ois", ""], ["Fani", "Andrea S. Marcano", ""], ["Garcia", "and Luis G. Uzeda", ""]]}, {"id": "2006.05038", "submitter": "Paul Keeler Dr", "authors": "Bartek B{\\l}aszczyszyn, Antoine Brochard, H. Paul Keeler", "title": "Coverage probability in wireless networks with determinantal scheduling", "comments": "8 pages. 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of algorithms for randomly scheduling network\ntransmissions. The idea is to use (discrete) determinantal point processes\n(subsets) to randomly assign medium access to various {\\em repulsive} subsets\nof potential transmitters. This approach can be seen as a natural extension of\n(spatial) Aloha, which schedules transmissions independently. Under a general\npath loss model and Rayleigh fading, we show that, similarly to Aloha, they are\nalso subject to elegant analysis of the coverage probabilities and transmission\nattempts (also known as local delay). This is mainly due to the explicit,\ndeterminantal form of the conditional (Palm) distribution and closed-form\nexpressions for the Laplace functional of determinantal processes.\nInterestingly, the derived performance characteristics of the network are\namenable to various optimizations of the scheduling parameters, which are\ndeterminantal kernels, allowing the use of techniques developed for statistical\nlearning with determinantal processes. Well-established sampling algorithms for\ndeterminantal processes can be used to cope with implementation issues, which\nis is beyond the scope of this paper, but it creates paths for further\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 04:05:50 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["B\u0142aszczyszyn", "Bartek", ""], ["Brochard", "Antoine", ""], ["Keeler", "H. Paul", ""]]}, {"id": "2006.05167", "submitter": "Sara Asgari", "authors": "Sara Asgari and Babak Sadeghiyan", "title": "Towards Generating Benchmark Datasets for Worm Infection Studies", "comments": null, "journal-ref": null, "doi": "10.1109/IST50524.2020.9345845", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Worm origin identification and propagation path reconstruction are among the\nessential problems in digital forensics. Until now, several methods have been\nproposed for this purpose. However, evaluating these methods is a big challenge\nbecause there are no suitable datasets containing both normal background\ntraffic and worm traffic to evaluate these methods. In this paper, we\ninvestigate different methods of generating such datasets and suggest a\ntechnique for this purpose. ReaSE is a tool for the creation of realistic\nsimulation environments. However, it needs some modifications to be suitable\nfor generating the datasets. So we make required modifications to it. Then, we\ngenerate several datasets for Slammer, Code Red I, Code Red II and modified\nversions of these worms in different scenarios using our technique and make\nthem publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 10:21:21 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 12:17:09 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 12:44:30 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 16:56:33 GMT"}, {"version": "v5", "created": "Sun, 21 Feb 2021 20:07:23 GMT"}, {"version": "v6", "created": "Sun, 30 May 2021 17:25:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Asgari", "Sara", ""], ["Sadeghiyan", "Babak", ""]]}, {"id": "2006.05182", "submitter": "Swati Goswami", "authors": "Swati Goswami, Nodir Kodirov, Craig Mustard, Ivan Beschastnikh, Margo\n  Seltzer", "title": "Parking Packet Payload with P4", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Function (NF) deployments suffer from poor link goodput, because\npopular NFs such as firewalls process only packet headers while receiving and\ntransmitting complete packets. As a result, unnecessary packet payloads\nneedlessly consume link bandwidth. We introduce PayloadPark, which improves\ngoodput by temporarily parking packet payloads in the stateful memory of\ndataplane programmable switches. PayloadPark forwards only packet headers to NF\nservers, thereby saving bandwidth between the switch and the NF server.\nPayloadPark is a transparent in-network optimization that complements existing\napproaches for optimizing NF performance on end-hosts.\n  We prototyped PayloadPark on a Barefoot Tofino ASIC using the P4 language.\nOur prototype, when deployed on a top-of-rack switch, can service up to 8 NF\nservers using less than 40% of the on-chip memory resources. The prototype\nimproves goodput by 10- 36% for Firewall and NAT NFs and by 10-26% for a\nFirewall -> NAT NF chain without harming latency. The prototype also reduces\nPCIe bus load by 2-58% on the NF server thanks to the reduced data transmission\nbetween the switch and the NF server. With workloads that have datacenter\nnetwork traffic characteristics, PayloadPark provides a 13% goodput gain with\nthe Firewall -> NAT -> LB NF chain without latency penalty. In the same setup,\nwe can further increase the goodput gain to 28% by using packet recirculation.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 11:02:19 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 09:25:29 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Goswami", "Swati", ""], ["Kodirov", "Nodir", ""], ["Mustard", "Craig", ""], ["Beschastnikh", "Ivan", ""], ["Seltzer", "Margo", ""]]}, {"id": "2006.05266", "submitter": "Yavuz Yaman", "authors": "Yavuz Yaman, Predrag Spasojevic", "title": "Beamwidth Selection for a Uniform Planar Array (UPA) Using RT-ICM mmWave\n  Clusters", "comments": "7 pages, 10 figures. arXiv admin note: substantial text overlap with\n  arXiv:2003.12947", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beamforming is the primary technology to overcome the high path loss in\nmillimeter-wave (mmWave) channels. Hence, performance improvement needs\nknowledge and control of the spatial domain. In particular, antenna structure\nand radiation parameters affect the beamforming performance in mmWave\ncommunications systems. In order to address the impairments such as beam\nmisalignments, outage loss, tracking inability, blockage, etc., an optimum\nvalue of the beamwidth must be determined. In our previous paper, assuming a\ncommunication system that creates a beam per cluster, we theoretically\ninvestigated the beamwidth-received power relation in the cluster level mmWave\nchannels. We used uniform linear array (ULA) antenna in our analysis. In this\npaper, we revisit the analysis and update the expressions for the scenario\nwhere we use rectangular uniform planar array (R-UPA) antenna. Rectangular beam\nmodel is considered to approximate the main lobe pattern of the antenna. For\nthe channel, we derive beamwidth-dependent extracted power expressions for two\nintra-cluster channel models, IEEE 802.11ad and our previous work based on\nray-tracing (RT-ICM). Combining antenna and channel gains, in case of the\nperfect alignment, we confirm that the optimum beamwidth converges zero.\nPerforming asymptotic analysis of the received power, we give the formulation\nand insights that the practical nonzero beamwidth values can be achieved\nalthough sacrificing subtle from the maximum received power. Our analysis shows\nthat to reach 95% of the maximum power for a typical indoor mmWave cluster, a\npractical beamwidth of 3.5 deg is enough. Finally, our analysis results show\nthat there is a 13 dB increase in the maximum theoretical received power when\nUPA is used over ULA. We show that an 8 x 8 UPA can reach 50% of that maximum\nreceived power while the received power is still 10 dB larger than the ULA\nscenario.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 18:48:36 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Yaman", "Yavuz", ""], ["Spasojevic", "Predrag", ""]]}, {"id": "2006.05277", "submitter": "Yevheniya Nosyk", "authors": "Maciej Korczy\\'nski, Yevheniya Nosyk, Qasim Lone, Marcin Skwarek,\n  Baptiste Jonglez and Andrzej Duda", "title": "The Closed Resolver Project: Measuring the Deployment of Source Address\n  Validation of Inbound Traffic", "comments": "arXiv admin note: substantial text overlap with arXiv:2002.00441", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source Address Validation (SAV) is a standard aimed at discarding packets\nwith spoofed source IP addresses. The absence of SAV for outgoing traffic has\nbeen known as a root cause of Distributed Denial-of-Service (DDoS) attacks and\nreceived widespread attention. While less obvious, the absence of inbound\nfiltering enables an attacker to appear as an internal host of a network and\nmay reveal valuable information about the network infrastructure. Inbound IP\nspoofing may amplify other attack vectors such as DNS cache poisoning or the\nrecently discovered NXNSAttack. In this paper, we present the preliminary\nresults of the Closed Resolver Project that aims at mitigating the problem of\ninbound IP spoofing. We perform the first Internet-wide active measurement\nstudy to enumerate networks that filter or do not filter incoming packets by\ntheir source address, for both the IPv4 and IPv6 address spaces. To achieve\nthis, we identify closed and open DNS resolvers that accept spoofed requests\ncoming from the outside of their network. The proposed method provides the most\ncomplete picture of inbound SAV deployment by network providers. Our\nmeasurements cover over 55 % IPv4 and 27 % IPv6 Autonomous Systems (AS) and\nreveal that the great majority of them are fully or partially vulnerable to\ninbound spoofing. By identifying dual-stacked DNS resolvers, we additionally\nshow that inbound filtering is less often deployed for IPv6 than it is for\nIPv4. Overall, we discover 13.9 K IPv6 open resolvers that can be exploited for\namplification DDoS attacks - 13 times more than previous work. Furthermore, we\nenumerate uncover 4.25 M IPv4 and 103 K IPv6 vulnerable closed resolvers that\ncould only be detected thanks to our spoofing technique, and that pose a\nsignificant threat when combined with the NXNSAttack.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 14:07:58 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Korczy\u0144ski", "Maciej", ""], ["Nosyk", "Yevheniya", ""], ["Lone", "Qasim", ""], ["Skwarek", "Marcin", ""], ["Jonglez", "Baptiste", ""], ["Duda", "Andrzej", ""]]}, {"id": "2006.05459", "submitter": "Dongzhu Liu", "authors": "Dongzhu Liu, Osvaldo Simeone", "title": "Privacy For Free: Wireless Federated Learning Via Uncoded Transmission\n  With Adaptive Power Control", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) refers to distributed protocols that avoid direct raw\ndata exchange among the participating devices while training for a common\nlearning task. This way, FL can potentially reduce the information on the local\ndata sets that is leaked via communications. In order to provide formal privacy\nguarantees, however, it is generally necessary to put in place additional\nmasking mechanisms. When FL is implemented in wireless systems via uncoded\ntransmission, the channel noise can directly act as a privacy-inducing\nmechanism. This paper demonstrates that, as long as the privacy constraint\nlevel, measured via differential privacy (DP), is below a threshold that\ndecreases with the signal-to-noise ratio (SNR), uncoded transmission achieves\nprivacy \"for free\", i.e., without affecting the learning performance. More\ngenerally, this work studies adaptive power allocation (PA) for decentralized\ngradient descent in wireless FL with the aim of minimizing the learning\noptimality gap under privacy and power constraints. Both orthogonal multiple\naccess (OMA) and non-orthogonal multiple access (NOMA) transmission with\n\"over-the-air-computing\" are studied, and solutions are obtained in closed form\nfor an offline optimization setting. Furthermore, heuristic online methods are\nproposed that leverage iterative one-step-ahead optimization. The importance of\ndynamic PA and the potential benefits of NOMA versus OMA are demonstrated\nthrough extensive simulations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 18:57:59 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 21:44:10 GMT"}, {"version": "v3", "created": "Sun, 27 Sep 2020 17:11:12 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liu", "Dongzhu", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2006.05545", "submitter": "Martin Reisslein", "authors": "Gamze Ozogul and Akhilesh S. Thyagaturu and Martin Reisslein and Anna\n  Scaglione", "title": "Physical Education and English Language Arts Based K-12 Engineering\n  Outreach in Software Defined Networking (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-12 engineering outreach has typically focused on elementary electrical and\nmechanical engineering or robot experiments integrated in science or math\nclasses. In contrast, we propose a novel outreach program focusing on\ncommunication network principles that enable the ubiquitous web and smart-phone\napplications. We design outreach activities that illustrate the communication\nnetwork principles through activities and team competitions in physical\neducation (PE) as well as story writing and cartooning in English Language Arts\n(ELA) classes. The PE activities cover the principles of store-and-forward\npacket switching, Hypertext Transfer Protocol (HTTP) web page download,\nconnection establishment in cellular wireless networks, as well as packet\nrouting in Software-Defined Networking (SDN). The proposed outreach program has\nbeen formatively evaluated by K-12 teachers. A survey for the evaluation of the\nimpact of the outreach program on the student perceptions, specifically, the\nstudents' interest, self-efficacy, utility, and negative stereotype perceptions\ntowards communication network engineering, is also presented.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 23:09:05 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Ozogul", "Gamze", ""], ["Thyagaturu", "Akhilesh S.", ""], ["Reisslein", "Martin", ""], ["Scaglione", "Anna", ""]]}, {"id": "2006.05619", "submitter": "Cleber Amaral Mr.", "authors": "Cleber Jorge Amaral, Jomi Fred H\\\"ubner and Timotheus Kampik", "title": "Towards Jacamo-rest: A Resource-Oriented Abstraction for Managing\n  Multi-Agent Systems", "comments": "11 pages, 5 figures, Accepted to present on 14th Workshop-School on\n  Agents, Environments, and Applications (WESAAC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Multi-Agent Oriented Programming (MAOP) paradigm provides abstractions to\nmodel and implements entities of agents, as well as of their organisations and\nenvironments. In recent years, researchers have started to explore the\nintegration of MAOP and the resource-oriented web architecture (REST). This\npaper further advances this line of research by presenting an ongoing work on\njacamo-rest, a resource-oriented web-based abstraction for the multi-agent\nprogramming platform JaCaMo. Jacamo-rest takes Multi-Agent System (MAS)\ninteroperability to a new level, enabling MAS to not only interact with\nservices or applications of the World Wide Web but also to be managed and\nupdated in their specifications by other applications. To add a developer\ninterface to JaCaMo that is suitable for the Web, we provide a novel conceptual\nperspective on the management of MAOP specification entities as web resources.\nWe tested jacamo-rest using it as a middleware of a programming interface\napplication that provides modern software engineering facilities such as\ncontinuous deployments and iterative software development for MAS.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 02:26:32 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Amaral", "Cleber Jorge", ""], ["H\u00fcbner", "Jomi Fred", ""], ["Kampik", "Timotheus", ""]]}, {"id": "2006.05812", "submitter": "Praneeth Vepakomma", "authors": "Ramesh Raskar, Greg Nadeau, John Werner, Rachel Barbar, Ashley Mehra,\n  Gabriel Harp, Markus Leopoldseder, Bryan Wilson, Derrick Flakoll, Praneeth\n  Vepakomma, Deepti Pahwa, Robson Beaudry, Emelin Flores, Maciej Popielarz,\n  Akanksha Bhatia, Andrea Nuzzo, Matt Gee, Jay Summet, Rajeev Surati, Bikram\n  Khastgir, Francesco Maria Benedetti, Kristen Vilcans, Sienna Leis, Khahlil\n  Louisy", "title": "COVID-19 Contact-Tracing Mobile Apps: Evaluation and Assessment for\n  Decision Makers", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of groups, from governments to non-profits, have quickly acted to\ninnovate the contact-tracing process: they are designing, building, and\nlaunching contact-tracing apps in response to the COVID-19 crisis. A diverse\nrange of approaches exist, creating challenging choices for officials looking\nto implement contact-tracing technology in their community and raising concerns\nabout these choices among citizens asked to participate in contact tracing. We\nare frequently asked how to evaluate and differentiate between the options for\ncontact-tracing applications. Here, we share the questions we ask about app\nfeatures and plans when reviewing the many contact-tracing apps appearing on\nthe global stage.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 02:08:02 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Raskar", "Ramesh", ""], ["Nadeau", "Greg", ""], ["Werner", "John", ""], ["Barbar", "Rachel", ""], ["Mehra", "Ashley", ""], ["Harp", "Gabriel", ""], ["Leopoldseder", "Markus", ""], ["Wilson", "Bryan", ""], ["Flakoll", "Derrick", ""], ["Vepakomma", "Praneeth", ""], ["Pahwa", "Deepti", ""], ["Beaudry", "Robson", ""], ["Flores", "Emelin", ""], ["Popielarz", "Maciej", ""], ["Bhatia", "Akanksha", ""], ["Nuzzo", "Andrea", ""], ["Gee", "Matt", ""], ["Summet", "Jay", ""], ["Surati", "Rajeev", ""], ["Khastgir", "Bikram", ""], ["Benedetti", "Francesco Maria", ""], ["Vilcans", "Kristen", ""], ["Leis", "Sienna", ""], ["Louisy", "Khahlil", ""]]}, {"id": "2006.05961", "submitter": "Vaneet Aggarwal", "authors": "Qinbo Bai and Vaneet Aggarwal and Ather Gattami", "title": "Model-Free Algorithm and Regret Analysis for MDPs with Long-Term\n  Constraints", "comments": "The result has error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the optimization of dynamical systems, the variables typically have\nconstraints. Such problems can be modeled as a constrained Markov Decision\nProcess (CMDP). This paper considers a model-free approach to the problem,\nwhere the transition probabilities are not known. In the presence of long-term\n(or average) constraints, the agent has to choose a policy that maximizes the\nlong-term average reward as well as satisfy the average constraints in each\nepisode. The key challenge with the long-term constraints is that the optimal\npolicy is not deterministic in general, and thus standard Q-learning approaches\ncannot be directly used. This paper uses concepts from constrained optimization\nand Q-learning to propose an algorithm for CMDP with long-term constraints. For\nany $\\gamma\\in(0,\\frac{1}{2})$, the proposed algorithm is shown to achieve\n$O(T^{1/2+\\gamma})$ regret bound for the obtained reward and\n$O(T^{1-\\gamma/2})$ regret bound for the constraint violation, where $T$ is the\ntotal number of steps. We note that these are the first results on regret\nanalysis for MDP with long-term constraints, where the transition probabilities\nare not known apriori.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 17:19:29 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 21:06:30 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bai", "Qinbo", ""], ["Aggarwal", "Vaneet", ""], ["Gattami", "Ather", ""]]}, {"id": "2006.06062", "submitter": "Piotr Jurkiewicz", "authors": "Piotr Jurkiewicz, Edyta Biernacka, Jerzy Dom\\.za{\\l}, Robert W\\'ojcik", "title": "Empirical Time Complexity of Generic Dijkstra Algorithm", "comments": "IFIP/IEEE International Symposium on Integrated Network Management\n  (IM 2021)", "journal-ref": "2021 IFIP/IEEE International Symposium on Integrated Network\n  Management (IM)", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic Dijkstra is a novel algorithm for finding the optimal shortest path\nin both wavelength-division multiplexed networks (WDM) and elastic optical\nnetworks (EON), claimed to outperform known algorithms considerably. Because of\nits novelty, it has not been independently implemented and verified. Its time\ncomplexity also remains unknown. In this paper, we perform run-time analysis\nand show that Generic Dijkstra running time grows quadratically with the number\nof graph vertices and logarithmically with the number of edge units. We also\ndiscover that the running time of the Generic Dijkstra algorithm in the\nfunction of network utilization is not monotonic, as peak running time is at\napproximately 0.25 network utilization. Additionally, we provide an independent\nopen source implementation of Generic Dijkstra in the Python language. We\nconfirm the correctness of the algorithm and its superior performance. In\ncomparison to the Filtered Graphs algorithm, Generic Dijkstra is approximately\n2.3 times faster in networks with 25 to 500 nodes, and in 90% of calls its\ncomputation takes less time.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 20:53:54 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 11:57:38 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 12:46:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Jurkiewicz", "Piotr", ""], ["Biernacka", "Edyta", ""], ["Dom\u017ca\u0142", "Jerzy", ""], ["W\u00f3jcik", "Robert", ""]]}, {"id": "2006.06131", "submitter": "Zhiyi Zhang", "authors": "Zhiyi Zhang, Yu Guan, Xinyu Ma, Tianyuan Yu, Lixia Zhang", "title": "Sovereign: User-Controlled Smart Homes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart homes made up of Internet of Things (IoT) devices have seen wide\ndeployment in recent years, with most, if not all, of them controlled by remote\nservers in the cloud. Such designs raise security and privacy concerns for end\nusers. We believe that the current situation has largely resulted from lacking\na systematic home IoT framework to support localized end user control.\n  To let end users take back the control of smart homes, we propose Sovereign,\nan IoT system framework that allows users to securely control home IoT systems\nwithout depending on a cloud backend. Unlike existing solutions, Sovereign\nnetworks home IoT devices and applications using named data with\napplication-level semantics; the names are then used to construct security\nmechanisms. Users define security policies and these policies are then executed\nby the localized security modules. We implement Sovereign as a pub/sub based\ndevelopment platform together with a prototype local IoT controller. Our\npreliminary evaluation shows that Sovereign provides an easy-to-use systematic\nsolution to secure smart homes under user control without imposing noticeable\noverhead.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 00:44:09 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 18:38:55 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhang", "Zhiyi", ""], ["Guan", "Yu", ""], ["Ma", "Xinyu", ""], ["Yu", "Tianyuan", ""], ["Zhang", "Lixia", ""]]}, {"id": "2006.06513", "submitter": "Klaus-Tycho Foerster", "authors": "Klaus-Tycho Foerster, Juho Hirvonen, Yvonne-Anne Pignolet, Stefan\n  Schmid, Gilles Tredan", "title": "On the Feasibility of Perfect Resilience with Local Fast Failover", "comments": "To appear in the proceedings of the 2nd Symposium on Algorithmic\n  Principles of Computer Systems (APOCS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to provide a high resilience and to react quickly to link failures,\nmodern computer networks support fully decentralized flow rerouting, also known\nas local fast failover. In a nutshell, the task of a local fast failover\nalgorithm is to pre-define fast failover rules for each node using locally\navailable information only. These rules determine for each incoming link from\nwhich a packet may arrive and the set of local link failures (i.e., the failed\nlinks incident to a node), on which outgoing link a packet should be forwarded.\nIdeally, such a local fast failover algorithm provides a perfect resilience\ndeterministically: a packet emitted from any source can reach any target, as\nlong as the underlying network remains connected. Feigenbaum et al. (ACM PODC\n2012) and also Chiesa et al. (IEEE/ACM Trans. Netw. 2017) showed that it is not\nalways possible to provide perfect resilience. Interestingly, not much more is\nknown currently about the feasibility of perfect resilience.\n  This paper revisits perfect resilience with local fast failover, both in a\nmodel where the source can and cannot be used for forwarding decisions. We\nfirst derive several fairly general impossibility results: By establishing a\nconnection between graph minors and resilience, we prove that it is impossible\nto achieve perfect resilience on any non-planar graph; furthermore, while\nplanarity is necessary, it is also not sufficient for perfect resilience. On\nthe positive side, we show that graph families closed under link subdivision\nallow for simple and efficient failover algorithms which simply skip failed\nlinks. We demonstrate this technique by deriving perfect resilience for\nouterplanar graphs and related scenarios, as well as for scenarios where the\nsource and target are topologically close after failures.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 15:30:08 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 17:55:15 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Foerster", "Klaus-Tycho", ""], ["Hirvonen", "Juho", ""], ["Pignolet", "Yvonne-Anne", ""], ["Schmid", "Stefan", ""], ["Tredan", "Gilles", ""]]}, {"id": "2006.06526", "submitter": "Zoraze Ali", "authors": "Zoraze Ali, Marco Miozzo, Lorenza Giupponi, Paolo Dini, Stojan Denic,\n  Stavroula Vassaki", "title": "Recurrent Neural Networks for Handover Management in Next-Generation\n  Self-Organized Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss a handover management scheme for Next Generation\nSelf-Organized Networks. We propose to extract experience from full protocol\nstack data, to make smart handover decisions in a multi-cell scenario, where\nusers move and are challenged by deep zones of an outage. Traditional handover\nschemes have the drawback of taking into account only the signal strength from\nthe serving, and the target cell, before the handover. However, we believe that\nthe expected Quality of Experience (QoE) resulting from the decision of target\ncell to handover to, should be the driving principle of the handover decision.\nIn particular, we propose two models based on multi-layer many-to-one LSTM\narchitecture, and a multi-layer LSTM AutoEncoder (AE) in conjunction with a\nMultiLayer Perceptron (MLP) neural network. We show that using experience\nextracted from data, we can improve the number of users finalizing the download\nby 18%, and we can reduce the time to download, with respect to a standard\nevent-based handover benchmark scheme. Moreover, for the sake of\ngeneralization, we test the LSTM Autoencoder in a different scenario, where it\nmaintains its performance improvements with a slight degradation, compared to\nthe original scenario.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 15:41:12 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ali", "Zoraze", ""], ["Miozzo", "Marco", ""], ["Giupponi", "Lorenza", ""], ["Dini", "Paolo", ""], ["Denic", "Stojan", ""], ["Vassaki", "Stavroula", ""]]}, {"id": "2006.06576", "submitter": "Tyler McDaniel", "authors": "Tyler McDaniel, Jared M. Smith, Max Schuchard", "title": "Flexsealing BGP Against Route Leaks: Peerlock Active Measurement and\n  Analysis", "comments": "NDSS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BGP route leaks frequently precipitate serious disruptions to interdomain\nrouting. These incidents have plagued the Internet for decades while deployment\nand usability issues cripple efforts to mitigate the problem. Peerlock,\nintroduced in 2016, addresses route leaks with a new approach. Peerlock enables\nfiltering agreements between transit providers to protect their own networks\nwithout the need for broad cooperation or a trust infrastructure. We outline\nthe Peerlock system and one variant, Peerlock-lite, and conduct live Internet\nexperiments to measure their deployment on the control plane. Our measurements\nfind evidence for significant Peerlock protection between Tier 1 networks in\nthe peering clique, where 48% of potential Peerlock filters are deployed, and\nreveal that many other networks also deploy filters against Tier 1 leaks. To\nguide further deployment, we also quantify Peerlock's impact on route leaks\nboth at currently observed levels and under hypothetical future deployment\nscenarios via BGP simulation. These experiments reveal present Peerlock\ndeployment restricts Tier 1 leak export to 10% or fewer networks for 40% of\nsimulated leaks. Strategic additional Peerlock-lite deployment at all large\nISPs (fewer than 1% of all networks), in tandem with Peerlock within the\npeering clique as deployed, completely mitigates 80% of simulated Tier 1 route\nleaks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 16:24:49 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 15:20:12 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 19:42:36 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 13:35:39 GMT"}, {"version": "v5", "created": "Tue, 17 Nov 2020 16:16:34 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["McDaniel", "Tyler", ""], ["Smith", "Jared M.", ""], ["Schuchard", "Max", ""]]}, {"id": "2006.06628", "submitter": "Mehrdad Khani", "authors": "Mehrdad Khani, Pouya Hamadanian, Arash Nasr-Esfahany, Mohammad\n  Alizadeh", "title": "Real-Time Video Inference on Edge Devices via Adaptive Model Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NI eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time video inference on edge devices like mobile phones and drones is\nchallenging due to the high computation cost of Deep Neural Networks. We\npresent Adaptive Model Streaming (AMS), a new approach to improving performance\nof efficient lightweight models for video inference on edge devices. AMS uses a\nremote server to continually train and adapt a small model running on the edge\ndevice, boosting its performance on the live video using online knowledge\ndistillation from a large, state-of-the-art model. We discuss the challenges of\nover-the-network model adaptation for video inference, and present several\ntechniques to reduce communication cost of this approach: avoiding excessive\noverfitting, updating a small fraction of important model parameters, and\nadaptive sampling of training frames at edge devices. On the task of video\nsemantic segmentation, our experimental results show 0.4--17.8 percent mean\nIntersection-over-Union improvement compared to a pre-trained model across\nseveral video datasets. Our prototype can perform video segmentation at 30\nframes-per-second with 40 milliseconds camera-to-label latency on a Samsung\nGalaxy S10+ mobile phone, using less than 300 Kbps uplink and downlink\nbandwidth on the device.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:25:44 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 23:29:53 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Khani", "Mehrdad", ""], ["Hamadanian", "Pouya", ""], ["Nasr-Esfahany", "Arash", ""], ["Alizadeh", "Mohammad", ""]]}, {"id": "2006.06822", "submitter": "Douglas Leith", "authors": "Douglas J. Leith and Stephen Farrell", "title": "Coronavirus Contact Tracing: Evaluating The Potential Of Using Bluetooth\n  Received Signal Strength For Proximity Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on measurements of Bluetooth Low Energy (LE) received signal\nstrength taken on mobile handsets in a variety of common, real-world settings.\nWe note that a key difficulty is obtaining the ground truth as to when people\nare in close proximity to one another. Knowledge of this ground truth is\nimportant for accurately evaluating the accuracy with which contact events are\ndetected by Bluetooth LE. We approach this by adopting a scenario-based\napproach. In summary, we find that the Bluetooth LE received signal strength\ncan vary substantially depending on the relative orientation of handsets, on\nabsorption by the human body, reflection/absorption of radio signals in\nbuildings and trains. Indeed we observe that the received signal strength need\nnot decrease with increasing distance. This suggests that the development of\naccurate methods for proximity detection based on Bluetooth LE received signal\nstrength is likely to be challenging. Our measurements also suggest that\ncombining use of Bluetooth LE contact tracing apps with adoption of new social\nprotocols may yield benefits but this requires further investigation. For\nexample, placing phones on the table during meetings is likely to simplify\nproximity detection using received signal strength. Similarly, carrying\nhandbags with phones placed close to the outside surface. In locations where\nthe complexity of signal propagation makes proximity detection using received\nsignal strength problematic entry/exit from the location might instead be\nlogged in an app by e.g. scanning a time-varying QR code or the like.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:51:23 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Leith", "Douglas J.", ""], ["Farrell", "Stephen", ""]]}, {"id": "2006.07349", "submitter": "Guto Leoni Santos Mr", "authors": "Guto Leoni Santos, Patricia Takako Endo", "title": "Using Reinforcement Learning to Allocate and Manage Service Function\n  Chains in Cellular Networks", "comments": "9 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is expected that the next generation cellular networks provide a connected\nsociety with fully mobility to empower the socio-economic transformation.\nSeveral other technologies will benefits of this evolution, such as Internet of\nThings, smart cities, smart agriculture, vehicular networks, healthcare\napplications, and so on. Each of these scenarios presents specific requirements\nand demands different network configurations. To deal with this heterogeneity,\nvirtualization technology is key technology. Indeed, the network function\nvirtualization (NFV) paradigm provides flexibility for the network manager,\nallocating resources according to the demand, and reduces acquisition and\noperational costs. In addition, it is possible to specify an ordered set of\nnetwork virtual functions (VNFs) for a given service, which is called as\nservice function chain (SFC). However, besides the advantages from service\nvirtualization, it is expected that network performance and availability do not\nbe affected by its usage. In this paper, we propose the use of reinforcement\nlearning to deploy a SFC of cellular network service and manage the VNFs\noperation. We consider that the SFC is deployed by the reinforcement learning\nagent considering a scenarios with distributed data centers, where the VNFs are\ndeployed in virtual machines in commodity servers. The NFV management is\nrelated to create, delete, and restart the VNFs. The main purpose is to reduce\nthe number of lost packets taking into account the energy consumption of the\nservers. We use the Proximal Policy Optimization (PPO) algorithm to implement\nthe agent and preliminary results show that the agent is able to allocate the\nSFC and manage the VNFs, reducing the number of lost packets.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 17:38:23 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 23:44:16 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 00:12:50 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Santos", "Guto Leoni", ""], ["Endo", "Patricia Takako", ""]]}, {"id": "2006.07419", "submitter": "Amer AlGhadhban Dr.", "authors": "Amer AlGhadhban", "title": "F4Tele: FSO for Data Center Network Management and Packet Telemetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of bandwidth-hungry applications and services forces\ndatacenter (DC) administrators to optimize the utilization of available\nresources. Precisely, the network share of management traffic has grown\nsignificantly because DC networks are becoming more sophisticated and require a\nmassive amount of data for efficient debugging and troubleshooting.\nAccordingly, we use free space optics communication (FSO) with wavelength\ndivision multiplexing (WDM) technology to build a flexible yet high-performance\nlogical network responsible for management traffic. The FSO-WDM can provide\nreconfigurable multi-terabit topology over line-of-sight (LoS) links. Due to\nspace and processing capacity reasons, we can not offer direct connections from\nevery data rack to the network management racks. Alternatively, the data racks\nare grouped together as each group is serviced for a duration of time matches\nits average arrival-rate. Since the data racks showed different arrival-rates,\nthe hotspot racks are allocated with longer service time. The evaluation\nresults show that F4Tele carried out high throughput close to the expensive\nsolution (benchmark).\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 18:48:50 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["AlGhadhban", "Amer", ""]]}, {"id": "2006.07453", "submitter": "Sameh Sorour", "authors": "Sameh Sorour, Umair Mohammad, Amr Abutuleb, Hossam Hassanein", "title": "Returning the Favor: What Wireless Networking Can Offer to AI and Edge\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) and artificial intelligence (AI) have recently made a\nsignificant impact on improving the operations of wireless networks and\nestablishing intelligence at the edge. In return, rare efforts were made to\nexplore how adapting, optimizing, and arranging wireless networks can\ncontribute to implementing ML/AI at the edge. This article aims to address this\nvoid by setting a vision on how wireless networking researchers can leverage\ntheir expertise to return the favor to edge learning. It will review the\nenabling technologies, summarize the inaugural works on this path, and shed\nlight on different directions to establish a comprehensive framework for mobile\nedge learning (MEL).\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 20:25:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Sorour", "Sameh", ""], ["Mohammad", "Umair", ""], ["Abutuleb", "Amr", ""], ["Hassanein", "Hossam", ""]]}, {"id": "2006.07505", "submitter": "Huan Wang", "authors": "Huan Wang, Guoming Tang, Kui Wu, Jianping Wang", "title": "PLVER: Joint Stable Allocation and Content Replication for Edge-assisted\n  Live Video Delivery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The live streaming services have gained extreme popularity in recent years.\nDue to the spiky traffic patterns of live videos, utilizing the distributed\nedge servers to improve viewers' quality of experience (QoE) has become a\ncommon practice nowadays. Nevertheless, current client-driven content caching\nmechanism does not support caching beforehand from the cloud to the edge,\nresulting in considerable cache missing in live video delivery.\nState-of-the-art research generally sacrifices the liveness of delivered videos\nin order to deal with the above problem. In this paper, by jointly considering\nthe features of live videos and edge servers, we propose PLVER, a proactive\nlive video push scheme to resolve the cache miss problem in live video\ndelivery. Specifically, PLVER first conducts a one-tomultiple stable allocation\nbetween edge clusters and user groups, to balance the load of live traffic over\nthe edge servers. Then it adopts proactive video replication algorithms to\nspeed up the video replication among the edge servers. We conduct extensive\ntrace-driven evaluations, covering 0.3 million Twitch viewers and more than 300\nTwitch channels. The results demonstrate that with PLVER, edge servers can\ncarry 28% and 82% more traffic than the auction-based replication method and\nthe caching on requested time method, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 23:04:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Wang", "Huan", ""], ["Tang", "Guoming", ""], ["Wu", "Kui", ""], ["Wang", "Jianping", ""]]}, {"id": "2006.07559", "submitter": "J. Andrew Zhang", "authors": "J. Andrew Zhang, Md Lushanur Rahman, Kai Wu, Xiaojing Huang, Y. Jay\n  Guo, Shanzhi Chen, and Jinhong Yuan", "title": "Enabling Joint Communication and Radar Sensing in Mobile Networks -- A\n  Survey", "comments": "32 pages, 12 figures, 11 tables, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile network is evolving from a communication-only network towards the one\nwith joint communication and radio/radar sensing (JCAS) capabilities, that we\ncall perceptive mobile network (PMN). Radio sensing here refers to information\nretrieval from received mobile signals for objects of interest in the\nenvironment surrounding the radio transceivers. In this paper, we provide a\ncomprehensive survey for systems and technologies that enable JCAS in PMN, with\na focus on works in the last ten years. Starting with reviewing the work on\ncoexisting communication and radar systems, we highlight their limits on\naddressing the interference problem, and then introduce the JCAS technology. We\nthen set up JCAS in the mobile network context, and envisage its potential\napplications. We continue to provide a brief review for three types of JCAS\nsystems, with particular attention to their differences on the design\nphilosophy. We then introduce a framework of PMN, including the system platform\nand infrastructure, three types of sensing operations, and signals usable for\nsensing, and discuss required system modifications to enable sensing on current\ncommunication-only infrastructure. Within the context of PMN, we review\nstimulating research problems and potential solutions, organized under eight\ntopics: mutual information, waveform optimization, antenna array design,\nclutter suppression, sensing parameter estimation, pattern analysis, networked\nsensing under cellular topology, and sensing-assisted secure communication.\nThis paper provides a comprehensive picture for the motivation, methodology,\nchallenges, and research opportunities of realizing PMN. The PMN is expected to\nprovide a ubiquitous radio sensing platform and enable a vast number of novel\nsmart applications.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 04:36:37 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 23:28:31 GMT"}, {"version": "v3", "created": "Sat, 16 Jan 2021 08:52:53 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Zhang", "J. Andrew", ""], ["Rahman", "Md Lushanur", ""], ["Wu", "Kai", ""], ["Huang", "Xiaojing", ""], ["Guo", "Y. Jay", ""], ["Chen", "Shanzhi", ""], ["Yuan", "Jinhong", ""]]}, {"id": "2006.07668", "submitter": "Lei Deng", "authors": "Lei Deng, Fang Liu, Yijin Zhang, Wing Shing Wong", "title": "Delay-Constrained Topology-Transparent Distributed Scheduling for MANETs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transparent topology is common in many mobile ad hoc networks (MANETs) such\nas vehicle ad hoc networks (VANETs), unmanned aerial vehicle (UAV) ad hoc\nnetworks, and wireless sensor networks due to their decentralization and\nmobility nature. There are many existing works on distributed scheduling scheme\ndesign for topology-transparent MANETs. Most of them focus on\ndelay-unconstrained settings. However, with the proliferation of real-time\napplications over wireless communications, it becomes more and more important\nto support delay-constrained traffic in MANETs. In such applications, each\npacket has a given hard deadline: if it is not delivered before its deadline,\nits validity will expire and it will be removed from the system. This feature\nis fundamentally different from the traditional delay-unconstrained one. In\nthis paper, we for the first time investigate distributed scheduling schemes\nfor a topology-transparent MANET to support delay-constrained traffic. We\nanalyze and compare probabilistic ALOHA scheme and deterministic sequence\nschemes, including the conventional time division multiple access (TDMA), the\nGalois field (GF) sequence scheme proposed in \\cite{chlamtac1994making}, and\nthe combination sequence scheme that we propose for a special type of sparse\nnetwork topology.We use both theoretical analysis and empirical simulations to\ncompare all these schemes and summarize the conditions under which different\nindividual schemes perform best.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 15:52:06 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 10:58:50 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 13:36:27 GMT"}, {"version": "v4", "created": "Sun, 8 Nov 2020 08:51:23 GMT"}, {"version": "v5", "created": "Tue, 10 Nov 2020 08:04:22 GMT"}, {"version": "v6", "created": "Fri, 25 Dec 2020 08:14:09 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Deng", "Lei", ""], ["Liu", "Fang", ""], ["Zhang", "Yijin", ""], ["Wong", "Wing Shing", ""]]}, {"id": "2006.07720", "submitter": "Carlos Bendicho PhD", "authors": "Carlos Bendicho", "title": "Techno-Economic Assessment in Communications: Models for Access Network\n  Technologies", "comments": "12 pages, 1 figure, 4 tables", "journal-ref": "Advances in Information and Communication. FICC 2021. Advances in\n  Intelligent Systems and Computing, vol 1363. Springer, Cham", "doi": "10.1007/978-3-030-73100-7_24", "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article shows State of the Art of techno-economic modeling for access\nnetwork technologies, presents the characteristics a universal techno-economic\nmodel should have, and shows a classification and analysis of techno-economic\nmodels in the literature based on such characteristics. As a result of his\nresearch in this direction, the author created and developed a Universal\nTechno-Economic Model and the corresponding methodology for techno-economic\nassessment in multiple domains, currently available for industry stakeholders\nunder specific licence of use.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 20:59:05 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 10:38:31 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Bendicho", "Carlos", ""]]}, {"id": "2006.07735", "submitter": "Olga Galinina", "authors": "Jani Urama, Richard Wiren, Olga Galinina, Juhani Kauppi, Kimmo\n  Hiltunen, Juha Erkkil\\\"a, Fedor Chernogorov, Pentti Etel\\\"aaho, Marjo\n  Heikkil\\\"a, Johan Torsner, Sergey Andreev, and Mikko Valkama", "title": "UAV-Aided Interference Assessment for Private 5G NR Deployments:\n  Challenges and Solutions", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial automation has created a high demand for private 5G networks, the\ndeployment of which calls for an efficient and reliable solution to ensure\nstrict compliance with the regulatory emission limits. While traditional\nmethods for measuring outdoor interference include collecting real-world data\nby walking or driving, the use of unmanned aerial vehicles (UAVs) offers an\nattractive alternative due to their flexible mobility and adaptive altitude. As\nUAVs perform measurements quickly and semiautomatically, they can potentially\nassist in near realtime adjustments of the network configuration and\nfine-tuning its parameters, such as antenna settings and transmit power, as\nwell as help improve indoor connectivity while respecting outdoor emission\nconstraints. This article offers a firsthand tutorial on using aerial 5G\nemission assessment for interference management in nonpublic networks (NPNs) by\nreviewing the key challenges of UAV-mounted radio-scanner measurements.\nParticularly, we (i) outline the challenges of practical assessment of the\noutdoor interference originating from a local indoor 5G network while\ndiscussing regulatory and other related constraints and (ii) address practical\nmethods and tools while summarizing the recent results of our measurement\ncampaign. The reported proof of concept confirms that UAV-based systems\nrepresent a promising tool for capturing outdoor interference from private 5G\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 22:39:01 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Urama", "Jani", ""], ["Wiren", "Richard", ""], ["Galinina", "Olga", ""], ["Kauppi", "Juhani", ""], ["Hiltunen", "Kimmo", ""], ["Erkkil\u00e4", "Juha", ""], ["Chernogorov", "Fedor", ""], ["Etel\u00e4aho", "Pentti", ""], ["Heikkil\u00e4", "Marjo", ""], ["Torsner", "Johan", ""], ["Andreev", "Sergey", ""], ["Valkama", "Mikko", ""]]}, {"id": "2006.07908", "submitter": "Akbar Siami Namin", "authors": "Moitrayee Chatterjee and Prerit Datta and Faranak Abri and Akbar Siami\n  Namin and Keith S. Jones", "title": "Launching Stealth Attacks using Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing offers users scalable platforms and low resource cost. At the\nsame time, the off-site location of the resources of this service model makes\nit more vulnerable to certain types of adversarial actions. Cloud computing has\nnot only gained major user base, but also, it has the features that attackers\ncan leverage to remain anonymous and stealth. With convenient access to data\nand technology, cloud has turned into an attack platform among other\nutilization. This paper reports our study to show that cyber attackers heavily\nabuse the public cloud platforms to setup their attack environments and launch\nstealth attacks. The paper first reviews types of attacks launched through\ncloud environment. It then reports case studies through which the processes of\nlaunching cyber attacks using clouds are demonstrated.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 14:20:13 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chatterjee", "Moitrayee", ""], ["Datta", "Prerit", ""], ["Abri", "Faranak", ""], ["Namin", "Akbar Siami", ""], ["Jones", "Keith S.", ""]]}, {"id": "2006.07914", "submitter": "Akbar Siami Namin", "authors": "Moitrayee Chatterjee and Prerit Datta and Faranak Abri and Akbar Siami\n  Namin and Keith S. Jones", "title": "Cloud as an Attack Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an exploratory study of responses from $75$ security professionals\nand ethical hackers in order to understand how they abuse cloud platforms for\nattack purposes. The participants were recruited at the Black Hat and DEF CON\nconferences. We presented the participants' with various attack scenarios and\nasked them to explain the steps they would have carried out for launching the\nattack in each scenario. Participants' responses were studied to understand\nattackers' mental models, which would improve our understanding of necessary\nsecurity controls and recommendations regarding precautionary actions to\ncircumvent the exploitation of clouds for malicious activities. We observed\nthat in 93.78% of the responses, participants are abusing cloud services to\nestablish their attack environment and launch attacks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 14:32:45 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chatterjee", "Moitrayee", ""], ["Datta", "Prerit", ""], ["Abri", "Faranak", ""], ["Namin", "Akbar Siami", ""], ["Jones", "Keith S.", ""]]}, {"id": "2006.08064", "submitter": "Keval Doshi", "authors": "Keval Doshi, Yasin Yilmaz and Suleyman Uludag", "title": "Timely Detection and Mitigation of Stealthy DDoS Attacks via IoT\n  Networks", "comments": "Submitted to IEEE Transactions on Dependable and Secure Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) networks consist of sensors, actuators, mobile and\nwearable devices that can connect to the Internet. With billions of such\ndevices already in the market which have significant vulnerabilities, there is\na dangerous threat to the Internet services and also some cyber-physical\nsystems that are also connected to the Internet. Specifically, due to their\nexisting vulnerabilities IoT devices are susceptible to being compromised and\nbeing part of a new type of stealthy Distributed Denial of Service (DDoS)\nattack, called Mongolian DDoS, which is characterized by its widely distributed\nnature and small attack size from each source. This study proposes a novel\nanomaly-based Intrusion Detection System (IDS) that is capable of timely\ndetecting and mitigating this emerging type of DDoS attacks. The proposed IDS's\ncapability of detecting and mitigating stealthy DDoS attacks with even very low\nattack size per source is demonstrated through numerical and testbed\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 00:54:49 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Doshi", "Keval", ""], ["Yilmaz", "Yasin", ""], ["Uludag", "Suleyman", ""]]}, {"id": "2006.08134", "submitter": "Jing Liu", "authors": "Jing Liu, Guochu Shou, Qingtian Wang, Yaqiong Liu, Yihong Hu, and\n  Zhigang Guo", "title": "Load-balanced Service Function Chaining in Edge Computing over FiWi\n  Access Networks for Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service function chaining (SFC) is promising to implement flexible and\nscalable virtual network infrastructure for the Internet of Things (IoT). Edge\ncomputing is envisioned to be an effective solution to process huge amount of\nIoT application data. In order to uniformly provide services to IoT\napplications among the distributed edge computing nodes (ECNs), we present a\nunified SFC orchestration framework based on the coordination of SDN and NFV,\nwhich provides a synergic edge cloud platform by exploiting the connectivity of\nFiWi access networks. In addition, we study the VNF deployment problem under\nour synergic framework, and we formulate it as a mixed-integer nonlinear\nprogramming (MINLP) problem jointly considering the load balancing of\nnetworking and computing for chaining VNFs. We also propose two approximation\noptimal deployment algorithms named Greedy-Bisection Multi-Path (GBMP) and KSP\nMultiPath (KSMP) taking advantage of the multi-instance virtual network\nfunctions (VNFs) deployed in ECNs and the multipath capacity in FiWi access\nnetworks. Extensive simulations are conducted in two types of IoT application\nscenarios in the EC over FiWi access networks. The numerical results show that\nour proposed algorithms are superior to single path and ECMP based deployment\nalgorithms in terms of load balancing, service acceptance ratio, and network\nutilization in both two typical scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 05:09:06 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Liu", "Jing", ""], ["Shou", "Guochu", ""], ["Wang", "Qingtian", ""], ["Liu", "Yaqiong", ""], ["Hu", "Yihong", ""], ["Guo", "Zhigang", ""]]}, {"id": "2006.08199", "submitter": "Turgay Pamuklu", "authors": "Turgay Pamuklu, Cem Ersoy", "title": "Reducing the total cost of ownership in radio access networks by using\n  renewable energy resources", "comments": null, "journal-ref": "Wireless Networks 26, 1667-1684 (2020)", "doi": "10.1007/s11276-018-1862-5", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing electricity prices motivates the mobile network operators to find\nnew energy-efficient solutions for radio access networks (RANs). In this study,\nwe focus on a specific type of RAN where the stand-alone solar panels are used\nas alternative energy sources to the electrical grid energy. First, we describe\nthis hybrid energy based radio access network (HEBRAN) and formulate an\noptimization problem which aims to reduce the total cost of ownership of this\nnetwork. Then, we propose a framework that provides a cost-efficient algorithm\nfor choosing the proper size for the solar panels and batteries of a HEBRAN and\ntwo novel switch on/off algorithms which regulate the consumption of grid\nelectricity during the operation of the network. In addition, we create a\nreduced model of the HEBRAN optimization problem to solve it in a mixed integer\nlinear programming (MILP) solver. The results show that our algorithms\noutperform the MILP solution and classical switch on/off methods. Moreover, our\nfindings show that migrating to a HEBRAN system is feasible and has\ncost-benefits for mobile network operators.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 07:58:18 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Pamuklu", "Turgay", ""], ["Ersoy", "Cem", ""]]}, {"id": "2006.08258", "submitter": "Turgay Pamuklu", "authors": "Turgay Pamuklu, Cicek Cavdar, Cem Ersoy", "title": "Renewable Energy Assisted Function Splitting in Cloud Radio Access\n  Networks", "comments": "Mobile Netw Appl (2020)", "journal-ref": "Mobile Networks and Applications V25, Page 2012-2023, 2020", "doi": "10.1007/s11036-020-01544-0", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud-Radio Access Network (C-RAN) is a promising network architecture to\nreduce energy consumption and the increasing number of base station deployment\ncosts in mobile networks. However, the necessity of enormous fronthaul\nbandwidth between a remote radio head and a baseband unit (BBU) calls for novel\nsolutions. One of the solutions introduces the edge-cloud layer in addition to\nthe centralized cloud (CC) to keep resources closer to the radio units (RUs).\nThen, split the BBU functions between the center cloud (CC) and edge clouds\n(ECs) to reduce the fronthaul bandwidth requirement and to relax the stringent\nend-to-end delay requirements. This paper expands this architecture by\ncombining it with renewable energy sources in CC and ECs. We explain this novel\nsystem and formulate a mixed-integer linear programming (MILP) problem, which\naims to reduce the operational expenditure of this system. Due to the NP-Hard\nproperty of this problem, we solve the smaller instances by using a MILP Solver\nand provide the results in this paper. Moreover, we propose a faster online\nheuristic to find solutions for high user densities. The results show that make\nsplitting decisions by considering renewable energy provides more\ncost-effective solutions to mobile network operators (MNOs). Lastly, we provide\nan economic feasibility study for renewable energy sources in a CRAN\narchitecture, which will encourage the MNOs to use these sources in this\narchitecture.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 09:50:09 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Pamuklu", "Turgay", ""], ["Cavdar", "Cicek", ""], ["Ersoy", "Cem", ""]]}, {"id": "2006.08421", "submitter": "Dimitra Tsigkari", "authors": "Dimitra Tsigkari and Thrasyvoulos Spyropoulos", "title": "An approximation algorithm for joint caching and recommendations in\n  cache networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming platforms, like Netflix and YouTube, strive to offer a high quality\nof service (QoS) to their users. Meanwhile, a significant share of content\nconsumption of these platforms is heavily influenced by recommendations. In\nthis setting, user experience is a product of both the quality of the\nrecommendations (QoR) and the quality of service (QoS) of the delivered\ncontent. However, network decisions (like caching) that affect QoS are usually\nmade without taking into account the recommender's actions. Likewise,\nrecommendation decisions are made independently of the potential delivery\nquality of the recommended content. The aim of this paper is to jointly\noptimize caching and recommendations in a generic network of caches, with the\nobjective of maximizing the quality of experience (QoE). This is in line with\nthe recent trend for large content providers to simultaneously act as Content\nDelivery Network (CDN) owners. We formulate this joint optimization problem and\nprove that it can be approximated up to a constant. We believe this to be the\nfirst polynomial algorithm to achieve a constant approximation ratio for the\njoint problem. Moreover, our numerical experiments show important performance\ngains of our algorithm over baseline schemes and existing algorithms in the\nliterature.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 14:20:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Tsigkari", "Dimitra", ""], ["Spyropoulos", "Thrasyvoulos", ""]]}, {"id": "2006.08456", "submitter": "Dimitrios Michael Manias", "authors": "Dimitrios Michael Manias, Hassan Hawilo, Abdallah Shami", "title": "A Machine Learning-Based Migration Strategy for Virtual Network Function\n  Instances", "comments": "Accepted - Future Technologies Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing demand for data connectivity, network service providers are\nfaced with the task of reducing their capital and operational expenses while\nsimultaneously improving network performance and addressing the increased\ndemand. Although Network Function Virtualization (NFV) has been identified as a\npromising solution, several challenges must be addressed to ensure its\nfeasibility. In this paper, we address the Virtual Network Function (VNF)\nmigration problem by developing the VNF Neural Network for Instance Migration\n(VNNIM), a migration strategy for VNF instances. The performance of VNNIM is\nfurther improved through the optimization of the learning rate hyperparameter\nthrough particle swarm optimization. Results show that the VNNIM is very\neffective in predicting the post-migration server exhibiting a binary accuracy\nof 99.07% and a delay difference distribution that is centered around a mean of\nzero when compared to the optimization model. The greatest advantage of VNNIM,\nhowever, is its run-time efficiency highlighted through a run-time analysis.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:03:27 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Manias", "Dimitrios Michael", ""], ["Hawilo", "Hassan", ""], ["Shami", "Abdallah", ""]]}, {"id": "2006.08543", "submitter": "Douglas Leith", "authors": "Douglas J. Leith, Stephen Farrell", "title": "Measurement-Based Evaluation Of Google/Apple Exposure Notification API\n  For Proximity Detection in a Commuter Bus", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0239943", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the results of a measurement study carried out on a commuter bus\nin Dublin, Ireland using the Google/Apple Exposure Notification (GAEN) API.\nThis API is likely to be widely used by Covid-19 contact tracing apps.\nMeasurements were collected between 60 pairs of handset locations and are\npublicly available. We find that the attenuation level reported by the GAEN API\nneed not increase with distance between handsets, consistent with there being a\ncomplex radio environment inside a bus caused by the metal-rich environment.\nChanging the people holding a pair of handsets, with the location of the\nhandsets otherwise remaining unchanged, can cause variations of +/-10dB in the\nattenuation level reported by the GAEN API. Applying the rule used by the Swiss\nCovid-19 contact tracing app to trigger an exposure notification to our bus\nmeasurements we find that no exposure notifications would have been triggered\ndespite the fact that all pairs of handsets were within 2m of one another for\nat least 15 mins. Applying an alternative threshold-based exposure notification\nrule can somewhat improve performance to a detection rate of 5% when an\nexposure duration threshold of 15 minutes is used, increasing to 8% when the\nexposure duration threshold is reduced to 10 mins. Stratifying the data by\ndistance between pairs of handsets indicates that there is only a weak\ndependence of detection rate on distance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 16:54:33 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Leith", "Douglas J.", ""], ["Farrell", "Stephen", ""]]}, {"id": "2006.08778", "submitter": "Hina Tabassum Prof.", "authors": "Javad Sayehvand and Hina Tabassum, Senior Member IEEE", "title": "Interference and Coverage Analysis in Coexisting RF and Dense TeraHertz\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a stochastic geometry framework to characterize the\nstatistics of the downlink interference and coverage probability of a typical\nuser in a coexisting terahertz (THz) and radio frequency (RF) network. We first\ncharacterize the exact Laplace Transform (LT) of the aggregate interference and\ncoverage probability of a user in a THz-only network. Then, for a coexisting\nRF/THz network, we derive the coverage probability of a typical user\nconsidering biased received signal power association (BRSP). The framework can\nbe customized to capture the performance of a typical user in various network\nconfigurations such as THz-only, opportunistic RF/THz, and hybrid RF/THz. In\naddition, asymptotic approximations are presented for scenarios where the\nintensity of THz BSs becomes large or molecular absorption coefficient in THz\napproaches to zero. Numerical results demonstrate the accuracy of the derived\nexpressions and extract insights related to the significance of the BRSP\nassociation compared to the conventional reference signal received power (RSRP)\nassociation in the coexisting network.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 21:25:49 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Sayehvand", "Javad", ""], ["Tabassum", "Hina", ""], ["IEEE", "Senior Member", ""]]}, {"id": "2006.08925", "submitter": "Amit Saha", "authors": "Ramdoot Pydipaty, Johnu George, Krishna Selvaraju, Amit Saha", "title": "Improving the Performance of Deep Learning for Wireless Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indoor localization systems are most commonly based on Received Signal\nStrength Indicator (RSSI) measurements of either WiFi or Bluetooth-Low-Energy\n(BLE) beacons. In such systems, the two most common techniques are\ntrilateration and fingerprinting, with the latter providing higher accuracy. In\nthe fingerprinting technique, Deep Learning (DL) algorithms are often used to\npredict the location of the receiver based on the RSSI measurements of multiple\nbeacons received at the receiver. In this paper, we address two practical\nissues with applying Deep Learning to wireless localization -- transfer of\nsolution from one wireless environment to another \\emph{and} small size of\nlabelled data set. First, we apply automatic hyperparameter optimization to a\ndeep neural network (DNN) system for indoor wireless localization, which makes\nthe system easy to port to new wireless environments. Second, we show how to\naugment a typically small labelled data set using the unlabelled data set. We\nobserved improved performance in DL by applying the two techniques.\nAdditionally, all relevant code has been made freely available.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 04:58:50 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Pydipaty", "Ramdoot", ""], ["George", "Johnu", ""], ["Selvaraju", "Krishna", ""], ["Saha", "Amit", ""]]}, {"id": "2006.09099", "submitter": "Philipp H. Kindt", "authors": "Christian Gentner, Daniel G\\\"unther, Philipp H. Kindt", "title": "Identifying the BLE Advertising Channel for Reliable Distance Estimation\n  on Smartphones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a response to the global COVID-19 surge in 2020, many countries have\nimplemented lockdown or stay-at-home policies. If, however, the contact persons\nof every infected patient could be identified, the number of virus\ntransmissions could be reduced, while the more incisive measures could be\nsoftened. For this purpose, contact tracing using smartphones is being\nconsidered as a promising technique. Here, smartphones emit and scan for\nBluetooth Low Energy (BLE) signals for detecting devices in range. When a\ndevice is detected, its distance is estimated by evaluating its received signal\nstrength. The main insight that is exploited for distance estimation is that\nthe attenuation of a signal increases with the distance along which it has\ntraveled. However, besides distance, there are multiple additional factors that\nimpact the attenuation and hence disturb distance estimation. Among them,\nfrequency-selective hardware and signal propagation belong to the most\nsignificant ones. For example, a BLE device transmits beacons on three\ndifferent frequencies (channels), while the transmit power and the receiver\nsensitivity depend on the frequency. As a result, the received signal strength\nvaries for each channel, even when the distance remains constant. However, the\ninformation on which wireless channel a beacon has been received is not made\navailable to a smartphone. Hence, this error cannot be compensated, e.g., by\ncalibration. In this paper, we for the first time provide a solution to detect\nthe wireless channel on which a packet has been received on a smartphone. We\nexperimentally evaluate our proposed technique on multiple different smartphone\nmodels. Our results help to make contact tracing more robust by improving the\naccuracy of distance estimation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 12:08:09 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 22:50:41 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 09:46:24 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Gentner", "Christian", ""], ["G\u00fcnther", "Daniel", ""], ["Kindt", "Philipp H.", ""]]}, {"id": "2006.09162", "submitter": "Sergio Fortes", "authors": "Carlos Baena, Sergio Fortes, Eduardo Baena, Raquel Barco", "title": "Estimation of Video Streaming KQIs for Radio Access Negotiation in\n  Network Slicing Scenarios", "comments": "4 pages, 4 figures", "journal-ref": "IEEE Communications Letters, vol. 24, no. 6, pp. 1304-1307, June\n  2020", "doi": "10.1109/LCOMM.2020.2979713", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of multimedia content has hugely increased in recent times, becoming\none of the most important services for the users of mobile networks.\nConsequently, network operators struggle to optimize their infrastructure to\nsupport the best video service-provision. As an additional challenge, 5G\nintroduces the concept of network slicing as a new paradigm that presents a\ncompletely different view of the network configuration and optimization. A main\nchallenge of this scheme is to establish which specific resources would provide\nthe necessary quality of service for the users using the slice. To address\nthis, the present work presents a complete framework for this support of the\nslice negotiation process through the estimation of the provided Video\nStreaming Key Quality Indicators (KQIs), which are calculated from network\nlow-layer configuration parameters and metrics. The proposed estimator is then\nevaluated in a real cellular scenario.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 14:10:54 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Baena", "Carlos", ""], ["Fortes", "Sergio", ""], ["Baena", "Eduardo", ""], ["Barco", "Raquel", ""]]}, {"id": "2006.09258", "submitter": "Sergio Fortes", "authors": "Sergio Fortes, David Palacios, Inmaculada Serrano, Raquel Barco", "title": "Applying Social Event Data for the Management of Cellular Networks", "comments": "9 pages, 5 figures", "journal-ref": "IEEE Communications Magazine, vol. 56, no. 11, pp. 36-43, November\n  2018", "doi": "10.1109/MCOM.2018.1700580", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet provides a growing variety of social data sources: calendars, event\naggregators, social networks, browsers, etc. Also, the mechanisms to gather\ninformation from these sources, such as web services, semantic web and big data\ntechniques have become more accessible and efficient. This allows a detailed\nprediction of the main expected events and their associated crowds. Due to the\nincreasing requirements for service provision, particularly in urban areas,\nhaving information on those events would be extremely useful for Operations,\nAdministration and Maintenance (OAM) tasks, since the social events largely\naffect the cellular network performance. Therefore, this paper presents a\nframework for the automatic acquisition and processing of social data, as well\nas their association with network elements (NEs) and their performance. The\nmain functionalities of this system, which have been devised to directly work\nin real networks, are defined and developed. Different OAM applications of the\nproposed approach are analyzed and the system is evaluated in a real\ndeployment.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 15:35:38 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Fortes", "Sergio", ""], ["Palacios", "David", ""], ["Serrano", "Inmaculada", ""], ["Barco", "Raquel", ""]]}, {"id": "2006.09272", "submitter": "Abdallah Moubayed", "authors": "Abdallah Moubayed and Emad Aqeeli and Abdallah Shami", "title": "Ensemble-based Feature Selection and Classification Model for DNS\n  Typo-squatting Detection", "comments": "6 pages, 2 figures, 6 tables, Accepted in 2020 IEEE CANADIAN\n  CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (CCECE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Name System (DNS) plays in important role in the current IP-based\nInternet architecture. This is because it performs the domain name to IP\nresolution. However, the DNS protocol has several security vulnerabilities due\nto the lack of data integrity and origin authentication within it. This paper\nfocuses on one particular security vulnerability, namely typo-squatting.\nTypo-squatting refers to the registration of a domain name that is extremely\nsimilar to that of an existing popular brand with the goal of redirecting users\nto malicious/suspicious websites. The danger of typo-squatting is that it can\nlead to information threat, corporate secret leakage, and can facilitate fraud.\nThis paper builds on our previous work in [1], which only proposed\nmajority-voting based classifier, by proposing an ensemble-based feature\nselection and bagging classification model to detect DNS typo-squatting attack.\nExperimental results show that the proposed framework achieves high accuracy\nand precision in identifying the malicious/suspicious typo-squatting domains (a\nloss of at most 1.5% in accuracy and 5% in precision when compared to the model\nthat used the complete feature set) while having a lower computational\ncomplexity due to the smaller feature set (a reduction of more than 50% in\nfeature set size).\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:07:19 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Moubayed", "Abdallah", ""], ["Aqeeli", "Emad", ""], ["Shami", "Abdallah", ""]]}, {"id": "2006.09301", "submitter": "Hawzhin Mohammed", "authors": "Terry N. Guo, Hawzhin Mohammed, and Syed R. Hasan", "title": "Collaborative Pipeline Using Opportunistic Mobile Resources via D2D for\n  Computation-Intensive Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a mobile pipeline computing concept in a Device-to-Device\n(D2D) communication setup and studies related issues, where D2D is likely based\non millimeter-wave (mmWave) in the 5G mobile communication. The proposed\nopportunistic system employs a cluster of pipelined resource-limited devices on\nthe move to handle real-time on-site computation-intensive tasks for which\ncurrent cloud computing technology may not be suitable. The feasibility of such\na system can be anticipated as high-speed and low-latency wireless technologies\nget mature. We present a system model by defining the architecture, basic\nfunctions, processes at both system-level and pipeline device level. A pipeline\npathfinding algorithm along with a multi-task optimization framework is\ndeveloped. To minimize the search space since the algorithm may need to be run\non resource-limited mobile devices, an adjacency-matrix-power-based graph\ntrimming technique is proposed and validated using simulation. A preliminary\nfeasibility assessment of our proposed techniques is performed using\nexperiments and computer simulation. As part of the feasibility assessment, the\nimpact of mmWave blockage on the pipeline stability is analyzed and examined\nfor both single-pipeline and concurrent-multiple-pipeline scenarios. Our design\nand analysis results provide certain insight to guide system design and lay a\nfoundation for further work in this line.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 16:45:17 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Guo", "Terry N.", ""], ["Mohammed", "Hawzhin", ""], ["Hasan", "Syed R.", ""]]}, {"id": "2006.09320", "submitter": "Carlos Pedroso", "authors": "Carlos Pedroso, Yan Uehara de Moraes, Michele Nogueira, Aldri Santos", "title": "Managing Consensus-Based Cooperative Task Allocation for IIoT Networks", "comments": "This work has been accept to the IEEE ISCC2020. Copyright\n  978-1-7281-8086-1/20/$31.00 2020 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current IoT services include industry-oriented services, which often require\nobjects to run more than one task. However, the exponential growth of objects\nin IoT poses the challenge of distributing and managing task allocation among\nobjects. One of the main goals of task allocation is to improve the quality of\ninformation and maximize the tasks to be performed. Although there are\napproaches that optimize and manage the dynamics of nodes, not all consider the\nquality of information and the distributed allocation over the cluster service.\nThis paper proposes the mechanism CONTASKI for task allocation in IIoT networks\nto distribute tasks among objects. It relies on collaborative consensus to\nallocate tasks and similarity capabilities to know which objects can play in\naccomplishing those tasks. CONTASKI was evaluated on NS-3 and achieved 100% of\nallocated tasks incases with 75 and 100 nodes, and, on average, more than 80%\nclusters performed tasks in a low response time.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 17:05:27 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Pedroso", "Carlos", ""], ["de Moraes", "Yan Uehara", ""], ["Nogueira", "Michele", ""], ["Santos", "Aldri", ""]]}, {"id": "2006.09655", "submitter": "Fuad A. Ghaleb Dr", "authors": "Fuad A. Ghaleb, Bander Ali Saleh Al-rimy, Maznah Kamat, Mohd. Foad\n  Rohani, Shukor Abd Razak", "title": "Fairness-Oriented Semi-Chaotic Genetic Algorithm-Based Channel\n  Assignment Technique for Nodes Starvation Problem in Wireless Mesh Network", "comments": "18 pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Radio Multi-Channel Wireless Mesh Networks (WMNs) have emerged as a\nscalable, reliable, and agile wireless network that supports many types of\ninnovative technologies such as the Internet of Things (IoT) and vehicular\nnetworks. Due to the limited number of orthogonal channels, interference\nbetween channels adversely affects the fair distribution of bandwidth among\nmesh clients, causing node starvation in terms of insufficient bandwidth, which\nimpedes the adoption of WMN as an efficient access technology. Therefore, a\nfair channel assignment is crucial for the mesh clients to utilize the\navailable resources. However, the node starvation problem due to unfair channel\ndistribution has been vastly overlooked during channel assignment by the extant\nresearch. Instead, existing channel assignment algorithms either reduce the\ntotal network interference or maximize the total network throughput, which\nneither guarantees a fair distribution of the channels nor eliminates node\nstarvation. To this end, the Fairness-Oriented Semi-Chaotic Genetic\nAlgorithm-Based Channel Assignment Technique (FA-SCGA-CAA) was proposed in this\npaper for Nodes Starvation Problem in Wireless Mesh Networks. FA-SCGA-CAA\noptimizes fairness based on multiple-criterion using a modified version of the\nGenetic Algorithm (GA). The modification includes proposing a semi-chaotic\ntechnique for creating the primary chromosome with powerful genes. Such a\nchromosome was used to create a strong population that directs the search\ntowards the global minima in an effective and efficient way. The outcome is a\nnonlinear fairness oriented fitness function that aims at maximizing the link\nfairness while minimizing the link interference. Comparison with related work\nshows that the proposed FA_SCGA_CAA reduced the potential nodes starvation by\n22% and improved network capacity utilization by 23%.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 04:43:47 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ghaleb", "Fuad A.", ""], ["Al-rimy", "Bander Ali Saleh", ""], ["Kamat", "Maznah", ""], ["Rohani", "Mohd. Foad", ""], ["Razak", "Shukor Abd", ""]]}, {"id": "2006.09658", "submitter": "Zhenyu Kang", "authors": "Zhenyu Kang, Changsheng You, Rui Zhang", "title": "3D Placement for Multi-UAV Relaying: An Iterative Gibbs-Sampling and\n  Block Coordinate Descent Optimization Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider an unmanned aerial vehicle (UAV) enabled relaying\nsystem where multiple UAVs are deployed as aerial relays to support\nsimultaneous communications from a set of source nodes to their destination\nnodes on the ground. An optimization problem is formulated under practical\nchannel models to maximize the minimum achievable expected rate among all pairs\nof ground nodes by jointly designing UAVs' three-dimensional (3D) placement as\nwell as the bandwidth-and-power allocation. This problem, however, is\nnon-convex and thus difficult to solve. As such, we propose a new method,\ncalled iterative Gibbs-sampling and block-coordinate-descent (IGS-BCD), to\nefficiently obtain a high-quality suboptimal solution by synergizing the\nadvantages of both the deterministic (BCD) and stochastic (GS) optimization\nmethods. Specifically, our proposed method alternates between two optimization\nphases until convergence is reached, namely, one phase that uses the BCD method\nto find locally-optimal UAVs' 3D placement and the other phase that leverages\nthe GS method to generate new UAVs' 3D placement for exploration. Moreover, we\npresent an efficient method for properly initializing UAVs' placement that\nleads to faster convergence of the proposed IGS-BCD algorithm. Numerical\nresults show that the proposed IGS-BCD and initialization methods outperform\nthe conventional BCD or GS method alone in terms of convergence-and-performance\ntrade-off, as well as other benchmark schemes.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 04:52:05 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 15:34:55 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Kang", "Zhenyu", ""], ["You", "Changsheng", ""], ["Zhang", "Rui", ""]]}, {"id": "2006.09683", "submitter": "Bohai Li", "authors": "Bohai Li, He Chen, Nikolaos Pappas, Yonghui Li", "title": "Optimizing Information Freshness in Two-Way Relay Networks", "comments": "6 pages. This work has been submitted to the IEEE for possible\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate an amplify-and-forward (AF) based two-way\ncooperative status update system, where two sources aim to exchange status\nupdates with each other as timely as possible with the help of a relay.\nSpecifically, the relay receives the sum signal from the two sources in one\ntime slot, and then amplifies and forwards the received signal to both the\nsources in the next time slot. We adopt a recently proposed concept, the age of\ninformation (AoI), to characterize the timeliness of the status updates.\nAssuming that the two sources are able to generate status updates at the\nbeginning of each time slot (i.e., generate-at-will model), we derive a\nclosed-form expression of the expected weighted sum AoI of the considered\nsystem. We further minimize the expected weighted sum AoI by optimizing the\ntransmission power at each node under the peak power constraints. Simulation\nresults corroborate the correctness of our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 06:51:52 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Li", "Bohai", ""], ["Chen", "He", ""], ["Pappas", "Nikolaos", ""], ["Li", "Yonghui", ""]]}, {"id": "2006.09684", "submitter": "Guorui Zhou", "authors": "Biye Jiang, Pengye Zhang, Rihan Chen, Binding Dai, Xinchen Luo, Yin\n  Yang, Guan Wang, Guorui Zhou, Xiaoqiang Zhu, Kun Gai", "title": "DCAF: A Dynamic Computation Allocation Framework for Online Serving\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern large-scale systems such as recommender system and online advertising\nsystem are built upon computation-intensive infrastructure. The typical\nobjective in these applications is to maximize the total revenue, e.g.\nGMV~(Gross Merchandise Volume), under a limited computation resource. Usually,\nthe online serving system follows a multi-stage cascade architecture, which\nconsists of several stages including retrieval, pre-ranking, ranking, etc.\nThese stages usually allocate resource manually with specific computing power\nbudgets, which requires the serving configuration to adapt accordingly. As a\nresult, the existing system easily falls into suboptimal solutions with respect\nto maximizing the total revenue. The limitation is due to the face that,\nalthough the value of traffic requests vary greatly, online serving system\nstill spends equal computing power among them.\n  In this paper, we introduce a novel idea that online serving system could\ntreat each traffic request differently and allocate \"personalized\" computation\nresource based on its value. We formulate this resource allocation problem as a\nknapsack problem and propose a Dynamic Computation Allocation Framework~(DCAF).\nUnder some general assumptions, DCAF can theoretically guarantee that the\nsystem can maximize the total revenue within given computation budget. DCAF\nbrings significant improvement and has been deployed in the display advertising\nsystem of Taobao for serving the main traffic. With DCAF, we are able to\nmaintain the same business performance with 20\\% computation resource\nreduction.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 07:00:57 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Jiang", "Biye", ""], ["Zhang", "Pengye", ""], ["Chen", "Rihan", ""], ["Dai", "Binding", ""], ["Luo", "Xinchen", ""], ["Yang", "Yin", ""], ["Wang", "Guan", ""], ["Zhou", "Guorui", ""], ["Zhu", "Xiaoqiang", ""], ["Gai", "Kun", ""]]}, {"id": "2006.09710", "submitter": "Xu Chen", "authors": "Huirong Ma and Zhi Zhou and Xu Chen", "title": "Leveraging the Power of Prediction: Predictive Service Placement for\n  Latency-Sensitive Mobile Edge Computing", "comments": "Accepted by IEEE Transactions on Wireless Communications, June 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing (MEC) is emerging to support delay-sensitive 5G\napplications at the edge of mobile networks. When a user moves erratically\namong multiple MEC nodes, the challenge of how to dynamically migrate its\nservice to maintain service performance (i.e., user-perceived latency) arises.\nHowever, frequent service migration can significantly increase operational\ncost, incurring the conflict between improving performance and reducing cost.\nTo address these mis-aligned objectives, this paper studies the performance\noptimization of mobile edge service placement under the constraint of long-term\ncost budget. It is challenging because the budget involves the future uncertain\ninformation (e.g., user mobility). To overcome this difficulty, we devote to\nleveraging the power of prediction and advocate predictive service placement\nwith predicted near-future information. By using two-timescale Lyapunov\noptimization method, we propose a T-slot predictive service placement (PSP)\nalgorithm to incorporate the prediction of user mobility based on a frame-based\ndesign. We characterize the performance bounds of PSP in terms of cost-delay\ntrade-off theoretically. Furthermore, we propose a new weight adjustment scheme\nfor the queue in each frame named PSP-WU to exploit the historical queue\ninformation, which greatly reduces the length of queue while improving the\nquality of user-perceived latency. Rigorous theoretical analysis and extensive\nevaluations using realistic data traces demonstrate the superior performance of\nthe proposed predictive schemes.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 08:09:52 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ma", "Huirong", ""], ["Zhou", "Zhi", ""], ["Chen", "Xu", ""]]}, {"id": "2006.09809", "submitter": "Jiska Classen", "authors": "Jan Ruge, Jiska Classen, Francesco Gringoli, Matthias Hollick", "title": "Frankenstein: Advanced Wireless Fuzzing to Exploit New Bluetooth\n  Escalation Targets", "comments": "To be published at USENIX Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless communication standards and implementations have a troubled history\nregarding security. Since most implementations and firmwares are closed-source,\nfuzzing remains one of the main methods to uncover Remote Code Execution (RCE)\nvulnerabilities in deployed systems. Generic over-the-air fuzzing suffers from\nseveral shortcomings, such as constrained speed, limited repeatability, and\nrestricted ability to debug. In this paper, we present Frankenstein, a fuzzing\nframework based on advanced firmware emulation, which addresses these\nshortcomings. Frankenstein brings firmware dumps \"back to life\", and provides\nfuzzed input to the chip's virtual modem. The speed-up of our new fuzzing\nmethod is sufficient to maintain interoperability with the attached operating\nsystem, hence triggering realistic full-stack behavior. We demonstrate the\npotential of Frankenstein by finding three zero-click vulnerabilities in the\nBroadcom and Cypress Bluetooth stack, which is used in most Apple devices, many\nSamsung smartphones, the Raspberry Pis, and many others.\n  Given RCE on a Bluetooth chip, attackers may escalate their privileges beyond\nthe chip's boundary. We uncover a Wi-Fi/Bluetooth coexistence issue that\ncrashes multiple operating system kernels and a design flaw in the Bluetooth\n5.2 specification that allows link key extraction from the host. Turning off\nBluetooth will not fully disable the chip, making it hard to defend against RCE\nattacks. Moreover, when testing our chip-based vulnerabilities on those\ndevices, we find BlueFrag, a chip-independent Android RCE.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 12:29:14 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ruge", "Jan", ""], ["Classen", "Jiska", ""], ["Gringoli", "Francesco", ""], ["Hollick", "Matthias", ""]]}, {"id": "2006.09970", "submitter": "Jiaxin Liang", "authors": "Jiaxin Liang, He Chen, and Soung Chang Liew", "title": "Design and Implementation of Time-Sensitive Wireless IoT Networks on\n  Software-Defined Radio", "comments": "13 pages, submitted to IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-sensitive wireless networks are an important enabling building block for\nmany emerging industrial Internet of Things (IoT) applications. Quick\nprototyping and evaluation of time-sensitive wireless technologies are\ndesirable for R&D efforts. Software-defined radio (SDR), by allowing wireless\nsignal processing on a personal computer (PC), has been widely used for such\nquick prototyping efforts. Unfortunately, because of the \\textit{uncontrollable\ndelay} between the PC and the radio board, SDR is generally deemed not suitable\nfor time-sensitive wireless applications that demand communication with low and\ndeterministic latency. For a rigorous evaluation of its suitability for\nindustrial IoT applications, this paper conducts a quantitative investigation\nof the synchronization accuracy and end-to-end latency achievable by an SDR\nwireless system. To this end, we designed and implemented a time-slotted\nwireless system on the Universal Software Radio Peripheral (USRP) SDR platform.\nWe developed a time synchronization mechanism to maintain synchrony among nodes\nin the system. To reduce the delays and delay jitters between the USRP board\nand its PC, we devised a {\\textit{Just-in-time}} algorithm to ensure that\npackets sent by the PC to the USRP can reach the USRP just before the time\nslots they are to be transmitted. Our experiments demonstrate that $90\\%$\n($100\\%$) of the time slots of different nodes can be synchronized and aligned\nto within $ \\pm 0.5$ samples or $ \\pm 0.05\\mu s$ ($ \\pm 1.5$ samples or $ \\pm\n0.15\\mu s$), and that the end-to-end packet delivery latency can be down to\n$3.75ms$. This means that SDR-based solutions can be applied in a range of IIoT\napplications that require tight synchrony and moderately low latency, e.g.,\nsensor data collection, automated guided vehicle (AGV) control, and\nHuman-Machine-Interaction (HMI).\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 16:31:30 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 09:30:07 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Liang", "Jiaxin", ""], ["Chen", "He", ""], ["Liew", "Soung Chang", ""]]}, {"id": "2006.09997", "submitter": "Arun Verma Mr.", "authors": "Arun Verma and Manjesh K. Hanawal", "title": "Stochastic Network Utility Maximization with Unknown Utilities:\n  Multi-Armed Bandits Approach", "comments": "Accepted to INFOCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study a novel Stochastic Network Utility Maximization (NUM)\nproblem where the utilities of agents are unknown. The utility of each agent\ndepends on the amount of resource it receives from a network\noperator/controller. The operator desires to do a resource allocation that\nmaximizes the expected total utility of the network. We consider threshold type\nutility functions where each agent gets non-zero utility if the amount of\nresource it receives is higher than a certain threshold. Otherwise, its utility\nis zero (hard real-time). We pose this NUM setup with unknown utilities as a\nregret minimization problem. Our goal is to identify a policy that performs as\n`good' as an oracle policy that knows the utilities of agents. We model this\nproblem setting as a bandit setting where feedback obtained in each round\ndepends on the resource allocated to the agents. We propose algorithms for this\nnovel setting using ideas from Multiple-Play Multi-Armed Bandits and\nCombinatorial Semi-Bandits. We show that the proposed algorithm is optimal when\nall agents have the same utility. We validate the performance guarantees of our\nproposed algorithms through numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 16:57:59 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2006.10188", "submitter": "Jen Rexford", "authors": "Rachit Agarwal and Jen Rexford (workshop co-chairs) with contributions\n  from numerous workshop attendees", "title": "Wide-Area Data Analytics", "comments": "A Computing Community Consortium (CCC) workshop report, 16 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020report_2", "categories": "cs.CY cs.DB cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We increasingly live in a data-driven world, with diverse kinds of data\ndistributed across many locations. In some cases, the datasets are collected\nfrom multiple locations, such as sensors (e.g., mobile phones and street\ncameras) spread throughout a geographic region. The data may need to be\nanalyzed close to where they are produced, particularly when the applications\nrequire low latency, high, low cost, user privacy, and regulatory constraints.\nIn other cases, large datasets are distributed across public clouds, private\nclouds, or edge-cloud computing sites with more plentiful computation, storage,\nbandwidth, and energy resources. Often, some portion of the analysis may take\nplace on the end-host or edge cloud (to respect user privacy and reduce the\nvolume of data) while relying on remote clouds to complete the analysis (to\nleverage greater computation and storage resources).\n  Wide-area data analytics is any analysis of data that is generated by, or\nstored at, geographically dispersed entities. Over the past few years, several\nparts of the computer science research community have started to explore\neffective ways to analyze data spread over multiple locations. In particular,\nseveral areas of \"systems\" research - including databases, distributed systems,\ncomputer networking, and security and privacy - have delved into these topics.\nThese research subcommunities often focus on different aspects of the problem,\nconsider different motivating applications and use cases, and design and\nevaluate their solutions differently. To address these challenges the Computing\nCommunity Consortium (CCC) convened a 1.5-day workshop focused on wide-area\ndata analytics in October 2019. This report summarizes the challenges discussed\nand the conclusions generated at the workshop.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 22:44:33 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Agarwal", "Rachit", "", "workshop co-chairs"], ["Rexford", "Jen", "", "workshop co-chairs"], ["attendees", "with contributions from numerous workshop", ""]]}, {"id": "2006.10409", "submitter": "Kleber Cardoso", "authors": "Kleber Vieira Cardoso, Cristiano Bonato Both, L\\'ucio Rene Prade, Ciro\n  J. A. Macedo, Victor Hugo L. Lopes", "title": "A softwarized perspective of the 5G networks", "comments": "23 pages (two columns), 23 figures, 3 tables, typos corrected, and\n  for additional material associated to the tutorial, see\n  https://github.com/LABORA-INF-UFG/NetSoft2020-Tutorial4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this article is to present the fundamental theoretical\nconcepts for the tutorial presented in IEEE NetSoft 2020. The article explores\nthe use of software in the 5G system composed of the Radio Access Network (RAN)\nand the core components, following the standards defined by 3GPP, particularly\nthe Release 15. The article provides a brief overview of mobile cellular\nnetworks, including basic concepts, operations, and evolution through the\ncalled `generations' of mobile networks. From a software perspective, RAN is\npresented in the context of 4G and 5G networks, which includes the\nvirtualization and disaggregation concepts. A significant part of the article\nis dedicated to 5G networks and beyond, focusing on core, i.e., considering the\nService-Based Architecture (SBA), due to its relevance and totally softwarized\napproach. Finally, the article briefly describes the demonstrations presented\nin IEEE NetSoft 2020, providing the link for the repository that has all\nmaterial employed in the tutorial.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 10:26:58 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 19:14:25 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 07:05:13 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Cardoso", "Kleber Vieira", ""], ["Both", "Cristiano Bonato", ""], ["Prade", "L\u00facio Rene", ""], ["Macedo", "Ciro J. A.", ""], ["Lopes", "Victor Hugo L.", ""]]}, {"id": "2006.10692", "submitter": "Marcin Bienkowski", "authors": "Marcin Bienkowski, David Fuchssteiner, Jan Marcinkowski, Stefan Schmid", "title": "Online Dynamic B-Matching With Applications to Reconfigurable Datacenter\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper initiates the study of online algorithms for the maximum weight\n$b$-matching problem, a generalization of maximum weight matching where each\nnode has at most $b \\geq 1$ adjacent matching edges. The problem is motivated\nby emerging optical technologies which allow to enhance datacenter networks\nwith reconfigurable matchings, providing direct connectivity between frequently\ncommunicating racks. These additional links may improve network performance, by\nleveraging spatial and temporal structure in the workload. We show that the\nunderlying algorithmic problem features an intriguing connection to online\npaging (a.k.a. caching), but introduces a novel challenge. Our main\ncontribution is an online algorithm which is $O(b)$-competitive; we also prove\nthat this is asymptotically optimal. We complement our theoretical results with\nextensive trace-driven simulations, based on real-world datacenter workloads as\nwell as synthetic traffic traces.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 17:23:46 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 17:41:51 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Bienkowski", "Marcin", ""], ["Fuchssteiner", "David", ""], ["Marcinkowski", "Jan", ""], ["Schmid", "Stefan", ""]]}, {"id": "2006.10843", "submitter": "Alaa Awad Abdellatif", "authors": "Alaa Awad Abdellatif, Abeer Z. Al-Marridi, Amr Mohamed, Aiman Erbad,\n  Carla Fabiana Chiasserini, and Ahmed Refaey", "title": "SSHealth: Toward Secure, Blockchain-Enabled Healthcare Systems", "comments": null, "journal-ref": "IEEE Network, 2020", "doi": "10.1109/MNET.011.1900553", "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The future of healthcare systems is being shaped by incorporating emerged\ntechnological innovations to drive new models for patient care. By acquiring,\nintegrating, analyzing, and exchanging medical data at different system levels,\nnew practices can be introduced, offering a radical improvement to healthcare\nservices. This paper presents a novel smart and secure Healthcare system\n(ssHealth), which, leveraging advances in edge computing and blockchain\ntechnologies, permits epidemics discovering, remote monitoring, and fast\nemergency response. The proposed system also allows for secure medical data\nexchange among local healthcare entities, thus realizing the integration of\nmultiple national and international entities and enabling the correlation of\ncritical medical events for, e.g., emerging epidemics management and control.\nIn particular, we develop a blockchain-based architecture and enable a flexible\nconfiguration thereof, which optimize medical data sharing between different\nhealth entities and fulfil the diverse levels of Quality of Service (QoS) that\nssHealth may require. Finally, we highlight the benefits of the proposed\nssHealth system and possible directions for future research.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 20:34:56 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Abdellatif", "Alaa Awad", ""], ["Al-Marridi", "Abeer Z.", ""], ["Mohamed", "Amr", ""], ["Erbad", "Aiman", ""], ["Chiasserini", "Carla Fabiana", ""], ["Refaey", "Ahmed", ""]]}, {"id": "2006.10969", "submitter": "Ekram Hossain", "authors": "Taniya Shafique, Hina Tabassum, and Ekram Hossain", "title": "Optimization of Wireless Relaying With Flexible UAV-Borne Reflecting\n  Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a theoretical framework to analyze the performance of\nintegrated unmanned aerial vehicle (UAV)-intelligent reflecting surface (IRS)\nrelaying system in which IRS provides an additional degree of freedom combined\nwith the flexible deployment of full-duplex UAV to enhance communication\nbetween ground nodes. Our framework considers three different transmission\nmodes: {\\bf (i)} UAV-only mode, {\\bf (ii)} IRS-only mode, and {\\bf (iii)}\nintegrated UAV-IRS mode to achieve spectral and energy-efficient relaying. For\nthe proposed modes, we provide exact and approximate expressions for the\nend-to-end outage probability, ergodic capacity, and energy efficiency (EE) in\nclosed-form.\n  We use the derived expressions to optimize key system parameters such as the\nUAV altitude and the number of elements on the IRS considering different modes.\nWe formulate the problems in the form of fractional programming (e.g. single\nratio, sum of multiple ratios or maximization-minimization of ratios) and\ndevise optimal algorithms using quadratic transformations. Furthermore, we\nderive an analytic criterion to optimally select different transmission modes\nto maximize ergodic capacity and EE for a given number of IRS elements.\nNumerical results validate the derived expressions with Monte-Carlo simulations\nand the proposed optimization algorithms with the solutions obtained through\nexhaustive search. Insights are drawn related to the different communication\nmodes, optimal number of IRS elements, and optimal UAV height.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 05:28:10 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Shafique", "Taniya", ""], ["Tabassum", "Hina", ""], ["Hossain", "Ekram", ""]]}, {"id": "2006.10985", "submitter": "Quentin Bramas", "authors": "Fran\\c{c}ois Bonnet (TITECH), Quentin Bramas (ICube, ICUBE-R\\'eseaux),\n  Xavier D\\'efago (TITECH)", "title": "Stateless Distributed Ledgers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In public distributed ledger technologies (DLTs), such as Blockchains, nodes\ncan join and leave the network at any time. A major challenge occurs when a new\nnode joining the network wants to retrieve the current state of the ledger.\nIndeed, that node may receive conflicting information from honest and Byzantine\nnodes, making it difficult to identify the current state. In this paper, we are\ninterested in protocols that are stateless, i.e., a new joining node should be\nable to retrieve the current state of the ledger just using a fixed amount of\ndata that characterizes the ledger (such as the genesis block in Bitcoin). We\ndefine three variants of stateless DLTs: weak, strong, and probabilistic. Then,\nwe analyze this property for DLTs using different types of consensus.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 07:22:35 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Bonnet", "Fran\u00e7ois", "", "TITECH"], ["Bramas", "Quentin", "", "ICube, ICUBE-R\u00e9seaux"], ["D\u00e9fago", "Xavier", "", "TITECH"]]}, {"id": "2006.11148", "submitter": "Chen Avin", "authors": "Chen Avin and Chen Griner and Iosif Salem and Stefan Schmid", "title": "An Online Matching Model for Self-Adjusting ToR-to-ToR Networks", "comments": "3 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a short note that formally presents the matching model for the\ntheoretical study of self-adjusting networks as initially proposed in [1].\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:20:13 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Avin", "Chen", ""], ["Griner", "Chen", ""], ["Salem", "Iosif", ""], ["Schmid", "Stefan", ""]]}, {"id": "2006.11283", "submitter": "Derya Malak", "authors": "Derya Malak and Muriel M\\'edard and Jeffrey G. Andrews", "title": "Spatial Concentration of Caching in Wireless Heterogeneous Networks", "comments": "to appear, IEEE TWC. arXiv admin note: text overlap with\n  arXiv:1901.11102", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a decentralized caching policy for wireless heterogeneous networks\nthat makes content placement decisions based on pairwise interactions between\ncache nodes. We call our proposed scheme {\\gamma}-exclusion cache placement\n(GEC), where a parameter {\\gamma} controls an exclusion radius that discourages\nnearby caches from storing redundant content. GEC takes into account item\npopularity and the nodes' caching priorities and leverages negative dependence\nto relax the classic 0-1 knapsack problem to yield spatially balanced sampling\nacross caches. We show that GEC guarantees a better concentration (reduced\nvariance) of the required cache storage size than the state of the art, and\nthat the cache size constraints can be satisfied with high probability. Given a\ncache hit probability target, we compare the 95\\% confidence intervals of the\nrequired cache sizes for three caching schemes: (i) independent placement, (ii)\nhard exclusion caching (HEC), and (iii) the proposed GEC approach. For uniform\nspatial traffic, we demonstrate that GEC provides approximately a 3x and 2x\nreduction in required cache size over (i) and (ii), respectively. For\nnon-uniform spatial traffic based on realistic peak-hour variations in urban\nscenarios, the gains are even greater.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 11:17:11 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 23:39:18 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Malak", "Derya", ""], ["M\u00e9dard", "Muriel", ""], ["Andrews", "Jeffrey G.", ""]]}, {"id": "2006.11307", "submitter": "Ramanujan K Sheshadri", "authors": "Ramanujan K Sheshadri, Eugene Chai, Karthikeyan Sundaresan, Sampath\n  Rangarajan", "title": "SkyHaul: An Autonomous Gigabit Network Fabric in the Sky", "comments": "15 pages report (with 32 figures including experiment results) on a\n  novel solution for a 5g mmWave enabled drone-network. This hasn't been\n  published in conferences/journals yet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and build SKYHAUL, the first large-scale, autonomous,\nself-organizing network of Unmanned Aerial Vehicles (UAVs) that are connected\nusing a mmWave wireless mesh backhaul. While the use of a mmWave backhaul paves\nthe way for a new class of bandwidth-intensive, latency-sensitive cooperative\napplications (e.g., LTE coverage during disasters, surveillance during rescue\nin challenging terrains), the network of UAVs allows these applications to be\nexecuted at operating ranges that are far beyond the line-of-sight distances\nthat limit individual UAVs today. To realize the challenging vision of\ndeploying and maintaining an airborne mmWave mesh backhaul to cater to dynamic\napplications, SKYHAUL's design incorporates various elements: (1) Role-specific\nUAV operations that simultaneously address application tracking and backhaul\nconnectivity (2) Novel algorithms to jointly address the problem of deployment\n(position, yaw of UAVs) and traffic routing across the UAV network; and (3) A\nprovably optimal solution for fast and safe reconfiguration of UAV backhaul\nduring application dynamics. We implement SKYHAUL on four DJI Matrice 600 Pros\nto demonstrate its practicality and performance through autonomous flight\noperations, complemented by large scale simulations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 18:12:06 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Sheshadri", "Ramanujan K", ""], ["Chai", "Eugene", ""], ["Sundaresan", "Karthikeyan", ""], ["Rangarajan", "Sampath", ""]]}, {"id": "2006.11606", "submitter": "Juwendo Denis", "authors": "Juwendo Denis and Hulya Seferoglu", "title": "Packet Completion Time Minimization via Joint D2D and Cellular\n  Communication: A Unified Network Coding Approach", "comments": "30 pages, 5 figures, submitted to IEEE Transaction on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of transmitting a common content to a number\nof cellular users by means of instantly decodable network coding (IDNC) with\nthe help of intermittently connected D2D links. Of particular interest are\nbroadcasting real-time applications such as video-on-demand, where common\ncontents may be partially received by cellular users due to packet erasures\nover cellular links. Specifically, we investigate the problem of packet\ncompletion time, defined as the number of transmission slots necessary to\ndeliver a common content to all users. Drawing on graph theory, we develop an\noptimal packet completion time strategy by constructing a two-layer IDNC\nconflict graph. The higher-layer graph permits us to determine all feasible\npacket combinations that can be transmitted over the cellular link, while the\nlower-layer graph enables us to find all feasible network coded packets and\nidentify the set of users that can generate and transmit these packets via\nintermittently connected D2D links. By combining the higher-layer and the\nlower-layer IDNC conflict graphs, we demonstrate that finding the optimal IDNC\npackets to minimize the packet completion time problem is equivalent to finding\nthe maximum independent set of the two-layer IDNC conflict graph, which is\nknown to be an NP-hard problem. We design a scheme that invokes the\nBron-Kerbosch algorithm to find the optimal policy. To circumvent the high\ncomputational complexity required to reach the global optimum, we establish a\npolynomial-time solvable low-complexity heuristic to find an efficient\nsub-optimal solution. The effectiveness of our proposed scheme is verified\nthrough extensive numerical results which indicate substantial performance\nimprovement in comparison with existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 16:22:09 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Denis", "Juwendo", ""], ["Seferoglu", "Hulya", ""]]}, {"id": "2006.12060", "submitter": "Pangun Park", "authors": "Pangun Park, Piergiuseppe Di Marco, Junghyo Nah, Carlo Fischione", "title": "Wireless Avionics Intra-Communications: A Survey of Benefits,\n  Challenges, and Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the aeronautics industry, wireless avionics intra-communications have a\ntremendous potential to improve efficiency and flexibility while reducing the\nweight, fuel consumption, and maintenance costs over traditional wired avionics\nsystems. This survey starts with an overview of the major benefits and\nopportunities in the deployment of wireless technologies for critical\napplications of an aircraft. The current state-of-art is presented in terms of\nsystem classifications based on data rate demands and transceiver installation\nlocations. We then discuss major technical challenges in the design and\nrealization of the envisioned aircraft applications. Although wireless avionics\nintra-communication has aspects and requirements similar to mission-critical\napplications of industrial automation, it also has specific issues such as\ncomplex structures, operations, and safety of the aircraft that make this area\nof research self-standing and challenging. To support the critical operations\nof an aircraft, existing wireless standards for mission-critical industrial\napplications are briefly discussed to investigate the applicability of the\ncurrent solutions. Specifically, IEEE 802.15.4-based protocols and Bluetooth\nare discussed for low data rate applications, whereas IEEE 802.11- based\nstandards are considered for high data rate applications. Eventually, we\npropose fundamental schemes in terms of network architecture, protocol, and\nresource management to support the critical avionics applications and discuss\nthe research directions in this emerging area.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 08:18:37 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Park", "Pangun", ""], ["Di Marco", "Piergiuseppe", ""], ["Nah", "Junghyo", ""], ["Fischione", "Carlo", ""]]}, {"id": "2006.12143", "submitter": "Elias Rohrer", "authors": "Elias Rohrer and Florian Tschorsch", "title": "Counting Down Thunder: Timing Attacks on Privacy in Payment Channel\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lightning Network is a scaling solution for Bitcoin that promises to\nenable rapid and private payment processing. In Lightning, multi-hop payments\nare secured by utilizing Hashed Time-Locked Contracts (HTLCs) and encrypted on\nthe network layer by an onion routing scheme to avoid information leakage to\nintermediate nodes. In this work, we however show that the privacy guarantees\nof the Lightning Network may be subverted by an on-path adversary conducting\ntiming attacks on the HTLC state negotiation messages. To this end, we provide\nestimators that enable an adversary to reduce the anonymity set and infer the\nlikeliest payment endpoints. We developed a proof-of-concept measurement node\nthat shows the feasibility of attaining time differences and evaluate the\nadversarial success in model-based network simulations. We find that\ncontrolling a small number malicious nodes is sufficient to observe a large\nshare of all payments, emphasizing the relevance of the on-path adversary\nmodel. Moreover, we show that adversaries of different magnitudes could employ\ntiming-based attacks to deanonymize payment endpoints with high precision and\nrecall.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 11:06:57 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Rohrer", "Elias", ""], ["Tschorsch", "Florian", ""]]}, {"id": "2006.12242", "submitter": "Israel Leyva-Mayorga", "authors": "Jonas W. Rabjerg, Israel Leyva-Mayorga, and Beatriz Soret", "title": "Exploiting topology awareness for routing in LEO satellite\n  constellations", "comments": "Submitted for publication at IEEE GLOBECOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low Earth Orbit (LEO) satellite constellations combine great flexibility and\nglobal coverage with short propagation delays when compared to satellites\ndeployed in higher orbits. However, the fast movement of the individual\nsatellites makes inter-satellite routing a complex and dynamic problem. In this\npaper, we investigate the limits of unipath routing in a scenario where ground\nstations (GSs) communicate with each other through a LEO constellation. For\nthis, we present a lightweight and topology-aware routing metric that favors\nthe selection of paths with high data rate inter-satellite links (ISLs).\nFurthermore, we analyze the overall routing latency in terms of propagation,\ntransmission, and queueing times and calculate the maximum traffic load that\ncan be supported by the constellation. In our setup, the traffic is injected by\na network of GSs with real locations and is routed through adaptive multi-rate\ninter-satellite links (ISLs). Our results illustrate the benefits of exploiting\nthe network topology, as the proposed metric can support up to 53% more traffic\nwhen compared to the selected benchmarks, and consistently achieves the\nshortest queueing times at the satellites and, ultimately, the shortest\nend-to-end latency.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 13:38:49 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 10:00:17 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 08:01:27 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Rabjerg", "Jonas W.", ""], ["Leyva-Mayorga", "Israel", ""], ["Soret", "Beatriz", ""]]}, {"id": "2006.12555", "submitter": "Karthika Subramani", "authors": "Karthika Subramani, Roberto Perdisci and Maria Konte", "title": "IXmon: Detecting and Analyzing DRDoS Attacks at Internet Exchange Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed reflective denial of service (DRDoS) attacks are a popular choice\namong adversaries. In fact, one of the largest DDoS attacks ever recorded,\nreaching a peak of 1.3Tbps against GitHub, was a memcached-based DRDoS attack.\nMore recently, a record-breaking 2.3Tbps attack against Amazon AWS was due to a\nCLDAP-based DRDoS attack. Although reflective attacks have been known for\nyears, DRDoS attacks are unfortunately still popular and largely unmitigated.\nIn this paper, we study in-the-wild DRDoS attacks observed from a large\nInternet exchange point (IXP) and provide a number of security-relevant\nmeasurements and insights.\n  To enable this study, we first developed IXmon, an open-source DRDoS\ndetection system specifically designed for deployment at large IXP-like network\nconnectivity providers and peering hubs. We deployed IXmon at Southern\nCrossroads (SoX), an IXP-like hub that provides both peering and upstream\nInternet connectivity services to more than 20 research and education (R&E)\nnetworks in the South-East United States. In a period of about 21 months, IXmon\ndetected more than 900 DRDoS attacks towards 31 different victim ASes. An\nanalysis of the real-world DRDoS attacks detected by our system shows that most\nDRDoS attacks are short lived, lasting only a few minutes, but that\nlarge-volume, long-lasting, and highly-distributed attacks against R&E networks\nare not uncommon. We then use the results of our analysis to discuss possible\nattack mitigation approaches that can be deployed at the IXP level, before the\nattack traffic overwhelms the victim's network bandwidth.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 18:31:01 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 17:32:52 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Subramani", "Karthika", ""], ["Perdisci", "Roberto", ""], ["Konte", "Maria", ""]]}, {"id": "2006.12570", "submitter": "Xiaofan Jiang", "authors": "Xiaofan Jiang, Heng zhang, Edgardo Alberto Barsallo Yi, Nithin\n  Raghunathan, Charilaos Mousoulis, Somali Chaterji, Dimitrios Peroulis, Ali\n  Shakouri and Saurabh Bagchi", "title": "Hybrid Low-Power Wide-Area Mesh Network for IoT Applications", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2020.3009228", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advancement of the Internet of Things (IoT) enables the\npossibility of data collection from diverse environments using IoT devices.\nHowever, despite the rapid advancement of low-power communication technologies,\nthe deployment of IoT networks still faces many challenges. In this paper, we\npropose a hybrid, low-power, wide-area network (LPWAN) structure that can\nachieve wide-area communication coverage and low power consumption on IoT\ndevices by utilizing both sub-GHz long-range radio and 2.4 GHz short-range\nradio. Specifically, we constructed a low-power mesh network with LoRa, a\nphysical-layer standard that can provide long-range (kilometers) point-to-point\ncommunication using custom time-division multiple access (TDMA). Furthermore,\nwe extended the capabilities of the mesh network by enabling ANT, an\nultra-low-power, short-range communication protocol to satisfy data collection\nin dense device deployments. Third, we demonstrate the performance of the\nhybrid network with two real-world deployments at the Purdue University campus\nand at the university-owned farm. The results suggest that both networks have\nsuperior advantages in terms of cost, coverage, and power consumption\nvis-\\`a-vis other IoT solutions, like LoRaWAN.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 19:05:42 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Jiang", "Xiaofan", ""], ["zhang", "Heng", ""], ["Yi", "Edgardo Alberto Barsallo", ""], ["Raghunathan", "Nithin", ""], ["Mousoulis", "Charilaos", ""], ["Chaterji", "Somali", ""], ["Peroulis", "Dimitrios", ""], ["Shakouri", "Ali", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "2006.12653", "submitter": "Tugba Erpek", "authors": "Tarun S. Cousik, Vijay K. Shah, Jeffrey H. Reed, Tugba Erpek, Yalin E.\n  Sagduyu", "title": "Fast Initial Access with Deep Learning for Beam Prediction in 5G mmWave\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents DeepIA, a deep learning solution for faster and more\naccurate initial access (IA) in 5G millimeter wave (mmWave) networks when\ncompared to conventional IA. By utilizing a subset of beams in the IA process,\nDeepIA removes the need for an exhaustive beam search thereby reducing the beam\nsweep time in IA. A deep neural network (DNN) is trained to learn the complex\nmapping from the received signal strengths (RSSs) collected with a reduced\nnumber of beams to the optimal spatial beam of the receiver (among a larger set\nof beams). In test time, DeepIA measures RSSs only from a small number of beams\nand runs the DNN to predict the best beam for IA. We show that DeepIA reduces\nthe IA time by sweeping fewer beams and significantly outperforms the\nconventional IA's beam prediction accuracy in both line of sight (LoS) and\nnon-line of sight (NLoS) mmWave channel conditions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 22:35:17 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Cousik", "Tarun S.", ""], ["Shah", "Vijay K.", ""], ["Reed", "Jeffrey H.", ""], ["Erpek", "Tugba", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "2006.12727", "submitter": "Xiangqiang Gao", "authors": "Xiangqiang Gao, Rongke liu, Aryan Kaushik", "title": "Service Chaining Placement Based on Satellite Mission Planning in Ground\n  Station Networks", "comments": "IEEE Transactions on Network and Service Management (2020)", "journal-ref": null, "doi": "10.1109/TNSM.2020.3045432", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the increase in satellite number and variety, satellite ground stations\nshould be required to offer user services in a flexible and efficient manner.\nNetwork function virtualization (NFV) can provide a new paradigm to allocate\nnetwork resources on-demand for user services over the underlying network.\nHowever, most of the existing work focuses on the virtual network function\n(VNF) placement and routing traffic problem for enterprise data center\nnetworks, the issue needs to further study in satellite communication\nscenarios. In this paper, we investigate the VNF placement and routing traffic\nproblem in satellite ground station networks. We formulate the problem of\nresource allocation as an integer nonlinear programming (INLP) model and the\nobjective is to minimize the link resource utilization and the number of\nservers used. Considering the information about satellite orbit fixation and\nmission planning, we propose location-aware resource allocation (LARA)\nalgorithms based on Greedy and IBM CPLEX 12.10, respectively. The proposed LARA\nalgorithm can assist in deploying VNFs and routing traffic flows by predicting\nthe running conditions of user services. We evaluate the performance of our\nproposed LARA algorithm in three networks of Fat-Tree, BCube, and VL2.\nSimulation results show that our proposed LARA algorithm performs better than\nthat without prediction, and can effectively decrease the average resource\nutilization of satellite ground station networks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 03:52:15 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 13:07:48 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 08:50:21 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Gao", "Xiangqiang", ""], ["liu", "Rongke", ""], ["Kaushik", "Aryan", ""]]}, {"id": "2006.12736", "submitter": "Ziaur Rahman", "authors": "Ziaur Rahman, Asma Islam Swapna, Habibur Rahman Habib and Akramuzzaman\n  Shaoun", "title": "Performance Evaluation of Fuzzy Integrated Firewall Model for Hybrid\n  Cloud based on Packet Utilization", "comments": "6 Pages, 2 Tables, 7 Figures", "journal-ref": "2016 First IEEE International Conference on Computer Communication\n  and the Internet (ICCCI), Wuhan, 2016, pp. 253-256", "doi": "10.1109/CCI.2016.7778919.", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cloud computing is one of the highly flexible, confidential and easily\naccessible medium of platforms and provides powerful service for sharing\ninformation over the Internet. Cloud security has become an emerging issue as\nnetwork manager eventually encounter its data protection, vulnerability during\ninformation exchange on the cloud system. We can protect our data from unwanted\naccess on a hybrid cloud through controlling the respective firewall of the\nnetwork. But, the firewall has already proved its weakness as it is unable to\nensure multi-layered, secured accessibility of the cloud network. Efficient\npacket utilization sometimes causes high response time in accessing hybrid\ncloud. In this paper, a Cloud Model with Hybrid functionality and a secure\nFuzzy Integrated Firewall for that Hybrid Cloud is proposed and thereby\nevaluated for the performance in traffic response. Experimental result\nillustrated that having a fuzzified firewall gives high point-to-point packet\nutilization decreasing the response time than a conventional firewall. Results\nfrom this research work will highly be implemented in transplanting artificial\nintelligence in future Internet of Things (IoT).\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 05:12:52 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Rahman", "Ziaur", ""], ["Swapna", "Asma Islam", ""], ["Habib", "Habibur Rahman", ""], ["Shaoun", "Akramuzzaman", ""]]}, {"id": "2006.13019", "submitter": "Wei-Kun Chen", "authors": "Wei-Kun Chen, Ya-Feng Liu, Antonio De Domenico, Zhi-Quan Luo, and\n  Yu-Hong Dai", "title": "Optimal Network Slicing for Service-Oriented Networks with Flexible\n  Routing and Guaranteed E2E Latency", "comments": "16 pages, 8 figures, accepted for publication in IEEE Transactions on\n  Network and Service Management, code available here:\n  https://github.com/chenweikun/networkslicing. arXiv admin note: text overlap\n  with arXiv:2002.07380", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network function virtualization is a promising technology to simultaneously\nsupport multiple services with diverse characteristics and requirements in the\n5G and beyond networks. In particular, each service consists of a predetermined\nsequence of functions, called service function chain (SFC), running on a cloud\nenvironment. To make different service slices work properly in harmony, it is\ncrucial to appropriately select the cloud nodes to deploy the functions in the\nSFC and flexibly route the flow of the services such that these functions are\nprocessed in the order defined in the corresponding SFC, the end-to-end (E2E)\nlatency constraints of all services are guaranteed, and all cloud and\ncommunication resource budget constraints are respected. In this paper, we\nfirst propose a new mixed binary linear program (MBLP) formulation of the above\nnetwork slicing problem that optimizes the system energy efficiency while\njointly considers the E2E latency requirement, resource budget, flow routing,\nand functional instantiation. Then, we develop another MBLP formulation and\nshow that the two formulations are equivalent in the sense that they share the\nsame optimal solution. However, since the numbers of variables and constraints\nin the second problem formulation are significantly smaller than those in the\nfirst one, solving the second problem formulation is more computationally\nefficient especially when the dimension of the corresponding network is large.\nNumerical results demonstrate the advantage of the proposed formulations\ncompared with the existing ones.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 04:49:13 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 08:11:40 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 00:27:58 GMT"}, {"version": "v4", "created": "Sat, 5 Jun 2021 11:44:10 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chen", "Wei-Kun", ""], ["Liu", "Ya-Feng", ""], ["De Domenico", "Antonio", ""], ["Luo", "Zhi-Quan", ""], ["Dai", "Yu-Hong", ""]]}, {"id": "2006.13086", "submitter": "Jordan Holland", "authors": "Jordan Holland, Ross Teixeira, Paul Schmitt, Kevin Borgolte, Jennifer\n  Rexford, Nick Feamster, Jonathan Mayer", "title": "Classifying Network Vendors at Internet Scale", "comments": "11 Pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a method to create a large, labeled dataset of\nvisible network device vendors across the Internet by mapping network-visible\nIP addresses to device vendors. We use Internet-wide scanning, banner grabs of\nnetwork-visible devices across the IPv4 address space, and clustering\ntechniques to assign labels to more than 160,000 devices. We subsequently probe\nthese devices and use features extracted from the responses to train a\nclassifier that can accurately classify device vendors. Finally, we demonstrate\nhow this method can be used to understand broader trends across the Internet by\npredicting device vendors in traceroutes from CAIDA's Archipelago measurement\nsystem and subsequently examining vendor distributions across these\ntraceroutes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 15:21:44 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 17:15:15 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Holland", "Jordan", ""], ["Teixeira", "Ross", ""], ["Schmitt", "Paul", ""], ["Borgolte", "Kevin", ""], ["Rexford", "Jennifer", ""], ["Feamster", "Nick", ""], ["Mayer", "Jonathan", ""]]}, {"id": "2006.13109", "submitter": "Saurabh Deochake", "authors": "Saurabh Deochake and Debajyoti Mukhopadhyay", "title": "An Agent-based Cloud Service Negotiation in Hybrid Cloud Computing", "comments": "Fifth International Conference on ICT for Sustainable Development", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the advent of evolution of cloud computing, large organizations have\nbeen scaling the on-premise IT infrastructure to the cloud. Although this being\na popular practice, it lacks comprehensive efforts to study the aspects of\nautomated negotiation of resources among cloud customers and providers. This\npaper proposes a full-fledged framework for the multi-party, multi-issue\nnegotiation system for cloud resources. It introduces a robust cloud\nmarketplace system to buy and sell cloud resources. The Belief-Desire-Intention\n(BDI) model-based cloud customer and provider agents concurrently negotiate on\nmultiple issues, pursuing a hybrid tactic of time and resource-based dynamic\ndeadline algorithms to generate offers and counter-offers. The cloud\nmarketplace-based system is further augmented with the assignment of behavior\nnorm score and reputation index to the agents to establish trust among them.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 05:23:38 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Deochake", "Saurabh", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "2006.13362", "submitter": "Yuxiang Luo", "authors": "Yuxiang Luo, Cheng Zhang, Yunqi Zhang, Chaoshun Zuo, Dong Xuan,\n  Zhiqiang Lin, Adam C. Champion, and Ness Shroff", "title": "ACOUSTIC-TURF: Acoustic-based Privacy-Preserving COVID-19 Contact\n  Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SD cs.SI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new privacy-preserving, automated contact tracing\nsystem, ACOUSTIC-TURF, to fight COVID-19 using acoustic signals sent from\nubiquitous mobile devices. At a high level, ACOUSTIC-TURF adaptively broadcasts\ninaudible ultrasonic signals with randomly generated IDs in the vicinity.\nSimultaneously, the system receives other ultrasonic signals sent from nearby\n(e.g., 6 feet) users. In such a system, individual user IDs are not disclosed\nto others and the system can accurately detect encounters in physical proximity\nwith 6-foot granularity. We have implemented a prototype of ACOUSTIC-TURF on\nAndroid and evaluated its performance in terms of acoustic-signal-based\nencounter detection accuracy and power consumption at different ranges and\nunder various occlusion scenarios. Experimental results show that ACOUSTIC-TURF\ncan detect multiple contacts within a 6-foot range for mobile phones placed in\npockets and outside pockets. Furthermore, our acoustic-signal-based system\nachieves greater precision than wireless-signal-based approaches when contact\ntracing is performed through walls. ACOUSTIC-TURF correctly determines that\npeople on opposite sides of a wall are not in contact with one another, whereas\nthe Bluetooth-based approaches detect nonexistent contacts among them.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 22:17:36 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Luo", "Yuxiang", ""], ["Zhang", "Cheng", ""], ["Zhang", "Yunqi", ""], ["Zuo", "Chaoshun", ""], ["Xuan", "Dong", ""], ["Lin", "Zhiqiang", ""], ["Champion", "Adam C.", ""], ["Shroff", "Ness", ""]]}, {"id": "2006.13372", "submitter": "Nikita Tafintsev", "authors": "Nikita Tafintsev, Dmitri Moltchanov, Sergey Andreev, Shu-ping Yeh,\n  Nageen Himayat, Yevgeni Koucheryavy, Mikko Valkama", "title": "Handling Spontaneous Traffic Variations in 5G+ via Offloading onto\n  mmWave-Capable UAV `Bridges'", "comments": "This work has been accepted for publication in the IEEE Transactions\n  on Vehicular Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are increasingly employed for numerous public\nand civil applications, such as goods delivery, medicine, surveillance, and\ntelecommunications. For the latter, UAVs with onboard communication equipment\nmay help temporarily offload traffic onto the neighboring cells in\nfifth-generation networks and beyond (5G+). In this paper, we propose and\nevaluate the use of UAVs traveling over the area of interest to relieve\ncongestion in 5G+ systems under spontaneous traffic fluctuations. To this end,\nwe assess two inherently different offloading schemes, named routed and\ncontrolled UAV `bridging'. Using the tools of renewal theory and stochastic\ngeometry, we analytically characterize these schemes in terms of the fraction\nof traffic demand that can be offloaded onto the UAV `bridge' as our parameter\nof interest. This framework accounts for the unique features of millimeter-wave\n(mmWave) radio propagation and city deployment types with potential\nline-of-sight (LoS) link blockage by buildings. We also introduce enhancements\nto the proposed schemes that significantly improve the offloading gains. Our\nfindings offer evidence that the UAV `bridges' may be used for efficient\ntraffic offloading in various urban scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 22:59:12 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Tafintsev", "Nikita", ""], ["Moltchanov", "Dmitri", ""], ["Andreev", "Sergey", ""], ["Yeh", "Shu-ping", ""], ["Himayat", "Nageen", ""], ["Koucheryavy", "Yevgeni", ""], ["Valkama", "Mikko", ""]]}, {"id": "2006.13502", "submitter": "Deepika Rajpoot", "authors": "Deepika Rajpoot", "title": "Sensing-Throughput analysis in NOMA-based CR Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cognitive Radio (CR) network provides the solution to the spectrum\ndeficiency problem by enhancing the spectrum utilization. In recent years,\nNon-orthogonal multiple access (NOMA) has also gained significant interest in\nimproving the spectrum efficiency of 5G networks. The simultaneous wireless\ninformation and power transfer (SWIPT) is a technique for the transfer of\nwireless information and power simultaneously for the power-limited wireless\nnetworks. In this paper, we are doing a comparative analysis between the\nobtainable throughput and standard throughput with perfect cancellation in the\nSIC receiver and also developed the golden selection search algorithm to\nacquire the optimal sensing time for maximizing the throughput in NOMA based CR\nnetwork by using the SWIPT technique. In addition to the sensing time\noptimization has also simulated the throughput with the interference\nprobability in perfect and imperfect sensing case.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 06:03:47 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Rajpoot", "Deepika", ""]]}, {"id": "2006.13551", "submitter": "Lucia Cavallaro", "authors": "Lucia Cavallaro, Stefania Costantini, Pasquale De Meo, Antonio Liotta,\n  Giovanni Stilo", "title": "Network connectivity under a probabilistic node failure model", "comments": "16 pages, 36 figures, submitted to IEEE Transaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Centrality metrics have been widely applied to identify the nodes in a graph\nwhose removal is effective in decomposing the graph into smaller\nsub-components. The node--removal process is generally used to test network\nrobustness against failures. Most of the available studies assume that the node\nremoval task is always successful. Yet, we argue that this assumption is\nunrealistic. Indeed, the removal process should take into account also the\nstrength of the targeted node itself, to simulate the failure scenarios in a\nmore effective and realistic fashion. Unlike previous literature, herein a {\\em\nprobabilistic node failure model} is proposed, in which nodes may fail with a\nparticular probability, considering two variants, namely: {\\em Uniform} (in\nwhich the nodes survival-to-failure probability is fixed) and {\\em Best\nConnected} (BC) (where the nodes survival probability is proportional to their\ndegree). To evaluate our method, we consider five popular centrality metrics\ncarrying out an experimental, comparative analysis to evaluate them in terms of\n{\\em effectiveness} and {\\em coverage}, on four real-world graphs. By\neffectiveness and coverage we mean the ability of selecting nodes whose removal\ndecreases graph connectivity the most. Specifically, the graph spectral radius\nreduction works as a proxy indicator of effectiveness, and the reduction of the\nlargest connected component (LCC) size is a parameter to assess coverage. The\nmetric that caused the biggest drop has been then compared with the Benchmark\nanalysis (i.e, the non-probabilistic degree centrality node removal process) to\ncompare the two approaches. The main finding has been that significant\ndifferences emerged through this comparison with a deviation range that varies\nfrom 2\\% up to 80\\% regardless of the dataset used that highlight the existence\nof a gap between the common practice with a more realistic approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 08:17:44 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Cavallaro", "Lucia", ""], ["Costantini", "Stefania", ""], ["De Meo", "Pasquale", ""], ["Liotta", "Antonio", ""], ["Stilo", "Giovanni", ""]]}, {"id": "2006.13625", "submitter": "Muhammad Mohtasim Sajjad", "authors": "Muhammad Mohtasim Sajjad, Dhammika Jayalath, Yu-Chu Tian, and Carlos\n  J. Bernardos", "title": "On Session Continuation among Slices for Inter-Slice Mobility Support in\n  3GPP Service-based Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 3GPP has provided its first standard specifications for network slicing\nin the recent Release 15. The fundamental principles are specified which\nconstitute the standard network slicing framework. These specifications,\nhowever, lack the session continuation mechanisms among slices, which is a\nfundamental requirement to achieve inter-slice mobility. In this paper, we\npropose three solutions which enable session continuation among slices in the\ncurrent 3GPP network slicing framework. These solutions are based on existing,\nwell-established standard mechanisms. The first solution is based on the Return\nRoutability/Binding Update (RR/BU) procedure of the popular Internet standard,\nMobile IPv6 (MIPv6). The second solution is based on the 3GPP standard GPRS\nTunnelling Protocol User Plane (GTPv1-U), which establishes a GTP tunnel\nbetween previous and new slice for session continuation. The third solution is\na hybrid solution of both MIPv6-RR/BU and GTPv1-U protocols. We compare the\nperformance of all these solutions through analytical modelling. Results show\nthat the GTPv1-U based and the hybrid MIPv6/GTPv1-U promise lower service\ndisruption latency, however, incur higher resource utilization overhead and\npacket delivery costs compared to MIPv6-RR/BU and 3GPP standard PDU Session\nEstablishment process.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 11:03:23 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Sajjad", "Muhammad Mohtasim", ""], ["Jayalath", "Dhammika", ""], ["Tian", "Yu-Chu", ""], ["Bernardos", "Carlos J.", ""]]}, {"id": "2006.14058", "submitter": "Asm Rizvi", "authors": "ASM Rizvi, Joao Ceron, Leandro Bertholdo, John Heidemann", "title": "Anycast Agility: Adaptive Routing to Manage DDoS", "comments": "18 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IP Anycast is used for services such as DNS and Content Delivery Networks to\nprovide the capacity to handle Distributed Denial-of-Service (DDoS) attacks.\nDuring a DDoS attack service operators may wish to redistribute traffic between\nanycast sites to take advantage of sites with unused or greater capacity.\nDepending on site traffic and attack size, operators may instead choose to\nconcentrate attackers in a few sites to preserve operation in others.\nPreviously service operators have taken these actions during attacks, but how\nto do so has not been described publicly. This paper meets that need,\ndescribing methods to use BGP to shift traffic when under DDoS that can build a\n\"response playbook\". Operators can use this playbook, with our new method to\nestimate attack size, to respond to attacks. We also explore constraints on\nresponses seen in an anycast deployment.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 21:23:35 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Rizvi", "ASM", ""], ["Ceron", "Joao", ""], ["Bertholdo", "Leandro", ""], ["Heidemann", "John", ""]]}, {"id": "2006.14074", "submitter": "Abdul Ahad Abro", "authors": "Abdul Ahad Abro, Ufaque Shaikh", "title": "Design And Develop Network Storage Virtualization By Using GNS3", "comments": "Journal of Information & Communication Technology - JICT Vol. 13\n  Issue. 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization is an emerging and optimistic prospect in the IT industry. Its\nimpact has a footprint widely in digital infrastructure. Many innovativeness\nsectors utilized the concept of virtualization to reduce the cost of\nframeworks. In this paper, we have designed and developed storage\nvirtualization for physical functional solutions. It is an auspicious type of\nvirtualization that is accessible, secure, scalable, and manageable. In the\npaper, we have proposed the pool storage method used the RAID-Z file system\nwith the ZFS model which provides the duplication of site approach, compression\nblueprint, adequate backup methods, expansion in error-correcting techniques,\nand tested procedure on the real-time network location. Therefore, this study\nprovides useful guidelines to design and develop optimized storage\nvirtualization.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 22:15:11 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Abro", "Abdul Ahad", ""], ["Shaikh", "Ufaque", ""]]}, {"id": "2006.14166", "submitter": "Ekram Hossain", "authors": "Angelo Vera Rivera, Ahmed Refaey, and Ekram Hossain", "title": "A Blockchain Framework for Secure Task Sharing in Multi-access Edge\n  Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of Multi-access Edge Computing (MEC), the task sharing\nmechanism among edge servers is an activity of vital importance for speeding up\nthe computing process and thereby improve user experience. The distributed\nresources in the form of edge servers are expected to collaborate with each\nother in order to boost overall performance of a MEC system. However, there are\nmany challenges to adopt global collaboration among the edge computing server\nentities among which the following two are significant: ensuring trust among\nthe servers and developing a unified scheme to enable real-time collaboration\nand task sharing. In this article, a blockchain framework is proposed to\nprovide a trusted collaboration mechanism between edge servers in a MEC\nenvironment. In particular, a permissioned blockchain scheme is investigated to\nsupport a trusted design that also provides incentives for collaboration.\nFinally, Caliper tool and Hyperledger Fabric benchmarks are used to conduct an\nexperimental evaluation of the proposed blockchain scheme embedded in a MEC\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 04:24:19 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Rivera", "Angelo Vera", ""], ["Refaey", "Ahmed", ""], ["Hossain", "Ekram", ""]]}, {"id": "2006.14186", "submitter": "Soubhik Deb", "authors": "Yifan Mao, Soubhik Deb, Shaileshh Bojja Venkatakrishnan, Sreeram\n  Kannan, Kannan Srinivasan", "title": "Perigee: Efficient Peer-to-Peer Network Design for Blockchains", "comments": "Accepted at ACM PODC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MA math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key performance metric in blockchains is the latency between when a\ntransaction is broadcast and when it is confirmed (the so-called, confirmation\nlatency). While improvements in consensus techniques can lead to lower\nconfirmation latency, a fundamental lower bound on confirmation latency is the\npropagation latency of messages through the underlying peer-to-peer (p2p)\nnetwork (inBitcoin, the propagation latency is several tens of seconds). The de\nfacto p2p protocol used by Bitcoin and other blockchains is based on random\nconnectivity: each node connects to a random subset of nodes. The induced p2p\nnetwork topology can be highly suboptimal since it neglects geographical\ndistance, differences in bandwidth, hash-power and computational abilities\nacross peers. We present Perigee, a decentralized algorithm that automatically\nlearns an efficient p2p topology tuned to the aforementioned network\nheterogeneities, purely based on peers' interactions with their neighbors.\nMotivated by the literature on the multi-armed bandit problem, Perigee\noptimally balances the tradeoff between retaining connections to known\nwell-connected neighbors, and exploring new connections to previously-unseen\nneighbors. Experimental evaluations show that Perigee reduces the latency to\nbroadcast by $33\\%$. Lastly Perigee is simple, computationally lightweight,\nadversary-resistant, and compatible with the selfish interests of peers, making\nit an attractive p2p protocol for blockchains.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 05:24:11 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Mao", "Yifan", ""], ["Deb", "Soubhik", ""], ["Venkatakrishnan", "Shaileshh Bojja", ""], ["Kannan", "Sreeram", ""], ["Srinivasan", "Kannan", ""]]}, {"id": "2006.14216", "submitter": "Charitha Madapatha Mr.", "authors": "Charitha Madapatha, Behrooz Makki, Chao Fang, Oumer Teyeb, Erik\n  Dahlman, Mohamed-Slim Alouini, Tommy Svensson", "title": "On Integrated Access and Backhaul Networks: Current Status and\n  Potentials", "comments": "Revised manuscript in IEEE Open Journal of the Communications Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce and study the potentials and challenges of\nintegrated access and backhaul (IAB) as one of the promising techniques for\nevolving 5G networks. We study IAB networks from different perspectives. We\nsummarize the recent Rel-16 as well as the upcoming Rel-17 3GPP discussions on\nIAB, and highlight the main IAB-specific agreements on different protocol\nlayers. Also, concentrating on millimeter wave-based communications, we\nevaluate the performance of IAB networks in both dense and suburban areas.\nUsing a finite stochastic geometry model, with random distributions of IAB\nnodes as well as user equipments (UEs) in a finite region, we study the service\ncoverage rate defined as the probability of the event that the UEs' minimum\nrate requirements are satisfied. We present comparisons between IAB and hybrid\nIAB/fiber-backhauled networks where a part or all of the small base stations\nare fiber-connected. Finally, we study the robustness of IAB networks to\nweather and various deployment conditions and verify their effects, such as\nblockage, tree foliage, rain as well as antenna height/gain on the coverage\nrate of IAB setups, as the key differences between the fiber-connected and IAB\nnetworks. As we show, IAB is an attractive approach to enable the network\ndensification required by 5G and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 07:26:35 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 11:38:22 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Madapatha", "Charitha", ""], ["Makki", "Behrooz", ""], ["Fang", "Chao", ""], ["Teyeb", "Oumer", ""], ["Dahlman", "Erik", ""], ["Alouini", "Mohamed-Slim", ""], ["Svensson", "Tommy", ""]]}, {"id": "2006.14358", "submitter": "Ralph Holz", "authors": "Finnegan Waugh and Ralph Holz", "title": "An empirical study of availability and reliability properties of the\n  Bitcoin Lightning Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bitcoin Lightning network is a mechanism to enable fast and inexpensive\noff-chain Bitcoin transactions using peer-to-peer (P2P) channels between nodes\nthat can also be composed into a routing path. Although the resulting possible\nchannel graphs are well-studied, there is no empirical data on the network's\nreliability in terms of being able to successfully route payments at a given\nmoment in time. In this paper we address this gap and investigate two forms of\navailability that are a necessary ingredient to achieve such reliability. We\nfirst study the Lightning network's ability to route payments of various sizes\nto nearly every participating node, over most available channels. We establish\nan inverse relationship between payment volume and success rate and show that\nat best only about a third of destination nodes can be successfully reached.\nThe routing is hampered by a number of possible errors, both transient and\npermanent. We then study the availability of nodes in the network\nlongitudinally and determine how long-lived they are. Churn in the network is\nactually low, and a considerable number of nodes are hosted on cloud providers.\nBy testing node liveness, we find that the propagated network information is\nrelatively often stale, however, both for IP addresses and Tor onion addresses.\nWe provide recommendations how the Lightning network can be improved, including\nconsiderations which trade-offs between privacy and decentralization on the one\nhand and reliability on the other hand should at least be reconsidered by the\ncommunity developing the Lightning network.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 12:57:55 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Waugh", "Finnegan", ""], ["Holz", "Ralph", ""]]}, {"id": "2006.14413", "submitter": "Kashif Inayat", "authors": "S.M. Usman Hashmi, Muntazir Hussain, Fahad Bin Muslim, Kashif Inayat\n  and Seong Oun Hwang", "title": "Implementation of Symbol Timing Recovery for Estimation of Clock Skew", "comments": null, "journal-ref": "International Journal of Internet Technology and Secured\n  Transactions (2020):\n  https://www.inderscience.com/info/ingeneral/forthcoming.php?jcode=ijitst", "doi": "10.1504/IJITST.2020.10033615", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time synchronization in any distributed network can be achieved by using\napplication layer protocols for time correction. Time synchronization method\nproposed in this article uses symbol timing recovery at the physical layer to\ncorrect application layer clock. This cross layer methodology diminishes the\nquantity of message trades needed by application layer for time synchronization\nthus resulting in energy saving. Precision of skew estimate can be increased by\nusing multiple message exchanges. Examination of the cross layer strategy\nincluding the simulation results, the experimentation outcomes and mathematical\nanalysis demonstrates that clock skew at physical layer is same as of\napplication layer, which is actually the skew of hardware clock within the\nnode.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 13:51:41 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Hashmi", "S. M. Usman", ""], ["Hussain", "Muntazir", ""], ["Muslim", "Fahad Bin", ""], ["Inayat", "Kashif", ""], ["Hwang", "Seong Oun", ""]]}, {"id": "2006.14513", "submitter": "Jiejun Hu", "authors": "Jiejun Hu, Martin Reed, Mays Al-Naday, Nikolaos Thomos", "title": "Blockchain-Aided Flow Insertion and Verification in Software Defined\n  Networks", "comments": "9 pages, 6 figures, published in Global Internet of Things Summit\n  2020", "journal-ref": null, "doi": "10.1109/GIOTS49054.2020.9119638", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) connected by Software Defined Networking (SDN)\npromises to bring great benefits to cyber-physical systems. However, the\nincreased attack surface offered by the growing number of connected vulnerable\ndevices and complex nature of SDN control plane applications could overturn the\nhuge benefits of such a system. This paper addresses the vulnerability of some\nunspecified security flaw in the SDN control plane application (such as a\nzero-day software vulnerability) which can be exploited to insert malicious\nflow rules in the switch that do not match network policies. Specifically, we\npropose a blockchain-as-a-service (BaaS) based framework that supports switch\nflow verification and insertion; and additionally provides straightforward\ndeployment of blockchain technology within an existing SDN infrastructure.\nWhile use of an external BaaS brings straightforward deployment, it obscures\nknowledge of the blockchain agents who are responsible for flow conformance\ntesting through a smart blockchain contract, leading to potential exploitation.\nThus, we design a strategy to prevent the blockchain agents from acting\narbitrarily, as this would result in what is termed a \"moral hazard\". We\nachieve this by developing a novel mathematical model of the fair reward scheme\nbased on game theory. To understand the performance of our system, we evaluate\nour model using a Matlab based simulation framework. The simulation results\ndemonstrate that the proposed algorithm balances the needs of the blockchain\nagents to maximise the overall social welfare, i.e. the sum of profits across\nall parties.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 16:06:19 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Hu", "Jiejun", ""], ["Reed", "Martin", ""], ["Al-Naday", "Mays", ""], ["Thomos", "Nikolaos", ""]]}, {"id": "2006.14576", "submitter": "Yi Shi", "authors": "Yi Shi, Kemal Davaslioglu, Yalin E. Sagduyu", "title": "Over-the-Air Membership Inference Attacks as Privacy Threats for Deep\n  Learning-based Wireless Signal Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents how to leak private information from a wireless signal\nclassifier by launching an over-the-air membership inference attack (MIA). As\nmachine learning (ML) algorithms are used to process wireless signals to make\ndecisions such as PHY-layer authentication, the training data characteristics\n(e.g., device-level information) and the environment conditions (e.g., channel\ninformation) under which the data is collected may leak to the ML model. As a\nprivacy threat, the adversary can use this leaked information to exploit\nvulnerabilities of the ML model following an adversarial ML approach. In this\npaper, the MIA is launched against a deep learning-based classifier that uses\nwaveform, device, and channel characteristics (power and phase shifts) in the\nreceived signals for RF fingerprinting. By observing the spectrum, the\nadversary builds first a surrogate classifier and then an inference model to\ndetermine whether a signal of interest has been used in the training data of\nthe receiver (e.g., a service provider). The signal of interest can then be\nassociated with particular device and channel characteristics to launch\nsubsequent attacks. The probability of attack success is high (more than 88%\ndepending on waveform and channel conditions) in identifying signals of\ninterest (and potentially the device and channel information) used to build a\ntarget classifier. These results show that wireless signal classifiers are\nvulnerable to privacy threats due to the over-the-air information leakage of\ntheir ML models\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 17:23:32 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Shi", "Yi", ""], ["Davaslioglu", "Kemal", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "2006.14659", "submitter": "Jaafar Elmirghani", "authors": "Amal A. Alahmadi, T. E. H. El-Gorashi, and Jaafar M. H. Elmirghani", "title": "Energy Efficient Processing Allocation in Opportunistic\n  Cloud-Fog-Vehicular Edge Cloud Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates distributed processing in Vehicular Edge Cloud\n(VECs), where a group of vehicles in a car park, at a charging station or at a\nroad traffic intersection, cluster and form a temporary vehicular cloud by\ncombining their computational resources in the cluster. We investigated the\nproblem of energy efficient processing task allocation in VEC by developing a\nMixed Integer Linear Programming (MILP) model to minimize power consumption by\noptimizing the allocation of different processing tasks to the available\nnetwork resources, cloud resources, fog resources and vehicular processing\nnodes resources. Three dimensions of processing allocation were investigated.\nThe first dimension compared centralized processing (in the central cloud) to\ndistributed processing (in the multi-layer fog nodes). The second dimension\nintroduced opportunistic processing in the vehicular nodes with low and high\nvehicular node density. The third dimension considered non-splittable tasks\n(single allocation) versus splittable tasks (distributed allocation),\nrepresenting real-time versus non real-time applications respectively. The\nresults revealed that a power savings up to 70% can be achieved by allocating\nprocessing to the vehicles. However, many factors have an impact on the power\nsaving such the vehicle processing capacities, vehicles density, workload size,\nand the number of generated tasks. It was observed that the power saving is\nimproved by exploiting the flexibility offered by task splitting among the\navailable vehicles.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 18:52:29 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Alahmadi", "Amal A.", ""], ["El-Gorashi", "T. E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2006.14884", "submitter": "Jizhou Li", "authors": "Tong Yang, Jizhou Li, Yikai Zhao, Kaicheng Yang, Hao Wang, Jie Jiang,\n  Yinda Zhang, Nicholas Zhang", "title": "QCluster: Clustering Packets for FlowScheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow scheduling is crucial in data centers, as it directly influences user\nexperience of applications. According to different assumptions and design\ngoals, there are four typical flow scheduling problems/solutions: SRPT, LAS,\nFair Queueing, and Deadline-Aware scheduling. When implementing these solutions\nin commodity switches with limited number of queues, they need to set static\nparameters by measuring traffic in advance, while optimal parameters vary\nacross time and space. This paper proposes a generic framework, namely\nQCluster, to adapt all scheduling problems for limited number of queues. The\nkey idea of QCluster is to cluster packets with similar weights/properties into\nthe same queue. QCluster is implemented in Tofino switches, and can cluster\npackets at a speed of 3.2 Tbps. To the best of our knowledge, QCluster is the\nfastest clustering algorithm. Experimental results in testbed with programmable\nswitches and ns-2 show that QCluster reduces the average flow completion time\n(FCT) for short flows up to 56.6%, and reduces the overall average FCT up to\n21.7% over state-of-the-art. All the source code is available in Github.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 09:38:43 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Yang", "Tong", ""], ["Li", "Jizhou", ""], ["Zhao", "Yikai", ""], ["Yang", "Kaicheng", ""], ["Wang", "Hao", ""], ["Jiang", "Jie", ""], ["Zhang", "Yinda", ""], ["Zhang", "Nicholas", ""]]}, {"id": "2006.15182", "submitter": "Mahshid Rahnamay-Naeini", "authors": "Ehsan Siavashi and Mahshid Rahnamay-Naeini", "title": "Dynamic Constraint-based Influence Framework and its Application in\n  Stochastic Modeling of Load Balancing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Components connected over a network influence each other and interact in\nvarious ways. Examples of such systems are networks of computing nodes, which\nthe nodes interact by exchanging workload, for instance, for load balancing\npurposes. In this paper, we first study the Influence Model, a networked Markov\nchain framework, for modeling network interactions and discuss two key\nlimitations of this model, which cause it to fall short in modeling\nconstraint-based and dynamic interactions in networks. Next, we propose the\nDynamic and Constraint-based Influence Model (DCIM) to alleviate the\nlimitations. The DCIM extends the application of the Influence Model to more\ngeneral network interaction scenarios. In this paper, the proposed DCIM is\nsuccessfully applied to stochastic modeling of load balancing in networks of\ncomputing nodes allowing for prediction of the load distribution in the system,\nwhich is a novel application for the Influence Model. The DCIM is further used\nto identify the optimum workload distribution policy for load balancing in\nnetworked computing systems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 19:17:49 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Siavashi", "Ehsan", ""], ["Rahnamay-Naeini", "Mahshid", ""]]}, {"id": "2006.15270", "submitter": "Kallol Krishna Karmakar", "authors": "Vijay Varadharajan and Uday Tupakula and Kallol Karmakar", "title": "Software Enabled Security Architecture and Mechanisms for Securing 5G\n  Network Services", "comments": "20 Pages. Submitted to Esorics 2020 (Under Review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 5G network systems are evolving and have complex network infrastructures.\nThere is a great deal of work in this area focused on meeting the stringent\nservice requirements for the 5G networks. Within this context, security\nrequirements play a critical role as 5G networks can support a range of\nservices such as healthcare services, financial and critical infrastructures.\n3GPP and ETSI have been developing security frameworks for 5G networks. Our\nwork in 5G security has been focusing on the design of security architecture\nand mechanisms enabling dynamic establishment of secure and trusted end to end\nservices as well as development of mechanisms to proactively detect and\nmitigate security attacks in virtualised network infrastructures. The focus of\nthis paper is on the latter, namely the facilities and mechanisms, and the\ndesign of a security architecture providing facilities and mechanisms to detect\nand mitigate specific security attacks. We have developed and implemented a\nsimplified version of the security architecture using Software Defined Networks\n(SDN) and Network Function Virtualisation (NFV) technologies. The specific\nsecurity functions developed in this architecture can be directly integrated\ninto the 5G core network facilities enhancing its security. We describe the\ndesign and implementation of the security architecture and demonstrate how it\ncan efficiently mitigate specific types of attacks.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 03:38:16 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Varadharajan", "Vijay", ""], ["Tupakula", "Uday", ""], ["Karmakar", "Kallol", ""]]}, {"id": "2006.15277", "submitter": "Aminollah Khormali", "authors": "Aminollah Khormali, Jeman Park, Hisham Alasmary, Afsah Anwar, David\n  Mohaisen", "title": "Domain Name System Security and Privacy: A Contemporary Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain name system (DNS) is one of the most important components of\ntoday's Internet, and is the standard naming convention between human-readable\ndomain names and machine-routable IP addresses of Internet resources. However,\ndue to the vulnerability of DNS to various threats, its security and\nfunctionality have been continuously challenged over the course of time.\nAlthough, researchers have addressed various aspects of the DNS in the\nliterature, there are still many challenges yet to be addressed. In order to\ncomprehensively understand the root causes of the vulnerabilities of DNS, it is\nmandatory to review the various activities in the research community on DNS\nlandscape. To this end, this paper surveys more than 170 peer-reviewed papers,\nwhich are published in both top conferences and journals in the last ten years,\nand summarizes vulnerabilities in DNS and corresponding countermeasures. This\npaper not only focuses on the DNS threat landscape and existing challenges, but\nalso discusses the utilized data analysis methods, which are frequently used to\naddress DNS threat vulnerabilities. Furthermore, we looked into the DNSthreat\nlandscape from the viewpoint of the involved entities in the DNS infrastructure\nin an attempt to point out more vulnerable entities in the system.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 04:04:43 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Khormali", "Aminollah", ""], ["Park", "Jeman", ""], ["Alasmary", "Hisham", ""], ["Anwar", "Afsah", ""], ["Mohaisen", "David", ""]]}, {"id": "2006.15342", "submitter": "Alaa Awad Abdellatif", "authors": "Alaa Awad Abdellatif, Lutfi Samara, Amr Mohamed, Mohsen Guizani, Aiman\n  Erbad, and Abdulla Al-Ali", "title": "Compress or Interfere?", "comments": null, "journal-ref": null, "doi": "10.1109/SAHCN.2019.8824824", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid evolution of wireless medical devices and network technologies has\nfostered the growth of remote monitoring systems. Such new technologies enable\nmonitoring patients' medical records anytime and anywhere without limiting\npatients' activities. However, critical challenges have emerged with remote\nmonitoring systems due to the enormous amount of generated data that need to be\nefficiently processed and wirelessly transmitted to the service providers in\ntime. Thus, in this paper, we leverage full-duplex capabilities for fast\ntransmission, while tackling the trade-off between Quality of Service (QoS)\nrequirements and consequent self-interference (SI) for efficient remote\nmonitoring healthcare systems. The proposed framework jointly considers the\nresidual SI resulting from simultaneous transmission and reception along with\nthe compressibility feature of medical data in order to optimize the data\ntransmission over wireless channels, while maintaining the application's QoS\nconstraint. Our simulation results demonstrate the efficiency of the proposed\nsolution in terms of minimizing the transmission power, residual\nself-interference, and encoding distortion.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 11:37:08 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Abdellatif", "Alaa Awad", ""], ["Samara", "Lutfi", ""], ["Mohamed", "Amr", ""], ["Guizani", "Mohsen", ""], ["Erbad", "Aiman", ""], ["Al-Ali", "Abdulla", ""]]}, {"id": "2006.15382", "submitter": "Bo Yang", "authors": "Bo Yang, Xuelin Cao, Xiangfang Li, Chau Yuen, and Lijun Qian", "title": "Lessons Learned from Accident of Autonomous Vehicle Testing: An Edge\n  Learning-aided Offloading Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter proposes an edge learning-based offloading framework for\nautonomous driving, where the deep learning tasks can be offloaded to the edge\nserver to improve the inference accuracy while meeting the latency constraint.\nSince the delay and the inference accuracy are incurred by wireless\ncommunications and computing, an optimization problem is formulated to maximize\nthe inference accuracy subject to the offloading probability, the pre-braking\nprobability, and data quality. Simulations demonstrate the superiority of the\nproposed offloading framework.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 15:21:00 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Yang", "Bo", ""], ["Cao", "Xuelin", ""], ["Li", "Xiangfang", ""], ["Yuen", "Chau", ""], ["Qian", "Lijun", ""]]}, {"id": "2006.15514", "submitter": "Behnam Dezfouli", "authors": "Jaykumar Sheth, Cyrus Miremadi, Amir Dezfouli, and Behnam Dezfouli", "title": "EAPS: Edge-Assisted Predictive Sleep Scheduling for 802.11 IoT Stations", "comments": null, "journal-ref": null, "doi": null, "report-no": "SIOTLAB-TECHREP-J272020", "categories": "cs.NI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broad deployment of 802.11 (a.k.a., WiFi) access points and significant\nenhancement of the energy efficiency of these wireless transceivers has\nresulted in increasing interest in building 802.11-based IoT systems.\nUnfortunately, the main energy efficiency mechanisms of 802.11, namely PSM and\nAPSD, fall short when used in IoT applications. PSM increases latency and\nintensifies channel access contention after each beacon instance, and APSD does\nnot inform stations about when they need to wake up to receive their downlink\npackets. In this paper, we present a new mechanism---edge-assisted predictive\nsleep scheduling (EAPS)---to adjust the sleep duration of stations while they\nexpect downlink packets. We first implement a Linux-based access point that\nenables us to collect parameters affecting communication latency. Using this\naccess point, we build a testbed that, in addition to offering traffic pattern\ncustomization, replicates the characteristics of real-world environments. We\nthen use multiple machine learning algorithms to predict downlink packet\ndelivery. Our empirical evaluations confirm that when using EAPS the energy\nconsumption of IoT stations is as low as PSM, whereas the delay of packet\ndelivery is close to the case where the station is always awake.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 05:10:42 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Sheth", "Jaykumar", ""], ["Miremadi", "Cyrus", ""], ["Dezfouli", "Amir", ""], ["Dezfouli", "Behnam", ""]]}, {"id": "2006.15598", "submitter": "A. Nezih Kasim", "authors": "A. Nezih Kasim", "title": "A Survey Mobility Management in 5G Networks", "comments": "6 pages, 2 figures, pre-print, survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the next wireless communication systems, the major challenges are to\nprovide ubiquitous wireless access abilities and maintain the quality of\nservice and seamless mobility management for mobile communication devices in\nheterogeneous networks. Due to the rapid growth of mobile users, this demand\nbecomes more challenging where the users always require seamless connectivity\nwhile they move to other places at any time. As the number of users increases,\nthe network load also increases, the handover process needs to be performed in\nan efficient way. However, in many situations, the handover blocking, and\nunnecessary handover frequently happens, then affect the network and reduces\nits performance. The problem arises with the movement of mobile users between\nbase stations while the link connectivity becomes weaker and the mobile node\ntries to switch to another base station to have a better link quality during a\ncall for higher QoS (Quality of Service). In this survey, it is aimed to gather\ntogether the studies that help to improve mobility management processes in 5G\n(Fifth Generation) cellular networks.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 13:24:58 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Kasim", "A. Nezih", ""]]}, {"id": "2006.15751", "submitter": "Meng Zhang", "authors": "Meng Zhang, Ahmed Arafa, Ermin Wei, and Randall A. Berry", "title": "Optimal and Quantized Mechanism Design for Fresh Data Acquisition", "comments": "Under review by IEEE JSAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of real-time applications has spurred much interest in data\nfreshness, captured by the {\\it age-of-information} (AoI) metric. When\nstrategic data sources have private market information, a fundamental economic\nchallenge is how to incentivize them to acquire fresh data and optimize the\nage-related performance. In this work, we consider an information update system\nin which a destination acquires, and pays for, fresh data updates from multiple\nsources. The destination incurs an age-related cost, modeled as a general\nincreasing function of the AoI. Each source is strategic and incurs a sampling\ncost, which is its private information and may not be truthfully reported to\nthe destination. The destination decides on the price of updates, when to get\nthem, and who should generate them, based on the sources' reported sampling\ncosts. We show that a benchmark that naively trusts the sources' reports can\nlead to an arbitrarily bad outcome compared to the case where sources\ntruthfully report. To tackle this issue, we design an optimal (economic)\nmechanism for timely information acquisition following Myerson's seminal work.\nTo this end, our proposed optimal mechanism minimizes the sum of the\ndestination's age-related cost and its payment to the sources, while ensuring\nthat the sources truthfully report their private information and will\nvoluntarily participate in the mechanism. However, finding the optimal\nmechanisms may suffer from \\textit{prohibitively expensive computational\noverheads} as it involves solving a nonlinear infinite-dimensional optimization\nproblem. We further propose a quantized version of the optimal mechanism that\nachieves asymptotic optimality, maintains the other economic properties, and\nenables one to tradeoff between optimality and computational overheads.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 00:05:39 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 16:34:45 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 22:25:07 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 22:36:40 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhang", "Meng", ""], ["Arafa", "Ahmed", ""], ["Wei", "Ermin", ""], ["Berry", "Randall A.", ""]]}, {"id": "2006.15756", "submitter": "Bo Zhou", "authors": "Bo Zhou, Walid Saad", "title": "Age of Information in Ultra-Dense IoT Systems: Performance and\n  Mean-Field Game Analysis", "comments": "Fixed typos in Equations (4) and (7). 30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a dense Internet of Things (IoT) monitoring system is\nconsidered in which a large number of IoT devices contend for channel access so\nas to transmit timely status updates to the corresponding receivers using a\ncarrier sense multiple access (CSMA) scheme. Under two packet management\nschemes with and without preemption in service, the closed-form expressions of\nthe average age of information (AoI) and the average peak AoI of each device is\ncharacterized. It is shown that the scheme with preemption in service always\nleads to a smaller average AoI and a smaller average peak AoI, compared to the\nscheme without preemption in service. Then, a distributed noncooperative medium\naccess control game is formulated in which each device optimizes its waiting\nrate so as to minimize its average AoI or average peak AoI under an average\nenergy cost constraint on channel sensing and packet transmitting. To overcome\nthe challenges of solving this game for an ultra-dense IoT, a mean-field game\n(MFG) approach is proposed to study the asymptotic performance of each device\nfor the system in the large population regime. The accuracy of the MFG is\nanalyzed, and the existence, uniqueness, and convergence of the mean-field\nequilibrium (MFE) are investigated. Simulation results show that the proposed\nMFG is accurate even for a small number of devices; and the proposed CSMA-type\nscheme under the MFG analysis outperforms two baseline schemes with fixed and\ndynamic waiting rates, with the average AoI reductions reaching up to 22% and\n34%, respectively. Moreover, it is observed that the average AoI and the\naverage peak AoI under the MFE do not necessarily decrease with the arrival\nrate.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 00:37:18 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 02:30:16 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 04:07:06 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Zhou", "Bo", ""], ["Saad", "Walid", ""]]}, {"id": "2006.15782", "submitter": "Shahzad Shahzad", "authors": "Shahzad and Eun-Sung Jung", "title": "Flexible IoT Datapath Programming using P4", "comments": "Conference: ICGHIT 2019, Malaysia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The progress of the network and device technologies enables any device to be\nconnected to the Internet thereby forming an Internet of Things (IoT)\narchitecture. Internet-related activities based on the IoT services can\ninevitably generate a lot of real-time data which leads a big data phenomenon.\nTo efficiently handle such big IoT data, software-defined networking (SDN)\ntechniques could come into play. Among SDN techniques, P4 is a highlevel\nlanguage for programming protocol-independent packet processors. This paper\npresents our preliminary work on how we can use P4 to achieve flexible datapath\nprogramming for large scale IoT streaming data streaming. As a case study, we\ndescribe the implementation of dynamic MST-based datapath programing for IoT\ndata collection in an arbitrary network topology.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 02:54:05 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Shahzad", "", ""], ["Jung", "Eun-Sung", ""]]}, {"id": "2006.15827", "submitter": "Tianbo Gu", "authors": "Tianbo Gu, Zheng Fang, Allaukik Abhishek, Hao Fu, Pengfei Hu, Prasant\n  Mohapatra", "title": "IoTGaze: IoT Security Enforcement via Wireless Context Analysis", "comments": "9 pages, 11 figures, 3 tables, to appear in the IEEE International\n  Conference on Computer Communications (IEEE INFOCOM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) has become the most promising technology for service\nautomation, monitoring, and interconnection, etc. However, the security and\nprivacy issues caused by IoT arouse concerns. Recent research focuses on\naddressing security issues by looking inside platform and apps. In this work,\nwe creatively change the angle to consider security problems from a wireless\ncontext perspective. We propose a novel framework called IoTGaze, which can\ndiscover potential anomalies and vulnerabilities in the IoT system via wireless\ntraffic analysis. By sniffing the encrypted wireless traffic, IoTGaze can\nautomatically identify the sequential interaction of events between apps and\ndevices. We discover the temporal event dependencies and generate the Wireless\nContext for the IoT system. Meanwhile, we extract the IoT Context, which\nreflects user's expectation, from IoT apps' descriptions and user interfaces.\nIf the wireless context does not match the expected IoT context, IoTGaze\nreports an anomaly. Furthermore, IoTGaze can discover the vulnerabilities\ncaused by the inter-app interaction via hidden channels, such as temperature\nand illuminance. We provide a proof-of-concept implementation and evaluation of\nour framework on the Samsung SmartThings platform. The evaluation shows that\nIoTGaze can effectively discover anomalies and vulnerabilities, thereby greatly\nenhancing the security of IoT systems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 06:14:06 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Gu", "Tianbo", ""], ["Fang", "Zheng", ""], ["Abhishek", "Allaukik", ""], ["Fu", "Hao", ""], ["Hu", "Pengfei", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2006.15832", "submitter": "Linshan Jiang", "authors": "Linshan Jiang, Rui Tan, Arvind Easwaran", "title": "Resilience Bounds of Network Clock Synchronization with Fault Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) will be a main data generation infrastructure\nfor achieving better system intelligence. This paper considers the design and\nimplementation of a practical privacy-preserving collaborative learning scheme,\nin which a curious learning coordinator trains a better machine learning model\nbased on the data samples contributed by a number of IoT objects, while the\nconfidentiality of the raw forms of the training data is protected against the\ncoordinator. Existing distributed machine learning and data encryption\napproaches incur significant computation and communication overhead, rendering\nthem ill-suited for resource-constrained IoT objects. We study an approach that\napplies independent random projection at each IoT object to obfuscate data and\ntrains a deep neural network at the coordinator based on the projected data\nfrom the IoT objects. This approach introduces light computation overhead to\nthe IoT objects and moves most workload to the coordinator that can have\nsufficient computing resources. Although the independent projections performed\nby the IoT objects address the potential collusion between the curious\ncoordinator and some compromised IoT objects, they significantly increase the\ncomplexity of the projected data. In this paper, we leverage the superior\nlearning capability of deep learning in capturing sophisticated patterns to\nmaintain good learning performance. Extensive comparative evaluation shows that\nthis approach outperforms other lightweight approaches that apply additive\nnoisification for differential privacy and/or support vector machines for\nlearning in the applications with light to moderate data pattern complexities.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 06:41:24 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Jiang", "Linshan", ""], ["Tan", "Rui", ""], ["Easwaran", "Arvind", ""]]}, {"id": "2006.15855", "submitter": "Kai Xiong", "authors": "Kai Xiong, Supeng Leng, Chongwen Huang, Chau Yuen, Liang Guan", "title": "Intelligent Task Offloading for Heterogeneous V2X Communications", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of autonomous driving technologies, it becomes\ndifficult to reconcile the conflict between ever-increasing demands for high\nprocess rate in the intelligent automotive tasks and resource-constrained\non-board processors. Fortunately, vehicular edge computing (VEC) has been\nproposed to meet the pressing resource demands. Due to the delay-sensitive\ntraits of automotive tasks, only a heterogeneous vehicular network with\nmultiple access technologies may be able to handle these demanding challenges.\nIn this paper, we propose an intelligent task offloading framework in\nheterogeneous vehicular networks with three Vehicle-to-Everything (V2X)\ncommunication technologies, namely Dedicated Short Range Communication (DSRC),\ncellular-based V2X (C-V2X) communication, and millimeter wave (mmWave)\ncommunication. Based on stochastic network calculus, this paper firstly derives\nthe delay upper bound of different offloading technologies with a certain\nfailure probability. Moreover, we propose a federated Q-learning method that\noptimally utilizes the available resources to minimize the\ncommunication/computing budgets and the offloading failure probabilities.\nSimulation results indicate that our proposed algorithm can significantly\noutperform the existing algorithms in terms of offloading failure probability\nand resource cost.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 07:58:22 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Xiong", "Kai", ""], ["Leng", "Supeng", ""], ["Huang", "Chongwen", ""], ["Yuen", "Chau", ""], ["Guan", "Liang", ""]]}, {"id": "2006.15875", "submitter": "Kai Xiong", "authors": "Kai Xiong, Supeng Leng, Xiaosha Chen, Chongwen Huang, Chau Yuen, Yong\n  Liang Guan", "title": "Communication and Computing Resource Optimization for Connected\n  Autonomous Driving", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation system is facing a sharp disruption since the Connected\nAutonomous Vehicles (CAVs) can free people from driving and provide good\ndriving experience with the aid of Vehicle-to-Vehicle (V2V) communications.\nAlthough CAVs bring benefits in terms of driving safety, vehicle string\nstability, and road traffic throughput, most existing work aims at improving\nonly one of these performance metrics. However, these metrics may be mutually\ncompetitive, as they share the same communication and computing resource in a\nroad segment. From the perspective of joint optimizing driving safety, vehicle\nstring stability, and road traffic throughput, there is a big research gap to\nbe filled on the resource management for connected autonomous driving. In this\npaper, we first explore the joint optimization on driving safety, vehicle\nstring stability, and road traffic throughput by leveraging on the consensus\nAlternating Directions Method of Multipliers algorithm (ADMM). However, the\nlimited communication bandwidth and on-board processing capacity incur the\nresource competition in CAVs. We next analyze the multiple tasks competition in\nthe contention based medium access to attain the upper bound delay of\nV2V-related application offloading. An efficient sleeping multi-armed bandit\ntree-based algorithm is proposed to address the resource assignment problem. A\nseries of simulation experiments are carried out to validate the performance of\nthe proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 08:56:53 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Xiong", "Kai", ""], ["Leng", "Supeng", ""], ["Chen", "Xiaosha", ""], ["Huang", "Chongwen", ""], ["Yuen", "Chau", ""], ["Guan", "Yong Liang", ""]]}, {"id": "2006.15888", "submitter": "Lorenzo Mucchi", "authors": "Dania Marabissi, Lorenzo Mucchi, Stefano Caputo, Francesca Nizzi,\n  Tommaso Pecorella, Romano Fantacci, Tassadaq Nawaz, Marco Seminara, Jacopo\n  Catani", "title": "Experimental measurements of a joint 5G-VLC communication for future\n  vehicular networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main revolutionary features of 5G networks is the ultra-low\nlatency that will enable new services such as those for the future smart\nvehicles. The 5G technology will be able to support extreme-low latency. Thanks\nto new technologies and the wide flexible architecture that integrates new\nspectra and access technologies. In particular, Visible Light Communication\n(VLC) is envisaged as a very promising technology for vehicular communications,\nsince the information can flow by using the lights (as traffic-lights and car\nlights). This paper describes one of the first experiments on the joint use of\n5G and VLC networks to provide real-time information to cars. The applications\nspan from road safety to emergency alarm.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 09:29:02 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Marabissi", "Dania", ""], ["Mucchi", "Lorenzo", ""], ["Caputo", "Stefano", ""], ["Nizzi", "Francesca", ""], ["Pecorella", "Tommaso", ""], ["Fantacci", "Romano", ""], ["Nawaz", "Tassadaq", ""], ["Seminara", "Marco", ""], ["Catani", "Jacopo", ""]]}, {"id": "2006.16368", "submitter": "Majid Raeis", "authors": "Majid Raeis, Ali Tizghadam, Alberto Leon-Garcia", "title": "Probabilistic Bounds on the End-to-End Delay of Service Function Chains\n  using Deep MDN", "comments": "7 pages, to be presented at IEEE PIMRC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring the conformance of a service system's end-to-end delay to service\nlevel agreement (SLA) constraints is a challenging task that requires\nstatistical measures beyond the average delay. In this paper, we study the\nreal-time prediction of the end-to-end delay distribution in systems with\ncomposite services such as service function chains. In order to have a general\nframework, we use queueing theory to model service systems, while also adopting\na statistical learning approach to avoid the limitations of queueing-theoretic\nmethods such as stationarity assumptions or other approximations that are often\nused to make the analysis mathematically tractable. Specifically, we use deep\nmixture density networks (MDN) to predict the end-to-end distribution of the\ndelay given the network's state. As a result, our method is sufficiently\ngeneral to be applied in different contexts and applications. Our evaluations\nshow a good match between the learned distributions and the simulations, which\nsuggest that the proposed method is a good candidate for providing\nprobabilistic bounds on the end-to-end delay of more complex systems where\nsimulations or theoretical methods are not applicable.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:45:52 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Raeis", "Majid", ""], ["Tizghadam", "Ali", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "2006.16441", "submitter": "Mohsin Ur Rahman", "authors": "Mohsin Ur Rahman", "title": "Investigating the Effects of Mobility Metrics in Mobile Ad Hoc Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Ad Hoc Networks (MANETs) are formed by a collection of mobile nodes\n(MNs) that are capable of moving from one location to another location. These\nnetworks are widely identified by their unique characteristics such as lack of\ninfrastructure, mobility and multi-hop communication. Unlike traditional\n(wired) networks, MNs in MANETs do not rely on any infrastructure or central\nmanagement. Mobility allows MNs to move at different values of speed. Multi-hop\ncommunication is used to deliver data across the entire network. Due to\nmobility and changing network topology, the performance of these networks is\nsignificantly affected by the choice of mobility models and routing protocols.\nOur research work aims to evaluate the effects of mobility metrics on\ndistinguishing between entity and group mobility models in MANETs. In addition,\nwe demonstrate the interactions between mobility metrics and performance\nmetrics. We also investigate how effective are the mobility metrics and which\nmetrics can clearly distinguish between entity and group mobility models?\n  We performed extensive simulations using network simulator, ns-2.35, to\ncapture mobility metrics as well as different performance metrics. Simulation\nresults reveal the efficiency of mobility metrics on distinguishing between\nentity and group mobility models. We also obtain useful interactions between\nmobility metrics and performance metrics. The results presented in this paper\nprovide new insights into the variability of mobility metrics in MANETs.\nFurthermore, our simulation results reveal better understanding of the\nrelationships between mobility metrics (e.g., relative speed, node degree,\nnetwork partitions etc.) and performance metrics (e.g., packet delivery ratio,\nend-to-end delay and normalized routing load\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 00:25:18 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Rahman", "Mohsin Ur", ""]]}, {"id": "2006.16534", "submitter": "Gaurang Naik", "authors": "Gaurang Naik, Jung-Min Park, Jonathan Ashdown, William Lehr", "title": "Next Generation Wi-Fi and 5G NR-U in the 6 GHz Bands: Opportunities &\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing demand for unlicensed spectrum has prompted regulators in\nthe US and Europe to consider opening up the 6 GHz bands for unlicensed access.\nThese bands will open up 1.2 GHz of additional spectrum for unlicensed radio\naccess technologies (RATs), such as Wi-Fi and 5G New Radio Unlicensed (NR-U),\nin the US and if permitted, 500 MHz of additional spectrum in Europe. The\nabundance of spectrum in these bands creates new opportunities for the design\nof mechanisms and features that can support the emerging bandwidth-intensive\nand latency-sensitive applications. However, coexistence of unlicensed devices\nboth with the bands' incumbent users and across different unlicensed RATs\npresent significant challenges. In this paper, we provide a comprehensive\nsurvey of the existing literature on various issues surrounding the operations\nof unlicensed RATs in the 6 GHz bands. In particular, we discuss how key\nfeatures in next-generation Wi-Fi are being designed to leverage these\nadditional unlicensed bands. We also shed light on the foreseeable challenges\nthat designers of unlicensed RATs might face in the near future. Our survey\nencompasses key research papers, contributions submitted to standardization\nbodies and regulatory agencies, and documents presented at various other\nvenues. Finally, we highlight a few key research problems that are likely to\narise due to unlicensed operations in the 6 GHz bands. Tackling these research\nchallenges effectively will be critical in ensuring that the new unlicensed\nbands are efficiently utilized while guaranteeing the interference-free\noperation of the bands' incumbent users.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 05:13:54 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 03:37:08 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Naik", "Gaurang", ""], ["Park", "Jung-Min", ""], ["Ashdown", "Jonathan", ""], ["Lehr", "William", ""]]}, {"id": "2006.16771", "submitter": "Tarik A. Rashid", "authors": "Godar J. Ibrahim, Tarik A. Rashid, Mobayode O. Akinsolu", "title": "An energy efficient service composition mechanism using a hybrid\n  meta-heuristic algorithm in a mobile cloud environment", "comments": "23 pages, Accepted. Journal of Parallel and Distributed Computing,\n  2020", "journal-ref": null, "doi": "10.1016/j.jpdc.2020.05.002", "report-no": null, "categories": "cs.NI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  By increasing mobile devices in technology and human life, using a runtime\nand mobile services has gotten more complex along with the composition of a\nlarge number of atomic services. Different services are provided by mobile\ncloud components to represent the non-functional properties as Quality of\nService (QoS), which is applied by a set of standards. On the other hand, the\ngrowth of the energy-source heterogeneity in mobile clouds is an emerging\nchallenge according to the energy-saving problem in mobile nodes. To mobile\ncloud service composition as an NP-Hard problem, an efficient selection method\nshould be taken by problem using optimal energy-aware methods that can extend\nthe deployment and interoperability of mobile cloud components. Also, an\nenergy-aware service composition mechanism is required to preserve high energy\nsaving scenarios for mobile cloud components. In this paper, an energy-aware\nmechanism is applied to optimize mobile cloud service composition using a\nhybrid Shuffled Frog Leaping Algorithm and Genetic Algorithm (SFGA).\nExperimental results capture that the proposed mechanism improves the\nfeasibility of the service composition with minimum energy consumption,\nresponse time, and cost for mobile cloud components against some current\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 21:38:55 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ibrahim", "Godar J.", ""], ["Rashid", "Tarik A.", ""], ["Akinsolu", "Mobayode O.", ""]]}, {"id": "2006.16805", "submitter": "Meng Zhang", "authors": "Meng Zhang, Ahmed Arafa, Jianwei Huang, and H. Vincent Poor", "title": "Pricing Fresh Data", "comments": "Published in IEEE JSAC. arXiv admin note: text overlap with\n  arXiv:1904.06899", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of {\\it fresh data trading}, in which a destination\nuser requests, and pays for, fresh data updates from a source provider, and\ndata freshness is captured by the {\\it age of information} (AoI) metric.\nKeeping data fresh relies on frequent data updates by the source, which\nmotivates the source to {\\it price fresh data}. In this work, the destination\nincurs an age-related cost, modeled as a general increasing function of the\nAoI. The source designs a pricing mechanism to maximize its profit; the\ndestination chooses a data update schedule to trade off its payments to the\nsource and its age-related cost. Depending on different real-time applications\nand scenarios, we study both a predictable-deadline and an\nunpredictable-deadline models. The key challenge of designing the optimal\npricing scheme lies in the destination's time-interdependent valuations, due to\nthe nature of AoI and the infinite-dimensional and dynamic optimization. To\nthis end, we consider three pricing schemes that exploit and understand the\nprofitability of three different dimensions in designing pricing: a {\\it\ntime-dependent} pricing scheme, in which the price for each update depends on\nwhen it is requested; a {\\it quantity-based} pricing scheme, in which the price\nof each update depends on how many updates have been previously requested; a\n{\\it subscription-based} pricing scheme, in which the price for each update is\nflat-rate but the source charges an additional subscription fee. Our analysis\nreveals that the optimal subscription-based pricing maximizes the source's\nprofit among all possible pricing schemes under both predictable deadline and\nunpredictable deadline models; the optimal quantity-based pricing scheme is\nonly optimal with a predictable deadline; the time-dependent pricing scheme,\nunder the unpredictable deadline, is asymptotically optimal under significant\ntime discounting.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 23:51:59 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 04:03:18 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 05:05:36 GMT"}, {"version": "v4", "created": "Sun, 2 May 2021 03:45:12 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Zhang", "Meng", ""], ["Arafa", "Ahmed", ""], ["Huang", "Jianwei", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2006.16811", "submitter": "Zheng Ma", "authors": "Zheng Ma, Junyu Xuan, Yu Guang Wang, Ming Li, Pietro Lio", "title": "Path Integral Based Convolution and Pooling for Graph Neural Networks", "comments": "15 pages, 4 figures, 6 tables. arXiv admin note: text overlap with\n  arXiv:1904.10996", "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.NI physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) extends the functionality of traditional neural\nnetworks to graph-structured data. Similar to CNNs, an optimized design of\ngraph convolution and pooling is key to success. Borrowing ideas from physics,\nwe propose a path integral based graph neural networks (PAN) for classification\nand regression tasks on graphs. Specifically, we consider a convolution\noperation that involves every path linking the message sender and receiver with\nlearnable weights depending on the path length, which corresponds to the\nmaximal entropy random walk. It generalizes the graph Laplacian to a new\ntransition matrix we call maximal entropy transition (MET) matrix derived from\na path integral formalism. Importantly, the diagonal entries of the MET matrix\nare directly related to the subgraph centrality, thus providing a natural and\nadaptive pooling mechanism. PAN provides a versatile framework that can be\ntailored for different graph data with varying sizes and structures. We can\nview most existing GNN architectures as special cases of PAN. Experimental\nresults show that PAN achieves state-of-the-art performance on various graph\nclassification/regression tasks, including a new benchmark dataset from\nstatistical mechanics we propose to boost applications of GNN in physical\nsciences.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 16:20:33 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 15:03:01 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ma", "Zheng", ""], ["Xuan", "Junyu", ""], ["Wang", "Yu Guang", ""], ["Li", "Ming", ""], ["Lio", "Pietro", ""]]}, {"id": "2006.16860", "submitter": "Sabah Al-Fedaghi Dr.", "authors": "Sabah Al-Fedaghi and Bader Behbehani", "title": "How to Document Computer Networks", "comments": "14 pages, 9 figures", "journal-ref": "Journal of Computer Science, 16 (6), 723-434, June, 2020", "doi": "10.3844/jcssp.2020.723.434", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Documenting networks is an essential tool for troubleshooting network\nproblems. The documentation details a network's structure and context, serves\nas a reference and makes network management more effective. Complex network\ndiagrams are hard to document and maintain and are not guaranteed to reflect\nreality. They contain many superficial icons (e.g., wall, screen and tower).\nDefining a single coherent network architecture and topology, similar to\nengineering schematics, has received great interest. We propose a fundamental\napproach for methodically specifying a network architecture using a diagramming\nmethod to conceptualize the network s structure. The method is called a\nthinging (abstract) machine, through which the network world is viewed as a\nsingle unifying element called the thing/machine (thimac), providing the\nontology for modeling the network. To test its viability, the\nthinging-machine-based methodology was applied to an existing computer network\nto produce a single integrated, diagrammatic representation that incorporates\ncommunication, software and hardware. The resultant description shows a viable,\ncoherent depiction that can replace the current methods.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 11:14:27 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Al-Fedaghi", "Sabah", ""], ["Behbehani", "Bader", ""]]}, {"id": "2006.16863", "submitter": "Jan Dvorak", "authors": "Jan Dvo\\v{r}\\'ak, Martin Heller, Zden\\v{e}k Hanz\\'alek", "title": "Makespan minimization of Time-Triggered traffic on a TTEthernet network", "comments": null, "journal-ref": null, "doi": "10.1109/WFCS.2017.7991955.", "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The reliability of the increasing number of modern applications and systems\nstrongly depends on interconnecting technology. Complex systems which usually\nneed to exchange, among other things, multimedia data together with\nsafety-related information, as in the automotive or avionic industry, for\nexample, make demands on both the high bandwidth and the deterministic behavior\nof the communication. TTEthernet is a protocol that has been developed to face\nthese requirements while providing the generous bandwidth of Ethernet up to\n1\\,Gbit/s and enhancing its determinism by the Time-Triggered message\ntransmission which follows the predetermined schedule. Therefore, synthesizing\na good schedule which meets all the real-time requirements is essential for the\nperformance of the whole system.\n  In this paper, we study the concept of creating the communication schedules\nfor the Time-Triggered traffic while minimizing its makespan. The aim is to\nmaximize the uninterrupted gap for remaining traffic classes in each\nintegration cycle. The provided scheduling algorithm, based on the\nResource-Constrained Project Scheduling Problem formulation and the load\nbalancing heuristic, obtains near-optimal (within 15\\% of non-tight lower\nbound) solutions in 5 minutes even for industrial sized instances. The\nuniversality of the provided method allows easily modify or extend the problem\nstatement according to particular industrial demands. Finally, the studied\nconcept of makespan minimization is justified through the concept of scheduling\nwith porosity according to the worst-case delay analysis of Event-Triggered\ntraffic.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 12:04:40 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Dvo\u0159\u00e1k", "Jan", ""], ["Heller", "Martin", ""], ["Hanz\u00e1lek", "Zden\u011bk", ""]]}, {"id": "2006.16864", "submitter": "Junaid Shuja Dr.", "authors": "Junaid Shuja, Kashif Bilal, Waleed Alasmary, Hassan Sinky, Eisa\n  Alanazi", "title": "Applying Machine Learning Techniques for Caching in Edge Networks: A\n  Comprehensive Survey", "comments": "This is the updated article submitted for publication", "journal-ref": "Journal of Network and Computer Applications,2021,103005", "doi": "10.1016/j.jnca.2021.103005", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge networking is a complex and dynamic computing paradigm that aims to push\ncloud resources closer to the end user improving responsiveness and reducing\nbackhaul traffic. User mobility, preferences, and content popularity are the\ndominant dynamic features of edge networks. Temporal and social features of\ncontent, such as the number of views and likes are leveraged to estimate the\npopularity of content from a global perspective. However, such estimates should\nnot be mapped to an edge network with particular social and geographic\ncharacteristics. In next generation edge networks, i.e., 5G and beyond 5G,\nmachine learning techniques can be applied to predict content popularity based\non user preferences, cluster users based on similar content interests, and\noptimize cache placement and replacement strategies provided a set of\nconstraints and predictions about the state of the network. These applications\nof machine learning can help identify relevant content for an edge network.\nThis article investigates the application of machine learning techniques for\nin-network caching in edge networks. We survey recent state-of-the-art\nliterature and formulate a comprehensive taxonomy based on (a) machine learning\ntechnique (method, objective, and features), (b) caching strategy (policy,\nlocation, and replacement), and (c) edge network (type and delivery strategy).\nA comparative analysis of the state-of-the-art literature is presented with\nrespect to the parameters identified in the taxonomy. Moreover, we debate\nresearch challenges and future directions for optimal caching decisions and the\napplication of machine learning in edge networks.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 09:31:56 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 10:17:52 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 07:10:46 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 18:05:37 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Shuja", "Junaid", ""], ["Bilal", "Kashif", ""], ["Alasmary", "Waleed", ""], ["Sinky", "Hassan", ""], ["Alanazi", "Eisa", ""]]}, {"id": "2006.16894", "submitter": "Muhammad Junaid Farooq", "authors": "Muhammad Junaid Farooq and Quanyan Zhu", "title": "QoE Based Revenue Maximizing Dynamic Resource Allocation and Pricing for\n  Fog-Enabled Mission-Critical IoT Applications", "comments": "IEEE Transactions on Mobile Computing 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog computing is becoming a vital component for Internet of things (IoT)\napplications, acting as its computational engine. Mission-critical IoT\napplications are highly sensitive to latency, which depends on the physical\nlocation of the cloud server. Fog nodes of varying response rates are available\nto the cloud service provider (CSP) and it is faced with a challenge of\nforwarding the sequentially received IoT data to one of the fog nodes for\nprocessing. Since the arrival times and nature of requests is random, it is\nimportant to optimally classify the requests in real-time and allocate\navailable virtual machine instances (VMIs) at the fog nodes to provide a high\nQoE to the users and consequently generate higher revenues for the CSP. In this\npaper, we use a pricing policy based on the QoE of the applications as a result\nof the allocation and obtain an optimal dynamic allocation rule based on the\nstatistical information of the computational requests. The developed solution\nis statistically optimal, dynamic, and implementable in real-time as opposed to\nother static matching schemes in the literature. The performance of the\nproposed framework has been evaluated using simulations and the results show\nsignificant improvement as compared with benchmark schemes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 05:33:59 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Farooq", "Muhammad Junaid", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2006.16895", "submitter": "Peter Hillmann", "authors": "Peter Hillmann and Lars Stiemert and Gabi Dreo Rodosek and Oliver Rose", "title": "Dragoon: Advanced Modelling of IP Geolocation by use of Latency\n  Measurements", "comments": "International Conference for Internet Technology and Secured\n  Transactions 2015. arXiv admin note: substantial text overlap with\n  arXiv:2004.07836, arXiv:2004.01531", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IP Geolocation is a key enabler for many areas of application like\ndetermination of an attack origin, targeted advertisement, and Content Delivery\nNetworks. Although IP Geolocation is an ongoing field of research for over one\ndecade, it is still a challenging task, whereas good results are only achieved\nby the use of active latency measurements. Nevertheless, an increased accuracy\nis needed to improve service quality. This paper presents an novel approach to\nfind optimized Landmark positions which are used for active probing. Since a\nreasonable Landmark selection is important for a highly accurate localization\nservice, the goal is to find Landmarks close to the target with respect to the\ninfrastructure and hop count. Furthermore, we introduce a new approach of an\nadaptable and more accurate mathematical modelling of an improved geographical\nlocation estimation process. Current techniques provide less information about\nsolving the Landmark problem as well as are using imprecise models. We\ndemonstrate the usability of our approach in a real-world environment and\nanalyse Geolocation for the first time in Europe. The combination of an\noptimized Landmark selection and advanced modulation results in an improved\naccuracy of IP Geolocation.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:22:46 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Hillmann", "Peter", ""], ["Stiemert", "Lars", ""], ["Rodosek", "Gabi Dreo", ""], ["Rose", "Oliver", ""]]}, {"id": "2006.16896", "submitter": "Anika Schwind", "authors": "Tobias Ho{\\ss}feld, Stefan Wunderer, Andr\\'e Beyer, Andrew Hall, Anika\n  Schwind, Christian Gassner, Fabrice Guillemin, Florian Wamser, Krzysztof\n  Wascinski, Matthias Hirth, Michael Seufert, Pedro Casas, Phuoc Tran-Gia,\n  Werner Robitza, Wojciech Wascinski, Zied Ben Houidi", "title": "White Paper on Crowdsourced Network and QoE Measurements -- Definitions,\n  Use Cases and Challenges", "comments": null, "journal-ref": null, "doi": "10.25972/OPUS-20232", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This white paper is the outcome of the W\\\"urzburg seminar on \"Crowdsourced\nNetwork and QoE Measurements\" which took place from 25-26 September 2019 in\nW\\\"urzburg, Germany. International experts were invited from industry and\nacademia. They are well known in their communities, having different\nbackgrounds in crowdsourcing, mobile networks, network measurements, network\nperformance, Quality of Service (QoS), and Quality of Experience (QoE). The\ndiscussions in the seminar focused on how crowdsourcing will support vendors,\noperators, and regulators to determine the Quality of Experience in new 5G\nnetworks that enable various new applications and network architectures. As a\nresult of the discussions, the need for a white paper manifested, with the goal\nof providing a scientific discussion of the terms \"crowdsourced network\nmeasurements\" and \"crowdsourced QoE measurements\", describing relevant use\ncases for such crowdsourced data, and its underlying challenges. During the\nseminar, those main topics were identified, intensively discussed in break-out\ngroups, and brought back into the plenum several times. The outcome of the\nseminar is this white paper at hand which is - to our knowledge - the first one\ncovering the topic of crowdsourced network and QoE measurements.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:59:12 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ho\u00dffeld", "Tobias", ""], ["Wunderer", "Stefan", ""], ["Beyer", "Andr\u00e9", ""], ["Hall", "Andrew", ""], ["Schwind", "Anika", ""], ["Gassner", "Christian", ""], ["Guillemin", "Fabrice", ""], ["Wamser", "Florian", ""], ["Wascinski", "Krzysztof", ""], ["Hirth", "Matthias", ""], ["Seufert", "Michael", ""], ["Casas", "Pedro", ""], ["Tran-Gia", "Phuoc", ""], ["Robitza", "Werner", ""], ["Wascinski", "Wojciech", ""], ["Houidi", "Zied Ben", ""]]}, {"id": "2006.16921", "submitter": "Jiska Classen", "authors": "J\\\"orn Tillmanns, Jiska Classen, Felix Rohrbach, Matthias Hollick", "title": "Firmware Insider: Bluetooth Randomness is Mostly Random", "comments": "WOOT'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bluetooth chips must include a Random Number Generator (RNG). This RNG is\nused internally within cryptographic primitives but also exposed to the\noperating system for chip-external applications. In general, it is a black box\nwith security-critical authentication and encryption mechanisms depending on\nit. In this paper, we evaluate the quality of RNGs in various Broadcom and\nCypress Bluetooth chips. We find that the RNG implementation significantly\nchanged over the last decade. Moreover, most devices implement an insecure\nPseudo-Random Number Generator (PRNG) fallback. Multiple popular devices, such\nas the Samsung Galaxy S8 and its variants as well as an iPhone, rely on the\nweak fallback due to missing a Hardware Random Number Generator (HRNG). We\nstatistically evaluate the output of various HRNGs in chips used by hundreds of\nmillions of devices. While the Broadcom and Cypress HRNGs pass advanced tests,\nit remains indistinguishable for users if a Bluetooth chip implements a secure\nRNG without an extensive analysis as in this paper. We describe our measurement\nmethods and publish our tools to enable further public testing.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 15:51:39 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Tillmanns", "J\u00f6rn", ""], ["Classen", "Jiska", ""], ["Rohrbach", "Felix", ""], ["Hollick", "Matthias", ""]]}, {"id": "2006.16993", "submitter": "Nick Feamster", "authors": "Kun Yang, Samory Kpotufe, Nick Feamster", "title": "Feature Extraction for Novelty Detection in Network Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data representation plays a critical role in the performance of novelty\ndetection (or ``anomaly detection'') methods in machine learning. The data\nrepresentation of network traffic often determines the effectiveness of these\nmodels as much as the model itself. The wide range of novel events that network\noperators need to detect (e.g., attacks, malware, new applications, changes in\ntraffic demands) introduces the possibility for a broad range of possible\nmodels and data representations. In each scenario, practitioners must spend\nsignificant effort extracting and engineering features that are most predictive\nfor that situation or application. While anomaly detection is well-studied in\ncomputer networking, much existing work develops specific models that presume a\nparticular representation -- often IPFIX/NetFlow. Yet, other representations\nmay result in higher model accuracy, and the rise of programmable networks now\nmakes it more practical to explore a broader range of representations. To\nfacilitate such exploration, we develop a systematic framework, open-source\ntoolkit, and public Python library that makes it both possible and easy to\nextract and generate features from network traffic and perform and end-to-end\nevaluation of these representations across most prevalent modern novelty\ndetection models. We first develop and publicly release an open-source tool, an\naccompanying Python library (NetML), and end-to-end pipeline for novelty\ndetection in network traffic. Second, we apply this tool to five different\nnovelty detection problems in networking, across a range of scenarios from\nattack detection to novel device detection. Our findings general insights and\nguidelines concerning which features appear to be more appropriate for\nparticular situations.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 17:53:59 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 15:58:34 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Yang", "Kun", ""], ["Kpotufe", "Samory", ""], ["Feamster", "Nick", ""]]}]