[{"id": "2104.00075", "submitter": "Mehdi Naderi Soorki", "authors": "Mehdi Naderi Soorki, Walid Saad, Mehdi Bennis, Choong Seon Hong", "title": "Ultra-Reliable Indoor Millimeter Wave Communications using Multiple\n  Artificial Intelligence-Powered Intelligent Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a novel framework for guaranteeing ultra-reliable millimeter\nwave (mmW) communications using multiple artificial intelligence (AI)-enabled\nreconfigurable intelligent surfaces (RISs) is proposed. The use of multiple\nAI-powered RISs allows changing the propagation direction of the signals\ntransmitted from a mmW access point (AP) thereby improving coverage\nparticularly for non-line-of-sight (NLoS) areas. However, due to the\npossibility of highly stochastic blockage over mmW links, designing an\nintelligent controller to jointly optimize the mmW AP beam and RIS phase shifts\nis a daunting task. In this regard, first, a parametric risk-sensitive episodic\nreturn is proposed to maximize the expected bit rate and mitigate the risk of\nmmW link blockage. Then, a closed-form approximation of the policy gradient of\nthe risk-sensitive episodic return is analytically derived. Next, the problem\nof joint beamforming for mmW AP and phase shift control for mmW RISs is modeled\nas an identical payoff stochastic game within a cooperative multi-agent\nenvironment, in which the agents are the mmW AP and the RISs. Two centralized\nand distributed controllers are proposed to control the policies of the mmW AP\nand RISs. To directly find an optimal solution, the parametric functional-form\npolicies for these controllers are modeled using deep recurrent neural networks\n(RNNs). Simulation results show that the error between policies of the optimal\nand the RNN-based controllers is less than 1.5%. Moreover, the variance of the\nachievable rates resulting from the deep RNN-based controllers is 60% less than\nthe variance of the risk-averse baseline.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 19:15:49 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Soorki", "Mehdi Naderi", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2104.00352", "submitter": "Akihito Taya", "authors": "Akihito Taya, Takayuki Nishio, Masahiro Morikura, Koji Yamamoto", "title": "Decentralized and Model-Free Federated Learning: Consensus-Based\n  Distillation in Function Space", "comments": "submitted to IEEE TSIPN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a decentralized FL scheme for IoE devices connected via\nmulti-hop networks. FL has gained attention as an enabler of privacy-preserving\nalgorithms, but it is not guaranteed that FL algorithms converge to the optimal\npoint because of non-convexity when using decentralized parameter averaging\nschemes. Therefore, a distributed algorithm that converges to the optimal\nsolution should be developed. The key idea of the proposed algorithm is to\naggregate the local prediction functions, not in a parameter space but in a\nfunction space. Since machine learning tasks can be regarded as convex\nfunctional optimization problems, a consensus-based optimization algorithm\nachieves the global optimum if it is tailored to work in a function space. This\npaper at first analyzes the convergence of the proposed algorithm in a function\nspace, which is referred to as a meta-algorithm. It is shown that spectral\ngraph theory can be applied to the function space in a similar manner as that\nof numerical vectors. Then, a CMFD is developed for NN as an implementation of\nthe meta-algorithm. CMFD leverages knowledge distillation to realize function\naggregation among adjacent devices without parameter averaging. One of the\nadvantages of CMFD is that it works even when NN models are different among the\ndistributed learners. This paper shows that CMFD achieves higher accuracy than\nparameter aggregation under weakly-connected networks. The stability of CMFD is\nalso higher than that of parameter aggregation methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 09:17:20 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 09:32:12 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Taya", "Akihito", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""], ["Yamamoto", "Koji", ""]]}, {"id": "2104.00475", "submitter": "Meysam Nasimi", "authors": "Meysam Nasimi, Mohammad Asif Habibi, Bin Han, Hans D. Schotten", "title": "Edge-Assisted Congestion Control Mechanism for 5G Network Using\n  Software-Defined Networking", "comments": "This paper presented in International Symposium on Wireless\n  Communication Systems (ISWCS 2018)", "journal-ref": null, "doi": "10.1109/ISWCS.2018.8491233", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to cope with the explosive growth of data traffic which is\nassociated with a wide plethora of emerging applications and services that are\nexpected to be used by both ordinary users and vertical industries, the\ncongestion control mechanism is considered to be vital. In this paper, we\nproposed a congestion control mechanism that could function within the\nframework of Multi-Access Edge Computing (MEC). The proposed mechanism is\naiming to make real-time decisions for selectively buffering traffic while\ntaking network condition and Quality of Service (QoS) into consideration. In\norder to support a MEC-assisted scheme, the MEC server is expected to locally\nstore delay-tolerant data traffics until the delay conditions expire. This\nenables the network to have better control over the radio resource provisioning\nof higher priority data. To achieve this, we introduced a dedicated function\nknown as Congestion Control Engine (CCE), which can capture Radio Access\nNetwork (RAN) condition through Radio Network Information Service (RNIS)\nfunction, and use this knowledge to make the real-time decision for selectively\noffloading traffic so that it can perform more intelligently. Analytical\nevaluation results of our proposed mechanism confirm that it can alleviate\nnetwork congestion more efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 14:04:43 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Nasimi", "Meysam", ""], ["Habibi", "Mohammad Asif", ""], ["Han", "Bin", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2104.00508", "submitter": "Valmir C. Barbosa", "authors": "Raphael M. Guedes, Jos\\'e F. de Rezende, Valmir C. Barbosa", "title": "Integrated optimization of heterogeneous-network management and the\n  elusive role of macrocells", "comments": "This version updates metadata", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider heterogeneous wireless networks in the physical interference\nmodel and introduce a new formulation of the mixed-integer nonlinear\nprogramming problem that addresses base-station activation and many-to-many\nassociations while minimizing power consumption. We also introduce HetNetGA, a\ngenetic algorithm that can tackle the problem without any approximations.\nThough unsuitable for practical deployment, HetNetGA enables the investigation\nof such networks' true possibilities. Results for scenarios involving both\nmacrocells and picocells often align with what is expected, but sometimes are\nunexpected and essentially point to the need to better understand the role of\nmacrocells in helping provide capacity while remaining energetically\nadvantageous.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 15:06:48 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 12:44:05 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 11:25:39 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Guedes", "Raphael M.", ""], ["de Rezende", "Jos\u00e9 F.", ""], ["Barbosa", "Valmir C.", ""]]}, {"id": "2104.00632", "submitter": "AKM Bahalul Haque", "authors": "Tahmid Hasan Pranto, Abdulla All Noman, Atik Mahmud and AKM Bahalul\n  Haque", "title": "Blockchain and smart contract for IoT enabled smart agriculture", "comments": null, "journal-ref": "PeerJ Computer Science, 2021", "doi": "10.7717/peerj-cs.407", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The agricultural sector is still lagging behind from all other sectors in\nterms of using the newest technologies. For production, the latest machines are\nbeing introduced and adopted. However, pre-harvest and post-harvest processing\nare still done by following traditional methodologies while tracing, storing,\nand publishing agricultural data. As a result, farmers are not getting deserved\npayment, consumers are not getting enough information before buying their\nproduct, and intermediate person/processors are increasing retail prices. Using\nblockchain, smart contracts, and IoT devices, we can fully automate the process\nwhile establishing absolute trust among all these parties. In this research, we\nexplored the different aspects of using blockchain and smart contracts with the\nintegration of IoT devices in pre-harvesting and post-harvesting segments of\nagriculture. We proposed a system that uses blockchain as the backbone while\nIoT devices collect data from the field level, and smart contracts regulate the\ninteraction among all these contributing parties. The system implementation has\nbeen shown in diagrams and with proper explanations. Gas costs of every\noperation have also been attached for a better understanding of the costs. We\nalso analyzed the system in terms of challenges and advantages. The overall\nimpact of this research was to show the immutable, available, transparent, and\nrobustly secure characteristics of blockchain in the field of agriculture while\nalso emphasizing the vigorous mechanism that the collaboration of blockchain,\nsmart contract, and IoT presents.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:26:09 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Pranto", "Tahmid Hasan", ""], ["Noman", "Abdulla All", ""], ["Mahmud", "Atik", ""], ["Haque", "AKM Bahalul", ""]]}, {"id": "2104.00735", "submitter": "K\\\"ur\\c{s}at Tekb{\\i}y{\\i}k", "authors": "K\\\"ur\\c{s}at Tekb{\\i}y{\\i}k, G\\\"une\\c{s} Karabulut Kurt, Ali R{\\i}za\n  Ekti, Halim Yanikomeroglu", "title": "Graph Attention Networks for Channel Estimation in RIS-assisted\n  Satellite IoT Communications", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Direct-to-satellite (DtS) communication has gained importance recently to\nsupport globally connected Internet of things (IoT) networks. However,\nrelatively long distances of densely deployed satellite networks around the\nEarth cause a high path loss. In addition, since high complexity operations\nsuch as beamforming, tracking and equalization have to be performed in IoT\ndevices partially, both the hardware complexity and the need for high-capacity\nbatteries of IoT devices increase. The reconfigurable intelligent surfaces\n(RISs) have the potential to increase the energy-efficiency and to perform\ncomplex signal processing over the transmission environment instead of IoT\ndevices. But, RISs need the information of the cascaded channel in order to\nchange the phase of the incident signal. This study proposes graph attention\nnetworks (GATs) for the challenging channel estimation problem and examines the\nperformance of DtS IoT networks for different RIS configurations under GAT\nchannel estimation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 19:15:04 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Tekb\u0131y\u0131k", "K\u00fcr\u015fat", ""], ["Kurt", "G\u00fcne\u015f Karabulut", ""], ["Ekti", "Ali R\u0131za", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "2104.00959", "submitter": "Pavlos Sermpezis", "authors": "Theodoros Giannakas, Pavlos Sermpezis, Anastasios Giovanidis,\n  Thrasyvoulos Spyropoulos, George Arvanitakis", "title": "Fairness in Network-Friendly Recommendations", "comments": "IEEE International Symposium on a World of Wireless, Mobile and\n  Multimedia Networks (WoWMoM), 2021", "journal-ref": "IEEE International Symposium on a World of Wireless, Mobile and\n  Multimedia Networks (WoWMoM), Jun 2021, Pisa (virtual), Italy", "doi": "10.1109/WoWMoM51794.2021.00020", "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As mobile traffic is dominated by content services (e.g., video), which\ntypically use recommendation systems, the paradigm of network-friendly\nrecommendations (NFR) has been proposed recently to boost the network\nperformance by promoting content that can be efficiently delivered (e.g.,\ncached at the edge). NFR increase the network performance, however, at the cost\nof being unfair towards certain contents when compared to the standard\nrecommendations. This unfairness is a side effect of NFR that has not been\nstudied in literature. Nevertheless, retaining fairness among contents is a key\noperational requirement for content providers. This paper is the first to study\nthe fairness in NFR, and design fair-NFR. Specifically, we use a set of metrics\nthat capture different notions of fairness, and study the unfairness created by\nexisting NFR schemes. Our analysis reveals that NFR can be significantly\nunfair. We identify an inherent trade-off between the network gains achieved by\nNFR and the resulting unfairness, and derive bounds for this trade-off. We show\nthat existing NFR schemes frequently operate far from the bounds, i.e., there\nis room for improvement. To this end, we formulate the design of Fair-NFR\n(i.e., NFR with fairness guarantees compared to the baseline recommendations)\nas a linear optimization problem. Our results show that the Fair-NFR can\nachieve high network gains (similar to non-fair-NFR) with little unfairness.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 09:50:39 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Giannakas", "Theodoros", ""], ["Sermpezis", "Pavlos", ""], ["Giovanidis", "Anastasios", ""], ["Spyropoulos", "Thrasyvoulos", ""], ["Arvanitakis", "George", ""]]}, {"id": "2104.00972", "submitter": "Bla\\v{z} Bertalani\\v{c}", "authors": "Blaz Bertalanic, Marko Meza and Carolina Fortuna", "title": "Time Series Imaging for Link Layer Anomaly Classification in Wireless\n  Networks", "comments": "10 pages, 3 figures, 18 subfigures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of end devices that use the last mile wireless connectivity is\ndramatically increasing with the rise of smart infrastructures and require\nreliable functioning to support smooth and efficient business processes. To\nefficiently manage such massive wireless networks, more advanced and accurate\nnetwork monitoring and malfunction detection solutions are required. In this\npaper, we perform a first time analysis of image-based representation\ntechniques for wireless anomaly detection using recurrence plots and Gramian\nangular fields and propose a new deep learning architecture enabling accurate\nanomaly detection. We examine the relative performance of the proposed model\nand show that the image transformation of time series improves the performance\nof anomaly detection by up to 29% for binary classification and by up to 27%\nfor multiclass classification. At the same time, the best performing model\nbased on recurrence plot transformation leads to up to 55% increase compared to\nthe state of the art where classical machine learning techniques are used. We\nalso provide insights for the decisions of the classifier using an instance\nbased approach enabled by insights into guided back-propagation. Our results\ndemonstrate the potential of transformation of time series signals to images to\nimprove classification performance compared to classification on raw time\nseries data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 10:23:06 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Bertalanic", "Blaz", ""], ["Meza", "Marko", ""], ["Fortuna", "Carolina", ""]]}, {"id": "2104.01036", "submitter": "Chong Zheng", "authors": "Chong Zheng and Shengheng Liu and Yongming Huang and Luxi Yang", "title": "Hybrid Policy Learning for Energy-Latency Tradeoff in MEC-Assisted VR\n  Video Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual reality (VR) is promising to fundamentally transform a broad spectrum\nof industry sectors and the way humans interact with virtual content. However,\ndespite unprecedented progress, current networking and computing\ninfrastructures are incompetent to unlock VR's full potential. In this paper,\nwe consider delivering the wireless multi-tile VR video service over a mobile\nedge computing (MEC) network. The primary goal is to minimize the system\nlatency/energy consumption and to arrive at a tradeoff thereof. To this end, we\nfirst cast the time-varying view popularity as a model-free Markov chain to\neffectively capture its dynamic characteristics. After jointly assessing the\ncaching and computing capacities on both the MEC server and the VR playback\ndevice, a hybrid policy is then implemented to coordinate the dynamic caching\nreplacement and the deterministic offloading, so as to fully utilize the system\nresources. The underlying multi-objective problem is reformulated as a\npartially observable Markov decision process, and a deep deterministic policy\ngradient algorithm is proposed to iteratively learn its solution, where a long\nshort-term memory neural network is embedded to continuously predict the\ndynamics of the unobservable popularity. Simulation results demonstrate the\nsuperiority of the proposed scheme in achieving a trade-off between the energy\nefficiency and the latency reduction over the baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 13:17:11 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Zheng", "Chong", ""], ["Liu", "Shengheng", ""], ["Huang", "Yongming", ""], ["Yang", "Luxi", ""]]}, {"id": "2104.01104", "submitter": "Yanyuan Qin", "authors": "Yanyuan Qin", "title": "Adaptive Bitrate Streaming Over Cellular Networks: Rate Adaptation and\n  Data Savings Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Adaptive bitrate streaming (ABR) has become thede factotechnique for\nvideostreaming over the Internet. Despite a flurry of techniques, achieving\nhigh quality ABRstreaming over cellular networks remains a tremendous\nchallenge. First, the design ofan ABR scheme needs to balance conflicting\nQuality of Experience (QoE) metrics suchas video quality, quality changes,\nstalls and startup performance, which is even harderunder highly dynamic\nbandwidth in cellular network. Second, streaming providers havebeen moving\ntowards using Variable Bitrate (VBR) encodings for the video content,which\nintroduces new challenges for ABR streaming, whose nature and implicationsare\nlittle understood. Third, mobile video streaming consumes a lot of data.\nAlthoughmany video and network providers currently offer data saving options,\nthe existingpractices are suboptimal in QoE and resource usage. Last, when the\naudio and videotracks are stored separately, video and audio rate adaptation\nneeds to be dynamicallycoordinated to achieve good overall streaming\nexperience, which presents interestingchallenges while, somewhat surprisingly,\nhas received little attention by the researchcommunity. In this dissertation,\nwe tackle each of the above four challenges.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 15:56:00 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 20:48:51 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Qin", "Yanyuan", ""]]}, {"id": "2104.01192", "submitter": "Tevfik Kosar", "authors": "Lavone Rodolph, MD S Q Zulkar Nine, Luigi Di Tacchio, Tevfik Kosar", "title": "Energy-saving Cross-layer Optimization of Big Data Transfer Based on\n  Historical Log Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the proliferation of data movement across the Internet, global data\ntraffic per year has already exceeded the Zettabyte scale. The network\ninfrastructure and end-systems facilitating the vast data movement consume an\nextensive amount of electricity, measured in terawatt-hours per year. This\nmassive energy footprint costs the world economy billions of dollars partially\ndue to energy consumed at the network end-systems. Although extensive research\nhas been done on managing power consumption within the core networking\ninfrastructure, there is little research on reducing the power consumption at\nthe end-systems during active data transfers. This paper presents a novel\ncross-layer optimization framework, called Cross-LayerHLA, to minimize energy\nconsumption at the end-systems by applying machine learning techniques to\nhistorical transfer logs and extracting the hidden relationships between\ndifferent parameters affecting both the performance and resource utilization.\nIt utilizes offline analysis to improve online learning and dynamic tuning of\napplication-level and kernel-level parameters with minimal overhead. This\napproach minimizes end-system energy consumption and maximizes data transfer\nthroughput. Our experimental results show that Cross-LayerHLA outperforms other\nstate-of-the-art solutions in this area.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 18:33:08 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Rodolph", "Lavone", ""], ["Nine", "MD S Q Zulkar", ""], ["Di Tacchio", "Luigi", ""], ["Kosar", "Tevfik", ""]]}, {"id": "2104.01283", "submitter": "Arnau Rovira Sugranes", "authors": "Arnau Rovira-Sugranes, Fatemeh Afghah, Jacob Chakareski, Abolfazl Razi", "title": "A Review of AI-enabled Routing Protocols for UAV Networks: Trends,\n  Challenges, and Future Outlook", "comments": "30 pages, 8 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs), as a recently emerging technology, enabled a\nnew breed of unprecedented applications in different domains. This technology's\nongoing trend is departing from large remotely-controlled drones to networks of\nsmall autonomous drones to collectively complete intricate tasks time and\ncost-effectively. An important challenge is developing efficient sensing,\ncommunication, and control algorithms that can accommodate the requirements of\nhighly dynamic UAV networks with heterogeneous mobility levels. Recently, the\nuse of Artificial Intelligence (AI) in learning-based networking has gained\nmomentum to harness the learning power of cognizant nodes to make more\nintelligent networking decisions. An important example of this trend is\ndeveloping learning-powered routing protocols, where machine learning methods\nare used to model and predict topology evolution, channel status, traffic\nmobility, and environmental factors for enhanced routing.\n  This paper reviews AI-enabled routing protocols designed primarily for aerial\nnetworks, with an emphasis on accommodating highly-dynamic network topology. To\nthis end, we review the basics of UAV technology, different approaches to swarm\nformation, and commonly-used mobility models, along with their impact on\nnetworking paradigms. We proceed with reviewing conventional and AI-enabled\nrouting protocols, including topology-predictive and self-adaptive\nlearning-based routing algorithms. We also discuss tools, simulation\nenvironments, remote experimentation platforms, and public datasets that can be\nused for developing and testing AI-enabled networking protocols for UAV\nnetworks. We conclude by presenting future trends, and the remaining challenges\nin AI-based UAV Networking, for different aspects of routing, connectivity,\ntopology control, security and privacy, energy efficiency, and spectrum\nsharing.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 00:15:34 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Rovira-Sugranes", "Arnau", ""], ["Afghah", "Fatemeh", ""], ["Chakareski", "Jacob", ""], ["Razi", "Abolfazl", ""]]}, {"id": "2104.01355", "submitter": "Ermin Sakic", "authors": "Ermin Sakic, Petra Vizarreta, Wolfgang Kellerer", "title": "SEER: Performance-Aware Leader Election in Single-Leader Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern stateful web services and distributed SDN controllers rely on log\nreplication to omit data loss in case of fail-stop failures. In single-leader\nexecution, the leader replica is responsible for ordering log updates and the\ninitiation of distributed commits, in order to guarantee log consistency.\nNetwork congestions, resource-heavy computation, and imbalanced resource\nallocations may, however, result in inappropriate leader election and increased\ncluster response times.\n  We present SEER, a logically centralized approach to performance prediction\nand efficient leader election in leader-based consensus systems. SEER\nautonomously identifies the replica that minimizes the average cluster response\ntime, using prediction models trained dynamically at runtime. To balance the\nexploration and exploitation, SEER explores replicas' performance and updates\ntheir prediction models only after detecting significant system changes. We\nevaluate SEER in a traffic management scenario comprising [3..7] Raft replicas,\nand well-known data-center and WAN topologies. Compared to the Raft's uniform\nleader election, SEER decreases the mean control plane response time by up to\n~32%. The benefit comes at the expense of the minimal adaptation of Raft\nelection procedure and a slight increase in leader reconfiguration frequency,\nthe latter being tunable with a guaranteed upper bound. No safety properties of\nRaft are invalidated by SEER.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 09:15:16 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Sakic", "Ermin", ""], ["Vizarreta", "Petra", ""], ["Kellerer", "Wolfgang", ""]]}, {"id": "2104.01386", "submitter": "Itamar Cohen", "authors": "Itamar Cohen, Gil Einziger and Gabriel Scalosub", "title": "Self-adjusting Advertisement of Cache Indicators with Bandwidth\n  Constraints", "comments": "Infocom 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cache advertisements reduce the access cost by allowing users to skip the\ncache when it does not contain their datum. Such advertisements are used in\nmultiple networked domains such as 5G networks, wide area networks, and\ninformation-centric networking. The selection of an advertisement strategy\nexposes a trade-off between the access cost and bandwidth consumption. Still,\nexisting works mostly apply a trial-and-error approach for selecting the best\nstrategy, as the rigorous foundations required for optimizing such decisions is\nlacking. Our work shows that the desired advertisement policy depends on\nnumerous parameters such as the cache policy, the workload, the cache size, and\nthe available bandwidth. In particular, we show that there is no ideal single\nconfiguration. Therefore, we design an adaptive, self-adjusting algorithm that\nperiodically selects an advertisement policy. Our algorithm does not require\nany prior information about the cache policy, cache size, or workload, and does\nnot require any apriori configuration. Through extensive simulations, using\nseveral state-of-the-art cache policies, and real workloads, we show that our\napproach attains a similar cost to that of the best static configuration (which\nis only identified in retrospect) in each case.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 12:24:51 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Cohen", "Itamar", ""], ["Einziger", "Gil", ""], ["Scalosub", "Gabriel", ""]]}, {"id": "2104.01406", "submitter": "Nuno M Garcia", "authors": "Nuno M. Garcia", "title": "The Internet Protocol -- Past, some current limitations and a glimpse of\n  a possible future", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The network layer is central to the networking scientific area. It is around\nthe network layer that all the data communications develop, and one of its main\ntasks is to allow the identification of each single interface/machine between\nthe potentially many interfaces in a network. This seminar addresses some of\nthe issues that are usually presented to young Computer Science Engineering\nstudents in the course of several classes, but also presents some topics that\nare not address in networking courses. It is mostly focused on using Internet\nProtocol addresses in Local Area Networks, also considering issues that belong\nto the Wide Area Networks, such as data aggregation. This document summarizes\nthe content of a seminar, therefore it comprehends both teaching and\nresearching subject. The seminar starts with a history of the evolution of the\ncommunication protocols from the early days of networks up until IPv6. It\ndescribes a new approach to define the addresses of network interfaces using\nVariable Length Subnet Masks, as usually this is a not an easy task for\nComputer Science Engineering undergraduate students. This summary also\ndescribes some of the limitations of the data communication in todays'\nnetworks, proposing some solutions, where possible, including a novel mean of\nconnectionless data transmission by using IPv6 addresses, by extension of\npreviously published research. The way the seminar is organized provides a\nhistory to the past of the Internet Protocol, a view of some of its well-known\ncurrent limitations, and a glimpse into a possible future regarding an improved\nconnectionless layer 3 data transfer protocol.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 13:52:03 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Garcia", "Nuno M.", ""]]}, {"id": "2104.01461", "submitter": "Mustafa Kishk", "authors": "Yujie Qin and Mustafa A. Kishk and Mohamed-Slim Alouini", "title": "On the Influence of Charging Stations Spatial Distribution on Aerial\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using drones for cellular coverage enhancement is a recent technology that\nhas shown a great potential in various practical scenarios. However, one of the\nmain challenges that limits the performance of drone-enabled wireless networks\nis the limited flight time. In particular, due to the limited on-board battery\nsize, the drone needs to frequently interrupt its operation and fly back to a\ncharging station to recharge/replace its battery. In addition, the charging\nstation might be responsible to recharge multiple drones. Given that the\ncharging station has limited capacity, it can only serve a finite number of\ndrones simultaneously. Hence, in order to accurately capture the influence of\nthe battery limitation on the performance, it is required to analyze the\ndynamics of the time spent by the drones at the charging stations. In this\npaper, we use tools from queuing theory and stochastic geometry to study the\ninfluence of each of the charging stations limited capacity and spatial density\non the performance of a drone-enabled wireless network.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 18:41:38 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Qin", "Yujie", ""], ["Kishk", "Mustafa A.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2104.01587", "submitter": "Cenk G\\\"undo\\u{g}an", "authors": "Cenk G\\\"undo\\u{g}an, Christian Ams\\\"uss, Thomas C. Schmidt, Matthias\n  W\\\"ahlisch", "title": "Networking Group Content: RESTful Multiparty Access to a Data-centric\n  Web of Things", "comments": null, "journal-ref": "Proceedings of IEEE LCN 2021", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content replication to many destinations is a common use case in the Internet\nof Things (IoT). The deployment of IP multicast has proven inefficient, though,\ndue to its lack of layer-2 support by common IoT radio technologies and its\nsynchronous end-to-end transmission, which is highly susceptible to\ninterference. Information-centric networking (ICN) introduced hop-wise\nmulti-party dissemination of cacheable content, which has proven valuable in\nparticular for low-power lossy networking regimes. Even NDN, however, the most\nprominent ICN protocol, suffers from a lack of deployment.\n  In this paper, we explore how multiparty content distribution in an\ninformation-centric Web of Things (WoT) can be built on CoAP. We augment the\nCoAP proxy by request aggregation and response replication functions, which\ntogether with proxy caches enable asynchronous group communication. In a\nfurther step, we integrate content object security with OSCORE into the CoAP\nmulticast proxy system, which enables ubiquitous caching of certified authentic\ncontent. In our evaluation, we compare NDN with different deployment models of\nCoAP, including our data-centric approach in realistic testbed experiments. Our\nfindings indicate that multiparty content distribution based on CoAP proxies\nperforms equally well as NDN, while remaining fully compatible with the\nestablished IoT protocol world of CoAP on the Internet.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 11:09:22 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["G\u00fcndo\u011fan", "Cenk", ""], ["Ams\u00fcss", "Christian", ""], ["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "2104.01804", "submitter": "Avik Dayal", "authors": "Avik Dayal, Vijay K. Shah, Biplav Choudhury, Vuk Marojevic, Carl\n  Dietrich, and Jeffrey H. Reed", "title": "Adaptive Semi-Persistent Scheduling for Enhanced On-road Safety in\n  Decentralized V2X Networks", "comments": "9 pages, 16 figures, To be published in IFIP Networking 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Decentralized vehicle-to-everything (V2X) networks (i.e., Mode-4 C-V2X and\nMode 2a NR-V2X), rely on periodic Basic Safety Messages (BSMs) to disseminate\ntime-sensitive information (e.g., vehicle position) and has the potential to\nimprove on-road safety. For BSM scheduling, decentralized V2X networks utilize\nsensing-based semi-persistent scheduling (SPS), where vehicles sense radio\nresources and select suitable resources for BSM transmissions at prespecified\nperiodic intervals termed as Resource Reservation Interval (RRI). In this\npaper, we show that such a BSM scheduling (with a fixed RRI) suffers from\nsevere under- and over- utilization of radio resources under varying vehicle\ntraffic scenarios; which severely compromises timely dissemination of BSMs,\nwhich in turn leads to increased collision risks. To address this, we extend\nSPS to accommodate an adaptive RRI, termed as SPS++. Specifically, SPS++ allows\neach vehicle -- (i) to dynamically adjust RRI based on the channel resource\navailability (by accounting for various vehicle traffic scenarios), and then,\n(ii) select suitable transmission opportunities for timely BSM transmissions at\nthe chosen RRI. Our experiments based on Mode-4 C-V2X standard implemented\nusing the ns-3 simulator show that SPS++ outperforms SPS by at least $50\\%$ in\nterms of improved on-road safety performance, in all considered simulation\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 07:54:30 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Dayal", "Avik", ""], ["Shah", "Vijay K.", ""], ["Choudhury", "Biplav", ""], ["Marojevic", "Vuk", ""], ["Dietrich", "Carl", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "2104.01929", "submitter": "Nik Sultana", "authors": "Andr\\'e DeHon, Hans Giesen, Nik Sultana, Yuanlong Xiao", "title": "Meta-level issues in Offloading: Scoping, Composition, Development, and\n  their Automation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.NI cs.SE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper argues for an accelerator development toolchain that takes into\naccount the whole system containing the accelerator. With whole-system\nvisibility, the toolchain can better assist accelerator scoping and composition\nin the context of the expected workloads and intended performance objectives.\nDespite being focused on the 'meta-level' of accelerators, this would build on\nexisting and ongoing DSLs and toolchains for accelerator design. Basing this on\nour experience in programmable networking and reconfigurable-hardware\nprogramming, we propose an integrative approach that relies on three\nactivities: (i) generalizing the focus of acceleration to offloading to\naccommodate a broader variety of non-functional needs -- such as security and\npower use -- while using similar implementation approaches, (ii) discovering\nwhat to offload, and to what hardware, through semi-automated analysis of a\nwhole system that might compose different offload choices that changeover time,\n(iii) connecting with research and state-of-the-art approaches for using\ndomain-specific languages (DSLs) and high-level synthesis (HLS) systems for\ncustom offload development. We outline how this integration can drive new\ndevelopment tooling that accepts models of programs and resources to assist\nsystem designers through design-space exploration for the accelerated system.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 14:16:54 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["DeHon", "Andr\u00e9", ""], ["Giesen", "Hans", ""], ["Sultana", "Nik", ""], ["Xiao", "Yuanlong", ""]]}, {"id": "2104.01946", "submitter": "Ke Liang", "authors": "Ke Liang and Mitchel Myers", "title": "Machine Learning Applications in the Routing in Computer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of routing algorithms is of clear importance as the volume of\nInternet traffic continues to increase. In this survey, there is much research\ninto how Machine Learning techniques can be employed to improve the performance\nand scalability of routing algorithms. We surveyed both centralized and\ndecentralized ML routing architectures and using a variety of ML techniques\nbroadly divided into supervised learning and reinforcement learning. Many of\nthe papers showed promise in their ability to optimize some aspect of network\nrouting. We also implemented two routing protocols within 14 surveyed routing\nalgorithms and verified the efficacy of their results. While the results of\nmost of the papers showed promise, many of them are based on simulations of\npotentially unrealistic network configurations. To provide further efficacy to\nthe results, more real-world results are necessary.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 15:08:35 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Liang", "Ke", ""], ["Myers", "Mitchel", ""]]}, {"id": "2104.02222", "submitter": "Roch Gu\\'erin", "authors": "Jiayi Song, Roch Gu\\'erin, and Henry Sariowan", "title": "Minimizing network bandwidth under latency constraints: The single node\n  case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Datacenters have become a significant source of traffic, much of which is\ncarried over private networks. The operators of those networks commonly have\naccess to detailed traffic profiles and performance goals, which they seek to\nmeet as efficiently as possible. Of interest are solutions for offering latency\nguarantees while minimizing the required network bandwidth. Of particular\ninterest is the extent to which traffic (re)shaping can be of benefit. The\npaper focuses on the most basic network configuration, namely, a single node,\nsingle link network, with extensions to more general, multi-node networks\ndiscussed in a companion paper. The main results are in the form of optimal\nsolutions for different types of schedulers of varying complexity, and\ntherefore cost. The results demonstrate how judicious traffic shaping can help\nlower complexity schedulers reduce the bandwidth they require, often performing\nas well as more complex ones.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 01:22:59 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 13:52:26 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Song", "Jiayi", ""], ["Gu\u00e9rin", "Roch", ""], ["Sariowan", "Henry", ""]]}, {"id": "2104.02346", "submitter": "Simon Scherrer", "authors": "Simon Scherrer, Markus Legner, Adrian Perrig, Stefan Schmid", "title": "Enabling Novel Interconnection Agreements with Path-Aware Networking\n  Architectures", "comments": "51st Annual IEEE/IFIP International Conference on Dependable Systems\n  and Networks (DSN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path-aware networks (PANs) are emerging as an intriguing new paradigm with\nthe potential to significantly improve the dependability and efficiency of\nnetworks. However, the benefits of PANs can only be realized if the adoption of\nsuch architectures is economically viable. This paper shows that PANs enable\nnovel interconnection agreements among autonomous systems, which allow to\nconsiderably improve both economic profits and path diversity compared to\ntoday's Internet. Specifically, by supporting packet forwarding along a path\nselected by the packet source, PANs do not require the Gao-Rexford conditions\nto ensure stability. Hence, autonomous systems can establish novel agreements,\ncreating new paths which demonstrably improve latency and bandwidth metrics in\nmany cases. This paper also expounds two methods to set up agreements which are\nPareto-optimal, fair, and thus attractive to both parties. We further present a\nbargaining mechanism that allows two parties to efficiently automate agreement\nnegotiations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 08:14:34 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Scherrer", "Simon", ""], ["Legner", "Markus", ""], ["Perrig", "Adrian", ""], ["Schmid", "Stefan", ""]]}, {"id": "2104.02390", "submitter": "Hanaa Abumarshoud", "authors": "Hanaa Abumarshoud, Lina Mohjazi, Octavia A. Dobre, Marco Di Renzo,\n  Muhammad Ali Imran, Harald Haas", "title": "LiFi Through Reconfigurable Intelligent Surfaces: A New Frontier for 6G?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Light fidelity (LiFi), which is based on visible light communications (VLC),\nis celebrated as a cutting-edge technological paradigm that is envisioned to be\nan indispensable part of 6G systems. Nonetheless, LiFi performance is subject\nto efficiently overcoming the line-of-sight blockage, whose adverse effect on\nwireless reception reliability becomes even more pronounced in highly dynamic\nenvironments, such as vehicular application scenarios. Meanwhile,\nreconfigurable intelligent surfaces (RIS) emerged recently as a revolutionary\nconcept that transfers the physical propagation environment into a fully\ncontrollable and customisable space in a low-cost low-power fashion. We\nanticipate that the integration of RIS in LiFi-enabled networks will not only\nsupport blockage mitigation but will also provision complex interactions among\nnetwork entities, and is hence manifested as a promising platform that enables\na plethora of technological trends and new applications. In this article, for\nthe first time in the open literature, we set the scene for a holistic overview\nof RIS-assisted LiFi systems. Specifically, we explore the underlying RIS\narchitecture from the perspective of physics and present a forward-looking\nvision that outlines potential operational elements supported by RIS-enabled\ntransceivers and RIS-enabled environments. Finally, we highlight major\nassociated challenges and offer a look ahead toward promising future\ndirections.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 09:35:55 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 09:01:55 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 12:38:03 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Abumarshoud", "Hanaa", ""], ["Mohjazi", "Lina", ""], ["Dobre", "Octavia A.", ""], ["Di Renzo", "Marco", ""], ["Imran", "Muhammad Ali", ""], ["Haas", "Harald", ""]]}, {"id": "2104.02393", "submitter": "Ilja Behnke", "authors": "Robert Danicki, Martin Haug, Ilja Behnke, Laurenz M\\\"adje, Lauritz\n  Thamsen", "title": "Detecting and Mitigating Network Packet Overloads on Real-Time Devices\n  in IoT Systems", "comments": "EdgeSys '21", "journal-ref": null, "doi": "10.1145/3434770.3459733", "report-no": null, "categories": "cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manufacturing, automotive, and aerospace environments use embedded systems\nfor control and automation and need to fulfill strict real-time guarantees. To\nfacilitate more efficient business processes and remote control, such devices\nare being connected to IP networks. Due to the difficulty in predicting network\npackets and the interrelated workloads of interrupt handlers and drivers,\ndevices controlling time critical processes stand under the risk of missing\nprocess deadlines when under high network loads. Additionally, devices at the\nedge of large networks and the internet are subject to a high risk of load\nspikes and network packet overloads.\n  In this paper, we investigate strategies to detect network packet overloads\nin real-time and present four approaches to adaptively mitigate local deadline\nmisses. In addition to two strategies mitigating network bursts with and\nwithout hysteresis, we present and discuss two novel mitigation algorithms,\ncalled Budget and Queue Mitigation. In an experimental evaluation, all\nalgorithms showed mitigating effects, with the Queue Mitigation strategy\nenabling most packet processing while preventing lateness of critical tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 09:49:56 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Danicki", "Robert", ""], ["Haug", "Martin", ""], ["Behnke", "Ilja", ""], ["M\u00e4dje", "Laurenz", ""], ["Thamsen", "Lauritz", ""]]}, {"id": "2104.02421", "submitter": "Xiangqiang Gao", "authors": "Xiangqiang Gao, Rongke Liu (Senior Member, IEEE), Aryan Kaushik\n  (Member, IEEE)", "title": "A Distributed Virtual Network Function Placement Approach in Satellite\n  Edge and Cloud Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satellite edge computing has become a promising way to provide computing\nservices for Internet of Things (IoT) devices in remote areas, which are out of\nthe coverage of terrestrial networks, nevertheless, it is not suitable for\nlarge-scale IoT devices due to the resource limitation of satellites. Cloud\ncomputing can provide sufficient available resources for IoT devices but it\ndoes not meet the service requirements of delay sensitive users as high network\nlatency. Collaborative edge and cloud computing is to facilitate flexible\nservice provisioning for numerous IoT devices by incorporating the advantages\nof edge and cloud computing. In this paper, we investigate the virtual network\nfunction (VNF) placement problem in collaborative satellite edge and cloud\ncomputing to minimize the satellite network bandwidth usage and the service\nend-to-end delay. We formulate the VNF placement problem as an integer\nnon-linear programming problem and propose a distributed VNF placement (D-VNFP)\nalgorithm to address it, as the VNF placement problem is NP-hard. The\nexperiments are conducted to evaluate the effectiveness of the proposed D-VNFP\nalgorithm. The results show that the proposed D-VNFP algorithm outperforms the\nexisting baseline algorithms of Greedy and Viterbi for solving the VNF\nplacement problem in satellite edge and cloud computing.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 10:54:52 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Gao", "Xiangqiang", "", "Senior Member, IEEE"], ["Liu", "Rongke", "", "Senior Member, IEEE"], ["Kaushik", "Aryan", "", "Member, IEEE"]]}, {"id": "2104.02426", "submitter": "Hanhui Deng", "authors": "Di Wu, Xiang Nie, Hanhui Deng, and Zhijin Qin", "title": "Software Defined Edge Computing for Distributed Management and Scalable\n  Control in IoT Multinetworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, edge computing has emerged as a promising paradigm to support\nmobile access in IoT multinetworks. However, coexistence of heterogeneous\nwireless communication schemes brings about new challenges to the mobility\nmanagement and access control in such networks. To maintain its computing\ncontinuum, Software-Defined Networking (SDN) architecture can be applied to the\ndistributed edge networks, which provides consistent frameworks for mobility\nmanagement and creates secure mechanisms for access control. In this paper, we\nfirst review the state-of-the-art SDN technology and its applications in edge\ncomputing. In particular, we highlight the prominent issues related to mobility\nmanagement and access control for SDN in the edge computing environment. We\nalso introduce a number of effective solutions to these issues by presenting\nreal-world testbed experiments, prototypes and numerical analysis of adopting\nSDN based edge computing paradigms for IoT multinetworks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 11:10:29 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Wu", "Di", ""], ["Nie", "Xiang", ""], ["Deng", "Hanhui", ""], ["Qin", "Zhijin", ""]]}, {"id": "2104.02463", "submitter": "William T\\\"arneberg", "authors": "Lars Larsson, William T\\\"arneberg, Cristian Klein, Maria Kihl, and\n  Erik Elmroth", "title": "Towards Soft Circuit Breaking in Service Meshes via Application-agnostic\n  Caching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service meshes factor out code dealing with inter-micro-service\ncommunication, such as circuit breaking. Circuit breaking actuation is\ncurrently limited to an \"on/off\" switch, i.e., a tripped circuit breaker will\nreturn an application-level error indicating service unavailability to the\ncalling micro-service. This paper proposes a soft circuit breaker actuator,\nwhich returns cached data instead of an error. The overall resilience of a\ncloud application is improved if constituent micro-services return stale data,\ninstead of no data at all. While caching is widely employed for serving web\nservice traffic, its usage in inter-micro-service communication is lacking.\nMicro-services responses are highly dynamic, which requires carefully choosing\nadaptive time-to-life caching algorithms. We evaluate our approach through two\nexperiments. First, we quantify the trade-off between traffic reduction and\ndata staleness using a purpose-build service, thereby identifying algorithm\nconfigurations that keep data staleness at about 3% or less while reducing\nnetwork load by up to 30%. Second, we quantify the network load reduction with\nthe micro-service benchmark by Google Cloud called Hipster Shop. Our approach\nresults in caching of about 80% of requests. Results show the feasibility and\nefficiency of our approach, which encourages implementing caching as a circuit\nbreaking actuator in service meshes.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 12:46:29 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Larsson", "Lars", ""], ["T\u00e4rneberg", "William", ""], ["Klein", "Cristian", ""], ["Kihl", "Maria", ""], ["Elmroth", "Erik", ""]]}, {"id": "2104.02599", "submitter": "Chien-Cheng Wu", "authors": "Chien-Cheng Wu", "title": "A Survey for Real-Time Network Performance Measurement via Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Real-Time Networks (RTNs) provide latency guarantees for time-critical\napplications and it aims to support different traffic categories via various\nscheduling mechanisms. Those scheduling mechanisms rely on a precise network\nperformance measurement to dynamically adjust the scheduling strategies.\nMachine Learning (ML) offers an iterative procedure to measure network\nperformance. Network Calculus (NC) can calculate the bounds for the main\nperformance indexes such as latencies and throughputs in an RTN for ML. Thus,\nthe ML and NC integration improve overall calculation efficiency. This paper\nwill provide a survey for different approaches of Real-Time Network performance\nmeasurement via NC as well as ML and present their results, dependencies, and\napplication scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 21:50:52 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Wu", "Chien-Cheng", ""]]}, {"id": "2104.02601", "submitter": "Masoud Movahhedi", "authors": "Hossein Nazemi-Rafi, Masoud Movahhedi", "title": "A Wave Trapping Dispersive Delay Structure Based on Substrate Integrated\n  Waveguide (SIW)", "comments": null, "journal-ref": null, "doi": "10.1049/iet-map.2020.0487", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A dispersive delay structure (DDS) is a device that creates a specified group\ndelay function over frequency bandwidth. In this paper, the idea of trapping\nthe electromagnetic waves in a feedback loop is proposed to achieve higher\ngroup delay swing. The proposed structure includes two transmission lines and\ntwo junctions that act as power divider/combiner. The transmission lines can be\neither dispersive or non-dispersive. The group delay in the proposed\nconfiguration is proportional to the injected power into the feedback loop. So,\nan increase in the group delay swing can be done by improving the junctions or\nby adding more feedback loops to the structure. Based on this configuration, a\nnovel DDS, using the substrate integrated waveguide (SIW) transmission line, is\nintroduced. According to the experimental results, the proposed device with a\nrelatively compact size creates high group delay swings (9 ns), and its\ninsertion loss is about 7 dB.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 16:06:46 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Nazemi-Rafi", "Hossein", ""], ["Movahhedi", "Masoud", ""]]}, {"id": "2104.02658", "submitter": "Santosh Ganji", "authors": "Santosh Ganji, Tzu-Hsiang Lin, Francisco A. Espinal, P. R. Kumar", "title": "UNBLOCK: Low Complexity Transient Blockage Recovery for Mobile mm-Wave\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directional radio beams are used in the mm-Wave band to combat the high path\nloss. The mm-Wave band also suffers from high penetration losses from drywall,\nwood, glass, concrete, etc., and also the human body. Hence, as a mobile user\nmoves, the Line of Sight (LoS) path between the mobile and the Base Station\n(BS) can be blocked by objects interposed in the path, causing loss of the\nlink. A mobile with a lost link will need to be re-acquired as a new user by\ninitial access, a process that can take up to a second, causing disruptions to\napplications. UNBLOCK is a protocol that allows a mobile to recover from\ntransient blockages, such as those caused by a human hand or another human\nwalking into the line of path or other temporary occlusions by objects, which\ntypically disappear within the order of $100$ ms, without having to go through\nre-acquisition. UNBLOCK is based on extensive experimentation in office type\nenvironments which has shown that while a LoS path is blocked, there typically\nexists a Non-LoS path, i.e., a reflected path through scatterers, with a loss\nwithin about $10$ dB of the LoS path. UNBLOCK proactively keeps such a NLoS\npath in reserve, to be used when blockage happens, typically without any\nwarning. UNBLOCK uses this NLoS path to maintain time-synchronization with the\nBS until the blockage disappears, as well as to search for a better NLoS path\nif available. When the transient blockage disappears, it reestablishes LoS\ncommunication at the epochs that have been scheduled by the BS for\ncommunication with the mobile.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 00:02:10 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Ganji", "Santosh", ""], ["Lin", "Tzu-Hsiang", ""], ["Espinal", "Francisco A.", ""], ["Kumar", "P. R.", ""]]}, {"id": "2104.02659", "submitter": "Petros Spachos", "authors": "Petros Spachos, Ioannis Papapanagiotou and Konstantinos Plataniotis", "title": "Microlocation for Smart Buildings in the Era of the Internet of Things:\n  A Survey of Technologies, Techniques, and Approaches", "comments": null, "journal-ref": null, "doi": "10.1109/MSP.2018.2846804", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Microlocation plays a key role in the transformation of traditional buildings\ninto smart infrastructure. Microlocation is the process of locating any entity\nwith a very high accuracy, possibly in centimeters. Such technologies require\nhigh detection accuracy, energy efficiency, wide reception range, low cost, and\navailability. In this article, we provide insights into various\nmicrolocation-enabling technologies, techniques, and services and discuss how\nthey can accelerate the incorporation of the Internet of Things (IoT) in smart\nbuildings. We cover the challenges and examine some signal processing filtering\ntechniques such that microlocation-enabling technologies and services can be\nthoroughly integrated with an IoT-equipped smart building. An experiment with\nBluetooth Low-Energy (BLE) beacons used for microlocation is also presented.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:12:27 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Spachos", "Petros", ""], ["Papapanagiotou", "Ioannis", ""], ["Plataniotis", "Konstantinos", ""]]}, {"id": "2104.02776", "submitter": "Islam Samy", "authors": "Islam Samy, Xiao Han, Loukas Lazos, Ming Li, Yong Xiao, Marwan Krunz", "title": "Misbehavior Detection in Wi-Fi/LTE Coexistence over Unlicensed Bands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of fair coexistence between LTE and Wi-Fi systems in\nthe unlicensed 5 GHz U-NII bands. We focus on the misbehavior opportunities due\nto the heterogeneity in channel access mechanism and the lack of a common\ncontrol plane. We define selfish misbehavior strategies for the LTE that yield\nan unfair share of the spectrum resources. Such strategies are based on\nmanipulating the operational parameters of the LTE-LAA standard, namely the\nbackoff mechanism, the traffic class parameters, the clear channel access (CCA)\nthreshold, and others. Prior methods for detecting misbehavior in homogeneous\nsettings are not applicable in a spectrum sharing scenario because the devices\nof one system cannot decode the transmissions of another. We develop implicit\nsensing techniques that can accurately estimate the operational parameters of\nLTE transmissions under various topological scenarios and {\\em without\ndecoding.} These techniques apply correlation-based signal detection to infer\nthe required information. Our techniques are validated through experiments on a\nUSRP testbed. We further apply a statistical inference framework for\ndetermining deviations of the LTE behavior from the coexistence etiquette. By\ncharacterizing the detection and false alarm probabilities, we show that our\nframework yields high detection accuracy at a very low false alarm rate.\nAlthough our methods focus on detecting misbehavior of the LTE system, they can\nbe generalized to other coexistence scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 20:34:39 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Samy", "Islam", ""], ["Han", "Xiao", ""], ["Lazos", "Loukas", ""], ["Li", "Ming", ""], ["Xiao", "Yong", ""], ["Krunz", "Marwan", ""]]}, {"id": "2104.02780", "submitter": "Thomas Sandholm", "authors": "Thomas Sandholm and Sayandev Mukherjee", "title": "Bandcoin: Using Smart Contracts to Automate Mobile Network Bandwidth\n  Roaming Agreements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new way to share licensed spectrum bandwidth capacity in mobile\nnetworks between operators, service providers and consumers using\nblockchain-based smart contracts. We discuss the foundational building blocks\nin the contract as well as various extensions to support more advanced features\nsuch as bulk purchases, future reservations, and various auction mechanisms.\nFurthermore, we demonstrate how the system can be implemented with an\nopen-source, permissioned Enterprise blockchain, Hyperledger Sawtooth. We show\nthat our smart contract implementation can improve blockchain transaction\nperformance, by approximately four orders of magnitude compared to serial\ntransactions and one order of magnitude compared to parallell transactions,\nusing PKI-driven bulk purchases of mobile access grants, paving the way for\nfully automated, efficient, and fine-grained roaming agreements.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 20:48:37 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Sandholm", "Thomas", ""], ["Mukherjee", "Sayandev", ""]]}, {"id": "2104.02783", "submitter": "Orhan Dagdeviren", "authors": "Vahid Khalilpour Akram, Orhan Dagdeviren (Member), Bulent Tavli", "title": "A Coverage-Aware Distributed k-Connectivity Maintenance Algorithm for\n  Arbitrarily Large k in Mobile Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile sensor networks (MSNs) have emerged from the interaction between\nmobile robotics and wireless sensor networks. MSNs can be deployed in harsh\nenvironments, where failures in some nodes can partition MSNs into disconnected\nnetwork segments or reduce the coverage area. A k-connected network can\ntolerate at least k-1 arbitrary node failures without losing its connectivity.\nIn this study, we present a coverage-aware distributed k-connectivity\nmaintenance (restoration) algorithm that generates minimum-cost movements of\nactive nodes after a node failure to preserve a persistent k value subject to a\ncoverage conservation criterion. The algorithm accepts a coverage conservation\nratio (as a trade-off parameter between coverage and movements) and facilitates\ncoverage with the generated movements according to this value. Extensive\nsimulations and testbed experiments reveal that the proposed algorithm restores\nk-connectivity more efficiently than the existing restoration algorithms.\nFurthermore, our algorithm can be utilized to maintain k-connectivity without\nsacrificing the coverage, significantly.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 21:00:21 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Akram", "Vahid Khalilpour", "", "Member"], ["Dagdeviren", "Orhan", "", "Member"], ["Tavli", "Bulent", ""]]}, {"id": "2104.03032", "submitter": "David M\\\"odinger", "authors": "David M\\\"odinger and Juri Dispan and Franz J. Hauck", "title": "Shared-Dining: Broadcasting Secret Shares using Dining-Cryptographers\n  Groups", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A k-anonymous broadcast can be implemented using a small group of dining\ncryptographers to first share the message, followed by a flooding phase started\nby group members. Members have little incentive to forward the message in a\ntimely manner, as forwarding incurs costs, or they may even profit from keeping\nthe message. In worst case, this leaves the true originator as the only sender,\nrendering the dining-cryptographers phase useless and compromising their\nprivacy. We present a novel approach using a modified dining-cryptographers\nprotocol to distributed shares of an (n,k)-Shamir's secret sharing scheme.\nFinally, all group members broadcast their received share through the network,\nallowing any recipient of k shares to reconstruct the message, enforcing\nanonymity. If less than k group members broadcast their shares, the message\ncannot be decoded thus preventing privacy breaches for the originator. Our\nsystem provides (n-|attackers|)-anonymity for up to k-1 attackers and has\nlittle performance impact on dissemination. We show these results in a security\nanalysis and performance evaluation based on a proof-of-concept prototype.\nThroughput rates between 10 and 100 kB/s are enough for many real applications\nwith high privacy requirements, e.g., financial blockchain system.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 10:15:25 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["M\u00f6dinger", "David", ""], ["Dispan", "Juri", ""], ["Hauck", "Franz J.", ""]]}, {"id": "2104.03044", "submitter": "Aristodemos Paphitis", "authors": "Aristodemos Paphitis, Nicolas Kourtellis, Michael Sirivianos", "title": "A First Look into the Structural Properties and Resilience of Blockchain\n  Overlays", "comments": "23 pages, 8 figures, 6 tables, submitted to ACM IMC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain (BC) systems are highly distributed peer-to-peer networks that\noffer an alternative to centralized services and promise robustness to\ncoordinated attacks. However, the resilience and overall security of a BC\nsystem rests heavily on the structural properties of its underlying\npeer-to-peer overlay. Despite their success, BC overlay networks' critical\ndesign aspects, connectivity properties and network-layer inter-dependencies\nare still poorly understood. In this work, we set out to fill this gap and\nstudy the most important overlay network structural properties and robustness\nto targeted attacks of seven distinct BC networks. In particular, we probe and\ncrawl these BC networks every two hours to gather information about all their\navailable peers, over a duration of 28 days. We analyze 335 network snapshots\nper BC network, for a total of 2345 snapshots. We construct, at frequent\nintervals, connectivity graphs for each BC network, consisting of all potential\nconnections between peers. We analyze the structural graph properties of these\nnetworks and compare them across the seven BC networks. We also study how these\nproperties associate with the resilience of each network to partitioning\nattacks, i.e., when peers are selected, attacked and taken offline, using\ndifferent selection strategies driven by the aforementioned structural\nproperties. In fact, we show that by targeting fewer than 10 highly-connected\npeers, major BCs such as Bitcoin can be partitioned into disjoint, i.e.,\ndisconnected, components. Finally, we uncover a hidden interconnection between\ndifferent BC networks, where certain peers participate in more than one BC\nnetwork, which has serious implications for the robustness of the overall BC\nnetwork ecosystem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 10:44:23 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 13:19:32 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Paphitis", "Aristodemos", ""], ["Kourtellis", "Nicolas", ""], ["Sirivianos", "Michael", ""]]}, {"id": "2104.03169", "submitter": "Boubakr Nour", "authors": "Afaf Taik and Boubakr Nour and Soumaya Cherkaoui", "title": "Empowering Prosumer Communities in Smart Grid with Wireless\n  Communications and Federated Edge Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The exponential growth of distributed energy resources is enabling the\ntransformation of traditional consumers in the smart grid into prosumers. Such\ntransition presents a promising opportunity for sustainable energy trading.\nYet, the integration of prosumers in the energy market imposes new\nconsiderations in designing unified and sustainable frameworks for efficient\nuse of the power and communication infrastructure. Furthermore, several issues\nneed to be tackled to adequately promote the adoption of decentralized\nrenewable-oriented systems, such as communication overhead, data privacy,\nscalability, and sustainability. In this article, we present the different\naspects and challenges to be addressed for building efficient energy trading\nmarkets in relation to communication and smart decision-making. Accordingly, we\npropose a multi-level pro-decision framework for prosumer communities to\nachieve collective goals. Since the individual decisions of prosumers are\nmainly driven by individual self-sufficiency goals, the framework prioritizes\nthe individual prosumers' decisions and relies on 5G wireless network for fast\ncoordination among community members. In fact, each prosumer predicts energy\nproduction and consumption to make proactive trading decisions as a response to\ncollective-level requests. Moreover, the collaboration of the community is\nfurther extended by including the collaborative training of prediction models\nusing Federated Learning, assisted by edge servers and prosumer home-area\nequipment. In addition to preserving prosumers' privacy, we show through\nevaluations that training prediction models using Federated Learning yields\nhigh accuracy for different energy resources while reducing the communication\noverhead.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 14:57:57 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Taik", "Afaf", ""], ["Nour", "Boubakr", ""], ["Cherkaoui", "Soumaya", ""]]}, {"id": "2104.03182", "submitter": "Lixuan Yang", "authors": "Lixuan Yang, Alessandro Finamore, Feng Jun, Dario Rossi", "title": "Deep Learning and Traffic Classification: Lessons learned from a\n  commercial-grade dataset with hundreds of encrypted and zero-day applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing success of Machine Learning (ML) and Deep Learning (DL) has\nrecently re-sparked interest towards traffic classification. While\nclassification of known traffic is a well investigated subject with supervised\nclassification tools (such as ML and DL models) are known to provide\nsatisfactory performance, detection of unknown (or zero-day) traffic is more\nchallenging and typically handled by unsupervised techniques (such as\nclustering algorithms).\n  In this paper, we share our experience on a commercial-grade DL traffic\nclassification engine that is able to (i) identify known applications from\nencrypted traffic, as well as (ii) handle unknown zero-day applications. In\nparticular, our contribution for (i) is to perform a thorough assessment of\nstate of the art traffic classifiers in commercial-grade settings comprising\nfew thousands of very fine grained application labels, as opposite to the few\ntens of classes generally targeted in academic evaluations. Additionally, we\ncontribute to the problem of (ii) detection of zero-day applications by\nproposing a novel technique, tailored for DL models, that is significantly more\naccurate and light-weight than the state of the art.\n  Summarizing our main findings, we gather that (i) while ML and DL models are\nboth equally able to provide satisfactory solution for classification of known\ntraffic, however (ii) the non-linear feature extraction process of the DL\nbackbone provides sizeable advantages for the detection of unknown classes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 15:21:22 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Yang", "Lixuan", ""], ["Finamore", "Alessandro", ""], ["Jun", "Feng", ""], ["Rossi", "Dario", ""]]}, {"id": "2104.03631", "submitter": "Daniel Reti", "authors": "Daniel Reti, Daniel Fraunholz, Janis Zemitis, Daniel Schneider, Hans\n  Dieter Schotten", "title": "Deep Down the Rabbit Hole: On References in Networks of Decoy Elements", "comments": null, "journal-ref": "2020 International Conference on Cyber Security and Protection of\n  Digital Services (Cyber Security)", "doi": "10.1109/CyberSecurity49315.2020.9138850", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deception technology has proven to be a sound approach against threats to\ninformation systems. Aside from well-established honeypots, decoy elements,\nalso known as honeytokens, are an excellent method to address various types of\nthreats. Decoy elements are causing distraction and uncertainty to an attacker\nand help detecting malicious activity. Deception is meant to be complementing\nfirewalls and intrusion detection systems. Particularly insider threats may be\nmitigated with deception methods. While current approaches consider the use of\nmultiple decoy elements as well as context-sensitivity, they do not\nsufficiently describe a relationship between individual elements. In this work,\ninter-referencing decoy elements are introduced as a plausible extension to\nexisting deception frameworks, leading attackers along a path of decoy\nelements. A theoretical foundation is introduced, as well as a stochastic model\nand a reference implementation. It was found that the proposed system is\nsuitable to enhance current decoy frameworks by adding a further dimension of\ninter-connectivity and therefore improve intrusion detection and prevention.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 09:34:05 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Reti", "Daniel", ""], ["Fraunholz", "Daniel", ""], ["Zemitis", "Janis", ""], ["Schneider", "Daniel", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "2104.03651", "submitter": "Daniel Reti", "authors": "Daniel Reti, Norman Becker", "title": "Escape the Fake: Introducing Simulated Container-Escapes for Honeypots", "comments": null, "journal-ref": "2020 Workshop on Next Generation Networks and Applications (NGNA)", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of network security, the concept of honeypots is well\nestablished in research as well as in production. Honeypots are used to imitate\na legitimate target on the network and to raise an alert on any interaction.\nThis does not only help learning about a breach, but also allows researchers to\nstudy the techniques of an attacker. With the rise of cloud computing,\ncontainer-based virtualization gained popularity for application deployment.\nThis paper investigates the possibilities of container-based honeypots and\nintroduces the concept of simulating container escapes as a deception\ntechnique.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 10:16:03 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Reti", "Daniel", ""], ["Becker", "Norman", ""]]}, {"id": "2104.03655", "submitter": "Haneet Kour", "authors": "Haneet Kour, Rakesh Kumar Jha", "title": "Electromagnetic Radiation Reduction in 5G Networks and Beyond using\n  Thermal Radiation Mode", "comments": "16 pages, 16 figures, 5 tables", "journal-ref": "IEEE Transactions on Vehicular Technology, 2020", "doi": "10.1109/TVT.2020.3020004", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the massive increase in the popularity of smartphones and mobile data\napplications demanding bandwidth requiring data rates of the order of Gigabits\nper second, exploration of untapped frequency spectrum such as millimeter-wave\nhas begun. Along with providing seamless connectivity and catering to achieving\nhigh Quality of Service and Quality of Experience, investigations are ongoing\nto enhance our knowledge about biological safety at high frequencies. There is\na need to ensure safety and reliability for the exposed public and updating the\ngovernment policies regarding safety standards and regulations. This article is\nconsecrated to provide an insight into health effects pertaining to millimeter\nfrequencies, addressing aspects such as thermal heating in the body tissues\nwith temperature rise, specific absorption rate, power density. As a solution,\na proposal has been given for Electromagnetic radiation reduction for the\nmobile communication system in the form of a proposed mode that is, Thermal\nRadiation mode endorsing its safe use, promoting Green WCN along with increased\nenergy efficiency and reduced complexity for the future generations to come.\nThe proposal also validates reduced power density, Specific Absorption Rate,\nand temperature elevation produced in the human tissue when compared to other\nmodels in the form of simulation results obtained. It can increase the safety\nand reliability of 5G and beyond i.e. 6G networks in the future.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 10:18:31 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Kour", "Haneet", ""], ["Jha", "Rakesh Kumar", ""]]}, {"id": "2104.03666", "submitter": "Daniel Reti", "authors": "Daniel Reti, David Klaa{\\ss}en, Simon Duque Anton, Hans Dieter\n  Schotten", "title": "Secure (S)Hell: Introducing an SSH Deception Proxy Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deceiving an attacker in the network security domain is a well established\napproach, mainly achieved through deployment of honeypots consisting of open\nnetwork ports with the sole purpose of raising an alert on a connection. With\nattackers becoming more careful to avoid honeypots, other decoy elements on\nreal host systems continue to create uncertainty for attackers. This\nuncertainty makes an attack more difficult, as an attacker cannot be sure\nwhether the system does contain deceptive elements or not. Consequently, each\naction of an attacker could lead to the discovery. In this paper a framework is\nproposed for placing decoy elements through an SSH proxy, allowing to deploy\ndecoy elements on-the-fly without the need for a modification of the protected\nhost system.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 10:28:27 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Reti", "Daniel", ""], ["Klaa\u00dfen", "David", ""], ["Anton", "Simon Duque", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "2104.03673", "submitter": "J\\'er\\'emie Decouchant", "authors": "Silvia Bonomi and J\\'er\\'emie Decouchant and Giovanni Farina and\n  Vincent Rahli and S\\'ebastien Tixeuil", "title": "Practical Byzantine Reliable Broadcast on Partially Connected Networks", "comments": "This is a preprint of a paper that will appear at the IEEE ICDCS 2021\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we consider the Byzantine reliable broadcast problem on\nauthenticated and partially connected networks. The state-of-the-art method to\nsolve this problem consists in combining two algorithms from the literature.\nHandling asynchrony and faulty senders is typically done thanks to Gabriel\nBracha's authenticated double-echo broadcast protocol, which assumes an\nasynchronous fully connected network. Danny Dolev's algorithm can then be used\nto provide reliable communications between processes in the global fault model,\nwhere up to f processes among N can be faulty in a communication network that\nis at least 2f+1-connected. Following recent works that showed that Dolev's\nprotocol can be made more practical thanks to several optimizations, we show\nthat the state-of-the-art methods to solve our problem can be optimized thanks\nto layer-specific and cross-layer optimizations. Our simulations with the\nOmnet++ network simulator show that these optimizations can be efficiently\ncombined to decrease the total amount of information transmitted or the\nprotocol's latency (e.g., respectively, -25% and -50% with a 16B payload, N=31\nand f=4) compared to the state-of-the-art combination of Bracha's and Dolev's\nprotocols.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 10:43:32 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Bonomi", "Silvia", ""], ["Decouchant", "J\u00e9r\u00e9mie", ""], ["Farina", "Giovanni", ""], ["Rahli", "Vincent", ""], ["Tixeuil", "S\u00e9bastien", ""]]}, {"id": "2104.03818", "submitter": "Boubakr Nour", "authors": "Boubakr Nour and Soumaya Cherkaoui", "title": "A Network-based Compute Reuse Architecture for IoT Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The tremendous advancements in the Internet of Things (IoT) increasingly\ninvolve computationally intensive services. These services often require more\ncomputation resources than can entirely be satisfied on local IoT devices.\nCloud computing is traditionally used to provide unlimited computation\nresources at distant servers. However, such remote computation may not address\nthe short-delay constraints that many of today's IoT applications require. Edge\ncomputing allows offloading computing close to end users to overcome\ncomputation and delay issues. Nonetheless, the edge servers may suffer from\ncomputing inefficiencies. Indeed, some IoT applications are invoked multiple\ntimes by multiple devices. These invocations are often used with the same or\nsimilar input data, which leads to the same computational output (results).\nStill, the edge server willfully executes all received redundant tasks. In this\nwork, we investigate the use of the computation reuse concept at the edge\nserver. We design a network-based computation reuse architecture for IoT\napplications. The architecture stores previously executed results and reuses\nthem to satisfy newly arrived similar tasks instead of performing computation\nfrom scratch. By doing so, we eliminate redundant computation, optimize\nresource utilization, and decrease task completion time. We implemented the\narchitecture and evaluated its performance both at the networking and\napplication levels. From the networking perspective, we reach up to an 80\\%\nreduction in task completion time and up to 60\\% reduction in resource\nutilization. From the application perspective, we achieve up to 90\\%\ncomputation correctness and accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 14:57:00 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Nour", "Boubakr", ""], ["Cherkaoui", "Soumaya", ""]]}, {"id": "2104.04060", "submitter": "Brice Ekane Apah", "authors": "Brice Ekane, Yohan Pipereau, Boris Teabe, Alain Tchana, Gael Thomas,\n  Noel de palma, Daniel Hagimont", "title": "Network in Disaggregated Datacenters", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, datacenters lean on a computer-centric approach based on monolithic\nservers which include all necessary hardware resources (mainly CPU, RAM,\nnetwork and disks) to run applications. Such an architecture comes with two\nmain limitations: (1) difficulty to achieve full resource utilization and (2)\ncoarse granularity for hardware maintenance. Recently, many works investigated\na resource-centric approach called disaggregated architecture where the\ndatacenter is composed of self-content resource boards interconnected using\nfast interconnection technologies, each resource board including instances of\none resource type. The resource-centric architecture allows each resource to be\nmanaged (maintenance, allocation) independently. LegoOS is the first work which\nstudied the implications of disaggregation on the operating system, proposing\nto disaggregate the operating system itself. They demonstrated the suitability\nof this approach, considering mainly CPU and RAM resources. However, they\ndidn't study the implication of disaggregation on network resources. We\nreproduced a LegoOS infrastructure and extended it to support disaggregated\nnetworking. We show that networking can be disaggregated following the same\nprinciples, and that classical networking optimizations such as DMA, DDIO or\nloopback can be reproduced in such an environment. Our evaluations show the\nviability of the approach and the potential of future disaggregated\ninfrastructures.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 23:27:02 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Ekane", "Brice", ""], ["Pipereau", "Yohan", ""], ["Teabe", "Boris", ""], ["Tchana", "Alain", ""], ["Thomas", "Gael", ""], ["de palma", "Noel", ""], ["Hagimont", "Daniel", ""]]}, {"id": "2104.04135", "submitter": "Ginno Mill\\'an", "authors": "G. Mill\\'an", "title": "On the Generation of Self-similar with Long-range Dependent Traffic\n  Using Piecewise Affine Chaotic One-dimensional Maps (Extended Version)", "comments": "13 pages, in Spanish, 10 figures, 4 tables, Review Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A qualitative and quantitative extension of the chaotic models used to\ngenerate self-similar traffic with long-range dependence (LRD) is presented by\nmeans of the formulation of a model that considers the use of piecewise affine\none-dimensional maps. Based on the disaggregation of the temporal series\ngenerated, a valid explanation of the behavior of the values of Hurst exponent\nis proposed and the feasibility of their control from the parameters of the\nproposed model is shown.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 15:36:51 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Mill\u00e1n", "G.", ""]]}, {"id": "2104.04164", "submitter": "Chao Ren", "authors": "Chao Ren and Jingze Hou and Biao Pan", "title": "3D Wireless Channel Modeling for Multi-layer Network on Chip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The resource constraints and accuracy requirements for Internet of Things\n(IoT) memory chips need three-dimensional (3D) monolithic integrated circuits,\nof which the increasing stack layers (currently more than 176) also cause\nexcessive energy consumption and increasing wire length. In this paper, a novel\n3D wireless network on chips (3DWiNoCs) model transmitting signal directly to\nthe destination in arbitrary layer is proposed and characterized. However, due\nto the the reflection and refraction characteristics in each layer, the complex\nand diverse wireless paths in 3DWiNoC add great difficulty to the channel\ncharacterization. To facilitate the modeling in massive layer NoC situation,\nboth boundary-less model boundary-constrained 3DWiNoC model are proposed, of\nwhich the channel gain can be obtained by a computational efficient approximate\nalgorithm. These 3DWiNoC models with approximation algorithm can well\ncharacterize the 3DWiNoC channel in aspect of complete reflection and\nrefraction characteristics, and avoid massive wired connections, high power\nconsumption of cross-layer communication and high-complexity of 3DWiNoC channel\ncharacterization. Numerical results show that: 1) The difference rate between\nthe two models is lower than 0.001% (signal transmit through 20 layers); 2) the\nchannel gain decreases sharply if refract time increases; and 3) the\napproximate algorithm can achieve an acceptable accuracy (error rate lower than\n0.1%).\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 02:42:02 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Ren", "Chao", ""], ["Hou", "Jingze", ""], ["Pan", "Biao", ""]]}, {"id": "2104.04293", "submitter": "Iosif Salem", "authors": "Krzysztof Pietrzak (1), Iosif Salem (2), Stefan Schmid (2), Michelle\n  Yeo (1) ((1) IST Austria, (2) Faculty of Computer Science, University of\n  Vienna)", "title": "LightPIR: Privacy-Preserving Route Discovery for Payment Channel\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Payment channel networks are a promising approach to improve the scalability\nof cryptocurrencies: they allow to perform transactions in a peer-to-peer\nfashion, along multi-hop routes in the network, without requiring consensus on\nthe blockchain. However, during the discovery of cost-efficient routes for the\ntransaction, critical information may be revealed about the transacting\nentities.\n  This paper initiates the study of privacy-preserving route discovery\nmechanisms for payment channel networks. In particular, we present LightPIR, an\napproach which allows a source to efficiently discover a shortest path to its\ndestination without revealing any information about the endpoints of the\ntransaction. The two main observations which allow for an efficient solution in\nLightPIR are that: (1) surprisingly, hub labelling algorithms - which were\ndeveloped to preprocess \"street network like\" graphs so one can later\nefficiently compute shortest paths - also work well for the graphs underlying\npayment channel networks, and that (2) hub labelling algorithms can be directly\ncombined with private information retrieval.\n  LightPIR relies on a simple hub labeling heuristic on top of existing hub\nlabeling algorithms which leverages the specific topological features of\ncryptocurrency networks to further minimize storage and bandwidth overheads. In\na case study considering the Lightning network, we show that our approach is an\norder of magnitude more efficient compared to a privacy-preserving baseline\nbased on using private information retrieval on a database that stores all\npairs shortest paths.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 10:41:23 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Pietrzak", "Krzysztof", ""], ["Salem", "Iosif", ""], ["Schmid", "Stefan", ""], ["Yeo", "Michelle", ""]]}, {"id": "2104.04297", "submitter": "Chathura Sarathchandra", "authors": "Chathura Sarathchandra, Kay Haensge, Sebastian Robitzsch, Mona\n  Ghassemian, Ulises Olvera-Hernandez", "title": "Enabling Bi-directional Haptic Control in Next Generation Communication\n  Systems: Research, Standards, and Vision", "comments": "Submitted to IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human sensing information such as audio (hearing) and visual (sight) or a\ncombination thereof audiovisual are transferred over communication networks.\nYet interacting sense of touch (haptic) and particularly the kinaesthetic\n(muscular movement) component has much stricter end-to-end latency\ncommunication requirements between tactile ends. The statements in this paper,\nto enable bi-directional haptic control, indeed follow the widely accepted\nunderstanding that edge computing is a key driver behind Tactile Internet\naiming to bring control and user plane services closer to where they are\nneeded. However, with an updated wider analysis of (pre)standardisation\nactivities that are chartered around Tactile Internet, this paper highlights\nthe technology gaps and recommends open research topics in this area.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 10:58:36 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Sarathchandra", "Chathura", ""], ["Haensge", "Kay", ""], ["Robitzsch", "Sebastian", ""], ["Ghassemian", "Mona", ""], ["Olvera-Hernandez", "Ulises", ""]]}, {"id": "2104.04479", "submitter": "Carlos Bendicho PhD", "authors": "Carlos Bendicho", "title": "Techno-Economic Assessment Models for 5G", "comments": "12 pages, 4 figures, 1 table", "journal-ref": "Proceedings of The 4th International Conference on Modern Research\n  in Science, Engineering and Technology, 2021", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the characteristics a techno-economic model for 5G should\nhave considering both mobile network operators perspective and end users needs.\nIt also presents a review and classification of models in the literature based\non the characteristics of such theoretical techno-economic reference model. The\nperformed analysis identifies current gaps in the techno-economic modeling\nliterature for 5G architectures and shows it can be enhanced using agile\ntechno-economic models like the Universal Techno-Economic Model (UTEM) created\nand developed by the author to industrialize assessment of different\ntechnological solutions, considering all market players perspectives and\napplicable to decision-making in multiple domains. This model can be used for\nan effective and agile 5G techno-economic assessment, including not only\nnetwork deployment perspective but also customers and end users requirements as\nwell as other stakeholders to select the most adequate 5G architectural\nsolution considering both technical and economic feasibility. UTEM model is\ncurrently available for all industry stakeholders under specific license of\nuse.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 16:56:26 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Bendicho", "Carlos", ""]]}, {"id": "2104.04492", "submitter": "Chih-Wei Huang", "authors": "Chih-Wei Huang, Yen-Cheng Chou, Hong-Yunn Chen, Cheng-Fu Chou", "title": "Joint QoS-Aware Scheduling and Precoding for Massive MIMO Systems via\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of mobile networks proliferates the demands of high\ndata rate, low latency, and high-reliability applications for the\nfifth-generation (5G) and beyond (B5G) mobile networks. Concurrently, the\nmassive multiple-input-multiple-output (MIMO) technology is essential to\nrealize the vision and requires coordination with resource management functions\nfor high user experiences. Though conventional cross-layer adaptation\nalgorithms have been developed to schedule and allocate network resources, the\ncomplexity of resulting rules is high with diverse quality of service (QoS)\nrequirements and B5G features. In this work, we consider a joint user\nscheduling, antenna allocation, and precoding problem in a massive MIMO system.\nInstead of directly assigning resources, such as the number of antennas, the\nallocation process is transformed into a deep reinforcement learning (DRL)\nbased dynamic algorithm selection problem for efficient Markov decision process\n(MDP) modeling and policy training. Specifically, the proposed utility function\nintegrates QoS requirements and constraints toward a long-term system-wide\nobjective that matches the MDP return. The componentized action structure with\naction embedding further incorporates the resource management process into the\nmodel. Simulations show 7.2% and 12.5% more satisfied users against static\nalgorithm selection and related works under demanding scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 17:19:23 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Huang", "Chih-Wei", ""], ["Chou", "Yen-Cheng", ""], ["Chen", "Hong-Yunn", ""], ["Chou", "Cheng-Fu", ""]]}, {"id": "2104.04572", "submitter": "Le Xia", "authors": "Le Xia, Yao Sun, Rafiq Swash, Lina Mohjazi, Lei Zhang, and Muhammad\n  Ali Imran", "title": "Smart and Secure CAV Networks Empowered by AI-Enabled Blockchain: Next\n  Frontier for Intelligent Safe-Driving Assessment", "comments": "8 pages, 6 figures, this paper has been submitted to IEEE Network\n  Magazine and is still awaiting the review results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Securing safe-driving for connected and autonomous vehicles (CAVs) continues\nto be a widespread concern despite various sophisticated functions delivered by\nartificial intelligence for in-vehicle devices. Besides, diverse malicious\nnetwork attacks become ubiquitous along with the worldwide implementation of\nthe Internet of Vehicles, which exposes a range of reliability and privacy\nthreats for managing data in CAV networks. Combined with the fact that the\ncapability of existing CAVs in handling intensive computation tasks is limited,\nthis implies a need for designing an efficient assessment system to guarantee\nautonomous driving safety without compromising data security. Motivated by\nthis, in this article, we propose a novel framework, namely Blockchain-enabled\nintElligent Safe-driving assessmenT (BEST), that offers a smart and reliable\napproach for conducting safe driving supervision while protecting vehicular\ninformation. Specifically, a promising solution that exploits a long short-term\nmemory model is introduced to assess the safety level of the moving CAVs. Then,\nwe investigate how a distributed blockchain obtains adequate trustworthiness\nand robustness for CAV data by adopting a byzantine fault tolerance-based\ndelegated proof-of-stake consensus mechanism. Simulation results demonstrate\nthat our presented BEST gains better data credibility with a higher prediction\naccuracy for vehicular safety assessment when compared with existing schemes.\nFinally, we discuss several open challenges that need to be addressed in future\nCAV networks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 19:08:34 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 11:03:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Xia", "Le", ""], ["Sun", "Yao", ""], ["Swash", "Rafiq", ""], ["Mohjazi", "Lina", ""], ["Zhang", "Lei", ""], ["Imran", "Muhammad Ali", ""]]}, {"id": "2104.04623", "submitter": "Andrea Bonfante", "authors": "Andrea Bonfante, Lorenzo Galati Giordano, Irene Macaluso and Nicola\n  Marchetti", "title": "Performance of Predictive Indoor mmWave Networks with Dynamic Blockers", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider millimeter Wave (mmWave) technology to provide\nreliable wireless network service within factories where links may experience\nrapid and temporary fluctuations of the received signal power due to dynamic\nblockers, such as humans and robots, moving in the environment. We propose a\nnovel beam recovery procedure that leverages Machine Learning (ML) tools to\npredict the starting and finishing of blockage events. This erases the delay\nintroduced by current 5G New Radio (5G-NR) procedures when switching to an\nalternative serving base station and beam, and then re-establish the primary\nconnection after the blocker has moved away. Firstly, we generate synthetic\ndata using a detailed system-level simulator that integrates the most recent\n3GPP 3D Indoor channel models and the geometric blockage Model-B. Then, we use\nthe generated data to train offline a set of beam-specific Deep Neural Network\n(DNN) models that provide predictions about the beams' blockage states.\nFinally, we deploy the DNN models online into the system-level simulator to\nevaluate the benefits of the proposed solution. Our prediction-based beam\nrecovery procedure guarantee higher signal level stability and up to $82\\%$\ndata rate improvement with respect detection-based methods when blockers move\nat speed of $2$ m/s.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 22:27:17 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bonfante", "Andrea", ""], ["Giordano", "Lorenzo Galati", ""], ["Macaluso", "Irene", ""], ["Marchetti", "Nicola", ""]]}, {"id": "2104.04645", "submitter": "Frank Slyne", "authors": "Line Larsen, Frank Slyne, Ghizlane Mountaser, Marco Ruffini, Toktam\n  Mahmoodi", "title": "Experimental Demonstration of RAN Functional Split over virtual PON\n  Transport Network", "comments": "11 figures, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloud-Radio Access Networks (Cloud-RANs) are separating the mobile networks\nbase station functions into three units, the connection between the two of them\nis referred to as the fronthaul network. This work demonstrates the\ntransmission of user data transport blocks between the distributed Medium\nAccess Control (MAC) layer and local Physical (PHY) layer in the radiounit over\na Passive Optical Network (PON). PON networks provide benefits in terms of\neconomy and flexibility when used for Cloud-RAN fronthaul transport. However,\nthe PON upstream scheduling can introduce additional latency that might not\nsatisfy the requirements imposed by Cloud-RAN functional split. In this work we\ndemonstrate how our virtual Dynamic Bandwidth Allocation(DBA) concept can be\nused to effectively communicate with the mobile Long Term Evolution (LTE)\nscheduler, adopting the well known cooperative DBA mechanism, to reduce the PON\nlatency to satisfactory values. Thus, our results show the feasibility ofusing\nPON technology as transport medium of the fronthaul for the MAC/PHY functional\nsplit, in a fully virtualised environment.Further background traffic is added,\nso that measurements show a more realistic scenario. The obtained round trip\ntimes indicates that using PON at fronthaul might be limited to the distance of\n11km for a synchronised scenario, or no compliance for a non-synchronised\nscenario.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 23:55:44 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Larsen", "Line", ""], ["Slyne", "Frank", ""], ["Mountaser", "Ghizlane", ""], ["Ruffini", "Marco", ""], ["Mahmoodi", "Toktam", ""]]}, {"id": "2104.04743", "submitter": "Mohammad Asif Habibi Mr.", "authors": "Mohammad Asif Habibi, Bin Han, Faqir Zarrar Yousaf, and Hans D.\n  Schotten", "title": "How Should Network Slice Instances be Provided to Multiple Use Cases of\n  a Single Vertical Industry?", "comments": null, "journal-ref": "in IEEE Communications Standards Magazine, vol. 4, no. 3, pp.\n  53-61, September 2020", "doi": "10.1109/MCOMSTD.001.1900050", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are a large number of vertical industries implementing multiple use\ncases, each use case characterized by diverging service, network, and\nconnectivity requirements such as automobile, manufacturing, power grid, etc.\nSuch heterogeneity cannot be effectively managed and efficiently mapped onto a\nsingle type of network slice instance (NSI). Thus the tailored provisioning of\nan end-to-end network slicing solution to a vertical industry that consists of\nmultiple use cases is a critical issue, which motivates this article, aimed at\nexploring this never-addressed and challenging research problem by proposing\nthe Use-case Specific Network Slicing and the SubNetwork Slicing concepts that\nenable the provisioning of Use-case-specific NSI(US-NSI) and GeNeric\nNSI(GN-NSI), respectively. Both approaches tackle the same technical issue of\nprovisioning, management, and orchestration of per vertical per use case NSIs\nin order to improve resource allocation and enhance network performance. The\narticle also presents the architectural frameworks for managing US-NSI and\nGN-NSI, which extend the service deployment concept and system architecture of\nnetwork slicing for vertical customers of fifth-generation (5G) mobile\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 12:01:48 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Habibi", "Mohammad Asif", ""], ["Han", "Bin", ""], ["Yousaf", "Faqir Zarrar", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2104.05026", "submitter": "Anna Melman", "authors": "Yaroslav Meshcheryakov, Anna Melman, Oleg Evsutin, Vladimir Morozov,\n  Yevgeni Koucheryavy", "title": "On performance of PBFT for IoT-applications with constrained devices", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems and the Internet of things (IoT) is becoming an\nintegral part of the digital society. The use of IoT services improves human\nlife in many ways. Protection against cyber threats is an important aspect of\nthe functioning of IoT devices. Malicious activities lead to confidential data\nleakages and incorrect performance of devices are becoming critical. Therefore,\ndevelopment of effective solutions that can protect both IoT devices data and\ndata exchange networks turns in to a real challenge. This study provides a\ncritical analysis of the feasibility of using blockchain technology to protect\nconstrained IoT devices data, justifies the choice of Practical Byzantine Fault\nTolerance (PBFT) consensus algorithm for implementation on such devices, and\nsimulates the main distributed ledger scenarios using PBFT. The simulation\nresults demonstrate the efficiency of the blockchain technology for constrained\ndevices and make it possible to evaluate the applicability limits of the chosen\nconsensus algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 15:20:12 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 09:39:23 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Meshcheryakov", "Yaroslav", ""], ["Melman", "Anna", ""], ["Evsutin", "Oleg", ""], ["Morozov", "Vladimir", ""], ["Koucheryavy", "Yevgeni", ""]]}, {"id": "2104.05117", "submitter": "Damu Ding", "authors": "Damu Ding, Marco Savi, Domenico Siracusa", "title": "Tracking Normalized Network Traffic Entropy to Detect DDoS Attacks in P4", "comments": "Submitted to TDSC on 2020-04-11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Denial-of-Service (DDoS) attacks represent a persistent threat to\nmodern telecommunications networks: detecting and counteracting them is still a\ncrucial unresolved challenge for network operators. DDoS attack detection is\nusually carried out in one or more central nodes that collect significant\namounts of monitoring data from networking devices, potentially creating issues\nrelated to network overload or delay in detection. The dawn of programmable\ndata planes in Software-Defined Networks can help mitigate this issue, opening\nthe door to the detection of DDoS attacks directly in the data plane of the\nswitches. However, the most widely-adopted data plane programming language,\nnamely P4, lacks supporting many arithmetic operations, therefore, some of the\nadvanced network monitoring functionalities needed for DDoS detection cannot be\nstraightforwardly implemented in P4. This work overcomes such a limitation and\npresents two novel strategies for flow cardinality and for normalized network\ntraffic entropy estimation that only use P4-supported operations and guarantee\na low relative error. Additionally, based on these contributions, we propose a\nDDoS detection strategy relying on variations of the normalized network traffic\nentropy. Results show that it has comparable or higher detection accuracy than\nstate-of-the-art solutions, yet being simpler and entirely executed in the data\nplane.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 21:43:23 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ding", "Damu", ""], ["Savi", "Marco", ""], ["Siracusa", "Domenico", ""]]}, {"id": "2104.05494", "submitter": "Asad Ali", "authors": "Asad Ali, Olga Galinina, and Sergey Andreev", "title": "System-Level Dynamics of Highly Directional Distributed Networks", "comments": "Accepted to IEEE Wireless Communications Letters on April 5, 2021.\n  Copyright may be transferred without further notice after which this version\n  may become non-available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While highly directional communications may offer considerable improvements\nin the link data rate and over-the-air latency of high-end wearable devices,\nthe system-level capacity trade-offs call for separate studies with respect to\nthe employed multiple access procedures and the network dynamics in general.\nThis letter proposes a framework for estimating the system-level area\nthroughput in dynamic distributed networks of highly-directional paired\ndevices. We provide numerical expressions for the steady-state distribution of\nthe number of actively communicating pairs and the probability of successful\nsession initialization as well as derive the corresponding closed-form\napproximation for dense deployments.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:25:13 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ali", "Asad", ""], ["Galinina", "Olga", ""], ["Andreev", "Sergey", ""]]}, {"id": "2104.05509", "submitter": "Abdullatif Albaseer Mr", "authors": "Abdullatif Albaseer, Mohamed Abdallah, Ala Al-Fuqaha, and Aiman Erbad", "title": "Threshold-Based Data Exclusion Approach for Energy-Efficient Federated\n  Edge Learning", "comments": "accepted to IEEE ICC 2021 WS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated edge learning (FEEL) is a promising distributed learning technique\nfor next-generation wireless networks. FEEL preserves the user's privacy,\nreduces the communication costs, and exploits the unprecedented capabilities of\nedge devices to train a shared global model by leveraging a massive amount of\ndata generated at the network edge. However, FEEL might significantly shorten\nenergy-constrained participating devices' lifetime due to the power consumed\nduring the model training round. This paper proposes a novel approach that\nendeavors to minimize computation and communication energy consumption during\nFEEL rounds to address this issue. First, we introduce a modified local\ntraining algorithm that intelligently selects only the samples that enhance the\nmodel's quality based on a predetermined threshold probability. Then, the\nproblem is formulated as joint energy minimization and resource allocation\noptimization problem to obtain the optimal local computation time and the\noptimal transmission time that minimize the total energy consumption\nconsidering the worker's energy budget, available bandwidth, channel states,\nbeamforming, and local CPU speed. After that, we introduce a tractable solution\nto the formulated problem that ensures the robustness of FEEL. Our simulation\nresults show that our solution substantially outperforms the baseline FEEL\nalgorithm as it reduces the local consumed energy by up to 79%.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 13:34:40 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Albaseer", "Abdullatif", ""], ["Abdallah", "Mohamed", ""], ["Al-Fuqaha", "Ala", ""], ["Erbad", "Aiman", ""]]}, {"id": "2104.05534", "submitter": "Niloofar Bahadori", "authors": "Niloofar Bahadori, Mahmoud Nabil, Brian Kelley, Abdollah Homaifar", "title": "Enabling Content-Centric Device-to-Device Communication in the\n  Millimeter-Wave Band", "comments": "Accepted in IEEE Transaction on Mobile Computing", "journal-ref": null, "doi": "10.1109/TMC.2021.3071468", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The growth in wireless traffic and mobility of devices have congested the\ncore network significantly. This bottleneck, along with spectrum scarcity, made\nthe conventional cellular networks insufficient for the dissemination of large\ncontents. In this paper, we propose a novel scheme that enables efficient\ninitialization of CCN-based D2D networks in the mmWave band through addressing\ndecentralized D2D peer association and antenna beamwidth selection. The\nproposed scheme considers mmWave characteristics such as directional\ncommunication and blockage susceptibility. We propose a heuristic peer\nassociation algorithm to associate D2D users using context information,\nincluding link stability time and content availability. The performance of the\nproposed scheme in terms of data throughput and transmission efficiency is\nevaluated through extensive simulations. Simulation results show that the\nproposed scheme improves network performance significantly and outperforms\nother methods in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:59:55 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bahadori", "Niloofar", ""], ["Nabil", "Mahmoud", ""], ["Kelley", "Brian", ""], ["Homaifar", "Abdollah", ""]]}, {"id": "2104.05569", "submitter": "Tao Lin", "authors": "Tao Lin", "title": "Deep Learning for IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning and other machine learning approaches are deployed to many\nsystems related to Internet of Things or IoT. However, it faces challenges that\nadversaries can take loopholes to hack these systems through tampering history\ndata. This paper first presents overall points of adversarial machine learning.\nThen, we illustrate traditional methods, such as Petri Net cannot solve this\nnew question efficiently. To help IoT data analysis more efficient, we propose\na retrieval method based on deep learning (recurrent neural network). Besides,\nthis paper presents a research on data retrieval solution to avoid hacking by\nadversaries in the fields of adversary machine leaning. It further directs the\nnew approaches in terms of how to implementing this framework in IoT settings\nbased on adversarial deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 15:39:30 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Lin", "Tao", ""]]}, {"id": "2104.05586", "submitter": "Francesc Wilhelmi", "authors": "Francesc Wilhelmi and Lorenza Giupponi", "title": "Discrete-Time Analysis of Wireless Blockchain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain (BC) technology can revolutionize future networks by providing a\ndistributed, secure, and unalterable way to boost collaboration among\noperators, users, and other stakeholders. Its implementations have\ntraditionally been supported by wired communications, with performance\nindicators like the high latency introduced by the BC being one of the key\ntechnology drawbacks. However, when applied to wireless communications, the\nperformance of BC remains unknown, especially if running over contention-based\nnetworks. In this paper, we evaluate the latency performance of BC technology\nwhen the supporting communication platform is wireless, specifically we focus\non IEEE 802.11ax, for the use case of users' radio resource provisioning. For\nthat purpose, we propose a discrete-time Markov model to capture the expected\ndelay incurred by the BC. Unlike other models in the literature, we consider\nthe effect that timers and forks have on the end-to-end latency.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 15:59:46 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wilhelmi", "Francesc", ""], ["Giupponi", "Lorenza", ""]]}, {"id": "2104.05960", "submitter": "Ning Liu", "authors": "Ning Liu, Songlei Jian, Dongsheng Li, Yiming Zhang, Zhiquan Lai,\n  Hongzuo Xu", "title": "Hierarchical Adaptive Pooling by Capturing High-order Dependency for\n  Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) have been proven to be mature enough for handling\ngraph-structured data on node-level graph representation learning tasks.\nHowever, the graph pooling technique for learning expressive graph-level\nrepresentation is critical yet still challenging. Existing pooling methods\neither struggle to capture the local substructure or fail to effectively\nutilize high-order dependency, thus diminishing the expression capability. In\nthis paper we propose HAP, a hierarchical graph-level representation learning\nframework, which is adaptively sensitive to graph structures, i.e., HAP\nclusters local substructures incorporating with high-order dependencies. HAP\nutilizes a novel cross-level attention mechanism MOA to naturally focus more on\nclose neighborhood while effectively capture higher-order dependency that may\ncontain crucial information. It also learns a global graph content GCont that\nextracts the graph pattern properties to make the pre- and post-coarsening\ngraph content maintain stable, thus providing global guidance in graph\ncoarsening. This novel innovation also facilitates generalization across graphs\nwith the same form of features. Extensive experiments on fourteen datasets show\nthat HAP significantly outperforms twelve popular graph pooling methods on\ngraph classification task with an maximum accuracy improvement of 22.79%, and\nexceeds the performance of state-of-the-art graph matching and graph similarity\nlearning algorithms by over 3.5% and 16.7%.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 06:22:24 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Liu", "Ning", ""], ["Jian", "Songlei", ""], ["Li", "Dongsheng", ""], ["Zhang", "Yiming", ""], ["Lai", "Zhiquan", ""], ["Xu", "Hongzuo", ""]]}, {"id": "2104.06131", "submitter": "Shuping Dang", "authors": "Shuping Dang, Chuanting Zhang, Basem Shihada, Mohamed-Slim Alouini", "title": "Big Communications: Connect the Unconnected", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present the analysis of the digital divide to illustrate\nthe unfair access to the benefits brought by information and communications\ntechnology (ICT) over the globe and provide our solution termed big\ncommunications (BigCom) to close the digital divide and democratize the\nbenefits of ICT. To facilitate the implementation of BigCom, we give a complete\nframework of BigCom considering both technological and non-technological\nfactors as well as a set of suggestions for content providers, mobile network\noperators, and governments. By implementing BigCom, we aim to connect the last\nfour billion unconnected people living in far-flung and underdeveloped areas\nand achieve the goal of global and ubiquitous connectivity for everyone in the\n6G era.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 12:08:28 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 06:46:46 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 07:08:16 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Dang", "Shuping", ""], ["Zhang", "Chuanting", ""], ["Shihada", "Basem", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2104.06139", "submitter": "Yiping Xie", "authors": "Chao Xu, Yiping Xie, Xijun Wang, Howard H. Yang, Dusit Niyato, Tony Q.\n  S. Quek", "title": "Optimizing the Long-Term Average Reward for Continuing MDPs: A Technical\n  Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we have struck the balance between the information freshness, in\nterms of age of information (AoI), experienced by users and energy consumed by\nsensors, by appropriately activating sensors to update their current status in\ncaching enabled Internet of Things (IoT) networks [1]. To solve this problem,\nwe cast the corresponding status update procedure as a continuing Markov\nDecision Process (MDP) (i.e., without termination states), where the number of\nstate-action pairs increases exponentially with respect to the number of\nconsidered sensors and users. Moreover, to circumvent the curse of\ndimensionality, we have established a methodology for designing deep\nreinforcement learning (DRL) algorithms to maximize (resp. minimize) the\naverage reward (resp. cost), by integrating R-learning, a tabular reinforcement\nlearning (RL) algorithm tailored for maximizing the long-term average reward,\nand traditional DRL algorithms, initially developed to optimize the discounted\nlong-term cumulative reward rather than the average one. In this technical\nreport, we would present detailed discussions on the technical contributions of\nthis methodology.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 12:29:55 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 10:32:18 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Xu", "Chao", ""], ["Xie", "Yiping", ""], ["Wang", "Xijun", ""], ["Yang", "Howard H.", ""], ["Niyato", "Dusit", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2104.06188", "submitter": "Foivos Michelinakis", "authors": "Salman Mohebi, Foivos Michelinakis, Ahmed Elmokashfi, Ole\n  Gr{\\o}ndalen, Kashif Mahmood, Andrea Zanella", "title": "Sectors, Beams and Environmental Impact on Commercial 5G mmWave Cell\n  Coverage: an Empirical Study", "comments": "6 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the results of a measurement campaign to investigate and\nanalyze the performance of a 5G mmWave cell. We evaluate the signal and beam\ncoverage map of an operational network, considering various scenarios,\nincluding human body blockage effects, foliage-caused and rain-induced\nattenuation, and water surface effects. To the best of our knowledge, this\npaper is the first to report on a commercial deployment while not treating the\nradio as a black box. This measurement analysis provides useful information for\nresearchers and 5G verticals to fully understand and appropriately model the\nmmWave signals propagation in a real-world and operational deployment.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 13:36:54 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Mohebi", "Salman", ""], ["Michelinakis", "Foivos", ""], ["Elmokashfi", "Ahmed", ""], ["Gr\u00f8ndalen", "Ole", ""], ["Mahmood", "Kashif", ""], ["Zanella", "Andrea", ""]]}, {"id": "2104.06277", "submitter": "Damu Ding", "authors": "Damu Ding, Marco Savi, Federico Pederzolli, Mauro Campanella, and\n  Domenico Siracusa", "title": "In-Network Volumetric DDoS Victim Identification Using Programmable\n  Commodity Switches", "comments": "Accepted by IEEE Transactions on Network and Service Management\n  Special issue on Latest Developments for Security Management of Networks and\n  Services", "journal-ref": null, "doi": "10.1109/TNSM.2021.3073597", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volumetric distributed Denial-of-Service (DDoS) attacks have become one of\nthe most significant threats to modern telecommunication networks. However,\nmost existing defense systems require that detection software operates from a\ncentralized monitoring collector, leading to increased traffic load and delayed\nresponse. The recent advent of Data Plane Programmability (DPP) enables an\nalternative solution: threshold-based volumetric DDoS detection can be\nperformed directly in programmable switches to skim only potentially hazardous\ntraffic, to be analyzed in depth at the controller. In this paper, we first\nintroduce the BACON data structure based on sketches, to estimate\nper-destination flow cardinality, and theoretically analyze it. Then we employ\nit in a simple in-network DDoS victim identification strategy, INDDoS, to\ndetect the destination IPs for which the number of incoming connections exceeds\na pre-defined threshold. We describe its hardware implementation on a\nTofino-based programmable switch using the domain-specific P4 language, proving\nthat some limitations imposed by real hardware to safeguard processing speed\ncan be overcome to implement relatively complex packet manipulations. Finally,\nwe present some experimental performance measurements, showing that our\nprogrammable switch is able to keep processing packets at line-rate while\nperforming volumetric DDoS detection, and also achieves a high F1 score on DDoS\nvictim identification.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 15:09:09 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 11:52:13 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 18:16:01 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ding", "Damu", ""], ["Savi", "Marco", ""], ["Pederzolli", "Federico", ""], ["Campanella", "Mauro", ""], ["Siracusa", "Domenico", ""]]}, {"id": "2104.06374", "submitter": "Aly El Gamal", "authors": "Ahmed P. Mohamed, Abu Shafin Mohammad Mahdee Jameel, Aly El Gamal", "title": "Knowledge Distillation For Wireless Edge Learning", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a framework for predicting frame errors in the\ncollaborative spectrally congested wireless environments of the DARPA Spectrum\nCollaboration Challenge (SC2) via a recently collected dataset. We employ\ndistributed deep edge learning that is shared among edge nodes and a central\ncloud. Using this close-to-practice dataset, we find that widely used federated\nlearning approaches, specially those that are privacy preserving, are worse\nthan local training for a wide range of settings. We hence utilize the\nsynthetic minority oversampling technique to maintain privacy via avoiding the\ntransfer of local data to the cloud, and utilize knowledge distillation with an\naim to benefit from high cloud computing and storage capabilities. The proposed\nframework achieves overall better performance than both local and federated\ntraining approaches, while being robust against catastrophic failures as well\nas challenging channel conditions that result in high frame error rates.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:20:08 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Mohamed", "Ahmed P.", ""], ["Jameel", "Abu Shafin Mohammad Mahdee", ""], ["Gamal", "Aly El", ""]]}, {"id": "2104.06375", "submitter": "Aly El Gamal", "authors": "Jinho Yi and Aly El Gamal", "title": "Gradient-based Adversarial Deep Modulation Classification with\n  Data-driven Subsampling", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic modulation classification can be a core component for intelligent\nspectrally efficient wireless communication networks, and deep learning\ntechniques have recently been shown to deliver superior performance to\nconventional model-based strategies, particularly when distinguishing between a\nlarge number of modulation types. However, such deep learning techniques have\nalso been recently shown to be vulnerable to gradient-based adversarial attacks\nthat rely on subtle input perturbations, which would be particularly feasible\nin a wireless setting via jamming. One such potent attack is the one known as\nthe Carlini-Wagner attack, which we consider in this work. We further consider\na data-driven subsampling setting, where several recently introduced\ndeep-learning-based algorithms are employed to select a subset of samples that\nlead to reducing the final classifier's training time with minimal loss in\naccuracy. In this setting, the attacker has to make an assumption about the\nemployed subsampling strategy, in order to calculate the loss gradient. Based\non state of the art techniques available to both the attacker and defender, we\nevaluate best strategies under various assumptions on the knowledge of the\nother party's strategy. Interestingly, in presence of knowledgeable attackers,\nwe identify computational cost reduction opportunities for the defender with no\nor minimal loss in performance.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:28:04 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Yi", "Jinho", ""], ["Gamal", "Aly El", ""]]}, {"id": "2104.06550", "submitter": "Jose Moura", "authors": "Hugo Alves, Luis Silva, Rui Marinheiro, Jose Moura", "title": "PMIPv6 Integrated with MIH for Flow Mobility Management: a Real Testbed\n  with Simultaneous Multi-Access in Heterogeneous Mobile Networks", "comments": "Accepted in Wireless Personal Communications", "journal-ref": null, "doi": "10.1007/s11277-017-4908-6", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The exponential growth of the number of multihomed mobile devices is changing\nthe way how we can connect to the Internet. Our mobile devices are demanding\nfor more network resources, in terms of traffic volume and QoS requirements.\nUnfortunately, it is very hard to a multihomed device to be simultaneously\nconnected to the network through multiple links. The current work enhances the\nnetwork access of multihomed devices agnostically to the deployed access\ntechnologies. This enhancement is achieved by using simultaneously all of the\nmobile devices interfaces, and by routing each individual data flow through the\nmost convenient access technology. The proposed solution is only deployed at\nthe network side and it extends Proxy Mobile IPv6 with flow mobility in a\ncompletely transparent way to mobile nodes. In fact, it gives particular\nattention to the handover mechanisms, by improving the detection and attachment\nof nodes in the network, with the inclusion of the IEEE 802.21 standard in the\nsolution. This provides the necessary implementation and integration details to\nextend a network topology with femtocell devices. Each femtocell is equipped\nwith various network interfaces supporting a diverse set of access\ntechnologies. There is also a decision entity that manages individually each\ndata flow according to its QoS / QoE requisites. The proposed solution has been\ndeveloped and extensively tested with a real prototype. Evaluation results\nevidence that the overhead for using the solution is negligible as compared to\nthe offered advantages such as: the support of flow mobility, the fulfil of\nVoIP functional requisites, the session continuity in spite of flows mobility,\nits low overhead, its high scalability, and the complete transparency of the\nproposed solution to the user terminals.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 23:38:09 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Alves", "Hugo", ""], ["Silva", "Luis", ""], ["Marinheiro", "Rui", ""], ["Moura", "Jose", ""]]}, {"id": "2104.06758", "submitter": "Xuelin Cao", "authors": "Xuelin Cao, Bo Yang, Chongwen Huang, Chau Yuen, Marco Di Renzo, Dusit\n  Niyato, and Zhu Han", "title": "Reconfigurable Intelligent Surface-Assisted Aerial-Terrestrial\n  Communications via Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aerial-terrestrial communication system constitutes an efficient paradigm\nfor supporting and complementing terrestrial communications. However, the\nbenefits of such a system cannot be fully exploited, especially when the\nline-of-sight (LoS) transmissions are prone to severe deterioration due to\ncomplex propagation environments in urban areas. The emerging technology of\nreconfigurable intelligent surfaces (RISs) has recently become a potential\nsolution to mitigate propagation-induced impairments and improve wireless\nnetwork coverage. Motivated by these considerations, in this paper, we address\nthe coverage and link performance problems of the aerial-terrestrial\ncommunication system by proposing an RIS-assisted transmission strategy. In\nparticular, we design an adaptive RIS-assisted transmission protocol, in which\nthe channel estimation, transmission strategy, and data transmission are\nindependently implemented in a frame. On this basis, we formulate an\nRIS-assisted transmission strategy optimization problem as a mixed-integer\nnon-linear program (MINLP) to maximize the overall system throughput. We then\nemploy multi-task learning to speed up the solution to the problem. Benefiting\nfrom multi-task learning, the computation time is reduced by about four orders\nof magnitude. Numerical results show that the proposed RIS-assisted\ntransmission protocol significantly improves the system throughput and reduces\nthe transmit power.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 10:35:22 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Cao", "Xuelin", ""], ["Yang", "Bo", ""], ["Huang", "Chongwen", ""], ["Yuen", "Chau", ""], ["Di Renzo", "Marco", ""], ["Niyato", "Dusit", ""], ["Han", "Zhu", ""]]}, {"id": "2104.06768", "submitter": "Augusto Luis Ballardini PhD", "authors": "Noelia Hern\\'andez, Ignacio Parra, H\\'ector Corrales, Rub\\'en\n  Izquierdo, Augusto Luis Ballardini, Carlota Salinas, Iv\\'an Garcia", "title": "WiFiNet: WiFi-based indoor localisation using CNNs", "comments": null, "journal-ref": "Expert Systems with Applications, Volume 177, 1 September 2021", "doi": "10.1016/j.eswa.2021.114906", "report-no": null, "categories": "cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Different technologies have been proposed to provide indoor localisation:\nmagnetic field, bluetooth , WiFi, etc. Among them, WiFi is the one with the\nhighest availability and highest accuracy. This fact allows for an ubiquitous\naccurate localisation available for almost any environment and any device.\nHowever, WiFi-based localisation is still an open problem.\n  In this article, we propose a new WiFi-based indoor localisation system that\ntakes advantage of the great ability of Convolutional Neural Networks in\nclassification problems. Three different approaches were used to achieve this\ngoal: a custom architecture called WiFiNet designed and trained specifically to\nsolve this problem and the most popular pre-trained networks using both\ntransfer learning and feature extraction.\n  Results indicate that WiFiNet is as a great approach for indoor localisation\nin a medium-sized environment (30 positions and 113 access points) as it\nreduces the mean localisation error (33%) and the processing time when compared\nwith state-of-the-art WiFi indoor localisation algorithms such as SVM.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 10:49:17 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Hern\u00e1ndez", "Noelia", ""], ["Parra", "Ignacio", ""], ["Corrales", "H\u00e9ctor", ""], ["Izquierdo", "Rub\u00e9n", ""], ["Ballardini", "Augusto Luis", ""], ["Salinas", "Carlota", ""], ["Garcia", "Iv\u00e1n", ""]]}, {"id": "2104.06913", "submitter": "Igor Sfiligoi", "authors": "Igor Sfiligoi, Michael Hare, David Schultz, Frank W\\\"urthwein,\n  Benedikt Riedel, Tom Hutton, Steve Barnet and Vladimir Brik", "title": "Managing Cloud networking costs for data-intensive applications by\n  provisioning dedicated network links", "comments": "8 pages, 7 figures, 4 tables, to be published in proceedings of\n  PEARC21", "journal-ref": null, "doi": "10.1145/3437359.3465563", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Many scientific high-throughput applications can benefit from the elastic\nnature of Cloud resources, especially when there is a need to reduce time to\ncompletion. Cost considerations are usually a major issue in such endeavors,\nwith networking often a major component; for data-intensive applications,\negress networking costs can exceed the compute costs. Dedicated network links\nprovide a way to lower the networking costs, but they do add complexity. In\nthis paper we provide a description of a 100 fp32 PFLOPS Cloud burst in support\nof IceCube production compute, that used Internet2 Cloud Connect service to\nprovision several logically-dedicated network links from the three major Cloud\nproviders, namely Amazon Web Services, Microsoft Azure and Google Cloud\nPlatform, that in aggregate enabled approximately 100 Gbps egress capability to\non-prem storage. It provides technical details about the provisioning process,\nthe benefits and limitations of such a setup and an analysis of the costs\nincurred.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 15:03:45 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Sfiligoi", "Igor", ""], ["Hare", "Michael", ""], ["Schultz", "David", ""], ["W\u00fcrthwein", "Frank", ""], ["Riedel", "Benedikt", ""], ["Hutton", "Tom", ""], ["Barnet", "Steve", ""], ["Brik", "Vladimir", ""]]}, {"id": "2104.06926", "submitter": "Juan Luis Herrera", "authors": "Juan Luis Herrera, Jaime Gal\\'an-Jim\\'enez, Javier Berrocal, Juan\n  Manuel Murillo", "title": "Optimizing Response Time in SDN-Edge Environments for Time-Strict IoT\n  Applications", "comments": "Submitted to IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of the Internet of Things (IoT) has opened new research lines that\nfocus on applying IoT applications to domains further beyond basic user-grade\napplications, such as Industry or Healthcare. These domains demand a very high\nQuality of Service (QoS), mainly a very short response time. In order to meet\nthese demands, some works are evaluating how to modularize and deploy IoT\napplications in different nodes of the infrastructure (edge, fog, cloud), as\nwell as how to place the network controllers, since these decisions affect the\nresponse time of the application. Some works in the literature have approached\nthis problem by providing separate plans for deployment and placing of\ncontrollers. However, this approach makes sub-optimal decisions, that\ncomplicate guaranteeing the demanded response time. To guarantee an optimal\nresponse time, it is crucial to solve the problem in a single effort that\nconsiders both, the networking and computing dimensions. In this work, we\nanalyze the influences between the response time of computing and networking in\nedge computing environments with SDN networks, merging both optimization\nefforts into a single one and proposing a solution to the joint problem. Our\nevaluation shows that our proposal can shorten response time by up to 28.97%\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 15:25:14 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Herrera", "Juan Luis", ""], ["Gal\u00e1n-Jim\u00e9nez", "Jaime", ""], ["Berrocal", "Javier", ""], ["Murillo", "Juan Manuel", ""]]}, {"id": "2104.06990", "submitter": "Cong Shen", "authors": "Cong Shen, Jie Xu, Sihui Zheng, Xiang Chen", "title": "Resource Rationing for Wireless Federated Learning: Concept, Benefits,\n  and Challenges", "comments": "7 pages, 6 pages, accepted to IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate a new resource allocation framework, which we term resource\nrationing, for wireless federated learning (FL). Unlike existing resource\nallocation methods for FL, resource rationing focuses on balancing resources\nacross learning rounds so that their collective impact on the federated\nlearning performance is explicitly captured. This new framework can be\nintegrated seamlessly with existing resource allocation schemes to optimize the\nconvergence of FL. In particular, a novel \"later-is-better\" principle is at the\nfront and center of resource rationing, which is validated empirically in\nseveral instances of wireless FL. We also point out technical challenges and\nresearch opportunities that are worth pursuing. Resource rationing highlights\nthe benefits of treating the emerging FL as a new class of service that has its\nown characteristics, and designing communication algorithms for this particular\nservice.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:16:33 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Shen", "Cong", ""], ["Xu", "Jie", ""], ["Zheng", "Sihui", ""], ["Chen", "Xiang", ""]]}, {"id": "2104.06993", "submitter": "Faris B Mismar", "authors": "Faris B. Mismar and Jakob Hoydis", "title": "Unsupervised Learning in Next-Generation Networks: Real-Time Performance\n  Self-Diagnosis", "comments": "5 pages, 5 figures. Submitted to IEEE Communications Letters", "journal-ref": null, "doi": "10.1109/LCOMM.2021.3101058", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter demonstrates the use of unsupervised machine learning to enable\nperformance self-diagnosis of next-generation cellular networks. We propose two\nsimplified applications of unsupervised learning that can enable real-time\nperformance self-diagnosis on edge nodes such as the radio access network\nintelligent controller (RIC). The first application detects anomalous\nperformance and finds its root cause of faults, configuration, or network\nprocedure failures. The second application uses clustering to learn the\nrelationship between two performance measures. Our proposed applications run in\nnear-constant time complexity, making them, combined with subject-matter\nexpertise validation, suitable real-time RIC applications for network\ndiagnosis.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:17:09 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 16:10:17 GMT"}, {"version": "v3", "created": "Sun, 27 Jun 2021 14:48:49 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Mismar", "Faris B.", ""], ["Hoydis", "Jakob", ""]]}, {"id": "2104.07183", "submitter": "Siamak Layeghy", "authors": "Mohanad Sarhan, Siamak Layeghy, Marius Portmann", "title": "An Explainable Machine Learning-based Network Intrusion Detection System\n  for Enabling Generalisability in Securing IoT Networks", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML)-based network intrusion detection systems bring many\nbenefits for enhancing the security posture of an organisation. Many systems\nhave been designed and developed in the research community, often achieving a\nperfect detection rate when evaluated using certain datasets. However, the high\nnumber of academic research has not translated into practical deployments.\nThere are a number of causes behind the lack of production usage. This paper\ntightens the gap by evaluating the generalisability of a common feature set to\ndifferent network environments and attack types. Therefore, two feature sets\n(NetFlow and CICFlowMeter) have been evaluated across three datasets, i.e.\nCSE-CIC-IDS2018, BoT-IoT, and ToN-IoT. The results showed that the NetFlow\nfeature set enhances the two ML models' detection accuracy in detecting\nintrusions across different datasets. In addition, due to the complexity of the\nlearning models, the SHAP, an explainable AI methodology, has been adopted to\nexplain and interpret the classification decisions of two ML models. The\nShapley values of the features have been analysed across multiple datasets to\ndetermine the influence contributed by each feature towards the final ML\nprediction.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 00:44:45 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Sarhan", "Mohanad", ""], ["Layeghy", "Siamak", ""], ["Portmann", "Marius", ""]]}, {"id": "2104.07332", "submitter": "Jose Moura", "authors": "Pedro Manso, Jose Moura, Carlos Serrao", "title": "SDN-Based Intrusion Detection System for Early Detection and Mitigation\n  of DDoS Attacks", "comments": "Published in MDPI Information", "journal-ref": "Information 2019, 10, 106", "doi": "10.3390/info10030106", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current paper addresses relevant network security vulnerabilities\nintroduced by network devices within the emerging paradigm of Internet of\nThings (IoT) as well as the urgent need to mitigate the negative effects of\nsome types of Distributed Denial of Service (DDoS) attacks that try to explore\nthose security weaknesses. We design and implement a Software-Defined Intrusion\nDetection System (IDS) that reactively impairs the attacks at its origin,\nensuring the normal operation of the network infrastructure. Our proposal\nincludes an IDS that automatically detects several DDoS attacks, and then as an\nattack is detected, it notifies a Software Defined Networking (SDN) controller.\nThe current proposal also downloads some convenient traffic forwarding\ndecisions from the SDN controller to network devices. The evaluation results\nsuggest that our proposal timely detects several types of cyber-attacks based\non DDoS, mitigates their negative impacts on the network performance, and\nensures the correct data delivery of normal traffic. Our work sheds light on\nthe programming relevance over an abstracted view of the network infrastructure\nto timely detect a Botnet exploitation, mitigate malicious traffic at its\nsource, and protect benign traffic.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 09:40:59 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Manso", "Pedro", ""], ["Moura", "Jose", ""], ["Serrao", "Carlos", ""]]}, {"id": "2104.07351", "submitter": "Zhaohui Huang", "authors": "Zhaohui Huang, Vasilis Friderikos", "title": "Enhanced LSTM-based Service Decomposition for Mobile Augmented Reality", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Undoubtedly, Mobile Augmented Reality (MAR) applications for 5G and Beyond\nwireless networks are witnessing a notable attention recently. However, they\nrequire significant computational and storage resources at the end device\nand/or the network via Edge Cloud (EC) support. In this work, a MAR service is\nconsidered under the lenses of microservices where MAR service components can\nbe decomposed and anchored at different locations ranging from the end device\nto different ECs in order to optimize the overall service and network\nefficiency. To this end, we propose a mobility aware MAR service decomposition\nusing a Long Short Term Memory (LSTM) deep neural network to provide efficient\npro-active decision making in real-time. More specifically, the LSTM deep\nneural network is trained with optimal solutions derived from a mathematical\nprogramming formulation in an offline manner. Then, decision making at the\ninference stage is used to optimize service decomposition of MAR services. A\nwide set of numerical investigations reveal that the mobility aware LSTM deep\nneural network manage to outperform recently proposed schemes in terms of both\ndecision making quality as well as computational time.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 10:19:45 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Huang", "Zhaohui", ""], ["Friderikos", "Vasilis", ""]]}, {"id": "2104.07470", "submitter": "Stefan Ruehrup", "authors": "Stefan Ruehrup", "title": "A public key infrastructure for compliant spectrum use by wireless\n  devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A multitude of wireless devices for radio local area networks (RLAN) use\nfrequency bands that are shared with other radio services or applications.\nEuropean market surveillance activities on 5 GHz RLAN indicate a growing number\nof non-compliant devices that do not fulfill all radio regulation requirements\nand may cause interference. This paper describes a concept and method for\nmitigating the use of non-compliant equipment based on a public key\ninfrastructure. If every RLAN device holds a security certificate, which is\nrevoked when non-compliance is found, then the connection establishment between\ndevices can be made dependent on compliance. The aim is that legitimate\nequipment rejects connections to non-compliant devices, so that non-compliant\ndevices will become isolated.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 14:07:18 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Ruehrup", "Stefan", ""]]}, {"id": "2104.07521", "submitter": "Sudeep Pasricha", "authors": "Saideep Tiku, Prathmesh Kale, Sudeep Pasricha", "title": "QuickLoc: Adaptive Deep-Learning for Fast Indoor Localization with\n  Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Indoor localization services are a crucial aspect for the realization of\nsmart cyber-physical systems within cities of the future. Such services are\npoised to reinvent the process of navigation and tracking of people and assets\nin a variety of indoor and subterranean environments. The growing ownership of\ncomputationally capable smartphones has laid the foundations of portable\nfingerprinting-based indoor localization through deep learning. However, as the\ndemand for accurate localization increases, the computational complexity of the\nassociated deep learning models increases as well. We present an approach for\nreducing the computational requirements of a deep learning-based indoor\nlocalization framework while maintaining localization accuracy targets. Our\nproposed methodology is deployed and validated across multiple smartphones and\nis shown to deliver up to 42% reduction in prediction latency and 45% reduction\nin prediction energy as compared to the best-known baseline deep learning-based\nindoor localization model.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 15:19:21 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Tiku", "Saideep", ""], ["Kale", "Prathmesh", ""], ["Pasricha", "Sudeep", ""]]}, {"id": "2104.07557", "submitter": "Yuben Qu", "authors": "Yuben Qu, Haipeng Dai, Yan Zhuang, Jiafa Chen, Chao Dong, Fan Wu, Song\n  Guo", "title": "Serverless Federated Learning for UAV Networks: Architecture,\n  Challenges, and Opportunities", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs), or say drones, are envisioned to support\nextensive applications in next-generation wireless networks in both civil and\nmilitary fields. Empowering UAVs networks intelligence by artificial\nintelligence (AI) especially machine learning (ML) techniques is inevitable and\nappealing to enable the aforementioned applications. To solve the problems of\ntraditional cloud-centric ML for UAV networks such as privacy concern,\nunacceptable latency, and resource burden, a distributed ML technique, i.e.,\nfederated learning (FL), has been recently proposed to enable multiple UAVs to\ncollaboratively train ML model without letting out raw data. However, almost\nall existing FL paradigms are server-based, i.e., a central entity is in charge\nof ML model aggregation and fusion over the whole network, which could result\nin the issue of a single point of failure and are inappropriate to UAV networks\nwith both unreliable nodes and links. To address the above issue, in this\narticle, we propose a novel architecture called SELF-UN\n(\\underline{SE}rver\\underline{L}ess \\underline{F}L for \\underline{U}AV\n\\underline{N}etworks), which enables FL within UAV networks without a central\nentity. We also conduct a preliminary simulation study to validate the\nfeasibility and effectiveness of the SELF-UN architecture. Finally, we discuss\nthe main challenges and potential research directions in the SELF-UN.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 16:11:13 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Qu", "Yuben", ""], ["Dai", "Haipeng", ""], ["Zhuang", "Yan", ""], ["Chen", "Jiafa", ""], ["Dong", "Chao", ""], ["Wu", "Fan", ""], ["Guo", "Song", ""]]}, {"id": "2104.07923", "submitter": "Miguel Sepulcre", "authors": "Miguel Sepulcre, Manuel Gonzalez-Martin, Javier Gozalvez, Rafael\n  Molina-Masegosa", "title": "Analytical Models of the Performance of IEEE 802.11p Vehicle to Vehicle\n  Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The critical nature of vehicular communications requires their extensive\ntesting and evaluation. Analytical models can represent an attractive and\ncost-effective approach for such evaluation if they can adequately model all\nunderlying effects that impact the performance of vehicular communications.\nSeveral analytical models have been proposed to date to model vehicular\ncommunications based on the IEEE 802.11p (or DSRC) standard. However, existing\nmodels normally model in detail the MAC (Medium Access Control), and generally\nsimplify the propagation and interference effects. This reduces their value as\nan alternative to evaluate the performance of vehicular communications. This\npaper addresses this gap, and presents the first analytical models capable to\naccurately model the performance of vehicle-to-vehicle communications based on\nthe IEEE 802.11p standard. The model quantifies the PDR (Packet Delivery Ratio)\nas a function of the distance between transmitter and receiver. The paper also\npresents new analytical models to quantify the probability of the four\ndifferent types of packet errors in IEEE 802.11p. In addition, the paper\npresents the first analytical model capable to accurately estimate the Channel\nBusy Ratio (CBR) metric even under high channel load levels. All the analytical\nmodels are validated by means of simulation for a wide range of parameters,\nincluding traffic densities, packet transmission frequencies, transmission\npower levels, data rates and packet sizes. An implementation of the models is\nprovided openly to facilitate their use by the community.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 06:51:47 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Sepulcre", "Miguel", ""], ["Gonzalez-Martin", "Manuel", ""], ["Gozalvez", "Javier", ""], ["Molina-Masegosa", "Rafael", ""]]}, {"id": "2104.07989", "submitter": "Fabian Mager", "authors": "Fabian Mager, Dominik Baumann, Carsten Herrmann, Sebastian Trimpe,\n  Marco Zimmerling", "title": "Scaling Beyond Bandwidth Limitations: Wireless Control With Stability\n  Guarantees Under Overload", "comments": "Submitted to ACM Transactions on Cyber-Physical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.NI cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important class of cyber-physical systems relies on multiple agents that\njointly perform a task by coordinating their actions over a wireless network.\nExamples include self-driving cars in intelligent transportation and production\nrobots in smart manufacturing. However, the scalability of existing\ncontrol-over-wireless solutions is limited as they cannot resolve overload\nsituations in which the communication demand exceeds the available bandwidth.\nThis paper presents a novel co-design of distributed control and wireless\ncommunication that overcomes this limitation by dynamically allocating the\navailable bandwidth to agents with the greatest need to communicate.\nExperiments on a real cyber-physical testbed with 20 agents, each consisting of\na wireless node and a cart-pole system, demonstrate that our solution achieves\nsignificantly better control performance under overload than the state of the\nart. We further prove that our co-design guarantees closed-loop stability for\nphysical systems with stochastic linear time-invariant dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 09:32:11 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Mager", "Fabian", ""], ["Baumann", "Dominik", ""], ["Herrmann", "Carsten", ""], ["Trimpe", "Sebastian", ""], ["Zimmerling", "Marco", ""]]}, {"id": "2104.08010", "submitter": "Ezra Tampubolon", "authors": "Ezra Tampubolon and Holger Boche", "title": "Welfare Measure for Resource Allocation with Algorithmic Implementation:\n  Beyond Average and Max-Min", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.GT cs.MA cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an axiomatic approach for measuring the\nperformance/welfare of a system consisting of concurrent agents in a\nresource-driven system. Our approach provides a unifying view on popular system\noptimality principles, such as the maximal average/total utilities and the\nmax-min fairness. Moreover, it gives rise to other system optimality notions\nthat have not been fully exploited yet, such as the maximal lowest total\nsubgroup utilities. For the axiomatically defined welfare measures, we provide\na generic gradient-based method to find an optimal resource allocation and\npresent a theoretical guarantee for its success. Lastly, we demonstrate the\npower of our approach through the power control application in wireless\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 10:11:01 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Tampubolon", "Ezra", ""], ["Boche", "Holger", ""]]}, {"id": "2104.08111", "submitter": "James Gross", "authors": "Paris Carbone, Gyoergy Dan, James Gross, Bo Goeransson, Marina Petrova", "title": "NeuroRAN: Rethinking Virtualization for AI-native Radio Access Networks\n  in 6G", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network softwarization has revolutionized the architecture of cellular\nwireless networks. State-of-the-art container based virtual radio access\nnetworks (vRAN) provide enormous flexibility and reduced life cycle management\ncosts, but they also come with prohibitive energy consumption. We argue that\nfor future AI-native wireless networks to be flexible and energy efficient,\nthere is a need for a new abstraction in network softwarization that caters for\nneural network type of workloads and allows a large degree of service\ncomposability. In this paper we present the NeuroRAN architecture, which\nleverages stateful function as a user facing execution model, and is\ncomplemented with virtualized resources and decentralized resource management.\nWe show that neural network based implementations of common transceiver\nfunctional blocks fit the proposed architecture, and we discuss key research\nchallenges related to compilation and code generation, resource management,\nreliability and security.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 13:38:57 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Carbone", "Paris", ""], ["Dan", "Gyoergy", ""], ["Gross", "James", ""], ["Goeransson", "Bo", ""], ["Petrova", "Marina", ""]]}, {"id": "2104.08122", "submitter": "Mounir Bensalem", "authors": "Mounir Bensalem and Admela Jukan", "title": "On the Effectiveness of Various Machine Learning Algorithms for THz\n  Channel Estimation", "comments": "This paper is uploaded here for research community, thus it is for\n  non-commercial purposes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Terahertz communication is one of the most promising wireless communication\ntechnologies, due to its capability to provide high bitrates. THz frequencies\nsuffer however from high signal attenuation and signal degradation, which makes\nthe THz channel modeling and estimation fundamentally hard. On the other hand,\nchannel estimation of THz transmission system is critical for THz systems to be\npractically adopted in wireless communications. We consider the problem of\nchannel modeling with deterministic channel propagation and the related\nphysical characteristics of THz bands, and study the effectiveness of various\nmachine learning algorithms to estimate the channel. We apply different machine\nlearning algorithms for channel estimation, including neural networks (NN),\nlogistic regression (LR), and projected gradient ascent (PGA). Numerical\nresults show that PGA algorithm yields the most promising performance at SNR=0\ndB with NMSE of -12.8 dB.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 14:01:36 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Bensalem", "Mounir", ""], ["Jukan", "Admela", ""]]}, {"id": "2104.08495", "submitter": "Hitesh Tewari", "authors": "Raman Singh and Hitesh Tewari", "title": "Blockchain-Enabled NextGen Service Architecture for Mobile Internet\n  Offload", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The amalgamation of different generations of mobile cellular networks around\nthe globe has resulted in diverse data speed experiences for end users. At\npresent there are no defined mechanisms in place for a subscriber of one mobile\nnetwork operator (MNO) to use the services of a WiFi provider. Cellular and\nData Service providers also have no standardized procedures to securely\ninteract with each other, and to allow their subscribers to use third party\nservices on a pay-as-you-go basis. This paper proposes a blockchain-based\noffloading framework that allows a subscriber of a mobile operator to\ntemporarily use another MNO or WiFi provider's higher speed network. Smart\ncontracts allow diverse entities such as MNOs, Brokers and WiFi Providers to\nautomatically execute mutual agreements to enable the utilization of third\nparty infrastructure in a secure and controlled manner. To test the proposed\nframework, the offloading of a subscriber from 3G/4G/4G-LTE/5G networks to a\nfixed broadband WiFi network was carried out and the results analyzed. The\noffloading framework was implemented using the ns-3 network simulator, and the\nEthereum blockchain smart contract features were used for the settlement of\ninvoices.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 09:34:27 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Singh", "Raman", ""], ["Tewari", "Hitesh", ""]]}, {"id": "2104.08549", "submitter": "Muhammad Nabeel", "authors": "Maxim Penner, Muhammad Nabeel, J\\\"urgen Peissig", "title": "Link-Level Performance Evaluation of IMT-2020 Candidate Technology:\n  DECT-2020 New Radio", "comments": "6 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ETSI has recently introduced the DECT-2020 New Radio (NR) as an IMT-2020\ncandidate technology for the mMTC and URLLC use cases. To consider DECT-2020 NR\nas an IMT-2020 technology, the ITU-R has determined different independent\nevaluation groups to assess its performance against the IMT-2020 requirements.\nThese independent evaluation groups are now in process of investigating the\nDECT-2020 NR. In order to successfully assess a technology, one important\naspect is to fully understand the underlying physical layer and its performance\nin different environments. Therefore, in this paper, we focus on the physical\nlayer of DECT-2020 NR and investigate its link-level performance with standard\nchannel models provided by the ITU-R for evaluation. We perform extensive\nsimulations to analyze the performance of DECT-2020 NR for both URLLC and mMTC\nuse cases. The results presented in this work are beneficial for the\nindependent evaluation groups and researchers as these results can help\ncalibrating their physical layer performance curves. These results can also be\nused directly for future system-level evaluations of DECT-2020 NR.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 14:00:33 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Penner", "Maxim", ""], ["Nabeel", "Muhammad", ""], ["Peissig", "J\u00fcrgen", ""]]}, {"id": "2104.08584", "submitter": "Jurandy Almeida", "authors": "Lucas Fernando Alvarenga e Silva, Bruno Yuji Lino Kimura, Jurandy\n  Almeida", "title": "Deep Learning in Beyond 5G Networks with Image-based Time-Series\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards the network innovation, the Beyond Five-Generation (B5G) networks\nenvision the use of machine learning (ML) methods to predict the network\nconditions and performance indicators in order to best make decisions and\nallocate resources. In this paper, we propose a new ML approach to accomplish\npredictions in B5G networks. Instead of handling the time-series in the network\ndomain of values, we transform them into image thus allowing to apply advanced\nML methods of Computer Vision field to reach better predictions in B5G\nnetworks. Particularly, we analyze different techniques to transform\ntime-series of network measures into image representation, e.g., Recurrence\nPlots, Markov Transition Fields, and Gramian Angular Fields. Then, we apply\ndeep neural networks with convolutional layers to predict different 5G radio\nsignal quality indicators. When comparing with other ML-based solutions,\nexperimental results from 5G transmission datasets showed the feasibility and\nsmall prediction errors of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 15:54:11 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Silva", "Lucas Fernando Alvarenga e", ""], ["Kimura", "Bruno Yuji Lino", ""], ["Almeida", "Jurandy", ""]]}, {"id": "2104.08651", "submitter": "Weizhao Jin", "authors": "Weizhao Jin, Xiaoyu Ji, Ruiwen He, Zhou Zhuang, Wenyuan Xu and Yuan\n  Tian", "title": "SMS Goes Nuclear: Fortifying SMS-Based MFA in Online Account Ecosystem", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of online services, the number of online accounts\nproliferates. The security of a single user account no longer depends merely on\nits own service provider but also the accounts on other service platforms(We\nrefer to this online account environment as Online Account Ecosystem). In this\npaper, we first uncover the vulnerability of Online Account Ecosystem, which\nstems from the defective multi-factor authentication (MFA), specifically the\nones with SMS-based verification, and dependencies among accounts on different\nplatforms. We propose Chain Reaction Attack that exploits the weakest point in\nOnline Account Ecosystem and can ultimately compromise the most secure\nplatform. Furthermore, we design and implement ActFort, a systematic approach\nto detect the vulnerability of Online Account Ecosystem by analyzing the\nauthentication credential factors and sensitive personal information as well as\nevaluating the dependency relationships among online accounts. We evaluate our\nsystem on hundreds of representative online services listed in Alexa in\ndiversified fields. Based on the analysis from ActFort, we provide several\npragmatic insights into the current Online Account Ecosystem and propose\nseveral feasible countermeasures including the online account exposed\ninformation protection mechanism and the built-in authentication to fortify the\nsecurity of Online Account Ecosystem.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 22:20:16 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 20:44:26 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jin", "Weizhao", ""], ["Ji", "Xiaoyu", ""], ["He", "Ruiwen", ""], ["Zhuang", "Zhou", ""], ["Xu", "Wenyuan", ""], ["Tian", "Yuan", ""]]}, {"id": "2104.08834", "submitter": "Ali Esmaeily", "authors": "Ali Esmaeily, Katina Kralevska", "title": "Small-Scale 5G Testbeds for Network Slicing Deployment: A Systematic\n  Review", "comments": "Accepted for publication in Wireless Communications and Mobile\n  Computing, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developing specialized cloud-based and open-source testbeds is a practical\napproach to investigate network slicing functionalities in the fifth-generation\n(5G) mobile networks. This paper provides a comprehensive review of most of the\nexisting cost-efficient and small-scale testbeds that partially or fully deploy\nnetwork slicing. First, we present relevant software packages for the three\nmain functional blocks of the ETSI NFV MANO framework and for emulating the\naccess and core network domains. Second, we define primary and secondary design\ncriteria for deploying network slicing testbeds. These design criteria are\nlater used for comparison between the testbeds. Third, we present the\nstate-of-the-art testbeds, including their design objectives, key technologies,\nnetwork slicing deployment, and experiments. Next, we evaluate the testbeds\naccording to the defined design criteria and present an in-depth summary table.\nThis assessment concludes with the superiority of some of them over the rest\nand the most dominant software packages satisfying the ETSI NFV MANO framework.\nFinally, challenges, potential solutions, and future works of network slicing\ntestbeds are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 12:09:57 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Esmaeily", "Ali", ""], ["Kralevska", "Katina", ""]]}, {"id": "2104.09029", "submitter": "Siamak Layeghy", "authors": "Siamak Layeghy, Marcus Gallagher, Marius Portmann", "title": "Benchmarking the Benchmark -- Analysis of Synthetic NIDS Datasets", "comments": "25 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network Intrusion Detection Systems (NIDSs) are an increasingly important\ntool for the prevention and mitigation of cyber attacks. A number of labelled\nsynthetic datasets generated have been generated and made publicly available by\nresearchers, and they have become the benchmarks via which new ML-based NIDS\nclassifiers are being evaluated. Recently published results show excellent\nclassification performance with these datasets, increasingly approaching 100\npercent performance across key evaluation metrics such as accuracy, F1 score,\netc. Unfortunately, we have not yet seen these excellent academic research\nresults translated into practical NIDS systems with such near-perfect\nperformance. This motivated our research presented in this paper, where we\nanalyse the statistical properties of the benign traffic in three of the more\nrecent and relevant NIDS datasets, (CIC, UNSW, ...). As a comparison, we\nconsider two datasets obtained from real-world production networks, one from a\nuniversity network and one from a medium size Internet Service Provider (ISP).\nOur results show that the two real-world datasets are quite similar among\nthemselves in regards to most of the considered statistical features. Equally,\nthe three synthetic datasets are also relatively similar within their group.\nHowever, and most importantly, our results show a distinct difference of most\nof the considered statistical features between the three synthetic datasets and\nthe two real-world datasets. Since ML relies on the basic assumption of\ntraining and test datasets being sampled from the same distribution, this\nraises the question of how well the performance results of ML-classifiers\ntrained on the considered synthetic datasets can translate and generalise to\nreal-world networks. We believe this is an interesting and relevant question\nwhich provides motivation for further research in this space.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 03:17:37 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Layeghy", "Siamak", ""], ["Gallagher", "Marcus", ""], ["Portmann", "Marius", ""]]}, {"id": "2104.09072", "submitter": "Ryan McConville", "authors": "Hok-Shing Lau, Ryan McConville, Mohammud J. Bocus, Robert J.\n  Piechocki, Raul Santos-Rodriguez", "title": "Self-Supervised WiFi-Based Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional approaches to activity recognition involve the use of wearable\nsensors or cameras in order to recognise human activities. In this work, we\nextract fine-grained physical layer information from WiFi devices for the\npurpose of passive activity recognition in indoor environments. While such data\nis ubiquitous, few approaches are designed to utilise large amounts of\nunlabelled WiFi data. We propose the use of self-supervised contrastive\nlearning to improve activity recognition performance when using multiple views\nof the transmitted WiFi signal captured by different synchronised receivers. We\nconduct experiments where the transmitters and receivers are arranged in\ndifferent physical layouts so as to cover both Line-of-Sight (LoS) and non LoS\n(NLoS) conditions. We compare the proposed contrastive learning system with\nnon-contrastive systems and observe a 17.7% increase in macro averaged F1 score\non the task of WiFi based activity recognition, as well as significant\nimprovements in one- and few-shot learning scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 06:40:21 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lau", "Hok-Shing", ""], ["McConville", "Ryan", ""], ["Bocus", "Mohammud J.", ""], ["Piechocki", "Robert J.", ""], ["Santos-Rodriguez", "Raul", ""]]}, {"id": "2104.09202", "submitter": "Sebastian Henningsen", "authors": "Leonhard Balduf, Sebastian Henningsen, Martin Florian, Sebastian Rust,\n  Bj\\\"orn Scheuermann", "title": "Monitoring Data Requests in Decentralized Data Storage Systems: A Case\n  Study of IPFS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized data storage systems like the Interplanetary Filesystem (IPFS)\nare becoming increasingly popular, e.g., as a data layer in blockchain\napplications and for sharing content in a censorship-resistant manner. In IPFS,\ndata is hosted by an open set of peers, requests to which are broadcast to all\ndirectly connected peers and routed via a DHT. In this paper, we showcase how\nthe monitoring of said data requests allows for profound insights about the\nIPFS network while simultaneously breaching individual users' privacy. To this\nend, we present a passive monitoring methodology that enables us to collect all\ndata requests of a significant and upscalable portion of the total IPFS node\npopulation. Using a measurement setup implementing our approach and data\ncollected over a period of nine months, we demonstrate the estimation of, among\nother things: the size of the IPFS network, activity levels and structure, and\ncontent popularity distributions. We furthermore present how our methodology\ncan be abused for attacks on users' privacy. As a demonstration, we identify\nand successfully surveil public IPFS/HTTP gateways, thereby also uncovering\ntheir (normally hidden) node identifiers. We give a detailed analysis of the\nmechanics and reasons behind implied privacy threats and discuss possible\ncountermeasures.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 10:57:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Balduf", "Leonhard", ""], ["Henningsen", "Sebastian", ""], ["Florian", "Martin", ""], ["Rust", "Sebastian", ""], ["Scheuermann", "Bj\u00f6rn", ""]]}, {"id": "2104.09249", "submitter": "Matthias Rost", "authors": "Robin M\\\"unk, Matthias Rost, Stefan Schmid, Harald R\\\"acke", "title": "It's Good to Relax: Fast Profit Approximation for Virtual Networks with\n  Latency Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new approximation algorithm for the offline Virtual\nNetwork Embedding Problem (VNEP) with latency constraints. Given is a set of\nvirtual networks with computational demands on nodes and bandwidth demands\ntogether with latency bounds on the edges. The VNEP's task is to feasibly embed\na subset of virtual networks on a shared physical infrastructure, e.g., a data\ncenter, while maximizing the attained profit. In contrast to existing works,\nour approximation algorithm AFlex allows for (slight) violations of the latency\nconstraints in order to greatly lower the runtime. To obtain this result, we\nuse a reduction to the Restricted Shortest Path Problem (RSP) and leverage a\nclassic result by Goel et al. We complement our formal analysis with an\nextensive simulation study demonstrating the computational benefits of our\napproach empirically. Notably, our results generalize to any other additive\nedge metric besides latency, including loss probability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 12:48:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["M\u00fcnk", "Robin", ""], ["Rost", "Matthias", ""], ["Schmid", "Stefan", ""], ["R\u00e4cke", "Harald", ""]]}, {"id": "2104.09304", "submitter": "Kohei Watabe", "authors": "Shohei Nakazawa, Yoshiki Sato, Kenji Nakagawa, Sho Tsugawa, Kohei\n  Watabe", "title": "A Tunable Model for Graph Generation Using LSTM and Conditional VAE", "comments": "Accepted at the 41st IEEE International Conference on Distributed\n  Computing Systems (ICDCS 2021) Poster Track. 2 pages, 3 pdf figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of graph applications, generative models for graphs have\nbeen more crucial. Classically, stochastic models that generate graphs with a\npre-defined probability of edges and nodes have been studied. Recently, some\nmodels that reproduce the structural features of graphs by learning from actual\ngraph data using machine learning have been studied. However, in these\nconventional studies based on machine learning, structural features of graphs\ncan be learned from data, but it is not possible to tune features and generate\ngraphs with specific features. In this paper, we propose a generative model\nthat can tune specific features, while learning structural features of a graph\nfrom data. With a dataset of graphs with various features generated by a\nstochastic model, we confirm that our model can generate a graph with specific\nfeatures.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 06:47:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Nakazawa", "Shohei", ""], ["Sato", "Yoshiki", ""], ["Nakagawa", "Kenji", ""], ["Tsugawa", "Sho", ""], ["Watabe", "Kohei", ""]]}, {"id": "2104.09382", "submitter": "Bo Yang", "authors": "Bo Yang, Omobayode Fagbohungbe, Xuelin Cao, Chau Yuen, Lijun Qian,\n  Dusit Niyato, and Yan Zhang", "title": "A Joint Energy and Latency Framework for Transfer Learning over 5G\n  Industrial Edge Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a transfer learning (TL)-enabled edge-CNN framework\nfor 5G industrial edge networks with privacy-preserving characteristic. In\nparticular, the edge server can use the existing image dataset to train the CNN\nin advance, which is further fine-tuned based on the limited datasets uploaded\nfrom the devices. With the aid of TL, the devices that are not participating in\nthe training only need to fine-tune the trained edge-CNN model without training\nfrom scratch. Due to the energy budget of the devices and the limited\ncommunication bandwidth, a joint energy and latency problem is formulated,\nwhich is solved by decomposing the original problem into an uploading decision\nsubproblem and a wireless bandwidth allocation subproblem. Experiments using\nImageNet demonstrate that the proposed TL-enabled edge-CNN framework can\nachieve almost 85% prediction accuracy of the baseline by uploading only about\n1% model parameters, for a compression ratio of 32 of the autoencoder.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 15:13:16 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yang", "Bo", ""], ["Fagbohungbe", "Omobayode", ""], ["Cao", "Xuelin", ""], ["Yuen", "Chau", ""], ["Qian", "Lijun", ""], ["Niyato", "Dusit", ""], ["Zhang", "Yan", ""]]}, {"id": "2104.09445", "submitter": "Paul Masur", "authors": "Paul H. Masur and Jeffrey H. Reed", "title": "Artificial Intelligence in Open Radio Access Network", "comments": "9 pages, 4 figures, 1 Table. Paper has been edited to conform to\n  journal submission standards. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial seeks to outline the proposed Open Radio Access Network (O-RAN)\ndeployment for Fifth generation (5G) wireless networks. O-RAN seeks to supplant\nhardware-specific Radio Access Network (RAN) components (e.g., the mobility\nmanagement entity (MME) or base station (gNB)) with generic hardware,\nspecialized software, and open signaling interfaces. The virtualization and\nnetwork slicing features of 5G allow for software to replace previously\nhardware specific functions. Software further provides faster analytics, thus\nsupporting 5Gs latency requirements and advanced usage scenarios (i.e.,\nenhanced mobile broadband (eMBB), massive machine type communications (mMTC),\nand ultra-reliable low latency communications (uRLLC)). Furthermore, as\nsoftware annexes control of the RAN, there is freedom to integrate Artificial\nIntelligence/Machine Learning (AI/ML) algorithms into RAN management\n(particularly at the user plane). This integration is one of the goals of\nO-RAN. Lastly, relying on generic hardware and specialized, open-source\nsoftware eliminates reliance upon specific device manufacturers. This paper\nwill provide questions regarding the future of O-RAN, with a focus on 5G\nnetwork device security.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 16:51:18 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 10:32:48 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Masur", "Paul H.", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "2104.09462", "submitter": "Tobias Fiebig", "authors": "Tobias Fiebig, Seda G\\\"urses, Carlos H. Ga\\~n\\'an, Erna Kotkamp,\n  Fernando Kuipers, Martina Lindorfer, Menghua Prisse, Taritha Sari", "title": "Heads in the Clouds: Measuring the Implications of Universities\n  Migrating to Public Clouds", "comments": "Update 2: Added data for Jan-June 2021; Fixed parsing error in mail\n  data that lead to an over-reporting of cloud use (e.g., U.S. now at ~80%\n  cloud-mail use instead of 93%); Added discussion on migration to Office365 in\n  the Netherlands; Fixed attribution of pphosted.com to Proofpoint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of mandatory remote education and work in universities due\nto COVID-19, the `zoomification' of higher education, i.e., the migration of\nuniversities to the clouds, reached the public discourse. Ongoing discussions\nreason about how this shift will take control over students' data away from\nuniversities, and may ultimately prevent privacy from being an attainable goal\nfor researchers and students alike. However, there has been no comprehensive\nmeasurement of universities' use of public clouds and reliance on\nSoftware-as-a-Service offerings to assess how far this migration has already\nprogressed.\n  In this paper, we perform a longitudinal study of the migration to public\nclouds among universities in the U.S. and Europe, as well as institutions\nlisted in the Times Higher Education (THE) Top100 between January 2015 and June\n2021. We find that cloud-adoption differs between countries, with one cluster\n(Germany, France, Austria, Switzerland) showing a limited move to clouds, while\nthe other cluster (U.S., U.K., the Netherlands, THE Top100) frequently migrates\nuniversities' core functions and services to public clouds -- starting long\nbefore the COVID-19 pandemic. We attribute this clustering to several\nsocio-economic factors in the respective countries, including the general\nculture of higher education and the administrative paradigm taken towards\nrunning universities. We then analyze and interpret our results, finding that\nthe implications reach beyond individuals' privacy towards questions of\nacademic independence and integrity.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:25:10 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 10:16:41 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 10:01:11 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Fiebig", "Tobias", ""], ["G\u00fcrses", "Seda", ""], ["Ga\u00f1\u00e1n", "Carlos H.", ""], ["Kotkamp", "Erna", ""], ["Kuipers", "Fernando", ""], ["Lindorfer", "Martina", ""], ["Prisse", "Menghua", ""], ["Sari", "Taritha", ""]]}, {"id": "2104.09571", "submitter": "Biswa P. S. Sahoo", "authors": "Biswa P. S. Sahoo, Styabrata Swain, Hung-Yu Wei, and Mahasweta Sarkar", "title": "Medium Access Strategies for Integrated Access and Backhaul at mmWaves\n  Unlicensed Spectrum", "comments": "6 pages, 6 figures, conference paper, Accepted for publication in\n  Wireless Telecommunications Symposium (WTS), San Francisco, USA, April 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The unlicensed spectrum is recently considered one of the defining solutions\nto meet the steadily growing traffic demand. This, in turn, has led to the\nenhancement for LTE in Release-13 to enable Licensed-Assisted Access (LAA)\noperations. The design of the medium access control (MAC) protocol for the LAA\nsystem to harmonically coexist with the incumbent WLAN system operating in an\nunlicensed band is critical and challenging. In this paper, we consider an\nIntegrated Access and Backhaul (IAB) system coexisting with a Wi-Fi network\noperating at millimeter-wave (mmWave) unlicensed spectrum, for which a\nlisten-before-talk-based (LBT) based medium access mechanism is carefully\ndesigned. Additionally, we have considered an in-band system that supports both\naccess and backhaul in a single node where the small-cell or the IAB nodes\ncompete with the WiGig for medium access. We present comprehensive experimental\nresults and give design insights based on the simulation results.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 02:23:49 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Sahoo", "Biswa P. S.", ""], ["Swain", "Styabrata", ""], ["Wei", "Hung-Yu", ""], ["Sarkar", "Mahasweta", ""]]}, {"id": "2104.09680", "submitter": "Sushovan Das", "authors": "Sushovan Das, Afsaneh Rahbar, Xinyu Crystal Wu, Zhuang Wang, Weitao\n  Wang, Ang Chen, T. S. Eugene Ng", "title": "Shufflecast: An Optical, Data-rate Agnostic and Low-Power Multicast\n  Architecture for Next-Generation Compute Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An optical circuit-switched network core has the potential to overcome the\ninherent challenges of a conventional electrical packet-switched core of\ntoday's compute clusters. As optical circuit switches (OCS) directly handle the\nphoton beams without any optical-electrical-optical (O/E/O) conversion and\npacket processing, OCS-based network cores have the following desirable\nproperties: a) agnostic to data-rate, b) negligible/zero power consumption, c)\nno need of transceivers, d) negligible forwarding latency, and e) no need for\nfrequent upgrade. Unfortunately, OCS can only provide point-to-point (unicast)\ncircuits. They do not have built-in support for one-to-many (multicast)\ncommunication, yet multicast is fundamental to a plethora of data-intensive\napplications running on compute clusters nowadays. In this paper, we propose\nShufflecast, a novel optical network architecture for next-generation compute\nclusters that can support high-performance multicast satisfying all the\nproperties of an OCS-based network core. Shufflecast leverages small fanout,\ninexpensive, passive optical splitters to connect the Top-of-rack (ToR) switch\nports, ensuring data-rate agnostic, low-power, physical-layer multicast. We\nthoroughly analyze Shufflecast's highly scalable data plane, light-weight\ncontrol plane, and graceful failure handling. Further, we implement a complete\nprototype of Shufflecast in our testbed and extensively evaluate the network.\nShufflecast is more power-efficient than the state-of-the-art multicast\nmechanisms. Also, Shufflecast is more cost-efficient than a conventional\npacket-switched network. By adding Shufflecast alongside an OCS-based unicast\nnetwork, an all-optical network core with the aforementioned desirable\nproperties supporting both unicast and multicast can be realized.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 23:05:39 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Das", "Sushovan", ""], ["Rahbar", "Afsaneh", ""], ["Wu", "Xinyu Crystal", ""], ["Wang", "Zhuang", ""], ["Wang", "Weitao", ""], ["Chen", "Ang", ""], ["Ng", "T. S. Eugene", ""]]}, {"id": "2104.09823", "submitter": "Lotte Weedage", "authors": "Lotte Weedage, Clara Stegehuis and Suzan Bayhan", "title": "Impact of Multi-connectivity on Channel Capacity and Outage Probability\n  in Wireless Networks", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-connectivity facilitates higher throughput, shorter delay, and lower\noutage probability for a user in a wireless network. Considering these\npromises, a rationale policy for a network operator would be to implement\nmulti-connectivity for all of its users. In this paper, we investigate whether\nthe promises of multi-connectivity also hold in such a setting where all users\nof a network are connected through multiple links. In particular, we consider a\nnetwork where every user connects to its k closest base stations. Using a\nframework of stochastic geometry and probability theory, we obtain analytic\nexpressions for per-user throughput and outage probability of $k$-connectivity\nnetworks under several failure models. In contrast to the conclusions of\nprevious research, our analysis shows that per-user throughput decreases with\nincreasing k. However, multi-connected networks are more resilient against\nfailures than single connected networks as reflected with lower outage\nprobability and lead to higher fairness among the users. Consequently, we\nconclude that rather than implementing multi-connectivity for all users, a\nnetwork operator should consider it for its users who would benefit from\nadditional links the most, e.g., cell edge users.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 08:20:18 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 11:29:54 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Weedage", "Lotte", ""], ["Stegehuis", "Clara", ""], ["Bayhan", "Suzan", ""]]}, {"id": "2104.09835", "submitter": "Amee Trivedi", "authors": "Amee Trivedi, Kate Silverstein, Emma Strubell, Mohit Iyyer, Prashant\n  Shenoy", "title": "WiFiMod: Transformer-based Indoor Human Mobility Modeling using Passive\n  Sensing", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling human mobility has a wide range of applications from urban planning\nto simulations of disease spread. It is well known that humans spend 80% of\ntheir time indoors but modeling indoor human mobility is challenging due to\nthree main reasons: (i) the absence of easily acquirable, reliable, low-cost\nindoor mobility datasets, (ii) high prediction space in modeling the frequent\nindoor mobility, and (iii) multi-scalar periodicity and correlations in\nmobility. To deal with all these challenges, we propose WiFiMod, a\nTransformer-based, data-driven approach that models indoor human mobility at\nmultiple spatial scales using WiFi system logs. WiFiMod takes as input\nenterprise WiFi system logs to extract human mobility trajectories from\nsmartphone digital traces. Next, for each extracted trajectory, we identify the\nmobility features at multiple spatial scales, macro, and micro, to design a\nmulti-modal embedding Transformer that predicts user mobility for several hours\nto an entire day across multiple spatial granularities. Multi-modal embedding\ncaptures the mobility periodicity and correlations across various scales while\nTransformers capture long-term mobility dependencies boosting model prediction\nperformance. This approach significantly reduces the prediction space by first\npredicting macro mobility, then modeling indoor scale mobility, micro-mobility,\nconditioned on the estimated macro mobility distribution, thereby using the\ntopological constraint of the macro-scale. Experimental results show that\nWiFiMod achieves a prediction accuracy of at least 10% points higher than the\ncurrent state-of-art models. Additionally, we present 3 real-world applications\nof WiFiMod - (i) predict high-density hot pockets for policy-making decisions\nfor COVID19 or ILI, (ii) generate a realistic simulation of indoor mobility,\n(iii) design personal assistants.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 08:45:17 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 17:38:18 GMT"}, {"version": "v3", "created": "Sat, 10 Jul 2021 07:20:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Trivedi", "Amee", ""], ["Silverstein", "Kate", ""], ["Strubell", "Emma", ""], ["Iyyer", "Mohit", ""], ["Shenoy", "Prashant", ""]]}, {"id": "2104.09919", "submitter": "Oliver Hope", "authors": "Oliver Hope, Eiko Yoneki", "title": "GDDR: GNN-based Data-Driven Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the feasibility of combining Graph Neural Network-based policy\narchitectures with Deep Reinforcement Learning as an approach to problems in\nsystems. This fits particularly well with operations on networks, which\nnaturally take the form of graphs. As a case study, we take the idea of\ndata-driven routing in intradomain traffic engineering, whereby the routing of\ndata in a network can be managed taking into account the data itself. The\nparticular subproblem which we examine is minimising link congestion in\nnetworks using knowledge of historic traffic flows. We show through experiments\nthat an approach using Graph Neural Networks (GNNs) performs at least as well\nas previous work using Multilayer Perceptron architectures. GNNs have the added\nbenefit that they allow for the generalisation of trained agents to different\nnetwork topologies with no extra work. Furthermore, we believe that this\ntechnique is applicable to a far wider selection of problems in systems\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 12:12:17 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Hope", "Oliver", ""], ["Yoneki", "Eiko", ""]]}, {"id": "2104.10095", "submitter": "Zezhong Zhang", "authors": "Zezhong Zhang, Guangxu Zhu, Rui Wang, Vincent K. N. Lau, and Kaibin\n  Huang", "title": "Turning Channel Noise into an Accelerator for Over-the-Air Principal\n  Component Analysis", "comments": "30 pages,9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently years, the attempts on distilling mobile data into useful knowledge\nhas been led to the deployment of machine learning algorithms at the network\nedge. Principal component analysis (PCA) is a classic technique for extracting\nthe linear structure of a dataset, which is useful for feature extraction and\ndata compression. In this work, we propose the deployment of distributed PCA\nover a multi-access channel based on the algorithm of stochastic gradient\ndescent to learn the dominant feature space of a distributed dataset at\nmultiple devices. Over-the-air aggregation is adopted to reduce the\nmulti-access latency, giving the name over-the-air PCA. The novelty of this\ndesign lies in exploiting channel noise to accelerate the descent in the region\naround each saddle point encountered by gradient descent, thereby increasing\nthe convergence speed of over-the-air PCA. The idea is materialized by\nproposing a power-control scheme which detects the type of descent region and\ncontrolling the level of channel noise accordingly. The scheme is proved to\nachieve a faster convergence rate than in the case without power control.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:28:33 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 02:21:15 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Zhang", "Zezhong", ""], ["Zhu", "Guangxu", ""], ["Wang", "Rui", ""], ["Lau", "Vincent K. N.", ""], ["Huang", "Kaibin", ""]]}, {"id": "2104.10135", "submitter": "Mario Di Mauro", "authors": "Mario Di Mauro, Giovanni Galatro, Maurizio Longo, Fabio Postiglione,\n  Marco Tambasco", "title": "HASFC: a MANO-compliant Framework for Availability Management of Service\n  Chains", "comments": null, "journal-ref": null, "doi": "10.1109/MCOM.001.2000939", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most softwarized telco services are conveniently framed as Service Function\nChains (SFCs). Indeed, being structured as a combination of interconnected\nnodes, service chains may suffer from the single point of failure problem,\nmeaning that an individual node malfunctioning could compromise the whole chain\noperation. To guarantee \"highly available\" (HA) levels, service providers are\nrequired to introduce redundancy strategies to achieve specific availability\ndemands, where cost constraints have to be taken into account as well. Along\nthese lines we propose HASFC (standing for High Availability SFC), a framework\ndesigned to support, through a dedicated REST interface, the MANO\ninfrastructure in deploying SFCs with an optimal availability-cost trade off.\nOur framework is equipped with: i) an availability model builder aimed to\nconstruct probabilistic models of the SFC nodes in terms of failure and repair\nactions; ii) a chaining and selection module to compose the possible redundant\nSFCs, and extract the best candidates thereof. Beyond providing architectural\ndetails, we demonstrate the functionalities of HASFC through a use case which\nconsiders the IP Multimedia Subsystem, an SFC-like structure adopted to manage\nmultimedia contents within 4G and 5G networks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 17:26:55 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Di Mauro", "Mario", ""], ["Galatro", "Giovanni", ""], ["Longo", "Maurizio", ""], ["Postiglione", "Fabio", ""], ["Tambasco", "Marco", ""]]}, {"id": "2104.10533", "submitter": "Xingqin Lin", "authors": "Xingqin Lin, Stefan Cioni, Gilles Charbit, Nicolas Chuberre, Sven\n  Hellsten, and Jean-Francois Boutillon", "title": "On the Path to 6G: Low Orbit is the New High", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an overview of the key aspects of low Earth orbit (LEO) satellite\ncommunication networks towards 6G. Offering space-based Internet services with\nmega-constellations of LEO satellites is a promising solution to connecting the\nunserved and underserved, thereby complementing the coverage of terrestrial\nnetworks and contributing to bridging the digital divide. Integrating LEO\nsatellite access in cellular systems will be one of the connectivity's new\nfrontiers on the path to 6G. There are however challenges from operational and\ntechnical obstacles to regulatory hurdles facing the development of LEO based\ncommunication networks. In this article, we review the evolution of LEO\nsatellite constellations and capabilities, analyze the technical challenges and\nsolutions of LEO satellite access networks, discuss the standardization aspects\nfrom 5G evolution to 6G, and investigate the use cases and business\nconsiderations towards 6G.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 13:47:18 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 16:30:08 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2021 13:49:06 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Lin", "Xingqin", ""], ["Cioni", "Stefan", ""], ["Charbit", "Gilles", ""], ["Chuberre", "Nicolas", ""], ["Hellsten", "Sven", ""], ["Boutillon", "Jean-Francois", ""]]}, {"id": "2104.10536", "submitter": "Guus Leenders", "authors": "Guus Leenders, Gilles Callebaut, Geoffrey Ottoy, Liesbet Van der\n  Perre, Lieven De Strycker", "title": "Multi-RAT for IoT: The Potential in Combining LoRaWAN and NB-IoT", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The broad range of requirements of Internet of Things applications has lead\nto the development of several dedicated communication technologies, each\ntailored to meet a specific feature set. A solution combining different\nwireless technologies in one device, can overcome the disadvantages of any\nindividual technology. The design of such Multiple Radio Access Technology\nsolutions based on the diverse characteristics of the technologies offers\ninteresting opportunities. In this work we analyze the potential of combining\nLoRaWAN and NB-IoT in a Multi-RAT solution for IoT. To that end we evaluate key\nIoT node requirements in function of payload size and link quality: (1) energy\nefficiency, (2) coverage, (3) payload size, (4) latency performance, (5)\nQuality of Service, and (6) cost efficiency. Our theoretical assessment and\nexperimental validation of these IoT features show the merits of a Multi-RAT\nsolution. Notably, energy consumption in use cases with only sporadic large\npayload requirements, can be improved by a factor of at least 4 with respect to\neither single-mode technologies. Moreover, latency-critical messages can get\ndelivered on time and coverage can be extended elegantly where needed.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 13:52:49 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 09:11:33 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Leenders", "Guus", ""], ["Callebaut", "Gilles", ""], ["Ottoy", "Geoffrey", ""], ["Van der Perre", "Liesbet", ""], ["De Strycker", "Lieven", ""]]}, {"id": "2104.10701", "submitter": "Cillian Harney", "authors": "Cillian Harney, Stefano Pirandola", "title": "Optimal Performance of Global Quantum Networks", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of a future, global quantum communication network (or quantum\ninternet) will enable high rate private communication and entanglement\ndistribution over very long distances. However, the large-scale performance of\nground-based quantum networks (which employ photons as information carriers\nthrough optical-fibres) is fundamentally limited by the fibre quality and link\nlength. While these fundamental limits are well established for arbitrary\nnetwork architectures, the question of how to best design these global\narchitectures remains open. In this work, we take a step forward in addressing\nthis problem by modelling global quantum networks with weakly-regular\narchitectures. Such networks are capable of idealising end-to-end performance\nwhilst remaining sufficiently realistic. In this way, we may investigate the\neffectiveness of large-scale networks with consistent connective properties,\nand unveil the global conditions under which end-to-end rates remain\nanalytically computable. Furthermore, by comparing the performance of ideal,\nground-based quantum networks with satellite quantum communication protocols,\nwe can establish conditions for which satellites can be used to outperform\nfibre-based quantum infrastructure.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 18:01:43 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Harney", "Cillian", ""], ["Pirandola", "Stefano", ""]]}, {"id": "2104.10761", "submitter": "Youri Raaijmakers", "authors": "Youri Raaijmakers and Silvio Mandelli and Mark Doll", "title": "Reinforcement learning for Admission Control in 5G Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The key challenge in admission control in wireless networks is to strike an\noptimal trade-off between the blocking probability for new requests while\nminimizing the dropping probability of ongoing requests. We consider two\napproaches for solving the admission control problem: i) the typically adopted\nthreshold policy and ii) our proposed policy relying on reinforcement learning\nwith neural networks. Extensive simulation experiments are conducted to analyze\nthe performance of both policies. The results show that the reinforcement\nlearning policy outperforms the threshold-based policies in the scenario with\nheterogeneous time-varying arrival rates and multiple user equipment types,\nproving its applicability in realistic wireless network scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 06:37:18 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Raaijmakers", "Youri", ""], ["Mandelli", "Silvio", ""], ["Doll", "Mark", ""]]}, {"id": "2104.10893", "submitter": "Xingqiu He", "authors": "Xingqiu He, Yuhang Shen, Xiong Wang, Sheng Wang, Shizhong Xu, Jing Ren", "title": "An Online Scheduling Algorithm for Energy Minimization in Wireless\n  Powered Mobile Edge Computing Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of Mobile Edge Computing (MEC) and Wireless Power Transfer\n(WPT), which is usually referred to as Wireless Powered Mobile Edge Computing\n(WP-MEC), has been recognized as a promising technique to enhance the lifetime\nand computation capacity of wireless devices (WDs). Compared to the\nconventional battery-powered MEC networks, WP-MEC brings new challenges to the\ncomputation scheduling problem because we have to jointly optimize the resource\nallocation in WPT and computation offloading. In this paper, we consider the\nenergy minimization problem for WP-MEC networks with multiple WDs and multiple\naccess points. We design an online algorithm by transforming the original\nproblem into a series of deterministic optimization problems based on the\nLyapunov optimization theory. To reduce the time complexity of our algorithm,\nthe optimization problem is relaxed and decomposed into several independent\nsubproblems. After solving each subproblem, we adjust the computed values of\nvariables to obtain a feasible solution. Extensive simulations are conducted to\nvalidate the performance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 06:53:18 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["He", "Xingqiu", ""], ["Shen", "Yuhang", ""], ["Wang", "Xiong", ""], ["Wang", "Sheng", ""], ["Xu", "Shizhong", ""], ["Ren", "Jing", ""]]}, {"id": "2104.11042", "submitter": "Laura Flueratoru", "authors": "L. Flueratoru, S. Wehrli, M. Magno, E. S. Lohan and D. Niculescu", "title": "High-Accuracy Ranging and Localization with Ultra-Wideband\n  Communications for Energy-Constrained Devices", "comments": "Submitted to the IEEE Internet of Things Journal (IoT-J)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ultra-wideband (UWB) communications have gained popularity in recent years\nfor being able to provide distance measurements and localization with high\naccuracy, which can enhance the capabilities of devices in the Internet of\nThings (IoT). Since energy efficiency is of utmost concern in such\napplications, in this work we evaluate the power and energy consumption,\ndistance measurements, and localization performance of two types of UWB\nphysical interfaces (PHYs), which use either a low- or high-rate pulse\nrepetition (LRP and HRP, respectively). The evaluation is done through\nmeasurements acquired in identical conditions, which is crucial in order to\nhave a fair comparison between the devices. The LRP devices that we tested have\nthe same ranging and localization performance, but ten times (10x) lower power\nconsumption, 6x lower energy consumption per distance measurement, and at least\n8x higher coverage than the HRP devices. Therefore, UWB LRP devices can offer\nhigh-accuracy ranging and localization even to ultra-low-power devices in the\nIoT. We performed measurements in typical LOS and NLOS scenarios and propose\ntheoretical models for the distance errors obtained in these situations. The\nmodels can be used to simulate realistic building deployments and we illustrate\nsuch an example. This paper, therefore, provides a comprehensive overview of\nthe energy demands, ranging characteristics, and localization performance of\nstate-of-the-art UWB devices.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:19:37 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Flueratoru", "L.", ""], ["Wehrli", "S.", ""], ["Magno", "M.", ""], ["Lohan", "E. S.", ""], ["Niculescu", "D.", ""]]}, {"id": "2104.11074", "submitter": "Adnan Aijaz", "authors": "Adnan Aijaz, Ben Holden, Fanyu Meng", "title": "Open and Programmable 5G Network-in-a-Box: Technology Demonstration and\n  Evaluation Results", "comments": "To appear in the IEEE International Conference on Network\n  Softwarization (NetSoft) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fifth-generation (5G) mobile/cellular technology is a game changer for\nindustrial systems. Private 5G deployments are promising to address the\nchallenges faced by industrial networks. Programmability and open-source are\ntwo key aspects which bring unprecedented flexibility and customizability to\nprivate 5G networks. Recent regulatory initiatives are removing barriers for\nindustrial stakeholders to deploy their own local 5G networks with dedicated\nequipment. To this end, this demonstration showcases an open and programmable\n5G network-in-a-box solution for private deployments. The network-in-a-box\nprovides an integrated solution, based on open-source software stack and\ngeneral-purpose hardware, for operation in 5G non-standalone (NSA) as well as\n4G long-term evolution (LTE) modes. The demonstration also shows the capability\nof operation in different sub-6 GHz frequency bands, some of which are\nspecifically available for private networks. Performance results, in terms of\nend-to-end latency and data rates, with a commercial off-the-shelf (COTS) 5G\ndevice are shown as well.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:53:00 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Aijaz", "Adnan", ""], ["Holden", "Ben", ""], ["Meng", "Fanyu", ""]]}, {"id": "2104.11135", "submitter": "Dariush M. Soleymani", "authors": "Mehdi Harounabadi, Dariush Mohammad Soleymani, Shubhangi Bhadauria,\n  Martin Leyh, Elke Roth-Mandutz", "title": "V2X in 3GPP Standardization: NR Sidelink in Rel-16 and Beyond", "comments": null, "journal-ref": null, "doi": "10.1109/MCOMSTD.001.2000070", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 5G mobile network brings several new features that can be applied to\nexisting and new applications. High reliability, low latency, and high data\nrate are some of the features which fulfill the requirements of vehicular\nnetworks. Vehicular networks aim to provide safety for road users and several\nadditional advantages such as enhanced traffic efficiency and in-vehicle\ninfotainment services. This paper summarizes the most important aspects of\nNR-V2X, which is standardized by 3GPP, focusing on sidelink communication. The\nmain part of this work belongs to the 3GPP Rel-16, which is the first 3GPP\nrelease for NR-V2X, and the work/study items of the future Rel-17\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 15:37:57 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Harounabadi", "Mehdi", ""], ["Soleymani", "Dariush Mohammad", ""], ["Bhadauria", "Shubhangi", ""], ["Leyh", "Martin", ""], ["Roth-Mandutz", "Elke", ""]]}, {"id": "2104.11146", "submitter": "Kun Yang", "authors": "Kun Yang, Samory Kpotufe, Nick Feamster", "title": "An Efficient One-Class SVM for Anomaly Detection in the Internet of\n  Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insecure Internet of things (IoT) devices pose significant threats to\ncritical infrastructure and the Internet at large; detecting anomalous behavior\nfrom these devices remains of critical importance, but fast, efficient,\naccurate anomaly detection (also called \"novelty detection\") for these classes\nof devices remains elusive. One-Class Support Vector Machines (OCSVM) are one\nof the state-of-the-art approaches for novelty detection (or anomaly detection)\nin machine learning, due to their flexibility in fitting complex nonlinear\nboundaries between {normal} and {novel} data. IoT devices in smart homes and\ncities and connected building infrastructure present a compelling use case for\nnovelty detection with OCSVM due to the variety of devices, traffic patterns,\nand types of anomalies that can manifest in such environments. Much previous\nresearch has thus applied OCSVM to novelty detection for IoT. Unfortunately,\nconventional OCSVMs introduce significant memory requirements and are\ncomputationally expensive at prediction time as the size of the train set\ngrows, requiring space and time that scales with the number of training points.\nThese memory and computational constraints can be prohibitive in practical,\nreal-world deployments, where large training sets are typically needed to\ndevelop accurate models when fitting complex decision boundaries. In this work,\nwe extend so-called Nystr\\\"om and (Gaussian) Sketching approaches to OCSVM, by\ncombining these methods with clustering and Gaussian mixture models to achieve\nsignificant speedups in prediction time and space in various IoT settings,\nwithout sacrificing detection accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 15:59:56 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Yang", "Kun", ""], ["Kpotufe", "Samory", ""], ["Feamster", "Nick", ""]]}, {"id": "2104.11307", "submitter": "Pawel Kryszkiewicz", "authors": "Pawel Kryszkiewicz, Hanna Bogucka", "title": "Low Complex, Narrowband-Interference Robust Synchronization for NC-OFDM\n  Cognitive Radio", "comments": null, "journal-ref": "in IEEE Transactions on Communications, vol. 64, no. 9, pp.\n  3644-3654, Sept. 2016", "doi": "10.1109/TCOMM.2016.2596780.", "report-no": null, "categories": "cs.SI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new, low-complexity algorithm for time and frequency\nsynchronization in a non-contiguous-orthogonal frequency division multiplexing\n(NC-OFDM) radio communication system in the presence of narrowband interference\n(NBI). This interference scenario is plausible for cognitive radio systems. The\ncomputational complexity of the proposed synchronization method is similar to\nthe known Schmidl&Cox algorithm. The algorithm is partially blind, i.e., it\ndoes not require information on the NC-OFDM subcarriers used, nor on the\ncenter-frequency of the NBI. Moreover, it does not require filtering to remove\nthe NBI. It performs best for the NBI of constant carrier frequency, but it\nalso provides good results for the frequency-modulated interfering signal.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 20:16:15 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Kryszkiewicz", "Pawel", ""], ["Bogucka", "Hanna", ""]]}, {"id": "2104.11320", "submitter": "Hina Tabassum Prof.", "authors": "Sheyda Zarandi and Hina Tabassum", "title": "Federated Double Deep Q-learning for Joint Delay and Energy Minimization\n  in IoT networks", "comments": "Accepted, in IEEE International Conference on Communications (ICC)\n  Workshops, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a federated deep reinforcement learning framework\nto solve a multi-objective optimization problem, where we consider minimizing\nthe expected long-term task completion delay and energy consumption of IoT\ndevices. This is done by optimizing offloading decisions, computation resource\nallocation, and transmit power allocation. Since the formulated problem is a\nmixed-integer non-linear programming (MINLP), we first cast our problem as a\nmulti-agent distributed deep reinforcement learning (DRL) problem and address\nit using double deep Q-network (DDQN), where the actions are offloading\ndecisions. The immediate cost of each agent is calculated through solving\neither the transmit power optimization or local computation resource\noptimization, based on the selected offloading decisions (actions). Then, to\nenhance the learning speed of IoT devices (agents), we incorporate federated\nlearning (FDL) at the end of each episode. FDL enhances the scalability of the\nproposed DRL framework, creates a context for cooperation between agents, and\nminimizes their privacy concerns. Our numerical results demonstrate the\nefficacy of our proposed federated DDQN framework in terms of learning speed\ncompared to federated deep Q network (DQN) and non-federated DDQN algorithms.\nIn addition, we investigate the impact of batch size, network layers, DDQN\ntarget network update frequency on the learning speed of the FDL.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 18:41:59 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Zarandi", "Sheyda", ""], ["Tabassum", "Hina", ""]]}, {"id": "2104.11331", "submitter": "Ali Bemani", "authors": "Ali Bemani, Nassar Ksairi, Marios Kountouris", "title": "AFDM: A Full Diversity Next Generation Waveform for High Mobility\n  Communications", "comments": "6 pages, 5 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Affine Frequency Division Multiplexing (AFDM), a new chirp-based\nmulticarrier transceiver scheme for high mobility communications in\nnext-generation wireless systems. AFDM is based on discrete affine Fourier\ntransform (DAFT), a generalization of discrete Fourier transform characterized\nwith two parameters that can be adapted to better cope with doubly dispersive\nchannels. Based on the derived input-output relation, the DAFT parameters\nunderlying AFDM are set in such a way to avoid that time domain channel paths\nwith distinct delays or Doppler frequency shifts overlap in the DAFT domain.\nThe resulting DAFT domain impulse response thus conveys a full delay-Doppler\nrepresentation of the channel. We show that AFDM can achieve the full diversity\nof linear time-varying (LTV) channels. Our analytical results are validated\nthrough numerical simulations, which evince that AFDM outperforms\nstate-of-the-art multicarrier schemes in terms of bit error rate (BER) in\ndoubly dispersive channels.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 21:30:52 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Bemani", "Ali", ""], ["Ksairi", "Nassar", ""], ["Kountouris", "Marios", ""]]}, {"id": "2104.11645", "submitter": "Di Wu", "authors": "Di Wu, Xiaofeng Xie, Xiang Ni, Bin Fu, Hanhui Deng, Haibo Zeng, and\n  Zhijin Qin", "title": "Software-Defined Edge Computing: A New Architecture Paradigm to Support\n  IoT Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid deployment of Internet of Things (IoT) applications leads to\nmassive data that need to be processed. These IoT applications have specific\ncommunication requirements on latency and bandwidth, and present new features\non their generated data such as time-dependency. Therefore, it is desirable to\nreshape the current IoT architectures by exploring their inherent nature of\ncommunication and computing to support smart IoT data process and analysis. We\nintroduce in this paper features of IoT data, trends of IoT network\narchitectures, some problems in IoT data analysis, and their solutions.\nSpecifically, we view that software-defined edge computing is a promising\narchitecture to support the unique needs of IoT data analysis. We further\npresent an experiment on data anomaly detection in this architecture, and the\ncomparison between two architectures for ECG diagnosis. Results show that our\nmethod is effective and feasible.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 11:19:20 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 02:39:57 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Wu", "Di", ""], ["Xie", "Xiaofeng", ""], ["Ni", "Xiang", ""], ["Fu", "Bin", ""], ["Deng", "Hanhui", ""], ["Zeng", "Haibo", ""], ["Qin", "Zhijin", ""]]}, {"id": "2104.11700", "submitter": "Saeedeh Parsaeefard", "authors": "Saeedeh Parsaeefard, Sayed Ehsan Etesami and Alberto Leon Garcia", "title": "Robust Federated Learning by Mixture of Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel weighted average model based on the mixture of experts\n(MoE) concept to provide robustness in Federated learning (FL) against the\npoisoned/corrupted/outdated local models. These threats along with the non-IID\nnature of data sets can considerably diminish the accuracy of the FL model. Our\nproposed MoE-FL setup relies on the trust between users and the server where\nthe users share a portion of their public data sets with the server. The server\napplies a robust aggregation method by solving the optimization problem or the\nSoftmax method to highlight the outlier cases and to reduce their adverse\neffect on the FL process. Our experiments illustrate that MoE-FL outperforms\nthe performance of the traditional aggregation approach for high rate of\npoisoned data from attackers.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:41:04 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Parsaeefard", "Saeedeh", ""], ["Etesami", "Sayed Ehsan", ""], ["Garcia", "Alberto Leon", ""]]}, {"id": "2104.11725", "submitter": "Sinan Aksoy", "authors": "Sinan Aksoy, Stephen Young, Jesun Firoz, Roberto Gioiosa, Mark Raugas,\n  Juan Escobedo", "title": "SpectralFly: Ramanujan Graphs as Flexible and Efficient Interconnection\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AR cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, graph theoretic considerations have become increasingly\nimportant in the design of HPC interconnection topologies. One approach is to\nseek optimal or near-optimal families of graphs with respect to a particular\ngraph theoretic property, such as diameter. In this work, we consider\ntopologies which optimize the spectral gap. In particular, we study a novel HPC\ntopology, SpectralFly, designed around the Ramanujan graph construction of\nLubotzky, Phillips, and Sarnak (LPS). We show combinatorial properties, such as\ndiameter, bisection bandwidth, average path length, and resilience to link\nfailure, of SpectralFly topologies are better than, or comparable to, similarly\nconstrained DragonFly, SlimFly, and BundleFly topologies. Additionally, we\nsimulate the performance of SpectralFly topologies on a representative sample\nof physics-inspired HPC workloads using the Structure Simulation Toolkit\nMacroscale Element Library simulator and demonstrate considerable benefit to\nusing the LPS construction as the basis of the SpectralFly topology.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 17:21:55 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Aksoy", "Sinan", ""], ["Young", "Stephen", ""], ["Firoz", "Jesun", ""], ["Gioiosa", "Roberto", ""], ["Raugas", "Mark", ""], ["Escobedo", "Juan", ""]]}, {"id": "2104.11785", "submitter": "Marco Giordani", "authors": "Valentina Rossi, Paolo Testolina, Marco Giordani, Michele Zorzi", "title": "On the Role of Sensor Fusion for Object Detection in Future Vehicular\n  Networks", "comments": "This paper has been accepted for presentation at the Joint European\n  Conference on Networks and Communications & 6G Summit (EuCNC/6G Summit). 6\n  pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully autonomous driving systems require fast detection and recognition of\nsensitive objects in the environment. In this context, intelligent vehicles\nshould share their sensor data with computing platforms and/or other vehicles,\nto detect objects beyond their own sensors' fields of view. However, the\nresulting huge volumes of data to be exchanged can be challenging to handle for\nstandard communication technologies. In this paper, we evaluate how using a\ncombination of different sensors affects the detection of the environment in\nwhich the vehicles move and operate. The final objective is to identify the\noptimal setup that would minimize the amount of data to be distributed over the\nchannel, with negligible degradation in terms of object detection accuracy. To\nthis aim, we extend an already available object detection algorithm so that it\ncan consider, as an input, camera images, LiDAR point clouds, or a combination\nof the two, and compare the accuracy performance of the different approaches\nusing two realistic datasets. Our results show that, although sensor fusion\nalways achieves more accurate detections, LiDAR only inputs can obtain similar\nresults for large objects while mitigating the burden on the channel.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 18:58:37 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Rossi", "Valentina", ""], ["Testolina", "Paolo", ""], ["Giordani", "Marco", ""], ["Zorzi", "Michele", ""]]}, {"id": "2104.11811", "submitter": "Takamochi Kanda", "authors": "T. Kanda, Y. Koda, K. Yamamoto, T. Nishio", "title": "ACK-Less Rate Adaptation for IEEE 802.11bc Enhanced Broadcast Services\n  Using Sim-to-Real Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In IEEE 802.11bc, the broadcast mode on wireless local area networks (WLANs),\ndata rate control that is based on acknowledgement (ACK) mechanism similar to\nthe one in the current IEEE 802.11 WLANs is not applicable because ACK\nmechanism is not implemented. This paper addresses this challenge by proposing\nACK-less data rate adaptation methods by capturing non-broadcast uplink frames\nof STAs. In IEEE 802.11bc, an use case is assumed, where a part of STAs in the\nbroadcast recipients is also associated with non-broadcast APs, and such STAs\nperiodically transmit uplink frames including ACK frames. The proposed method\nis based on the idea that by overhearing such uplink frames, the broadcast AP\nsurveys channel conditions at partial STAs, thereby setting appropriate data\nrates for the STAs. Furthermore, in order to avoid reception failures in a\nlarge portion of STAs, this paper proposes deep reinforcement learning\n(DRL)-based data rate adaptation framework that uses a sim-to-real approach.\nTherein, information of reception success/failure at broadcast recipient STAs,\nthat could not be notified to the broadcast AP in real deployments, are made\navailable by simulations beforehand, thereby forming data rate adaptation\nstrategies. Numerical results show that utilizing overheard uplink frames of\nrecipients makes it feasible to manage data rates in ACK-less broadcast WLANs,\nand using the sim-to-real DRL framework can decrease reception failures.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 20:16:56 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kanda", "T.", ""], ["Koda", "Y.", ""], ["Yamamoto", "K.", ""], ["Nishio", "T.", ""]]}, {"id": "2104.12147", "submitter": "Atri Mukhopadhyay", "authors": "Atri Mukhopadhyay, Goutam Das", "title": "Learning Aided Auctioning for Opportunistic Scheduling in a Wireless\n  Optical Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focusses on Service Level Agreement (SLA) based end-to-end Quality\nof Service (QoS) maintenance across a wireless optical integrated network. The\nwireless network used is Long Term Evolution/Long Term Evolution Advanced\n(LTE/LTE-A) mobile network and the optical network is comprised of an Ethernet\nPassive Optical Network (EPON). The proposal targets opportunistic allocation\nof any bandwidth that is available after meeting the SLA requirements. Such an\nopportunistic allocation is particularly beneficial when networking\napplications with varying urgency and quality of service requirements are being\noperated at the user end. The opportunistic allocation is carried out with the\nhelp of Vickerey-Clarke-Groves (VCG) auction. The proposal allows the users of\nthe integrated network to decide the payment they want to make in order to\nopportunistically avail bandwidth. Learning automata is used for the users to\nconverge to the optimal payment value based on the network load. The payment\nmade by the users is later used by the optical network units of the EPON to\nprepare the bids for the auction. The proposal has been verified through\nextensive simulations.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 13:04:23 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Mukhopadhyay", "Atri", ""], ["Das", "Goutam", ""]]}, {"id": "2104.12426", "submitter": "Pavlos Papadopoulos", "authors": "Pavlos Papadopoulos, Oliver Thornewill von Essen, Nikolaos Pitropakis,\n  Christos Chrysoulas, Alexios Mylonas, William J. Buchanan", "title": "Launching Adversarial Attacks against Network Intrusion Detection\n  Systems for IoT", "comments": "MDPI Mach. Learn. Knowl. Extr. 2021, 3(2), 333-356;\n  https://www.mdpi.com/2624-800X/1/2/14", "journal-ref": "J. Cybersecur. Priv. 2021, 1(2), 252-273", "doi": "10.3390/jcp1020014", "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the internet continues to be populated with new devices and emerging\ntechnologies, the attack surface grows exponentially. Technology is shifting\ntowards a profit-driven Internet of Things market where security is an\nafterthought. Traditional defending approaches are no longer sufficient to\ndetect both known and unknown attacks to high accuracy. Machine learning\nintrusion detection systems have proven their success in identifying unknown\nattacks with high precision. Nevertheless, machine learning models are also\nvulnerable to attacks. Adversarial examples can be used to evaluate the\nrobustness of a designed model before it is deployed. Further, using\nadversarial examples is critical to creating a robust model designed for an\nadversarial environment. Our work evaluates both traditional machine learning\nand deep learning models' robustness using the Bot-IoT dataset. Our methodology\nincluded two main approaches. First, label poisoning, used to cause incorrect\nclassification by the model. Second, the fast gradient sign method, used to\nevade detection measures. The experiments demonstrated that an attacker could\nmanipulate or circumvent detection with significant probability.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 09:36:29 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Papadopoulos", "Pavlos", ""], ["von Essen", "Oliver Thornewill", ""], ["Pitropakis", "Nikolaos", ""], ["Chrysoulas", "Christos", ""], ["Mylonas", "Alexios", ""], ["Buchanan", "William J.", ""]]}, {"id": "2104.12482", "submitter": "Richard Demo Souza", "authors": "Marcus Vinicius Bunn, Richard Demo Souza, Guilherme Luiz Moritz", "title": "Improving 6TiSCH Reliability and Latency with Simultaneous Multi-Band\n  Operation", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet Engineering Task Force (IETF) group \"IPv6 over the TSCH mode of\nIEEE 802.15.4e\" (6TiSCH) introduced a protocol, utilizing Time-Slotted Channel\nHopping (TSCH) from IEEE802.15.4e due to its high reliability and\ntime-deterministic characteristic, that achieves industrial performance\nrequirements while offering the benefits of IP connectivity. This work proposes\nthe addition of a second radio interface in 6TiSCH devices to operate a\nparallel network in sub-GHz, introducing transmit diversity while benefiting\nfrom decreased path-loss and reduced interference. Simulation results show an\nimprovement of 25% in Packet Delivery Ratio (PDR) and closely to 30% in latency\nin different 6TiSCH networks scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 11:26:55 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bunn", "Marcus Vinicius", ""], ["Souza", "Richard Demo", ""], ["Moritz", "Guilherme Luiz", ""]]}, {"id": "2104.12501", "submitter": "Sejin Seo", "authors": "Sejin Seo, Seung-Woo Ko, Jihong Park, Seong-Lyun Kim, and Mehdi Bennis", "title": "Communication-Efficient and Personalized Federated Lottery Ticket\n  Learning", "comments": "5 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The lottery ticket hypothesis (LTH) claims that a deep neural network (i.e.,\nground network) contains a number of subnetworks (i.e., winning tickets), each\nof which exhibiting identically accurate inference capability as that of the\nground network. Federated learning (FL) has recently been applied in LotteryFL\nto discover such winning tickets in a distributed way, showing higher accuracy\nmulti-task learning than Vanilla FL. Nonetheless, LotteryFL relies on unicast\ntransmission on the downlink, and ignores mitigating stragglers, questioning\nscalability. Motivated by this, in this article we propose a personalized and\ncommunication-efficient federated lottery ticket learning algorithm, coined\nCELL, which exploits downlink broadcast for communication efficiency.\nFurthermore, it utilizes a novel user grouping method, thereby alternating\nbetween FL and lottery learning to mitigate stragglers. Numerical simulations\nvalidate that CELL achieves up to 3.6% higher personalized task classification\naccuracy with 4.3x smaller total communication cost until convergence under the\nCIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 12:01:41 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Seo", "Sejin", ""], ["Ko", "Seung-Woo", ""], ["Park", "Jihong", ""], ["Kim", "Seong-Lyun", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2104.12602", "submitter": "Alex Sim", "authors": "Jeeyung Kim, Alex Sim, Jinoh Kim, Kesheng Wu, Jaegyoon Hahm", "title": "Improving Botnet Detection with Recurrent Neural Network and Transfer\n  Learning", "comments": "arXiv admin note: text overlap with arXiv:2004.00234", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Botnet detection is a critical step in stopping the spread of botnets and\npreventing malicious activities. However, reliable detection is still a\nchallenging task, due to a wide variety of botnets involving ever-increasing\ntypes of devices and attack vectors. Recent approaches employing machine\nlearning (ML) showed improved performance than earlier ones, but these ML-\nbased approaches still have significant limitations. For example, most ML\napproaches can not incorporate sequential pattern analysis techniques key to\ndetect some classes of botnets. Another common shortcoming of ML-based\napproaches is the need to retrain neural networks in order to detect the\nevolving botnets; however, the training process is time-consuming and requires\nsignificant efforts to label the training data. For fast-evolving botnets, it\nmight take too long to create sufficient training samples before the botnets\nhave changed again. To address these challenges, we propose a novel botnet\ndetection method, built upon Recurrent Variational Autoencoder (RVAE) that\neffectively captures sequential characteristics of botnet activities. In the\nexperiment, this semi-supervised learning method achieves better detection\naccuracy than similar learning methods, especially on hard to detect classes.\nAdditionally, we devise a transfer learning framework to learn from a\nwell-curated source data set and transfer the knowledge to a target problem\ndomain not seen before. Tests show that the true-positive rate (TPR) with\ntransfer learning is higher than the RVAE semi-supervised learning method\ntrained using the target data set (91.8% vs. 68.3%).\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 14:05:01 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kim", "Jeeyung", ""], ["Sim", "Alex", ""], ["Kim", "Jinoh", ""], ["Wu", "Kesheng", ""], ["Hahm", "Jaegyoon", ""]]}, {"id": "2104.12608", "submitter": "Saeedeh Parsaeefard", "authors": "Saeedeh Parsaeefard and Alberto Leon Garcia", "title": "Generalized ADMM in Distributed Learning via Variational Inequality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the explosion in size and complexity of modern data sets and privacy\nconcerns of data holders, it is increasingly important to be able to solve\nmachine learning problems in distributed manners. The Alternating Direction\nMethod of Multipliers (ADMM) through the concept of consensus variables is a\npractical algorithm in this context where its diverse variations and its\nperformance have been studied in different application areas. In this paper, we\nstudy the effect of the local data sets of users in the distributed learning of\nADMM. Our aim is to deploy variational inequality (VI) to attain an unified\nview of ADMM variations. Through the simulation results, we demonstrate how\nmore general definitions of consensus parameters and introducing the uncertain\nparameters in distribute approach can help to get the better results in\nlearning processes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 14:16:14 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Parsaeefard", "Saeedeh", ""], ["Garcia", "Alberto Leon", ""]]}, {"id": "2104.12678", "submitter": "Yuchang Sun", "authors": "Yuchang Sun and Jiawei Shao and Yuyi Mao and Jun Zhang", "title": "Semi-Decentralized Federated Edge Learning for Fast Convergence on\n  Non-IID Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated edge learning (FEEL) has emerged as an effective alternative to\nreduce the large communication latency in Cloud-based machine learning\nsolutions, while preserving data privacy. Unfortunately, the learning\nperformance of FEEL may be compromised due to limited training data in a single\nedge cluster. In this paper, we investigate a novel framework of FEEL, namely\nsemi-decentralized federated edge learning (SD-FEEL). By allowing model\naggregation between different edge clusters, SD-FEEL enjoys the benefit of FEEL\nin reducing training latency and improves the learning performance by accessing\nricher training data from multiple edge clusters. A training algorithm for\nSD-FEEL with three main procedures in each round is presented, including local\nmodel updates, intra-cluster and inter-cluster model aggregations, and it is\nproved to converge on non-independent and identically distributed (non-IID)\ndata. We also characterize the interplay between the network topology of the\nedge servers and the communication overhead of inter-cluster model aggregation\non training performance. Experiment results corroborate our analysis and\ndemonstrate the effectiveness of SD-FFEL in achieving fast convergence.\nBesides, guidelines on choosing critical hyper-parameters of the training\nalgorithm are also provided.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 16:11:47 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 04:27:54 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 06:38:39 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Sun", "Yuchang", ""], ["Shao", "Jiawei", ""], ["Mao", "Yuyi", ""], ["Zhang", "Jun", ""]]}, {"id": "2104.12878", "submitter": "Khondokar Fida Hasan", "authors": "Khondokar Fida Hasan, Anthony Overall, Keyvan Ansari, Gowri\n  Ramachandran, Raja Jurdak", "title": "Security, Privacy and Trust: Cognitive Internet of Vehicles", "comments": "19 pages, book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The recent advancement of cloud technology offers unparallel strength to\nsupport intelligent computations and advanced services to assist with automated\ndecisions to improve road transportation safety and comfort. Besides, the rise\nof machine intelligence propels the technological evolution of transportation\nsystems one step further and leads to a new framework known as Cognitive\nInternet of Vehicles (C-IoV). The redefined cognitive technology in this\nframework promises significant enhancements and optimized network capacities\ncompared with its predecessor framework, the Internet of Vehicles (IoV). CIoV\noffers additional security measures and introduces security and privacy\nconcerns, such as evasion attacks, additional threats of data poisoning, and\nlearning errors, which may likely lead to system failure and road user\nfatalities. Similar to many other public enterprise systems, transportation has\na significant impact on the population. Therefore, it is crucial to understand\nthe evolution and equally essential to identify potential security\nvulnerabilities and issues to offer mitigation towards success. This chapter\noffers discussions framing answers to the following two questions, 1) how and\nin what ways the penetration of the latest technologies are reshaping the\ntransportation system? 2) whether the evolved system is capable of addressing\nthe concerns of cybersecurity? This chapter, therefore, starts presenting the\nevolution of the transportation system followed by a quick overview of the\nevolved CIoV, highlighting the evolved cognitive design. Later it presents how\na cognitive engine can overcome legacy security concerns and also be subjected\nto further potential security, privacy, and trust issues that this cloud-based\nevolved transportation system may encounter.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 21:05:03 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Hasan", "Khondokar Fida", ""], ["Overall", "Anthony", ""], ["Ansari", "Keyvan", ""], ["Ramachandran", "Gowri", ""], ["Jurdak", "Raja", ""]]}, {"id": "2104.12900", "submitter": "Pawel Kryszkiewicz", "authors": "Pawel Kryszkiewicz, Hanna Bogucka", "title": "In-Band-Interference Robust Synchronization Algorithm for an NC-OFDM\n  System", "comments": null, "journal-ref": "in IEEE Transactions on Communications, vol. 64, no. 5, pp.\n  2143-2154, May 2016", "doi": "10.1109/TCOMM.2016.2540640", "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider receiver synchronization in the non-continguous orthogonal\nfrequency division multiplexing (NC-OFDM)-based radio system in the presence of\nin-band interfering signal, which occupies the frequency-band between blocks of\nsubcarriers (SCs) used by this system, i.e. in-band of NC-OFDM receiver\nspectrum range. This paper proposes a novel preamble-based synchronization\nalgorithm for estimation of the time and frequency offset based on the received\nsignal cross-correlation with the reference preamble. Contrary to the existing\nalgorithms, it is robust against in-band interference including narrowband\ninterference at the cost of increased complexity. Moreover, in the\ninterference-free system, the probability of frame synchronization error is\nimproved in comparison to all simulated algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 22:31:34 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Kryszkiewicz", "Pawel", ""], ["Bogucka", "Hanna", ""]]}, {"id": "2104.12913", "submitter": "Pawel Kryszkiewicz", "authors": "Pawel Kryszkiewicz, Filip Idzikowski, Bartosz Bossy, Bartosz Kopras,\n  Hanna Bogucka", "title": "Energy Savings by Task Offloading to a Fog Considering Radio Front-End\n  Characteristics", "comments": "IEEE International Symposium on Personal, Indoor and Mobile Radio\n  Communications 2019", "journal-ref": null, "doi": "10.1109/PIMRC.2019.8904231", "report-no": null, "categories": "cs.NI cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog computing can be used to offload computationally intensive tasks from\nbattery powered Internet of Things (IoT) devices. Although it reduces energy\nrequired for computations in an IoT device, it uses energy for communications\nwith the fog. This paper analyzes when usage of fog computing is more energy\nefficient than local computing. Detailed energy consumption models are built in\nboth scenarios with the focus set on the relation between energy consumption\nand distortion introduced by a Power Amplifier (PA). Numerical results show\nthat task offloading to a fog is the most energy efficient for short, wideband\nlinks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 23:49:56 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Kryszkiewicz", "Pawel", ""], ["Idzikowski", "Filip", ""], ["Bossy", "Bartosz", ""], ["Kopras", "Bartosz", ""], ["Bogucka", "Hanna", ""]]}, {"id": "2104.12959", "submitter": "Lifan Mei", "authors": "Lifan Mei, Jinrui Gou, Yujin Cai, Houwei Cao and Yong Liu", "title": "Realtime Mobile Bandwidth and Handoff Predictions in 4G/5G Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mobile apps are increasingly relying on high-throughput and low-latency\ncontent delivery, while the available bandwidth on wireless access links is\ninherently time-varying. The handoffs between base stations and access modes\ndue to user mobility present additional challenges to deliver a high level of\nuser Quality-of-Experience (QoE). The ability to predict the available\nbandwidth and the upcoming handoffs will give applications valuable leeway to\nmake proactive adjustments to avoid significant QoE degradation. In this paper,\nwe explore the possibility and accuracy of realtime mobile bandwidth and\nhandoff predictions in 4G/LTE and 5G networks. Towards this goal, we collect\nlong consecutive traces with rich bandwidth, channel, and context information\nfrom public transportation systems. We develop Recurrent Neural Network models\nto mine the temporal patterns of bandwidth evolution in fixed-route mobility\nscenarios. Our models consistently outperform the conventional univariate and\nmultivariate bandwidth prediction models. For 4G \\& 5G co-existing networks, we\npropose a new problem of handoff prediction between 4G and 5G, which is\nimportant for low-latency applications like self-driving strategy in realistic\n5G scenarios. We develop classification and regression based prediction models,\nwhich achieve more than 80\\% accuracy in predicting 4G and 5G handoffs in a\nrecent 5G dataset.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 03:19:40 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Mei", "Lifan", ""], ["Gou", "Jinrui", ""], ["Cai", "Yujin", ""], ["Cao", "Houwei", ""], ["Liu", "Yong", ""]]}, {"id": "2104.12993", "submitter": "Javad Sabzehali", "authors": "Javad Sabzehali, Vijay K. Shah, Harpreet S. Dhillon, and Jeffrey H.\n  Reed", "title": "3D Placement and Orientation of mmWave-based UAVs for Guaranteed LoS\n  Coverage", "comments": "To appear in IEEE Wireless Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MA cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs), as aerial base stations, are a promising\nsolution for providing wireless communications, thanks to their high\nflexibility and autonomy. Moreover, emerging services, such as extended\nreality, require high-capacity communications. To achieve this, millimeter wave\n(mmWave), and recently, terahertz bands have been considered for UAV\ncommunications. However, communication at these high frequencies requires a\nline-of-sight (LoS) to the terminals, which may be located in 3D space and may\nhave extremely limited direct-line-of-view (LoV) due to blocking objects, like\nbuildings and trees. In this paper, we investigate the problem of determining\n3D placement and orientation of UAVs such that users have guaranteed LoS\ncoverage by at least one UAV and the signal-to-noise ratio (SNR) between the\nUAV-user pairs are maximized. We formulate the problem as an integer linear\nprogramming(ILP) problem and prove its NP-hardness. Next, we propose a\nlow-complexity geometry-based greedy algorithm to solve the problem\nefficiently. Our simulation results show that the proposed algorithm (almost)\nalways guarantees LoS coverage to all users in all considered simulation\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 05:55:18 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Sabzehali", "Javad", ""], ["Shah", "Vijay K.", ""], ["Dhillon", "Harpreet S.", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "2104.13001", "submitter": "Ahmadreza Montazerolghaem", "authors": "Sahar Abdollahi, Arash Deldari, Hamid Asadi, AhmadReza\n  Montazerolghaem, Sayyed Majid Mazinani", "title": "Flow aware Forwarding in SDN Datacenters Using a Knapsack PSO Based\n  Solution", "comments": "https://ieeexplore.ieee.org/document/9373546", "journal-ref": null, "doi": "10.1109/TNSM.2021.3064974", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the rapid growth of different massive applications and parallel flow\nrequests in Data Center Networks (DCNs), today's providers are confronting\nchallenges in flow forwarding decisions. Since Software Defined Networking\n(SDN) provides fine granular control, it can be intelligently programmed to\ndistinguish between flow requirements. The present article proposes a knapsack\nmodel in which the link bandwidth and incoming flows are modeled as a knapsack\ncapacity and items, respectively. Furthermore, each flow consists of two size\nand value aspects, acquired through flow size extraction and the type of\nservice value assigned by the SDN controller decision. Indeed, the current work\nsplits the incoming flow size range into Type of Service (ToS) decimal value\nnumbers. The lower the flow size category, the higher the value dedicated to\nthe flow. Particle Swarm Optimization (PSO) optimizes the knapsack problem and\nfirst forwards the selected flows by KP-PSO, and the non-selected-flows second.\nTo address the shortcomings of these methods in the event of dense parallel\nflow detection, the present study puts the link under the threshold of a 70\npercent load by simultaneous requests. Experimental results indicate that the\nproposed method outperforms Sonum, Hedera, and ECMP in terms of flow completion\ntime, packet loss rate, and goodput regarding flow size requirements.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 06:48:08 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Abdollahi", "Sahar", ""], ["Deldari", "Arash", ""], ["Asadi", "Hamid", ""], ["Montazerolghaem", "AhmadReza", ""], ["Mazinani", "Sayyed Majid", ""]]}, {"id": "2104.13029", "submitter": "Davide Brunelli PhD", "authors": "Flavio Di Nuzzo, Davide Brunelli, Tommaso Polonelli, Luca Benini", "title": "Structural Health Monitoring system with Narrowband IoT and MEMS sensors", "comments": "10 pages, 10 figures, IEEE Sensors Journal", "journal-ref": null, "doi": "10.1109/JSEN.2021.3075093", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Monitoring of civil infrastructures is critically needed to track aging,\ndamages and ultimately to prevent severe failures which can endanger many\nlives. The ability to monitor in a continuous and fine-grained fashion the\nintegrity of a wide variety of buildings, referred to as structural health\nmonitoring, with low-cost, long-term and continuous measurements is essential\nfrom both an economic and a life-safety standpoint. To address these needs, we\npropose a low-cost wireless sensor node specifically designed to support modal\nanalysis over extended periods of time with long-range connectivity at low\npower consumption. Our design uses very cost-effective MEMS accelerometers and\nexploits the Narrowband IoT protocol (NB-IoT) to establish long-distance\nconnection with 4G infrastructure networks. Long-range wireless connectivity,\ncabling-free installation and multi-year lifetime are a unique combination of\nfeatures, not available, to the best of our knowledge, in any commercial or\nresearch device. We discuss in detail the hardware architecture and power\nmanagement of the node. Experimental tests demonstrate a lifetime of more than\nten years with a 17000 mAh battery or completely energy-neutral operation with\na small solar panel (60 mm x 120 mm). Further, we validate measurement accuracy\nand confirm the feasibility of modal analysis with the MEMS sensors: compared\nwith a high-precision instrument based on a piezoelectric transducer, our\nsensor node achieves a maximum difference of 0.08% at a small fraction of the\ncost and power consumption.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 07:59:00 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Di Nuzzo", "Flavio", ""], ["Brunelli", "Davide", ""], ["Polonelli", "Tommaso", ""], ["Benini", "Luca", ""]]}, {"id": "2104.13184", "submitter": "Luc Le Magoarou", "authors": "Luc Le Magoarou (IRT b-com, Hypermedia)", "title": "Efficient channel charting via phase-insensitive distance computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel charting is an unsupervised learning task whose objective is to\nencode channels so that the obtained representation reflects the relative\nspatial locations of the corresponding users. It has many potential\napplications, ranging from user scheduling to proactive handover. In this\npaper, a channel charting method is proposed, based on a distance measure\nspecifically designed to reduce the effect of small scale fading, which is an\nirrelevant phenomenon with respect to the channel charting task. A nonlinear\ndimensionality reduction technique aimed at preserving local distances (Isomap)\nis then applied to actually get the channel representation. The approach is\nempirically validated on realistic synthetic MIMO channels, achieving better\nresults than previously proposed approaches, at a lower cost.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 13:42:18 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Magoarou", "Luc Le", "", "IRT b-com, Hypermedia"]]}, {"id": "2104.13493", "submitter": "Yantong Wang", "authors": "Yantong Wang, Vasilis Friderikos", "title": "Energy-Efficient Proactive Caching with Multipath Routing", "comments": "20 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-continuing explosive growth of on-demand content requests has\nimposed great pressure on mobile/wireless network infrastructures. To ease\ncongestion in the network and increase perceived user experience, caching\npopular content closer to the end-users can play a significant role and as such\nthis issue received significant attention over the last few years.\nAdditionally, energy efficiency is treated as a fundamental requirement in the\ndesign of next-generation mobile networks. However, there has been little\nattention to the overlapping area between energy efficiency and network caching\nespecially when considering multipath routing. To this end, this paper proposes\nan energy-efficient caching with multipath routing support. The proposed scheme\nprovides a joint anchoring of popular content into a set of potential caching\nnodes with optimized multi-path support whilst ensuring a balance between\ntransmission and caching energy cost. The proposed model also considers\ndifferent content delivery modes, such as multicast and unicast. Two separated\nInteger-Linear Programming (ILP) models are formulated for each delivery mode.\nTo tackle the curse of dimensionality we then provide a greedy simulated\nannealing algorithm, which not only reduces the time complexity but also\nprovides a competitive performance as ILP models. A wide set of numerical\ninvestigations has shown that the proposed scheme is more energy-efficient\ncompared with other widely used approaches in caching under the premise of\nnetwork resource limitation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 22:16:27 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Wang", "Yantong", ""], ["Friderikos", "Vasilis", ""]]}, {"id": "2104.13574", "submitter": "Phillip Oni", "authors": "Phillip B. Oni and Steven D. Blostein", "title": "Joint AP Association and PCS Threshold Selection in Dense Full-duplex\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Joint access point (AP) association and physical carrier sensing (PCS)\nthreshold selection has the potential to improve the performance in high\ndensity wireless LANs (WLANs) under high contention, interference and\nself-interference (SI) limited transmissions. Using tools from stochastic\ngeometry, user and AP locations are independent realizations of spatial point\nprocesses. Considering the inherent effects of the channel access protocol, the\nspatial density of throughput (SDT), which depends on channel access\nprobability and coverage rate, is derived as the performance objective.\nLeveraging spatial statistics of the network, a throughput-utility maximization\nproblem is formulated to seek AP association and PCS threshold selection\npolicies that jointly maximize SDT. The AP association and the PCS threshold\nselection policies are derived analytically while an algorithm is proposed for\nnumerical solution. Under simulated scenarios involving full-duplex (FD) nodes,\noptimizing AP association yields performance gains for low to high node density\nin large-scale wireless networks. Considering PCS threshold selection\noptimization jointly with AP association is shown to improve performance by\neffectively separating concurrent transmissions in space. It is shown that AP\nassociation in FD WLANs groups users into minimal contention domains and PCS\nthreshold optimization reduces the interference domain of user groups for\nadditional performance gains.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 05:19:51 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Oni", "Phillip B.", ""], ["Blostein", "Steven D.", ""]]}, {"id": "2104.13623", "submitter": "Yong Niu", "authors": "Xiangfei Zhang, Yong Niu, Shiwen Mao, Yunlong Cai, Ruisi He, Bo Ai,\n  Zhangdui Zhong, Yiru Liu", "title": "Resource Allocation for Millimeter-Wave Train-Ground Communications in\n  High-Speed Railway Scenarios", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of wireless communication, higher requirements arise for\ntrain-ground wireless communications in high-speed railway (HSR) scenarios. The\nmillimeter-wave (mm-wave) frequency band with rich spectrum resources can\nprovide users in HSR scenarios with high performance broadband multimedia\nservices, while the full-duplex (FD) technology has become mature. In this\npaper, we study train-ground communication system performance in HSR scenarios\nwith mobile relays (MRs) mounted on rooftop of train and operating in the FD\nmode. We formulate a nonlinear programming problem to maximize network capacity\nby allocation of spectrum resources. Then, we develop a sequential quadratic\nprogramming (SQP) algorithm based on the Lagrange function to solve the\nbandwidth allocation optimization problem for track-side base station (BS) and\nMRs in this mm-wave train-ground communication system. Extensive simulation\nresults demonstrate that the proposed SQP algorithm can effectively achieve\nhigh network capacity for trainground communication in HSR scenarios while\nbeing robust to the residual self-interference (SI).\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 08:14:53 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Zhang", "Xiangfei", ""], ["Niu", "Yong", ""], ["Mao", "Shiwen", ""], ["Cai", "Yunlong", ""], ["He", "Ruisi", ""], ["Ai", "Bo", ""], ["Zhong", "Zhangdui", ""], ["Liu", "Yiru", ""]]}, {"id": "2104.13671", "submitter": "Pritam Majumder", "authors": "Pritam Majumder, Jiayi Huang, Sungkeun Kim, Abdullah Muzahid, Dylan\n  Siegers, Chia-Che Tsai, and Eun Jung Kim", "title": "Continual Learning Approach for Improving the Data and Computation\n  Mapping in Near-Memory Processing System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG cs.NI cs.OS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The resurgence of near-memory processing (NMP) with the advent of big data\nhas shifted the computation paradigm from processor-centric to memory-centric\ncomputing. To meet the bandwidth and capacity demands of memory-centric\ncomputing, 3D memory has been adopted to form a scalable memory-cube network.\nAlong with NMP and memory system development, the mapping for placing data and\nguiding computation in the memory-cube network has become crucial in driving\nthe performance improvement in NMP. However, it is very challenging to design a\nuniversal optimal mapping for all applications due to unique application\nbehavior and intractable decision space. In this paper, we propose an\nartificially intelligent memory mapping scheme, AIMM, that optimizes data\nplacement and resource utilization through page and computation remapping. Our\nproposed technique involves continuously evaluating and learning the impact of\nmapping decisions on system performance for any application. AIMM uses a neural\nnetwork to achieve a near-optimal mapping during execution, trained using a\nreinforcement learning algorithm that is known to be effective for exploring a\nvast design space. We also provide a detailed AIMM hardware design that can be\nadopted as a plugin module for various NMP systems. Our experimental evaluation\nshows that AIMM improves the baseline NMP performance in single and multiple\nprogram scenario by up to 70% and 50%, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 09:50:35 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Majumder", "Pritam", ""], ["Huang", "Jiayi", ""], ["Kim", "Sungkeun", ""], ["Muzahid", "Abdullah", ""], ["Siegers", "Dylan", ""], ["Tsai", "Chia-Che", ""], ["Kim", "Eun Jung", ""]]}, {"id": "2104.13774", "submitter": "Ahmed Saeed", "authors": "Yimeng Zhao and Ahmed Saeed and Mostafa Ammar and Ellen Zegura", "title": "Scouting the Path to a Million-Client Server", "comments": null, "journal-ref": "In: Hohlfeld O., Lutu A., Levin D. (eds) Passive and Active\n  Measurement. PAM 2021. Lecture Notes in Computer Science, vol 12671.\n  Springer, Cham", "doi": "10.1007/978-3-030-72582-2_20", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To keep up with demand, servers will scale up to handle hundreds of thousands\nof clients simultaneously. Much of the focus of the community has been on\nscaling servers in terms of aggregate traffic intensity (packets transmitted\nper second). However, bottlenecks caused by the increasing number of concurrent\nclients, resulting in a large number of concurrent flows, have received little\nattention. In this work, we focus on identifying such bottlenecks. In\nparticular, we define two broad categories of problems; namely, admitting more\npackets into the network stack than can be handled efficiently, and increasing\nper-packet overhead within the stack. We show that these problems contribute to\nhigh CPU usage and network performance degradation in terms of aggregate\nthroughput and RTT. Our measurement and analysis are performed in the context\nof the Linux networking stack, the the most widely used publicly available\nnetworking stack. Further, we discuss the relevance of our findings to other\nnetwork stacks. The goal of our work is to highlight considerations required in\nthe design of future networking stacks to enable efficient handling of large\nnumbers of clients and flows.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:03:46 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 15:14:36 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Zhao", "Yimeng", ""], ["Saeed", "Ahmed", ""], ["Ammar", "Mostafa", ""], ["Zegura", "Ellen", ""]]}, {"id": "2104.13785", "submitter": "Jun Kurihara", "authors": "Jun Kurihara and Takeshi Kubo", "title": "Mutualized oblivious DNS ($\\mu$ODNS): Hiding a tree in the wild forest", "comments": "article class, 17pages, 3 figures, 2 tables, the citation [16] is\n  corrected in version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional Domain Name System (DNS) lacks fundamental features of\nsecurity and privacy in its design. As concerns of privacy increased on the\nInternet, security and privacy enhancements of DNS have been actively\ninvestigated and deployed. Specially for user's privacy in DNS queries, several\nrelay-based anonymization schemes have been recently introduced, however, they\nare vulnerable to the collusion of a relay with a full-service resolver, i.e.,\nidentities of users cannot be hidden to the resolver. This paper introduces a\nnew concept of a multiple-relay-based DNS for user anonymity in DNS queries,\ncalled the mutualized oblivious DNS ($\\mu$ODNS), by extending the concept of\nexisting relay-based schemes. The $\\mu$ODNS introduces a small and reasonable\nassumption that each user has at least one trusted/dedicated relay in a network\nand mutually shares the dedicated one with others. The user just sets the\ndedicated one as his next-hop, first relay, conveying his queries to the\nresolver, and randomly chooses its $0$ or more subsequent relays shared by\nother entities. Under this small assumption, the user's identity is concealed\nto a target resolver in the $\\mu$ODNS even if a certain (unknown) subset of\nrelays collude with the resolver. That is, in $\\mu$ODNS, users can preserve\ntheir privacy and anonymity just by paying a small cost of sharing its\nresource. Moreover, we present a PoC implementation of $\\mu$ODNS that is\npublicly available on the Internet. We also show that by measurement of\nround-trip-time for queries, and our PoC implementation of $\\mu$ODNS achieves\nthe performance comparable to existing relay-based schemes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:18:30 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 00:11:05 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 07:14:39 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kurihara", "Jun", ""], ["Kubo", "Takeshi", ""]]}, {"id": "2104.13799", "submitter": "Yuan Liao", "authors": "Yuan Liao and Vasilis Friderikos", "title": "Trajectory Design in Rechargeable UAV Aided Wireless Networks: A Unified\n  Framework for Energy Efficiency and Flight Time Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a rechargeable unmanned aerial vehicle (UAV) assisted\nwireless network, where a UAV is dispatched to disseminate information to a\ngroup of ground terminals (GTs) and returns to a recharging station (RS) before\nthe on-board battery is depleted. The central aim is to design a UAV trajectory\nwith the minimum total time duration, including the flight and recharging time,\nby optimizing the flying velocity, transmit power and hovering positions\njointly. A flow-based mathematical programming formulation is proposed to\nprovide optimal for joint optimization of flying and recharging time.\nFurthermore, to attack the curse of dimensionality for optimal decision making,\na two-step method is proposed. In the first step, the UAV hovering positions is\nfixed and initialize a feasible trajectory design by solving a travelling\nsalesman problem with energy constraints (TSPE) problem. In the second step,\nfor the given initial trajectory, the time consumption for each sub-tour is\nminimized by optimizing the flying velocity, transmit power and hovering\npositions jointly. Numerical results show that the proposed method outperforms\nstate of art techniques and reduces the aggregate time duration in an efficient\nway.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:39:36 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Liao", "Yuan", ""], ["Friderikos", "Vasilis", ""]]}, {"id": "2104.13813", "submitter": "Mirko Zichichi", "authors": "Mirko Zichichi, Stefano Ferretti, Gabriele D'Angelo", "title": "MOVO: a dApp for DLT-based Smart Mobility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plenty of research on smart mobility is currently devoted to the inclusion of\nnovel decentralized software architectures to these systems, due to the\ninherent advantages in terms of transparency, traceability, trustworthiness.\nMOVO is a decentralized application (dApp) for smart mobility. It includes: (i)\na module for collecting data from vehicles and smartphones sensors; (ii) a\ncomponent for interacting with Distributed Ledger Technologies (DLT) and\nDecentralized File Storages (DFS), for storing and validating sensor data;\n(iii) a module for \"offline\" interaction between devices. The dApp consists of\nan Android application intended for use inside a vehicle, which helps the\nuser/driver collect contextually generated data (e.g. a driver's stress level,\nan electric vehicle's battery level), which can then be shared through the use\nof DLT (i.e., IOTA DLT and Ethereum smart contracts) and DFS (i.e., IPFS). The\nthird module consists of an implementation of a communication channel that, via\nWi-Fi Direct, allows two devices to exchange data and payment information with\nrespect to DLT (i.e. cryptocurrency and token) assets. In this paper, we\ndescribe the main software components and provide an experimental evaluation\nthat confirms the viability of the MOVO dApp in real mobility scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:01:28 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Zichichi", "Mirko", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "2104.13819", "submitter": "Mirko Zichichi", "authors": "Mirko Zichichi, Luca Serena, Stefano Ferretti, Gabriele D'Angelo", "title": "Towards Decentralized Complex Queries over Distributed Ledgers: a Data\n  Marketplace Use-case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Ledger Technologies (DLT) and Decentralized File Storages (DFS)\nare becoming increasingly used to create common, decentralized and trustless\ninfrastructures where participants interact and collaborate in Peer-to-Peer\ninteractions. A prominent use case is represented by decentralized data\nmarketplaces, where users are consumers and providers at the same time, and\ntrustless interactions are required. However, data in DLTs and DFS are usually\nunstructured and there are no efficient mechanisms to query a certain type of\ndata for the search in the market. In this paper, we propose the use of a\nDistributed Hash Table (DHT) as a layer on top of DLTs where, once the data are\nacquired and stored in the ledger, these can be searched through multiple\nkeyword based queries, thanks to the lookup functionalities offered by the DHT.\nThe DHT network is a hypercube overlay structure, organized for an efficient\nprocessing of multiple keyword-based queries. We provide the architecture of\nsuch solution for a decentralized data marketplace and an analysis based on a\nsimulation that proves the viability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:11:50 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 08:53:23 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Zichichi", "Mirko", ""], ["Serena", "Luca", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "2104.13873", "submitter": "Adnan Aijaz", "authors": "Haochuan Shi, Adnan Aijaz, Nan Jiang", "title": "Evaluating the Performance of Over-the-Air Time Synchronization for 5G\n  and TSN Integration", "comments": "accepted for IEEE BlackSeaCom 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IEEE 802.1 time-sensitive networking (TSN) standards aim at improving the\nreal-time capabilities of standard Ethernet. TSN is widely recognized as the\nlong-term replacement of proprietary technologies for industrial control\nsystems. However, wired connectivity alone is not sufficient to meet the\nrequirements of future industrial systems. The fifth-generation (5G)\nmobile/cellular technology has been designed with native support for\nultra-reliable low-latency communication (uRLLC). 5G is promising to meet the\nstringent requirements of industrial systems in the wireless domain. Converged\noperation of 5G and TSN systems is crucial for achieving end-to-end\ndeterministic connectivity in industrial networks. Accurate time\nsynchronization is key to integrated operation of 5G and TSN systems. To this\nend, this paper evaluates the performance of over-the-air time synchronization\nmechanism which has been proposed in 3GPP Release 16. We analyze the accuracy\nof time synchronization through the boundary clock approach in the presence of\nclock drift and different air-interface timing errors related to reference time\nindication. We also investigate frequency and scalability aspects of\nover-the-air time synchronization. Our performance evaluation reveals the\nconditions under which 1 \\(\\mu\\)s or below requirement for TSN time\nsynchronization can be achieved.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 16:38:32 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Shi", "Haochuan", ""], ["Aijaz", "Adnan", ""], ["Jiang", "Nan", ""]]}, {"id": "2104.14075", "submitter": "Samer Hanna", "authors": "Samer Hanna, Enes Krijestorac, and Danijela Cabric", "title": "UAV Swarm Position Optimization for High Capacity MIMO Backhaul", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A swarm of cooperating UAVs communicating with a distant multiantenna ground\nstation can leverage MIMO spatial multiplexing to scale the capacity. Due to\nthe line-of-sight propagation between the swarm and the ground station, the\nMIMO channel is highly correlated, leading to limited multiplexing gains. In\nthis paper, we optimize the UAV positions to attain the maximum MIMO capacity\ngiven by the single user bound. An infinite set of UAV placements that attains\nthe capacity bound is first derived. Given an initial swarm placement, we\nformulate the problem of minimizing the distance traveled by the UAVs to reach\na placement within the capacity maximizing set of positions. An offline\ncentralized solution to the problem using block coordinate descent is developed\nassuming known initial positions of UAVs. We also propose an online distributed\nalgorithm, where the UAVs iteratively adjust their positions to maximize the\ncapacity. Our proposed approaches are shown to significantly increase the\ncapacity at the expense of a bounded translation from the initial UAV\nplacements. This capacity increase persists when using a massive MIMO ground\nstation. Using numerical simulations, we show the robustness of our approaches\nin a Rician channel under UAV motion disturbances.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 01:57:43 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Hanna", "Samer", ""], ["Krijestorac", "Enes", ""], ["Cabric", "Danijela", ""]]}, {"id": "2104.14256", "submitter": "Peirui Cao", "authors": "Shizhen Zhao, Xiao Zhang, Peirui Cao, Xinbing Wang", "title": "Design of Robust and Efficient Edge Server Placement and Server\n  Scheduling Policies: Extended Version", "comments": "The extended version of (IWQoS 2021) accepted paper: Design of Robust\n  and Efficient Edge Server Placement and Server Scheduling Policies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study how to design edge server placement and server scheduling policies\nunder workload uncertainty for 5G networks. We introduce a new metric called\nresource pooling factor to handle unexpected workload bursts. Maximizing this\nmetric offers a strong enhancement on top of robust optimization against\nworkload uncertainty. Using both real traces and synthetic traces, we show that\nthe proposed server placement and server scheduling policies not only\ndemonstrate better robustness against workload uncertainty than existing\napproaches, but also significantly reduce the cost of service providers.\nSpecifically, in order to achieve close-to-zero workload rejection rate, the\nproposed server placement policy reduces the number of required edge servers by\nabout 25% compared with the state-of-the-art approach; the proposed server\nscheduling policy reduces the energy consumption of edge servers by about 13%\nwithout causing much impact on the service quality.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 11:01:42 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhao", "Shizhen", ""], ["Zhang", "Xiao", ""], ["Cao", "Peirui", ""], ["Wang", "Xinbing", ""]]}, {"id": "2104.14422", "submitter": "Ahmed Raoof", "authors": "Ahmed Raoof, Chung-Horng Lung, Ashraf Matrawy", "title": "Integrating 6LoWPAN Security with RPL Using The Chained Secure Mode\n  Framework", "comments": "6 pages, 5 figures, 2 tables, submitted to Globecom 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IPv6 over Low-powered Wireless Personal Area Network (6LoWPAN) protocol\nwas introduced to allow the transmission of Internet Protocol version 6 (IPv6)\npackets using the smaller-size frames of the IEEE 802.15.4 standard, which is\nused in many Internet of Things (IoT) networks. The primary duty of the 6LoWPAN\nprotocol is packet fragmentation and reassembly. However, the protocol standard\ncurrently does not include any security measures, not even authenticating the\nfragments immediate sender. This lack of immediate-sender authentication opens\nthe door for adversaries to launch several attacks on the fragmentation\nprocess, such as the buffer-reservation attacks that lead to a Denial of\nService (DoS) attack and resource exhaustion of the victim nodes. This paper\nproposes a security integration between 6LoWPAN and the Routing Protocol for\nLow Power and Lossy Networks (RPL) through the Chained Secure Mode (CSM)\nframework as a possible solution. Since the CSM framework provides a mean of\nimmediate-sender trust, through the use of Network Coding (NC), and an\nintegration interface for the other protocols (or mechanisms) to use this trust\nto build security decisions, 6LoWPAN can use this integration to build a\nchain-of-trust along the fragments routing path. A proof-of-concept\nimplementation was done in Contiki Operating System (OS), and its security and\nperformance were evaluated against an external adversary launching a\nbuffer-reservation attack. The results from the evaluation showed significant\nmitigation of the attack with almost no increase in power consumption, which\npresents the great potential for such integration to secure the forwarding\nprocess at the 6LoWPAN Adaptation Layer\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 15:40:34 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Raoof", "Ahmed", ""], ["Lung", "Chung-Horng", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "2104.14549", "submitter": "Hrishikesh Dutta", "authors": "Hrishikesh Dutta and Subir Biswas", "title": "Medium Access using Distributed Reinforcement Learning for IoTs with\n  Low-Complexity Wireless Transceivers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a distributed Reinforcement Learning (RL) based framework\nthat can be used for synthesizing MAC layer wireless protocols in IoT networks\nwith low-complexity wireless transceivers. The proposed framework does not rely\non complex hardware capabilities such as carrier sensing and its associated\nalgorithmic complexities that are often not supported in wireless transceivers\nof low-cost and low-energy IoT devices. In this framework, the access protocols\nare first formulated as Markov Decision Processes (MDP) and then solved using\nRL. A distributed and multi-Agent RL framework is used as the basis for\nprotocol synthesis. Distributed behavior makes the nodes independently learn\noptimal transmission strategies without having to rely on full network level\ninformation and direct knowledge of behavior of other nodes. The nodes learn to\nminimize packet collisions such that optimal throughput can be attained and\nmaintained for loading conditions that are higher than what the known benchmark\nprotocols (such as ALOHA) for IoT devices without complex transceivers. In\naddition, the nodes are observed to be able to learn to act optimally in the\npresence of heterogeneous loading and network topological conditions. Finally,\nthe proposed learning approach allows the wireless bandwidth to be fairly\ndistributed among network nodes in a way that is not dependent on such\nheterogeneities. Via simulation experiments, the paper demonstrates the\nperformance of the learning paradigm and its abilities to make nodes adapt\ntheir optimal transmission strategies on the fly in response to various network\ndynamics.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:57:43 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Dutta", "Hrishikesh", ""], ["Biswas", "Subir", ""]]}, {"id": "2104.14589", "submitter": "Hussein Ammar", "authors": "Hussein A. Ammar, Raviraj Adve, Shahram Shahbazpanahi, Gary Boudreau,\n  Kothapalli Venkata Srinivas", "title": "User-centric Cell-free Massive MIMO Networks: A Survey of Opportunities,\n  Challenges and Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI cs.SY eess.SP eess.SY math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Densification of network base stations is indispensable to achieve the\nstringent Quality of Service (QoS) requirements of future mobile networks.\nHowever, with a dense deployment of transmitters, interference management\nbecomes an arduous task. To solve this issue, exploring radically new network\narchitectures with intelligent coordination and cooperation capabilities is\ncrucial. This survey paper investigates the emerging user-centric cell-free\nmassive multiple-input multiple-output (MIMO) network architecture that sets a\nfoundation for future mobile networks. Such networks use a dense deployment of\ndistributed units (DUs) to serve users; the crucial difference from the\ntraditional cellular paradigm is that a specific serving cluster of DUs is\ndefined for each user. This framework provides macro diversity, power\nefficiency, interference management, and robust connectivity. Most importantly,\nthe user-centric approach eliminates cell edges, thus contributing to uniform\ncoverage and performance for users across the network area. We present here a\nguide to the key challenges facing the deployment of this network scheme and\ncontemplate the solutions being proposed for the main bottlenecks facing\ncell-free communications. Specifically, we survey the literature targeting the\nfronthaul, then we scan the details of the channel estimation required,\nresource allocation, delay, and scalability issues. Furthermore, we highlight\nsome technologies that can provide a management platform for this scheme such\nas distributed software-defined network (SDN) and self-organizing network\n(SON). Our article serves as a check point that delineates the current status\nand indicates future directions for this area in a comprehensive manner.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 18:21:18 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ammar", "Hussein A.", ""], ["Adve", "Raviraj", ""], ["Shahbazpanahi", "Shahram", ""], ["Boudreau", "Gary", ""], ["Srinivas", "Kothapalli Venkata", ""]]}, {"id": "2104.14833", "submitter": "Pablo Mu\\~noz", "authors": "Pablo Mu\\~noz, Oriol Sallent, Jordi P\\'erez-Romero", "title": "Capacity Self-Planning in Small Cell Multi-Tenant 5G Networks", "comments": null, "journal-ref": "P. Munoz, O. Sallent, J. Perez-Romero, \"Capacity Self-Planning in\n  Small Cell Multi-Tenant 5G Networks\", 2nd IFIP/IEEE International Workshop on\n  Management of 5G Networks (5GMan 2017), pp. 1109-1114, Lisbon, 2017", "doi": "10.23919/INM.2017.7987449", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multi-tenancy allows diverse agents sharing the infrastructure in the 5 th\ngeneration of mobile networks. Such a feature calls for more automated and\nfaster planning procedures in order to adapt the network capacity to the\nvarying traffic demand. To achieve these goals, Small Cells offer network\nproviders more flexible, scalable, and cost-effective solutions compared to\nmacrocell deployments. This paper proposes a novel framework for cell planning\nin multi-tenant Small Cell networks. In this framework, the tenant's contracted\ncapacity is translated to a set of detailed planning specifications over time\nand space domains in order to efficiently update the network infrastructure and\nconfiguration. Based on this, an algorithm is proposed that considers different\nactions such as adding/removing channels and adding or relocating small cells.\nThe proposed approach is evaluated considering the deployment of a new tenant,\nwhere different sets of planning specifications are tested.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 08:35:28 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Mu\u00f1oz", "Pablo", ""], ["Sallent", "Oriol", ""], ["P\u00e9rez-Romero", "Jordi", ""]]}, {"id": "2104.14906", "submitter": "Spyridon Mastorakis", "authors": "Mian Ahmad Jan and Fazlullah Khan and Spyridon Mastorakis and Muhammad\n  Adil and Aamir Akbar and Nicholas Stergiou", "title": "LightIoT: Lightweight and Secure Communication for Energy-Efficient IoT\n  in Health Informatics", "comments": "This paper has been accepted for publication by the IEEE Transactions\n  on Green Communications and Networking. The copyright is with the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is considered as a key enabler of health\ninformatics. IoT-enabled devices are used for in-hospital and in-home patient\nmonitoring to collect and transfer biomedical data pertaining to blood\npressure, electrocardiography (ECG), blood sugar levels, body temperature, etc.\nAmong these devices, wearables have found their presence in a wide range of\nhealthcare applications. These devices generate data in real-time and transmit\nthem to nearby gateways and remote servers for processing and visualization.\nThe data transmitted by these devices are vulnerable to a range of adversarial\nthreats, and as such, privacy and integrity need to be preserved. In this\npaper, we present LightIoT, a lightweight and secure communication approach for\ndata exchanged among the devices of a healthcare infrastructure. LightIoT\noperates in three phases: initialization, pairing, and authentication. These\nphases ensure the reliable transmission of data by establishing secure sessions\namong the communicating entities (wearables, gateways and a remote server).\nStatistical results exhibit that our scheme is lightweight, robust, and\nresilient against a wide range of adversarial attacks and incurs much lower\ncomputational and communication overhead for the transmitted data in the\npresence of existing approaches.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:09:05 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Jan", "Mian Ahmad", ""], ["Khan", "Fazlullah", ""], ["Mastorakis", "Spyridon", ""], ["Adil", "Muhammad", ""], ["Akbar", "Aamir", ""], ["Stergiou", "Nicholas", ""]]}, {"id": "2104.14944", "submitter": "Daniel Martins", "authors": "Yevgeni Koucheryavy, Anastasia Yastrebova, Daniel P. Martins,\n  Sasitharan Balasubramaniam", "title": "A Review on Bio-Cyber Interfaces for Intrabody Molecular Communications\n  Systems", "comments": "16 pages, 2 tables and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advancements in bio-engineering and wireless communications\nsystems have motivated researchers to propose novel applications for\ntelemedicine, therapeutics and human health monitoring. For instance, through\nwireless medical telemetry a healthcare worker can remotely measure biological\nsignals and control certain processes in the organism required for the\nmaintenance of the patient's health state. This technology can be further\nextended to use Bio-Nano devices to promote a real-time monitoring of the human\nhealth and storage of the gathered data in the cloud. This brings new\nchallenges and opportunities for the development of biosensing network, which\nwill depend on the extension of the current intrabody devices functionalities.\nIn this paper we will cover the recent progress made on implantable micro-scale\ndevices and introduce the perspective of improve them to foster the development\nof new theranostics based on data collected at the nanoscale level.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 12:16:49 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Koucheryavy", "Yevgeni", ""], ["Yastrebova", "Anastasia", ""], ["Martins", "Daniel P.", ""], ["Balasubramaniam", "Sasitharan", ""]]}, {"id": "2104.14985", "submitter": "Ruiqi Liu", "authors": "Ruiqi Liu, Qingqing Wu, Marco Di Renzo, Yifei Yuan", "title": "A Path to Smart Radio Environments: An Industrial Viewpoint on\n  Reconfigurable Intelligent Surfaces", "comments": "Submitted to IEEE Wireless Communications on April 27, 2021. Revised\n  on July 29, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With both the standardization and commercialization completed in an\nunforeseen pace for the 5th generation (5G) wireless network, researchers,\nengineers and executives from the academia and the industry have turned their\nsights on candidate technologies to support the next generation wireless\nnetworks. Reconfigurable intelligent surfaces (RIS), sometimes referred to as\nintelligent reflecting surfaces (IRS), have been identified to be potential\ncomponents of the future wireless networks because they can reconfigure the\npropagation environment for wireless signals with low-cost passive devices. In\ndoing so, the coverage of a cell can be expected to increase significantly as\nwell as the overall throughput of the network. RIS has not only become an\nattractive research area but also triggered a couple of projects to develop\nappropriate solutions to enable the set-up of hardware demonstrations and\nprototypes. In parallel, technical discussions and activities towards\nstandardization already took off in some regions. Promoting RIS to be\nintegrated into future commercial networks and become a commercial success\nrequires significant standardization work taken place both at regional level\nstandards developing organizations (SDO) and international SDOs such as the 3rd\nGeneration Partnership Project (3GPP). While many research papers study how RIS\ncan be used and optimized, few effort is devoted to analyzing the challenges to\ncommercialize RIS and how RIS can be standardized. This paper intends to shed\nsome light on RIS from an industrial viewpoint and provide a clear roadmap to\nmake RIS industrially feasible.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 13:21:40 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 15:09:08 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Liu", "Ruiqi", ""], ["Wu", "Qingqing", ""], ["Di Renzo", "Marco", ""], ["Yuan", "Yifei", ""]]}, {"id": "2104.15094", "submitter": "Nathaniel Hudson", "authors": "Nathaniel Hudson, Hana Khamfroush, Daniel E. Lucani", "title": "QoS-Aware Placement of Deep Learning Services on the Edge with Multiple\n  Service Implementations", "comments": "Accepted for publication through the 30th International Conference on\n  Computer Communications and Networks (ICCCN 2021). This manuscript contains a\n  complete proof of a theorem referenced in the ICCCN manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile edge computing pushes computationally-intensive services closer to the\nuser to provide reduced delay due to physical proximity. This has led many to\nconsider deploying deep learning models on the edge -- commonly known as edge\nintelligence (EI). EI services can have many model implementations that provide\ndifferent QoS. For instance, one model can perform inference faster than\nanother (thus reducing latency) while achieving less accuracy when evaluated.\nIn this paper, we study joint service placement and model scheduling of EI\nservices with the goal to maximize Quality-of-Servcice (QoS) for end users\nwhere EI services have multiple implementations to serve user requests, each\nwith varying costs and QoS benefits. We cast the problem as an integer linear\nprogram and prove that it is NP-hard. We then prove the objective is equivalent\nto maximizing a monotone increasing, submodular set function and thus can be\nsolved greedily while maintaining a (1-1/e)-approximation guarantee. We then\npropose two greedy algorithms: one that theoretically guarantees this\napproximation and another that empirically matches its performance with greater\nefficiency. Finally, we thoroughly evaluate the proposed algorithm for making\nplacement and scheduling decisions in both synthetic and real-world scenarios\nagainst the optimal solution and some baselines. In the real-world case, we\nconsider real machine learning models using the ImageNet 2012 data-set for\nrequests. Our numerical experiments empirically show that our more efficient\ngreedy algorithm is able to approximate the optimal solution with a 0.904\napproximation on average, while the next closest baseline achieves a 0.607\napproximation on average.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 16:20:27 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Hudson", "Nathaniel", ""], ["Khamfroush", "Hana", ""], ["Lucani", "Daniel E.", ""]]}]