[{"id": "2106.00005", "submitter": "Mahdi Chehimi", "authors": "Mahdi Chehimi and Walid Saad", "title": "Quantum Federated Learning with Quantum Data", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum machine learning (QML) has emerged as a promising field that leans on\nthe developments in quantum computing to explore large complex machine learning\nproblems. Recently, some purely quantum machine learning models were proposed\nsuch as the quantum convolutional neural networks (QCNN) to perform\nclassification on quantum data. However, all of the existing QML models rely on\ncentralized solutions that cannot scale well for large-scale and distributed\nquantum networks. Hence, it is apropos to consider more practical quantum\nfederated learning (QFL) solutions tailored towards emerging quantum network\narchitectures. Indeed, developing QFL frameworks for quantum networks is\ncritical given the fragile nature of computing qubits and the difficulty of\ntransferring them. On top of its practical momentousness, QFL allows for\ndistributed quantum learning by leveraging existing wireless communication\ninfrastructure. This paper proposes the first fully quantum federated learning\nframework that can operate over quantum data and, thus, share the learning of\nquantum circuit parameters in a decentralized manner. First, given the lack of\nexisting quantum federated datasets in the literature, the proposed framework\nbegins by generating the first quantum federated dataset, with a hierarchical\ndata format, for distributed quantum networks. Then, clients sharing QCNN\nmodels are fed with the quantum data to perform a classification task.\nSubsequently, the server aggregates the learnable quantum circuit parameters\nfrom clients and performs federated averaging. Extensive experiments are\nconducted to evaluate and validate the effectiveness of the proposed QFL\nsolution. This work is the first to combine Google's TensorFlow Federated and\nTensorFlow Quantum in a practical implementation.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 12:19:27 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Chehimi", "Mahdi", ""], ["Saad", "Walid", ""]]}, {"id": "2106.00011", "submitter": "Fahri Wisnu Murti", "authors": "Fahri Wisnu Murti, Samad Ali, and Matti Latva-aho", "title": "Constrained Deep Reinforcement Based Functional Split Optimization in\n  Virtualized RANs", "comments": "Submitted to IEEE for possible publication. arXiv admin note: text\n  overlap with arXiv:2105.14731", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualized Radio Access Network (vRAN) brings agility to Next-Generation RAN\nthrough functional split. It allows decomposing the base station (BS) functions\ninto virtualized components and hosts it either at the distributed-unit (DU) or\ncentral-unit (CU). However, deciding which functions to deploy at DU or CU to\nminimize the total network cost is challenging. In this paper, a constrained\ndeep reinforcement based functional split optimization (CDRS) is proposed to\noptimize the locations of functions in vRAN. Our formulation results in a\ncombinatorial and NP-hard problem for which finding the exact solution is\ncomputationally expensive. Hence, in our proposed approach, a policy gradient\nmethod with Lagrangian relaxation is applied that uses a penalty signal to lead\nthe policy toward constraint satisfaction. It utilizes a neural network\narchitecture formed by an encoder-decoder sequence-to-sequence model based on\nstacked Long Short-term Memory (LSTM) networks to approximate the policy.\nGreedy decoding and temperature sampling methods are also leveraged for a\nsearch strategy to infer the best solution among candidates from multiple\ntrained models that help to avoid a severe suboptimality. Simulations are\nperformed to evaluate the performance of the proposed solution in both\nsynthetic and real network datasets. Our findings reveal that CDRS successfully\nlearns the optimal decision, solves the problem with the accuracy of 0.05\\%\noptimality gap and becomes the most cost-effective compared to the available\nRAN setups. Moreover, altering the routing cost and traffic load does not\nsignificantly degrade the optimality. The results also show that all of our\nCDRS settings have faster computational time than the optimal baseline solver.\nOur proposed method fills the gap of optimizing the functional split offering a\nnear-optimal solution, faster computational time and minimal hand-engineering.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 07:57:27 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Murti", "Fahri Wisnu", ""], ["Ali", "Samad", ""], ["Latva-aho", "Matti", ""]]}, {"id": "2106.00066", "submitter": "Sudeep Pasricha", "authors": "Ninad Hogade, Sudeep Pasricha, Howard Jay Siegel", "title": "Energy and Network Aware Workload Management for Geographically\n  Distributed Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cloud service providers are distributing data centers geographically to\nminimize energy costs through intelligent workload distribution. With\nincreasing data volumes in emerging cloud workloads, it is critical to factor\nin the network costs for transferring workloads across data centers. For\ngeo-distributed data centers, many researchers have been exploring strategies\nfor energy cost minimization and intelligent inter-data-center workload\ndistribution separately. However, prior work does not comprehensively and\nsimultaneously consider data center energy costs, data transfer costs, and data\ncenter queueing delay. In this paper, we propose a novel game theory-based\nworkload management framework that takes a holistic approach to the cloud\noperating cost minimization problem by making intelligent scheduling decisions\naware of data transfer costs and the data center queueing delay. Our framework\nperforms intelligent workload management that considers heterogeneity in data\ncenter compute capability, cooling power, interference effects from task\nco-location in servers, time-of-use electricity pricing, renewable energy, net\nmetering, peak demand pricing distribution, and network pricing. Our\nsimulations show that the proposed game-theoretic technique can minimize the\ncloud operating cost more effectively than existing approaches.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 19:15:50 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Hogade", "Ninad", ""], ["Pasricha", "Sudeep", ""], ["Siegel", "Howard Jay", ""]]}, {"id": "2106.00073", "submitter": "Tanujay Saha", "authors": "Jacob Brown, Tanujay Saha, Niraj K. Jha", "title": "GRAVITAS: Graphical Reticulated Attack Vectors for Internet-of-Things\n  Aggregate Security", "comments": "This article has been published in IEEE Transactions on Emerging\n  Topics in Computing, 2021", "journal-ref": null, "doi": "10.1109/TETC.2021.3082525", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet-of-Things (IoT) and cyber-physical systems (CPSs) may consist of\nthousands of devices connected in a complex network topology. The diversity and\ncomplexity of these components present an enormous attack surface, allowing an\nadversary to exploit security vulnerabilities of different devices to execute a\npotent attack. Though significant efforts have been made to improve the\nsecurity of individual devices in these systems, little attention has been paid\nto security at the aggregate level. In this article, we describe a\ncomprehensive risk management system, called GRAVITAS, for IoT/CPS that can\nidentify undiscovered attack vectors and optimize the placement of defenses\nwithin the system for optimal performance and cost. While existing risk\nmanagement systems consider only known attacks, our model employs a machine\nlearning approach to extrapolate undiscovered exploits, enabling us to identify\nattacks overlooked by manual penetration testing (pen-testing). The model is\nflexible enough to analyze practically any IoT/CPS and provide the system\nadministrator with a concrete list of suggested defenses that can reduce system\nvulnerability at optimal cost. GRAVITAS can be employed by governments,\ncompanies, and system administrators to design secure IoT/CPS at scale,\nproviding a quantitative measure of security and efficiency in a world where\nIoT/CPS devices will soon be ubiquitous.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 19:35:23 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Brown", "Jacob", ""], ["Saha", "Tanujay", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2106.00239", "submitter": "Sergio Guti\\'errez", "authors": "Sergio Armando Guti\\'errez, John Willian Branch, Luciano Paschoal\n  Gaspary, Juan Felipe Botero", "title": "Watching Smartly from the Bottom: Intrusion Detection revamped through\n  Programmable Networks and Artificial Intelligence", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advent of Programmable Data Planes represents an outstanding evolution\nand complete revolution of the Software- Defined Networking paradigm. The\ncapacity to define the entire behavior of forwarding devices by controlling the\npacket parsing procedures and executing custom operations enables offloading\nfunctionalities traditionally performed at the control plane. A recent research\nline has explored the possibility of even offloading to the data plane part of\nArtificial Intelligence algorithms, and more specifically, Machine Learning\nones, to increase their accuracy and responsiveness (by having more detailed\nvisibility of the traffic). This introduces a significant opportunity for\nevolution in the critical field of Intrusion Detection. However, offloading\nfunctionalities to the data plane is not a straightforward task. In this paper,\nwe discuss how Programmable Data Planes might complement different stages of an\nIntrusion Detection System based on Machine Learning. We present two use cases\nthat make evident the feasibility of this approach and highlight aspects that\nmust be considered when addressing the challenge of deploying solutions\nleveraging data-plane functionalities.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 05:37:12 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Guti\u00e9rrez", "Sergio Armando", ""], ["Branch", "John Willian", ""], ["Gaspary", "Luciano Paschoal", ""], ["Botero", "Juan Felipe", ""]]}, {"id": "2106.00300", "submitter": "Ming-Chun Lee", "authors": "Ming-Chun Lee and Andreas F. Molisch and Mingyue Ji", "title": "Throughput-Outage Scaling Behaviors for Wireless Single-Hop D2D Caching\n  Networks with Physical Model -- Analysis and Derivations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughput-Outage scaling laws for single-hop cache-aided device-to-device\n(D2D) communications have been extensively investigated under the assumption of\nthe protocol model. However, the corresponding performance under physical\nmodels has not been explored; in particular it remains unclear whether\nlink-level power control and scheduling can improve the asymptotic performance.\nThis paper thus investigates the throughput-outage scaling laws of cache-aided\nsingle-hop D2D networks considering a general physical channel model. By\nconsidering the networks with and without the equal-throughput assumption, we\nanalyze the corresponding outer bounds and provide the achievable performance\nanalysis. Results show that when the equal-throughput assumption is considered,\nusing link-level power control and scheduling cannot improve the scaling laws.\nOn the other hand, when the equal-throughput assumption is not considered, we\nshow that the proposed double time-slot framework with appropriate link-level\npower control and scheduling can significantly improve the throughput-outage\nscaling laws, where the fundamental concept is to first distinguish links\naccording to their communication distances, and then enhance the throughput for\nlinks with small communication distances.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 08:13:39 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Lee", "Ming-Chun", ""], ["Molisch", "Andreas F.", ""], ["Ji", "Mingyue", ""]]}, {"id": "2106.00541", "submitter": "Fabio De Gaspari", "authors": "Michal Piskozub, Fabio De Gaspari, Frederick Barr-Smith, Luigi V.\n  Mancini, Ivan Martinovic", "title": "MalPhase: Fine-Grained Malware Detection Using Network Flow Data", "comments": "Paper accepted for publication at ACM AsiaCCS 2021", "journal-ref": null, "doi": "10.1145/3433210.3453101", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Economic incentives encourage malware authors to constantly develop new,\nincreasingly complex malware to steal sensitive data or blackmail individuals\nand companies into paying large ransoms. In 2017, the worldwide economic impact\nof cyberattacks is estimated to be between 445 and 600 billion USD, or 0.8% of\nglobal GDP. Traditionally, one of the approaches used to defend against malware\nis network traffic analysis, which relies on network data to detect the\npresence of potentially malicious software. However, to keep up with increasing\nnetwork speeds and amount of traffic, network analysis is generally limited to\nwork on aggregated network data, which is traditionally challenging and yields\nmixed results. In this paper we present MalPhase, a system that was designed to\ncope with the limitations of aggregated flows. MalPhase features a multi-phase\npipeline for malware detection, type and family classification. The use of an\nextended set of network flow features and a simultaneous multi-tier\narchitecture facilitates a performance improvement for deep learning models,\nmaking them able to detect malicious flows (>98% F1) and categorize them to a\nrespective malware type (>93% F1) and family (>91% F1). Furthermore, the use of\nrobust features and denoising autoencoders allows MalPhase to perform well on\nsamples with varying amounts of benign traffic mixed in. Finally, MalPhase\ndetects unseen malware samples with performance comparable to that of known\nsamples, even when interlaced with benign flows to reflect realistic network\nenvironments.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:53:38 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Piskozub", "Michal", ""], ["De Gaspari", "Fabio", ""], ["Barr-Smith", "Frederick", ""], ["Mancini", "Luigi V.", ""], ["Martinovic", "Ivan", ""]]}, {"id": "2106.00569", "submitter": "Sandip Das", "authors": "Sandip Das, Marco Ruffini", "title": "Optimal virtual PON slicing to support ultra-low latency mesh traffic\n  pattern in MEC-based Cloud-RAN", "comments": "5 pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As progressive densification of cells, deployment of Cloud-RAN and \\ac{MEC}\nare coming into reality to support the ultra-low latency with high reliability\nin 5G and beyond, it generates mesh traffic pattern across fronthaul network.\nThis led to evolution of PON architectural enhancements with virtualization in\norder to support such mesh traffic pattern. However, allocation of virtual PON\nslices dynamically over such mesh-PON based fronthaul transport is becoming a\nresearch challenge. In this paper, we provide a mixed analytical-iterative\nmodel to compute optimal virtual PON slice allocation, providing mesh access\nconnectivity with ultra-low end-to-end latency in next-generation MEC-based\nCloud-RAN. Our proposed method can compute optimal virtual PON slice allocation\nin timescales compatible with real-time or near real-time operations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 15:32:21 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Das", "Sandip", ""], ["Ruffini", "Marco", ""]]}, {"id": "2106.00654", "submitter": "Babatunji Omoniwa", "authors": "Babatunji Omoniwa, Maxime Gueriau and Ivana Dusparic", "title": "A reinforcement learning approach to improve communication performance\n  and energy utilization in fog-based IoT", "comments": "Submitted and published in IEEE proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown the potential of using available mobile fog devices\n(such as smartphones, drones, domestic and industrial robots) as relays to\nminimize communication outages between sensors and destination devices, where\nlocalized Internet-of-Things services (e.g., manufacturing process control,\nhealth and security monitoring) are delivered. However, these mobile relays\ndeplete energy when they move and transmit to distant destinations. As such,\npower-control mechanisms and intelligent mobility of the relay devices are\ncritical in improving communication performance and energy utilization. In this\npaper, we propose a Q-learning-based decentralized approach where each mobile\nfog relay agent (MFRA) is controlled by an autonomous agent which uses\nreinforcement learning to simultaneously improve communication performance and\nenergy utilization. Each autonomous agent learns based on the feedback from the\ndestination and its own energy levels whether to remain active and forward the\nmessage, or become passive for that transmission phase. We evaluate the\napproach by comparing with the centralized approach, and observe that with\nlesser number of MFRAs, our approach is able to ensure reliable delivery of\ndata and reduce overall energy cost by 56.76\\% -- 88.03\\%.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:38:20 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Omoniwa", "Babatunji", ""], ["Gueriau", "Maxime", ""], ["Dusparic", "Ivana", ""]]}, {"id": "2106.00834", "submitter": "Nelly Elsayed", "authors": "Zaghloul Saad Zaghloul, Nelly Elsayed, Chengcheng Li, Magdy Bayoumi", "title": "Green IoT System Architecture for Applied Autonomous Network\n  Cybersecurity Monitoring", "comments": "Cybersecurity, IoT, NSM, packet capture, sensor, green systems, oil\n  and gas, Network Security Monitoring. Accepted in IEEE WF-IoT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network security morning (NSM) is essential for any cybersecurity system,\nwhere the average cost of a cyberattack is $1.1 million. No matter how much a\nsystem is secure, it will eventually fail without proper and continuous\nmonitoring. No wonder that the cybersecurity market is expected to grow up to\n$170.4 billion in 2022. However, the majority of legacy industries do not\ninvest in NSM implementation until it is too late due to the initial and\noperation cost and static unutilized resources. Thus, this paper proposes a\nnovel dynamic Internet of things (IoT) architecture for an industrial NSM that\nfeatures a low installation and operation cost, low power consumption,\nintelligent organization behavior, and environmentally friendly operation. As a\ncase study, the system is implemented in a midrange oil a gas manufacture\nfacility in the southern states with more than 300 machines and servers over\nthree remote locations and a production plant that features a challenging\natmosphere condition. The proposed system successfully shows a significant\nsaving (>65%) in power consumption, acquires one-tenth the installation cost,\ndevelops an intelligent operation expert system tools as well as saves the\nenvironment from more than 500 mg of CO2 pollution per hour, promoting green\nIoT systems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 22:27:41 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Zaghloul", "Zaghloul Saad", ""], ["Elsayed", "Nelly", ""], ["Li", "Chengcheng", ""], ["Bayoumi", "Magdy", ""]]}, {"id": "2106.00845", "submitter": "Babatunji Omoniwa", "authors": "Babatunji Omoniwa, Boris Galkin, Ivana Dusparic", "title": "Energy-aware placement optimization of UAV base stations via\n  decentralized multi-agent Q-learning", "comments": "Submitted to IEEE Globecom SAC 2021, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles serving as aerial base stations (UAV-BSs) can be\ndeployed to provide wireless connectivity to ground devices in events of\nincreased network demand, points-of-failure in existing infrastructure, or\ndisasters. However, it is challenging to conserve the energy of UAVs during\nprolonged coverage tasks, considering their limited on-board battery capacity.\nReinforcement learning-based (RL) approaches have been previously used to\nimprove energy utilization of multiple UAVs, however, a central cloud\ncontroller is assumed to have complete knowledge of the end-devices' locations,\ni.e., the controller periodically scans and sends updates for UAV\ndecision-making. This assumption is impractical in dynamic network environments\nwith mobile ground devices. To address this problem, we propose a decentralized\nQ-learning approach, where each UAV-BS is equipped with an autonomous agent\nthat maximizes the connectivity to ground devices while improving its energy\nutilization. Experimental results show that the proposed design significantly\noutperforms the centralized approaches in jointly maximizing the number of\nconnected ground devices and the energy utilization of the UAV-BSs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 22:49:42 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Omoniwa", "Babatunji", ""], ["Galkin", "Boris", ""], ["Dusparic", "Ivana", ""]]}, {"id": "2106.00846", "submitter": "Babatunji Omoniwa", "authors": "Babatunji Omoniwa, Riaz Hussain, Muhammad Adil, Atif Shakeel, Ahmed\n  Kamal Tahir, Qadeer Ul Hasan, and Shahzad A. Malik", "title": "An Optimal Relay Scheme for Outage Minimization in Fog-based\n  Internet-of-Things (IoT) Networks", "comments": "Accepted and Published in IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog devices are beginning to play a key role in relaying data and services\nwithin the Internet-of-Things (IoT) ecosystem. These relays may be static or\nmobile, with the latter offering a new degree of freedom for performance\nimprovement via careful relay mobility design. Besides that, power conservation\nhas been a prevalent issue in IoT networks with devices being\npower-constrained, requiring optimal power-control mechanisms. In this paper,\nwe consider a multi-tier fog-based IoT architecture where a mobile/static fog\nnode acts as an amplify and forward relay that transmits received information\nfrom a sensor node to a higher hierarchically-placed static fog device, which\noffers some localized services. The outage probability of the presented\nscenario was efficiently minimized by jointly optimizing the mobility pattern\nand the transmit power of the fog relay. A closed-form analytical expression\nfor the outage probability was derived. Furthermore, due to the intractability\nand non-convexity of the formulated problem, we applied an iterative algorithm\nbased on the steepest descent method to arrive at a desirable objective.\nSimulations reveal that the outage probability was improved by 62.7% in the\noptimized-location fixed-power (OLFP) scheme, 79.3% in the optimized-power\nfixed-location (OPFL) scheme, and 94.2% in the optimized-location\noptimized-power (OLOP) scheme, as against the fixed-location and fixed-power\n(FLFP) scheme (i.e., without optimization). Lastly, we present an optimal relay\nselection strategy that chooses an appropriate relay node from randomly\ndistributed relaying candidates.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 22:57:51 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Omoniwa", "Babatunji", ""], ["Hussain", "Riaz", ""], ["Adil", "Muhammad", ""], ["Shakeel", "Atif", ""], ["Tahir", "Ahmed Kamal", ""], ["Hasan", "Qadeer Ul", ""], ["Malik", "Shahzad A.", ""]]}, {"id": "2106.01184", "submitter": "Matthew Daggitt Dr", "authors": "Matthew L. Daggitt, Timothy G. Griffin", "title": "Formally Verified Convergence of Policy-Rich DBF Routing Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present new general convergence results about the behaviour\nof Distributed Bellman-Ford (DBF) family of routing protocols, which includes\ndistance-vector protocols (e.g. RIP) and path-vector protocols (e.g. BGP).\n  First, we propose a new algebraic model for abstract routing problems which\nhas fewer primitives than previous models and can represent more expressive\npolicy languages. The new model is also the first to allow concurrent reasoning\nabout distance-vector and path-vector protocols.\n  Second, we explicitly demonstrate how DBF routing protocols are instances of\na larger class of asynchronous iterative algorithms, for which there already\nexist powerful results about convergence. These results allow us to build upon\nconditions previously shown by Sobrinho to be sufficient and necessary for the\nconvergence of path-vector protocols and generalise and strengthen them in\nvarious ways: we show that, with a minor modification, they also apply to\ndistance-vector protocols; we prove they guarantee that the final routing\nsolution reached is unique, thereby eliminating the possibility of anomalies\nsuch as BGP wedgies; we relax the model of asynchronous communication, showing\nthat the results still hold if routing messages can be lost, reordered, and\nduplicated.\n  Thirdly, our model and our accompanying theoretical results have been fully\nformalised in the Agda theorem prover. The resulting library is a powerful tool\nfor quickly prototyping and formally verifying new policy languages. As an\nexample, we formally verify the correctness of a policy language with many of\nthe features of BGP including communities, conditional policy, path-inflation\nand route filtering.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 14:27:19 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Daggitt", "Matthew L.", ""], ["Griffin", "Timothy G.", ""]]}, {"id": "2106.01438", "submitter": "Sohini Roy", "authors": "Sohini Roy, Arunabha Sen", "title": "A Leader-Follower Game Theoretic Approach to Arrest Cascading Failure in\n  Smart Grid", "comments": "This paper is accepted for publication in American Journal of Science\n  and Engineering. arXiv admin note: text overlap with arXiv:2101.08896", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Smart Grid System (SGS) is a joint network comprising the power and the\ncommunication network. In this paper, the underlying\nintra-and-interdependencies between entities for a given SGS is captured using\na dependency model called Modified Implicative Interdependency Model (MIIM)\n[1]. Given an integer K, the K-contingency list problem gives the list of\nK-most critical entities, failure of which maximizes the network damage at the\ncurrent time. The problem being NP complete [2] and owing to the higher running\ntime of the given Integer Linear Programming (ILP) based solution [3], a much\nfaster heuristic solution to generate an event driven self-updating\nK-contingency list [4] is also given in this paper. Based on the contingency\nlists obtained from both the solutions, this paper proposes an adaptive entity\nhardening technique based on a leader-follower game theoretic approach that\narrests the cascading failure of entities in the SGS after an initial failure\nof entities. The validation of the work is done by comparing the contingency\nlists using both types of solutions, obtained for different K values using the\nMIIM model on a smart grid of IEEE 14-Bus system with that obtained by\nsimulating the smart grid using a co-simulation system formed by MATPOWER and\nJava Network Simulator (JNS). The K-contingency list obtained for a smart grid\nof IEEE 14-Bus system also indicate that the network damage predicted by both\nthe ILP based solution and heuristic solution using MIIM are more realistic\ncompared to that obtained using another dependency model called Implicative\nInterdependency Model (IIM) [2]. Advantage of using the MIIM based heuristic\nsolution is also shown in this paper when larger SGS of IEEE 118-Bus is\nconsidered. Finally, it is shown how the adaptive hardening helps in improving\nthe network performance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 19:44:27 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 00:29:56 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Roy", "Sohini", ""], ["Sen", "Arunabha", ""]]}, {"id": "2106.01475", "submitter": "Jing Wang", "authors": "Jing Wang and Bernardo A. Huberman", "title": "A Reconfigurable Relay for Polarization Encoded QKD Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NI physics.app-ph", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a method for reconfiguring a relay node for polarization encoded\nquantum key distribution (QKD) networks. The relay can be switched between\ntrusted and untrusted modes to adapt to different network conditions, relay\ndistances, and security requirements. This not only extends the distance over\nwhich a QKD network operates but also enables point-to-multipoint (P2MP)\nnetwork topologies. The proposed architecture centralizes the expensive and\ndelicate single-photon detectors (SPDs) at the relay node with eased\nmaintenance and cooling while simplifying each user node so that it only needs\ncommercially available devices for low-cost qubit preparation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 21:24:47 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Wang", "Jing", ""], ["Huberman", "Bernardo A.", ""]]}, {"id": "2106.01482", "submitter": "Christina Delimitrou", "authors": "Nikita Lazarev and Shaojie Xiang and Neil Adit and Zhiru Zhang and\n  Christina Delimitrou", "title": "Dagger: Accelerating RPCs in Cloud Microservices Through Tightly-Coupled\n  Reconfigurable NICs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ongoing shift of cloud services from monolithic designs to microservices\ncreates high demand for efficient and high performance datacenter networking\nstacks, optimized for fine-grained workloads. Commodity networking systems\nbased on software stacks and peripheral NICs introduce high overheads when it\ncomes to delivering small messages.\n  We present Dagger, a hardware acceleration fabric for cloud RPCs based on\nFPGAs, where the accelerator is closely-coupled with the host processor over a\nconfigurable memory interconnect. The three key design principle of Dagger are:\n(1) offloading the entire RPC stack to an FPGA-based NIC, (2) leveraging memory\ninterconnects instead of PCIe buses as the interface with the host CPU, and (3)\nmaking the acceleration fabric reconfigurable, so it can accommodate the\ndiverse needs of microservices. We show that the combination of these\nprinciples significantly improves the efficiency and performance of cloud RPC\nsystems while preserving their generality. Dagger achieves 1.3-3.8x higher\nper-core RPC throughput compared to both highly-optimized software stacks, and\nsystems using specialized RDMA adapters. It also scales up to 84 Mrps with 8\nthreads on 4 CPU cores, while maintaining state-of-the-art us-scale tail\nlatency. We also demonstrate that large third-party applications, like\nmemcached and MICA KVS, can be easily ported on Dagger with minimal changes to\ntheir codebase, bringing their median and tail KVS access latency down to 2.8 -\n3.5us and 5.4 - 7.8us, respectively. Finally, we show that Dagger is beneficial\nfor multi-tier end-to-end microservices with different threading models by\nevaluating it using an 8-tier application implementing a flight check-in\nservice.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 21:37:50 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Lazarev", "Nikita", ""], ["Xiang", "Shaojie", ""], ["Adit", "Neil", ""], ["Zhang", "Zhiru", ""], ["Delimitrou", "Christina", ""]]}, {"id": "2106.02006", "submitter": "Khaleel Mershad", "authors": "Khaleel Mershad, Hayssam Dahrouj, Hadi Sarieddeen, Basem Shihada,\n  Tareq Al-Naffouri, and Mohamed-Slim Alouini", "title": "Cloud-Enabled High-Altitude Platform Systems: Challenges and\n  Opportunities", "comments": "18 pages, 4 figures, 4 tables, accepted for publication at the\n  Frontiers in Communications and Networks, Special Issue on Resource\n  Allocation in Cloud-Radio Access Networks and Fog-Radio Access Networks for\n  B5G Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Augmenting ground-level communications with flying networks, such as the\nhigh-altitude platform system (HAPS), is among the major innovative initiatives\nof the next generation of wireless systems (6G). Given HAPS quasi-static\npositioning at the stratosphere, HAPS-to-ground and HAPS-to-air connectivity\nframeworks are expected to be prolific in terms of data acquisition and\ncomputing, especially given the mild weather and quasi-constant wind speed\ncharacteristics of the stratospheric layer. This paper explores the\nopportunities stemming from the realization of cloud-enabled HAPS in the\ncontext of telecommunications applications and services. The paper first\nadvocates for the potential physical advantages of deploying HAPS as flying\ndata-centers, also known as super-macro base stations. The paper then describes\nvarious cloud services that can be offered from the HAPS and the merits that\ncan be achieved by this integration, such as enhancing the quality, speed, and\nrange of the offered services. The proposed services span a wide range of\nfields, including satellites, Internet of Things (IoT), ad hoc networks (such\nas sensor; vehicular; and aerial networks), gaming, and social networks. For\neach service, the paper illustrates the methods that would be used by cloud\nproviders to offload the service data to the HAPS and enable the cloud\ncustomers to consume the service. The paper further sheds light on the\nchallenges that need to be addressed for realizing practical cloud-enabled\nHAPS, mainly, those related to high energy, processing power, quality of\nservice (QoS), and security considerations. Finally, the paper discusses some\nopen issues on the topic, namely, HAPS mobility and message routing, HAPS\nsecurity via blockchain and machine learning, artificial intelligence-based\nresource allocation in cloud-enabled HAPS, and integration with vertical\nheterogeneous networks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:22:44 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 15:50:07 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Mershad", "Khaleel", ""], ["Dahrouj", "Hayssam", ""], ["Sarieddeen", "Hadi", ""], ["Shihada", "Basem", ""], ["Al-Naffouri", "Tareq", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2106.02156", "submitter": "Shih-Hao Tseng", "authors": "Shih-Hao Tseng, SooJean Han, and Adam Wierman", "title": "In-Network Freshness Control: Trading Throughput for Freshness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to traditional concerns such as throughput and latency, freshness\nis becoming increasingly important. To stay fresh, applications stream status\nupdates among their components, which can congest the network if the update\nfrequency is too high. Tuning to the right frequency is not trivial, especially\nin the presence of other flows, when network sharing becomes much more\ninvolved. Also, sophisticated tuning logic inevitably complicates the design of\nthe endhost devices.\n  In this paper, we take an alternative approach. Instead of tuning the update\nfrequency at the end-host, we let the endhost send out updates at its own pace\nand control the freshness within the network. This In-network Freshness Control\n(IFC) scheme allows the network operator to improve freshness while providing a\nfine-grained trade-off with throughput. IFC leverages in-network compute\nresources to filter out obsolete information during transmission of status\nupdates, while queueing other drop-averse traffic separately to provide high\nthroughput. We provide an analytic study of IFC and then implement IFC as Linux\nkernel modules. Our experiments show that IFC outperforms existing queueing\ndisciplines by improving both throughput (by up to 40%) and freshness (by up to\n50%). IFC can easily be combined with existing methods, e.g., BBR and DCTCP,\nand is effective even in partial deployments.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 22:23:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Tseng", "Shih-Hao", ""], ["Han", "SooJean", ""], ["Wierman", "Adam", ""]]}, {"id": "2106.02167", "submitter": "Nguyen Phong Hoang", "authors": "Nguyen Phong Hoang, Arian Akhavan Niaki, Jakub Dalek, Jeffrey Knockel,\n  Pellaeon Lin, Bill Marczak, Masashi Crete-Nishihata, Phillipa Gill, Michalis\n  Polychronakis", "title": "How Great is the Great Firewall? Measuring China's DNS Censorship", "comments": "To appear at the 30th USENIX Security Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The DNS filtering apparatus of China's Great Firewall (GFW) has evolved\nconsiderably over the past two decades. However, most prior studies of China's\nDNS filtering were performed over short time periods, leading to unnoticed\nchanges in the GFW's behavior. In this study, we introduce GFWatch, a\nlarge-scale, longitudinal measurement platform capable of testing hundreds of\nmillions of domains daily, enabling continuous monitoring of the GFW's DNS\nfiltering behavior.\n  We present the results of running GFWatch over a nine-month period, during\nwhich we tested an average of 411M domains per day and detected a total of 311K\ndomains censored by GFW's DNS filter. To the best of our knowledge, this is the\nlargest number of domains tested and censored domains discovered in the\nliterature. We further reverse engineer regular expressions used by the GFW and\nfind 41K innocuous domains that match these filters, resulting in overblocking\nof their content. We also observe bogus IPv6 and globally routable IPv4\naddresses injected by the GFW, including addresses owned by US companies, such\nas Facebook, Dropbox, and Twitter.\n  Using data from GFWatch, we studied the impact of GFW blocking on the global\nDNS system. We found 77K censored domains with DNS resource records polluted in\npopular public DNS resolvers, such as Google and Cloudflare. Finally, we\npropose strategies to detect poisoned responses that can (1) sanitize poisoned\nDNS records from the cache of public DNS resolvers, and (2) assist in the\ndevelopment of circumvention tools to bypass the GFW's DNS censorship.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 22:59:27 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Hoang", "Nguyen Phong", ""], ["Niaki", "Arian Akhavan", ""], ["Dalek", "Jakub", ""], ["Knockel", "Jeffrey", ""], ["Lin", "Pellaeon", ""], ["Marczak", "Bill", ""], ["Crete-Nishihata", "Masashi", ""], ["Gill", "Phillipa", ""], ["Polychronakis", "Michalis", ""]]}, {"id": "2106.02370", "submitter": "Deep Shrestha", "authors": "Yuxin Zhao, Deep Shrestha", "title": "Uncertainty in Position Estimation Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UE localization has proven its implications on multitude of use cases ranging\nfrom emergency call localization to new and emerging use cases in industrial\nIoT. To support plethora of use cases Radio Access Technology (RAT)-based\npositioning has been supported by 3GPP since Release 9 of its specifications\nthat featured basic positioning methods based on Cell Identity (CID) and\nEnhanced-CID (E-CID). Since then, multiple positioning techniques and solutions\nare proposed and integrated in to the 3GPP specifications. When it comes to\nevaluating performance of the positioning techniques, achievable accuracy\n(2-Dimensional or 3-Dimensional) has, so far, been the primary metric. With the\nadvent of Release 16 New Radio (NR) positioning, it is possible to configure\nPositioning Reference Signal (PRS) with wide bandwidth that naturally helps\nimproving the positioning accuracy. However, the improvement is evident when\nthe conditions are ideal for positioning. In practice where the conditions are\nnon-ideal and the positioning accuracy is severely impacted, estimating the\nuncertainty in position estimation becomes important and can provide\nsignificant insight on how reliable a position estimation is. In order to\ndetermine the uncertainty in position estimation we resort to Machine Learning\n(ML) techniques that offer ways to determine the uncertainty/reliability of the\npredictions for a trained model. Hence, in this work we propose to combine ML\nmethods such as Gaussian Process (GP) and Random Forest (RF) with RAT-based\npositioning measurements to predict the location of a UE and in the meantime\nalso assess the uncertainty of the estimated position. The results show that\nboth GP and RF not only achieve satisfactory positioning accuracy but also give\na reliable uncertainty assessment of the predicted position of the UE.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 09:35:58 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Zhao", "Yuxin", ""], ["Shrestha", "Deep", ""]]}, {"id": "2106.02420", "submitter": "Emna Baccour", "authors": "Emna Baccour, Fatima Haouari, Aiman Erbad, Amr Mohamed, Kashif Bilal,\n  Mohsen Guizani, Mounir Hamdi", "title": "An Intelligent Resource Reservation for Crowdsourced Live Video\n  Streaming Applications in Geo-Distributed Cloud Environment", "comments": "Published in IEEE systems journal", "journal-ref": null, "doi": "10.1109/JSYST.2021.3077707", "report-no": null, "categories": "cs.NI cs.DC cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Crowdsourced live video streaming (livecast) services such as Facebook Live,\nYouNow, Douyu and Twitch are gaining more momentum recently. Allocating the\nlimited resources in a cost-effective manner while maximizing the Quality of\nService (QoS) through real-time delivery and the provision of the appropriate\nrepresentations for all viewers is a challenging problem. In our paper, we\nintroduce a machine-learning based predictive resource allocation framework for\ngeo-distributed cloud sites, considering the delay and quality constraints to\nguarantee the maximum QoS for viewers and the minimum cost for content\nproviders. First, we present an offline optimization that decides the required\ntranscoding resources in distributed regions near the viewers with a trade-off\nbetween the QoS and the overall cost. Second, we use machine learning to build\nforecasting models that proactively predict the approximate transcoding\nresources to be reserved at each cloud site ahead of time. Finally, we develop\na Greedy Nearest and Cheapest algorithm (GNCA) to perform the resource\nallocation of real-time broadcasted videos on the rented resources. Extensive\nsimulations have shown that GNCA outperforms the state-of-the art resource\nallocation approaches for crowdsourced live streaming by achieving more than\n20% gain in terms of system cost while serving the viewers with relatively\nlower latency.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 11:45:09 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Baccour", "Emna", ""], ["Haouari", "Fatima", ""], ["Erbad", "Aiman", ""], ["Mohamed", "Amr", ""], ["Bilal", "Kashif", ""], ["Guizani", "Mohsen", ""], ["Hamdi", "Mounir", ""]]}, {"id": "2106.02491", "submitter": "Sajjad Baghaee", "authors": "Elif Uysal, Onur Kaya, Sajjad Baghaee, Hasan Burhan Beytur", "title": "Age of Information in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While age of Information (AoI) has gained importance as a metric\ncharacterizing the fresh-ness of information in information-update systems and\ntime-critical applications, most previous studies on AoI have been theoretical.\nIn this chapter, we compile a set of recent works reporting API measurements in\nreal-life networks and experimental testbeds, and investigating practical\nissues such as synchronization, the role of various transport layer protocols,\ncongestion control mechanisms, application of machine learning for adaptation\nto network conditions, and device related bottlenecks such as limited\nprocessing power.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 21:33:44 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Uysal", "Elif", ""], ["Kaya", "Onur", ""], ["Baghaee", "Sajjad", ""], ["Beytur", "Hasan Burhan", ""]]}, {"id": "2106.02533", "submitter": "Weiwei Jiang", "authors": "Weiwei Jiang", "title": "Graph-based Deep Learning for Communication Networks: A Survey", "comments": "Github link: https://github.com/jwwthu/GNN-Communication-Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication networks are important infrastructures in contemporary society.\nThere are still many challenges that are not fully solved and new solutions are\nproposed continuously in this active research area. In recent years, to model\nthe network topology, graph-based deep learning has achieved state-of-the-art\nperformance in a series of problems in communication networks. In this survey,\nwe review the rapidly growing body of research using different graph-based deep\nlearning models, e.g. graph convolutional and graph attention networks, in\nvarious problems from different communication networks, e.g. wireless networks,\nwired networks, and software-defined networks. We also present a well-organized\nlist of the problem and solution for each study and identify future research\ndirections. To the best of our knowledge, this paper is the first survey that\nfocuses on the application of graph-based deep learning methods in\ncommunication networks. To track the follow-up research, a public GitHub\nrepository is created, where the relevant papers will be updated continuously.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 14:59:10 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Jiang", "Weiwei", ""]]}, {"id": "2106.02540", "submitter": "Mohamed Sana", "authors": "Mohamed Sana, Nicola di Pietro, Emilio Calvanese Strinati", "title": "Transferable and Distributed User Association Policies for 5G and Beyond\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of user association, namely finding the optimal\nassignment of user equipment to base stations to achieve a targeted network\nperformance. In this paper, we focus on the knowledge transferability of\nassociation policies. Indeed, traditional non-trivial user association schemes\nare often scenario-specific or deployment-specific and require a policy\nre-design or re-learning when the number or the position of the users change.\nIn contrast, transferability allows to apply a single user association policy,\ndevised for a specific scenario, to other distinct user deployments, without\nneeding a substantial re-learning or re-design phase and considerably reducing\nits computational and management complexity. To achieve transferability, we\nfirst cast user association as a multi-agent reinforcement learning problem.\nThen, based on a neural attention mechanism that we specifically conceived for\nthis context, we propose a novel distributed policy network architecture, which\nis transferable among users with zero-shot generalization capability i.e.,\nwithout requiring additional training.Numerical results show the effectiveness\nof our solution in terms of overall network communication rate, outperforming\ncentralized benchmarks even when the number of users doubles with respect to\nthe initial training point.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 15:08:39 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Sana", "Mohamed", ""], ["di Pietro", "Nicola", ""], ["Strinati", "Emilio Calvanese", ""]]}, {"id": "2106.02777", "submitter": "Zach Van Hyfte", "authors": "Zach Van Hyfte and Avideh Zakhor", "title": "Immediate Proximity Detection Using Wi-Fi-Enabled Smartphones", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphone apps for exposure notification and contact tracing have been shown\nto be effective in controlling the COVID-19 pandemic. However, Bluetooth Low\nEnergy tokens similar to those broadcast by existing apps can still be picked\nup far away from the transmitting device. In this paper, we present a new class\nof methods for detecting whether or not two Wi-Fi-enabled devices are in\nimmediate physical proximity, i.e. 2 or fewer meters apart, as established by\nthe U.S. Centers for Disease Control and Prevention (CDC). Our goal is to\nenhance the accuracy of smartphone-based exposure notification and contact\ntracing systems. We present a set of binary machine learning classifiers that\ntake as input pairs of Wi-Fi RSSI fingerprints. We empirically verify that a\nsingle classifier cannot generalize well to a range of different environments\nwith vastly different numbers of detectable Wi-Fi Access Points (APs). However,\nspecialized classifiers, tailored to situations where the number of detectable\nAPs falls within a certain range, are able to detect immediate physical\nproximity significantly more accurately. As such, we design three classifiers\nfor situations with low, medium, and high numbers of detectable APs. These\nclassifiers distinguish between pairs of RSSI fingerprints recorded 2 or fewer\nmeters apart and pairs recorded further apart but still in Bluetooth range. We\ncharacterize their balanced accuracy for this task to be between 66.8% and\n77.8%.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 02:17:01 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Van Hyfte", "Zach", ""], ["Zakhor", "Avideh", ""]]}, {"id": "2106.02807", "submitter": "Sarath Yasodharan", "authors": "Sarath Yasodharan and Rajesh Sundaresan", "title": "The Four Levels of Fixed-Points in Mean-Field Models", "comments": "Accepted for publication at the Twenty Seventh National Conference on\n  Communications (NCC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fixed-point analysis refers to the study of fixed-points that arise in\nthe context of complex systems with many interacting entities. In this\nexpository paper, we describe four levels of fixed-points in mean-field\ninteracting particle systems. These four levels are (i) the macroscopic\nobservables of the system, (ii) the probability distribution over states of a\nparticle at equilibrium, (iii) the time evolution of the probability\ndistribution over states of a particle, and (iv) the probability distribution\nover trajectories. We then discuss relationships among the fixed-points at\nthese four levels. Finally, we describe some issues that arise in the\nfixed-point analysis when the system possesses multiple fixed-points at the\nlevel of distribution over states, and how one goes beyond the fixed-point\nanalysis to tackle such issues.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 05:29:47 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yasodharan", "Sarath", ""], ["Sundaresan", "Rajesh", ""]]}, {"id": "2106.02927", "submitter": "Monireh Ghasri", "authors": "Monireh Allah Gholi Ghasri, Ali Mohammad Afshin Hemmatyar", "title": "A Framework for Dynamic Optimal Next-Hop Selection and RF Interface\n  Setting in IoT with the Same Source Requests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Various applications of machines in Internet of Things require different\nbandwidths. Each machine may choose its RF interface in machine-to-machines or\nmachine-to-base stations communications according to required bandwidth. We\npropose an optimal next-hop selection framework with a dynamic RF interface\nsetting for sources with the same requested bandwidth. This framework enables\nmachines to optimally select network devices with different RF equipment. In\nthis way, the efficient use of RF network resources can be improved. The\nsimulations show that the average data rate of sources improved between 11.1%\nto 117%, and the average unmatched source number improved between 1.9% and\n5.3%.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 16:13:25 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 12:05:59 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ghasri", "Monireh Allah Gholi", ""], ["Hemmatyar", "Ali Mohammad Afshin", ""]]}, {"id": "2106.02996", "submitter": "Wataru Uemura", "authors": "Wataru Uemura and Yasuhiro Fukumori and Takato Hayama", "title": "About Digital Communication Methods for Visible Light Communication", "comments": null, "journal-ref": "International Journal of Computer Networks & Communications, Vol.\n  13, No. 3, pp. 1-13, 2021", "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The visible light communication (VLC) by LED is one of the important\ncommunication methods because LED can work as high speed and VLC sends the\ninformation by high flushing LED. We use the pulse wave modulation for the VLC\nwith LED because LED can be controlled easily by the microcontroller, which has\nthe digital output pins. At the pulse wave modulation, deciding the high and\nlow voltage by the middle voltage when the receiving signal level is amplified\nis equal to deciding it by the threshold voltage without amplification. In this\npaper, we proposed two methods that adjust the threshold value using counting\nthe slot number and measuring the signal level. The number of signal slots is\nconstant per one symbol when we use Pulse Position Modulation (PPM). If the\nnumber of received signal slots per one symbol time is less than the\ntheoretical value, that means the threshold value is higher than the optimal\nvalue. If it is more than the theoretical value, that means the threshold value\nis lower. So, we can adjust the threshold value using the number of received\nsignal slots. At the second proposed method, the average received signal level\nis not equal to the signal level because there is a ratio between the number of\nhigh slots and low slots. So, we can calculate the threshold value from the\naverage received signal level and the slot ratio. We show these performances as\nreal experiments.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 01:00:45 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Uemura", "Wataru", ""], ["Fukumori", "Yasuhiro", ""], ["Hayama", "Takato", ""]]}, {"id": "2106.03002", "submitter": "Luz Angela Aristiz\\'abal Quintero", "authors": "Luz Angela Aristiz\\'abal Q and Nicol\\'as Toro G", "title": "Multilayer Representation and Multiscale Analysis on Data Networks", "comments": "15 pages", "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC). Volumen 13, Number 1 (2021)", "doi": "10.13039/501100002753", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constant increase in the complexity of data networks motivates the search\nfor strategies that make it possible to reduce current monitoring times. This\npaper shows the way in which multilayer network representation and the\napplication of multiscale analysis techniques, as applied to software-defined\nnetworks, allows for the visualization of anomalies from \"coarse views of the\nnetwork topology\". This implies the analysis of fewer data, and consequently\nthe reduction of the time that a process takes to monitor the network. The fact\nthat software-defined networks allow for the obtention of a global view of\nnetwork behavior facilitates detail recovery from affected zones detected in\nmonitoring processes. The method is evaluated by calculating the reduction\nfactor of nodes, checked during anomaly detection, with respect to the total\nnumber of nodes in the network.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 01:39:52 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Q", "Luz Angela Aristiz\u00e1bal", ""], ["G", "Nicol\u00e1s Toro", ""]]}, {"id": "2106.03049", "submitter": "Michael Baddeley Dr", "authors": "Miheer Kulkarni, Michael Baddeley and Israat Haque", "title": "Embedded vs. External Controllers in Software-Defined IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The flexible and programmable architectural model offered by Software-Defined\nNetworking (SDN) has re-imagined modern networks. Supported by powerful\nhardware and high-speed communications between devices and the controller, SDN\nprovides a means to virtualize control functionality and enable rapid network\nreconfiguration in response to dynamic application requirements. However,\nrecent efforts to apply SDN's centralized control model to the Internet of\nThings (IoT) have identified significant challenges due to the constraints\nfaced by embedded low-power devices and networks that reside at the IoT edge.\nIn particular, reliance on external SDN controllers on the backbone network\nintroduces a performance bottleneck (e.g., latency). To this end, we advocate a\ncase for supporting Software-Defined IoT networks through the introduction of\nlightweight SDN controllers directly on the embedded hardware. We firstly\nexplore the performance of two popular SDN implementations for IoT mesh\nnetworks, $\\mu$SDN and SDN-WISE, showing the former demonstrates considerable\ngains over the latter. We consequently employ $\\mu$SDN to conduct a study of\nembedded vs. external SDN controller performance. We highlight how the\nadvantage of an embedded controller is reduced as the network scales, and\nquantify a point at which an external controller should be used for larger\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 07:02:00 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kulkarni", "Miheer", ""], ["Baddeley", "Michael", ""], ["Haque", "Israat", ""]]}, {"id": "2106.03504", "submitter": "Eugenio Moro", "authors": "Paolo Fiore, Eugenio Moro, Ilario Filippini, Antonio Capone, Danilo De\n  Donno", "title": "Boosting 5G mm-Wave IAB Reliability with Reconfigurable Intelligent\n  Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The introduction of the mm-Wave spectrum into 5G NR promises to bring about\nunprecedented data throughput to future mobile wireless networks, but comes\nwith several challenges. Network densification has been proposed as a viable\nsolution to increase RAN resilience and newly introduced IAB is considered as a\nkey enabling technology with compelling cost-reducing opportunities for such\ndense deployments. Reconfigurable Intelligent Surfaces (RISes) have recently\ngained extreme popularity as they can create Smart Radio Environments by EM\nwave manipulation. Recent studies have shown how this technology can behave as\ninexpensive passive relays. However, it is not yet clear what role this\ntechnology can play in a large RAN deployment. With the scope of filling this\ngap, we propose a new mm-Wave IAB planning tool where RISes can be installed\nalongside base stations to maximize the network resilience against blockages\ndue to nomadic obstacles and human self-blocking. Numerical results show how\nadding RISes to IAB deployments can provide high levels of blockage resistance,\nwhile they also significantly reduce the overall network planning cost.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 10:48:03 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Fiore", "Paolo", ""], ["Moro", "Eugenio", ""], ["Filippini", "Ilario", ""], ["Capone", "Antonio", ""], ["De Donno", "Danilo", ""]]}, {"id": "2106.03601", "submitter": "Junfeng Li", "authors": "Junfeng Li, Sameer G. Kulkarni, K. K. Ramakrishnan, Dan Li", "title": "Analyzing Open-Source Serverless Platforms: Characteristics and\n  Performance", "comments": null, "journal-ref": null, "doi": "10.18293/SEKE2021-129", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serverless computing is increasingly popular because of its lower cost and\neasier deployment. Several cloud service providers (CSPs) offer serverless\ncomputing on their public clouds, but it may bring the vendor lock-in risk. To\navoid this limitation, many open-source serverless platforms come out to allow\ndevelopers to freely deploy and manage functions on self-hosted clouds.\nHowever, building effective functions requires much expertise and thorough\ncomprehension of platform frameworks and features that affect performance. It\nis a challenge for a service developer to differentiate and select the\nappropriate serverless platform for different demands and scenarios. Thus, we\nelaborate the frameworks and event processing models of four popular\nopen-source serverless platforms and identify their salient idiosyncrasies. We\nanalyze the root causes of performance differences between different service\nexporting and auto-scaling modes on those platforms. Further, we provide\nseveral insights for future work, such as auto-scaling and metric collection.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 16:16:54 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Li", "Junfeng", ""], ["Kulkarni", "Sameer G.", ""], ["Ramakrishnan", "K. K.", ""], ["Li", "Dan", ""]]}, {"id": "2106.03639", "submitter": "Metodi Yankov", "authors": "Metodi Plamenov Yankov, Pawel Marcin Kaminski, Henrik Enggaard Hansen,\n  Francesco Da Ros", "title": "SNR optimization of multi-span fiber optic communication systems\n  employing EDFAs with non-flat gain and noise figure", "comments": "submitted to JLT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughput optimization of optical communication systems is a key challenge\nfor current optical networks. The use of gain-flattening filters (GFFs)\nsimplifies the problem at the cost of insertion loss, higher power consumption\nand potentially poorer performance. In this work, we propose a component wise\nmodel of a multi-span transmission system for signal-to-noise (SNR)\noptimization. A machine-learning based model is trained for the gain and noise\nfigure spectral profile of a C-band amplifier without a GFF. The model is\ncombined with the Gaussian noise model for nonlinearities in optical fibers\nincluding stimulated Raman scattering and the implementation penalty spectral\nprofile measured in back-to-back in order to predict the SNR in each channel of\na multi-span wavelength division multiplexed system. All basic components in\nthe system model are differentiable and allow for the gradient descent-based\noptimization of a system of arbitrary configuration in terms of number of spans\nand length per span. When the input power profile is optimized for flat and\nmaximized received SNR per channel, the minimum performance in an arbitrary\n3-span experimental system is improved by up to 8 dB w.r.t. a system with flat\ninput power profile. An SNR flatness down to 1.2 dB is simultaneously achieved.\nThe model and optimization methods are used to optimize the performance of an\nexample core network, and 0.2 dB of gain is shown w.r.t. solutions that do not\ntake into account nonlinearities. The method is also shown to be beneficial for\nsystems with ideal gain flattening, achieving up to 0.3 dB of gain w.r.t. a\nflat input power profile.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 14:09:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yankov", "Metodi Plamenov", ""], ["Kaminski", "Pawel Marcin", ""], ["Hansen", "Henrik Enggaard", ""], ["Da Ros", "Francesco", ""]]}, {"id": "2106.03732", "submitter": "Michael Gundall", "authors": "Michael Gundall, Christopher Huber, Sergiy Melnyk, Hans D. Schotten", "title": "Extending Reference Broadcast Infrastructure Synchronization Protocol in\n  IEEE 802.11 as Enabler for the IIoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realizing the industrial Internet of Things, more andmore mobile use cases\nwill emerge in the industrial landscape,requiring both novel concepts and\nsmooth integration into legacydeployments.Since accurate time synchronization\nis particularly challengingfor wireless devices, we propose a concept for\nsimple but accuratesynchronization in IEEE 802.11 wireless local area network\nthatextends the Reference Broadcast Infrastructure Synchronizationprotocol, and\na suitable integration of IEEE 802.1AS that is partof the IEEE time-sensitive\nnetworking standards. In addition,the concept is evaluated with a testbed using\ncommercial off-the-shelf hardware and a realistic discrete automation\ndemonstratorequipped mostly with industrial components. By using the\nafore-mentioned devices for wireless communications, this concept canbe\ndirectly applied in existing industrial solutions, thus achievingthe proposed\nresults. It is shown that the achieved synchronicity issuitable for a wide\nrange of mandatory mobile use cases, which aremost important for a fully\nfunctional industrial Internet of Things.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 15:52:52 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Gundall", "Michael", ""], ["Huber", "Christopher", ""], ["Melnyk", "Sergiy", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2106.03750", "submitter": "Himanshu Thapliyal", "authors": "Amit Degada, Himanshu Thapliyal, Saraju P. Mohanty", "title": "Smart Village: An IoT Based Digital Transformation", "comments": "5 Pages, Conference: IEEE 7th World Forum on Internet of Things\n  (WF-IoT), New Orleans, June 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Almost 46% of the world's population resides in a rural landscape. Smart\nvillages, alongside smart cities, are in need of time for future economic\ngrowth, improved agriculture, better health, and education. The smart village\nis a concept that improves the traditional rural aspects with the help of\ndigital transformation. The smart village is built up using heterogeneous\ndigital technologies pillared around the Internet-of-Thing (IoT). There exist\nmany opportunities in research to design a low-cost, secure, and efficient\ntechnical ecosystem. This article identifies the key application areas, where\nthe IoT can be applied in the smart village. The article also presents a\ncomparative study of communication technology options.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:16:33 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Degada", "Amit", ""], ["Thapliyal", "Himanshu", ""], ["Mohanty", "Saraju P.", ""]]}, {"id": "2106.03822", "submitter": "Yuan Liao", "authors": "Yuan Liao and Vasilis Friderikos", "title": "Energy and Age Pareto Optimal Trajectories in UAV-assisted Wireless Data\n  Collection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies an unmanned aerial vehicle (UAV)-assisted wireless\nnetwork, where a UAV is dispatched to gather information from ground sensor\nnodes (SN) and transfer the collected data to the depot. The information\nfreshness is captured by the age of information (AoI) metric, whilst the energy\nconsumption of the UAV is seen as another performance criterion. Most\nimportantly, the AoI and energy efficiency are inherently competing metrics,\nsince decreasing the AoI requires the UAV returning to the depot more\nfrequently, leading to a higher energy consumption. To this end, we design UAV\npaths that optimize these two competing metrics and reveal the Pareto frontier.\nTo formulate this problem, a multi-objective mixed integer linear programming\n(MILP) is proposed with a flow-based constraint set and we apply Bender's\ndecomposition on the proposed formulation. The overall outcome shows that the\nproposed method allows deriving non-dominated solutions for decision making for\nUAV based wireless data collection. Numerical results are provided to\ncorroborate our study by presenting the Pareto front of the two objectives and\nthe effect on the UAV trajectory.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:42:47 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Liao", "Yuan", ""], ["Friderikos", "Vasilis", ""]]}, {"id": "2106.03850", "submitter": "Onur Barut", "authors": "Onur Barut, Yan Luo, Tong Zhang, Weigang Li, Peilong Li", "title": "Multi-Task Hierarchical Learning Based Network Traffic Analytics", "comments": "6 pages, 2 figures, 1 table. arXiv admin note: substantial text\n  overlap with arXiv:2004.13006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying network traffic is the basis for important network applications.\nPrior research in this area has faced challenges on the availability of\nrepresentative datasets, and many of the results cannot be readily reproduced.\nSuch a problem is exacerbated by emerging data-driven machine learning based\napproaches. To address this issue, we present(N et)2databasewith three open\ndatasets containing nearly 1.3M labeled flows in total, with a comprehensive\nlist of flow features, for there search community1. We focus on broad aspects\nin network traffic analysis, including both malware detection and application\nclassification. As we continue to grow them, we expect the datasets to serve as\na common ground for AI driven, reproducible research on network flow analytics.\nWe release the datasets publicly and also introduce a Multi-Task Hierarchical\nLearning (MTHL)model to perform all tasks in a single model. Our results show\nthat MTHL is capable of accurately performing multiple tasks with hierarchical\nlabeling with a dramatic reduction in training time.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 02:25:59 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Barut", "Onur", ""], ["Luo", "Yan", ""], ["Zhang", "Tong", ""], ["Li", "Weigang", ""], ["Li", "Peilong", ""]]}, {"id": "2106.04030", "submitter": "Zhiyi Zhang", "authors": "Zhiyi Zhang, Siqi Liu, Randy King, Lixia Zhang", "title": "Supporting Multiparty Signing over Named Data Networking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern digitally controlled systems require multiparty authentication and\nauthorization to meet the desired security requirement. This paper describes\nthe design and development of NDN-MPS, an automated solution to support\nmultiparty signature signing and verification for NDN-enabled applications.\nNDN-MPS suggests several changes and extensions to the existing NDN security\nsolutions. First, it introduces a new type of trust schema to support signing\nand verification for multiple signers under complex policies such as threshold\nschemes. Second, it extends the NDN signature format to accommodate\nmultisignature schemes such as BLS signature. Third, it introduces a signature\ncollection protocol to solicit signatures securely from multiple signers. We\nfurther evaluate NDN-MPS by assessing its security properties and measuring its\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 00:49:34 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Zhang", "Zhiyi", ""], ["Liu", "Siqi", ""], ["King", "Randy", ""], ["Zhang", "Lixia", ""]]}, {"id": "2106.04120", "submitter": "Mengbing Liu", "authors": "Mengbing Liu, Guangji Chen, and Ling Qiu", "title": "Throughput Analysis of UAV-assisted CellularNetworks by Mat\\'{e}rn\n  Hardcore Point Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are expected to coexist with conventional\nterrestrial cellular networks and become an important component to support high\nrate transmissions. This paper presents an analytical framework for evaluating\nthe throughput performance of a downlink two-tier heterogeneous network.\nConsidering the minimum distance constraint among UAVs, Mat\\'{e}rn hardcore\npoint process (MHP) is utilized to model the locations of UAVs. The locations\nof terrestrial base stations (BSs) are modeled by Poisson point process (PPP).\nTools of stochastic geometry are invoked to derive tractable expressions for\naverage data rates of users. With the analytical results, we discuss the\noptimal combinations of UAVs' height and power control factor. The result shows\nthat an appropriate power control factor can effectively maximize UAV users'\naverage data rate as well as guaranteeing the BS users' performance under our\nproposed model.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 06:12:02 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Liu", "Mengbing", ""], ["Chen", "Guangji", ""], ["Qiu", "Ling", ""]]}, {"id": "2106.04228", "submitter": "Etienne Boursier", "authors": "Flore Sentenac and Etienne Boursier and Vianney Perchet", "title": "Decentralized Learning in Online Queuing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by packet routing in computer networks, online queuing systems are\ncomposed of queues receiving packets at different rates. Repeatedly, they send\npackets to servers, each of them treating only at most one packet at a time. In\nthe centralized case, the number of accumulated packets remains bounded (i.e.,\nthe system is \\textit{stable}) as long as the ratio between service rates and\narrival rates is larger than $1$. In the decentralized case, individual\nno-regret strategies ensures stability when this ratio is larger than $2$. Yet,\nmyopically minimizing regret disregards the long term effects due to the\ncarryover of packets to further rounds. On the other hand, minimizing long term\ncosts leads to stable Nash equilibria as soon as the ratio exceeds\n$\\frac{e}{e-1}$. Stability with decentralized learning strategies with a ratio\nbelow $2$ was a major remaining question. We first argue that for ratios up to\n$2$, cooperation is required for stability of learning strategies, as selfish\nminimization of policy regret, a \\textit{patient} notion of regret, might\nindeed still be unstable in this case. We therefore consider cooperative queues\nand propose the first learning decentralized algorithm guaranteeing stability\nof the system as long as the ratio of rates is larger than $1$, thus reaching\nperformances comparable to centralized strategies.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 10:10:21 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Sentenac", "Flore", ""], ["Boursier", "Etienne", ""], ["Perchet", "Vianney", ""]]}, {"id": "2106.04230", "submitter": "Adnan Aijaz", "authors": "Adnan Aijaz, Aleksandar Stanoev, Dominic London, Victor Marot", "title": "Demystifying the Performance of Bluetooth Mesh: Experimental Evaluation\n  and Optimization", "comments": "To appear in IEEE Wireless Days 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mesh connectivity is attractive for Internet-of- Things (IoT) applications\nfrom various perspectives. The recent Bluetooth mesh specification provides a\nfull-stack mesh networking solution, potentially for thousands of nodes.\nAlthough Bluetooth mesh has been adopted for various IoT applications, its\nperformance aspects are not extensively investigated in literature. This paper\nprovides an experimental evaluation of Bluetooth mesh (using Nordic nRF52840\ndevices) with an emphasis on those aspects which are not well-investigated in\nliterature. Such aspects include evaluation of unicast and group modes,\nperformance under different traffic patterns, impact of message segmentation,\nand most importantly, latency performance for perfect reliability. The paper\nalso investigates performance enhancement of Bluetooth mesh based on different\ntechniques including parametric adjustments, extended advertisements\n(introduced in Bluetooth 5.0), power control, and customized relaying. Results\nprovide insights into system-level performance of Bluetooth mesh while\nclarifying various important issues identified in recent studies.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 10:17:03 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Aijaz", "Adnan", ""], ["Stanoev", "Aleksandar", ""], ["London", "Dominic", ""], ["Marot", "Victor", ""]]}, {"id": "2106.04248", "submitter": "Xuelin Cao", "authors": "Xuelin Cao, Bo Yang, Chongwen Huang, Chau Yuen, Yan Zhang, Dusit\n  Niyato, and Zhu Han", "title": "Converged Reconfigurable Intelligent Surface and Mobile Edge Computing\n  for Space Information Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space information networks (SIN) are facing an ever-increasing thirst for\nhigh-speed and high-capacity seamless data transmission due to the integration\nof ground, air, and space communications. However, this imposes a new paradigm\non the architecture design of the integrated SIN. Recently, reconfigurable\nintelligent surfaces (RISs) and mobile edge computing (MEC) are the most\npromising techniques, conceived to improve communication and computation\ncapability by reconfiguring the wireless propagation environment and\noffloading. Hence, converging RISs and MEC in SIN is becoming an effort to reap\nthe double benefits of computation and communication. In this article, we\npropose an RIS-assisted collaborative MEC architecture for SIN and discuss its\nimplementation. Then we present its potential benefits, major challenges, and\nfeasible applications. Subsequently, we study different cases to evaluate the\nsystem data rate and latency. Finally, we conclude with a list of open issues\nin this research area.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 10:52:51 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Cao", "Xuelin", ""], ["Yang", "Bo", ""], ["Huang", "Chongwen", ""], ["Yuen", "Chau", ""], ["Zhang", "Yan", ""], ["Niyato", "Dusit", ""], ["Han", "Zhu", ""]]}, {"id": "2106.04277", "submitter": "Christoph D\\\"opmann", "authors": "Christoph D\\\"opmann, Matthias Marx, Hannes Federrath, Florian\n  Tschorsch", "title": "Operating Tor Relays at Universities: Experiences and Considerations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In today's digital society, the Tor network has become an indispensable tool\nfor individuals to protect their privacy on the Internet. Operated by\nvolunteers, relay servers constitute the core component of Tor and are used to\ngeographically escape surveillance. It is therefore essential to have a large,\nyet diverse set of relays. In this work, we analyze the contribution of\neducational institutions to the Tor network and report on our experience of\noperating exit relays at a university. Taking Germany as an example (but\narguing that the global situation is similar), we carry out a quantitative\nstudy and find that universities contribute negligible amounts of relays and\nbandwidth. Since many universities all over the world have excellent conditions\nthat render them perfect places to host Tor (exit) relays, we encourage other\ninterested people and institutions to join. To this end, we discuss and resolve\ncommon concerns and provide lessons learned.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 12:14:27 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 10:22:08 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["D\u00f6pmann", "Christoph", ""], ["Marx", "Matthias", ""], ["Federrath", "Hannes", ""], ["Tschorsch", "Florian", ""]]}, {"id": "2106.04314", "submitter": "Anders E. Kal{\\o}r", "authors": "Petar Popovski and Federico Chiariotti and Kaibin Huang and Anders E.\n  Kal{\\o}r and Marios Kountouris and Nikolaos Pappas and Beatriz Soret", "title": "A Perspective on Time towards Wireless 6G", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of 5G technology, the notion of latency got a prominent role\nin wireless connectivity, serving as a proxy term for addressing the\nrequirements for real-time communication. As wireless systems evolve towards\n6G, the ambition to immerse the digital into the physical reality will\nincrease. Besides making the real-time requirements more stringent, this\nimmersion will bring the notions of time, simultaneity, presence, and causality\nto a new level of complexity. A growing body of research points out that\nlatency is insufficient to parameterize all real-time requirements. Notably,\none such requirement that received a significant attention is information\nfreshness, defined through the Age of Information (AoI) and its derivatives.\nThe objective of this article is to investigate the general notion of timing in\nwireless communication systems and networks and its relation to effective\ninformation generation, processing, transmission, and reconstruction at the\nsenders and receivers. We establish a general statistical framework of timing\nrequirements in wireless communication systems, which subsumes both latency and\nAoI. The framework is made by associating a timing component with the two basic\nstatistical operations, decision and estimation. We first use the framework to\npresent a representative sample of the existing works that deal with timing in\nwireless communication. Next, it is shown how the framework can be used with\ndifferent communication models of increasing complexity, starting from the\nbasic Shannon one-way communication model and arriving to communication models\nfor consensus, distributed learning, and inference. Overall, this paper fills\nan important gap in the literature by providing a systematic treatment of\nvarious timing measures in wireless communication and sets the basis for design\nand optimization for the next-generation real-time systems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 13:23:49 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Popovski", "Petar", ""], ["Chiariotti", "Federico", ""], ["Huang", "Kaibin", ""], ["Kal\u00f8r", "Anders E.", ""], ["Kountouris", "Marios", ""], ["Pappas", "Nikolaos", ""], ["Soret", "Beatriz", ""]]}, {"id": "2106.04449", "submitter": "Michael Gundall", "authors": "Michael Gundall, Christopher Huber, Hans D. Schotten", "title": "Computation Offloading at Field Level: Motivation and Break-Even Point\n  Calculation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart manufacturing has the objective of creating highly flexible and\nresource optimized industrial plants. Furthermore, the improvement of product\nquality is another important target. These requirements implicate more complex\ncontrol algo-rithms. Processing these algorithms may exceed the capabilities of\nresource constrained devices, such as programmable logic controllers (PLCs). In\nthis case, the necessity for computation offloading is given. Due to the fact\nthat industrial plants are currently designed for a life-cycle-time of more\nthan ten years, in a realistic smart manufacturing scenario, these devices have\nto be considered. Therefore, we investigate the impact of complex algorithms on\nconventional PLCs by simulating them with a load generator. In addition, we\npropose a realistic factory scenario including benchmarks for both wireline and\nwireless communication systems. Thus, their round-trip time (RTT) is measured\nwith and without additional load on the network. With the help of these\ninvestigations, break-even points for the application of computation offloading\nof two typical PLCs of Siemens S7 series can be calculated.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 15:30:54 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Gundall", "Michael", ""], ["Huber", "Christopher", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2106.04549", "submitter": "Daniel Bogdoll", "authors": "Daniel Bogdoll, Patrick Matalla, Christoph F\\\"ullner, Christian Raack,\n  Shi Li, Tobias K\\\"afer, Stefan Orf, Marc Ren\\'e Zofka, Finn Sartoris,\n  Christoph Schweikert, Thomas Pfeiffer, Andr\\'e Richter, Sebastian Randel,\n  Rene Bonk", "title": "KIGLIS: Smart Networks for Smart Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart cities will be characterized by a variety of intelligent and networked\nservices, each with specific requirements for the underlying network\ninfrastructure. While smart city architectures and services have been studied\nextensively, little attention has been paid to the network technology. The\nKIGLIS research project, consisting of a consortium of companies, universities\nand research institutions, focuses on artificial intelligence for optimizing\nfiber-optic networks of a smart city, with a special focus on future mobility\napplications, such as automated driving. In this paper, we present early\nresults on our process of collecting smart city requirements for communication\nnetworks, which will lead towards reference infrastructure and architecture\nsolutions. Finally, we suggest directions in which artificial intelligence will\nimprove smart city networks.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:06:08 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 07:42:15 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Bogdoll", "Daniel", ""], ["Matalla", "Patrick", ""], ["F\u00fcllner", "Christoph", ""], ["Raack", "Christian", ""], ["Li", "Shi", ""], ["K\u00e4fer", "Tobias", ""], ["Orf", "Stefan", ""], ["Zofka", "Marc Ren\u00e9", ""], ["Sartoris", "Finn", ""], ["Schweikert", "Christoph", ""], ["Pfeiffer", "Thomas", ""], ["Richter", "Andr\u00e9", ""], ["Randel", "Sebastian", ""], ["Bonk", "Rene", ""]]}, {"id": "2106.04699", "submitter": "Jaafar Elmirghani", "authors": "Opeyemi O. Ajibola, Taisir E. H. El-Gorashi, and Jaafar M. H.\n  Elmirghani", "title": "Network Topologies for Composable Data Centres", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Suitable composable data center networks (DCNs) are essential to support the\ndisaggregation of compute components in highly efficient next generation data\ncenters (DCs). However, designing such composable DCNs can be challenging. A\ncomposable DCN that adopts a full mesh backplane between disaggregated compute\ncomponents within a rack and employs dedicated interfaces on each\npoint-to-point link is wasteful and expensive. In this paper, we propose and\ndescribe two (i.e., electrical, and electrical-optical) variants of a network\nfor composable DC (NetCoD). NetCoD adopts a targeted design to reduce the\nnumber of transceivers required when a mesh physical backplane is deployed\nbetween disaggregated compute components in the same rack. The targeted design\nleverages optical communication techniques and components to achieve this with\nminimal or no network performance degradation. We formulate a MILP model to\nevaluate the performance of both variants of NetCoD in rack-scale composable\nDCs that implement different forms of disaggregation. The electrical-optical\nvariant of NetCoD achieves similar performance as a reference network while\nutilizing fewer transceivers per compute node. The targeted adoption of optical\ntechnologies by both variants of NetCoD achieves greater (4 - 5 times greater)\nutilization of available network throughput than the reference network which\nimplements a generic design. Under the various forms of disaggregation\nconsidered, both variant of NetCoD achieve near-optimal compute energy\nefficiency in the composable DC while satisfying both compute and network\nconstraints. This is because marginal concession of optimal compute energy\nefficiency is often required to achieve overall optimal energy efficiency in\ncomposable DCs.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 21:25:58 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ajibola", "Opeyemi O.", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2106.04738", "submitter": "Jaafar Elmirghani", "authors": "Opeyemi O. Ajibola, Taisir E. H. El-Gorashi, and Jaafar M. H.\n  Elmirghani", "title": "Optical Networks for Composable Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Composable data centers (DCs) have been proposed to enable greater\nefficiencies as the uptake of on-demand computing services grows. In this\narticle we give an overview of composable DCs by discussing their enabling\ntechnologies, benefits, challenges, and research directions. We then describe a\nnetwork for composable DCs that leverages optical communication technologies\nand components to implement a targeted design. Relative to the implementation\nof a generic design that requires a (high capacity) dedicated transceiver on\neach point-to-point link on a mesh optical fabric in a composable DC rack, the\ntargeted design can significantly reduce capital expenditure (by up to 34\ntimes) because fewer transceivers are used. This is achieved with little or no\ndegradation of expected performance in composable DCs.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 23:47:36 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ajibola", "Opeyemi O.", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2106.04811", "submitter": "Jem Guhit", "authors": "Jem Guhit, Edward Colone, Shawn McKee, Kris Steinhoff, and Katarina\n  Thomas", "title": "Benchmarking NetBASILISK: a Network Security Project for Science", "comments": "12 pages, 4 figures, presented at vCHEP '21 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.DB cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Infrastructures supporting distributed scientific collaborations must address\ncompeting goals in both providing high-performance access to resources while\nsimultaneously securing the infrastructure against security threats. The\nNetBASILISK project is attempting to improve the security of such\ninfrastructures while not adversely impacting their performance. This paper\nwill present our work to create a benchmark and monitoring infrastructure that\nallows us to test for any degradation in transferring data into a NetBASILISK\nprotected site.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 05:08:26 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Guhit", "Jem", ""], ["Colone", "Edward", ""], ["McKee", "Shawn", ""], ["Steinhoff", "Kris", ""], ["Thomas", "Katarina", ""]]}, {"id": "2106.04871", "submitter": "Brian McCarthy", "authors": "Brian McCarthy and Aisling O'Driscoll", "title": "Congestion Control in the Cellular-V2X Sidelink", "comments": "8 Pages, 7 Figures, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a detailed quantitative evaluation of standardised\nDecentralised Congestion Control (DCC) and packet dropping mechanisms for\nCellular V2X (C-V2X). Based on the identified shortcomings, an Access layer DCC\nscheme, RRI adaptive, is then proposed. RRI adaptive accommodates the sidelink\nscheduling mechanism Sensing Based Semi-Persistent Scheduling (SB-SPS),\neliminating incompatibilities between current standards and the scheduling\nmechanism, to avoid unnecessary and reoccurring collisions. Two variants are\nproposed; one is an evolution of the ETSI Reactive DCC mechanism and the other\naligns with the 3GPP approach based on channel occupancy ratio (CR). Both\napproaches are compared with current ETSI and 3GPP standards and exhibit\nimproved performance. An evaluation of existing DCC standards and RRI Adaptive\nto meet the Quality of Service (QoS) requirements of vehicular cooperative\nawareness applications is also conducted.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 07:53:23 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 10:38:23 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["McCarthy", "Brian", ""], ["O'Driscoll", "Aisling", ""]]}, {"id": "2106.04906", "submitter": "Edward Oughton", "authors": "Edward J. Oughton and Erik Boch and Julius Kusuma", "title": "Engineering-Economic Evaluation of Diffractive Non-Line-Of-Sight\n  Backhaul (e3nb): A Techno-economic Model for 3D Wireless Backhaul Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY cs.ET econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing ways to affordably deliver broadband connectivity is one of the\nmajor issues of our time. In challenging deployment locations with irregular\nterrain, fiber optic or traditional Clear-Line-Of-Sight (CLOS) wireless links\ncan be uneconomical to deploy, resulting from the number of required towers\nmaking infrastructure deployment unviable. With the emergence of new research\nfocusing on developing wireless diffractive backhaul technologies to provide\ndiffractive Non-Line-Of-Sight (NLOS) links, this paper evaluates the\nengineering-economic implications of such approaches. To quantify different\ntechnology strategies, a Three-Dimensional (3D) techno-economic assessment\nframework is presented to help prioritize regions for future investment in\nbroadband connectivity, utilizing a combination of remote sensing and viewshed\ngeospatial techniques. Such a method is an essential evaluation step prior to\nbeginning detailed Radio Frequency (RF) Quality of Service engineering but has\nhitherto received less research attention in the literature. This framework is\napplied to assess both Clear-Line-Of-Sight and diffractive Non-Line-Of-Sight\nstrategies for deployment in Peru, as well as the islands of Kalimantan and\nPapua, in Indonesia. The results find that a hybrid strategy combining the use\nof Clear-Line-Of-Sight and diffractive Non-Line-Of-Sight links produces a 15-43\npercent cost-efficiency saving, relative to only using traditional\nClear-Line-Of-Sight wireless backhaul links. The codebase is released\nopensource via the Engineering-Economic Evaluation of Non-Line-of-Sight\nBackhaul (e3nb) repository.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:43:46 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Oughton", "Edward J.", ""], ["Boch", "Erik", ""], ["Kusuma", "Julius", ""]]}, {"id": "2106.05086", "submitter": "Di Zhang Dr.", "authors": "Di Zhang, Joel J. P. C. Rodrigues, Yunkai Zhai, Takuro Sato", "title": "Design and Implementation of 5G eHealth Systems, Technologies, Use Cases\n  and Future Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fifth generation (5G) aims to connect massive devices with even higher\nreliability, lower latency and even faster transmission speed, which are vital\nfor implementing the e-health systems. However, the current efforts on 5G\ne-health systems are still not enough to accomplish its full blueprint. In this\narticle, we first discuss the related technologies from physical layer, upper\nlayer and cross layer perspectives on designing the 5G e-health systems. We\nafterwards elaborate two use cases according to our implementations, i.e., 5G\ne-health systems for remote health and 5G e-health systems for Covid-19\npandemic containment. We finally envision the future research trends and\nchallenges of 5G e-health systems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 14:05:07 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 05:48:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhang", "Di", ""], ["Rodrigues", "Joel J. P. C.", ""], ["Zhai", "Yunkai", ""], ["Sato", "Takuro", ""]]}, {"id": "2106.05100", "submitter": "Claudio Gennaro", "authors": "Giuseppe Amato, Stefano Chessa, Mauro Dragone, Claudio Gennaro,\n  Claudio Vairo", "title": "A Communication Layer for Integrated Sensors and Robotic ecology\n  Solutions to Ambient Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a communication framework built to simplify the\nconstruction of robotic ecologies, i.e., networks of heterogeneous\ncomputational nodes interfaced with sensors, actuators, and mobile robots.\nBuilding integrated ambient intelligence (AmI) solutions out of such a wide\nrange of heterogeneous devices is a key requirement for a range of application\ndomains, such as home automation, logistic, security and Ambient Assisted\nLiving (AAL). This goal is challenging since these ecologies need to adapt to\nchanging environments and especially when they include tiny embedded devices\nwith limited computational resources. We discuss a number of requirements\ncharacterizing this type of systems and illustrate how they have been addressed\nin the design of the new communication framework. The most distinguishing\naspect of our frameworks is the transparency with which the same communication\nfeatures are offered across heterogeneous programming languages and operating\nsystems under a consistent API. Finally, we illustrate how the framework has\nbeen used to bind together and to support the operations of all the components\nof adaptive robotic ecologies in two real-world test-beds.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 14:24:18 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Amato", "Giuseppe", ""], ["Chessa", "Stefano", ""], ["Dragone", "Mauro", ""], ["Gennaro", "Claudio", ""], ["Vairo", "Claudio", ""]]}, {"id": "2106.05244", "submitter": "Hanna Bogucka", "authors": "Marcin Parzy, Hanna Bogucka", "title": "Coopetition methodology for resource sharing in distributed OFDM-based\n  cognitive radio networks", "comments": "12 pages, 13 figures", "journal-ref": "IEEE Transactions on Communications, May 2014, Volume: 62 , Issue\n  5, pp. 1518 - 1529", "doi": "10.1109/TCOMM.2014.031214.130451", "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a distributed resource allocation mechanism in\ncognitive radio networks, based on a new coopeti-tion methodology, which\ncombines advantages of nodes competition and cooperation. We postulate that\nthis new method allows for fully distributed resource management between\ncognitive radio devices. The presented framework is generic, however, we\nconsider it for the application in OFDMA networks. Coopetition takes the best\nfrom cooperative and competitive problem formulation and provides the\nopportunity to control the balance between fairness and spectral efficiency\n(SE) of resource allocation. Simulation results confirm that coopetition allows\nfor efficient resource utilization, and may be used practically in wireless\ncognitive networks.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 13:01:57 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Parzy", "Marcin", ""], ["Bogucka", "Hanna", ""]]}, {"id": "2106.05407", "submitter": "Rahmadi Trimananda", "authors": "Rahmadi Trimananda, Hieu Le, Hao Cui, Janice Tran Ho, Anastasia Shuba,\n  Athina Markopoulou", "title": "Auditing Network Traffic and Privacy Policies in Oculus VR", "comments": "13 pages (and 4 pages of references), 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Virtual reality (VR) is an emerging technology that enables new applications\nbut also introduces privacy risks. In this paper, we focus on Oculus VR (OVR),\nthe leading platform in the VR space, and we provide the first comprehensive\nanalysis of personal data exposed by OVR apps and the platform itself, from a\ncombined networking and privacy policy perspective. We experimented with the\nQuest 2 headset, and we tested the most popular VR apps available on the\nofficial Oculus and the SideQuest app stores. We developed OVRseen, a\nmethodology and system for collecting, analyzing, and comparing network traffic\nand privacy policies on OVR. On the networking side, we captured and decrypted\nnetwork traffic of VR apps, which was previously not possible on OVR, and we\nextracted data flows (defined as <app, data type, destination>). We found that\nthe OVR ecosystem (compared to the mobile and other app ecosystems) is more\ncentralized, and driven by tracking and analytics, rather than by third-party\nadvertising. We show that the data types exposed by VR apps include personally\nidentifiable information (PII), device information that can be used for\nfingerprinting, and VR-specific data types. By comparing the data flows found\nin the network traffic with statements made in the apps' privacy policies, we\ndiscovered that approximately 70% of OVR data flows were not properly\ndisclosed. Furthermore, we provided additional context for these data flows,\nincluding the purpose, which we extracted from the privacy policies, and\nobserved that 69% were sent for purposes unrelated to the core functionality of\napps.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 21:52:13 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 04:36:50 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Trimananda", "Rahmadi", ""], ["Le", "Hieu", ""], ["Cui", "Hao", ""], ["Ho", "Janice Tran", ""], ["Shuba", "Anastasia", ""], ["Markopoulou", "Athina", ""]]}, {"id": "2106.05420", "submitter": "Rohan Bhatia", "authors": "Rohan Bhatia, Arpit Gupta, Rob Harrison, Daniel Lokshtanov, Walter\n  Willinger", "title": "DynamiQ: Planning for Dynamics in Network Streaming Analytics Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of programmable data-plane targets has motivated a new hybrid\ndesign for network streaming analytics systems that combine these targets' fast\npacket processing speeds with the rich compute resources available at modern\nstream processors. However, these systems require careful query planning; that\nis, specifying the minute details of executing a given set of queries in a way\nthat makes the best use of the limited resources and programmability offered by\ndata-plane targets. We use such an existing system, Sonata, and real-world\npacket traces to understand how executing a fixed query workload is affected by\nthe unknown dynamics of the traffic that defines the target's input workload.\nWe observe that static query planning, as employed by Sonata, cannot handle\neven small changes in the input workload, wasting data-plane resources to the\npoint where query execution is confined mainly to userspace.\n  This paper presents the design and implementation of DynamiQ, a new network\nstreaming analytics platform that employs dynamic query planning to deal with\nthe dynamics of real-world input workloads. Specifically, we develop a suite of\npractical algorithms for (i) computing effective initial query plans (to start\nquery execution) and (ii) enabling efficient updating of portions of such an\ninitial query plan at runtime (to adapt to changes in the input workload).\nUsing real-world packet traces as input workload, we show that compared to\nSonata, DynamiQ reduces the stream processor's workload by two orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 22:27:03 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Bhatia", "Rohan", ""], ["Gupta", "Arpit", ""], ["Harrison", "Rob", ""], ["Lokshtanov", "Daniel", ""], ["Willinger", "Walter", ""]]}, {"id": "2106.05467", "submitter": "Penglai Cui", "authors": "Penglai Cui, Heng Pan, Zhenyu Li, Jiaoren Wu, Shengzhuo Zhang, Xingwu\n  Yang, Hongtao Guan, Gaogang Xie", "title": "NetFC: enabling accurate floating-point arithmetic on programmable\n  switches", "comments": "10 pages body, 11 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-network computation has been widely used to accelerate data-intensive\ndistributed applications. Some computational tasks, traditional performed on\nservers, are offloaded to the network (i.e. programmable switches). However,\nthe computational capacity of programmable switches is limited to simple\ninteger arithmetic operations while many of applications require on-the-fly\nfloating-point operations. To address this issue, prior approaches either adopt\na float-to-integer method or directly offload computational tasks to the local\nCPUs of switches, incurring accuracy loss and delayed processing. To this end,\nwe propose NetFC, a table-lookup method to achieve on-the-fly in-network\nfloating-point arithmetic operations nearly without accuracy loss. NetFC adopts\na divide-and-conquer mechanism that converts the original huge table into\nseveral much small tables together with some integer operations. NetFC adopts a\nscaling-factor mechanism for computational accuracy improvement, and a\nprefix-based lossless table compression method to reduce the memory overhead.\nWe use different types of datasets to evaluate NetFC. The experimental results\nshow that the average accuracy of NetFC can be as high as up to 99.94% at worst\nwith only 448KB memory consumption. Furthermore, we integrate NetFC into Sonata\nfor detecting Slowloris attack, yielding significant decrease of detection\ndelay.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 02:58:04 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Cui", "Penglai", ""], ["Pan", "Heng", ""], ["Li", "Zhenyu", ""], ["Wu", "Jiaoren", ""], ["Zhang", "Shengzhuo", ""], ["Yang", "Xingwu", ""], ["Guan", "Hongtao", ""], ["Xie", "Gaogang", ""]]}, {"id": "2106.05553", "submitter": "Sergio Barrachina-Mu\\~noz Dr", "authors": "Sergio Barrachina-Mu\\~noz, Alessandro Chiumento, Boris Bellalta", "title": "Stateless Reinforcement Learning for Multi-Agent Systems: the Case of\n  Spectrum Allocation in Dynamic Channel Bonding WLANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectrum allocation in the form of primary channel and bandwidth selection is\na key factor for dynamic channel bonding (DCB) wireless local area networks\n(WLANs). To cope with varying environments, where networks change their\nconfigurations on their own, the wireless community is looking towards\nsolutions aided by machine learning (ML), and especially reinforcement learning\n(RL) given its trial-and-error approach. However, strong assumptions are\nnormally made to let complex RL models converge to near-optimal solutions. Our\ngoal with this paper is two-fold: justify in a comprehensible way why RL should\nbe the approach for wireless networks problems like decentralized spectrum\nallocation, and call into question whether the use of complex RL algorithms\nhelps the quest of rapid learning in realistic scenarios. We derive that\nstateless RL in the form of lightweight multi-armed-bandits (MABs) is an\nefficient solution for rapid adaptation avoiding the definition of extensive or\nmeaningless RL states.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 07:27:12 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Barrachina-Mu\u00f1oz", "Sergio", ""], ["Chiumento", "Alessandro", ""], ["Bellalta", "Boris", ""]]}, {"id": "2106.05652", "submitter": "Federico Chiariotti", "authors": "Federico Chiariotti and Beatriz Soret and Petar Popovski", "title": "Latency and Information Freshness in Multipath Communications for\n  Virtual Reality", "comments": "Submitted to IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wireless Virtual Reality (VR) and Augmented Reality (AR) will contribute to\npeople increasingly working and socializing remotely. However, the VR/AR\nexperience is very susceptible to various delays and timing discrepancies,\nwhich can lead to motion sickness and discomfort. This paper models and\nexploits the existence of multiple paths and redundancy to improve the timing\nperformance of wireless VR communications. We consider Multiple Description\nCoding (MDC), a scheme where the video stream is encoded in Q streams (Q = 2 in\nthis paper) known as descriptors and delivered independently over multiple\npaths. We also consider an alternating scheme, that simply switches between the\npaths. We analyze the full distribution of two relevant metrics: the packet\ndelay and the Peak Age of Information (PAoI), which measures the freshness of\nthe information at the receiver. The results show interesting trade-offs\nbetween picture quality, frame rate, and latency: full duplication results in\nfewer lost frames, but a higher latency than schemes with less redundancy. Even\nthe simple alternating scheme can outperform duplication in terms of PAoI, but\nMDC can exploit the independent decodability of the descriptors to deliver a\nbasic version of the frames faster, while still getting the full-quality frames\nwith a slightly higher delay.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 10:47:54 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Chiariotti", "Federico", ""], ["Soret", "Beatriz", ""], ["Popovski", "Petar", ""]]}, {"id": "2106.06203", "submitter": "Israel Leyva-Mayorga", "authors": "Israel Leyva-Mayorga, Maik R\\\"oper, Bho Matthiesen, Armin Dekorsy,\n  Petar Popovski, and Beatriz Soret", "title": "Inter-Plane Inter-Satellite Connectivity in LEO Constellations: Beam\n  Switching vs. Beam Steering", "comments": "Submitted to IEEE GLOBECOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low Earth orbit (LEO) satellite constellations rely on inter-satellite links\n(ISLs) to provide global connectivity. However, one significant challenge is to\nestablish and maintain inter-plane ISLs, which support communication between\ndifferent orbital planes. This is due to the fast movement of the\ninfrastructure and to the limited computation and communication capabilities on\nthe satellites. In this paper, we make use of antenna arrays with either Butler\nmatrix beam switching networks or digital beam steering to establish the\ninter-plane ISLs in a LEO satellite constellation. Furthermore, we present a\ngreedy matching algorithm to establish inter-plane ISLs with the objective of\nmaximizing the sum of rates. This is achieved by sequentially selecting the\npairs, switching or pointing the beams and, finally, setting the data rates.\nOur results show that, by selecting an update period of 30 seconds for the\nmatching, reliable communication can be achieved throughout the constellation,\nwhere the impact of interference in the rates is less than 0.7 % when compared\nto orthogonal links, even for relatively small antenna arrays. Furthermore,\ndoubling the number of antenna elements increases the rates by around one order\nof magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 07:16:56 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Leyva-Mayorga", "Israel", ""], ["R\u00f6per", "Maik", ""], ["Matthiesen", "Bho", ""], ["Dekorsy", "Armin", ""], ["Popovski", "Petar", ""], ["Soret", "Beatriz", ""]]}, {"id": "2106.06291", "submitter": "Anum Talpur", "authors": "Anum Talpur and Mohan Gurusamy", "title": "DRLD-SP: A Deep Reinforcement Learning-based Dynamic Service Placement\n  in Edge-Enabled Internet of Vehicles", "comments": "Submitted to IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of 5G and edge computing has enabled the emergence of Internet of\nVehicles. It supports different types of services with different resource and\nservice requirements. However, limited resources at the edge, high mobility of\nvehicles, increasing demand, and dynamicity in service request-types have made\nservice placement a challenging task. A typical static placement solution is\nnot effective as it does not consider the traffic mobility and service\ndynamics. Handling dynamics in IoV for service placement is an important and\nchallenging problem which is the primary focus of our work in this paper. We\npropose a Deep Reinforcement Learning-based Dynamic Service Placement (DRLD-SP)\nframework with the objective of minimizing the maximum edge resource usage and\nservice delay while considering the vehicle's mobility, varying demand, and\ndynamics in the requests for different types of services. We use SUMO and\nMATLAB to carry out simulation experiments. The experimental results show that\nthe proposed DRLD-SP approach is effective and outperforms other static and\ndynamic placement approaches.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 10:17:27 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Talpur", "Anum", ""], ["Gurusamy", "Mohan", ""]]}, {"id": "2106.06293", "submitter": "Dionysios Diamantopoulos", "authors": "Dionysios Diamantopoulos, Raphael Polig, Burkhard Ringlein, Mitra\n  Purandare, Beat Weiss, Christoph Hagleitner, Mark Lantz, Francois Abel", "title": "Acceleration-as-a-{\\mu}Service: A Cloud-native Monte-Carlo Option\n  Pricing Engine on CPUs, GPUs and Disaggregated FPGAs", "comments": "3 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The evolution of cloud applications into loosely-coupled microservices opens\nnew opportunities for hardware accelerators to improve workload performance.\nExisting accelerator techniques for cloud sacrifice the consolidation benefits\nof microservices. This paper presents CloudiFi, a framework to deploy and\ncompare accelerators as a cloud service. We evaluate our framework in the\ncontext of a financial workload and present early results indicating up to 485x\ngains in microservice response time.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 10:27:11 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Diamantopoulos", "Dionysios", ""], ["Polig", "Raphael", ""], ["Ringlein", "Burkhard", ""], ["Purandare", "Mitra", ""], ["Weiss", "Beat", ""], ["Hagleitner", "Christoph", ""], ["Lantz", "Mark", ""], ["Abel", "Francois", ""]]}, {"id": "2106.06335", "submitter": "Martino Trevisan Dr", "authors": "Martino Trevisan, Ali Safari Khatouni, Danilo Giordano", "title": "ERRANT: Realistic Emulation of Radio Access Networks", "comments": null, "journal-ref": "Computer Networks 176 (2020): 107289", "doi": "10.1016/j.comnet.2020.107289", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile networks have become ubiquitous, but running experiments on them is\nexpensive and hard, given their complexity and diversity. Emulation can be the\nsolution, and, with ERRANT, we offer a realistic emulator of mobile networks\nbased on a large measurement campaign on European Mobile Network Operators. It\nimproves the current situation, where tools and emulators only implement\npre-defined profiles, with built-in parameters, which are not supported with\nreal measurements.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 12:16:29 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Trevisan", "Martino", ""], ["Khatouni", "Ali Safari", ""], ["Giordano", "Danilo", ""]]}, {"id": "2106.06595", "submitter": "Edval J. P. Santos PhD", "authors": "Edval J. P. Santos", "title": "Bucket-brigade inspired power line network protocol for sensed quantity\n  profile acquisition with smart sensors deployed as a queue in harsh\n  environment", "comments": "19 pages, 13 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Pressure and temperature profile are key data for safe production in oil and\ngas wells. In this paper, a bucket-brigade inspired sensor network protocol is\nproposed which can be used to extract sensed data profile from the nanoscale up\nto kilometer long structures. The PHY/MAC layers are discussed. This protocol\nis best suited for low data rate exchanges in small fixed-size packets, named\nbuckets, transmitted as time-domain bursts among high-precision smart sensors\ndeployed as a queue. There is only one coordinator, which is not directly\naccessible by most of the sensor nodes. The coordinator is responsible for\ncollecting the measurement profile and send it to a supervisory node. There is\nno need for complex routing mechanism, as the network topology is determined\nduring deployment. There are many applications which require sensors to be\ndeployed as a long queue and sensed data could be transmitted at low data\nrates. Examples of such monitoring applications are: neural connected\nartificial skin, oil/gas/water pipeline integrity, power transmission line\ntower integrity, (rail)road/highway lighting and integrity, individualized\nmonitoring in vineyard or re-foresting or plantation, underwater\ntelecommunications cable integrity, oil/gas riser integrity, oil/gas well\ntemperature and pressure profile, among others. For robustness and reduced\nelectromagnetic interference, wired network is preferred. Besides in some harsh\nenvironment wireless is not feasible. To reduce wiring, communications can be\ncarried out in the same cable used to supply electrical power.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 20:01:21 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Santos", "Edval J. P.", ""]]}, {"id": "2106.06646", "submitter": "\\c{C}a\\u{g}kan Yapar", "authors": "Mozhgan Bayat, \\c{C}a\\u{g}kan Yapar, and Giuseppe Caire", "title": "Spatially Scalable Lossy Coded Caching", "comments": "This paper was presented in the IEEE International Symposium on\n  Wireless Communication Systems (ISWCS 2018) in Lisbon, Portugal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the coded caching scheme proposed by Maddah-Ali and Niesen to a\nmultipoint multicasting video paradigm. Partially caching the video files on\nthe wireless devices provides an opportunity to decrease data traffic load in\npeak hours via sending multicast coded messages to users. In this paper, we\npropose a two-hop wireless network for video multicasting, where the common\ncoded multicast message is transmitted through different single antenna Edge\nNodes (ENs) to multiple antenna users. Each user can decide to decode any EN by\nusing a zero forcing receiver. Motivated by Scalable Video Coding (SVC), we\nconsider successive refinement source coding in order to provide a ``softer''\ntradeoff between the number of decoded ENs and the source distortion at each\nuser receiver. The resulting coding scheme can be seen as the concatenation of\nMaddah-Ali and Niesen coded caching for each source-coded layer, and multiple\ndescription coding. Using stochastic geometry, we investigate the tradeoff\nbetween delivery time and per-user average source distortion. The proposed\nsystem is spatially scalable in the sense that, for given users' and ENs'\nspatial density, the achieved distortion-delivery time performance is\nindependent of the coverage area (for in the limit of large area).\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 00:09:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Bayat", "Mozhgan", ""], ["Yapar", "\u00c7a\u011fkan", ""], ["Caire", "Giuseppe", ""]]}, {"id": "2106.06692", "submitter": "Seyed Hamed Rastegar", "authors": "Seyed Hamed Rastegar, Aliazam Abbasfar, Vahid Shah-Mansouri", "title": "Delay Analysis of Base Station Flow Table in SDN-enabled Radio Access\n  Networks", "comments": "3 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future generation wireless networks are designed with extremely low delay\nrequirements which makes even small contributed delays important. On the other\nhand, software defined networking (SDN) has been introduced as a key enabler of\nfuture wireless and cellular networks in order to make them more flexible. In\nSDN, a central controller manages all network equipments by setting the\nmatch-action pairs in flow tables of the devices. However, these flow tables\nhave limited capacity and thus are not capable of storing the rules of all the\nusers. In this paper, we consider an SDN-enabled base station (SD-BS) in a cell\nequipped with a limited capacity flow table. We analyze the expected delay\nincurred in processing of the incoming packets to the SD-BS and present a\nmathematical expression for it in terms of density of the users and cell area.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 05:49:08 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Rastegar", "Seyed Hamed", ""], ["Abbasfar", "Aliazam", ""], ["Shah-Mansouri", "Vahid", ""]]}, {"id": "2106.06721", "submitter": "Hoang-Loc La", "authors": "Hoang-Loc La, Anh-Tu Ngoc Tran, Quang-Trai Le, Masato Yoshimi, Takuma\n  Nakajima, and Nam Thoai", "title": "A use case of Content Delivery Network raw logfile analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The growth of video streaming has stretched the Internet to its limitation.\nIn other words, the Internet was originally devised to connect a limited number\nof computers so that they can share network resources, so the Internet cannot\nhandle a large amount of traffic at a time, which leads to network congestion.\nTo overcome this, CDNs are built on top of the Internet as an overlay to\nefficiently store and swiftly disseminate contents to users by placing many\nservers and data centers around the globe. The topic of CDNs has been\nextensively studied in the last several decades. However, there is still a\ncertain gap between theories in academia and current technologies in industry.\nIn this paper, we take a close look at the design, implementation, solution,\nand performance of a CDN system by analyzing its raw log files. Specifically,\nits infrastructure and system design are first presented, and then we conduct a\ntrace-based study to understand user access patterns, the sources of requests,\nsystem performance, and how such information can be used to improve the whole\nCDN system.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 09:00:20 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 16:09:33 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["La", "Hoang-Loc", ""], ["Tran", "Anh-Tu Ngoc", ""], ["Le", "Quang-Trai", ""], ["Yoshimi", "Masato", ""], ["Nakajima", "Takuma", ""], ["Thoai", "Nam", ""]]}, {"id": "2106.06836", "submitter": "Jeya Pradha Jeyaraj", "authors": "Jeya Pradha Jeyaraj, and Martin Haenggi", "title": "Cox Models for Vehicular Networks: SIR Performance and Equivalence", "comments": "15 pages, 11 figures", "journal-ref": "in IEEE Transactions on Wireless Communications, vol. 20, no. 1,\n  pp. 171-185, Jan. 2021", "doi": "10.1109/TWC.2020.3023914", "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a general framework for the modeling and analysis of vehicular\nnetworks by defining street systems as random 1D subsets of $\\mathbb{R}^{2}$.\nThe street system, in turn, specifies the random intensity measure of a Cox\nprocess of vehicles, i.e., vehicles form independent 1D Poisson point processes\non each street. Models in this Coxian framework can characterize streets of\ndifferent lengths and orientations forming intersections or T-junctions. The\nlengths of the streets can be infinite or finite and mutually independent or\ndependent. We analyze the reliability of communication for different models,\nwhere reliability is the probability that a vehicle at an intersection, a\nT-junction, or a general location can receive a message successfully from a\ntransmitter at a certain distance. Further, we introduce a notion of\nequivalence between vehicular models, which means that a representative model\ncan be used as a proxy for other models in terms of reliability. Specifically,\nwe prove that the Poisson stick process-based vehicular network is equivalent\nto the Poisson line process-based and Poisson lilypond model-based vehicular\nnetworks, and their rotational variants.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 19:14:18 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Jeyaraj", "Jeya Pradha", ""], ["Haenggi", "Martin", ""]]}, {"id": "2106.06933", "submitter": "Amin Shahraki", "authors": "Amin Shahraki, Mahmoud Abbasi, Amir Taherkordi and Anca Delia Jurcut", "title": "Active Learning for Network Traffic Classification: A Technical Survey", "comments": "This work has been submitted to the IEEE Transactions on Cognitive\n  Communications and Networking journal for possible publication. Copyright may\n  be transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network Traffic Classification (NTC) has become an important component in a\nwide variety of network management operations, e.g., Quality of Service (QoS)\nprovisioning and security purposes. Machine Learning (ML) algorithms as a\ncommon approach for NTC methods can achieve reasonable accuracy and handle\nencrypted traffic. However, ML-based NTC techniques suffer from the shortage of\nlabeled traffic data which is the case in many real-world applications. This\nstudy investigates the applicability of an active form of ML, called Active\nLearning (AL), which reduces the need for a high number of labeled examples by\nactively choosing the instances that should be labeled. The study first\nprovides an overview of NTC and its fundamental challenges along with surveying\nthe literature in the field of using ML techniques in NTC. Then, it introduces\nthe concepts of AL, discusses it in the context of NTC, and review the\nliterature in this field. Further, challenges and open issues in the use of AL\nfor NTC are discussed. Additionally, as a technical survey, some experiments\nare conducted to show the broad applicability of AL in NTC. The simulation\nresults show that AL can achieve high accuracy with a small amount of data.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 06:37:50 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Shahraki", "Amin", ""], ["Abbasi", "Mahmoud", ""], ["Taherkordi", "Amir", ""], ["Jurcut", "Anca Delia", ""]]}, {"id": "2106.06945", "submitter": "Chao Xu", "authors": "Chao Xu, Yiping Xie, Xijun Wang, Howard H. Yang, Dusit Niyato, and\n  Tony Q. S. Quek", "title": "Optimal Status Update for Caching Enabled IoT Networks: A Dueling Deep\n  R-Network Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Internet of Things (IoT) networks, caching is a promising technique to\nalleviate energy consumption of sensors by responding to users' data requests\nwith the data packets cached in the edge caching node (ECN). However, without\nan efficient status update strategy, the information obtained by users may be\nstale, which in return would inevitably deteriorate the accuracy and\nreliability of derived decisions for real-time applications. In this paper, we\nfocus on striking the balance between the information freshness, in terms of\nage of information (AoI), experienced by users and energy consumed by sensors,\nby appropriately activating sensors to update their current status.\nParticularly, we first depict the evolutions of the AoI with each sensor from\ndifferent users' perspective with time steps of non-uniform duration, which are\ndetermined by both the users' data requests and the ECN's status update\ndecision. Then, we formulate a non-uniform time step based dynamic status\nupdate optimization problem to minimize the long-term average cost, jointly\nconsidering the average AoI and energy consumption. To this end, a Markov\nDecision Process is formulated and further, a dueling deep R-network based\ndynamic status update algorithm is devised by combining dueling deep Q-network\nand tabular R-learning, with which challenges from the curse of dimensionality\nand unknown of the environmental dynamics can be addressed. Finally, extensive\nsimulations are conducted to validate the effectiveness of our proposed\nalgorithm by comparing it with five baseline deep reinforcement learning\nalgorithms and policies.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 08:39:36 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Xu", "Chao", ""], ["Xie", "Yiping", ""], ["Wang", "Xijun", ""], ["Yang", "Howard H.", ""], ["Niyato", "Dusit", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2106.06949", "submitter": "Nadia Adem", "authors": "Nadia Adem, Ahmed Benfaid, Ramy Harib, and Anas Alarabi", "title": "How Crucial Is It for 6G Networks to Be Autonomous?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sixth generation (6G), unlike any of the previous generations, is\nenvisioned by 2030 to connect everything. Moreover, in addition to the new use\ncases, 6G is expected to support, it will need to provide a superior\nperformance over 5G. The global connectivity, large network dimensions, users\nheterogeneity, extremely low-power consumption, high throughput, ultrahigh\nreliability, efficient network operation and maintenance, and low-latency\nrequirements to be met by future networks inevitably necessitate the autonomy\nof 6G. Intelligence, facilitated mainly by the advancement of artificial\nintelligence (AI) techniques, is a key to achieve autonomy. In this paper, we\nprovide a bird's-eye view of 6G, its vision, progress, and objectives.\nFurthermore, we present some technologies that would be mainly enabling\nintelligent globally connected world. In addition to discussing the role of AI\nfor future wireless communications, we, unlike any other review papers, provide\nour original results which give early evidence for the viability of achieving\n6G networks autonomy through leveraging AI advances. Furthermore, we, very\nimportantly, identify 6G implementation challenges and key innovative\ntechniques that promise to solve them. This article serves as a starting point\nfor learners to acquire more knowledge about 6G and also for researchers to\npromote more development to the field.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 09:30:03 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 13:02:04 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 10:05:38 GMT"}, {"version": "v4", "created": "Fri, 9 Jul 2021 12:18:02 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Adem", "Nadia", ""], ["Benfaid", "Ahmed", ""], ["Harib", "Ramy", ""], ["Alarabi", "Anas", ""]]}, {"id": "2106.07051", "submitter": "Thulani Phakathi", "authors": "Thulani Phakathi, Bukohwo Michael Esiefarienrhe and Francis Lugayizi", "title": "Comparative analysis of quality of service scheduling classes in mobile\n  ad-hoc networks", "comments": null, "journal-ref": "NCWMC - 2021 pp. 211-220, 2021. CS & IT - CSCP 2021", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quality of Service (QoS) is now regarded as a requirement for all networks in\nmanaging resources like bandwidth and avoidance of network impairments like\npacket loss, jitter, and delay. Media transfer or streaming would be virtually\nimpossible if QoS parameters were not used even if the streaming protocols were\nperfectly designed. QoS Scheduling classes help in network traffic optimization\nand the priority management of packets. This paper presents an analysis of QoS\nscheduling classes using video traffic in a MANET. The main objective was to\nidentify a scheduling class that provides better QoS for video streaming. A\nsimulation was conducted using NetSim and results were analyzed according to\nthroughput, jitter, and delay. The overall results showed that extended\nreal-time Polling Service (ertPS) outperformed the other classes. ertPS has\nhybrid features of both real-time Polling Service (rtPS) and Unsolicited Grant\nService(UGS) hence the enhanced performance. It is recommended that ertPS\nscheduling class should be used in MANET where QoS consideration is utmost\nparticularly in multimedia streaming applications.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 17:27:19 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Phakathi", "Thulani", ""], ["Esiefarienrhe", "Bukohwo Michael", ""], ["Lugayizi", "Francis", ""]]}, {"id": "2106.07160", "submitter": "Kim Hammar", "authors": "Kim Hammar and Rolf Stadler", "title": "Learning Intrusion Prevention Policies through Optimal Stopping", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We study automated intrusion prevention using reinforcement learning. In a\nnovel approach, we formulate the problem of intrusion prevention as an optimal\nstopping problem. This formulation allows us insight into the structure of the\noptimal policies, which turn out to be threshold based. Since the computation\nof the optimal defender policy using dynamic programming is not feasible for\npractical cases, we approximate the optimal policy through reinforcement\nlearning in a simulation environment. To define the dynamics of the simulation,\nwe emulate the target infrastructure and collect measurements. Our evaluations\nshow that the learned policies are close to optimal and that they indeed can be\nexpressed using thresholds.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 04:45:37 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hammar", "Kim", ""], ["Stadler", "Rolf", ""]]}, {"id": "2106.07351", "submitter": "Oliver Gasser", "authors": "Florian Aschenbrenner, Tanya Shreedhar, Oliver Gasser, Nitinder Mohan,\n  J\\\"org Ott", "title": "From Single Lane to Highways: Analyzing the Adoption of Multipath TCP in\n  the Internet", "comments": "Proceedings of the 2021 IFIP Networking Conference (Networking '21).\n  Visit https://mptcp.io for up-to-date MPTCP measurement results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multipath TCP (MPTCP) extends traditional TCP to enable simultaneous use of\nmultiple connection endpoints at the source and destination. MPTCP has been\nunder active development since its standardization in 2013, and more recently\nin February 2020, MPTCP was upstreamed to the Linux kernel.\n  In this paper, we provide the first broad analysis of MPTCPv0 in the\nInternet. We probe the entire IPv4 address space and an IPv6 hitlist to detect\nMPTCP-enabled systems operational on port 80 and 443. Our scans reveal a steady\nincrease in MPTCP-capable IPs, reaching 9k+ on IPv4 and a few dozen on IPv6. We\nalso discover a significant share of seemingly MPTCP-capable hosts, an artifact\nof middleboxes mirroring TCP options. We conduct targeted HTTP(S) measurements\ntowards select hosts and find that middleboxes can aggressively impact the\nperceived quality of applications utilizing MPTCP. Finally, we analyze two\ncomplementary traffic traces from CAIDA and MAWI to shed light on the\nreal-world usage of MPTCP. We find that while MPTCP usage has increased by a\nfactor of 20 over the past few years, its traffic share is still quite low.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 12:34:04 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Aschenbrenner", "Florian", ""], ["Shreedhar", "Tanya", ""], ["Gasser", "Oliver", ""], ["Mohan", "Nitinder", ""], ["Ott", "J\u00f6rg", ""]]}, {"id": "2106.07417", "submitter": "Bin Han", "authors": "Yasameen Shihab Hamad, Bin Han, and Osman Nuri ucan", "title": "Online Estimation of Resource Overload Risk in 5G Multi-Tenancy Network", "comments": "To appear at ESREL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technology of network slicing, as the most characteristic feature of the\nfifth generation (5G) wireless networks, manages the resources and network\nfunctions in heterogeneous and logically isolated slices on the top of a shared\nphysical infrastructure, where every slice can be independently customized to\nfulfill the specific requirements of its devoted service type. It enables a new\nparadigm of multi-tenancy networking, where the network slices can be leased by\nthe mobile network operator (MNO) to tenants in form of public cloud computing\nservice, known as Slice-asa- Service (SlaaS). Similar to classical cloud\ncomputing scenarios, SlaaS benefits from overbooking its resources to numerous\ntenants, taking advantage of the resource elasticity and diversity, at a price\nof risking overloading network resources and violating the service-level\nagreements (SLAs), which stipulate the quality of service (QoS) that shall be\nguaranteed to the network slices. Thus, it becomes a critical challenge to the\nMNOs, accurately estimating the resource overload risk - especially under the\nsophisticated network dynamics - for monitoring and enhancing the reliability\nof SlaaS business.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 13:27:46 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 08:28:34 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Hamad", "Yasameen Shihab", ""], ["Han", "Bin", ""], ["ucan", "Osman Nuri", ""]]}, {"id": "2106.07536", "submitter": "Cao Chen", "authors": "Cao Chen, Fen Zhou, Yuanhao Liu, and Shilin Xiao", "title": "Throughput Maximization Leveraging Just-Enough SNR Margin and Channel\n  Spacing Optimization", "comments": "submitted to IEEE JLT, Jul. 17th, 2021. 14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Flexible optical network is a promising technology to accommodate\nhigh-capacity demands in next-generation networks. To ensure uninterrupted\ncommunication, existing lightpath provisioning schemes are mainly done with the\nassumption of worst-case resource under-provisioning and fixed channel spacing,\nwhich preserves an excessive signal-to-noise ratio (SNR) margin. However, under\na resource over-provisioning scenario, the excessive SNR margin restricts the\ntransmission bit-rate or transmission reach, leading to physical layer resource\nwaste and stranded transmission capacity. To tackle this challenging problem,\nwe leverage an iterative feedback tuning algorithm to provide a just-enough SNR\nmargin, so as to maximize the network throughput. Specifically, the proposed\nalgorithm is implemented in three steps. First, starting from the high SNR\nmargin setup, we establish an integer linear programming model as well as a\nheuristic algorithm to maximize the network throughput by solving the problem\nof routing, modulation format, forward error correction, baud-rate selection,\nand spectrum assignment. Second, we optimize the channel spacing of the\nlightpaths obtained from the previous step, thereby increasing the available\nphysical layer resources. Finally, we iteratively reduce the SNR margin of each\nlightpath until the network throughput cannot be increased. Through numerical\nsimulations, we confirm the throughput improvement in different networks and\nwith different baud-rates. In particular, we find that our algorithm enables\nover 20\\% relative gain when network resource is over-provisioned, compared to\nthe traditional method preserving an excessive SNR margin.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 16:02:19 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 00:03:50 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chen", "Cao", ""], ["Zhou", "Fen", ""], ["Liu", "Yuanhao", ""], ["Xiao", "Shilin", ""]]}, {"id": "2106.07596", "submitter": "Cao Chen", "authors": "Cao Chen, Fen Zhou, Massimo Tornatore, and Shilin Xiao", "title": "Maximizing Revenue with Adaptive Modulation and Multiple FECs in\n  Flexible Optical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Flexible optical networks (FONs) are being adopted to accommodate the\nincreasingly heterogeneous traffic in today's Internet. However, in presence of\nhigh traffic load, not all offered traffic can be satisfied at all time. As\ncarried traffic load brings revenues to operators, traffic blocking due to\nlimited spectrum resource leads to revenue losses. In this study, given a set\nof traffic requests to be provisioned, we consider the problem of maximizing\noperator's revenue, subject to limited spectrum resource and physical layer\nimpairments (PLIs), namely amplified spontaneous emission noise (ASE),\nself-channel interference (SCI), cross-channel interference (XCI), and node\ncrosstalk. In FONs, adaptive modulation, multiple FEC, and the tuning of power\nspectrum density (PSD) can be effectively employed to mitigate the impact of\nPLIs. Hence, in our study, we propose a universal bandwidth-related impairment\nevaluation model based on channel bandwidth, which allows a performance\nanalysis for different PSD, FEC and modulations. Leveraging this PLI model and\na piecewise linear fitting function, we succeed to formulate the revenue\nmaximization problem as a mixed integer linear program. Then, to solve the\nproblem on larger network instances, a fast two-phase heuristic algorithm is\nalso proposed, which is shown to be near-optimal for revenue maximization.\nThrough simulations, we demonstrate that using adaptive modulation enables to\nsignificantly increase revenues in the scenario of high signal-to-noise ratio\n(SNR), where the revenue can even be doubled for high traffic load, while using\nmultiple FECs is more profitable for scenarios with low SNR.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 17:01:43 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chen", "Cao", ""], ["Zhou", "Fen", ""], ["Tornatore", "Massimo", ""], ["Xiao", "Shilin", ""]]}, {"id": "2106.07778", "submitter": "Debajyoti Halder", "authors": "Prashant Kumar, Saksham Bhushan, Debajyoti Halder, and Anand M.\n  Baswade", "title": "fybrrLink: Efficient QoS-aware Routing in SDN enabled Next-Gen Satellite\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Providing high-speed Internet service using satellite network has attracted\nresearchers from both academia and industry mainly due to the characteristics\nof Low Earth Orbit (LEO) satellite networks such as global coverage,\nscalability, and lower transmission delay. With the recent advancements in the\nSoftware-Defined Network (SDN), implementation of SDN in Non-Terrestrial\nNetworks (NTN) can help to achieve the set goals for 5G and beyond networks.\nSince satellite networks have a distinct architecture, some of the traditional\nprotocols no longer remain useful. Therefore, to satisfy the diverse Quality of\nService (QoS) requirements for a variety of applications, we propose a novel\nand centralized QoS-aware routing algorithm, called fybrrLink in which the\nglobal view of the network in SDN is utilized. We implement a modified\nBresenham's algorithm and Dijkstra's algorithm to find the optimal path in a\nsignificantly reduced computation time. Also, taking advantage of the\ndeterministic satellite constellation, we propose a flow rule transfer\nalgorithm and a topology monitoring algorithm. Further, fybrrLink is evaluated\nwith multiple NS3 simulations, and results confirm its supremacy over other\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 22:21:08 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kumar", "Prashant", ""], ["Bhushan", "Saksham", ""], ["Halder", "Debajyoti", ""], ["Baswade", "Anand M.", ""]]}, {"id": "2106.07856", "submitter": "Akarsh Prabhakara", "authors": "Diana Zhang, Akarsh Prabhakara, Sirajum Munir, Aswin Sankaranarayanan,\n  Swarun Kumar", "title": "A Hybrid mmWave and Camera System for Long-Range Depth Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NI cs.RO eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  mmWave radars offer excellent depth resolution owing to their high bandwidth\nat mmWave radio frequencies. Yet, they suffer intrinsically from poor angular\nresolution, that is an order-of-magnitude worse than camera systems, and are\ntherefore not a capable 3-D imaging solution in isolation. We propose\nMetamoran, a system that combines the complimentary strengths of radar and\ncamera systems to obtain depth images at high azimuthal resolutions at\ndistances of several tens of meters with high accuracy, all from a single fixed\nvantage point. Metamoran enables rich long-range depth imaging outdoors with\napplications to roadside safety infrastructure, surveillance and wide-area\nmapping. Our key insight is to use the high azimuth resolution from cameras\nusing computer vision techniques, including image segmentation and monocular\ndepth estimation, to obtain object shapes and use these as priors for our novel\nspecular beamforming algorithm. We also design this algorithm to work in\ncluttered environments with weak reflections and in partially occluded\nscenarios. We perform a detailed evaluation of Metamoran's depth imaging and\nsensing capabilities in 200 diverse scenes at a major U.S. city. Our evaluation\nshows that Metamoran estimates the depth of an object up to 60~m away with a\nmedian error of 28~cm, an improvement of 13$\\times$ compared to a naive\nradar+camera baseline and 23$\\times$ compared to monocular depth estimation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 03:19:35 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhang", "Diana", ""], ["Prabhakara", "Akarsh", ""], ["Munir", "Sirajum", ""], ["Sankaranarayanan", "Aswin", ""], ["Kumar", "Swarun", ""]]}, {"id": "2106.07866", "submitter": "Bishnu Prasad Gautam Dr.", "authors": "Gautam Bishnu Prasad, Batajoo Amit, Wasaki Katsumi", "title": "Fogging Jyaguchi Services in Tensai Gothalo", "comments": "7 pages with figures", "journal-ref": "International Journal of Computer Trends and Technology (IJCTT),\n  2015", "doi": "10.14445/22312803/IJCTT-V28P122", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the efficient method of fogging in Tensai Gothalo.\nTensai Gothalo is a novel dynamic router device developed in Gautam-Asami\nLaboratory of Wakkanai Hokusei Gakuen University which has sensing, actuating,\nmonitoring and movable capability. Similarly, fogging is a new concept of cloud\ncomputing at which the data plane is defined in user device. In this paper we\nwould like to present the stepwise explanation about how to fog in Tensai\nGothalo. Furthermore, we will elaborate a technique to decentralize data with\nimprovement in QoS and reducing latency without affecting the legacy services\nof clouds that can still work together while needed.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 04:01:21 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Prasad", "Gautam Bishnu", ""], ["Amit", "Batajoo", ""], ["Katsumi", "Wasaki", ""]]}, {"id": "2106.07997", "submitter": "Qingqing Wu", "authors": "Qingqing Wu, Xinrong Guan, Rui Zhang", "title": "Intelligent Reflecting Surface Aided Wireless Energy and Information\n  Transmission: An Overview", "comments": "Invited by Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AR cs.NI math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligent reflecting surface (IRS) is a promising technology for achieving\nspectrum and energy efficient wireless networks cost-effectively. Most existing\nworks on IRS have focused on exploiting IRS to enhance the performance of\nwireless communication or wireless information transmission (WIT), while its\npotential for boosting the efficiency of radio-frequency (RF) wireless energy\ntransmission (WET) still remains largely open. Although IRS-aided WET shares\nsimilar characteristics with IRS-aided WIT, they differ fundamentally in terms\nof design objective, receiver architecture, and practical constraints. In this\npaper, we provide a tutorial overview on how to efficiently design IRS-aided\nWET systems as well as IRS-aided systems with both WIT and WET, namely\nIRS-aided simultaneous wireless information and power transfer (SWIPT) and\nIRS-aided wireless powered communication network (WPCN), mainly from a\ncommunication and signal processing perspective. In particular, we present\nstate-of-the-art solutions to tackle the unique challenges in operating these\nsystems, such as IRS passive reflection optimization, channel estimation and\ndeployment. In addition, we also propose new solution approaches and point out\nimportant directions for future research and investigation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 09:22:56 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 01:08:46 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 06:03:52 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Wu", "Qingqing", ""], ["Guan", "Xinrong", ""], ["Zhang", "Rui", ""]]}, {"id": "2106.08286", "submitter": "Steffen Kaup", "authors": "Steffen Kaup, Andr\\'e Ludwig, Bogdan Franczyk", "title": "Framework Artifact for the Road-Based Physical Internet based on\n  Internet Protocols", "comments": "16 pages, 8th International Physical Internet Conference, Athens", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Physical Internet (PI) raises high expectations for efficiency gains in\ntransport and logistics. The PI represents the network of logistics networks\nfor physical objects in analogy to the Data Internet (DI). Road based traffic\nrepresents one of these logistics networks. Here, many empty runs and\nunderutilized trips still take place. Hence, there is a lot of potential in the\nroad-based Physical Internet (RBPI), which will have an impact on transport and\nlogistics strategies, but also on vehicle design. On the DI, logistics\nstrategies are implemented in protocols. In order to transfer such concepts to\nthe RBPI, relevant protocols of the DI had been analyzed and transferred to the\nworld of physical objects. However, not all functionalities can be transferred\none-to-one, e.g. a data packet in the DI can simply be re-generated by a hub in\ncase of damage or loss. To compensate for the challenges, a framework artifact\nhas been designed with appropriate transformation customizations based on\ndesign science principles. From this, resulting requirements for future\nvehicles were derived. This paper makes a contribution to the implementation of\nthe RBPI in order to fit road based vehicles to the future world of transport\nand logistics.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 16:53:50 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kaup", "Steffen", ""], ["Ludwig", "Andr\u00e9", ""], ["Franczyk", "Bogdan", ""]]}, {"id": "2106.08592", "submitter": "Wanli Ni", "authors": "Wanli Ni, Yuanwei Liu, Yonina C. Eldar, Zhaohui Yang, Hui Tian", "title": "STAR-RIS Enabled Heterogeneous Networks: Ubiquitous NOMA Communication\n  and Pervasive Federated Learning", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper integrates non-orthogonal multiple access (NOMA) and over-the-air\nfederated learning (AirFL) into a unified framework using one simultaneous\ntransmitting and reflecting reconfigurable intelligent surface (STAR-RIS). The\nSTAR-RIS plays an important role in adjusting the decoding order of hybrid\nusers for efficient interference mitigation and omni-directional coverage\nextension. To capture the impact of non-ideal wireless channels on AirFL, a\nclosed-form expression for the optimality gap (a.k.a. convergence upper bound)\nbetween the actual loss and the optimal loss is derived. This analysis reveals\nthat the learning performance is significantly affected by active and passive\nbeamforming schemes as well as wireless noise. Furthermore, when the learning\nrate diminishes as the training proceeds, the optimality gap is explicitly\ncharacterized to converge with a linear rate. To accelerate convergence while\nsatisfying QoS requirements, a mixed-integer non-linear programming (MINLP)\nproblem is formulated by jointly designing the transmit power at users and the\nconfiguration mode of STAR-RIS. Next, a trust region-based successive convex\napproximation method and a penalty-based semidefinite relaxation approach are\nproposed to handle the decoupled non-convex subproblems iteratively. An\nalternating optimization algorithm is then developed to find a suboptimal\nsolution for the original MINLP problem. Extensive simulation results show that\ni) the proposed framework can efficiently support NOMA and AirFL users via\nconcurrent uplink communications, ii) our algorithms can achieve a faster\nconvergence rate on IID and non-IID settings compared to existing baselines,\nand iii) both the spectrum efficiency and learning performance can be\nsignificantly improved with the aid of the well-tuned STAR-RIS.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 07:38:15 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 07:32:32 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ni", "Wanli", ""], ["Liu", "Yuanwei", ""], ["Eldar", "Yonina C.", ""], ["Yang", "Zhaohui", ""], ["Tian", "Hui", ""]]}, {"id": "2106.08654", "submitter": "Steffen Wendzel", "authors": "Steffen Wendzel, Luca Caviglione, Wojciech Mazurczyk, Aleksandra\n  Mileva, Jana Dittmann, Christian Kr\\\"atzer, Kevin Lamsh\\\"oft, Claus\n  Vielhauer, Laura Hartmann, J\\\"org Keller, Tom Neubert", "title": "A Revised Taxonomy of Steganography Embedding Patterns", "comments": null, "journal-ref": "In Proc. of the 16th International Conference on Availability,\n  Reliability and Security (ARES'21), August 17--20, 2021, Vienna, Austria", "doi": "10.1145/3465481.347006", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Steganography embraces several hiding techniques which spawn across multiple\ndomains. However, the related terminology is not unified among the different\ndomains, such as digital media steganography, text steganography,\ncyber-physical systems steganography, network steganography (network covert\nchannels), local covert channels, and out-of-band covert channels. To cope with\nthis, a prime attempt has been done in 2015, with the introduction of the\nso-called hiding patterns, which allow to describe hiding techniques in a more\nabstract manner. Despite significant enhancements, the main limitation of such\na taxonomy is that it only considers the case of network steganography.\n  Therefore, this paper reviews both the terminology and the taxonomy of hiding\npatterns as to make them more general. Specifically, hiding patterns are split\ninto those that describe the embedding and the representation of hidden data\nwithin the cover object.\n  As a first research action, we focus on embedding hiding patterns and we show\nhow they can be applied to multiple domains of steganography instead of being\nlimited to the network scenario. Additionally, we exemplify representation\npatterns using network steganography. Our pattern collection is available under\nhttps://patterns.ztt.hs-worms.de.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 09:34:40 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Wendzel", "Steffen", ""], ["Caviglione", "Luca", ""], ["Mazurczyk", "Wojciech", ""], ["Mileva", "Aleksandra", ""], ["Dittmann", "Jana", ""], ["Kr\u00e4tzer", "Christian", ""], ["Lamsh\u00f6ft", "Kevin", ""], ["Vielhauer", "Claus", ""], ["Hartmann", "Laura", ""], ["Keller", "J\u00f6rg", ""], ["Neubert", "Tom", ""]]}, {"id": "2106.08729", "submitter": "Joberto Martins Prof. Dr.", "authors": "David S. Barreto and Rafael F. Reale and Joberto S. B. Martins", "title": "Modeling and Accomplishing the BEREC Network Neutrality Policy", "comments": "17 pages, 8 figures, IJNM preprint", "journal-ref": "International Journal of Network Management, vol na, p e2148, 2020", "doi": "10.5281/zenodo.4554025", "report-no": null, "categories": "cs.NI cs.CY cs.PF", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Network neutrality (NN) is a principle of equal treatment of data in network\ninfrastructures with fairness and universality being the primary outcomes of\nthe NN management practice. For networks, the accomplishment of NN management\npractice is essential to deal with heterogeneous user requirements and the\never-increasing data traffic. Current tools and methods address the NN problem\nby detecting network neutrality violations and detecting traffic\ndifferentiation. This paper proposes the NN-PCM (Network Neutrality Policy\nConformance Module) that deploys the BEREC network neutrality policy using a\nbandwidth allocation model (BAM). The NN-PCM new approach allocates bandwidth\nto network users and accomplishes the BEREC NN policy concomitantly. Network\nneutrality is achieved by grouping users with similar traffic requirements in\nclasses and leveraging the bandwidth allocation model's characteristics. The\nconceptual analysis and simulation results indicate that NN-PCM allocates\nbandwidth to users and accomplishes BEREC network neutrality conformance by\ndesign with transparent, non-discriminatory, exceptional, and proportional\nmanagement practices.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 12:11:11 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Barreto", "David S.", ""], ["Reale", "Rafael F.", ""], ["Martins", "Joberto S. B.", ""]]}, {"id": "2106.08809", "submitter": "Rami Hamdi", "authors": "Rami Hamdi, Mingzhe Chen, Ahmed Ben Said, Marwa Qaraqe, H. Vincent\n  Poor", "title": "Federated Learning over Energy Harvesting Wireless Networks", "comments": "To appear in IEEE Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2021.3089054", "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the deployment of federated learning (FL) is investigated in\nan energy harvesting wireless network in which the base station (BS) employs\nmassive multiple-input multiple-output (MIMO) to serve a set of users powered\nby independent energy harvesting sources. Since a certain number of users may\nnot be able to participate in FL due to the interference and energy\nconstraints, a joint energy management and user scheduling problem in FL over\nwireless systems is formulated. This problem is formulated as an optimization\nproblem whose goal is to minimize the FL training loss via optimizing user\nscheduling. To find how the factors such as transmit power and number of\nscheduled users affect the training loss, the convergence rate of the FL\nalgorithm is first analyzed. Given this analytical result, the user scheduling\nand energy management optimization problem can be decomposed, simplified, and\nsolved. Further, the system model is extended by considering multiple BSs.\nHence, a joint user association and scheduling problem in FL over wireless\nsystems is studied. The optimal user association problem is solved using the\nbranch-and-bound technique. Simulation results show that the proposed user\nscheduling and user association algorithm can reduce training loss compared to\na standard FL algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 14:17:49 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Hamdi", "Rami", ""], ["Chen", "Mingzhe", ""], ["Said", "Ahmed Ben", ""], ["Qaraqe", "Marwa", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2106.08833", "submitter": "Sebastiano Miano", "authors": "Sebastiano Miano, Alireza Sanaee, Fulvio Risso, G\\'abor R\\'etv\\'ari,\n  Gianni Antichi", "title": "Dynamic Recompilation of Software Network Services with Morpheus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art approaches to design, develop and optimize software\npacket-processing programs are based on static compilation: the compiler's\ninput is a description of the forwarding plane semantics and the output is a\nbinary that can accommodate any control plane configuration or input traffic.\nIn this paper, we demonstrate that tracking control plane actions and\npacket-level traffic dynamics at run time opens up new opportunities for code\nspecialization. We present Morpheus, a system working alongside static\ncompilers that continuously optimizes the targeted networking code. We\nintroduce a number of new techniques, from static code analysis to adaptive\ncode instrumentation, and we implement a toolbox of domain specific\noptimizations that are not restricted to a specific data plane framework or\nprogramming language. We apply Morpheus to several eBPF and DPDK programs\nincluding Katran, Facebook's production-grade load balancer. We compare\nMorpheus against state-of-the-art optimization frameworks and show that it can\nbring up to 2x throughput improvement, while halving the 99th percentile\nlatency.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 14:51:57 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Miano", "Sebastiano", ""], ["Sanaee", "Alireza", ""], ["Risso", "Fulvio", ""], ["R\u00e9tv\u00e1ri", "G\u00e1bor", ""], ["Antichi", "Gianni", ""]]}, {"id": "2106.09261", "submitter": "Yuris Mulya Saputra", "authors": "Yuris Mulya Saputra, Diep N. Nguyen, Dinh Thai Hoang, and Eryk\n  Dutkiewicz", "title": "Coded Federated Learning Framework for AI-Based Mobile Application\n  Services with Privacy-Awareness", "comments": "18 pages (submitted to an IEEE journal)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By encoding computing tasks, coded computing can not only mitigate straggling\nproblems in federated learning (FL), but also preserve privacy of sensitive\ndata uploaded/contributed by participating mobile users (MUs) to the\ncentralized server, owned by a mobile application provider (MAP). However,\nthese advantages come with extra coding cost/complexity and communication\noverhead (referred to as \\emph{privacy cost}) that must be considered given the\nlimited computing/communications resources at MUs/MAP, the rationality and\nincentive competition among MUs in contributing data to the MAP. This article\nproposes a novel coded FL-based framework for a privacy-aware mobile\napplication service to address these challenges. In particular, the MAP first\ndetermines a set of the best MUs for the FL process based on MUs' provided\ninformation/features. Then, each selected MU can propose a contract to the MAP\naccording to its expected trainable local data and privacy-protected coded\ndata. To find the optimal contracts that can maximize utilities of the MAP and\nall the participating MUs while maintaining high learning quality of the whole\nsystem, we first develop a multi-principal one-agent contract-based problem\nleveraging coded FL-based multiple utility functions under the MUs' privacy\ncost, the MAP's limited computing resource, and asymmetric information between\nthe MAP and MUs. Then, we transform the problem into an equivalent\nlow-complexity problem and develop an iterative algorithm to solve it.\nExperiments with a real-world dataset show that our framework can speed up\ntraining time up to 49% and improve prediction accuracy up to 4.6 times while\nenhancing network's social welfare, i.e., total utility of all participating\nentities, up to 114% under the privacy cost consideration compared with those\nof baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 06:10:53 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Saputra", "Yuris Mulya", ""], ["Nguyen", "Diep N.", ""], ["Hoang", "Dinh Thai", ""], ["Dutkiewicz", "Eryk", ""]]}, {"id": "2106.09274", "submitter": "Xiang Tan", "authors": "Xiang Tan, Li Zhou, Haijun Wang, Yuli Sun, Haitao Zhao, Boon-Chong\n  Seet, Jibo Wei and Victor C.M. Leung", "title": "Cooperative Multi-Agent Reinforcement Learning Based Distributed Dynamic\n  Spectrum Access in Cognitive Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of the 5G and Internet of Things, amounts of wireless\ndevices need to share the limited spectrum resources. Dynamic spectrum access\n(DSA) is a promising paradigm to remedy the problem of inefficient spectrum\nutilization brought upon by the historical command-and-control approach to\nspectrum allocation. In this paper, we investigate the distributed DSA problem\nfor multi-user in a typical multi-channel cognitive radio network. The problem\nis formulated as a decentralized partially observable Markov decision process\n(Dec-POMDP), and we proposed a centralized off-line training and distributed\non-line execution framework based on cooperative multi-agent reinforcement\nlearning (MARL). We employ the deep recurrent Q-network (DRQN) to address the\npartial observability of the state for each cognitive user. The ultimate goal\nis to learn a cooperative strategy which maximizes the sum throughput of\ncognitive radio network in distributed fashion without coordination information\nexchange between cognitive users. Finally, we validate the proposed algorithm\nin various settings through extensive experiments. From the simulation results,\nwe can observe that the proposed algorithm can converge fast and achieve almost\nthe optimal performance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 06:52:21 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Tan", "Xiang", ""], ["Zhou", "Li", ""], ["Wang", "Haijun", ""], ["Sun", "Yuli", ""], ["Zhao", "Haitao", ""], ["Seet", "Boon-Chong", ""], ["Wei", "Jibo", ""], ["Leung", "Victor C. M.", ""]]}, {"id": "2106.09420", "submitter": "Hossam Farag", "authors": "Hossam Farag, Aleksandar Vujic, Milos Kostic, Goran Bijelic, and\n  Cedomir Stefanovic", "title": "Remote Health-Monitoring of First Responders over TETRA Links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a system for remote health-monitoring of first\nresponders over TETRA radio links. The system features a smart garment that\nperiodically records and sends physiological parameters of first responders to\na remote agent, which processes the recordings and feeds back the health-status\nnotifications and warnings in the form of electrotactile stimuli. The choice of\nTETRA as the connectivity solution is driven by its routine use by first\nresponders all over the world, thus representing a convenient and\neconomically-effective connectivity basis. Although the support for data\ncommunications in TETRA is rather limited and in practice reduced to the Short\nData Service, we show that TETRA can serve the intended purpose in the\nconsidered scenario, achieving tolerable delay and message-loss performance.\nMoreover, when the system is examined and optimized in terms of the peak\nAge-of-Information, a metric suitable to characterize the quasi-periodic nature\nof the monitoring process, its performance becomes rather favorable, enabling\ntimely monitoring of the first responders' health status.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 12:13:43 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Farag", "Hossam", ""], ["Vujic", "Aleksandar", ""], ["Kostic", "Milos", ""], ["Bijelic", "Goran", ""], ["Stefanovic", "Cedomir", ""]]}, {"id": "2106.09518", "submitter": "Song-Kyoo Amang Kim Ph.D.", "authors": "Song-Kyoo Kim", "title": "Multi-Layered Blockchain Governance Game", "comments": "This working paper is targeted to submit at an international journal\n  in the Applied Mathematics area", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper deals with design of an integrated secure Blockchain network\nframework to prevent damages from attackers. The multi-layer concept which\ncould handle multiple number of networks is adapted on the top of Blockchain\nGovernance Game frameworks. This new integrated theoretical model is designed\nto find the best strategies toward preparation for preventing whole network\nsystems malfunction from attackers and it is developed based on the combination\nof the Blockchain Governance Game and the Strategic Alliance for Blockchain\nGovernance Game. Analytically tractable results for executing a safety mode are\nfully obtained and simulated results are demonstrated to obtain the optimal\nvalues of hyper parameters of a Blockchain based security network. This\nresearch helps those whom are constructing a multiple layer network by\nenhancing security features through multi-layer framework in a decentralized\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 13:47:15 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Kim", "Song-Kyoo", ""]]}, {"id": "2106.09754", "submitter": "Paul Almasan", "authors": "Paul Almasan, Jos\\'e Su\\'arez-Varela, Bo Wu, Shihan Xiao, Pere\n  Barlet-Ros, Albert Cabellos-Aparicio", "title": "Towards Real-Time Routing Optimization with Deep Reinforcement Learning:\n  Open Challenges", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digital transformation is pushing the existing network technologies\ntowards new horizons, enabling new applications (e.g., vehicular networks). As\na result, the networking community has seen a noticeable increase in the\nrequirements of emerging network applications. One main open challenge is the\nneed to accommodate control systems to highly dynamic network scenarios.\nNowadays, existing network optimization technologies do not meet the needed\nrequirements to effectively operate in real time. Some of them are based on\nhand-crafted heuristics with limited performance and adaptability, while some\ntechnologies use optimizers which are often too time-consuming. Recent advances\nin Deep Reinforcement Learning (DRL) have shown a dramatic improvement in\ndecision-making and automated control problems. Consequently, DRL represents a\npromising technique to efficiently solve a variety of relevant network\noptimization problems, such as online routing. In this paper, we explore the\nuse of state-of-the-art DRL technologies for real-time routing optimization and\noutline some relevant open challenges to achieve production-ready DRL-based\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:21:46 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Almasan", "Paul", ""], ["Su\u00e1rez-Varela", "Jos\u00e9", ""], ["Wu", "Bo", ""], ["Xiao", "Shihan", ""], ["Barlet-Ros", "Pere", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "2106.09789", "submitter": "Tom Hanika", "authors": "Bastian Schaefermeier and Gerd Stumme and Tom Hanika", "title": "Topological Indoor Mapping through WiFi Signals", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquitous presence of WiFi access points and mobile devices capable of\nmeasuring WiFi signal strengths allow for real-world applications in indoor\nlocalization and mapping. In particular, no additional infrastructure is\nrequired. Previous approaches in this field were, however, often hindered by\nproblems such as effortful map-building processes, changing environments and\nhardware differences. We tackle these problems focussing on topological maps.\nThese represent discrete locations, such as rooms, and their relations, e.g.,\ndistances and transition frequencies. In our unsupervised method, we employ\nWiFi signal strength distributions, dimension reduction and clustering. It can\nbe used in settings where users carry mobile devices and follow their normal\nroutine. We aim for applications in short-lived indoor events such as\nconferences.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 20:06:09 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Schaefermeier", "Bastian", ""], ["Stumme", "Gerd", ""], ["Hanika", "Tom", ""]]}, {"id": "2106.09837", "submitter": "Mohammed Abdelsadek", "authors": "Mohammed Y. Abdelsadek, Halim Yanikomeroglu and Gunes Karabulut Kurt", "title": "Future Ultra-Dense LEO Satellite Networks: A Cell-Free Massive MIMO\n  Approach", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low Earth orbit (LEO) satellite networks (SatNets) are envisioned to play a\ncrucial role in providing global and ubiquitous connectivity efficiently.\nAccordingly, in the coming years, thousands of LEO satellites will be launched\nto create ultradense LEO mega-constellations, and the Third Generation\nPartnership Project (3GPP) is working on evolving fifth-generation (5G) systems\nto support such non-terrestrial networks (NTN). However, many challenges are\nassociated with the deployment of LEOs from communications and networking\nperspectives. In this paper, we propose a novel cell-free massive\nmultiple-input multiple-output (CF-mMIMO) based architecture for future\nultra-dense LEO SatNets. We discuss various aspects of network design, such as\nduplexing mode, pilot assignment, beamforming, and handover management. In\naddition, we propose a joint optimization framework for the power allocation\nand handover management processes to maximize the network throughput and\nminimize the handover rate while ensuring quality-of-service (QoS) satisfaction\nfor users. To the best of our knowledge, this is the first work to introduce\nand study CF-mMIMO-based LEO SatNets. Extensive simulation results demonstrate\nthe superior performance of the proposed architecture and solutions compared to\nthose of conventional single-satellite connectivity and handover techniques\nfrom the literature.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 22:18:09 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Abdelsadek", "Mohammed Y.", ""], ["Yanikomeroglu", "Halim", ""], ["Kurt", "Gunes Karabulut", ""]]}, {"id": "2106.09849", "submitter": "Prabhu Kaliyammal Thiruvasagam", "authors": "Prabhu Kaliyammal Thiruvasagam, Abhishek Chakraborty, and C. Siva Ram\n  Murthy", "title": "Latency-aware and Survivable Mapping of VNFs in 5G Network Edge Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Network Functions Virtualization (NFV) and Multi-access Edge Computing (MEC)\nplay crucial roles in 5G networks for dynamically provisioning diverse\ncommunication services with heterogeneous service requirements. In particular,\nwhile NFV improves flexibility and scalability by softwarizing physical network\nfunctions as Virtual Network Functions (VNFs), MEC enables to provide\ndelay-sensitive/time-critical services by moving computing facilities to the\nnetwork edge. However, these new paradigms introduce challenges in terms of\nlatency, availability, and resource allocation. In this paper, we first explore\nMEC cloud facility location selection and then latency-aware placement of VNFs\nin different selected locations of NFV enabled MEC cloud facilities in order to\nmeet the ultra-low latency requirements of different applications (e.g.,\nTactile Internet, virtual reality, and mission-critical applications).\nFurthermore, we also aim to guarantee the survivability of VNFs and an edge\nserver against failures in resource limited MEC cloud facility due to software\nbugs, configuration faults, etc. To this end, we formulate the problem of\nlatency-aware and survivable mapping of VNFs in different MEC cloud facilities\nas an Integer Linear Programming (ILP) to minimize the overall service\nprovisioning cost, and show that the problem is NP-hard. Owing to the high\ncomputational complexity of solving the ILP, we propose a simulated annealing\nbased heuristic algorithm to obtain near-optimal solution in polynomial time.\nWith extensive simulations, we show the effectiveness of our proposed solution\nin a real-world network topology, which performs close to the optimal solution.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 23:57:08 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Thiruvasagam", "Prabhu Kaliyammal", ""], ["Chakraborty", "Abhishek", ""], ["Murthy", "C. Siva Ram", ""]]}, {"id": "2106.10006", "submitter": "Sebahat Sinem Kaf{\\i}lo\\u{g}lu", "authors": "S. Sinem Kaf{\\i}lo\\u{g}lu, G\\\"urkan G\\\"ur, Fatih Alag\\\"oz", "title": "Energy Prioritized Caching for Cellular D2D Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimedia content transmission heavily taxes network resources and puts a\nsignificant burden on wireless systems in terms of capacity and energy\nconsumption. In this context, device-to-device (D2D) paradigm has a utilitarian\nvalue to alleviate the network burden by utilizing short-range transmissions\nwith less energy cost. For the realization of proper D2D networking, caching in\ndevices is essential. Additionally, caching needs to operate efficiently with\nthe aim of realizing network-wide energy improvements. To this end, we study\nmultimedia caching in cellular D2D networks and propose an energy prioritized\nD2D caching (EPDC) algorithm in this work. We also investigate the optimal\ncaching policy in that system setting. The impact of device capacity and D2D\ntransmission range on energy consumption is studied by focusing on different\noperation modes such as D2D and base station transmissions. According to the\nsimulation results, EPDC algorithm has substantial energy-efficiency gains over\nthe commonly utilized Least Recently Used (LRU) algorithm and content-based\ncaching algorithms PDC and SXO. For larger D2D transmission ranges, this\nimprovement becomes more evident.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 08:55:23 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Kaf\u0131lo\u011flu", "S. Sinem", ""], ["G\u00fcr", "G\u00fcrkan", ""], ["Alag\u00f6z", "Fatih", ""]]}, {"id": "2106.10014", "submitter": "Jonathan Sherwin", "authors": "Jonathan Sherwin (Munster Technological University), Cormac J. Sreenan\n  (University College Cork)", "title": "Software-Defined Networking for Data Centre Network Management: A Survey", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data centres are growing in numbers and size, and their networks expanding to\ncarry larger amounts of traffic. The traffic profile is constantly varying,\nparticularly in cloud data centres where tenants arrive, leave, and may change\ntheir resource requirements in between, and so the network configuration must\nchange at a commensurate rate. Software-Defined Networking - programmatic\ncontrol of network configuration - has been critical to meeting the demands of\nmodern data centre network management, and has been the subject of intense\nfocus by the research community, working in conjunction with industry. In this\nsurvey, we review Software-Defined Networking research targeting the management\nand operation of data centre networks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 09:15:13 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Sherwin", "Jonathan", "", "Munster Technological University"], ["Sreenan", "Cormac J.", "", "University College Cork"]]}, {"id": "2106.10063", "submitter": "Falko Dressler", "authors": "Falko Dressler, Carla Fabiana Chiasserini, Frank H.P. Fitzek, Holger\n  Karl, Renato Lo Cigno, Antonio Capone, Claudio Casetti, Francesco Malandrino,\n  Vincenzo Mancuso, Florian Klingler, Gianluca Rizzo", "title": "V-Edge: Virtual Edge Computing as an Enabler for Novel Microservices and\n  Cooperative Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we move from 5G to 6G, edge computing is one of the concepts that needs\nrevisiting. Its core idea is still intriguing: instead of sending all data and\ntasks from an end user's device to the cloud, possibly covering thousands of\nkilometers and introducing delays that are just owed to limited propagation\nspeed, edge servers deployed in close proximity to the user, e.g., at some 5G\ngNB, serve as proxy for the cloud. Yet this promising idea is hampered by the\nlimited availability of such edge servers. In this paper, we discuss a way\nforward, namely the virtual edge computing (V-Edge) concept. V-Edge bridges the\ngap between cloud, edge, and fog by virtualizing all available resources\nincluding the end users' devices and making these resources widely available\nusing well-defined interfaces. V-Edge also acts as an enabler for novel\nmicroservices as well as cooperative computing solutions. We introduce the\ngeneral V-Edge architecture and we characterize some of the key research\nchallenges to overcome, in order to enable wide-spread and even more powerful\nedge services.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 11:20:45 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Dressler", "Falko", ""], ["Chiasserini", "Carla Fabiana", ""], ["Fitzek", "Frank H. P.", ""], ["Karl", "Holger", ""], ["Cigno", "Renato Lo", ""], ["Capone", "Antonio", ""], ["Casetti", "Claudio", ""], ["Malandrino", "Francesco", ""], ["Mancuso", "Vincenzo", ""], ["Klingler", "Florian", ""], ["Rizzo", "Gianluca", ""]]}, {"id": "2106.10423", "submitter": "Nam Chu", "authors": "Nam H.Chu, Dinh Thai Hoang, Diep N. Nguyen, Nguyen Van Huynh, Eryk\n  Dutkiewicz", "title": "Joint Speed Control and Energy Replenishment Optimization for\n  UAV-assisted IoT Data Collection with Deep Reinforcement Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicle (UAV)-assisted data collection has been emerging as a\nprominent application due to its flexibility, mobility, and low operational\ncost. However, under the dynamic and uncertainty of IoT data collection and\nenergy replenishment processes, optimizing the performance for UAV collectors\nis a very challenging task. Thus, this paper introduces a novel framework that\njointly optimizes the flying speed and energy replenishment for each UAV to\nsignificantly improve the data collection performance. Specifically, we first\ndevelop a Markov decision process to help the UAV automatically and dynamically\nmake optimal decisions under the dynamics and uncertainties of the environment.\nWe then propose a highly-effective reinforcement learning algorithm leveraging\ndeep Q-learning, double deep Q-learning, and a deep dueling neural network\narchitecture to quickly obtain the UAV's optimal policy. The core ideas of this\nalgorithm are to estimate the state values and action advantages separately and\nsimultaneously and to employ double estimators for estimating the action\nvalues. Thus, these proposed techniques can stabilize the learning process and\neffectively address the overestimation problem of conventional Q-learning\nalgorithms. To further reduce the learning time as well as significantly\nimprove learning quality, we develop advanced transfer learning techniques to\nallow UAVs to ``share'' and ``transfer'' learning knowledge. Extensive\nsimulations demonstrate that our proposed solution can improve the average data\ncollection performance of the system up to 200% compared with those of current\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 04:40:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chu", "Nam H.", ""], ["Hoang", "Dinh Thai", ""], ["Nguyen", "Diep N.", ""], ["Van Huynh", "Nguyen", ""], ["Dutkiewicz", "Eryk", ""]]}, {"id": "2106.10685", "submitter": "Toni Mancini", "authors": "Quian Matteo Chen, Alberto Finzi, Toni Mancini, Igor Melatti, Enrico\n  Tronci", "title": "MILP, pseudo-boolean, and OMT solvers for optimal fault-tolerant\n  placements of relay nodes in mission critical wireless networks", "comments": "33 pages, 11 figures", "journal-ref": "Fundamenta Informaticae, 174(3-4):229-258, 2020", "doi": "10.3233/FI-2020-1941", "report-no": null, "categories": "cs.AI cs.DC cs.LO cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In critical infrastructures like airports, much care has to be devoted in\nprotecting radio communication networks from external electromagnetic\ninterference. Protection of such mission-critical radio communication networks\nis usually tackled by exploiting radiogoniometers: at least three suitably\ndeployed radiogoniometers, and a gateway gathering information from them,\npermit to monitor and localise sources of electromagnetic emissions that are\nnot supposed to be present in the monitored area. Typically, radiogoniometers\nare connected to the gateway through relay nodes. As a result, some degree of\nfault-tolerance for the network of relay nodes is essential in order to offer a\nreliable monitoring. On the other hand, deployment of relay nodes is typically\nquite expensive. As a result, we have two conflicting requirements: minimise\ncosts while guaranteeing a given fault-tolerance. In this paper, we address the\nproblem of computing a deployment for relay nodes that minimises the relay node\nnetwork cost while at the same time guaranteeing proper working of the network\neven when some of the relay nodes (up to a given maximum number) become faulty\n(fault-tolerance). We show that, by means of a computation-intensive\npre-processing on a HPC infrastructure, the above optimisation problem can be\nencoded as a 0/1 Linear Program, becoming suitable to be approached with\nstandard Artificial Intelligence reasoners like MILP, PB-SAT, and SMT/OMT\nsolvers. Our problem formulation enables us to present experimental results\ncomparing the performance of these three solving technologies on a real case\nstudy of a relay node network deployment in areas of the Leonardo da Vinci\nAirport in Rome, Italy.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 12:14:36 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Quian Matteo", ""], ["Finzi", "Alberto", ""], ["Mancini", "Toni", ""], ["Melatti", "Igor", ""], ["Tronci", "Enrico", ""]]}, {"id": "2106.10836", "submitter": "Yuya Senzaki", "authors": "Yuya Senzaki, Christian Hamelain", "title": "Active Learning for Deep Neural Networks on Edge Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  When dealing with deep neural network (DNN) applications on edge devices,\ncontinuously updating the model is important. Although updating a model with\nreal incoming data is ideal, using all of them is not always feasible due to\nlimits, such as labeling and communication costs. Thus, it is necessary to\nfilter and select the data to use for training (i.e., active learning) on the\ndevice. In this paper, we formalize a practical active learning problem for\nDNNs on edge devices and propose a general task-agnostic framework to tackle\nthis problem, which reduces it to a stream submodular maximization. This\nframework is light enough to be run with low computational resources, yet\nprovides solutions whose quality is theoretically guaranteed thanks to the\nsubmodular property. Through this framework, we can configure data selection\ncriteria flexibly, including using methods proposed in previous active learning\nstudies. We evaluate our approach on both classification and object detection\ntasks in a practical setting to simulate a real-life scenario. The results of\nour study show that the proposed framework outperforms all other methods in\nboth tasks, while running at a practical speed on real devices.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 03:55:33 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Senzaki", "Yuya", ""], ["Hamelain", "Christian", ""]]}, {"id": "2106.10963", "submitter": "Changsheng You", "authors": "Changsheng You and Rui Zhang", "title": "Wireless Communication Aided by Intelligent Reflecting Surface: Active\n  or Passive?", "comments": "We studied the comparison between active and passive IRS with\n  optimized IRS deployment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this letter, we consider an intelligent reflecting surface (IRS)-aided\nwireless communication system, where an active or passive IRS is employed to\nassist the communication between an access point and a user. First, we consider\nthe downlink/uplink communication separately and optimize the IRS placement for\nrate maximization with an active or passive IRS. We show that the active IRS\nshould be deployed closer to the receiver with the IRS's decreasing\namplification power; while in contrast, the passive IRS should be deployed near\neither the transmitter or receiver. Moreover, with optimized IRS placement, the\npassive IRS is shown to outperform its active counterpart when the number of\nreflecting elements is sufficiently large and/or the active-IRS amplification\npower is too small. Next, we optimize the IRS placement for both active and\npassive IRSs to maximize the weighted sum-rate of uplink and downlink\ncommunications. We show that in this case, the passive IRS is more likely to\nachieve superior rate performance. This is because the optimal active-IRS\nplacement needs to balance the rate performance in the uplink and downlink,\nwhile deploying the passive IRS near the transmitter or receiver is optimal\nregardless of the uplink or downlink.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 10:19:17 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["You", "Changsheng", ""], ["Zhang", "Rui", ""]]}, {"id": "2106.10964", "submitter": "Ningrinla Marchang", "authors": "Bishal Chhetry and Ningrinla Marchang", "title": "Detection Of Primary User Emulation Attack (PUEA) In Cognitive Radio\n  Networks Using One-Class Classification", "comments": "7 pages, 10 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Opportunistic usage of spectrum owned by licensed (or primary) users is the\ncornerstone on which the Cognitive Radio technology is built. Unlicensed (or\nsecondary) users that thus use the spectrum rely opportunistically on spectrum\nsensing to determine the presence of primary user signal. In such a context, an\nattacker may mimic the behavior of a primary user (PU) to deceive the secondary\nusers (SUs) into believing that a PU signal is present whereas it is not. Such\nan attack is known as the Primary User Emulation Attack (PUEA). A malicious\nuser may launch a PUEA with the intention of grabbing the vacant bands for its\nown transmission. Another reason may be to simply disrupt the functioning of\nthe Cognitive Radio Network (CRN). This work investigates the use of one-class\nclassification for detecting PUEA in an infrastructure-based CRN. We opine that\nsensing data collected at the fusion center mainly for Collaborative Spectrum\nSensing (CSS) can be exploited to characterize a PU signal. The PU signal\nfeatures thus learned can aid in distinguishing a PU signal from a PU signal\nemulation. In particular, we investigate the use of one-class classification\ntechniques, viz., Isolation Forest, Support Vector Machines (SVM), Minimum\nCovariance Determinant(MCD) and Local Outlier Factor(LOF) for detection of PUEA\nattacks. Simulation results support the validity of using one-class\nclassification for detection of PUEA.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 10:20:45 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chhetry", "Bishal", ""], ["Marchang", "Ningrinla", ""]]}, {"id": "2106.11181", "submitter": "Junbin Zhang", "authors": "Pei-Hsuan Tsai, Yu-Lin Tseng, Jun-Bin Zhang, Meng-Hsun Tsai", "title": "A Query-based Routing Table Update Mechanism for Content-Centric Network", "comments": "6 pages, 14 figures, conference. ISBN:978-1-7281-9256-7", "journal-ref": "2020 International Computer Symposium (ICS), 2020, pp. 266-271", "doi": "10.1109/ICS51289.2020.00060", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the popularity of network applications, such as multimedia, online\nshopping, Internet of Things (IoT), and 5G, the contents cached in the routers\nare frequently replaced in Content-Centric Networking (CCN). Generally, cache\nmiss causes numerous propagated packets to get the required content that\ndeteriorates network congestion and delay the response time of consumers. Many\ncaching strategies and routing policies were proposed to solve the problem.\nThis paper presents an alternative solution by designing a query-based routing\ntable update mechanism to increase the accuracy of routing tables. By adding an\nadditional query content in interest packets, our approach real-time explores\nthe cached content in routers and updated the routing table accordingly. This\npaper uses a general network simulator, ndnSIM, to compare basic CCN and our\napproach. The results show that our approach improves the response time of\nconsumers and network congestion and is compatible with general forwarding\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 15:20:21 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Tsai", "Pei-Hsuan", ""], ["Tseng", "Yu-Lin", ""], ["Zhang", "Jun-Bin", ""], ["Tsai", "Meng-Hsun", ""]]}, {"id": "2106.11341", "submitter": "Jeremy Straub", "authors": "Dominic Rosch-Grace, Jeremy Straub", "title": "Consideration of the Need for Quantum Grid Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Quantum computing is poised to dramatically change the computational\nlandscape, worldwide. Quantum computers can solve complex problems that are, at\nleast in some cases, beyond the ability of even advanced future classical-style\ncomputers. In addition to being able to solve these classical\ncomputer-unsolvable problems, quantum computers have demonstrated a capability\nto solve some problems (such as prime factoring) much more efficiently than\nclassical computing. This will create problems for encryption techniques, which\ndepend on the difficulty of factoring for their security. Security, scientific,\nand other applications will require access to quantum computing resources to\naccess their unique capabilities, speed and economic (aggregate computing time\ncost) benefits. Many scientific applications, as well as numerous other ones,\nuse grid computing to provide benefits such as scalability and resource access.\nAs these applications may benefit from quantum capabilities - and some future\napplications may require quantum capabilities - identifying how to integrate\nquantum computing systems into grid computing environments is critical. This\npaper discusses the benefits of grid-connected quantum computers and what is\nrequired to achieve this.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:19:22 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Rosch-Grace", "Dominic", ""], ["Straub", "Jeremy", ""]]}, {"id": "2106.11368", "submitter": "Jaafar Elmirghani", "authors": "Abdelrahman S. Elgamal, Osama Z. Alsulami, Ahmad Adnan Qidan, Taisir\n  E.H. El-Gorashi and Jaafar M. H. Elmirghani", "title": "Reinforcement Learning for Resource Allocation in Steerable Laser-based\n  Optical Wireless Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Vertical Cavity Surface Emitting Lasers (VCSELs) have demonstrated\nsuitability for data transmission in indoor optical wireless communication\n(OWC) systems due to the high modulation bandwidth and low manufacturing cost\nof these sources. Specifically, resource allocation is one of the major\nchallenges that can affect the performance of multi-user optical wireless\nsystems. In this paper, an optimisation problem is formulated to optimally\nassign each user to an optical access point (AP) composed of multiple VCSELs\nwithin a VCSEL array at a certain time to maximise the signal to interference\nplus noise ratio (SINR). In this context, a mixed-integer linear programming\n(MILP) model is introduced to solve this optimisation problem. Despite the\noptimality of the MILP model, it is considered impractical due to its high\ncomplexity, high memory and full system information requirements. Therefore,\nreinforcement Learning (RL) is considered, which recently has been widely\ninvestigated as a practical solution for various optimization problems in\ncellular networks due to its ability to interact with environments with no\nprevious experience. In particular, a Q-learning (QL) algorithm is investigated\nto perform resource management in a steerable VCSEL-based OWC systems. The\nresults demonstrate the ability of the QL algorithm to achieve optimal\nsolutions close to the MILP model. Moreover, the adoption of beam steering,\nusing holograms implemented by exploiting liquid crystal devices, results in\nfurther enhancement in the performance of the network considered.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:57:03 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Elgamal", "Abdelrahman S.", ""], ["Alsulami", "Osama Z.", ""], ["Qidan", "Ahmad Adnan", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2106.11390", "submitter": "Bhagyashri Tushir", "authors": "Holden Gordon, Conrad Park, Bhagyashri Tushir, Yuhong Liu, Behnam\n  Dezfouli", "title": "An Efficient SDN Architecture for Smart Home Security Accelerated by\n  FPGA", "comments": "published in LANMAN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise in Internet of Things (IoT) devices, home network management\nand security are becoming complex. There is an urgent requirement to make smart\nhome network management efficient. This work proposes an SDN-based architecture\nto secure smart home networks through K-Nearest Neighbor (KNN) based device\nclassifications and malicious traffic detection. The efficiency is further\nenhanced by offloading the computation-intensive KNN model to Field\nProgrammable Gate Arrays (FPGA), which offers parallel processing power of GPU\nplatforms at lower costs and higher efficiencies, and can be used to accelerate\ntime-sensitive tasks. The proposed parallelization and implementation of KNN on\nFPGA are achieved by using the Vivado Design Suite from Xilinx and High-Level\nSynthesis (HLS). When optimized with 10-fold cross-validation, the proposed\nsolution for KNN consistently exhibits the best performances on FPGA when\ncompared with four alternative KNN instances (i.e., 78% faster than the\nparallel bubble sort-based implementation and 99\\% faster than the other three\nsorting algorithms). Moreover, with 36,225 training samples, the proposed KNN\nsolution classifies a test query with 95% accuracy in approximately 4\nmilliseconds on FPGA compared to 57 seconds on a CPU platform.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 19:59:14 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 01:08:09 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gordon", "Holden", ""], ["Park", "Conrad", ""], ["Tushir", "Bhagyashri", ""], ["Liu", "Yuhong", ""], ["Dezfouli", "Behnam", ""]]}, {"id": "2106.11595", "submitter": "Philippe Mary", "authors": "Philippe Mary, Visa Koivunen, Christophe Moy", "title": "Reinforcement Learning for Physical Layer Communications", "comments": "Machine Learning and Wireless Communications, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we will give comprehensive examples of applying RL in\noptimizing the physical layer of wireless communications by defining different\nclass of problems and the possible solutions to handle them. In Section 9.2, we\npresent all the basic theory needed to address a RL problem, i.e. Markov\ndecision process (MDP), Partially observable Markov decision process (POMDP),\nbut also two very important and widely used algorithms for RL, i.e. the\nQ-learning and SARSA algorithms. We also introduce the deep reinforcement\nlearning (DRL) paradigm and the section ends with an introduction to the\nmulti-armed bandits (MAB) framework. Section 9.3 focuses on some toy examples\nto illustrate how the basic concepts of RL are employed in communication\nsystems. We present applications extracted from literature with simplified\nsystem models using similar notation as in Section 9.2 of this Chapter. In\nSection 9.3, we also focus on modeling RL problems, i.e. how action and state\nspaces and rewards are chosen. The Chapter is concluded in Section 9.4 with a\nprospective thought on RL trends and it ends with a review of a broader state\nof the art in Section 9.5.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 08:02:06 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 16:20:43 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Mary", "Philippe", ""], ["Koivunen", "Visa", ""], ["Moy", "Christophe", ""]]}, {"id": "2106.11656", "submitter": "Xuelin Cao", "authors": "Xuelin Cao, Bo Yang, Chau Yuen, Zhu Han", "title": "HAP-Reserved Communications in Space-Air-Ground Integrated Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terrestrial communication networks have experienced significant development\nin recent years by providing emerging services for ground users. However, one\ncritical challenge raised is to provide full coverage (especially in dense\nhigh-rise urban environments) for ground users due to scarce network resources\nand limited coverage. To meet this challenge, we propose a high altitude\nplatform (HAP)-reserved ground-air-space (GAS) transmission scheme, which\ncombines with the ground-to-space (G2S) transmission scheme to strengthen the\nterrestrial communication and save the transmission power. To integrate the two\ntransmission schemes, we propose a transmission control strategy. Wherein, the\nground user decides its transmission scheme, i.e., switches between the GAS\nlink transmission and the G2S link transmission with a probability. We then\nmaximize the overall throughput and derive the optimal probability that a\nground user adopts the GAS transmission scheme. Numerical results demonstrate\nthe superiority of the proposed transmission control strategy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 10:27:35 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Cao", "Xuelin", ""], ["Yang", "Bo", ""], ["Yuen", "Chau", ""], ["Han", "Zhu", ""]]}, {"id": "2106.11784", "submitter": "Mithun Mukherjee", "authors": "Mithun Mukherjee and Vikas Kumar and Mian Guo and Daniel Benevides da\n  Costa and Ertugrul Basar and Zhiguo Ding", "title": "The Interplay of Reconfigurable Intelligent Surfaces and Mobile Edge\n  Computing in Future Wireless Networks: A Win-Win Strategy to 6G", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.ET cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reconfigurable intelligent surface (RIS)-empowered communication is being\nconsidered as an enabling technology for sixth generation (6G) wireless\nnetworks. The key idea of RIS-assisted communication is to enhance the\ncapacity, coverage, energy efficiency, physical layer security, and many other\naspects of modern wireless networks. At the same time, mobile edge computing\n(MEC) has already shown its huge potential by extending the computation,\ncommunication, and caching capabilities of a standalone cloud server to the\nnetwork edge. In this article, we first provide an overview of how MEC and RIS\ncan benefit each other. We envision that the integration of MEC and RIS will\nbring an unprecedented transformation to the future evolution of wireless\nnetworks. We provide a system-level perspective on the MEC-aided RIS (and\nRIS-assisted MEC) that will evolve wireless network towards 6G. We also outline\nsome of the fundamental challenges that pertain to the implementation of\nMEC-aided RIS (and RIS-assisted MEC) networks. Finally, the key research trends\nin the RIS-assisted MEC are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 02:44:22 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Mukherjee", "Mithun", ""], ["Kumar", "Vikas", ""], ["Guo", "Mian", ""], ["da Costa", "Daniel Benevides", ""], ["Basar", "Ertugrul", ""], ["Ding", "Zhiguo", ""]]}, {"id": "2106.11825", "submitter": "Hirley Alves", "authors": "Hirley Alves, Gweon Do Jo, JaeSheung Shin, Choongil Yeh, Nurul Huda\n  Mahmood, Carlos Lima, Chanho Yoon, Nandana Rahatheva, Ok-Sun Park, Seokki\n  Kim, Eunah Kim, Ville Niemel\\\"a, Hyeon Woo Lee, Ari Pouttu, Hyun Kyu Chung,\n  Matti Latva-aho", "title": "Beyond 5G URLLC Evolution: New Service Modes and Practical\n  Considerations", "comments": "Submitted to IEEE Wireless Commun. Mag", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-reliable low latency communications (URLLC) arose to serve industrial\nIoT (IIoT) use cases within the 5G. Currently, it has inherent limitations to\nsupport future services. Based on state-of-the-art research and practical\ndeployment experience, in this article, we introduce and advocate for three\nvariants: broadband, scalable and extreme URLLC. We discuss use cases and key\nperformance indicators and identify technology enablers for the new service\nmodes. We bring practical considerations from the IIoT testbed and provide an\noutlook toward some new research directions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 12:43:56 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Alves", "Hirley", ""], ["Jo", "Gweon Do", ""], ["Shin", "JaeSheung", ""], ["Yeh", "Choongil", ""], ["Mahmood", "Nurul Huda", ""], ["Lima", "Carlos", ""], ["Yoon", "Chanho", ""], ["Rahatheva", "Nandana", ""], ["Park", "Ok-Sun", ""], ["Kim", "Seokki", ""], ["Kim", "Eunah", ""], ["Niemel\u00e4", "Ville", ""], ["Lee", "Hyeon Woo", ""], ["Pouttu", "Ari", ""], ["Chung", "Hyun Kyu", ""], ["Latva-aho", "Matti", ""]]}, {"id": "2106.12117", "submitter": "Khondokar Fida Hasan", "authors": "Timothy Jones, Khondokar Fida Hasan", "title": "Long-Range Time-Synchronisation Methods in LoRaWAN-based IoT", "comments": "23 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  LoRa (Long-Range) is an LPWAN (low-power wide-area network) protocol that is\npart of the IoT family that focusses on long-range communication of up to 14km,\nalbeit with delay-inherent transmissions. Three IoT-based time synchronisation\nmethodologies are analysed, and their efficacy measured through a systematic\ncritical literature review. These include a GNSS-based method, an off-the-shelf\nGPS hardware resampling method, and the LongShoT method, within the context of\nvehicular ad-hoc networks (VANET), wireless sensor networks (WSN), and\nlong-range wide area network (LoRaWAN) respectively. Although two of the three\nmethods are not LoRaWAN-specific, the findings obtained from the research are\napplied to the context of LoRa in the proposed methodology. A methodology for\nselecting a time synchronisation methodology with regards to LoRa specifically\nis posited, whereby each requirement of synchronisation objective, energy\nconsumption and costs, scenario and security analysis, application\nrequirements, microcontroller requirements and transceiver requirements are\ntaken into consideration. These are then followed by a fine-grain approach to\nthe selection of a particular time-sync method. The resultant methodology may\nnot only have implications in the field of research, where practitioners may\nadopt this literature review as a baseline understanding of time\nsynchronisation methods and obstacles encountered toward LoRa, however\ndevelopers of applications for the LoRaWAN may adapt the analysed methods\noutlined within.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 01:17:01 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Jones", "Timothy", ""], ["Hasan", "Khondokar Fida", ""]]}, {"id": "2106.12178", "submitter": "Hossein Sadr", "authors": "Zeinab Khodaverdian, Hossein Sadr, Seyed Ahmad Edalatpanah and Mojdeh\n  Nazari Solimandarabi", "title": "Combination of Convolutional Neural Network and Gated Recurrent Unit for\n  Energy Aware Resource Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing service models have experienced rapid growth and inefficient\nresource usage is known as one of the greatest causes of high energy\nconsumption in cloud data centers. Resource allocation in cloud data centers\naiming to reduce energy consumption has been conducted using live migration of\nVirtual Machines (VMs) and their consolidation into the small number of\nPhysical Machines (PMs). However, the selection of the appropriate VM for\nmigration is an important challenge. To solve this issue, VMs can be classified\naccording to the pattern of user requests into sensitive or insensitive classes\nto latency, and thereafter suitable VMs can be selected for migration. In this\npaper, the combination of Convolution Neural Network (CNN) and Gated Recurrent\nUnit (GRU) is utilized for the classification of VMs in the Microsoft Azure\ndataset. Due to the fact the majority of VMs in this dataset are labeled as\ninsensitive to latency, migration of more VMs in this group not only reduces\nenergy consumption but also decreases the violation of Service Level Agreements\n(SLA). Based on the empirical results, the proposed model obtained an accuracy\nof 95.18which clearly demonstrates the superiority of our proposed model\ncompared to other existing models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 05:57:51 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Khodaverdian", "Zeinab", ""], ["Sadr", "Hossein", ""], ["Edalatpanah", "Seyed Ahmad", ""], ["Solimandarabi", "Mojdeh Nazari", ""]]}, {"id": "2106.12187", "submitter": "Rafael Diniz", "authors": "Rafael Diniz, Myl\\`ene C. Q. Farias", "title": "Enlaces de r\\'adio de longa dist\\^ancia utilizando a banda de HF", "comments": "in Portuguese. Article present at SET eXperience 2020. Video\n  presentation at: https://youtu.be/shkyEcHl7Fk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The interest in the use of the HF band in telecommunication has increased\nsignificantly in the last decade, mainly due to the development of new\nstandards for military telecommunications in HF, as well as the expansion of\ndigital broadcasting in the HF band. More specifically, these new standards\nallow the implementation of links of hundreds or thousands of kilometers at a\nlow cost, which suggests a widespread adoption can occur. In Brazil, this type\nof communication can be used in remote regions or regions of difficult access,\nsuch as the Amazon rain-forest region. In addition to the evolution of\ntechnologies concerning the physical layer of the HF telecommunication systems,\nthere has been a great development of techniques that use machine learning\nalgorithms for audio and image coding. It is believed that all these advances\nwill enable the use of the HF band for communication services in places without\ntelecommunication infrastructure. This work presents recent applications of HF\nradio for digital links in Brazil, describing the challenges present for the\ndevelopment of telecommunication systems in the HF band.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 06:25:12 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Diniz", "Rafael", ""], ["Farias", "Myl\u00e8ne C. Q.", ""]]}, {"id": "2106.12188", "submitter": "Onel Luis Alcaraz Lopez", "authors": "Onel L. A. L\\'opez, Dileep Kumar, Richard Demo Souza, Petar Popovski,\n  Antti T\\\"olli, Matti Latva-aho", "title": "Cell-Free Massive MIMO with Radio Stripes for Indoor Wireless Energy\n  Transfer", "comments": "Submitted to IEEE TWC. 32 pags, 13 figures, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio frequency wireless energy transfer (WET) is a promising solution for\npowering autonomous IoT deployments. Recent works on WET have mainly focused on\nextremely low-power/cost IoT applications. However, trending technologies such\nas energy beamforming and waveform optimization, distributed and massive\nantenna systems, smart reflect arrays and reconfigurable metasurfaces, flexible\nenergy transmitters, and mobile edge computing, may broaden WET applicability,\nand turn it plausible for powering more energy-hungry IoT devices. In this\nwork, we specifically leverage energy beamforming for powering multiple user\nequipments (UEs) with stringent energy harvesting (EH) demands in an indoor\ncell-free massive MIMO. Based on semi-definite programming, successive convex\napproximation (SCA), and maximum ratio transmission (MRT) techniques, we derive\noptimal and sub-optimal precoders aimed at minimizing the radio stripes'\ntransmit power while exploiting information of the power transfer efficiency of\nthe EH circuits at the UEs. Moreover, we propose an analytical framework to\nassess and control the electromagnetic field (EMF) radiation exposure in the\nconsidered indoor scenario. Numerical results show that i) the EMF radiation\nexposure can be more easily controlled at higher frequencies at the cost of a\nhigher transmit power consumption, ii) training is not a very critical factor\nfor the considered indoor system, iii) MRT/SCA-based precoders are particularly\nappealing when serving a small number of UEs, thus, specially suitable for\nimplementation in a time domain multiple access (TDMA) scheduling framework,\nand iv) TDMA is more efficient than spatial domain multiple access (SDMA) when\nserving a relatively small number of UEs. Results suggest that additional\nboosting performance strategies are needed to increase the overall system\nefficiency, thus making the technology viable in practice.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 06:25:15 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["L\u00f3pez", "Onel L. A.", ""], ["Kumar", "Dileep", ""], ["Souza", "Richard Demo", ""], ["Popovski", "Petar", ""], ["T\u00f6lli", "Antti", ""], ["Latva-aho", "Matti", ""]]}, {"id": "2106.12454", "submitter": "Jan Grash\\\"ofer", "authors": "Jan Grash\\\"ofer, Peter Oettig, Robin Sommer, Tim Wojtulewicz, Hannes\n  Hartenstein", "title": "Advancing Protocol Diversity in Network Security Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With information technology entering new fields and levels of deployment,\ne.g., in areas of energy, mobility, and production, network security monitoring\nneeds to be able to cope with those environments and their evolution. However,\nstate-of-the-art Network Security Monitors (NSMs) typically lack the necessary\nflexibility to handle the diversity of the packet-oriented layers below the\nabstraction of TCP/IP connections. In this work, we advance the software\narchitecture of a network security monitor to facilitate the flexible\nintegration of lower-layer protocol dissectors while maintaining required\nperformance levels. We proceed in three steps: First, we identify the\nchallenges for modular packet-level analysis, present a refined NSM\narchitecture to address them and specify requirements for its implementation.\nSecond, we evaluate the performance of data structures to be used for protocol\ndispatching, implement the proposed design into the popular open-source NSM\nZeek and assess its impact on the monitor performance. Our experiments show\nthat hash-based data structures for dispatching introduce a significant\noverhead while array-based approaches qualify for practical application.\nFinally, we demonstrate the benefits of the proposed architecture and\nimplementation by migrating Zeek's previously hard-coded stack of link and\ninternet layer protocols to the new interface. Furthermore, we implement\ndissectors for non-IP based industrial communication protocols and leverage\nthem to realize attack detection strategies from recent applied research. We\nintegrate the proposed architecture into the Zeek open-source project and\npublish the implementation to support the scientific community as well as\npractitioners, promoting the transfer of research into practice.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 15:03:10 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Grash\u00f6fer", "Jan", ""], ["Oettig", "Peter", ""], ["Sommer", "Robin", ""], ["Wojtulewicz", "Tim", ""], ["Hartenstein", "Hannes", ""]]}, {"id": "2106.12553", "submitter": "Emmanuel Baccelli", "authors": "Koen Zandberg, Emmanuel Baccelli", "title": "Femto-Containers: DevOps on Microcontrollers with Lightweight\n  Virtualization & Isolation for IoT Software Modules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NI cs.OS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Development, deployment and maintenance of networked software has been\nrevolutionized by DevOps practices, which boost system software quality and\nagile evolution. However, as the Internet of Things (IoT) connects low-power,\nmicrocontroller-based devices which take part in larger distributed\ncyberphysical systems, such low-power IoT devices are not easy to integrate in\nDevOps workflows. In this paper, we contribute to mitigate this problem by\ndesigning Femto-Containers, a new hardware-independent mechanism which enable\nthe virtualization and isolation of software modules embedded on\nmicrocontrollers, using an approach extending and adapting Berkeley Packet\nFilters (eBPF). We implement a Femto-Container hosting engine, which we\nintegrate in a common low-power IoT operating system (RIOT), and is thus\nenhanced with the ability to start, update or terminate Femto-Containers on\ndemand, securely over a standard IPv6/6LoWPAN network. We evaluate the\nperformance of Femto-Containers in a variety of use cases. We show that\nFemto-Containers can virtualize and isolate multiple software modules executed\nconcurrently, with very small memory footprint overhead (below 10%) and very\nsmall startup time (tens of microseconds) compared to native code execution. We\ncarry out experiments deploying Femto-Containers on a testbed using\nheterogeneous IoT hardware based on the popular microcontroller architectures\nArm Cortex-M, ESP32 and RISC-V. We show that compared to prior work on\nsoftware-based low-power virtualization and isolation, Femto-Containers offer\nan attractive trade-off in terms of memory footprint, energy consumption, and\nsecurity. The characteristics of Femto-Containers satisfy both the requirements\nof software modules hosting high-level logic coded in a variety of common\nprogramming languages, and the constraints of low-level debug snippets inserted\non a hot code path.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 10:54:29 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zandberg", "Koen", ""], ["Baccelli", "Emmanuel", ""]]}, {"id": "2106.12556", "submitter": "\\c{C}a\\u{g}kan Yapar", "authors": "\\c{C}a\\u{g}kan Yapar, Ron Levie, Gitta Kutyniok, Giuseppe Caire", "title": "Real-time Outdoor Localization Using Radio Maps: A Deep Learning\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of localization in a cellular network in a\ndense urban scenario. Global Navigation Satellite Systems typically perform\npoorly in urban environments, where the likelihood of line-of-sight conditions\nbetween the devices and the satellites is low, and thus alternative\nlocalization methods are required for good accuracy. We present a deep learning\nmethod for localization, based merely on pathloss, which does not require any\nincrease in computation complexity at the user devices with respect to the\ndevice standard operations, unlike methods that rely on time of arrival or\nangle of arrival information. In a wireless network, user devices scan the base\nstation beacon slots and identify the few strongest base station signals for\nhandover and user-base station association purposes. In the proposed method,\nthe user to be localized simply reports such received signal strengths to a\ncentral processing unit, which may be located in the cloud. For each base\nstation we have good approximation of the pathloss at every location in a dense\ngrid in the map. This approximation is provided by RadioUNet, a deep\nlearning-based simulator of pathloss functions in urban environment, that we\nhave previously proposed and published. Using the estimated pathloss radio maps\nof all base stations and the corresponding reported signal strengths, the\nproposed deep learning algorithm can extract a very accurate localization of\nthe user. The proposed method, called LocUNet, enjoys high robustness to\ninaccuracies in the estimated radio maps. We demonstrate this by numerical\nexperiments, which obtain state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 17:27:04 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Yapar", "\u00c7a\u011fkan", ""], ["Levie", "Ron", ""], ["Kutyniok", "Gitta", ""], ["Caire", "Giuseppe", ""]]}, {"id": "2106.12684", "submitter": "Darius Saif", "authors": "Darius Saif, Ashraf Matrawy", "title": "A Pure HTTP/3 Alternative to MQTT-over-QUIC in Resource-Constrained IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this letter, we address the issue of scalable and timely dissemination of\ninformation in resource-constrained IoT networks. The scalability is addressed\nby adopting a publishsubscribe architecture. To address the timely\ndissemination, we propose an HTTP/3 (H3) publish-subscribe solution that\nexploits the wide-ranging improvements offered by H3. We evaluated our solution\nby comparing it to a state-of-the-art work which maps MQTT to QUIC. Because\nQUIC and H3 have been developed in tandem, we hypothesized that H3 would take\nbetter advantage of QUIC transport than an MQTT mapping would. Performance,\nnetwork overhead, and device overhead were investigated for both\nimplementations. Our H3-based solution satisfied our timely dissemination\nrequirement by offering a key performance savings of 1 RoundTrip Time (RTT) for\npublish messages to arrive at the broker. In IoT networks, with typically high\nRTT, this savings is significant. On the other hand, we found that\nMQTT-over-QUIC put marginally less strain over the network.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 23:17:38 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Saif", "Darius", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "2106.12693", "submitter": "Niloofar Bayat", "authors": "Niloofar Bayat and Weston Jackson and Derrick Liu", "title": "Deep Learning for Network Traffic Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Monitoring network traffic to identify content, services, and applications is\nan active research topic in network traffic control systems. While modern\nfirewalls provide the capability to decrypt packets, this is not appealing for\nprivacy advocates. Hence, identifying any information from encrypted traffic is\na challenging task. Nonetheless, previous work has identified machine learning\nmethods that may enable application and service identification. The process\ninvolves high level feature extraction from network packet data then training a\nrobust machine learning classifier for traffic identification. We propose a\nclassification technique using an ensemble of deep learning architectures on\npacket, payload, and inter-arrival time sequences. To our knowledge, this is\nthe first time such deep learning architectures have been applied to the Server\nName Indication (SNI) classification problem. Our ensemble model beats the\nstate of the art machine learning methods and our up-to-date model can be found\non github: \\url{https://github.com/niloofarbayat/NetworkClassification}\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 04:11:32 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bayat", "Niloofar", ""], ["Jackson", "Weston", ""], ["Liu", "Derrick", ""]]}, {"id": "2106.12805", "submitter": "Weiheng Jiang", "authors": "Jingfu Li (1), Wenjiang Feng (1) and Weiheng Jiang (1) ((1) the School\n  of Microelectronics and Communication Engineering, Chongqing University)", "title": "Retrospective Interference Regeneration Schemes for Relay-Aided K-user\n  MIMO Broadcast Networks", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a novel method to increase channel capacity of networks, interference\nalignment (IA) technique has attracted wide attention in fifth-generation\nwireless networks (5G). However, when it is applied in interference networks,\nthe problem about information delay arises which has not been noticed yet. In\nthis paper, we first propose degree of delay (DoD) to quantify the issue of\ninformation delay, and characterize DoD for three typical transmission schemes,\ni.e., TDMA, beamforming based TDMA (BD-TDMA) and retrospective interference\nalignment (RIA). By analyzing DoD of these schemes, its value mainly depends on\nthree factors, i.e., delay sensitive factor, queueing delay slot and size of\ndataset. Therefore, to improve queueing delay slot and reduce DoD, three novel\njoint IA schemes are proposed for BC networks with different amounts of users.\nThat is, hybrid antenna array based partial interference elimination and\nretrospective interference regeneration scheme (HAA-PIE-RIR), HAA based\nimproved PIE and RIR scheme (HAA-IPIE-RIR) and HAA based cyclic interference\nelimination and RIR scheme (HAA-CIE-RIR). The second scheme extends the\napplication scenarios of the first scheme from 2-user to K-user while brings\nhuge computational burden. The third scheme relieves this computational\ncomplexity burden but it has somewhat degree of freedom (DoF) loss. Overall,\nthe performances of proposed schemes are all superior to that of traditional IA\ntechniques in DoF and DoD.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 07:42:30 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Li", "Jingfu", ""], ["Feng", "Wenjiang", ""], ["Jiang", "Weiheng", ""]]}, {"id": "2106.12883", "submitter": "Dongzi Jin", "authors": "Dongzi Jin, Yong Xiao, Yingyu Li, Guangming Shi, Dusit Niyato", "title": "Optimizing Intelligent Reflecting Surface-Base Station Association for\n  Mobile Networks", "comments": "This paper has been accepted by ICC 2021 I", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies a multi-Intelligent Reflecting Surfaces (IRSs)-assisted\nwireless network consisting of multiple base stations (BSs) serving a set of\nmobile users. We focus on the IRS-BS association problem in which multiple BSs\ncompete with each other for controlling the phase shifts of a limited number of\nIRSs to maximize the long-term downlink data rate for the associated users. We\npropose MDLBI, a Multi-agent Deep Reinforcement Learning-based BS-IRS\nassociation scheme that optimizes the BS-IRS association as well as the\nphase-shift of each IRS when being associated with different BSs. MDLBI does\nnot require information exchanging among BSs. Simulation results show that\nMDLBI achieves significant performance improvement and is scalable for large\nnetworking systems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 09:06:50 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Jin", "Dongzi", ""], ["Xiao", "Yong", ""], ["Li", "Yingyu", ""], ["Shi", "Guangming", ""], ["Niyato", "Dusit", ""]]}, {"id": "2106.12884", "submitter": "Peshal Nayak", "authors": "Peshal Nayak, Sudhanshu Verma, Preetam Kumar", "title": "A Novel Compact Tri-Band Antenna Design for WiMAX, WLAN and Bluetooth\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A novel and compact tri-band planar antenna for 2.4/5.2/5.8-GHz wireless\nlocal area network (WLAN), 2.3/3.5/5.5GHz Worldwide Interoperability for\nMicrowave Access (WiMAX) and Bluetooth applications is proposed and studied in\nthis paper. The antenna comprises of a L-shaped element which is coupled with a\nground shorted parasitic resonator to generate three resonant modes for\ntri-band operation. The L-shaped element which is placed on top of the\nsubstrate is fed by a 50$\\Omega$ microstrip feed line and is responsible for\nthe generation of a wide band at 5.5 GHz. The parasitic resonator is placed on\nthe other side of the substrate and is directly connected to the ground plane.\nThe presence of the parasitic resonator gives rise to two additional resonant\nbands at 2.3 GHz and 3.5 GHz. Thus, together the two elements generate three\nresonant bands to cover WLAN, WiMAX and Bluetooth bands of operation. A\nthorough parametric study has been performed on the antenna and it has been\nfound that the three bands can be tuned by varying certain dimensions of the\nantenna. Hence, the same design can be used for frequencies in adjacent bands\nas well with minor changes in its dimensions. Important antenna parameters such\nas return loss, radiation pattern and peak gains in the operating bands have\nbeen studied in detail to prove that the proposed design is a promising\ncandidate for the aforementioned wireless technologies.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 18:19:52 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Nayak", "Peshal", ""], ["Verma", "Sudhanshu", ""], ["Kumar", "Preetam", ""]]}, {"id": "2106.12968", "submitter": "Osmel Mart\\'inez Rosabal", "authors": "Osmel Mart\\'inez Rosabal, Onel L. Alcaraz L\\'opez, Hirley Alves,\n  Richard D. Souza, Samuel Montejo-S\\'anchez", "title": "Massive Wireless Energy Transfer with Multiple Power Beacons for very\n  large Internet of Things", "comments": "7 pages, 6 figures, Submitted to \"The International Workshop on Very\n  Large Internet of Things (2021)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) comprises an increasing number of low-power and\nlow-cost devices that autonomously interact with the surrounding environment.\nAs a consequence of their popularity, future IoT deployments will be massive,\nwhich demands energy-efficient systems to extend their lifetime and improve the\nuser experience. Radio frequency wireless energy transfer has the potential of\npowering massive IoT networks, thus eliminating the need for frequent battery\nreplacement by using the so-called power beacons (PBs). In this paper, we\nprovide a framework for minimizing the sum transmit power of the PBs using\ndevices' positions information and their current battery state. Our strategy\naims to reduce the PBs' power consumption and to mitigate the possible impact\nof the electromagnetic radiation on human health. We also present analytical\ninsights for the case of very distant clusters and evaluate their\napplicability. Numerical results show that our proposed framework reduces the\noutage probability as the number of PBs and/or the energy demands increase.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 12:38:08 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Rosabal", "Osmel Mart\u00ednez", ""], ["L\u00f3pez", "Onel L. Alcaraz", ""], ["Alves", "Hirley", ""], ["Souza", "Richard D.", ""], ["Montejo-S\u00e1nchez", "Samuel", ""]]}, {"id": "2106.13022", "submitter": "Weiheng Jiang", "authors": "Jingfu Li (1), Wenjiang Feng (1), F. Richard Yu (2), Weiheng Jiang (1)\n  ((1) the School of Microelectronics and Communication Engineering, Chongqing\n  University (2) the Department of System and Computer Engineering, Carleton\n  University)", "title": "Two New Kinds of Interference Alignment Schemes for Cellular K-user MIMO\n  Downlink Networks", "comments": "16 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is known that interference alignment (IA) plays an important role in\nimproving the degree of freedom (DoF) of multi-input and multi-output (MIMO)\nsystems. However, most of the traditional IA schemes suffer from the high\ncomputational complexity and require the global and instantaneous channel state\ninformation (CSI), both of which make them difficult to be extended to cellular\nMIMO systems. To handle these issues, two new interference alignment schemes,\ni.e., the retrospective interference regeneration (RIR) scheme and the\nbeamforming based distributed retrospective interference alignment (B-DRIA)\nscheme, are proposed for cellular K-user MIMO downlink networks. For the RIR\nscheme, it adopts interference elimination algorithm to erase redundant symbols\nin inter-cell interference (ICI) signals, and then uses interference\nregeneration algorithm to avoid secondary interference. The RIR scheme obtains\ngreater DoF gain than the retrospective interference alignment (RIA) scheme,\nbut incurs performance degradation when the transceiver antennas ratio (TAR)\napproaches 1. Therefore, the B-DRIA scheme is further proposed. For the B-DRIA\nscheme, the cellular beamforming matrix is introduced to eliminate the ICI, and\nmeanwhile distributed retrospective interference alignment algorithm is adopted\nto align inter-user interference (IUI). The simulation results show that the\nB-DRIA scheme obtains larger DoF than the RIR scheme locally. Specifically,\nwhen TAR approaches 1, two schemes obtain the same DoF. While TAR approaches 2,\nthe DoF of the B-DRIA scheme is superior than the RIR scheme.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 14:31:11 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Li", "Jingfu", ""], ["Feng", "Wenjiang", ""], ["Yu", "F. Richard", ""], ["Jiang", "Weiheng", ""]]}, {"id": "2106.13232", "submitter": "Peshal Nayak", "authors": "Peshal B. Nayak, Ramu Endluri, Sudhanshu Verma and Preetam Kumar", "title": "A Novel Compact Dual-Band Antenna Design for WLAN Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A novel and compact dual band planar antenna for 2.4/5.2/5.8-GHz wireless\nlocal area network(WLAN) applications is proposed and studied in this paper.\nThe antenna comprises of a T-shaped and a F-shaped element to generate two\nresonant modes for dual band operation. The two elements can independently\ncontrol the operating frequencies of the two excited resonant modes. The\nT-element which is fed directly by a 50 $\\Omega$ microstrip line generates a\nfrequency band at around 5.2 GHz and the antenna parameters can be adjusted to\ngenerate a frequency band at 5.8 GHz as well, thus covering the two higher\nbands of WLAN systems individually. By couple-feeding the F-element through the\nT-element, a frequency band can be generated at 2.4 GHz to cover the lower band\nof WLAN system. Hence, the two elements together are very compact with a total\narea of only 11$\\times$6.5 mm$^{2}$. A thorough parametric study of key\ndimensions in the design has been performed and the results obtained have been\nused to present a generalized design approach. Plots of the return loss and\nradiation pattern have been given and discussed in detail to show that the\ndesign is a very promising candidate for WLAN applications.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 23:27:38 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Nayak", "Peshal B.", ""], ["Endluri", "Ramu", ""], ["Verma", "Sudhanshu", ""], ["Kumar", "Preetam", ""]]}, {"id": "2106.13286", "submitter": "Ren\\'e S{\\o}rensen", "authors": "Andr\\'e S{\\o}rensen, Hua Wang, Maxime J\\'er\\^ome Remy, Nicolaj\n  Kjettrup, Ren\\'e Brandborg S{\\o}rensen, Jimmy Jessen Nielsen, Petar Popovsky,\n  Germ\\'an Corrales Madue\\~no", "title": "A Modelling and Experimental Framework for Battery Lifetime Estimation\n  in NB-IoT and LTE-M", "comments": "submitted to IEEE Internet of Things Journal, 12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable large-scale Internet of Things (IoT) deployment, Low-power\nwide-area networking (LPWAN) has attracted a lot of research attention with the\ndesign objectives of low-power consumption, wide-area coverage, and low cost.\nIn particular, long battery lifetime is central to these technologies since\nmany of the IoT devices will be deployed in hard-toaccess locations. Prediction\nof the battery lifetime depends on the accurate modelling of power consumption.\nThis paper presents detailed power consumption models for two cellular IoT\ntechnologies: Narrowband Internet of Things (NB-IoT) and Long Term Evolution\nfor Machines (LTE-M). A comprehensive power consumption model based on User\nEquipment (UE) states and procedures for device battery lifetime estimation is\npresented. An IoT device power measurement testbed has been setup and the\nproposed model has been validated via measurements with different coverage\nscenarios and traffic configurations, achieving the modelling inaccuracy within\n5%. The resulting estimated battery lifetime is promising, showing that the\n10-year battery lifetime requirement specified by 3GPP can be met with proper\nconfiguration of traffic profile, transmission, and network parameters.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 19:21:02 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["S\u00f8rensen", "Andr\u00e9", ""], ["Wang", "Hua", ""], ["Remy", "Maxime J\u00e9r\u00f4me", ""], ["Kjettrup", "Nicolaj", ""], ["S\u00f8rensen", "Ren\u00e9 Brandborg", ""], ["Nielsen", "Jimmy Jessen", ""], ["Popovsky", "Petar", ""], ["Madue\u00f1o", "Germ\u00e1n Corrales", ""]]}, {"id": "2106.13306", "submitter": "Dingwen Tao", "authors": "Chengming Zhang, Sian Jin, Tong Geng, Jiannan Tian, Ang Li, Dingwen\n  Tao", "title": "CEAZ: Accelerating Parallel I/O via Hardware-Algorithm Co-Design of\n  Efficient and Adaptive Lossy Compression", "comments": "14 pages, 17 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As supercomputers continue to grow to exascale, the amount of data that needs\nto be saved or transmitted is exploding. To this end, many previous works have\nstudied using error-bounded lossy compressors to reduce the data size and\nimprove the I/O performance. However, little work has been done for effectively\noffloading lossy compression onto FPGA-based SmartNICs to reduce the\ncompression overhead. In this paper, we propose a hardware-algorithm co-design\nof efficient and adaptive lossy compressor for scientific data on FPGAs (called\nCEAZ) to accelerate parallel I/O. Our contribution is fourfold: (1) We propose\nan efficient Huffman coding approach that can adaptively update Huffman\ncodewords online based on codewords generated offline (from a variety of\nrepresentative scientific datasets). (2) We derive a theoretical analysis to\nsupport a precise control of compression ratio under an error-bounded\ncompression mode, enabling accurate offline Huffman codewords generation. This\nalso helps us create a fixed-ratio compression mode for consistent throughput.\n(3) We develop an efficient compression pipeline by adopting cuSZ's\ndual-quantization algorithm to our hardware use case. (4) We evaluate CEAZ on\nfive real-world datasets with both a single FPGA board and 128 nodes from\nBridges-2 supercomputer. Experiments show that CEAZ outperforms the second-best\nFPGA-based lossy compressor by 2X of throughput and 9.6X of compression ratio.\nIt also improves MPI_File_write and MPI_Gather throughputs by up to 25.8X and\n24.8X, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 20:26:52 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Zhang", "Chengming", ""], ["Jin", "Sian", ""], ["Geng", "Tong", ""], ["Tian", "Jiannan", ""], ["Li", "Ang", ""], ["Tao", "Dingwen", ""]]}, {"id": "2106.13476", "submitter": "Zhen Gao", "authors": "Malong Ke, Zhen Gao, Yang Huang, Guoru Ding, Derrick Wing Kwan Ng,\n  Qihui Wu, and Jun Zhang", "title": "An Edge Computing Paradigm for Massive IoT Connectivity over\n  High-Altitude Platform Networks", "comments": "8 pages, 6 figures. The current version has been accepted by IEEE\n  Wireless Communications Magzine Special Issue on Aerial Computing: Drones for\n  Multi-Access Edge Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of the Internet-of-Things (IoT) era, the ever-increasing\nnumber of devices and emerging applications have triggered the need for\nubiquitous connectivity and more efficient computing paradigms. These stringent\ndemands have posed significant challenges to the current wireless networks and\ntheir computing architectures. In this article, we propose a high-altitude\nplatform (HAP) network-enabled edge computing paradigm to tackle the key issues\nof massive IoT connectivity. Specifically, we first provide a comprehensive\noverview of the recent advances in non-terrestrial network-based edge computing\narchitectures. Then, the limitations of the existing solutions are further\nsummarized from the perspectives of the network architecture, random access\nprocedure, and multiple access techniques. To overcome the limitations, we\npropose a HAP-enabled aerial cell-free massive multiple-input multiple-output\nnetwork to realize the edge computing paradigm, where multiple HAPs cooperate\nvia the edge servers to serve IoT devices. For the case of a massive number of\ndevices, we further adopt a grant-free massive access scheme to guarantee\nlow-latency and high-efficiency massive IoT connectivity to the network.\nBesides, a case study is provided to demonstrate the effectiveness of the\nproposed solution. Finally, to shed light on the future research directions of\nHAP network-enabled edge computing paradigms, the key challenges and open\nissues are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 07:41:16 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Ke", "Malong", ""], ["Gao", "Zhen", ""], ["Huang", "Yang", ""], ["Ding", "Guoru", ""], ["Ng", "Derrick Wing Kwan", ""], ["Wu", "Qihui", ""], ["Zhang", "Jun", ""]]}, {"id": "2106.13478", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen, Joonas Salovaara, Ville Lepp\\\"anen", "title": "Crossing Cross-Domain Paths in the Current Web", "comments": "Proceedings of the 16th Annual Conference on Privacy, Security and\n  Trust (PST 2018), Belfast, IEEE, pp. 1-5", "journal-ref": null, "doi": "10.1109/PST.2018.8514163", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loading of resources from third-parties has evoked new security and\nprivacy concerns about the current world wide web. Building on the concepts of\nforced and implicit trust, this paper examines cross-domain transmission\ncontrol protocol (TCP) connections that are initiated to domains other than the\ndomain queried with a web browser. The dataset covers nearly ten thousand\ndomains and over three hundred thousand TCP connections initiated by querying\npopular Finnish websites and globally popular sites. According to the results,\n(i) cross-domain connections are extremely common in the current Web. (ii) Most\nof these transmit encrypted content, although mixed content delivery is\nrelatively common; many of the cross-domain connections deliver unencrypted\ncontent at the same time. (iii) Many of the cross-domain connections are\ninitiated to known web advertisement domains, but a much larger share traces to\nsocial media platforms and cloud infrastructures. Finally, (iv) the results\ndiffer slightly between the Finnish web sites sampled and the globally popular\nsites. With these results, the paper contributes to the ongoing work for better\nunderstanding cross-domain connections and dependencies in the world wide web.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 07:51:01 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Ruohonen", "Jukka", ""], ["Salovaara", "Joonas", ""], ["Lepp\u00e4nen", "Ville", ""]]}, {"id": "2106.13710", "submitter": "Ike Kunze", "authors": "Ike Kunze and Klaus Wehrle and Jan R\\\"uth", "title": "L, Q, R, and T -- Which Spin Bit Cousin Is Here to Stay?", "comments": null, "journal-ref": null, "doi": "10.1145/3472305.3472319", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network operators utilize traffic monitoring to locate and fix faults or\nperformance bottlenecks. This often relies on intrinsic protocol semantics,\ne.g., sequence numbers, that many protocols share implicitly through their\npacket headers. The arrival of (almost) fully encrypted transport protocols,\nsuch as QUIC, significantly complicates this monitoring as header data is no\nlonger visible to passive observers. Recognizing this challenge, QUIC offers\nexplicit measurement semantics by exposing the spin bit to measure a flow's\nRTT. Ongoing efforts in the IETF IPPM working group argue to expose further\ninformation and enable the passive quantification of packet loss. This work\nimplements and evaluates four currently proposed measurement techniques (L-,\nQ-, R-, and T-bit). We find that all techniques generally provide accurate loss\nestimations, but that longer algorithmic intervals for Q and R, yet foremost\nfor T, complicate detecting very small loss rates or loss on short connections.\nDeployment combinations of Q & R as well as Q & L, thus, have the best\npotential for accurately grasping the loss in networks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 15:50:23 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Kunze", "Ike", ""], ["Wehrle", "Klaus", ""], ["R\u00fcth", "Jan", ""]]}, {"id": "2106.13896", "submitter": "Alireza Khodaei", "authors": "Alireza Khodaei and Jitender Deogun", "title": "Optical MIMO Communication Using Holographic Spectral Multiplexing of\n  Pulsed Ultrashort Laser", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we introduce Holographic Spectral Multiplexing (HSM) as a\nnovel technique to enable multiple-input multiple-output (MIMO) communication\nin optical networks. HSM uses the spectral space of ultrashort laser pulses to\ncreate line codes in the form of 2D holograms. The pulse processing is\nperformed in the temporal Fourier domain by spatially dispersing the pulse\nfrequency components in a spectral processing device (SPD). The 2D holograms\nare composed of the patterns of intensity disparities that an SLM inscribes on\nthe spectrally-decomposed Fourier plane of the pulse. The holographic line\ncodes defined in this way transform the ultrashort laser pulses into\nhigh-entropy data symbols, hence, enhance the communication's spectral\nefficiency. Unlike conventional optical multiplexing schemes (e.g., TDM, WDM,\nor SDM), HSM does not physically or abstractly separate the communication\npropagation space into subchannels. Rather, HSM realizes a MIMO communication\nparadigm by allowing the photonic waves under the pulse envelope to propagate\nin the same space so they scatter and interfere by chromatic dispersion. This\nallows HSM to form beams between the pixels of SLM at the sender and receiver\nsides and optimize the beam to adapt to channel scattering situations. In this\nway, HSM delivers a rate gain that in the best case exponentially increases the\ninformation rate of communication.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 21:57:55 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Khodaei", "Alireza", ""], ["Deogun", "Jitender", ""]]}, {"id": "2106.13917", "submitter": "Furqan Ahmed", "authors": "Furqan Ahmed and Petri M\\\"ah\\\"onen", "title": "Quantum Computing for Artificial Intelligence Based Mobile Network\n  Optimization", "comments": "Accepted in 2021 IEEE 32nd Annual International Symposium on\n  Personal, Indoor and Mobile Radio Communications (PIMRC) - Track 4: Mobile\n  and Wireless Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we discuss how certain radio access network optimization\nproblems can be modelled using the concept of constraint satisfaction problems\nin artificial intelligence, and solved at scale using a quantum computer. As a\ncase study, we discuss root sequence index (RSI) assignment problem - an\nimportant LTE/NR physical random access channel configuration related\nautomation use-case. We formulate RSI assignment as quadratic unconstrained\nbinary optimization (QUBO) problem constructed using data ingested from a\ncommercial mobile network, and solve it using a cloud-based commercially\navailable quantum computing platform. Results show that quantum annealing\nsolver can successfully assign conflict-free RSIs. Comparison with well-known\nheuristics reveals that some classic algorithms are even more effective in\nterms of solution quality and computation time. The non-quantum advantage is\ndue to the fact that current implementation is a semi-quantum proof-of-concept\nalgorithm. Also, the results depend on the type of quantum computer used.\nNevertheless, the proposed framework is highly flexible and holds tremendous\npotential for harnessing the power of quantum computing in mobile network\nautomation.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 01:05:43 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ahmed", "Furqan", ""], ["M\u00e4h\u00f6nen", "Petri", ""]]}, {"id": "2106.13950", "submitter": "Amin Farajzadeh", "authors": "Amin Farajzadeh, Mohammad G. Khoshkholgh, Halim Yanikomeroglu, Ozgur\n  Ercetin", "title": "Self-Evolving Integrated Vertical Heterogeneous Networks", "comments": "23 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:1901.07955, arXiv:2006.02931 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of future networks into fully autonomous entities appears\ninevitable. The need for greater operational agility in supporting a wide range\nof services and use cases together with increasing network complexity creates,\nin all likelihood, unforeseen new challenges. 6G and beyond networks will have\na disruptive architecture imposing some crucial requirements: 1) Support\nuniversal access to intelligence sustained by a distributed computing, sensing,\nand control infrastructure; 2) manage with a unified framework of a\nheterogeneous communication, computing, caching, and control infrastructure; 3)\nsupport highly dynamic and possibly intermittent networks of vertical networks.\nThis study first advocates the merits of integrated vertical heterogeneous\nnetwork (VHetNet) architecture in support of 6G infrastructure. We then review\nthe current literature on network management of vertical networks and discuss a\nunified network management framework to analyze new architecture-dependent\nchallenges and their coordination with existing network management services and\nrequirements. Third, we investigate recent advancements in artificial\nintelligence (AI)/machine learning (ML) methods in current VHetNets and discuss\nthe core challenges of integrating AI/ML in VHetNets. Finally, we discuss\npotential future research directions for advancing the autonomous and evolving\ncapabilities of VHetNets.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 05:57:06 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Farajzadeh", "Amin", ""], ["Khoshkholgh", "Mohammad G.", ""], ["Yanikomeroglu", "Halim", ""], ["Ercetin", "Ozgur", ""]]}, {"id": "2106.14100", "submitter": "Ahmed M. Abdelmoniem", "authors": "Ahmed M. Abdelmoniem and Brahim Bensaou", "title": "Implementation and Evaluation of Data Center Congestion Controller with\n  Switch Assistance", "comments": "arXiv admin note: text overlap with arXiv:2012.00339", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide the design and implementation of a switch-assisted\ncongestion control algorithm for data center networks (DCNs). In particular, we\nprovide a prototype of the switch-driven congestion control algorithm and\ndeploy it in a real data center. The prototype is based on few simple\nmodifications to the switch software. The modifications imposed by the\nalgorithm on the switch are to enable the switch to modify the TCP\nreceive-window field in the packet headers. By doing so, the algorithm can\nenforce a pre-calculated (or target rate) to limit the sending rate at the\nsources. Therefore, the algorithm requires no modifications to the TCP source\nor receiver code which considered out of the DCN operators' control (e.g., in\nthe public cloud where the VM is maintained by the tenant). This paper\ndescribes in detail two implementations, one as a Linux kernel module and the\nsecond as an added feature to the well-known software switch, Open vSwitch.\nThen we present evaluation results based on experiments of the deployment of\nboth designs in a small testbed to demonstrate the effectiveness of the\nproposed technique in achieving high throughput, good fairness, and short flow\ncompletion times for delay-sensitive flows.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 22:18:35 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Abdelmoniem", "Ahmed M.", ""], ["Bensaou", "Brahim", ""]]}, {"id": "2106.14149", "submitter": "Xu Wang Dr", "authors": "Xu Wang (1), Wei Ni (2), Xuan Zha (3), Guangsheng Yu (1), Ren Ping Liu\n  (1), Nektarios Georgalas (4), Andrew Reeves (4) ((1) Global Big Data\n  Technologies Centre, University of Technology Sydney, Australia, (2) Data61,\n  CSIRO, Australia, (3) China Academy of Information and Communications\n  Technology, Beijing, China, (4) Applied Research, British Telecom,\n  Martlesham, UK)", "title": "Capacity Analysis of Public Blockchain", "comments": null, "journal-ref": null, "doi": "10.1016/j.comcom.2021.06.019", "report-no": null, "categories": "cs.CR cs.DC cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As distributed ledgers, blockchains run consensus protocols which trade\ncapacity for consistency, especially in non-ideal networks with incomplete\nconnectivity and erroneous links. Existing studies on the tradeoff between\ncapacity and consistency are only qualitative or rely on specific assumptions.\nThis paper presents discrete-time Markov chain models to quantify the capacity\nof Proof-of-Work based public blockchains in non-ideal networks. The\ncomprehensive model is collapsed to be ergodic under the eventual consistency\nof blockchains, achieving tractability and efficient evaluations of blockchain\ncapacity. A closed-form expression for the capacity is derived in the case of\ntwo miners. Another important aspect is that we extend the ergodic model to\nanalyze the capacity under strong consistency, evaluating the robustness of\nblockchains against double-spending attacks. Validated by simulations, the\nproposed models are accurate and reveal the effect of link quality and the\ndistribution of mining rates on blockchain capacity and the ratio of stale\nblocks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 05:38:13 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wang", "Xu", ""], ["Ni", "Wei", ""], ["Zha", "Xuan", ""], ["Yu", "Guangsheng", ""], ["Liu", "Ren Ping", ""], ["Georgalas", "Nektarios", ""], ["Reeves", "Andrew", ""]]}, {"id": "2106.14229", "submitter": "Dian Fan", "authors": "Haoming Ma, Xiaojun Yuan, Dian Fan, Zhi Ding, Xin Wang", "title": "Multi-task Over-the-Air Federated Learning: A Non-Orthogonal\n  Transmission Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we propose a multi-task over-theair federated learning\n(MOAFL) framework, where multiple learning tasks share edge devices for data\ncollection and learning models under the coordination of a edge server (ES).\nSpecially, the model updates for all the tasks are transmitted and\nsuperpositioned concurrently over a non-orthogonal uplink channel via\nover-the-air computation, and the aggregation results of all the tasks are\nreconstructed at the ES through an extended version of the turbo compressed\nsensing algorithm. Both the convergence analysis and numerical results\ndemonstrate that the MOAFL framework can significantly reduce the uplink\nbandwidth consumption of multiple tasks without causing substantial learning\nperformance degradation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 13:09:32 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 07:34:10 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ma", "Haoming", ""], ["Yuan", "Xiaojun", ""], ["Fan", "Dian", ""], ["Ding", "Zhi", ""], ["Wang", "Xin", ""]]}, {"id": "2106.14273", "submitter": "Hasan Ali Khattak", "authors": "Sidra Zafar, Mohsin Nazir, Taimur Bakhshi, Hasan Ali Khattak,\n  Sarmadullah Khan, Muhammad Bilal, Kim-Kwang Raymond Choo, Kyung-Sup Kwak7,\n  Aneeqa Sabah", "title": "A Systematic Review of Bio-Cyber Interface Technologies and Security\n  Issues for Internet of Bio-Nano Things", "comments": "41 pages, 9 tables, 6 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3093442", "report-no": null, "categories": "cs.NI cs.CR cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advances in synthetic biology and nanotechnology have contributed to the\ndesign of tools that can be used to control, reuse, modify, and re-engineer\ncells' structure, as well as enabling engineers to effectively use biological\ncells as programmable substrates to realize Bio-Nano Things (biological\nembedded computing devices). Bio-NanoThings are generally tiny, non-intrusive,\nand concealable devices that can be used for in-vivo applications such as\nintra-body sensing and actuation networks, where the use of artificial devices\ncan be detrimental. Such (nano-scale) devices can be used in various healthcare\nsettings such as continuous health monitoring, targeted drug delivery, and\nnano-surgeries. These services can also be grouped to form a collaborative\nnetwork (i.e., nanonetwork), whose performance can potentially be improved when\nconnected to higher bandwidth external networks such as the Internet, say via\n5G. However, to realize the IoBNT paradigm, it is also important to seamlessly\nconnect the biological environment with the technological landscape by having a\ndynamic interface design to convert biochemical signals from the human body\ninto an equivalent electromagnetic signal (and vice versa). This,\nunfortunately, risks the exposure of internal biological mechanisms to\ncyber-based sensing and medical actuation, with potential security and privacy\nimplications. This paper comprehensively reviews bio-cyber interface for IoBNT\narchitecture, focusing on bio-cyber interfacing options for IoBNT like\nbiologically inspired bio-electronic devices, RFID enabled implantable chips,\nand electronic tattoos. This study also identifies known and potential security\nand privacy vulnerabilities and mitigation strategies for consideration in\nfuture IoBNT designs and implementations.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 16:37:11 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zafar", "Sidra", ""], ["Nazir", "Mohsin", ""], ["Bakhshi", "Taimur", ""], ["Khattak", "Hasan Ali", ""], ["Khan", "Sarmadullah", ""], ["Bilal", "Muhammad", ""], ["Choo", "Kim-Kwang Raymond", ""], ["Kwak7", "Kyung-Sup", ""], ["Sabah", "Aneeqa", ""]]}, {"id": "2106.14315", "submitter": "Puneet Kumar", "authors": "Puneet Kumar", "title": "Point to Point Ethernet TransmissionWireless Backhaul Links Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Arxiv is acting weird and throwing error: \"Bad character(s) in field\nAbstract.\" for no reason. Please refer to the manuscript.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 19:49:13 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kumar", "Puneet", ""]]}, {"id": "2106.14356", "submitter": "Mithun Mukherjee", "authors": "Mian Guo and Chun Shan and Mithun Mukherjee and Jaime Lloret and\n  Quansheng Guan", "title": "Collaborative Edge Learning in MIMO-NOMA Uplink Transmission Environment", "comments": "5 pages, 3 figures, accepted for publication in IEEE/CIC ICCC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple-input multiple-output non-orthogonal multiple access (MIMO-NOMA)\ncellular network is promising for supporting massive connectivity. This paper\nexploits low-latency machine learning in the MIMO-NOMA uplink transmission\nenvironment, where a substantial amount of data must be uploaded from multiple\ndata sources to a one-hop away edge server for machine learning. A delay-aware\nedge learning framework with the collaboration of data sources, the edge\nserver, and the base station, referred to as DACEL, is proposed. Based on the\ndelay analysis of DACEL, a NOMA channel allocation algorithm is further\ndesigned to minimize the learning delay. The simulation results show that the\nproposed algorithm outperforms the baseline schemes in terms of learning delay\nreduction.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 00:47:27 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Guo", "Mian", ""], ["Shan", "Chun", ""], ["Mukherjee", "Mithun", ""], ["Lloret", "Jaime", ""], ["Guan", "Quansheng", ""]]}, {"id": "2106.14426", "submitter": "Debabrata Das", "authors": "Sharvari Ravindran, Saptarshi Chaudhuri, Jyotsna Bapat, Debabrata Das", "title": "Optimization Results for 5G Slice-in-Slice Scheduling", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Radio Access Network (ORAN) Slicing for 5G and Beyond is an emerging\narchitecture and feature that will facilitate challenging RAN Service Level\nAgreement (SLA) assurance targets. This could pave the way for operators to\nrealize the benefits of network slicing efficiently. In this paper, we provide\nnovel and detailed optimization results to achieve Slice-in-Slice Scheduling\nfor 5G User Services in ORAN slicing.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 07:14:05 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ravindran", "Sharvari", ""], ["Chaudhuri", "Saptarshi", ""], ["Bapat", "Jyotsna", ""], ["Das", "Debabrata", ""]]}, {"id": "2106.14666", "submitter": "Ginno Mill\\'an", "authors": "G. Mill\\'an, G. Lefranc, R. Osorio-Compar\\'an", "title": "The Associative Multifractal Process: A Novel Model for Computer Network\n  Traffic Flows", "comments": "4 pages, IEEE Networking Letters 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP physics.soc-ph", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A novel constructive mathematical model based on the multifractal formalism\nin order to accurately characterizing the localized fluctuations present in the\ncourse of traffic flows today high-speed computer networks is presented. The\nproposed model has the target to analyze self-similar second-order time series\nrepresentative of traffic flows in terms of their roughness and impulsivity.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 19:02:04 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Mill\u00e1n", "G.", ""], ["Lefranc", "G.", ""], ["Osorio-Compar\u00e1n", "R.", ""]]}, {"id": "2106.14727", "submitter": "Ke Li Kl", "authors": "Joseph Billingsley, Ke Li, Wang Miao, Geyong Min, Nektarios Georgalas", "title": "Evolutionary Multi-Objective Virtual Network Function Placement: A\n  Formal Model and Effective Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data centers are critical to the commercial and social activities of modern\nsociety but are also major electricity consumers. To minimize their\nenvironmental impact, it is imperative to make data centers more energy\nefficient while maintaining a high quality of service (QoS). Bearing this\nconsideration in mind, we develop an analytical model using queueing theory for\nevaluating the QoS of a data center. Furthermore, based on this model, we\ndevelop a domain-specific evolutionary optimization framework featuring a\ntailored solution representation and a constraint-aware initialization operator\nfor finding the optimal placement of virtual network functions in a data center\nthat optimizes multiple conflicting objectives with regard to energy\nconsumption and QoS. In particular, our framework is applicable to any existing\nevolutionary multi-objective optimization algorithm in a plug-in manner.\nExtensive experiments validate the efficiency and accuracy of our QoS model as\nwell as the effectiveness of our tailored algorithms for virtual network\nfunction placement problems at various scales.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 13:58:28 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Billingsley", "Joseph", ""], ["Li", "Ke", ""], ["Miao", "Wang", ""], ["Min", "Geyong", ""], ["Georgalas", "Nektarios", ""]]}, {"id": "2106.14750", "submitter": "Gabriele Santin", "authors": "E. Leoni and G. Cencetti and G. Santin and T. Istomin and D. Molteni\n  and G. P. Picco and E. Farella and B. Lepri and A. M. Murphy", "title": "Measuring close proximity interactions in summer camps during the\n  COVID-19 pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy makers have implemented multiple non-pharmaceutical strategies to\nmitigate the COVID-19 worldwide crisis. Interventions had the aim of reducing\nclose proximity interactions, which drive the spread of the disease. A deeper\nknowledge of human physical interactions has revealed necessary, especially in\nall settings involving children, whose education and gathering activities\nshould be preserved. Despite their relevance, almost no data are available on\nclose proximity contacts among children in schools or other educational\nsettings during the pandemic. Contact data are usually gathered via Bluetooth,\nwhich nonetheless offers a low temporal and spatial resolution. Recently,\nultra-wideband (UWB) radios emerged as a more accurate alternative that\nnonetheless exhibits a significantly higher energy consumption, limiting\nin-field studies. In this paper, we leverage a novel approach, embodied by the\nJanus system that combines these radios by exploiting their complementary\nbenefits. The very accurate proximity data gathered in-field by Janus, once\naugmented with several metadata, unlocks unprecedented levels of information,\nenabling the development of novel multi-level risk analyses. By means of this\ntechnology, we have collected real contact data of children and educators in\nthree summer camps during summer 2020 in the province of Trento, Italy. The\nwide variety of performed daily activities induced multiple individual\nbehaviors, allowing a rich investigation of social environments from the\ncontagion risk perspective. We consider risk based on duration and proximity of\ncontacts and classify interactions according to different risk levels. We can\nthen evaluate the summer camps' organization, observe the effect of partition\nin small groups, or social bubbles, and identify the organized activities that\nmitigate the riskier behaviors. [...]\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:26:18 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Leoni", "E.", ""], ["Cencetti", "G.", ""], ["Santin", "G.", ""], ["Istomin", "T.", ""], ["Molteni", "D.", ""], ["Picco", "G. P.", ""], ["Farella", "E.", ""], ["Lepri", "B.", ""], ["Murphy", "A. M.", ""]]}, {"id": "2106.14928", "submitter": "Qiqi Ren", "authors": "Qiqi Ren, Omid Abbasi, Gunes Karabulut Kurt, Halim Yanikomeroglu, and\n  Jian Chen", "title": "Caching and Computation Offloading in High Altitude Platform Station\n  (HAPS) Assisted Intelligent Transportation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge intelligence, which is a new paradigm to accelerate artificial\nintelligence (AI) applications by leveraging computing resources on the network\nedge, can be used to improve intelligent transportation systems (ITS). However,\ndue to physical limitations and energy-supply constraints, the computing powers\nof edge equipment are usually limited. High altitude platform station (HAPS)\ncomputing can be considered as a promising extension of edge computing. HAPS is\ndeployed in the stratosphere to provide wide coverage and strong computational\ncapabilities. It is suitable to coordinate terrestrial resources and store the\nfundamental data associated with ITS-based applications. In this work, three\ncomputing layers,i.e., vehicles, terrestrial network edges, and HAPS, are\nintegrated to build a computation framework for ITS, where the HAPS data\nlibrary stores the fundamental data needed for the applications. In addition,\nthe caching technique is introduced for network edges to store some of the\nfundamental data from the HAPS so that large propagation delays can be reduced.\nWe aim to minimize the delay of the system by optimizing computation offloading\nand caching decisions as well as bandwidth and computing resource allocations.\nThe simulation results highlight the benefits of HAPS computing for mitigating\ndelays and the significance of caching at network edges.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 18:17:44 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ren", "Qiqi", ""], ["Abbasi", "Omid", ""], ["Kurt", "Gunes Karabulut", ""], ["Yanikomeroglu", "Halim", ""], ["Chen", "Jian", ""]]}, {"id": "2106.14941", "submitter": "Firuz Kamalov", "authors": "Firuz Kamalov, Sherif Moussa, Rita Zgheib, Omar Mashaal", "title": "Feature selection for intrusion detection systems", "comments": "Accepted version of conference paper presented at ISCID 2020", "journal-ref": null, "doi": "10.1109/ISCID51228.2020.00065", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze existing feature selection methods to identify the\nkey elements of network traffic data that allow intrusion detection. In\naddition, we propose a new feature selection method that addresses the\nchallenge of considering continuous input features and discrete target values.\nWe show that the proposed method performs well against the benchmark selection\nmethods. We use our findings to develop a highly effective machine\nlearning-based detection systems that achieves 99.9% accuracy in distinguishing\nbetween DDoS and benign signals. We believe that our results can be useful to\nexperts who are interested in designing and building automated intrusion\ndetection systems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 18:53:21 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kamalov", "Firuz", ""], ["Moussa", "Sherif", ""], ["Zgheib", "Rita", ""], ["Mashaal", "Omar", ""]]}, {"id": "2106.15197", "submitter": "Kaifeng Han", "authors": "Zhiqin Wang, Kaifeng Han, Jiamo Jiang, Zhiqing Wei, Guangxu Zhu,\n  Zhiyong Feng, Jianmin Lu and Chunwei Meng", "title": "Symbiotic Sensing and Communications Towards 6G: Vision, Applications,\n  and Technology Trends", "comments": "5 pages, 3 figures, submitted to IEEE VTC 2021 Fall, Workshop on\n  Integrated Sensing and Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the vision of intelligent connection of everything and digital twin\ntowards 6G, a myriad of new applications, such as immersive extended reality,\nautonomous driving, holographic communications, intelligent industrial\ninternet, will emerge in the near future, holding the promise to revolutionize\nthe way we live and work. These trends inspire a novel technical design\nprinciple that seamlessly integrates two originally decoupled functionalities,\ni.e., wireless communication and sensing, into one system in a symbiotic way,\nwhich is dubbed symbiotic sensing and communications (SSaC), to endow the\nwireless network with the capability to \"see\" and \"talk\" to the physical world\nsimultaneously. Noting that the term SSaC is used instead of ISAC (integrated\nsensing and communications) because the word ``symbiotic/symbiosis\" is more\ninclusive and can better accommodate different integration levels and evolution\nstages of sensing and communications. Aligned with this understanding, this\narticle makes the first attempts to clarify the concept of SSaC, illustrate its\nvision, envision the three-stage evolution roadmap, namely neutralism,\ncommensalism, and mutualism of SaC. Then, three categories of applications of\nSSaC are introduced, followed by detailed description of typical use cases in\neach category. Finally, we summarize the major performance metrics and key\nenabling technologies for SSaC.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:31:26 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Wang", "Zhiqin", ""], ["Han", "Kaifeng", ""], ["Jiang", "Jiamo", ""], ["Wei", "Zhiqing", ""], ["Zhu", "Guangxu", ""], ["Feng", "Zhiyong", ""], ["Lu", "Jianmin", ""], ["Meng", "Chunwei", ""]]}, {"id": "2106.15229", "submitter": "Debabrata Das", "authors": "Sharvari Ravindran, Saptarshi Chaudhuri, Jyotsna Bapat, and Debabrata\n  Das", "title": "Predictive Dynamic Scaling Multi-Slice-in-Slice-Connected Users for 5G\n  System Resource Scheduling", "comments": "6 pages, 4 figures, Submitted to IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing is an effective 5G concept for improved resource utilization\nand service scalability tailored to users (UEs) requirements. According to the\nstandardization, 5G system should support UEs through specification of its\nheterogenous requirements such as, high data rates, traffic density, latency,\nreliability, UE density, system efficiency and service availability. These\nrequirements are specified as Service Level Agreements (SLAs) between UEs and\nnetwork operators resulting in increased interest to develop novel challenging\nmechanisms for improved interference-free resource efficient performances. An\nemerging concept that enables such demanding SLA assurances is Open-Radio\nAccess Network (O-RAN). In this paper, we study a novel resource scheduling\nproblem for UE services conditioned on other services in network slicing. To\nimprove system performance, we propose that UEs are connected across network\nslices to serve several applications. UEs of similar service classes (defined\nby SLAs) are grouped to form optimized slice-in-slice category(s) within\nnetwork slice(s).We propose novel Predictive Dynamic Scaling Multi-UE service\nspecific System Resource Optimized Scheduling (DMUSO) algorithm(s).\nMultiobjective multi-constraint optimization problems (MOP) are formed to learn\nthe dynamic system resource allocation and throughput for UE services\nconditioned on new services entering the network slice. An epsilon-constraint\nline search algorithm is presented to estimate UE service bandwidth. Using the\ntheoretical models, DMUSO forms optimal slice-in-slice categories and estimates\nthe maximum dynamic additional slice-in-slice categories, throughput served\nacross network slices. Finally, compared to state-of-the-art literatures, DMUSO\nguarantees UEs SLAs with 4.4 and 7.5 times performance gains\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 10:26:20 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ravindran", "Sharvari", ""], ["Chaudhuri", "Saptarshi", ""], ["Bapat", "Jyotsna", ""], ["Das", "Debabrata", ""]]}, {"id": "2106.15234", "submitter": "Hadi Khodabandeh", "authors": "David Eppstein, Hadi Khodabandeh", "title": "Optimal Spanners for Unit Ball Graphs in Doubling Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resolving an open question from 2006, we prove the existence of light-weight\nbounded-degree spanners for unit ball graphs in the metrics of bounded doubling\ndimension, and we design a simple $\\mathcal{O}(\\log^*n)$-round distributed\nalgorithm that given a unit ball graph $G$ with $n$ vertices and a positive\nconstant $\\epsilon < 1$ finds a $(1+\\epsilon)$-spanner with constant bounds on\nits maximum degree and its lightness using only 2-hop neighborhood information.\nThis immediately improves the algorithm of Damian, Pandit, and Pemmaraju which\nruns in $\\mathcal{O}(\\log^*n)$ rounds but has a $\\mathcal{O}(\\log \\Delta)$\nbound on its lightness, where $\\Delta$ is the ratio of the length of the\nlongest edge in $G$ to the length of the shortest edge. We further study the\nproblem in the two dimensional Euclidean plane and we provide a construction\nwith similar properties that has a constant average number of edge intersection\nper node. This is the first distributed low-intersection topology control\nalgorithm to the best of our knowledge. Our distributed algorithms rely on the\nmaximal independent set algorithm of Schneider and Wattenhofer that runs in\n$\\mathcal{O}(\\log^*n)$ rounds of communication. If a maximal independent set is\nknown beforehand, our algorithms run in constant number of rounds.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 10:36:37 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Eppstein", "David", ""], ["Khodabandeh", "Hadi", ""]]}, {"id": "2106.15262", "submitter": "Hannaneh Barahouei Pasandi", "authors": "Hannaneh Barahouei Pasandi and Tamer Nadeem and Hadi Amirpour", "title": "MU-MIMO Grouping For Real-time Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, the bandwidth expansion and MU-MIMO spectral efficiency\nhave promised to increase data throughput by allowing concurrent communication\nbetween one Access Point and multiple users. However, we are still a long way\nfrom enjoying such MU-MIMO MAC protocol improvements for bandwidth hungry\napplications such as video streaming in practical WiFi network settings due to\nheterogeneous channel conditions and devices, unreliable transmissions, and\nlack of useful feedback exchange among the lower and upper layers'\nrequirements. This paper introduces MuViS, a novel dual-phase optimization\nframework that proposes a Quality of Experience (QoE) aware MU-MIMO\noptimization for multi-user video streaming over IEEE 802.11ac. MuViS first\nemploys reinforcement learning to optimize the MU-MIMO user group and mode\nselection for users based on their PHY/MAC layer characteristics. The video\nbitrate is then optimized based on the user's mode (Multi-User (MU) or\nSingle-User (SU)). We present our design and its evaluation on smartphones and\nlaptops using 802.11ac WiFi. Our experimental results in various indoor\nenvironments and configurations show a scalable framework that can support a\nlarge number of users with streaming at high video rates and satisfying QoE\nrequirements.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 11:40:28 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 19:59:46 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Pasandi", "Hannaneh Barahouei", ""], ["Nadeem", "Tamer", ""], ["Amirpour", "Hadi", ""]]}, {"id": "2106.15454", "submitter": "Marcelo Bianchetti Lic.", "authors": "Marcelo Bianchetti, Javier Marenco", "title": "Valid inequalities and a branch-and-cut algorithm for the routing and\n  spectrum allocation problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  One of the most promising solutions to deal with huge data traffic demands in\nlarge communication networks is given by flexible optical networking, in\nparticular the flexible grid (flexgrid) technology specified in the ITU-T\nstandard G.694.1. In this specification, the frequency spectrum of an optical\nfiber link is divided into narrow frequency slots. Any sequence of consecutive\nslots can be used as a simple channel, and such a channel can be switched in\nthe network nodes to create a lightpath. In this kind of networks, the problem\nof establishing lightpaths for a set of end-to-end demands that compete for\nspectrum resources is called the routing and spectrum allocation problem (RSA).\nDue to its relevance, RSA has been intensively studied in the last years. It\nhas been shown to be NP-hard and different solution approaches have been\nproposed for this problem. In this paper we present several families of valid\ninequalities, valid equations, and optimality cuts for a natural integer\nprogramming formulation of RSA and, based on these results, we develop a\nbranch-and-cut algorithm for this problem. Our computational experiments\nsuggest that such an approach is effective at tackling this problem.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 14:41:38 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bianchetti", "Marcelo", ""], ["Marenco", "Javier", ""]]}, {"id": "2106.15477", "submitter": "Yong Xiao", "authors": "Yong Xiao and Marwan Krunz", "title": "AdaptiveFog: A Modelling and Optimization Framework for Fog Computing in\n  Intelligent Transportation Systems", "comments": "accepted at IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog computing has been advocated as an enabling technology for\ncomputationally intensive services in smart connected vehicles. Most existing\nworks focus on analyzing the queueing and workload processing latencies\nassociated with fog computing, ignoring the fact that wireless access latency\ncan sometimes dominate the overall latency. This motivates the work in this\npaper, where we report on a five-month measurement study of the wireless access\nlatency between connected vehicles and a fog/cloud computing system supported\nby commercially available LTE networks. We propose AdaptiveFog, a novel\nframework for autonomous and dynamic switching between different LTE networks\nthat implement a fog/cloud infrastructure. AdaptiveFog's main objective is to\nmaximize the service confidence level, defined as the probability that the\nlatency of a given service type is below some threshold. To quantify the\nperformance gap between different LTE networks, we introduce a novel\nstatistical distance metric, called weighted Kantorovich-Rubinstein (K-R)\ndistance. Two scenarios based on finite- and infinite-horizon optimization of\nshort-term and long-term confidence are investigated. For each scenario, a\nsimple threshold policy based on weighted K-R distance is proposed and proved\nto maximize the latency confidence for smart vehicles. Extensive analysis and\nsimulations are performed based on our latency measurements. Our results show\nthat AdaptiveFog achieves around 30% to 50% improvement in the confidence\nlevels of fog and cloud latencies, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 15:00:56 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Xiao", "Yong", ""], ["Krunz", "Marwan", ""]]}, {"id": "2106.15565", "submitter": "Daniele De Sensi PhD", "authors": "Daniele De Sensi, Salvatore Di Girolamo, Saleh Ashkboos, Shigang Li,\n  Torsten Hoefler", "title": "Flare: Flexible In-Network Allreduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The allreduce operation is one of the most commonly used communication\nroutines in distributed applications. To improve its bandwidth and to reduce\nnetwork traffic, this operation can be accelerated by offloading it to network\nswitches, that aggregate the data received from the hosts, and send them back\nthe aggregated result. However, existing solutions provide limited\ncustomization opportunities and might provide suboptimal performance when\ndealing with custom operators and data types, with sparse data, or when\nreproducibility of the aggregation is a concern. To deal with these problems,\nin this work we design a flexible programmable switch by using as a building\nblock PsPIN, a RISC-V architecture implementing the sPIN programming model. We\nthen design, model, and analyze different algorithms for executing the\naggregation on this architecture, showing performance improvements compared to\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:58:32 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["De Sensi", "Daniele", ""], ["Di Girolamo", "Salvatore", ""], ["Ashkboos", "Saleh", ""], ["Li", "Shigang", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2106.15718", "submitter": "Hamed Moasses", "authors": "Hamed Moasses, Abdulbaghi Ghaderzadeh, Keyhan Khamforoosh", "title": "HetEng: An Improved Distributed Energy Efficient Clustering Scheme for\n  Heterogeneous IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network lifetime is always a challenging issue in battery-powered networks\ndue to the difficulty of recharging or replacing nodes in some scenarios.\nClustering methods are a promising approach to tackle this challenge and\nprolong lifetime by efficiently distributing tasks among nodes in the cluster.\nThe present study aimed to improve energy consumption in heterogeneous IoT\ndevices using an energy-aware clustering method. In a heterogeneous IoT\nnetwork, nodes (i.e., battery-powered IoT devices) can have a variety of energy\nprofiles and communication capabilities. Most of the existing clustering\nalgorithms have neglected the heterogeneity of energy capacity among nodes and\nassumed that they are of the same energy level. In this work, we present\nHetEng, a Cluster Head (CH) selection process that extended an existing\nclustering algorithm, named Smart-BEEM. To this end, we proposed a statistical\napproach that distributes energy consumption among highly energetic nodes in\nthe network topology by constantly changing the CH role between the nodes based\non their real energy levels (in joules). Experimental results showed that\nHetEng resulted in a 6.6% increase of alive nodes and 3% improvement in\nresidual energy among the nodes in comparison with SmartBEEM. Moreover, our\nmethod reduced the total number of iterations by 1% on average.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 20:47:58 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Moasses", "Hamed", ""], ["Ghaderzadeh", "Abdulbaghi", ""], ["Khamforoosh", "Keyhan", ""]]}, {"id": "2106.15734", "submitter": "Su Wang", "authors": "Su Wang, Seyyedali Hosseinalipour, Maria Gorlatova, Christopher G.\n  Brinton, Mung Chiang", "title": "UAV-assisted Online Machine Learning over Multi-Tiered Networks: A\n  Hierarchical Nested Personalized Federated Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed machine learning (ML) through unmanned aerial\nvehicles (UAVs) for geo-distributed device clusters. We propose five new\ntechnologies/techniques: (i) stratified UAV swarms with leader, worker, and\ncoordinator UAVs, (ii) hierarchical nested personalized federated learning\n(HN-PFL): a holistic distributed ML framework for personalized model training\nacross the worker-leader-core network hierarchy, (iii) cooperative UAV resource\npooling for distributed ML using the UAVs' local computational capabilities,\n(iv) aerial data caching and relaying for efficient data relaying to conduct\nML, and (v) concept/model drift, capturing online data variations at the\ndevices. We split the UAV-enabled model training problem as two parts. (a)\nNetwork-aware HN-PFL, where we optimize a tradeoff between energy consumption\nand ML model performance by configuring data offloading among devices-UAVs and\nUAV-UAVs, UAVs' CPU frequencies, and mini-batch sizes subject to\ncommunication/computation network heterogeneity. We tackle this optimization\nproblem via the method of posynomial condensation and propose a distributed\nalgorithm with a performance guarantee. (b) Macro-trajectory and learning\nduration design, which we formulate as a sequential decision making problem,\ntackled via deep reinforcement learning. Our simulations demonstrate the\nsuperiority of our methodology with regards to the distributed ML performance,\nthe optimization of network resources, and the swarm trajectory efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 21:40:28 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 17:31:56 GMT"}, {"version": "v3", "created": "Sun, 11 Jul 2021 19:33:00 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Su", ""], ["Hosseinalipour", "Seyyedali", ""], ["Gorlatova", "Maria", ""], ["Brinton", "Christopher G.", ""], ["Chiang", "Mung", ""]]}, {"id": "2106.15832", "submitter": "Markus Amend", "authors": "Nathalie Romo Moreno, Markus Amend, Anna Brunstrom, Andreas Kassler\n  and Veselin Rakocevic", "title": "CCID5: An implementation of the BBR Congestion Control algorithm for\n  DCCP and its impact over multi-path scenarios", "comments": null, "journal-ref": null, "doi": "10.1145/3472305.3472322", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing multi-connectivity services is an important goal for next\ngeneration wireless networks, where multiple access networks are available and\nneed to be integrated into a coherent solution that efficiently supports both\nreliable and non reliable traffic. Based on virtual network interfaces and per\npath congestion controlled tunnels, the MP-DCCP based multiaccess aggregation\nframework presents as a novel solution that flexibly supports different path\nschedulers and congestion control algorithms as well as reordering modules. The\nframework has been implemented within the Linux kernel space and has been\ntested over different prototypes. Experimental results have shown that the\noverall performance strongly depends upon the congestion control algorithm used\non the individual DCCP tunnels, denoted as CCID. In this paper, we present an\nimplementation of the BBR (Bottleneck Bandwidth Round Trip propagation time)\ncongestion control algorithm for DCCP in the Linux kernel. We show how BBR is\nintegrated into the MP-DCCP multi-access framework and evaluate its performance\nover both single and multi-path environments. Our evaluation results show that\nBBR improves the performance compared to CCID2 for multi-path scenarios due to\nthe faster response to changes in the available bandwidth, which reduces\nlatency and increases performance, especially for unreliable traffic. the\nMP-DCCP framework code, including the new CCID5 is available as OpenSource.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 06:26:02 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Moreno", "Nathalie Romo", ""], ["Amend", "Markus", ""], ["Brunstrom", "Anna", ""], ["Kassler", "Andreas", ""], ["Rakocevic", "Veselin", ""]]}, {"id": "2106.15836", "submitter": "Jie Feng", "authors": "Jie Feng, Biqian Feng, Yongpeng Wu, Li Shen, Wenjun Zhang", "title": "MIMO Transmission Under Discrete Input Signal Constraints", "comments": "This paper contains 6 pages with 5 figures and has been accepted by\n  2021 IEEE/CIC International Conference on Communications in China (ICCC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a multiple-input multipleoutput (MIMO) transmission\nstrategy that is closer to the Shannon limit than the existing strategies.\nDifferent from most existing strategies which only consider uniformly\ndistributed discrete input signals, we present a unified framework to optimize\nthe MIMO precoder and the discrete input signal distribution jointly. First, a\ngeneral model of MIMO transmission under discrete input signals and its\nequivalent formulation are established. Next, in order to maximize the mutual\ninformation between the input and output signals, we provide an algorithm that\njointly optimizes the precoder and the input distribution. Finally, we compare\nour strategy with other existing strategies in the simulation. Numerical\nresults indicate that our strategy narrows the gap between the mutual\ninformation and Shannon limit, and shows a lower frame error rate in\nsimulation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 06:38:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Feng", "Jie", ""], ["Feng", "Biqian", ""], ["Wu", "Yongpeng", ""], ["Shen", "Li", ""], ["Zhang", "Wenjun", ""]]}, {"id": "2106.15905", "submitter": "Meng Zhang", "authors": "Meng Zhang, Ermin Wei, and Randall Berry", "title": "Faithful Edge Federated Learning: Scalability and Privacy", "comments": "Under review by JSAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning enables machine learning algorithms to be trained over a\nnetwork of multiple decentralized edge devices without requiring the exchange\nof local datasets. Successfully deploying federated learning requires ensuring\nthat agents (e.g., mobile devices) faithfully execute the intended algorithm,\nwhich has been largely overlooked in the literature. In this study, we first\nuse risk bounds to analyze how the key feature of federated learning,\nunbalanced and non-i.i.d. data, affects agents' incentives to voluntarily\nparticipate and obediently follow traditional federated learning algorithms.\n  To be more specific, our analysis reveals that agents with less typical data\ndistributions and relatively more samples are more likely to opt out of or\ntamper with federated learning algorithms. To this end, we formulate the first\nfaithful implementation problem of federated learning and design two faithful\nfederated learning mechanisms which satisfy economic properties, scalability,\nand privacy. Further, the time complexity of computing all agents' payments in\nthe number of agents is $\\mathcal{O}(1)$. First, we design a Faithful Federated\nLearning (FFL) mechanism which approximates the Vickrey-Clarke-Groves (VCG)\npayments via an incremental computation. We show that it achieves (probably\napproximate) optimality, faithful implementation, voluntary participation, and\nsome other economic properties (such as budget balance). Second, by\npartitioning agents into several subsets, we present a scalable VCG mechanism\napproximation. We further design a scalable and Differentially Private FFL\n(DP-FFL) mechanism, the first differentially private faithful mechanism, that\nmaintains the economic properties. Our mechanism enables one to make three-way\nperformance tradeoffs among privacy, the iterations needed, and payment\naccuracy loss.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 08:46:40 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zhang", "Meng", ""], ["Wei", "Ermin", ""], ["Berry", "Randall", ""]]}, {"id": "2106.16003", "submitter": "Andreas Kassler", "authors": "Marcus Pieska, Alexander Rabitsch, Anna Brunstrom, Andreas Kassler,\n  Markus Amend", "title": "Adaptive Cheapest Path First Scheduling in a Transport-Layer Multi-Path\n  Tunnel Context", "comments": "To appear at Applied Networking Research Workshop (ANRW 2021)", "journal-ref": null, "doi": "10.1145/3472305.3472316", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bundling multiple access technologies increases capacity, resiliency and\nrobustness of network connections. Multi-access is currently being standardized\nin the ATSSS framework in 3GPP, supporting different access bundling\nstrategies. Within ATSSS, a multipath scheduler needs to decide which path to\nuse for each user packet based on path characteristics. The Cheapest Path First\n(CPF) scheduler aims to utilize the cheapest path (e.g. WiFi) before sending\npackets over other paths (e.g. cellular). In this paper, we demonstrate that\nusing CPF with an MP-DCCP tunnel may lead to sub-optimal performance. This is\ndue to adverse interactions between the scheduler and end-to-end and tunnel\ncongestion control. Hence, we design the Adaptive Cheapest Path First (ACPF)\nscheduler that limits queue buildup in the primary bottleneck and moves traffic\nto the secondary path earlier. We implement ACPF over both TCP and DCCP\ncongestion controlled tunnels. Our evaluation shows that ACPF improves the\naverage throughput over CPF between 24% to 86%.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 11:52:03 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Pieska", "Marcus", ""], ["Rabitsch", "Alexander", ""], ["Brunstrom", "Anna", ""], ["Kassler", "Andreas", ""], ["Amend", "Markus", ""]]}, {"id": "2106.16037", "submitter": "Elif Tugce Ceran", "authors": "Elif Tugce Ceran, Deniz Gunduz, and Andras Gyorgy", "title": "Learning to Minimize Age of Information over an Unreliable Channel with\n  Energy Harvesting", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.09467", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The time average expected age of information (AoI) is studied for status\nupdates sent over an error-prone channel from an energy-harvesting transmitter\nwith a finite-capacity battery. Energy cost of sensing new status updates is\ntaken into account as well as the transmission energy cost better capturing\npractical systems. The optimal scheduling policy is first studied under the\nhybrid automatic repeat request (HARQ) protocol when the channel and energy\nharvesting statistics are known, and the existence of a threshold-based optimal\npolicy is shown. For the case of unknown environments, average-cost\nreinforcement-learning algorithms are proposed that learn the system parameters\nand the status update policy in real-time. The effectiveness of the proposed\nmethods is demonstrated through numerical results.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 13:05:37 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ceran", "Elif Tugce", ""], ["Gunduz", "Deniz", ""], ["Gyorgy", "Andras", ""]]}, {"id": "2106.16051", "submitter": "Igor Donevski", "authors": "Igor Donevski, Christian Raffelsberger, Micha Sende, Aymen\n  Fakhreddine, Jimmy Jessen Nielsen", "title": "An Experimental Analysis on Drone-Mounted Access Points for Improved\n  Latency-Reliability", "comments": "To be published in proceedings of DroNet21. Winner of DroNet21's Best\n  Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The anticipated densification of contemporary communications infrastructure\nexpects the use of drone small cells (DSCs). Thus, we experimentally evaluate\nthe capability of providing local and personalized coverage with a drone\nmounted Wi-Fi access point that uses the nearby LTE infrastructure as a\nbackhaul in areas with mixed line of sight(LoS) and Non-LoS (NLoS) links to the\nlocal cellular infrastructure. To assess the potential of DSCs for reliable and\nlow latency communication of outdoor users, we measure the channel quality and\nthe total round trip latency of the system. For a drone following the ground\nuser, the DSC-provided network extends the coverage for an extra 6.4% when\ncompared to the classical LTE-direct link. Moreover, the DSC setup provides\nlatencies that are consistently smaller than 50 msfor 95% of the experiment.\nWithin the coverage of the LTE-direct connection, we observed a latency ceiling\nof 120ms for 95% reliability of the LTE-direct connection. The highest latency\nobserved for the DSC system was 1200ms, while the LTE-direct link never\nexceeded 500 ms. As such, DSC setups are not only essential in NLoS situations,\nbut consistently improve the latency of users in outdoor scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 13:25:59 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Donevski", "Igor", ""], ["Raffelsberger", "Christian", ""], ["Sende", "Micha", ""], ["Fakhreddine", "Aymen", ""], ["Nielsen", "Jimmy Jessen", ""]]}, {"id": "2106.16083", "submitter": "Fotios Lazarinis", "authors": "Theodore Karachalios, Dimitris Kanellopoulos, Fotis Lazarinis", "title": "Arduino sensor integrated drone for weather indices: a prototype for\n  pre-flight preparation", "comments": "12 pages, 8 figures", "journal-ref": "Journal of Information Technology and Applications, 2021", "doi": "10.7251/JIT2101005K", "report-no": null, "categories": "cs.RO cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Commercial weather stations can effectively collect weather data for a\nspecified area. However, their ground sensors limit the amount of data that can\nbe logged, thus failing to collect precise meteorological data in a local area\nsuch as a micro-scale region. This happens because weather conditions at a\nmicro-scale region can vary greatly even with small altitude changes. For now,\ndrone operators must check the local weather conditions to ensure a safe and\nsuccessful flight. This task is often a part of pre-flight preparations. Since\nflight conditions (and most important flight safety) are greatly affected by\nweather, drone operators need a more accurate localized weather map reading for\nthe flight area. In this paper, we present the Arduino Sensor Integrated Drone\n(ASID) with a built-in meteorological station that logs the weather conditions\nin the vertical area where the drone will be deployed. ASID is an autonomous\ndrone-based system that monitors weather conditions for pre-flight preparation.\nThe operation of the ASID system is based on the Arduino microcontroller\nrunning automatic flight profiles to record meteorological data such as\ntemperature, barometric pressure, humidity, etc. The Arduino microcontroller\nalso takes photos of the horizon for an objective assessment of the visibility,\nthe base, and the number of clouds.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 14:18:10 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Karachalios", "Theodore", ""], ["Kanellopoulos", "Dimitris", ""], ["Lazarinis", "Fotis", ""]]}, {"id": "2106.16140", "submitter": "Ying Zhang", "authors": "Ying Zhang", "title": "Revisiting Time, Clocks, and Synchronization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sub-nanosecond precision clock synchronization over the packet network has\nbeen achieved by the White Rabbit protocol for a decade. However, few computer\nsystems utilize such a technique. We try to attract more interest in the clock\nsynchronization problem. We first introduce the basics of clock and\nsynchronization in the time and frequency discipline. Then we revisit several\nrelated works, such as Google's Spanner, Huygens, FARMv2, DTP, and Sundial,\nexplain why these works could be improved. Finally, we briefly discuss an\nindependent time network approach towards low-cost and high-precision\nsynchronization.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 13:21:58 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zhang", "Ying", ""]]}, {"id": "2106.16143", "submitter": "Winston Seah", "authors": "Wei-Chuan Lin, Winston K.G. Seah and Wei Li", "title": "People Counting using Radio Irregularity in Wireless Sensor Networks --\n  An Experimental Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.OH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet has grown into a large cyber-physical system centered that\nconnects not just computer systems but a plethora of systems, devices, and\nobjects, collectively referred to as \"Things\", giving rise to the term\n\"Internet of Things\" (IoT). It encompasses technologies for identification and\ntracking, sensing and actuation, both wired and wireless communications, and\nalso, intelligence and cognition. Wireless communications, which is an integral\npart of IoT, suffers from radio irregularity -- a phenomenon referring to radio\nwaves being selectively absorbed, reflected or scattered by objects in their\npaths, e.g., human bodies that comprises liquid, bone and flesh. Radio\nirregularity is often regarded as a problem in wireless communications but,\nwith the envisioned pervasiveness of IoT, we aim to exploit radio irregularity\nas a means to detect and estimate the number of people. We demonstrate how\nradio signal fluctuations arising from radio irregularity, combined with\ndiscriminant analysis, can be used to provide a simple low-cost alternative to\ndedicated sensing systems for indoor people counting.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 22:35:04 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Lin", "Wei-Chuan", ""], ["Seah", "Winston K. G.", ""], ["Li", "Wei", ""]]}, {"id": "2106.16144", "submitter": "Faisal Nadeem", "authors": "Faisal Nadeem, Mahyar Shirvanimoghaddam, Yonghui Li and Branka Vucetic", "title": "Non-orthogonal HARQ for URLLC Design and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fifth-generation (5G) of mobile standards is expected to provide\nultra-reliability and low-latency communications (URLLC) for various\napplications and services, such as online gaming, wireless industrial control,\naugmented reality, and self driving cars. Meeting the contradictory\nrequirements of URLLC, i.e., ultra-reliability and low-latency, is considered\nto be very challenging, especially in bandwidth-limited scenarios. Most\ncommunication strategies rely on hybrid automatic repeat request (HARQ) to\nimprove reliability at the expense of increased packet latency due to the\nretransmission of failing packets. To guarantee high-reliability and very low\nlatency simultaneously, we enhance HARQ retransmission mechanism to achieve\nreliability with guaranteed packet level latency and in-time delivery. The\nproposed non-orthogonal HARQ (N-HARQ) utilizes non-orthogonal sharing of time\nslots for conducting retransmission. The reliability and delay analysis of the\nproposed N-HARQ in the finite block length (FBL) regime shows very high\nperformance gain in packet delivery delay over conventional HARQ in both\nadditive white Gaussian noise (AWGN) and Rayleigh fading channels. We also\npropose an optimization framework to further enhance the performance of N-HARQ\nfor single and multiple retransmission cases.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 15:41:06 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Nadeem", "Faisal", ""], ["Shirvanimoghaddam", "Mahyar", ""], ["Li", "Yonghui", ""], ["Vucetic", "Branka", ""]]}, {"id": "2106.16146", "submitter": "Marouan Mizmizi Dr", "authors": "Marouan Mizmizi, Mattia Brambilla, Dario Tagliaferri, Christian\n  Mazzucco, Merouane Debbah, Tomasz Mach, Rino Simeone, Silvio Mandelli,\n  Valerio Frascolla, Renato Lombardi, Maurizio Magarini, Monica Nicoli, Umberto\n  Spagnolini", "title": "6G V2X Technologies and Orchestrated Sensing for Autonomous Driving", "comments": "9 Pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  6G technology targets to revolutionize the mobility industry by revamping the\nrole of wireless connections. In this article, we draw out our vision on an\nintelligent, cooperative, and sustainable mobility environment of the future,\ndiscussing how 6G will positively impact mobility services and applications.\nThe scenario in focus is a densely populated area by smart connected entities\nthat are mutually connected over a 6G virtual bus, which enables access to an\nextensive and always up-to-date set of context-sensitive information. The\naugmented dataset is functional to let vehicles engage in adaptive and\ncooperative learning mechanisms, enabling fully automated functionalities with\nhigher communication integrity and reduced risk of accidents while being a\nsentient and collaborative processing node of the same ecosystem. Smart sensing\nand communication technologies are discussed herein, and their convergence is\ndevised by the pervasiveness of artificial intelligence in centralized or\ndistributed and federated network architectures.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 11:11:08 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Mizmizi", "Marouan", ""], ["Brambilla", "Mattia", ""], ["Tagliaferri", "Dario", ""], ["Mazzucco", "Christian", ""], ["Debbah", "Merouane", ""], ["Mach", "Tomasz", ""], ["Simeone", "Rino", ""], ["Mandelli", "Silvio", ""], ["Frascolla", "Valerio", ""], ["Lombardi", "Renato", ""], ["Magarini", "Maurizio", ""], ["Nicoli", "Monica", ""], ["Spagnolini", "Umberto", ""]]}]