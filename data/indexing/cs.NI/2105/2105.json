[{"id": "2105.00001", "submitter": "Pablo Mu\\~noz", "authors": "Pablo Mu\\~noz, Oriol Sallent, Jordi P\\'erez-Romero", "title": "Self-Dimensioning and Planning of Small Cell Capacity in Multitenant 5G\n  Networks", "comments": "arXiv admin note: text overlap with arXiv:2104.14833", "journal-ref": "P. Munoz, O. Sallent, J. Perez-Romero, \"Self-Dimensioning and\n  Planning of Small Cell Capacity in Multi-Tenant 5G Networks\", IEEE\n  Transactions on Vehicular Technology, 67-5, pp. 4552-4564, 2018", "doi": "10.1109/TVT.2018.2793418", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An important concept in the fifth generation of mobile networks is\nmultitenancy, which allows diverse operators sharing the same wireless\ninfrastructure. To support this feature in conjunction with the challenging\nperformance requirements of future networks, more automated and faster planning\nof the required radio capacity is needed. Likewise, installing small cells is\nan effective resource to provide greater performance and capacity to both\nindoor and outdoor places. This paper proposes a new framework for automated\ncell planning in multitenant small cell networks. In particular, taking\nadvantage of the available network data, a set of detailed planning\nspecifications over time and space domains are generated in order to meet the\ncontracted capacity by each tenant. Then, the network infrastructure and\nconfiguration are updated according to an algorithm that considers different\nactions such as adding/removing channels and adding or relocating small cells.\nThe simulation results show the effectiveness of various methods to derive the\nplanning specifications depending on the correlation between the tenant's and\nnetwork's traffic demands.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 08:53:39 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Mu\u00f1oz", "Pablo", ""], ["Sallent", "Oriol", ""], ["P\u00e9rez-Romero", "Jordi", ""]]}, {"id": "2105.00013", "submitter": "Martin Henze", "authors": "Tim Krause, Raphael Ernst, Benedikt Klaer, Immanuel Hacker, Martin\n  Henze", "title": "Cybersecurity in Power Grids: Challenges and Opportunities", "comments": "11 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing volatilities within power transmission and distribution force\npower grid operators to amplify their use of communication infrastructure to\nmonitor and control their grid. The resulting increase in communication creates\na larger attack surface for malicious actors. Indeed, cyber attacks on power\ngrids have already succeeded in causing temporary, large-scale blackouts in the\nrecent past. In this paper, we analyze the communication infrastructure of\npower grids to derive resulting fundamental challenges of power grids with\nrespect to cybersecurity. Based on these challenges, we identify a broad set of\nresulting attack vectors and attack scenarios that threaten the security of\npower grids. To address these challenges, we propose to rely on a\ndefense-in-depth strategy, which encompasses measures for (i) device and\napplication security, (ii) network security, (iii) physical security, as well\nas (iv) policies, procedures, and awareness. For each of these categories, we\ndistill and discuss a comprehensive set of state-of-the art approaches, and\nidentify further opportunities to strengthen cybersecurity in interconnected\npower grids.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 18:00:09 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Krause", "Tim", ""], ["Ernst", "Raphael", ""], ["Klaer", "Benedikt", ""], ["Hacker", "Immanuel", ""], ["Henze", "Martin", ""]]}, {"id": "2105.00074", "submitter": "Sayantan Chowdhury", "authors": "Sayantan Chowdhury, Ben Liang, Ali Tizghadam, Ilijc Albanese", "title": "Flow-Packet Hybrid Traffic Classification for Class-Aware Network\n  Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network traffic classification using machine learning techniques has been\nwidely studied. Most existing schemes classify entire traffic flows, but there\nare major limitations to their practicality. At a network router, the packets\nneed to be processed with minimum delay, so the classifier cannot wait until\nthe end of the flow to make a decision. Furthermore, a complicated machine\nlearning algorithm can be too computationally expensive to implement inside the\nrouter. In this paper, we introduce flow-packet hybrid traffic classification\n(FPHTC), where the router makes a decision per packet based on a routing policy\nthat is designed through transferring the learned knowledge from a flow-based\nclassifier residing outside the router. We analyze the generalization bound of\nFPHTC and show its advantage over regular packet-based traffic classification.\nWe present experimental results using a real-world traffic dataset to\nillustrate the classification performance of FPHTC. We show that it is robust\ntoward traffic pattern changes and can be deployed with limited computational\nresource.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 20:30:36 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chowdhury", "Sayantan", ""], ["Liang", "Ben", ""], ["Tizghadam", "Ali", ""], ["Albanese", "Ilijc", ""]]}, {"id": "2105.00151", "submitter": "Hiroshi Saito", "authors": "Hiroshi Saito", "title": "Theoretical Analysis for Determining Geographical Route of Cable Network\n  with Various Disaster-Endurance Levels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper theoretically analyzes cable network disconnection due to randomly\noccurring natural disasters, where the disaster-endurance (DE) levels of the\nnetwork are determined by a network entity such as the type of shielding method\nused for a duct containing cables. The network operator can determine which\nparts have a high DE level. When a part of a network can be protected, the\nplacement of that part can be specified to decrease the probability of\ndisconnecting two given nodes.\n  The maximum lower bound of the probability of connecting two given nodes is\nexplicitly derived. Conditions decreasing (not decreasing) the probability of\nconnecting two given nodes with a partially protected network are provided.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 02:35:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Saito", "Hiroshi", ""]]}, {"id": "2105.00155", "submitter": "Mansour Naslcheraghi", "authors": "Mansour Naslcheraghi, Constant Wette, and Brunilde Sanso", "title": "Probabilistic Analysis of Operating Modes in Cache-Enabled Full-Duplex\n  D2D Networks", "comments": "27 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the extensive acquisition of various mobile applications, cellular\nnetworks are facing challenges due to exponentially growing demand for high\ndata rate, which causes a great burden on mobile core networks and backhaul\nlinks. Cache-enabled Device-to-Device (D2D) communication, which is recognized\nas one of the key enablers of the fifth generation (5G) cellular network, is a\npromising solution to alleviate this problem. However, conventional half-duplex\n(HD) communication may not be sufficient to provide fast enough content\ndelivery over D2D links in order to meet strict latency targets of emerging D2D\napplications. In-band full-duplex (FD), with its capability of allowing\nsimultaneous transmission and reception, can provide more content delivery\nopportunities, thus resulting improved spectral efficiency and latency\nreduction. However, given the random nature of the cached contents in user\ndevices and users' random requests, it is unlikely to consider all involving\nnodes in content exchange collaborations as a pure HD or FD network. In this\npaper, we aim to analyze the caching perspective of a finite network of D2D\nnodes in which each node is endowed with FD capability and utilize a more\nrealistic caching policy. We model and analyze all possible operating modes for\nan arbitrary device, which we compute the probability of occurrence of each\nmode along with the Probability Mass Functions (PMFs) of nodes that are\noperating in all possible modes. Our analysis concretely quantize all possible\noutcomes that strongly depend on the random nature of the caching parameters,\nyielding to have an accurate insight on the caching performance and all\npossible outcomes of the cache-enabled FD-D2D network.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 03:15:17 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Naslcheraghi", "Mansour", ""], ["Wette", "Constant", ""], ["Sanso", "Brunilde", ""]]}, {"id": "2105.00384", "submitter": "Arlindo Flavio da Concei\\c{c}\\~ao", "authors": "Poliana de Moraes and Arlindo Flavio da Concei\\c{c}\\~ao", "title": "A Systematic Review of Security in the LoRaWAN Network Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The age of the Internet of Things is adding an increasing number of new\ndevices to the Internet and is expected to have fifty billion connected units\nby 2021. These form an extensive network that may have multiple points where\nthere is a risk of attacks that can compromise the entire system. This paper\nhas conducted a systematic review of security in LoRaWAN protocol specification\nversions 1.0 and 1.1 by locating its vulnerabilities and determining what\nmeasures can be taken for improvement and how they can be checked or tested.\nThe review identifies nineteen areas of vulnerability in the LoRaWAN protocol\nand shows that the current studies focus on specification version 1.0, key\nmanagement, and authentication procedures.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 02:51:57 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["de Moraes", "Poliana", ""], ["da Concei\u00e7\u00e3o", "Arlindo Flavio", ""]]}, {"id": "2105.00395", "submitter": "Yusuke Koda", "authors": "Yusuke Koda and Jihong Park and Mehdi Bennis and Praneeth Vepakomma\n  and Ramesh Raskar", "title": "AirMixML: Over-the-Air Data Mixup for Inherently Privacy-Preserving Edge\n  Machine Learning", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless channels can be inherently privacy-preserving by distorting the\nreceived signals due to channel noise, and superpositioning multiple signals\nover-the-air. By harnessing these natural distortions and superpositions by\nwireless channels, we propose a novel privacy-preserving machine learning (ML)\nframework at the network edge, coined over-the-air mixup ML (AirMixML). In\nAirMixML, multiple workers transmit analog-modulated signals of their private\ndata samples to an edge server who trains an ML model using the received\nnoisy-and superpositioned samples. AirMixML coincides with model training using\nmixup data augmentation achieving comparable accuracy to that with raw data\nsamples. From a privacy perspective, AirMixML is a differentially private (DP)\nmechanism limiting the disclosure of each worker's private sample information\nat the server, while the worker's transmit power determines the privacy\ndisclosure level. To this end, we develop a fractional channel-inversion power\ncontrol (PC) method, {\\alpha}-Dirichlet mixup PC (DirMix({\\alpha})-PC), wherein\nfor a given global power scaling factor after channel inversion, each worker's\nlocal power contribution to the superpositioned signal is controlled by the\nDirichlet dispersion ratio {\\alpha}. Mathematically, we derive a closed-form\nexpression clarifying the relationship between the local and global PC factors\nto guarantee a target DP level. By simulations, we provide DirMix({\\alpha})-PC\ndesign guidelines to improve accuracy, privacy, and energy-efficiency. Finally,\nAirMixML with DirMix({\\alpha})-PC is shown to achieve reasonable accuracy\ncompared to a privacy-violating baseline with neither superposition nor PC.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 05:45:43 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Koda", "Yusuke", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Vepakomma", "Praneeth", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2105.00437", "submitter": "Xuelin Cao", "authors": "Xuelin Cao, Bo Yang, Chongwen Huang, Chau Yuen, Marco Di Renzo, Zhu\n  Han, Dusit Niyato, H. Vincent Poor, Lajos Hanzo", "title": "AI-Assisted MAC for Reconfigurable Intelligent Surface-Aided Wireless\n  Networks: Challenges and Opportunities", "comments": "16 pages, 5 figures, 1 table, and 15 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, significant research attention has been devoted to the study of\nreconfigurable intelligent surfaces (RISs), which are capable of reconfiguring\nthe wireless propagation environment by exploiting the unique properties of\nmetamaterials-based integrated large arrays of inexpensive antennas. Existing\nresearch demonstrates that RISs significantly improve the physical layer\nperformance, including the wireless coverage, achievable data rate and energy\nefficiency. However, the medium access control (MAC) of multiple users\naccessing an RIS-enabled channel is still in its infancy, while many open\nissues remain to be addressed. In this article, we present four typical\nRIS-aided multi-user scenarios with special emphasis on the MAC schemes. We\nthen propose and elaborate upon centralized, distributed and hybrid\nartificial-intelligence (AI)-assisted MAC architectures in RIS-aided multi-user\ncommunications systems. Finally, we discuss some challenges, perspectives and\npotential applications of RISs as they are related to MAC design.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 10:06:51 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Cao", "Xuelin", ""], ["Yang", "Bo", ""], ["Huang", "Chongwen", ""], ["Yuen", "Chau", ""], ["Di Renzo", "Marco", ""], ["Han", "Zhu", ""], ["Niyato", "Dusit", ""], ["Poor", "H. Vincent", ""], ["Hanzo", "Lajos", ""]]}, {"id": "2105.00542", "submitter": "Ronen Ben David", "authors": "Ronen Ben David, Anat Bremler Barr", "title": "Kubernetes Autoscaling: YoYo Attack Vulnerability and Mitigation", "comments": "Paper contains 14 pages, 4 figures. This paper was presented in\n  CLOSER 2021 conference on April 28,2021. CLOSER 2021 is the 11th\n  International Conference on Cloud Computing and Services Science, which was\n  organized by INSTICC. The paper is available soon at SCITEPRESS Digital\n  Library", "journal-ref": "Volume 1: CLOSER 2021,ISBN 978-989-758-510-4, pages 34-44", "doi": "10.5220/0010397900340044", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, we have witnessed a new kind of DDoS attack, the burst\nattack(Chai, 2013; Dahan, 2018), where the attacker launches periodic bursts of\ntraffic overload on online targets. Recent work presents a new kind of Burst\nattack, the YoYo attack (Bremler-Barr et al., 2017) that operates against the\nauto-scaling mechanism of VMs in the cloud. The periodic bursts of traffic\nloads cause the auto-scaling mechanism to oscillate between scale-up and\nscale-down phases. The auto-scaling mechanism translates the flat DDoS attacks\ninto Economic Denial of Sustainability attacks (EDoS), where the victim suffers\nfrom economic damage accrued by paying for extra resources required to process\nthe traffic generated by the attacker. However, it was shown that YoYo attack\nalso causes significant performance degradation since it takes time to scale-up\nVMs. In this research, we analyze the resilience of Kubernetes auto-scaling\nagainst YoYo attacks. As containerized cloud applications using Kubernetes gain\npopularity and replace VM-based architecture in recent years. We present\nexperimental results on Google Cloud Platform, showing that even though the\nscale-up time of containers is much lower than VM, Kubernetes is still\nvulnerable to the YoYo attack since VMs are still involved. Finally, we\nevaluate ML models that can accurately detect YoYo attack on a Kubernetes\ncluster.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 19:54:35 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 09:37:32 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["David", "Ronen Ben", ""], ["Barr", "Anat Bremler", ""]]}, {"id": "2105.00544", "submitter": "Fuad Yimer Mr.", "authors": "Fuad Yimer Yesuf and M. Prathap", "title": "CARL-DTN: Context Adaptive Reinforcement Learning based Routing\n  Algorithm in Delay Tolerant Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The term Delay/Disruption-Tolerant Networks (DTN) invented to describe and\ncover all types of long-delay, disconnected, intermittently connected networks,\nwhere mobility and outages or scheduled contacts may be experienced. This\nenvironment is characterized by frequent network partitioning, intermittent\nconnectivity, large or variable delay, asymmetric data rate, and low\ntransmission reliability. There have been routing protocols developed in DTN.\nHowever, those routing algorithms are design based upon specific assumptions.\nThe assumption makes existing algorithms suitable for specific environment\nscenarios. Different routing algorithm uses different relay node selection\ncriteria to select the replication node. Too Frequently forwarding messages can\nresult in excessive packet loss and large buffer and network overhead. On the\nother hand, less frequent transmission leads to a lower delivery ratio. In DTN\nthere is a trade-off off between delivery ratio and overhead. In this study, we\nproposed context-adaptive reinforcement learning based routing(CARL-DTN)\nprotocol to determine optimal replicas of the message based on the real-time\ndensity. Our routing protocol jointly uses a real-time physical context,\nsocial-tie strength, and real-time message context using fuzzy logic in the\nrouting decision. Multi-hop forwarding probability is also considered for the\nrelay node selection by employing Q-Learning algorithm to estimate the\nencounter probability between nodes and to learn about nodes available in the\nneighbor by discounting reward. The performance of the proposed protocol is\nevaluated based on various simulation scenarios. The result shows that the\nproposed protocol has better performance in terms of message delivery ratio and\noverhead.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 20:08:17 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Yesuf", "Fuad Yimer", ""], ["Prathap", "M.", ""]]}, {"id": "2105.00560", "submitter": "Brad Calder", "authors": "Anna Berenberg and Brad Calder", "title": "Deployment Archetypes for Cloud Applications", "comments": "Under review for publication at ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is a survey paper that explores six Cloud-based deployment archetypes\nfor Cloud applications and the tradeoffs between them to achieve high\navailability, low end-user latency, and acceptable costs. These are (1) Zonal,\n(2) Regional, (3) Multi-Regional, (4) Global, (5) Hybrid, and (6) Multi-Cloud\ndeployment archetypes. The goal is to classify cloud applications into a set of\ndeployment archetypes and deployment models that tradeoff their needs around\navailability, latency, and geographical constraints with a focus on serving\napplications. This enables application owners to better examine the tradeoffs\nof each deployment model and what is needed for achieving the availability and\nlatency goals for their application.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 22:02:50 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Berenberg", "Anna", ""], ["Calder", "Brad", ""]]}, {"id": "2105.00721", "submitter": "Marcell Feh\\'er", "authors": "Marcell Feh\\'er, Daniel E. Lucani, Morten Tranberg Hansen, Flemming\n  Enevold Vester", "title": "Stream Compression of DLMS Smart Meter Readings", "comments": "6 pages, 7 figures, IEEE conference format, submitted to Globecom'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart electricity meters typically upload readings a few times a day. Utility\nproviders aim to increase the upload frequency in order to access consumption\ninformation in near real time, but the legacy compressors fail to provide\nsufficient savings on the low-bandwidth, high-cost data connection. We propose\na new compression method and data format for DLMS smart meter readings, which\nis significantly better with frequent uploads and enable reporting every\nreading in near real time with the same or lower data sizes than the currently\navailable compressors in the DLMS protocol.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 10:01:33 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Feh\u00e9r", "Marcell", ""], ["Lucani", "Daniel E.", ""], ["Hansen", "Morten Tranberg", ""], ["Vester", "Flemming Enevold", ""]]}, {"id": "2105.00872", "submitter": "Shuo Wan", "authors": "Shuo Wan, Jiaxun Lu, Pingyi Fan, Yunfeng Shao, Chenghui Peng and\n  Khaled B. letaief", "title": "Convergence Analysis and System Design for Federated Learning over\n  Wireless Networks", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has recently emerged as an important and promising\nlearning scheme in IoT, enabling devices to jointly learn a model without\nsharing their raw data sets. However, as the training data in FL is not\ncollected and stored centrally, FL training requires frequent model exchange,\nwhich is largely affected by the wireless communication network. Therein,\nlimited bandwidth and random package loss restrict interactions in training.\nMeanwhile, the insufficient message synchronization among distributed clients\ncould also affect FL convergence. In this paper, we analyze the convergence\nrate of FL training considering the joint impact of communication network and\ntraining settings. Further by considering the training costs in terms of time\nand power, the optimal scheduling problems for communication networks are\nformulated. The developed theoretical results can be used to assist the system\nparameter selections and explain the principle of how the wireless\ncommunication system could influence the distributed training process and\nnetwork scheduling.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 02:33:29 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Wan", "Shuo", ""], ["Lu", "Jiaxun", ""], ["Fan", "Pingyi", ""], ["Shao", "Yunfeng", ""], ["Peng", "Chenghui", ""], ["letaief", "Khaled B.", ""]]}, {"id": "2105.00884", "submitter": "Giulia Milan", "authors": "Giulia Milan, Luca Vassio, Idilio Drago, Marco Mellia", "title": "RL-IoT: Reinforcement Learning to Interact with IoT Devices", "comments": "9 pages, 11 figures, submitted to IEEE COINS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our life is getting filled by Internet of Things (IoT) devices. These devices\noften rely on closed or poorly documented protocols, with unknown formats and\nsemantics. Learning how to interact with such devices in an autonomous manner\nis the key for interoperability and automatic verification of their\ncapabilities. In this paper, we propose RL-IoT, a system that explores how to\nautomatically interact with possibly unknown IoT devices. We leverage\nreinforcement learning (RL) to recover the semantics of protocol messages and\nto take control of the device to reach a given goal, while minimizing the\nnumber of interactions. We assume to know only a database of possible IoT\nprotocol messages, whose semantics are however unknown. RL-IoT exchanges\nmessages with the target IoT device, learning those commands that are useful to\nreach the given goal. Our results show that RL-IoT is able to solve both simple\nand complex tasks. With properly tuned parameters, RL-IoT learns how to perform\nactions with the target device, a Yeelight smart bulb in our case study,\ncompleting non-trivial patterns with as few as 400 interactions. RL-IoT paves\nthe road for automatic interactions with poorly documented IoT protocols, thus\nenabling interoperable systems.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 14:09:03 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 10:48:44 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Milan", "Giulia", ""], ["Vassio", "Luca", ""], ["Drago", "Idilio", ""], ["Mellia", "Marco", ""]]}, {"id": "2105.00964", "submitter": "Alex Sim", "authors": "Elizabeth Copps, Huiyi Zhang, Alex Sim, Kesheng Wu, Inder Monga, Chin\n  Guok, Frank W\\\"urthwein, Diego Davila, Edgar Fajardo", "title": "Analyzing scientific data sharing patterns for in-network data caching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The volume of data moving through a network increases with new scientific\nexperiments and simulations. Network bandwidth requirements also increase\nproportionally to deliver data within a certain time frame. We observe that a\nsignificant portion of the popular dataset is transferred multiple times to\ndifferent users as well as to the same user for various reasons. In-network\ndata caching for the shared data has shown to reduce the redundant data\ntransfers and consequently save network traffic volume. In addition, overall\napplication performance is expected to improve with in-network caching because\naccess to the locally cached data results in lower latency. This paper shows\nhow much data was shared over the study period, how much network traffic volume\nwas consequently saved, and how much the temporary in-network caching increased\nthe scientific application performance. It also analyzes data access patterns\nin applications and the impacts of caching nodes on the regional data\nrepository. From the results, we observed that the network bandwidth demand was\nreduced by nearly a factor of 3 over the study period.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 16:01:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Copps", "Elizabeth", ""], ["Zhang", "Huiyi", ""], ["Sim", "Alex", ""], ["Wu", "Kesheng", ""], ["Monga", "Inder", ""], ["Guok", "Chin", ""], ["W\u00fcrthwein", "Frank", ""], ["Davila", "Diego", ""], ["Fajardo", "Edgar", ""]]}, {"id": "2105.01046", "submitter": "Hai Dao", "authors": "Dao Thanh Hai", "title": "Three Shades of Partial Protection in Elastic Optical Networks", "comments": "17 pages, 9 figures, submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Partial protection strategies based on the observation that in failure\nevents, a service can tolerate a certain amount of degradation and therefore by\nreducing the protection traffic in the network, better spectrum utilization\ncould be attained. Such concept has been widely studied in the traditional WDM\ncontext and yet has been somehow faded due to the fact that fixed transmission\ntechnologies allow small room for spectral improvement. This paper aims to\nrenew the interest in partial protection and re-adapt it to the context of\nelastic optical networks. The evolutionary perspective we lay out in this paper\nidentifies a new route for achieving greater spectral efficiency in a pragmatic\nway by simply differentiating the protection services for each demand rather\nthan the uniform treatment for all demands. In doing so, we present a new\nresearch problem entitled, routing, modulation level, spectrum and protection\nservice assignment which is an extension of the well-established one, that is,\nrouting, modulation level, and spectrum assignment as the (partial) protection\nservice for each demand is taken into account and optimized. Three variants of\nthat problem reflecting shades of applying partial protection are covered in\ndetails. Specifically, the first one considers the intuitive case as the\nrelative amount of protection traffic for each demand is given as the input to\nthe network planning process while the second one is dedicated to the special\ncase of enforcing the same figure of partial protection for all demands. More\ninteresting is brought in the third variant where given the service level\nagreement for the total network traffic, we provide the optimal solution that\ndetermine the protection service for each individual demand so as to minimize\nthe spectral occupancy.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 17:45:48 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hai", "Dao Thanh", ""]]}, {"id": "2105.01183", "submitter": "Andres Arcia Moret", "authors": "Andres Arcia-Moret, Jesus Gomez, Arjuna Sathiaseelan", "title": "Octopus: A Zero-Cost Architecture for Stream Network Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Considering the growing demand and popularity of Do-It-Yourself (DIY)\nnetworks, low-cost devices managed by the people, for the people and the ease\nof deployment of localised/decentralised Internet services, it is convenient\nfor such networks to have an efficient low-cost monitoring platform to ensure\navailability, responsiveness and users' Quality of Experience (QoE). This is\nespecially relevant for the developing world where Community Networks (CN) are\nincreasing in popularity and complexity. In this letter, we discuss Octopus: an\narchitecture for stream network monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 21:37:25 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Arcia-Moret", "Andres", ""], ["Gomez", "Jesus", ""], ["Sathiaseelan", "Arjuna", ""]]}, {"id": "2105.01194", "submitter": "Hai Dao", "authors": "Hai Dao", "title": "Three Commandments for Applying (Photonic) Network Coding To Optical\n  Core Networks", "comments": "6 pages, 6 figures, 4 tables, submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The digital transformation has been underway, creating digital shadows of\n(almost) all physical entities and moving them to the Internet. The era of\nInternet of Everything has therefore started to come into play, giving rise to\nunprecedented traffic growths. In this context, optical core networks forming\nthe backbone of Internet infrastructure have been under critical issues of\nreaching the capacity limit of conventional fiber, a phenomenon widely referred\nas capacity crunch. For many years, the many-fold increases in fiber capacity\nis thanks to exploiting physical dimensions for multiplexing optical signals\nsuch as wavelength, polarization, time and lately space-division multiplexing\nusing multi-core fibers and such route seems to come to an end as almost all\nknown ways have been exploited. This necessitates for a departure from\ntraditional approaches to use the fiber capacity more efficiently and thereby\nimprove economics of scale. This paper lays out a new perspective to integrate\nnetwork coding (NC) functions into optical networks to achieve greater capacity\nefficiency by upgrading intermediate nodes functionalities. In addition to the\nreview of recent proposals on new research problems enabled by NC operation in\noptical networks, we also report state-of-the-art findings in the literature in\nan effort to renew the interest of NC in optical networks and discuss three\ncritical points for pushing forward its applicability and practicality\nincluding i) NC as a new dimension for multiplexing optical signals ii)\nalgorithmic aspects of NC-enabled optical networks design iii) NC as an\nentirely fresh way for securing optical signals at physical layers\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 22:25:57 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Dao", "Hai", ""]]}, {"id": "2105.01308", "submitter": "Nguyen Van Huynh", "authors": "Nguyen Van Huynh, Diep N. Nguyen, Dinh Thai Hoang, Thang X. Vu, Eryk\n  Dutkiewicz, and Symeon Chatzinotas", "title": "Defeating Super-Reactive Jammers With Deception Strategy: Modeling,\n  Signal Detection, and Performance Analysis", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a novel framework to defeat a super-reactive jammer, one\nof the most difficult jamming attacks to deal with in practice. Specifically,\nthe jammer has an unlimited power budget and is equipped with the\nself-interference suppression capability to simultaneously attack and listen to\nthe transmitter's activities. Consequently, dealing with super-reactive jammers\nis very challenging. Thus, we introduce a smart deception mechanism to attract\nthe jammer to continuously attack the channel and then leverage jamming signals\nto transmit data based on the ambient backscatter communication technology. To\ndetect the backscattered signals, the maximum likelihood detector can be\nadopted. However, this method is notorious for its high computational\ncomplexity and requires the model of the current propagation environment as\nwell as channel state information. Hence, we propose a deep learning-based\ndetector that can dynamically adapt to any channels and noise distributions.\nWith a Long Short-Term Memory network, our detector can learn the received\nsignals' dependencies to achieve a performance close to that of the optimal\nmaximum likelihood detector. Through simulation and theoretical results, we\ndemonstrate that with our approaches, the more power the jammer uses to attack\nthe channel, the better bit error rate performance the transmitter can achieve.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 06:13:35 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Van Huynh", "Nguyen", ""], ["Nguyen", "Diep N.", ""], ["Hoang", "Dinh Thai", ""], ["Vu", "Thang X.", ""], ["Dutkiewicz", "Eryk", ""], ["Chatzinotas", "Symeon", ""]]}, {"id": "2105.01373", "submitter": "Xavier Gelabert", "authors": "J. Rodriguez, G. P. Koudouridis, X. Gelabert, M. Tayyab, R. Bassoli,\n  F. H.P. Fitzek, R. Torre, R. Abd-Alhameed, M. Sajedin, I. Elfergani, S. Irum,\n  G. Schulte, P. Diogo, F. Marzouk, M. de Ree, G. Mantas, I. Politis", "title": "Secure Virtual Mobile Small Cells: A Stepping Stone Towards 6G", "comments": "9 pages, 5 figures. IEEE Communications Standards Magazine, 2021", "journal-ref": null, "doi": "10.1109/MCOMSTD.001.2000019", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As 5th Generation research reaches the twilight, the research community must\ngo beyond 5G and look towards the 2030 connectivity landscape, namely 6G. In\nthis context, this work takes a step towards the 6G vision by proposing a next\ngeneration communication platform, which aims to extend the rigid coverage area\nof fixed deployment networks by considering virtual mobile small cells (MSC)\nthat are created on demand. Relying on emerging computing paradigms such as NFV\n(Network Function Virtualization) and SDN (Software Defined Networking), these\ncells can harness radio and networking capability locally reducing protocol\nsignaling latency and overhead. These MSCs constitute an intelligent pool of\nnetworking resources that can collaborate to form a wireless network of MSCs\nproviding a communication platform for localized, ubiquitous and reliable\nconnectivity. The technology enablers for implementing the MSC concept are also\naddressed in terms of virtualization, lightweight wireless security, and energy\nefficient RF. The benefits of the MSC architecture towards reliable and\nefficient cell offloading are demonstrated as a use-case.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 09:01:54 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Rodriguez", "J.", ""], ["Koudouridis", "G. P.", ""], ["Gelabert", "X.", ""], ["Tayyab", "M.", ""], ["Bassoli", "R.", ""], ["Fitzek", "F. H. P.", ""], ["Torre", "R.", ""], ["Abd-Alhameed", "R.", ""], ["Sajedin", "M.", ""], ["Elfergani", "I.", ""], ["Irum", "S.", ""], ["Schulte", "G.", ""], ["Diogo", "P.", ""], ["Marzouk", "F.", ""], ["de Ree", "M.", ""], ["Mantas", "G.", ""], ["Politis", "I.", ""]]}, {"id": "2105.01478", "submitter": "Jithin Jagannath", "authors": "Keyvan Ramezanpour and Jithin Jagannath", "title": "Intelligent Zero Trust Architecture for 5G/6G Tactical Networks:\n  Principles, Challenges, and the Role of Machine Learning", "comments": "Submitted for possible publication in IEEE Journal. For\n  non-commercial use only. Please contact Dr. Jithin Jagannath for any other\n  use case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this position paper, we discuss the critical need for integrating zero\ntrust (ZT) principles into next-generation communication networks (5G/6G) for\nboth tactical and commercial applications. We highlight the challenges and\nintroduce the concept of an intelligent zero trust architecture (i-ZTA) as a\nsecurity framework in 5G/6G networks with untrusted components. While network\nvirtualization, software-defined networking (SDN), and service-based\narchitectures (SBA) are key enablers of 5G networks, operating in an untrusted\nenvironment has also become a key feature of the networks. Further, seamless\nconnectivity to a high volume of devices in multi-radio access technology (RAT)\nhas broadened the attack surface on information infrastructure. Network\nassurance in a dynamic untrusted environment calls for revolutionary\narchitectures beyond existing static security frameworks. This paper presents\nthe architectural design of an i-ZTA upon which modern artificial intelligence\n(AI) algorithms can be developed to provide information security in untrusted\nnetworks. We introduce key ZT principles as real-time Monitoring of the\nsecurity state of network assets, Evaluating the risk of individual access\nrequests, and Deciding on access authorization using a dynamic trust algorithm,\ncalled MED components. The envisioned architecture adopts an SBA-based design,\nsimilar to the 3GPP specification of 5G networks, by leveraging the open radio\naccess network (O-RAN) architecture with appropriate real-time engines and\nnetwork interfaces for collecting necessary machine learning data. The i-ZTA is\nalso expected to exploit the multi-access edge computing (MEC) technology of 5G\nas a key enabler of intelligent MED components for resource-constraint devices.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 13:14:29 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ramezanpour", "Keyvan", ""], ["Jagannath", "Jithin", ""]]}, {"id": "2105.01511", "submitter": "Ruisi He", "authors": "Ruisi He, Bo Ai, Zhangdui Zhong, Mi Yang, Chen Huang, Ruifeng Chen,\n  Jianwen Ding, Hang Mi, Zhangfeng Ma, Guiqi Sun, Changzhu Liu", "title": "Radio Communication Scenarios in 5G-Railways", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of railways, especially high-speed railways, there\nis an increasingly urgent demand for new wireless communication system for\nrailways. Taking the mature 5G technology as an opportunity, 5G-railways (5G-R)\nhave been widely regarded as a solution to meet the diversified demands of\nrailway wireless communications. For the design, deployment and improvement of\n5G-R networks, radio communication scenario classification plays an important\nrole, affecting channel modeling and system performance evaluation. In this\npaper, a standardized radio communication scenario classification, including 18\nscenarios, is proposed for 5G-R. This paper analyzes the differences of 5G-R\nscenarios compared with the traditional cellular networks and GSM-railways,\naccording to 5G-R requirements and the unique physical environment and\npropagation characteristics. The proposed standardized scenario classification\nhelps deepen the research of 5G-R and promote the development and application\nof the existing advanced technologies in railways.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 07:09:09 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["He", "Ruisi", ""], ["Ai", "Bo", ""], ["Zhong", "Zhangdui", ""], ["Yang", "Mi", ""], ["Huang", "Chen", ""], ["Chen", "Ruifeng", ""], ["Ding", "Jianwen", ""], ["Mi", "Hang", ""], ["Ma", "Zhangfeng", ""], ["Sun", "Guiqi", ""], ["Liu", "Changzhu", ""]]}, {"id": "2105.01641", "submitter": "Silviu Craciunas", "authors": "Mohammadreza Barzegaran, Niklas Reusch, Luxi Zhao, Silviu S.\n  Craciunas, Paul Pop", "title": "Real-Time Guarantees for Critical Traffic in IEEE 802.1Qbv TSN Networks\n  with Unscheduled and Unsynchronized End-Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-Sensitive Networking (TSN) aims to extend the IEEE 802.1Q Ethernet\nstandard with real-time and time-aware capabilities. Each device's transmission\nof time-critical frames is done according to a so-called Gate Control List\n(GCL) schedule via the timed-gate mechanism described in IEEE 802.1Qbv. Most\nschedule generation mechanisms for TSN have a constraining assumption that both\nswitches and end-systems in the network must have at least the TSN capabilities\nrelated to scheduled gates and time synchronization. However, many TSN networks\nuse off-the-shelf end-systems, e.g., for providing sensor data, which are not\nscheduled and/or synchronized.\n  In this paper, we propose a more flexible scheduling strategy that considers\na worst-case delay analysis within the scheduling synthesis step, leveraging\nthe solution's optimality to support TSN networks with unscheduled and\nunsynchronized end-systems while still being able to guarantee bounded latency\nfor critical messages. Our method enables real-world systems that feature\noff-the-shelf microcontrollers and sensor nodes without TSN capabilities\nconnected to state-of-the-art TSN networks to communicate critical messages in\na real-time fashion. We evaluate our approach using both synthetic and\nreal-world test cases, comparing it with existing scheduling mechanisms.\nFurthermore, we use OMNET++ to validate the generated GCL schedules.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 17:37:06 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Barzegaran", "Mohammadreza", ""], ["Reusch", "Niklas", ""], ["Zhao", "Luxi", ""], ["Craciunas", "Silviu S.", ""], ["Pop", "Paul", ""]]}, {"id": "2105.01771", "submitter": "Sumudu Samarakoon Dr.", "authors": "Sumudu Samarakoon and Jihong Park and Mehdi Bennis", "title": "Robust Reconfigurable Intelligent Surfaces via Invariant Risk and Causal\n  Representations", "comments": "5 pages, 5 figures, conference: The 22nd IEEE International Workshop\n  on Signal Processing Advances in Wireless Communications (SPAWC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of robust reconfigurable intelligent surface (RIS)\nsystem design under changes in data distributions is investigated. Using the\nnotion of invariant risk minimization (IRM), an invariant causal representation\nacross multiple environments is used such that the predictor is simultaneously\noptimal for each environment. A neural network-based solution is adopted to\nseek the predictor and its performance is validated via simulations against an\nempirical risk minimization-based design. Results show that leveraging\ninvariance yields more robustness against unseen and out-of-distribution\ntesting environments.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 21:36:31 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Samarakoon", "Sumudu", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2105.01901", "submitter": "Nicolas Kuhn Dr.", "authors": "Kuhn Nicolas and Fernandes David and Dubois Emmanuel and Pradas David", "title": "Impact of channel access and transport mechanisms on QoE in\n  GEO-satellite based LTE backhauling systems", "comments": "5 pages, 5 Figures, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Backhauling services through satellite systems have doubled between 2012 and\n2018. There is an increasing demand for this service for which satellite\nsystems typically allocate a fixed resource. This solution may not help in\noptimizing the usage of the scarce satellite resource.\n  This study measures the relevance of using dynamic resource allocation\nmechanisms for backhaul services through satellite systems. The satellite\nsystem is emulated with OpenSAND, the LTE system with Amarisoft and the\nexperiments are orchestrated by OpenBACH. We compare the relevance of applying\nTCP PEP mechanisms and dynamic resource allocations for different traffic\nservices by measuring the QoE for web browsing, data transfer and VoIP\napplications.\n  The main conclusions are the following. When the system is congested, PEP and\nlayer-2 access mechanisms do not provide significant improvements. When the\nsystem is not congested, data transfer can be greatly improved through\nprotocols and channel access mechanism optimization. Tuning the Constant Rate\nAssignment can help in reducing the cost of the resource and provide QoE\nimprovements when the network is not loaded.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 07:27:29 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Nicolas", "Kuhn", ""], ["David", "Fernandes", ""], ["Emmanuel", "Dubois", ""], ["David", "Pradas", ""]]}, {"id": "2105.01948", "submitter": "Marcin Hoffmann", "authors": "Marcin Hoffmann, Pawe{\\l} Kryszkiewicz", "title": "Similarity Measures for Location-Dependent MMIMO, 5G Base Stations\n  On/Off Switching Using Radio Environment Map", "comments": null, "journal-ref": null, "doi": "10.1109/WoWMoM51794.2021.00053", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Massive Multiple-Input Multiple-Output (MMIMO) technique together with\nHeterogeneous Network (Het-Net) deployment enables high throughput of 5G and\nbeyond networks. However, a high number of antennas and a high number of Base\nStations (BSs) can result in significant power consumption. Previous studies\nhave shown that the energy efficiency (EE) of such a network can be effectively\nincreased by turning off some BSs depending on User Equipments (UEs) positions.\nSuch mapping is obtained by using Reinforcement Learning. Its results are\nstored in a so-called Radio Environment Map (REM). However, in a real network,\nthe number of UEs' positions patterns would go to infinity. This paper aims to\ndetermine how to match the current set of UEs' positions to the most similar\npattern, i.e., providing the same optimal active BSs set, saved in REM. We\ncompare several state-of-the-art distance metrics using a computer simulator:\nan accurate 3D-Ray-Tracing model of the radio channel and an advanced\nsystem-level simulator of MMIMO Het-Net. The results have shown that the\nso-called Sum of Minimums Distance provides the best matching between REM data\nand UEs' positions, enabling up to 56% EE improvement over the scenario without\nEE optimization.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 09:36:30 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Hoffmann", "Marcin", ""], ["Kryszkiewicz", "Pawe\u0142", ""]]}, {"id": "2105.01988", "submitter": "Jonathan Falk", "authors": "Jonathan Falk, Heiko Geppert, Frank D\\\"urr, Sukanya Bhowmik, Kurt\n  Rothermel", "title": "Dynamic QoS-Aware Traffic Planning for Time-Triggered Flows with\n  Conflict Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR-2021/01", "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many networked applications, e.g., in the domain of cyber-physical systems,\nrequire strict service guarantees, usually in the form of jitter and latency\nbounds, for time-triggered traffic flows. It is a notoriously hard problem to\ncompute a network-wide traffic plan that satisfies these requirements, and\ndynamic changes in the flow set add even more challenges. Existing\ntraffic-planning methods are ill-suited for dynamic scenarios because they\neither suffer from high computational cost, can result in low network\nutilization, or provide no explicit guarantees when transitioning to a new\ntraffic plan that incorporates new flows.\n  Therefore, we present a novel approach for dynamic traffic planning of\ntime-triggered flows. Our conflict-graph based modeling of the traffic planning\nproblem allows to reconfigure active flows to increase the network utilization,\nwhile also providing per-flow QoS guarantees during the transition to the new\ntraffic plan. Additionally, we introduce a novel heuristic for computing the\nnew traffic plans. Evaluations of our prototypical implementation show that we\ncan efficiently compute new traffic plans in scenarios with hundreds of active\nflows for a wide range of scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 11:31:58 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Falk", "Jonathan", ""], ["Geppert", "Heiko", ""], ["D\u00fcrr", "Frank", ""], ["Bhowmik", "Sukanya", ""], ["Rothermel", "Kurt", ""]]}, {"id": "2105.02002", "submitter": "Ashok Krishnan K.S.", "authors": "Ashok Krishnan K.S, Chandramani Singh, Siva Theja Maguluri, Parimal\n  Parag", "title": "Optimal Pricing in Multi Server Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study optimal service pricing in server farms where customers arrive\naccording to a renewal process and have independent and identical ($i.i.d.$)\nexponential service times and $i.i.d.$ valuations of the service. The service\nprovider charges a time varying service fee aiming at maximizing its revenue\nrate. The customers that find free servers and service fees lesser than their\nvaluation join for the service else they leave without waiting. We consider\nboth finite server and infinite server farms. We solve the optimal pricing\nproblems using the framework of Markov decision problems. We show that the\noptimal prices depend on the number of free servers. We propose algorithms to\ncompute the optimal prices. We also establish several properties of the optimal\nprices and the corresponding revenue rates in the case of Poisson customer\narrivals. We illustrate all our findings via numerical results.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 11:56:54 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["S", "Ashok Krishnan K.", ""], ["Singh", "Chandramani", ""], ["Maguluri", "Siva Theja", ""], ["Parag", "Parimal", ""]]}, {"id": "2105.02051", "submitter": "Ilaria Malanchini", "authors": "Ilaria Malanchini, Patrick Agostini, Khurshid Alam, Michael Baumgart,\n  Martin Kasparick, Qi Liao, Fabian Lipp, Nikolaj Marchenko, Nicola Michailow,\n  Rastin Pries, Hans Schotten, Slawomir Stanczak, Stanislaw Strzyz", "title": "Leveraging Machine Learning for Industrial Wireless Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two main trends characterize today's communication landscape and are finding\ntheir way into industrial facilities: the rollout of 5G with its distinct\nsupport for vertical industries and the increasing success of machine learning\n(ML). The combination of those two technologies open the doors to many exciting\nindustrial applications and its impact is expected to rapidly increase in the\ncoming years, given the abundant data growth and the availability of powerful\nedge computers in production facilities. Unlike most previous work that has\nconsidered the application of 5G and ML in industrial environment separately,\nthis paper highlights the potential and synergies that result from combining\nthem. The overall vision presented here generates from the KICK project, a\ncollaboration of several partners from the manufacturing and communication\nindustry as well as research institutes. This unprecedented blend of 5G and ML\nexpertise creates a unique perspective on ML-supported industrial\ncommunications and their role in facilitating industrial automation. The paper\nidentifies key open industrial challenges that are grouped into four use cases:\nwireless connectivity and edge-cloud integration, flexibility in network\nreconfiguration, dynamicity of heterogeneous network services, and mobility of\nrobots and vehicles. Moreover, the paper provides insights into the advantages\nof ML-based industrial communications and discusses current challenges of data\nacquisition in real systems.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 13:43:10 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Malanchini", "Ilaria", ""], ["Agostini", "Patrick", ""], ["Alam", "Khurshid", ""], ["Baumgart", "Michael", ""], ["Kasparick", "Martin", ""], ["Liao", "Qi", ""], ["Lipp", "Fabian", ""], ["Marchenko", "Nikolaj", ""], ["Michailow", "Nicola", ""], ["Pries", "Rastin", ""], ["Schotten", "Hans", ""], ["Stanczak", "Slawomir", ""], ["Strzyz", "Stanislaw", ""]]}, {"id": "2105.02146", "submitter": "Suayb Arslan", "authors": "Suayb S. Arslan, Massoud Pourmandi, Elif Haytaoglu", "title": "Cooperative Network Coding for Distributed Storage using Base Stations\n  with Link Constraints", "comments": "8 pages, 4 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider a novel distributed data storage/caching scenario\nin a cellular setting where multiple nodes may fail/depart at the same time. In\norder to maintain the target reliability, we allow cooperative regeneration of\nlost nodes with the help of base stations allocated in a set of hierarchical\nlayers. Due to this layered structure, a symbol download from each base station\nhas a different cost, while the link capacities connecting the nodes of the\ncellular system and the base stations are also limited. In this more practical\nand general scenario, we present the fundamental trade-off between repair\nbandwidth cost and the storage space per node. Particularly interesting\noperating points are the minimum storage as well as bandwidth cost points in\nthis trade-off curve. We provide closed-form expressions for the corresponding\nbandwidth (cost) and storage space per node for these operating points.\nFinally, we provide an explicit optimal code construction for the minimum\nstorage regeneration point for a given set of system parameters.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 15:57:07 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Arslan", "Suayb S.", ""], ["Pourmandi", "Massoud", ""], ["Haytaoglu", "Elif", ""]]}, {"id": "2105.02147", "submitter": "Bryar Hassan Dr.", "authors": "Miran Hama Rahim Saeed, Bryar A. Hassan, Shko M. Qader", "title": "An Optimized Framework to Adopt Computer Laboratory Administrations for\n  Operating System and Application Installations", "comments": null, "journal-ref": null, "doi": "10.24017/science.2017.3.8", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Nowadays, in most of the fields, task automation is area of interest and\nresearch due to that manual execution of a task is error prone, time consuming,\ninvolving more human resources and focus concerning. In the area of Computer\nlaboratory administration, the old fashioned administration cannot run with\ntodays growth, where the Operating System (OS) and required applications are\ninstalled on all the machines one by one. Therefore, a framework for automating\nLab administration in regards of Operating Systems and Application\ninstallations will be proposed in this research. Affordability, simplicity,\nusability are taken into major consideration. All the parts of the framework\nare implemented and illustrated in detail which promotes a great enhancement in\nthe area of Computer Lab Administration.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 15:58:40 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Saeed", "Miran Hama Rahim", ""], ["Hassan", "Bryar A.", ""], ["Qader", "Shko M.", ""]]}, {"id": "2105.02346", "submitter": "Pavlos Sermpezis", "authors": "Pavlos Sermpezis, Vasileios Kotronis, Konstantinos Arakadakis, Athena\n  Vakali", "title": "Estimating the Impact of BGP Prefix Hijacking", "comments": "IFIP Networking conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  BGP prefix hijacking is a critical threat to the resilience and security of\ncommunications in the Internet. While several mechanisms have been proposed to\nprevent, detect or mitigate hijacking events, it has not been studied how to\naccurately quantify the impact of an ongoing hijack. When detecting a hijack,\nexisting methods do not estimate how many networks in the Internet are affected\n(before and/or after its mitigation). In this paper, we study fundamental and\npractical aspects of the problem of estimating the impact of an ongoing hijack\nthrough network measurements. We derive analytical results for the involved\ntrade-offs and limits, and investigate the performance of different measurement\napproaches (control/data-plane measurements) and use of public measurement\ninfrastructure. Our findings provide useful insights for the design of accurate\nhijack impact estimation methodologies. Based on these insights, we design (i)\na lightweight and practical estimation methodology that employs ping\nmeasurements, and (ii) an estimator that employs public infrastructure\nmeasurements and eliminates correlations between them to improve the accuracy.\nWe validate the proposed methodologies and findings against results from\nhijacking experiments we conduct in the real Internet.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 22:06:58 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Sermpezis", "Pavlos", ""], ["Kotronis", "Vasileios", ""], ["Arakadakis", "Konstantinos", ""], ["Vakali", "Athena", ""]]}, {"id": "2105.02371", "submitter": "Arvin Tashakori", "authors": "Arvin Tashakori", "title": "Survey on Multi-Agent Q-Learning frameworks for resource management in\n  wireless sensor network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report aims to survey multi-agent Q-Learning algorithms, analyze\ndifferent game theory frameworks used, address each framework's applications,\nand report challenges and future directions. The target application for this\nstudy is resource management in the wireless sensor network.\n  In the first section, the author provided an introduction regarding the\napplications of wireless sensor networks. After that, the author presented a\nsummary of the Q-Learning algorithm, a well-known classic solution for\nmodel-free reinforcement learning problems.\n  In the third section, the author extended the Q-Learning algorithm for\nmulti-agent scenarios and discussed its challenges.\n  In the fourth section, the author surveyed sets of game-theoretic frameworks\nthat researchers used to address this problem for resource allocation and task\nscheduling in the wireless sensor networks. Lastly, the author mentioned some\ninteresting open challenges in this domain.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 23:43:30 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Tashakori", "Arvin", ""]]}, {"id": "2105.02510", "submitter": "Tareq Si Salem", "authors": "Tareq Si Salem, Gabriele Castellano, Giovanni Neglia, Fabio Pianese\n  and Andrea Araldo", "title": "Towards Inference Delivery Networks: Distributing Machine Learning with\n  Optimality Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An increasing number of applications rely on complex inference tasks that are\nbased on machine learning (ML). Currently, there are two options to run such\ntasks: either they are served directly by the end device (e.g., smartphones,\nIoT equipment, smart vehicles), or offloaded to a remote cloud. Both options\nmay be unsatisfactory for many applications: local models may have inadequate\naccuracy, while the cloud may fail to meet delay constraints. In this paper, we\npresent the novel idea of \\emph{inference delivery networks} (IDNs), networks\nof computing nodes that coordinate to satisfy ML inference requests achieving\nthe best trade-off between latency and accuracy. IDNs bridge the dichotomy\nbetween device and cloud execution by integrating inference delivery at the\nvarious tiers of the infrastructure continuum (access, edge, regional data\ncenter, cloud). We propose a distributed dynamic policy for ML model allocation\nin an IDN by which each node dynamically updates its local set of inference\nmodels based on requests observed during the recent past plus limited\ninformation exchange with its neighboring nodes. Our policy offers strong\nperformance guarantees in an adversarial setting and shows improvements over\ngreedy heuristics with similar complexity in realistic scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 08:18:17 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 20:29:17 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Salem", "Tareq Si", ""], ["Castellano", "Gabriele", ""], ["Neglia", "Giovanni", ""], ["Pianese", "Fabio", ""], ["Araldo", "Andrea", ""]]}, {"id": "2105.02710", "submitter": "Sebastian Garcia PhD.", "authors": "Lisandro Ubiedo, Thomas O'Hara, Mar\\'ia Jos\\'e Erquiaga and Sebastian\n  Garcia", "title": "Current State of IPv6 Security in IoT", "comments": "Editor: Veronica Valeros", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This report presents the current state of security in IPv6 for IoT devices.\nIn this research conducted from May 2020 to July 2020, we explored the global\ngrowth of IPv6 and compared it with the real growth of IPv6 in a medium size\nnetwork. If IPv6 is already being used, are attackers already attacking using\nthis protocol? To answer this question we look at the current vulnerabilities,\nattacks, and malware leveraging IPv6.\n  Our research showed that while IPv6 adoption is growing, we are years away of\na full adoption. The current global adoption is of 35\\%, however there are\ncountries rapidly adopting IPv6, such as India with 60\\% of IPv6 enabled in the\ncountry.\n  IPv6 brings new challenges for both attackers and defenders. With a larger\naddress space, the activity of device discovery will force attackers to devise\nnew techniques and tools. Defenders will also have to adapt their tools and\nmonitoring technology to be able to work with IPv6.\n  There are currently more than 16 million devices exposed on the internet on\nIPv6, however malware authors seem to be still focused mainly on IPv4. There is\nto date, one malware capable of attacking IPv6 networks. This may give an edge\nto defenders, who have now the opportunity to give the first step ahead of\nattackers.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 14:53:23 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ubiedo", "Lisandro", ""], ["O'Hara", "Thomas", ""], ["Erquiaga", "Mar\u00eda Jos\u00e9", ""], ["Garcia", "Sebastian", ""]]}, {"id": "2105.02755", "submitter": "Bechir Hamdaoui", "authors": "Bechir Hamdaoui, Abdurrahman Elmaghbub, Seifeddine Mejri", "title": "Deep Neural Network Feature Designs for RF Data-Driven Wireless Device\n  Classification", "comments": null, "journal-ref": null, "doi": "10.1109/MNET.011.2000492", "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most prior works on deep learning-based wireless device classification using\nradio frequency (RF) data apply off-the-shelf deep neural network (DNN) models,\nwhich were matured mainly for domains like vision and language. However,\nwireless RF data possesses unique characteristics that differentiate it from\nthese other domains. For instance, RF data encompasses intermingled time and\nfrequency features that are dictated by the underlying hardware and protocol\nconfigurations. In addition, wireless RF communication signals exhibit\ncyclostationarity due to repeated patterns (PHY pilots, frame prefixes, etc.)\nthat these signals inherently contain. In this paper, we begin by explaining\nand showing the unsuitability as well as limitations of existing DNN feature\ndesign approaches currently proposed to be used for wireless device\nclassification. We then present novel feature design approaches that exploit\nthe distinct structures of the RF communication signals and the spectrum\nemissions caused by transmitter hardware impairments to custom-make DNN models\nsuitable for classifying wireless devices using RF signal data. Our proposed\nDNN feature designs substantially improve classification robustness in terms of\nscalability, accuracy, signature anti-cloning, and insensitivity to environment\nperturbations. We end the paper by presenting other feature design strategies\nthat have great potentials for providing further performance improvements of\nthe DNN-based wireless device classification, and discuss the open research\nchallenges related to these proposed strategies.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 20:19:05 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Hamdaoui", "Bechir", ""], ["Elmaghbub", "Abdurrahman", ""], ["Mejri", "Seifeddine", ""]]}, {"id": "2105.02762", "submitter": "Danilo B\\'orquez-Paredes Ph.D.", "authors": "Felipe Falc\\'on and Gonzalo Espa\\~na and Danilo B\\'orquez-Paredes", "title": "Flex Net Sim: A Lightly Manual", "comments": "9 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common problem in elastic optical networks is to study the behavior of\ndifferent resources allocation algorithms, such as signal modulation formats or\nquality of service, in optical networks in dynamic scenarios where connections\nare assigned and released following different traffic profiles. To achieve\nthis, one of the busiest tools is simulators. Normally each research group has\nits own simulator created entirely by them, which works on a particular\nsimulation scenario, generating multiple versions of the same simulator. For\nthis reason, this project aims to create a tool that allows focusing on the\ncreation of algorithms, generating a common platform for simulation. We present\na C ++ library that contains the most common modules belonging to an\nevent-oriented simulator for flexible grid optical networks. This library\nallows researchers to worry about algorithm generation rather than\nmaintaining/modifying a simulator. The final product is a library capable of\nbeing included in any program written in C ++, allowing the design of resource\nallocation algorithms through macros used in the same source file of the user\nthat uses the library.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 15:35:00 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Falc\u00f3n", "Felipe", ""], ["Espa\u00f1a", "Gonzalo", ""], ["B\u00f3rquez-Paredes", "Danilo", ""]]}, {"id": "2105.02867", "submitter": "Baturalp Buyukates", "authors": "Baturalp Buyukates and Melih Bastopcu and Sennur Ulukus", "title": "Age of Gossip in Networks with Community Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a network consisting of a single source and $n$ receiver nodes\nthat are grouped into $m$ equal size communities, i.e., clusters, where each\ncluster includes $k$ nodes and is served by a dedicated cluster head. The\nsource node keeps versions of an observed process and updates each cluster\nthrough the associated cluster head. Nodes within each cluster are connected to\neach other according to a given network topology. Based on this topology, each\nnode relays its current update to its neighboring nodes by $local$ $gossiping$.\nWe use the $version$ $age$ metric to quantify information timeliness at the\nreceiver nodes. We consider disconnected, ring, and fully connected network\ntopologies for each cluster. For each of these network topologies, we\ncharacterize the average version age at each node and find the version age\nscaling as a function of the network size $n$. Our results indicate that per\nnode version age scalings of $O(\\sqrt{n})$, $O(n^{\\frac{1}{3}})$, and $O(\\log\nn)$ are achievable in disconnected, ring, and fully connected cluster models,\nrespectively. Finally, through numerical evaluations, we determine the version\nage-optimum $(m,k)$ pairs as a function of the source, cluster head, and node\nupdate rates.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:52:33 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 22:18:09 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Buyukates", "Baturalp", ""], ["Bastopcu", "Melih", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2105.02905", "submitter": "Roberto Metere", "authors": "Roberto Metere, Myriam Neaimeh, Charles Morisset, Carsten Maple,\n  Xavier Bellekens, Ricardo M. Czekster", "title": "Securing the Electric Vehicle Charging Infrastructure", "comments": "39 pages, white paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electric Vehicles (EVs) can help alleviate our reliance on fossil fuels for\ntransport and electricity systems. However, charging millions of EV batteries\nrequires management to prevent overloading the electricity grid and minimise\ncostly upgrades that are ultimately paid for by consumers.\n  Managed chargers, such as Vehicle-to-Grid (V2G) chargers, allow control over\nthe time, speed and direction of charging. Such control assists in balancing\nelectricity supply and demand across a green electricity system and could\nreduce costs for consumers.\n  Smart and V2G chargers connect EVs to the power grid using a charging device\nwhich includes a data connection to exchange information and control commands\nbetween various entities in the EV ecosystem. This introduces data privacy\nconcerns and is a potential target for cyber-security attacks. Therefore, the\nimplementation of a secure system is crucial to permit both consumers and\nelectricity system operators to trust smart charging and V2G.\n  In principle, we already have the technology needed for a connected EV\ncharging infrastructure to be securely enabled, borrowing best practices from\nthe Internet and industrial control systems. We must properly adapt the\nsecurity technology to take into account the challenges peculiar to the EV\ncharging infrastructure. Challenges go beyond technical considerations and\nother issues arise such as balancing trade-offs between security and other\ndesirable qualities such as interoperability, scalability, crypto-agility,\naffordability and energy efficiency.\n  This document reviews security and privacy topics relevant to the EV charging\necosystem with a focus on smart charging and V2G.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 18:10:42 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Metere", "Roberto", ""], ["Neaimeh", "Myriam", ""], ["Morisset", "Charles", ""], ["Maple", "Carsten", ""], ["Bellekens", "Xavier", ""], ["Czekster", "Ricardo M.", ""]]}, {"id": "2105.02920", "submitter": "Ginno Mill\\'an", "authors": "G. Mill\\'an", "title": "On the Time Series Length for an Accurate Fractal Analysis in Network\n  Systems", "comments": "7 pages, in Spanish, 8 figures, Draft Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  It is well-known that fractal signals appear in many fields of science. LAN\nand WWW traces, wireless traffic, VBR resources, etc. are among the ones with\nthis behavior in computer networks traffic flows. An important question in\nthese applications is how long a measured trace should be to obtain reliable\nestimates of de Hurst index (H). This paper addresses this question by first\nproviding a thorough study of estimator for short series based on the behavior\nof bias, standard deviation (s), Root-Mean-Square Error (RMSE), and convergence\nwhen using Gaussian H-Self-Similar with Stationary Increments signals (H-sssi\nsignals). Results show that Whittle-type estimators behave the best when\nestimating H for short signals. Based on the results, empirically derived the\nminimum trace length for the estimators is proposed. Finally for testing the\nresults, the application of estimators to real traces is accomplished.\nImmediate applications from this can be found in the real-time estimation of H\nwhich is useful in agent-based control of Quality of Service (QoS) parameters\nin the high-speed computer network traffic flows.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 19:32:47 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Mill\u00e1n", "G.", ""]]}, {"id": "2105.03204", "submitter": "Mahendra Shukla", "authors": "Abhishek Gupta, Om Jee Pandey, Mahendra Shukla, Anjali Dadhich, Samar\n  Mathur, Anup Ingle", "title": "Computational Intelligence based Intrusion Detection Systems for\n  Wireless Communication", "comments": null, "journal-ref": null, "doi": "10.1109/ICCIC.2013.6724156", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The emerging trend of ubiquitous and pervasive computing aims at embedding\neveryday devices such as wristwatches, smart phones, home video systems,\nautofocus cameras, intelligent vehicles, musical instruments, kitchen\nappliances etc. with microprocessors and imparts them with wireless\ncommunication capability. This advanced computing paradigm, also known as the\nInternet of Things or cyber-physical computing, leads internet and computing to\nappear everywhere and anywhere using any device and location. With maximum\nappreciation and due regards to the evolutionary arc, depth and scope of\nceaseless internet utilities, it is equally necessary to envisage the security\nand data confidentiality challenges posed by the free and ubiquitous\navailability of internet. This paper analyses the role of computational\nintelligence techniques to design adaptive and cognitive intrusion detection\nsystems that can efficiently detect malicious network activities and proposes\nnovel three-tier architecture for designing intelligent intrusion detection\nsystems for wireless networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 10:14:52 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Gupta", "Abhishek", ""], ["Pandey", "Om Jee", ""], ["Shukla", "Mahendra", ""], ["Dadhich", "Anjali", ""], ["Mathur", "Samar", ""], ["Ingle", "Anup", ""]]}, {"id": "2105.03220", "submitter": "Abdollah Ghaffari Sheshjavani", "authors": "Abdollah Ghaffari Sheshjavani (1), Ahmad Khonsari (1 and 2), Seyed\n  Pooya Shariatpanahi (1), Masoumeh Moradian (2) ((1) School of Electrical and\n  Computer Engineering, College of Engineering, University of Tehran, Iran, (2)\n  School of Computer Science, Institute for Research in Fundamental Sciences\n  (IPM), Iran)", "title": "Content Caching for Shared Medium Networks Under Heterogeneous Users'\n  Behaviours", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content caching is a widely studied technique aimed to reduce the network\nload imposed by data transmission during peak time while ensuring users'\nquality of experience. It has been shown that when there is a common link\nbetween caches and the server, delivering contents via the coded caching scheme\ncan significantly improve performance over conventional caching. However,\nfinding the optimal content placement is a challenge in the case of\nheterogeneous users' behaviours. In this paper we consider heterogeneous number\nof demands and non-uniform content popularity distribution in the case of\nhomogeneous and heterogeneous user preferences. We propose a hybrid\ncoded-uncoded caching scheme to trade-off between popularity and diversity. We\nderive explicit closed-form expressions of the server load for the proposed\nhybrid scheme and formulate the corresponding optimization problem. Results\nshow that the proposed hybrid caching scheme can reduce the server load\nsignificantly and outperforms the baseline pure coded and pure uncoded and\nprevious works in the literature for both homogeneous and heterogeneous user\npreferences.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 12:49:45 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Sheshjavani", "Abdollah Ghaffari", "", "1 and 2"], ["Khonsari", "Ahmad", "", "1 and 2"], ["Shariatpanahi", "Seyed Pooya", ""], ["Moradian", "Masoumeh", ""]]}, {"id": "2105.03221", "submitter": "Jaafar Elmirghani", "authors": "Barzan A. Yosuf, Sanaa H. Mohamed, Mohamed Alenazi, Taisir E. H.\n  El-Gorashi and Jaafar M. H. Elmirghani", "title": "Energy-Efficient AI over a Virtualized Cloud Fog Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep Neural Networks (DNNs) have served as a catalyst in introducing a\nplethora of next-generation services in the era of Internet of Things (IoT),\nthanks to the availability of massive amounts of data collected by the objects\non the edge. Currently, DNN models are used to deliver many Artificial\nIntelligence (AI) services that include image and natural language processing,\nspeech recognition, and robotics. Accordingly, such services utilize various\nDNN models that make it computationally intensive for deployment on the edge\ndevices alone. Thus, most AI models are offloaded to distant cloud data centers\n(CDCs), which tend to consolidate large amounts of computing and storage\nresources into one or more CDCs. Deploying services in the CDC will inevitably\nlead to excessive latencies and overall increase in power consumption. Instead,\nfog computing allows for cloud services to be extended to the edge of the\nnetwork, which allows for data processing to be performed closer to the\nend-user device. However, different from cloud data centers, fog nodes have\nlimited computational power and are highly distributed in the network. In this\npaper, using Mixed Integer Linear Programming (MILP), we formulate the\nplacement of DNN inference models, which is abstracted as a network embedding\nproblem in a Cloud Fog Network (CFN) architecture, where power savings are\nintroduced through trade-offs between processing and networking. We study the\nperformance of the CFN architecture by comparing the energy savings when\ncompared to the baseline approach which is the CDC.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 12:49:58 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Yosuf", "Barzan A.", ""], ["Mohamed", "Sanaa H.", ""], ["Alenazi", "Mohamed", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2105.03503", "submitter": "Hai Dao", "authors": "Dao Thanh Hai", "title": "The Consolation of Network Coding and Partial Protection Techniques to\n  Optical Transport Networks in Data, Data, Data Era", "comments": "5 pages, 5 figures, 2 tables, submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The age of acceleration is taking place, driven by the revolutionary digital\ntransformation creating basically a digital version of our physical world and\nthe currency in that digital space is data. Massive amount of data has been\ngenerated ranging from wearable devices monitoring our physical health every\nsingle millisecond to autonomous vehicles generating roughly 5Tb hourly to even\nastronomical activities producing an order of Exabytes on daily basis and then\nultra-broadband Internet comes into play, moving such data to the cloud.\nInternet traffic therefore has been experiencing explosive growth and in this\ncontext, optical transport networks forming the backbone of the Internet are\npushed for transformation in system capacity. While the intuitive solution of\ndeploying multiple fibers can address the pressing demand for increased\ncapacity, doing so does not bring improvement in economic of scales in terms of\ncost, power consumption and spectral efficiency. This necessitates for a\ndifferent approach so that the fiber capacity could be utilized in a more\nefficient manner. In this paper, we focus on innovative techniques, that is,\nnetwork coding and partial protection, to reduce the effective traffic load in\norder to achieve greater capacity efficiency for optical transport networks.\nSpecifically, the application of network coding is examined by upgrading the\nfunctionalities of intermediate nodes with processing (i.e., encoding and\ndecoding) capabilities. Besides, partial protection relying on the premise of\nproviding just enough bandwidth in case of failure events is investigated for\nsaving the redundant protection capacity. What is more interesting arises when\ncombining both network coding and partial protection and we present insights on\nhow to derive compounding gains in such unique prospect.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 21:00:37 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Hai", "Dao Thanh", ""]]}, {"id": "2105.03517", "submitter": "Mahmoud Al Shugran Shugran", "authors": "Mahmoud Ali Al Shugran", "title": "Applicability of overlay non-delay tolerant position-based protocols in\n  highways and urban environments for vanet", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vehicular Ad hoc Network (VANET) is a new sort of wireless ad-hoc network.\nVehicle-to-Vehicle (V2V) communication is one of the main communication\nparadigms that provide a level of safety and convenience to drivers and\npassengers on the road. In such an environment, routing data packets is\nchallenging due to frequent changes of network topology because of the highly\ndynamic nature of vehicles. Thus, routing in VANETs requires efficient\nprotocols that guarantee message transmission among vehicles. Numerous routing\nprotocols and algorithms have been proposed or enhanced to solve the\naforementioned problems. Many position-based routing protocols have been\ndeveloped for routing messages that have been identified to be appropriate for\nVANETs. This work explores the performances of selected unicast non-delay\ntolerant overlay position-based routing protocols. The evaluation has been\nconducted in highway and urban environments in two different scenarios. The\nevaluation metrics that are used are Packet Delivery Ratio (PDR), Void Problem\nOccurrence (VPO), and Average Hop Count (AHC).\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 21:36:16 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Shugran", "Mahmoud Ali Al", ""]]}, {"id": "2105.03591", "submitter": "Pengyuan Zhou", "authors": "Pengyuan Zhou, Pei Fang, Pan Hui", "title": "Loss Tolerant Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated learning has attracted attention in recent years for\ncollaboratively training data on distributed devices with privacy-preservation.\nThe limited network capacity of mobile and IoT devices has been seen as one of\nthe major challenges for cross-device federated learning. Recent solutions have\nbeen focusing on threshold-based client selection schemes to guarantee the\ncommunication efficiency. However, we find this approach can cause biased\nclient selection and results in deteriorated performance. Moreover, we find\nthat the challenge of network limit may be overstated in some cases and the\npacket loss is not always harmful. In this paper, we explore the loss tolerant\nfederated learning (LT-FL) in terms of aggregation, fairness, and\npersonalization. We use ThrowRightAway (TRA) to accelerate the data uploading\nfor low-bandwidth-devices by intentionally ignoring some packet losses. The\nresults suggest that, with proper integration, TRA and other algorithms can\ntogether guarantee the personalization and fairness performance in the face of\npacket loss below a certain fraction (10%-30%).\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 04:44:47 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhou", "Pengyuan", ""], ["Fang", "Pei", ""], ["Hui", "Pan", ""]]}, {"id": "2105.03671", "submitter": "Mauro Piva", "authors": "Mauro Piva, Gaia Maselli, Francesco Restuccia", "title": "The Tags Are Alright: Robust Large-Scale RFID Clone Detection Through\n  Federated Data-Augmented Radio Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Millions of RFID tags are pervasively used all around the globe to\ninexpensively identify a wide variety of everyday-use objects. One of the key\nissues of RFID is that tags cannot use energy-hungry cryptography. For this\nreason, radio fingerprinting (RFP) is a compelling approach that leverages the\nunique imperfections in the tag's wireless circuitry to achieve large-scale\nRFID clone detection. Recent work, however, has unveiled that time-varying\nchannel conditions can significantly decrease the accuracy of the RFP process.\nWe propose the first large-scale investigation into RFP of RFID tags with\ndynamic channel conditions. Specifically, we perform a massive data collection\ncampaign on a testbed composed by 200 off-the-shelf identical RFID tags and a\nsoftware-defined radio (SDR) tag reader. We collect data with different\ntag-reader distances in an over-the-air configuration. To emulate implanted\nRFID tags, we also collect data with two different kinds of porcine meat\ninserted between the tag and the reader. We use this rich dataset to train and\ntest several convolutional neural network (CNN)--based classifiers in a variety\nof channel conditions. Our investigation reveals that training and testing on\ndifferent channel conditions drastically degrades the classifier's accuracy.\nFor this reason, we propose a novel training framework based on federated\nmachine learning (FML) and data augmentation (DAG) to boost the accuracy.\nExtensive experimental results indicate that (i) our FML approach improves\naccuracy by up to 48%; (ii) our DA approach improves the FML performance by up\nto 31%. To the best of our knowledge, this is the first paper experimentally\ndemonstrating the efficacy of FML and DA on a large device population. We are\nsharing with the research community our fully-labeled 200-GB RFID waveform\ndataset, the entirety of our code and trained models.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 10:48:02 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Piva", "Mauro", ""], ["Maselli", "Gaia", ""], ["Restuccia", "Francesco", ""]]}, {"id": "2105.03778", "submitter": "Mohammed Gharib Dr.", "authors": "Mohammed Gharib and Shashidhar Nandadapu and Fatemeh Afghah", "title": "An Exhaustive Study of Using Commercial LTE Network for UAV\n  Communication in Rural Areas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) have been increasingly used in a wide area of\nmilitary and civilian applications such as data collection and monitoring. A\nreliable network for command and control, communication, and data transfer is\ncrucial, not only for mission purposes but also for safety concerns. The\nalready deployed cellular networks are appropriate candidates for UAV\ncommunication given the solid security and wide coverage of these networks.\nHowever, the reliability of such networks needs a comprehensive investigation.\nIn this paper, we use the long-term evolution (LTE) network as the\ninfrastructure for drone communication and data transfer, in a rural area. We\nstudy the communication characteristics of an LTE-connected drone during\nlow-altitude flights, for different altitudes and UAV speeds. We show that, in\nsuch areas, the higher elevation benefits from a better signal quality and\nexperiences a fewer number of handover processes. Higher speed flights also\nslightly degrade the communication performance.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 21:07:08 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Gharib", "Mohammed", ""], ["Nandadapu", "Shashidhar", ""], ["Afghah", "Fatemeh", ""]]}, {"id": "2105.03864", "submitter": "Junfeng Li", "authors": "Junfeng Li, Dan Li, Yukai Huang, Yang Cheng, Ruilin Ling", "title": "Quick NAT: High performance NAT system on commodity platforms", "comments": null, "journal-ref": "2017 IEEE International Symposium on Local and Metropolitan Area\n  Networks (LANMAN)", "doi": "10.1109/LANMAN.2017.7972137", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NAT gateway is an important network system in today's IPv4 network when\ntranslating a private IPv4 address to a public address. However, traditional\nNAT system based on Linux Netfilter cannot achieve high network throughput to\nmeet modern requirements such as data centers. To address this challenge, we\nimprove the network performance of NAT system by three ways. First, we leverage\nDPDK to enable polling and zero-copy delivery, so as to reduce the cost of\ninterrupt and packet copies. Second, we enable multiple CPU cores to process in\nparallel and use lock-free hash table to minimize the contention between CPU\ncores. Third, we use hash search instead of sequential search when looking up\nthe NAT rule table. Evaluation shows that our Quick NAT system significantly\nimproves the performance of NAT on commodity platforms.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 07:44:17 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Li", "Junfeng", ""], ["Li", "Dan", ""], ["Huang", "Yukai", ""], ["Cheng", "Yang", ""], ["Ling", "Ruilin", ""]]}, {"id": "2105.04083", "submitter": "Carlos Alexandre Gouvea da Silva", "authors": "Carlos Alexandre Gouvea da Silva, Allan Christian Krainski Ferrari,\n  Cristiano Osinski and Douglas Antonio Firmino Pelacini", "title": "The Behavior of Internet Traffic for Internet Services during COVID-19\n  Pandemic Scenario", "comments": "4 pages, 2 figures, Submitted to XXXIX Simp\\'osio Brasileiro de\n  Telecomunica\\c{c}\\~oes e Processamento de Sinais, SBrT 2021, Fortaleza, CE,\n  Brasil", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the end of 2019, the SARS-CoV-2 virus known as COVID-19 has spread\nrapidly around the world, forcing many governments to impose restrictive\nblocking or lockdown to combat the pandemic. With locomotion restriction of\npeople in almost of countries of the world, workers and students needed to keep\ntheir activities at home. As a result, people's behavior, habits, and the way\nthey started using the Internet changed significantly. Like professionals of\noffices, the younger played an important role in this behavior, especially in\nthe type of resources used by them. As result, the characterization and traffic\nof communication networks were affected in some way. In this perspective\narticle, we join from many available studies about the COVID-19 effect at\nnetworks and investigate the effects on the Internet traffic of using services\nsuch as video streaming, video conferencing, and gaming during 2020's months of\nthe pandemic.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 02:50:01 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["da Silva", "Carlos Alexandre Gouvea", ""], ["Ferrari", "Allan Christian Krainski", ""], ["Osinski", "Cristiano", ""], ["Pelacini", "Douglas Antonio Firmino", ""]]}, {"id": "2105.04184", "submitter": "Hojjat Navidan", "authors": "Hojjat Navidan, Parisa Fard Moshiri, Mohammad Nabati, Reza Shahbazian,\n  Seyed Ali Ghorashi, Vahid Shah-Mansouri and David Windridge", "title": "Generative Adversarial Networks (GANs) in Networking: A Comprehensive\n  Survey & Evaluation", "comments": "Accepted for publication at Journal of Computer Networks", "journal-ref": null, "doi": "10.1016/j.comnet.2021.108149", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Despite the recency of their conception, Generative Adversarial Networks\n(GANs) constitute an extensively researched machine learning sub-field for the\ncreation of synthetic data through deep generative modeling. GANs have\nconsequently been applied in a number of domains, most notably computer vision,\nin which they are typically used to generate or transform synthetic images.\nGiven their relative ease of use, it is therefore natural that researchers in\nthe field of networking (which has seen extensive application of deep learning\nmethods) should take an interest in GAN-based approaches. The need for a\ncomprehensive survey of such activity is therefore urgent. In this paper, we\ndemonstrate how this branch of machine learning can benefit multiple aspects of\ncomputer and communication networks, including mobile networks, network\nanalysis, internet of things, physical layer, and cybersecurity. In doing so,\nwe shall provide a novel evaluation framework for comparing the performance of\ndifferent models in non-image applications, applying this to a number of\nreference network datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 08:28:36 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Navidan", "Hojjat", ""], ["Moshiri", "Parisa Fard", ""], ["Nabati", "Mohammad", ""], ["Shahbazian", "Reza", ""], ["Ghorashi", "Seyed Ali", ""], ["Shah-Mansouri", "Vahid", ""], ["Windridge", "David", ""]]}, {"id": "2105.04230", "submitter": "Adrian Redder", "authors": "Adrian Redder, Arunselvan Ramaswamy, Holger Karl", "title": "Practical sufficient conditions for convergence of distributed\n  optimisation algorithms over communication networks with interference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information exchange over networks can be affected by various forms of delay.\nThis causes challenges for using the network by a multi-agent system to solve a\ndistributed optimisation problem. Distributed optimisation schemes, however,\ntypically do not assume network models that are representative for real-world\ncommunication networks, since communication links are most of the time\nabstracted as lossless. Our objective is therefore to formulate a\nrepresentative network model and provide practically verifiable network\nconditions that ensure convergence of distributed algorithms in the presence of\ninterference and possibly unbounded delay. Our network is modelled by a\nsequence of directed-graphs, where to each network link we associate a process\nfor the instantaneous signal-to-interference-plus-noise ratio. We then\nformulate practical conditions that can be verified locally and show that the\nage of information (AoI) associated with data communicated over the network is\nin $\\mathcal{O}(\\sqrt{n})$. Under these conditions we show that a penalty-based\ngradient descent algorithm can be used to solve a rich class of stochastic,\nconstrained, distributed optimisation problems. The strength of our result lies\nin the bridge between practical verifiable network conditions and an abstract\noptimisation theory. We illustrate numerically that our algorithm converges in\nan extreme scenario where the average AoI diverges.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 09:45:00 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Redder", "Adrian", ""], ["Ramaswamy", "Arunselvan", ""], ["Karl", "Holger", ""]]}, {"id": "2105.04524", "submitter": "Peshal Nayak", "authors": "Peshal Nayak", "title": "AP-side WLAN Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Monitoring the network performance experienced by the end-user is crucial for\nmanagers of wireless networks as it can enable them to remotely modify the\nnetwork parameters to improve the end-user experience. Unfortunately, for\nperformance monitoring, managers are typically limited to the logs of the\nAccess Points (APs) that they manage. This information does not directly\ncapture factors that can hinder station (STA) side transmissions. Consequently,\nstate-of-the-art methods to measure such metrics primarily involve active\nmeasurements. Unfortunately, such active measurements increase traffic load and\nif used regularly and for all the STAs can potentially disrupt user traffic,\nthereby worsening performance for other users in the network and draining the\nbattery of mobile devices.\n  This thesis enables passive AP-side network analytics. In the first part of\nthe thesis, I present virtual speed test, a measurement based framework that\nenables an AP to estimate speed test results for any of its associated clients\nsolely based on AP-side observables. Next, I present Uplink Latency Microscope\n(uScope), an AP-side framework for estimation of WLAN uplink latency for any of\nthe associated STAs and decomposition into its constituent components. Similar\nto virtual speed test, uScope makes estimations solely based on passive AP-side\nobservations. We implement both frameworks on a commodity hardware platform and\nconduct extensive field trials on a university campus and in a residential\napartment complex. In over 1 million tests, the two proposed frameworks\ndemonstrate an estimation accuracy with errors under 10%.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 17:20:04 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Nayak", "Peshal", ""]]}, {"id": "2105.04701", "submitter": "Amine Abouaomar", "authors": "Amine Abouaomar, Soumaya Cherkaoui, Zoubeir Mlika, and Abdellatif\n  Kobbane", "title": "Service Function Chaining in MEC: A Mean-Field Game and Reinforcement\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-access edge computing (MEC) and network virtualization technologies are\nimportant enablers for fifth-generation (5G) networks to deliver diverse\napplications and services. Services are often provided as fully connected\nvirtual network functions (VNF)s, through service function chaining (SFC).\nHowever, the problem of allocating SFC resources at the network edge still\nfaces many challenges related to the way VNFs are placed, chained and\nscheduled. In this paper, to solve these problems, we propose a game\ntheory-based approach with the objective to reduce service latency in the\ncontext of SFC at the network edge. The problem of allocating SFC resources can\nbe divided into two subproblems. 1) The VNF placement and routing subproblem,\nand 2) the VNF scheduling subproblem. For the former subproblem, we formulate\nit as a mean field game (MFG) in which VNFs are modeled as entities contending\nover edge resources with the goal of reducing the resource consumption of MEC\nnodes and reducing latency for users. We propose a on a reinforcement\nlearning-based technique, where the Ishikawa-Mann learning algorithm (IMLA) is\nused. For the later subproblem we formulate it as a matching game between the\nVFNs and an edge resources in order to find the execution order of the VNFs\nwhile reducing the latency. To efficiently solve it, we propose a modified\nversion of the many-to-one deferred acceptance algorithm (DAA), called the\nenhanced multi-step deferred acceptance algorithm (eMSDA). To illustrate the\nperformance of the proposed approaches, we perform extensive simulations. The\nobtained results show that the proposed approaches outperform the benchmarks\nother state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 22:49:56 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Abouaomar", "Amine", ""], ["Cherkaoui", "Soumaya", ""], ["Mlika", "Zoubeir", ""], ["Kobbane", "Abdellatif", ""]]}, {"id": "2105.04803", "submitter": "Dong Liu", "authors": "Dong Liu, Pingshan Li and Bicheng Zhang", "title": "Component Edge Connectivity of Hypercube-like Networks", "comments": "8 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a generalization of the traditional connectivity, the g-component edge\nconnectivity c{\\lambda}g(G) of a non-complete graph G is the minimum number of\nedges to be deleted from the graph G such that the resulting graph has at least\ng components. Hypercube-like networks (HL-networks for short) are obtained by\nmanipulating some pairs of edges in hypercubes, which contain several famous\ninterconnection networks such as twisted cubes, Mobius cubes, crossed cubes,\nlocally twisted cubes. In this paper, we determine the (g + 1)-component edge\nconnectivity of the n-dimensional HL-networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 06:29:34 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Liu", "Dong", ""], ["Li", "Pingshan", ""], ["Zhang", "Bicheng", ""]]}, {"id": "2105.04842", "submitter": "Giovanni Geraci", "authors": "Giovanni Geraci, Adrian Garcia-Rodriguez, M. Mahdi Azari, Angel\n  Lozano, Marco Mezzavilla, Symeon Chatzinotas, Yun Chen, Sundeep Rangan and\n  Marco Di Renzo", "title": "What Will the Future of UAV Cellular Communications Be? A Flight from 5G\n  to 6G", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What will the future of UAV cellular communications be? In this tutorial\narticle, we address such a compelling yet difficult question by embarking on a\njourney from 5G to 6G and sharing a large number of realistic case studies\nsupported by original results. We start by overviewing the status quo on UAV\ncommunications from an industrial standpoint, providing fresh updates from the\n3GPP and detailing new 5G NR features in support of aerial devices. We then\nshow the potential and the limitations of such features. In particular, we\ndemonstrate how sub-6 GHz massive MIMO can successfully tackle cell selection\nand interference challenges, we showcase encouraging mmWave coverage\nevaluations in both urban and suburban/rural settings, and we examine the\npeculiarities of direct device-to-device communications in the sky. Moving on,\nwe sneak a peek at next-generation UAV communications, listing some of the use\ncases envisioned for the 2030s. We identify the most promising 6G enablers for\nUAV communication, those expected to take the performance and reliability to\nthe next level. For each of these disruptive new paradigms (non-terrestrial\nnetworks, cell-free architectures, artificial intelligence, reconfigurable\nintelligent surfaces, and THz communications), we gauge the prospective\nbenefits for UAVs and discuss the main technological hurdles that stand in the\nway. All along, we distil our numerous findings into essential takeaways, and\nwe identify key open problems worthy of further study.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 07:59:02 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Geraci", "Giovanni", ""], ["Garcia-Rodriguez", "Adrian", ""], ["Azari", "M. Mahdi", ""], ["Lozano", "Angel", ""], ["Mezzavilla", "Marco", ""], ["Chatzinotas", "Symeon", ""], ["Chen", "Yun", ""], ["Rangan", "Sundeep", ""], ["Di Renzo", "Marco", ""]]}, {"id": "2105.04987", "submitter": "Francisco Carpio", "authors": "Francisco Carpio, Wolfgang Bziuk and Admela Jukan", "title": "Scaling Migrations and Replications of Virtual Network Functions based\n  on Network Traffic Forecasting", "comments": "arXiv admin note: text overlap with arXiv:2007.04151", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Migration and replication of virtual network functions (VNFs) are well-known\nmechanisms to face dynamic resource requests in Internet Service Provider (ISP)\nedge networks. They are not only used to reallocate resources in carrier\nnetworks, but in case of excessive traffic churns also to offloading VNFs to\nthird party cloud providers. We propose to study how traffic forecasting can\nhelp to reduce the number of required migrations and replications when the\ntraffic dynamically changes in the network. We analyze and compare three\nscenarios for the VNF migrations and replications based on: (i) the current\nobserved traffic demands only, (ii) specific maximum traffic demand value\nobserved in the past, or (iii) predictive traffic values. For the prediction of\ntraffic demand values, we use an LSTM model which is proven to be one of the\nmost accurate methods in time series forecasting problems. Based the traffic\nprediction model, we then use a Mixed-Integer Linear Programming (MILP) model\nas well as a greedy algorithm to solve this optimization problem that considers\nmigrations and replications of VNFs. The results show that LSTM-based traffic\nprediction can reduce the number of migrations up to 45\\% when there is enough\navailable resources to allocate replicas, while less cloud-based offloading is\nrequired compared to overprovisioning.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 12:44:16 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Carpio", "Francisco", ""], ["Bziuk", "Wolfgang", ""], ["Jukan", "Admela", ""]]}, {"id": "2105.04995", "submitter": "Francisco Carpio", "authors": "Francisco Carpio, Marc Michalke and Admela Jukan", "title": "Engineering and Experimentally Benchmarking a Serverless Edge Computing\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the latest advances in containerization, the serverless edge\ncomputing model is becoming close to reality. Serverless at the edge is\nexpected to enable low latency applications with fast autoscaling mechanisms,\nall running on heterogeneous and resource-constrained devices. In this work, we\nengineer and experimentally benchmark a serverless edge computing system\narchitecture. We deploy a decentralized edge computing platform for serverless\napplications providing processing, storage, and communication capabilities\nusing only open-source software, running over heterogeneous resources (e.g.,\nvirtual machines, Raspberry Pis, or bare metal servers, etc). To achieve that,\nwe provision an overlay-network based on Nebula network agnostic technology,\nrunning over private or public networks, and use K3s to provide hardware\nabstraction. We benchmark the system in terms of response times, throughput and\nscalability using different hardware devices connected through the public\nInternet. The results show that while serverless is feasible on heterogeneous\ndevices showing a good performance on constrained devices, such as Raspberry\nPis, the lack of support when determining computational power and network\ncharacterization leaves much room for improvement in edge environments.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 12:56:29 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Carpio", "Francisco", ""], ["Michalke", "Marc", ""], ["Jukan", "Admela", ""]]}, {"id": "2105.04998", "submitter": "Anatolij Zubow", "authors": "Piotr Gawlowicz, Anatolij Zubow, Falko Dressler", "title": "Wi-Lo: Emulating LoRa using COTS WiFi", "comments": "5 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Wi-Lo, which allows to convert an ordinary 802.11 (WiFi) access\npoint into an internet of things (IoT) gateway supporting the low-power wide\narea network (LPWAN) technology LoRa in the downlink. Our Wi-Lo system only\nrequires a software update and no additional hardware. It uses signal emulation\ntechnique based on complementary code keying modulation from 802.11b in order\nto emulate a downlink LoRa (long range) transmission. The Wi-Lo gateway can be\nused by a normal WiFi-enabled smartphone to send packets to LoRa compliant IoT\ndevices like smart sensors. We implemented a prototype using commodity WiFi\nhardware. Experimental results show that Wi-Lo enables a normal WiFi node to\ncommunication to LoRa devices even over long distances, which is comparable to\nthe configurations using pure LoRa transmitter and receivers.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 13:01:53 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Gawlowicz", "Piotr", ""], ["Zubow", "Anatolij", ""], ["Dressler", "Falko", ""]]}, {"id": "2105.05004", "submitter": "Jindian Liu", "authors": "Zhuo Li, Jindian Liu, Liu Yan, Beichuan Zhang, Peng Luo, Kaihua Liu", "title": "Smart Name Lookup for NDN Forwarding Plane via Neural Networks", "comments": "We need to refine the paper further including the title and the\n  structure of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Name lookup is a key technology for the forwarding plane of content router in\nNamed Data Networking (NDN). To realize the efficient name lookup, what counts\nis deploying a highperformance index in content routers. So far, the proposed\nindexes have shown good performance, most of which are optimized for or\nevaluated with URLs collected from the current Internet, as the large-scale NDN\nnames are not available yet. Unfortunately, the performance of these indexes is\nalways impacted in terms of lookup speed, memory consumption and false positive\nprobability, as the distributions of URLs retrieved in memory may differ from\nthose of real NDN names independently generated by content-centric applications\nonline. Focusing on this gap, a smart mapping model named Pyramid-NN via neural\nnetworks is proposed to build an index called LNI for NDN forwarding plane.\nThrough learning the distributions of the names retrieved in the static memory,\nLNI can not only reduce the memory consumption and the probability of false\npositive, but also ensure the performance of real NDN name lookup. Experimental\nresults show that LNI-based FIB can reduce the memory consumption to 58.258 MB\nfor 2 million names. Moreover, as it can be deployed on SRAMs, the throughput\nis about 177 MSPS, which well meets the current network requirement for fast\npacket processing.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 13:13:50 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 11:31:14 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Li", "Zhuo", ""], ["Liu", "Jindian", ""], ["Yan", "Liu", ""], ["Zhang", "Beichuan", ""], ["Luo", "Peng", ""], ["Liu", "Kaihua", ""]]}, {"id": "2105.05162", "submitter": "Anna Maria Mandalari", "authors": "Anna Maria Mandalari, Daniel J. Dubois, Roman Kolcun, Muhammad Talha\n  Paracha, Hamed Haddadi and David Choffnes", "title": "Blocking without Breaking: Identification and Mitigation of\n  Non-Essential IoT Traffic", "comments": null, "journal-ref": "Privacy Enhancing Technologies Symposium (PETS) 2021", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the prevalence of Internet of Things (IoT) devices, there is little\ninformation about the purpose and risks of the Internet traffic these devices\ngenerate, and consumers have limited options for controlling those risks. A key\nopen question is whether one can mitigate these risks by automatically blocking\nsome of the Internet connections from IoT devices, without rendering the\ndevices inoperable. In this paper, we address this question by developing a\nrigorous methodology that relies on automated IoT-device experimentation to\nreveal which network connections (and the information they expose) are\nessential, and which are not. We further develop strategies to automatically\nclassify network traffic destinations as either required (i.e., their traffic\nis essential for devices to work properly) or not, hence allowing firewall\nrules to block traffic sent to non-required destinations without breaking the\nfunctionality of the device. We find that indeed 16 among the 31 devices we\ntested have at least one blockable non-required destination, with the maximum\nnumber of blockable destinations for a device being 11. We further analyze the\ndestination of network traffic and find that all third parties observed in our\nexperiments are blockable, while first and support parties are neither\nuniformly required or non-required. Finally, we demonstrate the limitations of\nexisting blocklists on IoT traffic, propose a set of guidelines for\nautomatically limiting non-essential IoT traffic, and we develop a prototype\nsystem that implements these guidelines.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 16:13:12 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Mandalari", "Anna Maria", ""], ["Dubois", "Daniel J.", ""], ["Kolcun", "Roman", ""], ["Paracha", "Muhammad Talha", ""], ["Haddadi", "Hamed", ""], ["Choffnes", "David", ""]]}, {"id": "2105.05179", "submitter": "Mounir Bensalem", "authors": "Mounir Bensalem, Jasenka Dizdarevi\\'c, Francisco Carpio, and Admela\n  Jukan", "title": "The Role of Intent-Based Networking in ICT Supply Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The evolution towards Industry 4.0 is driving the need for innovative\nsolutions in the area of network management, considering the complex, dynamic\nand heterogeneous nature of ICT supply chains. To this end, Intent-Based\nnetworking (IBN) which is already proven to evolve how network management is\ndriven today, can be implemented as a solution to facilitate the management of\nlarge ICT supply chains. In this paper, we first present a comparison of the\nmain architectural components of typical IBN systems and, then, we study the\nkey engineering requirements when integrating IBN with ICT supply chain network\nsystems while considering AI methods. We also propose a general architecture\ndesign that enables intent translation of ICT supply chain specifications into\nlower level policies, to finally show an example of how the access control is\nperformed in a modeled ICT supply chain system.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 16:32:40 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Bensalem", "Mounir", ""], ["Dizdarevi\u0107", "Jasenka", ""], ["Carpio", "Francisco", ""], ["Jukan", "Admela", ""]]}, {"id": "2105.05237", "submitter": "Priyanka Kaswan", "authors": "Priyanka Kaswan and Melih Bastopcu and Sennur Ulukus", "title": "Freshness Based Cache Updating in Parallel Relay Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a system consisting of a server, which receives updates for $N$\nfiles according to independent Poisson processes. The goal of the server is to\ndeliver the latest version of the files to the user through a parallel network\nof $K$ caches. We consider an update received by the user successful, if the\nuser receives the same file version that is currently prevailing at the server.\nWe derive an analytical expression for information freshness at the user. We\nobserve that freshness for a file increases with increase in consolidation of\nrates across caches. To solve the multi-cache problem, we first solve the\nauxiliary problem of a single-cache system. We then rework this auxiliary\nsolution to our parallel-cache network by consolidating rates to single routes\nas much as possible. This yields an approximate (sub-optimal) solution for the\noriginal problem. We provide an upper bound on the gap between the sub-optimal\nsolution and the optimal solution. Numerical results show that the sub-optimal\npolicy closely approximates the optimal policy.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 17:55:07 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Kaswan", "Priyanka", ""], ["Bastopcu", "Melih", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2105.05243", "submitter": "Akhil Bhimaraju", "authors": "Akhil Bhimaraju, Atul A. Zacharias, Avhishek Chatterjee", "title": "Resource Allocation for Smooth Streaming: Non-convexity and Bandits", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User dissatisfaction due to buffering pauses during streaming is a\nsignificant cost to the system, which we model as a non-decreasing function of\nthe frequency of buffering pause. Minimization of total user dissatisfaction in\na multi-channel cellular network leads to a non-convex problem. Utilizing a\ncombinatorial structure in this problem, we first propose a polynomial time\njoint admission control and channel allocation algorithm which is provably\n(almost) optimal. This scheme assumes that the base station (BS) knows the\nframe statistics of the streams. In a more practical setting, where these\nstatistics are not available a priori at the BS, a learning based scheme with\nprovable guarantees is developed. This learning based scheme has relation to\nregret minimization in multi-armed bandits with non-i.i.d. and delayed reward\n(cost). All these algorithms require none to minimal feedback from the user\nequipment to the base station regarding the states of the media player buffer\nat the application layer, and hence, are of practical interest.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 17:59:32 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Bhimaraju", "Akhil", ""], ["Zacharias", "Atul A.", ""], ["Chatterjee", "Avhishek", ""]]}, {"id": "2105.05248", "submitter": "Reza Fotohi", "authors": "Samane Asgari, Shahram Jamali, Reza Fotohi, and Mahdi Nooshyar", "title": "Performance-aware placement and chaining scheme for virtualized network\n  functions: a particle swarm optimization approach", "comments": "22 pages, 10 Figures, 3 Tables, J Supercomput (2021)", "journal-ref": null, "doi": "10.1007/s11227-021-03758-9", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network functions virtualization (NFV) is a new concept that has received the\nattention of both researchers and network providers. NFV decouples network\nfunctions from specialized hardware devices and virtualizes these network\nfunctions as software instances called virtualized network functions (VNFs).\nNFV leads to various benefits, including more flexibility, high resource\nutilization, and easy upgrades and maintenances. Despite recent works in this\nfield, placement and chaining of VNFs need more attention. More specifically,\nsome of the existing works have considered only the placement of VNFs and\nignored the chaining part. So, they have not provided an integrated view of\nhost or bandwidth resources and propagation delay of paths. In this paper, we\nsolve the VNF placement and chaining problem as an optimization problem based\non the particle swarm optimization (PSO) algorithm. Our goal is to minimize the\nrequired number of used servers, the average propagation delay of paths, and\nthe average utilization of links while meeting network demands and constraints.\nBased on the obtained results, the algorithm proposed in this study can find\nfeasible and high-quality solutions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 07:26:50 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Asgari", "Samane", ""], ["Jamali", "Shahram", ""], ["Fotohi", "Reza", ""], ["Nooshyar", "Mahdi", ""]]}, {"id": "2105.05560", "submitter": "Yuanjie Li", "authors": "Yuanjie Li, Hewu Li, Lixin Liu, Wei Liu, Jiayi Liu, Jianping Wu, Qian\n  Wu, Jun Liu, Zeqi Lai, Guojie Fan", "title": "Fractal Rosette: A Stable Space-Ground Network Structure in\n  Mega-Constellation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present F-Rosette, a stable space-ground network structure for low-earth\norbit (LEO) satellite mega-constellations at scale. Due to the dynamic\nmany-to-many space-ground mapping in high mobility, existing LEO\nmega-constellations with IP protocol stack suffer from frequent user IP address\nchanges (every 133~510s per user) and network routing re-convergence (<20%\nnetwork usability). To provably stabilize the space-ground network under high\nmobility and many-to-many dynamics, F-Rosette adopts a recursive structure over\nthe Rosette constellation, derives a hierarchical and time-invariant network\naddress space from a new geographical coordinate system, and ensures efficient\nand stable routing via geographical-to-topological routing embedding without\nre-convergence. Our hardware-in-the-loop, trace-driven emulations validate\nF-Rosette's stability, near-optimal routing (<1.4% additional delays), and\nmarginal overhead (<1% CPU, <2MB memory) for resource-constrained satellites.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:18:57 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Li", "Yuanjie", ""], ["Li", "Hewu", ""], ["Liu", "Lixin", ""], ["Liu", "Wei", ""], ["Liu", "Jiayi", ""], ["Wu", "Jianping", ""], ["Wu", "Qian", ""], ["Liu", "Jun", ""], ["Lai", "Zeqi", ""], ["Fan", "Guojie", ""]]}, {"id": "2105.05564", "submitter": "Nikolaos Nomikos Dr.", "authors": "Nikolaos Nomikos, Spyros Zoupanos, Themistoklis Charalambous, Ioannis\n  Krikidis, Athina Petropulu", "title": "A Survey on Reinforcement Learning-Aided Caching in Mobile Edge Networks", "comments": "26 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Mobile networks are experiencing tremendous increase in data volume and user\ndensity. An efficient technique to alleviate this issue is to bring the data\ncloser to the users by exploiting the caches of edge network nodes, such as\nfixed or mobile access points and even user devices. Meanwhile, the fusion of\nmachine learning and wireless networks offers a viable way for network\noptimization as opposed to traditional optimization approaches which incur high\ncomplexity, or fail to provide optimal solutions. Among the various machine\nlearning categories, reinforcement learning operates in an online and\nautonomous manner without relying on large sets of historical data for\ntraining. In this survey, reinforcement learning-aided mobile edge caching is\npresented, aiming at highlighting the achieved network gains over conventional\ncaching approaches. Taking into account the heterogeneity of sixth generation\n(6G) networks in various wireless settings, such as fixed, vehicular and flying\nnetworks, learning-aided edge caching is presented, departing from traditional\narchitectures. Furthermore, a categorization according to the desirable\nperformance metric, such as spectral, energy and caching efficiency, average\ndelay, and backhaul and fronthaul offloading is provided. Finally, several open\nissues are discussed, targeting to stimulate further interest in this important\nresearch field.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:30:56 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 09:04:15 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 18:57:45 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Nomikos", "Nikolaos", ""], ["Zoupanos", "Spyros", ""], ["Charalambous", "Themistoklis", ""], ["Krikidis", "Ioannis", ""], ["Petropulu", "Athina", ""]]}, {"id": "2105.05594", "submitter": "Kashif Mehmood", "authors": "Kashif Mehmood, H. V. Kalpanie Mendis, Katina Kralevska, and Poul E.\n  Heegaard", "title": "Intent-based Network Management and Orchestration for Smart Distribution\n  Grids", "comments": "This paper has been accepted for presentation at the 28th\n  International Conference on Telecommunications (ICT 21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  5G technology complements the enabling of communication services for\ndifferent vertical industries such as smart distribution grids. Automation is\nan integral and necessary part of the power distribution grid operation and\nmanagement. This paper postulates a framework by which the smart distribution\ngrid can obtain service-oriented communication services using 5G network\nslicing and intent-based networking (IBN). IBN provides an interface to service\nusers and network stakeholders to cooperate through a high level abstraction\nmodel of service provisioning in a network agnostic manner. The automation and\nadaptability of the distribution grid are facilitated by using the dynamic and\nclosed-loop mechanism of IBN together with network slicing and network function\nvirtualization for network management and orchestration. We identify the\nautomation parts of the power distribution grid and illustrate the intent\nprocessing and its inclusion in the definition of network slice instances,\nservice and network configuration models.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 11:22:29 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Mehmood", "Kashif", ""], ["Mendis", "H. V. Kalpanie", ""], ["Kralevska", "Katina", ""], ["Heegaard", "Poul E.", ""]]}, {"id": "2105.05751", "submitter": "Revanth V S", "authors": "Revanth V S, Suthan L", "title": "Prevention Of Attack In Vehicular Adhoc Network Using Trust Model", "comments": "i have to modify the contents of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Vehicular ad hoc networks is a modern technology that holds an important\naspect in the transportation domain due to its abilities to increase traffic\nefficiency and safety. It is a another variant of Mobile ad-hoc networks that\nprovides Vehicles to Vehicles (V2V), Rode-side Unit to Road-side Unit(R2R) and\nVehicles to road-side Unit (V2R) communication.VANET is a multidimensional\nnetwork in which the vehicles ceaselessly alter their locations. Connected\nvehicles broadcast sensitive information which must be communicated with the\nneighbors in a safe and established environment. VANET may also contain\ndishonest nodes such as man in -the-middle attackers that aim to distribute and\nshare malicious content with the vehicles, thus contaminating the network with\nsecure information. In this situation implementing a trust among connected\nvehicles can raise security as every participating vehicle will create and\npropagate authentic, accurate,and trusted content within the network.In this\npaper we used a trust model to determine the trust level and eliminate the\nmalicious nodes.We created a simulation for calculating the trust level and\neliminating the malicious node in the wireless ad hoc networks using ns2\nsimulator and network animator(nam).The simulation results showed a better\nbandwidth in communication between the nodes after the trust level is updated\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 16:08:54 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 14:16:57 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["S", "Revanth V", ""], ["L", "Suthan", ""]]}, {"id": "2105.05924", "submitter": "Xun Guan", "authors": "Xun Guan, Wei Shi, Jia Liu, Peng Tan, Jim Slevinsky, and Leslie A.\n  Rusch", "title": "Silicon Photonics in Optical Access Networks for 5G Communications", "comments": "6 pages, 5 figures, accepted to IEEE communication magazine", "journal-ref": null, "doi": "10.1109/MCOM.001.2001005", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Only radio access networks can provide connectivity across multiple antenna\nsites to achieve the great leap forward in capacity targeted by 5G. Optical\nfronthaul remains a sticking point in that connectivity, and we make the case\nfor analog radio over fiber signals and an optical access network smartedge to\nachieve the potential of radio access networks. The edge of the network would\nhouse the intelligence that coordinates wireless transmissions to minimize\ninterference and maximize throughput. As silicon photonics provides a hardware\nplatform well adapted to support optical fronthaul, it is poised to drive smart\nedge adoption. We draw out the issues in adopting oursolution, propose a\nstrategy for network densification, and cite recent demonstrations to support\nour approach.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 19:35:25 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 16:13:10 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Guan", "Xun", ""], ["Shi", "Wei", ""], ["Liu", "Jia", ""], ["Tan", "Peng", ""], ["Slevinsky", "Jim", ""], ["Rusch", "Leslie A.", ""]]}, {"id": "2105.06053", "submitter": "Bin Hu", "authors": "Bin Hu and Hamid Gharavi", "title": "A Hybrid Wired/Wireless Deterministic Network for Smart Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the rapid growth of time-critical applications in smart grid, robotics,\nautonomous vehicles, and industrial automation, demand for high reliability,\nlow latency and strictly bounded jitter is sharply increasing. High-precision\ntime synchronization communications, such as Time Triggered Ethernet (TTE),\nhave been successfully developed for wired networks. However, the high cost of\ndeploying additional equipment and extra wiring limits the scalability of these\nnetworks. Therefore, in this paper, a hybrid wired/wireless high-precision time\nsynchronization network based on a combination of high-speed TTE and 5G\nUltra-Reliable and Low-Latency Communications (URLLC) is proposed. The main\nmotivation is to comply with the low latency, low jitter, and high reliability\nrequirements of time critical applications, such as smart grid synchrophasor\ncommunications. Therefore, in the proposed hybrid network architecture, a\nhigh-speed TTE is considered as the main bus (i.e., backbone network), whereas\na Precision Time Protocol (PTP) aided 5G-URLLC-based wireless access is used as\na sub-network. The main challenge is to achieve interoperability between the\nPTP aided URLLC and the TTE, while ensuring high precision timing and\nsynchronization. The simulation results demonstrate the impact of the PTP-aided\nURLLC in maintaining network reliability, latency, and jitter in full\ncoordination with the TTE-network.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 03:06:31 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Hu", "Bin", ""], ["Gharavi", "Hamid", ""]]}, {"id": "2105.06105", "submitter": "Kristen Titus W", "authors": "Prasanna Venkatesan E, Kristen Titus W", "title": "Trusted Authentication using hybrid security algorithm in VANET", "comments": "arXiv admin note: text overlap with arXiv:2105.05751", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Vehicular Ad Hoc Networks (VANETs) improves traffic management and reduce the\namount of road accidents by providing safety applications. However, VANETs are\nvulnerable to variety of security attacks from malicious entities. An\nauthentication is an integral a neighborhood of trust establishment and secure\ncommunications between vehicles. The Road-side Unit (RSU) evaluates trust-value\nand the Agent Trusted Authority (ATA) helps in computing the trust-value of\nauto supported its reward-points. The communication between nodes is enhanced,\nthis can reduce 50% of road accidents. The security of the VANET is improved.\nWe propose the utilization of Elliptic Curve Cryptography in the design of an\nefficient data encryption/decryption system for sensor nodes in a wireless\nnetwork. Elliptic Curve Cryptography can provide impressive levels of security\nstandards while keeping down the cost of certain issues, primarily storage\nspace. Sensors will benefit from having to store relatively smaller keys\ncoupled with increased computational capability and this will be a stronger\ndesign as the bit-level security is improved. Thus, reducing the time delay\nbetween the nodes and to provide better results between them we have made use\nof this method. The implementation of this work is done with NS2 software.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 06:51:51 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["E", "Prasanna Venkatesan", ""], ["W", "Kristen Titus", ""]]}, {"id": "2105.06524", "submitter": "Hongpeng Guo", "authors": "Hongpeng Guo, Shuochao Yao, Zhe Yang, Qian Zhou, Klara Nahrstedt", "title": "CrossRoI: Cross-camera Region of Interest Optimization for Efficient\n  Real Time Video Analytics at Scale", "comments": "accepted in 12th ACM Multimedia Systems Conference (MMsys 21')", "journal-ref": null, "doi": "10.1145/3458305.3463381", "report-no": null, "categories": "cs.DC cs.CV cs.MM cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Video cameras are pervasively deployed in city scale for public good or\ncommunity safety (i.e. traffic monitoring or suspected person tracking).\nHowever, analyzing large scale video feeds in real time is data intensive and\nposes severe challenges to network and computation systems today. We present\nCrossRoI, a resource-efficient system that enables real time video analytics at\nscale via harnessing the videos content associations and redundancy across a\nfleet of cameras. CrossRoI exploits the intrinsic physical correlations of\ncross-camera viewing fields to drastically reduce the communication and\ncomputation costs. CrossRoI removes the repentant appearances of same objects\nin multiple cameras without harming comprehensive coverage of the scene.\nCrossRoI operates in two phases - an offline phase to establish cross-camera\ncorrelations, and an efficient online phase for real time video inference.\nExperiments on real-world video feeds show that CrossRoI achieves 42% - 65%\nreduction for network overhead and 25% - 34% reduction for response delay in\nreal time video analytics applications with more than 99% query accuracy, when\ncompared to baseline methods. If integrated with SotA frame filtering systems,\nthe performance gains of CrossRoI reach 50% - 80% (network overhead) and 33% -\n61% (end-to-end delay).\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 19:29:14 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Guo", "Hongpeng", ""], ["Yao", "Shuochao", ""], ["Yang", "Zhe", ""], ["Zhou", "Qian", ""], ["Nahrstedt", "Klara", ""]]}, {"id": "2105.06619", "submitter": "Jianshen Liu", "authors": "Jianshen Liu, Carlos Maltzahn, Craig Ulmer, Matthew Leon Curry", "title": "Performance Characteristics of the BlueField-2 SmartNIC", "comments": "13 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance computing (HPC) researchers have long envisioned scenarios\nwhere application workflows could be improved through the use of programmable\nprocessing elements embedded in the network fabric. Recently, vendors have\nintroduced programmable Smart Network Interface Cards (SmartNICs) that enable\ncomputations to be offloaded to the edge of the network. There is great\ninterest in both the HPC and high-performance data analytics communities in\nunderstanding the roles these devices may play in the data paths of upcoming\nsystems.\n  This paper focuses on characterizing both the networking and computing\naspects of NVIDIA's new BlueField-2 SmartNIC when used in an Ethernet\nenvironment. For the networking evaluation we conducted multiple transfer\nexperiments between processors located at the host, the SmartNIC, and a remote\nhost. These tests illuminate how much processing headroom is available on the\nSmartNIC during transfers. For the computing evaluation we used the stress-ng\nbenchmark to compare the BlueField-2 to other servers and place realistic\nbounds on the types of offload operations that are appropriate for the\nhardware.\n  Our findings from this work indicate that while the BlueField-2 provides a\nflexible means of processing data at the network's edge, great care must be\ntaken to not overwhelm the hardware. While the host can easily saturate the\nnetwork link, the SmartNIC's embedded processors may not have enough computing\nresources to sustain more than half the expected bandwidth when using\nkernel-space packet processing. From a computational perspective, encryption\noperations, memory operations under contention, and on-card IPC operations on\nthe SmartNIC perform significantly better than the general-purpose servers used\nfor comparisons in our experiments. Therefore, applications that mainly focus\non these operations may be good candidates for offloading to the SmartNIC.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 02:25:04 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Liu", "Jianshen", ""], ["Maltzahn", "Carlos", ""], ["Ulmer", "Craig", ""], ["Curry", "Matthew Leon", ""]]}, {"id": "2105.06657", "submitter": "Zhengrui Huang", "authors": "Zhengrui Huang", "title": "Multi-Link and AUV-aided Energy-Efficient Underwater Emergency Response", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent development of wireless communication has provided many promising\nsolutions to emergency response. To effectively realize the energy-efficient\nunderwater emergency response and adequately harness merits of different\nunderwater communication links (UCL), this article proposes an underwater\nemergency communication network (UECN) aided by multiple UCLs and autonomous\nunderwater vehicles (AUV) to collect underwater emergency data. Specifically,\nwe first select the optimal emergency response mode (ERM) for each underwater\nsensor node (USN) with the help of greedy searching and reinforcement learning\n(RL), and the \"isolated\" USNs (IUSN) can be found out. Second, based on the\ndistribution of IUSNs, we dispatch AUVs to assist IUSNs in underwater\ncommunication by jointly solving the optimal AUV position and velocity, which\ncan dramatically shorten the amount of time for data collection and motion.\nFinally, the best tradeoff between response efficiency and energy consumption\nis achieved by multiobjective optimization, where the amount of time for\nemergency response and the total energy consumption are simultaneously\nminimized, subject to a given set of transmit power,\nsignal-to-interference-plus-noise ratio (SINR), outage probability, and energy\nconstraints. Simulation results show that the proposed system significantly\nimproves the response efficiency and overcomes the limitations of existing\nworks, which makes contributions to emergency decision-making.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 06:04:44 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Huang", "Zhengrui", ""]]}, {"id": "2105.06658", "submitter": "Zhengrui Huang", "authors": "Zhengrui Huang", "title": "Hybrid Device-to-Device and Device-to-Vehicle Networks for\n  Energy-Efficient Emergency Communication", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the energy-efficient emergency response, subject to a given set\nof constraints on emergency communication networks (ECN), this article proposes\na hybrid device-to-device (D2D) and device-to-vehicle (D2V) network for\ncollecting and transmitting emergency information. First, we establish the D2D\nnetwork from the perspective of complex networks by jointly determining the\noptimal network partition (ONP) and the temporary data caching centers (TDCC),\nand thus emergency data can be forwarded and cached in TDCCs. Second, based on\nthe distribution of TDCCs, the D2V network is established by unmanned aerial\nvehicles (UAV)-based waypoint and motion planning, which saves the time for\nwireless transmission and aerial moving. Finally, the amount of time for\nemergency response and the total energy consumption are simultaneously\nminimized by a multiobjective evolutionary algorithm based on decomposition\n(MOEA/D), subject to a given set of minimum signal-to-interference-plus-noise\nratio (SINR), number of UAVs, transmit power, and energy constraints.\nSimulation results show that the proposed method significantly improves\nresponse efficiency and reasonably controls the energy, thus overcoming\nlimitations of existing ECNs. Therefore, this network effectively solves the\nkey problem in the rescue system and makes great contributions to post-disaster\ndecision-making.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 06:06:09 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 03:02:24 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Huang", "Zhengrui", ""]]}, {"id": "2105.06741", "submitter": "Amina Boubendir", "authors": "Jose Jurandir Alves Esteves, Amina Boubendir, Fabrice Guillemin, and\n  Pierre Sens", "title": "A Heuristically Assisted Deep Reinforcement Learning Approach for\n  Network Slice Placement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Slice placement with the problem of allocation of resources from a\nvirtualized substrate network is an optimization problem which can be\nformulated as a multiobjective Integer Linear Programming (ILP) problem.\nHowever, to cope with the complexity of such a continuous task and seeking for\noptimality and automation, the use of Machine Learning (ML) techniques appear\nas a promising approach. We introduce a hybrid placement solution based on Deep\nReinforcement Learning (DRL) and a dedicated optimization heuristic based on\nthe Power of Two Choices principle. The DRL algorithm uses the so-called\nAsynchronous Advantage Actor Critic (A3C) algorithm for fast learning, and\nGraph Convolutional Networks (GCN) to automate feature extraction from the\nphysical substrate network. The proposed Heuristically-Assisted DRL (HA-DRL)\nallows to accelerate the learning process and gain in resource usage when\ncompared against other state-of-the-art approaches as the evaluation results\nevidence.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 10:04:17 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Esteves", "Jose Jurandir Alves", ""], ["Boubendir", "Amina", ""], ["Guillemin", "Fabrice", ""], ["Sens", "Pierre", ""]]}, {"id": "2105.06812", "submitter": "Adrian Schumacher", "authors": "Adrian Schumacher, Ruben Merz, Andreas Burg", "title": "3.5 GHz Coverage Assessment with a 5G Testbed", "comments": "Published at 2019 IEEE 89th Vehicular Technology Conference\n  (VTC2019-Spring)", "journal-ref": "2019 IEEE 89th Vehicular Technology Conference (VTC2019-Spring)", "doi": "10.1109/VTCSpring.2019.8746551", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Today, cellular networks have saturated frequencies below 3\\,GHz. Because of\nincreasing capacity requirements, 5th generation (5G) mobile networks target\nthe 3.5\\,GHz band (3.4 to 3.8\\,GHz). Despite its expected wide usage, there is\nlittle empirical path loss data and mobile radio network planning experience\nfor the 3.5\\,GHz band available. This paper presents the results of rural,\nsuburban, and urban measurement campaigns using a pre-standard 5G prototype\ntestbed operating at 3.5\\,GHz, with outdoor as well as outdoor-to-indoor\nscenarios. Based on the measurement results, path loss models are evaluated,\nwhich are essential for network planning.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 13:16:56 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Schumacher", "Adrian", ""], ["Merz", "Ruben", ""], ["Burg", "Andreas", ""]]}, {"id": "2105.06845", "submitter": "Federico Chiariotti", "authors": "Federico Chiariotti, Josefine Holm, Anders E. Kal{\\o}r, Beatriz Soret,\n  S{\\o}ren K. Jensen, Torben B. Pedersen, Petar Popovski", "title": "Query Age of Information: Freshness in Pull-Based Communication", "comments": "Submitted to IEEE Transactions on Communications. arXiv admin note:\n  substantial text overlap with arXiv:2011.00917", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Age of Information (AoI) has become an important concept in communications,\nas it allows system designers to measure the freshness of the information\navailable to remote monitoring or control processes. However, its definition\ntacitly assumes that new information is used at any time, which is not always\nthe case: the instants at which information is collected and used are dependent\non a certain query process. We propose a model that accounts for the discrete\ntime nature of many monitoring processes, considering a pull-based\ncommunication model in which the freshness of information is only important\nwhen the receiver generates a query: if the monitoring process is not using the\nvalue, the age of the last update is irrelevant. We then define the Age of\nInformation at Query (QAoI), a more general metric that fits the pull-based\nscenario, and show how its optimization can lead to very different choices from\ntraditional push-based AoI optimization when using a Packet Erasure Channel\n(PEC) and with limited link availability. Our results show that QAoI-aware\noptimization can significantly reduce the average and worst-case perceived age\nfor both periodic and stochastic queries.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 14:16:13 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Chiariotti", "Federico", ""], ["Holm", "Josefine", ""], ["Kal\u00f8r", "Anders E.", ""], ["Soret", "Beatriz", ""], ["Jensen", "S\u00f8ren K.", ""], ["Pedersen", "Torben B.", ""], ["Popovski", "Petar", ""]]}, {"id": "2105.06885", "submitter": "Adrian Schumacher", "authors": "Adrian Schumacher, Ruben Merz, Andreas Burg", "title": "A mmWave Bridge Concept to Solve the Cellular Outdoor-to-Indoor\n  Challenge", "comments": "Published at 2020 IEEE 91st Vehicular Technology Conference\n  (VTC2020-Spring)", "journal-ref": "2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring)", "doi": "10.1109/VTC2020-Spring48590.2020.9128458", "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Wireless indoor coverage and data capacity are important aspects of cellular\nnetworks. With the ever-increasing data traffic, demand for more data capacity\nindoors is also growing. The lower frequencies of the legacy frequency bands of\nmacro outdoor cells manage to provide coverage inside buildings, however, new\nfrequencies foreseen for the 5th generation (5G) of mobile communications in\nthe millimeter wave (mmWave) spectrum penetrate very poorly into buildings.\nTherefore, a massive densification of the network would require to deploy a\nlarge number of indoor small cells, which would lead to high deployment costs\nto install the necessary wired/optical backhaul. Hence, other methods are\nneeded that allow an increase of the data capacity indoors, bearing a lower\ncost than a fiber deployment. We propose a cost-efficient out-of-band repeater\narchitecture that provides more data capacity indoors than an outdoor\nmacro/micro network can provide to indoor, without adversely affecting a legacy\nnetwork, and which readily works with the established cellular infrastructure\nas well as standard handsets/smartphones. This proposal is compared to\nconventional in- and out-of-band repeaters and relay nodes in order to\nhighlight the advantages of our solution. While the data capacity for a single\nlink is similar to that of repeaters and relays, a macro cell can be\neffectively offloaded. Cell capacities corresponding to at least 3--4 times\nthat of a repeater or relay solution can be provided, depending on the number\nof parallel installed links and the bandwidth in the mmWave spectrum.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:15:00 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Schumacher", "Adrian", ""], ["Merz", "Ruben", ""], ["Burg", "Andreas", ""]]}, {"id": "2105.06898", "submitter": "Adrian Schumacher", "authors": "Nima Jamaly, Stefan Mauron, Ruben Merz, Adrian Schumacher, Daniel\n  Wenger", "title": "Delivering Gigabit Capacities to Passenger Trains Tales from an Operator\n  on the Road to 5G", "comments": "Published in IEEE Communications Magazine (Volume: 57, Issue: 9,\n  September 2019)", "journal-ref": "IEEE Communications Magazine (Volume: 57, Issue: 9, September\n  2019)", "doi": "10.1109/MCOM.2019.1800949", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Delivering reliable and high-capacity Internet connectivity to high-speed\ntrain users is a challenge. Modern railway cars act as Faraday cages and a\ntypical train consist comprises several hundreds of users moving at high\nvelocity. Furthermore, with the global availability of fourth generation (4G)\nLong Term Evolution (LTE), user expectations have dramatically increased: it is\nexpected to be online anytime and anywhere. Demand for mobile high-capacity is\nbeing driven by video and music streaming services, for lower latency and\nhigher availability by gaming, and for more reliability and even uplink\ncapacity by mission critical applications. Finally, the life-cycle of the\nrailway industry is much longer than for telecommunications, which makes\nsupporting 5G challenging. In this paper, we survey the challenges associated\nwith delivering high-capacity connectivity to train users, describe potential\noptions, and highlight how a leading western European operator is tackling\nthese challenges and preparing for 5G and beyond.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:34:46 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Jamaly", "Nima", ""], ["Mauron", "Stefan", ""], ["Merz", "Ruben", ""], ["Schumacher", "Adrian", ""], ["Wenger", "Daniel", ""]]}, {"id": "2105.06899", "submitter": "H{\\aa}rek Haugerud", "authors": "Eirik Molde B{\\aa}rli, Anis Yazidi, Enrique Herrera Viedma, H{\\aa}rek\n  Haugerud", "title": "DoS and DDoS Mitigation Using Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DoS and DDoS attacks have been growing in size and number over the last\ndecade and existing solutions to mitigate these attacks are in general\ninefficient. Compared to other types of malicious cyber attacks, DoS and DDoS\nattacks are particularly more challenging to combat. With their ability to mask\nthemselves as legitimate traffic, developing methods to detect these types of\nattacks on a packet or flow level, has proven to be a difficult task. In this\npaper, we explore the potential of Variational Autoencoders to serve as a\ncomponent within an intelligent security solution that differentiates between\nnormal and malicious traffic. Two methods based on the ability of Variational\nAutoencoders to learn latent representations from network traffic flows are\nproposed. The first method resorts to a classifier based on the latent\nencodings obtained from Variational Autoencoders learned from traffic traces.\nThe second method is rather an anomaly detection method where the Variational\nAutoencoder is used to learn the abstract feature representations of\nexclusively legitimate traffic. Then anomalies are filtered out by relying on\nthe reconstruction loss of the Variational Autoencoder.\n  Both of the proposed methods have been thoroughly tested on two separate\ndatasets with a similar feature space. The results show that both methods are\npromising, with a slight superiority of the classifier based method over the\nanomaly based one.\n  %that the first method is able to successfully detect individual traffic\nflows with high precision on the training and validation data, slightly less\nsuccessfully on the test data. For the second method, the Variational\nAutoencoder will require further adjustments to be able to sufficiently filter\nout anomalies from network traffic flows.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:38:40 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["B\u00e5rli", "Eirik Molde", ""], ["Yazidi", "Anis", ""], ["Viedma", "Enrique Herrera", ""], ["Haugerud", "H\u00e5rek", ""]]}, {"id": "2105.06911", "submitter": "Adrian Schumacher", "authors": "Adrian Schumacher, Ruben Merz, Andreas Burg", "title": "Adding Indoor Capacity Without Fiber Backhaul: A mmWave Bridge Prototype", "comments": "To be published in IEEE Communications Magazine (Volume: 59, Issue:\n  4, April 2021)", "journal-ref": null, "doi": "10.1109/MCOM.001.2000722", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Today, a large portion of the mobile data traffic is consumed behind the\nshielding walls of buildings or in the Faraday cage of trains. This renders\ncellular network coverage from outdoor cell sites difficult. Indoor small cells\nand distributed antennas along train tracks are often considered as a solution,\nbut the cost and the need for optical fiber backhaul are often prohibitive. To\nalleviate this issue, we describe an out-of-band repeater that converts a sub-6\nGHz cell signal from a small cell installed at a cell tower to a mmWave\nfrequency for the fronthaul to buildings or distributed antenna sites, where\nthe signal is downconverted to the original frequency and emitted for example\ninside a building. This concept does not require fiber deployment, provides\nbackward compatibility to equipment already in use, and additional indoor\ncapacity is gained while outdoor networks are offloaded. The architecture and\nhardware prototype implementation are described, and measurements are reported\nto demonstrate the functionality and compatibility with commercial\ninfrastructure and mobile terminals.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:48:28 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Schumacher", "Adrian", ""], ["Merz", "Ruben", ""], ["Burg", "Andreas", ""]]}, {"id": "2105.07006", "submitter": "Leon Kellerhals", "authors": "Aleksander Figiel, Leon Kellerhals, Rolf Niedermeier, Matthias Rost,\n  Stefan Schmid and Philipp Zschoche", "title": "Optimal Virtual Network Embeddings for Tree Topologies", "comments": "An extended abstract of this work appears in the Proceedings of the\n  33rd ACM Symposium on Parallelism in Algorithms and Architectures (SPAA '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of distributed and data-centric applications often critically\ndepends on the interconnecting network. Applications are hence modeled as\nvirtual networks, also accounting for resource demands on links. At the heart\nof provisioning such virtual networks lies the NP-hard Virtual Network\nEmbedding Problem (VNEP): how to jointly map the virtual nodes and links onto a\nphysical substrate network at minimum cost while obeying capacities.\n  This paper studies the VNEP in the light of parameterized complexity. We\nfocus on tree topology substrates, a case often encountered in practice and for\nwhich the VNEP remains NP-hard. We provide the first fixed-parameter algorithm\nfor the VNEP with running time $O(3^r (s+r^2))$ for requests and substrates of\n$r$ and $s$ nodes, respectively. In a computational study our algorithm yields\nrunning time improvements in excess of 200x compared to state-of-the-art\ninteger programming approaches. This makes it comparable in speed to the\nwell-established ViNE heuristic while providing optimal solutions. We\ncomplement our algorithmic study with hardness results for the VNEP and related\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 18:00:02 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Figiel", "Aleksander", ""], ["Kellerhals", "Leon", ""], ["Niedermeier", "Rolf", ""], ["Rost", "Matthias", ""], ["Schmid", "Stefan", ""], ["Zschoche", "Philipp", ""]]}, {"id": "2105.07052", "submitter": "Mushu Li", "authors": "Mushu Li, Jie Gao, Conghao Zhou, Xuemin (Sherman) Shen, Weihua Zhuang", "title": "Slicing-Based AI Service Provisioning on Network Edge", "comments": "8 pages, 6 figures, Submitted to IEEE Vehicular Technology Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge intelligence leverages computing resources on network edge to provide\nartificial intelligence (AI) services close to network users. As it enables\nfast inference and distributed learning, edge intelligence is envisioned to be\nan important component of 6G networks. In this article, we investigate AI\nservice provisioning for supporting edge intelligence. First, we present the\nfeatures and requirements of AI services. Then, we introduce AI service data\nmanagement, and customize network slicing for AI services. Specifically, we\npropose a novel resource pooling method to jointly manage service data and\nnetwork resources for AI services. A trace-driven case study demonstrates the\neffectiveness of the proposed resource pooling method. Through this study, we\nillustrate the necessity, challenge, and potential of AI service provisioning\non network edge.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 19:52:35 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Li", "Mushu", "", "Sherman"], ["Gao", "Jie", "", "Sherman"], ["Zhou", "Conghao", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""], ["Zhuang", "Weihua", ""]]}, {"id": "2105.07088", "submitter": "Hai Dao", "authors": "Dao Thanh Hai", "title": "The Achilles Heel of Some Optical Network Designs and Performance\n  Comparisons", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This non-conventional paper represents the first attempt to uncover a\npossible vulnerability in some proposals for optical network designs and\nperformance comparisons. While optical network designs and planning lie at the\nheart of achieving fiber capacity efficiency and/or operational efficiency, its\ncombinatorial nature makes it computationally hard to reach optimal solutions\nfor realistic scenarios. Therefore, the well-established way that have been\ntaken for granted by not-so-small number of research papers is that an\noptimization model based on mixed integer linear programming (MILP) is first\nproposed and then due to the intractability of such combinatorial model, an\nheuristic algorithm is offered as an approximation. The solution-quality\ncomparison between the MILP and heuristic is then carried out on small-scale\ninstances including topologies and traffic tests to verify the efficacy of the\nproposed heuristic and the next step is to use such allegedly verified\nheuristic for optical network designs of realistic scenarios. This approach may\nnevertheless leave a critical vulnerability as there is no guarantee that one\nperforms well in small tests will generalize adequately for large-scale cases,\na common pitfall widely referred as the peril of extrapolation and/or\noverfitting. Besides, it is not uncommon that in some research works, for\nbenchmarking purpose, the comparison between a new design proposal whose\nperformance is obtained from on one heuristic and a reference design based on\nanother heuristic is carried out. As the result of missing solution quality\ncheck, such performance comparison relied merely on heuristic solutions may be\nequally vulnerable as its results can be distorted and thus, be far from the\npossibly achieved zones. In this work, we pinpoint those issues and provide a\nrealistic case study to highlight and demonstrate the impact of such\nvulnerabilities.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 22:51:55 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Hai", "Dao Thanh", ""]]}, {"id": "2105.07172", "submitter": "Masoud Hayeri Khyavi", "authors": "Masoud Hayeri Khyavi", "title": "Rescue Network: Using UAVs (drones) in Earthquake Crisis Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Earthquake is one of the natural disasters which cannot be either controlled\nor predicted absolutely. Since preventing earthquake is impossible, preventing\nits damages is also difficult. Unfortunately, after each earthquake and its\nfinancial and life losses, the initial panic of the people results in the\nsecond wave of accidents and damages. Inrush of confused people to escape the\ncities, streets and houses is a great problem. Apart from training in seismic\nareas which is very important, considering security arrangements and observing\nsecurity principles in construction, instructing the people is also important.\nOther than searching for and rescuing the people who are trapped under\ndetrimental or are in danger, those who thieve the damaged area is another\nimportant issue after each earthquake. Thus, a solution is proposed to use\nmodern technology to reduce threats of natural disasters including earthquake.\nToday, UAVs are being used in natural disasters and accidents. To this end and\nconsidering the ever-increasing developments of network technologies and\ncommunication including IoT and cloud, an efficient design is presented which\nincreases rescue factor of live creatures in natural disasters that can be used\nto rescue human lives and prevent subsequent outcomes after a few seconds. In\nthis study, focus is on time of occurrence of earthquake and after earthquake\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 08:19:41 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Khyavi", "Masoud Hayeri", ""]]}, {"id": "2105.07182", "submitter": "Tom Luan", "authors": "Tom H. Luan, Ruhan Liu, Longxiang Gao, Rui Li, Haibo Zhou", "title": "The Paradigm of Digital Twin Communications", "comments": "7 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast evolving of cloud computing and artificial intelligence (AI),\nthe concept of digital twin (DT) has recently been proposed and finds broad\napplications in industrial Internet, IoT, smart city, etc. The DT builds a\nmirror integrated multi-physics of the physical system in the digital space. By\ndoing so, the DT can utilize the rich computing power and AI at the cloud to\noperate on the mirror physical system, and accordingly provides feedbacks to\nhelp the real-world physical system in their practical task completion. The\nexisting literature mainly considers DT as a simulation/emulation approach,\nwhereas the communication framework for DT has not been clearly defined and\ndiscussed. In this article, we describe the basic DT communication models and\npresent the open research issues. By combining wireless communications,\nartificial intelligence (AI) and cloud computing, we show that the DT\ncommunication provides a novel framework for futuristic mobile agent systems.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 09:25:11 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Luan", "Tom H.", ""], ["Liu", "Ruhan", ""], ["Gao", "Longxiang", ""], ["Li", "Rui", ""], ["Zhou", "Haibo", ""]]}, {"id": "2105.07292", "submitter": "Shweta Jain", "authors": "Shweta Jain, Snehapreethi Gopinath, Dipankar Raychaudhuri", "title": "Storage Aware Routing for Generalized Delay Tolerant Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel storage aware routing (STAR) protocol designed to\nprovide a general networking solution over a broad range of wired and wireless\nusage scenarios. STAR enables routing policies which adapt seamlessly from a\nwell-connected wired network to a disconnected wireless network. STAR uses a\n2-Dimensional routing metric composed of a short and a long term route cost and\nstorage availability on downstream routers to make store or forward routing\ndecisions. Temporary in-network storage is preferred over forwarding along a\npath that is slower than average and opportunistic transmission is encouraged\nwhen faster than average routes become available. Results from ns2 based\nsimulations show that STAR achieves $40-50\\%$ higher throughput compared to\nOLSR in mobile vehicular and DTN scenarios and does $12-20\\%$ better than OLSR\nin the static mesh case. Experimental evaluation of STAR on the ORBIT testbed\nvalidates the protocol implementation, and demonstrates significant performance\nimprovements with 25\\% higher peak throughput compared to OLSR in a wireless\nmesh network.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 20:29:45 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Jain", "Shweta", ""], ["Gopinath", "Snehapreethi", ""], ["Raychaudhuri", "Dipankar", ""]]}, {"id": "2105.07428", "submitter": "Xianjun Jiao", "authors": "Xianjun Jiao, Michael Mehari, Wei Liu, Muhammad Aslam, Ingrid Moerman", "title": "Openwifi CSI fuzzer for authorized sensing and covert channels", "comments": "Accepted by ACM WiSec 2021", "journal-ref": null, "doi": "10.1145/3448300.3468255", "report-no": null, "categories": "cs.CR cs.AR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  CSI (Channel State Information) of WiFi systems contains the environment\nchannel response between the transmitter and the receiver, so the\npeople/objects and their movement in between can be sensed. To get CSI, the\nreceiver performs channel estimation based on the pre-known training field of\nthe transmitted WiFi signal. CSI related technology is useful in many cases,\nbut it also brings concerns on privacy and security. In this paper, we open\nsourced a CSI fuzzer to enhance the privacy and security of WiFi CSI\napplications. It is built and embedded into the transmitter of openwifi, which\nis an open source full-stack WiFi chip design, to prevent unauthorized sensing\nwithout sacrificing the WiFi link performance. The CSI fuzzer imposes an\nartificial channel response to the signal before it is transmitted, so the CSI\nseen by the receiver will indicate the actual channel response combined with\nthe artificial response. Only the authorized receiver, that knows the\nartificial response, can calculate the actual channel response and perform the\nCSI sensing. Another potential application of the CSI fuzzer is covert channels\nbased on a set of pre-defined artificial response patterns. Our work resolves\nthe pain point of implementing the anti-sensing idea based on the commercial\noff-the-shelf WiFi devices.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 13:00:00 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 21:30:42 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Jiao", "Xianjun", ""], ["Mehari", "Michael", ""], ["Liu", "Wei", ""], ["Aslam", "Muhammad", ""], ["Moerman", "Ingrid", ""]]}, {"id": "2105.07475", "submitter": "Seung-Woo Ko", "authors": "Seung Min Yu, Jihong Park, Sung Mo Kim, and Seung-Woo Ko", "title": "Integrating Geometry-Driven and Data-Driven Positioning via\n  Combinatorial Data Augmentation", "comments": "submitted to a possible IEEE journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Precise positioning has become one core topic in wireless communications by\nfacilitating candidate techniques of B5G. Nevertheless, most existing\npositioning algorithms, categorized into geometric-driven and data-driven\napproaches, fail to simultaneously fulfill diversified requirements for\npractical use, e.g., accuracy, real-time operation, scalability, maintenance,\netc. This article aims at introducing a new principle, called\n\\emph{combinatorial data augmentation} (CDA), a catalyst for the two\napproaches' tight integration. We first explain the concept of CDA and its\ncritical advantages over the two standalone approaches. Then, we confirm the\nCDA's effectiveness from field experiments based on WiFi round-trip time and\ninertial measurement units. Lastly, we present its potential beyond\npositioning, expected to play a critical role in B5G.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 16:37:26 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Yu", "Seung Min", ""], ["Park", "Jihong", ""], ["Kim", "Sung Mo", ""], ["Ko", "Seung-Woo", ""]]}, {"id": "2105.07558", "submitter": "Debajyoti Halder", "authors": "Debajyoti Halder, Prashant Kumar, Saksham Bhushan, and Anand M.\n  Baswade", "title": "fybrrStream: A WebRTC based Efficient and Scalable P2P Live Streaming\n  Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The demand for streaming media and live video conferencing is at peak and\nexpected to grow further, thereby the need for low-cost streaming services with\nbetter quality and lower latency is essential. Therefore, in this paper, we\npropose a novel peer-to-peer (P2P) live streaming platform, called fybrrStream,\nwhere a logical mesh and physical tree i.e., hybrid topology-based approach is\nleveraged for low latency streaming. fybrrStream distributes the load on\nparticipating peers in a hierarchical manner by considering their network\nbandwidth, network latency, and node stability. fybrrStream costs as low as the\ncost of just hosting a light-weight website and the performance is comparable\nto the existing state-of-the-art media streaming services. We evaluated and\ntested the proposed fybrrStream platform with real-field experiments using 50+\nusers spread across India and results obtained show significant improvements in\nthe live streaming performance over other schemes.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 00:55:31 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Halder", "Debajyoti", ""], ["Kumar", "Prashant", ""], ["Bhushan", "Saksham", ""], ["Baswade", "Anand M.", ""]]}, {"id": "2105.07560", "submitter": "Varsha Lohani", "authors": "Varsha Lohani, Anjali Sharma, and Yatindra Nath Singh", "title": "Dynamic Routing and Spectrum Assignment based on the Availability of\n  Consecutive Sub-channels in Flexi-grid Optical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using Optical Orthogonal Frequency Multiplexing (O-OFDM), variable bandwidth\nchannels can be created in Elastic Optical Networks (EON). This allows the use\nof spectrum more efficiently by allocating integral multiple of basic bandwidth\nslots to the lightpath requests. Consequently, such networks are also called\nflexible grid optical networks. It also adds a constraint of keeping all the\nallocated slots together when deciding the routes for the requests. This\nconstraint called the contiguity constraint makes the routing and spectrum\nalgorithms more challenging. In any network, the lightpath requests will arrive\nand depart dynamically and will invariably lead to spectrum fragmentation, and\nhence network will have a reduction in maximum possible utilization due to\nincreased blocking probability. In this paper, we have presented an improvised\nRSA algorithm that leads to lesser fragmentation. It is evident from the\nresults that the presented RSA algorithm uses adaptive parameters to reduce the\nblocking probability and fragmentation compared to other algorithms reported in\nthe recent past.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 01:15:14 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Lohani", "Varsha", ""], ["Sharma", "Anjali", ""], ["Singh", "Yatindra Nath", ""]]}, {"id": "2105.07578", "submitter": "Abhiram Bhaskar Kakarla", "authors": "Abhiram Bhaskar Kakarla", "title": "Towards Novel Multipath Data Scheduling For Future IoT Systems: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the initial years of its inception, the Internet was widely used for\ntransferring data packets between users and respective data sources by using IP\naddresses. With the advancements in technology, the Internet has been used to\nshare data within several small and resource-constrained devices connected in\nbillions to create the framework for the so-called Internet of Things (IoT).\nThese systems were known for the presentation of a large quantum of data\nemerging within these devices. On the flip side, these devices are known to\nimpose huge overheads on the IoT network. Therefore, it was essential to\ndevelop solutions concerning different network-related problems as a part of\nIoT networking. In this paper, we review these challenges emerge in routing,\ncongestion, energy conservation, scalability, heterogeneity, reliability,\nsecurity, and quality of service (QoS). This can be leverage to use the\navailable network optimally. As part of this research work, a detailed survey\nis to be conducted on the network optimization process within IoT, as presented\nin another research. Owing to the advances in wireless networking, relevant\nInternet-of-Things (IoT) devices were equipped with several elements, including\nmultiple network access interfaces. The adoption of multipath TCP (MPTCP)\ntechnology would improve the total throughput of data transmission. On the\nother hand, leveraging traditional MPTCP path management algorithms lead to\nother problems in data transport areas along with even buffer blockage. This\nshall lead to massive issues in areas of reduction of transmission performance\nacross the entire IoT network. To this end, we develop a novel multipath\nalgorithm that would efficiently manage the data transport in an intelligently\nscheduled and seamless manner using multiple wireless/wireline paths.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 02:28:36 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kakarla", "Abhiram Bhaskar", ""]]}, {"id": "2105.07584", "submitter": "Md Ashiqur Rahman", "authors": "Md Ashiqur Rahman, Beichuan Zhang", "title": "On Data-centric Forwarding in Mobile Ad-hoc Networks: Baseline Design\n  and Simulation Analysis", "comments": "Accepted at The 30th International Conference on Computer\n  Communications and Networks (ICCCN 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IP networking deals with end-to-end communication where the network layer\nrouting protocols maintain the reachability from one address to another.\nHowever, challenging environments, such as mobile ad-hoc networks or MANETs,\nlead to frequent path failures and changes between the sender and receiver,\nincurring higher packet loss. The obligatory route setup and maintenance of a\ndevice-to-device stable path in MANETs incur significant data retrieval delay\nand transmission overhead. Such overhead exaggerates the packet loss manifold.\n  Named Data Networking (NDN) can avoid such delays and overhead and\nsignificantly improve the overall network performance. It does so with direct\napplication-controlled named-data retrieval from any node in a network instead\nof reaching a specific IP address with protocol message exchange. However,\nexisting works lack any explicit or systematic analysis to justify such claims.\nOur work analyzes the core NDN and IP architectures in a MANET at a baseline\nlevel. The extensive simulations show that NDN, when applied correctly, yields\nmuch lower data retrieval latency than IP and can lower the network\ntransmission overhead in most cases. As a result, NDN's stateful forwarder can\nsignificantly increase the retrieval rate, offering a better trade-off at the\nnetwork layer. Such performance comes from its caching, built-in multicast, and\nrequest aggregation without requiring an IP-like separate routing control\nplane.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 02:58:36 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Rahman", "Md Ashiqur", ""], ["Zhang", "Beichuan", ""]]}, {"id": "2105.07605", "submitter": "Shenghao Yang", "authors": "Yanyan Dong, Sheng Jin, Yanzuo Chen, Shenghao Yang and Hoover H. F.\n  Yin", "title": "Utility Maximization for Multihop Wireless Networks Employing BATS Codes", "comments": "This paper was presented in part at 2020 IEEE International\n  Conference on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BATS codes are a class of efficient random linear network coding variation\nthat has been studied for multihop wireless networks mostly in scenarios of a\nsingle communication flow. Towards sophisticated multi-flow network\ncommunications, we formulate a network utility maximization (NUM) problem that\njointly optimizes the BATS code parameters of all the flows and network\nscheduling. The NUM problem adopts a batch-wise packet loss model that can be\nobtained from the network local statistics without any constraints on packet\nloss patterns. Moreover, the NUM problem allows a different number of recoded\npackets to be transmitted for different batches in a flow, which is called\nadaptive recoding. Due to both the non-convex objective and the BATS\ncode-related variables, the algorithms developed for the existing flow\noptimization problems can not be directed applied to solve our NUM problem. We\nintroduce a two-step algorithm for solving the NUM problem, where the first\nstep solves the problem with nonadaptive recoding schemes, and the second step\noptimizes adaptive recoding hop-by-hop from upstream to downstream in each\nflow. We perform various numerical evaluations and simulations to verify the\neffectiveness and efficiency of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 04:23:26 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Dong", "Yanyan", ""], ["Jin", "Sheng", ""], ["Chen", "Yanzuo", ""], ["Yang", "Shenghao", ""], ["Yin", "Hoover H. F.", ""]]}, {"id": "2105.07609", "submitter": "Hoover H. F. Yin", "authors": "Hoover H. F. Yin, Ka Hei Ng, Allen Z. Zhong, Raymond W. Yeung,\n  Shenghao Yang, Ian Y. Y. Chan", "title": "Intrablock Interleaving for Batched Network Coding with Blockwise\n  Adaptive Recoding", "comments": "submitted for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batched network coding (BNC) is a low-complexity solution to network\ntransmission in feedbackless multi-hop packet networks with packet loss. BNC\nencodes the source data into batches of packets. As a network coding scheme,\nthe intermediate nodes perform recoding on the received packets instead of just\nforwarding them. Blockwise adaptive recoding (BAR) is a recoding strategy which\ncan enhance the throughput and adapt real-time changes in the incoming channel\ncondition. In wireless applications, in order to combat burst packet loss,\ninterleavers can be applied for BNC in a hop-by-hop manner. In particular, a\nbatch-stream interleaver that permutes packets across blocks can be applied\nwith BAR to further boost the throughput. However, the previously proposed\nminimal communication protocol for BNC only supports permutation of packets\nwithin a block, called intrablock interleaving, and so it is not compatible\nwith the batch-stream interleaver. In this paper, we design an intrablock\ninterleaver for BAR that is backward compatible with the aforementioned minimal\nprotocol, so that the throughput can be enhanced without upgrading all the\nexisting devices.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 04:55:45 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Yin", "Hoover H. F.", ""], ["Ng", "Ka Hei", ""], ["Zhong", "Allen Z.", ""], ["Yeung", "Raymond W.", ""], ["Yang", "Shenghao", ""], ["Chan", "Ian Y. Y.", ""]]}, {"id": "2105.07614", "submitter": "Hoover H. F. Yin", "authors": "Hoover H. F. Yin, Bin Tang, Ka Hei Ng, Shenghao Yang, Xishi Wang,\n  Qiaoqiao Zhou", "title": "A Unified Adaptive Recoding Framework for Batched Network Coding", "comments": "submitted for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batched network coding is a variation of random linear network coding which\nhas low computational and storage costs. In order to adapt random fluctuations\nin the number of erasures in individual batches, it is not optimal to recode\nand transmit the same number of packets for all batches. Different distributed\noptimization models, which are called adaptive recoding schemes, were\nformulated for this purpose. The key component of these optimization problems\nis the expected value of the rank distribution of a batch at the next network\nnode, which is also known as the expected rank. In this paper, we put forth a\nunified adaptive recoding framework. We show that the expected rank functions\nare concave when the packet loss pattern is a stationary stochastic process\nregardless of the field size, which covers but not limited to independent\npacket loss and burst packet loss. Under this concavity assumption, we show\nthat there always exists a solution which not only can minimize the randomness\non the number of recoded packets but also can tolerate rank distribution errors\ndue to inaccurate measurements or limited precision of the machine. To obtain\nsuch an optimal solution, we propose tuning schemes that can turn any feasible\nsolution into a desired optimal solution.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 05:18:48 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Yin", "Hoover H. F.", ""], ["Tang", "Bin", ""], ["Ng", "Ka Hei", ""], ["Yang", "Shenghao", ""], ["Wang", "Xishi", ""], ["Zhou", "Qiaoqiao", ""]]}, {"id": "2105.07617", "submitter": "Hoover H. F. Yin", "authors": "Hoover H. F. Yin, Shenghao Yang, Qiaoqiao Zhou, Lily M. L. Yung, Ka\n  Hei Ng", "title": "BAR: Blockwise Adaptive Recoding for Batched Network Coding", "comments": "submitted for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop networks become popular network topologies in various emerging\nInternet of things applications. Batched network coding (BNC) is a solution to\nreliable communications in such networks with packet loss. By grouping packets\ninto small batches and restricting recoding to the packets belonging to the\nsame batch, BNC has a much smaller computational and storage requirements at\nthe intermediate nodes compared with a direct application of random linear\nnetwork coding. In this paper, we propose a practical recoding scheme called\nblockwise adaptive recoding (BAR) which learns the latest channel knowledge\nfrom short observations so that BAR can adapt to the fluctuation of channel\nconditions. We focus on investigating practical concerns such as the design of\nefficient BAR algorithms. We also design and investigate feedback schemes for\nBAR under imperfect feedback systems. Our numerical evaluations show that BAR\nhas significant throughput gain for small batch size compared with the existing\nbaseline recoding scheme. More importantly, this gain is insensitive to\ninaccurate channel knowledge. This encouraging result suggests that BAR is\nsuitable to be realized in practice as the exact channel model and its\nparameters could be unknown and subject to change from time to time.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 05:42:10 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Yin", "Hoover H. F.", ""], ["Yang", "Shenghao", ""], ["Zhou", "Qiaoqiao", ""], ["Yung", "Lily M. L.", ""], ["Ng", "Ka Hei", ""]]}, {"id": "2105.07653", "submitter": "Roza Goscien", "authors": "R\\'o\\.za Go\\'scie\\'n", "title": "Traffic-Aware Service Relocation in Cloud-Oriented Elastic Optical\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we study problem of efficient service relocation (i.e.,\nchanging assigned data center for a selected client node) in elastic optical\nnetworks (EONs) in order to increase network performance (measured by the\nvolume of accepted traffic). To this end, we first propose novel traffic model\nfor cloud ready transport networks. The model takes into account four flow\ntypes (i.e., city-to-city, city-to-data center, data center-to-data center and\ndata center-to-data center) while the flow characteristics are based on real\neconomical and geographical parameters of the cities related to network nodes.\nThen, we propose dedicated flow allocation algorithm that can be supported by\nthe service relocation process. We also introduce 21 different relocation\npolicies, which use three types of data for decision making - network\ntopological characteristics, rejection history and traffic prediction.\nEventually, we perform extensive numerical experiments in order to: (i) tune\nproposed optimization approaches and (ii) evaluate and compare their efficiency\nand select the best one. The results of the investigation prove high efficiency\nof the proposed policies. The propoerly designed relocation policy allowed to\nallocate up to 3% more traffic (compared to the allocation without that\npolicy). The results also reveal that the most efficient relocation policy\nbases its decisions on two types of data simultaneously - the rejection history\nand traffic prediction.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 08:00:55 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Go\u015bcie\u0144", "R\u00f3\u017ca", ""]]}, {"id": "2105.07711", "submitter": "Spyridon Mastorakis", "authors": "Muhammad Adil and Mian Ahmad Jan and Spyridon Mastorakis and Houbing\n  Song and Muhammad Mohsin Jadoon and Safia Abbas and Ahmed Farouk", "title": "Hash-MAC-DSDV: Mutual Authentication for Intelligent IoT-Based\n  Cyber-Physical Systems", "comments": "Accepted by the IEEE Internet of Things Journal. The copyright is\n  with the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPS) connected in the form of Internet of Things\n(IoT) are vulnerable to various security threats, due to the\ninfrastructure-less deployment of IoT devices. Device-to-Device (D2D)\nauthentication of these networks ensures the integrity, authenticity, and\nconfidentiality of information in the deployed area. The literature suggests\ndifferent approaches to address security issues in CPS technologies. However,\nthey are mostly based on centralized techniques or specific system deployments\nwith higher cost of computation and communication. It is therefore necessary to\ndevelop an effective scheme that can resolve the security problems in CPS\ntechnologies of IoT devices. In this paper, a lightweight Hash-MAC-DSDV (Hash\nMedia Access Control Destination Sequence Distance Vector) routing scheme is\nproposed to resolve authentication issues in CPS technologies, connected in the\nform of IoT networks. For this purpose, a CPS of IoT devices (multi-WSNs) is\ndeveloped from the local-chain and public chain, respectively. The proposed\nscheme ensures D2D authentication by the Hash-MAC-DSDV mutual scheme, where the\nMAC addresses of individual devices are registered in the first phase and\nadvertised in the network in the second phase. The proposed scheme allows\nlegitimate devices to modify their routing table and unicast the one-way hash\nauthentication mechanism to transfer their captured data from source towards\nthe destination. Our evaluation results demonstrate that Hash- MAC-DSDV\noutweighs the existing schemes in terms of attack detection, energy consumption\nand communication metrics.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 10:05:08 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Adil", "Muhammad", ""], ["Jan", "Mian Ahmad", ""], ["Mastorakis", "Spyridon", ""], ["Song", "Houbing", ""], ["Jadoon", "Muhammad Mohsin", ""], ["Abbas", "Safia", ""], ["Farouk", "Ahmed", ""]]}, {"id": "2105.07839", "submitter": "Prabath Abeysiriwardana", "authors": "Prabath Chaminda Abeysiriwardana, Udith K. Jayasinghe-Mudalige, Saluka\n  R. Kodituwakku", "title": "\"Connected Researches\" in \"Smart Lab Bubble\": A Lifeline for Commercial\n  Agriculture in \"New Normal\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.RO cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research in commercial agriculture is the best strategy that can be adopted\nby a country to keep on track of the second sustainable goal -- zero hunger by\n2030. Analyzing the drawbacks of present research environment and find\nsolutions through digital intervention would be ideal solution to de-isolate\nthe research out come in light of disruptions caused by the Covid pandemic. The\nperformance of the research institutes is not expected to remain the same and\nwould prefer to be stagnated at a lower level. The right evacuation plan that\ncould be worked out by establishing connected research through the digital\nsolution and followed by digitally endorsed performance monitoring and\nevaluation would be saviour for keeping the research in commercial agriculture\nlive at this pandemic. This paper will discuss what are the problems in\ncarrying out research in commercial agriculture and propose a conceptual model\nto connect research beyond physical presence by digital transformations in\norganization design of research institutes in light of Covid-19. Further,\ndigitally endorsed performance measurements and evaluation is envisaged in a\ndigitally empowered connected lab complex -- \"Smart Lab Bubble\" that is further\nfacilitated through policy measures. The connected lab complex called the\n\"Smart Lab Bubble\" concept we present here could be viewed or applied in\ndifferent perspectives to engineer the real need of the time for the\nsustainability of research in commercial agriculture. Further, it could be\nadopted in research in other life science areas.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 15:08:41 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Abeysiriwardana", "Prabath Chaminda", ""], ["Jayasinghe-Mudalige", "Udith K.", ""], ["Kodituwakku", "Saluka R.", ""]]}, {"id": "2105.08109", "submitter": "Yangming Zhao", "authors": "Yangming Zhao and Chunming Qiao", "title": "Quantum Transport Protocols for Distributed Quantum Computing", "comments": "16 pages, 27 figures, will be submitted to an ACM conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing holds a great promise and this work proposes to use new\nquantum data networks (QDNs) to connect multiple small quantum computers to\nform a cluster. Such a QDN differs from existing QKD networks in that the\nformer must deliver data qubits reliably within itself. Two types of QDNs are\nstudied, one using teleportation and the other using tell-and-go (TAG) to\nexchange quantum data. Two corresponding quantum transport protocols (QTPs),\nnamed Tele-QTP and TAG-QTP, are proposed to address many unique design\nchallenges involved in reliable delivery of data qubits, and constraints\nimposed by quantum physics laws such as the no-cloning theorem, and limited\navailability of quantum memory.\n  The proposed Tele-QTP and TAG-QTP are the first transport layer protocols for\nQDNs, complementing other works on the network protocol stack. Tele-QTP and\nTAG-QTP have novel mechanisms to support congestion-free and reliable delivery\nof streams of data qubits by managing the limited quantum memory at end hosts\nas well as intermediate nodes. Both analysis and extensive simulations show\nthat the proposed QTPs can achieve a high throughput and fairness. This study\nalso offers new insights into potential tradeoffs involved in using the two\nmethods, teleportation and TAG, in two types of QDNs.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 18:36:06 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 03:34:56 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Zhao", "Yangming", ""], ["Qiao", "Chunming", ""]]}, {"id": "2105.08151", "submitter": "J\\'eferson Campos Nobre", "authors": "J\\'eferson C. Nobre, Lisandro Z. Granville, Alberto G. Prieto,\n  Alexander Clemm", "title": "On Using P2P Technology for Decentralized Detection of Service Level\n  Agreement Violations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Critical networked services enable significant revenue for network operators\nand, in turn, are regulated by Service Level Agreements (SLAs). In order to\nensure SLAs are being met, service levels need to be monitored. One technique\nfor this involves active measurement mechanisms which employ measurement probes\nalong the network to inject synthetic traffic and compute the network\nperformance. However, these mechanisms are expensive in terms of resources\nconsumption. Thus, these mechanisms usually can cover only a fraction of what\ncould be measured, which can lead to SLA violations being missed. Besides that,\nthe definition of this fraction is a practice done by human administrators,\nwhich does not scale well and does not adapt to highly dynamic networking\npatterns. In this article, we examine the potential benefits of using P2P\ntechnology to improve the detection of SLA Violations. We first describe the\nprinciples of a P2P-based steering of active measurement mechanisms. These\nprinciples are characterized by a high degree of decentralized decision making\nacross a network using a self-organizing overlay. In a second step, we present\nmeasurement session activation strategies based on these principles. These\nstrategies do not require human intervention, are adaptive to changes in\nnetwork conditions, and independent of the underlying active measurement\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 20:39:55 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Nobre", "J\u00e9ferson C.", ""], ["Granville", "Lisandro Z.", ""], ["Prieto", "Alberto G.", ""], ["Clemm", "Alexander", ""]]}, {"id": "2105.08395", "submitter": "Nikos Fotiou", "authors": "Nikos Fotiou, Vasilios A. Siris, George C. Polyzos", "title": "Enabling self-verifiable mutable content items in IPFS using\n  Decentralized Identifiers", "comments": "In: DI2F: Decentralising the Internet with IPFS and Filecoin, IFIP\n  Networking 2021 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In IPFS content identifiers are constructed based on the item's data\ntherefore the binding between an item's identifier and its data can be\ndeterministically verified. Nevertheless, once an item is modified, its\nidentifier also changes. Therefore when it comes to mutable content there is a\nneed for keeping track of the \"latest\" IPFS identifier. This is achieved using\nnaming protocols on top of IPFS, such as IPNS and DNSlink, that map a constant\nname to an IPFS identifier, allowing at the same time content owners to update\nthese mappings. Nevertheless, IPNS relies on a cryptographic key pair that\ncannot be rotated, and DNSlink does not provide content authenticity\nprotection. In this paper, we propose a naming protocol that combines DNSlink\nand decentralized identifiers to enable self-verifiable content items. Our\nprotocol provides content authenticity without imposing any security\nrequirement to DNSlink. Furthermore, our protocol prevent fake content even if\nattackers have access to the DNS server of the content owner or have access to\nthe content owner secret keys. Our proof of concept implementation shows that\nour protocol is feasible and can be used with existing IPFS tools.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 09:46:50 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Fotiou", "Nikos", ""], ["Siris", "Vasilios A.", ""], ["Polyzos", "George C.", ""]]}, {"id": "2105.08576", "submitter": "Conghao Zhou", "authors": "Wen Wu, Conghao Zhou, Mushu Li, Huaqing Wu, Haibo Zhou, Ning Zhang,\n  Xuemin (Sherman) Shen, Weihua Zhuang", "title": "AI-Native Network Slicing for 6G Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the global roll-out of the fifth generation (5G) networks, it is\nnecessary to look beyond 5G and envision the sixth generation (6G) networks.\nThe 6G networks are expected to have space-air-ground integrated networking,\nadvanced network virtualization, and ubiquitous intelligence. This article\nproposes an artificial intelligence (AI)-native network slicing architecture\nfor 6G networks to facilitate intelligent network management and support\nemerging AI services. AI is built in the proposed network slicing architecture\nto enable the synergy of AI and network slicing. AI solutions are investigated\nfor the entire lifecycle of network slicing to facilitate intelligent network\nmanagement, i.e., AI for slicing. Furthermore, network slicing approaches are\ndiscussed to support emerging AI services by constructing slice instances and\nperforming efficient resource management, i.e., slicing for AI. Finally, a case\nstudy is presented, followed by a discussion of open research issues that are\nessential for AI-native network slicing in 6G.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:01:57 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Wu", "Wen", "", "Sherman"], ["Zhou", "Conghao", "", "Sherman"], ["Li", "Mushu", "", "Sherman"], ["Wu", "Huaqing", "", "Sherman"], ["Zhou", "Haibo", "", "Sherman"], ["Zhang", "Ning", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""], ["Zhuang", "Weihua", ""]]}, {"id": "2105.08588", "submitter": "Hai Dao", "authors": "Dao Thanh Hai and Le Anh Ngoc", "title": "A pragmatic approach for designing transparent WDM optical networks with\n  multi-objectives", "comments": "9 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In facing with the explosive Internet traffic growth, optical transport\nnetworks based on WDM technologies forming the core part of Internet\ninfrastructure carrying multi-Tb/s has to be re-considered from both designing,\nplanning, operation and management perspectives to attain greater efficiency.\nThanks to the convergence of significant advances in optical transmission\ntechnologies, and photonic switching, transparent (all-optical) architecture\nhas come into practice, paving the way for eliminating the over-utilization of\ncostly optical-electrical-optical (O-E-O) interfaces and hence, yielding\nremarkable savings of cost and energy consumption compared to opaque\narchitecture. Traditional designs for transparent optical networks based on\nsingle-objective optimization model aiming at optimizing solely a single\nperformance metric appears to be insufficient to capture the nuances of\npractical designs while conventional multi-objective approach tends to reach\n(non-) optimal solutions. Different from existing works, we present a new\nframework for multi-objective WDM network designs capturing several goals on\none hand and on the other hand, achieving optimal solutions. Moreover, our\nproposal exploits the characteristics of each constituent objectives to lay the\nfoundation for setting up weight coefficient so that the order of optimization\nis guaranteed. Equally important, our proposal is pragmatic in the sense that\nthe complexity of the optimization model remains the same as the\nsingle-objective model while the quality of solution has been greatly improved.\nWe have extensively tested realistic optical core networks topologies, that is,\nCOST239 and NSFNET, with various network traffic conditions and it turns out\nthat our design brings about a saving of wavelength link usage up to roughly\n$28\\%$ in the most favorable cases while $14\\%$ is expected for the least\nfavorable cases.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:19:43 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Hai", "Dao Thanh", ""], ["Ngoc", "Le Anh", ""]]}, {"id": "2105.08713", "submitter": "Karim Banawan", "authors": "Karim Banawan and Ahmed Arafa and Sennur Ulukus", "title": "Timely Private Information Retrieval", "comments": "Accepted for presentation in ISIT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.NI eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the problem of \\emph{timely} private information retrieval (PIR)\nfrom $N$ non-colluding and replicated servers. In this problem, a user desires\nto retrieve a message out of $M$ messages from the servers, whose contents are\ncontinuously updating. The retrieval process should be executed in a timely\nmanner such that no information is leaked about the identity of the message. To\nassess the timeliness, we use the \\emph{age of information} (AoI) metric.\nInterestingly, the timely PIR problem reduces to an AoI minimization subject to\nPIR constraints under \\emph{asymmetric traffic}. We explicitly characterize the\noptimal tradeoff between the PIR rate and the AoI metric (peak AoI or average\nAoI) for the case of $N=2$, $M=3$. Further, we provide some structural insights\non the general problem with arbitrary $N$, $M$.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:53:00 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Banawan", "Karim", ""], ["Arafa", "Ahmed", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2105.08967", "submitter": "Rahul Vaze", "authors": "Rahul Vaze, Jayakrishnan Nair", "title": "Speed Scaling On Parallel Servers with MapReduce Type Precedence\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A multiple server setting is considered, where each server has tunable speed,\nand increasing the speed incurs an energy cost. Jobs arrive to a single queue,\nand each job has two types of sub-tasks, map and reduce, and a {\\bf precedence}\nconstraint among them: any reduce task of a job can only be processed once all\nthe map tasks of the job have been completed. In addition to the scheduling\nproblem, i.e., which task to execute on which server, with tunable speed, an\nadditional decision variable is the choice of speed for each server, so as to\nminimize a linear combination of the sum of the flow times of jobs/tasks and\nthe total energy cost. The precedence constraints present new challenges for\nthe speed scaling problem with multiple servers, namely that the number of\ntasks that can be executed at any time may be small but the total number of\noutstanding tasks might be quite large. We present simple speed scaling\nalgorithms that are shown to have competitive ratios, that depend on the power\ncost function, and/or the ratio of the size of the largest task and the\nshortest reduce task, but not on the number of jobs, or the number of servers.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 07:37:47 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Vaze", "Rahul", ""], ["Nair", "Jayakrishnan", ""]]}, {"id": "2105.09004", "submitter": "Mario Di Mauro", "authors": "Mario Di Mauro, Giovanni Galatro, Fabio Postiglione, Marco Tambasco", "title": "Performability of Network Service Chains: Stochastic Modeling and\n  Assessment of Softwarized IP Multimedia Subsystem", "comments": null, "journal-ref": null, "doi": "10.1109/TDSC.2021.3082626", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service provisioning mechanisms implemented across 5G infrastructures take\nbroadly into use the network service chain concept. Typically, it is coupled\nwith Network Function Virtualization (NFV) paradigm, and consists in defining a\npre-determined path traversed by a set of softwarized network nodes to provide\nspecific services. A well known chain-like framework is the IP Multimedia\nSubsystem (IMS), a key infrastructure of 5G networks, that we characterize both\nby a performance and an availability perspective. Precisely, supported by a\ndesigned from scratch testbed realized through Clearwater platform, we perform\na stochastic assessment of a softwarized IMS (softIMS) architecture where two\nmain stages stand out: i) a performance analysis, where, exploiting the\nqueueing network decomposition method, we formalize an optimization problem of\nresource allocation by modeling each softIMS node as an M/G/c system; ii) an\navailability assessment, where, adopting the Stochastic Reward Net methodology,\nwe are able to characterize the behavior of softIMS in terms of failure/repair\nevents, and to derive a set of optimal configurations satisfying a given\navailability requirement (e.g. five nines) while minimizing deployment costs.\nTwo routines dubbed OptCNT and OptSearchChain have been devised to govern the\nperformance and availability analyses, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 09:13:52 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Di Mauro", "Mario", ""], ["Galatro", "Giovanni", ""], ["Postiglione", "Fabio", ""], ["Tambasco", "Marco", ""]]}, {"id": "2105.09230", "submitter": "Vasilis Friderikos", "authors": "Vasilis Friderikos", "title": "Airborne Urban Microcells with Grasping End Effectors: A Game Changer\n  for 6G Networks?", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airborne (or flying) base stations (ABSs) embedded on drones or unmanned\naerial vehicles (UAVs) can be deemed as a central element of envisioned 6G\ncellular networks where significant cell densification with mmWave/Terahertz\ncommunications will be part of the ecosystem. Nonetheless, one of the key\nchallenges facing the deployment of ABSs is the inherent limited available\nenergy of the drone, which limits the hovering time for serving ground users to\nthe orders of minutes. This impediment deteriorate the performance of the\nUAV-enabled cellular network and hinders wide adoption and use of the\ntechnology. In this paper, we propose robotic airborne base stations (RABSs)\nwith grasping capabilities to increase the serving time of ground users by\nmultiple orders of magnitude compared to nominal hovering based operation. More\nspecifically, to perform the grasping task, the RABS is equipped with a\nversatile, albeit, general purpose gripper manipulator. Depending on the type\nof the gripper RABS can provide service in the range of hours, compared to\nminutes of hovering based ABSs. In theory it is possible that grasping can be\nenergy neutral, hence the time of service can be bounded by the communications\nenergy consumption. To illustrate the case, energy consumption comparison\nbetween hovering and grasping is performed in order to reveal the significant\nbenefits of the proposed approach. Finally, overarching challenges, design\nconsiderations for RABS, and future avenues of research are outlined to realize\nthe full potential of the proposed robotic aerial base stations.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 16:24:39 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Friderikos", "Vasilis", ""]]}, {"id": "2105.09389", "submitter": "Shay Vargaftik", "authors": "Guy Goren, Shay Vargaftik, Yoram Moses", "title": "Stochastic Coordination in Heterogeneous Load Balancing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current-day data centers and high-volume cloud services employ a broad set of\nheterogeneous servers. In such settings, client requests typically arrive at\nmultiple entry points, and dispatching them to servers is an urgent distributed\nsystems problem. This paper presents an efficient solution to the load\nbalancing problem in such systems that improves on and overcomes problems of\nprevious solutions. The load balancing problem is formulated as a stochastic\noptimization problem, and an efficient algorithmic solution is obtained based\non a subtle mathematical analysis of the problem. Finally, extensive evaluation\nof the solution on simulated data shows that it outperforms previous solutions.\nMoreover, the resulting dispatching policy can be computed very efficiently,\nmaking the solution practically viable.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 20:38:37 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 14:04:09 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Goren", "Guy", ""], ["Vargaftik", "Shay", ""], ["Moses", "Yoram", ""]]}, {"id": "2105.09459", "submitter": "Md Mohaimenuzzaman", "authors": "Md Mohaimenuzzaman, SM Monzurur Rahman, Musaed Alhussein, Ghulam\n  Muhammad and Khondaker Abdullah Al Mamun", "title": "Enhancing safety in water transport system based on Internet of Things\n  for developing countries", "comments": null, "journal-ref": "International Journal of Distributed Sensor Networks (2016),\n  12(2), 2834616", "doi": "10.1155/2016/2834616", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accidents in inland waterways in developing countries are a regular\nphenomenon throughout the year causing deaths, injuries, monetary loss, and a\nsignificant amount of missing people. In consequence, a lot of families are\nlosing their dear ones leading to much misery. The above context demands an\nintelligent, safe, and reliable water transport system for the developing\ncountries. The concept of Intelligent Transport System (ITS) can be applied to\ndevelop such system; however, there are issues with ITS and Internet of Things\n(IoT) unlocks a new way of developing it. This paper proposes a model to\ntransform the water transport system into an intelligent system based on IoT.\nIPv6 based machine-to-machine (M2M) protocol, 3G telecommunication technology,\nand IEEE 802.15.4 network standard play a significant role in this proposed IoT\nbased system.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 06:09:11 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Mohaimenuzzaman", "Md", ""], ["Rahman", "SM Monzurur", ""], ["Alhussein", "Musaed", ""], ["Muhammad", "Ghulam", ""], ["Mamun", "Khondaker Abdullah Al", ""]]}, {"id": "2105.09460", "submitter": "Mingming Liu", "authors": "Hongde Wu, Zhengyong Chen, Noel E. O'Connor and Mingming Liu", "title": "Optimal Distributed Bandwidth Allocation in NB-IoT Networks", "comments": "The paper has been accepted by the 6th ACM/IEEE Conference on\n  Internet of Things Design and Implementation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a key problem of Narrowband-Internet of Things\n(NB-IoT) in the context of 5G with Mobile Edge Computing (MEC). We address the\nchallenge that IoT devices may have different priorities when demanding\nbandwidth for data transmission in specific applications and services. Due to\nthe scarcity of bandwidth in an MEC enabled IoT network, our objective is to\noptimize bandwidth allocation for a group of NB-IoT devices in a way that the\ngroup can work collaboratively to maximize their overall utility. To this end,\nwe design an optimal distributed algorithm and use simulations to demonstrate\nits efficacy to effectively manage various IoT data streams in a fully\ndistributed framework.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 16:56:23 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Wu", "Hongde", ""], ["Chen", "Zhengyong", ""], ["O'Connor", "Noel E.", ""], ["Liu", "Mingming", ""]]}, {"id": "2105.09461", "submitter": "Ayman Al-Kababji", "authors": "Ayman Al-Kababji, Abbes Amira, Faycal Bensaali, Abdulah Jarouf, Lisan\n  Shidqi, Hamza Djelouat", "title": "An IoT-Based Framework for Remote Fall Monitoring", "comments": "30 Pages, 9 figures, 9 tables. This is a the Accepted Manuscript\n  version of the article published in Biomedical Signal Processing and Control\n  (URL: https://doi.org/10.1016/j.bspc.2021.102532)", "journal-ref": null, "doi": "10.1016/j.bspc.2021.102532", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fall detection is a serious healthcare issue that needs to be solved. Falling\nwithout quick medical intervention would lower the chances of survival for the\nelderly, especially if living alone. Hence, the need is there for developing\nfall detection algorithms with high accuracy. This paper presents a novel\nIoT-based system for fall detection that includes a sensing device transmitting\ndata to a mobile application through a cloud-connected gateway device. Then,\nthe focus is shifted to the algorithmic aspect where multiple features are\nextracted from 3-axis accelerometer data taken from existing datasets. The\nresults emphasize on the significance of Continuous Wavelet Transform (CWT) as\nan influential feature for determining falls. CWT, Signal Energy (SE), Signal\nMagnitude Area (SMA), and Signal Vector Magnitude (SVM) features have shown\npromising classification results using K-Nearest Neighbors (KNN) and E-Nearest\nNeighbors (ENN). For all performance metrics (accuracy, recall, precision,\nspecificity, and F1 Score), the achieved results are higher than 95% for a\ndataset of small size, while more than 98.47% score is achieved in the\naforementioned criteria over the UniMiB-SHAR dataset by the same algorithms,\nwhere the classification time for a single test record is extremely efficient\nand is real-time\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 22:37:19 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Al-Kababji", "Ayman", ""], ["Amira", "Abbes", ""], ["Bensaali", "Faycal", ""], ["Jarouf", "Abdulah", ""], ["Shidqi", "Lisan", ""], ["Djelouat", "Hamza", ""]]}, {"id": "2105.09462", "submitter": "Ruikang Zhong", "authors": "Ruikang Zhong, Xiao Liu, Yuanwei Liu, Yue Chen and Zhu Han", "title": "Mobile Reconfigurable Intelligent Surfaces for NOMA Networks: Federated\n  Learning Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A novel framework of reconfigurable intelligent surfaces (RISs)-enhanced\nindoor wireless networks is proposed, where an RIS mounted on the robot is\ninvoked to enable mobility of the RIS and enhance the service quality for\nmobile users. Meanwhile, non-orthogonal multiple access (NOMA) techniques are\nadopted to further increase the spectrum efficiency since RISs are capable to\nprovide NOMA with artificial controlled channel conditions, which can be seen\nas a beneficial operation condition to obtain NOMA gains. To optimize the sum\nrate of all users, a deep deterministic policy gradient (DDPG) algorithm is\ninvoked to optimize the deployment and phase shifts of the mobile RIS as well\nas the power allocation policy. In order to improve the efficiency and\neffectiveness of agent training for the DDPG agents, a federated learning (FL)\nconcept is adopted to enable multiple agents to simultaneously explore similar\nenvironments and exchange experiences. We also proved that with the same random\nexploring policy, the FL armed deep reinforcement learning (DRL) agents can\ntheoretically obtain a reward gain compare to the independent agents. Our\nsimulation results indicate that the mobile RIS scheme can significantly\noutperform the fixed RIS paradigm, which provides about three times data rate\ngain compare to the fixed RIS paradigm. Moreover, the NOMA scheme is capable to\nachieve a gain of 42% in contrast with the OMA scheme in terms of sum rate.\nFinally, the multi-cell simulation proved that the FL enhanced DDPG algorithm\nhas a superior convergence rate and optimization performance than the\nindependent training framework.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 21:23:50 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Zhong", "Ruikang", ""], ["Liu", "Xiao", ""], ["Liu", "Yuanwei", ""], ["Chen", "Yue", ""], ["Han", "Zhu", ""]]}, {"id": "2105.09463", "submitter": "Javad Hajipour", "authors": "Javad Hajipour", "title": "Stochastic Buffer-Aided Relay-Assisted MEC in Time-Slotted Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Edge Computing (MEC) is a promising paradigm to respond to the rising\ncomputation requests of the users in the emerging wireless networks, and\nespecially in the Internet of Things (IoT). In this paper, we study\nbuffer-aided relay-assisted MEC in systems with discrete transmission time-line\nand block fading channels. We consider a hierarchical network composed of a\nsource, a buffer-aided relay, and another node in a higher level in the\nhierarchy. The source sends its tasks to the relay which in turn randomly\nassigns the received tasks to its own computing server or to the server of the\nnext node in the hierarchy. We provide a framework to take into account the\ndelays in both the transmission and computation buffers which facilitates the\nderivation of the expression for the Average Response Time (ART) in the system.\nBased on that and the system average power consumption in each slot, we\nintroduce the concept of Average Response Energy (ARE) as a novel metric to\ncapture the energy efficiency in MEC. Accordingly, we propose two offloading\nschemes with relevant problem formulations, namely the Minimum ART (MART) and\nthe Minimum ARE (MARE) schemes, to optimize the ART or the ARE while keeping\nthe system queues stable. We analyze the properties of the formulated problems,\nin terms of the feasible sets and the objective functions and noting them, we\npropose effective solution methods. Using extensive simulations, we validate\nthe presented analysis and show the effectiveness of the proposed schemes in\ncomparison with various baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 07:44:55 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hajipour", "Javad", ""]]}, {"id": "2105.09493", "submitter": "Yilong Hui", "authors": "Yilong Hui and Zhou Su and Tom H. Luan and Nan Cheng", "title": "Futuristic Intelligent Transportation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The emerging autonomous vehicles (AVs) will inevitably revolutionize the\ntransportation systems. This is because of a key feature of AVs; instead of\nbeing managed by human drivers as the conventional vehicles, AVs are of the\ncomplete capability to manage the driving by themselves. As a result, the\nfuturistic intelligent transportation system (FITS) can be a centrally managed\nand optimized system with the fully coordinated driving of vehicles, which is\nimpossible by the current transportation systems controlled by humans. In this\narticle, we envision the operation of such FITS when AVs, advanced vehicular\nnetworks (VANETs) and artificial intelligence (AI) are adopted. Specifically,\nwe first develop the autonomous vehicular networks (AVNs) based on the advanced\ndevelopment of AVs and heterogeneous vehicular communication technologies to\nachieve global data collection and real-time data sharing. With this network\narchitecture, we then integrate AVNs and AI based on the intelligent digital\ntwin (IDT) to design the FITS with the target of setting up an accurate and\nefficient global traffic scheduling system. After that, compared with the\nconventional schemes, a customized path planning case is studied to evaluate\nthe performance of the proposed FITS. Finally, we highlight the emerging issues\nrelated to the FITS for future research.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 03:34:05 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hui", "Yilong", ""], ["Su", "Zhou", ""], ["Luan", "Tom H.", ""], ["Cheng", "Nan", ""]]}, {"id": "2105.09553", "submitter": "Monireh Ghasri", "authors": "Monireh Allah Gholi Ghasri, Ali Mohammad Afshin Hemmatyar", "title": "A New Dynamic Optimal Relay Selection and RF interfaces Setting\n  Algorithm (DORSA) in M2M for IoT Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine-to-Machine (M2M) communication is one of the main communications in\nthe Internet of Things (IoT). How to send data in these high-density\ncommunications using relay selection can help better performance of this type\nof communications in various applications. In addition, the possibility of\nsimultaneous use of different Radio Frequency (RF) interfaces helps to make\nbetter use of the network radio frequencies.\n  Therefore, in this work, we try to further use of machine communication\nequipment and improve the average data rate of networks in different\napplications such as the Internet of Things, which have different bandwidth\nrequirements, by providing an optimization algorithm for relay selection as\nwell as the simultaneous and dynamic multiple M2M RF interfaces setting that\ncalled Dynamic Optimal Relay Selection and RF interfaces Setting Algorithm\n(DORSA).\n  The simulation results show that the average DORSA\\_W-B-Z data rate is\nimproved by 0.8 to 10% compared to the studied algorithms such as direct\ntransmission as well as relay selection algorithms with static RF interface\nsetting.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 07:16:45 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 10:34:36 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ghasri", "Monireh Allah Gholi", ""], ["Hemmatyar", "Ali Mohammad Afshin", ""]]}, {"id": "2105.09584", "submitter": "Deep Shrestha", "authors": "Maria Posluk, Jesper Ahlander, Deep Shrestha, Sara Modarres Razavi,\n  Gustav Lindmark and Fredrik Gunnarsson", "title": "5G Deployment Strategies for High Positioning Accuracy in Indoor\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indoor positioning is currently recognized as one of the important features\nin emergency, commercial and industrial applications. The 5G network enhances\nmobility, flexibility, reliability, and security to new higher levels which\ngreatly benefit the IoT and industrial applications. Industrial IoT (IIoT)\nuse-cases are characterized by ambitious system requirements for positioning\naccuracy in many verticals. For example, on the factory floor, it is important\nto locate assets and moving objects such as forklifts. The deployment design\nfor different IIoT environments has a significant impact on the positioning\nper-performance in terms of both accuracy and availability of the service.\nIndoor factory (InF) and indoor open office (IOO) are two available and\nstandardized Third Generation Partnership Project (3GPP) scenarios for\nevaluation of indoor channel models and positioning performance in IIoT use\ncases. This paper aims to evaluate the positioning performance in terms of\naccuracy and availability while considering different deployment strategies.\nOur simulation-based evaluation shows that deployment plays a vital role when\nit comes to achieving high accuracy positioning performance. It is for example\nfavorable to deploy the 5G Transmission and Reception Points (TRPs) on the\nwalls of the factory halls than deploying them attached to the ceiling.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 08:20:13 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Posluk", "Maria", ""], ["Ahlander", "Jesper", ""], ["Shrestha", "Deep", ""], ["Razavi", "Sara Modarres", ""], ["Lindmark", "Gustav", ""], ["Gunnarsson", "Fredrik", ""]]}, {"id": "2105.09641", "submitter": "Latif U. Khan", "authors": "Latif U. Khan, Yan Kyaw Tun, Madyan Alsenwi, Muhammad Imran, Zhu Han,\n  and Choong Seon Hong", "title": "A Dispersed Federated Learning Framework for 6G-Enabled Autonomous\n  Driving Cars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sixth-Generation (6G)-based Internet of Everything applications (e.g.\nautonomous driving cars) have witnessed a remarkable interest. Autonomous\ndriving cars using federated learning (FL) has the ability to enable different\nsmart services. Although FL implements distributed machine learning model\ntraining without the requirement to move the data of devices to a centralized\nserver, it its own implementation challenges such as robustness, centralized\nserver security, communication resources constraints, and privacy leakage due\nto the capability of a malicious aggregation server to infer sensitive\ninformation of end-devices. To address the aforementioned limitations, a\ndispersed federated learning (DFL) framework for autonomous driving cars is\nproposed to offer robust, communication resource-efficient, and privacy-aware\nlearning. A mixed-integer non-linear (MINLP) optimization problem is formulated\nto jointly minimize the loss in federated learning model accuracy due to packet\nerrors and transmission latency. Due to the NP-hard and non-convex nature of\nthe formulated MINLP problem, we propose the Block Successive Upper-bound\nMinimization (BSUM) based solution. Furthermore, the performance comparison of\nthe proposed scheme with three baseline schemes has been carried out. Extensive\nnumerical results are provided to show the validity of the proposed BSUM-based\nscheme.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 10:17:50 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Khan", "Latif U.", ""], ["Tun", "Yan Kyaw", ""], ["Alsenwi", "Madyan", ""], ["Imran", "Muhammad", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2105.09678", "submitter": "Hossam Farag", "authors": "Hossam Farag and Cedomir Stefanovic", "title": "Congestion-Aware Routing in Dynamic IoT Networks: A Reinforcement\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The innovative services empowered by the Internet of Things (IoT) require a\nseamless and reliable wireless infrastructure that enables communications\nwithin heterogeneous and dynamic low-power and lossy networks (LLNs). The\nRouting Protocol for LLNs (RPL) was designed to meet the communication\nrequirements of a wide range of IoT application domains. However, a load\nbalancing problem exists in RPL under heavy traffic-load scenarios, degrading\nthe network performance in terms of delay and packet delivery. In this paper,\nwe tackle the problem of load-balancing in RPL networks using a\nreinforcement-learning framework. The proposed method adopts Q-learning at each\nnode to learn an optimal parent selection policy based on the dynamic network\nconditions. Each node maintains the routing information of its neighbours as\nQ-values that represent a composite routing cost as a function of the\ncongestion level, the link-quality and the hop-distance. The Q-values are\nupdated continuously exploiting the existing RPL signalling mechanism. The\nperformance of the proposed approach is evaluated through extensive simulations\nand compared with the existing work to demonstrate its effectiveness. The\nresults show that the proposed method substantially improves network\nperformance in terms of packet delivery and average delay with a marginal\nincrease in the signalling frequency.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 11:32:32 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Farag", "Hossam", ""], ["Stefanovic", "Cedomir", ""]]}, {"id": "2105.09687", "submitter": "Gaurav Kasbekar", "authors": "Akash Gupta, Gaurav S. Kasbekar", "title": "Secure, Anonymity-Preserving and Lightweight Mutual Authentication and\n  Key Agreement Protocol for Home Automation IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Home automation Internet of Things (IoT) systems have recently become a\ntarget for several types of attacks. In this paper, we present an\nauthentication and key agreement protocol for a home automation network based\non the ZigBee standard, which connects together a central controller and\nseveral end devices. Our scheme performs mutual authentication between end\ndevices and the controller, which is followed by device-to-device\ncommunication. The scheme achieves confidentiality, message integrity,\nanonymity, unlinkability, forward and backward secrecy, and availability. Our\nscheme uses only simple hash and XOR computations and symmetric key encryption,\nand hence is resource-efficient. We show using a detailed security analysis and\nnumerical results that our proposed scheme provides better security and\nanonymity, and is more efficient in terms of computation time, communication\ncost, and storage cost than schemes proposed in prior works.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 11:56:10 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 05:04:24 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Gupta", "Akash", ""], ["Kasbekar", "Gaurav S.", ""]]}, {"id": "2105.09696", "submitter": "Samuel Pagliarini", "authors": "Mateus Saquetti, Raphael M. Brum, Bruno Zatt, Samuel Pagliarini,\n  Weverton Cordeiro, Jose R. Azambuja", "title": "A Terabit Hybrid FPGA-ASIC Platform for Switch Virtualization", "comments": "ISVLSI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The roll-out of technologies like 5G and the need for multi-terabit bandwidth\nin backbone networks requires networking companies to make significant\ninvestments to keep up with growing service demands. For lower capital\nexpenditure and faster time-to-market, companies can resort to\nanything-as-a-service providers to lease virtual resources. Nevertheless,\nexisting virtualization technologies are still lagging behind next-generation\nnetworks' requirements. This paper breaks the terabit barrier by introducing a\nhybrid FPGA-ASIC architecture to virtualize programmable forwarding planes. In\ncontrast to existing solutions, our architecture involves an ASIC that\nmultiplexes network flows between programmable virtual switches running in an\nFPGA capable of full and partial reconfiguration, enabling virtual switch\nhot-swapping. Our evaluation shows the feasibility of a switch virtualization\narchitecture capable of achieving a combined throughput of 3.2 Tbps by having\nup to 26 virtual switch instances in parallel with low resource occupation\noverhead.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 12:17:49 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Saquetti", "Mateus", ""], ["Brum", "Raphael M.", ""], ["Zatt", "Bruno", ""], ["Pagliarini", "Samuel", ""], ["Cordeiro", "Weverton", ""], ["Azambuja", "Jose R.", ""]]}, {"id": "2105.10048", "submitter": "Jaafar Elmirghani", "authors": "Mohammed M. Alenazi, Barzan A. Yosuf, Sanaa H. Mohamed, Taisir E.H.\n  El-Gorashi, Jaafar M. H. Elmirghani", "title": "Energy-Efficient Distributed Machine Learning in Cloud Fog Networks", "comments": "arXiv admin note: text overlap with arXiv:2105.03221", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Massive amounts of data are expected to be generated by the billions of\nobjects that form the Internet of Things (IoT). A variety of automated services\nsuch as monitoring will largely depend on the use of different Machine Learning\n(ML) algorithms. Traditionally, ML models are processed by centralized cloud\ndata centers, where IoT readings are offloaded to the cloud via multiple\nnetworking hops in the access, metro, and core layers. This approach will\ninevitably lead to excessive networking power consumptions as well as\nQuality-of-Service (QoS) degradation such as increased latency. Instead, in\nthis paper, we propose a distributed ML approach where the processing can take\nplace in intermediary devices such as IoT nodes and fog servers in addition to\nthe cloud. We abstract the ML models into Virtual Service Requests (VSRs) to\nrepresent multiple interconnected layers of a Deep Neural Network (DNN). Using\nMixed Integer Linear Programming (MILP), we design an optimization model that\nallocates the layers of a DNN in a Cloud/Fog Network (CFN) in an energy\nefficient way. We evaluate the impact of DNN input distribution on the\nperformance of the CFN and compare the energy efficiency of this approach to\nthe baseline where all layers of DNNs are processed in the centralized Cloud\nData Center (CDC).\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 21:51:46 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Alenazi", "Mohammed M.", ""], ["Yosuf", "Barzan A.", ""], ["Mohamed", "Sanaa H.", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2105.10061", "submitter": "Hao Feng", "authors": "Hao Feng, Jaime Llorca, Antonia M. Tulino, Danny Raz, Andreas F.\n  Molisch", "title": "Approximation Algorithms for the NFV Service Distribution Problem", "comments": "This 11-page draft is a modified long version of the conference paper\n  \"Approximation Algorithms for the NFV Service Distribution Problem\" published\n  in IEEE Infocom 2017 and contains the complete proof referred by the\n  conference paper. This draft is listed as Ref. [15] in the conference paper", "journal-ref": "IEEE Conference on Computer Communications (INFOCOM), pp. 1-9,\n  2017", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed cloud networking builds on network functions virtualization (NFV)\nand software defined networking (SDN) to enable the deployment of network\nservices in the form of elastic virtual network functions (VNFs) instantiated\nover general purpose servers at distributed cloud locations. We address the\ndesign of fast approximation algorithms for the NFV service distribution\nproblem (NSDP), whose goal is to determine the placement of VNFs, the routing\nof service flows, and the associated allocation of cloud and network resources\nthat satisfy client demands with minimum cost. We show that in the case of\nload-proportional costs, the resulting fractional NSDP can be formulated as a\nmulti-commodity-chain flow problem on a cloud augmented graph, and design a\nqueue-length based algorithm, named QNSD, that provides an O(\\epsilon)\napproximation in time O(1/\\epsilon). We then address the case in which resource\ncosts are a function of the integer number of allocated resources and design a\nvariation of QNSD that effectively pushes for flow consolidation into a limited\nnumber of active resources to minimize overall cloud network cost.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 22:55:58 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Feng", "Hao", ""], ["Llorca", "Jaime", ""], ["Tulino", "Antonia M.", ""], ["Raz", "Danny", ""], ["Molisch", "Andreas F.", ""]]}, {"id": "2105.10199", "submitter": "\\'Alvaro L\\'opez-Ravent\\'os", "authors": "\\'Alvaro L\\'opez-Ravent\\'os, Boris Bellalta", "title": "IEEE 802.11be Multi-Link Operation: When the Best Could Be to Use Only a\n  Single Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The multi-link operation (MLO) is a new feature proposed to be part of the\nIEEE 802.11be Extremely High Throughput (EHT) amendment. Through MLO, access\npoints and stations will be provided with the capabilities to transmit and\nreceive data from the same traffic flow over multiple radio interfaces.\nHowever, the question on how traffic flows should be distributed over the\ndifferent interfaces to maximize the WLAN performance is still unresolved. To\nthat end, we evaluate in this article different traffic allocation policies,\nunder a wide variety of scenarios and traffic loads, in order to shed some\nlight on that question. The obtained results confirm that congestion-aware\npolicies outperform static ones. However, and more importantly, the results\nalso reveal that traffic flows become highly vulnerable to the activity of\nneighboring networks when they are distributed across multiple links. As a\nresult, the best performance is obtained when a new arriving flow is simply\nassigned entirely to the emptiest interface.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 08:16:34 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["L\u00f3pez-Ravent\u00f3s", "\u00c1lvaro", ""], ["Bellalta", "Boris", ""]]}, {"id": "2105.10242", "submitter": "Jaafar Elmirghani", "authors": "Abdullah M. Alqahtani, Barzan Yosuf, Sanaa H. Mohamed, Taisir E.H.\n  El-Gorashi, and Jaafar M.H. Elmirghani", "title": "Energy Minimized Federated Fog Computing over Passive Optical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The rapid growth of time-sensitive applications and services has driven\nenhancements to computing infrastructures. The main challenge that needs\naddressing for these applications is the optimal placement of the end-users\ndemands to reduce the total power consumption and delay. One of the widely\nadopted paradigms to address such a challenge is fog computing. Placing fog\nunits close to end-users at the edge of the network can help mitigate some of\nthe latency and energy efficiency issues. Compared to the traditional\nhyperscale cloud data centres, fog computing units are constrained by\ncomputational power, hence, the capacity of fog units plays a critical role in\nmeeting the stringent demands of the end-users due to intensive processing\nworkloads. In this paper, we aim to optimize the placement of virtual machines\n(VMs) demands originating from end-users in a fog computing setting by\nformulating a Mixed Integer Linear Programming (MILP) model to minimize the\ntotal power consumption through the use of a federated architecture made up of\nmultiple distributed fog cells. The obtained results show an increase in\nprocessing capacity in the fog layer and a reduction in the power consumption\nby up to 26% compared to the Non-Federated fogs network.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 09:55:52 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Alqahtani", "Abdullah M.", ""], ["Yosuf", "Barzan", ""], ["Mohamed", "Sanaa H.", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2105.10282", "submitter": "Mohsen Pourghasemian", "authors": "Mohsen Pourghasemian, Mohammad Reza Abedi, Shima Salarhosseini, Nader\n  Mokari, Mohammad Reza Javan, Eduard A. Jorswieck", "title": "AI-Based and Mobility-Aware Energy Efficient Resource Allocation and\n  Trajectory Design for NFV Enabled Aerial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel joint intelligent trajectory design and\nresource allocation algorithm based on user's mobility and their requested\nservices for unmanned aerial vehicles (UAVs) assisted networks, where UAVs act\nas nodes of a network function virtualization (NFV) enabled network. Our\nobjective is to maximize energy efficiency and minimize the average delay on\nall services by allocating the limited radio and NFV resources. In addition,\ndue to the traffic conditions and mobility of users, we let some Virtual\nNetwork Functions (VNFs) to migrate from their current locations to other\nlocations to satisfy the Quality of Service requirements. We formulate our\nproblem to find near-optimal locations of UAVs, transmit power, subcarrier\nassignment, placement, and scheduling the requested service's functions over\nthe UAVs and perform suitable VNF migration. Then we propose a novel\nHierarchical Hybrid Continuous and Discrete Action (HHCDA) deep reinforcement\nlearning method to solve our problem. Finally, the convergence and\ncomputational complexity of the proposed algorithm and its performance analyzed\nfor different parameters. Simulation results show that our proposed HHCDA\nmethod decreases the request reject rate and average delay by 31.5% and 20% and\nincreases the energy efficiency by 40% compared to DDPG method.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 11:13:06 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Pourghasemian", "Mohsen", ""], ["Abedi", "Mohammad Reza", ""], ["Salarhosseini", "Shima", ""], ["Mokari", "Nader", ""], ["Javan", "Mohammad Reza", ""], ["Jorswieck", "Eduard A.", ""]]}, {"id": "2105.10330", "submitter": "Lorenzo Bertizzolo", "authors": "Zhangyu Guan, Lorenzo Bertizzolo, Emrecan Demirors, Tommaso Melodia", "title": "WNOS: Enabling Principled Software-Defined Wireless Networking", "comments": "Extended journal version of arXiv:1712.08667", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates the basic design principles for a new Wireless\nNetwork Operating System (WNOS), a radically different approach to\nsoftware-defined networking (SDN) for infrastructure-less wireless networks.\nDeparting from well-understood approaches inspired by OpenFlow, WNOS provides\nthe network designer with an abstraction hiding (i) the lower-level details of\nthe wireless protocol stack and (ii) the distributed nature of the network\noperations. Based on this abstract representation, the WNOS takes network\ncontrol programs written on a centralized, high-level view of the network and\nautomatically generates distributed cross-layer control programs based on\ndistributed optimization theory that are executed by each individual node on an\nabstract representation of the radio hardware. We first discuss the main\narchitectural principles of WNOS. Then, we discuss a new approach to\nautomatically generate solution algorithms for each of the resulting\nsubproblems in an automated fashion. Finally, we illustrate a prototype\nimplementation of WNOS on software-defined radio devices and test its\neffectiveness by considering specific cross-layer control problems.\nExperimental results indicate that, based on the automatically generated\ndistributed control programs, WNOS achieves 18%, 56% and 80.4% utility gain in\nnetworks with low, medium and high levels of interference; maybe more\nimportantly, we illustrate how the global network behavior can be controlled by\nmodifying a few lines of code on a centralized abstraction.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 20:55:39 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Guan", "Zhangyu", ""], ["Bertizzolo", "Lorenzo", ""], ["Demirors", "Emrecan", ""], ["Melodia", "Tommaso", ""]]}, {"id": "2105.10355", "submitter": "Julien Gedeon", "authors": "Julien Gedeon, Martin Wagner, Karolis Skaisgiris, Florian Brandherm,\n  Max M\\\"uhlh\\\"auser", "title": "Chameleons on Cloudlets: Elastic Edge Computing Through Microservice\n  Variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Common deployment models for Edge Computing are based on (composable)\nmicroservices that are offloaded to cloudlets. Runtime adaptations-in response\nto varying load, QoS fulfillment, mobility, etc.-are typically based on\ncoarse-grained and costly management operations such as resource re-allocation\nor migration. The services themselves, however, remain non-adaptive, worsening\nthe already limited elasticity of Edge Computing compared to Cloud Computing.\nEdge computing applications often have stringent requirements on the execution\ntime but are flexible regarding the quality of a computation. The potential\nbenefits of exploiting this trade-off remain untapped. This paper introduces\nthe concept of adaptable microservices that provide alternative variants of\nspecific functionalities. We define so-called service variants that differ\nw.r.t. the internal functioning of the service, manifested in different\nalgorithms, parameters, and auxiliary data they use. Such variants allow\nfine-grained trade-offs between the QoS (e.g., a maximum tolerable execution\ntime) and the quality of the computation. We integrate adaptable microservices\ninto an Edge Computing framework, show the practical impact of service\nvariants, and present a strategy for switching variants at runtime.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 19:10:41 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Gedeon", "Julien", ""], ["Wagner", "Martin", ""], ["Skaisgiris", "Karolis", ""], ["Brandherm", "Florian", ""], ["M\u00fchlh\u00e4user", "Max", ""]]}, {"id": "2105.10413", "submitter": "Anum Masood", "authors": "Anum Masood", "title": "Survey on Energy-Efficient Techniques for Wireless Sensor Networks", "comments": "Original Article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of energy-efficient computing is not new but recently the focus\nof the industries related to technology has been shifted towards energy\nutilization techniques with minimum energy loss. Computer Networks also needed\nto be energy efficient. Energy Consumption is also an important challenge in\nthe Wireless Sensor network. Energy efficiency can be achieved with the help of\nclustering algorithms, energy-efficient routing methods, improved data\naggregation schemes, and energy-efficient MAC protocols for WSN.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 15:32:42 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Masood", "Anum", ""]]}, {"id": "2105.10499", "submitter": "Jing Dong", "authors": "Yan Chen and Jing Dong", "title": "Scheduling with Service-Time Information: The Power of Two Priority\n  Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilizing customers' service-time information, we study an easy-to-implement\nscheduling policy with two priority classes. By carefully designing the\nclasses, the two-class priority rule achieves near-optimal performance. In\nparticular, for a single-server queue, as the traffic intensity approaches 1,\nthe policy achieves a scaling for the queue length processes that is similar to\nthe shortest remaining processing time first policy. Our analysis quantifies\nhow the tail of the service time distribution affects the benefits one can gain\nfrom service-time-based scheduling policies. When the service times are\nmisspecified, we further quantify how imperfect observation of the service time\naffects the performance of the two-class priority rule through both theoretical\nand numerical analysis. Our results demonstrate the robustness of the two-class\npriority rule. Specifically, even with imperfect service-time information, the\ntwo-class priority rules can still achieve substantial performance improvement\nover the first come first served.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 19:28:48 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Chen", "Yan", ""], ["Dong", "Jing", ""]]}, {"id": "2105.10500", "submitter": "Yingjie Zhou", "authors": "Yingjie Zhou, Xucheng Song, Yanru Zhang, Fanxing Liu, Ce Zhu and\n  Lingqiao Liu", "title": "Feature Encoding with AutoEncoders for Weakly-supervised Anomaly\n  Detection", "comments": "12pages,4 figures, published by IEEE Transactions on Neural Networks\n  and Learning Systems,2021,DOI: 10.1109/TNNLS.2021.3086137", "journal-ref": "IEEE Transactions on Neural Networks and Learning\n  Systems,2021,DOI: 10.1109/TNNLS.2021.3086137", "doi": "10.1109/TNNLS.2021.3086137", "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly-supervised anomaly detection aims at learning an anomaly detector from\na limited amount of labeled data and abundant unlabeled data. Recent works\nbuild deep neural networks for anomaly detection by discriminatively mapping\nthe normal samples and abnormal samples to different regions in the feature\nspace or fitting different distributions. However, due to the limited number of\nannotated anomaly samples, directly training networks with the discriminative\nloss may not be sufficient. To overcome this issue, this paper proposes a novel\nstrategy to transform the input data into a more meaningful representation that\ncould be used for anomaly detection. Specifically, we leverage an autoencoder\nto encode the input data and utilize three factors, hidden representation,\nreconstruction residual vector, and reconstruction error, as the new\nrepresentation for the input data. This representation amounts to encode a test\nsample with its projection on the training data manifold, its direction to its\nprojection and its distance to its projection. In addition to this encoding, we\nalso propose a novel network architecture to seamlessly incorporate those three\nfactors. From our extensive experiments, the benefits of the proposed strategy\nare clearly demonstrated by its superior performance over the competitive\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 16:23:05 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 11:42:19 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 05:06:18 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Zhou", "Yingjie", ""], ["Song", "Xucheng", ""], ["Zhang", "Yanru", ""], ["Liu", "Fanxing", ""], ["Zhu", "Ce", ""], ["Liu", "Lingqiao", ""]]}, {"id": "2105.10535", "submitter": "Abhishek Kumar Singh", "authors": "Abhishek Kumar Singh, Kyle Jamieson, Davide Venturelli, Peter McMahon", "title": "Ising Machines' Dynamics and Regularization for Near-Optimal Large and\n  Massive MIMO Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal MIMO detection has been one of the most challenging and\ncomputationally inefficient tasks in wireless systems. We show that the new\nanalog computing techniques like Coherent Ising Machines (CIM) and\nOscillator-based Ising Machines (OIM) are promising candidates for performing\nnear-optimal MIMO detection. We illustrate a fundamental problem with using\nclassical, optical or quantum mechanical Ising Machines for MIMO detection: the\nerror floor problem, which is a major bottleneck to practical deployments of\nIsing machine-based MIMO detectors. We propose a novel regularized Ising\nformulation for MIMO detection that mitigates the error floor and further\nevolves it into an algorithm that achieves near-optimal MIMO detection. Massive\nMIMO systems, that have a much larger number of antennas at the Access point\n(AP) than at the users, allow linear detectors to be near-optimal. However, the\nsimplified detection in these systems comes at the cost of overall throughput,\nwhich can be improved by supporting more users. We show that our methods allow\nus to add more transmitter antennas/users and increase the overall throughput\nof the cell by several folds. We further show that our methods allow us to\noperate using more aggressive modulation and coding schemes and hence achieve\nmuch higher throughput. We demonstrate that, for a $16\\times16$ large MIMO\nsystem, our methods achieve around 2.5$\\times$ more throughput in mid-SNR\nregime ($\\approx 12 dB$) and 2$\\times$ more throughput in high-SNR regime( $>$\n20dB) than MMSE.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 18:55:15 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Singh", "Abhishek Kumar", ""], ["Jamieson", "Kyle", ""], ["Venturelli", "Davide", ""], ["McMahon", "Peter", ""]]}, {"id": "2105.10553", "submitter": "Maria Apostolaki", "authors": "Maria Apostolaki and Vamsi Addanki and Manya Ghobadi and Laurent\n  Vanbever", "title": "FB: A Flexible Buffer Management Scheme for Data Center Switches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, network devices share buffer across priority queues to avoid drops\nduring transient congestion. While cost-effective most of the time, this\nsharing can cause undesired interference among seemingly independent traffic.\nAs a result, low-priority traffic can cause increased packet loss to\nhigh-priority traffic. Similarly, long flows can prevent the buffer from\nabsorbing incoming bursts even if they do not share the same queue. The cause\nof this perhaps unintuitive outcome is that today's buffer sharing techniques\nare unable to guarantee isolation across (priority) queues without statically\nallocating buffer space. To address this issue, we designed FB, a novel buffer\nsharing scheme that offers strict isolation guarantees to high-priority traffic\nwithout sacrificing link utilizations. Thus, FB outperforms conventional buffer\nsharing algorithms in absorbing bursts while achieving on-par throughput. We\nshow that FB is practical and runs at line-rate on existing hardware (Barefoot\nTofino). Significantly, FB's operations can be approximated in non-programmable\ndevices.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 19:55:07 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Apostolaki", "Maria", ""], ["Addanki", "Vamsi", ""], ["Ghobadi", "Manya", ""], ["Vanbever", "Laurent", ""]]}, {"id": "2105.10663", "submitter": "Purva Sharma", "authors": "Purva Sharma, Vimal Bhatia, and Shashi Prakash", "title": "Securing Optical Networks using Quantum-secured Blockchain: An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of optical network infrastructure and network services is growing\nexponentially for beyond 5G networks. Since the uptake of e-commerce and\ne-services has seen unprecedented serge in recent months due to the global\nCOVID-19 pandemic era, the security of such transactions in optical\ncommunication has gained much importance. Optical fiber communication networks\nare vulnerable to several types of security threats, such as single point\nfailure, wormhole attacks, and sybil attacks. Therefore, blockchain is a\npromising solution to protect confidential information against attacks and\nhelps in achieving trusted network architecture by creating a distributed\nledger platform. Recently, blockchain has received much attention because of\nits decentralized and distributed ledger technology. Hence, blockchain has also\nbeen employed to protect network against such attacks. However, blockchain\ntechnology's security relies on the platform of computational complexity, and\nbecause of the evolution of quantum computers, it will become insecure in the\nnear future. Therefore, for enhancing blockchain security, research focus on\ncombining quantum key distribution (QKD) with blockchain. This new technology\nis known as quantum-secured blockchain. The article describes the attacks in\noptical networks and provides a solution to protect network against security\nattacks by employing quantum-secured blockchain in optical networks. It\nprovides a brief overview of blockchain technology with its security loopholes\nand focuses on QKD, which makes blockchain technology more robust against\nquantum-attacks. Next, the article provides a broad view of quantum-secured\nblockchain and presents the network architecture for future research and\ndevelopment of secure and trusted optical communication networks using\nquantum-secured blockchain.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 08:30:13 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Sharma", "Purva", ""], ["Bhatia", "Vimal", ""], ["Prakash", "Shashi", ""]]}, {"id": "2105.10666", "submitter": "Syed Waqas Haider Shah", "authors": "Syed Waqas Haider Shah, Adnan Noor Mian, Shahid Mumtaz, Miaowen Wen,\n  T. Hong, Michel Kadoch", "title": "Protocol Stack Perspective For Low Latency and Massive Connectivity in\n  Future Cellular Networks", "comments": "IEEE International Conference on Communications (ICC-2019)", "journal-ref": null, "doi": "10.1109/ICC.2019.8762083", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the emergence of Internet-of-Things (IoT) and ever-increasing demand for\nthe newly connected devices, there is a need for more effective storage and\nprocessing paradigms to cope with the data generated from these devices. In\nthis study, we have discussed different paradigms for data processing and\nstorage including Cloud, Fog, and Edge computing models and their suitability\nin integrating with the IoT. Moreover, a detailed discussion on low latency and\nmassive connectivity requirements of future cellular networks in accordance\nwith machine-type communication (MTC) is also presented. Furthermore, the need\nto bring IoT devices to Internet connectivity and a standardized protocol stack\nto regulate the data transmission between these devices is also addressed while\nkeeping in view the resource constraint nature of IoT devices.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 09:00:03 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Shah", "Syed Waqas Haider", ""], ["Mian", "Adnan Noor", ""], ["Mumtaz", "Shahid", ""], ["Wen", "Miaowen", ""], ["Hong", "T.", ""], ["Kadoch", "Michel", ""]]}, {"id": "2105.10680", "submitter": "Mark Asch", "authors": "Mark Asch, Fran\\c{c}ois Bodin, Micah Beck, Terry Moore, Michela\n  Taufer, Martin Swany and Jean-Pierre Vilotte", "title": "Cybercosm: New Foundations for a Converged Science Data Ecosystem", "comments": "Updated author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Scientific communities naturally tend to organize around data ecosystems\ncreated by the combination of their observational devices, their data\nrepositories, and the workflows essential to carry their research from\nobservation to discovery. However, these legacy data ecosystems are now\nbreaking down under the pressure of the exponential growth in the volume and\nvelocity of these workflows, which are further complicated by the need to\nintegrate the highly data intensive methods of the Artificial Intelligence\nrevolution. Enabling ground breaking science that makes full use of this new,\ndata saturated research environment will require distributed systems that\nsupport dramatically improved resource sharing, workflow portability and\ncomposability, and data ecosystem convergence.\n  The Cybercosm vision presented in this white paper describes a radically\ndifferent approach to the architecture of distributed systems for\ndata-intensive science and its application workflows. As opposed to traditional\nmodels that restrict interoperability by hiving off storage, networking, and\ncomputing resources in separate technology silos, Cybercosm defines a minimally\nsufficient hypervisor as a spanning layer for its data plane that virtualizes\nand converges the local resources of the system's nodes in a fully\ninteroperable manner. By building on a common, universal interface into which\nthe problems that infect today's data-intensive workflows can be decomposed and\nattacked, Cybercosm aims to support scalable, portable and composable workflows\nthat span and merge the distributed data ecosystems that characterize leading\nedge research communities today.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 10:24:01 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 14:59:14 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 06:20:34 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Asch", "Mark", ""], ["Bodin", "Fran\u00e7ois", ""], ["Beck", "Micah", ""], ["Moore", "Terry", ""], ["Taufer", "Michela", ""], ["Swany", "Martin", ""], ["Vilotte", "Jean-Pierre", ""]]}, {"id": "2105.10715", "submitter": "Chittaranjan Swain", "authors": "Chittaranjan Swain, Manmath Narayan Sahoo, Anurag Satpathy", "title": "SPATO: A Student Project Allocation Based Task Offloading in IoT-Fog\n  Systems", "comments": "6 pages, 5 figures, accepted for publication in IEEE International\n  Conference on Communications (ICC)-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Things (IoT) devices are highly reliant on cloud systems to\nmeet their storage and computational demands. However, due to the remote\nlocation of cloud servers, IoT devices often suffer from intermittent Wide Area\nNetwork (WAN) latency which makes execution of delay-critical IoT applications\ninconceivable. To overcome this, service providers (SPs) often deploy multiple\nfog nodes (FNs) at the network edge that helps in executing offloaded\ncomputations from IoT devices with improved user experience. As the FNs have\nlimited resources, matching IoT services to FNs while ensuring minimum latency\nand energy from an end-user's perspective and maximizing revenue and tasks\nmeeting deadlines from an SP's standpoint is challenging. Therefore in this\npaper, we propose a student project allocation (SPA) based efficient task\noffloading strategy called SPATO that takes into account key parameters from\ndifferent stakeholders. Thorough simulation analysis shows that SPATO is able\nto reduce the offloading energy and latency respectively by 29% and 40% and\nimproves the revenue by 25% with 99.3% of tasks executing within their\ndeadline.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 12:42:50 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Swain", "Chittaranjan", ""], ["Sahoo", "Manmath Narayan", ""], ["Satpathy", "Anurag", ""]]}, {"id": "2105.10729", "submitter": "Jaafar Elmirghani", "authors": "Abdelrahman S. Elgamal, Osama Z. Alsulami, Ahmad Adnan Qidan, Taisir\n  E.H. El-Gorashi and Jaafar M. H. Elmirghani", "title": "Q-learning algorithm for resource allocation in WDMA-based optical\n  wireless communication networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Visible Light Communication (VLC) has been widely investigated during the\nlast decade due to its ability to provide high data rates with low power\nconsumption. In general, resource management is an important issue in cellular\nnetworks that can highly effect their performance. In this paper, an\noptimisation problem is formulated to assign each user to an optimal access\npoint and a wavelength at a given time. This problem can be solved using mixed\ninteger linear programming (MILP). However, using MILP is not considered a\npractical solution due to its complexity and memory requirements. In addition,\naccurate information must be provided to perform the resource allocation.\nTherefore, the optimisation problem is reformulated using reinforcement\nlearning (RL), which has recently received tremendous interest due to its\nability to interact with any environment without prior knowledge. In this\npaper, we investigate solving the resource allocation optimisation problem in\nVLC systems using the basic Q-learning algorithm. Two scenarios are simulated\nto compare the results with the previously proposed MILP model. The results\ndemonstrate the ability of the Q-learning algorithm to provide optimal\nsolutions close to the MILP model without prior knowledge of the system.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 13:37:54 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Elgamal", "Abdelrahman S.", ""], ["Alsulami", "Osama Z.", ""], ["Qidan", "Ahmad Adnan", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2105.10755", "submitter": "Sai Teja Suggala", "authors": "Sai Teja Suggala, Siddhartha Pothukuchi and Naimat Ali Khan", "title": "SDN assisted UAV communication systems : Efficient Deployment Strategies", "comments": "7 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, Unmanned Aerial Vehicle (UAV) based communications systems have\nattracted increasing research and commercial interest due to their cost\neffective deployment and ease of mobility.During natural disasters and\nemergencies, such networks are extremely useful to provide communication\nservice. In such scenarios, UAVs position and trajectory must be optimal to\nmaintain Quality of Service at the user end. This paper focuses on the\ndeployment of an SDN-based UAV network providing communication service to the\nusers. We consider the deployment of the system in stadiums and events. In this\npaper, we propose a scheme to allocate UAVs to the users and a traffic\ncongestion algorithm to reduce the number of packets dropped to avoid\nre-transmissions from the user end. We also propose an energy efficient multi\nhop routing mechanism to avoid the high power requirement to transmit longer\ndistances. We assume that all the back-haul links have sufficient capacities to\ncarry all the traffic from the front-haul links and the design of UAVs must\nconsider their power requirements for both flight and transmission.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 16:10:54 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 18:52:59 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 08:20:16 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Suggala", "Sai Teja", ""], ["Pothukuchi", "Siddhartha", ""], ["Khan", "Naimat Ali", ""]]}, {"id": "2105.10852", "submitter": "Mouhamed Abdulla Ph.D.", "authors": "Alvin Ramoutar and Zohreh Motamedi and Mouhamed Abdulla", "title": "Latency of Concatenating Unlicensed LPWAN with Cellular IoT: An\n  Experimental QoE Study", "comments": "Experimental dataset is openly available here:\n  https://dx.doi.org/10.21227/zzax-g919", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AR cs.IT cs.PF math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developing low-power wide-area network (LPWAN) solutions that are efficient\nto adopt, deploy and maintain are vital for smart cities. The poor\nquality-of-service of unlicensed LPWAN, and the high service cost of\nLTE-M/NB-IoT are key disadvantages of these technologies. Concatenating\nunlicensed with licensed LPWANs can overcome these limitations and harness\ntheir benefits. However, a concatenated LPWAN architecture will inevitably\nresult in excess latency which may impact users' quality-of-experience (QoE).\nTo evaluate the real-life feasibility of this system, we first propose a\nconcatenated LPWAN architecture and experimentally measure the statistics of\nend-to-end (E2E) latencies. The concatenated delay margin is determined by\nbenchmarking the latencies with different LPWAN architecture schemes, namely\nwith unlicensed IoT (standalone LoRa), cellular IoT (standalone LTE-M), and\nconcatenated IoT (LoRa interfaced with LTE-M). Through extensive experimental\nmeasurement campaigns of 30,000 data points of E2E latencies, we show that the\nexcess delay due to LPWAN interfacing introduces on average less than 300\nmilliseconds. The proof-of-concept results suggest that the latency for\nconcatenating unlicensed LPWAN with cellular IoT is negligible for smart city\nuse cases where human perception and decision making is in the loop.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 03:53:37 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 19:06:41 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ramoutar", "Alvin", ""], ["Motamedi", "Zohreh", ""], ["Abdulla", "Mouhamed", ""]]}, {"id": "2105.11099", "submitter": "Huanding Zhang", "authors": "Huanding Zhang, Tao Shen, Fei Wu, Mingyang Yin, Hongxia Yang, Chao Wu", "title": "Federated Graph Learning -- A Position Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) have been successful in many fields, and derived\nvarious researches and applications in real industries. However, in some\nprivacy sensitive scenarios (like finance, healthcare), training a GNN model\ncentrally faces challenges due to the distributed data silos. Federated\nlearning (FL) is a an emerging technique that can collaboratively train a\nshared model while keeping the data decentralized, which is a rational solution\nfor distributed GNN training. We term it as federated graph learning (FGL).\nAlthough FGL has received increasing attention recently, the definition and\nchallenges of FGL is still up in the air. In this position paper, we present a\ncategorization to clarify it. Considering how graph data are distributed among\nclients, we propose four types of FGL: inter-graph FL, intra-graph FL and\ngraph-structured FL, where intra-graph is further divided into horizontal and\nvertical FGL. For each type of FGL, we make a detailed discussion about the\nformulation and applications, and propose some potential challenges.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 05:39:24 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zhang", "Huanding", ""], ["Shen", "Tao", ""], ["Wu", "Fei", ""], ["Yin", "Mingyang", ""], ["Yang", "Hongxia", ""], ["Wu", "Chao", ""]]}, {"id": "2105.11166", "submitter": "Mikolaj Jankowski", "authors": "Mikolaj Jankowski, Deniz Gunduz, Krystian Mikolajczyk", "title": "AirNet: Neural Network Transmission over the Air", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art performance for many emerging edge applications is achieved\nby deep neural networks (DNNs). Often, these DNNs are location and time\nsensitive, and the parameters of a specific DNN must be delivered from an edge\nserver to the edge device rapidly and efficiently to carry out time-sensitive\ninference tasks. We introduce AirNet, a novel training and analog transmission\nmethod that allows efficient wireless delivery of DNNs. We first train the DNN\nwith noise injection to counter the wireless channel noise. We also employ\npruning to reduce the channel bandwidth necessary for transmission, and perform\nknowledge distillation from a larger model to achieve satisfactory performance,\ndespite the channel perturbations. We show that AirNet achieves significantly\nhigher test accuracy compared to digital alternatives under the same bandwidth\nand power constraints. It also exhibits graceful degradation with channel\nquality, which reduces the requirement for accurate channel estimation.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 09:16:04 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 15:44:49 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Jankowski", "Mikolaj", ""], ["Gunduz", "Deniz", ""], ["Mikolajczyk", "Krystian", ""]]}, {"id": "2105.11213", "submitter": "Avi Mohan", "authors": "Avinash Mohan, Arpan Chattopadhyay, Shivam Vinayak Vatsa, and Anurag\n  Kumar", "title": "Decentralized, Hybrid MAC Design with Reduced State Information Exchange\n  for Low-Delay IoT Applications", "comments": "56 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a system of several collocated nodes sharing a time slotted\nwireless channel, and seek a MAC that (i) provides low mean delay, (ii) has\ndistributed control (i.e., there is no central scheduler), and (iii) does not\nrequire explicit exchange of state information or control signals. The design\nof such MAC protocols must keep in mind the need for contention access at light\ntraffic, and scheduled access in heavy traffic, leading to the long-standing\ninterest in hybrid, adaptive MACs.\n  We first propose EZMAC, a simple extension of an existing decentralized,\nhybrid MAC called ZMAC. Next, motivated by our results on delay and throughput\noptimality in partially observed, constrained queuing networks, we develop\nanother decentralized MAC protocol that we term QZMAC. A method to improve the\nshort-term fairness of QZMAC is proposed and analysed, and the resulting\nmodified algorithm is shown to possess better fairness properties than QZMAC.\nThe theory developed to reduce delay is also shown to work %with different\ntraffic types (batch arrivals, for example) and even in the presence of\ntransmission errors and fast fading.\n  Extensions to handle time critical traffic (alarms, for example) and hidden\nnodes are also discussed. Practical implementation issues, such as handling\nClear Channel Assessment (CCA) errors, are outlined. We implement and\ndemonstrate the performance of QZMAC on a test bed consisting of CC2420 based\nCrossbow telosB motes, running the 6TiSCH communication stack on the Contiki\noperating system over the 2.4GHz ISM band.\n  Finally, using simulations, we show that both protocols achieve mean delays\nmuch lower than those achieved by ZMAC, and QZMAC provides mean delays very\nclose to the minimum achievable in this setting, i.e., that of the centralized\ncomplete knowledge scheduler.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 11:44:08 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Mohan", "Avinash", ""], ["Chattopadhyay", "Arpan", ""], ["Vatsa", "Shivam Vinayak", ""], ["Kumar", "Anurag", ""]]}, {"id": "2105.11332", "submitter": "Jue Wang", "authors": "Jue Wang, Xuanxuan Wang, Ruifeng Gao, Chengleyang Lei, Wei Feng, Ning\n  Ge, Shi Jin, and Tony Q. S. Quek", "title": "Physical Layer Security for UAV Communications in 5G and Beyond Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its high mobility and flexible deployment, unmanned aerial vehicle\n(UAV) is drawing unprecedented interest in both military and civil applications\nto enable agile wireless communications and provide ubiquitous connectivity.\nMainly operating in an open environment, UAV communications can benefit from\ndominant line-of-sight links; however, it on the other hand renders the UAVs\nmore vulnerable to malicious eavesdropping or jamming attacks. Recently,\nphysical layer security (PLS), which exploits the inherent randomness of the\nwireless channels for secure communications, has been introduced to UAV systems\nas an important complement to the conventional cryptography-based approaches.\nIn this paper, a comprehensive survey on the current achievements of the\nUAV-aided wireless communications is conducted from the PLS perspective. We\nfirst introduce the basic concepts of UAV communications including the typical\nstatic/mobile deployment scenarios, the unique characteristics of air-to-ground\nchannels, as well as various roles that a UAV may act when PLS is concerned.\nThen, we introduce the widely used secrecy performance metrics and start by\nreviewing the secrecy performance analysis and enhancing techniques for\nstatically deployed UAV systems, and extend the discussion to a more general\nscenario where the UAVs' mobility is further exploited. For both cases,\nrespectively, we summarize the commonly adopted methodologies in the\ncorresponding analysis and design, then describe important works in the\nliterature in detail. Finally, potential research directions and challenges are\ndiscussed to provide an outlook for future works in the area of UAV-PLS in 5G\nand beyond networks.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 15:13:09 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Wang", "Jue", ""], ["Wang", "Xuanxuan", ""], ["Gao", "Ruifeng", ""], ["Lei", "Chengleyang", ""], ["Feng", "Wei", ""], ["Ge", "Ning", ""], ["Jin", "Shi", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2105.11491", "submitter": "Jou-Ming Chang", "authors": "Xiao-Yan Li, Wanling Lin, Jou-Ming Chang, Xiaohua Jia", "title": "Transmission Failure Analysis of Multi-Protection Routing in Data Center\n  Networks with Heterogeneous Edge-Core Servers", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed RCube network is a cube-based server-centric data\ncenter network (DCN), including two types of heterogeneous servers, called core\nand edge servers. Remarkably, it takes the latter as backup servers to deal\nwith server failures and thus achieve high availability. This paper first\npoints out that RCube is suitable as a candidate topology of DCNs for edge\ncomputing. Three transmission types are among core and edge servers based on\nthe demand for applications' computation and instant response. We then employ\nprotection routing to analyze the transmission failure of RCube DCNs. Unlike\ntraditional protection routing, which only tolerates a single link or node\nfailure, we use the multi-protection routing scheme to improve fault-tolerance\ncapability. To configure a protection routing in a network, according to\nTapolcai's suggestion, we need to construct two completely independent spanning\ntrees (CISTs). A logic graph of RCube, denoted by $L$-$RCube(n,m,k)$, is a\nnetwork with a recursive structure. Each basic building element consists of $n$\ncore servers and $m$ edge servers, where the order $k$ is the number of\nrecursions applied in the structure. In this paper, we provide algorithms to\nconstruct $\\min\\{n,\\lfloor(n+m)/2\\rfloor\\}$ CISTs in $L$-$RCube(n,m,k)$ for\n$n+m\\geqslant 4$ and $n>1$. From a combination of the multiple CISTs, we can\nconfigure the desired multi-protection routing. In our simulation, we configure\nup to 10 protection routings for RCube DCNs. As far as we know, in past\nresearch, there were at most three protection routings developed in other\nnetwork structures. Finally, we summarize some crucial analysis viewpoints\nabout the transmission efficiency of DCNs with heterogeneous edge-core servers\nfrom the simulation results.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 18:34:01 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Li", "Xiao-Yan", ""], ["Lin", "Wanling", ""], ["Chang", "Jou-Ming", ""], ["Jia", "Xiaohua", ""]]}, {"id": "2105.11493", "submitter": "Rafael Teixeira", "authors": "Rafael R. Teixeira, Juliana B. Puccinelli, Luis Poersch, Marcelo R.\n  Pias, Vin\\'icius M. Oliveira, Ahmed Janati, Maxime Paris", "title": "Towards Precision Aquaculture: A High Performance, Cost-effective IoT\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Demand for ocean-based high-quality and sustainable fish protein soared in\nthe last decade. Unlike precision agriculture, aquaculture remains an\nunder-equipped farming activity. To fully realise a vision of \\textit{precision\naquaculture}, smart IoT can offer the essential tools to local producers\nworldwide. This paper addresses the question of whether it is feasible to\ndeploy a water quality sensor network in aquaculture for real-time user\nvisualisation and decision making. The proposed system design and its\nimplementation have been validated in a typical aquaculture farming facility.\nPreliminary results suggest the approach is feasible for short to medium LoRa\ncommunication range (up to 110m from outdoor water tanks). Although sensor data\nloss occurred, the end-to-end data path from the water sensors up to the user's\nmonitoring app has been a positive outcome. The proposed IoT system approach\nprovides the ground for a sustainable precision aquaculture\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 18:38:04 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Teixeira", "Rafael R.", ""], ["Puccinelli", "Juliana B.", ""], ["Poersch", "Luis", ""], ["Pias", "Marcelo R.", ""], ["Oliveira", "Vin\u00edcius M.", ""], ["Janati", "Ahmed", ""], ["Paris", "Maxime", ""]]}, {"id": "2105.11620", "submitter": "Yanjun Wang", "authors": "Yanjun Wang, Zixuan Li, Xiaokang Qiu, Sanjay G. Rao", "title": "Comparative Synthesis: Learning Optimal Programs with Indeterminate\n  Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative program synthesis aims to generate a program that satisfies not\nonly boolean specifications but also quantitative objectives. Nonetheless,\nobtaining precise quantitative objectives per se can be a challenging task. In\nthis paper, we propose comparative synthesis, a bootstrapping quantitative\nsynthesis framework in which an indeterminate objective and a satisfying\nprogram are synthesized in tandem. The key idea is to make comparative queries\nto learn the user's preference over candidate programs, with which objectives\ncan be conjectured. These objectives, which are indeterminate as they can be\nrefined along the course of user interaction, guide the search of satisfying\nprograms.\n  Within the comparative synthesis framework, we developed two novel\ncomparative synthesis procedures (CLPs) with the aim of minimizing the number\nof queries to the user. We prove that both CLPs converge and use them in two\ncase studies: generating bandwidth allocations for network design and solving\nSyGuS benchmarks with syntactic objectives. Experiments show that our framework\ncan successfully synthesize satisfying/optimal solutions by making queries\nonly, without a priori knowledge about the quantitative objective.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 02:36:13 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Wang", "Yanjun", ""], ["Li", "Zixuan", ""], ["Qiu", "Xiaokang", ""], ["Rao", "Sanjay G.", ""]]}, {"id": "2105.11701", "submitter": "Yingjue Chen", "authors": "Yingjue Chen, Yingnan Gu, Panfeng Li and Feng Lin", "title": "Minimizing the Number of Wireless Charging PAD for UAV-Based Wireless\n  Rechargeable Sensor Networks", "comments": "9 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In wireless rechargeable sensor networks (WRSNs), most of researches address\nenergy scarcity by introducing one or multiple ground mobile vehicles to\nrecharge energy-hungry sensor nodes. The charging efficiency is limited by the\nmoving speed of ground chargers and rough environments, especially in\nlarge-scale scenarios or challenging scenarios such as separate islands. To\naddress the limitations, some researchers consider replacing ground mobile\nchargers with lightweight unmanned aerial vehicles (UAVs) to support extremely\nlarge-scale scenarios, because of the UAV moving at higher speed without\ngeographical limitation. Moreover, multiple automatic landing wireless charging\nPADs are deployed in the network to recharge UAVs automatically. In this work,\nwe investigate the problem of introducing the minimal number of PADs in\nUAV-based WRSNs. We propose a novel and adaptive PAD deployment scheme named\nCDC & DSC that can adapt to arbitrary locations of the base station, arbitrary\ngeographic distributions of sensor nodes, and arbitrary sizes of network areas.\nIn the proposed scheme, we first obtain an initial PAD deployment solution by\nclustering nodes in geographic locations. Then, we propose a center shift\ncombining algorithm to optimize this solution by shifting the location of PADs\nand attempting to merge the adjacent PADs. The simulation results show that\ncompared to existing algorithms, our proposed scheme can use fewer PADs to\ncharge the whole network.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 06:50:18 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Chen", "Yingjue", ""], ["Gu", "Yingnan", ""], ["Li", "Panfeng", ""], ["Lin", "Feng", ""]]}, {"id": "2105.11727", "submitter": "Bin Han", "authors": "Bin Han, Yihua Xu, Di Feng, Vincenzo Sciancalepore, Hans D. Schotten", "title": "Risk-Based Tenant Impatience for Privacy-Intolerant Queuing in B5G Cloud\n  Services", "comments": "Working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by emerging tolerance-critical use cases of future communication\nnetworks, the demand on cloud computing service providers for their reliable\nand timely service delivery is to dramatically increase in the upcoming era.\nAdvanced techniques to resolve the congestion of task queues are therefore\ncalled for. In this study we propose to rely on the impatient behavior of cloud\nservice tenants towards a distributed risk-based queue management, which\nenables a profitability-sensitive task dropping while protecting the tenants'\ndata privacy. Regarding the service provider's data privacy, we propose a\ndynamic online learning scheme, which allows the tenant to learn the queue\ndynamics from an adaptive number of observations on its own position in queue,\nso as to make a rational decision of impatient behavior.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 07:49:25 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Han", "Bin", ""], ["Xu", "Yihua", ""], ["Feng", "Di", ""], ["Sciancalepore", "Vincenzo", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2105.11738", "submitter": "Gwendal Simon", "authors": "Massimo Gallo, Alessandro Finamore, Gwendal Simon, and Dario Rossi", "title": "FENXI: Deep-learning Traffic Analytics at the Edge", "comments": "14 pages, 12 figures. Accepted for publication at the Sixth ACM/IEEE\n  Symposium on Edge Computing (SEC'21), December 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Live traffic analysis at the first aggregation point in the ISP network\nenables the implementation of complex traffic engineering policies but is\nlimited by the scarce processing capabilities, especially for Deep Learning\n(DL) based analytics. The introduction of specialized hardware accelerators\ni.e., Tensor Processing Unit (TPU), offers the opportunity to enhance the\nprocessing capabilities of network devices at the edge. Yet, to date, no packet\nprocessing pipeline is capable of offering DL-based analysis capabilities in\nthe data-plane, without interfering with network operations.\n  In this paper, we present FENXI, a system to run complex analytics by\nleveraging TPU. The design of FENXI decouples forwarding operations and traffic\nanalytics which operates at different granularities i.e., packet and flow\nlevels. We conceive two independent modules that asynchronously communicate to\nexchange network data and analytics results, and design data structures to\nextract flow level statistics without impacting per-packet processing. We\nprototyped and evaluated FENXI on general-purpose servers considering both\nadversarial and realistic network conditions. Our analysis shows that FENXI can\nsustain 100 Gbps line rate traffic processing requiring only limited resources,\nwhile also dynamically adapting to variable network conditions.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 08:02:44 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Gallo", "Massimo", ""], ["Finamore", "Alessandro", ""], ["Simon", "Gwendal", ""], ["Rossi", "Dario", ""]]}, {"id": "2105.11755", "submitter": "Eugenio Moro", "authors": "Eugenio Moro, Ilario Filippini, Antonio Capone, Danilo De Donno", "title": "Planning Mm-Wave Access Networks With Reconfigurable Intelligent\n  Surfaces", "comments": null, "journal-ref": "IEEE International Symposium on Personal, Indoor and Mobile Radio\n  Communications (PIMRC) 2021", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the capability to support gigabit data rates, millimetre-wave (mm-Wave)\ncommunication is unanimously considered a key technology of future cellular\nnetworks. However, the harsh propagation at such high frequencies makes these\nnetworks quite susceptible to failures due to obstacle blockages. Recently\nintroduced Reconfigurable Intelligent Surfaces (RISs) can enhance the coverage\nof mm-Wave communications by improving the received signal power and offering\nan alternative radio path when the direct link is interrupted. While several\nworks have addressed this possibility from a communication standpoint, none of\nthese has yet investigated the impact of RISs on large-scale mm-Wave networks.\nAiming to fill this literature gap, we propose a new mathematical formulation\nof the coverage planning problem that includes RISs. Using well-established\nplanning methods, we have developed a new optimization model where RISs can be\ninstalled alongside base stations to assist the communications, creating what\nwe have defined as Smart Radio Connections. Our simulation campaigns show that\nRISs effectively increase both throughput and coverage of access networks,\nwhile further numerical results highlight additional benefits that the\nsimplified scenarios analyzed by previous works could not reveal.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 08:48:32 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 14:03:15 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Moro", "Eugenio", ""], ["Filippini", "Ilario", ""], ["Capone", "Antonio", ""], ["De Donno", "Danilo", ""]]}, {"id": "2105.11793", "submitter": "Jakob Struye", "authors": "Jakob Struye, Filip Lemic and Jeroen Famaey", "title": "Millimeter-Wave Beamforming with Continuous Coverage for Mobile\n  Interactive Virtual Reality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary Virtual Reality (VR) setups commonly consist of a Head-Mounted\nDisplay (HMD) tethered to a content-generating server. \"Cutting the wire\" in\nsuch setups and going truly wireless will require a wireless network capable of\ndelivering enormous amounts of video data at an extremely low latency. Higher\nfrequencies, such as the millimeter-wave (mmWave) band, can support these\nrequirements. Due to high attenuation and path loss in the mmWave frequencies,\nbeamforming is essential. For VR setups, beamforming must adapt in real-time to\nthe user's head rotations, but can rely on the HMD's built-in sensors providing\naccurate orientation estimates. In this work, we present coVRage, a beamforming\nsolution tailored for VR HMDs. Based on past and current head orientations, the\nHMD predicts how the Angle of Arrival (AoA) from the access point will change\nin the near future, and covers this AoA trajectory with a dynamically shaped\nbeam, synthesized using sub-arrays. We show that this solution can cover such\ntrajectories with consistently high gain, unlike regular single-beam solutions.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 09:50:48 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Struye", "Jakob", ""], ["Lemic", "Filip", ""], ["Famaey", "Jeroen", ""]]}, {"id": "2105.11865", "submitter": "Mattia Lecci", "authors": "Matteo Drago, Tommy Azzino, Mattia Lecci, Andrea Zanella, Michele\n  Zorzi", "title": "A Simulation Framework for Contention-Free Scheduling on WiGig", "comments": "6 pages, 3 figures, 1 table. This paper has been submitted to IEEE\n  GLOBECOM 2021. Copyright may change without notice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest IEEE 802.11 amendments provide support to directional\ncommunications in the Millimeter Wave spectrum and, thanks to the wide\nbandwidth available at such frequencies, makes it possible to wirelessly\napproach several emergent use cases, such as virtual and augmented reality,\ntelepresence, and remote control of industrial facilities. However, these\napplications require stringent Quality of Service, that only contention-free\nscheduling algorithms can guarantee. In this paper, we propose an end-to-end\nframework for the joint admission control and scheduling of periodic traffic\nstreams over mmWave Wireless Local Area Networks based on Network Simulator 3,\na popular full-stack open-source network simulator. Moreover, we design a\nbaseline algorithm to handle scheduling requests, and we evaluate its\nperformance with a full-stack perspective. The algorithm is tested in three\nscenarios, where we investigated different configurations and features to\nhighlight the differences and trade-offs between contention-based and\ncontention-free access strategies.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 12:08:49 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Drago", "Matteo", ""], ["Azzino", "Tommy", ""], ["Lecci", "Mattia", ""], ["Zanella", "Andrea", ""], ["Zorzi", "Michele", ""]]}, {"id": "2105.11868", "submitter": "Ivan Iudice Ph.D.", "authors": "Donatella Darsena, Giacinto Gelli, Ivan Iudice, Francesco Verde", "title": "Detection and blind channel estimation for UAV-aided wireless sensor\n  networks in smart cities under mobile jamming attack", "comments": "16 pages, 7 figures, 4 tables, submitted to IEEE Internet of Things\n  Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist several ways of integrating unmanned aerial vehicles (UAVs) into\nwireless sensor networks (WSNs) for smart city applications. Among the others,\na UAV can be employed as a relay in a \"store-carry and forward\" fashion by\nuploading data from ground sensors and meters and, then, downloading it to a\ncentral unit. However, both the uploading and downloading phases can be prone\nto potential threats and attacks. As a legacy from traditional wireless\nnetworks, the jamming attack is still one of the major and serious threats to\nUAV-aided communications, especially when the jammer is mobile, too, e.g., it\nis mounted on an UAV or inside a terrestrial vehicle. In this paper, we\ninvestigate anti-jamming communications in UAV-aided WSNs operating over\ndoubly-selective channels. In such a scenario, the signals transmitted by the\nlegitimate transmitters (sensors and meters in the uploading phase or the UAV\nin the downloading phase) and the malicious mobile jammer undergo both time\ndispersion due to multipath propagation effects and frequency dispersion caused\nby Doppler shifts. To suppress the jamming signal, we propose a blind\nphysical-layer technique that jointly exploits amplitudes, phases, time delays,\nand Doppler shifts differences between the two superimposed signals. Such\nparameters are estimated from data through the use of algorithms exploiting the\nalmost-cyclostationarity properties of the received signal. Simulation results\ncorroborate the antijamming capabilities of the proposed method, for different\nmobility scenario of the jammer.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 12:12:46 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Darsena", "Donatella", ""], ["Gelli", "Giacinto", ""], ["Iudice", "Ivan", ""], ["Verde", "Francesco", ""]]}, {"id": "2105.11931", "submitter": "Guy Amir", "authors": "Guy Amir, Michael Schapira and Guy Katz", "title": "Towards Scalable Verification of RL-Driven Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have gained significant popularity in recent\nyears, becoming the state of the art in a variety of domains. In particular,\ndeep reinforcement learning (DRL) has recently been employed to train DNNs that\nact as control policies for various types of real-world systems. In this work,\nwe present the whiRL 2.0 tool, which implements a new approach for verifying\ncomplex properties of interest for such DRL systems. To demonstrate the\nbenefits of whiRL 2.0, we apply it to case studies from the communication\nnetworks domain that have recently been used to motivate formal verification of\nDRL systems, and which exhibit characteristics that are conducive for scalable\nverification. We propose techniques for performing k-induction and automated\ninvariant inference on such systems, and use these techniques for proving\nsafety and liveness properties of interest that were previously impossible to\nverify due to the scalability barriers of prior approaches. Furthermore, we\nshow how our proposed techniques provide insights into the inner workings and\nthe generalizability of DRL systems. whiRL 2.0 is publicly available online.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 13:34:40 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Amir", "Guy", ""], ["Schapira", "Michael", ""], ["Katz", "Guy", ""]]}, {"id": "2105.11999", "submitter": "Arjun Balasingam", "authors": "Arjun Balasingam, Karthik Gopalakrishnan, Radhika Mittal, Venkat Arun,\n  Ahmed Saeed, Mohammad Alizadeh, Hamsa Balakrishnan, Hari Balakrishnan", "title": "Throughput-Fairness Tradeoffs in Mobility Platforms", "comments": "Technical report for paper to appear at ACM MobiSys 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA cs.NI cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper studies the problem of allocating tasks from different customers\nto vehicles in mobility platforms, which are used for applications like food\nand package delivery, ridesharing, and mobile sensing. A mobility platform\nshould allocate tasks to vehicles and schedule them in order to optimize both\nthroughput and fairness across customers. However, existing approaches to\nscheduling tasks in mobility platforms ignore fairness.\n  We introduce Mobius, a system that uses guided optimization to achieve both\nhigh throughput and fairness across customers. Mobius supports spatiotemporally\ndiverse and dynamic customer demands. It provides a principled method to\nnavigate inherent tradeoffs between fairness and throughput caused by shared\nmobility. Our evaluation demonstrates these properties, along with the\nversatility and scalability of Mobius, using traces gathered from ridesharing\nand aerial sensing applications. Our ridesharing case study shows that Mobius\ncan schedule more than 16,000 tasks across 40 customers and 200 vehicles in an\nonline manner.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 15:04:04 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Balasingam", "Arjun", ""], ["Gopalakrishnan", "Karthik", ""], ["Mittal", "Radhika", ""], ["Arun", "Venkat", ""], ["Saeed", "Ahmed", ""], ["Alizadeh", "Mohammad", ""], ["Balakrishnan", "Hamsa", ""], ["Balakrishnan", "Hari", ""]]}, {"id": "2105.12084", "submitter": "Jaafar Elmirghani", "authors": "Khulood Alazwary, Ahmad Adnan Qidan, Taisir El-Gorashi and Jaafar M.\n  H. Elmirghani", "title": "Rate Splitting in VCSEL-based Optical Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Optical wireless communication is an effective potential solution for\nenabling high speed next generation cellular networks. In this paper, laser\nsources, in particular, vertical-cavity surface-emitting (VCSEL) lasers are\nused for data transmission due to their high modulation speed compared with\nlight emitting diode (LED) sources. To manage multi-user interference, rate\nsplitting (RS) is implemented where the message of a user is split into common\nand private parts. However, the performance of RS is limited in high density\nnetworks. Therefore, hierarchical rate splitting (HRS) particularly suited in\nhigh density networks is considered. The results demonstrate the high data rate\nachieved by using VCSELs. Moreover, HRS is more suitable for achieving high\nperformance in optical networks compared with RS.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 17:05:53 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Alazwary", "Khulood", ""], ["Qidan", "Ahmad Adnan", ""], ["El-Gorashi", "Taisir", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2105.12096", "submitter": "Nelly Elsayed", "authors": "Nelly Elsayed, Zaghloul Saad Zaghloul, Sylvia Worlali Azumah,\n  Chengcheng Li", "title": "Intrusion Detection System in Smart Home Network Using Bidirectional\n  LSTM and Convolutional Neural Networks Hybrid Model", "comments": "4 pages, 6 figures, Accepted in the MWSCAS 2021. This material is\n  based upon work supported by the National Science Foundation under Grant No.\n  (CNS-1801593). Any opinions, findings, and conclusions or recommendations\n  expressed in this material are those of the author(s) and do not necessarily\n  reflect the views of the National Science Foundation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) allowed smart homes to improve the quality and the\ncomfort of our daily lives. However, these conveniences introduced several\nsecurity concerns that increase rapidly. IoT devices, smart home hubs, and\ngateway raise various security risks. The smart home gateways act as a\ncentralized point of communication between the IoT devices, which can create a\nbackdoor into network data for hackers. One of the common and effective ways to\ndetect such attacks is intrusion detection in the network traffic. In this\npaper, we proposed an intrusion detection system (IDS) to detect anomalies in a\nsmart home network using a bidirectional long short-term memory (BiLSTM) and\nconvolutional neural network (CNN) hybrid model. The BiLSTM recurrent behavior\nprovides the intrusion detection model to preserve the learned information\nthrough time, and the CNN extracts perfectly the data features. The proposed\nmodel can be applied to any smart home network gateway.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 17:32:03 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 01:44:52 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Elsayed", "Nelly", ""], ["Zaghloul", "Zaghloul Saad", ""], ["Azumah", "Sylvia Worlali", ""], ["Li", "Chengcheng", ""]]}, {"id": "2105.12527", "submitter": "Jorge Mart\\'in-P\\'erez", "authors": "Jorge Mart\\'in-P\\'erez, Koteswararao Kondepu, Danny De Vleeschauwer,\n  Venkatarami Reddy, Carlos Guimar\\~aes, Andrea Sgambelluri, Luca Valcarenghi,\n  Chrysa Papagianni, Carlos J. Bernardos", "title": "Dimensioning of V2X Services in 5G Networks through Forecast-based\n  Scaling", "comments": "10 pages, 7 figures, pre-print, arXiv:1406.6768", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing adoption of intelligent transportation systems and the\nupcoming era of autonomous vehicles, vehicular services (such as, remote\ndriving, cooperative awareness, and hazard warning) will face an ever changing\nand dynamic environment. Traffic flows on the roads is a critical condition for\nthese services and, therefore, it is of paramount importance to forecast how\nthey will evolve over time. By knowing future events (such as, traffic jams),\nvehicular services can be dimensioned in an on-demand fashion in order to\nminimize Service Level Agreements (SLAs) violations, thus reducing the chances\nof car accidents. This research departs from an evaluation of traditional\ntime-series techniques with recent Machine Learning (ML)-based solutions to\nforecast traffic flows in the roads of Torino (Italy). Given the accuracy of\nthe selected forecasting techniques, a forecast-based scaling algorithm is\nproposed and evaluated over a set of dimensioning experiments of three distinct\nvehicular services with strict latency requirements. Results show that the\nproposed scaling algorithm enables resource savings of up to a 5% at the cost\nof incurring in an increase of less than 0.4% of latency violations.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 13:04:05 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Mart\u00edn-P\u00e9rez", "Jorge", ""], ["Kondepu", "Koteswararao", ""], ["De Vleeschauwer", "Danny", ""], ["Reddy", "Venkatarami", ""], ["Guimar\u00e3es", "Carlos", ""], ["Sgambelluri", "Andrea", ""], ["Valcarenghi", "Luca", ""], ["Papagianni", "Chrysa", ""], ["Bernardos", "Carlos J.", ""]]}, {"id": "2105.12663", "submitter": "Maciej Besta", "authors": "Maciej Besta, Marcel Schneider, Salvatore Di Girolamo, Ankit Singla,\n  Torsten Hoefler", "title": "Towards Million-Server Network Simulations on Just a Laptop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing size of data center and HPC networks pose unprecedented\nrequirements on the scalability of simulation infrastructure. The ability to\nsimulate such large-scale interconnects on a simple PC would facilitate\nresearch efforts. Unfortunately, as we first show in this work, existing\nshared-memory packet-level simulators do not scale to the sizes of the largest\nnetworks considered today. We then illustrate a feasibility analysis and a set\nof enhancements that enable a simple packet-level htsim simulator to scale to\nthe unprecedented simulation sizes on a single PC. Our code is available online\nand can be used to design novel schemes in the coming era of omnipresent data\ncenters and HPC clusters.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 16:21:33 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Besta", "Maciej", ""], ["Schneider", "Marcel", ""], ["Di Girolamo", "Salvatore", ""], ["Singla", "Ankit", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2105.12714", "submitter": "Biswa P. S. Sahoo", "authors": "Biswa PS Sahoo, Deepak Puthal, Saraju P. Mohanty, and Prashant Pillai", "title": "Personal Internet of Things (PIoT): What is it Exactly?", "comments": "This article has been accepted for publication in a future issue of\n  IEEE Consumer Electronics Magazine", "journal-ref": null, "doi": "10.1109/MCE.2021.3077721", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Internet of Things (IoT) devices in homes and the immediate\nproximity of an individual communicates to create Personal IoT (PIoT) networks.\nThe exploratory study of PIoT is in its infancy, which will explore the\nexpansion of new use cases, service requirements, and the proliferation of PIoT\ndevices. This article provides a big picture of PIoT architecture, vision, and\nfuture research scope.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 17:03:30 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Sahoo", "Biswa PS", ""], ["Puthal", "Deepak", ""], ["Mohanty", "Saraju P.", ""], ["Pillai", "Prashant", ""]]}, {"id": "2105.12823", "submitter": "Alireza Shamsoshoara", "authors": "Alireza Shamsoshoara, Fatemeh Afghah, Erik Blasch, Jonathan Ashdown,\n  Mehdi Bennis", "title": "UAV-Assisted Communication in Remote Disaster Areas using Imitation\n  Learning", "comments": "15 pages, 14 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The damage to cellular towers during natural and man-made disasters can\ndisturb the communication services for cellular users. One solution to the\nproblem is using unmanned aerial vehicles to augment the desired communication\nnetwork. The paper demonstrates the design of a UAV-Assisted Imitation Learning\n(UnVAIL) communication system that relays the cellular users' information to a\nneighbor base station. Since the user equipment (UEs) are equipped with buffers\nwith limited capacity to hold packets, UnVAIL alternates between different UEs\nto reduce the chance of buffer overflow, positions itself optimally close to\nthe selected UE to reduce service time, and uncovers a network pathway by\nacting as a relay node. UnVAIL utilizes Imitation Learning (IL) as a\ndata-driven behavioral cloning approach to accomplish an optimal scheduling\nsolution. Results demonstrate that UnVAIL performs similar to a human expert\nknowledge-based planning in communication timeliness, position accuracy, and\nenergy consumption with an accuracy of 97.52% when evaluated on a developed\nsimulator to train the UAV.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 00:26:44 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Shamsoshoara", "Alireza", ""], ["Afghah", "Fatemeh", ""], ["Blasch", "Erik", ""], ["Ashdown", "Jonathan", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2105.12826", "submitter": "Babak Mafakheri Dr", "authors": "Babak Mafakheri, Pierpaolo Gonnella, Alessandro Bazzi, Barbara Mavi\n  Masini, Michele Caggiano, Roberto Verdone", "title": "Optimizations for Hardware-in-the-Loop-Based V2X Validation Platforms", "comments": "The 2021 IEEE 93rd Vehicular Technology Conference: VTC2021-Spring", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectivity and automation are increasingly getting importance in the\nautomotive industry, which is observing a radical change from vehicles driven\nby humans to fully automated and remotely controlled ones. The test and\nvalidation of all the related devices and applications is thus becoming a\ncrucial aspect; this is raising the interest on hardware-in-the-loop (HiL)\nplatforms which reduce the need for complicated field trials, thus limiting the\ncosts and delay added to the process. With reference to the test and validation\nof vehicle-to-everything (V2X) communications aspects, and assuming either\nsidelink LTE/5GV2X or IEEE 802.11p/bd technologies, in this work we focus on\nthe real-time HiL simulation of the information exchanged by one vehicle under\ntest and the surrounding, simulated, objects. Such exchange must be reproduced\nin a time-efficient manner, with elaborations done fast enough to allow testing\nthe applications in real-time. More precisely, we discuss the simulation of\nnonideal positioning and channel propagation taking into account current\nimpairments. We also provide details on optimization solutions that allowed us\nto trade-off minor loss in accuracy with a significant reduction of the\ncomputation time burden, reaching up to more than one order of magnitude speed\nincrease in our experiments.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 10:49:45 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Mafakheri", "Babak", ""], ["Gonnella", "Pierpaolo", ""], ["Bazzi", "Alessandro", ""], ["Masini", "Barbara Mavi", ""], ["Caggiano", "Michele", ""], ["Verdone", "Roberto", ""]]}, {"id": "2105.12827", "submitter": "Evgeny Bobrov", "authors": "Evgeny Bobrov (1, 2), Dmitry Kropotov (2, 3), Hao Lu (1), Danila Zaev\n  (1) ((1) Moscow Research Center, Huawei Technologies, Russia, (2) M. V.\n  Lomonosov Moscow State University, Russia, (3) National Research University\n  Higher School of Economics, Russia)", "title": "Massive MIMO Adaptive Modulation and Coding Using Online Deep Learning", "comments": "The paper has been submitted to the IEEE WCL journal and has 4 pages\n  and 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper describes an online deep learning algorithm for the adaptive\nmodulation and coding in 5G Massive MIMO. The algorithm is based on a fully\nconnected neural network, which is initially trained on the output of the\ntraditional algorithm and then is incrementally retrained by the service\nfeedback of its output. We show the advantage of our solution over the\nstate-of-the-art Q-Learning approach. We provide system-level simulation\nresults to support this conclusion in various scenarios with different channel\ncharacteristics and different user speeds. Compared with traditional OLLA our\nalgorithm shows 10% to 20% improvement of user throughput in full buffer case.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 06:02:24 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 07:40:32 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 01:47:09 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bobrov", "Evgeny", ""], ["Kropotov", "Dmitry", ""], ["Lu", "Hao", ""], ["Zaev", "Danila", ""]]}, {"id": "2105.12834", "submitter": "Mohammed Hirzallah", "authors": "Mohammed Hirzallah, Marwan Krunz", "title": "Sense-Bandits: AI-based Adaptation of Sensing Thresholds for\n  Heterogeneous-technology Coexistence Over Unlicensed Bands", "comments": "ICCCN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we present Sense-Bandits, an AI-based framework for\ndistributed adaptation of the sensing thresholds (STs) over shared spectrum.\nThis framework specifically targets the coexistence of heterogenous\ntechnologies, e.g., Wi-Fi, 4G Licensed-Assisted Access (LAA), and 5G New Radio\nUnlicensed (NR-U), over unlicensed channels. To access the channel, a device\ncompares the measured power with a predefined ST value and accordingly decides\nif the channel is idle or not. Improper setting of the ST values creates\nasymmetric sensing floors, resulting in collisions due to hidden terminals\nand/or reduction in the spatial reuse due to exposed terminals. Optimal ST\nsetting is challenging because it requires global knowledge of mobility,\ntraffic loads, and channel access behavior of all contending devices. Sense-\nBandits tackles this problem by employing a clustering-based multi-armed bandit\n(MAB) algorithm, which adapts its learning behavior based on network dynamics.\nClustering allows the algorithm to track network changes in real-time, ensuring\nfast learning of the best ST values by classifying the state and dynamics of\ncoexisting networks. We develop a C++-based network simulator that implements\nSense-Bandits and we apply it to evaluate the coexistence of Wi-Fi and 5G NR-U\nsystems over the unlicensed 5 GHz U NII bands. Our simulation results indicate\nthat ST-adaptive devices employing Sense-Bandits do not harm neighboring\ndevices that adopt a fixed ST value.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 08:23:50 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Hirzallah", "Mohammed", ""], ["Krunz", "Marwan", ""]]}, {"id": "2105.12835", "submitter": "Kumar Umesh Pentakota Mr", "authors": "Subhash Bhagavan Kommina, Kiran Kumar Pulamoluy, Kumar Umesh\n  Pentakota, S Sravya", "title": "A Review on Applications and Challenges in Internet of Things", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  World has been introduced with a new way of living by inventing this advanced\ntechnology Internet of Things (IOT). By using this technology all the\nreal-world objects can be made to interconnect and communicate with each other\nwhich can be done by diagnosing, sensing and networking over the internet to\nfulfill some objectives. Due to advancements that have taken place in sensors,\nwireless communication systems and cloud computing has brought steps to invent\nthis innovative technology. This paper deals with the elements, applications\nand the challenges faced by Internet of Things. This paper mainly concentrates\non the current scenario of IoT\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 02:30:37 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Kommina", "Subhash Bhagavan", ""], ["Pulamoluy", "Kiran Kumar", ""], ["Pentakota", "Kumar Umesh", ""], ["Sravya", "S", ""]]}, {"id": "2105.12871", "submitter": "Ekram Hossain", "authors": "Carlos A. Astudillo, Ekram Hossain, and Nelson L. S. da Fonseca", "title": "Random Access Based on Maximum Average Distance Code for Massive MTC in\n  Cellular IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Code-expanded Random Access (CeRA) is a promising technique for supporting\nmMTC in cellular IoT networks.\n  However, its potentiality is limited by code ambiguity, which results from\nthe inference of a larger number of codewords than those actually transmitted.\n  In this letter, we propose a random access scheme to alleviate this problem\nby allowing devices to select the preambles to be transmitted considering a\nq-ary code with maximum average distance.\n  Moreover, a CeRA decoding approach based on hypergraphs is proposed and an\nanalytical model is derived.\n  Numerical results show that the proposed scheme significantly increases the\nprobability of successful channel access as well as resource utilization.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 22:57:20 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Astudillo", "Carlos A.", ""], ["Hossain", "Ekram", ""], ["da Fonseca", "Nelson L. S.", ""]]}, {"id": "2105.13147", "submitter": "Alexander Marin\\v{s}ek", "authors": "Alexander Marin\\v{s}ek and Liesbet Van der Perre", "title": "Keeping up with the bits: tracking physical layer latency in\n  millimeter-wave Wi-Fi networks", "comments": "This work has been accepted to the 41st WIC Symposium On Information\n  Theory and Signal Processing in the Benelux (SITB 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The wireless communications landscape is anticipated to offer new service\nlevels following the introduction of the millimeter-wave (mmWave) spectrum to\nconsumer electronics. With their broad bandwidths and corresponding multi-Gbps\ndata rates, these mmWaves are a perfect fit for data hungry applications, such\nas streaming video to extended reality devices. However, the latter are also\nbound by maximal latency constraints as low as 1 ms. Understanding where such\nminuscule time delays lurk requires a close-up study of individual layers in\nthe network stack. Starting from the bottom up, the present work describes an\nendeavor at uncloaking the origins of physical layer (PHY) latency in mmWave\nWi-Fi networks. It proposes a newly designed simulation framework and sheds\nlight on how any conventional laboratory can be turned into a virtual\nexperiment setting, speeding up computation. A case study based on the IEEE\n802.11ad standard demonstrates the framework's ability to track packet latency\nat the PHY-level and identify individual bottlenecks. In particular, it\nevaluates the impact of the number of LDPC decoding iterations on latency in\nshort transmission sequences.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 13:50:10 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Marin\u0161ek", "Alexander", ""], ["Van der Perre", "Liesbet", ""]]}, {"id": "2105.13172", "submitter": "Ami Paz", "authors": "Monika Henzinger, Ami Paz, Stefan Schmid", "title": "On the Complexity of Weight-Dynamic Network Algorithms", "comments": "To appear in IFIP Networking 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While operating communication networks adaptively may improve utilization and\nperformance, frequent adjustments also introduce an algorithmic challenge: the\nre-optimization of traffic engineering solutions is time-consuming and may\nlimit the granularity at which a network can be adjusted. This paper is\nmotivated by question whether the reactivity of a network can be improved by\nre-optimizing solutions dynamically rather than from scratch, especially if\ninputs such as link weights do not change significantly. This paper explores to\nwhat extent dynamic algorithms can be used to speed up fundamental tasks in\nnetwork operations. We specifically investigate optimizations related to\ntraffic engineering (namely shortest paths and maximum flow computations), but\nalso consider spanning tree and matching applications. While prior work on\ndynamic graph algorithms focuses on link insertions and deletions, we are\ninterested in the practical problem of link weight changes. We revisit existing\nupper bounds in the weight-dynamic model, and present several novel lower\nbounds on the amortized runtime for recomputing solutions. In general, we find\nthat the potential performance gains depend on the application, and there are\nalso strict limitations on what can be achieved, even if link weights change\nonly slightly.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 14:29:27 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Henzinger", "Monika", ""], ["Paz", "Ami", ""], ["Schmid", "Stefan", ""]]}, {"id": "2105.13194", "submitter": "Ami Paz", "authors": "Seth Gilbert, Uri Meir, Ami Paz, Gregory Schwartzman", "title": "On the Complexity of Load Balancing in Dynamic Networks", "comments": "To be presented in SPAA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the load balancing problem, each node in a network is assigned a load, and\nthe goal is to equally distribute the loads among the nodes, by preforming\nlocal load exchanges. While load balancing was extensively studied in static\nnetworks, only recently a load balancing algorithm for dynamic networks with a\nbounded convergence time was presented. In this paper, we further study the\ntime complexity of load balancing in the context of dynamic networks.\n  First, we show that randomness is not necessary, and present a deterministic\nalgorithm which slightly improves the running time of the previous algorithm,\nat the price of not being matching-based. Then, we consider integral loads,\ni.e., loads that cannot be split indefinitely, and prove that no matching-based\nalgorithm can have a bounded convergence time for this case.\n  To circumvent both this impossibility result, and a known one for the\nnon-integral case, we apply the method of smoothed analysis, where random\nperturbations are made over the worst-case choices of network topologies. We\nshow both impossibility results do not hold under this kind of analysis,\nsuggesting that load-balancing in real world systems might be faster than the\nlower bounds suggest.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 14:42:56 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Gilbert", "Seth", ""], ["Meir", "Uri", ""], ["Paz", "Ami", ""], ["Schwartzman", "Gregory", ""]]}, {"id": "2105.13289", "submitter": "Li Yang", "authors": "Li Yang, Abdallah Moubayed, Abdallah Shami", "title": "MTH-IDS: A Multi-Tiered Hybrid Intrusion Detection System for Internet\n  of Vehicles", "comments": "Accepted and to appear in IEEE Internet of Things Journal; Code is\n  available at Github link:\n  https://github.com/Western-OC2-Lab/Intrusion-Detection-System-Using-Machine-Learning", "journal-ref": null, "doi": "10.1109/JIOT.2021.3084796", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicles, including connected vehicles and autonomous vehicles,\nnowadays involve many electronic control units connected through intra-vehicle\nnetworks to implement various functionalities and perform actions. Modern\nvehicles are also connected to external networks through vehicle-to-everything\ntechnologies, enabling their communications with other vehicles,\ninfrastructures, and smart devices. However, the improving functionality and\nconnectivity of modern vehicles also increase their vulnerabilities to\ncyber-attacks targeting both intra-vehicle and external networks due to the\nlarge attack surfaces. To secure vehicular networks, many researchers have\nfocused on developing intrusion detection systems (IDSs) that capitalize on\nmachine learning methods to detect malicious cyber-attacks. In this paper, the\nvulnerabilities of intra-vehicle and external networks are discussed, and a\nmulti-tiered hybrid IDS that incorporates a signature-based IDS and an\nanomaly-based IDS is proposed to detect both known and unknown attacks on\nvehicular networks. Experimental results illustrate that the proposed system\ncan detect various types of known attacks with 99.99% accuracy on the\nCAN-intrusion-dataset representing the intra-vehicle network data and 99.88%\naccuracy on the CICIDS2017 dataset illustrating the external vehicular network\ndata. For the zero-day attack detection, the proposed system achieves high\nF1-scores of 0.963 and 0.800 on the above two datasets, respectively. The\naverage processing time of each data packet on a vehicle-level machine is less\nthan 0.6 ms, which shows the feasibility of implementing the proposed system in\nreal-time vehicle systems. This emphasizes the effectiveness and efficiency of\nthe proposed IDS.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 17:36:35 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Yang", "Li", ""], ["Moubayed", "Abdallah", ""], ["Shami", "Abdallah", ""]]}, {"id": "2105.13383", "submitter": "Vishrant Tripathi", "authors": "Vishrant Tripathi, Eytan Modiano", "title": "An Online Learning Approach to Optimizing Time-Varying Costs of AoI", "comments": "Accepted to ACM Mobihoc '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider systems that require timely monitoring of sources over a\ncommunication network, where the cost of delayed information is unknown,\ntime-varying and possibly adversarial. For the single source monitoring\nproblem, we design algorithms that achieve sublinear regret compared to the\nbest fixed policy in hindsight. For the multiple source scheduling problem, we\ndesign a new online learning algorithm called\nFollow-the-Perturbed-Whittle-Leader and show that it has low regret compared to\nthe best fixed scheduling policy in hindsight, while remaining computationally\nfeasible. The algorithm and its regret analysis are novel and of independent\ninterest to the study of online restless multi-armed bandit problems. We\nfurther design algorithms that achieve sublinear regret compared to the best\ndynamic policy when the environment is slowly varying. Finally, we apply our\nalgorithms to a mobility tracking problem. We consider non-stationary and\nadversarial mobility models and illustrate the performance benefit of using our\nonline learning algorithms compared to an oblivious scheduling policy.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 18:10:56 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Tripathi", "Vishrant", ""], ["Modiano", "Eytan", ""]]}, {"id": "2105.13389", "submitter": "James Saxon", "authors": "James Saxon, Nick Feamster", "title": "GPS-Based Geolocation of Consumer IP Addresses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper uses two commercial datasets of IP addresses from smartphones,\ngeolocated through the Global Positioning System (GPS), to characterize the\ngeography of IP address subnets from mobile and broadband ISPs. Datasets that\nge olocate IP addresses based on GPS offer superlative accuracy and precision\nfor IP geolocation and thus provide an unprecedented opportunity to understand\nboth the accuracy of existing geolocation databases as well as other properties\nof IP addresses, such as mobility and churn. We focus our analysis on large\ncities in the United States.\n  After evaluating the accuracy of existing geolocation databases, we analyze\nthe circumstances under which IP geolocation databases may be more or less\naccurate. We find that geolocation databases are more accurate on fixed-line\nthan mobile networks, that IP addresses on university networks can be more\naccurately located than those from consumer or business networks, and that\noften the paid versions of these databases are not significantly more accurate\nthan the free versions. We then characterize how quickly subnets associated\nwith fixed-line networks change geographic locations, and how long residential\nbroadband ISP subscribers retain individual IP addresses. We find, generally,\nthat most IP address assignments are stable over two months, although stability\ndoes vary across ISPs. Finally, we evaluate the suitability of existing IP\ngeolocation databases for understanding Internet access and performance in\nhuman populations within specific geographies and demographics. Although the\nmedian accuracy of IP geolocation is better than 3 km in some contexts, we\nconclude that relying on IP geolocation databases to understand Internet access\nin densely populated regions such as cities is premature.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 18:38:44 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Saxon", "James", ""], ["Feamster", "Nick", ""]]}, {"id": "2105.13424", "submitter": "Christina Delimitrou", "authors": "Yanqi Zhang, Weizhe Hua, Zhuangzhuang Zhou, Edward Suh, Christina\n  Delimitrou", "title": "Sinan: Data-Driven, QoS-Aware Cluster Management for Microservices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloud applications are increasingly shifting from large monolithic services,\nto large numbers of loosely-coupled, specialized microservices. Despite their\nadvantages in terms of facilitating development, deployment, modularity, and\nisolation, microservices complicate resource management, as dependencies\nbetween them introduce backpressure effects and cascading QoS violations.\n  We present Sinan, a data-driven cluster manager for interactive cloud\nmicroservices that is online and QoS-aware. Sinan leverages a set of scalable\nand validated machine learning models to determine the performance impact of\ndependencies between microservices, and allocate appropriate resources per tier\nin a way that preserves the end-to-end tail latency target. We evaluate Sinan\nboth on dedicated local clusters and large-scale deployments on Google Compute\nEngine (GCE) across representative end-to-end applications built with\nmicroservices, such as social networks and hotel reservation sites. We show\nthat Sinan always meets QoS, while also maintaining cluster utilization high,\nin contrast to prior work which leads to unpredictable performance or\nsacrifices resource efficiency. Furthermore, the techniques in Sinan are\nexplainable, meaning that cloud operators can yield insights from the ML models\non how to better deploy and design their applications to reduce unpredictable\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 19:57:51 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Zhang", "Yanqi", ""], ["Hua", "Weizhe", ""], ["Zhou", "Zhuangzhuang", ""], ["Suh", "Edward", ""], ["Delimitrou", "Christina", ""]]}, {"id": "2105.13478", "submitter": "Kyle MacMillan", "authors": "Kyle MacMillan, Tarun Mangla, James Saxon, Nick Feamster", "title": "Measuring the Performance and Network Utilization of Popular Video\n  Conferencing Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Video conferencing applications (VCAs) have become a critical Internet\napplication, even more so during the COVID-19 pandemic, as users worldwide now\nrely on them for work, school, and telehealth. It is thus increasingly\nimportant to understand the resource requirements of different VCAs and how\nthey perform under different network conditions, including: how much speed\n(upstream and downstream throughput) a VCA needs to support high quality of\nexperience; how VCAs perform under temporary reductions in available capacity;\nhow they compete with themselves, with each other, and with other applications;\nand how usage modality (e.g., number of participants) affects utilization. We\nstudy three modern VCAs: Zoom, Google Meet, and Microsoft Teams. Answers to\nthese questions differ substantially depending on VCA. First, the average\nutilization on an unconstrained link varies between 0.8 Mbps and 1.9 Mbps.\nGiven temporary reduction of capacity, some VCAs can take as long as 50 seconds\nto recover to steady state. Differences in proprietary congestion control\nalgorithms also result in unfair bandwidth allocations: in constrained\nbandwidth settings, one Zoom video conference can consume more than 75% of the\navailable bandwidth when competing with another VCA (e.g., Meet, Teams). For\nsome VCAs, client utilization can decrease as the number of participants\nincreases, due to the reduced video resolution of each participant's video\nstream given a larger number of participants. Finally, one participant's\nviewing mode (e.g., pinning a speaker) can affect the upstream utilization of\nother participants.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 22:21:57 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["MacMillan", "Kyle", ""], ["Mangla", "Tarun", ""], ["Saxon", "James", ""], ["Feamster", "Nick", ""]]}, {"id": "2105.13500", "submitter": "Jan Janak", "authors": "Jan Janak, Teresa Tseng, Aliza Isaacs, Henning Schulzrinne", "title": "An Analysis of Amazon Echo's Network Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With over 20 million units sold since 2015, Amazon Echo, the Alexa-enabled\nsmart speaker developed by Amazon, is probably one of the most widely deployed\nInternet of Things consumer devices. Despite the very large installed base,\nsurprisingly little is known about the device's network behavior. We modify a\nfirst generation Echo device, decrypt its communication with Amazon cloud, and\nanalyze the device pairing, Alexa Voice Service, and drop-in calling protocols.\nWe also describe our methodology and the experimental setup. We find a minor\nshortcoming in the device pairing protocol and learn that drop-in calls are\nend-to-end encrypted and based on modern open standards. Overall, we find the\nEcho to be a well-designed device from the network communication perspective.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 23:26:18 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Janak", "Jan", ""], ["Tseng", "Teresa", ""], ["Isaacs", "Aliza", ""], ["Schulzrinne", "Henning", ""]]}, {"id": "2105.13503", "submitter": "Pangun Park", "authors": "Pangun Park, Piergiuseppe Di Marco, Carlo Fischione", "title": "Wireless for Control: Over-the-Air Controller", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NI cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In closed-loop wireless control systems, the state-of-the-art approach\nprescribes that a controller receives by wireless communications the individual\nsensor measurements, and then sends the computed control signal to the\nactuators. We propose an over-the-air controller scheme where all sensors\nattached to the plant simultaneously transmit scaled sensing signals directly\nto the actuator; then the feedback control signal is computed partially over\nthe air and partially by a scaling operation at the actuator. Such over-the-air\ncontroller essentially adopts the over-the-air computation concept to compute\nthe control signal for closed-loop wireless control systems. In contrast to the\nstate-of-the-art sensor-to-controller and controller-to-actuator communication\napproach, the over-the-air controller exploits the superposition properties of\nmultiple-access wireless channels to complete the communication and computation\nof a large number of sensing signals in a single communication resource unit.\nTherefore, the proposed scheme can obtain significant benefits in terms of low\nactuation delay and low wireless resource utilization by a simple network\narchitecture that does not require a dedicated controller. Numerical results\nshow that our proposed over-the-air controller achieves a huge widening of the\nstability region in terms of sampling time and delay, and a significant\nreduction of the computation error of the control signal.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 23:36:07 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Park", "Pangun", ""], ["Di Marco", "Piergiuseppe", ""], ["Fischione", "Carlo", ""]]}, {"id": "2105.13592", "submitter": "Asm Rizvi", "authors": "ASM Rizvi and John Heidemann", "title": "Chhoyhopper: A Moving Target Defense with IPv6", "comments": "3 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Services on the public Internet are frequently scanned, then subject to\nbrute-force and denial-of-service attacks. We would like to run such services\nstealthily, available to friends but hidden from adversaries. In this work, we\npropose a moving target defense named \"Chhoyhopper\" that utilizes the vast IPv6\naddress space to conceal publicly available services. The client and server to\nhop to different IPv6 addresses in a pattern based on a shared, pre-distributed\nsecret and the time-of-day. By hopping over a /64 prefix, services cannot be\nfound by active scanners, and passively observed information is useless after\ntwo minutes. We demonstrate our system with SSH, and show that it can be\nextended to other applications.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 05:18:49 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Rizvi", "ASM", ""], ["Heidemann", "John", ""]]}, {"id": "2105.13600", "submitter": "Jiangbin Lyu Dr.", "authors": "Bifeng Ling, Jiangbin Lyu and Liqun Fu", "title": "Placement Optimization and Power Control in Intelligent Reflecting\n  Surface Aided Multiuser System", "comments": "2-col, 7 pages. This paper focuses on the multi-IRS placement\n  optimization and downlink AP power control for achieving max-min throughput\n  in a single-cell multi-user system. A ring-based IRS placement scheme is\n  proposed which utilizes the near-AP/near-user deployment modes. Closed-form\n  power control policy is devised to equalize the users' non-outage probability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent reflecting surface (IRS) is a new and revolutionary technology\ncapable of reconfiguring the wireless propagation environment by controlling\nits massive low-cost passive reflecting elements. Different from prior works\nthat focus on optimizing IRS reflection coefficients or single-IRS placement,\nwe aim to maximize the minimum throughput of a single-cell multiuser system\naided by multiple IRSs, by joint multi-IRS placement and power control at the\naccess point (AP), which is a mixed-integer non-convex problem with drastically\nincreased complexity with the number of IRSs/users. To tackle this challenge, a\nring-based IRS placement scheme is proposed along with a power control policy\nthat equalizes the users' non-outage probability. An efficient searching\nalgorithm is further proposed to obtain a close-to-optimal solution for\narbitrary number of IRSs/rings. Numerical results validate our analysis and\nshow that our proposed scheme significantly outperforms the benchmark schemes\nwithout IRS and/or with other power control policies. Moreover, it is shown\nthat the IRSs are preferably deployed near AP for coverage range extension,\nwhile with more IRSs, they tend to spread out over the cell to cover more and\nget closer to target users.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 06:03:30 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Ling", "Bifeng", ""], ["Lyu", "Jiangbin", ""], ["Fu", "Liqun", ""]]}, {"id": "2105.13603", "submitter": "Junfeng Li", "authors": "Junfeng Li, Dan Li, Yukai Huang, Yang Cheng, Ruilin Ling", "title": "High Performance and Scalable NAT System on Commodity Platforms", "comments": "in Chinese language", "journal-ref": null, "doi": "10.13190/j.jbupt.2020-133", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quick network address translation (NAT) is proposed to improve the network\nperformance of the NAT system on the commodity server by three ways. First, the\nquick NAT search algorithm is designed to use the Hash search instead of the\nsequential search to reduce latency when looking up the NAT rule table. Second,\nto leverage the power of the multi-core central processing unit (CPU) and the\nmulti-queue network interface card, Quick NAT enables multiple CPU cores to\nprocess in parallel. The localized connection tracking table and the\ncompare-and-swap based lock-free NAT Hash tables are designed to eliminate the\nlock overhead. Third, Quick NAT uses the polling and zero-copy delivery to\nreduce the cost of interrupt and packet copies. The evaluation results show\nthat Quick NAT obtains high scalability and line-rate throughput on the\ncommodity server.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 06:10:41 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Li", "Junfeng", ""], ["Li", "Dan", ""], ["Huang", "Yukai", ""], ["Cheng", "Yang", ""], ["Ling", "Ruilin", ""]]}, {"id": "2105.13964", "submitter": "Nelly Elsayed", "authors": "Olivia Haring, Sylvia Worlali Azumah, Nelly Elsayed", "title": "A Review of Network Evolution Towards a Smart Connected World", "comments": "This material is based upon work supported by the National Science\n  Foundation under Grant No. (CNS-1801593). Any opinions, findings, and\n  conclusions or recommendations expressed in this material are those of the\n  author(s) and do not necessarily reflect the views of the National Science\n  Foundation", "journal-ref": "Volume 183- Number 5, 2021", "doi": "10.5120/ijca2021921311", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid innovations in technology, wireless internet-connected devices\nare more ubiquitous than ever and can be found in virtually every aspect of\nboth our personal and professional lives. In this paper, we propose a\ncomprehensive literature review that focuses on various network components that\ncreate connectivity among different devices, specifically Wireless Sensor\nNetworks (WSNs), Radio-Frequency Identification (RFID) tags, Internet of Things\n(IoT) devices, and how these devices helped usher in the 4th Industrial\nRevolution, or Industry 4.0. This paper focuses on the protocols, architecture,\nuses, security concerns, and solutions used in these network technologies, as\nwell as their differences and similarities.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 16:43:11 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Haring", "Olivia", ""], ["Azumah", "Sylvia Worlali", ""], ["Elsayed", "Nelly", ""]]}, {"id": "2105.14088", "submitter": "Liang Luo", "authors": "Liang Luo, Jacob Nelson, Arvind Krishnamurthy, Luis Ceze", "title": "Cloud Collectives: Towards Cloud-aware Collectives forML Workloads with\n  Rank Reordering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ML workloads are becoming increasingly popular in the cloud. Good cloud\ntraining performance is contingent on efficient parameter exchange among VMs.\nWe find that Collectives, the widely used distributed communication algorithms,\ncannot perform optimally out of the box due to the hierarchical topology of\ndatacenter networks and multi-tenancy nature of the cloudenvironment.In this\npaper, we present Cloud Collectives , a prototype that accelerates collectives\nby reordering theranks of participating VMs such that the communication pattern\ndictated by the selected collectives operation best exploits the locality in\nthe network.Collectives is non-intrusive, requires no code changes nor rebuild\nof an existing application, and runs without support from cloud providers. Our\npreliminary application of Cloud Collectives on allreduce operations in public\nclouds results in a speedup of up to 3.7x in multiple microbenchmarks and 1.3x\nin real-world workloads of distributed training of deep neural networks and\ngradient boosted decision trees using state-of-the-art frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 20:14:38 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Luo", "Liang", ""], ["Nelson", "Jacob", ""], ["Krishnamurthy", "Arvind", ""], ["Ceze", "Luis", ""]]}, {"id": "2105.14143", "submitter": "Alexander Stolyar", "authors": "Alexander Stolyar", "title": "Parallel server systems with cancel-on-completion redundancy", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a parallel server system with so-called cancel-on-completion\nredundancy. There are $n$ servers and multiple job classes $j$. An arriving\nclass $j$ job consists of $d_j$ components, placed on a randomly selected\nsubset of servers; the job service is complete as soon as $k_j$ components out\nof $d_j$ complete their service, at which point the service of all remaining\n$d_j-k_j$ components is canceled. The system is in general non-work-conserving\n-- the average amount of new workload added to the system by an arriving class\n$j$ job depends on the system state. This poses the main challenge for the\nsystem analysis.\n  The results of this paper concern both the system with fixed number of\nservers $n$ and the mean-field asymptotic regime when $n\\to\\infty$ while each\njob class arrival rate per server remains constant. The main question we\naddress for the asymptotic regime is whether the steady-state asymptotic\nindependence of server workloads holds. We prove that this property does hold\nunder certain conditions, including the important special case when job\ncomponents of each class $j$ are i.i.d. with an increasing-hazard-rate\ndistribution.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 23:26:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Stolyar", "Alexander", ""]]}, {"id": "2105.14157", "submitter": "Tevfik Kosar", "authors": "Bing Zhang and Tevfik Kosar", "title": "SMURF: Efficient and Scalable Metadata Access for Distributed\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In parallel with big data processing and analysis dominating the usage of\ndistributed and cloud infrastructures, the demand for distributed metadata\naccess and transfer has increased. In many application domains, the volume of\ndata generated exceeds petabytes, while the corresponding metadata amounts to\nterabytes or even more. This paper proposes a novel solution for efficient and\nscalable metadata access for distributed applications across wide-area\nnetworks, dubbed SMURF. Our solution combines novel pipelining and concurrent\ntransfer mechanisms with reliability, provides distributed continuum caching\nand prefetching strategies to sidestep fetching latency, and achieves scalable\nand high-performance metadata fetch/prefetch services in the cloud. We also\nstudy the phenomenon of semantic locality in real trace logs, which is not well\nutilized in metadata access prediction. We implement a novel prefetch predictor\nbased on this observation and compare it with three existing state-of-the-art\nprefetch schemes on Yahoo! Hadoop audit traces. By effectively caching and\nprefetching metadata based on the access patterns, our continuum caching and\nprefetching mechanism significantly improves local cache hit rate and reduces\nthe average fetching latency. We replayed approximately 20 Million metadata\naccess operations from real audit traces, in which our system achieved 90%\naccuracy during prefetch prediction and reduced the average fetch latency by\n50% compared to the state-of-the-art mechanisms.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 00:27:27 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Bing", ""], ["Kosar", "Tevfik", ""]]}, {"id": "2105.14219", "submitter": "Francesc Wilhelmi", "authors": "Francesc Wilhelmi, David G\\'oez, Paola Soto, Ramon Vall\\'es, Mohammad\n  Alfaifi, Abdulrahman Algunayah, Jorge Martin-P\\'erez, Luigi Girletti,\n  Rajasekar Mohan, K Venkat Ramnan, Boris Bellalta", "title": "Machine Learning for Performance Prediction of Channel Bonding in\n  Next-Generation IEEE 802.11 WLANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of Artificial Intelligence (AI)-empowered communications,\nindustry, academia, and standardization organizations are progressing on the\ndefinition of mechanisms and procedures to address the increasing complexity of\nfuture 5G and beyond communications. In this context, the International\nTelecommunication Union (ITU) organized the first AI for 5G Challenge to bring\nindustry and academia together to introduce and solve representative problems\nrelated to the application of Machine Learning (ML) to networks. In this paper,\nwe present the results gathered from Problem Statement~13 (PS-013), organized\nby Universitat Pompeu Fabra (UPF), which primary goal was predicting the\nperformance of next-generation Wireless Local Area Networks (WLANs) applying\nChannel Bonding (CB) techniques. In particular, we overview the ML models\nproposed by participants (including Artificial Neural Networks, Graph Neural\nNetworks, Random Forest regression, and gradient boosting) and analyze their\nperformance on an open dataset generated using the IEEE 802.11ax-oriented\nKomondor network simulator. The accuracy achieved by the proposed methods\ndemonstrates the suitability of ML for predicting the performance of WLANs.\nMoreover, we discuss the importance of abstracting WLAN interactions to achieve\nbetter results, and we argue that there is certainly room for improvement in\nthroughput prediction through ML.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 05:33:07 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wilhelmi", "Francesc", ""], ["G\u00f3ez", "David", ""], ["Soto", "Paola", ""], ["Vall\u00e9s", "Ramon", ""], ["Alfaifi", "Mohammad", ""], ["Algunayah", "Abdulrahman", ""], ["Martin-P\u00e9rez", "Jorge", ""], ["Girletti", "Luigi", ""], ["Mohan", "Rajasekar", ""], ["Ramnan", "K Venkat", ""], ["Bellalta", "Boris", ""]]}, {"id": "2105.14221", "submitter": "Francesc Wilhelmi", "authors": "Francesc Wilhelmi, Lorenza Giupponi", "title": "On the Performance of Blockchain-enabled RAN-as-a-service in Beyond 5G\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain (BC) technology can revolutionize the future of communications by\nenabling decentralized and open sharing networks. In this paper, we propose the\napplication of BC to facilitate Mobile Network Operators (MNOs) and other\nplayers such as Verticals or Over-The-Top (OTT) service providers to exchange\nRadio Access Network (RAN) resources (e.g., infrastructure, spectrum) in a\nsecure, flexible and autonomous manner. In particular, we propose a BC-enabled\nreverse auction mechanism for RAN sharing and dynamic users' service provision\nin Beyond 5G networks, and we analyze its potential advantages with respect to\ncurrent service provisioning and RAN sharing schemes. Moreover, we study the\ndelay and overheads incurred by the BC in the whole process, when running over\nboth wireless and wired interfaces.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 05:40:16 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wilhelmi", "Francesc", ""], ["Giupponi", "Lorenza", ""]]}, {"id": "2105.14271", "submitter": "Shiva Raj Pokhrel Dr", "authors": "Shiva Raj Pokhrel and Anwar Walid", "title": "Learning to Harness Bandwidth with Multipath Congestion Control and\n  Scheduling", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multipath TCP (MPTCP) has emerged as a facilitator for harnessing and pooling\navailable bandwidth in wireless/wireline communication networks and in data\ncenters. Existing implementations of MPTCP such as, Linked Increase Algorithm\n(LIA), Opportunistic LIA (OLIA) and BAlanced LInked Adaptation (BALIA) include\nseparate algorithms for congestion control and packet scheduling, with\npre-selected control parameters. We propose a Deep Q-Learning (DQL) based\nframework for joint congestion control and packet scheduling for MPTCP. At the\nheart of the solution is an intelligent agent for interface, learning and\nactuation, which learns from experience optimal congestion control and\nscheduling mechanism using DQL techniques with policy gradients. We provide a\nrigorous stability analysis of system dynamics which provides important\npractical design insights. In addition, the proposed DQL-MPTCP algorithm\nutilizes the `recurrent neural network' and integrates it with `long short-term\nmemory' for continuously i) learning dynamic behavior of subflows (paths) and\nii) responding promptly to their behavior using prioritized experience replay.\nWith extensive emulations, we show that the proposed DQL-based MPTCP algorithm\noutperforms MPTCP LIA, OLIA and BALIA algorithms. Moreover, the DQL-MPTCP\nalgorithm is robust to time-varying network characteristics, and provides\ndynamic exploration and exploitation of paths.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 11:14:30 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Pokhrel", "Shiva Raj", ""], ["Walid", "Anwar", ""]]}, {"id": "2105.14359", "submitter": "Ahmed Elzanaty Dr.", "authors": "Zhengying Lou and Ahmed Elzanaty and Mohamed-Slim Alouini", "title": "Green Tethered UAVs for EMF-Aware Cellular Networks", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A prevalent theory circulating among the non-scientific community is that the\nintensive deployment of base stations over the territory significantly\nincreases the level of electromagnetic field (EMF) exposure and affects\npopulation health. To alleviate this concern, in this work, we propose a\nnetwork architecture that introduces tethered unmanned aerial vehicles (TUAVs)\ncarrying green antennas to minimize the EMF exposure while guaranteeing a high\ndata rate for users. In particular, each TUAV can attach itself to one of the\npossible ground stations at the top of some buildings. The location of the\nTUAVs, transmit power of user equipment and association policy are optimized to\nminimize the EMF exposure. Unfortunately, the problem turns out to be\nmixed-integer non-linear programming (MINLP), which is non-deterministic\npolynomial-time (NP) hard. We propose an efficient low-complexity algorithm\ncomposed of three submodules. Firstly, we propose an algorithm based on the\ngreedy principle to determine the optimal association matrix between the users\nand base stations. Then, we offer two approaches, a modified K-mean and shrink\nand realign (SR) process, to associate each TUAV with a ground station.\nFinally, we put forward two algorithms based on the golden search and SR\nprocess to adjust the TUAV's position within the hovering area over the\nbuilding. After that, we consider the dual problem that maximizes the sum rate\nwhile keeping the exposure below a predefined value, such as the level enforced\nby the regulation. Next, we perform extensive simulations to show the\neffectiveness of the proposed TUAVs to reduce the exposure compared to various\narchitectures. Eventually, we show that TUAVs with green antennas can\neffectively mitigate the EMF exposure by more than 20% compared to fixed green\nsmall cells while achieving a higher data rate.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 19:22:59 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 23:21:49 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Lou", "Zhengying", ""], ["Elzanaty", "Ahmed", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2105.14380", "submitter": "Derya Malak", "authors": "Derya Malak and Faruk V. Mutlu and Jinkun Zhang and Edmund M. Yeh", "title": "Transmission Delay Minimization via Joint Power Control and Caching in\n  Wireless HetNets", "comments": "Supplementary material for conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in wireless heterogeneous networks (HetNets) is to\neffectively utilize the limited transmission and storage resources in the\npresence of increasing deployment density and backhaul capacity constraints. To\nalleviate bottlenecks and reduce resource consumption, we design optimal\ncaching and power control algorithms for multi-hop wireless HetNets. We\nformulate a joint optimization framework to minimize the average transmission\ndelay as a function of the caching variables and the\nsignal-to-interference-plus-noise ratios (SINR) which are determined by the\ntransmission powers, while explicitly accounting for backhaul connection costs\nand the power constraints.\n  Using convex relaxation and rounding, we obtain a reduced-complexity\nformulation (RCF) of the joint optimization problem, which can provide a\nconstant factor approximation to the globally optimal solution. We then solve\nRCF in two ways: 1) alternating optimization of the power and caching variables\nby leveraging biconvexity, and 2) joint optimization of power control and\ncaching. We characterize the necessary (KKT) conditions for an optimal solution\nto RCF, and use strict quasi-convexity to show that the KKT points are Pareto\noptimal for RCF. We then devise a subgradient projection algorithm to jointly\nupdate the caching and power variables, and show that under appropriate\nconditions, the algorithm converges at a linear rate to the local minima of\nRCF, under general SINR conditions. We support our analytical findings with\nresults from extensive numerical experiments.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 21:55:25 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Malak", "Derya", ""], ["Mutlu", "Faruk V.", ""], ["Zhang", "Jinkun", ""], ["Yeh", "Edmund M.", ""]]}, {"id": "2105.14405", "submitter": "Yinxin Wan", "authors": "Yinxin Wan, Kuai Xu, Feng Wang, Guoliang Xue", "title": "IoTAthena: Unveiling IoT Device Activities from Network Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent spate of cyber attacks towards Internet of Things (IoT) devices in\nsmart homes calls for effective techniques to understand, characterize, and\nunveil IoT device activities. In this paper, we present a new system, named\nIoTAthena, to unveil IoT device activities from raw network traffic consisting\nof timestamped IP packets. IoTAthena characterizes each IoT device activity\nusing an activity signature consisting of an ordered sequence of IP packets\nwith inter-packet time intervals. IoTAthena has two novel polynomial time\nalgorithms, sigMatch and actExtract. For any given signature, sigMatch can\ncapture all matches of the signature in the raw network traffic. Using sigMatch\nas a subfunction, actExtract can accurately unveil the sequence of various IoT\ndevice activities from the raw network traffic. Using the network traffic of\nheterogeneous IoT devices collected at the router of a real-world smart home\ntestbed and a public IoT dataset, we demonstrate that IoTAthena is able to\ncharacterize and generate activity signatures of IoT device activities and\naccurately unveil the sequence of IoT device activities from raw network\ntraffic.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 01:40:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wan", "Yinxin", ""], ["Xu", "Kuai", ""], ["Wang", "Feng", ""], ["Xue", "Guoliang", ""]]}, {"id": "2105.14507", "submitter": "Mahdi Chehimi", "authors": "Mahdi Chehimi and Walid Saad", "title": "Entanglement Rate Optimization in Heterogeneous Quantum Communication\n  Networks", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum communication networks are emerging as a promising technology that\ncould constitute a key building block in future communication networks in the\n6G era and beyond. These networks have an inherent feature of parallelism that\nallows them to boost the capacity and enhance the security of communication\nsystems. Recent advances led to the deployment of small- and large-scale\nquantum communication networks with real quantum hardware. In quantum networks,\nentanglement is a key resource that allows for data transmission between\ndifferent nodes. However, to reap the benefits of entanglement and enable\nefficient quantum communication, the number of generated entangled pairs must\nbe optimized. Indeed, if the entanglement generation rates are not optimized,\nthen some of these valuable resources will be discarded and lost. In this\npaper, the problem of optimizing the entanglement generation rates and their\ndistribution over a quantum memory is studied. In particular, a quantum network\nin which users have heterogeneous distances and applications is considered.\nThis problem is posed as a mixed integer nonlinear programming optimization\nproblem whose goal is to efficiently utilize the available quantum memory by\ndistributing the quantum entangled pairs in a way that maximizes the user\nsatisfaction. An interior point optimization method is used to solve the\noptimization problem and extensive simulations are conducted to evaluate the\neffectiveness of the proposed system. Simulation results show the key design\nconsiderations for efficient quantum networks, and the effect of different\nnetwork parameters on the network performance.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 11:34:23 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chehimi", "Mahdi", ""], ["Saad", "Walid", ""]]}, {"id": "2105.14607", "submitter": "Adnan Akhunzada", "authors": "Adnan Akhunzada (Senior Member, IEEE), Sherali Zeadally (Senior\n  Member, IEEE), Saif ul Islam", "title": "Power and Performance Efficient SDN-Enabled Fog Architecture", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software Defined Networks (SDNs) have dramatically simplified network\nmanagement. However, enabling pure SDNs to respond in real-time while handling\nmassive amounts of data still remains a challenging task. In contrast, fog\ncomputing has strong potential to serve large surges of data in real-time. SDN\ncontrol plane enables innovation, and greatly simplifies network operations and\nmanagement thereby providing a promising solution to implement energy and\nperformance aware SDN-enabled fog computing. Besides, power efficiency and\nperformance evaluation in SDN-enabled fog computing is an area that has not yet\nbeen fully explored by the research community. We present a novel SDN-enabled\nfog architecture to improve power efficacy and performance by leveraging\ncooperative and non-cooperative policy-based computing. Preliminary results\nfrom extensive simulation demonstrate an improvement in the power utilization\nas well as the overall performance (i.e., processing time, response time).\nFinally, we discuss several open research issues that need further\ninvestigation in the future.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 19:28:52 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Akhunzada", "Adnan", "", "Senior Member, IEEE"], ["Zeadally", "Sherali", "", "Senior\n  Member, IEEE"], ["Islam", "Saif ul", ""]]}, {"id": "2105.14675", "submitter": "Huanle Zhang", "authors": "Huanle Zhang, Jeonghoon Kim", "title": "Towards a Federated Learning Framework for Heterogeneous Devices of\n  Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) has received a significant amount of attention in the\nindustry and research community due to its capability of keeping data on local\ndevices. To aggregate the gradients of local models to train the global model,\nexisting works require that the global model and the local models are the same.\nHowever, Internet of Things (IoT) devices are inherently diverse regarding\ncomputation speed and onboard memory. In this paper, we propose an FL framework\ntargeting the heterogeneity of IoT devices. Specifically, local models are\ncompressed from the global model, and the gradients of the compressed local\nmodels are used to update the global model. We conduct preliminary experiments\nto illustrate that our framework can facilitate the design of IoT-aware FL.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 02:08:36 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Huanle", ""], ["Kim", "Jeonghoon", ""]]}, {"id": "2105.14731", "submitter": "Fahri Wisnu Murti", "authors": "Fahri Wisnu Murti, Samad Ali, and Matti Latva-aho", "title": "Deep Reinforcement Based Optimization of Function Splitting in\n  Virtualized Radio Access Networks", "comments": "This paper has been accepted in IEEE International Conference on\n  Communications Workshops (ICC Workshops) 2021", "journal-ref": null, "doi": "10.1109/ICCWorkshops50388.2021.9473703", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualized Radio Access Network (vRAN) is one of the key enablers of future\nwireless networks as it brings the agility to the radio access network (RAN)\narchitecture and offers degrees of design freedom. Yet, it also creates a\nchallenging problem on how to design the functional split configuration. In\nthis paper, a deep reinforcement learning approach is proposed to optimize\nfunction splitting in vRAN. A learning paradigm is developed that optimizes the\nlocation of functions in the RAN. These functions can be placed either at a\ncentral/cloud unit (CU) or a distributed unit (DU). This problem is formulated\nas constrained neural combinatorial reinforcement learning to minimize the\ntotal network cost. In this solution, a policy gradient method with Lagrangian\nrelaxation is applied that uses a stacked long short-term memory (LSTM) neural\nnetwork architecture to approximate the policy. Then, a sampling technique with\na temperature hyperparameter is applied for the inference process. The results\nshow that our proposed solution can learn the optimal function split decision\nand solve the problem with a $0.4\\%$ optimality gap. Moreover, our method can\nreduce the cost by up to $320\\%$ compared to a distributed-RAN (D-RAN). We also\nconclude that altering the traffic load and routing cost does not significantly\ndegrade the optimality performance.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 06:51:26 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Murti", "Fahri Wisnu", ""], ["Ali", "Samad", ""], ["Latva-aho", "Matti", ""]]}, {"id": "2105.15022", "submitter": "Anum Talpur", "authors": "Anum Talpur and Mohan Gurusamy", "title": "Reinforcement Learning-based Dynamic Service Placement in Vehicular\n  Networks", "comments": "Accepted and presented in IEEE 93rd Vehicular Technology Conference\n  VTC2021-Spring", "journal-ref": null, "doi": "10.1109/VTC2021-Spring51267.2021.9448645", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of technologies such as 5G and mobile edge computing has\nenabled provisioning of different types of services with different resource and\nservice requirements to the vehicles in a vehicular network.The growing\ncomplexity of traffic mobility patterns and dynamics in the requests for\ndifferent types of services has made service placement a challenging task. A\ntypical static placement solution is not effective as it does not consider the\ntraffic mobility and service dynamics. In this paper, we propose a\nreinforcement learning-based dynamic (RL-Dynamic) service placement framework\nto find the optimal placement of services at the edge servers while considering\nthe vehicle's mobility and dynamics in the requests for different types of\nservices. We use SUMO and MATLAB to carry out simulation experiments. In our\nlearning framework, for the decision module, we consider two alternative\nobjective functions-minimizing delay and minimizing edge server utilization. We\ndeveloped an ILP based problem formulation for the two objective functions. The\nexperimental results show that 1) compared to static service placement,\nRL-based dynamic service placement achieves fair utilization of edge server\nresources and low service delay, and 2) compared to delay-optimized placement,\nserver utilization optimized placement utilizes resources more effectively,\nachieving higher fairness with lower edge-server utilization.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:01:35 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 13:38:15 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Talpur", "Anum", ""], ["Gurusamy", "Mohan", ""]]}, {"id": "2105.15035", "submitter": "Anum Talpur", "authors": "Anum Talpur and Mohan Gurusamy", "title": "Machine Learning for Security in Vehicular Networks: A Comprehensive\n  Survey", "comments": "Submitted in IEEE Communications Surveys & Tutorials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has emerged as an attractive and viable technique to\nprovide effective solutions for a wide range of application domains. An\nimportant application domain is vehicular networks wherein ML-based approaches\nare found to be very useful to address various problems. The use of wireless\ncommunication between vehicular nodes and/or infrastructure makes it vulnerable\nto different types of attacks. In this regard, ML and its variants are gaining\npopularity to detect attacks and deal with different kinds of security issues\nin vehicular communication. In this paper, we present a comprehensive survey of\nML-based techniques for different security issues in vehicular networks. We\nfirst briefly introduce the basics of vehicular networks and different types of\ncommunications. Apart from the traditional vehicular networks, we also consider\nmodern vehicular network architectures. We propose a taxonomy of security\nattacks in vehicular networks and discuss various security challenges and\nrequirements. We classify the ML techniques developed in the literature\naccording to their use in vehicular network applications. We explain the\nsolution approaches and working principles of these ML techniques in addressing\nvarious security challenges and provide insightful discussion. The limitations\nand challenges in using ML-based methods in vehicular networks are discussed.\nFinally, we present observations and lessons learned before we conclude our\nwork.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:15:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Talpur", "Anum", ""], ["Gurusamy", "Mohan", ""]]}, {"id": "2105.15096", "submitter": "Shu Sun Dr.", "authors": "Shu Sun, Hangsong Yan", "title": "Small-Scale Spatial-Temporal Correlation Modeling for Reconfigurable\n  Intelligent Surfaces", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.ET eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconfigurable intelligent surface (RIS) is an emerging promising\ncandidate technology for the sixth-generation wireless networks, where the\nelement spacing is usually of sub-wavelength. Only limited knowledge, however,\nhas been gained about the spatial-temporal correlation behavior among the\nelements in an RIS. In this paper, we investigate the joint spatial-temporal\ncorrelation models for an RIS in a wireless communication system. Joint\nsmall-scale spatial-temporal correlation functions are provided and analyzed\nfor both ideal isotropic scattering and more practical non-isotropic scattering\nenvironments, where the latter is studied by employing an angular distribution\nderived from real-world millimeter-wave measurements. Analytical and simulation\nresults demonstrate that the joint spatial-temporal correlation can be\nrepresented by a four-dimensional sinc function under isotropic scattering,\nwhile the correlation is generally stronger with more fluctuation for\nnon-isotropic scattering with various motion directions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:42:56 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sun", "Shu", ""], ["Yan", "Hangsong", ""]]}, {"id": "2105.15097", "submitter": "Yueyan Chu", "authors": "Yueyan Chu, Kangyong You, Wenbin Guo", "title": "Multiple Sources Localization with Sparse Recovery under Log-normal\n  Shadow Fading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization based on received signal strength (RSS) has drawn great interest\nin the wireless sensor network (WSN). In this paper, we investigate the\nRSS-based multi-sources localization problem with unknown transmitted power\nunder shadow fading. The log-normal shadowing effect is approximated through\nFenton-Wilkinson (F-W) method and maximum likelihood estimation is adopted to\noptimize the RSS-based multiple sources localization problem. Moreover, we\nexploit a sparse recovery and weighted average of candidates (SR-WAC) based\nmethod to set up an initiation, which can efficiently approach a superior local\noptimal solution. It is shown from the simulation results that the proposed\nmethod has a much higher localization accuracy and outperforms the other\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 02:30:19 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chu", "Yueyan", ""], ["You", "Kangyong", ""], ["Guo", "Wenbin", ""]]}, {"id": "2105.15098", "submitter": "Yongxin Liu", "authors": "Yongxin Liu, Jian Wang, Jianqiang Li, Shuteng Niu, Houbing Song", "title": "Zero-bias Deep Learning Enabled Quick and Reliable Abnormality Detection\n  in IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abnormality detection is essential to the performance of safety-critical and\nlatency-constrained systems. However, as systems are becoming increasingly\ncomplicated with a large quantity of heterogeneous data, conventional\nstatistical change point detection methods are becoming less effective and\nefficient. Although Deep Learning (DL) and Deep Neural Networks (DNNs) are\nincreasingly employed to handle heterogeneous data, they still lack theoretic\nassurable performance and explainability. This paper integrates zero-bias DNN\nand Quickest Event Detection algorithms to provide a holistic framework for\nquick and reliable detection of both abnormalities and time-dependent abnormal\nevents in the Internet of Things (IoT). We first use the zero-bias dense layer\nto increase the explainability of DNN. We provide a solution to convert\nzero-bias DNN classifiers into performance assured binary abnormality\ndetectors. Using the converted abnormality detector, we then present a\nsequential quickest detection scheme that provides the theoretically assured\nlowest abnormal event detection delay under false alarm constraints. Finally,\nwe demonstrate the effectiveness of the framework using both massive signal\nrecords from real-world aviation communication systems and simulated data. Code\nand data of our work is available at\n\\url{https://github.com/pcwhy/AbnormalityDetectionInZbDNN}\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 03:31:50 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Liu", "Yongxin", ""], ["Wang", "Jian", ""], ["Li", "Jianqiang", ""], ["Niu", "Shuteng", ""], ["Song", "Houbing", ""]]}, {"id": "2105.15100", "submitter": "Suman Kumar", "authors": "Suman Kumar, Kazi Amanul Islam Siddiqui, Mukesh Kumary", "title": "Skin-Health Monitoring system using a Wireless Body Area Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A new class of sensing paradigm known as lab-onskin where stretchable and\nflexible smart sensor devices are integrated into the skin, provides direct\nmonitoring and diagnostic interfaces to the body. Distributed lab-on-skin\nwireless sensors have the ability to provide continuous long term assessment of\nthe skin health. This paper proposes a distributed skin health monitoring\nsystem using a wireless body area network. The system is responsive to the\ndynamic changes in the skin health, and remotely reports on the same. The\nproposed algorithm detects the abnormal skin and creates an energy efficient\ndata aggregation tree covering the affected area while putting the unnecessary\nsensors to sleep mode. The algorithm responds to the changing conditions of the\nskin by dynamically adapting the size and shape of the monitoring trees to that\nof the abnormal skin areas thus providing a comprehensive monitoring.\nSimulation results demonstrate the application and utility of the proposed\nalgorithm for changing wound shapes and sizes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 20:32:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kumar", "Suman", ""], ["Siddiqui", "Kazi Amanul Islam", ""], ["Kumary", "Mukesh", ""]]}, {"id": "2105.15101", "submitter": "Saeed Ghadiri", "authors": "Saeed Ghadiri", "title": "Anchor Nodes Positioning for Self-localization in Wireless Sensor\n  Networks using Belief Propagation and Evolutionary Algorithms", "comments": "5 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI eess.SP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Locating each node in a wireless sensor network is essential for starting the\nmonitoring job and sending information about the area. One method that has been\nused in hard and inaccessible environments is randomly scattering each node in\nthe area. In order to reduce the cost of using GPS at each node, some nodes\nshould be equipped with GPS (anchors), Then using the belief propagation\nalgorithm, locate other nodes. The number of anchor nodes must be reduced since\nthey are expensive. Furthermore, the location of these nodes affects the\nalgorithm's performance. Using multi-objective optimization, an algorithm is\nintroduced in this paper that minimizes the estimated location error and the\nnumber of anchor nodes. According to simulation results, This algorithm\nproposes a set of solutions with less energy consumption and less error than\nsimilar algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 10:05:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ghadiri", "Saeed", ""]]}, {"id": "2105.15102", "submitter": "Chathuranga M. Wijerathna Basnayaka", "authors": "Chathuranga M. Wijerathna Basnayaka, Dushantha Nalin K. Jayakody,\n  Tharindu D. Ponnimbaduge Perera, Moises Vidal Ribeiro", "title": "Age of Information in an URLLC-enabled Decode-and-Forward Wireless\n  Communication System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Age of Information (AoI) measures the freshness of data in mission critical\nInternet-of-Things (IoT) applications i.e., industrial internet, intelligent\ntransportation systems etc. In this paper, a new system model is proposed to\nestimate the average AoI (AAoI) in an ultra-reliable low latency communication\n(URLLC) enabled wireless communication system with decodeand-forward relay\nscheme over the quasi-static Rayleigh block fading channels. Short packet\ncommunication scheme is used to meet both reliability and latency requirements\nof the proposed wireless network. By resorting finite block length information\ntheory, queuing theory and stochastic processes, a closed-form expression for\nAAoI is obtained. Finally, the impact of the system parameters, such as update\ngeneration rate, block length and block length allocation factor on the AAoI\nare investigated. All results are validated by the numerical results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 10:48:38 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Basnayaka", "Chathuranga M. Wijerathna", ""], ["Jayakody", "Dushantha Nalin K.", ""], ["Perera", "Tharindu D. Ponnimbaduge", ""], ["Ribeiro", "Moises Vidal", ""]]}, {"id": "2105.15103", "submitter": "Krishna Sivalingam", "authors": "Krishna M. Sivalingam", "title": "Applications of Artificial Intelligence, Machine Learning and related\n  techniques for Computer Networking Systems", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This article presents a primer/overview of applications of Artificial\nIntelligence and Machine Learning (AI/ML) techniques to address problems in the\ndomain of computer networking. In particular, the techniques have been used to\nsupport efficient and accurate traffic prediction, traffic classification,\nanomaly detection, network management, network security, network resource\nallocation and optimization, network scheduling algorithms, fault diagnosis and\nmany more such applications. The article first summarizes some of the key\nnetworking concepts and a few representative machine learning techniques and\nalgorithms. The article then presents details regarding the availability of\ndata sets for networking applications and machine learning software and\ntoolkits for processing these data sets. Highlights of some of the standards\nactivities, pursued by ITU-T and ETSI, which are related to AI/ML for\nnetworking, are also presented. Finally, the article discusses a small set of\nrepresentative networking problems where AI/ML techniques have been\nsuccessfully applied.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 05:40:07 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sivalingam", "Krishna M.", ""]]}, {"id": "2105.15105", "submitter": "Davide Callegaro", "authors": "Davide Callegaro and Marco Levorato and Francesco Restuccia", "title": "SeReMAS: Self-Resilient Mobile Autonomous Systems Through Predictive\n  Edge Computing", "comments": "Corrected typo in title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing enables Mobile Autonomous Systems (MASs) to execute continuous\nstreams of heavy-duty mission-critical processing tasks, such as real-time\nobstacle detection and navigation. However, in practical applications, erratic\npatterns in channel quality, network load, and edge server load can interrupt\nthe task flow execution, which necessarily leads to severe disruption of the\nsystem's key operations. Existing work has mostly tackled the problem with\nreactive approaches, which cannot guarantee task-level reliability. Conversely,\nin this paper we focus on learning-based predictive edge computing to achieve\nself-resilient task offloading. By conducting a preliminary experimental\nevaluation, we show that there is no dominant feature that can predict the\nedge-MAS system reliability, which calls for an ensemble and selection of\nweaker features. To tackle the complexity of the problem, we propose SeReMAS, a\ndata-driven optimization framework. We first mathematically formulate a\nRedundant Task Offloading Problem (RTOP), where a MAS may connect to multiple\nedge servers for redundancy, and needs to select which server(s) to transmit\nits computing tasks in order to maximize the probability of task execution\nwhile minimizing channel and edge resource utilization. We then create a\npredictor based on Deep Reinforcement Learning (DRL), which produces the\noptimum task assignment based on application-, network- and telemetry-based\nfeatures. We prototype SeReMAS on a testbed composed by a drone, mounting a\nPixHawk flight controller, a Jetson Nano board, and three 802.11n WiFi\ninterfaces. We extensively evaluate SeReMAS by considering an application where\none drone offloads high-resolution images for real-time analysis to three edge\nservers on the ground. Experimental results show that SeReMAS improves task\nexecution probability by $17\\%$ with respect to existing reactive-based\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 05:15:44 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 16:59:05 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Callegaro", "Davide", ""], ["Levorato", "Marco", ""], ["Restuccia", "Francesco", ""]]}]