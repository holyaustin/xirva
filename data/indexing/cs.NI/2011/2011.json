[{"id": "2011.00363", "submitter": "Cao Vien Phung", "authors": "Cao Vien Phung and Admela Jukan", "title": "Increasing Transmission Distance in THz systems with Erasure Coding and\n  Auxiliary Channels", "comments": "6pages, 6 figures, TeraHertz wireless networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze whether the THz transmission distance can be extended with\nsystematic linear network coding (sRLNC) and a low-bitrate additional channel.\nWhile various coding techniques have been proposed to mitigate issues of\nchannel quality, and other techniques have used auxiliary channels to enable an\neffective THz transmission system configuration, their combination is new, and\ncarries potential for significant improvements in transmission quality. Our\nspecific solution is designed to complementing a generic low complexity FEC\ncode by a low complexity erasure code (sRLNC), whereby channel coding is\nproposed to simultaneously send the native and coded data over two parallel\nchannels, including one main THz channel and one auxiliary channel with\ncomparably lower bitrate. We show theoretically that the proposed system can\nimprove throughput, support higher modulation levels and transfer data over the\nlonger distances with THz communications.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 21:28:43 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Phung", "Cao Vien", ""], ["Jukan", "Admela", ""]]}, {"id": "2011.00365", "submitter": "Qahhar M Qadir", "authors": "Qahhar Muhammad Qadir", "title": "Analysis of the reliability of LoRa", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": "10.1109/LCOMM.2020.3034865", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter studies the performance of a single gateway LoRa system in the\npresence of different interference considering the imperfect orthogonality\neffect. It utilizes concepts of stochastic geometry to present a low-complexity\napproximate closed-form model for computing the success and coverage\nprobabilities under these challenging conditions. Monte Carlo simulation\nresults have shown that LoRa is not as theoretically described as a technology\nthat can cover few to ten kilometers. It was found that in the presence of the\ncombination of signal-to-noise ratio (SNR) and imperfect orthogonality between\nspreading factors (SF), the performance degrades dramatically beyond a couple\nof kilometers. However, better performance is observed when perfect\northogonality is considered and SNR is not included. Furthermore, the\nperformance is annulus dependent and slightly improves at the border of the\ndeployment cell annuli. Finally, the coverage probability declines\nexponentially as the average number of end devices grows.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 21:38:24 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Qadir", "Qahhar Muhammad", ""]]}, {"id": "2011.00419", "submitter": "Shinan Liu", "authors": "Shinan Liu, Paul Schmitt, Francesco Bronzino, Nick Feamster", "title": "Characterizing Service Provider Response to the COVID-19 Pandemic in the\n  United States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has resulted in dramatic changes to the daily habits of\nbillions of people. Users increasingly have to rely on home broadband Internet\naccess for work, education, and other activities. These changes have resulted\nin corresponding changes to Internet traffic patterns. This paper aims to\ncharacterize the effects of these changes with respect to Internet service\nproviders in the United States. We study three questions: (1)How did traffic\ndemands change in the United States as a result of the COVID-19 pandemic?;\n(2)What effects have these changes had on Internet performance?; (3)How did\nservice providers respond to these changes? We study these questions using data\nfrom a diverse collection of sources. Our analysis of interconnection data for\ntwo large ISPs in the United States shows a 30-60% increase in peak traffic\nrates in the first quarter of 2020. In particular, we observe traffic\ndownstream peak volumes for a major ISP increase of 13-20% while upstream peaks\nincreased by more than 30%. Further, we observe significant variation in\nperformance across ISPs in conjunction with the traffic volume shifts, with\nevident latency increases after stay-at-home orders were issued, followed by a\nstabilization of traffic after April. Finally, we observe that in response to\nchanges in usage, ISPs have aggressively augmented capacity at interconnects,\nat more than twice the rate of normal capacity augmentation. Similarly, video\nconferencing applications have increased their network footprint, more than\ndoubling their advertised IP address space.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:22:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Shinan", ""], ["Schmitt", "Paul", ""], ["Bronzino", "Francesco", ""], ["Feamster", "Nick", ""]]}, {"id": "2011.00427", "submitter": "Xiaochen Liu", "authors": "Xiaochen Liu", "title": "Efficient Pipelines for Vision-Based Context Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context awareness is an essential part of mobile and ubiquitous computing.\nIts goal is to unveil situational information about mobile users like locations\nand activities. The sensed context can enable many services like navigation,\nAR, and smarting shopping. Such context can be sensed in different ways\nincluding visual sensors. There is an emergence of vision sources deployed\nworldwide. The cameras could be installed on roadside, in-house, and on mobile\nplatforms. This trend provides huge amount of vision data that could be used\nfor context sensing. However, the vision data collection and analytics are\nstill highly manual today. It is hard to deploy cameras at large scale for data\ncollection. Organizing and labeling context from the data are also labor\nintensive. In recent years, advanced vision algorithms and deep neural networks\nare used to help analyze vision data. But this approach is limited by data\nquality, labeling effort, and dependency on hardware resources. In summary,\nthere are three major challenges for today's vision-based context sensing\nsystems: data collection and labeling at large scale, process large data\nvolumes efficiently with limited hardware resources, and extract accurate\ncontext out of vision data. The thesis explores the design space that consists\nof three dimensions: sensing task, sensor types, and task locations. Our prior\nwork explores several points in this design space. We make contributions by (1)\ndeveloping efficient and scalable solutions for different points in the design\nspace of vision-based sensing tasks; (2) achieving state-of-the-art accuracy in\nthose applications; (3) and developing guidelines for designing such sensing\nsystems.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 05:09:13 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Xiaochen", ""]]}, {"id": "2011.00612", "submitter": "Nasim Ferdosian", "authors": "Nasim Ferdosian, Sara Berri, Arsenia Chorti", "title": "5G New Radio Resource Allocation Optimization for Heterogeneous Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G new radio (NR) introduced flexible numerology to provide the necessary\nflexibility for multiplexing the communication of heterogeneous services on a\nshared channel. One of the fundamental challenges of 5G NR is to develop\nresource allocation schemes to efficiently exploit such flexibility to optimize\nresource allocation of ultra-reliable low-latency communications (URLLC) in\ncoexistence with enhanced mobile broadband (eMBB) while ensuring their\ncolliding performance requirements. To address this challenge, we present a new\nformulation of 5G NR resource allocation to accommodate eMBB and URLLC\nservices, by considering their interplay. The objective of the formulated\nproblem is to meet throughput quality of service (QoS) requirements\nprobabilistically when the optimal global solution is infeasible. To this end,\nwe express the problem as an integer linear program and consider two\nformulations with hard and soft URLLC throughput constraints. Furthermore, we\npropose a low-complexity two-step heuristic approach, inspired by an instance\nof bin packing optimization, to provide a trade-off between resource allocation\nefficiency and computational complexity. Finally, performance results are\nprovided and demonstrate that the proposed approaches can provide\nlow-complexity resource allocation solutions, in balance with the performance\ntargets of the services.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 19:48:26 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ferdosian", "Nasim", ""], ["Berri", "Sara", ""], ["Chorti", "Arsenia", ""]]}, {"id": "2011.00917", "submitter": "Anders E. Kal{\\o}r", "authors": "Josefine Holm, Anders E. Kal{\\o}r, Federico Chiariotti, Beatriz Soret,\n  S{\\o}ren K. Jensen, Torben B. Pedersen, Petar Popovski", "title": "Freshness on Demand: Optimizing Age of Information for the Query Process", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Age of Information (AoI) has become an important concept in communications,\nas it allows system designers to measure the freshness of the information\navailable to remote monitoring or control processes. However, its definition\ntacitly assumed that new information is used at any time, which is not always\nthe case and the instants at which information is collected and used are\ndependent on a certain query process. We propose a model that accounts for the\ndiscrete time nature of many monitoring processes, considering a pull-based\ncommunication model in which the freshness of information is only important\nwhen the receiver generates a query. We then define the Age of Information at\nQuery (QAoI), a more general metric that fits the pull-based scenario, and show\nhow its optimization can lead to very different choices from traditional\npush-based AoI optimization when using a Packet Erasure Channel (PEC).\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 11:54:52 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Holm", "Josefine", ""], ["Kal\u00f8r", "Anders E.", ""], ["Chiariotti", "Federico", ""], ["Soret", "Beatriz", ""], ["Jensen", "S\u00f8ren K.", ""], ["Pedersen", "Torben B.", ""], ["Popovski", "Petar", ""]]}, {"id": "2011.01096", "submitter": "Javad Zarrin", "authors": "Javad Zarrin, Phang Hao Wen, Lakshmi Babu Saheer, Bahram Zarrin", "title": "Blockchain for Decentralization of Internet: Prospects, Trends, and\n  Challenges", "comments": "Under Review in Cluster Computing, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain has made an impact on today's technology by revolutionizing the\nfinancial industry in its utilization on cryptocurrency and the features it\nprovided on decentralization. With the current trend of pursuing the\ndecentralized Internet, many methods have been proposed to achieve\ndecentralization considering different aspects of the current Internet model\nranging from infrastructure and protocols to services and applications. This\npaper focuses on using Blockchain to provide a robust and secure decentralized\ncomputing system. The paper conducts a literature review on Blockchain-based\nmethods capable for the decentralization of the future Internet. To achieve\nthat decentralization, two research aspects of Blockchain have been\ninvestigated that are highly relevant in realizing the decentralized Internet.\nThe first aspect is the consensus algorithms, which are vital components for\ndecentralization of Blockchain. We have identified three consensus algorithms\nbeing PoP, Paxos, and PoAH to be more adequate for reaching consensus in\nBlockchain-enabled Internet architecture. The second aspect that we\ninvestigated is the impact of future Internet technologies on Blockchain, where\ntheir combinations with Blockchain would help to make it overcome its\nestablished flaws and be more optimized and applicable for Internet\ndecentralization.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:31:13 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zarrin", "Javad", ""], ["Wen", "Phang Hao", ""], ["Saheer", "Lakshmi Babu", ""], ["Zarrin", "Bahram", ""]]}, {"id": "2011.01112", "submitter": "Shuochao Yao", "authors": "Shuochao Yao, Yifan Hao, Yiran Zhao, Huajie Shao, Dongxin Liu,\n  Shengzhong Liu, Tianshi Wang, Jinyang Li, Tarek Abdelzaher", "title": "Scheduling Real-time Deep Learning Services as Imprecise Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an efficient real-time scheduling algorithm for\nintelligent real-time edge services, defined as those that perform machine\nintelligence tasks, such as voice recognition, LIDAR processing, or machine\nvision, on behalf of local embedded devices that are themselves unable to\nsupport extensive computations. The work contributes to a recent direction in\nreal-time computing that develops scheduling algorithms for machine\nintelligence tasks with anytime prediction. We show that deep neural network\nworkflows can be cast as imprecise computations, each with a mandatory part and\n(several) optional parts whose execution utility depends on input data. The\ngoal of the real-time scheduler is to maximize the average accuracy of deep\nneural network outputs while meeting task deadlines, thanks to opportunistic\nshedding of the least necessary optional parts. The work is motivated by the\nproliferation of increasingly ubiquitous but resource-constrained embedded\ndevices (for applications ranging from autonomous cars to the Internet of\nThings) and the desire to develop services that endow them with intelligence.\nExperiments on recent GPU hardware and a state of the art deep neural network\nfor machine vision illustrate that our scheme can increase the overall accuracy\nby 10%-20% while incurring (nearly) no deadline misses.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:43:04 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yao", "Shuochao", ""], ["Hao", "Yifan", ""], ["Zhao", "Yiran", ""], ["Shao", "Huajie", ""], ["Liu", "Dongxin", ""], ["Liu", "Shengzhong", ""], ["Wang", "Tianshi", ""], ["Li", "Jinyang", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2011.01258", "submitter": "Frank Cangialosi", "authors": "Frank Cangialosi, Akshay Narayan, Prateesh Goyal, Radhika Mittal,\n  Mohammad Alizadeh, Hari Balakrishnan", "title": "Site-to-Site Internet Traffic Control", "comments": "15 pages, 14 figures", "journal-ref": null, "doi": "10.1145/3447786.3456260", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Queues allow network operators to control traffic: where queues build, they\ncan enforce scheduling and shaping policies. In the Internet today, however,\nthere is a mismatch between where queues build and where control is most\neffectively enforced; queues build at bottleneck links that are often not under\nthe control of the data sender. To resolve this mismatch, we propose a new kind\nof middlebox, called Bundler. Bundler uses a novel inner control loop between a\nsendbox (in the sender's site) and a receivebox (in the receiver's site) to\ndetermine the aggregate rate for the bundle, leaving the end-to-end connections\nand their control loops intact. Enforcing this sending rate ensures that\nbottleneck queues that would have built up from the bundle's packets now shift\nfrom the bottleneck to the sendbox. The sendbox then exercises control over its\ntraffic by scheduling packets to achieve higher-level objectives. We have\nimplemented Bundler in Linux and evaluated it with real-world and emulation\nexperiments. We find that Bundler allows the sender-chosen policy to be\neffective: when configured to implement Stochastic Fairness Queueing (SFQ), it\nimproves median flow completion time (FCT) by between 28% and 97% across\nvarious scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 19:02:13 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 15:28:41 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 11:26:36 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Cangialosi", "Frank", ""], ["Narayan", "Akshay", ""], ["Goyal", "Prateesh", ""], ["Mittal", "Radhika", ""], ["Alizadeh", "Mohammad", ""], ["Balakrishnan", "Hari", ""]]}, {"id": "2011.01410", "submitter": "Hai Zhou", "authors": "Hai Zhou, Dan Feng, Yuchong Hu", "title": "Multi-level Forwarding and Scheduling Recovery Algorithm in\n  Rapidly-changing Network for Erasure-coded Clusters", "comments": "We have modified the algorithm of this article, and a submission\n  meeting is required. However, the meeting request cannot be published, so we\n  apply to withdraw the article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key design goal of erasure-coded clusters is to reduce the repair time. The\nexisting Erasure-coded data repair schemes are roughly classified into two\ncategories: 1. Designing rapid data repair (e.g., PPR) in a homogeneous\nenvironment. 2. Constructing data repair (e.g., PPT) based on bandwidth in a\nheterogeneous environment. However, these solutions are difficult to cope with\nthe heterogeneous and Rapidly-changing network in erasure-coded clusters. To\naddress this problem, a bandwidth-aware multi-level forwarding repair\nalgorithm, called BMFRepair, is proposed. BMFRepair monitors the network\nbandwidth in real time when data is forwarded, and selects idle nodes with\nhigh-bandwidth links to assist in forwarding. Thus, it can reduce the time\nbottleneck caused by low link transmission. At the same time, multi-node repair\nbecomes very complicated when the bandwidth changes drastically. A multi-node\nscheduling repairing algorithm, called MSRepair, is proposed for multi-node\nrepairing problems, which can repair multiple failed blocks in parallel by\nscheduling node resources. The two algorithms can flexibly adapt to the rapidly\nchanging network environment and make full use of the bandwidth resources of\nidle nodes. Most importantly, algorithms can continuously adjust the repair\nplan according to the bandwidth change in fast and dynamic network. The\nalgorithms have been evaluated by both simulations on Mininet and real\nexperiments on Aliyun cloud platform ECS. Results show that compared with the\nstate-of-the-art repair schemes PPR and PPT, the algorithms can significantly\nreduce the repair time in rapidly-changing network.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 01:36:52 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 06:02:03 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Zhou", "Hai", ""], ["Feng", "Dan", ""], ["Hu", "Yuchong", ""]]}, {"id": "2011.01514", "submitter": "Shitong Zhu", "authors": "Shitong Zhu, Shasha Li, Zhongjie Wang, Xun Chen, Zhiyun Qian, Srikanth\n  V. Krishnamurthy, Kevin S. Chan, Ananthram Swami", "title": "You Do (Not) Belong Here: Detecting DPI Evasion Attacks with Context\n  Learning", "comments": "12 pages, 12 figures; accepted to ACM CoNEXT 2020", "journal-ref": null, "doi": "10.1145/3386367.3431311", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Deep Packet Inspection (DPI) middleboxes become increasingly popular, a\nspectrum of adversarial attacks have emerged with the goal of evading such\nmiddleboxes. Many of these attacks exploit discrepancies between the middlebox\nnetwork protocol implementations, and the more rigorous/complete versions\nimplemented at end hosts. These evasion attacks largely involve subtle\nmanipulations of packets to cause different behaviours at DPI and end hosts, to\ncloak malicious network traffic that is otherwise detectable. With recent\nautomated discovery, it has become prohibitively challenging to manually curate\nrules for detecting these manipulations. In this work, we propose CLAP, the\nfirst fully-automated, unsupervised ML solution to accurately detect and\nlocalize DPI evasion attacks. By learning what we call the packet context,\nwhich essentially captures inter-relationships across both (1) different\npackets in a connection; and (2) different header fields within each packet,\nfrom benign traffic traces only, CLAP can detect and pinpoint packets that\nviolate the benign packet contexts (which are the ones that are specially\ncrafted for evasion purposes). Our evaluations with 73 state-of-the-art DPI\nevasion attacks show that CLAP achieves an Area Under the Receiver Operating\nCharacteristic Curve (AUC-ROC) of 0.963, an Equal Error Rate (EER) of only\n0.061 in detection, and an accuracy of 94.6% in localization. These results\nsuggest that CLAP can be a promising tool for thwarting DPI evasion attacks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:18:47 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Zhu", "Shitong", ""], ["Li", "Shasha", ""], ["Wang", "Zhongjie", ""], ["Chen", "Xun", ""], ["Qian", "Zhiyun", ""], ["Krishnamurthy", "Srikanth V.", ""], ["Chan", "Kevin S.", ""], ["Swami", "Ananthram", ""]]}, {"id": "2011.01523", "submitter": "Wolfgang Bauer PhD MSc", "authors": "Wolfgang Bauer (1), Natalia Kryvinska (1), J\\\"urgen Dorn (2) ((1)\n  Comenius University in Bratislava, Information Systems Department (2)\n  Technical University in Vienna, Institute for Information Systems\n  Engineering)", "title": "Model of Trust Management for Digital Industry Services. Towards\n  E-Commerce 4.0", "comments": "12 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The progressive digitalization is changing the way businesses work and\ninteract. Concepts like Internet of Things, Cloud Computing, Industry 4.0,\nService 4.0, Smart Production or Smart Cities are based on systems that are\nlinked to the Internet. The online access to the provided data creates\npotential to optimize processes and cost reductions, but also exposes it to a\nrisk for an inappropriate use. Trust management systems are necessary in terms\nof data security, but also to assure the trustworthiness of data that is\ndistributed. Fake news in social media is an example for problems with online\ndata that is not trustable. Security and trustworthiness of data are major\nconcerns today. The speed in digitalization makes it even a greater challenge\nfor future research. This article introduces therefore a model of online trust\ncontent usable to compute the trust of an online service advertisement. It\ncontributes to standardize business service descriptions necessary to realize\nvisions of E-commerce 4.0, because it is the basis for the development of AI\nsystems that are able to match an service request to a service advertisement.\nIt is necessary for building trust enhancing architectures in B2B e-commerce.\nTo do so, we conducted case studies, analysed websites, developed a prototype\nsystem and verified it by conducting expert interviews.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:31:46 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Bauer", "Wolfgang", ""], ["Kryvinska", "Natalia", ""], ["Dorn", "J\u00fcrgen", ""]]}, {"id": "2011.01537", "submitter": "Durgesh Singh", "authors": "Durgesh Singh, Arpan Chattopadhyay, Sasthi C. Ghosh", "title": "Local Relay Selection in Presence of Dynamic Obstacles in Millimeter\n  Wave D2D Communication", "comments": "arXiv admin note: text overlap with arXiv:1910.14367", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockage due to obstacles in millimeter wave (mmWave) device to device (D2D)\ncommunication is a prominent problem due to their severe penetration losses.\nPotential user equipments (UEs) in vicinity of the source UE must be explored\nin order to select a new relay when the current link gets blocked. However,\ndynamic obstacles are not known in advance and thus may cause unpredictable\nfluctuations to D2D channel quality causing newly selected relay link also to\nbe susceptible to blockage. This might cause frequent relay switching leading\nto call drops and high energy consumption. We have proposed the idea of\nreducing frequency in relay exploration and switching and thus average\nend-to-end delay (in seconds) at the expense of additional exploration time\nunits (few milliseconds) during beam alignment. We seek to learn the\nuncertainty in D2D link qualities by modeling the problem as finite horizon\npartially observable Markov decision process (POMDP) framework locally at each\nUE. We have derived an optimal threshold policy which maps the state to set of\nactions. We then give a simplified and easy to implement stationary threshold\npolicy which counts the number of successive acknowledgment successes/failures\nfor making decisions of selecting or not selecting a given relay locally.\nThrough extensive simulation, we validate our theoretical findings and\ndemonstrate that our approach captures the trade-off between average\nexploration time and average end-to-end (E2E) delay in presence of dynamic\nobstacles.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 19:00:05 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Singh", "Durgesh", ""], ["Chattopadhyay", "Arpan", ""], ["Ghosh", "Sasthi C.", ""]]}, {"id": "2011.01683", "submitter": "Vitaly Petrov", "authors": "Vitaly Petrov and Thomas K\\\"urner and and Iwao Hosako", "title": "IEEE 802.15.3d: First Standardization Efforts for Sub-Terahertz Band\n  Communications towards 6G", "comments": "Accepted to IEEE Communications Magazine, November 2020. \\copyright\n  2020 IEEE. Personal use of this material is permitted. Permission from IEEE\n  must be obtained for all other uses, in any current or future media,\n  including reprinting/republishing this material, creating new works, for\n  resale or redistribution to servers or lists, or reuse of any copyrighted\n  component of this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ratification of the IEEE 802.15.3d amendment to the 802.15.3, a\nfirst step has been made to standardize consumer wireless communications in the\nsub-THz frequency band. The IEEE 802.15.3d offers switched point-to-point\nconnectivity with the data rates of 100\\,Gbit/s and higher at distances ranging\nfrom tens of centimeters up to a few hundred meters. In this article, we\nprovide a detailed introduction to the IEEE 802.15.3d and the key design\nprinciples beyond the developed standard. We particularly describe the target\napplications and usage scenarios, as well as the specifics of the IEEE\n802.15.3d physical and medium access layers. Later, we present the results of\nthe initial performance evaluation of IEEE 802.15.3d wireless communications.\nThe obtained first-order performance predictions show non-incremental benefits\ncompared to the characteristics of the fifth-generation wireless systems, thus\npaving the way towards the six-generation (6G) THz networks. We conclude the\narticle by outlining the further standardization and regulatory activities on\nwireless networking in the THz frequency band.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:19:07 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 12:55:01 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Petrov", "Vitaly", ""], ["K\u00fcrner", "Thomas", ""], ["Hosako", "and Iwao", ""]]}, {"id": "2011.02019", "submitter": "Joao Ceron", "authors": "Joao M. Ceron and Justyna J. Chromik and Jair Santanna and Aiko Pras", "title": "Online Discoverability and Vulnerabilities of ICS/SCADA Devices in the\n  Netherlands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On a regular basis, we read in the news about cyber-attacks on critical\ninfrastructures, such as power plants. Such infrastructures rely on the\nso-called Industrial Control Systems (ICS) / Supervisory Control And Data\nAcquisition (SCADA) networks. By hacking the devices in such systems and\nnetworks, attackers may take over the control of critical infrastructures, with\npotentially devastating consequences. This report focusses on critical\ninfrastructures in the Netherlands and investigates three main questions: 1)\nHow many ICS/SCADA devices located in the Netherlands can be easily found by\npotential attackers?, 2) How many of these devices are vulnerable to\ncyber-attacks?, and 3) What measures should be taken to prevent these devices\nfrom being hacked?\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 21:50:56 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ceron", "Joao M.", ""], ["Chromik", "Justyna J.", ""], ["Santanna", "Jair", ""], ["Pras", "Aiko", ""]]}, {"id": "2011.02053", "submitter": "Chanaka Janitha Samarathunga Samarathungage", "authors": "Chanaka Samarathunga, Mohamed Abouelseoud, Kazuyuki Sakoda, Morteza\n  Hashemi", "title": "Multi-hop Routing with Proactive Route Refinement for 60 GHz\n  Millimeter-Wave Networks", "comments": "6 pages", "journal-ref": "2021 IEEE 18th Annual Consumer Communications & Networking\n  Conference (CCNC)", "doi": "10.1109/CCNC49032.2021.9369504", "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental requirements of mmWave systems are peak data rates of multiple\nGbps and latencies of the order of at most a few milliseconds. However, highly\ndirectional mmWave links are susceptible to frequent link failures under stress\nconditions such as mobility and human blockage. Under these conditions,\nmulti-hop routing can achieve reliable and robust performance. In this paper,\nwe consider multi-hop millimeter wave (mmWave) wireless systems and propose\nproactive route refinement schemes that are particularly important under\ndynamic scenarios. First, we consider the AODV-type protocols and propose a\ncross-layer approach that integrates sectorized communication at the MAC layer\nwith on-demand multi-hop routing at the network layer. Next, we consider\nBackpressure routing protocol, and enhance this protocol with periodic HELLO\nstatus messages. System-level simulation results based on the IEEE 802.11ad\nstandard are provided that confirm the benefits of proactive route refinement\nfor the ADOV-type and Backpressure routing protocols.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 22:57:26 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 03:07:30 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Samarathunga", "Chanaka", ""], ["Abouelseoud", "Mohamed", ""], ["Sakoda", "Kazuyuki", ""], ["Hashemi", "Morteza", ""]]}, {"id": "2011.02154", "submitter": "Jia Yan", "authors": "Jia Yan, Suzhi Bi, Lingjie Duan, and Ying-Jun Angela Zhang", "title": "Pricing-Driven Service Caching and Task Offloading in Mobile Edge\n  Computing", "comments": "This paper is under major revision with IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Provided with mobile edge computing (MEC) services, wireless devices (WDs) no\nlonger have to experience long latency in running their desired programs\nlocally, but can pay to offload computation tasks to the edge server. Given its\nlimited storage space, it is important for the edge server at the base station\n(BS) to determine which service programs to cache by meeting and guiding WDs'\noffloading decisions. In this paper, we propose an MEC service pricing scheme\nto coordinate with the service caching decisions and control WDs' task\noffloading behavior. We propose a two-stage dynamic game of incomplete\ninformation to model and analyze the two-stage interaction between the BS and\nmultiple associated WDs. Specifically, in Stage I, the BS determines the MEC\nservice caching and announces the service program prices to the WDs, with the\nobjective to maximize its expected profit under both storage and computation\nresource constraints. In Stage II, given the prices of different service\nprograms, each WD selfishly decides its offloading decision to minimize\nindividual service delay and cost, without knowing the other WDs' desired\nprogram types or local execution delays. Despite the lack of WD's information\nand the coupling of all the WDs' offloading decisions, we derive the optimal\nthreshold-based offloading policy that can be easily adopted by the WDs in\nStage II at the Bayesian equilibrium. Then, by predicting the WDs' offloading\nequilibrium, we jointly optimize the BS' pricing and service caching in Stage I\nvia a low-complexity algorithm. In particular, we study both the uniform and\ndifferentiated pricing schemes. For differentiated pricing, we prove that the\nsame price should be charged to the cached programs of the same workload.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:57:52 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Yan", "Jia", ""], ["Bi", "Suzhi", ""], ["Duan", "Lingjie", ""], ["Zhang", "Ying-Jun Angela", ""]]}, {"id": "2011.02335", "submitter": "Filip Lemic", "authors": "Filip Lemic, Sergi Abadal, Chong Han, Johann Marquez-Barja, Eduard\n  Alarc\\'on, Jeroen Famaey", "title": "Localization in Power-Constrained Terahertz-Operating Software-Defined\n  Metamaterials", "comments": "49 pages, 19 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.ET cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software-Defined Metamaterials (SDMs) show a strong potential for advancing\nthe engineered control of electromagnetic waves. As such, they are envisioned\nto enable a variety of exciting applications, among others in the domains of\nsmart textiles, high-resolution structural monitoring, and sensing in\nchallenging environments. Many of the applications envisage deformations of the\nSDM structures, such as their bending, stretching or rolling, which implies\nthat the locations of metamaterial elements will be changing relative to one\nanother. In this paper, we argue that if the metamaterial elements would be\naccurately localizable, this location information could potentially be utilized\nfor enabling novel SDM applications, as well as for optimizing the control of\nthe elements themselves. To enable their localization, we assume that these\nelements are controlled wirelessly through a Terahertz (THz)-operating\nnanonetwork. We consider the elements to be power-constrained, with their sole\npowering option being to harvest energy from different environmental sources.\nBy means of simulation, we demonstrate sub-millimeter accuracy of the two-way\nTime of Flight (ToF)-based localization, as well as high availability of the\nservice (i.e., consistently more than 80% of the time), which is a result of\nthe low energy consumed in the localization process. Finally, we qualitatively\ncharacterize the latency of the proposed localization service, as well as\noutline several challenges and future research directions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 10:57:35 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 14:09:44 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 10:32:37 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Lemic", "Filip", ""], ["Abadal", "Sergi", ""], ["Han", "Chong", ""], ["Marquez-Barja", "Johann", ""], ["Alarc\u00f3n", "Eduard", ""], ["Famaey", "Jeroen", ""]]}, {"id": "2011.02367", "submitter": "Jihong Park", "authors": "Hyowoon Seo, Jihong Park, Seungeun Oh, Mehdi Bennis, Seong-Lyun Kim", "title": "Federated Knowledge Distillation", "comments": "30 pages, 12 figures, 2 tables; This chapter is written for the\n  forthcoming book, Machine Learning and Wireless Communications (Cambridge\n  University Press), edited by H. V. Poor, D. Gunduz, A. Goldsmith, and Y.\n  Eldar", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning frameworks often rely on exchanging model parameters\nacross workers, instead of revealing their raw data. A prime example is\nfederated learning that exchanges the gradients or weights of each neural\nnetwork model. Under limited communication resources, however, such a method\nbecomes extremely costly particularly for modern deep neural networks having a\nhuge number of model parameters. In this regard, federated distillation (FD) is\na compelling distributed learning solution that only exchanges the model\noutputs whose dimensions are commonly much smaller than the model sizes (e.g.,\n10 labels in the MNIST dataset). The goal of this chapter is to provide a deep\nunderstanding of FD while demonstrating its communication efficiency and\napplicability to a variety of tasks. To this end, towards demystifying the\noperational principle of FD, the first part of this chapter provides a novel\nasymptotic analysis for two foundational algorithms of FD, namely knowledge\ndistillation (KD) and co-distillation (CD), by exploiting the theory of neural\ntangent kernel (NTK). Next, the second part elaborates on a baseline\nimplementation of FD for a classification task, and illustrates its performance\nin terms of accuracy and communication efficiency compared to FL. Lastly, to\ndemonstrate the applicability of FD to various distributed learning tasks and\nenvironments, the third part presents two selected applications, namely FD over\nasymmetric uplink-and-downlink wireless channels and FD for reinforcement\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 15:56:13 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Seo", "Hyowoon", ""], ["Park", "Jihong", ""], ["Oh", "Seungeun", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""]]}, {"id": "2011.02586", "submitter": "Golam Kayas", "authors": "Golam Kayas, Jamie Payton, Mahmud Hossain, S. M. Riazul Islam", "title": "VSDM: A Virtual Service Device Management Scheme for UPnP-Based IoT\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquitous nature of IoT devices has brought new and exciting\napplications in computing and communication paradigms. Due to its ability to\nenable auto-configurable communication between IoT devices, pervasive\napplications, and remote clients, the use of the Universal Plug and Play (UPnP)\nprotocol is widespread. However, the advertisement and discovery mechanism of\nUPnP incurs significant overhead on resource-constrained IoT devices. In this\npaper, we propose a delegation-based approach that extends the UPnP protocol by\noffloading the service advertisement and discovery-related overhead from\nresource-limited IoT devices to the resource-rich neighbours of a UPnP-enabled\nIoT network. Our experimental evaluations demonstrate that the proposed scheme\nshows significant improvement over the basic UPnP, reducing energy consumption\nand network overhead.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 23:54:32 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Kayas", "Golam", ""], ["Payton", "Jamie", ""], ["Hossain", "Mahmud", ""], ["Islam", "S. M. Riazul", ""]]}, {"id": "2011.02616", "submitter": "Qiong Wu", "authors": "Qiong Wu, Hongmei Ge, Pingyi Fan, Jiangzhou Wang, Qiang Fan, Zhengquan\n  Li", "title": "Time-dependent Performance Analysis of the 802.11p-based Platooning\n  Communications Under Disturbance", "comments": "This paper has been accepted by IEEE Transactions on Vehicular\n  Technology. Simulation codes have been provided at:\n  https://github.com/qiongwu86/TVT_code", "journal-ref": null, "doi": "10.1109/TVT.2020.3034622", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Platooning is a critical technology to realize autonomous driving. Each\nvehicle in platoons adopts the IEEE 802.11p standard to exchange information\nthrough communications to maintain the string stability of platoons. However,\none vehicle in platoons inevitably suffers from a disturbance resulting from\nthe leader vehicle acceleration/deceleration, wind gust and uncertainties in a\nplatoon control system, i.e., aerodynamics drag and rolling resistance moment\netc. Disturbances acting on one vehicle may inevitably affect the following\nvehicles and cause that the spacing error is propagated or even amplified\ndownstream along the platoon, i.e., platoon string instability. In this case,\nthe connectivity among vehicles is dynamic, resulting in the performance of\n802.11p in terms of packet delay and packet delivery ratio being time-varying.\nThe effect of the string instability would be further deteriorated once the\ntime-varying performance of 802.11p cannot satisfy the basic communication\nrequirement. Unlike the existing works which only analyze the steady\nperformance of 802.11p in vehicular networks, we will focus on the impact of\ndisturbance and construct models to analyze the time-dependent performance of\n802.11p-based platooning communications. The effectiveness of the models is\nvalidated through simulation results. Moreover, the time-dependent performance\nof 802.11p is analyzed through numerical results and it is validated that\n802.11p is able to satisfy the communication requirement under disturbance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 02:12:56 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Wu", "Qiong", ""], ["Ge", "Hongmei", ""], ["Fan", "Pingyi", ""], ["Wang", "Jiangzhou", ""], ["Fan", "Qiang", ""], ["Li", "Zhengquan", ""]]}, {"id": "2011.02644", "submitter": "Zhiyang Wang", "authors": "Zhiyang Wang, Mark Eisen and Alejandro Ribeiro", "title": "Unsupervised Learning for Asynchronous Resource Allocation in Ad-hoc\n  Wireless Networks", "comments": "5 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimal resource allocation problems under asynchronous wireless\nnetwork setting. Without explicit model knowledge, we design an unsupervised\nlearning method based on Aggregation Graph Neural Networks (Agg-GNNs).\nDepending on the localized aggregated information structure on each network\nnode, the method can be learned globally and asynchronously while implemented\nlocally. We capture the asynchrony by modeling the activation pattern as a\ncharacteristic of each node and train a policy-based resource allocation\nmethod. We also propose a permutation invariance property which indicates the\ntransferability of the trained Agg-GNN. We finally verify our strategy by\nnumerical simulations compared with baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 03:38:36 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Wang", "Zhiyang", ""], ["Eisen", "Mark", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2011.02653", "submitter": "Nitish K Panigrahy", "authors": "Nitish K. Panigrahy, Prithwish Basu, Don Towsley, Ananthram Swami and\n  Kin K. Leung", "title": "On the Analysis of Spatially Constrained Power of Two Choice Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of power of two choice based assignment policies for\nallocating users to servers, where both users and servers are located on a\ntwo-dimensional Euclidean plane. In this framework, we investigate the inherent\ntradeoff between the communication cost, and load balancing performance of\ndifferent allocation policies. To this end, we first design and evaluate a\nSpatial Power of two (sPOT) policy in which each user is allocated to the least\nloaded server among its two geographically nearest servers sequentially. When\nservers are placed on a two-dimensional square grid, sPOT maps to the classical\nPower of two (POT) policy on the Delaunay graph associated with the Voronoi\ntessellation of the set of servers. We show that the associated Delaunay graph\nis 4-regular and provide expressions for asymptotic maximum load using results\nfrom the literature. For uniform placement of servers, we map sPOT to a\nclassical balls and bins allocation policy with bins corresponding to the\nVoronoi regions associated with the second order Voronoi diagram of the set of\nservers. We provide expressions for the lower bound on the asymptotic expected\nmaximum load on the servers and prove that sPOT does not achieve POT load\nbalancing benefits. However, experimental results suggest the efficacy of sPOT\nwith respect to expected communication cost. Finally, we propose two\nnon-uniform server sampling based POT policies that achieve the best of both\nthe performance metrics. Experimental results validate the effctiveness of our\nproposed policies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 04:19:17 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Panigrahy", "Nitish K.", ""], ["Basu", "Prithwish", ""], ["Towsley", "Don", ""], ["Swami", "Ananthram", ""], ["Leung", "Kin K.", ""]]}, {"id": "2011.02699", "submitter": "Fabrice Guillemin", "authors": "Veronica Quintuna Rodriguez, Romuald Corbel, Fabrice Guillemin,\n  Alexandre Ferrieux", "title": "Cloud-RAN Factory: Instantiating virtualized mobile networks with ONAP", "comments": "Demo paper presenter at NoF 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this demo, we exhibit the negotiation based on the TM Forum framework\n(Customer Facing Service and Resource Facing Service) and the deployment of a\nfully virtualized end-to-end mobile network (including a RAN desegregated into\nRemote Unit, Distributed Unit and Centralized Unit) by using ONAP, an\nopen-source network automation platform. The various components of mobile\nnetwork are containerized and deployed by ONAP on top of Kubernetes. The demo\nis the first illustration of an end-to-end mobile network, which is fully\nvirtualized up to the remote unit, whose architecture is compatible with the\nOpen-RAN framework, and which implements a PHY layer on the basis of 3GPP 7.3\nfunctional split in Open Air Interface code.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 08:26:53 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Rodriguez", "Veronica Quintuna", ""], ["Corbel", "Romuald", ""], ["Guillemin", "Fabrice", ""], ["Ferrieux", "Alexandre", ""]]}, {"id": "2011.02752", "submitter": "V\\'ictor Valls", "authors": "V\\'ictor Valls, George Iosifidis, Leandros Tassiulas", "title": "Birkhoff's Decomposition Revisited: Sparse Scheduling for High-Speed\n  Circuit Switches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data centers are increasingly using high-speed circuit switches to cope with\nthe growing demand and reduce operational costs. One of the fundamental tasks\nof circuit switches is to compute a sparse collection of switching\nconfigurations to support a traffic demand matrix. Such a problem has been\naddressed in the literature with variations of the approach proposed by\nBirkhoff in 1946 to decompose a doubly stochastic matrix exactly. However, the\nexisting methods are heuristic and do not have theoretical guarantees on how\nwell a collection of switching configurations (i.e., permutations) can\napproximate a traffic matrix (i.e., a scaled doubly stochastic matrix).\n  In this paper, we revisit Birkhoff's approach and make three contributions.\nFirst, we establish the first theoretical bound on the sparsity of Birkhoff's\nalgorithm (i.e., the number of switching configurations necessary to\napproximate a traffic matrix). In particular, we show that by using a subset of\nthe admissible permutation matrices, Birkhoff's algorithm obtains an\n$\\epsilon$-approximate decomposition with at most $O( \\log(1 / \\epsilon))$\npermutations. Second, we propose a new algorithm, Birkhoff+, which combines the\nwealth of Frank-Wolfe with Birkhoff's approach to obtain sparse decompositions\nin a fast manner. And third, we evaluate the performance of the proposed\nalgorithm numerically and study how this affects the performance of a circuit\nswitch. Our results show that Birkhoff+ is superior to previous algorithms in\nterms of throughput, running time, and number of switching configurations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 10:50:15 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Valls", "V\u00edctor", ""], ["Iosifidis", "George", ""], ["Tassiulas", "Leandros", ""]]}, {"id": "2011.02801", "submitter": "Christoph Strnadl", "authors": "Christoph F. Strnadl", "title": "End-to-end-Architekturen zur Datenmonetarisierung im IIoT. Konzepte und\n  Implementierungen", "comments": "38 Seiten, 13 Abbildungen, 4 Tabellen, Abk\\\"urzungsverzeichnis. This\n  contribution is in the German language. Dieser Beitrag ist in Deutscher\n  Sprache.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The value creation potential of the Internet of Things (IoT), that is the\nconnection of arbitrary objects to the Internet, lies in the creation of\nbusiness benefits through accessing and processing the circa 80 Zettabytes (1\nZB = 10^21 Bytes) of data produced by an estimated 40 billions of IoT endpoints\n(prognosis for 2025). This contribution derives and presents the information\ntechnology-related fundament and basis required to be able to reap this\npotential. Quantity and heterogeneity of the devices and machines especially\nencountered in the industry at large in the so-called industrial IoT (IIoT)\nrequire the use of a typically cloud-based IoT platform for logical\nconcentration and more efficient management of the -- unavoidable in industry\n-- complexity. Stringent non-functional requirements especially regarding (low)\nlatency, (high) bandwidth, access to large processing capacities, and security\nand privacy-related aspects necessitate the deployment of intermediary IoT\ngateways endowed with different capability sets in the edge continuum between\nIoT endpoints and the IoT platform in the cloud. This will be illustrated in\nthe form of two use cases from corporate projects using a component\narchitecture view point. Finally we argue that this classical concept of IoT\nprojects needs to be strategically widened towards application integration (key\nword: IT/OT integration) and API management resulting in the coupling of a\nsuitable integration and API management platforms to the IoT platform in order\nto use this end-to-end understanding of IoT/IIoT to fully leverage the\ninnovation-stimulating and transformational character of IIoT and Industry 4.0.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:11:57 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Strnadl", "Christoph F.", ""]]}, {"id": "2011.02964", "submitter": "Andras Farago", "authors": "Andr\\'as Farag\\'o", "title": "Optimization of Virtual Networks", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general and comprehensive model for the design and\noptimization of Virtual Networks, and for the related concept of Network\nSlicing. The model is flexible, so that by adjusting some of its elements, it\ncan accommodate many different specific cases of importance. Yet, surprisingly,\nit still allows efficient optimization, in the sense that the global optimum\ncan be well approximated by efficient algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:45:12 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Farag\u00f3", "Andr\u00e1s", ""]]}, {"id": "2011.03169", "submitter": "Venkata Prashant Modekurthy", "authors": "Venkata Prashant Modekurthy", "title": "Real-Time Control over Wireless Networks", "comments": "Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial internet of Things (IIoT) are gaining popularity for use in\nlarge-scale applications such as oil-field management (e.g., $74\\times 8$km$^2$\nEast Texas Oil-field), smart farming, smart manufacturing, smart grid, and data\ncenter power management. These applications require the wireless stack to\nprovide a scalable, reliable, low-power and low-latency communication. To\nrealize a predictable and reliable communication in a highly unreliable\nwireless environment, industrial wireless standards use a centralized wireless\nstack design. In a centralized wireless stack design, a central manager\ngenerates routes and a communication schedule for a multi-channel time division\nmultiple access communication (TDMA) based medium access control (MAC).\nHowever, a centralized wireless stack design is highly energy consuming, not\nscalable, and does not support frequent changes to networks or workloads. To\naddress these challenges, the following contributions are made in this\ndissertation: (1) A scalable and distributed routing algorithm for industrial\nIoT which generates graph routes, which offer a high degree of redundancy, (2)\nA local and online scheduling algorithm that is scalable, energy-efficient, and\nsupports network/workload dynamics while ensuring reliability and real-time\nperformance, (3) An approach to minimize latency for in-band integration of\nmultiple low-power networks, (4) A fast and efficient test of schedulability\nthat determines if an application meets the real-time performance requirement\nfor given network topology, and (5) A distributed scheduling and control\nco-design that balances the control performance requirement and real-time\nperformance for industrial IoT.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:05:06 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Modekurthy", "Venkata Prashant", ""]]}, {"id": "2011.03206", "submitter": "Gautham Krishna Gudur", "authors": "Gautham Krishna Gudur, Bala Shyamala Balaji, Satheesh K. Perepu", "title": "Resource-Constrained Federated Learning with Heterogeneous Labels and\n  Models", "comments": "6 pages, 5 figures, ACM KDD 2020 (The 3rd International Workshop on\n  Artificial Intelligence of Things - AIoT'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various IoT applications demand resource-constrained machine learning\nmechanisms for different applications such as pervasive healthcare, activity\nmonitoring, speech recognition, real-time computer vision, etc. This\nnecessitates us to leverage information from multiple devices with few\ncommunication overheads. Federated Learning proves to be an extremely viable\noption for distributed and collaborative machine learning. Particularly,\non-device federated learning is an active area of research, however, there are\na variety of challenges in addressing statistical (non-IID data) and model\nheterogeneities. In addition, in this paper we explore a new challenge of\ninterest -- to handle label heterogeneities in federated learning. To this end,\nwe propose a framework with simple $\\alpha$-weighted federated aggregation of\nscores which leverages overlapping information gain across labels, while saving\nbandwidth costs in the process. Empirical evaluation on Animals-10 dataset\n(with 4 labels for effective elucidation of results) indicates an average\ndeterministic accuracy increase of at least ~16.7%. We also demonstrate the\non-device capabilities of our proposed framework by experimenting with\nfederated learning and inference across different iterations on a Raspberry Pi\n2, a single-board computing platform.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 06:23:47 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Gudur", "Gautham Krishna", ""], ["Balaji", "Bala Shyamala", ""], ["Perepu", "Satheesh K.", ""]]}, {"id": "2011.03216", "submitter": "Sandeep Chinchali", "authors": "Manabu Nakanoya, Sandeep Chinchali, Alexandros Anemogiannis, Akul\n  Datta, Sachin Katti, Marco Pavone", "title": "Task-relevant Representation Learning for Networked Robotic Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.IT cs.NI cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, even the most compute-and-power constrained robots can measure\ncomplex, high data-rate video and LIDAR sensory streams. Often, such robots,\nranging from low-power drones to space and subterranean rovers, need to\ntransmit high-bitrate sensory data to a remote compute server if they are\nuncertain or cannot scalably run complex perception or mapping tasks locally.\nHowever, today's representations for sensory data are mostly designed for\nhuman, not robotic, perception and thus often waste precious compute or\nwireless network resources to transmit unimportant parts of a scene that are\nunnecessary for a high-level robotic task. This paper presents an algorithm to\nlearn task-relevant representations of sensory data that are co-designed with a\npre-trained robotic perception model's ultimate objective. Our algorithm\naggressively compresses robotic sensory data by up to 11x more than competing\nmethods. Further, it achieves high accuracy and robust generalization on\ndiverse tasks including Mars terrain classification with low-power deep\nlearning accelerators, neural motion planning, and environmental timeseries\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 07:39:08 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Nakanoya", "Manabu", ""], ["Chinchali", "Sandeep", ""], ["Anemogiannis", "Alexandros", ""], ["Datta", "Akul", ""], ["Katti", "Sachin", ""], ["Pavone", "Marco", ""]]}, {"id": "2011.03236", "submitter": "Boris Galkin Dr", "authors": "Boris Galkin, Erika Fonseca, Gavin Lee, Conor Duff, Marvin Kelly,\n  Edward Emmanuel, Ivana Dusparic", "title": "Experimental Evaluation of a UAV User QoS from a Two-Tier 3.6GHz\n  Spectrum Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Vehicle (UAV) technology is becoming increasingly used in a\nvariety of applications such as video surveillance and deliveries. To enable\nsafe and efficient use of UAVs, the devices will need to be connected into\ncellular networks. Existing research on UAV cellular connectivity shows that\nUAVs encounter significant issues with existing networks, such as strong\ninterference and antenna misalignment. In this work, we perform a novel\nmeasurement campaign of the performance of a UAV user when it connects to an\nexperimental two-tier cellular network in two different areas of Dublin city's\nSmart Docklands, which includes massive MIMO macrocells and\nwirelessly-backhauled small cells. We measure Reference Signal Received Power\n(RSRP), Reference Signal Received Quality (RSRQ), Signal to Interference and\nNoise Ratio (SINR), the downlink throughput, and the small cell handover rate.\nOur results show that increasing the UAV height reduces the performance in both\ntiers, due to issues such as antenna misalignment. The small cell tier,\nhowever, can maintain relatively stable performance across the entire range of\nUAV heights, suggesting that UAV users can successfully connect to small cells\nduring their flight. Furthermore, we demonstrate that while the UAV handover\nrate significantly fluctuates at different heights, the overall observed\nhandover rates are very low. Our results highlight the potential for small\ncells in urban areas to provide connectivity to UAVs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 08:51:06 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 13:01:55 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 14:45:56 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Galkin", "Boris", ""], ["Fonseca", "Erika", ""], ["Lee", "Gavin", ""], ["Duff", "Conor", ""], ["Kelly", "Marvin", ""], ["Emmanuel", "Edward", ""], ["Dusparic", "Ivana", ""]]}, {"id": "2011.03242", "submitter": "Vamsi Talla", "authors": "Vamsi Talla, Joshua Smith and Shyamnath Gollakota", "title": "Advances and Open Problems in Backscatter Networking", "comments": "To appear in ACM GetMobile", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant research in backscatter communication over the past\ndecade, key technical open problems remain under-explored. Here, we first\nsystematically lay out the design space for backscatter networking and identify\napplications that make backscatter an attractive communication primitive. We\nthen identify 10 research problems that remain to be solved in backscatter\nnetworking. These open problems span across the network stack to include\ncircuits, embedded systems, physical layer, MAC and network protocols as well\nas applications. We believe that addressing these problems can help deliver on\nbackscatter's promise of low-power ubiquitous connectivity.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 09:12:49 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Talla", "Vamsi", ""], ["Smith", "Joshua", ""], ["Gollakota", "Shyamnath", ""]]}, {"id": "2011.03381", "submitter": "Siamak Layeghy", "authors": "Seyedeh Faezeh Hosseini Noorbin, Siamak Layeghy, Brano Kusy, Raja\n  Jurdak, Greg Bishop-hurley, Marius Portmann", "title": "Deep Learning-based Cattle Activity Classification Using Joint\n  Time-frequency Data Representation", "comments": "22 pages, 17 figures", "journal-ref": null, "doi": "10.1016/j.compag.2021.106241", "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated cattle activity classification allows herders to continuously\nmonitor the health and well-being of livestock, resulting in increased quality\nand quantity of beef and dairy products. In this paper, a sequential deep\nneural network is used to develop a behavioural model and to classify cattle\nbehaviour and activities. The key focus of this paper is the exploration of a\njoint time-frequency domain representation of the sensor data, which is\nprovided as the input to the neural network classifier. Our exploration is\nbased on a real-world data set with over 3 million samples, collected from\nsensors with a tri-axial accelerometer, magnetometer and gyroscope, attached to\ncollar tags of 10 dairy cows and collected over a one month period. The key\nresults of this paper is that the joint time-frequency data representation,\neven when used in conjunction with a relatively basic neural network\nclassifier, can outperform the best cattle activity classifiers reported in the\nliterature. With a more systematic exploration of neural network classifier\narchitectures and hyper-parameters, there is potential for even further\nimprovements. Finally, we demonstrate that the time-frequency domain data\nrepresentation allows us to efficiently trade-off a large reduction of model\nsize and computational complexity for a very minor reduction in classification\naccuracy. This shows the potential for our classification approach to run on\nresource-constrained embedded and IoT devices.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 14:24:55 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Noorbin", "Seyedeh Faezeh Hosseini", ""], ["Layeghy", "Siamak", ""], ["Kusy", "Brano", ""], ["Jurdak", "Raja", ""], ["Bishop-hurley", "Greg", ""], ["Portmann", "Marius", ""]]}, {"id": "2011.03476", "submitter": "Daniel Park", "authors": "Daniel Park, Hannah Powers, Benji Prashker, Leland Liu and B\\\"ulent\n  Yener", "title": "Towards Obfuscated Malware Detection for Low Powered IoT Devices", "comments": "preprint. to appear at the International Conference on Machine\n  Learning Applications (ICMLA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased deployment of IoT and edge devices into commercial and\nuser networks, these devices have become a new threat vector for malware\nauthors. It is imperative to protect these devices as they become more\nprevalent in commercial and personal networks. However, due to their limited\ncomputational power and storage space, especially in the case of\nbattery-powered devices, it is infeasible to deploy state-of-the-art malware\ndetectors onto these systems. In this work, we propose using and extracting\nfeatures from Markov matrices constructed from opcode traces as a low cost\nfeature for unobfuscated and obfuscated malware detection. We empirically show\nthat our approach maintains a high detection rate while consuming less power\nthan similar work.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 17:10:26 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Park", "Daniel", ""], ["Powers", "Hannah", ""], ["Prashker", "Benji", ""], ["Liu", "Leland", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "2011.03615", "submitter": "Ekram Hossain", "authors": "Amal Feriani and Ekram Hossain", "title": "Single and Multi-Agent Deep Reinforcement Learning for AI-Enabled\n  Wireless Networks: A Tutorial", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has recently witnessed significant advances\nthat have led to multiple successes in solving sequential decision-making\nproblems in various domains, particularly in wireless communications. The\nfuture sixth-generation (6G) networks are expected to provide scalable,\nlow-latency, ultra-reliable services empowered by the application of\ndata-driven Artificial Intelligence (AI). The key enabling technologies of\nfuture 6G networks, such as intelligent meta-surfaces, aerial networks, and AI\nat the edge, involve more than one agent which motivates the importance of\nmulti-agent learning techniques. Furthermore, cooperation is central to\nestablishing self-organizing, self-sustaining, and decentralized networks. In\nthis context, this tutorial focuses on the role of DRL with an emphasis on deep\nMulti-Agent Reinforcement Learning (MARL) for AI-enabled 6G networks. The first\npart of this paper will present a clear overview of the mathematical frameworks\nfor single-agent RL and MARL. The main idea of this work is to motivate the\napplication of RL beyond the model-free perspective which was extensively\nadopted in recent years. Thus, we provide a selective description of RL\nalgorithms such as Model-Based RL (MBRL) and cooperative MARL and we highlight\ntheir potential applications in 6G wireless networks. Finally, we overview the\nstate-of-the-art of MARL in fields such as Mobile Edge Computing (MEC),\nUnmanned Aerial Vehicles (UAV) networks, and cell-free massive MIMO, and\nidentify promising future research directions. We expect this tutorial to\nstimulate more research endeavors to build scalable and decentralized systems\nbased on MARL.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 22:12:40 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Feriani", "Amal", ""], ["Hossain", "Ekram", ""]]}, {"id": "2011.03698", "submitter": "Kyuwon Han", "authors": "Kyuwon Han, Seung Min Yu, Seong-Lyun Kim, and Seung-Woo Ko", "title": "Exploiting User Mobility for WiFi RTT Positioning: A Geometric Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, round-trip time (RTT) measured by a fine-timing measurement\nprotocol has received great attention in the area of WiFi positioning. It\nprovides an acceptable ranging accuracy in favorable environments when a\nline-of-sight (LOS) path exists. Otherwise, a signal is detoured along with\nnon-LOS paths, making the resultant ranging results different from the\nground-truth, called an RTT bias, which is the main reason for poor positioning\nperformance. To address it, we aim at leveraging the user mobility trajectory\ndetected by a smartphone's inertial measurement units, called pedestrian dead\nreckoning (PDR). Specifically, PDR provides the geographic relation among\nadjacent locations, guiding the resultant positioning estimates' sequence not\nto deviate from the user trajectory. To this end, we describe their relations\nas multiple geometric equations, enabling us to render a novel positioning\nalgorithm with acceptable accuracy. Depending on the mobility pattern being\nlinear or arbitrary, we develop different algorithms divided into two phases.\nFirst, we can jointly estimate an RTT bias of each AP and the user's step\nlength by leveraging the geometric relation mentioned above. It enables us to\nconstruct a user's relative trajectory defined on the concerned AP's local\ncoordinate system. Second, we align every AP's relative trajectory into a\nsingle one, called trajectory alignment, equivalent to transformation to the\nglobal coordinate system. As a result, we can estimate the sequence of the\nuser's absolute locations from the aligned trajectory. Various field\nexperiments extensively verify the proposed algorithm's effectiveness that the\naverage positioning error is approximately 0.369 (m) and 1.705 (m) in LOS and\nNLOS environments, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 05:12:17 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 03:28:08 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Han", "Kyuwon", ""], ["Yu", "Seung Min", ""], ["Kim", "Seong-Lyun", ""], ["Ko", "Seung-Woo", ""]]}, {"id": "2011.03734", "submitter": "Sandra Lagen", "authors": "Sandra Lagen, Lorenza Giupponi, Andreas Hansson, Xavier Gelabert", "title": "Modulation Compression in Next Generation RAN: Air Interface and\n  Fronthaul trade-offs", "comments": "to appear in IEEE Commun. Mag", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modulation compression is a technique considered in the recent Open-RAN\n(O-RAN) framework, which has continued the 3GPP effort towards the definition\nof new virtualized and multi-vendor RAN architectures. Basically, fronthaul\ncompression is achieved by means of reducing the modulation order, thus\nenabling a dramatic reduction of the required fronthaul capacity with a simple\ntechnique. In this work, we provide a survey of the architectures, functional\nsplits, and fronthaul compression techniques envisioned in 3GPP and O-RAN.\nThen, we focus on assessing the trade-offs that modulation compression exhibits\nin terms of reduced fronthaul capacity versus the impact on the air interface\nperformance, through a dynamic multi-cell system-level simulation. For that, we\nuse an ns-3 based system-level simulator compliant with 5G New Radio (NR)\nspecifications and evaluate different traffic load conditions and NR\nnumerologies. In a multi-cell scenario, our results show that an 82% reduction\nof the required fronthaul capacity can be achieved with negligible air\ninterface performance degradation by reducing the modulation order down to\n64QAM, for different numerologies and load conditions. A higher modulation\norder reduction without degradation is permitted in low/medium traffic loads\n(reaching up to 94% fronthaul capacity reduction).\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:39:27 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Lagen", "Sandra", ""], ["Giupponi", "Lorenza", ""], ["Hansson", "Andreas", ""], ["Gelabert", "Xavier", ""]]}, {"id": "2011.03952", "submitter": "Mohamad Katanbaf", "authors": "Mohamad Katanbaf, Anthony Weinand, and Vamsi Talla", "title": "Simplifying Backscatter Deployment: Full-Duplex LoRa Backscatter", "comments": "This article has been accepted for publication in 18th USENIX\n  Symposium on Networked Systems Design and Implementation (NSDI '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the practical challenges in the deployment of existing half-duplex\nsystems, the promise of ubiquitous backscatter connectivity has eluded us. To\naddress this, we design the first long-range full-duplex LoRa backscatter\nreader. We leverage existing LoRa chipsets as transceivers and use a\nmicrocontroller in combination with inexpensive passive elements including a\nhybrid coupler, inductors, tunable capacitors, and resistors to achieve 78 dB\nof self-interference cancellation and build a low-cost, long-range, and\nsmall-form-factor Full-Duplex LoRa Backscatter reader.\n  We evaluate our system in various deployments and show that we can\nsuccessfully communicate with a backscatter tag at distances of up to 300 ft in\nline of sight, and through obstacles, such as walls and cubicles, in a 4,000\nft$^2$ office area. We reconfigure our reader to conform to the size and power\nrequirements of a smartphone, and demonstrate communication with a\ncontact-lens-form-factor prototype device. Finally, we attach our reader to a\ndrone and demonstrate backscatter sensing for precision agriculture with an\ninstantaneous coverage of 7,850 ft$^2$.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 10:53:02 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Katanbaf", "Mohamad", ""], ["Weinand", "Anthony", ""], ["Talla", "Vamsi", ""]]}, {"id": "2011.04105", "submitter": "Puneet Kumar", "authors": "Puneet Kumar", "title": "Evolution of Artificial Intelligent Plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of the internet, it is becoming hard to manage, configure and\nmonitor networks. Recent trends to control and operate them is artificial\nintelligence based automation to minimize human intervention. Albeit this\nconcept has been introduced since a decade with several different names, but\nthe underlying goal remains the same, which is to make network intelligent\nenough to assemble, reassemble if configuration changes, and detect a problem\non its own and fix it. As a result, in addition to Data Plane, Control Plane\nand Management Plane, a new plane called Artificial Intelligence (AI) Plane is\nintroduced. Our main objective is to analyze all major AI plane techniques,\nframeworks and algorithms proposed in various types of networks. We propose a\ncomprehensive and network independent framework to cover all aspects of AI\nplane, in particular we provide a systematically means of comparison. In\nconjunction to make AI plane understand simpler, this framework highlights\nrelevant challenges and design considerations for future research. To the best\nof our knowledge this is the first survey report which represents a complete\ncomparison of AI planes with their investigation issues in several types of\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 23:33:12 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Kumar", "Puneet", ""]]}, {"id": "2011.04178", "submitter": "Mostafa Hussien", "authors": "Mostafa Hussien, Kim Khoa Nguyen, Mohamed Cheriet", "title": "PRVNet: Variational Autoencoders for Massive MIMO CSI Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a frequency division duplexing multiple-input multiple-output (FDD-MIMO)\nsystem, the user equipment (UE) send the downlink channel state information\n(CSI) to the base station for performance improvement. However, with the\ngrowing complexity of MIMO systems, this feedback becomes expensive and has a\nnegative impact on the bandwidth. Although this problem has been largely\nstudied in the literature, the noisy nature of the feedback channel is less\nconsidered. In this paper, we introduce PRVNet, a neural architecture based on\nvariational autoencoders (VAE). VAE gained large attention in many fields\n(e.g., image processing, language models, or recommendation system). However,\nit received less attention in the communication domain generally and in CSI\nfeedback problem specifically. We also introduce a different regularization\nparameter for the learning objective, which proved to be crucial for achieving\ncompetitive performance. In addition, we provide an efficient way to tune this\nparameter using KL-annealing. Empirically, we show that the proposed model\nsignificantly outperforms state-of-the-art, including two neural network\napproaches. The proposed model is also proved to be more robust against\ndifferent levels of noise.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:07:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hussien", "Mostafa", ""], ["Nguyen", "Kim Khoa", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "2011.04339", "submitter": "Wen Wang", "authors": "Wen Wang, Hui Tian, Wanli Ni, and Meihui Hua", "title": "Intelligent Reflecting Surface Aided Secure UAV Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we study the secure communication problem in the unmanned\naerial vehicle (UAV) enabled networks aided by an intelligent reflecting\nsurface (IRS) from the physical-layer security perspective.\n  Specifically, the IRS is deployed to assist the wireless transmission from\nthe UAV to the ground user in the presence of an eavesdropper.\n  The objective of this work is to maximize the secrecy rate by jointly\noptimizing the phase shifts at the IRS as well as the transmit power and\nlocation of the UAV.\n  However, the formulated problem is difficult to solve directly due to the\nnon-linear and non-convex objective function and constraints.\n  By invoking fractional programming and successive convex approximation\ntechniques, the original problem is decomposed into three subproblems, which\nare then transformed into convex ones. Next, a low-complexity alternating\nalgorithm is proposed to solve the challenging non-convex problem effectively,\nwhere the closed-form expressions for transmit power and phase shifts are\nobtained at each iteration.\n  Simulations results demonstrate that the designed algorithm for IRS-aided UAV\ncommunications can achieve higher secrecy rate than benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 11:06:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wang", "Wen", ""], ["Tian", "Hui", ""], ["Ni", "Wanli", ""], ["Hua", "Meihui", ""]]}, {"id": "2011.04407", "submitter": "Taqwa Saeed", "authors": "Taqwa Saeed, Vassos Soteriou, Christos Liaskos, Andreas Pitsillides\n  and Marios Lestas", "title": "Toward Fault-Tolerant Deadlock-Free Routing in HyperSurface-Embedded\n  Controller Networks", "comments": null, "journal-ref": "IEEE Networking Letters, vol 2, 140--144, year 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HyperSurfaces (HSFs) consist of structurally reconfigurable metasurfaces\nwhose electromagnetic properties can be changed via a software interface, using\nan embedded miniaturized network of controllers. With the HSF controllers,\ninterconnected in an irregular, near-Manhattan geometry, we propose a robust,\ndeterministic Fault-Tolerant (FT), deadlock- and livelock-free routing protocol\nwhere faults are contained in a set of disjointed rectangular regions called\nfaulty blocks. The proposed FT protocol can support an unbounded number of\nfaulty nodes as long as nodes outside the faulty blocks are connected.\nSimulation results show the efficacy of the proposed FT protocol under various\nfaulty node distribution scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 13:24:40 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Saeed", "Taqwa", ""], ["Soteriou", "Vassos", ""], ["Liaskos", "Christos", ""], ["Pitsillides", "Andreas", ""], ["Lestas", "Marios", ""]]}, {"id": "2011.04448", "submitter": "Emmanouil Fountoulakis", "authors": "Emmanouil Fountoulakis, Nikolaos Pappas, Anthony Ephremides", "title": "Dynamic Power Control for Time-Critical Networking with Heterogeneous\n  Traffic", "comments": "Submitted in a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future wireless networks will be characterized by heterogeneous traffic\nrequirements. Such requirements can be low-latency or minimum-throughput.\nTherefore, the network has to adjust to different needs. Usually, users with\nlow-latency requirements have to deliver their demand within a specific time\nframe, i.e., before a deadline, and they co-exist with throughput oriented\nusers. In addition, the users are mobile and they share the same wireless\nchannel. Therefore, they have to adjust their power transmission to achieve\nreliable communication. However, due to the limited power budget of wireless\nmobile devices, a power-efficient scheduling scheme is required by the network.\nIn this work, we cast a stochastic network optimization problem for minimizing\nthe packet drop rate while guaranteeing a minimum throughput and taking into\naccount the limited-power capabilities of the users. We apply tools from\nLyapunov optimization theory in order to provide an algorithm, named Dynamic\nPower Control (DPC) algorithm, that solves the formulated problem in realtime.\nIt is proved that the DPC algorithm gives a solution arbitrarily close to the\noptimal one. Simulation results show that our algorithm outperforms the\nbaseline Largest-Debt-First (LDF) algorithm for short deadlines and multiple\nusers.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 14:15:25 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Fountoulakis", "Emmanouil", ""], ["Pappas", "Nikolaos", ""], ["Ephremides", "Anthony", ""]]}, {"id": "2011.04607", "submitter": "Yu Chen", "authors": "Yu Chen, Jie Chen, Ganesh Krishnamurthi, Huijing Yang, Huahui Wang,\n  Wenjie Zhao", "title": "Deep reinforcement learning for RAN optimization and control", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the high variability of the traffic in the radio access network (RAN),\nfixed network configurations are not flexible enough to achieve optimal\nperformance. Our vendors provide several settings of the eNodeB to optimize the\nRAN performance, such as media access control scheduler, loading balance, etc.\nBut the detailed mechanisms of the eNodeB configurations are usually very\ncomplicated and not disclosed, not to mention the large key performance\nindicators (KPIs) space needed to be considered. These make constructing a\nsimulator, offline tuning, or rule-based solutions difficult. We aim to build\nan intelligent controller without strong assumption or domain knowledge about\nthe RAN and can run 24/7 without supervision. To achieve this goal, we first\nbuild a closed-loop control testbed RAN in a lab environment with one eNodeB\nprovided by one of the largest wireless vendors and four smartphones. Next, we\nbuild a double Q network agent trained with the live feedback of the key\nperformance indicators from the RAN. Our work proved the effectiveness of\napplying deep reinforcement learning to improve network performance in a real\nRAN network environment.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 18:02:52 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 16:47:01 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Chen", "Yu", ""], ["Chen", "Jie", ""], ["Krishnamurthi", "Ganesh", ""], ["Yang", "Huijing", ""], ["Wang", "Huahui", ""], ["Zhao", "Wenjie", ""]]}, {"id": "2011.04608", "submitter": "Ararat Shaverdian", "authors": "Ararat Shaverdian, Shahram Shahsavari, and Catherine Rosenberg", "title": "A General Framework for Airplane Air-to-Ground Communications in mmWave\n  and Microwave Bands", "comments": "38 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airplane sensors and on-board equipment collect an increasingly large amount\nof maintenance data during flights that are used for airplane maintenance. We\npropose to download part of the data during airplane's descent via a cellular\nbase station (BS) located at the airport. We formulate and solve an offline\noptimization problem to quantify how much data can be offloaded in a\nnon-dedicated band while ensuring that the interference at the terrestrial BSs\nin the vicinity of the airport remains below a maximum allowable threshold. Our\nproblem allows for adaptive tuning of transmit power, number of frequency\nchannels to be used, and beamforming according to the position of the plane on\nthe descent path. Our results show that during the last 5 minutes of descent,\nin the microwave band the plane can offload up to 5 GB of maintenance data in a\n20~MHz band, while in the mmWave band the plane can offload up to 24 times more\ndata in a 1~GHz band. Beamforming, power and bandwidth tuning are all crucial\nin maintaining a good performance in the mmWave band while in the microwave\nband, dynamic tuning of bandwidth does not improve the performance much.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 18:03:12 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Shaverdian", "Ararat", ""], ["Shahsavari", "Shahram", ""], ["Rosenberg", "Catherine", ""]]}, {"id": "2011.04877", "submitter": "Danshi Wang", "authors": "Danshi Wang, Zhiguo Zhang, Min Zhang, Meixia Fu, Jin Li, Shanyong Cai,\n  Chunyu Zhang, and Xue Chen", "title": "Role of Digital Twin in Optical Communication: Fault Management,\n  Hardware Configuration, and Transmission Simulation", "comments": "Accepted by IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical communication is developing rapidly in the directions of hardware\nresource diversification, transmission system flexibility, and network function\nvirtualization. Its proliferation poses a significant challenge to traditional\noptical communication management and control systems. Digital twin (DT), a\ntechnology that utilizes data, models, and algorithms and integrates multiple\ndisciplines, acts as a bridge between the real and virtual worlds for\ncomprehensive connectivity. In the digital space, virtual models are stablished\ndynamically to simulate and describe the states, behaviors, and rules of\nphysical objects in the physical space. DT has been significantly developed and\nwidely applied in industrial and military fields. This study introduces the DT\ntechnology to optical communication through interdisciplinary crossing and\nproposes a DT framework suitable for optical communication. The intelligent\nfault management model, flexible hardware configuration model, and dynamic\ntransmission simulation model are established in the digital space with the\nhelp of deep learning algorithms to ensure the highreliability operation and\nhigh-efficiency management of optical communication systems and networks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 03:55:33 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Danshi", ""], ["Zhang", "Zhiguo", ""], ["Zhang", "Min", ""], ["Fu", "Meixia", ""], ["Li", "Jin", ""], ["Cai", "Shanyong", ""], ["Zhang", "Chunyu", ""], ["Chen", "Xue", ""]]}, {"id": "2011.04902", "submitter": "Maxwell Young", "authors": "William C. Anderton and Trisha Chakraborty and Maxwell Young", "title": "Windowed Backoff Algorithms for WiFi: Theory and Performance under\n  Batched Arrivals", "comments": "arXiv admin note: substantial text overlap with arXiv:1705.09271", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary exponential backoff (BEB) is a decades-old algorithm for coordinating\naccess to a shared channel. In modern networks, BEB plays an important role in\nWiFi (IEEE 802.11) and other wireless communication standards.\n  Despite this track record, well-known theoretical results indicate that under\nbursty traffic BEB yields poor makespan, and superior algorithms are possible.\nTo date, the degree to which these findings impact performance in wireless\nnetworks has not been examined.\n  To address this issue, we investigate one of the strongest cases against BEB:\na single burst batch of packets that simultaneously contend for access to a\nwireless channel. Using Network Simulator 3, we incorporate into IEEE 802.11g\nseveral newer algorithms that, while inspired by BEB, possess makespan\nguarantees that are theoretically superior. Surprisingly, we discover that\nthese newer algorithms underperform BEB.\n  Investigating further, we identify as the culprit a common abstraction\nregarding the cost of collisions. Our experimental results are complemented by\nanalytical arguments that the number of collisions - and not solely makespan -\nis an important metric to optimize. We argue that these findings have\nimplications for the design of backoff algorithms in wireless networks.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 22:57:08 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 16:57:49 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Anderton", "William C.", ""], ["Chakraborty", "Trisha", ""], ["Young", "Maxwell", ""]]}, {"id": "2011.05045", "submitter": "Mattia Lecci", "authors": "Mattia Lecci, Matteo Drago, Andrea Zanella, Michele Zorzi", "title": "Exploiting Scheduled Access Features of mmWave WLANs for Periodic\n  Traffic Sources", "comments": "8 pages, 6 figures, 2 algorithms. This paper was submitted to IEEE\n  MedComNet 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current and future multimedia and industrial applications, like video\nstreaming, eXtended Reality or remote robot control, are characterized by\nperiodic data transmissions with strict latency and reliability constraints. In\nan effort to meet the stringent demand of such traffic sources, the WiGig\nstandards support a contention-free channel access mechanism, named Service\nPeriod, that makes it possible to allocate dedicated time intervals to certain\nwireless stations. However, the standard only covers the fundamental aspects\nthat ensure interoperability, while the actual schedule logic is left to\nvendors. In this paper, we propose two algorithms for joint admission control\nand scheduling of periodic traffic streams with contrasting performance\nobjectives, specifically a simple scheduler and a max-min fair scheduler. The\nschemes are compared in two different scenarios, in order to characterize and\nhighlight some fundamental trade-offs. As expected from their design\nprinciples, the simple scheduler tends to trade acceptance rate for resource\navailability, contrary to the max-min fair scheduler, giving to implementers a\nclear performance trade-off, although performance cannot be balanced by means\nof a tunable parameter.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 11:14:22 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 11:05:05 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Lecci", "Mattia", ""], ["Drago", "Matteo", ""], ["Zanella", "Andrea", ""], ["Zorzi", "Michele", ""]]}, {"id": "2011.05163", "submitter": "Sandeep Dsouza", "authors": "Sandeep Dsouza, Victor Bahl, Lixiang Ao and Landon P. Cox", "title": "Amadeus: Scalable, Privacy-Preserving Live Video Analytics", "comments": "17 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart-city applications ranging from traffic management to public-safety\nalerts rely on live analytics of video from surveillance cameras in public\nspaces. However, a growing number of government regulations stipulate how data\ncollected from these cameras must be handled in order to protect citizens'\nprivacy. This paper describes Amadeus, which balances privacy and utility by\nredacting video in near realtime for smart-city applications. Our main insight\nis that whitelisting objects, or blocking by default, is crucial for scalable,\nprivacy-preserving video analytics. In the context of modern object detectors,\nwe prove that whitelisting reduces the risk of an object-detection error\nleading to a privacy violation, and helps Amadeus scale to a large and diverse\nset of applications. In particular, Amadeus utilizes whitelisting to generate\ncomposable encrypted object-specific live streams, which simultaneously meet\nthe requirements of multiple applications in a privacy-preserving fashion,\nwhile reducing the compute and streaming-bandwidth requirements at the edge.\nExperiments with our Amadeus prototype show that compared to blacklisting\nobjects, whitelisting yields significantly better privacy (up to ~28x) and\nbandwidth savings (up to ~5.5x). Additionally, our experiments also indicate\nthat the composable live streams generated by Amadeus are usable by real-world\napplications with minimum utility loss.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 05:28:31 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Dsouza", "Sandeep", ""], ["Bahl", "Victor", ""], ["Ao", "Lixiang", ""], ["Cox", "Landon P.", ""]]}, {"id": "2011.05191", "submitter": "Jean-Romain Luttringer", "authors": "Jean-Romain Luttringer (UNISTRA), Thomas Alfroy (UNISTRA), Pascal\n  M\\'erindol (UNISTRA), Quentin Bramas (UNISTRA), Fran\\c{c}ois Clad, Cristel\n  Pelsser (UNISTRA)", "title": "Computing Delay-Constrained Least-Cost Paths for Segment Routing is\n  Easier Than You Think", "comments": null, "journal-ref": "IEEE International Symposium on Network Computing and\n  Applications, Nov 2020, On-Line, France", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of demands for quasi-instantaneous communication services\nsuch as real-time video streaming, cloud gaming, and industry 4.0 applications,\nmulti-constraint Traffic Engineering (TE) becomes increasingly important. While\nlegacy TE management planes have proven laborious to deploy, Segment Routing\n(SR) drastically eases the deployment of TE paths and thus became the most\nappropriate technology for many operators. The flexibility of SR sparked\ndemands in ways to compute more elaborate paths. In particular, there exists a\nclear need in computing and deploying Delay-Constrained Least-Cost paths (DCLC)\nfor real-time applications requiring both low delay and high bandwidth routes.\nHowever, most current DCLC solutions are heuristics not specifically tailored\nfor SR. In this work, we leverage both inherent limitations in the accuracy of\ndelay measurements and an operational constraint added by SR. We include these\ncharacteristics in the design of BEST2COP, an exact but efficient ECMP-aware\nalgorithm that natively solves DCLC in SR domains. Through an extensive\nperformance evaluation, we first show that BEST2COP scales well even in large\nrandom networks. In real networks having up to thousands of destinations, our\nalgorithm returns all DCLC solutions encoded as SR paths in way less than a\nsecond.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:45:10 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Luttringer", "Jean-Romain", "", "UNISTRA"], ["Alfroy", "Thomas", "", "UNISTRA"], ["M\u00e9rindol", "Pascal", "", "UNISTRA"], ["Bramas", "Quentin", "", "UNISTRA"], ["Clad", "Fran\u00e7ois", "", "UNISTRA"], ["Pelsser", "Cristel", "", "UNISTRA"]]}, {"id": "2011.05202", "submitter": "Israel Leyva-Mayorga", "authors": "Beatriz Soret, Israel Leyva-Mayorga, Stefano Cioni, and Petar Popovski", "title": "5G satellite networks for IoT: offloading and backhauling", "comments": "Submitted for publication to the International Journal of Satellite\n  Communications and Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main drivers of 5G cellular networks is provision of connectivity\nservice for various Internet of Things (IoT) devices. Considering the potential\nvolume of IoT devices at a global scale, the next leap is to integrate\nNon-Terrestrial Networks (NTN) into 5G terrestrial systems, thereby extend the\ncoverage and complement the terrestrial service. This paper focuses on the use\nof Low-Earth Orbit (LEO) satellite constellations for two specific purposes:\noffloading and backhauling. The former allows offloading IoT traffic from a\ncongested terrestrial network, usually in a very dense area. In the latter\napplication, the constellation provides a multi-hop backhaul that connects a\nremote terrestrial gNB to the 5G core network. After providing an overview of\nthe status of the 3GPP standardization process, we model and analyze the user\ndata performance, specifically in the uplink access and the satellite multi-hop\nconstellation path. The evaluation of the collisions, the delay and the Age of\nInformation, and the comparison of the terrestrial and the satellite access\nnetworks provide useful insights to understand the potential of LEO\nconstellations for offloading and backhauling of IoT traffic.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:56:33 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Soret", "Beatriz", ""], ["Leyva-Mayorga", "Israel", ""], ["Cioni", "Stefano", ""], ["Popovski", "Petar", ""]]}, {"id": "2011.05219", "submitter": "Micha{\\l} Gajda", "authors": "Micha{\\l} J. Gajda", "title": "Curious properties of latency distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network latency distributions, their algebra, and use examples. This paper\nconsiders modeling of capacity-insensitive processes and distributed systems.\nIt provides algebraic properties of the latency distribution algebra and\nHaskell code to implement the model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 20:49:16 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Gajda", "Micha\u0142 J.", ""]]}, {"id": "2011.05267", "submitter": "Chaoyun Zhang", "authors": "Chaoyun Zhang", "title": "Deep Neural Mobile Networking", "comments": "PhD thesis, University of Edinburgh (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next generation of mobile networks is set to become increasingly complex,\nas these struggle to accommodate tremendous data traffic demands generated by\never-more connected devices that have diverse performance requirements in terms\nof throughput, latency, and reliability. This makes monitoring and managing the\nmultitude of network elements intractable with existing tools and impractical\nfor traditional machine learning algorithms that rely on hand-crafted feature\nengineering. In this context, embedding machine intelligence into mobile\nnetworks becomes necessary, as this enables systematic mining of valuable\ninformation from mobile big data and automatically uncovering correlations that\nwould otherwise have been too difficult to extract by human experts. In\nparticular, deep learning based solutions can automatically extract features\nfrom raw data, without human expertise. The performance of artificial\nintelligence (AI) has achieved in other domains draws unprecedented interest\nfrom both academia and industry in employing deep learning approaches to\naddress technical challenges in mobile networks. This thesis attacks important\nproblems in the mobile networking area from various perspectives by harnessing\nrecent advances in deep neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 09:23:36 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhang", "Chaoyun", ""]]}, {"id": "2011.05624", "submitter": "Qianru Zhou", "authors": "Qianru Zhou, Alasdair J. G. Gray, Dimitrios Pezaros, Stephen\n  McLaughlin", "title": "SARA -- A Semantic Access Point Resource Allocation Service for\n  Heterogenous Wireless Networks", "comments": "2019 IEEE Wireless Day", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we present SARA, a Semantic Access point Resource Allocation\nservice for heterogenous wireless networks with various wireless access\ntechnologies existing together. By automatically reasoning on the knowledge\nbase of the full system provided by a knowledge based autonomic network\nmanagement system -- SEANET, SARA selects the access point providing the best\nquality of service among the different access technologies. Based on an\nontology assisted knowledge based system SEANET, SARA can also adapt the access\npoint selection strategy according to customer defined rules automatically.\nResults of our evaluation based on emulated networks with hybrid access\ntechnologies and various scales show that SARA is able to improve the channel\ncondition, in terms of throughput, evidently. Comparisons with current AP\nselection algorithms demonstrate that SARA outperforms the existing AP\nselection algorithms. The overhead in terms of time expense is reasonable and\nis shown to be faster than traditional access point selection approaches.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 08:32:12 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Zhou", "Qianru", ""], ["Gray", "Alasdair J. G.", ""], ["Pezaros", "Dimitrios", ""], ["McLaughlin", "Stephen", ""]]}, {"id": "2011.05708", "submitter": "Zehong Lin", "authors": "Zehong Lin, Suzhi Bi, Ying-Jun Angela Zhang", "title": "Optimizing AI Service Placement and Resource Allocation in Mobile Edge\n  Intelligence Systems", "comments": "The paper has been accepted for publication by IEEE Transactions on\n  Wireless Communications (May 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging recent advances on mobile edge computing (MEC), edge intelligence\nhas emerged as a promising paradigm to support mobile artificial intelligence\n(AI) applications at the network edge. In this paper, we consider the AI\nservice placement problem in a multi-user MEC system, where the access point\n(AP) places the most up-to-date AI program at user devices to enable local\ncomputing/task execution at the user side. To fully utilize the stringent\nwireless spectrum and edge computing resources, the AP sends the AI service\nprogram to a user only when enabling local computing at the user yields a\nbetter system performance. We formulate a mixed-integer non-linear programming\n(MINLP) problem to minimize the total computation time and energy consumption\nof all users by jointly optimizing the service placement (i.e., which users to\nreceive the program) and resource allocation (on local CPU frequencies, uplink\nbandwidth, and edge CPU frequency). To tackle the MINLP problem, we derive\nanalytical expressions to calculate the optimal resource allocation decisions\nwith low complexity. This allows us to efficiently obtain the optimal service\nplacement solution by search-based algorithms such as meta-heuristic or greedy\nsearch algorithms. To enhance the algorithm scalability in large-sized\nnetworks, we further propose an ADMM (alternating direction method of\nmultipliers) based method to decompose the optimization problem into parallel\ntractable MINLP subproblems. The ADMM method eliminates the need of searching\nin a high-dimensional space for service placement decisions and thus has a low\ncomputational complexity that grows linearly with the number of users.\nSimulation results show that the proposed algorithms perform extremely close to\nthe optimum and significantly outperform the other representative benchmark\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:23:13 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 03:57:30 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2021 12:00:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lin", "Zehong", ""], ["Bi", "Suzhi", ""], ["Zhang", "Ying-Jun Angela", ""]]}, {"id": "2011.05925", "submitter": "Saurabh Bagchi", "authors": "Shikhar Suryavansh, Chandan Bothra, Kwang Taik Kim, Mung Chiang,\n  Chunyi Peng, Saurabh Bagchi", "title": "I-BOT: Interference-Based Orchestration of Tasks for Dynamic Unmanaged\n  Edge Computing", "comments": "14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, edge computing has become a popular choice for\nlatency-sensitive applications like facial recognition and augmented reality\nbecause it is closer to the end users compared to the cloud. Although\ninfrastructure providers are working toward creating managed edge networks,\npersonal devices such as laptops and tablets, which are widely available and\nare underutilized, can also be used as potential edge devices. We call such\ndevices Unmanaged Edge Devices (UEDs). Scheduling application tasks on such an\nunmanaged edge system is not straightforward because of three fundamental\nreasons-heterogeneity in the computational capacity of the UEDs, uncertainty in\nthe availability of the UEDs (due to devices leaving the system), and\ninterference among multiple tasks sharing a UED. In this paper, we present\nI-BOT, an interference-based orchestration scheme for latency-sensitive tasks\non an Unmanaged Edge Platform (UEP). It minimizes the completion time of\napplications and is bandwidth efficient. I-BOT brings forth three innovations.\nFirst, it profiles and predicts the interference patterns of the tasks to make\nscheduling decisions. Second, it uses a feedback mechanism to adjust for\nchanges in the computational capacity of the UEDs and a prediction mechanism to\nhandle their sporadic exits. Third, it accounts for input dependence of tasks\nin its scheduling decision (such as, two tasks requiring the same input data).\nTo evaluate I-BOT, we run end-to-end simulations with applications representing\nautonomous driving, composed of multiple tasks. We compare to two basic\nbaselines (random and round-robin) and two state-of-the-arts, Lavea [SEC-2017]\nand Petrel [MSN-2018]. Compared to these baselines, I-BOT significantly reduces\nthe average service time of application tasks. This reduction is more\npronounced in dynamic heterogeneous environments, which would be the case in a\nUEP.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:34:18 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Suryavansh", "Shikhar", ""], ["Bothra", "Chandan", ""], ["Kim", "Kwang Taik", ""], ["Chiang", "Mung", ""], ["Peng", "Chunyi", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "2011.05935", "submitter": "S.M. Riazul Islam PhD", "authors": "Lewis Nkenyereye, S. M. Riazul Islam, Mahmud Hossain, M.\n  Abdullah-Al-Wadud, and Atif Alamri", "title": "Blockchain-Enabled EHR Framework for Internet of Medical Things", "comments": "9 pages (CMC Journal, Tech Science Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Medical Things (IoMT) offers an infrastructure made of smart\nmedical equipment and software applications for health services. Through the\ninternet, the IoMT is capable of providing remote medical diagnosis and timely\nhealth services. The patients can use their smart devices to create, store and\nshare their electronic health records (EHR) with a variety of medical personnel\nincluding medical doctors and nurses. However, unless the underlying\ncombination within IoMT is secured, malicious users can intercept, modify and\neven delete the sensitive EHR data of patients. Patients also lose full control\nof their EHR since most health services within IoMT are constructed under a\ncentralized platform outsourced in the cloud. Therefore, it is appealing to\ndesign a decentralized, auditable and secure EHR system that guarantees\nabsolute access control for the patients while ensuring privacy and security.\nUsing the features of blockchain including decentralization, auditability and\nimmutability, we propose a secure EHR framework which is mainly maintained by\nthe medical centers. In this framework, the patients' EHR data are encrypted\nand stored in the servers of medical institutions while the corresponding hash\nvalues are kept on the blockchain. We make use of security primitives to offer\nauthentication, integrity and confidentiality of EHR data while access control\nand immutability is guaranteed by the blockchain technology. The security\nanalysis and performance evaluation of the proposed framework confirms its\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:50:03 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Nkenyereye", "Lewis", ""], ["Islam", "S. M. Riazul", ""], ["Hossain", "Mahmud", ""], ["Abdullah-Al-Wadud", "M.", ""], ["Alamri", "Atif", ""]]}, {"id": "2011.05948", "submitter": "Ryan Doenges", "authors": "Ryan Doenges, Mina Tahmasbi Arashloo, Santiago Bautista, Alexander\n  Chang, Newton Ni, Samwise Parkinson, Rudy Peterson, Alaia Solko-Breslin,\n  Amanda Xu, Nate Foster", "title": "Petr4: Formal Foundations for P4 Data Planes", "comments": "54 pages. Extended version of POPL 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  P4 is a domain-specific language for programming and specifying\npacket-processing systems. It is based on an elegant design with high-level\nabstractions like parsers and match-action pipelines that can be compiled to\nefficient implementations in software or hardware. Unfortunately, like many\nindustrial languages, P4 has developed without a formal foundation. The P4\nLanguage Specification is a 160-page document with a mixture of informal prose,\ngraphical diagrams, and pseudocode. The P4 reference implementation is a\ncomplex system, running to over 40KLoC of C++ code. Clearly neither of these\nartifacts is suitable for formal reasoning.\n  This paper presents a new framework, called Petr4, that puts P4 on a solid\nfoundation. Petr4 consists of a clean-slate definitional interpreter and a\ncalculus that models the semantics of a core fragment of P4. Throughout the\nspecification, some aspects of program behavior are left up to targets. Our\ninterpreter is parameterized over a target interface which collects all the\ntarget-specific behavior in the specification in a single interface.\n  The specification makes ad-hoc restrictions on the nesting of certain program\nconstructs in order to simplify compilation and avoid the possibility of\nnonterminating programs. We captured the latter intention in our core calculus\nby stratifying its type system, rather than imposing unnatural syntactic\nrestrictions, and we proved that all programs in this core calculus terminate.\n  We have validated the interpreter against a suite of over 750 tests from the\nP4 reference implementation, exercising our target interface with tests for\ndifferent targets. We established termination for the core calculus by\ninduction on the stratified type system. While developing Petr4, we reported\ndozens of bugs in the language specification and the reference implementation,\nmany of which have been fixed.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:09:52 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Doenges", "Ryan", ""], ["Arashloo", "Mina Tahmasbi", ""], ["Bautista", "Santiago", ""], ["Chang", "Alexander", ""], ["Ni", "Newton", ""], ["Parkinson", "Samwise", ""], ["Peterson", "Rudy", ""], ["Solko-Breslin", "Alaia", ""], ["Xu", "Amanda", ""], ["Foster", "Nate", ""]]}, {"id": "2011.05950", "submitter": "Eugenio Moro", "authors": "Eugenio Moro and Ilario Filippini", "title": "Joint Management of Compute and Radio Resources in Mobile Edge\n  Computing: a Market Equilibrium Approach", "comments": "Corrected typos and figure orientation. in IEEE Transactions on\n  Mobile Computing", "journal-ref": null, "doi": "10.1109/TMC.2021.3091764", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing has been recently introduced as a way to bring computational\ncapabilities closer to end users of modern network-based services, in order to\nsupport existent and future delay-sensitive applications by effectively\naddressing the high propagation delay issue that affects cloud computing.\nHowever, the problem of efficiently and fairly manage the system resources\npresents particular challenges due to the limited capacity of both edge nodes\nand wireless access networks, as well as the heterogeneity of resources and\nservices' requirements. To this end, we propose a techno-economic market where\nservice providers act as buyers, securing both radio and computing resources\nfor the execution of their associated end users' jobs, while being constrained\nby a budget limit. We design an allocation mechanism that employs convex\nprogramming in order to find the unique market equilibrium point that maximizes\nfairness, while making sure that all buyers receive their preferred resource\nbundle. Additionally, we derive theoretical properties that confirm how the\nmarket equilibrium approach strikes a balance between fairness and efficiency.\nWe also propose alternative allocation mechanisms and give a comparison with\nthe market-based mechanism. Finally, we conduct simulations in order to\nnumerically analyze and compare the performance of the mechanisms and confirm\nthe theoretical properties of the market model.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:14:09 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 08:23:00 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Moro", "Eugenio", ""], ["Filippini", "Ilario", ""]]}, {"id": "2011.06059", "submitter": "Luis Sequeira Dr", "authors": "Luis Sequeira, Julian Fernandez-Navajas, Jose Saldana and Luis\n  Casadesus", "title": "Empirically Characterizing the Buffer Behaviour of Real Devices", "comments": null, "journal-ref": "Proc. International Symposium on Performance Evaluation of\n  Computer and Telecommunication Systems SPECTS 2012, July 8-11, 2012, Genoa,\n  Italy. ISBN: 978-1-4673-2235-5", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All the routers include a buffer in order to enqueue packets waiting to be\ntransmitted. The behaviour of the routers' buffer is of primary importance when\nstudying network traffic, since it may modify some characteristics, as delay or\njitter, and may also drop packets. As a consequence, the characterization of\nthis buffer is interesting, especially when real-time flows are being\ntransmitted: if the buffer characteristics are known, then different techniques\ncan be used so as to adapt the traffic: multiplexing a number of small packets\ninto a big one, fragmentation, etc. This work presents a preliminary study of\nhow to determine the technical and functional characteristics of the buffer of\na certain device (as e.g. behaviour, size, limits, input and output rate), or\neven in a remote Internet network node. Two different methodologies are\nconsidered, and tested on two real scenarios which have been implemented; real\nmeasurements permit the estimation of the buffer size, and the input and output\nrates, when there is physical or remote access to the \"System Under Test\". In\ncase of having physical access, the maximum number of packets in the queue can\nbe determined by counting. In contrast, if the node is remote, its buffer size\nhas to be estimated. We have obtained accurate results in wired and wireless\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 20:31:44 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Sequeira", "Luis", ""], ["Fernandez-Navajas", "Julian", ""], ["Saldana", "Jose", ""], ["Casadesus", "Luis", ""]]}, {"id": "2011.06134", "submitter": "Nam Chu", "authors": "Nam H. Chu, Dinh Thai Hoang, Diep N. Nguyen, Nguyen Van Huynh, and\n  Eryk Dutkiewicz", "title": "Fast or Slow: An Autonomous Speed Control Approach for UAV-assisted IoT\n  Data Collection Networks", "comments": null, "journal-ref": null, "doi": "10.1109/WCNC49053.2021.9417563", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) have been emerging as an effective solution\nfor IoT data collection networks thanks to their outstanding flexibility,\nmobility, and low operation costs. However, due to the limited energy and\nuncertainty from the data collection process, speed control is one of the most\nimportant factors to optimize the energy usage efficiency and performance for\nUAV collectors. This work aims to develop a novel autonomous speed control\napproach to address this issue. To that end, we first formulate the dynamic\nspeed control task of a UAV as a Markov decision process taking into account\nits energy status and location. In this way, the Q-learning algorithm can be\nadopted to obtain the optimal speed control policy for the UAV. To further\nimprove the system performance, we develop an highly-effective deep dueling\ndouble Q-learning algorithm utilizing outstanding features of the deep neural\nnetworks as well as advanced dueling architecture to quickly stabilize the\nlearning process and obtain the optimal policy. Through simulation results, we\nshow that our proposed solution can achieve up to 40% greater performance\ncompared with other conventional methods. Importantly, the simulation results\nalso reveal significant impacts of UAV's energy and charging time on the system\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 00:38:36 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chu", "Nam H.", ""], ["Hoang", "Dinh Thai", ""], ["Nguyen", "Diep N.", ""], ["Van Huynh", "Nguyen", ""], ["Dutkiewicz", "Eryk", ""]]}, {"id": "2011.06257", "submitter": "Teik Guan Tan", "authors": "Teik Guan Tan and Pawel Szalachowski and Jianying Zhou", "title": "Securing Password Authentication for Web-based Applications", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of passwords and the need to protect passwords are not going away.\nThe majority of websites that require authentication continue to support\npassword authentication. Even high-security applications such as Internet\nBanking portals, which deploy 2-factor authentication, rely on password\nauthentication as one of the authentication factors. However phishing attacks\ncontinue to plague password-based authentication despite aggressive efforts in\ndetection and takedown as well as comprehensive user awareness and training\nprograms.\n  There is currently no foolproof mechanism even for security-conscious\nwebsites to prevent users from being directed to fraudulent websites and having\ntheir passwords phished. In this paper, we apply a threat analysis on the web\npassword login process, and uncover a design vulnerability in the\nHTML<inputtype=\"password\"> field. This vulnerability can be exploited for\nphishing attacks as the web authentication process is not end-to-end secured\nfrom each input password field to the web server. We identify four properties\nthat encapsulate the requirements to stop web-based password phishing, and\npropose a secure protocol to be used with a new credential field that complies\nwith the four properties. We further analyze the proposed protocol through an\nabuse-case evaluation, discuss various deployment issues, and also perform a\ntest implementation to understand its data and execution overheads\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 08:30:42 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Tan", "Teik Guan", ""], ["Szalachowski", "Pawel", ""], ["Zhou", "Jianying", ""]]}, {"id": "2011.06304", "submitter": "Mahdi Jafari Siavoshani", "authors": "Mahdi Jafari Siavoshani, Amir Hossein Khajepour, Amirmohammad Ziaei,\n  Amir Ali Gatmiri, Ali Taheri", "title": "Machine Learning Interpretability Meets TLS Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Protecting users' privacy over the Internet is of great importance. However,\ndue to the increasing complexity of network protocols and components, it\nbecomes harder and harder to maintain. Therefore, investigating and\nunderstanding how data is leaked from the information transport\nplatform/protocols can lead us to a more secure environment.\n  In this paper, we propose an iterative framework to find the most vulnerable\ninformation fields in a network protocol systematically. To this end, focusing\non the Transport Layer Security (TLS) protocol, we perform different\nmachine-learning-based fingerprinting attacks by collecting data from more than\n70 domains (websites) to understand how and where this information leakage\noccurs in the TLS protocol. Then, by employing the interpretation techniques\ndeveloped in the machine learning community, and using our framework, we find\nthe most vulnerable information fields in the TLS protocol. Our findings\ndemonstrate that the TLS handshake (which is mainly unencrypted), the TLS\nrecord length appears in the TLS application data header, and the\ninitialization vector (IV) field are among the most critical leaker parts in\nthis protocol, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:37:45 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Siavoshani", "Mahdi Jafari", ""], ["Khajepour", "Amir Hossein", ""], ["Ziaei", "Amirmohammad", ""], ["Gatmiri", "Amir Ali", ""], ["Taheri", "Ali", ""]]}, {"id": "2011.06313", "submitter": "Michael Gundall", "authors": "Michael Gundall, Christopher Huber, Peter Rost, Ruediger Halfmann, and\n  Hans D. Schotten", "title": "Integration of 5G with TSN as Prerequisite for a Highly Flexible Future\n  Industrial Automation: Time Synchronization based on IEEE 802.1AS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry 4.0 brings up new types of use cases, whereby mobile use cases play\na significant role. These use cases have stringent requirements on both\nautomation and communication systems that cannot be achieved with recent shop\nfloor technologies. Therefore, novel technologies such as IEEE time-sensitive\nnetworking (TSN) and Open Platform Communications Unified Architecture (OPC UA)\nare being introduced. In addition, for the realization of mobile use cases,\nwireline technologies cannot be used and have to be replaced by wireless\nconnections, which have to meet the high demands of the industrial landscape.\nHere, 5th generation wireless communication system (5G) is seen as a promising\ncandidate. Especially encouraging and similarly challenging is the cooperative\nwork of mobile robots, where particularly high demands on time synchronization\narise. Therefore, this paper introduces a concept for the integration of TSN\ntime synchronization (IEEE 802.1AS) conform with 5G to fulfill the requirements\nof these use cases. Furthermore, the paper describes a testbed for discrete\nmanufacturing, consisting pre-dominantly of industrial equipment, in order to\nevaluate the presented approach.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:59:42 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Gundall", "Michael", ""], ["Huber", "Christopher", ""], ["Rost", "Peter", ""], ["Halfmann", "Ruediger", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2011.06325", "submitter": "Jack Li", "authors": "Jianhua Li, Jiong Jin, Lingjuan Lyu, Dong Yuan, Yingying Yang,\n  Longxiang Gao, Chao Shen", "title": "A Fast and Scalable Authentication Scheme in IoT for Smart Living", "comments": "15 pages, 7 figures, 3 tables, to appear in FGCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous resource-limited smart objects (SOs) such as sensors and actuators\nhave been widely deployed in smart environments, opening new attack surfaces to\nintruders. The severe security flaw discourages the adoption of the Internet of\nthings in smart living. In this paper, we leverage fog computing and\nmicroservice to push certificate authority (CA) functions to the proximity of\ndata sources. Through which, we can minimize attack surfaces and authentication\nlatency, and result in a fast and scalable scheme in authenticating a large\nvolume of resource-limited devices. Then, we design lightweight protocols to\nimplement the scheme, where both a high level of security and low computation\nworkloads on SO (no bilinear pairing requirement on the client-side) is\naccomplished. Evaluations demonstrate the efficiency and effectiveness of our\nscheme in handling authentication and registration for a large number of nodes,\nmeanwhile protecting them against various threats to smart living. Finally, we\nshowcase the success of computing intelligence movement towards data sources in\nhandling complicated services.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 11:41:26 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Li", "Jianhua", ""], ["Jin", "Jiong", ""], ["Lyu", "Lingjuan", ""], ["Yuan", "Dong", ""], ["Yang", "Yingying", ""], ["Gao", "Longxiang", ""], ["Shen", "Chao", ""]]}, {"id": "2011.06355", "submitter": "Daniel Brennan", "authors": "Daniel Brennan and Vuk Marojevic", "title": "UHD-DPDK Performance Analysis for Advanced Software Radio Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research conducted in LTE and 5G wireless communications systems uses common\noff-the-shelf hardware components and commercial software defined radio (SDR)\nhardware. One of the more popular SDR platforms is the Ettus USRP product line\nwhich uses the UHD driver and transport protocol framework. System performance\ncan be increased using kernel bypass frameworks along with UHD. This paper\ninvestigates UHD with DPDK in an SDR environment using srslTE as the SDR\napplication. We present measurement results using the iperf3 network\nperformance application that show performance improvements when employing a\nkernel bypass framework to facilitate data transfer over the network interface\nbetween the SDR application and the radio hardware.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 12:57:13 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Brennan", "Daniel", ""], ["Marojevic", "Vuk", ""]]}, {"id": "2011.06427", "submitter": "Sadra Rahimi Kari", "authors": "S. Rahimi Kari", "title": "Realization of Stochastic Neural Networks and Its Potential Applications", "comments": "6 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.NI eess.SP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successive Cancellation Decoders have come a long way since the\nimplementation of traditional SC decoders, but there still is a potential for\nimprovement. The main struggle over the years was to find an optimal algorithm\nto implement them. Most of the proposed algorithms are not practical enough to\nbe implemented in real-life. In this research, we aim to introduce the\nEfficiency of stochastic neural networks as an SC decoder and Find the possible\nways of improving its performance and practicality. In this paper, after a\nbrief introduction to stochastic neurons and SNNs, we introduce methods to\nrealize Stochastic NNs on both deterministic and stochastic platforms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 15:01:07 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kari", "S. Rahimi", ""]]}, {"id": "2011.06488", "submitter": "Florian Jacob", "authors": "Florian Jacob, Carolin Beer, Norbert Henze, Hannes Hartenstein", "title": "Analysis of the Matrix Event Graph Replicated Data Type", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3058576", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Matrix is a new kind of decentralized, topic-based publish-subscribe\nmiddleware for communication and data storage that is getting popular\nparticularly as a basis for secure instant messaging. In comparison to\ntraditional decentralized communication systems, Matrix replaces pure message\npassing with a replicated data structure. This data structure, which we extract\nand call the Matrix Event Graph (MEG), depicts the causal history of messages.\nWe show that this MEG represents an interesting and important replicated data\ntype for general decentralized applications that are based on causal histories\nof publish-subscribe events: we show that a MEG possesses strong properties\nwith respect to consistency, byzantine attackers, and scalability. First, we\nshow that the MEG provides Strong Eventual Consistency (SEC), and that it is\navailable under partition, by proving that the MEG is a Conflict-Free\nReplicated Data Type for causal histories. While strong consistency is\nimpossible here as shown by the famous CAP theorem, SEC is among the best known\nachievable trade-offs. Second, we discuss the implications of byzantine\nattackers on the data type's properties. We note that the MEG, as it does not\nstrive for consensus, can cope with $n > f$ environments with $n$ total\nparticipants of which $f$ show byzantine faults. Furthermore, we analyze\nscalability: Using Markov chains we study the width of the MEG, defined as the\nnumber of forward extremities, over time and observe an almost optimal\nevolution. We conjecture that this property is inherent to the underlying\nspatially inhomogeneous random walk.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:45:02 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Jacob", "Florian", ""], ["Beer", "Carolin", ""], ["Henze", "Norbert", ""], ["Hartenstein", "Hannes", ""]]}, {"id": "2011.06622", "submitter": "Luis Sequeira Dr", "authors": "Luis Sequeira, Julian Fernandez-Navajas, Luis Casadesus, Jose Saldana,\n  Idelkys Quintana, Jose Ruiz-Mas", "title": "The Influence of the Buffer Size in Packet Loss for Competing Multimedia\n  and Bursty Traffic", "comments": null, "journal-ref": "Proc. International Symposium on Performance Evaluation of\n  Computer and Telecommunication Systems SPECTS 2013, Toronto, Canada, July\n  2013, pp 645-652. ISBN 1-56555-352-7", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an analysis of the effect of the access router buffer size\non packet loss rate and how it can affect the QoS of multimedia services when\nbursty traffic is present. VoIP traffic, real traces of viedoconferencing and\nvideosurvellance are used in two different scenarios with medium link\nutilization. The study shows that the bursty nature of some applications may\nimpair the MOS of voice calls especially when a certain number of bursts\noverlap. When link utilization is above 70% good values of VoIP QoS cannot be\nobtained.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 19:08:27 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Sequeira", "Luis", ""], ["Fernandez-Navajas", "Julian", ""], ["Casadesus", "Luis", ""], ["Saldana", "Jose", ""], ["Quintana", "Idelkys", ""], ["Ruiz-Mas", "Jose", ""]]}, {"id": "2011.06713", "submitter": "Sathiya Kumaran Mani", "authors": "Sathiya Kumaran Mani, Yi Cao, Paul Barford, Darryl Veitch", "title": "iHorology: Lowering the Barrier to Microsecond-level Internet Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High precision, synchronized clocks are essential to a growing number of\nInternet applications. Standard protocols and their associated server\ninfrastructure have been shown to typically enable client clocks to synchronize\non the order of tens of milliseconds. We address one of the key challenges to\nhigh precision Internet timekeeping - the intrinsic contribution to clock error\nof path asymmetry between client and time server, a fundamental barrier to\nmicrosecond level accuracy. We first exploit results of a measurement study to\nquantify asymmetry and its effect on timing. We then describe three approaches\nto addressing the path asymmetry problem: LBBE, SBBE and K-SBBE, each based on\ntimestamp exchange with multiple servers, with the goal of tightening bounds on\nasymmetry for each client. We explore their capabilities and limitations\nthrough simulation and argument. We show that substantial improvements are\npossible, and discuss whether, and how, the goal of microsecond accuracy might\nbe attained.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 01:17:33 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Mani", "Sathiya Kumaran", ""], ["Cao", "Yi", ""], ["Barford", "Paul", ""], ["Veitch", "Darryl", ""]]}, {"id": "2011.06725", "submitter": "Olakunle Ibitoye", "authors": "Olakunle Ibitoye, Ashraf Matrawy, and M. Omair Shafiq", "title": "A GAN-based Approach for Mitigating Inference Attacks in Smart Home\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of smart, connected, always listening devices have\nintroduced significant privacy risks to users in a smart home environment.\nBeyond the notable risk of eavesdropping, intruders can adopt machine learning\ntechniques to infer sensitive information from audio recordings on these\ndevices, resulting in a new dimension of privacy concerns and attack variables\nto smart home users. Techniques such as sound masking and microphone jamming\nhave been effectively used to prevent eavesdroppers from listening in to\nprivate conversations. In this study, we explore the problem of adversaries\nspying on smart home users to infer sensitive information with the aid of\nmachine learning techniques. We then analyze the role of randomness in the\neffectiveness of sound masking for mitigating sensitive information leakage. We\npropose a Generative Adversarial Network (GAN) based approach for privacy\npreservation in smart homes which generates random noise to distort the\nunwanted machine learning-based inference. Our experimental results demonstrate\nthat GANs can be used to generate more effective sound masking noise signals\nwhich exhibit more randomness and effectively mitigate deep learning-based\ninference attacks while preserving the semantics of the audio samples.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 02:14:32 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Ibitoye", "Olakunle", ""], ["Matrawy", "Ashraf", ""], ["Shafiq", "M. Omair", ""]]}, {"id": "2011.06779", "submitter": "Innocent Onwuegbuzie Mr", "authors": "Onwuegbuzie Innocent Uzougbo, Samuel-Soma M. Ajibade, Fele Taiwo", "title": "An overview of wireless sensor network security attacks: Mode of\n  operation, severity and mitigation techniques", "comments": "14 Pages, 3 Figures, SSCS Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wireless Sensor Network (WSN) is the network of the future. As it gradually\ngains ground by transforming our lives and environments into a Smart World, it\nwill definitely call for attention from selfish minded Attackers. The first\nsection of this paper introduces the Wireless Sensor Network, its constraints,\narchitecture, and mode of operation. It goes ahead to discuss the applications\nof WSN in health, agriculture, military, transportation, environment,\nindustries. However, WSN automatically inherits the security challenges of the\ntraditional network. The Network security goals which are Confidentiality,\nIntegrity, Availability, and Authentication sometimes called the CIA of Network\nsecurity is discussed with respect to WSN. This is followed by the security\nchallenges of WSN, these challenges are categorized into two (2), Passive and\nActive Attacks, Passive attack is interested in the message, data or\ninformation that traverses the network without hindering the network channel or\nmedium of communication while Active attack is interested in both the data as\nwell as compromising and if possible shutting down the communication channel in\norder to hinders the smooth running of the network. In line with these security\nchallenges, mitigation techniques are proffered to possibly prevent or lessen\nthe severity of the attacks as its almost impossible to stop attackers from\ncarrying out their malicious activities.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 06:33:02 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Uzougbo", "Onwuegbuzie Innocent", ""], ["Ajibade", "Samuel-Soma M.", ""], ["Taiwo", "Fele", ""]]}, {"id": "2011.06935", "submitter": "Ishfaq Hussain", "authors": "Ishfaq Hussain and Janibul Bashir", "title": "Measuring time delay in path MTU discovery in transmitting a packet in\n  IPv4 and IPv6 network", "comments": "14 pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Path MTU Discovery (PMTUD) was initially designed for Internet protocol\nversion 4 (IPv4) to prevent the communication loss due to smaller path MTU.\nThis protocol is then further developed for Internet protocol version 6 (IPv6)\nwith new set of constraints. In IPv4 network, the PMTUD activates when the\npackets DF bit is set, while as in IPv6, PMTUD is always running for every\npacket. In this paper, we analyzed the time consumed to transmit a single\npacket from source to destination in IPv6 and IPv4 network in the presence of\nPMTUD. Based on our analysis we concluded that the communication time increases\nwith the varying MTU of the intermediate nodes. Moreover, we formulated the\nmathematical model to determine the communication delay in a network. Our model\nshows that the asymptotic lower bound for time taken is {\\Omega}(n) and the\nasymptotic upper bound is {\\Theta}(n^2), using path MTU discovery.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 22:21:04 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hussain", "Ishfaq", ""], ["Bashir", "Janibul", ""]]}, {"id": "2011.07238", "submitter": "Canhui Chen", "authors": "Canhui Chen, Xu Chen, Jiangshan Yu, Weigang Wu, Di Wu", "title": "Impact of Temporary Fork on the Evolution of Mining Pools in Blockchain\n  Networks: An Evolutionary Game Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Temporary fork is a fundamental phenomenon in many blockchains with proof of\nwork, and the analysis of temporary fork has recently drawn great attention.\nDifferent from existing efforts that focus on the blockchain system factors\nsuch as block size, network propagation delay or block generation speed, in\nthis paper we explore a new key dimension of computing power from the miners'\nperspective. Specifically, we first propose a detailed mathematical model to\ncharacterize the impact of computing power competition of the mining pools on\nthe temporary fork. We also derive closed-form formula of the probability of\ntemporary fork and the expected mining reward of a mining pool. To reveal the\nlong-term trends on the computing power distributions over the competing mining\npools, we then develop an evolutionary game framework based on the temporary\nfork modeling and accordingly characterize the set of stable evolution\nequilibriums. Both extensive numerical simulations and realistic blockchain\ndata based evaluation provide evidence to support our theoretical models and\ndiscoveries.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 08:18:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chen", "Canhui", ""], ["Chen", "Xu", ""], ["Yu", "Jiangshan", ""], ["Wu", "Weigang", ""], ["Wu", "Di", ""]]}, {"id": "2011.07306", "submitter": "Pietro Tedeschi", "authors": "Pietro Tedeschi, Spiridon Bakiras, Roberto Di Pietro", "title": "SpreadMeNot: A Provably Secure and Privacy-Preserving Contact Tracing\n  Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A plethora of contact tracing apps have been developed and deployed in\nseveral countries around the world in the battle against Covid-19. However,\npeople are rightfully concerned about the security and privacy risks of such\napplications. To this end, the contribution of this work is twofold. First, we\npresent an in-depth analysis of the security and privacy characteristics of the\nmost prominent contact tracing protocols, under both passive and active\nadversaries. The results of our study indicate that all protocols are\nvulnerable to a variety of attacks, mainly due to the deterministic nature of\nthe underlying cryptographic protocols. Our second contribution is the design\nand implementation of SpreadMeNot, a novel contact tracing protocol that can\ndefend against most passive and active attacks, thus providing strong\n(provable) security and privacy guarantees that are necessary for such a\nsensitive application. Our detailed analysis, both formal and experimental,\nshows that SpreadMeNot satisfies security, privacy, and performance\nrequirements, hence being an ideal candidate for building a contact tracing\nsolution that can be adopted by the majority of the general public, as well as\nto serve as an open-source reference for further developments in the field.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 14:03:53 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 09:02:33 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Tedeschi", "Pietro", ""], ["Bakiras", "Spiridon", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2011.07397", "submitter": "Quntao Zhuang", "authors": "Quntao Zhuang and Bingzhi Zhang", "title": "Quantum communication capacity transition of complex quantum networks", "comments": "10 pages 14 figures, comments are welcomed", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum network is the key to enable distributed quantum information\nprocessing. As the single-link communication rate decays exponentially with the\ndistance, to enable reliable end-to-end quantum communication, the number of\nnodes need to grow with the network scale. For highly connected networks, we\nidentify a threshold transition in the capacity as the density of network nodes\nincreases -- below a critical density, the rate is almost zero, while above the\nthreshold the rate increases linearly with the density. Notably, our prediction\nof the critical density is one-order-of-magnitude higher than that in the\nrecent work [Phys. Rev. Lett.124, 210501 (2020)]. Surprisingly, above the\nthreshold the typical communication capacity between two nodes is independent\nof the distance between them, due to multi-path routing enabled by the quantum\nnetwork. In contrast, for less connected networks such as scale-free networks,\nthe end-to-end capacity saturates to constants as the number of nodes increase,\nand always decays with the distance; Our results are based on capacity\nevaluations, therefore is universal for general architectures and protocols of\nquantum networks.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 21:42:04 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 23:18:02 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Zhuang", "Quntao", ""], ["Zhang", "Bingzhi", ""]]}, {"id": "2011.07447", "submitter": "Qinzi Zhang", "authors": "Qinzi Zhang, Lewis Tseng", "title": "Echo-CGC: A Communication-Efficient Byzantine-tolerant Distributed\n  Machine Learning Algorithm in Single-Hop Radio Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we focus on a popular DML framework -- the parameter server\ncomputation paradigm and iterative learning algorithms that proceed in rounds.\nWe aim to reduce the communication complexity of Byzantine-tolerant DML\nalgorithms in the single-hop radio network. Inspired by the CGC filter\ndeveloped by Gupta and Vaidya, PODC 2020, we propose a gradient descent-based\nalgorithm, Echo-CGC. Our main novelty is a mechanism to utilize the broadcast\nproperties of the radio network to avoid transmitting the raw gradients (full\n$d$-dimensional vectors). In the radio network, each worker is able to overhear\nprevious gradients that were transmitted to the parameter server. Roughly\nspeaking, in Echo-CGC, if a worker \"agrees\" with a combination of prior\ngradients, it will broadcast the \"echo message\" instead of the its raw local\ngradient. The echo message contains a vector of coefficients (of size at most\n$n$) and the ratio of the magnitude between two gradients (a float). In\ncomparison, the traditional approaches need to send $n$ local gradients in each\nround, where each gradient is typically a vector in an ultra-high dimensional\nspace ($d\\gg n$). The improvement on communication complexity of our algorithm\ndepends on multiple factors, including number of nodes, number of faulty\nworkers in an execution, and the cost function. We numerically analyze the\nimprovement, and show that with a large number of nodes, Echo-CGC reduces\n$80\\%$ of the communication under standard assumptions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 04:35:09 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Zhang", "Qinzi", ""], ["Tseng", "Lewis", ""]]}, {"id": "2011.07479", "submitter": "Yin Yang", "authors": "Liang Yang, Yin Yang, Daniel Benevides da Costa, and Imene Trigui", "title": "Performance Analysis of an Interference-Limited RIS-Aided Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, the performance of reconfigurable intelligent surface\n(RIS)-aided communication systems corrupted by the co-channel interference\n(CCI) at the destination is investigated. Assuming Rayleigh fading and\nequal-power CCI, we present the analysis for the outage probability (OP),\naverage bit error rate (BER), and ergodic capacity. In addition, an asymptotic\noutage analysis is carried in order to obtain further insights. Our analysis\nshows that the number of reflecting elements as well as the number of\ninterferers have a great impact on the overall system performance.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 08:32:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Yang", "Liang", ""], ["Yang", "Yin", ""], ["da Costa", "Daniel Benevides", ""], ["Trigui", "Imene", ""]]}, {"id": "2011.07761", "submitter": "Lamiaa Basyoni", "authors": "Lamiaa Basyoni, Aiman Erbad, Amr Mohamed, Ahmed Refaey, Mohsen Guizani", "title": "Proportionally Fair approach for Tor's Circuits Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The number of users adopting Tor to protect their online privacy is\nincreasing rapidly. With a limited number of volunteered relays in the network,\nthe number of clients' connections sharing the same relays is increasing to the\nextent that it is starting to affect the performance. Recently, Tor's resource\nallocation among circuits has been studied as one cause of poor Tor network\nperformance. In this paper, we propose two scheduling approaches that guarantee\nproportional fairness between circuits that are sharing the same connection. In\nour evaluation, we show that the average-rate-base scheduler allocates Tor's\nresources in an optimal fair scheme, increasing the total throughput achieved\nby Tor's relays. However, our second proposed approach, an optimization-based\nscheduler, maintains acceptable fairness while reducing the latency experienced\nby Tor's clients.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 07:35:46 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Basyoni", "Lamiaa", ""], ["Erbad", "Aiman", ""], ["Mohamed", "Amr", ""], ["Refaey", "Ahmed", ""], ["Guizani", "Mohsen", ""]]}, {"id": "2011.07804", "submitter": "Michael Gundall", "authors": "Michael Gundall, Daniel Reti, and Hans D. Schotten", "title": "Application of Virtualization Technologies in Novel Industrial\n  Automation: Catalyst or Show-Stopper?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry 4.0 describes an adaptive and changeable production, where its\nfactory cells have to be reconfigured at very short intervals, e.g. after each\nworkpiece. Furthermore, this scenario cannot be realized with traditional\ndevices, such as programmable logic controllers. Here the use of well-proven\ntechnologies of the information technology are conquering the production hall\n(IT-OT convergence). Therefore, both virtualization and novel communication\ntechnologies are being introduced in the field of industrial automation. In\naddition, these technologies are seen as the key for facilitating various\nemerging use cases. However, it is not yet clear whether each of the dedicated\nhardware and software components, which have been developed for specific\ncontrol tasks and have performed well over decades, can be upgraded without\nmajor adjustments. In this paper, we examine the opportunities and challenges\nof hardware and operating system-level virtualization based on the stringent\nrequirements imposed by industrial applications. For that purpose, benchmarks\nfor different virtualization technologies are set by determining their\ncomputational and networking overhead, configuration effort, accessibility,\nscalability, and security.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 09:12:52 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Gundall", "Michael", ""], ["Reti", "Daniel", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2011.07806", "submitter": "Michael Gundall", "authors": "Michael Gundall, Calvin Glas, and Hans D. Schotten", "title": "Introduction of an Architecture for Flexible Future Process Control\n  Systems as Enabler for Industry 4.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term Industry 4.0, which refers to the fourth industrial revolution, aims\nat the digitalization of industries, including all kinds of production assets.\nWith the help of these, so-called industrial cyber-physical systems, which form\nthe industrial Internet of Things, numerous novel use cases that are key\nenabler for a smart manufacturing, can be realized. However, existing\nfacilities mainly consist of legacy equipment and technologies that do not\noffer these kind of flexibility. To address this issue, we introduce an\narchitecture that allows a flexible reconfiguration and redeployment of future\nprocess control systems. Moreover, a high system availability and reliability,\nas required by industrial applications, has been taken into account. The\narchitectural design follows the 4+1 model approach as it is available in the\nliterature. This ensures, that the design results in a holistic architecture.\nAdditionally, we provide insights into first results and outline future\ndevelopment steps.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 09:14:50 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Gundall", "Michael", ""], ["Glas", "Calvin", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2011.07860", "submitter": "Daniel Lindenschmit", "authors": "Daniel Lindenschmitt, Michael Karrenbauer and Hans D. Schotten", "title": "Analyzing Current Interference Situations of Connected Devices Using\n  Context-Information and the Centralized Broker-Approach", "comments": "conferene, interference situation, context-information,\n  context-awareness, 802.11n, medium access control, spectrum management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The digitalization of manufacturing processes is leading to a highly\nincreased amount of connected devices. In the course of this development a\nprocess was developed and implemented, which optimizes IEEE 802.11-systems\nrelating to the interference situation by using context-information. This was\nrealized by division into two fields. First of all, data providers calculate\ntheir own interference situation to determine the optimal frequency out of the\nascertained data. In this case optimal means that the chosen channel should\nhave the lowest interference power. In a second step these providers also\ncalculating the interference information about all Service Set Identifier\n(SSID) in range. The measured data is then divided into the allowed radio\nchannel. Afterwards the gathered information will be transferred to a central\nspace. An already existing infrastructure is used as a initial point for the\nfurther process. As soon as the provider has transferred new data, a broker can\ninform connected users that there is an update in the inference situation. With\nthis developed architecture an approach to face the hidden node problem is\ngiven. Additional a system for safety-critical information is implemented.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 10:58:13 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lindenschmitt", "Daniel", ""], ["Karrenbauer", "Michael", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2011.08381", "submitter": "Minoo Hosseinzadeh", "authors": "Minoo Hosseinzadeh, Andrew Wachal, Hana Khamfroush, Daniel E. Lucani", "title": "Optimal Accuracy-Time Trade-off for Deep Learning Services in Edge\n  Computing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing demand for computationally intensive services like deep\nlearning tasks, emerging distributed computing platforms such as edge computing\n(EC) systems are becoming more popular. Edge computing systems have shown\npromising results in terms of latency reduction compared to the traditional\ncloud systems. However, their limited processing capacity imposes a trade-off\nbetween the potential latency reduction and the achieved accuracy in\ncomputationally-intensive services such as deep learning-based services. In\nthis paper, we focus on finding the optimal accuracy-time trade-off for running\ndeep learning services in a three-tier EC platform where several deep learning\nmodels with different accuracy levels are available. Specifically, we cast the\nproblem as an Integer Linear Program, where optimal task scheduling decisions\nare made to maximize overall user satisfaction in terms of accuracy-time\ntrade-off. We prove that our problem is NP-hard and then provide a polynomial\nconstant-time greedy algorithm, called GUS, that is shown to attain\nnear-optimal results. Finally, upon vetting our algorithmic solution through\nnumerical experiments and comparison with a set of heuristics, we deploy it on\na test-bed implemented to measure for real-world results. The results of both\nnumerical analysis and real-world implementation show that GUS can outperform\nthe baseline heuristics in terms of the average percentage of satisfied users\nby a factor of at least 50%.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 02:39:13 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hosseinzadeh", "Minoo", ""], ["Wachal", "Andrew", ""], ["Khamfroush", "Hana", ""], ["Lucani", "Daniel E.", ""]]}, {"id": "2011.08406", "submitter": "DongNyeong Heo", "authors": "DongNyeong Heo, Doyoung Lee, Hee-Gon Kim, Suhyun Park, Heeyoul Choi", "title": "Reinforcement Learning of Graph Neural Networks for Service Function\n  Chaining", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the management of computer network systems, the service function chaining\n(SFC) modules play an important role by generating efficient paths for network\ntraffic through physical servers with virtualized network functions (VNF). To\nprovide the highest quality of services, the SFC module should generate a valid\npath quickly even in various network topology situations including dynamic VNF\nresources, various requests, and changes of topologies. The previous supervised\nlearning method demonstrated that the network features can be represented by\ngraph neural networks (GNNs) for the SFC task. However, the performance was\nlimited to only the fixed topology with labeled data. In this paper, we apply\nreinforcement learning methods for training models on various network\ntopologies with unlabeled data. In the experiments, compared to the previous\nsupervised learning method, the proposed methods demonstrated remarkable\nflexibility in new topologies without re-designing and re-training, while\npreserving a similar level of performance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 03:50:53 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Heo", "DongNyeong", ""], ["Lee", "Doyoung", ""], ["Kim", "Hee-Gon", ""], ["Park", "Suhyun", ""], ["Choi", "Heeyoul", ""]]}, {"id": "2011.08605", "submitter": "Roman Kolcun", "authors": "Roman Kolcun (1), Diana Andreea Popescu (2), Vadim Safronov (2),\n  Poonam Yadav (3), Anna Maria Mandalari (1), Yiming Xie (1), Richard Mortier\n  (2) and Hamed Haddadi (1) ((1) Imperial College London, (2) University of\n  Cambridge, (3) University of York)", "title": "The Case for Retraining of ML Models for IoT Device Identification at\n  the Edge", "comments": "13 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet-of-Things (IoT) devices are known to be the source of many security\nproblems, and as such they would greatly benefit from automated management.\nThis requires robustly identifying devices so that appropriate network security\npolicies can be applied. We address this challenge by exploring how to\naccurately identify IoT devices based on their network behavior, using\nresources available at the edge of the network.\n  In this paper, we compare the accuracy of five different machine learning\nmodels (tree-based and neural network-based) for identifying IoT devices by\nusing packet trace data from a large IoT test-bed, showing that all models need\nto be updated over time to avoid significant degradation in accuracy. In order\nto effectively update the models, we find that it is necessary to use data\ngathered from the deployment environment, e.g., the household. We therefore\nevaluate our approach using hardware resources and data sources representative\nof those that would be available at the edge of the network, such as in an IoT\ndeployment. We show that updating neural network-based models at the edge is\nfeasible, as they require low computational and memory resources and their\nstructure is amenable to being updated. Our results show that it is possible to\nachieve device identification and categorization with over 80% and 90% accuracy\nrespectively at the edge.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:01:04 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kolcun", "Roman", ""], ["Popescu", "Diana Andreea", ""], ["Safronov", "Vadim", ""], ["Yadav", "Poonam", ""], ["Mandalari", "Anna Maria", ""], ["Xie", "Yiming", ""], ["Mortier", "Richard", ""], ["Haddadi", "Hamed", ""]]}, {"id": "2011.08608", "submitter": "Marco Giordani", "authors": "Dengke Wang, Marco Giordani, Mohamed-Slim Alouini, Michele Zorzi", "title": "The Potential of Multi-Layered Hierarchical Non-Terrestrial Networks for\n  6G", "comments": "8 pages, 6 figures, 1 table. Accepted for publication in the IEEE\n  Vehicular Technology Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  6th generation (6G) communication research is currently focusing on\nnon-terrestrial networks (NTNs) to promote ubiquitous and ultra-high-capacity\nglobal connectivity. Specifically, multi-layered hierarchical networks, i.e.,\nthe orchestration among different aerial/space platforms, including Low and\nHigh Altitude Platforms (LAPs and HAPs), and satellites co-operating at\ndifferent altitudes, currently represent one the most attractive technological\noptions to solve coverage and latency constraints associated with the NTN\nparadigm. However, there are still several issues to be resolved for proper\nnetwork design. In this work, we evaluate the performance of different\nmulti-layered non-terrestrial configurations, and provide guidelines on the\noptimal working point(s) for which it is possible to achieve a good compromise\nbetween improved system flexibility and network performance, with respect to a\nbaseline standalone deployment.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:04:41 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 08:51:37 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wang", "Dengke", ""], ["Giordani", "Marco", ""], ["Alouini", "Mohamed-Slim", ""], ["Zorzi", "Michele", ""]]}, {"id": "2011.09035", "submitter": "Seyedmohammad Salehi", "authors": "Seyedmohammad Salehi, Abdullah Alnajim, Xiaoqing Zhu, Malcolm Smith,\n  Chien-Chung Shen and Leonard Cimini", "title": "Traffic Characteristics of Virtual Reality over Edge-enabled Wi-Fi\n  Networks", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Virtual reality (VR) is becoming prevalent with a plethora of applications in\neducation, healthcare, entertainment, etc. To increase the user mobility, and\nto reduce the energy consumption and production cost of VR head mounted\ndisplays (HMDs), wireless VR with edge-computing has been the focus of both\nindustry and academia. However, transferring large video frames of VR\napplications with their stringent Quality of Service (QoS) requirements over\nwireless network requires innovations and optimizations across different\nnetwork layers. In order to develop efficient architectures, protocols and\nscheduling mechanisms, the traffic characteristics of various types of VR\napplications are required. In this paper, we first compute the theoretical\nthroughput requirements of an ideal VR experience as well as a popular VR HMD.\nWe then examine the traffic characteristics of a set of VR applications using\nan edge-enabled Wi-Fi network. Our results reveal interesting findings that can\nbe considered in developing new optimizations, protocols, access mechanisms and\nscheduling algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 01:56:36 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Salehi", "Seyedmohammad", ""], ["Alnajim", "Abdullah", ""], ["Zhu", "Xiaoqing", ""], ["Smith", "Malcolm", ""], ["Shen", "Chien-Chung", ""], ["Cimini", "Leonard", ""]]}, {"id": "2011.09107", "submitter": "Levente Csikor PhD", "authors": "Levente Csikor, Vipul Ujawane, Dinil Mon Divakaran", "title": "On the Feasibility and Enhancement of the Tuple Space Explosion Attack\n  against Open vSwitch", "comments": "13 pages + bios in IEEE two-column journal style Submitted only to\n  arXiv!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Being a crucial part of networked systems, packet classification has to be\nhighly efficient; however, software switches in cloud environments still face\nperformance challenges. The recently proposed Tuple Space Explosion (TSE)\nattack exploits an algorithmic deficiency in Open vSwitch (OVS). In TSE,\nlegitimate low-rate attack traffic makes the cardinal linear search algorithm\nin the Tuple Space Search (TSS) algorithm to spend an unaffordable time for\nclassifying each packet resulting in a denial-of-service (DoS) for the rest of\nthe users. In this paper, we investigate the feasibility of TSE from multiple\nperspectives. Besides showing that TSE is still efficient in the newer version\nof OVS, we show that when the kernel datapath is compiled from a different\nsource, it can degrade its performance to ~1% of its baseline with less than 1\nMbps attack rate. Finally, we show that TSE is much less effective against\nOVS-DPDK with userspace datapath due to the enhanced ranking process in its TSS\nimplementation. Therefore, we propose TSE 2.0 to defeat the ranking process and\nachieve a complete DoS against OVS-DPDK. Furthermore, we present TSE 2.1, which\nachieves the same goal against OVS-DPDK running on multiple cores without\nsignificantly increasing the attack rate.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 06:13:08 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Csikor", "Levente", ""], ["Ujawane", "Vipul", ""], ["Divakaran", "Dinil Mon", ""]]}, {"id": "2011.09121", "submitter": "Mahdi Miraz", "authors": "Mahdi H. Miraz and Maaruf Ali", "title": "Integration of Blockchain and IoT: An Enhanced Security Perspective", "comments": "arXiv admin note: substantial text overlap with arXiv:1806.05242", "journal-ref": "Annals of Emerging Technologies in Computing (AETiC), Print ISSN:\n  2516-0281, Online ISSN: 2516-029X, pp. 52-63, Vol. 4, No. 4, 1st October\n  2020, Available: http://aetic.theiaer.org/archive/v4/v4n4/p6.html", "doi": "10.33166/AETiC.2020.04.006", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain (BC), a by-product of Bitcoin cryptocurrency, has gained immense\nand wide scale popularity for its applicability in various diverse domains -\nespecially in multifaceted non-monetary systems. By adopting cryptographic\ntechniques such as hashing and asymmetric encryption - along with distributed\nconsensus approach, a Blockchain based distributed ledger not only becomes\nhighly secure but also immutable and thus eliminates the need for any\nthird-party intermediators. On the contrary, innumerable IoT (Internet of\nThings) devices are increasingly being added to the network. This phenomenon\nposes higher risk in terms of security and privacy. It is thus extremely\nimportant to address the security aspects of the growing IoT ecosystem. This\npaper explores the applicability of BC for ensuring enhanced security and\nprivacy in the IoT ecosystem. Recent research articles and projects or\napplications were surveyed to assess the implementation of BC for IoT Security\nand identify associated challenges and propose solutions for BC enabled\nenhanced security for the IoT ecosystem.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:42:35 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Miraz", "Mahdi H.", ""], ["Ali", "Maaruf", ""]]}, {"id": "2011.09144", "submitter": "Siamak Layeghy", "authors": "Mohanad Sarhan, Siamak Layeghy, Nour Moustafa, Marius Portmann", "title": "NetFlow Datasets for Machine Learning-based Network Intrusion Detection\n  Systems", "comments": null, "journal-ref": "BDTA 2020", "doi": "10.1007/978-3-030-72802-1_9", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML)-based Network Intrusion Detection Systems (NIDSs) have\nproven to become a reliable intelligence tool to protect networks against\ncyberattacks. Network data features has a great impact on the performances of\nML-based NIDSs. However, evaluating ML models often are not reliable, as each\nML-enabled NIDS is trained and validated using different data features that may\ndo not contain security events. Therefore, a common ground feature set from\nmultiple datasets is required to evaluate an ML model's detection accuracy and\nits ability to generalise across datasets. This paper presents NetFlow features\nfrom four benchmark NIDS datasets known as UNSW-NB15, BoT-IoT, ToN-IoT, and\nCSE-CIC-IDS2018 using their publicly available packet capture files. In a\nreal-world scenario, NetFlow features are relatively easier to extract from\nnetwork traffic compared to the complex features used in the original datasets,\nas they are usually extracted from packet headers. The generated Netflow\ndatasets have been labelled for solving binary- and multiclass-based learning\nchallenges. Preliminary results indicate that NetFlow features lead to similar\nbinary-class results and lower multi-class classification results amongst the\nfour datasets compared to their respective original features datasets. The\nNetFlow datasets are named NF-UNSW-NB15, NF-BoT-IoT, NF-ToN-IoT,\nNF-CSE-CIC-IDS2018 and NF-UQ-NIDS are published at\nhttp://staff.itee.uq.edu.au/marius/NIDS_datasets/ for research purposes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 07:50:38 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Sarhan", "Mohanad", ""], ["Layeghy", "Siamak", ""], ["Moustafa", "Nour", ""], ["Portmann", "Marius", ""]]}, {"id": "2011.09611", "submitter": "Francis Yan", "authors": "Emily Marx, Francis Y. Yan, Keith Winstein", "title": "Implementing BOLA-BASIC on Puffer: Lessons for the use of SSIM in ABR\n  logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One ABR algorithm implemented on Puffer is BOLA-BASIC, the simplest variant\nof BOLA. BOLA finds wide use in industry, notably in the MPEG-DASH reference\nplayer used as the basis for video players at Akamai, BBC, Orange, and CBS. The\noverall goal of BOLA is to maximize each encoded chunk's video quality while\nminimizing rebuffering. To measure video quality, Puffer uses the structural\nsimilarity metric SSIM, whereas BOLA and other ABR algorithms like BBA, MPC,\nand Pensieve are more commonly implemented using bitrate (or a variant of\nbitrate).\n  While bitrate is frequently used, BOLA allows the video provider to define\nits own proxy of video quality as the algorithm's \"utility\" function. However,\nusing SSIM as utility proved surprisingly complex for BOLA-BASIC, despite the\nalgorithm's simplicity. Given the rising popularity of SSIM and related quality\nmetrics, we anticipate that a growing number of Puffer-like systems will face\nsimilar challenges. We hope developers of such systems find our experiences\ninformative as they implement algorithms designed with bitrate-based utility in\nmind.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 01:53:36 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Marx", "Emily", ""], ["Yan", "Francis Y.", ""], ["Winstein", "Keith", ""]]}, {"id": "2011.09621", "submitter": "Pierre Boisrond", "authors": "Pierre Boisrond", "title": "To Terminate or Not to Terminate Secure Sockets Layer (SSL) Traffic at\n  the Load Balancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concepts of terminating or not terminating Secure Sockets Layer (SSL) at\nthe load balancer have always generated intriguing conversations. In this\npaper, the author explains the pros and cons of such concepts in a simplistic\nmanner and also provides suggested recommendations to help organizations\nunderstand the security implications associated with unencrypted traffic\nflowing from the Load Balancer to the App Servers.\n  Keywords: Secure Sockets Layer (SSL), Load Balancer, App Server,\nMan-in-the-Middle Attack (MITM),End to End Encryption (E2EE)\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 02:50:13 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Boisrond", "Pierre", ""]]}, {"id": "2011.09629", "submitter": "Tengfei Cao", "authors": "Qiyue Li, Tengfei Cao, Wei Sun and Weitao Li", "title": "Throughput Optimal Uplink Scheduling in Heterogeneous PLC and LTE\n  Communication for Delay Aware Smart Grid Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Smart grid is an energy network that integrates advanced power equipment,\ncommunication technology and control technology. It can transmit two-way power\nand data among all components of the grid at the same time. The existing smart\ngrid communication technologies include power line carrier (PLC)\ncom-munication, industrial Ethernet, passive optical networks and wireless\ncommuni-cation, each of which have different advantages. Due to the complex\napplication scenarios, massive sampling points and high transmission\nreliability require-ments, a single communication method cannot fully meet the\ncommunication re-quirements of smart grid, and heterogeneous communication\nmodes are required. In addition, with the development of cellular technology,\nlong term evolution (LTE)-based standards have been identified as a promising\ntechnology that can meet the strict requirements of various operations in smart\ngrid. In this paper, we analyze the advantages and disadvantages of PLC and LTE\ncommunication, and design a network framework for PLC and LTE communication\nuplink heteroge-neous communication in smart grid. Then, we propose an uplink\nscheduling transmission method for sampling data with optimized throughput\naccording to the requirements of system delay and reliability. Then, we use the\nformula deri-vation to prove the stability and solvability of the scheduling\nsystem in theory. Finally, the simulation results show that under the condition\nof satisfying the de-lay requirement, our proposed framework can optimally\nallocate the wireless communication resource and maximize the throughput of the\nuplink transmission system. Keywords: smart grid, heterogeneous communication,\noptimized throughput.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 03:28:09 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Li", "Qiyue", ""], ["Cao", "Tengfei", ""], ["Sun", "Wei", ""], ["Li", "Weitao", ""]]}, {"id": "2011.09747", "submitter": "Jernej Hribar Dr.", "authors": "Jernej Hribar, Andrei Marinescu, Alessandro Chiumento, and Luiz A.\n  DaSilva", "title": "Energy Aware Deep Reinforcement Learning Scheduling for Sensors\n  Correlated in Time and Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of battery-powered sensors deployed for monitoring purposes in a\nmultitude of scenarios, e.g., agriculture, smart cities, industry, etc.,\nrequire energy-efficient solutions to prolong their lifetime. When these\nsensors observe a phenomenon distributed in space and evolving in time, it is\nexpected that collected observations will be correlated in time and space. In\nthis paper, we propose a Deep Reinforcement Learning (DRL) based scheduling\nmechanism capable of taking advantage of correlated information. We design our\nsolution using the Deep Deterministic Policy Gradient (DDPG) algorithm. The\nproposed mechanism is capable of determining the frequency with which sensors\nshould transmit their updates, to ensure accurate collection of observations,\nwhile simultaneously considering the energy available. To evaluate our\nscheduling mechanism, we use multiple datasets containing environmental\nobservations obtained in multiple real deployments. The real observations\nenable us to model the environment with which the mechanism interacts as\nrealistically as possible. We show that our solution can significantly extend\nthe sensors' lifetime. We compare our mechanism to an idealized, all-knowing\nscheduler to demonstrate that its performance is near-optimal. Additionally, we\nhighlight the unique feature of our design, energy-awareness, by displaying the\nimpact of sensors' energy levels on the frequency of updates.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 09:53:27 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Hribar", "Jernej", ""], ["Marinescu", "Andrei", ""], ["Chiumento", "Alessandro", ""], ["DaSilva", "Luiz A.", ""]]}, {"id": "2011.09972", "submitter": "Steffen Kaup", "authors": "Steffen Kaup, Andr\\'e Ludwig, Bogdan Franczyk", "title": "Design and Evaluation of Routing Artifacts as a Part of the Physical\n  Internet Framework", "comments": "7th International Physical Internet Conference, Shenzhen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Global freight demand will triple between 2015 and 2050, based on the current\ndemand pathway, as predicted in the Transport Outlook 2019. Hence, a\nrevolutionary change in transport efficiency is urgently needed. One approach\nto tackle this change is to transfer the successful model of the Digital\nInternet for data exchange to the physical transport of goods: The so-called\nPhysical Internet (PI, or $\\pi$). The potential of the Physical Internet lies\nin dynamic routing, which increases the utilization of transport modalities,\nlike trucks and vans, and makes transport more efficient. Previous concept\ntransfers have identified and determined the $\\pi$-nodes as routing entities.\nHere, the problem is that the $\\pi$-nodes have no information about real-time\ndata on transport vacancies. This leads to a great challenge for the\n$\\pi$-nodes with regard to routing, in particular in determining the next best\nappropriate node for onward transport of the freight package. This paper\nevolved the state of research concept as an artifact that considers the\n$\\pi$-nodes as routers in a way that it distributes and replicates real-time\ndata to the $\\pi$-nodes in order to enable more effective routing decisions.\nThis real-time data is provided by vehicles, or so-called $\\pi$-transporters,\non the road. Therefore, a second artifact will be designed in which\n$\\pi$-transporters take over the routing role. In order to be able to take a\nholistic perspective on the routing topic, the goods that are actually to be\nmoved, the so-called $\\pi$-containers, are also designed as routing entities in\na third artifact. These three artifacts are then compared and evaluated for the\nconsideration of real-time traffic data. This paper proposes $\\pi$-transporters\nas routing entities whose software representatives negotiate freight handover\npoints in a cloud-based marketplace.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 17:18:09 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Kaup", "Steffen", ""], ["Ludwig", "Andr\u00e9", ""], ["Franczyk", "Bogdan", ""]]}, {"id": "2011.10017", "submitter": "Brent Lagesse", "authors": "Adedayo Odesile, Brent Lagesse", "title": "TrustSense: An energy efficient trust scheme for clustered wireless\n  sensor networks", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Designing security systems for wireless sensor networks presents a challenge\ndue to their relatively low computational resources. This has rendered many\ntraditional defense mechanisms based on cryptography infeasible for deployment\non such networks. Reputation and anomaly detection systems have been\nimplemented as viable alternatives, but existing implementations still struggle\nwith providing efficient security without a significant impact on energy\nconsumption. To address this trade-off between resource consumption and\nresiliency, we designed TrustSense, a reputation management protocol for\nclustered WSNs. It is a semi-centralized family of algorithms that combine\nperiodic trust updates, spatial correlation, and packet sequence validation at\nthe cluster-heads' hierarchy to relieve the sensor nodes of unnecessary opinion\nqueries and trust evaluation computation. We compared the efficiency of\nTrustSense with legacy reputation systems such as EigenTrust and the results of\nsimulations show a significant improvement in reliability and energy usage\nwhile maintaining an acceptable path length with varying numbers of malicious\nnodes. We believe the approach of combining different techniques from various\nclasses of intrusion detection systems unlocks several possibilities of\nachieving better results by more complex and versatile composition of these\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:34:31 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Odesile", "Adedayo", ""], ["Lagesse", "Brent", ""]]}, {"id": "2011.10080", "submitter": "Elif Ak", "authors": "Elif Ak, Taner Ozdas, Serkan Sevim and Berk Canberk", "title": "WAE: Workload Automation Engine for CDN-specialized Container\n  Orchestration", "comments": "5 pages, 6 figures, 3 tables Conference Publication Keywords: Content\n  delivery networks, containerization, network functions virtualization This\n  paper is published in 2018 IEEE Second International Balkan Conference on\n  Communications and Networking, Podgorica, Montenegro, June 6-8,2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Content Delivery Network (CDN) has been emerged as a compelling technology to\nprovide efficient and scalable web services even under high client request.\nHowever, this leads to a dilemma between minimum deployment cost and robust\nservice under heavy loads. To solve this problem, we propose the Workload\nAutomation Engine (WAE) which enables dynamic resource management, automated\nscaling and rapid service deployment with least cost for CDN providers. Our\nmodular design uses an algorithm to calculate the optimal assignment of virtual\nCDN functions such as streaming, progressive delivering and load balancer. In\nparticular, we study on real CDN data which belongs to Medianova CDN Company in\nTurkey. Also we use Docker containerization as an underlying system. The\nresults reveal that our containerized design reduces the latency and deployment\ncost by 45% and by 66%, respectively. Moreover, we obtain roughly 20% more CPU\nefficiency and 35% more utilized network.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 19:35:56 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Ak", "Elif", ""], ["Ozdas", "Taner", ""], ["Sevim", "Serkan", ""], ["Canberk", "Berk", ""]]}, {"id": "2011.10121", "submitter": "Sudheesh Singanamalla", "authors": "Sudheesh Singanamalla, Suphanat Chunhapanya, Marek Vavru\\v{s}a, Tanya\n  Verma, Peter Wu, Marwan Fayed, Kurtis Heimerl, Nick Sullivan, Christopher\n  Wood", "title": "Oblivious DNS over HTTPS (ODoH): A Practical Privacy Enhancement to DNS", "comments": "16 pages, 7 figures, Under submission and Presented at IETF 109 MAPRG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Domain Name System (DNS) is the foundation of a human-usable Internet,\nresponding to client queries for host-names with corresponding IP addresses and\nrecords. Traditional DNS is also unencrypted, and leaks user information to\nnetwork operators. Recent efforts to secure DNS using DNS over TLS (DoT) and\nDNS over HTTPS (DoH) have been gaining traction, ostensibly protecting traffic\nand hiding content from on-lookers. However, one of the criticisms of DoT and\nDoH is brought to bear by the small number of large-scale deployments (e.g.,\nComcast, Google, Cloudflare): DNS resolvers can associate query contents with\nclient identities in the form of IP addresses. Oblivious DNS over HTTPS(ODoH)\nsafeguards against this problem. In this paper we ask what it would take to\nmake ODoH practical? We describe ODoH, a practical DNS protocol aimed at\nresolving this issue by both protecting the client's content and identity. We\nimplement and deploy the protocol, and perform measurements to show that ODoH\nhas comparable performance to protocols like DoH and DoT which are gaining\nwidespread adoption, while improving client privacy, making ODoH a practical\nprivacy enhancing replacement for the usage of DNS.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 22:04:43 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Singanamalla", "Sudheesh", ""], ["Chunhapanya", "Suphanat", ""], ["Vavru\u0161a", "Marek", ""], ["Verma", "Tanya", ""], ["Wu", "Peter", ""], ["Fayed", "Marwan", ""], ["Heimerl", "Kurtis", ""], ["Sullivan", "Nick", ""], ["Wood", "Christopher", ""]]}, {"id": "2011.10282", "submitter": "Hang Liu", "authors": "Hang Liu, Xiaojun Yuan, Ying-Jun Angela Zhang", "title": "Reconfigurable Intelligent Surface Enabled Federated Learning: A Unified\n  Communication-Learning Design Approach", "comments": "Simulation codes are available at\n  https://github.com/liuhang1994/RIS-FL. This work has been accepted by IEEE\n  Transactions on Wireless Communications. Copyright may be transferred without\n  notice, after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To exploit massive amounts of data generated at mobile edge networks,\nfederated learning (FL) has been proposed as an attractive substitute for\ncentralized machine learning (ML). By collaboratively training a shared\nlearning model at edge devices, FL avoids direct data transmission and thus\novercomes high communication latency and privacy issues as compared to\ncentralized ML. To improve the communication efficiency in FL model\naggregation, over-the-air computation has been introduced to support a large\nnumber of simultaneous local model uploading by exploiting the inherent\nsuperposition property of wireless channels. However, due to the heterogeneity\nof communication capacities among edge devices, over-the-air FL suffers from\nthe straggler issue in which the device with the weakest channel acts as a\nbottleneck of the model aggregation performance. This issue can be alleviated\nby device selection to some extent, but the latter still suffers from a\ntradeoff between data exploitation and model communication. In this paper, we\nleverage the reconfigurable intelligent surface (RIS) technology to relieve the\nstraggler issue in over-the-air FL. Specifically, we develop a learning\nanalysis framework to quantitatively characterize the impact of device\nselection and model aggregation error on the convergence of over-the-air FL.\nThen, we formulate a unified communication-learning optimization problem to\njointly optimize device selection, over-the-air transceiver design, and RIS\nconfiguration. Numerical experiments show that the proposed design achieves\nsubstantial learning accuracy improvement compared with the state-of-the-art\napproaches, especially when channel conditions vary dramatically across edge\ndevices.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:54:13 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 14:59:36 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 09:25:59 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 14:47:11 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Liu", "Hang", ""], ["Yuan", "Xiaojun", ""], ["Zhang", "Ying-Jun Angela", ""]]}, {"id": "2011.10293", "submitter": "Zhuojia Gu", "authors": "Zhuojia Gu, Hancheng Lu, Peilin Hong, Yongdong Zhang", "title": "Reliability Enhancement for VR Delivery in Mobile-Edge Empowered\n  Dual-Connectivity Sub-6 GHz and mmWave HetNets", "comments": "35 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliability of current virtual reality (VR) delivery is low due to the\nlimited resources on VR head-mounted displays (HMDs) and the transmission rate\nbottleneck of sub-6 GHz networks. In this paper, we propose a dual-connectivity\nsub-6 GHz and mmWave heterogeneous network architecture empowered by mobile\nedge capability. The core idea of the proposed architecture is to utilize the\ncomplementary advantages of sub-6 GHz links and mmWave links to conduct a\ncollaborative edge resource design, which aims to improve the reliability of VR\ndelivery. From the perspective of stochastic geometry, we analyze the\nreliability of VR delivery and theoretically demonstrate that sub-6 GHz links\ncan be used to enhance the reliability of VR delivery despite the large mmWave\nbandwidth. Based on our analytical work, we formulate a joint caching and\ncomputing optimization problem with the goal to maximize the reliability of VR\ndelivery. By analyzing the coupling caching and computing strategies at HMDs,\nsub-6 GHz and mmWave base stations (BSs), we further transform the problem into\na multiple-choice multi-dimension knapsack problem. A best-first branch and\nbound algorithm and a difference of convex programming algorithm are proposed\nto obtain the optimal and sub-optimal solution, respectively. Numerical results\ndemonstrate the performance improvement using the proposed algorithms, and\nreveal that caching more monocular videos at sub-6 GHz BSs and more\nstereoscopic videos at mmWave BSs can improve the VR delivery reliability\nefficiently.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 09:43:38 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 03:24:17 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Gu", "Zhuojia", ""], ["Lu", "Hancheng", ""], ["Hong", "Peilin", ""], ["Zhang", "Yongdong", ""]]}, {"id": "2011.10473", "submitter": "Charlotte Langlais", "authors": "Israa Khaled (IMT Atlantique - ELEC, LU), Charlotte Langlais (IMT\n  Atlantique - ELEC), Ammar Falou (LU), Bachar Elhassan (LU), Michel Jezequel\n  (IMT Atlantique - ELEC)", "title": "Low-Complexity Angle-Domain MIMO NOMA System with partial channel state\n  information for MmWave Communications *", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In millimeter-wave communication, digital beamsteering (DBS), only based on\nthe user direction, is a promising angle-domain multi-antenna technique to\nmitigate the severe path loss and multiuser interference, with low-complexity\nand partial channel state information (CSI). In this paper, we design a\npower-domain non-orthogonal multiple access (NOMA) scheme that enhances the DBS\nperformance trading-off complexity , energy-consumption and capacity\nperformance. In particular, we propose a user-clustering algorithm to pair\nusers, based on a geometric-interference metric, so that the inter-user\ninterference is reduced. Afterward, based on a fixed inter-cluster power\nallocation, we derive analytically a sub-optimal intra-cluster power allocation\noptimization problem to maximize the network throughput. To address the issue\nof partial CSI, we rewrite the aforementioned optimization problem, by relying\nonly on the user direction. Performance evaluation of the proposed schemes is\ndeveloped in rural environment, based on the New York University\nmillimeter-wave simulator. The obtained results demonstrate that the proposed\nlow-complexity NOMA-DBS schemes with either full-or partial-CSI achieve\nsignificant performance improvement over the classical DBS, in terms of\nspectral-and energy-efficiencies (up to 26.8% bps/Hz rate gain for 45 users\nusing the proposed scheme with partial CSI).\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:09:25 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Khaled", "Israa", "", "IMT Atlantique - ELEC, LU"], ["Langlais", "Charlotte", "", "IMT\n  Atlantique - ELEC"], ["Falou", "Ammar", "", "LU"], ["Elhassan", "Bachar", "", "LU"], ["Jezequel", "Michel", "", "IMT Atlantique - ELEC"]]}, {"id": "2011.10563", "submitter": "Konstantinos Kousias", "authors": "Konstantinos Kousias, Apostolos Pappas, Ozgu Alay, Antonios Argyriou\n  and Michael Riegler", "title": "Long Short Term Memory Networks for Bandwidth Forecasting in Mobile\n  Broadband Networks under Mobility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bandwidth forecasting in Mobile Broadband (MBB) networks is a challenging\ntask, particularly when coupled with a degree of mobility. In this work, we\nintroduce HINDSIGHT++, an open-source R-based framework for bandwidth\nforecasting experimentation in MBB networks with Long Short Term Memory (LSTM)\nnetworks. We instrument HINDSIGHT++ following an Automated Machine Learning\n(AutoML) paradigm to first, alleviate the burden of data preprocessing, and\nsecond, enhance performance related aspects. We primarily focus on bandwidth\nforecasting for Fifth Generation (5G) networks. In particular, we leverage\n5Gophers, the first open-source attempt to measure network performance on\noperational 5G networks in the US. We further explore the LSTM performance\nboundaries on Fourth Generation (4G) commercial settings using NYU-METS, an\nopen-source dataset comprising of hundreds of bandwidth traces spanning\ndifferent mobility scenarios. Our study aims to investigate the impact of\nhyperparameter optimization on achieving state-of-the-art performance and\nbeyond. Results highlight its significance under 5G scenarios showing an\naverage Mean Absolute Error (MAE) decrease of near 30% when compared to prior\nstate-of-the-art values. Due to its universal design, we argue that HINDSIGHT++\ncan serve as a handy software tool for a multitude of applications in other\nscientific fields.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 18:59:27 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Kousias", "Konstantinos", ""], ["Pappas", "Apostolos", ""], ["Alay", "Ozgu", ""], ["Argyriou", "Antonios", ""], ["Riegler", "Michael", ""]]}, {"id": "2011.10602", "submitter": "Thembelihle Dlamini", "authors": "Thembelihle Dlamini, Sifiso Vilakati", "title": "LSTM-based Traffic Load Balancing and Resource Allocation for an Edge\n  System", "comments": "8 Figures, 13 pages", "journal-ref": "Wireless Communications and Mobile Computing, 2020", "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The massive deployment of small cell Base Stations (SBSs) empowered with\ncomputing capabilities presents one of the most ingenious solutions adopted for\n5G cellular networks towards meeting the foreseen data explosion and the\nultra-low latency demanded by mobile applications. This empowerment of SBSs\nwith Multi-access Edge Computing (MEC) has emerged as a tentative solution to\novercome the latency demands and bandwidth consumption required by mobile\napplications at the network edge. The MEC paradigm offers a limited amount of\nresources to support computation, thus mandating the use of intelligence\nmechanisms for resource allocation. The use of green energy for powering the\nnetwork apparatuses (e.g., Base Stations (BSs), MEC servers) has attracted\nattention towards minimizing the carbon footprint and network operational\ncosts. However, due to their high intermittency and unpredictability, the\nadoption of learning methods is a requisite. Towards intelligent edge system\nmanagement, this paper proposes a Green-based Edge Network Management (GENM)\nalgorithm, which is a online edge system management algorithm for enabling\ngreen-based load balancing in BSs and energy savings within the MEC server. The\nmain goal is to minimize the overall energy consumption and guarantee the\nQuality of Service (QoS) within the network. To achieve this, the GENM\nalgorithm performs dynamic management of BSs, autoscaling and reconfiguration\nof the computing resources, and on/off switching of the fast tunable laser\ndrivers coupled with location-aware traffic scheduling in the MEC server. The\nobtained simulation results validate our analysis and demonstrate the superior\nperformance of GENM compared to a benchmark algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 19:27:48 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Dlamini", "Thembelihle", ""], ["Vilakati", "Sifiso", ""]]}, {"id": "2011.10799", "submitter": "Boris Chidlovskii", "authors": "Leonid Antsfeld, Boris Chidlovskii, Emilio Sansano-Sansano", "title": "Deep Smartphone Sensors-WiFi Fusion for Indoor Positioning and Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the indoor localization problem, where the goal is to predict\nuser's trajectory from the data collected by their smartphone, using inertial\nsensors such as accelerometer, gyroscope and magnetometer, as well as other\nenvironment and network sensors such as barometer and WiFi. Our system\nimplements a deep learning based pedestrian dead reckoning (deep PDR) model\nthat provides a high-rate estimation of the relative position of the user.\nUsing Kalman Filter, we correct the PDR's drift using WiFi that provides a\nprediction of the user's absolute position each time a WiFi scan is received.\nFinally, we adjust Kalman Filter results with a map-free projection method that\ntakes into account the physical constraints of the environment (corridors,\ndoors, etc.) and projects the prediction on the possible walkable paths. We\ntest our pipeline on IPIN'19 Indoor Localization challenge dataset and\ndemonstrate that it improves the winner's results by 20\\% using the challenge\nevaluation protocol.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 14:20:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Antsfeld", "Leonid", ""], ["Chidlovskii", "Boris", ""], ["Sansano-Sansano", "Emilio", ""]]}, {"id": "2011.10813", "submitter": "Zirui Xu", "authors": "Zirui Xu, Jinjun Xiong, Fuxun Yu, Xiang Chen", "title": "Efficient Neural Network Implementation with Quadratic Neuron", "comments": "2 pages, 1 figure, accepted by 2020 3rd IBM IEEE CAS/EDS AI Compute\n  Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous works proved that the combination of the linear neuron network with\nnonlinear activation functions (e.g. ReLu) can achieve nonlinear function\napproximation. However, simply widening or deepening the network structure will\nintroduce some training problems. In this work, we are aiming to build a\ncomprehensive second-order CNN implementation framework that includes\nneuron/network design and system deployment optimization.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 15:46:46 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Xu", "Zirui", ""], ["Xiong", "Jinjun", ""], ["Yu", "Fuxun", ""], ["Chen", "Xiang", ""]]}, {"id": "2011.10892", "submitter": "Umut Can Cabuk", "authors": "Umut Can Cabuk, Vahid Khalilpour Akram, Orhan Dagdeviren", "title": "Analysis of Movement-Based Connectivity Restoration Problem in Wireless\n  Ad-Hoc and Sensor Networks", "comments": "International Conference on Artificial Intelligence and Applied\n  Mathematics in Engineering (ICAIAME) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Topology control, including topology construction and maintenance phases, is\na vital conception for wireless ad-hoc networks of any kind, expressly the\nwireless sensor networks (WSN). Topology maintenance, the latter phase,\nconcerns several problems, such as optimizing the energy consumption,\nincreasing the data rate, making clusters, and sustaining the connectivity. A\ndisconnected network, among other strategies, can efficiently be connected\nagain using a Movement-based Connectivity Restoration (MCR) method, where a\ncommensurate number of nodes move (or are moved) to the desired positions.\nHowever, finding an optimal route for the nodes to be moved can be a formidable\nproblem. As a matter of fact, this paper presents details regarding a direct\nproof of the NP-Completeness of the MCR Problem by a reduction of the\nwell-studied Steiner Tree Problem using the minimum number of Steiner points\nand the bounded edge length.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 23:25:19 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Cabuk", "Umut Can", ""], ["Akram", "Vahid Khalilpour", ""], ["Dagdeviren", "Orhan", ""]]}, {"id": "2011.10911", "submitter": "Meenakshi Syamkumar", "authors": "Meenakshi Syamkumar, Yugali Gullapalli, Wei Tang, Paul Barford, Joel\n  Sommers", "title": "BigBen: Telemetry Processing for Internet-wide Event Monitoring", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes BigBen, a network telemetry processing system designed\nto enable accurate and timely reporting of Internet events (e.g., outages,\nattacks and configuration changes). BigBen is distinct from other Internet-wide\nevent detection systems in its use of passive measurements of Network Time\nProtocol (NTP) traffic. We describe the architecture of BigBen, which includes\n(i) a distributed NTP traffic collection component, (ii) an Extract Transform\nLoad (ETL) component, (iii) an event identification component, and (iv) a\nvisualization and reporting component. We also describe a cloud-based\nimplementation of BigBen developed to process large NTP data sets and provide\ndaily event reporting. We demonstrate BigBen on a 15.5TB corpus of NTP data. We\nshow that our implementation is efficient and could support hourly event\nreporting. We show that BigBen identifies a wide range of Internet events\ncharacterized by their location, scope and duration. We compare the events\ndetected by BigBen vs. events detected by a large active probe-based detection\nsystem. We find only modest overlap and show how BigBen provides details on\nevents that are not available from active measurements. Finally, we report on\nthe perspective that BigBen provides on Internet events that were reported by\nthird parties. In each case, BigBen confirms the event and provides details\nthat were not available in prior reports, highlighting the utility of the\npassive, NTP-based approach.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 01:42:36 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Syamkumar", "Meenakshi", ""], ["Gullapalli", "Yugali", ""], ["Tang", "Wei", ""], ["Barford", "Paul", ""], ["Sommers", "Joel", ""]]}, {"id": "2011.11126", "submitter": "Umut Can Cabuk", "authors": "Mustafa Tosun, Umut Can Cabuk, Vahid Khalilpour Akram, Orhan\n  Dagdeviren", "title": "On Connectivity-Aware Distributed Mobility Models for Area Coverage in\n  Drone Networks", "comments": "International Conference on Artificial Intelligence and Applied\n  Mathematics in Engineering (ICAIAME) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Drone networks are becoming increasingly popular in recent years and they are\nbeing used in many applications such as area coverage, delivery systems,\nmilitary operations, etc. Area coverage is a broad family of applications where\na group of connected drones collaboratively visit the whole or parts of an area\nto fulfill a specific objective and is widely being researched. Accordingly,\ndifferent mobility models have been designed to define the rules of movements\nof the participating drones. However, most of them do not consider the network\nconnectivity which is crucial, plus many models lack the priorities and\noptimization strategies that are important for drone networks. Therefore within\nthis study, three known connectivity-aware mobility models have been analyzed\ncomparatively. Two non-connectivity-aware mobility models have further been\nimplemented to catch the placebo effect if any. Per the detailed experiments on\nthe mobility models, coverage rates, connectivity levels, and message traffic\nhave been evaluated. The study shows that the Distributed Pheromone Repel (DPR)\nmodel provides a decent coverage performance, while the Connectivity-based\nmodel and the Connected Coverage model provide better connectivity and\ncommunication quality.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 22:31:26 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Tosun", "Mustafa", ""], ["Cabuk", "Umut Can", ""], ["Akram", "Vahid Khalilpour", ""], ["Dagdeviren", "Orhan", ""]]}, {"id": "2011.11138", "submitter": "Jie Gao", "authors": "Jie Gao, Weihua Zhuang, Mushu Li, Xuemin (Sherman) Shen, Xu Li", "title": "MAC for Machine Type Communications in Industrial IoT -- Part I:\n  Protocol Design and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this two-part paper, we propose a novel medium access control (MAC)\nprotocol for machine-type communications in the industrial internet of things.\nThe considered use case features a limited geographical area and a massive\nnumber of devices with sporadic data traffic and different priority types. We\ntarget at supporting the devices while satisfying their quality of service\n(QoS) requirements with a single access point and a single channel, which\nnecessitates a customized design that can significantly improve the MAC\nperformance. In Part I of this paper, we present the MAC protocol that\ncomprises a new slot structure, corresponding channel access procedure, and\nmechanisms for supporting high device density and providing differentiated QoS.\nA key idea behind this protocol is sensing-based distributed coordination for\nsignificantly improving channel utilization. To characterize the proposed\nprotocol, we analyze its delay performance based on the packet arrival rates of\ndevices. The analytical results provide insights and lay the groundwork for the\nfine-grained scheduling with QoS guarantee as presented in Part II.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 23:33:41 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Gao", "Jie", "", "Sherman"], ["Zhuang", "Weihua", "", "Sherman"], ["Li", "Mushu", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""], ["Li", "Xu", ""]]}, {"id": "2011.11139", "submitter": "Jie Gao", "authors": "Jie Gao, Mushu Li, Weihua Zhuang, Xuemin (Sherman) Shen, Xu Li", "title": "MAC for Machine Type Communications in Industrial IoT -- Part II:\n  Scheduling and Numerical Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the second part of this paper, we develop a centralized packet\ntransmission scheduling scheme to pair with the protocol designed in Part I and\ncomplete our medium access control (MAC) design for machine-type communications\nin the industrial internet of things. For the networking scenario, fine-grained\nscheduling that attends to each device becomes necessary, given stringent\nquality of service (QoS) requirements and diversified service types, but\nprohibitively complex for a large number of devices. To address this challenge,\nwe propose a scheduling solution in two steps. First, we develop algorithms for\ndevice assignment based on the analytical results from Part I, when parameters\nof the proposed protocol are given. Then, we train a deep neural network for\nassisting in the determination of the protocol parameters. The two-step\napproach ensures the accuracy and granularity necessary for satisfying the QoS\nrequirements and avoids excessive complexity from handling a large number of\ndevices. Integrating the distributed coordination in the protocol design from\nPart I and the centralized scheduling from this part, the proposed MAC protocol\nachieves high performance, demonstrated through extensive simulations. For\nexample, the results show that the proposed MAC can support 1000 devices under\nan aggregated traffic load of 3000 packets per second with a single channel and\nachieve <0.5ms average delay and <1% average collision probability among 50\nhigh priority devices.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 23:33:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Gao", "Jie", "", "Sherman"], ["Li", "Mushu", "", "Sherman"], ["Zhuang", "Weihua", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""], ["Li", "Xu", ""]]}, {"id": "2011.11450", "submitter": "Petr Hn\\v{e}tynka", "authors": "Lubom\\'ir Bulej, Tom\\'a\\v{s} Bure\\v{s}, Adam Filandr, Petr\n  Hn\\v{e}tynka, Iveta Hn\\v{e}tynkova, Jan Pacovsk\\'y, Gabor Sandor, Ilias\n  Gerostathopoulos", "title": "Managing Latency in Edge-Cloud Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Modern Cyber-physical Systems (CPS) include applications like smart traffic,\nsmart agriculture, smart power grid, etc. Commonly, these systems are\ndistributed and composed of end-user applications and microservices that\ntypically run in the cloud. The connection with the physical world, which is\ninherent to CPS, brings the need to operate and respond in real-time. As the\ncloud becomes part of the computation loop, the real-time requirements have to\nbe also reflected by the cloud. In this paper, we present an approach that\nprovides soft real-time guarantees on the response time of services running in\ncloud and edge-cloud (i.e., cloud geographically close to the end-user), where\nthese services are developed in high-level programming languages. In\nparticular, we elaborate a method that allows us to predict the upper bound of\nthe response time of a service when sharing the same computer with other\nservices. Importantly, as our approach focuses on minimizing the impact on the\ndeveloper of such services, it does not require any special programming model\nnor limits usage of common libraries, etc.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 14:52:43 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bulej", "Lubom\u00edr", ""], ["Bure\u0161", "Tom\u00e1\u0161", ""], ["Filandr", "Adam", ""], ["Hn\u011btynka", "Petr", ""], ["Hn\u011btynkova", "Iveta", ""], ["Pacovsk\u00fd", "Jan", ""], ["Sandor", "Gabor", ""], ["Gerostathopoulos", "Ilias", ""]]}, {"id": "2011.11463", "submitter": "Yu-Pin Hsu", "authors": "Yu-Pin Hsu", "title": "Efficient Broadcast for Timely Updates in Mobile Networks", "comments": "6 pages, technical report for the IEEE CL paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study considers a wireless network where an access point (AP) broadcasts\ntimely updates to numerous mobile users. The timeliness of information owned by\na user is characterized by the age of information. Frequently broadcasting the\ntimely updates at constant maximum power can minimize the age of information\nfor all users, but wastes valuable communication resources (ie., time and\nenergy). To address the age-energy trade-off, it is critical to develop an\nefficient scheduling algorithm that identifies broadcast times and allocates\npower. Moreover, unpredictable user movement would cause rapidly varying\ncommunication channels; in particular, those channels can be non-stationary.\nOur main contribution is to develop an online scheduling algorithm and a\nchannel-agnostic scheduling algorithm for such a mobile network with a provable\nperformance guarantee.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 15:21:15 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 08:53:08 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 05:35:40 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 01:45:40 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Hsu", "Yu-Pin", ""]]}, {"id": "2011.11876", "submitter": "Nway Nway Ei", "authors": "Nway Nway Ei, Madyan Alsenwi, Yan Kyaw Tun, Zhu Han, and Choong Seon\n  Hong", "title": "Energy-Efficient Resource Allocation in Multi-UAV-Assisted Two-Stage\n  Edge Computing for Beyond 5G Networks", "comments": "This paper was submitted to IEEE Transactions on Intelligent\n  Transportation System", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicle (UAV)-assisted multi-access edge computing (MEC) has\nbecome one promising solution for energy-constrained devices to meet the\ncomputation demand and the stringent delay requirement. In this work, we\ninvestigate a multiple UAVs-assisted two-stage MEC system in which the\ncomputation-intensive and delay-sensitive tasks of mobile devices (MDs) are\ncooperatively executed on both MEC-enabled UAVs and terrestrial base station\n(TBS) attached with the MEC server. Specifically, UAVs provide the computing\nand relaying services to the mobile devices. In this regard, we formulate a\njoint task offloading, communication and computation resource allocation\nproblem to minimize the energy consumption of MDs and UAVs by considering the\nlimited communication resources for the uplink transmission, the computation\nresources of UAVs and the tolerable latency of the tasks. The formulated\nproblem is a mixed-integer non-convex problem which is NP hard. Thus, we relax\nthe channel assignment variable from the binary to continuous values. However,\nthe problem is still non-convex due to the coupling among the variables. To\nsolve the formulated optimization problem, we apply the Block Successive\nUpper-bound Minimization (BSUM) method which guarantees to obtain the\nstationary points of the non-convex objective function. In essence, the\nnon-convex objective function is decomposed into multiple subproblems which are\nthen solved in a block-by-block manner. Finally, the extensive evaluation\nresults are conducted to show the superior performance of our proposed\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 03:33:16 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Ei", "Nway Nway", ""], ["Alsenwi", "Madyan", ""], ["Tun", "Yan Kyaw", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2011.11995", "submitter": "Silas Lobo", "authors": "Silas C. Lobo, Stefan Neumeier, Evelio M. G. Fernandez, Christian\n  Facchi", "title": "InTAS -- The Ingolstadt Traffic Scenario for SUMO", "comments": "Paper presented on SUMO User Conference 2020 The scenario is freely\n  available at https://github.com/silaslobo/InTAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Vehicular Ad Hoc Networks (VANETs) are expected to be the next big step\ntowards safer road transport, supporting applications to exchange information\nbetween vehicles. To develop novel applications for this area a high number of\ntests, considering all traffic situations, are demanded. However, it is\nunfeasible to reproduce these tests in real life, by the fact that any failure\non the applications would cause severe impacts on transport system safety and\ncould risk human lives. Thus, this paper presents the concept, model, and\nvalidation for InTAS, a realistic traffic scenario for Ingolstadt. InTAS road\ntopology accurately represents Ingolstadt real road map. Elements such as\nbuildings, bus stops, and traffic lights were added to the map. Twenty traffic\nlights systems were simulated according to the real program deployed on the\ntraffic lights. Traffic demand was modeled based on the activitygen method,\nconsidering demographic data and real-traffic information. The city public\ntransport system was also simulated accordingly to bus time-tables and their\nroutes. The simulation step was implemented considering the best value for\ndevice.rerouting.probability, which was defined by evaluating InTAS output and\nreal traffic data. The scenario was validated by comparing real-traffic data\nfrom 24 measurement points with InTAS simulation results.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 09:47:02 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Lobo", "Silas C.", ""], ["Neumeier", "Stefan", ""], ["Fernandez", "Evelio M. G.", ""], ["Facchi", "Christian", ""]]}, {"id": "2011.12035", "submitter": "Emmanuel Baccelli", "authors": "Gabriele Restuccia, Hannes Tschofenig, Emmanuel Baccelli", "title": "Low-Power IoT Communication Security: On the Performance of DTLS and TLS\n  1.3", "comments": null, "journal-ref": "In proceedings of IFIP/IEEE PEMWN 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarly to elsewhere on the Internet, practical security in the Internet of\nThings (IoT) is achieved by combining an array of mechanisms, at work at all\nlayers of the protocol stack, in system software, and in hardware. Standard\nprotocols such as Datagram Transport Layer Security (DTLS 1.2) and Transport\nLayer Security (TLS 1.2) are often recommended to secure communications to/from\nIoT devices. Recently, the TLS 1.3 standard was released and DTLS 1.3 is in the\nfinal stages of standardization. In this paper, we give an overview of version\n1.3 of these protocols, and we provide the first experimental comparative\nperformance analysis of different implementations and various configurations of\nthese protocols, on real IoT devices based on low-power microcontrollers. We\nshow how different implementations lead to different compromises. We measure\nand compare bytes-over-the-air, memory footprint, and energy consumption. We\nshow that, when DTLS/TLS 1.3 requires more resources than DTLS/TLS 1.2, this\nadditional overhead is quite reasonable. We also observe that, in some\nconfigurations, DTLS/TLS 1.3 actually decreases overhead and resource\nconsumption. All in all, our study indicates that there is still room to\noptimize the existing implementations of these protocols.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 11:27:39 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 07:53:57 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Restuccia", "Gabriele", ""], ["Tschofenig", "Hannes", ""], ["Baccelli", "Emmanuel", ""]]}, {"id": "2011.12047", "submitter": "Emmanuel Baccelli", "authors": "Koen Zandberg, Emmanuel Baccelli", "title": "Minimal Virtual Machines on IoT Microcontrollers: The Case of Berkeley\n  Packet Filters with rBPF", "comments": null, "journal-ref": "In proceedings of IFIP/IEEE PEMWN 2020", "doi": null, "report-no": null, "categories": "cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual machines (VM) are widely used to host and isolate software modules.\nHowever, extremely small memory and low-energy budgets have so far prevented\nwide use of VMs on typical microcontroller-based IoT devices. In this paper, we\nexplore the potential of two minimal VM approaches on such low-power hardware.\nWe design rBPF, a register-based VM based on extended Berkeley Packet Filters\n(eBPF). We compare it with a stack-based VM based on WebAssembly (Wasm) adapted\nfor embedded systems. We implement prototypes of each VM, hosted in the IoT\noperating system RIOT. We perform measurements on commercial off-the-shelf IoT\nhardware. Unsurprisingly, we observe that both Wasm and rBPF virtual machines\nyield execution time and memory overhead, compared to not using a VM. We show\nhowever that this execution time overhead is tolerable for low-throughput,\nlow-energy IoT devices. We further show that, while using a VM based on Wasm\nentails doubling the memory budget for a simple networked IoT application using\na 6LoWPAN/CoAP stack, using a VM based on rBPF requires only negligible memory\noverhead (less than 10% more memory). rBPF is thus a promising approach to host\nsmall software modules, isolated from OS software, and updatable on-demand,\nover low-power networks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 11:46:00 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 08:15:30 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Zandberg", "Koen", ""], ["Baccelli", "Emmanuel", ""]]}, {"id": "2011.12095", "submitter": "Spyridon Mastorakis", "authors": "Muhammad Atif Ur Rehman and Rehmat Ullah and Byung-Seo Kim and Boubakr\n  Nour and Spyridon Mastorakis", "title": "CCIC-WSN: An Architecture for Single Channel Cluster-based\n  Information-Centric Wireless Sensor Networks", "comments": "This paper has been accepted for publication by the IEEE Internet of\n  Things Journal. The copyright is with IEEE and the final version will be\n  published by IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The promising vision of Information-Centric Networking (ICN) and of its\nrealization, Named Data Networking (NDN), has attracted extensive attention in\nrecent years in the context of the Internet of Things (IoT) and Wireless Sensor\nNetworks (WSNs). However, a comprehensive NDN/ICN-based architectural design\nfor WSNs, including specially tailored naming schemes and forwarding\nmechanisms, has yet to be explored. In this paper, we present single-Channel\nCluster-based Information-Centric WSN (CCIC-WSN), an NDN/ICN-based framework to\nfulfill the requirements of cluster-based WSNs, such as communication between\nchild nodes and cluster heads, association of new child nodes with cluster\nheads, discovery of the namespace of newly associated nodes, and child node\nmobility. Through an extensive simulation study, we demonstrate that CCIC-WSN\nachieves 71-90% lower energy consumption and 74-96% lower data retrieval delays\nthan recently proposed frameworks for NDN/ICN-based WSNs under various\nevaluation settings.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 14:02:37 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Rehman", "Muhammad Atif Ur", ""], ["Ullah", "Rehmat", ""], ["Kim", "Byung-Seo", ""], ["Nour", "Boubakr", ""], ["Mastorakis", "Spyridon", ""]]}, {"id": "2011.12288", "submitter": "Srinivasan Sridharan", "authors": "Srinivasan Sridharan", "title": "Machine Learning (ML) In a 5G Standalone (SA) Self Organizing Network\n  (SON)", "comments": "5G, Machine learning (ML), Self-organizing Networks (SONs), 5G\n  Standalone, Artificial Intelligence (AI)", "journal-ref": null, "doi": "10.14445/22312803/IJCTT-V68I11P105", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is included in Self-organizing Networks (SONs) that are\nkey drivers for enhancing the Operations, Administration, and Maintenance (OAM)\nactivities. It is included in the 5G Standalone (SA) system is one of the 5G\ncommunication tracks that transforms 4G networking to next-generation\ntechnology that is based on mobile applications. The research's main aim is to\nan overview of machine learning (ML) in 5G standalone core networks. 5G\nStandalone is considered a key enabler by the service providers as it improves\nthe efficacy of the throughput that edges the network. It also assists in\nadvancing new cellular use cases like ultra-reliable low latency communications\n(URLLC) that supports combinations of frequencies.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 18:57:40 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Sridharan", "Srinivasan", ""]]}, {"id": "2011.12644", "submitter": "Luis F. Abanto-Leon", "authors": "Luis F. Abanto-Leon and Andreas Baeuml and Gek Hong (Allyson) Sim and\n  Matthias Hollick and Arash Asadi", "title": "Stay Connected, Leave no Trace: Enhancing Security and Privacy in WiFi\n  via Obfuscating Radiometric Fingerprints", "comments": "ACM Sigmetrics 2021 / In Proc. ACM Meas. Anal. Comput. Syst., Vol. 4,\n  3, Article 44 (December 2020)", "journal-ref": null, "doi": "10.1145/3428329", "report-no": null, "categories": "cs.CR cs.CY cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The intrinsic hardware imperfection of WiFi chipsets manifests itself in the\ntransmitted signal, leading to a unique radiometric fingerprint. This\nfingerprint can be used as an additional means of authentication to enhance\nsecurity. In fact, recent works propose practical fingerprinting solutions that\ncan be readily implemented in commercial-off-the-shelf devices. In this paper,\nwe prove analytically and experimentally that these solutions are highly\nvulnerable to impersonation attacks. We also demonstrate that such a unique\ndevice-based signature can be abused to violate privacy by tracking the user\ndevice, and, as of today, users do not have any means to prevent such privacy\nattacks other than turning off the device.\n  We propose RF-Veil, a radiometric fingerprinting solution that not only is\nrobust against impersonation attacks but also protects user privacy by\nobfuscating the radiometric fingerprint of the transmitter for non-legitimate\nreceivers. Specifically, we introduce a randomized pattern of phase errors to\nthe transmitted signal such that only the intended receiver can extract the\noriginal fingerprint of the transmitter. In a series of experiments and\nanalyses, we expose the vulnerability of adopting naive randomization to\nstatistical attacks and introduce countermeasures. Finally, we show the\nefficacy of RF-Veil experimentally in protecting user privacy and enhancing\nsecurity. More importantly, our proposed solution allows communicating with\nother devices, which do not employ RF-Veil.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:10:59 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 12:25:18 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Abanto-Leon", "Luis F.", "", "Allyson"], ["Baeuml", "Andreas", "", "Allyson"], ["Hong", "Gek", "", "Allyson"], ["Sim", "", ""], ["Hollick", "Matthias", ""], ["Asadi", "Arash", ""]]}, {"id": "2011.12691", "submitter": "Yong Xiao", "authors": "Yong Xiao and Yingyu Li and Guangming Shi and H. Vincent Poor", "title": "Optimizing Resource-Efficiency for Federated Edge Intelligence in IoT\n  Networks", "comments": "Accepted at International Conference on Wireless Communications and\n  Signal Processing (WCSP), Nanjing, China, October 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies an edge intelligence-based IoT network in which a set of\nedge servers learn a shared model using federated learning (FL) based on the\ndatasets uploaded from a multi-technology-supported IoT network. The data\nuploading performance of IoT network and the computational capacity of edge\nservers are entangled with each other in influencing the FL model training\nprocess. We propose a novel framework, called federated edge intelligence\n(FEI), that allows edge servers to evaluate the required number of data samples\naccording to the energy cost of the IoT network as well as their local data\nprocessing capacity and only request the amount of data that is sufficient for\ntraining a satisfactory model. We evaluate the energy cost for data uploading\nwhen two widely-used IoT solutions: licensed band IoT (e.g., 5G NB-IoT) and\nunlicensed band IoT (e.g., Wi-Fi, ZigBee, and 5G NR-U) are available to each\nIoT device. We prove that the cost minimization problem of the entire IoT\nnetwork is separable and can be divided into a set of subproblems, each of\nwhich can be solved by an individual edge server. We also introduce a mapping\nfunction to quantify the computational load of edge servers under different\ncombinations of three key parameters: size of the dataset, local batch size,\nand number of local training passes. Finally, we adopt an Alternative Direction\nMethod of Multipliers (ADMM)-based approach to jointly optimize energy cost of\nthe IoT network and average computing resource utilization of edge servers. We\nprove that our proposed algorithm does not cause any data leakage nor disclose\nany topological information of the IoT network. Simulation results show that\nour proposed framework significantly improves the resource efficiency of the\nIoT network and edge servers with only a limited sacrifice on the model\nconvergence performance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 12:51:59 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Xiao", "Yong", ""], ["Li", "Yingyu", ""], ["Shi", "Guangming", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2011.12715", "submitter": "Jayant A. Gupchup", "authors": "Jayant Gupchup, Ashkan Aazami, Yaran Fan, Senja Filipi, Tom Finley,\n  Scott Inglis, Marcus Asteborg, Luke Caroll, Rajan Chari, Markus Cozowicz,\n  Vishak Gopal, Vinod Prakash, Sasikanth Bendapudi, Jack Gerrits, Eric Lau,\n  Huazhou Liu, Marco Rossi, Dima Slobodianyk, Dmitri Birjukov, Matty Cooper,\n  Nilesh Javar, Dmitriy Perednya, Sriram Srinivasan, John Langford, Ross\n  Cutler, Johannes Gehrke", "title": "Resonance: Replacing Software Constants with Context-Aware Models in\n  Real-time Communication", "comments": "Workshop on ML for Systems at NeurIPS 2020, Accepted", "journal-ref": "ML for Systems, NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large software systems tune hundreds of 'constants' to optimize their runtime\nperformance. These values are commonly derived through intuition, lab tests, or\nA/B tests. A 'one-size-fits-all' approach is often sub-optimal as the best\nvalue depends on runtime context. In this paper, we provide an experimental\napproach to replace constants with learned contextual functions for Skype - a\nwidely used real-time communication (RTC) application. We present Resonance, a\nsystem based on contextual bandits (CB). We describe experiences from three\nreal-world experiments: applying it to the audio, video, and transport\ncomponents in Skype. We surface a unique and practical challenge of performing\nmachine learning (ML) inference in large software systems written using\nencapsulation principles. Finally, we open-source FeatureBroker, a library to\nreduce the friction in adopting ML models in such development environments\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 00:34:56 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Gupchup", "Jayant", ""], ["Aazami", "Ashkan", ""], ["Fan", "Yaran", ""], ["Filipi", "Senja", ""], ["Finley", "Tom", ""], ["Inglis", "Scott", ""], ["Asteborg", "Marcus", ""], ["Caroll", "Luke", ""], ["Chari", "Rajan", ""], ["Cozowicz", "Markus", ""], ["Gopal", "Vishak", ""], ["Prakash", "Vinod", ""], ["Bendapudi", "Sasikanth", ""], ["Gerrits", "Jack", ""], ["Lau", "Eric", ""], ["Liu", "Huazhou", ""], ["Rossi", "Marco", ""], ["Slobodianyk", "Dima", ""], ["Birjukov", "Dmitri", ""], ["Cooper", "Matty", ""], ["Javar", "Nilesh", ""], ["Perednya", "Dmitriy", ""], ["Srinivasan", "Sriram", ""], ["Langford", "John", ""], ["Cutler", "Ross", ""], ["Gehrke", "Johannes", ""]]}, {"id": "2011.12978", "submitter": "Lan Wei", "authors": "Lan Wei, John Heidemann", "title": "Whac-A-Mole: Six Years of DNS Spoofing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNS is important in nearly all interactions on the Internet. All large DNS\noperators use IP anycast, announcing servers in BGP from multiple physical\nlocations to reduce client latency and provide capacity. However, DNS is easy\nto spoof: third parties intercept and respond to queries for benign or\nmalicious purposes. Spoofing is of particular risk for services using anycast,\nsince service is already announced from multiple origins. In this paper, we\ndescribe methods to identify DNS spoofing, infer the mechanism being used, and\nidentify organizations that spoof from historical data. Our methods detect\novert spoofing and some covertly-delayed answers, although a very diligent\nadversarial spoofer can hide. We use these methods to study more than six years\nof data about root DNS servers from thousands of vantage points. We show that\nspoofing today is rare, occurring only in about 1.7% of observations. However,\nthe rate of DNS spoofing has more than doubled in less than seven years, and it\noccurs globally. Finally, we use data from B-Root DNS to validate our methods\nfor spoof detection, showing a true positive rate over 0.96. B-Root confirms\nthat spoofing occurs with both DNS injection and proxies, but proxies account\nfor nearly all spoofing we see.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 19:02:05 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Wei", "Lan", ""], ["Heidemann", "John", ""]]}, {"id": "2011.12996", "submitter": "Jayasree Sengupta", "authors": "Somnath Karmakar and Jayasree Sengupta and Sipra Das Bit", "title": "LEADER: Low Overhead Rank Attack Detection for Securing RPL based IoT", "comments": "9 pages, 9 figures, 4 tables. Accepted at 13th International\n  Conference on COMmunication Systems & NETworkS (COMSNETS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent times researchers have found several security vulnerabilities in\nthe Routing Protocol for Low power and Lossy network (RPL), amongst which rank\nattack is a predominant one causing detrimental effects on the network by\ncreating a fake topology. To address this concern, we propose a low-overhead\nrank attack detection scheme for non-storing mode of RPL used in IoT to deal\nwith both increased and decreased rank attacks. Accordingly, we have modified\nthe RPL Destination Oriented Directed Acyclic Graph (DODAG) formation algorithm\nto detect rank attacks during topology formation and maintenance. The\ndistributed module of the algorithm runs in all the participating nodes whereas\nthe centralized module runs in the sink. Unlike many existing schemes, instead\nof sending additional control message, we make the scheme low-overhead by\nsimply modifying the DAO control message. Additionally, a lightweight Message\nAuthentication Code (HMAC-LOCHA) is used to verify the integrity and\nauthenticity of the control messages exchanged between nodes and the sink. The\ncorrectness of the proposed scheme is established through a concrete proof\nusing multiple test case scenarios. Finally, the performance of the proposed\nscheme is evaluated both theoretically and through simulation in Contiki-based\nCooja simulator. Theoretical evaluation proves the energy efficiency of the\nscheme. Simulation results show that our scheme outperforms over a\nstate-of-the-art rank attack detection scheme in terms of detection accuracy,\nfalse positive or negative rate and energy consumption while also keeping\nacceptable network performance such as improved detection latency and at par\npacket delivery ratio.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 19:42:32 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Karmakar", "Somnath", ""], ["Sengupta", "Jayasree", ""], ["Bit", "Sipra Das", ""]]}, {"id": "2011.13075", "submitter": "Haoxin Wang", "authors": "Haoxin Wang, BaekGyu Kim, Jiang Xie and Zhu Han", "title": "Energy Drain of the Object Detection Processing Pipeline for Mobile\n  Devices: Analysis and Implications", "comments": "This is a personal copy of the authors. Not for redistribution. The\n  final version of this paper was accepted by IEEE Transactions on Green\n  Communications and Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CV cs.MM cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Applying deep learning to object detection provides the capability to\naccurately detect and classify complex objects in the real world. However,\ncurrently, few mobile applications use deep learning because such technology is\ncomputation-intensive and energy-consuming. This paper, to the best of our\nknowledge, presents the first detailed experimental study of a mobile augmented\nreality (AR) client's energy consumption and the detection latency of executing\nConvolutional Neural Networks (CNN) based object detection, either locally on\nthe smartphone or remotely on an edge server. In order to accurately measure\nthe energy consumption on the smartphone and obtain the breakdown of energy\nconsumed by each phase of the object detection processing pipeline, we propose\na new measurement strategy. Our detailed measurements refine the energy\nanalysis of mobile AR clients and reveal several interesting perspectives\nregarding the energy consumption of executing CNN-based object detection.\nFurthermore, several insights and research opportunities are proposed based on\nour experimental results. These findings from our experimental study will guide\nthe design of energy-efficient processing pipeline of CNN-based object\ndetection.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 00:32:07 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Wang", "Haoxin", ""], ["Kim", "BaekGyu", ""], ["Xie", "Jiang", ""], ["Han", "Zhu", ""]]}, {"id": "2011.13097", "submitter": "Shashi Raj Pandey", "authors": "Shashi Raj Pandey, Kitae Kim, Madyan Alsenwi, Yan Kyaw Tun, Zhu Han,\n  Choong Seon Hong", "title": "Latency-sensitive Service Delivery with UAV-Assisted 5G Networks", "comments": "Accepted in IEEE Wireless Communications Letters", "journal-ref": null, "doi": "10.1109/LWC.2021.3073014", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, a novel framework to deliver critical spread out URLLC\nservices deploying unmanned aerial vehicles (UAVs) in an out-of-coverage area\nis developed. To this end, the resource optimization problem, i.e., resource\nblocks (RBs) and power allocation, and optimal UAV deployment strategy are\nstudied for UAV-assisted 5G networks to jointly maximize the average sum-rate\nand minimize the transmit power of UAV while satisfying the URLLC requirements.\nTo cope with the sporadic URLLC traffic problem, an efficient online URLLC\ntraffic prediction model based on Gaussian Process Regression (GPR) is proposed\nwhich derives optimal URLLC scheduling and transmit power strategy. The\nformulated problem is revealed as a mixed-integer nonlinear programming\n(MINLP), which is solved following the introduced successive minimization\nalgorithm. Finally, simulation results are provided to show our proposed\nsolution approach's efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 02:30:10 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 06:04:07 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 02:35:19 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Pandey", "Shashi Raj", ""], ["Kim", "Kitae", ""], ["Alsenwi", "Madyan", ""], ["Tun", "Yan Kyaw", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2011.13152", "submitter": "Shengheng Liu", "authors": "Yongming Huang, Shengheng Liu, Cheng Zhang, Xiaohu You, Hequan Wu", "title": "True-data Testbed for 5G/B5G Intelligent Network", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.AR eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Future beyond fifth-generation (B5G) and sixth-generation (6G) mobile\ncommunications will shift from facilitating interpersonal communications to\nsupporting Internet of Everything (IoE), where intelligent communications with\nfull integration of big data and artificial intelligence (AI) will play an\nimportant role in improving network efficiency and providing high-quality\nservice. As a rapid evolving paradigm, the AI-empowered mobile communications\ndemand large amounts of data acquired from real network environment for\nsystematic test and verification. Hence, we build the world's first true-data\ntestbed for 5G/B5G intelligent network (TTIN), which comprises 5G/B5G on-site\nexperimental networks, data acquisition & data warehouse, and AI engine &\nnetwork optimization. In the TTIN, true network data acquisition, storage,\nstandardization, and analysis are available, which enable system-level online\nverification of B5G/6G-orientated key technologies and support data-driven\nnetwork optimization through the closed-loop control mechanism. This paper\nelaborates on the system architecture and module design of TTIN. Detailed\ntechnical specifications and some of the established use cases are also\nshowcased.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 06:42:36 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 08:51:23 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Huang", "Yongming", ""], ["Liu", "Shengheng", ""], ["Zhang", "Cheng", ""], ["You", "Xiaohu", ""], ["Wu", "Hequan", ""]]}, {"id": "2011.13224", "submitter": "Gunes Karabulut Kurt", "authors": "Gunes Karabulut Kurt and Halim Yanikomeroglu", "title": "Communication, Computing, Caching, and Sensing for Next Generation\n  Aerial Delivery Networks", "comments": "7 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the envisioned interactions between the information and\ncommunication technology and aerospace industries to serve autonomous devices\nfor next generation aerial parcel delivery networks. The autonomous features of\nfleet elements of the delivery network are enabled by the increased throughput,\nimproved coverage, and near-user computation capabilities of vertical\nheterogeneous networks (VHetNets). A high altitude platform station (HAPS),\nlocated around 20~km above the ground level in a quasi-stationary manner,\nserves as the main enabler of the vision we present. In addition to the sensing\npotential of the HAPS nodes, the use of communication, computing, and caching\ncapabilities demonstrate the attainability of the ambitious goal of serving a\nfully autonomous aerial fleet capable of addressing instantaneous user demands\nand enabling supply chain management interactions with delivery services in\nlow-latency settings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:50:43 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 19:37:49 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 12:43:34 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kurt", "Gunes Karabulut", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "2011.13556", "submitter": "R. Ghosh", "authors": "R K Ghosh, Vinay R and Arnab Bhattacharyya", "title": "Eco-Routing Using Open Street Maps", "comments": "16 pages, 17 figures, 41 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A vehicle's fuel consumption depends on its type, the speed, the condition,\nand the gradients of the road on which it is moving. We developed a Routing\nEngine for finding an eco-route (one with low fuel consumption) between a\nsource and a destination. Open Street Maps has data on road conditions. We used\nCGIAR-CSI road elevation data 16[4] to integrate the road gradients into the\nproposed route-finding algorithm that modifies Open Street Routing Machine\n(OSRM). It allowed us to dynamically predict a vehicle's velocity, considering\nboth the conditions and the road segment's slope. Using Highway EneRgy\nAssessment (HERA) methodology, we calculated the fuel consumed by a vehicle\ngiven its type and velocity. We have created both web and mobile interfaces\nthrough which users can specify Geo coordinates or human-readable addresses of\na source and a destination. The user interface graphically displays the route\nobtained from the proposed Routing Engine with a detailed travel itinerary.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 04:52:22 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Ghosh", "R K", ""], ["R", "Vinay", ""], ["Bhattacharyya", "Arnab", ""]]}, {"id": "2011.13634", "submitter": "Apostolos Avranas Mr", "authors": "Apostolos Avranas (EURECOM), Marios Kountouris (EURECOM), Philippe\n  Ciblat (T\\'el\\'ecom Paris)", "title": "Deep Reinforcement Learning for Wireless Scheduling with Multiclass\n  Services", "comments": "Corrected typos on formulas, Header removed, Corrected a misplaced\n  paragraph on B.1.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we investigate the problem of scheduling and resource\nallocation over a time varying set of clients with heterogeneous demands.In\nthis context, a service provider has to schedule traffic destined to users with\ndifferent classes of requirements and to allocate bandwidth resources over time\nas a means to efficiently satisfy service demands within a limited time\nhorizon. This is a highly intricate problem, in particular in wireless\ncommunication systems, and solutions may involve tools stemming from diverse\nfields, including combinatorics and constrained optimization. Although recent\nwork has successfully proposed solutions based on Deep Reinforcement Learning\n(DRL), the challenging setting of heterogeneous user traffic and demands has\nnot been addressed. We propose a deep deterministic policy gradient algorithm\nthat combines state-of-the-art techniques, namely Distributional RL and Deep\nSets, to train a model for heterogeneous traffic scheduling. We test on diverse\nscenarios with different time dependence dynamics, users' requirements, and\nresources available, demonstrating consistent results using both synthetic and\nreal data. We evaluate the algorithm on a wireless communication setting using\nboth synthetic and real data and show significant gains in terms of Quality of\nService (QoS) defined by the classes, against state-of-the-art conventional\nalgorithms from combinatorics, optimization and scheduling metric(e.g.\nKnapsack, Integer Linear Programming, Frank-Wolfe, Exponential Rule).\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 09:49:38 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 21:07:06 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Avranas", "Apostolos", "", "EURECOM"], ["Kountouris", "Marios", "", "EURECOM"], ["Ciblat", "Philippe", "", "T\u00e9l\u00e9com Paris"]]}, {"id": "2011.13676", "submitter": "Anderson Queiroz Aalq", "authors": "Anderson Queiroz, Eduardo Oliveira, Maria Barbosa and Kelvin Dias", "title": "A Survey on Blockchain and Edge Computing applied to the Internet of\n  Vehicles", "comments": "6 pages, 2 pictures and 1 table (IEEE International Conference on\n  Advanced Networks and Telecommunications Systems - Workshop on New Advances\n  on Vehicle-to-Everything (V2X) Communications and Networking, 14-17 December\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With the advent of Intelligent Transportation Systems (ITS), data from\ndiverse sensors either embedded into the vehicles or present along with the\nsmart city infrastructure, are of utmost importance and require both processing\npower and efficient trust mechanisms for information exchange in\nvehicle-to-everything (V2X) communications. To accomplish these requirements,\nboth edge computing and blockchain have been recently adopted towards a secure,\ndistributed, and computation empowered Internet of Vehicles (IoV). This paper\nsurveys prominent solutions for blockchain-based vehicular edge computing\n(VEC), provides a taxonomy, highlights their main features, advantages, and\nlimitations to provide subsidies for further proposals.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 11:25:20 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 14:37:05 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Queiroz", "Anderson", ""], ["Oliveira", "Eduardo", ""], ["Barbosa", "Maria", ""], ["Dias", "Kelvin", ""]]}, {"id": "2011.14167", "submitter": "Pouya Aminaie", "authors": "Pouya Aminaie and Poorya Aminaie", "title": "Profinet vs Profibus", "comments": "12 pages, 13 figure and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a step by step definition of Profinet and Profibus. We introduced\ndifferent types of each of the two communication protocols. Then, the topology\nand performance of each one has been described individually. Finally, the\nproperties of them have been compared to show that which one has a better\nperformance in the industry.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 17:00:02 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Aminaie", "Pouya", ""], ["Aminaie", "Poorya", ""]]}, {"id": "2011.14421", "submitter": "Maxime Labonne", "authors": "Maxime Labonne, Jorge L\\'opez, Claude Poletti, Jean-Baptiste Munier", "title": "Short-Term Flow-Based Bandwidth Forecasting using Machine Learning", "comments": "4 pages, 1 figure 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel framework to predict traffic flows' bandwidth\nahead of time. Modern network management systems share a common issue: the\nnetwork situation evolves between the moment the decision is made and the\nmoment when actions (countermeasures) are applied. This framework converts\npackets from real-life traffic into flows containing relevant features. Machine\nlearning models, including Decision Tree, Random Forest, XGBoost, and Deep\nNeural Network, are trained on these data to predict the bandwidth at the next\ntime instance for every flow. Predictions can be fed to the management system\ninstead of current flows bandwidth in order to take decisions on a more\naccurate network state. Experiments were performed on 981,774 flows and 15\ndifferent time windows (from 0.03s to 4s). They show that the Random Forest is\nthe best performing and most reliable model, with a predictive performance\nconsistently better than relying on the current bandwidth (+19.73% in mean\nabsolute error and +18.00% in root mean square error). Experimental results\nindicate that this framework can help network management systems to take more\ninformed decisions using a predicted network state.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 19:06:15 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 12:51:24 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Labonne", "Maxime", ""], ["L\u00f3pez", "Jorge", ""], ["Poletti", "Claude", ""], ["Munier", "Jean-Baptiste", ""]]}, {"id": "2011.14706", "submitter": "Mostafa Haghi Kashani", "authors": "Mostafa Haghi Kashani, Ahmad Ahmadzadeh, Ebrahim Mahdipour", "title": "Load balancing mechanisms in fog computing: A systematic review", "comments": "19 pages, 9 figures, 11 tables, 94 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, fog computing has been introduced as a modern distributed paradigm\nand complement to cloud computing to provide services. Fog system extends\nstoring and computing to the edge of the network, which can solve the problem\nabout service computing of the delay-sensitive applications remarkably besides\nenabling the location awareness and mobility support. Load balancing is an\nimportant aspect of fog networks that avoids a situation with some under-loaded\nor overloaded fog nodes. Quality of Service (QoS) parameters such as resource\nutilization, throughput, cost, response time, performance, and energy\nconsumption can be improved with load balancing. In recent years, some\nresearches in load balancing techniques in fog networks have been carried out,\nbut there is no systematic review to consolidate these studies. This article\nreviews the load-balancing mechanisms systematically in fog computing in four\nclassifications, including approximate, exact, fundamental, and hybrid methods\n(published between 2013 and August 2020). Also, this article investigates load\nbalancing metrics with all advantages and disadvantages related to chosen load\nbalancing mechanisms in fog networks. The evaluation techniques and tools\napplied for each reviewed study are explored as well. Additionally, the\nessential open challenges and future trends of these mechanisms are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 11:33:40 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 11:26:44 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Kashani", "Mostafa Haghi", ""], ["Ahmadzadeh", "Ahmad", ""], ["Mahdipour", "Ebrahim", ""]]}, {"id": "2011.14732", "submitter": "Mostafa Haghi Kashani", "authors": "Maryam Songhorabadi, Morteza Rahimi, Amir Mahdi Moghaddam Farid,\n  Mostafa Haghi Kashani", "title": "Fog Computing Approaches in Smart Cities: A State-of-the-Art Review", "comments": "19pages, 8 figures, 9 tables, 97 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These days, the development of smart cities, specifically in location-aware,\nlatency-sensitive, and security-crucial applications (such as emergency fire\nevents, patient health monitoring, or real-time manufacturing) heavily depends\non a more advance computing paradigms that can address these requirements. In\nthis regard, fog computing, a robust cloud computing complement, plays a\npreponderant role by virtue of locating closer to the end-devices. Nonetheless,\nutilized approaches in smart cities are frequently cloud-based, which causes\nnot only the security and time-sensitive services to suffer but also its\nflexibility and reliability to be restricted. So as to obviate the limitations\nof cloud and other related computing paradigms such as edge computing, this\npaper proposes a systematic literature review (SLR) for the state-of-the-art\nfog-based approaches in smart cities. Furthermore, according to the content of\nthe reviewed researches, a taxonomy is proposed, falls into three classes,\nincluding service-based, resource-based, and application-based. This SLR also\ninvestigates the evaluation factors, used tools, evaluation methods, merits,\nand demerits of each class. Types of proposed algorithms in each class are\nmentioned as well. Above all else, by taking various perspectives into account,\ncomprehensive and distinctive open issues and challenges are provided via\nclassifying future trends and issues into practical sub-classes.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 12:22:18 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 11:29:08 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Songhorabadi", "Maryam", ""], ["Rahimi", "Morteza", ""], ["Farid", "Amir Mahdi Moghaddam", ""], ["Kashani", "Mostafa Haghi", ""]]}, {"id": "2011.14763", "submitter": "Kevin Weinberger", "authors": "Kevin Weinberger, Alaa Alameer Ahmad, Aydin Sezgin (Ruhr-Universit\\\"at\n  Bochum, Germany)", "title": "On Synergistic Benefits of Rate Splitting in IRS-assisted Cloud Radio\n  Access Networks", "comments": "6 pages, 2 figures, conference, submitted to ICC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of intelligent reflecting surfaces (IRSs) is considered as a\npromising technology for increasing the efficiency of mobile wireless networks.\nThis is achieved by employing a vast amount of low-cost individually adjustable\npassive reflect elements, that are able to apply changes to the reflected\nsignal. To this end, the IRS makes the environment realtime controllable and\ncan be adjusted to significantly increase the received signal quality at the\nusers by passive beamsteering. However, the changes to the reflected signals\nhave an effect on all users near the IRS, which makes it impossible to optimize\nthe changes to positively influence every transmission, affected by the\nreflections. This results in some users not only experiencing better signal\nquality, but also an increase in received interference. To mitigate this\nnegative side effect of the IRS, this paper utilizes the rate splitting (RS)\ntechnique, which enables the mitigation of interference within the network in\nsuch a way that it also mitigates the increased interference caused by the IRS.\nTo investigate the effects on the overall power savings, that can be achieved\nby combining both techniques, we minimize the required transmit power, needed\nto satisfy per-user quality-of-service (QoS) constraints. Numerical results\nshow the improved power savings, that can be gained by utilizing the IRS and\nthe RS technique simultaneously. In fact, the concurrent use of both techniques\nyields power savings, which are beyond the cumulative power savings of using\neach technique separately.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 08:11:18 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Weinberger", "Kevin", "", "Ruhr-Universit\u00e4t\n  Bochum, Germany"], ["Ahmad", "Alaa Alameer", "", "Ruhr-Universit\u00e4t\n  Bochum, Germany"], ["Sezgin", "Aydin", "", "Ruhr-Universit\u00e4t\n  Bochum, Germany"]]}, {"id": "2011.14775", "submitter": "Santu Sardar", "authors": "Santu Sardar, Amit K. Mishra and Mohammed Z. A. Khan", "title": "Crowd Size using CommSense Instrument for COVID-19 Echo Period", "comments": "Accepted in IEEE Consumer Electronics Magazine (IEEE-CEM); to be\n  Published", "journal-ref": null, "doi": "10.1109/MCE.2020.3032791", "report-no": null, "categories": "cs.NI cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The period after the COVID-19 wave is called the Echo-period. Estimation of\ncrowd size in an outdoor environment is essential in the Echo-period. Making a\nsimple and flexible working system for the same is the need of the hour. This\narticle proposes and evaluates a non-intrusive, passive, and costeffective\nsolution for crowd size estimation in an outdoor environment. We call the\nproposed system as LTE communication infrastructure based environment sensing\nor LTE-CommSense. This system does not need any active signal transmission as\nit uses LTE transmitted signal. So, this is a power-efficient, simple low\nfootprint device. Importantly, the personal identity of the people in the crowd\ncan not be obtained using this method. First, the system uses practical data to\ndetermine whether the outdoor environment is empty or not. If not, it tries to\nestimate the number of people occupying the near range locality. Performance\nevaluation with practical data confirms the feasibility of this proposed\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 12:22:16 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sardar", "Santu", ""], ["Mishra", "Amit K.", ""], ["Khan", "Mohammed Z. A.", ""]]}, {"id": "2011.14776", "submitter": "Ruikang Zhong", "authors": "Ruikang Zhong, Xiao Liu, Yuanwei Liu and Yue Chen", "title": "NOMA in UAV-aided cellular offloading: A machine learning approach", "comments": "arXiv admin note: substantial text overlap with arXiv:2010.09094", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel framework is proposed for cellular offloading with the aid of\nmultiple unmanned aerial vehicles (UAVs), while non-orthogonal multiple access\n(NOMA) technique is employed at each UAV to further improve the spectrum\nefficiency of the wireless network. The optimization problem of joint\nthree-dimensional (3D) trajectory design and power allocation is formulated for\nmaximizing the throughput. In an effort to solve this pertinent dynamic\nproblem, a K-means based clustering algorithm is first adopted for periodically\npartitioning users. Afterward, a mutual deep Q-network (MDQN) algorithm is\nproposed to jointly determine the optimal 3D trajectory and power allocation of\nUAVs. In contrast to the conventional deep Q-network (DQN) algorithm, the MDQN\nalgorithm enables the experience of multi-agent to be input into a shared\nneural network to shorten the training time with the assistance of state\nabstraction. Numerical results demonstrate that: 1) the proposed MDQN algorithm\nhas a faster convergence rate than the conventional DQN algorithm in the\nmulti-agent case; 2) The achievable sum rate of the NOMA enhanced UAV network\nis $23\\%$ superior to the case of orthogonal multiple access (OMA); 3) By\ndesigning the optimal 3D trajectory of UAVs with the aid of the MDON algorithm,\nthe sum rate of the network enjoys ${142\\%}$ and ${56\\%}$ gains than that of\ninvoking the circular trajectory and the 2D trajectory, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 17:38:48 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhong", "Ruikang", ""], ["Liu", "Xiao", ""], ["Liu", "Yuanwei", ""], ["Chen", "Yue", ""]]}, {"id": "2011.14795", "submitter": "Adam Barker", "authors": "Adam Barker and Martin Swany", "title": "Energy Aware Routing with Computational Offloading for Wireless Sensor\n  Networks", "comments": "17 pages, NeTIOT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wireless sensor networks (WSN) are characterized by a network of small,\nbattery powered devices, operating remotely with no pre-existing\ninfrastructure. The unique structure of WSN allow for novel approaches to data\nreduction and energy preservation. This paper presents a modification to the\nexisting Q-routing protocol by providing an alternate action of performing\nsensor data reduction in place thereby reducing energy consumption, bandwidth\nusage, and message transmission time. The algorithm is further modified to\ninclude an energy factor which increases the cost of forwarding as energy\nreserves deplete. This encourages the network to conserve energy in favor of\nnetwork preservation when energy reserves are low. Our experimental results\nshow that this approach can, in periods of high network traffic, simultaneously\nreduce bandwidth, conserve energy, and maintain low message transition times.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:54:37 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Barker", "Adam", ""], ["Swany", "Martin", ""]]}, {"id": "2011.14799", "submitter": "Ramkumar Raghu", "authors": "Ramkumar Raghu, Mahadesh Panju, Vaneet Aggarwal and Vinod Sharma", "title": "Scheduling and Power Control for Wireless Multicast Systems via Deep\n  Reinforcement Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.05308", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multicasting in wireless systems is a natural way to exploit the redundancy\nin user requests in a Content Centric Network. Power control and optimal\nscheduling can significantly improve the wireless multicast network's\nperformance under fading. However, the model based approaches for power control\nand scheduling studied earlier are not scalable to large state space or\nchanging system dynamics. In this paper, we use deep reinforcement learning\nwhere we use function approximation of the Q-function via a deep neural network\nto obtain a power control policy that matches the optimal policy for a small\nnetwork. We show that power control policy can be learnt for reasonably large\nsystems via this approach. Further we use multi-timescale stochastic\noptimization to maintain the average power constraint. We demonstrate that a\nslight modification of the learning algorithm allows tracking of time varying\nsystem statistics. Finally, we extend the multi-timescale approach to\nsimultaneously learn the optimal queueing strategy along with power control. We\ndemonstrate scalability, tracking and cross layer optimization capabilities of\nour algorithms via simulations. The proposed multi-timescale approach can be\nused in general large state space dynamical systems with multiple objectives\nand constraints, and may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:59:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Raghu", "Ramkumar", ""], ["Panju", "Mahadesh", ""], ["Aggarwal", "Vaneet", ""], ["Sharma", "Vinod", ""]]}, {"id": "2011.14830", "submitter": "Elaheh Alipourchavary", "authors": "Elaheh AlipourChavary, Sarah M. Erfani, Christopher Leckie", "title": "Improving Scalability of Contrast Pattern Mining for Network Traffic\n  Using Closed Patterns", "comments": "4 pages; 3figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrast pattern mining (CPM) aims to discover patterns whose support\nincreases significantly from a background dataset compared to a target dataset.\nCPM is particularly useful for characterising changes in evolving systems,\ne.g., in network traffic analysis to detect unusual activity. While most\nexisting techniques focus on extracting either the whole set of contrast\npatterns (CPs) or minimal sets, the problem of efficiently finding a relevant\nsubset of CPs, especially in high dimensional datasets, is an open challenge.\nIn this paper, we focus on extracting the most specific set of CPs to discover\nsignificant changes between two datasets. Our approach to this problem uses\nclosed patterns to substantially reduce redundant patterns. Our experimental\nresults on several real and emulated network traffic datasets demonstrate that\nour proposed unsupervised algorithm is up to 100 times faster than an existing\napproach for CPM on network traffic data [2]. In addition, as an application of\nCPs, we demonstrate that CPM is a highly effective method for detection of\nmeaningful changes in network traffic.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 08:52:47 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["AlipourChavary", "Elaheh", ""], ["Erfani", "Sarah M.", ""], ["Leckie", "Christopher", ""]]}, {"id": "2011.14832", "submitter": "Wei-Chang Yeh", "authors": "Wei-Chang Yeh", "title": "Novel Bounded Binary-Addition Tree Algorithm for Binary-State Network\n  Reliability Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many network applications are based on binary-state networks, where each\ncomponent has one of two states: success or failure. Efficient algorithms to\nevaluate binary-state network reliability are continually being developed.\nReliability estimates the probability of the success state and is an effective\nand popular evaluation technique for binary-state networks. Binary-addition\ntree (BAT) algorithms are frequently used to calculate the efficiency and\nreliability of binary-state networks. In this study, we propose a novel,\nbounded BAT algorithm that employs three novel concepts: the first connected\nvector, the last disconnected vector, and super vectors. These vectors and the\ncalculations of their occurrent probabilities narrow the search space and\nsimplify the probability calculations to reduce the run time of the algorithm.\nMoreover, we show that replacing each undirected arc with two directed arcs,\nwhich is required in traditional direct methods, is unnecessary in the proposed\nalgorithm. We call this novel concept the undirected vectors. The performance\nof the proposed bounded BAT algorithm was verified experimentally by solving a\nbenchmark set of problems.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 07:42:50 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yeh", "Wei-Chang", ""]]}, {"id": "2011.14838", "submitter": "Taqwa Saeed", "authors": "Taqwa Saeed, Sergi Abadal, Christos Liaskos, Andreas Pitsillides,\n  Hamidreza Taghvaee, Albert Cabellos-Aparicio, Marios Lestas, Eduard Alarcon", "title": "Workload Characterization of Programmable Metasurfaces", "comments": null, "journal-ref": "Proceedings of the Sixth Annual ACM International Conference on\n  Nanoscale Computing and Communication, year 2019, page 1-6", "doi": null, "report-no": null, "categories": "cs.NI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metasurfaces are envisaged to play a key role in next-generation wireless\nsystems due to their powerful control over electromagnetic waves. The last\ndecade has witnessed huge advances in this regard, shifting from static to\nprogrammable metasurfaces. The HyperSurface (HSF) paradigm takes one step\nfurther by integrating a network of controllers within the device with the aim\nof adding intelligence, connectivity, and autonomy. However, little is known\nabout the traffic that this network will have to support as the target\nelectromagnetic function or boundary conditions change. In this paper, we lay\ndown the foundations of a methodology to characterize the workload of\nprogrammable metasurfaces and then employ it to analyze the case of beam\nsteering HSFs. We observe that traffic is bursty and highly dependent on the\nposition of the target. These results will enable the early-stage evaluation of\nintra-HSF networks, as well as the estimation of the system performance and\ncost.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 09:02:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Saeed", "Taqwa", ""], ["Abadal", "Sergi", ""], ["Liaskos", "Christos", ""], ["Pitsillides", "Andreas", ""], ["Taghvaee", "Hamidreza", ""], ["Cabellos-Aparicio", "Albert", ""], ["Lestas", "Marios", ""], ["Alarcon", "Eduard", ""]]}, {"id": "2011.14840", "submitter": "Wei-Chang Yeh", "authors": "Wei-Chang Yeh", "title": "A new BAT for Acyclic Multistate Information Network Reliability\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The acyclic multistate information network (AMIN), which is a kind of MIN\nthat does not require the conservation law of flow, plays an important role\nnowadays because many modern network structures present AMIN as the\nconstruction such as social networks, local area networks (LANs), 4G/5G\nnetworks, etc. To effectively evaluate the network reliability of AMIN, which\nindicates the reliable operation of the network, showing a major and primary\nmetrics for determining the performance and quality of the overall network. The\nnetwork reliability, which has been shown a NP-hard, has been successfully\nresolved and approached by the universal generation function method (UGFM).\nHowever, the UGFM can only solve small-scale problems due to the overflow in\ncomputer memory. To overcome the memory obstacle, an improved and enhanced\nbinary-addition vectors tree algorithm (BAT) is proposed to effectively\nevaluate and analyze the reliability of AMIN. The performance of the proposed\nBAT is validated on examples.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 02:20:06 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yeh", "Wei-Chang", ""]]}, {"id": "2011.14841", "submitter": "Baldomero Coll-Perales", "authors": "Baldomero Coll-Perales, Gokulnath Thandavarayan, Miguel Sepulcre and\n  Javier Gozalvez", "title": "Context-based Broadcast Acknowledgement for Enhanced Reliability of\n  Cooperative V2X Messages", "comments": "2020 IEEE Forum on Integrated and Sustainable Transportation Systems\n  (ISTS). 6 pages, 6 figures", "journal-ref": null, "doi": "10.1109/FISTS46898.2020.9264879", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most V2X applications/services are supported by the continuous exchange of\nbroadcast messages. One of the main challenges is to increase the reliability\nof broadcast transmissions that lack of mechanisms to assure the correct\ndelivery of the messages. To address this issue, one option is the use of\nacknowledgments. However, this option has scalability issues when applied to\nbroadcast transmissions because multiple vehicles can transmit acknowledgments\nsimultaneously. To control scalability while addressing reliability of\nbroadcast messages, this paper proposes and evaluates a context-based broadcast\nacknowledgement mechanism where the transmitting vehicles selectively request\nthe acknowledgment of specific/critical broadcast messages, and performs\nretransmissions if they are not correctly received. In addition, the V2X\napplications/services identify the situations/conditions that trigger the\nexecution of the broadcast acknowledgment mechanism, and the receiver(s) that\nshould acknowledge the broadcast messages. The paper evaluates the performance\nof the context-based broadcast acknowledgment mechanism for a Collective\nPerception Service. The obtained results show the proposed mechanism can\ncontribute to improve the awareness of crossing pedestrians at intersections by\nincreasing the reliability in the exchange of CPM messages between vehicles\napproaching the intersection. This solution is being discussed under IEEE\n802.11bd, and thus can be relevant for the standardization process.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 23:09:43 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Coll-Perales", "Baldomero", ""], ["Thandavarayan", "Gokulnath", ""], ["Sepulcre", "Miguel", ""], ["Gozalvez", "Javier", ""]]}, {"id": "2011.14844", "submitter": "Emilio Calvanese Strinati", "authors": "Emilio Calvanese Strinati and Sergio Barbarossa", "title": "6G Networks: Beyond Shannon Towards Semantic and Goal-Oriented\n  Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to promote the idea that including semantic and\ngoal-oriented aspects in future 6G networks can produce a significant leap\nforward in terms of system effectiveness and sustainability. Semantic\ncommunication goes beyond the common Shannon paradigm of guaranteeing the\ncorrect reception of each single transmitted packet, irrespective of the\nmeaning conveyed by the packet. The idea is that, whenever communication occurs\nto convey meaning or to accomplish a goal, what really matters is the impact\nthat the correct reception/interpretation of a packet is going to have on the\ngoal accomplishment. Focusing on semantic and goal-oriented aspects, and\npossibly combining them, helps to identify the relevant information, i.e. the\ninformation strictly necessary to recover the meaning intended by the\ntransmitter or to accomplish a goal. Combining knowledge representation and\nreasoning tools with machine learning algorithms paves the way to build\nsemantic learning strategies enabling current machine learning algorithms to\nachieve better interpretation capabilities and contrast adversarial attacks. 6G\nsemantic networks can bring semantic learning mechanisms at the edge of the\nnetwork and, at the same time, semantic learning can help 6G networks to\nimprove their efficiency and sustainability.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 13:33:04 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 17:00:59 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 08:38:38 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Strinati", "Emilio Calvanese", ""], ["Barbarossa", "Sergio", ""]]}, {"id": "2011.14847", "submitter": "Kirill Krinkin", "authors": "Kirill Krinkin, Igor Dronnikov", "title": "Media Content Delivery Protocols Performance and Reliability Evaluation\n  in Cellular Mobile Networks", "comments": "6 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently, tens of millions of devices around the world communicate with/\neach other via cellular networks. In this paper, we study the stability of\nnetwork content delivery protocols to the effects of network interference. To\nconduct the research, a tool was developed that allows testing of protocols,\nsuch as TCP, UDP, and QUIC. The analysis and comparison of the obtained test\nresults were carried out. In the conclusion, the best protocols for content\ndelivery were shown\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 14:39:29 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Krinkin", "Kirill", ""], ["Dronnikov", "Igor", ""]]}, {"id": "2011.14968", "submitter": "Furqan Ahmed", "authors": "Jessica Moysen, Furqan Ahmed, Mario Garc\\'ia-Lozano, Jarno Niemel\\\"a", "title": "Big Data-driven Automated Anomaly Detection and Performance Forecasting\n  in Mobile Networks", "comments": "Accepted in IEEE Globecomm 2020 workshop on AI-Enabled 5G/6G\n  Networks: Automation, Openness, and Radio Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The massive amount of data available in operational mobile networks offers an\ninvaluable opportunity for operators to detect and analyze possible anomalies\nand predict network performance. In particular, application of advanced machine\nlearning (ML) techniques on data aggregated from multiple sources can lead to\nimportant insights, not only for the detection of anomalous behavior but also\nfor performance forecasting, thereby complementing classic network operation\nand maintenance solutions with intelligent monitoring tools. In this paper, we\npropose a novel framework that aggregates diverse data sets (e.g.\nconfiguration, performance, inventory, locations, user speeds) from an\noperational LTE network and applies ML algorithms to diagnose network issues\nand analyze their impact on key performance indicators. To this end, pattern\nidentification and time-series forecasting algorithms are used on the ingested\ndata. Results show that proposed framework can indeed be leveraged to automate\nthe identification of anomalous behaviors associated with the spatial-temporal\ncharacteristics, and predict customer impact in an accurate manner.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:39:31 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Moysen", "Jessica", ""], ["Ahmed", "Furqan", ""], ["Garc\u00eda-Lozano", "Mario", ""], ["Niemel\u00e4", "Jarno", ""]]}, {"id": "2011.15114", "submitter": "Melih Bastopcu", "authors": "Melih Bastopcu and Sennur Ulukus", "title": "Timely Group Updating", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two closely related problems: anomaly detection in sensor\nnetworks and testing for infections in human populations. In both problems, we\nhave $n$ nodes (sensors, humans), and each node exhibits an event of interest\n(anomaly, infection) with probability $p$. We want to keep track of the\nanomaly/infection status of all nodes at a central location. We develop a\n$group$ $updating$ scheme, akin to group testing, which updates a central\nlocation about the status of each member of the population by appropriately\ngrouping their individual status. Unlike group testing, which uses the expected\nnumber of tests as a metric, in group updating, we use the expected age of\ninformation at the central location as a metric. We determine the optimal group\nsize to minimize the age of information. We show that, when $p$ is small, the\nproposed group updating policy yields smaller age compared to a sequential\nupdating policy.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:48:35 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Bastopcu", "Melih", ""], ["Ulukus", "Sennur", ""]]}]