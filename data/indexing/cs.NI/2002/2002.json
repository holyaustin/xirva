[{"id": "2002.00073", "submitter": "Sami Khairy", "authors": "Sami Khairy, Prasanna Balaprakash, Lin X. Cai, Yu Cheng", "title": "Constrained Deep Reinforcement Learning for Energy Sustainable Multi-UAV\n  based Random Access IoT Networks with NOMA", "comments": "Submitted to IEEE JSAC Special Issue on Massive Access for 5G and\n  Beyond", "journal-ref": null, "doi": "10.1109/JSAC.2020.3018804", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply the Non-Orthogonal Multiple Access (NOMA) technique\nto improve the massive channel access of a wireless IoT network where\nsolar-powered Unmanned Aerial Vehicles (UAVs) relay data from IoT devices to\nremote servers. Specifically, IoT devices contend for accessing the shared\nwireless channel using an adaptive $p$-persistent slotted Aloha protocol; and\nthe solar-powered UAVs adopt Successive Interference Cancellation (SIC) to\ndecode multiple received data from IoT devices to improve access efficiency. To\nenable an energy-sustainable capacity-optimal network, we study the joint\nproblem of dynamic multi-UAV altitude control and multi-cell wireless channel\naccess management of IoT devices as a stochastic control problem with multiple\nenergy constraints. To learn an optimal control policy, we first formulate this\nproblem as a Constrained Markov Decision Process (CMDP), and propose an online\nmodel-free Constrained Deep Reinforcement Learning (CDRL) algorithm based on\nLagrangian primal-dual policy optimization to solve the CMDP. Extensive\nsimulations demonstrate that our proposed algorithm learns a cooperative policy\namong UAVs in which the altitude of UAVs and channel access probability of IoT\ndevices are dynamically and jointly controlled to attain the maximal long-term\nnetwork capacity while maintaining energy sustainability of UAVs. The proposed\nalgorithm outperforms Deep RL based solutions with reward shaping to account\nfor energy costs, and achieves a temporal average system capacity which is\n$82.4\\%$ higher than that of a feasible DRL based solution, and only $6.47\\%$\nlower compared to that of the energy-constraint-free system.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 22:05:30 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 02:03:28 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Khairy", "Sami", ""], ["Balaprakash", "Prasanna", ""], ["Cai", "Lin X.", ""], ["Cheng", "Yu", ""]]}, {"id": "2002.00131", "submitter": "Md Khaja Mohiddin", "authors": "Md. Khaja Mohiddin, V. B. S. Srilatha Indira Dutt", "title": "An optimum energy consumption hybrid algorithm for xln strategic design\n  in wsns", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, X-Layer protocol is originated which executes mobility error\nprediction (MEP) algorithm to calculate the remaining energy level of each\nnode. This X-Layer protocol structure employs the mobility aware protocol that\nsenses the mobility concerned to each node with the utilization of Ad-hoc\nOn-Demand Distance Vector (AODV), which shares the information or data specific\nto the distance among individual nodes. With the help of this theory, the\nneighbour list will be updated only to those nodes which are mobile resulting\nin less energy consumption when compared to all (static/mobile) other nodes in\nthe network. Apart from the MEP algorithm, clustering head (CH) election\nalgorithm has also been specified to identify the relevant clusters whether\nthey exists within the network region or not. Also clustering multi-hop routing\n(CMHR) algorithm was implemented in which the node can identify the cluster to\nwhich it belongs depending upon the distance from each cluster surrounding the\nnode. Finally comprising the AODV routing protocol with the Two-Ray Ground\nmethod, we implement X-Layer protocol structure by considering MAC protocol in\naccordance to IEEE 802.15.4 to obtain the best results in energy consumption\nand also by reducing the energy wastage with respect to each node. The\neffective results had been illustrated through Network Simulator-II platform.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 03:28:01 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Mohiddin", "Md. Khaja", ""], ["Dutt", "V. B. S. Srilatha Indira", ""]]}, {"id": "2002.00252", "submitter": "Kevin Vermeulen", "authors": "Kevin Vermeulen, Burim Ljuma, Vamsi Addanki, Matthieu Gouel, Olivier\n  Fourmaux, Timur Friedman and Reza Rejaie", "title": "Alias Resolution Based on ICMP Rate Limiting", "comments": "Preprint to appear in Proceedings of Passive and Active Measurement\n  (PAM 2020) Conference, Eugene, OR, March 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alias resolution techniques (e.g., Midar) associate, mostly through active\nmeasurement, a set of IP addresses as belonging to a common router. These\ntechniques rely on distinct router features that can serve as a signature.\nTheir applicability is affected by router support of the features and the\nrobustness of the signature. This paper presents a new alias resolution tool\ncalled Limited Ltd. that exploits ICMP rate limiting, a feature that is\nincreasingly supported by modern routers that has not previously been used for\nalias resolution. It sends ICMP probes toward target interfaces in order to\ntrigger rate limiting, extracting features from the probe reply loss traces. It\nuses a machine learning classifier to designate pairs of interfaces as aliases.\nWe describe the details of the algorithm used by Limited Ltd. and illustrate\nits feasibility and accuracy. Limited Ltd. not only is the first tool that can\nperform alias resolution on IPv6 routers that do not generate monotonically\nincreasing fragmentation IDs (e.g., Juniper routers) but it also complements\nthe state-of-the-art techniques for IPv4 alias resolution. All of our code and\nthe collected dataset are publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 18:11:19 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Vermeulen", "Kevin", ""], ["Ljuma", "Burim", ""], ["Addanki", "Vamsi", ""], ["Gouel", "Matthieu", ""], ["Fourmaux", "Olivier", ""], ["Friedman", "Timur", ""], ["Rejaie", "Reza", ""]]}, {"id": "2002.00331", "submitter": "Jun Zhao", "authors": "Yulan Gao, Chao Yong, Zehui Xiong, Jun Zhao, Yue Xiao, Dusit Niyato", "title": "Reflection Resource Management for Intelligent Reflecting Surface Aided\n  Wireless Networks", "comments": "Please feel free to contact us for questions or remarks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI cs.PF eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the adoption of an intelligent reflecting surface (IRS) for\nmultiple single-antenna source terminal (ST)-DT pairs in two-hop networks is\ninvestigated. Different from the previous studies on IRS that merely focused on\ntuning the reflection coefficient of all the reflection elements at IRS, in\nthis paper, we consider the true reflection resource management. Specifically,\nthe true reflection resource management can be realized via trigger module\nselection based on our proposed IRS architecture that all the reflection\nelements are partially controlled by multiple parallel switches of controller.\nAs the number of reflection elements increases, the true reflection resource\nmanagement will become urgently needed in this context, which is due to the\nnon-ignorable energy consumption. Moreover, the proposed modular architecture\nof IRS is designed to make the reflection elements part independent and\ncontrollable. As such, our goal is to maximize the minimum\nsignal-to-interference-plus-noise ratio (SINR) at DTs via a joint trigger\nmodule subset selection, transmit power allocation of STs, and the\ncorresponding passive beamforming of the trigger modules, subject to per ST\npower budgets and module size constraint. Whereas this problem is NP-hard due\nto the module size constraint, to deal with it, we transform the hard module\nsize constraint into the group sparse constraint by introducing the mixed row\nblock norm, which yields a suitable semidefinite relaxation. Additionally, the\nparallel alternating direction method of multipliers (PADMM) is proposed to\nidentify the trigger module subset, and then subsequently the transmit power\nallocation and passive beamforming can be obtained by solving the original\nminimum SINR maximization problem without the group sparse constraint via\npartial linearization for generalized fractional programs.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 05:15:14 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 17:28:31 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Gao", "Yulan", ""], ["Yong", "Chao", ""], ["Xiong", "Zehui", ""], ["Zhao", "Jun", ""], ["Xiao", "Yue", ""], ["Niyato", "Dusit", ""]]}, {"id": "2002.00403", "submitter": "He Chen", "authors": "He Chen, Qian Wang, Zheng Dong, Ning Zhang", "title": "Multiuser Scheduling for Minimizing Age of Information in Uplink MIMO\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the user scheduling problem in a multiuser multiple-input\nmulti-output (MIMO) status update system, in which multiple single-antenna\ndevices aim to send their latest statuses to a multiple-antenna\ninformation-fusion access point (AP) via a shared wireless channel. The\ninformation freshness in the considered system is quantified by a recently\nproposed metric, termed age of information (AoI). Thanks to the extra spatial\ndegrees-of-freedom brought about by the multiple antennas at the AP, multiple\ndevices can be granted to transmit simultaneously in each time slot. We aim to\nseek the optimal scheduling policy that can minimize the network-wide AoI by\noptimally deciding which device or group of devices to be scheduled for\ntransmission in each slot given the instantaneous AoI values of all devices at\nthe beginning of the slot. To that end, we formulate the multiuser scheduling\nproblem as a Markov decision process (MDP). We attain the optimal policy by\nresolving the formulated MDP problem and develop a low-complexity sub-optimal\npolicy. Simulation results show that the proposed optimal and sub-optimal\npolicies significantly outperform the state-of-the-art benchmark schemes.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 14:36:10 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 05:31:11 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Chen", "He", ""], ["Wang", "Qian", ""], ["Dong", "Zheng", ""], ["Zhang", "Ning", ""]]}, {"id": "2002.00441", "submitter": "Yevheniya Nosyk", "authors": "Maciej Korczy\\'nski, Yevheniya Nosyk, Qasim Lone, Marcin Skwarek,\n  Baptiste Jonglez, Andrzej Duda", "title": "Don't Forget to Lock the Front Door! Inferring the Deployment of Source\n  Address Validation of Inbound Traffic", "comments": null, "journal-ref": "Proceedings of the Passive and Active Network Measurement\n  Conference, 2020", "doi": "10.1007/978-3-030-44081-7_7", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the problem of the absence of ingress filtering at the\nnetwork edge, one of the main causes of important network security issues.\nNumerous network operators do not deploy the best current practice - Source\nAddress Validation (SAV) that aims at mitigating these issues. We perform the\nfirst Internet-wide active measurement study to enumerate networks not\nfiltering incoming packets by their source address. The measurement method\nconsists of identifying closed and open DNS resolvers handling requests coming\nfrom the outside of the network with the source address from the range assigned\ninside the network under the test. The proposed method provides the most\ncomplete picture of the inbound SAV deployment state at network providers. We\nreveal that 32 673 Autonomous Systems (ASes) and 197 641 Border Gateway\nProtocol (BGP) prefixes are vulnerable to spoofing of inbound traffic. Finally,\nusing the data from the Spoofer project and performing an open resolver scan,\nwe compare the filtering policies in both directions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 18:04:26 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Korczy\u0144ski", "Maciej", ""], ["Nosyk", "Yevheniya", ""], ["Lone", "Qasim", ""], ["Skwarek", "Marcin", ""], ["Jonglez", "Baptiste", ""], ["Duda", "Andrzej", ""]]}, {"id": "2002.00458", "submitter": "Ashutosh Bhatia Dr.", "authors": "Ashutosh Bhatia, R. C. Hansdah", "title": "A Classification Framework for TDMA Scheduling techniques in WSNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges in wireless sensor networks (WSNs) is the\nmitigation of collisions due to simultaneous transmissions by multiple nodes\nover a common channel which are located in a proximity. TDMA-based channel\naccess provides energy-efficient and collision-free transmissions. It is\nespecially suitable for traffic with periodic transmission patterns and\nguaranteed QoS requirements. For that reason, a large number of TDMA-scheduling\nalgorithms are available in the literature, and consequently, a good number of\nsurvey papers on TDMA-scheduling algorithms have been written. In this work, we\npropose a novel classification framework to categorize the existing\nTDMA-scheduling algorithms available for WSNs. As against existing survey\nworks, the proposed framework possess certain new dimensions (categories) to\nclassify existing TDMA-scheduling algorithms. Additionally, we introduce a\ncouple of new sub-categories for the existing classes which would help\nresearchers to even differentiate between two TDMA-Scheduling algorithms that\nare assumed to be similar as per existing classification schemes. Finally, we\nalso discuss few important works in the context of proposed classification\nscheme.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 18:59:14 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Bhatia", "Ashutosh", ""], ["Hansdah", "R. C.", ""]]}, {"id": "2002.00473", "submitter": "Min Yee Teh", "authors": "Min Yee Teh, Shizhen Zhao, Keren Bergman", "title": "METTEOR: Robust Multi-Traffic Topology Engineering for Commercial Data\n  Center Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous optical circuit switched data center networks have been proposed\nover the past decade for higher capacity, though commercial adoption of these\narchitectures have been minimal so far. One major challenge commonly facing\nthese architectures is the difficulty of handling bursty traffic with optical\ncircuit switches (OCS) with high switching latency. Prior works generally rely\non fast-switching OCS prototypes to better react to traffic changes via\nfrequent reconfigurations. This approach, unfortunately, adds further\ncomplexity to the control plane. We propose METTEOR, an easily deployable\nsolution for optical circuit switched data centers, that is designed for the\ncurrent capabilities of commercial OCSs. Using multiple predicted traffic\nmatrices, METTEOR designs data center topologies that are less sensitive to\ntraffic changes, thus eliminating the need of frequently reconfiguring OCSs\nupon traffic changes. Results based on extensive evaluations using production\ntraces show that METTEOR increases the percentage of direct-hop traffic by\nabout 80% over a fat tree at comparable cost, and by about 30% over a uniform\nmesh, at comparable maximum link utilizations. Compared to ideal solutions that\nreconfigure OCSs on every traffic matrix, METTEOR achieves close-to-optimal\nbandwidth utilization even with biweekly reconfiguration. This drastically\nlowers the controller and management complexity needed to perform METTEOR in\ncommercial settings.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 19:38:53 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Teh", "Min Yee", ""], ["Zhao", "Shizhen", ""], ["Bergman", "Keren", ""]]}, {"id": "2002.00578", "submitter": "Burak Soner", "authors": "Mertkan Koca, Gokhan Gurbilek, Burak Soner and Sinem Coleri", "title": "Empirical Feasibility Analysis for Energy Harvesting Intra-Vehicular\n  Wireless Sensor Networks", "comments": "7 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle electronic systems currently utilize wired networks for power\ndelivery (from the main battery) and communication (e.g., LIN, CAN, FlexRay)\nbetween nodes. Wired networks cannot practically accommodate nodes in moving\nparts (e.g., tires) and with the increasing functional complexity in vehicles,\nthey require kilometer-long harnesses, significantly increasing fuel\nconsumption and manufacturing and design costs. As an alternative, energy\nharvesting intra-vehicular wireless sensor networks (IVWSN) can accommodate\nnodes in all locations and they obviate the need for wiring, significantly\nlowering costs. In this paper, we empirically analyze the feasibility of such\nan IVWSN framework via extensive in-vehicle measurements for communications at\n2.4 GHz, ultra wideband (UWB) and millimeter wave (mmWave) frequencies together\nwith radio frequency (RF), thermal and vibration energy harvesting. Our\nanalyses show that mmWave performs best for short line-of-sight (LoS) links in\nthe engine compartment with performance close to UWB for LoS links in the\nchassis and passenger compartments in terms of worst case\nsignal-to-interference-and-noise-ratio. For non-LoS links, which appear\nespecially more in the engine compartment and chassis, UWB provides the highest\nsecurity and reliability. 2.4 GHz suffers heavily from interference in all\ncompartments while UWB utilizes narrowband suppression techniques at the cost\nof lower bandwidth; mmWave inherently experiences very low interference due to\nits propagation characteristics. On the other hand, RF energy harvesting\nprovides up to 1 mW of power in all compartments. Vibration and thermal energy\nharvesters can supply all nodes consuming <10 mW in the engine compartment and\nall <5 mW nodes in the chassis. In the passenger compartment, thermal\nharvesting is not available due to low temperature gradients but vibration and\nRF sources can supply <1 mW nodes.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 06:50:58 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Koca", "Mertkan", ""], ["Gurbilek", "Gokhan", ""], ["Soner", "Burak", ""], ["Coleri", "Sinem", ""]]}, {"id": "2002.00611", "submitter": "Aysun Gurur \\\"Onalan", "authors": "Aysun Gurur Onalan, Elif Dilek Salik, Sinem Coleri", "title": "Relay Selection, Scheduling and Power Control in Wireless Powered\n  Cooperative Communication Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relay nodes are used to improve the throughput, delay and reliability\nperformance of energy harvesting networks by assisting both energy and\ninformation transfer between information nodes and access point. Previous\nstudies on radio frequency energy harvesting networks are limited to single\nsource single/multiple relay networks. In this paper, a novel joint relay\nselection, scheduling and power control problem for multiple source multiple\nrelay network is formulated with the objective of minimizing the total duration\nof wireless power and information transfer. The formulated problem is\nnon-convex mixed-integer non-linear programming problem, and proven to be\nNP-hard. We first formulate a sub-problem on scheduling and power control for a\ngiven relay selection. We propose an efficient optimal algorithm based on a\nbi-level optimization over power transfer time allocation. Then, for optimal\nrelay selection, we present optimal exponential-time Branch-and-Bound (BB)\nbased algorithm where the nodes are pruned with problem specific lower and\nupper bounds. We also provide two BB-based heuristic approaches limiting the\nnumber of branches generated from a BB-node, and a relay criterion based lower\ncomplexity heuristic algorithm. The performance of the proposed algorithms are\ndemonstrated to outperform conventional harvest-then-cooperate approaches with\nup to $88\\%$ lower schedule length for various network settings.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 09:08:43 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Onalan", "Aysun Gurur", ""], ["Salik", "Elif Dilek", ""], ["Coleri", "Sinem", ""]]}, {"id": "2002.00771", "submitter": "Xiaohu Ge", "authors": "Shuang Zheng, Tao Han, Yuna Jiang, Xiaohu Ge", "title": "Smart Contract-based Secure Spectrum Sharing in Multi-Operators Wireless\n  Communication Networks", "comments": null, "journal-ref": "IEEE Access 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-operators (multi-OPs) spectrum sharing mechanism can effectively\nimprove the spectrum utilization in fifth-generation (5G) wireless\ncommunication networks. The secondary users are introduced to opportunistically\naccess the licensed spectrum of idle operators (OPs). However, the identity\nprivacy and data security issues raise great concerns about the secure spectrum\nsharing among multi-OPs. To address these challenges, a consortium blockchain\ntrust framework is proposed for the spectrum sharing in multi-OPs wireless\ncommunication networks in this paper. A real consortium blockchain is\nconstructed among multi-OPs. The Multi-Ops Spectrum Sharing (MOSS) smart\ncontract is designed on the constructed consortium blockchain to implement the\nspectrum trading among multi-OPs. Without the need of trustless spectrum\nbroker, the MOSS smart contract enforces multi-OPs to share the spectrum\ntruthfully and designs a punishment mechanism to punish malicious OPs.\nSimulation results tested on the Remix integrated development environment (IDE)\nindicate the feasibility of the designed MOSS smart contract. The performance\nanalysis of the proposed consortium blockchain trust framework demonstrates\nthat the privacy, openness and fairness of the proposed solution are better\nthan traditional spectrum allocation solutions.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:17:06 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 14:45:29 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Zheng", "Shuang", ""], ["Han", "Tao", ""], ["Jiang", "Yuna", ""], ["Ge", "Xiaohu", ""]]}, {"id": "2002.00802", "submitter": "Madhusanka Dinesh Weeraratne Manimel Wadu", "authors": "Madhusanka Manimel Wadu, Sumudu Samarakoon, Mehdi Bennis", "title": "Federated Learning under Channel Uncertainty: Joint Client Scheduling\n  and Resource Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel joint client scheduling and resource block\n(RB) allocation policy to minimize the loss of accuracy in federated learning\n(FL) over wireless compared to a centralized training-based solution, under\nimperfect channel state information (CSI). First, the problem is cast as a\nstochastic optimization problem over a predefined training duration and solved\nusing the Lyapunov optimization framework. In order to learn and track the\nwireless channel, a Gaussian process regression (GPR)-based channel prediction\nmethod is leveraged and incorporated into the scheduling decision. The proposed\nscheduling policies are evaluated via numerical simulations, under both perfect\nand imperfect CSI. Results show that the proposed method reduces the loss of\naccuracy up to 25.8% compared to state-of-the-art client scheduling and RB\nallocation methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:52:22 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 12:06:45 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Wadu", "Madhusanka Manimel", ""], ["Samarakoon", "Sumudu", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2002.00808", "submitter": "Piotr Gawlowicz", "authors": "Piotr Gaw{\\l}owicz and Elnaz Alizadeh Jarchlo and Anatolij Zubow", "title": "Practical MIMO for Visible Light Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visible Light Communication (VLC) is seen as a complementary wireless\ntechnology to Radio Frequency (RF). However, VLC is very sensitive to the\nsignal blockage and suffers from shadowing due to the high directionality of\nthe optical channel. Hence there is a big interest in researching novel\napproaches for VLC like usage of multiple antenna techniques providing spatial\ndiversity which can be exploited as a way to combat signal blockage and fading.\nWe present a complete and low-cost MIMO-VLC transceiver system consisting of\nCOTS components. In particular, we show that COTS 802.11n (WiFi) devices can be\nused so that the physical and data link layers of RF WiFi are reused for VLC.\nIn addition, this allows us to directly utilize the multiple antenna (spatial)\ntechniques available in 802.11n. Results from our measurement study show that\nsuch techniques are highly effective at improving the robustness of VLC links\nin the presence of obstacles and node mobility. Moreover, we show that multiple\nantennas can also be used to increase the data rate of VLC by means of spatial\nmultiplexing.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:03:49 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Gaw\u0142owicz", "Piotr", ""], ["Jarchlo", "Elnaz Alizadeh", ""], ["Zubow", "Anatolij", ""]]}, {"id": "2002.00831", "submitter": "Xiaohu Ge", "authors": "Zhiwei Chen, Yi Zhong, Xiaohu Ge, Yi Ma", "title": "An Actor-Critic-Based UAV-BSs Deployment Method for Dynamic Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the real-time deployment of unmanned aerial vehicles (UAVs) as\nflying base stations (BSs) for optimizing the throughput of mobile users is\ninvestigated for UAV networks. This problem is formulated as a time-varying\nmixed-integer non-convex programming (MINP) problem, which is challenging to\nfind an optimal solution in a short time with conventional optimization\ntechniques. Hence, we propose an actor-critic-based (AC-based) deep\nreinforcement learning (DRL) method to find near-optimal UAV positions at every\nmoment. In the proposed method, the process searching for the solution\niteratively at a particular moment is modeled as a Markov decision process\n(MDP). To handle infinite state and action spaces and improve the robustness of\nthe decision process, two powerful neural networks (NNs) are configured to\nevaluate the UAV position adjustments and make decisions, respectively.\nCompared with the heuristic algorithm, sequential least-squares programming and\nfixed UAVs methods, simulation results have shown that the proposed method\noutperforms these three benchmarks in terms of the throughput at every moment\nin UAV networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:39:56 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Chen", "Zhiwei", ""], ["Zhong", "Yi", ""], ["Ge", "Xiaohu", ""], ["Ma", "Yi", ""]]}, {"id": "2002.00910", "submitter": "Luca Chiaraviglio", "authors": "Luca Chiaraviglio, Cristian Di Paolo, Giuseppe Bianchi, Nicola\n  Blefari-Melazzi", "title": "Is It Safe Living in the Vicinity of Cellular Towers? Analysis of\n  Long-Term Human EMF Exposure at Population Scale", "comments": "Cite as: Luca Chiaraviglio, Cristian Di Paolo, Giuseppe Bianchi,\n  Nicola Blefari-Melazzi, \"Is It Safe Living in the Vicinity of Cellular\n  Towers? Analysis of Long-Term Human EMF Exposure at Population Scale'', IEEE\n  91st Vehicular Technology Conference, Antwerp, Belgium, May 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the ElectroMagnetic Field (EMF) exposure safety for people living\nin the vicinity of cellular towers. To this aim, we analyze a large dataset of\nlong-term EMF measurements collected over almost 20 years in more than 2000\nmeasurement points spread over an Italian region. We evaluate the relationship\nbetween EMF exposure and the following factors: (i) distance from the closest\ninstallation(s), (ii) type of EMF sources in the vicinity, (iii) Base Station\n(BS) technology, and (iv) EMF regulation updates. Overall, the exposure levels\nfrom BSs in the vicinity are below the Italian EMF limits, thus ensuring safety\nfor the population. Moreover, BSs represent the lowest exposure compared to\nRadio/TV repeaters and other EMF sources. However, the BS EMF exposure in\nproximity to users exhibits an increasing trend over the last years, which is\nlikely due to the pervasive deployment of multiple technologies and to the EMF\nregulation updates. As a side consideration, if the EMF levels continue to\nincrease with the current trends, the EMF exposure in proximity to BSs will\nsaturate to the maximum EMF limit by the next 20 years at a distance of 30\nmeters from the closest BS.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:39:52 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 13:08:16 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chiaraviglio", "Luca", ""], ["Di Paolo", "Cristian", ""], ["Bianchi", "Giuseppe", ""], ["Blefari-Melazzi", "Nicola", ""]]}, {"id": "2002.01081", "submitter": "Naoki Shibata", "authors": "Babatunde Ojetunde, Naoki Shibata, Juntao Gao", "title": "Secure Payment System Utilizing MANET for Disaster Areas", "comments": null, "journal-ref": "in IEEE Transactions on Systems, Man, and Cybernetics: Systems,\n  vol. 49, no. 12, pp. 2651-2663, Dec. 2019", "doi": "10.1109/TSMC.2017.2752203", "report-no": null, "categories": "cs.DC cs.CY cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile payment system in a disaster area have the potential to provide\nelectronic transactions for people purchasing recovery goods like foodstuffs,\nclothes, and medicine. Conversely, to enable transactions in a disaster area,\ncurrent payment systems need communication infrastructures (such as wired\nnetworks and cellular networks) which may be ruined during such disasters as\nlarge-scale earthquakes and flooding and thus cannot be depended on in a\ndisaster area. In this paper, we introduce a new mobile payment system\nutilizing infrastructureless MANETs to enable transactions that permit users to\nshop in disaster areas. Specifically, we introduce an endorsement-based\nmechanism to provide payment guarantees for a customer-to-merchant transaction\nand a multilevel endorsement mechanism with a lightweight scheme based on Bloom\nfilter and Merkle tree to reduce communication overheads. Our mobile payment\nsystem achieves secure transaction by adopting various schemes such as\nlocation-based mutual monitoring scheme and blind signature, while our newly\nintroduce event chain mechanism prevents double spending attacks. As validated\nby simulations, the proposed mobile payment system is useful in a disaster\narea, achieving high transaction completion ratio, 65% - 90% for all scenario\ntested, and is storage-efficient for mobile devices with an overall average of\n7MB merchant message size.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 01:38:14 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Ojetunde", "Babatunde", ""], ["Shibata", "Naoki", ""], ["Gao", "Juntao", ""]]}, {"id": "2002.01101", "submitter": "Xiaohu Ge", "authors": "Anqi Huang, Yingyu Li, Yong Xiao, Xiaohu Ge, Sumei Sun, Han-Chieh Chao", "title": "Distributed Resource Allocation for Network Slicing of Bandwidth and\n  Computational Resource", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing has been considered as one of the key enablers for 5G to\nsupport diversified services and application scenarios. This paper studies the\ndistributed network slicing utilizing both the spectrum resource offered by\ncommunication network and computational resources of a coexisting fog computing\nnetwork. We propose a novel distributed framework based on a new control plane\nentity, regional orchestrator (RO), which can be deployed between base stations\n(BSs) and fog nodes to coordinate and control their bandwidth and computational\nresources. We propose a distributed resource allocation algorithm based on\nAlternating Direction Method of Multipliers with Partial Variable Splitting\n(DistADMM-PVS). We prove that the proposed algorithm can minimize the average\nlatency of the entire network and at the same time guarantee satisfactory\nlatency performance for every supported type of service. Simulation results\nshow that the proposed algorithm converges much faster than some other existing\nalgorithms. The joint network slicing with both bandwidth and computational\nresources can offer around 15% overall latency reduction compared to network\nslicing with only a single resource.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 03:24:35 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Huang", "Anqi", ""], ["Li", "Yingyu", ""], ["Xiao", "Yong", ""], ["Ge", "Xiaohu", ""], ["Sun", "Sumei", ""], ["Chao", "Han-Chieh", ""]]}, {"id": "2002.01106", "submitter": "Karol Rydzewski", "authors": "Karol Rydzewski, Jerzy Konorski", "title": "A reactive algorithm for deducing nodal forwarding behavior in a\n  multihop ad-hoc wireless network in the presence of errors", "comments": "7 pages, 4 figures, computer networks, detection, agent systems, ad\n  hoc networks, reputation, errors", "journal-ref": "A reactive algorithm for deducing nodal forwarding behavior in a\n  multihop ad-hoc wireless networks in the presence of errors, Intl. Journal of\n  Electronics and Telecommunications, vol. 66, no. 1, pp. 193-199, Polish\n  Academy of Sciences 2020", "doi": "10.24425/ijet.2020.131863", "report-no": null, "categories": "cs.NI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  novel algorithm is presented to deduce individual nodal forwarding behavior\nfrom standard end-to-end acknowledgments. The algorithm is based on a\nwell-established mathematical method and is robust to network related errors\nand nodal behavior changes. The proposed solution was verified in a network\nsimulation, during which it achieved sound results in a challenging multihop\nad-hoc network environment.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 03:33:45 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Rydzewski", "Karol", ""], ["Konorski", "Jerzy", ""]]}, {"id": "2002.01255", "submitter": "Zhiyuan Jiang", "authors": "Zhiyuan Jiang, Zixu Cao, Siyu Fu, Fei Peng, Shan Cao, Shunqing Zhang,\n  and Shugong Xu", "title": "Revealing Much While Saying Less: Predictive Wireless for Status Update", "comments": "To appear in IEEE INFOCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless communications for status update are becoming increasingly\nimportant, especially for machine-type control applications. Existing work has\nbeen mainly focused on Age of Information (AoI) optimizations. In this paper, a\nstatus-aware predictive wireless interface design, networking and\nimplementation are presented which aim to minimize the status recovery error of\na wireless networked system by leveraging online status model predictions. Two\ncritical issues of predictive status update are addressed: practicality and\nusefulness. Link-level experiments on a Software-Defined-Radio (SDR) testbed\nare conducted and test results show that the proposed design can significantly\nreduce the number of wireless transmissions while maintaining a low status\nrecovery error. A Status-aware Multi-Agent Reinforcement learning neTworking\nsolution (SMART) is proposed to dynamically and autonomously control the\ntransmit decisions of devices in an ad hoc network based on their individual\nstatuses. System-level simulations of a multi dense platooning scenario are\ncarried out on a road traffic simulator. Results show that the proposed schemes\ncan greatly improve the platooning control performance in terms of the minimum\nsafe distance between successive vehicles, in comparison with the AoI-optimized\nstatus-unaware and communication latency-optimized schemes---this demonstrates\nthe usefulness of our proposed status update schemes in a real-world\napplication.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 12:31:52 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Jiang", "Zhiyuan", ""], ["Cao", "Zixu", ""], ["Fu", "Siyu", ""], ["Peng", "Fei", ""], ["Cao", "Shan", ""], ["Zhang", "Shunqing", ""], ["Xu", "Shugong", ""]]}, {"id": "2002.01358", "submitter": "Shan Zhang", "authors": "Xiao Ma, Ao Zhou, Shan Zhang, Shangguang Wang", "title": "Cooperative Service Caching and Workload Scheduling in Mobile Edge\n  Computing", "comments": "INFOCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing is beneficial to reduce service response time and core\nnetwork traffic by pushing cloud functionalities to network edge. Equipped with\nstorage and computation capacities, edge nodes can cache services of\nresource-intensive and delay-sensitive mobile applications and process the\ncorresponding computation tasks without outsourcing to central clouds. However,\nthe heterogeneity of edge resource capacities and inconsistence of edge storage\nand computation capacities make it difficult to jointly fully utilize the\nstorage and computation capacities when there is no cooperation among edge\nnodes. To address this issue, we consider cooperation among edge nodes and\ninvestigate cooperative service caching and workload scheduling in mobile edge\ncomputing. This problem can be formulated as a mixed integer nonlinear\nprogramming problem, which has non-polynomial computation complexity. To\novercome the challenges of subproblem coupling, computation-communication\ntradeoff, and edge node heterogeneity, we develop an iterative algorithm called\nICE. This algorithm is designed based on Gibbs sampling, which has provably\nnear-optimal results, and the idea of water filling, which has polynomial\ncomputation complexity. Simulations are conducted and the results demonstrate\nthat our algorithm can jointly reduce the service response time and the\noutsourcing traffic compared with the benchmark algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:06:44 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Ma", "Xiao", ""], ["Zhou", "Ao", ""], ["Zhang", "Shan", ""], ["Wang", "Shangguang", ""]]}, {"id": "2002.01376", "submitter": "Petros Spachos", "authors": "Marc Baucas, Petros Spachos", "title": "A Scalable IoT-Fog Framework for Urban Sound Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is a system of interrelated devices that can be used\nto allow large-scale collection and analysis of data. However, as it grew, IoT\nnetworks were not capable of managing the data from these services. As a\nresult, cloud computing was introduced to address the need for datacentres for\nIoT networks. As the technology evolved, the demand for a proper means of\nsupporting and managing crowdsensing and real-time data increased, and cloud\nservers could no longer keep up with the large volumes of incoming data. This\ndemand brought rise to fog computing. It became an extension to the cloud and\nallowed resources to be allocated around the network effectively. Its\nintegration to IoT reduced the strain towards the cloud servers. However,\nissues in high power consumption at the end device and data management\nconstraints surfaced. This paper proposes two approaches to alleviate these\nissues to keep fog computing remain as a reliable option for IoT-related\napplications. We created an IoT-based sensing framework that used an urban\nsound classification model. Through active low and high power states and\nresource reallocation, we created a network configuration. We tested this\nconfiguration against IoT frameworks that use the default fog and cloud setups.\nThe results improved the framework's end device power consumption and server\nlatency. Overall, with the proposed framework, fog computing was proven to be\ncapable of supporting a scalable IoT framework for urban sound sensing.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:50:59 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Baucas", "Marc", ""], ["Spachos", "Petros", ""]]}, {"id": "2002.01419", "submitter": "Christina Delimitrou", "authors": "Justin Hu, Ariana Bruno, Brian Ritchken, Brendon Jackson, Mateo\n  Espinosa, Aditya Shah, Christina Delimitrou", "title": "HiveMind: A Scalable and Serverless Coordination Control Platform for\n  UAV Swarms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarms of autonomous devices are increasing in ubiquity and size. There are\ntwo main trains of thought for controlling devices in such swarms; centralized\nand distributed control. Centralized platforms achieve higher output quality\nbut result in high network traffic and limited scalability, while decentralized\nsystems are more scalable, but less sophisticated.\n  In this work we present HiveMind, a centralized coordination control platform\nfor IoT swarms that is both scalable and performant. HiveMind leverages a\ncentralized cluster for all resource-intensive computation, deferring\nlightweight and time-critical operations, such as obstacle avoidance to the\nedge devices to reduce network traffic. HiveMind employs an event-driven\nserverless framework to run tasks on the cluster, guarantees fault tolerance\nboth in the edge devices and serverless functions, and handles straggler tasks\nand underperforming devices. We evaluate HiveMind on a swarm of 16 programmable\ndrones on two scenarios; searching for given items, and counting unique people\nin an area. We show that HiveMind achieves better performance and battery\nefficiency compared to fully centralized and fully decentralized platforms,\nwhile also handling load imbalances and failures gracefully, and allowing edge\ndevices to leverage the cluster to collectively improve their output quality.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:38:56 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Hu", "Justin", ""], ["Bruno", "Ariana", ""], ["Ritchken", "Brian", ""], ["Jackson", "Brendon", ""], ["Espinosa", "Mateo", ""], ["Shah", "Aditya", ""], ["Delimitrou", "Christina", ""]]}, {"id": "2002.01450", "submitter": "Aleksandar Ichkov", "authors": "Aleksandar Ichkov, Daniel Sialkowski, Petri M\\\"ah\\\"onen and Ljiljana\n  Simi\\'c", "title": "Multi-User Provisioning in Millimeter-Wave Urban Cellular Networks", "comments": "14 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the first comprehensive study of the multi-user\ncapacity of millimeter-wave (mm-wave) urban cellular networks, using\nsite-specific ray-tracing propagation data and realistic antenna array\npatterns. We compare the performance of TDMA and SDMA (time and spatial\ndivision multiple access, respectively) for diverse network scenarios and\nantenna configurations. We propose a greedy heuristic algorithm to solve the\nnetwork-wide directional link allocation problem, thereby estimating the\nachievable capacity and coverage of multi-user mm-wave networks. Our results\nshow that inter-cell interference is negligible, so that TDMA performance is\nstrictly limited by air-time sharing. By contrast, the major limiting factor\nfor SDMA is intra-cell interference, emphasizing the impact of real antenna\narray sidelobes. Nonetheless, SDMA significantly outperforms TDMA in terms of\naverage UE throughput, by up to 2 Gbps using 8x8 arrays. As an important design\ninsight, our results show that larger base station antenna arrays limit\nintra-cell interference while compensating for small UE arrays, reducing costs\nand beamforming requirements in practical SDMA networks. Our analysis also\nshows that the limited number of antenna sub-arrays in a practical hybrid\nbeamforming architecture may force SDMA to drop UEs with good coverage,\nhighlighting a tradeoff between base station densification and antenna\nresources.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:26:20 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Ichkov", "Aleksandar", ""], ["Sialkowski", "Daniel", ""], ["M\u00e4h\u00f6nen", "Petri", ""], ["Simi\u0107", "Ljiljana", ""]]}, {"id": "2002.01472", "submitter": "Laksh Bhatia", "authors": "Ivana Tomi\\'c, Laksh Bhatia, Michael J. Breza, Julie A. McCann", "title": "The Limits of LoRaWAN in Event-Triggered Wireless Networked Control\n  Systems", "comments": "6 pages, 5 figures, Accepted at 2018 UKACC 12th International\n  Conference on Control (CONTROL)", "journal-ref": null, "doi": "10.1109/CONTROL.2018.8516774", "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless sensors and actuators offer benefits to large industrial control\nsystems. The absence of wires for communication reduces the deployment cost,\nmaintenance effort, and provides greater flexibility for sensor and actuator\nlocation and system architecture. These benefits come at a cost of a high\nprobability of communication delay or message loss due to the unreliability of\nradio-based communication. This unreliability poses a challenge to contemporary\ncontrol systems that are designed with the assumption of instantaneous and\nreliable communication. Wireless sensors and actuators create a paradigm shift\nin engineering energy-efficient control schemes coupled with robust\ncommunication schemes that can maintain system stability in the face of\nunreliable communication. This paper investigates the feasibility of using the\nlow-power wide-area communication protocol LoRaWAN with an event-triggered\ncontrol scheme through modelling in Matlab. We show that LoRaWAN is capable of\nmeeting the maximum delay and message loss requirements of an event-triggered\ncontroller for certain classes of applications. We also expose the limitation\nin the use of LoRaWAN when message size or communication range requirements\nincrease or the underlying physical system is exposed to significant external\ndisturbances.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:58:41 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Tomi\u0107", "Ivana", ""], ["Bhatia", "Laksh", ""], ["Breza", "Michael J.", ""], ["McCann", "Julie A.", ""]]}, {"id": "2002.01552", "submitter": "Ren\\'e S{\\o}rensen", "authors": "Ren\\'e Brandborg S{\\o}rensen, Jimmy Jessen Nielsen, Petar Popovski", "title": "Machine Learning Methods for Monitoring of Quasi-Periodic Traffic in\n  Massive IoT Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2020.2983217", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central problems in massive Internet of Things (IoT) deployments\nis the monitoring of the status of a massive number of links. The problem is\naggravated by the irregularity of the traffic transmitted over the link, as the\ntraffic intermittency can be disguised as a link failure and vice versa. In\nthis work we present a traffic model for IoT devices running quasi-periodic\napplications and we present both supervised and unsupervised machine learning\nmethods for monitoring the network performance of IoT deployments with\nquasi-periodic reporting, such as smart-metering, environmental monitoring and\nagricultural monitoring. The unsupervised methods are based on the Lomb-Scargle\nperiodogram, an approach developed by astronomers for estimating the spectral\ndensity of unevenly sampled time series.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 21:42:56 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 15:25:07 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["S\u00f8rensen", "Ren\u00e9 Brandborg", ""], ["Nielsen", "Jimmy Jessen", ""], ["Popovski", "Petar", ""]]}, {"id": "2002.01553", "submitter": "Suzan Bayhan", "authors": "Suzan Bayhan and Setareh Maghsudi and Anatolij Zubow", "title": "EdgeDASH: Exploiting Network-Assisted Adaptive Video Streaming for Edge\n  Caching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While edge video caching has great potential to decrease the core network\ntraffic as well as the users' experienced latency, it is often challenging to\nexploit the caches in current client-driven video streaming solutions due to\ntwo key reasons. First, even those clients interested in the same content might\nrequest different quality levels as a video content is encoded into multiple\nqualities to match a wide range of network conditions and device capabilities.\nSecond, the clients, who select the quality of the next chunk to request, are\nunaware of the cached content at the network edge. Hence, it becomes imperative\nto develop network-side solutions to exploit caching. This can also mitigate\nsome performance issues, in particular for the scenarios in which multiple\nvideo clients compete for some bottleneck capacity. In this paper, we propose a\nnetwork-side control logic running at a WiFi AP to facilitate the use of cached\nvideo content. In particular, an AP can assign a client station a different\nvideo quality than its request, in case the alternative quality provides a\nbetter utility. We formulate the quality assignment problem as an optimization\nproblem and develop several heuristics with polynomial complexity. Compared to\nthe baseline where the clients determine the quality adaptation, our proposals,\nreferred to as EdgeDASH, offer higher video quality, higher cache hits, and\nlower stalling ratio which are essential for user's satisfaction. Our\nsimulations show that EdgeDASH facilitates significant cache hits and decreases\nthe buffer stalls only by changing the client's request by one quality level.\nMoreover, from our analysis, we conclude that the network assistance provides\nsignificant performance improvement, especially when the clients with identical\ninterests compete for a bottleneck link's capacity.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 21:45:27 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Bayhan", "Suzan", ""], ["Maghsudi", "Setareh", ""], ["Zubow", "Anatolij", ""]]}, {"id": "2002.01716", "submitter": "Hamza Sami Ullah", "authors": "S. Aslam and H. Sami Ullah", "title": "A Comprehensive Review of Smart Cities Components, Applications, and\n  Technologies Based on Internet of Things", "comments": "9 Pages, 1 figure, 1 Table, 42 References", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart city technology is making cities more effective which is necessary for\nthe rapid growth in urban population. With the rapid increase in advanced\nmetering infrastructure and other digital technologies, Smart cities have\nbecome smarter with efficient electronic devices and embedded sensors based on\nthe Internet of Things (IoT). This paper provides a comprehensive review of the\nsmart cities concept with its components and applications. Moreover,\ntechnologies of IoT used in smart cities infrastructure and some practically\nimplemented smart cities in the world are mentioned as exemplary\nimplementations. Some open issues and future directions concluded the paper.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 10:33:24 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Aslam", "S.", ""], ["Ullah", "H. Sami", ""]]}, {"id": "2002.01735", "submitter": "Ismael Castell-Uroz", "authors": "Ismael Castell-Uroz, Josep Sol\\'e-Pareta and Pere Barlet-Ros", "title": "Demystifying content-blockers: A large scale study of actual performance\n  gains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the evolution of the online advertisement and tracking ecosystem,\ncontent-filtering has become the reference tool for improving the security,\nprivacy and browsing experience when surfing the Internet. It is also commonly\nbelieved that using content-blockers to stop unsolicited content decreases the\ntime needed for loading websites. In this work, we perform a large scale study\nwith the 100K most popular websites on the actual performance improvements of\nusing content-blockers. We focus our study in the two most relevant metrics for\nuser experience; bandwidth and latency. Our results show that using such tools\nresults in small improvements in terms of bandwidth usage but, contrary to\npopular belief, it has a negligible impact in terms of loading time. We also\nfind that, in the case of small and fast loading websites, the use of\ncontent-blockers can even result in increased browsing latency.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 11:32:15 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Castell-Uroz", "Ismael", ""], ["Sol\u00e9-Pareta", "Josep", ""], ["Barlet-Ros", "Pere", ""]]}, {"id": "2002.02074", "submitter": "Pooja Gupta", "authors": "Pooja Gupta, Volkan Dedeoglu, Kamran Najeebullah, Salil S. Kanhere and\n  Raja Jurdak", "title": "Energy-aware Demand Selection and Allocation for Real-time IoT Data\n  Trading", "comments": "Accepted in SmartComp 2020", "journal-ref": null, "doi": "10.1109/SMARTCOMP50058.2020.00038", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal IoT data is a new economic asset that individuals can trade to\ngenerate revenue on the emerging data marketplaces. Typically, marketplaces are\ncentralized systems that raise concerns of privacy, single point of failure,\nlittle transparency and involve trusted intermediaries to be fair. Furthermore,\nthe battery-operated IoT devices limit the amount of IoT data to be traded in\nreal-time that affects buyer/seller satisfaction and hence, impacting the\nsustainability and usability of such a marketplace. This work proposes to\nutilize blockchain technology to realize a trusted and transparent\ndecentralized marketplace for contract compliance for trading IoT data streams\ngenerated by battery-operated IoT devices in real-time. The contribution of\nthis paper is two-fold: (1) we propose an autonomous blockchain-based\nmarketplace equipped with essential functionalities such as agreement\nframework, pricing model and rating mechanism to create an effective\nmarketplace framework without involving a mediator, (2) we propose a mechanism\nfor selection and allocation of buyers' demands on seller's devices under\nquality and battery constraints. We present a proof-of-concept implementation\nin Ethereum to demonstrate the feasibility of the framework. We investigated\nthe impact of buyer's demand on the battery drainage of the IoT devices under\ndifferent scenarios through extensive simulations. Our results show that this\napproach is viable and benefits the seller and buyer for creating a sustainable\nmarketplace model for trading IoT data in real-time from battery-powered IoT\ndevices.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:35:05 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 05:41:52 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Gupta", "Pooja", ""], ["Dedeoglu", "Volkan", ""], ["Najeebullah", "Kamran", ""], ["Kanhere", "Salil S.", ""], ["Jurdak", "Raja", ""]]}, {"id": "2002.02173", "submitter": "Yingyu Li", "authors": "Qiang Li, Yuanmei Zhang, Yingyu Li, Yong Xiao, and Xiaohu Ge", "title": "Capacity-Aware Edge Caching in Fog Computing Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies edge caching in fog computing networks, where a\ncapacity-aware edge caching framework is proposed by considering both the\nlimited fog cache capacity and the connectivity capacity of base stations\n(BSs). By allowing cooperation between fog nodes and cloud data center, the\naverage-download-time (ADT) minimization problem is formulated as a multi-class\nprocessor queuing process. We prove the convexity of the formulated problem and\npropose an Alternating Direction Method of Multipliers (ADMM)-based algorithm\nthat can achieve the minimum ADT and converge much faster than existing\nalgorithms. Simulation results demonstrate that the allocation of fog cache\ncapacity and connectivity capacity of BSs needs to be balanced according to the\nnetwork status. While the maximization of the edge-cache-hit-ratio (ECHR) by\nutilizing all available fog cache capacity is helpful when the BS connectivity\ncapacity is sufficient, it is preferable to keep a lower ECHR and allocate more\ntraffic to the cloud when the BS connectivity capacity is deficient.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 09:46:48 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Li", "Qiang", ""], ["Zhang", "Yuanmei", ""], ["Li", "Yingyu", ""], ["Xiao", "Yong", ""], ["Ge", "Xiaohu", ""]]}, {"id": "2002.02400", "submitter": "Brian Kim", "authors": "Brian Kim and Yalin E. Sagduyu and Kemal Davaslioglu and Tugba Erpek\n  and Sennur Ulukus", "title": "Over-the-Air Adversarial Attacks on Deep Learning Based Modulation\n  Classifier over Wireless Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a wireless communication system that consists of a transmitter, a\nreceiver, and an adversary. The transmitter transmits signals with different\nmodulation types, while the receiver classifies its received signals to\nmodulation types using a deep learning-based classifier. In the meantime, the\nadversary makes over-the-air transmissions that are received as superimposed\nwith the transmitter's signals to fool the classifier at the receiver into\nmaking errors. While this evasion attack has received growing interest\nrecently, the channel effects from the adversary to the receiver have been\nignored so far such that the previous attack mechanisms cannot be applied under\nrealistic channel effects. In this paper, we present how to launch a realistic\nevasion attack by considering channels from the adversary to the receiver. Our\nresults show that modulation classification is vulnerable to an adversarial\nattack over a wireless channel that is modeled as Rayleigh fading with path\nloss and shadowing. We present various adversarial attacks with respect to\navailability of information about channel, transmitter input, and classifier\narchitecture. First, we present two types of adversarial attacks, namely a\ntargeted attack (with minimum power) and non-targeted attack that aims to\nchange the classification to a target label or to any other label other than\nthe true label, respectively. Both are white-box attacks that are transmitter\ninput-specific and use channel information. Then we introduce an algorithm to\ngenerate adversarial attacks using limited channel information where the\nadversary only knows the channel distribution. Finally, we present a black-box\nuniversal adversarial perturbation (UAP) attack where the adversary has limited\nknowledge about both channel and transmitter input.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 18:45:43 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 17:35:34 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Kim", "Brian", ""], ["Sagduyu", "Yalin E.", ""], ["Davaslioglu", "Kemal", ""], ["Erpek", "Tugba", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2002.02423", "submitter": "Ali Kheradmand", "authors": "Ali Kheradmand", "title": "Automatic Inference of High-Level Network Intents by Mining Forwarding\n  Patterns", "comments": "SOSR 2020", "journal-ref": null, "doi": "10.1145/3373360.3380831", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a semantic gap between the high-level intents of network operators\nand the low-level configurations that achieve the intents. Previous works tried\nto bridge the gap using verification or synthesis techniques, both requiring\nformal specifications of the intended behavior which are rarely available or\neven known in the real world. This paper discusses an alternative approach for\nbridging the gap, namely to infer the high-level intents from the low-level\nnetwork behavior. Specifically, we provide Anime, a framework and a tool that\ngiven a set of observed forwarding behavior, automatically infers a set of\npossible intents that best describe all observations. Our results show that\nAnime can infer high-quality intents from the low-level forwarding behavior\nwith acceptable performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:06:42 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 19:05:15 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Kheradmand", "Ali", ""]]}, {"id": "2002.02451", "submitter": "Yingyu Li", "authors": "Yingyu Li, Anqi Huang, Yong Xiao, Xiaohu Ge, Sumei Sun, Han-Chieh Chao", "title": "Federated Orchestration for Network Slicing of Bandwidth and\n  Computational Resource", "comments": "arXiv admin note: substantial text overlap with arXiv:2002.01101", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing has been considered as one of the key enablers for 5G to\nsupport diversified IoT services and application scenarios. This paper studies\nthe distributed network slicing for a massive scale IoT network supported by 5G\nwith fog computing. Multiple services with various requirements need to be\nsupported by both spectrum resource offered by 5G network and computational\nresourc of the fog computing network. We propose a novel distributed framework\nbased on a new control plane entity, federated-orchestrator , which can\ncoordinate the spectrum and computational resources without requiring any\nexchange of the local data and resource information from BSs. We propose a\ndistributed resource allocation algorithm based on Alternating Direction Method\nof Multipliers with Partial Variable Splitting . We prove DistADMM-PVS\nminimizes the average service response time of the entire network with\nguaranteed worst-case performance for all supported types of services when the\ncoordination between the F-orchestrator and BSs is perfectly synchronized.\nMotivated by the observation that coordination synchronization may result in\nhigh coordination delay that can be intolerable when the network is large in\nscale, we propose a novel asynchronized ADMM algorithm. We prove that AsynADMM\ncan converge to the global optimal solution with improved scalability and\nnegligible coordination delay. We evaluate the performance of our proposed\nframework using two-month of traffic data collected in a in-campus smart\ntransportation system supported by a 5G network. Extensive simulation has been\nconducted for both pedestrian and vehicular-related services during peak and\nnon-peak hours. Our results show that the proposed framework offers significant\nreduction on service response time for both supported services, especially\ncompared to network slicing with only a single resource.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 08:51:47 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Li", "Yingyu", ""], ["Huang", "Anqi", ""], ["Xiao", "Yong", ""], ["Ge", "Xiaohu", ""], ["Sun", "Sumei", ""], ["Chao", "Han-Chieh", ""]]}, {"id": "2002.02522", "submitter": "Ayan Chatterjee", "authors": "Saptarshi Pal, Ayan Chatterjee, Dripto Bakshi, Amitava Mukherjee", "title": "Link Capacity Distributions and Optimal Capacities for Competent Network\n  Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of evaluating optimal link capacities of a\npacket-flow network for the objective of congestion minimization. We present a\nsimple model of packet flow in networks and present a numerical approach to\nevaluate packet flow probability mass function at any arbitrary edge of the\nnetwork for a given routing algorithm and traffic rate. We further discuss\ntechniques of assigning optimal capacity at each edge for attaining desired\nminimized congestion and discuss related trade-offs. Our framework is built\naround the assumption of Poisson traffic, however the numerical approach fits\nfor any general distribution of packet influx. Lastly, we define metrics of\nglobal performance of link capacities allocation and discuss the effect of\nnetwork structure on capacity allocation and performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 22:02:06 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Pal", "Saptarshi", ""], ["Chatterjee", "Ayan", ""], ["Bakshi", "Dripto", ""], ["Mukherjee", "Amitava", ""]]}, {"id": "2002.02596", "submitter": "Xiaowen Gong", "authors": "Xiaowen Gong", "title": "Delay-Optimal Distributed Edge Computing in Wireless Edge Networks", "comments": "This paper has been accepted by IEEE INFOCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By integrating edge computing with parallel computing, distributed edge\ncomputing (DEC) makes use of distributed devices in edge networks to perform\ncomputing in parallel, which can substantially reduce service delays. In this\npaper, we explore DEC that exploits distributed edge devices connected by a\nwireless network to perform a computation task offloaded from an end device. In\nparticular, we study the fundamental problem of minimizing the delay of\nexecuting a distributed algorithm of the computation task. We first establish\nsome structural properties of the optimal communication scheduling policy.\nThen, given these properties, we characterize the optimal computation\nallocation policy, which can be found by an efficient algorithm. Next, based on\nthe optimal computation allocation, we characterize the optimal scheduling\norder of communications for some special cases, and develop an efficient\nalgorithm with a finite approximation ratio to find it for the general case.\nLast, based on the optimal computation allocation and communication scheduling,\nwe further show that the optimal selection of devices can be found efficiently\nfor some special cases. Our results provide some useful insights for the\noptimal computation-communication co-design. We evaluate the performance of the\ntheoretical findings using simulations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 02:45:54 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Gong", "Xiaowen", ""]]}, {"id": "2002.02708", "submitter": "Mounir Bensalem", "authors": "Mounir Bensalem, \\'Italo Brasileiro, Andr\\'e Drummond, Admela Jukan", "title": "Embedding Jamming Attacks into Physical Layer Models in Optical Networks", "comments": null, "journal-ref": null, "doi": "10.23919/ONDM48393.2020.9132999", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical networks are prone to physical layer attacks, in particular the\ninsertion of high jamming power. In this paper, we present a study of jamming\nattacks in elastic optical networks (EON) by embedding the jamming into the\nphysical layer model, and we analyze its impact on the blocking probability and\nslots utilization. We evaluate our proposed model using a single link and a\nnetwork topology and we show that for in-band-jamming, the slots utilization\ndecreases with the increase of jamming power, and becomes null when the jamming\npower is higher than 3 dB, while for out-of-band jamming, the impact is maximal\nfor a specific jamming power, 1.75 dB in our simulation. Considering multiple\npositions of attackers, we attained the highest blocking probability 32% for a\nspecific jamming power 2 dB. We conclude that the impact of jamming depends on\nattacker positions as well as the jamming power.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:53:17 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Bensalem", "Mounir", ""], ["Brasileiro", "\u00cdtalo", ""], ["Drummond", "Andr\u00e9", ""], ["Jukan", "Admela", ""]]}, {"id": "2002.02771", "submitter": "Jalal Rachad", "authors": "Jalal Rachad, Ridha Nasri, Laurent Decreusefond", "title": "Dynamic-TDD Interference Tractability Approaches and Performance\n  Analysis in Macro-Cell and Small-Cell Deployments", "comments": "arXiv admin note: text overlap with arXiv:1805.06638", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meeting the continued growth in data traffic volume, Dynamic Time Division\nDuplex (D-TDD) has been introduced as a solution to deal with the uplink (UL)\nand downlink (DL) traffic asymmetry, mainly observed for dense heterogeneous\nnetwork deployments, since it is based on instantaneous traffic estimation and\nprovide more flexibility in resource assignment. However, the use of this\nfeature requires new interference mitigation schemes capable to handle two\nadditional types of interference between cells in opposite transmission\ndirection: DL to UL and UL to DL interference. The aim of this work is to\nprovide a complete analytical approach to model inter-cell interference in\nmacro-cell and dense small-cell networks. We derive the explicit expressions of\nInterference to Signal Ratio (ISR) at each position of the network, in both DL\nand UL, to quantify the impact of each type of interference on the system\nperformance. Also, we provide the explicit expressions of the coverage\nprobability as functions of different system parameters by covering different\nscenarios. Finally, through system level simulations, we analyze the\nfeasibility of D-TDD implementation in both deployments and we compare its\nperformance to the static-TDD (S-TDD) configuration.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:35:15 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 13:55:00 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Rachad", "Jalal", ""], ["Nasri", "Ridha", ""], ["Decreusefond", "Laurent", ""]]}, {"id": "2002.02880", "submitter": "Mingcong Yang", "authors": "Mingcong Yang, Qian Wu, Maiko Shigeno, and YongbingZhang", "title": "Multilayer Routing and Resource Assignment in Spatial Channel Networks\n  (SCNs): Oriented Toward the Massive SDM Era", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few decades, optical transport networks (OTNs) have undergone\nsignificant evolution, from the earliest wavelength-division multiplexing (WDM)\nOTNs to elastic optical networks (EONs) and later to space-division\nmultiplexing (SDM) OTNs, to address the continuous growth of Internet traffic.\nBy 2024, Pbps-level OTNs are expected, far exceeding the capacity limit of\nsingle-mode fibers. The massive SDM era is on the horizon. In this context,\nnewly designed OTNs called spatial channel networks (SCNs), which achieve high\ncost efficiency by means of practical hierarchical optical cross-connects, have\nrecently been proposed. However, the evolution of OTNs will simultaneously\npresent challenges related to resource allocation in networking. For instance,\nwith the evolution from WDM-OTNs to EONs, the resource allocation problem was\ntransformed from the routing and wavelength assignment (RWA) problem to the\nrouting and spectrum assignment (RSA) problem due to the additionally\nintroduced constraint of spectrum contiguity. Similarly, specially designed\nalgorithms are also expected to be essential for addressing the resource\nallocation problem in SCNs. In this paper, we define this new problem as the\nrouting, spatial channel, and spectrum assignment (RSCSA) problem. We propose\nan integer linear programming (ILP) model and a heuristic algorithm to solve\nthe RSCSA problem. We examine the performance of the proposed approaches via\nsimulation experiments. The results show that both proposed approaches are\neffective in finding the optimal solutions or solutions close to the lower\nbounds. To the best of our knowledge, this is the first work to focus on the\nproblem of resource allocation in SCNs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:32:48 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Yang", "Mingcong", ""], ["Wu", "Qian", ""], ["Shigeno", "Maiko", ""], ["YongbingZhang", "", ""]]}, {"id": "2002.02897", "submitter": "Yu Zhang", "authors": "Yu Zhang, Tao Gu, Xi Zhang", "title": "MDLdroid: a ChainSGD-reduce Approach to Mobile Deep Learning for\n  Personal Mobile Sensing", "comments": "Published in the International Conference on Information Processing\n  in Sensor Networks (IPSN), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal mobile sensing is fast permeating our daily lives to enable activity\nmonitoring, healthcare and rehabilitation. Combined with deep learning, these\napplications have achieved significant success in recent years. Different from\nconventional cloud-based paradigms, running deep learning on devices offers\nseveral advantages including data privacy preservation and low-latency response\nfor both model inference and update. Since data collection is costly in\nreality, Google's Federated Learning offers not only complete data privacy but\nalso better model robustness based on multiple user data. However, personal\nmobile sensing applications are mostly user-specific and highly affected by\nenvironment. As a result, continuous local changes may seriously affect the\nperformance of a global model generated by Federated Learning. In addition,\ndeploying Federated Learning on a local server, e.g., edge server, may quickly\nreach the bottleneck due to resource constraint and serious failure by attacks.\nTowards pushing deep learning on devices, we present MDLdroid, a novel\ndecentralized mobile deep learning framework to enable resource-aware on-device\ncollaborative learning for personal mobile sensing applications. To address\nresource limitation, we propose a ChainSGD-reduce approach which includes a\nnovel chain-directed Synchronous Stochastic Gradient Descent algorithm to\neffectively reduce overhead among multiple devices. We also design an\nagent-based multi-goal reinforcement learning mechanism to balance resources in\na fair and efficient manner. Our evaluations show that our model training on\noff-the-shelf mobile devices achieves 2x to 3.5x faster than single-device\ntraining, and 1.5x faster than the master-slave approach.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:55:21 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 14:34:48 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Yu", ""], ["Gu", "Tao", ""], ["Zhang", "Xi", ""]]}, {"id": "2002.03071", "submitter": "Nariman Torkzaban", "authors": "Nariman Torkzaban, Anousheh Gholami, Chrysa Papagianni, John S. Baras", "title": "Joint Satellite Gateway Placement and Routing for Integrated\n  Satellite-Terrestrial Networks", "comments": "6 pages, In Proceedings of IEEE ICC 2020.\n  https://ieeexplore.ieee.org/document/9149175 N. Torkzaban, A. Gholami, J. S.\n  Baras and C. Papagianni, \"Joint Satellite Gateway Placement and Routing for\n  Integrated Satellite-Terrestrial Networks,\" ICC 2020 - 2020 IEEE\n  International Conference on Communications (ICC), Dublin, Ireland, 2020, pp.\n  1-6. doi: 10.1109/ICC40277.2020.9149175", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing attention to the integrated satellite-terrestrial\nnetworks (ISTNs), the satellite gateway placement problem becomes of paramount\nimportance. The resulting network performance may vary depending on the\ndifferent design strategies. In this paper, a joint satellite gateway placement\nand routing strategy for the terrestrial network is proposed to minimize the\noverall cost of gateway deployment and traffic routing, while adhering to the\naverage delay requirement for traffic demands. Although traffic routing and\ngateway placement can be solved independently, the dependence between the\nrouting decisions for different demands makes it more realistic to solve an\naggregated model instead. We develop a mixed-integer linear program (MILP)\nformulation for the problem. We relax the integrality constraints to achieve a\nlinear program (LP) which reduces time-complexity at the expense of a\nsub-optimal solution. We further propose a variant of the proposed model to\nbalance the load between the selected gateways.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 02:47:53 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 20:10:36 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Torkzaban", "Nariman", ""], ["Gholami", "Anousheh", ""], ["Papagianni", "Chrysa", ""], ["Baras", "John S.", ""]]}, {"id": "2002.03144", "submitter": "Andrei Bytes", "authors": "Andrei Bytes and Jay Prakash and Jianying Zhou and Tony Q.S. Quek", "title": "Why is My Secret Leaked? Discovering Vulnerabilities in Device-to-Device\n  File Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of active users of Wi-Fi Direct Device-to-Device file sharing\napplications on Android has exceeded 1.8 billion. Wi-Fi Direct, also known as\nWi-Fi P2P, is commonly used for peer-to-peer, high-speed file transfer between\nmobile devices, as well as a close proximity connection mode for wireless\ncameras, network printers, TVs and other IoT and mobile devices. For its end\nusers, such type of direct file transfer does not incur cellular data charges.\nHowever, despite the popularity of such applications, we observe that the\nsoftware vendors tend to prioritize the ease of user flow over the security in\ntheir implementations, which leads to serious security flaws. We perform a\ncomprehensive security analysis in the context of security and usability and\nreport our findings in the form of 17 Common Vulnerabilities and Exposures\n(CVE) which have been disclosed to the corresponding vendors. To address the\nsimilar flaws at the early stage of the application design, we propose a joint\nconsideration of security and usability for such applications and their\nprotocols that can be visualized in form of a customised User Journey Map\n(UJM).\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 11:21:21 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 15:23:23 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bytes", "Andrei", ""], ["Prakash", "Jay", ""], ["Zhou", "Jianying", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2002.03301", "submitter": "Omar Alhussein", "authors": "Omar Alhussein and Phu Thinh Do and Qiang Ye and Junling Li and Weisen\n  Shi and Weihua Zhuang and Xuemin (Sherman) Shen and Xu Li and Jaya Rao", "title": "A Virtual Network Customization Framework for Multicast Services in\n  NFV-enabled Core Networks", "comments": "Accepted to IEEE Journal on Selected Areas in Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paradigm of network function virtualization (NFV) with the support of\nsoftware defined networking (SDN) emerges as a promising approach for\ncustomizing network services in fifth generation (5G) networks. In this paper,\na multicast service orchestration framework is presented, where joint traffic\nrouting and virtual network function (NF) placement are studied for\naccommodating multicast services over an NFV-enabled physical substrate\nnetwork. First, we investigate a joint routing and NF placement problem for a\nsingle multicast request accommodated over a physical substrate network, with\nboth single-path and multipath traffic routing. The joint problem is formulated\nas a mixed integer linear programming (MILP) problem to minimize the function\nand link provisioning costs, under the physical network resource constraints,\nflow conservation constraints, and NF placement rules; Second, we develop an\nMILP formulation that jointly handles the static embedding of multiple service\nrequests over the physical substrate network, where we determine the optimal\ncombination of multiple services for embedding and their joint routing and\nplacement configurations, such that the aggregate throughput of the physical\nsubstrate is maximized, while the function and link provisioning costs are\nminimized. Since the presented problem formulations are NP-hard, low complexity\nheuristic algorithms are proposed to find an efficient solution for both\nsingle-path and multipath routing scenarios. Simulation results are presented\nto demonstrate the effectiveness and accuracy of the proposed heuristic\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 06:45:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Alhussein", "Omar", "", "Sherman"], ["Do", "Phu Thinh", "", "Sherman"], ["Ye", "Qiang", "", "Sherman"], ["Li", "Junling", "", "Sherman"], ["Shi", "Weisen", "", "Sherman"], ["Zhuang", "Weihua", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""], ["Li", "Xu", ""], ["Rao", "Jaya", ""]]}, {"id": "2002.03349", "submitter": "Emmanouil Fountoulakis", "authors": "Emmanouil Fountoulakis, Georgios S. Paschos, and Nikolaos Pappas", "title": "UAV Trajectory Optimization for Time Constrained Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI math.OC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) are poised to revolutionize communications.\nUtilizing their flexibility and fast deployment, we can deliver content in\ncongested areas or provide services in areas without infrastructure. In this\npaper, we consider a UAV that flies over multiple locations and serves as many\nusers as possible within a given time duration. We study the problem of optimal\ntrajectory design, which we formulate as a mixed-integer linear program. For\nlarge instances of the problem where the options for trajectories become\nprohibitively many, we establish a connection to the orienteering problem, and\npropose a corresponding greedy algorithm. Simulation results show that the\nproposed algorithm is fast and yields solutions close to the optimal ones. The\nproposed algorithm can be used for trajectory planning in strategic content\ncaching or tactical field operations.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 11:59:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Fountoulakis", "Emmanouil", ""], ["Paschos", "Georgios S.", ""], ["Pappas", "Nikolaos", ""]]}, {"id": "2002.03391", "submitter": "Stephan Kleber", "authors": "Stephan Kleber, Rens Wouter van der Heijden, Frank Kargl", "title": "Message Type Identification of Binary Network Protocols using Continuous\n  Segment Similarity", "comments": "11 pages, 4 figures, to be published in IEEE International Conference\n  on Computer Communications. INFOCOM. Beijing, China, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protocol reverse engineering based on traffic traces infers the behavior of\nunknown network protocols by analyzing observable network messages. To perform\ncorrect deduction of message semantics or behavior analysis, accurate message\ntype identification is an essential first step. However, identifying message\ntypes is particularly difficult for binary protocols, whose structural features\nare hidden in their densely packed data representation. We leverage the\nintrinsic structural features of binary protocols and propose an accurate\nmethod for discriminating message types.\n  Our approach uses a similarity measure with continuous value range by\ncomparing feature vectors where vector elements correspond to the fields in a\nmessage, rather than discrete byte values. This enables a better recognition of\nstructural patterns, which remain hidden when only exact value matches are\nconsidered. We combine Hirschberg alignment with DBSCAN as cluster algorithm to\nyield a novel inference mechanism. By applying novel autoconfiguration schemes,\nwe do not require manually configured parameters for the analysis of an unknown\nprotocol, as required by earlier approaches.\n  Results of our evaluations show that our approach has considerable advantages\nin message type identification result quality and also execution performance\nover previous approaches.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 16:00:05 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Kleber", "Stephan", ""], ["van der Heijden", "Rens Wouter", ""], ["Kargl", "Frank", ""]]}, {"id": "2002.03464", "submitter": "Omar Alhussein", "authors": "Omar Alhussein and Weihua Zhuang", "title": "Robust Online Composition, Routing and NF Placement for NFV-enabled\n  Services", "comments": "To appear in IEEE Journal on Selected Areas in Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network function virtualization (NFV) fosters innovation in the networking\nfield and reduces the complexity involved in managing modern-day conventional\nnetworks. Via NFV, the provisioning of a network service becomes more agile,\nwhereby virtual network functions can be instantiated on commodity servers and\ndata centers on demand. Network functions can be either mandatory or\nbest-effort. The former type is strictly necessary for the correctness of a\nnetwork service, whereas the latter is preferrable yet not necessary. In this\npaper, we study the online provisioning of NFV-enabled network services. We\nconsider both unicast and multicast NFV-enabled services with multiple\nmandatory and best-effort NF instances. We propose a primal-dual based online\napproximation algorithm that allocates both processing and transmission\nresources to maximize a profit function, subject to resource constraints on\nphysical links and NFV nodes. The online algorithm resembles a joint admission\nmechanism and an online composition, routing and NF placement framework. The\nonline algorithm is derived from an offline formulation through a primal-dual\nbased analysis. Such analysis offers direct insights and a fundamental\nunderstanding on the nature of the profit-maximization problem for NFV-enabled\nservices with multiple resource types.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 22:38:42 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Alhussein", "Omar", ""], ["Zhuang", "Weihua", ""]]}, {"id": "2002.03475", "submitter": "Yaxiong Xie", "authors": "Yaxiong Xie, Fan Yi, Kyle Jamieson", "title": "PBE-CC: Congestion Control via Endpoint-Centric, Physical-Layer\n  Bandwidth Measurements", "comments": null, "journal-ref": null, "doi": "10.1145/3387514.3405880", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless networks are becoming ever more sophisticated and overcrowded,\nimposing the most delay, jitter, and throughput damage to end-to-end network\nflows in today's internet. We therefore argue for fine-grained mobile\nendpoint-based wireless measurements to inform a precise congestion control\nalgorithm through a well-defined API to the mobile's wireless physical layer.\nOur proposed congestion control algorithm is based on Physical-Layer Bandwidth\nmeasurements taken at the Endpoint (PBE-CC), and captures the latest 5G New\nRadio innovations that increase wireless capacity, yet create abrupt rises and\nfalls in available wireless capacity that the PBE-CC sender can react to\nprecisely and very rapidly. We implement a proof-of-concept prototype of the\nPBE measurement module on software-defined radios and the PBE sender and\nreceiver in C. An extensive performance evaluation compares PBE-CC head to head\nagainst the leading cellular-aware and wireless-oblivious congestion control\nprotocols proposed in the research community and in deployment, in mobile and\nstatic mobile scenarios, and over busy and quiet networks. Results show 6.3%\nhigher average throughput than BBR, while simultaneously reducing 95th\npercentile delay by 1.8x.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 00:20:18 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 21:03:43 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Xie", "Yaxiong", ""], ["Yi", "Fan", ""], ["Jamieson", "Kyle", ""]]}, {"id": "2002.03792", "submitter": "Onel Luis Alcaraz L\\'opez", "authors": "Onel L. A. L\\'opez, Samuel Montejo-S\\'anchez, Richard D. Souza, Hirley\n  Alves, Constantinos B. Papadias", "title": "On CSI-free Multi-Antenna Schemes for Massive RF Wireless Energy\n  Transfer", "comments": "16 pags, 10 figs, 1 table, submitted to IEEE JSAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI cs.PF stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Energy Transfer (WET) is emerging as a potential green enabler for\nmassive Internet of Things (IoT). Herein, we analyze Channel State Information\n(CSI)-free multi-antenna strategies for powering wirelessly a large set of\nsingle-antenna IoT devices. The CSI-free schemes are AA-SS (AA-IS), where all\nantennas transmit the same (independent) signal(s), and SA, where just one\nantenna transmits at a time such that all antennas are utilized during the\ncoherence block. We characterize the distribution of the provided energy under\ncorrelated Rician fading for each scheme and find out that while AA-IS and SA\ncannot take advantage of the multiple antennas to improve the average provided\nenergy, its dispersion can be significantly reduced. Meanwhile, AA-SS provides\nthe greatest average energy, but also the greatest energy dispersion, and the\ngains depend critically on the mean phase shifts between the antenna elements.\nWe find that consecutive antennas must be $\\pi$ phase-shifted for optimum\naverage energy performance under AA-SS. Our numerical results evidenced that\ncorrelation is beneficial under AA-SS, while a greater line of sight (LOS)\nand/or number of antennas is not always beneficial under such scheme.\nMeanwhile, both AA-IS and SA schemes benefit from small correlation, large LOS\nand/or large number of antennas.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 07:38:53 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 15:05:43 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["L\u00f3pez", "Onel L. A.", ""], ["Montejo-S\u00e1nchez", "Samuel", ""], ["Souza", "Richard D.", ""], ["Alves", "Hirley", ""], ["Papadias", "Constantinos B.", ""]]}, {"id": "2002.03795", "submitter": "Hannaneh Barahouei Pasandi", "authors": "Hannaneh Barahouei Pasandi, Tamer Nadeem", "title": "Unboxing MAC Protocol Design Optimization Using Deep Learning", "comments": "2020 IEEE International Conference on Pervasive Computing and\n  Communications Workshops (PerCom Workshops). arXiv admin note: substantial\n  text overlap with arXiv:2002.02075", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolving amendments of 802.11 standards feature a large set of physical and\nMAC layer control parameters to support the increasing communication objectives\nspanning application requirements and network dynamics. The significant growth\nand penetration of various devices come along with a tremendous increase in the\nnumber of applications supporting various domains and services which will\nimpose a never-before-seen burden on wireless networks. The challenge however,\nis that each scenario requires a different wireless protocol functionality and\nparameter setting to optimally determine how to tune these functionalities and\nparameters to adapt to varying network scenarios. The traditional trial-error\napproach of manual tuning of parameters is not just becoming difficult to\nrepeat but also sub-optimal for different networking scenarios. In this paper,\nwe describe how we can leverage a deep reinforcement learning framework to be\ntrained to learn the relation between different parameters in the physical and\nMAC layer and show that how our learning-based approach could help us in\ngetting insights about protocol design optimization task.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:17:19 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pasandi", "Hannaneh Barahouei", ""], ["Nadeem", "Tamer", ""]]}, {"id": "2002.03797", "submitter": "Hannaneh Barahouei Pasandi", "authors": "Hannaneh Barahouei Pasandi, Tamer Nadeem", "title": "CONVINCE: Collaborative Cross-Camera Video Analytics at the Edge", "comments": "6 pages, 4 figures, 2020 IEEE International Conference on Pervasive\n  Computing and Communications Workshops (PerCom Workshops)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, video cameras are deployed in dense for monitoring physical places\ne.g., city, industrial, or agricultural sites. In the current systems, each\ncamera node sends its feed to a cloud server individually. However, this\napproach suffers from several hurdles including higher computation cost, large\nbandwidth requirement for analyzing the enormous data, and privacy concerns. In\ndense deployment, video nodes typically demonstrate a significant\nspatio-temporal correlation. To overcome these obstacles in current approaches,\nthis paper introduces CONVINCE, a new approach to look at the network cameras\nas a collective entity that enables collaborative video analytics pipeline\namong cameras. CONVINCE aims at 1) reducing the computation cost and bandwidth\nrequirements by leveraging spatio-temporal correlations among cameras in\neliminating redundant frames intelligently, and ii) improving vision\nalgorithms' accuracy by enabling collaborative knowledge sharing among relevant\ncameras. Our results demonstrate that CONVINCE achieves an object\nidentification accuracy of $\\sim$91\\%, by transmitting only about $\\sim$25\\% of\nall the recorded frames.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 23:55:45 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pasandi", "Hannaneh Barahouei", ""], ["Nadeem", "Tamer", ""]]}, {"id": "2002.03805", "submitter": "Francisco Carpio", "authors": "Francisco Carpio, Marta Delgado and Admela Jukan", "title": "Engineering and Experimentally Benchmarking a Container-based Edge\n  Computing System", "comments": null, "journal-ref": null, "doi": "10.1109/ICC40277.2020.9148636", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While edge computing is envisioned to superbly serve latency sensitive\napplications, the implementation-based studies benchmarking its performance are\nfew and far between. To address this gap, we engineer a modular edge cloud\ncomputing system architecture that is built on latest advances in\ncontainerization techniques, including Kafka, for data streaming, Docker, as\napplication platform, and Firebase Cloud, as realtime database system. We\nbenchmark the performance of the system in terms of scalability, resource\nutilization and latency by comparing three scenarios: cloud-only, edge-only and\ncombined edge-cloud. The measurements show that edge-only solution outperforms\nother scenarios only when deployed with data located at one edge only, i.e.,\nwithout edge computing wide data synchronization. In case of applications\nrequiring data synchronization through the cloud, edge-cloud scales around a\nfactor 10 times better than cloud-only, until certain number of concurrent\nusers in the system, and above this point, cloud-only scales better. In terms\nof resource utilization, we observe that whereas the mean utilization increases\nlinearly with the number of user requests, the maximum values for the memory\nand the network I/O heavily increase when with an increasing amount of data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:38:24 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Carpio", "Francisco", ""], ["Delgado", "Marta", ""], ["Jukan", "Admela", ""]]}, {"id": "2002.03838", "submitter": "Lucas Costa", "authors": "Lucas R. Costa and Andr\\'e C. Drummond", "title": "Dynamic Multi-Modulation Allocation Scheme for Elastic Optical Networks", "comments": "10 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to deal with the recent rapid increase in Internet traffic, a\ntransmission technology is required to enable the efficient use of the optical\nfiber spectrum while offering flexibility in network bandwidth. To meet these\nchallenges, the emergence of Elastic Optical Networks (EON) has brought new\nconceptions in the operation of optical networks, improving flexibility and\nefficiency for the next generation core networks. In EON, traffic demands are\ntypically supported by allocating bandwidth-variable optical channels with\nheterogeneous modulation formats in a spectral-efficient manner. Elastic\noptical path networks require the routing, modulation level, and spectrum\nallocation (RMLSA) to efficiently allocate optical spectrum resources to\noptical paths. To address the RMLSA problem, Modulation Scheme approaches have\nrecently been proposed to allow the use of any routing and spectrum assignment\n(RSA) algorithm to solve the RMLSA problem. In this paper, we propose a new\nModulation Scheme that enables the routing of traffic through dynamic\nmulti-modulation allocation in multiple hops to achieve blocking performance\nimprovement. Numerical results demonstrate that the proposed adaptive\nmodulation scheme achieves a reduction in bandwidth blocking of up to two\norders of magnitude in an underloaded network scenario, and 86% with higher\nloads, playing an important role in spectrum savings compared with the\nliterature schemes.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:03:35 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Costa", "Lucas R.", ""], ["Drummond", "Andr\u00e9 C.", ""]]}, {"id": "2002.03872", "submitter": "Maximilian Bachl", "authors": "Maximilian Bachl, Fares Meghdouri, Joachim Fabini, Tanja Zseby", "title": "SparseIDS: Learning Packet Sampling with Reinforcement Learning", "comments": null, "journal-ref": "2020 IEEE Conference on Communications and Network Security (CNS),\n  Avignon, France", "doi": "10.1109/CNS48642.2020.9162253", "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent Neural Networks (RNNs) have been shown to be valuable for\nconstructing Intrusion Detection Systems (IDSs) for network data. They allow\ndetermining if a flow is malicious or not already before it is over, making it\npossible to take action immediately. However, considering the large number of\npackets that has to be inspected, for example in cloud/fog and edge computing,\nthe question of computational efficiency arises. We show that by using a novel\nReinforcement Learning (RL)-based approach called SparseIDS, we can reduce the\nnumber of consumed packets by more than three fourths while keeping\nclassification accuracy high. To minimize the computational expenses of the\nRL-based sampling we show that a shared neural network can be used for both the\nclassifier and the RL logic. Thus, no additional resources are consumed by the\nsampling in deployment. Comparing to various other sampling techniques,\nSparseIDS consistently achieves higher classification accuracy by learning to\nsample only relevant packets. A major novelty of our RL-based approach is that\nit can not only skip up to a predefined maximum number of samples like other\napproaches proposed in the domain of Natural Language Processing but can even\nskip arbitrarily many packets in one step. This enables saving even more\ncomputational resources for long sequences. Inspecting SparseIDS's behavior of\nchoosing packets shows that it adopts different sampling strategies for\ndifferent attack types and network flows. Finally we build an automatic\nsteering mechanism that can guide SparseIDS in deployment to achieve a desired\nlevel of sparsity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:38:38 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 12:18:44 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 15:22:43 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Bachl", "Maximilian", ""], ["Meghdouri", "Fares", ""], ["Fabini", "Joachim", ""], ["Zseby", "Tanja", ""]]}, {"id": "2002.03905", "submitter": "Mohammad Imran Syed", "authors": "Mohammad Imran Syed (MIMOVE, SU), Renata Teixeira (MIMOVE), Sara\n  Ayoubi (MIMOVE), Giulio Grassi (MIMOVE)", "title": "The Challenges of Trace-Driven Wi-Fi Emulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wi-Fi link is unpredictable and it has never been easy to measure it\nperfectly; there is always bound to be some bias. As wireless becomes the\nmedium of choice, it is useful to capture Wi-Fi traces in order to evaluate,\ntune, and adapt the different applications and protocols. Several methods have\nbeen used for the purpose of experimenting with different wireless conditions:\nsimulation, experimentation, and trace-driven emulation. In this paper, we\nargue that trace-driven emulation is the most favourable approach. In the\nabsence of a trace-driven emulation tool for Wi-Fi, we evaluate the\nstate-of-the-art trace driven emulation tool for Cellular networks and we\nidentify issues for Wi-Fi: interference with concurrent traffic, interference\nwith its own traffic if measurements are done on both uplink and downlink\nsimultaneously , and packet loss. We provide a solid argument as to why this\ntool falls short from effectively capturing Wi-Fi traces. The outcome of our\nanalysis guides us to propose a number of suggestions on how the existing tool\ncan be tweaked to accurately capture Wi-Fi traces.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:13:04 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Syed", "Mohammad Imran", "", "MIMOVE, SU"], ["Teixeira", "Renata", "", "MIMOVE"], ["Ayoubi", "Sara", "", "MIMOVE"], ["Grassi", "Giulio", "", "MIMOVE"]]}, {"id": "2002.04077", "submitter": "Joshua Lawrence Benjamin", "authors": "Joshua L. Benjamin, Thomas Gerard, Domani\\c{c} Lavery, Polina Bayvel\n  and Georgios Zervas", "title": "PULSE: Optical circuit switched Data Center architecture operating at\n  nanosecond timescales", "comments": "16 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PULSE, a sub-microsecond optical circuit-switched data centre\nnetwork architecture controlled by distributed hardware schedulers. PULSE is a\nflat architecture that uses parallel passive coupler-based broadcast and select\nnetworks. We employ a novel transceiver architecture, for dynamic\nwavelength-timeslot selection, to achieve a reconfiguration time down to\nO(100ps), establishing timeslots of O(10ns). A novel scheduling algorithm that\nhas a clock period of 2.3ns performs multiple iterations to maximize\nthroughput, wavelength usage and reduce latency, enhancing the overall\nperformance. In order to scale, the single-hop PULSE architecture uses\nsub-networks that are disjoint by using multiple transceivers for each node in\n64 node racks. At the reconfiguration circuit duration (epoch = 120 ns), the\nscheduling algorithm is shown to achieve up to 93% throughput and 100%\nwavelength usage of 64 wavelengths, incurring an average latency that ranges\nfrom 0.7-1.2 microseconds with best-case 0.4 microsecond median and 5\nmicrosecond tail latency, limited by the timeslot (20 ns) and epoch size (120\nns). We show how the 4096-node PULSE architecture allows up to 260k optical\nchannels to be re-used across sub-networks achieving a capacity of 25.6 Pbps\nwith an energy consumption of 85 pJ/bit.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 20:34:20 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 09:32:08 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Benjamin", "Joshua L.", ""], ["Gerard", "Thomas", ""], ["Lavery", "Domani\u00e7", ""], ["Bayvel", "Polina", ""], ["Zervas", "Georgios", ""]]}, {"id": "2002.04096", "submitter": "Roger Immich", "authors": "Ademar T. Akabane, Roger Immich, Luiz F. Bittencourt, Edmundo\n  R.M.Madeira, Leandro A.Villas", "title": "Towards a distributed and infrastructure-less vehicular traffic\n  management system", "comments": "preprint", "journal-ref": "Computer Communications, 2020", "doi": "10.1016/j.comcom.2020.01.002", "report-no": null, "categories": "cs.NI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the past few years, several systems have been proposed to deal with issues\nrelated to the vehicular traffic management. Usually, their solutions include\nthe integration of computational technologies such as vehicular networks,\ncentral servers, and roadside units. Most systems use a hybrid approach, which\nmeans they still need a central entity (central server or roadside unit) and\nInternet connection to find out an en-route event as well as alternative routes\nfor vehicles. It is easy to understand the need for a central entity because\nselecting the most appropriate vehicle to perform aforementioned procedures is\na difficult task. In addition to that, as far as we know, there are very few\nsystems that apply the altruistic approach (not selfish behavior) to routing\ndecisions. Because of that, the issue addressed in this work is how to perform\nthe vehicular traffic management, when an en-route event is detected, in a\ndistributed, scalable, and cost-effective fashion. To deal with these issues,\nwe proposed a distributed vehicle traffic management system, named as dEASY\n(distributed vEhicle trAffic management SYstem). The dEASY system was designed\nand implemented on a three-layer architecture, namely environment sensing and\nvehicle ranking, knowledge generation and distribution, and knowledge\nconsumption. Each layer of the dEASY architecture is responsible for dealing\nwith the main issues that were not addressed in related works or could be\nimproved. Simulation results have shown that, compared with other systems from\nthe literature, our proposed system has lower network overhead due to applied\nvehicle selection and broadcast suppression mechanisms. In average, dEASY also\noutperformed all other competitors in what regards to the travel time and time\nlost metrics. Through the analysis of results, it is possible to conclude that\nour infrastructure-less system is scalable and cost-effective.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:36:26 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Akabane", "Ademar T.", ""], ["Immich", "Roger", ""], ["Bittencourt", "Luiz F.", ""], ["Madeira", "Edmundo R. M.", ""], ["Villas", "Leandro A.", ""]]}, {"id": "2002.04124", "submitter": "Maede Zolanvari", "authors": "Deval Bhamare, Maede Zolanvari, Aiman Erbad, Raj Jain, Khaled Khan,\n  Nader Meskin", "title": "Cybersecurity for Industrial Control Systems: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial Control System (ICS) is a general term that includes supervisory\ncontrol & data acquisition (SCADA) systems, distributed control systems (DCS),\nand other control system configurations such as programmable logic controllers\n(PLC). ICSs are often found in the industrial sectors and critical\ninfrastructures, such as nuclear and thermal plants, water treatment\nfacilities, power generation, heavy industries, and distribution systems.\nThough ICSs were kept isolated from the Internet for so long, significant\nachievable business benefits are driving a convergence between ICSs and the\nInternet as well as information technology (IT) environments, such as cloud\ncomputing. As a result, ICSs have been exposed to the attack vectors used in\nthe majority of cyber-attacks. However, ICS devices are inherently much less\nsecure against such advanced attack scenarios. A compromise to ICS can lead to\nenormous physical damage and danger to human lives. In this work, we have a\nclose look at the shift of the ICS from stand-alone systems to cloud-based\nenvironments. Then we discuss the major works, from industry and academia\ntowards the development of the secure ICSs, especially applicability of the\nmachine learning techniques for the ICS cyber-security. The work may help to\naddress the challenges of securing industrial processes, particularly while\nmigrating them to the cloud environments.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:52:14 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Bhamare", "Deval", ""], ["Zolanvari", "Maede", ""], ["Erbad", "Aiman", ""], ["Jain", "Raj", ""], ["Khan", "Khaled", ""], ["Meskin", "Nader", ""]]}, {"id": "2002.04244", "submitter": "Pradipta Ghosh", "authors": "Pradipta Ghosh, Jonathan Bunton, Dimitrios Pylorof, Marcos Vieira,\n  Kevin Chan, Ramesh Govindan, Gaurav Sukhatme, Paulo Tabuada and Gunjan Verma", "title": "Rapid Top-Down Synthesis of Large-Scale IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in optimization and constraint satisfaction techniques, together\nwith the availability of elastic computing resources, have spurred interest in\nlarge-scale network verification and synthesis. Motivated by this, we consider\nthe top-down synthesis of ad-hoc IoT networks for disaster response and search\nand rescue operations. This synthesis problem must satisfy complex and\ncompeting constraints: sensor coverage, line-of-sight visibility, and network\nconnectivity. The central challenge in our synthesis problem is quickly scaling\nto large regions while producing cost-effective solutions. We explore two\nqualitatively different representations of the synthesis problems\nsatisfiability modulo convex optimization (SMC), and mixed-integer linear\nprogramming (MILP). The former is more expressive, for our problem, than the\nlatter, but is less well-suited for solving optimization problems like ours. We\nshow how to express our network synthesis in these frameworks, and, to scale to\nproblem sizes beyond what these frameworks are capable of, develop a\nhierarchical synthesis technique that independently synthesizes networks in\nsub-regions of the deployment area, then combines these. We find that, while\nMILP outperforms SMC in some settings for smaller problem sizes, the fact that\nSMC's expressivity matches our problem ensures that it uniformly generates\nbetter quality solutions at larger problem sizes.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:59:16 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 23:12:18 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Ghosh", "Pradipta", ""], ["Bunton", "Jonathan", ""], ["Pylorof", "Dimitrios", ""], ["Vieira", "Marcos", ""], ["Chan", "Kevin", ""], ["Govindan", "Ramesh", ""], ["Sukhatme", "Gaurav", ""], ["Tabuada", "Paulo", ""], ["Verma", "Gunjan", ""]]}, {"id": "2002.04269", "submitter": "Ludovic Thomas", "authors": "Ludovic Thomas (1) and Jean-Yves Le Boudec (1) ((1) \\'Ecole\n  Polytechnique F\\'ed\\'erale de Lausanne)", "title": "On Time Synchronization Issues in Time-Sensitive Networks with\n  Regulators and Nonideal Clocks", "comments": "ACM SIGMETRICS 2020 Boston, Massachusetts, USA June 8-12, 2020", "journal-ref": "In Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, 2, Article 27\n  (June 2020). ACM, New York, NY", "doi": "10.1145/3392145", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow reshaping is used in time-sensitive networks (as in the context of IEEE\nTSN and IETF Detnet) in order to reduce burstiness inside the network and to\nsupport the computation of guaranteed latency bounds. This is performed using\nper-flow regulators (such as the Token Bucket Filter) or interleaved regulators\n(as with IEEE TSN Asynchronous Traffic Shaping). Both types of regulators are\nbeneficial as they cancel the increase of burstiness due to multiplexing inside\nthe network. It was demonstrated, by using network calculus, that they do not\nincrease the worst-case latency. However, the properties of regulators were\nestablished assuming that time is perfect in all network nodes. In reality,\nnodes use local, imperfect clocks. Time-sensitive networks exist in two\nflavours: (1) in non-synchronized networks, local clocks run independently at\nevery node and their deviations are not controlled and (2) in synchronized\nnetworks, the deviations of local clocks are kept within very small bounds\nusing for example a synchronization protocol (such as PTP) or a satellite based\ngeo-positioning system (such as GPS). We revisit the properties of regulators\nin both cases. In non-synchronized networks, we show that ignoring the timing\ninaccuracies can lead to network instability due to unbounded delay in per-flow\nor interleaved regulators. We propose and analyze two methods (rate and burst\ncascade, and asynchronous dual arrival-curve method) for avoiding this problem.\nIn synchronized networks, we show that there is no instability with per-flow\nregulators but, surprisingly, interleaved regulators can lead to instability.\nTo establish these results, we develop a new framework that captures industrial\nrequirements on clocks in both non-synchronized and synchronized networks, and\nwe develop a toolbox that extends network calculus to account for clock\nimperfections.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:17:20 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:28:54 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 15:00:46 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Thomas", "Ludovic", ""], ["Boudec", "Jean-Yves Le", ""]]}, {"id": "2002.04451", "submitter": "Jalal Rachad", "authors": "Jalal Rachad, Ridha Nasri, Laurent Decreusefond", "title": "A 3D Beamforming Scheme Based on The Spatial Distribution of User\n  Locations", "comments": "arXiv admin note: text overlap with arXiv:1912.05056", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-antenna technologies such as massive Multiple-Input Multiple-Output\n(massive MIMO) and beamforming are key features to enhance performance, in\nterms of capacity and coverage, by using a large number of antennas\nintelligently. With the upcoming 5G New Radio (NR), FD-MIMO (Full Dimension\nMIMO) will play a major key role. FD-MIMO consists in arranging a large number\nof antennas in a 2D array, which enables to use 3D beamforming i.e.,\nbeamforming in both horizontal and vertical dimensions. The present paper\nprovides a 3D beamforming model where beam steering depends on the random\nspatial distribution of users. We attempt to derive some analytical results\nregarding the probability distribution of antenna beamforming radiation\npattern. Also, through system level simulations, we show how 3D beamforming can\nreduce interference impact, compared to the traditional 2D beamforming, and\nenhances system performance in terms of the coverage probability and users\nthroughput.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:08:37 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Rachad", "Jalal", ""], ["Nasri", "Ridha", ""], ["Decreusefond", "Laurent", ""]]}, {"id": "2002.04533", "submitter": "Haoqian Zhang", "authors": "Haoqian Zhang, Yancheng Zhao, Abhishek Paryani, Ke Yi", "title": "Infnote: A Decentralized Information Sharing Platform Based on\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet censorship has been implemented in several countries to prevent\ncitizens from accessing information and to suppress discussion of specific\ntopics. This paper presents Infnote, a platform that helps eliminate the\nproblem of sharing content in these censorship regimes. Infnote is a\ndecentralized information sharing system based on blockchain and peer-to-peer\nnetwork, aiming to provide an easy-to-use medium for users to share their\nthoughts, insights and views freely without worrying about data tampering and\ndata loss. Infnote provides a solution that is able to work on any level of\nInternet censorship. Infnote uses multi-chains architecture to support various\nindependent applications or different functions in an application.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 16:35:40 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Zhang", "Haoqian", ""], ["Zhao", "Yancheng", ""], ["Paryani", "Abhishek", ""], ["Yi", "Ke", ""]]}, {"id": "2002.04568", "submitter": "Igor Sfiligoi", "authors": "Igor Sfiligoi, John Graham and Frank Wuerthwein", "title": "Characterizing network paths in and out of the clouds", "comments": "7 pages, 1 figure, 5 tables, to be published in CHEP19 proceedings", "journal-ref": "EPJ Web of Conferences 245, 07059 (2020)", "doi": "10.1051/epjconf/202024507059", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Commercial Cloud computing is becoming mainstream, with funding agencies\nmoving beyond prototyping and starting to fund production campaigns, too. An\nimportant aspect of any scientific computing production campaign is data\nmovement, both incoming and outgoing. And while the performance and cost of VMs\nis relatively well understood, the network performance and cost is not. This\npaper provides a characterization of networking in various regions of Amazon\nWeb Services, Microsoft Azure and Google Cloud Platform, both between Cloud\nresources and major DTNs in the Pacific Research Platform, including OSG data\nfederation caches in the network backbone, and inside the clouds themselves.\nThe paper contains both a qualitative analysis of the results as well as\nlatency and throughput measurements. It also includes an analysis of the costs\ninvolved with Cloud-based networking.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 17:47:06 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Sfiligoi", "Igor", ""], ["Graham", "John", ""], ["Wuerthwein", "Frank", ""]]}, {"id": "2002.04597", "submitter": "Zheng Dong", "authors": "Zheng Dong, Yan Lu, Guangmo Tong, Yuanchao Shu, Shuai Wang, Weisong\n  Shi", "title": "WatchDog: Real-time Vehicle Tracking on Geo-distributed Edge Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle tracking, a core application to smart city video analytics, is\nbecoming more widely deployed than ever before thanks to the increasing number\nof traffic cameras and recent advances of computer vision and machine learning.\nDue to the constraints of bandwidth, latency, and privacy concerns, tracking\ntasks are more preferable to run on edge devices sitting close to the cameras.\nHowever, edge devices are provisioned with a fixed amount of compute budget,\nmaking them incompetent to adapt to time-varying tracking workloads caused by\ntraffic dynamics. In coping with this challenge, we propose WatchDog, a\nreal-time vehicle tracking system fully utilizes edge nodes across the road\nnetwork. WatchDog leverages computer vision tasks with different\nresource-accuracy trade-offs, and decompose and schedule tracking tasks\njudiciously across edge devices based on the current workload to maximize the\nnumber of tasks while ensuring a provable response time bound at each edge\ndevice. Extensive evaluations have been conducted using real-world city-wide\nvehicle trajectory datasets, showing a 100% tracking coverage with real-time\nguarantee.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 18:41:57 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Dong", "Zheng", ""], ["Lu", "Yan", ""], ["Tong", "Guangmo", ""], ["Shu", "Yuanchao", ""], ["Wang", "Shuai", ""], ["Shi", "Weisong", ""]]}, {"id": "2002.04731", "submitter": "Keen Sung", "authors": "Keen Sung, Brian Levine, Mariya Zheleva", "title": "ZipPhone: Protecting user location privacy from cellular service\n  providers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless service providers track the time and location of all user\nconnections. Location inference attacks have been effective in revealing the\nidentity of anonymous users of wireless services. In this paper, we propose\nZipPhone, a solution that leverages existing cellular infrastructure to improve\nuser privacy. Spartacus allows a community of users to strategically time their\nconnections to remain anonymous while incurring a minimal loss of utility. We\nevaluate ZipPhone from the perspective of a cell service provider and a\ncommunity of privacy-seeking users, and quantify the privacy/utility trade-off\nof ZipPhone using two datasets containing cell tower logs of hundreds of users.\nWe present and assess a deanonymization algorithm that uses both location\nprofiling and trajectory linking. We find that by renewing identifiers every\nten minutes and remaining offline for 30 seconds, users can reduce their\nidentifiability by up to 45%.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 23:28:07 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Sung", "Keen", ""], ["Levine", "Brian", ""], ["Zheleva", "Mariya", ""]]}, {"id": "2002.04834", "submitter": "Leila Rashidi", "authors": "Leila Rashidi, Don Towsley, Arman Mohseni-Kabir, and Ali Movaghar", "title": "On the Performance Analysis of Epidemic Routing in Non-Sparse Delay\n  Tolerant Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of epidemic routing in a delay tolerant network as a\nfunction of node density. Focusing on the probability of successful delivery to\na destination within a deadline (PS), we show that PS experiences a phase\ntransition as node density increases. Specifically, we prove that PS exhibits a\nphase transition when nodes are placed according to a Poisson process and\nallowed to move according to independent and identical processes with limited\nspeed. We then propose four fluid models to evaluate the performance of\nepidemic routing in non-sparse networks. A model is proposed for supercritical\nnetworks based on approximation of the infection rate as a function of time.\nOther models are based on the approximation of the pairwise infection rate. Two\nof them, one for subcritical networks and another for supercritical networks,\nuse the pairwise infection rate as a function of the number of infected nodes.\nThe other model uses pairwise infection rate as a function of time, and can be\napplied for both subcritical and supercritical networks achieving good\naccuracy. The model for subcritical networks is accurate when density is not\nclose to the percolation critical density. Moreover, the models that target\nonly supercritical regime are accurate.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:15:23 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Rashidi", "Leila", ""], ["Towsley", "Don", ""], ["Mohseni-Kabir", "Arman", ""], ["Movaghar", "Ali", ""]]}, {"id": "2002.04851", "submitter": "Jianhui Liu", "authors": "Jianhui Liu and Qi Zhang", "title": "Computation Resource Allocation for Heterogeneous Time-Critical IoT\n  Services in MEC", "comments": "Accepted in IEEE Wireless Communications and Networking Conference\n  (WCNC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing (MEC) is one of the promising solutions to process\ncomputational-intensive tasks within short latency for emerging\nInternet-of-Things (IoT) use cases, e.g., virtual reality (VR), augmented\nreality (AR), autonomous vehicle. Due to the coexistence of heterogeneous\nservices in MEC system, the task arrival interval and required execution time\ncan vary depending on services. It is challenging to schedule computation\nresource for the services with stochastic arrivals and runtime at an edge\nserver (ES). In this paper, we propose a flexible computation offloading\nframework among users and ESs. Based on the framework, we propose a\nLyapunov-based algorithm to dynamically allocate computation resource for\nheterogeneous time-critical services at the ES. The proposed algorithm\nminimizes the average timeout probability without any prior knowledge on task\narrival process and required runtime. The numerical results show that, compared\nwith the standard queuing models used at ES, the proposed algorithm achieves at\nleast 35% reduction of the timeout probability, and approximated utilization\nefficiency of computation resource to non-cause queuing model under various\nscenarios.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:00:55 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Liu", "Jianhui", ""], ["Zhang", "Qi", ""]]}, {"id": "2002.04858", "submitter": "Jianhui Liu", "authors": "Jianhui Liu and Qi Zhang", "title": "Adaptive Task Partitioning at Local Device or Remote Edge Server for\n  Offloading in MEC", "comments": "Accepted in IEEE Wireless Communications and Networking Conference\n  (WCNC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing (MEC) is one of the promising solutions to process\ncomputational-intensive tasks for the emerging time-critical Internet-of-Things\n(IoT) use cases, e.g., virtual reality (VR), augmented reality (AR), autonomous\nvehicle. The latency can be reduced further, when a task is partitioned and\ncomputed by multiple edge servers' (ESs) collaboration. However, the\nstate-of-the-art work studies the MEC-enabled offloading based on a static\nframework, which partitions tasks at either the local user equipment (UE) or\nthe primary ES. The dynamic selection between the two offloading schemes has\nnot been well studied yet. In this paper, we investigate a dynamic offloading\nframework in a multi-user scenario. Each UE can decide who partitions a task\naccording to the network status, e.g., channel quality and allocated\ncomputation resource. Based on the framework, we model the latency to complete\na task, and formulate an optimization problem to minimize the average latency\namong UEs. The problem is solved by jointly optimizing task partitioning and\nthe allocation of the communication and computation resources. The numerical\nresults show that, compared with the static offloading schemes, the proposed\nalgorithm achieves the lower latency in all tested scenarios. Moreover, both\nmathematical derivation and simulation illustrate that the wireless channel\nquality difference between a UE and different ESs can be used as an important\ncriterion to determine the right scheme.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:13:07 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Liu", "Jianhui", ""], ["Zhang", "Qi", ""]]}, {"id": "2002.04902", "submitter": "Roberto Doriguzzi Corin", "authors": "Roberto Doriguzzi-Corin, Stuart Millar, Sandra Scott-Hayward, Jesus\n  Martinez-del-Rincon, Domenico Siracusa", "title": "LUCID: A Practical, Lightweight Deep Learning Solution for DDoS Attack\n  Detection", "comments": "Accepted for publication in the IEEE Transactions on Network and\n  Service Management", "journal-ref": null, "doi": "10.1109/TNSM.2020.2971776", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Denial of Service (DDoS) attacks are one of the most harmful\nthreats in today's Internet, disrupting the availability of essential services.\nThe challenge of DDoS detection is the combination of attack approaches coupled\nwith the volume of live traffic to be analysed. In this paper, we present a\npractical, lightweight deep learning DDoS detection system called LUCID, which\nexploits the properties of Convolutional Neural Networks (CNNs) to classify\ntraffic flows as either malicious or benign. We make four main contributions;\n(1) an innovative application of a CNN to detect DDoS traffic with low\nprocessing overhead, (2) a dataset-agnostic preprocessing mechanism to produce\ntraffic observations for online attack detection, (3) an activation analysis to\nexplain LUCID's DDoS classification, and (4) an empirical validation of the\nsolution on a resource-constrained hardware platform. Using the latest\ndatasets, LUCID matches existing state-of-the-art detection accuracy whilst\npresenting a 40x reduction in processing time, as compared to the\nstate-of-the-art. With our evaluation results, we prove that the proposed\napproach is suitable for effective DDoS detection in resource-constrained\noperational environments.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 10:34:18 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 08:15:19 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Doriguzzi-Corin", "Roberto", ""], ["Millar", "Stuart", ""], ["Scott-Hayward", "Sandra", ""], ["Martinez-del-Rincon", "Jesus", ""], ["Siracusa", "Domenico", ""]]}, {"id": "2002.05037", "submitter": "Youssouf Drif", "authors": "Youssouf Drif, Emmanuel Chaput, Emmanuel Lavinal, Pascal Berthou,\n  Boris Tiomela Jou, Olivier Gremillet, Fabrice Arnal", "title": "An Extensible Network Slicing Framework for Satellite Integration into\n  5G", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the past decades, networks have evolved to increase their performances,\ntheir capacities, to reduce latencies and optimize their resource management in\norder to remain competitive and adapted to the market. Today, the way consumers\nuse networks has changed and more heterogeneous services with their own\nrequirements have emerged. This has led network operators to define the network\nslicing paradigm. Network slicing creates multiple partitions in the network,\neach partition can be dedicated to a particular service allowing vertical\nmarkets and multiple services with different requirements to run on top of a\nsingle infrastructure. To allow the flexibility level required by network\nslicing, satellite technologies have to evolve. Satcoms actors have therefore\nbeen working on improving satellite equipments. Testbeds followed the\ntheoretical analysis and ESA's current project SATis5 is making it its core\ntopic. The work presented in the full-paper of this extend abstract is the next\nstep we propose to those initiatives. It focuses on the network slicing concept\napplied to satellite networks which, we believe, is a mandatory requirement for\na full integrated satellite into 5G networks. We first start by describing the\nmain challenges associated to the satellite slice definition. We then highlight\na set of requirements for such a satellite slice. Based on those requirements,\nwe construct and propose a complete Satellite Slice as a Service (S3) framework\nwhich mutualizes the satellite infrastructure to provide a seamless integration\ninto 5G networks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:10:03 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Drif", "Youssouf", ""], ["Chaput", "Emmanuel", ""], ["Lavinal", "Emmanuel", ""], ["Berthou", "Pascal", ""], ["Jou", "Boris Tiomela", ""], ["Gremillet", "Olivier", ""], ["Arnal", "Fabrice", ""]]}, {"id": "2002.05091", "submitter": "James Pavur", "authors": "James Pavur, Martin Strohmeier, Vincent Lenders, Ivan Martinovic", "title": "QPEP: A QUIC-Based Approach to Encrypted Performance Enhancing Proxies\n  for High-Latency Satellite Broadband", "comments": "A reference implementation of QPEP and a dockerized version of the\n  testbed and scripts used for its evaluation can be found at\n  https://www.github.com/pavja2/qpep", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Satellite broadband services are critical infrastructures enabling advanced\ntechnologies to function in the most remote regions of the globe. However,\nstatus-quo services are often unencrypted by default and vulnerable to\neavesdropping attacks. In this paper, we challenge the historical perception\nthat over-the-air security must trade off with TCP performance in high-latency\nsatellite networks due to the deep-packet inspection requirements of\nPerformance Enhancing Proxies (PEPs).\n  After considering why prior work in this area has failed to find wide\nadoption, we present an open-source encrypted-by-default PEP - QPEP - which\nseeks to address these issues. QPEP is built around the open QUIC standard and\ndesigned so individual customers may adopt it without ISP involvement. QPEP's\nperformance is assessed through simulations in a replicable docker-based\ntestbed. Across many benchmarks and network conditions, QPEP is found to avoid\nthe perceived security-encryption trade-off in PEP design. Compared to\nunencrypted PEP implementations, QPEP reduces average page load times by more\nthan 30% while also offering over-the-air privacy. Compared to the traditional\nVPN encryption available to customers today, QPEP more than halves average page\nload times. Together, these experiments lead to the conclusion that QPEP\nrepresents a promising new approach to protecting modern satellite broadband\nconnections.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:54:00 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Pavur", "James", ""], ["Strohmeier", "Martin", ""], ["Lenders", "Vincent", ""], ["Martinovic", "Ivan", ""]]}, {"id": "2002.05162", "submitter": "Georges Nassif", "authors": "Georges Nassif, Catherine Gloaguen, and Philippe Martins", "title": "A Combined Stochastic and Physical Framework for Modeling Indoor 5G\n  Millimeter Wave Propagation", "comments": "30 pages, 18 figures, and 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indoor coverage is a major challenge for 5G millimeter waves (mmWaves). In\nthis paper, we address this problem through a novel theoretical framework that\ncombines stochastic indoor environment modeling with advanced physical\npropagation simulation. This approach is particularly adapted to investigate\nindoor-to-indoor 5G mmWave propagation. Its system implementation, so-called\niGeoStat, generates parameterized typical environments that account for the\nindoor spatial variations, then simulates radio propagation based on the\nphysical interaction between electromagnetic waves and material properties.\nThis framework is not dedicated to a particular environment, material,\nfrequency or use case and aims to statistically understand the influence of\nindoor environment parameters on mmWave propagation properties, especially\ncoverage and path loss. Its implementation raises numerous computational\nchallenges that we solve by formulating an adapted link budget and designing\nnew memory optimization algorithms. The first simulation results for two major\n5G applications are validated with measurement data and show the efficiency of\niGeoStat to simulate multiple diffusion in realistic environments, within a\nreasonable amount of time and memory resources. Generated output maps confirm\nthat diffusion has a critical impact on indoor mmWave propagation and that\nproper physical modeling is of the utmost importance to generate relevant\npropagation models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:28:30 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 11:12:59 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Nassif", "Georges", ""], ["Gloaguen", "Catherine", ""], ["Martins", "Philippe", ""]]}, {"id": "2002.05300", "submitter": "Roger Immich", "authors": "Flavia Pisani, Fabiola M. C. de Oliveira, Eduardo S. Gama, Roger\n  Immich, Luiz F. Bittencourt, and Edson Borin", "title": "Fog Computing on Constrained Devices: Paving the Way for the Future IoT", "comments": "http://ebooks.iospress.nl/volumearticle/53823", "journal-ref": "IOS Press Advances in Edge Computing: Massive Parallel Processing\n  and Applications, Series Advances in Parallel Computing, Volume 35 (2020).\n  ISBN978-1-64368-062-0 (print) | 978-1-64368-063-7 (online)", "doi": "10.3233/APC200003", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the long term, the Internet of Things (IoT) is expected to become an\nintegral part of people's daily lives. In light of this technological\nadvancement, an ever-growing number of objects with limited hardware may become\nconnected to the Internet. In this chapter, we explore the importance of these\nconstrained devices as well as how we can use them in conjunction with fog\ncomputing to change the future of the IoT. First, we present an overview of the\nconcepts of constrained devices, IoT, and fog and mist computing, and then we\npresent a classification of applications according to the amount of resources\nthey require (e.g., processing power and memory). After that, we tie in these\ntopics with a discussion of what can be expected in a future where constrained\ndevices and fog computing are used to push the IoT to new limits. Lastly, we\ndiscuss some challenges and opportunities that these technologies may bring.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 01:12:31 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 17:52:55 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Pisani", "Flavia", ""], ["de Oliveira", "Fabiola M. C.", ""], ["Gama", "Eduardo S.", ""], ["Immich", "Roger", ""], ["Bittencourt", "Luiz F.", ""], ["Borin", "Edson", ""]]}, {"id": "2002.05339", "submitter": "Tatsuaki Kimura", "authors": "Tatsuaki Kimura, Masaki Ogura", "title": "Distributed Collaborative 3D-Deployment of UAV Base Stations for\n  On-Demand Coverage", "comments": "to appear in IEEE International Conference on Computer Communications\n  2020 (INFOCOM2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of unmanned aerial vehicles (UAVs) performing as flying aerial\nbase stations (BSs) has a great potential of adaptively serving ground users\nduring temporary events, such as major disasters and massive events. However,\nplanning an efficient, dynamic, and 3D deployment of UAVs in adaptation to\ndynamically and spatially varying ground users is a highly complicated problem\ndue to the complexity in air-to-ground channels and interference among UAVs. In\nthis paper, we propose a novel distributed 3D deployment method for UAV-BSs in\na downlink network for on-demand coverage. Our method consists mainly of the\nfollowing two parts: sensing-aided crowd density estimation and distributed\npush-sum algorithm. The first part estimates the ground user density from its\nobservation through on-ground sensors, thereby allowing us to avoid the\ncomputationally intensive process of obtaining the positions of all the ground\nusers. On the basis of the estimated user density, in the second part, each UAV\ndynamically updates its 3D position in collaboration with its neighboring UAVs\nfor maximizing the total coverage. We prove the convergence of our distributed\nalgorithm by employing a distributed push-sum algorithm framework. Simulation\nresults demonstrate that our method can improve the overall coverage with a\nlimited number of ground sensors. We also demonstrate that our method can be\napplied to a dynamic network in which the density of ground users varies\ntemporally.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 04:32:49 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Kimura", "Tatsuaki", ""], ["Ogura", "Masaki", ""]]}, {"id": "2002.05400", "submitter": "Mike Kosek", "authors": "Mike Kosek, Leo Bl\\\"ocher, Jan R\\\"uth, Torsten Zimmermann, Oliver\n  Hohlfeld", "title": "MUST, SHOULD, DON'T CARE: TCP Conformance in the Wild", "comments": null, "journal-ref": "International Conference on Passive and Active Network Measurement\n  (PAM) 2020", "doi": "10.1007/978-3-030-44081-7_8", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standards govern the SHOULD and MUST requirements for protocol implementers\nfor interoperability. In case of TCP that carries the bulk of the Internets'\ntraffic, these requirements are defined in RFCs. While it is known that not all\noptional features are implemented and nonconformance exists, one would assume\nthat TCP implementations at least conform to the minimum set of MUST\nrequirements. In this paper, we use Internet-wide scans to show how Internet\nhosts and paths conform to these basic requirements. We uncover a\nnon-negligible set of hosts and paths that do not adhere to even basic\nrequirements. For example, we observe hosts that do not correctly handle\nchecksums and cases of middlebox interference for TCP options. We identify\nhosts that drop packets when the urgent pointer is set or simply crash. Our\npublicly available results highlight that conformance to even fundamental\nprotocol requirements should not be taken for granted but instead checked\nregularly.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:30:14 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 09:31:33 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Kosek", "Mike", ""], ["Bl\u00f6cher", "Leo", ""], ["R\u00fcth", "Jan", ""], ["Zimmermann", "Torsten", ""], ["Hohlfeld", "Oliver", ""]]}, {"id": "2002.05437", "submitter": "Yin Bonan", "authors": "Bonan Yin, Mugen Peng, Shi Yan and Chunjing Hu", "title": "Tradeoff between Ergodic Rate and Delivery Latency in Fog Radio Access\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless content caching has recently been considered as an efficient way in\nfog radio access networks (FRANs) to alleviate the heavy burden on\ncapacity-limited fronthaul links and reduce delivery latency. In this paper, an\nadvanced minimal delay association policy is proposed to minimize latency while\nguaranteeing spectral efficiency in F-RANs. By utilizing stochastic geometry\nand queueing theory, closed-form expressions of successful delivery\nprobability, average ergodic rate, and average delivery latency are derived,\nwhere both the traditional association policy based on accessing the base\nstation with maximal received power and the proposed minimal delay association\npolicy are concerned. Impacts of key operating parameters on the aforementioned\nperformance metrics are exploited. It is shown that the proposed association\npolicy has a better delivery latency than the traditional association policy.\nIncreasing the cache size of fog-computing based access points (F-APs) can more\nsignificantly reduce average delivery latency, compared with increasing the\ndensity of F-APs. Meanwhile, the latter comes at the expense of decreasing\naverage ergodic rate. This implies the deployment of large cache size at F-APs\nrather than high density of F-APs can promote performance effectively in\nF-RANs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 10:45:53 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yin", "Bonan", ""], ["Peng", "Mugen", ""], ["Yan", "Shi", ""], ["Hu", "Chunjing", ""]]}, {"id": "2002.05485", "submitter": "Xinran Zhang", "authors": "Xinran Zhang, Mugen Peng, Shi Yan, and Yaohua Sun", "title": "Deep Reinforcement Learning Based Mode Selection and Resource Allocation\n  for Cellular V2X Communications", "comments": "12 pages, 11 figures, accepted by IEEE IoT Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular vehicle-to-everything (V2X) communication is crucial to support\nfuture diverse vehicular applications. However, for safety-critical\napplications, unstable vehicle-to-vehicle (V2V) links and high signalling\noverhead of centralized resource allocation approaches become bottlenecks. In\nthis paper, we investigate a joint optimization problem of transmission mode\nselection and resource allocation for cellular V2X communications. In\nparticular, the problem is formulated as a Markov decision process, and a deep\nreinforcement learning (DRL) based decentralized algorithm is proposed to\nmaximize the sum capacity of vehicle-to-infrastructure users while meeting the\nlatency and reliability requirements of V2V pairs. Moreover, considering\ntraining limitation of local DRL models, a two-timescale federated DRL\nalgorithm is developed to help obtain robust model. Wherein, the graph theory\nbased vehicle clustering algorithm is executed on a large timescale and in turn\nthe federated learning algorithm is conducted on a small timescale. Simulation\nresults show that the proposed DRL-based algorithm outperforms other\ndecentralized baselines, and validate the superiority of the two-timescale\nfederated DRL algorithm for newly activated V2V pairs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 13:00:47 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zhang", "Xinran", ""], ["Peng", "Mugen", ""], ["Yan", "Shi", ""], ["Sun", "Yaohua", ""]]}, {"id": "2002.05666", "submitter": "Behnam Pourghassemi", "authors": "Behnam Pourghassemi, Jordan Bonecutter, Zhou Li, Aparna\n  Chandramowlishwaran", "title": "adPerf: Characterizing the Performance of Third-party Ads", "comments": "13 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monetizing websites and web apps through online advertising is widespread in\nthe web ecosystem. The online advertising ecosystem nowadays forces publishers\nto integrate ads from these third-party domains. On the one hand, this raises\nseveral privacy and security concerns that are actively studied in recent\nyears. On the other hand, given the ability of today's browsers to load dynamic\nweb pages with complex animations and Javascript, online advertising has also\ntransformed and can have a significant impact on webpage performance. The\nperformance cost of online ads is critical since it eventually impacts user\nsatisfaction as well as their Internet bill and device energy consumption.\n  In this paper, we apply an in-depth and first-of-a-kind performance\nevaluation of web ads. Unlike prior efforts that rely primarily on adblockers,\nwe perform a fine-grained analysis on the web browser's page loading process to\ndemystify the performance cost of web ads. We aim to characterize the cost by\nevery component of an ad, so the publisher, ad syndicate, and advertiser can\nimprove the ad's performance with detailed guidance. For this purpose, we\ndevelop an infrastructure, adPerf, for the Chrome browser that classifies page\nloading workloads into ad-related and main-content at the granularity of\nbrowser activities (such as Javascript and Layout). Our evaluations show that\nonline advertising entails more than 15% of browser page loading workload and\napproximately 88% of that is spent on JavaScript. We also track the sources and\ndelivery chain of web ads and analyze performance considering the origin of the\nad contents. We observe that 2 of the well-known third-party ad domains\ncontribute to 35% of the ads performance cost and surprisingly, top news\nwebsites implicitly include unknown third-party ads which in some cases build\nup to more than 37% of the ads performance cost.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:09:05 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Pourghassemi", "Behnam", ""], ["Bonecutter", "Jordan", ""], ["Li", "Zhou", ""], ["Chandramowlishwaran", "Aparna", ""]]}, {"id": "2002.05711", "submitter": "Baturalp Buyukates", "authors": "Baturalp Buyukates and Sennur Ulukus", "title": "Age of Information with Gilbert-Elliot Servers and Samplers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study age of information in a status updating system that consists of a\nsingle sampler, i.e., source node, that sends time-sensitive status updates to\na single monitor node through a server node. We first consider a Gilbert-Elliot\nservice profile at the server node. In this model, service times at the server\nnode follow a finite state Markov chain with two states: ${bad}$ state $b$ and\n${good}$ state $g$ where the server is faster in state $g$. We determine the\ntime average age experienced by the monitor node and characterize the\nage-optimal state transition matrix $P$ with and without an average cost\nconstraint on the service operation. Next, we consider a Gilbert-Elliot\nsampling profile at the source. In this model, the interarrival times follow a\nfinite state Markov chain with two states: ${bad}$ state $b$ and ${good}$ state\n$g$ where samples are more frequent in state $g$. We find the time average age\nexperienced by the monitor node and characterize the age-optimal state\ntransition matrix $P$.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:52:13 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Buyukates", "Baturalp", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2002.05814", "submitter": "Zhuohan Li", "authors": "Siyuan Zhuang, Zhuohan Li, Danyang Zhuo, Stephanie Wang, Eric Liang,\n  Robert Nishihara, Philipp Moritz, Ion Stoica", "title": "Hoplite: Efficient Collective Communication for Task-Based Distributed\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective communication systems such as MPI offer high performance group\ncommunication primitives at the cost of application flexibility. Today, an\nincreasing number of distributed applications (e.g, reinforcement learning)\nrequire flexibility in expressing dynamic and asynchronous communication\npatterns. To accommodate these applications, task-based distributed computing\nframeworks (e.g., Ray, Dask, Hydro) have become popular as they allow\napplications to dynamically specify communication by invoking tasks, or\nfunctions, at runtime. This design makes efficient collective communication\nchallenging because (1) the group of communicating processes is chosen at\nruntime, and (2) processes may not all be ready at the same time.\n  We design and implement Hoplite, a communication layer for task-based\ndistributed systems that achieves high performance collective communication\nwithout compromising application flexibility. The key idea of Hoplite is to use\ndistributed protocols to compute a data transfer schedule on the fly. This\nenables the same optimizations used in traditional collective communication,\nbut for applications that specify the communication incrementally. We show that\nHoplite can achieve similar performance compared with a traditional collective\ncommunication library, MPICH. We port a popular distributed computing\nframework, Ray, on atop of Hoplite. We show that Hoplite can speed up\nasynchronous parameter server and distributed reinforcement learning workloads\nthat are difficult to execute efficiently with traditional collective\ncommunication by up to 8.1x and 3.9x, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 23:48:54 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Zhuang", "Siyuan", ""], ["Li", "Zhuohan", ""], ["Zhuo", "Danyang", ""], ["Wang", "Stephanie", ""], ["Liang", "Eric", ""], ["Nishihara", "Robert", ""], ["Moritz", "Philipp", ""], ["Stoica", "Ion", ""]]}, {"id": "2002.05868", "submitter": "Shan Zhang", "authors": "Shan Zhang, Liudi Wang, Hongbin Luo, Xiao Ma, Sheng Zhou", "title": "AoI-Delay Tradeoff in Mobile Edge Caching with Freshness-Aware Content\n  Refreshing", "comments": "Submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge caching can effectively reduce service delay but may introduce\ninformation staleness, calling for timely content refreshing. However, content\nrefreshing consumes additional transmission resources and may degrade the delay\nperformance of mobile systems. In this work, we propose a freshness-aware\nrefreshing scheme to balance the service delay and content freshness measured\nby Age of Information (AoI). Specifically, the cached content items will be\nrefreshed to the up-to-date version upon user requests if the AoI exceeds a\ncertain threshold (named as refreshing window). The average AoI and service\ndelay are derived in closed forms approximately, which reveals an AoI-delay\ntradeoff relationship with respect to the refreshing window. In addition, the\nrefreshing window is optimized to minimize the average delay while meeting the\nAoI requirements, and the results indicate to set a smaller refreshing window\nfor the popular content items. Extensive simulations are conducted on the\nOMNeT++ platform to validate the analytical results. The results indicate that\nthe proposed scheme can restrain frequent refreshing as the request arrival\nrate increases, whereby the average delay can be reduced by around 80% while\nmaintaining the AoI below one second in heavily-loaded scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 04:29:56 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Zhang", "Shan", ""], ["Wang", "Liudi", ""], ["Luo", "Hongbin", ""], ["Ma", "Xiao", ""], ["Zhou", "Sheng", ""]]}, {"id": "2002.05884", "submitter": "Leila Rashidi", "authors": "Leila Rashidi, Amir Dalili-Yazdi, Reza Entezari-Maleki, Leonel Sousa,\n  and Ali Movaghar", "title": "Performance Modeling of Epidemic Routing in Mobile Social Networks with\n  Emphasis on Scalability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the performance of epidemic routing in mobile social\nnetworks. It first analyzes the time taken for a node to meet the first node of\na set of nodes restricted to move in a specific subarea. Afterwards, a\nmonolithic Stochastic Reward Net (SRN) is proposed to evaluate the delivery\ndelay and the average number of transmissions under epidemic routing by\nconsidering skewed location visiting preferences. This model is not scalable\nenough, in terms of the number of nodes and frequently visited locations. In\norder to achieve higher scalability, the folding technique is applied to the\nmonolithic model, and an approximate folded SRN is proposed to evaluate\nperformance of epidemic routing. Discrete-event simulation is used to validate\nthe proposed models. Both SRN models show high accuracy in predicting the\nperformance of epidemic routing. We also propose an Ordinary Differential\nEquation (ODE) model for epidemic routing and compare it with the folded model.\nObtained results show that the folded model is more accurate than the ODE\nmodel. Moreover, it is proved that the number of transmissions by the time of\ndelivery follows uniform distribution, in a general class of networks, where\npositions of nodes are always independent and identically distributed.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 06:29:12 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Rashidi", "Leila", ""], ["Dalili-Yazdi", "Amir", ""], ["Entezari-Maleki", "Reza", ""], ["Sousa", "Leonel", ""], ["Movaghar", "Ali", ""]]}, {"id": "2002.05929", "submitter": "Mohammad Abu Alsheikh", "authors": "Mohammad Abu Alsheikh, Dinh Thai Hoang, Dusit Niyato, Derek Leong,\n  Ping Wang, and Zhu Han", "title": "Optimal Pricing of Internet of Things: A Machine Learning Approach", "comments": "17 pages", "journal-ref": "IEEE Journal on Selected Areas in Communications, 2020 dIEEE\n  Journal on Selected Areas in Communications IEEE Journal on Selected Areas in\n  Communications", "doi": "10.1109/JSAC.2020.2971898 10.1109/JSAC.2020.2971898", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of things (IoT) produces massive data from devices embedded with\nsensors. The IoT data allows creating profitable services using machine\nlearning. However, previous research does not address the problem of optimal\npricing and bundling of machine learning-based IoT services. In this paper, we\ndefine the data value and service quality from a machine learning perspective.\nWe present an IoT market model which consists of data vendors selling data to\nservice providers, and service providers offering IoT services to customers.\nThen, we introduce optimal pricing schemes for the standalone and bundled\nselling of IoT services. In standalone service sales, the service provider\noptimizes the size of bought data and service subscription fee to maximize its\nprofit. For service bundles, the subscription fee and data sizes of the grouped\nIoT services are optimized to maximize the total profit of cooperative service\nproviders. We show that bundling IoT services maximizes the profit of service\nproviders compared to the standalone selling. For profit sharing of bundled\nservices, we apply the concepts of core and Shapley solutions from cooperative\ngame theory as efficient and fair allocations of payoffs among the cooperative\nservice providers in the bundling coalition.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:17:40 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Alsheikh", "Mohammad Abu", ""], ["Hoang", "Dinh Thai", ""], ["Niyato", "Dusit", ""], ["Leong", "Derek", ""], ["Wang", "Ping", ""], ["Han", "Zhu", ""]]}, {"id": "2002.06116", "submitter": "Ziru Chen", "authors": "Ziru Chen, Yong Liu, Sami Khairy, Lin X. Cai, Yu Cheng and Ran Zhang", "title": "Optimizing Non-Orthogonal Multiple Access in Random Access Networks", "comments": "Accepted by VTC 2020 spring", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-orthogonal multiple access (NOMA) has been considered as a promising\nsolution for improving the spectrum efficiency of next-generation wireless\nnetworks. In this paper, the performance of a p-persistent slotted ALOHA system\nin support of NOMA transmissions is investigated. Specifically, wireless users\ncan choose to use high or low power for data transmissions with certain\nprobabilities. To achieve the maximum network throughput, an analytical\nframework is developed to analyze the successful transmission probability of\nNOMA and long term average throughput of users involved in the non-orthogonal\ntransmissions. The feasible region of the maximum number of concurrent users\nusing high and low power to ensure successful NOMA transmissions are\nquantified. Based on the analysis, an algorithm is proposed to find the optimal\ntransmission probabilities for users to choose high and low power to achieve\nthe maximum system throughput. In addition, the impact of power settings on the\nnetwork performance is further investigated. Simulations are conducted to\nvalidate the analysis.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:33:05 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 18:16:51 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chen", "Ziru", ""], ["Liu", "Yong", ""], ["Khairy", "Sami", ""], ["Cai", "Lin X.", ""], ["Cheng", "Yu", ""], ["Zhang", "Ran", ""]]}, {"id": "2002.06246", "submitter": "Michel Bakni", "authors": "Michel Bakni, Luis Manuel Moreno Chac\\'on, Yudith Cardinale, Guillaume\n  Terrasson, and Octavian Curea", "title": "WSN simulators evaluation: an approach focusing on energy awareness", "comments": "20 Pages", "journal-ref": null, "doi": "10.5121/ijwmn.2019.11601", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The large number of Wireless Sensor Networks (WSN) simulators available\nnowadays, differ in their design, goals, and characteristics. Users who have to\ndecide which simulator is the most appropriate for their particular\nrequirements, are today lost, faced with a panoply of disparate and diverse\nsimulators. Hence, it is obvious the need for establishing guidelines that\nsupport users in the tasks of selecting a simulator to suit their preferences\nand needs. In previous works, we proposed a generic and novel approach to\nevaluate networks simulators, considering a methodological process and a set of\nqualitative and quantitative criteria. In particularly, for WSN simulators, the\ncriteria include relevant aspects for this kind of networks, such as energy\nconsumption modelling and scalability capacity. The aims of this work are: (i)\ndescribe deeply the criteria related to WSN aspects; (ii) extend and update the\nstate of the art of WSN simulators elaborated in our previous works to identify\nthe most used and cited in scientific articles; and (iii) demonstrate the\nsuitability of our novel methodological approach by evaluating and comparing\nthe three most cited simulators, specially in terms of energy modelling and\nscalability capacities. Results show that our proposed approach provides\nresearchers with an evaluation tool that can be used to describe and compare\nWSN simulators in order to select the most appropriate one for a given scenario\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 07:53:11 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bakni", "Michel", ""], ["Chac\u00f3n", "Luis Manuel Moreno", ""], ["Cardinale", "Yudith", ""], ["Terrasson", "Guillaume", ""], ["Curea", "Octavian", ""]]}, {"id": "2002.06248", "submitter": "Benedikt Jahnel", "authors": "Alexander Hinsen, Benedikt Jahnel, Elie Cali, and Jean-Philippe Wary", "title": "Malware propagation in urban D2D networks", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce and analyze models for the propagation of malware in pure D2D\nnetworks given via stationary Cox-Gilbert graphs. Here, the devices form a\nPoisson point process with random intensity measure $\\lambda\\Lambda$, where\n$\\Lambda$ is stationary and given, for example, by the edge-length measure of a\nrealization of a Poisson-Voronoi tessellation that represents an urban street\nsystem. We assume that, at initial time, a typical device at the center of the\nnetwork carries a malware and starts to infect neighboring devices after random\nwaiting times. Here we focus on Markovian models, where the waiting times are\nexponential random variables, and non-Markovian models, where the waiting times\nfeature strictly positive minimal and finite maximal waiting times. We present\nnumerical results for the speed of propagation depending on the system\nparameters. In a second step, we introduce and analyze a counter measure for\nthe malware propagation given by special devices called white knights, which\nhave the ability, once attacked, to eliminate the malware from infected devices\nand turn them into white knights. Based on simulations, we isolate parameter\nregimes in which the malware survives or is eliminated, both in the Markovian\nand non-Markovian setting.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 20:33:08 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Hinsen", "Alexander", ""], ["Jahnel", "Benedikt", ""], ["Cali", "Elie", ""], ["Wary", "Jean-Philippe", ""]]}, {"id": "2002.06251", "submitter": "Jie Gao", "authors": "Jie Gao, Shan Zhang, Lian Zhao, Xuemin (Sherman) Shen", "title": "The Design of Dynamic Probabilistic Caching with Time-Varying Content\n  Popularity", "comments": "13 pages; 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design dynamic probabilistic caching for the scenario when\nthe instantaneous content popularity may vary with time while it is possible to\npredict the average content popularity over a time window. Based on the average\ncontent popularity, optimal content caching probabilities can be found, e.g.,\nfrom solving optimization problems, and existing results in the literature can\nimplement the optimal caching probabilities via static content placement. The\nobjective of this work is to design dynamic probabilistic caching that: i)\nconverge (in distribution) to the optimal content caching probabilities under\ntime-invariant content popularity, and ii) adapt to the time-varying\ninstantaneous content popularity under time-varying content popularity.\nAchieving the above objective requires a novel design of dynamic content\nreplacement because static caching cannot adapt to varying content popularity\nwhile classic dynamic replacement policies, such as LRU, cannot converge to\ntarget caching probabilities (as they do not exploit any content popularity\ninformation). We model the design of dynamic probabilistic replacement policy\nas the problem of finding the state transition probability matrix of a Markov\nchain and propose a method to generate and refine the transition probability\nmatrix. Extensive numerical results are provided to validate the effectiveness\nof the proposed design.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 17:35:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gao", "Jie", "", "Sherman"], ["Zhang", "Shan", "", "Sherman"], ["Zhao", "Lian", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""]]}, {"id": "2002.06254", "submitter": "Minseok Choi Dr.", "authors": "Minseok Choi, Andreas F. Molisch, Dong-Jun Han, Joongheon Kim and\n  Jaekyun Moon", "title": "Cache Allocations for Consecutive Requests of Categorized Contents:\n  Service Provider's Perspective", "comments": "7 pages, 5 figures, IEEE Wireless Communications and Networking\n  Conference (WCNC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless caching networks, a user generally has a concrete purpose of\nconsuming contents in a certain preferred category, and requests multiple\ncontents in sequence. While most existing research on wireless caching and\ndelivery has focused only on one-shot requests, the popularity distribution of\ncontents requested consecutively is definitely different from the one-shot\nrequest and has been not considered. Also, especially from the perspective of\nthe service provider, it is advantageous for users to consume as many contents\nas possible. Thus, this paper proposes two cache allocation policies for\ncategorized contents and consecutive user demands, which maximize 1) the cache\nhit rate and 2) the number of consecutive content consumption, respectively.\nNumerical results show how categorized contents and consecutive content\nrequests have impacts on the cache allocation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 09:09:12 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Choi", "Minseok", ""], ["Molisch", "Andreas F.", ""], ["Han", "Dong-Jun", ""], ["Kim", "Joongheon", ""], ["Moon", "Jaekyun", ""]]}, {"id": "2002.06255", "submitter": "Pradnya Kiri Taksande", "authors": "Pradnya Kiri Taksande, Prasanna Chaporkar, Pranav Jha, and Abhay\n  Karandikar", "title": "Proportional Fairness through Dual Connectivity in Heterogeneous\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proportional Fair (PF) is a scheduling technique to maintain a balance\nbetween maximizing throughput and ensuring fairness to users. Dual Connectivity\n(DC) technique was introduced by the 3rd Generation Partnership Project (3GPP)\nto improve the mobility robustness and system capacity in heterogeneous\nnetworks. In this paper, we demonstrate the utility of DC in improving\nproportional fairness in the system. We propose a low complexity centralized PF\nscheduling scheme for DC and show that it outperforms the standard PF\nscheduling scheme. Since the problem of dual association of users for\nmaximizing proportional fairness in the system is NP-hard, we propose three\nheuristic user association schemes for DC. We demonstrate that DC, along with\nthe proposed PF scheme, gives remarkable gains on PF utility over single\nconnectivity and performs almost close to the optimal PF scheme in\nheterogeneous networks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 14:02:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Taksande", "Pradnya Kiri", ""], ["Chaporkar", "Prasanna", ""], ["Jha", "Pranav", ""], ["Karandikar", "Abhay", ""]]}, {"id": "2002.06256", "submitter": "Pradnya Kiri Taksande Dr.", "authors": "Pradnya Kiri Taksande, Pranav Jha, Abhay Karandikar, and Prasanna\n  Chaporkar", "title": "Open5G: A Software-Defined Networking Protocol for 5G Multi-RAT Wireless\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile Networks today comprise of multiple Radio Access Technologies (RATs),\ne.g., 4G LTE, Wireless Local Area Network (WLAN), and the upcoming 5G-New Radio\n(5G-NR). The access networks of these RATs are controlled by RAT-specific\nentities, e.g., the resource management function located inside an individual\nLTE eNB is used for the eNB control, or access controllers are used for\ncontrolling WLAN Access Points. Even in the 3GPP's 5G architecture, which has a\ncommon Core supporting multiple RATs, radio access related decisions are taken\nindependently within individual RATs. Due to the fragmented nature of\ncontrol-plane in multi-RAT Radio Access Network (RAN), a unified global view of\nnetwork resources is unavailable, hindering optimized allocation of resources.\nIt also brings complexity to the features involving multiple RATs, e.g., dual\nconnectivity. To address these issues, we introduced an SDN-based Multi-RAT RAN\narchitecture (SMRAN) in our earlier work [arXiv:1812.11825], where the RAN\ncontrol-plane is segregated from the data-plane. As part of the SMRAN\narchitecture, we defined a logically centralized multi-RAT RAN Controller and\nindividual RAT-specific data-plane functions. In the current work, we define a\nprotocol, called Open5G, to be used for control and management of the SMRAN\ndata-plane. Open5G is based on OpenFlow (OF) and OF-Config, which are commonly\nused protocols in the SDN-based wired networks and data centers.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 14:45:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Taksande", "Pradnya Kiri", ""], ["Jha", "Pranav", ""], ["Karandikar", "Abhay", ""], ["Chaporkar", "Prasanna", ""]]}, {"id": "2002.06259", "submitter": "Hui Yang", "authors": "Hui Yang, Kaixuan Zhan, Michel Kadoch, Yongshen Liang, Mohamed Cheriet", "title": "BLCS: Brain-Like based Distributed Control Security in Cyber Physical\n  Systems", "comments": "accepted by IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical system (CPS) has operated, controlled and coordinated the\nphysical systems integrated by a computing and communication core applied in\nindustry 4.0. To accommodate CPS services, fog radio and optical networks\n(F-RON) has become an important supporting physical cyber infrastructure taking\nadvantage of both the inherent ubiquity of wireless technology and the large\ncapacity of optical networks. However, cyber security is the biggest issue in\nCPS scenario as there is a tradeoff between security control and privacy\nexposure in F-RON. To deal with this issue, we propose a brain-like based\ndistributed control security (BLCS) architecture for F-RON in CPS, by\nintroducing a brain-like security (BLS) scheme. BLCS can accomplish the secure\ncross-domain control among tripartite controllers verification in the scenario\nof decentralized F-RON for distributed computing and communications, which has\nno need to disclose the private information of each domain against\ncyber-attacks. BLS utilizes parts of information to perform control\nidentification through relation network and deep learning of behavior library.\nThe functional modules of BLCS architecture are illustrated including various\ncontrollers and brain-like knowledge base. The interworking procedures in\ndistributed control security modes based on BLS are described. The overall\nfeasibility and efficiency of architecture are experimentally verified on the\nsoftware defined network testbed in terms of average mistrust rate, path\nprovisioning latency, packet loss probability and blocking probability. The\nemulation results are obtained and dissected based on the testbed.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 09:14:10 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yang", "Hui", ""], ["Zhan", "Kaixuan", ""], ["Kadoch", "Michel", ""], ["Liang", "Yongshen", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "2002.06284", "submitter": "Jiangping Han", "authors": "Jiangping Han, Yitao Xing, Kaiping Xue, David S.L. Wei, Guoliang Xue,\n  Peilin Hong", "title": "Leveraging Coupled BBR and Adaptive Packet Scheduling to Boost MPTCP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quite a few algorithms have been proposed to optimize the transmission\nperformance of Multipath TCP (MPTCP). However, existing MPTCP protocols are\nstill far from satisfactory in lossy and ever-changing networks because of\ntheir loss-based congestion control and the difficulty of managing multiple\nsubflows. Recently, a congestion-based congestion control, BBR, is proposed to\npromote TCP transmission performance through better use of bandwidth. Due to\nthe superior performance of BBR, we try to boost MPTCP with it. For this\npropose, coupled congestion control should be redesigned for MPTCP, and a\nfunctional scheduler able to effectively make use of the characteristics of BBR\nmust also be developed for better performance. In this paper, we first propose\nCoupled BBR as a coupled congestion control algorithm for MPTCP to achieve high\nthroughput and stable sending rate in lossy network scenarios with guaranteed\nfairness with TCP BBR flows and balanced congestion. Then, to further improve\nthe performance, we propose an Adaptively Redundant and Packet-by-Packet\n(AR\\&P) scheduler, which includes two scheduling methods to improve\nadaptability in highly dynamic network scenarios and keep in-order packet\ndelivery in asymmetric networks. Based on Linux kernel implementation and\nexperiments in both testbed and real network scenarios, we show that the\nproposed scheme not only provides higher throughput, but also improves\nrobustness and reduces out-of-order packets in some harsh circumstances.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 00:08:45 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 03:06:08 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Han", "Jiangping", ""], ["Xing", "Yitao", ""], ["Xue", "Kaiping", ""], ["Wei", "David S. L.", ""], ["Xue", "Guoliang", ""], ["Hong", "Peilin", ""]]}, {"id": "2002.06359", "submitter": "Jielun Zhang", "authors": "Jielun Zhang, Fuhao Li, Feng Ye, Hongyu Wu", "title": "Autonomous Unknown-Application Filtering and Labeling for DL-based\n  Traffic Classifier Update", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network traffic classification has been widely studied to fundamentally\nadvance network measurement and management. Machine Learning is one of the\neffective approaches for network traffic classification. Specifically, Deep\nLearning (DL) has attracted much attention from the researchers due to its\neffectiveness even in encrypted network traffic without compromising neither\nuser privacy nor network security. However, most of the existing models are\ncreated from closed-world datasets, thus they can only classify those existing\nclasses previously sampled and labeled. In this case, unknown classes cannot be\ncorrectly classified. To tackle this issue, an autonomous learning framework is\nproposed to effectively update DL-based traffic classification models during\nactive operations. The core of the proposed framework consists of a DL-based\nclassifier, a self-learned discriminator, and an autonomous self-labeling\nmodel. The discriminator and self-labeling process can generate new dataset\nduring active operations to support classifier update. Evaluation of the\nproposed framework is performed on an open dataset, i.e., ISCX VPN-nonVPN, and\nindependently collected data packets. The results demonstrate that the proposed\nautonomous learning framework can filter packets from unknown classes and\nprovide accurate labels. Thus, corresponding DL-based classification models can\nbe updated successfully with the autonomously generated dataset.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 10:32:46 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zhang", "Jielun", ""], ["Li", "Fuhao", ""], ["Ye", "Feng", ""], ["Wu", "Hongyu", ""]]}, {"id": "2002.06403", "submitter": "Ashutosh Bhatia Dr.", "authors": "Aman Sharma, Ashutosh Bhatia", "title": "Bitcoin's Blockchain Data Analytics: A Graph Theoretic Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is the most popular cryptocurrency used worldwide. It provides\npseudonymity to its users by establishing identity using public keys as\ntransaction end-points. These transactions are recorded on an immutable public\nledger called Blockchain which is an append-only data structure. The popularity\nof Bitcoin has increased unreasonably. The general trend shows a positive\nresponse from the common masses indicating an increase in trust and privacy\nconcerns which makes an interesting use case from the analysis point of view.\nMoreover, since the blockchain is publicly available and up-to-date, any\nanalysis would provide a live insight into the usage patterns which ultimately\nwould be useful for making a number of inferences by law-enforcement agencies,\neconomists, tech-enthusiasts, etc. In this paper, we study various applications\nand techniques of performing data analytics over Bitcoin blockchain from a\ngraph theoretic perspective. We also propose a framework for performing such\ndata analytics and explored a couple of use cases using the proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 16:07:34 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Sharma", "Aman", ""], ["Bhatia", "Ashutosh", ""]]}, {"id": "2002.06474", "submitter": "Sherif ElAzzouni", "authors": "Sherif ElAzzouni, Eylem Ekici, Ness Shroff", "title": "Is Deadline Oblivious Scheduling Efficient for Controlling Real-Time\n  Traffic in Cellular Downlink Systems?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of bandwidth-intensive latency-critical traffic in 5G Networks,\nsuch as Virtual Reality, has motivated interest in wireless resource allocation\nproblems for flows with hard-deadlines. Attempting to solve this problem brings\nabout two challenges: (i) The flow arrival and the channel state are not known\nto the Base Station (BS) apriori, thus, the allocation decisions need to be\nmade online. (ii) Wireless resource allocation algorithms that attempt to\nmaximize a reward will likely be unfair, causing unacceptable service for some\nusers. We model the problem as an online convex optimization problem. We\npropose a primal-dual Deadline-Oblivious (DO) algorithm, and show it is\napproximately 3.6-competitive. Furthermore, we show via simulations that our\nalgorithm tracks the prescient offline solution very closely, significantly\noutperforming several existing algorithms. In the second part, we impose a\nstochastic constraint on the allocation, requiring a guarantee that each user\nachieves a certain timely throughput (amount of traffic delivered within the\ndeadline over a period of time). We propose the Long-term Fair Deadline\nOblivious (LFDO) algorithm for that setup. We combine the Lyapunov framework\nwith analysis of online algorithms, to show that LFDO retains the\nhigh-performance of DO, while satisfying the long-term stochastic constraints.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 23:52:01 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["ElAzzouni", "Sherif", ""], ["Ekici", "Eylem", ""], ["Shroff", "Ness", ""]]}, {"id": "2002.06635", "submitter": "Pedro Oliveira", "authors": "Pedro Oliveira, Alexandre Silva, Rui Valadas", "title": "The HPIM-DM Multicast Routing Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the HPIM-DM (Hard-state Protocol Independent Multicast -\nDense Mode) multicast routing protocol. HPIM-DM is a hard-state version of\nPIM-DM that keeps its main characteristics but has faster convergence and\nbetter resilience to replay attacks. Like PIM-DM, HPIM-DM is meant for dense\nnetworks and supports its operation on a unicast routing protocol and reverse\npath forwarding checks. However, routers maintain sense of the multicast trees\nat all times, allowing fast reconfiguration in the presence of network failures\nor unicast route changes. This is achieved by (i) keeping information on all\nupstream neighbors from which multicast data can be received, (ii) ensuring the\nreliable transmission and sequencing of control messages, and (iii)\nsynchronizing the routing information immediately when a new router joins the\nnetwork. The protocol was fully implemented in Python, and the implementation\nis publicly available. Finally, the correctness of the protocol was extensively\nvalidated using model checking, logical reasoning and tests performed over the\nprotocol implementation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 18:16:47 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Oliveira", "Pedro", ""], ["Silva", "Alexandre", ""], ["Valadas", "Rui", ""]]}, {"id": "2002.06928", "submitter": "Hamza Khan", "authors": "Hamza Khan, Sumudu Samarakoon, and Mehdi Bennis", "title": "Enhancing Video Streaming in Vehicular Networks via Resource Slicing", "comments": "10 Pages, 7 Figures, 2 Tables (Accepted for publication in the\n  special section of the IEEE Transactions on Vehicular Technology)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle-to-everything (V2X) communication is a key enabler that connects\nvehicles to neighboring vehicles, infrastructure and pedestrians. In the past\nfew years, multimedia services have seen an enormous growth and it is expected\nto increase as more devices will utilize infotainment services in the future\ni.e. vehicular devices. Therefore, it is important to focus on user centric\nmeasures i.e. quality-of-experience (QoE) such as video quality (resolution)\nand fluctuations therein. In this paper, a novel joint video quality selection\nand resource allocation technique is proposed for increasing the QoE of\nvehicular devices. The proposed approach exploits the queuing dynamics and\nchannel states of vehicular devices, to maximize the QoE while ensuring\nseamless video playback at the end users with high probability. The network\nwide QoE maximization problem is decoupled into two subparts. First, a network\nslicing based clustering algorithm is applied to partition the vehicles into\nmultiple logical networks. Secondly, vehicle scheduling and quality selection\nis formulated as a stochastic optimization problem which is solved using the\nLyapunov drift plus penalty method. Numerical results show that the proposed\nalgorithm ensures high video quality experience compared to the baseline.\nSimulation results also show that the proposed technique achieves low latency\nand high-reliability communication.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:53:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Khan", "Hamza", ""], ["Samarakoon", "Sumudu", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2002.06969", "submitter": "Lorenzo Bertizzolo", "authors": "Lorenzo Bertizzolo, Emrecan Demirors, Zhangyu Guan, Tommaso Melodia", "title": "CoBeam: Beamforming-based Spectrum Sharing With Zero Cross-Technology\n  Signaling for 5G Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies an essential yet challenging problem in 5G wireless\nnetworks: \\emph{Is it possible to enable spectrally-efficient spectrum sharing\nfor heterogeneous wireless networks with different, possibly incompatible,\nspectrum access technologies on the same spectrum bands; without modifying the\nprotocol stacks of existing wireless networks?} To answer this question, this\narticle explores the system challenges that need to be addressed to enable a\nnew spectrum sharing paradigm based on beamforming, which we refer to as {\\em\nCoBeam}. In CoBeam, a secondary wireless network is allowed to access a\nspectrum band based on {\\em cognitive beamforming} without mutual temporal\nexclusion, i.e., without interrupting the ongoing transmissions of coexisting\nwireless networks on the same bands; and without cross-technology\ncommunication. We first describe the main components of CoBeam, including\n\\emph{programmable physical layer driver}, \\emph{cognitive sensing engine}, and\n\\emph{beamforming engine}, and then we showcase the potential of the CoBeam\nframework by designing a practical coexistence scheme between Wi-Fi and LTE on\nunlicensed bands. We present a prototype of the resulting coexisting\nWi-Fi/U-LTE network built on off-the-shelf software radios based on which we\nevaluate the performance of CoBeam through an extensive experimental campaign.\nPerformance evaluation results indicate that CoBeam can achieve on average\n$169\\%$ throughput gain while requiring \\emph{no} signaling exchange between\nthe coexisting wireless networks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:19:19 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bertizzolo", "Lorenzo", ""], ["Demirors", "Emrecan", ""], ["Guan", "Zhangyu", ""], ["Melodia", "Tommaso", ""]]}, {"id": "2002.07027", "submitter": "Kamil Tokmakov", "authors": "Kamil Tokmakov, Mitalee Sarker, J\\\"org Domaschka, Stefan Wesner", "title": "A Case for Data Centre Traffic Management on Software Programmable\n  Ethernet Switches", "comments": "8th IEEE International Conference on Cloud Networking (IEEE CloudNet\n  2019)", "journal-ref": "2019 IEEE 8th International Conference on Cloud Networking\n  (CloudNet)", "doi": "10.1109/CloudNet47604.2019.9064114", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualisation first and cloud computing later has led to a consolidation of\nworkload in data centres that also comprises latency-sensitive application\ndomains such as High Performance Computing and telecommunication. These types\nof applications require strict latency guarantees to maintain their Quality of\nService. In virtualised environments with their churn, this demands for\nadaptability and flexibility to satisfy. At the same time, the mere scale of\nthe infrastructures favours commodity (Ethernet) over specialised (Infiniband)\nhardware. For that purpose, this paper introduces a novel traffic management\nalgorithm that combines Rate-limited Strict Priority and Deficit round-robin\nfor latency-aware and fair scheduling respectively. In addition, we present an\nimplementation of this algorithm on the bmv2 P4 software switch by evaluating\nit against standard priority-based and best-effort scheduling.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:12:28 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Tokmakov", "Kamil", ""], ["Sarker", "Mitalee", ""], ["Domaschka", "J\u00f6rg", ""], ["Wesner", "Stefan", ""]]}, {"id": "2002.07098", "submitter": "Muhammad Amjad", "authors": "Muhammad Amjad, Leila Musavian, and Sonia A\\\"issa", "title": "Effective Capacity of NOMA with Finite Blocklength for Low-Latency\n  Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the link-layer rate of a two-users\nnon-orthogonal multiple access (NOMA) network in finite blocklength (short\npacket communications) regime, where the two users are paired from a set of V\nusers. The overall reliability consists of the transmission error probability\nand the queuing delay violation probability. The performance of the two-users\nNOMA network in finite blocklength is verified for achieving latency and\nreliability, using the effective capacity (EC) framework. Specifically, we\nderive closed-form expressions for the EC of the two-users NOMA network in\nfinite blocklength regime, considering transmissions over Rayleigh fading\nchannels. We also study a multiuser NOMA network and derive the total EC of\ntwo-users NOMA subsets, and show that the NOMA set with users having distinct\nchannel conditions achieve maximum total EC. Focusing on a two-users NOMA\nnetwork, we study the impact of the transmit signal-to-noise ratio, delay\nexponent, and transmission error probability, on the achievable EC of each\nuser. The analysis shows that when the delay exponent is high, the delay\nviolation probability does not improve below a certain value due to the\ndominant factor of the transmission error probability. The accuracy of the\nproposed closed-form expressions for the individual EC of a two-users NOMA is\nverified using the Monte-Carlo simulations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:34:16 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Amjad", "Muhammad", ""], ["Musavian", "Leila", ""], ["A\u00efssa", "Sonia", ""]]}, {"id": "2002.07155", "submitter": "Wei Wang Dr.", "authors": "Wei Wang, Shiyue He, Qian Zhang, Tao Jiang", "title": "Enabling Low-Power OFDM for IoT by Exploiting Asymmetric Clock Rates", "comments": "To appear at IEEE/ACM Trans. Netw. arXiv admin note: substantial text\n  overlap with arXiv:1801.02811", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional high-speed Wi-Fi has recently become a contender for\nlow-power Internet-of-Things (IoT) communications. OFDM continues its adoption\nin the new IoT Wi-Fi standard due to its spectrum efficiency that can support\nthe demand of massive IoT connectivity. While the IoT Wi-Fi standard offers\nmany new features to improve power and spectrum efficiency, the basic physical\nlayer (PHY) structure of transceiver design still conforms to its conventional\ndesign rationale where access points (AP) and clients employ the same OFDM PHY.\nIn this paper, we argue that current Wi-Fi PHY design does not take full\nadvantage of the inherent asymmetry between AP and IoT. To fill the gap, we\npropose an asymmetric design where IoT devices transmit uplink packets using\nthe lowest power while pushing all the decoding burdens to the AP side. Such a\ndesign utilizes the sufficient power and computational resources at AP to trade\nfor the transmission (TX) power of IoT devices. The core technique enabling\nthis asymmetric design is that the AP takes full power of its high clock rate\nto boost the decoding ability. We provide an implementation of our design and\nshow that it can reduce up to 88% of the IoT's TX power when the AP sets\n$8\\times$ clock rate.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 11:12:54 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wang", "Wei", ""], ["He", "Shiyue", ""], ["Zhang", "Qian", ""], ["Jiang", "Tao", ""]]}, {"id": "2002.07178", "submitter": "Ghassan Samara", "authors": "Ghassan Samara, Ghadeer Al Besani, Mohammad Alauthman, and Mohammad Al\n  Khaldy", "title": "Energy-Efficiency Routing algorithms in Wireless Sensor Networks: a\n  Survey", "comments": "5 pages", "journal-ref": "International Journal of Scientific & Technology Research, Vol 9,\n  ISSUE 1, Jan 2020 ISSN 2277-8616", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Wireless Sensor Network (WSN) is a collection of tiny nodes that have low\nenergy levels and have become an essential component of the modern\ncommunication infrastructure and very important in industry and academia.\nEnergy is crucial in WSN, and thus the design of WSN in the research community\nis based on energy efficiency, and node energy consumption is a great challenge\nto enhance WSN's lifetime. It may be costly or even impossible to charge or\nreplace consumed batteries because of the difficult environment. Many energy\nefficiency methods are introduced in this article to decrease energy\nconsumption, improve network performance and increase network lifetime.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 10:18:28 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Samara", "Ghassan", ""], ["Besani", "Ghadeer Al", ""], ["Alauthman", "Mohammad", ""], ["Khaldy", "Mohammad Al", ""]]}, {"id": "2002.07223", "submitter": "AlMaha Abuzraiq", "authors": "Almaha Abuzuraiq, Mouhammd Alkasassbeh, and Mohammad Almseidin", "title": "Intelligent Methods for Accurately Detecting Phishing Websites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing technology developments, there is a massive number of\nwebsites with varying purposes. But a particular type exists within this large\ncollection, the so-called phishing sites which aim to deceive their users. The\nmain challenge in detecting phishing websites is discovering the techniques\nthat have been used. Where phishers are continually improving their strategies\nand creating web pages that can protect themselves against many forms of\ndetection methods. Therefore, it is very necessary to develop reliable, active\nand contemporary methods of phishing detection to combat the adaptive\ntechniques used by phishers. In this paper, different phishing detection\napproaches are reviewed by classifying them into three main groups. Then, the\nproposed model is presented in two stages. In the first stage, different\nmachine learning algorithms are applied to validate the chosen dataset and\napplying features selection methods on it. Thus, the best accuracy was achieved\nby utilizing only 20 features out of 48 features combined with Random Forest is\n98.11%. While in the second stage, the same dataset is applied to various fuzzy\nlogic algorithms. As well the experimental results from the application of\nFuzzy logic algorithms were incredible. Where in applying the FURIA algorithm\nwith only five features the accuracy rate was 99.98%. Finally, comparison and\ndiscussion of the results between applying machine learning algorithms and\nfuzzy logic algorithms is done. Where the performance of using fuzzy logic\nalgorithms exceeds the use of machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 19:57:03 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Abuzuraiq", "Almaha", ""], ["Alkasassbeh", "Mouhammd", ""], ["Almseidin", "Mohammad", ""]]}, {"id": "2002.07340", "submitter": "He Chen", "authors": "He Chen, Qian Wang, Parthajit Mohapatra, Nikolaos Pappas", "title": "Secure Status Updates under Eavesdropping: Age of Information-based\n  Physical Layer Security Metrics", "comments": "Submitted for possible publication. The first two authors contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter studies the problem of maintaining information freshness under\npassive eavesdropping attacks. The classical three-node wiretap channel model\nis considered, in which a source aims to send its latest status wirelessly to\nits intended destination, while protecting the message from being overheard by\nan eavesdropper. Considering that conventional channel capacity-based secrecy\nmetrics are no longer adequate to measure the information timeliness in status\nupdate systems, we define two new age of information-based metrics to\ncharacterize the secrecy performance of the considered system. We further\npropose, analyze, and optimize a randomized stationary transmission policy\nimplemented at the source for further enhancing the secrecy performance.\nSimulation results are provided to validate our analysis and optimization.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 02:32:33 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Chen", "He", ""], ["Wang", "Qian", ""], ["Mohapatra", "Parthajit", ""], ["Pappas", "Nikolaos", ""]]}, {"id": "2002.07380", "submitter": "Wei-Kun Chen", "authors": "Wei-Kun Chen, Ya-Feng Liu, Antonio De Domenico, Zhi-Quan Luo", "title": "Network Slicing for Service-Oriented Networks with Flexible Routing and\n  Guaranteed E2E Latency", "comments": "5 pages, 3 figures, accepted for publication in IEEE SPAWC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network function virtualization is a promising technology to simultaneously\nsupport multiple services with diverse characteristics and requirements in the\nfifth generation and beyond networks. In practice, each service consists of a\npredetermined sequence of functions, called service function chain (SFC),\nrunning on a cloud environment. To make different service slices work properly\nin harmony, it is crucial to select the cloud nodes to deploy the functions in\nthe SFC and flexibly route the flow of the services such that these functions\nare processed in sequence, the end-to-end (E2E) latency constraints of all\nservices are guaranteed, and all resource constraints are respected. In this\npaper, we propose a new (mixed binary linear program) formulation of the above\nnetwork slicing problem that optimizes the system energy efficiency while\njointly considers the resource budget, functional instantiation, flow routing,\nand E2E latency requirement. Numerical results show the advantage of the\nproposed formulation compared to the existing ones.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:33:55 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 10:11:26 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Chen", "Wei-Kun", ""], ["Liu", "Ya-Feng", ""], ["De Domenico", "Antonio", ""], ["Luo", "Zhi-Quan", ""]]}, {"id": "2002.07491", "submitter": "Romain Jacob", "authors": "Romain Jacob, Licong Zhang, Marco Zimmerling, Jan Beutel, Samarjit\n  Chakraborty, Lothar Thiele", "title": "The Time-Triggered Wireless Architecture", "comments": "Accepted at ECRTS 2020", "journal-ref": null, "doi": "10.4230/LIPIcs.ECRTS.2020.19", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wirelessly interconnected sensors, actuators, and controllers promise greater\nflexibility, lower installation and maintenance costs, and higher robustness in\nharsh conditions than wired solutions. However, to facilitate the adoption of\nwireless communication in cyber-physical systems (CPS), the functional and\nnon-functional properties must be similar to those known from wired\narchitectures. We thus present Time-Triggered Wireless (TTW), a wireless\narchitecture for multi-mode CPS that offers reliable communication with\nguarantees on end-to-end delays among distributed applications executing on\nlow-cost, low-power embedded devices. We achieve this by exploiting the high\nreliability and deterministic behavior of a synchronous transmission based\ncommunication stack we design, and by coupling the timings of distributed task\nexecutions and message exchanges across the wireless network by solving a novel\nco-scheduling problem. While some of the concepts in TTW have existed for some\ntime and TTW has already been successfully applied for feedback control and\ncoordination of multiple mechanical systems with closed-loop stability\nguarantees, this paper presents the key algorithmic, scheduling, and networking\nmechanisms behind TTW, along with their experimental evaluation, which have not\nbeen known so far. TTW is open source and ready to use: ttw.ethz.ch\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 11:17:26 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 08:51:28 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Jacob", "Romain", ""], ["Zhang", "Licong", ""], ["Zimmerling", "Marco", ""], ["Beutel", "Jan", ""], ["Chakraborty", "Samarjit", ""], ["Thiele", "Lothar", ""]]}, {"id": "2002.07535", "submitter": "Georg Von Zengen", "authors": "Georg von Zengen, Jingjing Yu and Lars C. Wolf", "title": "Adaptive Real-Time Scheduling for Cooperative Cyber-Physical Systems", "comments": "12 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CPSs are widely used in all sorts of applications ranging from industrial\nautomation to search-and-rescue. So far, in these applications they work either\nisolated with a high mobility or operate in a static networks setup. If mobile\nCPSs work cooperatively, it is in applications with relaxed real-time\nrequirements. To enable such cooperation also in hard real-time applications we\npresent a scheduling approach that is able to adapt real-time schedules to the\nchanges that happen in mobile networks. We present a Mixed Integer Linear\nProgrammingmodel and a heuristic to generate schedules for those networks. One\nof the key challenges is that running applications must not be interrupted\nwhile the schedule is adapted. Therefore, the scheduling has to consider the\ndelay and jitter boundaries, given by the application, while generating the\nadapted schedule.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 13:04:22 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["von Zengen", "Georg", ""], ["Yu", "Jingjing", ""], ["Wolf", "Lars C.", ""]]}, {"id": "2002.07584", "submitter": "Alon Rashelbach", "authors": "Alon Rashelbach, Ori Rottenstreich, Mark Silberstein", "title": "A Computational Approach to Packet Classification", "comments": "To appear in SIGCOMM 2020", "journal-ref": null, "doi": "10.1145/3387514.3405886", "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-field packet classification is a crucial component in modern\nsoftware-defined data center networks. To achieve high throughput and low\nlatency, state-of-the-art algorithms strive to fit the rule lookup data\nstructures into on-die caches; however, they do not scale well with the number\nof rules. We present a novel approach, NuevoMatch, which improves the memory\nscaling of existing methods. A new data structure, Range Query Recursive Model\nIndex (RQ-RMI), is the key component that enables NuevoMatch to replace most of\nthe accesses to main memory with model inference computations. We describe an\nefficient training algorithm that guarantees the correctness of the\nRQ-RMI-based classification. The use of RQ-RMI allows the rules to be\ncompressed into model weights that fit into the hardware cache. Further, it\ntakes advantage of the growing support for fast neural network processing in\nmodern CPUs, such as wide vector instructions, achieving a rate of tens of\nnanoseconds per lookup. Our evaluation using 500K multi-field rules from the\nstandard ClassBench benchmark shows a geometric mean compression factor of\n4.9x, 8x, and 82x, and average performance improvement of 2.4x, 2.6x, and 1.6x\nin throughput compared to CutSplit, NeuroCuts, and TupleMerge, all\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:47:02 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 06:18:41 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Rashelbach", "Alon", ""], ["Rottenstreich", "Ori", ""], ["Silberstein", "Mark", ""]]}, {"id": "2002.07593", "submitter": "Francesco Malandrino", "authors": "Alaa Awad Abdellatif and Carla Fabiana Chiasserini and Francesco\n  Malandrino", "title": "Active Learning-based Classification in Automated Connected Vehicles", "comments": null, "journal-ref": "PERSIST-IoT 2020: IEEE INFOCOM workshop on Pervasive Systems in\n  the IoT era", "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has emerged as a promising paradigm for enabling connected,\nautomated vehicles to autonomously cruise the streets and react to unexpected\nsituations. A key challenge, however, is to collect and select real-time and\nreliable information for the correct classification of unexpected, and often\nrare, situations that may happen on the road. Indeed, the data generated by\nvehicles, or received from neighboring vehicles, may be affected by errors or\nhave different levels of resolution and freshness. To tackle this challenge, we\npropose an active learning framework that, leveraging the information collected\nthrough onboard sensors as well as received from other vehicles, effectively\ndeals with scarce and noisy data. In particular, given the available\ninformation, our solution selects the data to add to the training set by\ntrading off between two essential features, namely, quality and diversity. The\nresults, obtained using real-world data sets, show that the proposed method\nsignificantly outperforms state-of-the-art solutions, providing high\nclassification accuracy at the cost of a limited bandwidth requirement for the\ndata exchange between vehicles.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 14:43:42 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Abdellatif", "Alaa Awad", ""], ["Chiasserini", "Carla Fabiana", ""], ["Malandrino", "Francesco", ""]]}, {"id": "2002.07747", "submitter": "Sebastian Henningsen", "authors": "Sebastian Henningsen and Martin Florian and Sebastian Rust and Bj\\\"orn\n  Scheuermann", "title": "Mapping the Interplanetary Filesystem", "comments": "The code can be found at https://github.com/scriptkitty/ipfs-crawler", "journal-ref": "Proceedings of IFIP Networking 2020", "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Interplanetary Filesystem (IPFS) is a distributed data storage service\nfrequently used by blockchain applications and for sharing content in a\ncensorship-resistant manner. Data is distributed within an open set of peers\nusing a Kademlia-based distributed hash table (DHT). In this paper, we study\nthe structure of the resulting overlay network, as it significantly influences\nthe robustness and performance of IPFS. We monitor and systematically crawl\nIPFS' DHT towards mapping the IPFS overlay network. Our measurements found an\naverage of 44474 nodes at every given time. At least 52.19% of these reside\nbehind a NAT and are not reachable from the outside, suggesting that a large\nshare of the network is operated by private individuals on an as-needed basis.\nBased on our measurements and our analysis of the IPFS code, we conclude that\nthe topology of the IPFS network is, in its current state, closer to an\nunstructured overlay network than it is to a classical DHT. While such a\nstructure has benefits for robustness and the resistance against Sybil attacks,\nit leaves room for improvement in terms of performance and query privacy.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:27:03 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Henningsen", "Sebastian", ""], ["Florian", "Martin", ""], ["Rust", "Sebastian", ""], ["Scheuermann", "Bj\u00f6rn", ""]]}, {"id": "2002.07759", "submitter": "Nan Jiang", "authors": "Nan Jiang, Yansha Deng, Arumugam Nallanathan", "title": "Traffic Prediction and Random Access Control Optimization: Learning and\n  Non-learning based Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random access schemes in modern wireless communications are generally based\non the framed-ALOHA (f-ALOHA), which can be optimized by flexibly organizing\ndevices' transmission and re-transmission. However, this optimization is\ngenerally intractable due to the lack of information about complex traffic\ngeneration statistics and the occurrence of the random collision. In this\narticle, we first summarize the general structure of access control\noptimization for different random access schemes, and then review the existing\naccess control optimization based on Machine Learning (ML) and non-ML\ntechniques. We demonstrate that the ML-based methods can better optimize the\naccess control problem compared with non-ML based methods, due to their\ncapability in solving high complexity long-term optimization problem and\nlearning experiential knowledge from reality. To further improve the random\naccess performance, we propose two-step learning optimizers for access control\noptimization, which individually execute the traffic prediction and the access\ncontrol configuration. In detail, our traffic prediction method relies on\nonline supervised learning adopting Recurrent Neural Networks (RNNs) that can\naccurately capture traffic statistics over consecutive frames, and the access\ncontrol configuration can use either a non-ML based controller or a\ncooperatively trained Deep Reinforcement Learning (DRL) based controller\ndepending on the complexity of different random access schemes. Numerical\nresults show that the proposed two-step cooperative learning optimizer\nconsiderably outperforms the conventional Deep Q-Network (DQN) in terms of\nhigher training efficiency and better access performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:49:06 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jiang", "Nan", ""], ["Deng", "Yansha", ""], ["Nallanathan", "Arumugam", ""]]}, {"id": "2002.07763", "submitter": "Quentin Bramas", "authors": "Jean-Philippe Abegg (ICube, UNISTRA), Quentin Bramas (ICube, UNISTRA),\n  Thomas Noel (ICube, UNISTRA)", "title": "Blockchain using Proof-of-Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper we define a new Puzzle called Proof-of-Interaction and we show how\nit can replace, in the Bitcoin protocol, the Proof-of-Work algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:55:50 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Abegg", "Jean-Philippe", "", "ICube, UNISTRA"], ["Bramas", "Quentin", "", "ICube, UNISTRA"], ["Noel", "Thomas", "", "ICube, UNISTRA"]]}, {"id": "2002.07842", "submitter": "Yan Liu", "authors": "Yan Liu, Yansha Deng, Maged Elkashlan, Arumugam Nallanathan, and\n  George K. Karagiannidis", "title": "Analyzing Grant-Free Access for URLLC Service", "comments": "Accepted in IEEE JSAC SI on MA for B5G IEEE JSAC SI on MASSIVE ACCESS\n  FOR 5G AND BEYOND", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G New Radio (NR) is expected to support new ultra-reliable low-latency\ncommunication (URLLC) service targeting at supporting the small packets\ntransmissions with very stringent latency and reliability requirements. Current\nLong Term Evolution (LTE) system has been designed based on grantbased (GB)\n(i.e., dynamic grant) random access, which can hardly support the URLLC\nrequirements. Grant-free (GF) (i.e., configured grant) access is proposed as a\nfeasible and promising technology to meet such requirements, especially for\nuplink transmissions, which effectively saves the time of requesting/waiting\nfor a grant. While some basic GF access features have been proposed and\nstandardized in NR Release-15, there is still much space to improve. Being\nproposed as 3GPP study items, three GF access schemes with Hybrid Automatic\nRepeat reQuest (HARQ) retransmissions including Reactive, K-repetition, and\nProactive, are analyzed in this paper. Specifically, we present a\nspatiotemporal analytical framework for the contention-based GF access\nanalysis. Based on this framework, we define the latent access failure\nprobability to characterize URLLC reliability and latency performances. We\npropose a tractable approach to derive and analyze the latent access failure\nprobability of the typical UE under three GF HARQ schemes. Our results show\nthat under shorter latency constraints, the Proactive scheme provides the\nlowest latent access failure probability, whereas, under longer latency\nconstraints, the K-repetition scheme achieves the lowest latent access failure\nprobability, which depends on K. If K is overestimated, the Proactive scheme\nprovides lower latent access failure probability than the K-repetition scheme.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:36:04 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 19:21:42 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Liu", "Yan", ""], ["Deng", "Yansha", ""], ["Elkashlan", "Maged", ""], ["Nallanathan", "Arumugam", ""], ["Karagiannidis", "George K.", ""]]}, {"id": "2002.07883", "submitter": "Luis Torres Figueroa", "authors": "Luis Torres-Figueroa, Henning F. Schepker and Josef Jiru", "title": "QoS Evaluation and Prediction for C-V2X Communication in\n  Commercially-Deployed LTE and Mobile Edge Networks", "comments": "7 pages, 10 figures, 7 tables. Accepted for publication in the 2020\n  IEEE 91st Vehicular Technology Conference: VTC2020-Spring", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular vehicle-to-everything (C-V2X) communication is a key enabler for\nfuture cooperative automated driving and safety-related applications. The\nrequirements they demand in terms of Quality of Service (QoS) performance vary\naccording to the use case. For instance, Day-1 applications such as Emergency\nBrake Light warning have less strict requirements than remote driving. In this\npaper, we seek to answer two questions: Are current LTE networks ready to\nsupport Day-1 applications at all times? And, can underperforming situations be\nreliably predicted based on GPS and network-related information? To address\nthese questions, we first implement a system that collects positioning data and\nLTE key performance indicators (KPIs) with a higher time resolution than\ncommercial off-the-shelf LTE modems, while simultaneously measuring the\nend-to-end (E2E) delay of an LTE network. We then use this system to assess the\nreadiness of multiple mobile network operators (MNOs) and a live Mobile Edge\nComputing (MEC) deployment in an urban scenario. For evaluating whether an\nadaptable operation is possible in adverse circumstances, e.g., by performing\nhybrid networking or graceful degradation, we finally use Machine Learning to\ngenerate a client-based QoS predictor and forecast the achievable QoS levels.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 21:22:07 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Torres-Figueroa", "Luis", ""], ["Schepker", "Henning F.", ""], ["Jiru", "Josef", ""]]}, {"id": "2002.07957", "submitter": "Zoubeir Mlika", "authors": "Zoubeir Mlika and Soumaya Cherkaoui", "title": "Massive Access in Beyond 5G IoT Networks with NOMA: NP-hardness,\n  Competitiveness and Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of online user grouping, scheduling and power\nallocation in beyond 5G cellular-based Internet of things networks. Due to the\nmassive number of devices trying to be granted to the network, non-orthogonal\nmultiple access method is adopted in order to accommodate multiple devices in\nthe same radio resource block. Different from most previous works, the\nobjective is to maximize the number of served devices while allocating their\ntransmission powers such that their real-time requirements as well as their\nlimited operating energy are respected. First, we formulate the general problem\nas a mixed integer non-linear program (MINLP) that can be transformed easily to\nMILP for some special cases. Second, we study its computational complexity by\ncharacterizing the NP-hardness of different special cases. Then, by dividing\nthe problem into multiple NOMA grouping and scheduling subproblems, efficient\nonline competitive algorithms are proposed. Further, we show how to use these\nonline algorithms and combine their solutions in a reinforcement learning\nsetting to obtain the power allocation and hence the global solution to the\nproblem. Our analysis are supplemented by simulation results to illustrate the\nperformance of the proposed algorithms with comparison to optimal and\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:45:32 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Mlika", "Zoubeir", ""], ["Cherkaoui", "Soumaya", ""]]}, {"id": "2002.08027", "submitter": "Minghong Fang", "authors": "Minghong Fang, Jia Liu", "title": "Toward Low-Cost and Stable Blockchain Networks", "comments": "Accepted by IEEE ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Envisioned to be the future of secured distributed systems, blockchain\nnetworks have received increasing attention from both the industry and academia\nin recent years. However, blockchain mining processes demand high hardware\ncosts and consume a vast amount of energy (studies have shown that the amount\nof energy consumed in Bitcoin mining is almost the same as the electricity used\nin Ireland). To address the high mining cost problem of blockchain networks, in\nthis paper, we propose a blockchain mining resources allocation algorithm to\nreduce the mining cost in PoW-based (proof-of-work-based) blockchain networks.\nWe first propose an analytical queueing model for general blockchain networks.\nIn our queueing model, transactions arrive randomly to the queue and are served\nin a batch manner with unknown service rate probability distribution and\nagnostic to any priority mechanism. Then, we leverage the Lyapunov optimization\ntechniques to propose a dynamic mining resources allocation algorithm (DMRA),\nwhich is parameterized by a tuning parameter $K>0$. We show that our algorithm\nachieves an $[O(1/K), O(K)]$ cost-optimality-gap-vs-delay tradeoff. Our\nsimulation results also demonstrate the effectiveness of DMRA in reducing\nmining costs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:42:33 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 20:39:50 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Fang", "Minghong", ""], ["Liu", "Jia", ""]]}, {"id": "2002.08040", "submitter": "Fanyi Wu", "authors": "F. Wu, H. Zhang, J. Wu and L. Song", "title": "Cellular UAV-to-Device Communications: Trajectory Design and Mode\n  Selection by Multi-agent Deep Reinforcement Learning", "comments": "33 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current unmanned aircraft systems (UASs) for sensing services,\nunmanned aerial vehicles (UAVs) transmit their sensory data to terrestrial\nmobile devices over the unlicensed spectrum. However, the interference from\nsurrounding terminals is uncontrollable due to the opportunistic channel\naccess. In this paper, we consider a cellular Internet of UAVs to guarantee the\nQuality-of-Service (QoS), where the sensory data can be transmitted to the\nmobile devices either by UAV-to-Device (U2D) communications over cellular\nnetworks, or directly through the base station (BS). Since UAVs' sensing and\ntransmission may influence their trajectories, we study the trajectory design\nproblem for UAVs in consideration of their sensing and transmission. This is a\nMarkov decision problem (MDP) with a large state-action space, and thus, we\nutilize multi-agent deep reinforcement learning (DRL) to approximate the\nstate-action space, and then propose a multi-UAV trajectory design algorithm to\nsolve this problem. Simulation results show that our proposed algorithm can\nachieve a higher total utility than policy gradient algorithm and single-agent\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 07:56:06 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 14:25:06 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Wu", "F.", ""], ["Zhang", "H.", ""], ["Wu", "J.", ""], ["Song", "L.", ""]]}, {"id": "2002.08084", "submitter": "Arliones Stevert Hoeller Junior", "authors": "Arliones Hoeller, Richard Demo Souza, Samuel Montejo-S\\'anchez, and\n  Hirley Alves", "title": "Performance Analysis of Single-Cell Adaptive Data Rate-Enabled LoRaWAN", "comments": "4 pages, 4 figures, accepted for publication in IEEE Wireless\n  Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LoRaWAN enables massive connectivity for Internet-of-Things applications.\nMany published works employ stochastic geometry to derive outage models of\nLoRaWAN over fading channels assuming fixed transmit power and distance-based\nspreading factor (SF) allocation. However, in practice, LoRaWAN employs the\nAdaptive Data Rate (ADR) mechanism, which dynamically adjusts SF and transmit\npower of nodes based on channel state. The community addressed the performance\nof ADR using simulations, but analytical models have not been introduced. In\nthis letter, we seek to close this gap. We build over an analytical LoRaWAN\nmodel to consider the performance of steady-state ADR-enabled LoRaWAN. We\nderive outage expressions and an optimization procedure to maximize the number\nof users under reliability constraints. Results show that power allocation\nreduces interference and improves network capacity while reducing average\npower.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 09:41:44 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Hoeller", "Arliones", ""], ["Souza", "Richard Demo", ""], ["Montejo-S\u00e1nchez", "Samuel", ""], ["Alves", "Hirley", ""]]}, {"id": "2002.08119", "submitter": "Jia Yan", "authors": "Jia Yan, Suzhi Bi, and Ying-Jun Angela Zhang", "title": "Offloading and Resource Allocation with General Task Graph in Mobile\n  Edge Computing: A Deep Reinforcement Learning Approach", "comments": "This paper is under minor revision with IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a mobile-edge computing system, where an access\npoint assists a mobile device (MD) to execute an application consisting of\nmultiple tasks following a general task call graph. The objective is to jointly\ndetermine the offloading decision of each task and the resource allocation\nunder time-varying wireless fading channels and stochastic edge computing\ncapability, so that the energy-time cost (ETC) of the MD is minimized. Solving\nthe problem is particularly hard due to the combinatorial offloading decisions\nand the strong coupling among task executions under the general dependency\nmodel. Conventional numerical optimization methods are inefficient to solve\nsuch a problem, especially when the problem size is large. To address the\nissue, we propose a deep reinforcement learning (DRL) framework based on the\nactor-critic learning structure. In particular, the actor network utilizes a\nDNN to learn the optimal mapping from the input states to the binary offloading\ndecision of each task. Meanwhile, by analyzing the structure of the optimal\nsolution, we derive a low-complexity algorithm for the critic network to\nquickly evaluate the ETC performance of the offloading decisions output by the\nactor network. With the low-complexity critic network, we can quickly select\nthe best offloading action and subsequently store the state-action pair in an\nexperience replay memory as the training dataset to continuously improve the\naction generation DNN. To further reduce the complexity, we show that the\noptimal offloading decision exhibits an one-climb structure, which can be\nutilized to significantly reduce the search space of action generation.\nNumerical results show that for various types of task graphs, the proposed\nalgorithm achieves up to $99.1\\%$ of the optimal performance while\nsignificantly reducing the computational complexity compared to the existing\noptimization methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:42:07 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Yan", "Jia", ""], ["Bi", "Suzhi", ""], ["Zhang", "Ying-Jun Angela", ""]]}, {"id": "2002.08141", "submitter": "Avi Mohan", "authors": "Avinash Mohan, Aditya Gopalan and Anurag Kumar", "title": "Throughput Optimal Decentralized Scheduling with Single-bit State\n  Feedback for a Class of Queueing Systems", "comments": "53 pages, 18 figures, IEEE/ACM Transactions on Networking", "journal-ref": "IEEE/ACM Transactions on Networking, April 2020", "doi": "10.1109/TNET.2020.2976923", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by medium access control for resource-challenged wireless Internet\nof Things (IoT), we consider the problem of queue scheduling with reduced queue\nstate information. In particular, we consider a time-slotted scheduling model\nwith $N$ sensor nodes, with pair-wise dependence, such that Nodes $i$ and $i +\n1,~0 < i < N$ cannot transmit together. We develop new throughput-optimal\nscheduling policies requiring only the empty-nonempty state of each queue that\nwe term Queue Nonemptiness-Based (QNB) policies. We propose a Policy Splicing\ntechnique to combine scheduling policies for small networks in order to\nconstruct throughput-optimal policies for larger networks, some of which also\naim for low delay. For $N = 3,$ there exists a sum-queue length optimal QNB\nscheduling policy. We show, however, that for $N > 4,$ there is no QNB policy\nthat is sum-queue length optimal over all arrival rate vectors in the capacity\nregion.\n  We then extend our results to a more general class of interference\nconstraints that we call cluster-of-cliques (CoC) conflict graphs. We consider\ntwo types of CoC networks, namely, Linear Arrays of Cliques (LAoC) and\nStar-of-Cliques (SoC) networks. We develop QNB policies for these classes of\nnetworks, study their stability and delay properties, and propose and analyze\ntechniques to reduce the amount of state information to be disseminated across\nthe network for scheduling. In the SoC setting, we propose a throughput-optimal\npolicy that only uses information that nodes in the network can glean by\nsensing activity (or lack thereof) on the channel. Our throughput-optimality\nresults rely on two new arguments: a Lyapunov drift lemma specially adapted to\npolicies that are queue length-agnostic, and a priority queueing analysis for\nshowing strong stability.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 12:48:20 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Mohan", "Avinash", ""], ["Gopalan", "Aditya", ""], ["Kumar", "Anurag", ""]]}, {"id": "2002.08256", "submitter": "Arliones Stevert Hoeller Junior", "authors": "Arliones Hoeller, Jean Sant'Ana, Juho Markkula, Konstantin Mikhaylov,\n  Richard Souza, Hirley Alves", "title": "Beyond 5G Low-Power Wide-Area Networks: A LoRaWAN Suitability Study", "comments": "5 pages, 4 figures, accepted for presentation at 6G Wireless Summit\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deliver a discussion regarding the role of Low-Power\nWide-Area Networks (LPWAN) in the cellular Internet-of-Things (IoT)\ninfrastructure to support massive Machine-Type Communications (mMTC) in\nnext-generation wireless systems beyond 5G. We commence by presenting a\nperformance analysis of current LPWAN systems, specifically LoRaWAN, in terms\nof coverage and throughput. The results obtained using analytic methods and\nnetwork simulations are combined in the paper for getting a more comprehensive\nvision. Next, we identify possible performance bottlenecks, speculate on the\ncharacteristics of coming IoT applications, and seek to identify potential\nenhancements to the current technologies that may overcome the identified\nshortcomings.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:03:28 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Hoeller", "Arliones", ""], ["Sant'Ana", "Jean", ""], ["Markkula", "Juho", ""], ["Mikhaylov", "Konstantin", ""], ["Souza", "Richard", ""], ["Alves", "Hirley", ""]]}, {"id": "2002.08419", "submitter": "Hongyu Xiang", "authors": "Hongyu Xiang, Mugen Peng, Yaohua Sun, and Shi Yan", "title": "Mode Selection and Resource Allocation in Sliced Fog Radio Access\n  Networks: A Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mode selection and resource allocation in fog radio access networks\n(F-RANs) have been advocated as key techniques to improve spectral and energy\nefficiency. In this paper, we investigate the joint optimization of mode\nselection and resource allocation in uplink F-RANs, where both of the\ntraditional user equipments (UEs) and fog UEs are served by constructed network\nslice instances. The concerned optimization is formulated as a mixed-integer\nprogramming problem, and both the orthogonal and multiplexed subchannel\nallocation strategies are proposed to guarantee the slice isolation. Motivated\nby the development of machine learning, two reinforcement learning based\nalgorithms are developed to solve the original high complexity problem under\ntraditional and fog UEs' specific performance requirements. The basic idea of\nthe proposals is to generate a good mode selection policy according to the\nimmediate reward fed back by an environment. Simulation results validate the\nbenefits of our proposed algorithms and show that a tradeoff between system\npower consumption and queue delay can be achieved.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 10:51:06 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Xiang", "Hongyu", ""], ["Peng", "Mugen", ""], ["Sun", "Yaohua", ""], ["Yan", "Shi", ""]]}, {"id": "2002.08420", "submitter": "Abdulkadir Celik", "authors": "Abdulkadir Celik, Nasir Saeed, Basem Shihada, Tareq Y. Al-Naffouri,\n  and Mohamed-Slim Alouini", "title": "Opportunistic Routing for Opto-Acoustic Internet of Underwater Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of underwater things (IoUT) is a technological revolution that could\nmark a new era for scientific, industrial, and military underwater\napplications. To mitigate the hostile underwater channel characteristics, this\npaper hybridizes underwater acoustic and optical wireless communications to\nachieve a ubiquitous control and high-speed low-latency networking performance,\nrespectively. Since underwater optical wireless communications (UOWC) suffers\nfrom limited range, it requires effective multi-hop routing solutions. In this\nregard, we propose a Sector-based Opportunistic Routing (SectOR) protocol.\nUnlike the traditional routing (TR) techniques which unicast packets to a\nunique relay, opportunistic routing (OR) targets a set of candidate relays by\nleveraging the broadcast nature of the UOWC channel. OR improves the packet\ndelivery ratio as the likelihood of having at least one successful packet\nreception is much higher than that in conventional unicast routing. Contingent\nupon the performance characterization of a single-hop link, we obtain a variety\nof local and global metrics to evaluate the fitness of a candidate set (CS) and\nprioritize the members of a CS. Since rate-error and range-beamwidth tradeoffs\nyield different candidate set diversities, we develop a candidate filtering and\nsearching algorithm to find the optimal sector-shaped coverage region by\nscanning the feasible search space. Moreover, a hybrid acoustic/optic\ncoordination mechanism is considered to avoid duplicate transmission of the\nrelays. Numerical results show that SectOR protocol can perform even better\nthan an optimal unicast routing protocol in well-connected UOWNs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:05:17 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Celik", "Abdulkadir", ""], ["Saeed", "Nasir", ""], ["Shihada", "Basem", ""], ["Al-Naffouri", "Tareq Y.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2002.08488", "submitter": "Konstantinos Dovelos", "authors": "Konstantinos Dovelos, Michail Matthaiou, Hien Quoc Ngo, and Boris\n  Bellalta", "title": "Massive MIMO with Multi-Antenna Users under Jointly Correlated Ricean\n  Fading", "comments": "Submitted to ICC 2020", "journal-ref": "ICC 2020 - 2020 IEEE International Conference on Communications\n  (ICC)", "doi": "10.1109/ICC40277.2020.9148706", "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the uplink performance of massive multiple-input multiple-output\n(MIMO) when users are equipped with multiple antennas. To this end, we consider\na generalized channel model that accounts for line-of-sight propagation and\nspatially correlated multipath fading. Most importantly, we employ the\nWeichselberger correlation model, which has been shown to alleviate the\ndeficiencies of the popular Kronecker model. The main contribution of this\npaper is a rigorous closed-form expression for the uplink spectral efficiency\nusing maximum-ratio combining and minimum mean square error channel estimation.\nOur result is a non-trivial generalization of previous results on massive MIMO\nwith spatially correlated channels, thereby enabling us to have suitable\ndesigns for future massive MIMO systems. Numerical simulations corroborate our\nanalysis and provide useful insights on how different propagation conditions\naffect system performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 22:53:26 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Dovelos", "Konstantinos", ""], ["Matthaiou", "Michail", ""], ["Ngo", "Hien Quoc", ""], ["Bellalta", "Boris", ""]]}, {"id": "2002.08735", "submitter": "Khaled Abdelfadeel", "authors": "Khaled Abdelfadeel, Tom Farrell, David McDonald, Dirk Pesch", "title": "How to make Firmware Updates over LoRaWAN Possible", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded software management requirements due to concerns about security\nvulnerabilities or for feature updates in the Internet of Things (IoT)\ndeployments have raised the need for Firmware Update Over The Air (FUOTA). With\nFUOTA's support, security updates, new functionalities, and optimization\npatches can be deployed with little human intervention to embedded devices over\ntheir lifetime. However, supporting FUTOA over one of the most promising IoT\nnetworking technologies, LoRaWAN, is not a straightforward task due to\nLoRaWAN's limitations that do not provide for data bulk transfer such as a\nfirmware image. Therefore, the LoRa Alliance has proposed new specifications to\nsupport multicast, fragmentation, and clock synchronization, which are\nessential features to enable efficient FUOTA in LoRaWAN. In this paper, we\nreview these new specifications and evaluate the FUOTA process in order to\nquantify the impact of the different FUOTA parameters in terms of the firmware\nupdate time, the device's energy consumption, and the firmware update\nefficiency, showing different trade-offs among the parameters. For this, we\ndeveloped FUOTASim, a simulation tool that allows us to determine the best\nFUOTA parameters.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:58:28 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Abdelfadeel", "Khaled", ""], ["Farrell", "Tom", ""], ["McDonald", "David", ""], ["Pesch", "Dirk", ""]]}, {"id": "2002.08736", "submitter": "Yan Shi", "authors": "Shenzhi Chen, Jinling Hu, Yan Shi, Li Zhao, and Wen Li", "title": "A Vision of C-V2X: Technologies, Field Testing and Challenges with\n  Chinese Development", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2020.2974823", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  C-V2X (Cellular Vehicle-to-Everything) is the important enabling technology\nfor autonomous driving and intelligent transportation systems. It evolves from\nLTE (Long Term Evolution)-V2X to NR (New Radio)-V2X, which will coexist and be\ncomplementary with each other to provide low latency, high reliability, and\nhigh throughput communications for various C-V2X applications. In this article,\na vision of C-V2X is presented. The requirements of the basic road safety and\nadvanced applications, the architecture, the key technologies, and the\nstandards of C-V2X are introduced, highlighting the technical evolution path\nfrom LTE-V2X to NR-V2X. Especially, based on the continual and active promotion\nof C-V2X research, field testing and development in China, the related works\nand progresses are also presented. Lastly, the trends of C-V2X applications\nwith technical challenges are envisioned.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:00:59 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Chen", "Shenzhi", ""], ["Hu", "Jinling", ""], ["Shi", "Yan", ""], ["Zhao", "Li", ""], ["Li", "Wen", ""]]}, {"id": "2002.08768", "submitter": "Howard H. Yang", "authors": "Howard H. Yang, Ahmed Arafa, Tony Q. S. Quek, H. Vincent Poor", "title": "Optimizing Information Freshness in Wireless Networks: A Stochastic\n  Geometry Approach", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.09674", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of information freshness in wireless networks has usually been\nperformed based on queueing analysis that captures only the temporal traffic\ndynamics associated with the transmitters and receivers. However, the effect of\ninterference, which is mainly dominated by the interferers' geographic\nlocations, is not well understood. In this paper, we leverage a spatiotemporal\nmodel, which allows one to characterize the age of information (AoI) from a\njoint queueing-geometry perspective, for the design of a decentralized\nscheduling policy that exploits local observation to make transmission\ndecisions that minimize the AoI. To quantify the performance, we also derive\naccurate and tractable expressions for the peak AoI. Numerical results reveal\nthat: i) the packet arrival rate directly affects the service process due to\nqueueing interactions, ii) the proposed scheme can adapt to traffic variations\nand largely reduce the peak AoI, and iii) the proposed scheme scales well as\nthe network grows in size. This is done by adaptively adjusting the radio\naccess probability at each transmitter to the change of the ambient\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:48:51 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Yang", "Howard H.", ""], ["Arafa", "Ahmed", ""], ["Quek", "Tony Q. S.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2002.08798", "submitter": "Antzela Kosta", "authors": "Antzela Kosta, Nikolaos Pappas, Anthony Ephremides, and Vangelis\n  Angelakis", "title": "The Age of Information in a Discrete Time Queue: Stationary Distribution\n  and Non-linear Age Mean Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate information freshness in a status update\ncommunication system consisting of a source-destination link. Initially, we\nstudy the properties of a sample path of the age of information (AoI) process\nat the destination. We obtain a general formula of the stationary distribution\nof the AoI, under the assumption of ergodicity. We relate this result to a\ndiscrete time queueing system and provide a general expression of the\ngenerating function of AoI in relation with the system time and the peak age of\ninformation (PAoI) metric. Furthermore, we consider three different\nsingle-server system models and we obtain closed-form expressions of the\ngenerating functions and the stationary distributions of the AoI and the PAoI.\nThe first model is a first-come-first-served (FCFS) queue, the second model is\na preemptive last-come-first-served (LCFS) queue, and the last model is a\nbufferless system with packet dropping. We build upon these results to provide\na methodology for analyzing general non-linear age functions for this type of\nsystems, using representations of functions as power series.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:22:05 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 20:34:45 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Kosta", "Antzela", ""], ["Pappas", "Nikolaos", ""], ["Ephremides", "Anthony", ""], ["Angelakis", "Vangelis", ""]]}, {"id": "2002.08805", "submitter": "Jian Li", "authors": "Qilin Fan, Xiuhua Li, Jian Li, Qiang He, Kai Wang, Junhao Wen", "title": "PA-Cache: Evolving Learning-Based Popularity-Aware Content Caching in\n  Edge Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As ubiquitous and personalized services are growing boomingly, an\nincreasingly large amount of traffic is generated over the network by massive\nmobile devices. As a result, content caching is gradually extending to network\nedges to provide low-latency services, improve quality of service, and reduce\nredundant data traffic. Compared to the conventional content delivery networks,\ncaches in edge networks with smaller sizes usually have to accommodate more\nbursty requests. In this paper, we propose an evolving learning-based content\ncaching policy, named PA-Cache in edge networks. It adaptively learns\ntime-varying content popularity and determines which contents should be\nreplaced when the cache is full. Unlike conventional deep neural networks\n(DNNs), which learn a fine-tuned but possibly outdated or biased prediction\nmodel using the entire training dataset with high computational complexity,\nPA-Cache weighs a large set of content features and trains the multi-layer\nrecurrent neural network from shallow to deeper when more requests arrive over\ntime. We extensively evaluate the performance of our proposed PA-Cache on\nreal-world traces from a large online video-on-demand service provider. \\rb{The\nresults show that PA-Cache outperforms existing popular caching algorithms and\napproximates the optimal algorithm with only a 3.8\\% performance gap when the\ncache percentage is 1.0\\%}. PA-Cache also significantly reduces the\ncomputational cost compared to conventional DNN-based approaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:38:01 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 02:54:51 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Fan", "Qilin", ""], ["Li", "Xiuhua", ""], ["Li", "Jian", ""], ["He", "Qiang", ""], ["Wang", "Kai", ""], ["Wen", "Junhao", ""]]}, {"id": "2002.08833", "submitter": "Sheng Zhou", "authors": "Yuxuan Sun, Sheng Zhou, Zhisheng Niu", "title": "Distributed Task Replication for Vehicular Edge Computing: Performance\n  Analysis and Learning-based Algorithm", "comments": "Submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a vehicular edge computing (VEC) system, vehicles can share their surplus\ncomputation resources to provide cloud computing services. The highly dynamic\nenvironment of the vehicular network makes it challenging to guarantee the task\noffloading delay. To this end, we introduce task replication to the VEC system,\nwhere the replicas of a task are offloaded to multiple vehicles at the same\ntime, and the task is completed upon the first response among replicas. First,\nthe impact of the number of task replicas on the offloading delay is\ncharacterized, and the optimal number of task replicas is approximated in\nclosed-form. Based on the analytical result, we design a learning-based task\nreplication algorithm (LTRA) with combinatorial multi-armed bandit theory,\nwhich works in a distributed manner and can automatically adapt itself to the\ndynamics of the VEC system. A realistic traffic scenario is used to evaluate\nthe delay performance of the proposed algorithm. Results show that, under our\nsimulation settings, LTRA with an optimized number of task replicas can reduce\nthe average offloading delay by over 30% compared to the benchmark without task\nreplication, and at the same time can improve the task completion ratio from\n97% to 99.6%.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:16:47 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Sun", "Yuxuan", ""], ["Zhou", "Sheng", ""], ["Niu", "Zhisheng", ""]]}, {"id": "2002.08932", "submitter": "Salih Safa Bacanli", "authors": "Rajarshi Haldar, Salih Safa Bacanli, Moayad Aloqaily, Adel Ben\n  Mnaouer, Damla Turgut", "title": "Cluster Aware Mobility Encounter Dataset Enlargement", "comments": "5 pages, 4 figures. In 2019 International Wireless Communications and\n  Mobile Computing Conference (IWCMC), June 2019", "journal-ref": null, "doi": "10.1109/IWCMC.2019.8766720", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent emerging fields in data processing and manipulation has\nfacilitated the need for synthetic data generation. This is also valid for\nmobility encounter dataset generation. Synthetic data generation might be\nuseful to run research-based simulations and also create mobility encounter\nmodels. Our approach in this paper is to generate a larger dataset by using a\ngiven dataset which includes the clusters of people. Based on the cluster\ninformation, we created a framework. Using this framework, we can generate a\nsimilar dataset that is statistically similar to the input dataset. We have\ncompared the statistical results of our approach with the real dataset and an\nencounter mobility model generation technique in the literature. The results\nshowed that the created datasets have similar statistical structure with the\ngiven dataset.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:30:32 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Haldar", "Rajarshi", ""], ["Bacanli", "Salih Safa", ""], ["Aloqaily", "Moayad", ""], ["Mnaouer", "Adel Ben", ""], ["Turgut", "Damla", ""]]}, {"id": "2002.08984", "submitter": "Abulfazl Zakeri", "authors": "Abulfazl Zakeri, Narges Gholipoor, Mohsen Tajallifar, Sina Ebrahimi,\n  Mohammad Reza Javan, Nader Mokari, Ahmad Reza Sharafat", "title": "E2E Migration Strategies Towards 5G: Long-term Migration Plan and\n  Evolution Roadmap", "comments": "Migration, 5G, evolution, roadmap, option, path, 3 Figure, 4Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After freezing the first phase of the fifth generation of wireless networks\n(5G) standardization, it finally goes live now and the rollout of the\ncommercial launch (most in fixed 5G broadband services) and migration has been\nstarted. However, some challenges are arising in the deployment, integration of\neach technology, and the interoperability in the network of the communication\nservice providers (CSPs). At the same time, the evolution of 5G is not clear\nand many questions arise such as whether 5G has long-term evolution or when 5G\nwill change to a next-generation one. This paper provides long-term migration\noptions and paths towards 5G considering many key factors such as the cost,\nlocal/national data traffic, marketing, and the standardization trends in the\nradio access network (RAN), the transport network (TN), the core network (CN),\nand E2E network. Moreover, we outline some 5G evolution road maps emphasizing\non the technologies, standards, and service time lines. The proposed migration\npaths can be the answer to some CSPs concerns about how to do long-term\nmigration to 5G and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:35:12 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zakeri", "Abulfazl", ""], ["Gholipoor", "Narges", ""], ["Tajallifar", "Mohsen", ""], ["Ebrahimi", "Sina", ""], ["Javan", "Mohammad Reza", ""], ["Mokari", "Nader", ""], ["Sharafat", "Ahmad Reza", ""]]}, {"id": "2002.08987", "submitter": "Muhammad Shahbaz", "authors": "Tushar Swamy, Alexander Rucker, Muhammad Shahbaz, and Kunle Olukotun", "title": "Taurus: An Intelligent Data Plane", "comments": "12 pages, 13 figures, and 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging applications -- cloud computing, the internet of things, and\naugmented/virtual reality -- need responsive, available, secure, ubiquitous,\nand scalable datacenter networks. Network management currently uses simple,\nper-packet, data-plane heuristics (e.g., ECMP and sketches) under an\nintelligent, millisecond-latency control plane that runs data-driven\nperformance and security policies. However, to meet users' quality-of-service\nexpectations in a modern data center, networks must operate intelligently at\nline rate. In this paper, we present Taurus, an intelligent data plane capable\nof machine-learning inference at line rate. Taurus adds custom hardware based\non a map-reduce abstraction to programmable network devices, such as switches\nand NICs; this new hardware uses pipelined and SIMD parallelism for fast\ninference. Our evaluation of a Taurus-enabled switch ASIC -- supporting several\nreal-world benchmarks -- shows that Taurus operates three orders of magnitude\nfaster than a server-based control plane, while increasing area by 24% and\nlatency, on average, by 178 ns. On the long road to self-driving networks,\nTaurus is the equivalent of adaptive cruise control: deterministic rules steer\nflows, while machine learning tunes performance and heightens security.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:18:36 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Swamy", "Tushar", ""], ["Rucker", "Alexander", ""], ["Shahbaz", "Muhammad", ""], ["Olukotun", "Kunle", ""]]}, {"id": "2002.09055", "submitter": "Austin Hounsel", "authors": "Austin Hounsel, Paul Schmitt, Kevin Borgolte, Nick Feamster", "title": "Designing for Tussle in (Encrypted) DNS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent concerns over the privacy implications of the Domain Name System (DNS)\nhave led to encrypting DNS queries and responses through protocols like\nDNS-over-HTTPS (DoH) and DNS-over-TLS (DoT). While the trend towards encryption\nis a positive development, the resulting centralization of the DNS has fomented\ntussles involving ISPs, browser and device vendors, content delivery networks,\nand users. Current deployment trends, should they continue, result in dynamics\nthat will increase barriers to entry to competition and threaten consumer\nprotection. This development makes it necessary for us to re-think name\nresolution to allow tussles to play out within the context of the design of the\nInternet architecture. This paper articulates several current DNS tussles and\noffers principles to guide system design and implementation such that all\nstakeholders in the space could participate. We then explore how a refactored\nclient DNS mechanism can open up new possibilities for de-centralized name\nresolution, preserving the benefits of encrypted DNS while satisfying other\narchitectural desiderata, including performance, resilience, and privacy.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:54:00 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 00:00:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hounsel", "Austin", ""], ["Schmitt", "Paul", ""], ["Borgolte", "Kevin", ""], ["Feamster", "Nick", ""]]}, {"id": "2002.09098", "submitter": "Yizhe Zhao", "authors": "Yizhe Zhao and Jie Hu and Duohua Wang and Kun Yang", "title": "H-AP Deployment for Joint Wireless Information and Energy Transfer in\n  Smart Cities", "comments": "13pages, 11figures", "journal-ref": "IEEE Transactions on Vehicular Technology, 67 (2018) 7485 - 7496", "doi": "10.1109/TVT.2018.2821978", "report-no": null, "categories": "eess.SY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wireless communication being more various in the future, it's\nbecoming challenging to prolong the lifetime of many battery powered devices,\nsince frequently replacing their batteries is a cumbersome job. An hybrid\naccess point (H-AP) is capable of simultaneously operating wireless information\ntransfer (WIT) and wireless energy transfer (WET) by exploiting the radio\nfrequency (RF) signals. By jointly considering both the mobility of the user\nand the popularity of the sites, we focus on the design of the H-AP's\ndeployment scheme. Specifically, a mobility model of the grid based city\nstreets is exploited for characterising the users' movements. Based on this\nmobility model, the impact of the deployment site's popularity on the WIT and\nWET efficiencies is firstly analysed. Then, an H-AP deployment scheme for\nstriking a balance between the WIT and the WET efficiencies is proposed, which\nis regarded as the B-deployment scheme. The simulation results demonstrate that\nthe B-deployment scheme is more flexible for satisfying diverse requirement of\nthe WIT and WET efficiencies.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:35:59 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhao", "Yizhe", ""], ["Hu", "Jie", ""], ["Wang", "Duohua", ""], ["Yang", "Kun", ""]]}, {"id": "2002.09179", "submitter": "Mattia Lecci", "authors": "Mattia Lecci and Paolo Testolina and Marco Giordani and Michele Polese\n  and Tanguy Ropitault and Camillo Gentile and Neeraj Varshney and Anuraag Bodi\n  and Michele Zorzi", "title": "Simplified Ray Tracing for the Millimeter Wave Channel: A Performance\n  Evaluation", "comments": "6 pages, 6 figures, 1 table. This paper has been accepted for\n  presentation at ITA 2020. (c) 2020 IEEE. Please cite it as: M. Lecci, P.\n  Testolina, M. Giordani, M. Polese, T. Ropitault, C. Gentile, N. Varshney, A.\n  Bodi, M. Zorzi, \"Simplified Ray Tracing for the Millimeter Wave Channel: A\n  Performance Evaluation,\" Information Theory and Applications Workshop (ITA),\n  San Diego, US, 2020", "journal-ref": null, "doi": "10.1109/ITA50056.2020.9244950", "report-no": null, "categories": "eess.SP cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter-wave (mmWave) communication is one of the cornerstone innovations\nof fifth-generation (5G) wireless networks, thanks to the massive bandwidth\navailable in these frequency bands. To correctly assess the performance of such\nsystems, however, it is essential to have reliable channel models, based on a\ndeep understanding of the propagation characteristics of the mmWave signal. In\nthis respect, ray tracers can provide high accuracy, at the expense of a\nsignificant computational complexity, which limits the scalability of\nsimulations. To address this issue, in this paper we present possible\nsimplifications that can reduce the complexity of ray tracing in the mmWave\nenvironment, without significantly affecting the accuracy of the model. We\nevaluate the effect of such simplifications on link-level metrics, testing\ndifferent configuration parameters and propagation scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 08:32:07 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Lecci", "Mattia", ""], ["Testolina", "Paolo", ""], ["Giordani", "Marco", ""], ["Polese", "Michele", ""], ["Ropitault", "Tanguy", ""], ["Gentile", "Camillo", ""], ["Varshney", "Neeraj", ""], ["Bodi", "Anuraag", ""], ["Zorzi", "Michele", ""]]}, {"id": "2002.09194", "submitter": "Peng Yang", "authors": "Peng Yang, Xing Xi, Yaru Fu, Tony Q. S. Quek, Xianbin Cao, Dapeng Wu", "title": "Multicast eMBB and Bursty URLLC Service Multiplexing in a CoMP-Enabled\n  RAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with slicing a radio access network (RAN) for\nsimultaneously serving two typical 5G and beyond use cases, i.e., enhanced\nmobile broadband (eMBB) and ultra-reliable and low latency communications\n(URLLC). Although many researches have been conducted to tackle this issue, few\nof them have considered the impact of bursty URLLC. The bursty characteristic\nof URLLC traffic may significantly increase the difficulty of RAN slicing on\nthe aspect of ensuring a ultra-low packet blocking probability. To reduce the\npacket blocking probability, we re-visit the structure of physical resource\nblocks (PRBs) orchestrated for bursty URLLC traffic in the time-frequency plane\nbased on our theoretical results. Meanwhile, we formulate the problem of\nslicing a RAN enabling coordinated multi-point (CoMP) transmissions for\nmulticast eMBB and bursty URLLC service multiplexing as a multi-timescale\noptimization problem. The goal of this problem is to maximize multicast eMBB\nand bursty URLLC slice utilities, subject to physical resource constraints. To\nmitigate this thorny multi-timescale problem, we transform it into multiple\nsingle timescale problems by exploring the fundamental principle of a sample\naverage approximation (SAA) technique. Next, an iterative algorithm with\nprovable performance guarantees is developed to obtain solutions to these\nsingle timescale problems and aggregate the obtained solutions into those of\nthe multi-timescale problem. We also design a prototype for the CoMP-enabled\nRAN slicing system incorporating with multicast eMBB and bursty URLLC traffic\nand compare the proposed iterative algorithm with the state-of-the-art\nalgorithm to verify the effectiveness of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:23:48 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Yang", "Peng", ""], ["Xi", "Xing", ""], ["Fu", "Yaru", ""], ["Quek", "Tony Q. S.", ""], ["Cao", "Xianbin", ""], ["Wu", "Dapeng", ""]]}, {"id": "2002.09341", "submitter": "Tommaso Zugno", "authors": "Tommaso Zugno, Michele Polese, Natale Patriciello, Biljana Bojovi\\'c,\n  Sandra Lagen and Michele Zorzi", "title": "Implementation of A Spatial Channel Model for ns-3", "comments": "This paper has been accepted for presentation at the 2020 Workshop on\n  ns-3 (WNS3 2020), June 17--18, 2020, Gaithersburg, MD, USA", "journal-ref": null, "doi": "10.1145/3389400.3389401", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next generation of wireless networks will feature a more flexible radio\naccess design, integrating multiple new technological solutions (e.g., massive\nMultiple-Input Multiple-Output (MIMO), millimeter waves) to satisfy different\nverticals and use cases. The performance evaluation of these networks will\nrequire more complex models to represent the interactions of different\ncomponents of the networks accurately. For example, channel models, which are\nof paramount importance to precisely characterize the behavior of such systems,\nneed to account for multi-antenna systems and new frequency bands. This paper\npresents the ns-3 implementation of a spatial channel model for the 0.5-100 GHz\nspectrum, following the 3GPP Technical Report 38.901. The code, designed to be\nflexible and easily extensible, is integrated in ns-3's antenna, propagation\nand spectrum models, and offers the support for the investigation of future\nwireless systems in ns-3.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:56:29 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:50:16 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zugno", "Tommaso", ""], ["Polese", "Michele", ""], ["Patriciello", "Natale", ""], ["Bojovi\u0107", "Biljana", ""], ["Lagen", "Sandra", ""], ["Zorzi", "Michele", ""]]}, {"id": "2002.09430", "submitter": "Jaafar Elmirghani", "authors": "Osama Zwaid Alsulami, Sarah O. M. Saeed, Sanaa Hamid Mohamed, T. E. H.\n  El-Gorashi, Mohammed T. Alresheedi, and Jaafar M. H. Elmirghani", "title": "Shared optical wireless cells for in-cabin aircraft links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of a wireless communication system that can support multiple users\nat high data rates inside an aircraft is a key requirement of aircraft\nmanufacturers. This paper examines the design of an on-board visible light\ncommunication (VLC) system for transmitting data on board Boeing 747-400\naircraft. The reading light unit of each seat is utilised as an optical\ntransmitter. A red, yellow, green, and blue (RYGB) laser diode (LD) is used in\neach reading light unit for transmitting data. An angle diversity receiver\n(ADR), which is an optical receiver that is composed of four branches (in this\nwork), is evaluated. The signal-to-interference-plus-noise ratio (SINR) and\ndata rate are determined. Three scenarios have been examined where, in the\nfirst scenario, one device is used, in the second scenario two devices are used\nand in the third scenario three devices are used by each passenger. The\nproposed system can offer high SINRs that support high data rates for each\npassenger by using simple on-off-keying (OOK).\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:24:00 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Alsulami", "Osama Zwaid", ""], ["Saeed", "Sarah O. M.", ""], ["Mohamed", "Sanaa Hamid", ""], ["El-Gorashi", "T. E. H.", ""], ["Alresheedi", "Mohammed T.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2002.09623", "submitter": "Tao Cao", "authors": "Yuan Zhou, Tao Cao, and Wei Xiang", "title": "Anypath Routing Protocol Design via Q-Learning for Underwater Sensor\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a promising technology in the Internet of Underwater Things, underwater\nsensor networks have drawn a widespread attention from both academia and\nindustry. However, designing a routing protocol for underwater sensor networks\nis a great challenge due to high energy consumption and large latency in the\nunderwater environment. This paper proposes a Q-learning-based\nlocalization-free anypath routing (QLFR) protocol to prolong the lifetime as\nwell as reduce the end-to-end delay for underwater sensor networks. Aiming at\noptimal routing policies, the Q-value is calculated by jointly considering the\nresidual energy and depth information of sensor nodes throughout the routing\nprocess. More specifically, we define two reward functions (i.e., depth-related\nand energy-related rewards) for Q-learning with the objective of reducing\nlatency and extending network lifetime. In addition, a new holding time\nmechanism for packet forwarding is designed according to the priority of\nforwarding candidate nodes. Furthermore, a mathematical analysis is presented\nto analyze the performance of the proposed routing protocol. Extensive\nsimulation results demonstrate the superiority performance of the proposed\nrouting protocol in terms of the end-to-end delay and the network lifetime.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 04:28:00 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhou", "Yuan", ""], ["Cao", "Tao", ""], ["Xiang", "Wei", ""]]}, {"id": "2002.09805", "submitter": "Bo Zhou", "authors": "Bo Zhou, Walid Saad, Mehdi Bennis, Petar Popovski", "title": "Risk-Aware Optimization of Age of Information in the Internet of Things", "comments": "6 pages. Accepted to IEEE International Conference on Communications\n  (ICC) 2020, Dublin, Ireland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimization of the expected value of age of information (AoI) is a\nrisk-neutral approach, and it thus cannot capture rare, yet critical, events\nwith potentially large AoI. In order to capture the effect of these events, in\nthis paper, the notion of conditional value-at-risk (CVaR) is proposed as an\neffective coherent risk measure that is suitable for minimization of AoI for\nreal-time IoT status updates. In the considered monitoring system, an IoT\ndevice monitors a physical process and sends the status updates to a remote\nreceiver with an updating cost. The optimal status update process is designed\nto jointly minimize the AoI at the receiver, the CVaR of the AoI at the\nreceiver, and the energy cost. This stochastic optimization problem is\nformulated as an infinite horizon discounted risk-aware Markov decision process\n(MDP), which is computationally intractable due to the time inconsistency of\nthe CVaR. By exploiting the special properties of coherent risk measures, the\nrisk-aware MDP is reduced to a standard MDP with an augmented state space, for\nwhich we derive the optimal stationary policy using dynamic programming. In\nparticular, the optimal history-dependent policy of the risk-aware MDP is shown\nto depend on the history only through the augmented system states and can be\nreadily constructed using the optimal stationary policy of the augmented MDP.\nThe proposed solution is shown to be computationally tractable and able to\nminimize the AoI in real-time IoT monitoring systems in a risk-aware manner.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 01:43:30 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 19:56:42 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Zhou", "Bo", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""], ["Popovski", "Petar", ""]]}, {"id": "2002.09825", "submitter": "Taran Lynn", "authors": "Taran Lynn, Dipak Ghosal, Nathan Hanford", "title": "Model Predictive Congestion Control for TCP Endpoints", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem in science networks and private wide area networks (WANs) is\nthat of achieving predictable data transfers of multiple concurrent flows by\nmaintaining specific pacing rates for each. We address this problem by\ndeveloping a control algorithm based on concepts from model predictive control\n(MPC) to produce flows with smooth pacing rates and round trip times (RTTs). In\nthe proposed approach, we model the bottleneck link as a queue and derive a\nmodel relating the pacing rate and the RTT. A MPC based control algorithm based\non this model is shown to avoid the extreme window (which translates to rate)\nreduction that exists in current control algorithms when facing network\ncongestion. We have implemented our algorithm as a Linux kernel module. Through\nsimulation and experimental analysis, we show that our algorithm achieves the\ngoals of a low standard deviation of RTT and pacing rate, even when the\nbottleneck link is fully utilized. In the case of multiple flows, we can assign\ndifferent rates to each flow and as long as the sum of rates is less than\nbottleneck rate, they can maintain their assigned pacing rate with low standard\ndeviation. This is achieved even when the flows have different RTTs.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 04:12:31 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lynn", "Taran", ""], ["Ghosal", "Dipak", ""], ["Hanford", "Nathan", ""]]}, {"id": "2002.09832", "submitter": "Lior Rokach", "authors": "Sigal Shaked, Amos Zamir, Roman Vainshtein, Moshe Unger, Lior Rokach,\n  Rami Puzis, Bracha Shapira", "title": "Sequence Preserving Network Traffic Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Network Traffic Generator (NTG), a framework for perturbing\nrecorded network traffic with the purpose of generating diverse but realistic\nbackground traffic for network simulation and what-if analysis in enterprise\nenvironments. The framework preserves many characteristics of the original\ntraffic recorded in an enterprise, as well as sequences of network activities.\nUsing the proposed framework, the original traffic flows are profiled using 200\ncross-protocol features. The traffic is aggregated into flows of packets\nbetween IP pairs and clustered into groups of similar network activities.\nSequences of network activities are then extracted. We examined two methods for\nextracting sequences of activities: a Markov model and a neural language model.\nFinally, new traffic is generated using the extracted model. We developed a\nprototype of the framework and conducted extensive experiments based on two\nreal network traffic collections. Hypothesis testing was used to examine the\ndifference between the distribution of original and generated features, showing\nthat 30-100\\% of the extracted features were preserved. Small differences\nbetween n-gram perplexities in sequences of network activities in the original\nand generated traffic, indicate that sequences of network activities were well\npreserved.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 05:17:37 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shaked", "Sigal", ""], ["Zamir", "Amos", ""], ["Vainshtein", "Roman", ""], ["Unger", "Moshe", ""], ["Rokach", "Lior", ""], ["Puzis", "Rami", ""], ["Shapira", "Bracha", ""]]}, {"id": "2002.10242", "submitter": "Zhiyuan Jiang", "authors": "Fei Peng, Zhiyuan Jiang, Shunqing Zhang, Shugong Xu", "title": "Age of Information Optimized MAC in V2X Sidelink via Piggyback-Based\n  Collaboration", "comments": "Submitted to IEEE TWC for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time status update in future vehicular networks is vital to enable\ncontrol-level cooperative autonomous driving. Cellular Vehicle-to-Everything\n(C-V2X), as one of the most promising vehicular wireless technologies, adopts a\nSemi-Persistent Scheduling (SPS) based Medium-Access-Control (MAC) layer\nprotocol for its sidelink communications. Despite the recent and ongoing\nefforts to optimize SPS, very few work has considered the status update\nperformance of SPS. In this paper, Age of Information (AoI) is first leveraged\nto evaluate the MAC layer performance of C-V2X sidelink. Critical issues of\nSPS, i.e., persistent packet collisions and Half-Duplex (HD) effects, are\nidentified to hinder its AoI performance. Therefore, a piggyback-based\ncollaboration method is proposed accordingly, whereby vehicles collaborate to\ninform each other of potential collisions and collectively afford HD errors,\nwhile entailing only a small signaling overhead. Closed-form AoI performance is\nderived for the proposed scheme, optimal configurations for key parameters are\nhence calculated, and the convergence property is proved for decentralized\nimplementation. Simulation results show that compared with the standardized SPS\nand its state-of-the-art enhancement schemes, the proposed scheme shows\nsignificantly better performance, not only in terms of AoI, but also of\nconventional metrics such as transmission reliability.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:43:43 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 12:13:46 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Peng", "Fei", ""], ["Jiang", "Zhiyuan", ""], ["Zhang", "Shunqing", ""], ["Xu", "Shugong", ""]]}, {"id": "2002.10258", "submitter": "Suzhi Bi", "authors": "Yuegui Chen, Suzhi Bi, Xian Li, Xiaohui Lin, and Hui Wang", "title": "Computation Rate Maximization in Wireless Powered MEC with Spread\n  Spectrum Multiple Access", "comments": "The paper has been accepted for publication by Proc. IEEE ITOEC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of mobile edge computing (MEC) and wireless power transfer\n(WPT) technologies has recently emerged as an effective solution for extending\nbattery life and increasing the computing power of wireless devices. In this\npaper, we study the resource allocation problem of a multi-user wireless\npowered MEC system, where the users share the wireless channel via direct\nsequence code division multiple access (DS-CDMA). In particular, we are\ninterested in jointly optimizing the task offloading decisions and resource\nallocation, to maximize the weighted sum computation rate of all the users in\nthe network. The optimization problem is formulated as a mixed integer\nnon-linear programming (MINLP). For a given offloading user set, we implement\nan efficient Fractional Programming (FP) approach to mitigate the multi-user\ninterference in the uplink task offloading. On top of that, we then propose a\nStochastic Local Search algorithm to optimize the offloading decisions.\nSimulation results show that the proposed method can effectively enhance the\ncomputing performance of a wireless powered MEC with spread spectrum multiple\naccess compared to other representative benchmark methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:50:57 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chen", "Yuegui", ""], ["Bi", "Suzhi", ""], ["Li", "Xian", ""], ["Lin", "Xiaohui", ""], ["Wang", "Hui", ""]]}, {"id": "2002.10347", "submitter": "Michele Polese", "authors": "Matteo Drago, Tommaso Zugno, Michele Polese, Marco Giordani, Michele\n  Zorzi", "title": "MilliCar -- An ns-3 Module for mmWave NR V2X Networks", "comments": "8 pages, 5 figures. Submitted to WNS3 2020. The code related to this\n  paper can be found at https://github.com/signetlabdei/millicar", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle-to-vehicle (V2V) communications have opened the way towards\ncooperative automated driving as a means to guarantee improved road safety and\ntraffic efficiency. The use of the millimeter wave (mmWave) spectrum for V2V,\nin particular, holds great promise since the large bandwidth available offers\nthe possibility of realizing high-data-rate connections. However, this\npotential is hindered by the significant path and penetration loss experienced\nat these frequencies. It then becomes fundamental to practically evaluate the\nfeasibility of installing mmWave-based technologies in the vehicular scenario,\nin view of the strict latency and throughput requirements of future automotive\napplications. To do so, in this paper we present MilliCar, the first ns-3\nmodule for V2V mmWave networks, which features a detailed implementation of the\nsidelink Physical (PHY) and Medium Access Control (MAC) layers based on the\nlatest NR V2X specifications, the 3GPP standard for next-generation vehicular\nsystems. Our module is open-source and enables researchers to compare possible\ndesign options and their relative performance through an end-to-end full-stack\napproach, thereby stimulating further research on this topic.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:18:34 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Drago", "Matteo", ""], ["Zugno", "Tommaso", ""], ["Polese", "Michele", ""], ["Giordani", "Marco", ""], ["Zorzi", "Michele", ""]]}, {"id": "2002.10563", "submitter": "Behzad Khamidehi", "authors": "Behzad Khamidehi and Elvino S. Sousa", "title": "A Double Q-Learning Approach for Navigation of Aerial Vehicles with\n  Connectivity Constraint", "comments": "Accepted to appear in IEEE ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the trajectory optimization problem for an aerial vehicle\nwith the mission of flying between a pair of given initial and final locations.\nThe objective is to minimize the travel time of the aerial vehicle ensuring\nthat the communication connectivity constraint required for the safe operation\nof the aerial vehicle is satisfied. We consider two different criteria for the\nconnectivity constraint of the aerial vehicle which leads to two different\nscenarios. In the first scenario, we assume that the maximum continuous time\nduration that the aerial vehicle is out of the coverage of the ground base\nstations (GBSs) is limited to a given threshold. In the second scenario,\nhowever, we assume that the total time periods that the aerial vehicle is not\ncovered by the GBSs is restricted. Based on these two constraints, we formulate\ntwo trajectory optimization problems. To solve these non-convex problems, we\nuse an approach based on the double Q-learning method which is a model-free\nreinforcement learning technique and unlike the existing algorithms does not\nneed perfect knowledge of the environment. Moreover, in contrast to the\nwell-known Q-learning technique, our double Q-learning algorithm does not\nsuffer from the over-estimation issue. Simulation results show that although\nour algorithm does not require prior information of the environment, it works\nwell and shows near optimal performance.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 22:01:56 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Khamidehi", "Behzad", ""], ["Sousa", "Elvino S.", ""]]}, {"id": "2002.10569", "submitter": "Francisco J. Escribano", "authors": "Dejan Vukobratovic and Francisco J. Escribano", "title": "Adaptive Multi-Receiver Coded Slotted ALOHA for Indoor Optical Wireless\n  Communications", "comments": "5 pages, 6 figures. Accepted for publication at IEEE Communications\n  Letters", "journal-ref": null, "doi": "10.1109/LCOMM.2020.2981070", "report-no": null, "categories": "eess.SP cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design a novel high-throughput random access scheme for an\nindoor optical wireless communication (OWC) massive Internet of Things (IoT)\nscenario. Due to the large density of both IoT devices and OWC access points\n(APs), we base the proposed scheme on multi-receiver coded slotted ALOHA. In\nthis scenario, collisions at APs are resolved by a centralized interference\ncancellation decoder that may exploit both spatial and temporal diversity. By\napplying adaptive control of each OWC AP field of view (FOV), the proposed\nsystem is able to dynamically adapt to different IoT device activation rates,\nin order to maintain a high total throughput. Using illustrative simulation\nresults, we demonstrate the design methodology and performance possibilities of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 22:15:56 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 12:11:14 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 10:31:55 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Vukobratovic", "Dejan", ""], ["Escribano", "Francisco J.", ""]]}, {"id": "2002.10577", "submitter": "Md Ferdous Pervej", "authors": "Md Ferdous Pervej and Shih-Chun Lin", "title": "Dynamic Power Allocation and Virtual Cell Formation for\n  Throughput-Optimal Vehicular Edge Networks in Highway Transportation", "comments": "Accepted for publication in ICC Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NI cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates highly mobile vehicular networks from users'\nperspectives in highway transportation. Particularly, a centralized\nsoftware-defined architecture is introduced in which centralized resources can\nbe assigned, programmed, and controlled using the anchor nodes (ANs) of the\nedge servers. Unlike the legacy networks, where a typical user is served from\nonly one access point (AP), in the proposed system model, a vehicle user is\nserved from multiple APs simultaneously. While this increases the reliability\nand the spectral efficiency of the assisted users, it also necessitates an\naccurate power allocation in all transmission time slots. As such, a joint user\nassociation and power allocation problem is formulated to achieve enhanced\nreliability and weighted user sum rate. However, the formulated problem is a\ncomplex combinatorial problem, remarkably hard to solve. Therefore,\nfine-grained machine learning algorithms are used to efficiently optimize joint\nuser associations and power allocations of the APs in a highly mobile vehicular\nnetwork. Furthermore, a distributed single-agent reinforcement learning\nalgorithm, namely SARL-MARL, is proposed which obtains nearly identical\ngenie-aided optimal solutions within a nominal number of training episodes than\nthe baseline solution. Simulation results validate that our solution\noutperforms existing schemes and can attain genie-aided optimal performances.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 22:52:26 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 01:56:23 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Pervej", "Md Ferdous", ""], ["Lin", "Shih-Chun", ""]]}, {"id": "2002.10671", "submitter": "Xu Chen", "authors": "Qiong Wu and Kaiwen He and Xu Chen", "title": "Personalized Federated Learning for Intelligent IoT Applications: A\n  Cloud-Edge based Framework", "comments": "Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) have widely penetrated in different aspects of\nmodern life and many intelligent IoT services and applications are emerging.\nRecently, federated learning is proposed to train a globally shared model by\nexploiting a massive amount of user-generated data samples on IoT devices while\npreventing data leakage. However, the device, statistical and model\nheterogeneities inherent in the complex IoT environments pose great challenges\nto traditional federated learning, making it unsuitable to be directly\ndeployed. In this article we advocate a personalized federated learning\nframework in a cloud-edge architecture for intelligent IoT applications. To\ncope with the heterogeneity issues in IoT environments, we investigate emerging\npersonalized federated learning methods which are able to mitigate the negative\neffects caused by heterogeneity in different aspects. With the power of edge\ncomputing, the requirements for fast-processing capacity and low latency in\nintelligent IoT applications can also be achieved. We finally provide a case\nstudy of IoT based human activity recognition to demonstrate the effectiveness\nof personalized federated learning for intelligent IoT applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:11:06 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 13:46:54 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 08:44:54 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wu", "Qiong", ""], ["He", "Kaiwen", ""], ["Chen", "Xu", ""]]}, {"id": "2002.10681", "submitter": "Fahri Wisnu Murti", "authors": "Fahri Wisnu Murti, Andres Garcia-Saavedra, Xavier Costa-Perez, George\n  Iosifidis", "title": "On the Optimization of Multi-Cloud Virtualized Radio Access Networks", "comments": "This preprint is to be published in Proc. of IEEE International\n  Conference on Communications (ICC) 2020", "journal-ref": "2020 IEEE International Conference on Communications (ICC)", "doi": "10.1109/ICC40277.2020.9149318", "report-no": "June 2020, pp. 1-7", "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the important and challenging problem of virtualized radio access\nnetwork (vRAN) design in its most general form. We develop an optimization\nframework that decides the number and deployment locations of central/cloud\nunits (CUs); which distributed units (DUs) each of them will serve; the\nfunctional split that each BS will implement; and the network paths for routing\nthe traffic to CUs and the network core. Our design criterion is to minimize\nthe operator's expenditures while serving the expected traffic. To this end, we\ncombine a linearization technique with a cutting-planes method in order to\nexpedite the exact solution of the formulated problem. We evaluate our\nframework using real operational networks and system measurements, and follow\nan exhaustive parameter-sensitivity analysis. We find that the benefits when\ndeparting from single-CU deployments can be as high as 30% for our networks,\nbut these gains diminish with the further addition of CUs. Our work sheds light\non the vRAN design from a new angle, highlights the importance of deploying\nmultiple CUs, and offers a rigorous framework for optimizing the costs of\nMulti-CUs vRAN.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:40:00 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 09:37:40 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Murti", "Fahri Wisnu", ""], ["Garcia-Saavedra", "Andres", ""], ["Costa-Perez", "Xavier", ""], ["Iosifidis", "George", ""]]}, {"id": "2002.10722", "submitter": "Peter Hillmann", "authors": "Peter Hillmann, Marcus Kn\\\"upfer, Tobias Guggemos, Klement Streit", "title": "CAKE: An Efficient Group Key Management for Dynamic Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid increase of mobile computing and wireless network linkage, the\ninformation exchange between connected systems and within groups increases\nheavily. Exchanging confidential information within groups via unsecured\ncommunication channels is a high security threat. In order to prevent third\nparties from accessing this data, it is essential to encrypt it. For this\npurpose, the group participants need a common group key to enable encrypted\nbroadcast messages. But efficient key management of secured group communication\nis a challenging task, if participants rely on low performance hardware and\nsmall bandwidth. For coordination and distribution, we present the modular\ngroup key management procedure CAKE that is centrally organized and meets\nstrict security requirements. The lightweight G-IKEv2 protocol in combination\nwith the key exchange concept of CAKE leads to an efficiently integrated\nsolution. The hybrid approach combines the advantages of the existing protocols\nwith the objective to reduce the computation and communication effort. It is\nshown that the procedure is more suitable for changing MANET groups than the\nexisting ones. Moreover, the exchanged group key can be used for any services\nwhich provides a wide range of applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:09:08 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Hillmann", "Peter", ""], ["Kn\u00fcpfer", "Marcus", ""], ["Guggemos", "Tobias", ""], ["Streit", "Klement", ""]]}, {"id": "2002.10731", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen", "title": "Measuring Basic Load-Balancing and Fail-Over Setups for Email Delivery\n  via DNS MX Records", "comments": null, "journal-ref": "Proceedings of the Global Internet Symposium (GIS 2020), IFIP\n  Networking Conference (Networking 2020), Paris (online), IEEE, pp. 815-820,\n  https://ieeexplore.ieee.org/document/9142814", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain name system (DNS) has long provided means to assure basic\nload-balancing and fail-over (BLBFO) for email delivery. A traditional method\nuses multiple mail exchanger (MX) records to distribute the load across\nmultiple email servers. Round-robin DNS is the common alternative to this\nMX-based balancing. Despite the classical nature of these two solutions,\nneither one has received particular attention in Internet measurement research.\nTo patch this gap, this paper examines BLBFO configurations with an active\nmeasurement study covering over 2.7 million domains from which about 2.1\nmillion have MX records. Of these MX-enabled domains, about 60% are observed to\nuse BLBFO, and MX-based balancing seems more common than round-robin DNS. Email\nhosting services offer one explanation for this adoption rate. Many domains\nseem to also prefer fine-tuned configurations instead of relying on\nrandomization assumptions. Furthermore, about 27% of the domains have at least\none exchanger with a valid IPv6 address. Finally, some misconfigurations and\nrelated oddities are visible.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:34:03 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 04:32:54 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Ruohonen", "Jukka", ""]]}, {"id": "2002.10758", "submitter": "Koya Sato", "authors": "Koya Sato, Yasuyuki Satoh, Daisuke Sugimura", "title": "Network-Density-Controlled Decentralized Parallel Stochastic Gradient\n  Descent in Wireless Systems", "comments": "6 pages, 11 figures. Accepted for presentation at IEEE ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a communication strategy for decentralized learning on\nwireless systems. Our discussion is based on the decentralized parallel\nstochastic gradient descent (D-PSGD), which is one of the state-of-the-art\nalgorithms for decentralized learning. The main contribution of this paper is\nto raise a novel open question for decentralized learning on wireless systems:\nthere is a possibility that the density of a network topology significantly\ninfluences the runtime performance of D-PSGD. In general, it is difficult to\nguarantee delay-free communications without any communication deterioration in\nreal wireless network systems because of path loss and multi-path fading. These\nfactors significantly degrade the runtime performance of D-PSGD. To alleviate\nsuch problems, we first analyze the runtime performance of D-PSGD by\nconsidering real wireless systems. This analysis yields the key insights that\ndense network topology (1) does not significantly gain the training accuracy of\nD-PSGD compared to sparse one, and (2) strongly degrades the runtime\nperformance because this setting generally requires to utilize a low-rate\ntransmission. Based on these findings, we propose a novel communication\nstrategy, in which each node estimates optimal transmission rates such that\ncommunication time during the D-PSGD optimization is minimized under the\nconstraint of network density, which is characterized by radio propagation\nproperty. The proposed strategy enables to improve the runtime performance of\nD-PSGD in wireless systems. Numerical simulations reveal that the proposed\nstrategy is capable of enhancing the runtime performance of D-PSGD.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:20:10 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Sato", "Koya", ""], ["Satoh", "Yasuyuki", ""], ["Sugimura", "Daisuke", ""]]}, {"id": "2002.10777", "submitter": "Edmond Shami", "authors": "Edmond Shami, Abdelmalek Saleh", "title": "Comparison Study for Multi-vendor Versus Single-vendor for Enterprise\n  Computer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the topics that concerns the way computer networks are designed, is\nthe single-vendor and multi-vendor solutions. Where the performance and\noperation of your network depends on which model you choose for your\nenterprise, and the future risks aligned with such models. This study outlines\nthe strengths and average price ranges of multiple vendors in the past 2 years\n(2018 and 2019), practical cases in which each model works, a case study done\nby Gartner, and finally, recommendations that can help push the design\npractices when it comes to network design.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:18:11 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Shami", "Edmond", ""], ["Saleh", "Abdelmalek", ""]]}, {"id": "2002.11040", "submitter": "Haris Gacanin", "authors": "Haris Gacanin and Marco Di Renzo", "title": "Wireless 2.0: Towards an Intelligent Radio Environment Empowered by\n  Reconfigurable Meta-Surfaces and Artificial Intelligence", "comments": "7 pages, 4 figures, 15 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce \"Wireless 2.0\": The future generation of wireless communication\nnetworks, where the radio environment becomes controllable, programmable, and\nintelligent by leveraging the emerging technologies of reconfigurable\nmetasurfaces and artificial intelligence (AI). This paper, in particular, puts\nthe emphasis on AI-based computational methods and commence with an overview of\nthe concept of intelligent radio environments based on reconfigurable\nmeta-surfaces. Later we elaborate on data management aspects, the requirements\nof supervised learning by examples, and the paradigm of reinforcement learning\n(RL) to learn by acting. Finally, we highlight numerous open challenges and\nresearch directions.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 06:05:49 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Gacanin", "Haris", ""], ["Di Renzo", "Marco", ""]]}, {"id": "2002.11045", "submitter": "Changyang She", "authors": "Changyang She and Rui Dong and Zhouyou Gu and Zhanwei Hou and Yonghui\n  Li and Wibowo Hardjawana and Chenyang Yang and Lingyang Song and Branka\n  Vucetic", "title": "Deep Learning for Ultra-Reliable and Low-Latency Communications in 6G\n  Networks", "comments": "The manuscript contains 4 figures 2 tables. It has been submitted to\n  IEEE Network (in the second round of revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the future 6th generation networks, ultra-reliable and low-latency\ncommunications (URLLC) will lay the foundation for emerging mission-critical\napplications that have stringent requirements on end-to-end delay and\nreliability. Existing works on URLLC are mainly based on theoretical models and\nassumptions. The model-based solutions provide useful insights, but cannot be\ndirectly implemented in practice. In this article, we first summarize how to\napply data-driven supervised deep learning and deep reinforcement learning in\nURLLC, and discuss some open problems of these methods. To address these open\nproblems, we develop a multi-level architecture that enables device\nintelligence, edge intelligence, and cloud intelligence for URLLC. The basic\nidea is to merge theoretical models and real-world data in analyzing the\nlatency and reliability and training deep neural networks (DNNs). Deep transfer\nlearning is adopted in the architecture to fine-tune the pre-trained DNNs in\nnon-stationary networks. Further considering that the computing capacity at\neach user and each mobile edge computing server is limited, federated learning\nis applied to improve the learning efficiency. Finally, we provide some\nexperimental and simulation results and discuss some future directions.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 14:38:11 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["She", "Changyang", ""], ["Dong", "Rui", ""], ["Gu", "Zhouyou", ""], ["Hou", "Zhanwei", ""], ["Li", "Yonghui", ""], ["Hardjawana", "Wibowo", ""], ["Yang", "Chenyang", ""], ["Song", "Lingyang", ""], ["Vucetic", "Branka", ""]]}, {"id": "2002.11047", "submitter": "Anwen Wang", "authors": "Anwen Wang, Xianjia Meng, Lvju Wang, Xiang Ji, Hao Chen, Baoying Liu,\n  Feng Chen, Yajuan Du, Guangcheng Yin", "title": "TLFW: A Three-layer Framework in Wireless Rechargeable Sensor Network\n  with a Mobile Base Station", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless sensor networks as the base support for the Internet of things has\nbeen a large number of popularity and application. Such as intelligent\nagriculture, we have to use the sensor network to obtain the growth\nenvironmental data of crops, etc.. However, the difficulty of power supply of\nwireless nodes has seriously hindered the application and development of\nInternet of things. In order to solve this problem, people use low-power, sleep\nscheduling and other energy-saving methods on the nodes. Although these methods\ncan prolong the working time of nodes, they will eventually become invalid\nbecause of the exhaustion of energy. The use of solar energy, wind energy, and\nwireless signals in the environment to obtain energy is another way to solve\nthe energy problem of nodes. However, these methods are affected by weather,\nenvironment and other factors, and are unstable. Thus, the discontinuity work\nof the node is caused. In recent years, the development of wireless power\ntransfer (WPT) has brought another solution to this problem. In this paper, a\nthree-layer framework is proposed for mobile station data collection in\nrechargeable wireless sensor networks to keep the node running forever, named\nTLFW which includes the sensor layer, cluster head layer, and mobile station\nlayer. And the framework can minimize the total energy consumption of the\nsystem. The simulation results show that the scheme can reduce the energy\nconsumption of the entire system, compared with a Mobile Station in a\nRechargeable Sensor Network(MSiRSN).\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:33:20 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Wang", "Anwen", ""], ["Meng", "Xianjia", ""], ["Wang", "Lvju", ""], ["Ji", "Xiang", ""], ["Chen", "Hao", ""], ["Liu", "Baoying", ""], ["Chen", "Feng", ""], ["Du", "Yajuan", ""], ["Yin", "Guangcheng", ""]]}, {"id": "2002.11059", "submitter": "Tianzhu Zhang", "authors": "Tianzhu Zhang", "title": "NFV Platform Design: A Survey", "comments": "This report will be updated every six months to include the most\n  up-to-date NFV platforms and design choices, in IEEE Transactions on Network\n  and Service Management", "journal-ref": null, "doi": "10.1109/TNSM.2020.3045381", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the intrinsically inefficient service provisioning in traditional\nnetworks, Network Function Virtualization (NFV) keeps gaining attention from\nboth industry and academia. By replacing the purpose-built, expensive,\nproprietary network equipment with software network functions consolidated on\ncommodity hardware, NFV envisions a shift towards a more agile and open service\nprovisioning paradigm with much lower capital expenditure (CapEx) and\noperational expenditure (OpEx). Nonetheless, just like any complex system, NFV\nplatforms commonly consist of abounding software and hardware components and\nusually incorporate disparate design choices based on distinct motivations or\nuse cases. This broad collection of convoluted alternatives makes it extremely\narduous for network operators to make proper choices. Although numerous efforts\nhave been devoted to investigating different aspects of NFV, none of them\nspecifically focused on NFV platforms or attempted to explore the design space.\nIn this paper, we present a comprehensive survey on NFV platform design. Our\nstudy solely targets existing NFV platform implementations. We begin with an\narchitectural view of the standard reference NFV platform and present our\ntaxonomy of existing NFV platforms based on the principal purpose of design.\nThen we thoroughly explore the design space and elaborate on the implementation\nchoices each platform opts for. We believe that our study gives a detailed\nguideline for network operators or service providers to choose or implement the\nmost appropriate NFV platforms based on their respective requirements. Note\nthat this report serves as a complementary document for a published IEEE TNSM\npaper [1]. We will periodically update this document to include the newly\nproposed NFV platforms and design choices.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 17:29:54 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 19:44:40 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 10:06:09 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhang", "Tianzhu", ""]]}, {"id": "2002.11110", "submitter": "Muhammad Majid Butt", "authors": "M. Majid Butt, Galymzhan Nauryzbayev, Nicola Marchetti", "title": "On Maximizing Information Reliability in Wireless Powered Cooperative\n  Networks", "comments": "Submitted for publication. arXiv admin note: substantial text overlap\n  with arXiv:1608.07518", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unpredictable nature of fading channels and difficulty in tracking channel\nstate information pose major challenge in wireless energy harvesting\ncommunication system design. In this work, we address relay selection problem\nfor wireless powered communication networks, where the relays harvest energy\nfrom the source radio frequency signals. A single source-destination pair is\nconsidered without a direct link. The connecting relay nodes are equipped with\nstorage batteries of infinite size. We assume that the channel state\ninformation (CSI) on the source-relay link is available at the relay nodes.\nDepending on the availability of the CSI on the relay-destination link at the\nrelay node, we propose two relay selection schemes and evaluate their outage\nprobability. Availability of the CSI at the relay node on the relay-destination\nlink considerably improves the performance due to additional flexibility in the\nrelay selection mechanism. Due to absence of CSI throughout the network at the\ntime of transmission path selection, the analysis of the problem is not\ntractable. Therefore, we relax our assumptions on availability of CSI and\nclosed-form expressions of the outage probability as a function of the amount\nof the available harvested energy are derived for both CSI availability cases.\nFinally, we numerically quantify the performance for the proposed schemes and\ncompare the outage probability for fixed and equal number of wireless powered\nforwarding relays.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 20:19:07 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Butt", "M. Majid", ""], ["Nauryzbayev", "Galymzhan", ""], ["Marchetti", "Nicola", ""]]}, {"id": "2002.11188", "submitter": "Sakib Ahmed", "authors": "Sakib Ahmed (1), Touseef Saleh Bin Ahmed (1), Sumaiya Jafreen (1),\n  Jannatul Tajrin (1) and Jia Uddin (1) ((1) BRAC University)", "title": "IoT Based Real Time Noise Mapping System for Urban Sound Pollution Study", "comments": "Appendix by Sakib Ahmed Accepted as Conference Paper at ICIEV and\n  icIVPR, 2018, Student Conference on Informatics, Electronics & Vision\n  (SCIEV): Paper ID 175", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IR eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the development of a system that enables real time data\nvisualization via a webapp regarding sound intensity using multiple node\ndevices connected through internet. The prototypes were realized using\nATmega328 (Arduino Nano) and ESP8266 hardware modules, NodeMCU Arduino wrapper\nlibrary, Google maps and firebase API along with JavaScript webapp. System\narchitecture is such that multiple node devices will be installed in different\nlocations of the target area. On each node device, an Arduino Nano interfaced\nwith a Sound Sensor measures the ambient sound intensity and ESP8266 Wi-Fi\nmodule transmits the data to a database via web API. On the webapp, it plots\nall the real-time data from the devices over Google maps according to the\nlocations of the node devices. The logged data that is collected can then be\nused to carry out researches regarding sound pollution in targeted areas.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:53:06 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Ahmed", "Sakib", "", "BRAC University"], ["Ahmed", "Touseef Saleh Bin", "", "BRAC University"], ["Jafreen", "Sumaiya", "", "BRAC University"], ["Tajrin", "Jannatul", "", "BRAC University"], ["Uddin", "Jia", "", "BRAC University"]]}, {"id": "2002.11269", "submitter": "Parth Sane", "authors": "Parth Sane", "title": "Is the OWASP Top 10 list comprehensive enough for writing secure code?", "comments": "5 pages, Pre-print 2020 ICISE-IEEE Conference at University of\n  Manchester, Manchester UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The OWASP Top 10 is a list that is published by the Open Web Application\nSecurity Project (OWASP). The general purpose is to serve as a watchlist for\nbugs to avoid while writing code. This paper compares how many of those\nweakness as described in the top ten list are actually reported in\nvulnerabilities listed in the National Vulnerability Database (NVD). That way\nit makes it possible to empirically show whether the OWASP Top 10 list is\ncomprehensive enough or not, for code weaknesses that have been found in the\npast decade.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 02:53:52 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Sane", "Parth", ""]]}, {"id": "2002.11375", "submitter": "Adnan Shahid", "authors": "Ingrid Moerman, Djamal Zeghlache, Adnan Shahid, Joao F. Santos, Luiz\n  A. DaSilva, Klaus David, John Farserotu, Ad de Ridder, Wei Liu, and Jeroen\n  Hoebeke", "title": "Mandate-driven Networking Eco-system: A Paradigm Shift in End-to-End\n  Communications", "comments": "internal organisation policy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wireless industry is driven by key stakeholders that follow a holistic\napproach of \"one-system-fits-all\" that leads to moving network functionality of\nmeeting stringent E2E communication requirements towards the core and cloud\ninfrastructures. This trend is limiting smaller and new players for bringing in\nnew and novel solutions. For meeting these E2E requirements, tenants and\nend-users need to be active players for bringing their needs and innovations.\nDriving E2E communication not only in terms of QoS but also overall carbon\nfootprint and spectrum efficiency from one specific community may lead to\nundesirable simplifications and a higher level of abstraction of other network\nsegments may lead to sub-optimal operations. Based on this, the paper presents\na paradigm shift that will enlarge the role of wireless innovation at academia,\nSME's, industries and start-ups while taking into account decentralized\nmandate-driven intelligence in E2E communications\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 09:28:48 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 15:16:13 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 10:27:24 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Moerman", "Ingrid", ""], ["Zeghlache", "Djamal", ""], ["Shahid", "Adnan", ""], ["Santos", "Joao F.", ""], ["DaSilva", "Luiz A.", ""], ["David", "Klaus", ""], ["Farserotu", "John", ""], ["de Ridder", "Ad", ""], ["Liu", "Wei", ""], ["Hoebeke", "Jeroen", ""]]}, {"id": "2002.11490", "submitter": "Ioannis Avgouleas", "authors": "Ioannis Avgouleas, Nikolaos Pappas and Vangelis Angelakis", "title": "Cacheable and Non-Cacheable Traffic Interplay in a Relay-Assisted\n  Wireless Network", "comments": "6 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a discrete-time wireless network that serves both cacheable and\nnon-cacheable traffic with assistance of a relay node with storage capabilities\nfor both types of traffic. We investigate how allocating the storage capacity\nto cacheable and non-cacheable traffic affects the network throughput. Our\nnumerical results provide useful insights by varying not only the allocation of\ncacheable to non-cacheable storage but also the rate by which non-cacheable\ncontent is transmitted, the rate by which cacheable content is requested, as\nwell as different popularity distributions of the cached files.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 13:57:17 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Avgouleas", "Ioannis", ""], ["Pappas", "Nikolaos", ""], ["Angelakis", "Vangelis", ""]]}, {"id": "2002.11625", "submitter": "Gregory Falco", "authors": "Gregory Falco", "title": "Death by AI: Where Assured Autonomy in Smart Cities Meets the End-to-End\n  Argument", "comments": "PREPRINT, 6 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A smart city involves critical infrastructure systems that have been\ndigitally enabled. Increasingly, many smart city cyber-physical systems are\nbecoming automated. The extent of automation ranges from basic logic gates to\nsophisticated, artificial intelligence (AI) that enables fully autonomous\nsystems. Because of modern society's reliance on autonomous systems in smart\ncities, it is crucial for them to operate in a safe manner; otherwise, it is\nfeasible for these systems to cause considerable physical harm or even death.\nBecause smart cities could involve thousands of autonomous systems operating in\nconcert in densely populated areas, safety assurances are required. Challenges\nabound to consistently manage the safety of such autonomous systems due to\ntheir disparate developers, manufacturers, operators and users. A novel network\nand a sample of associated network functions for autonomous systems is proposed\nthat aims to provide a baseline of safety for autonomous systems. This is\naccomplished by establishing a custom-designed network for autonomous systems\nthat is separate from the Internet, and can handle certain functions that\nenable safety through active networking. Such a network design sits at the\nmargins of the end-to-end principle, which is warranted considering the safety\nof autonomous systems is at stake as is argued in this paper. Without a\nscalable safety strategy for autonomous systems as proposed, assured autonomy\nin smart cities will remain elusive.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 20:14:25 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Falco", "Gregory", ""]]}, {"id": "2002.11686", "submitter": "Jaidip Kotak", "authors": "Jaidip Kotak and Yuval Elovici", "title": "IoT Device Identification Using Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-57805-3_8", "report-no": null, "categories": "cs.CR cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing use of IoT devices in organizations has increased the number of\nattack vectors available to attackers due to the less secure nature of the\ndevices. The widely adopted bring your own device (BYOD) policy which allows an\nemployee to bring any IoT device into the workplace and attach it to an\norganization's network also increases the risk of attacks. In order to address\nthis threat, organizations often implement security policies in which only the\nconnection of white-listed IoT devices is permitted. To monitor adherence to\nsuch policies and protect their networks, organizations must be able to\nidentify the IoT devices connected to their networks and, more specifically, to\nidentify connected IoT devices that are not on the white-list (unknown\ndevices). In this study, we applied deep learning on network traffic to\nautomatically identify IoT devices connected to the network. In contrast to\nprevious work, our approach does not require that complex feature engineering\nbe applied on the network traffic, since we represent the communication\nbehavior of IoT devices using small images built from the IoT devices network\ntraffic payloads. In our experiments, we trained a multiclass classifier on a\npublicly available dataset, successfully identifying 10 different IoT devices\nand the traffic of smartphones and computers, with over 99% accuracy. We also\ntrained multiclass classifiers to detect unauthorized IoT devices connected to\nthe network, achieving over 99% overall average detection accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:24:49 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kotak", "Jaidip", ""], ["Elovici", "Yuval", ""]]}, {"id": "2002.11808", "submitter": "Daniele Cuomo", "authors": "Daniele Cuomo, Marcello Caleffi and Angela Sara Cacciapuoti", "title": "Towards a Distributed Quantum Computing Ecosystem", "comments": null, "journal-ref": "https://digital-library.theiet.org/content/journals/10.1049/iet-qtc.2020.0002", "doi": "10.1049/iet-qtc.2020.0002", "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quantum Internet, by enabling quantum communications among remote quantum\nnodes, is a network capable of supporting functionalities with no direct\ncounterpart in the classical world. Indeed, with the network and communications\nfunctionalities provided by the Quantum Internet, remote quantum devices can\ncommunicate and cooperate for solving challenging computational tasks by\nadopting a distributed computing approach. The aim of this paper is to provide\nthe reader with an overview about the main challenges and open problems arising\nwith the design of a Distributed Quantum Computing ecosystem. For this, we\nprovide a survey, following a bottom-up approach, from a communications\nengineering perspective. We start by introducing the Quantum Internet as the\nfundamental underlying infrastructure of the Distributed Quantum Computing\necosystem. Then we go further, by elaborating on a high-level system\nabstraction of the Distributed Quantum Computing ecosystem. Such an abstraction\nis described through a set of logical layers. Thereby, we clarify dependencies\namong the aforementioned layers and, at the same time, a road-map emerges.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:39:41 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 18:00:16 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Cuomo", "Daniele", ""], ["Caleffi", "Marcello", ""], ["Cacciapuoti", "Angela Sara", ""]]}, {"id": "2002.11850", "submitter": "Junghoon Kim", "authors": "Junghoon Kim, Taejoon Kim, Morteza Hashemi, Christopher G. Brinton,\n  David J. Love", "title": "Joint Optimization of Signal Design and Resource Allocation in Wireless\n  D2D Edge Computing", "comments": "10 pages, 7 figures, Accepted by INFOCOM 2020", "journal-ref": null, "doi": "10.1109/INFOCOM41043.2020.9155510", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the distributed computational capabilities of\ndevice-to-device (D2D) networks. A key characteristic of D2D networks is that\ntheir topologies are reconfigurable to cope with network demands. For\ndistributed computing, resource management is challenging due to limited\nnetwork and communication resources, leading to inter-channel interference. To\novercome this, recent research has addressed the problems of wireless\nscheduling, subchannel allocation, power allocation, and multiple-input\nmultiple-output (MIMO) signal design, but has not considered them jointly. In\nthis paper, unlike previous mobile edge computing (MEC) approaches, we propose\na joint optimization of wireless MIMO signal design and network resource\nallocation to maximize energy efficiency. Given that the resulting problem is a\nnon-convex mixed integer program (MIP) which is prohibitive to solve at scale,\nwe decompose its solution into two parts: (i) a resource allocation subproblem,\nwhich optimizes the link selection and subchannel allocations, and (ii) MIMO\nsignal design subproblem, which optimizes the transmit beamformer, transmit\npower, and receive combiner. Simulation results using wireless edge topologies\nshow that our method yields substantial improvements in energy efficiency\ncompared with cases of no offloading and partially optimized methods and that\nthe efficiency scales well with the size of the network.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 00:12:00 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 13:57:15 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 01:49:48 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kim", "Junghoon", ""], ["Kim", "Taejoon", ""], ["Hashemi", "Morteza", ""], ["Brinton", "Christopher G.", ""], ["Love", "David J.", ""]]}, {"id": "2002.12473", "submitter": "Paul Schmitt", "authors": "Bilal Saleem and Paul Schmitt and Jay Chen and Barath Raghavan", "title": "Beyond the Trees: Resilient Multipath for Last-mile WISP Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expanding the reach of the Internet is a topic of widespread interest today.\nGoogle and Facebook, among others, have begun investing substantial research\nefforts toward expanding Internet access at the edge. Compared to data center\nnetworks, which are relatively over-engineered, last-mile networks are highly\nconstrained and end up being ultimately responsible for the performance issues\nthat impact the user experience.\n  The most viable and cost-effective approach for providing last-mile\nconnectivity has proved to be Wireless ISPs (WISPs), which rely on\npoint-to-point wireless backhaul infrastructure to provide connectivity using\ncheap commodity wireless hardware. However, individual WISP network links are\nknown to have poor reliability and the networks as a whole are highly cost\nconstrained.\n  Motivated by these observations, we propose Wireless ISPs with Redundancy\n(WISPR), which leverages the cost-performance tradeoff inherent in commodity\nwireless hardware to move toward a greater number of inexpensive links in WISP\nnetworks thereby lowering costs. To take advantage of this new path diversity,\nwe introduce a new, general protocol that provides increased performance,\nreliability, or a combination of the two.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 22:55:25 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Saleem", "Bilal", ""], ["Schmitt", "Paul", ""], ["Chen", "Jay", ""], ["Raghavan", "Barath", ""]]}, {"id": "2002.12507", "submitter": "Hong Xing", "authors": "Hong Xing and Osvaldo Simeone and Suzhi Bi", "title": "Decentralized Federated Learning via SGD over Wireless D2D Networks", "comments": "5 pages, 3 figures, submitted for possible conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL), an emerging paradigm for fast intelligent\nacquisition at the network edge, enables joint training of a machine learning\nmodel over distributed data sets and computing resources with limited\ndisclosure of local data. Communication is a critical enabler of large-scale FL\ndue to significant amount of model information exchanged among edge devices. In\nthis paper, we consider a network of wireless devices sharing a common fading\nwireless channel for the deployment of FL. Each device holds a generally\ndistinct training set, and communication typically takes place in a\nDevice-to-Device (D2D) manner. In the ideal case in which all devices within\ncommunication range can communicate simultaneously and noiselessly, a standard\nprotocol that is guaranteed to converge to an optimal solution of the global\nempirical risk minimization problem under convexity and connectivity\nassumptions is Decentralized Stochastic Gradient Descent (DSGD). DSGD\nintegrates local SGD steps with periodic consensus averages that require\ncommunication between neighboring devices. In this paper, wireless protocols\nare proposed that implement DSGD by accounting for the presence of path loss,\nfading, blockages, and mutual interference. The proposed protocols are based on\ngraph coloring for scheduling and on both digital and analog transmission\nstrategies at the physical layer, with the latter leveraging over-the-air\ncomputing via sparsity-based recovery.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 01:41:30 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Xing", "Hong", ""], ["Simeone", "Osvaldo", ""], ["Bi", "Suzhi", ""]]}, {"id": "2002.12561", "submitter": "Cheng-Xiang Wang", "authors": "Jie Huang, Cheng-Xiang Wang, Lu Bai, Jian Sun, Yang Yang, Jie Li, Olav\n  Tirkkonen, and Ming-Tuo Zhou", "title": "A Big Data Enabled Channel Model for 5G Wireless Communication Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standardization process of the fifth generation (5G) wireless\ncommunications has recently been accelerated and the first commercial 5G\nservices would be provided as early as in 2018. The increasing of enormous\nsmartphones, new complex scenarios, large frequency bands, massive antenna\nelements, and dense small cells will generate big datasets and bring 5G\ncommunications to the era of big data. This paper investigates various\napplications of big data analytics, especially machine learning algorithms in\nwireless communications and channel modeling. We propose a big data and machine\nlearning enabled wireless channel model framework. The proposed channel model\nis based on artificial neural networks (ANNs), including feed-forward neural\nnetwork (FNN) and radial basis function neural network (RBF-NN). The input\nparameters are transmitter (Tx) and receiver (Rx) coordinates, Tx-Rx distance,\nand carrier frequency, while the output parameters are channel statistical\nproperties, including the received power, root mean square (RMS) delay spread\n(DS), and RMS angle spreads (ASs). Datasets used to train and test the ANNs are\ncollected from both real channel measurements and a geometry based stochastic\nmodel (GBSM). Simulation results show good performance and indicate that\nmachine learning algorithms can be powerful analytical tools for future\nmeasurement-based wireless channel modeling.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:56:14 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Huang", "Jie", ""], ["Wang", "Cheng-Xiang", ""], ["Bai", "Lu", ""], ["Sun", "Jian", ""], ["Yang", "Yang", ""], ["Li", "Jie", ""], ["Tirkkonen", "Olav", ""], ["Zhou", "Ming-Tuo", ""]]}, {"id": "2002.12660", "submitter": "Meysam Goodarzi", "authors": "M. Goodarzi, D. Cvetkovski, N. Maletic, J. Gutierrez and E. Grass", "title": "Synchronization in 5G: a Bayesian Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a hybrid approach to synchronize large scale\nnetworks. In particular, we draw on Kalman Filtering (KF) along with\ntime-stamps generated by the Precision Time Protocol (PTP) for pairwise node\nsynchronization. Furthermore, we investigate the merit of Factor Graphs (FGs)\nalong with Belief Propagation (BP) algorithm in achieving high precision\nend-to-end network synchronization. Finally, we present the idea of dividing\nthe large-scale network into local synchronization domains, for each of which a\nsuitable sync algorithm is utilized. The simulation results indicate that,\ndespite the simplifications in the hybrid approach, the error in the offset\nestimation remains below 5 ns.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 11:27:48 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Goodarzi", "M.", ""], ["Cvetkovski", "D.", ""], ["Maletic", "N.", ""], ["Gutierrez", "J.", ""], ["Grass", "E.", ""]]}, {"id": "2002.12729", "submitter": "Mansaf Alam Dr", "authors": "Syed Arshad Ali, Manzoor Ansari and Mansaf Alam", "title": "Resource Management Techniques for Cloud-Based IoT Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is an Internet-based environment of connected\ndevices and applications. IoT creates an environment where physical devices and\nsensors are flawlessly combined into information nodes to deliver innovative\nand smart services for human-being to make their life easier and more\nefficient. The main objective of the IoT devices-network is to generate data,\nwhich are converted into useful information by the data analysis process, it\nalso provides useful resources to the end users. IoT resource management is a\nkey challenge to ensure the quality of end user experience. Many IoT smart\ndevices and technologies like sensors, actuators, RFID, UMTS, 3G, and GSM etc.\nare used to develop IoT networks. Cloud Computing plays an important role in\nthese networks deployment by providing physical resources as virtualized\nresources consist of memory, computation power, network bandwidth, virtualized\nsystem and device drivers in secure and pay as per use basis. One of the major\nconcerns of Cloud-based IoT environment is resource management, which ensures\nefficient resource utilization, load balancing, reduce SLA violation, and\nimprove the system performance by reducing operational cost and energy\nconsumption. Many researchers have been proposed IoT based resource management\ntechniques. The focus of this paper is to investigate these proposed resource\nallocation techniques and finds which parameters must be considered for\nimprovement in resource allocation for IoT networks. Further, this paper also\nuncovered challenges and issues of Cloud-based resource allocation for IoT\nenvironment.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:50:40 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Ali", "Syed Arshad", ""], ["Ansari", "Manzoor", ""], ["Alam", "Mansaf", ""]]}, {"id": "2002.12906", "submitter": "Beshr Al Nahas", "authors": "Beshr Al Nahas, Antonio Escobar-Molero, Jirka Klaue, Simon Duquennoy,\n  Olaf Landsiedel", "title": "BlueFlood: Concurrent Transmissions for Multi-Hop Bluetooth 5 --\n  Modeling and Evaluation", "comments": "Extension of conference publication:\n  https://dl.acm.org/doi/abs/10.5555/3324320.3324336 In Section 3.2.4, we have\n  a new numerical analysis that better aligns to the micro evaluation. Later in\n  Section 3.4, we discuss the practical implications of the feasibility study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bluetooth is an omnipresent technology, available on billions of devices\ntoday. While it has been traditionally limited to peer-to-peer communication\nand star networks, the recent Bluetooth Mesh standard extends it to multi-hop\nnetworking. In addition, the Bluetooth 5 standard introduces new modes to allow\nfor increased reliability. In this paper, we evaluate the feasibility of\nconcurrent transmissions (CT) in Bluetooth via modeling and controlled\nexperiments and then devise an efficient network-wide data dissemination\nprotocol, BlueFlood, based on CT for multi-hop Bluetooth networks.\n  First, we model and analyze how CT distorts the received waveform and\ncharacterize the Bit Error Rate of a Frequency-Shift Keying receiver to show\nthat CT is feasible over Bluetooth. Second, we verify our analytic results with\na controlled experimental study of CT over Bluetooth PHY. Third, we present\nBlueFlood, a fast and efficient network-wide data dissemination in multi-hop\nBluetooth networks.\n  In our experimental evaluation, in two testbeds deployed in university\nbuildings, we show that BlueFlood achieves 99.9% end-to-end delivery ratio with\na duty-cycle of 0.4% for periodic dissemination of advertising packets of 38\nbytes with 200 milliseconds intervals at 2 Mbps. Moreover, we show that\nBlueFlood can be received by off-the-shelf devices such as smartphones, paving\na seamless integration with existing technologies.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:21:29 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 09:10:23 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2021 10:50:13 GMT"}, {"version": "v4", "created": "Sat, 24 Apr 2021 08:42:59 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Nahas", "Beshr Al", ""], ["Escobar-Molero", "Antonio", ""], ["Klaue", "Jirka", ""], ["Duquennoy", "Simon", ""], ["Landsiedel", "Olaf", ""]]}]