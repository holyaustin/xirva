[{"id": "1910.00043", "submitter": "Parham Gohari", "authors": "Parham Gohari, Bo Wu, Matthew Hale and Ufuk Topcu", "title": "The Dirichlet Mechanism for Differential Privacy on the Unit Simplex", "comments": "Submitted to ACC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As members of a network share more information with each other and network\nproviders, sensitive data leakage raises privacy concerns. To address this need\nfor a class of problems, we introduce a novel mechanism that privatizes vectors\nbelonging to the unit simplex. Such vectors can be seen in many applications,\nsuch as privatizing a decision-making policy in a Markov decision process. We\nuse differential privacy as the underlying mathematical framework for these\ndevelopments. The introduced mechanism is a probabilistic mapping that maps a\nvector within the unit simplex to the same domain according to a Dirichlet\ndistribution. We find the mechanism well-suited for inputs within the unit\nsimplex because it always returns a privatized output that is also in the unit\nsimplex. Therefore, no further projection back onto the unit simplex is\nrequired. We verify the privacy guarantees of the mechanism for two cases,\nnamely, identity queries and average queries. In the former case, we derive\nexpressions for the differential privacy level of privatizing a single vector\nwithin the unit simplex. In the latter case, we study the mechanism for\nprivatizing the average of a collection of vectors, each of which is in the\nunit simplex. We establish a trade-off between the strength of privacy and the\nvariance of the mechanism output, and we introduce a parameter to balance the\ntrade-off between them. Numerical results illustrate these developments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 18:26:46 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Gohari", "Parham", ""], ["Wu", "Bo", ""], ["Hale", "Matthew", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1910.00159", "submitter": "Matteo Varvello", "authors": "Matteo Varvello, I\\~nigo Querejeta Azurmendi, Antonio Nappa,\n  Panagiotis Papadopoulos, Goncalo Pestana, Ben Livshits", "title": "VPN0: A Privacy-Preserving Decentralized Virtual Private Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Virtual Private Networks (dVPNs) are new VPN solutions aiming to\nsolve the trust-privacy concern of a VPN's central authority by leveraging a\ndistributed architecture. In this paper, we first review the existing dVPN\necosystem and debate on its privacy requirements. Then, we present VPN0, a dVPN\nwith strong privacy guarantees and minimal performance impact on its users.\nVPN0 guarantees that a dVPN node only carries traffic it has \"whitelisted\",\nwithout revealing its whitelist or knowing the traffic it tunnels. This is\nachieved via three main innovations. First, an attestation mechanism which\nleverages TLS to certify a user visit to a specific domain. Second, a zero\nknowledge proof to certify that some incoming traffic is authorized, e.g.,\nfalls in a node's whitelist, without disclosing the target domain. Third, a\ndynamic chain of VPN tunnels to both increase privacy and guarantee service\ncontinuation while traffic certification is in place. The paper demonstrates\nVPN0 functioning when integrated with several production systems, namely\nBitTorrent DHT and ProtonVPN.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 00:18:19 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Varvello", "Matteo", ""], ["Azurmendi", "I\u00f1igo Querejeta", ""], ["Nappa", "Antonio", ""], ["Papadopoulos", "Panagiotis", ""], ["Pestana", "Goncalo", ""], ["Livshits", "Ben", ""]]}, {"id": "1910.00162", "submitter": "Martin Reisslein", "authors": "Ahmed Nasrallah, Venkatraman Balasubramanian, Akhilesh Thyagaturu,\n  Martin Reisslein, Hesham ElBakoury", "title": "Large Scale Deterministic Networking: A Simulation Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Ethernet switched networks usually involves best effort service. A\nrecent effort by the IEEE 802.1/3 TSN group has sought to standardize the\nEthernet data-link protocol such that it operates on a deterministic service in\naddition to the best effort service targeting Operational Technology\napplications, e.g., industrial control systems. This paper investigates the\nCyclic Queueing and Forwarding (CQF) and Paternoster scheduling protocols in a\ntypical industrial control loop with varying propagation delays emulating large\nscale networks. Our main findings for CQF and Paternoster are that CQF has an\nadvantage towards real-time streams with hard-deadlines whilst Paternoster is\nfor streams with more relaxed deadlines but can operate without time\nsynchronization.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 00:43:30 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 19:17:25 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Nasrallah", "Ahmed", ""], ["Balasubramanian", "Venkatraman", ""], ["Thyagaturu", "Akhilesh", ""], ["Reisslein", "Martin", ""], ["ElBakoury", "Hesham", ""]]}, {"id": "1910.00300", "submitter": "Marco Giordani", "authors": "Tommaso Zugno, Matteo Drago, Marco Giordani, Michele Polese, Michele\n  Zorzi", "title": "Towards Standardization of Millimeter Wave Vehicle-to-Vehicle Networks:\n  Open Challenges and Performance Evaluation", "comments": "7 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IEEE 802.11bd and 3GPP NR V2X represent the new specifications for next\ngeneration vehicular networks, exploiting new communication technologies and\nnew spectrum, such as the millimeter wave (mmWave) band, to improve throughput\nand reduce latency. In this paper, we specifically focus on the challenges that\nmmWaves introduce for Vehicle-to-Vehicle (V2V) networking, by reviewing the\nlatest standard developments and the issues that 802.11bd and NR V2X will have\nto address for V2V operations at mmWaves. To the best of our knowledge, our\nwork is the first that considers a full-stack, end-to-end approach for the\ndesign of mmWave V2V networks, discussing open issues that span from the\nphysical to the higher layers, and reporting the results of an end-to-end\nperformance evaluation that highlight the potential of mmWaves for V2V\ncommunications.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 10:56:16 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 14:18:48 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Zugno", "Tommaso", ""], ["Drago", "Matteo", ""], ["Giordani", "Marco", ""], ["Polese", "Michele", ""], ["Zorzi", "Michele", ""]]}, {"id": "1910.00431", "submitter": "Steven Weber", "authors": "Jonathan Stokes and Steven Weber", "title": "Graph search via star sampling with and without replacement", "comments": "17 pages, 9 figures. arXiv admin note: substantial text overlap with\n  arXiv:1901.03393", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Star sampling (SS) is a random sampling procedure on a graph wherein each\nsample consists of a randomly selected vertex (the star center) and its\n(one-hop) neighbors (the star points). We consider the use of SS to find any\nmember of a target set of vertices in a graph, where the figure of merit (cost)\nis either the expected number of samples (unit cost) or the expected number of\nstar centers plus star points (linear cost) until a vertex in the target set is\nencountered, either as a star center or as a star point. We analyze these two\nperformance measures on three related star sampling paradigms: SS with\nreplacement (SSR), SS without center replacement (SSC), and SS without star\nreplacement (SSS). Exact and approximate expressions are derived for the\nexpected unit and linear costs of SSR, SSC, and SSS on Erd\\H{o}s-R\\'{e}nyi (ER)\nrandom graphs. The approximations are seen to be accurate. SSC/SSS are notably\nbetter than SSR under unit cost for low-density ER graphs, while SSS is notably\nbetter than SSR/SSC under linear cost for low- to moderate-density ER graphs.\nSimulations on twelve \"real-world\" graphs shows the cost approximations to be\nof variable quality: the SSR and SSC approximations are uniformly accurate,\nwhile the SSS approximation, derived for an ER graph, is of variable accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:12:14 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 00:18:56 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Stokes", "Jonathan", ""], ["Weber", "Steven", ""]]}, {"id": "1910.00507", "submitter": "Dmitry Bankov", "authors": "Dmitry Bankov, Evgeny Khorov, Andrey Lyakhov, Sigurd Schelstraete", "title": "Beacons in Dense Wi-Fi Networks: How to Befriend with Neighbors in the\n  5G World?", "comments": null, "journal-ref": "2016 IEEE 17th International Symposium on A World of Wireless,\n  Mobile and Multimedia Networks (WoWMoM)", "doi": "10.1109/WoWMoM.2016.7523579", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address 5G challenges, IEEE 802.11 is currently developing new amendments\nto the Wi-Fi standard, the most promising of which is 802.11ax. A key scenario\nconsidered by the developers of this amendment is dense and overlapped networks\ntypically present in residential buildings, offices, airports, stadiums, and\nother places of a modern city. Being crucial for Wi-Fi hotspots, the hidden\nstation problem becomes even more challenging for dense and overlapped\nnetworks, where even access points (APs) can be hidden. In this case, user\nstations can experience continuous collisions of beacons sent by different APs,\nwhich can cause disassociation and break Internet access. In this paper, we\nshow that beacon collisions are rather typical for residential networks and may\nlead to unexpected and irreproducible malfunction. We investigate how often\nbeacon collisions occur, and describe a number of mechanisms which can be used\nto avoid beacon collisions in dense deployment. Specifically, we pay much\nattention to those mechanisms which are currently under consideration of the\nIEEE 802.11ax group.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 15:58:38 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Bankov", "Dmitry", ""], ["Khorov", "Evgeny", ""], ["Lyakhov", "Andrey", ""], ["Schelstraete", "Sigurd", ""]]}, {"id": "1910.00653", "submitter": "Anis Koubaa", "authors": "Anis Koubaa, Abdulrahman Aldawood, Bassel Saeed, Abdullatif Hadid,\n  Mohanned Ahmed, Abdulrahman Saad, Hesham Alkhouja, Mohamed Alkanhal", "title": "Smart Palm: An IoT Framework for Red Palm Weevil Early Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart agriculture is an evolving trend in agriculture industry, where sensors\nare embedded into plants to collect vital data and help in decision making to\nensure higher quality of crops and prevent pests, disease, and other possible\nthreats. In Saudi Arabia, growing palms is the most important agricultural\nactivity, and there is an increasing need to leverage smart agriculture\ntechnology to improve the production of dates and prevent diseases. One of the\nmost critical diseases of palms if the red palm weevil, which is an insect that\ncauses a lot of damage to palm trees and can devast large areas of palm trees.\nThe most challenging problem is that the effect of the weevil is not visible by\nhumans until the palm reaches an advanced infestation state. For this reason,\nthere is a need to use advanced technology for early detection and prevention\nof infestation propagation. In this project, we have developed am IoT based\nsmart palm monitoring prototype as a proof-of-concept that (1) allows to\nmonitor palms remotely using smart agriculture sensors, (2) contribute to the\nearly detection of red palm weevil. Users can use web/mobile application to\ninteract with their palm farms and help them in getting early detection of\npossible infestations. We used Elm company IoT platform to interface between\nthe sensor layer and the user layer. In addition, we have collected data using\naccelerometer sensors and we applied signal processing and statistical\ntechniques to analyze collected data and determine a fingerprint of the\ninfestation.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 12:50:08 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Koubaa", "Anis", ""], ["Aldawood", "Abdulrahman", ""], ["Saeed", "Bassel", ""], ["Hadid", "Abdullatif", ""], ["Ahmed", "Mohanned", ""], ["Saad", "Abdulrahman", ""], ["Alkhouja", "Hesham", ""], ["Alkanhal", "Mohamed", ""]]}, {"id": "1910.00677", "submitter": "Mahmoud Abbasi", "authors": "Mahmoud Abbasi", "title": "NB-IoT Small Cell: A 3GPP Perspective", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Narrowband Internet of Things (NB-IoT) technology was introduced in 3GPP\nRelease 13 to accommodate device-generated traffic over cellular networks.\nThere have been efforts in Release 14 to deliver further improvements to\nfacilitate the deployment of Internet of Things (IoT) use cases, such as\ncoverage enhancement, and support for low cost, low complexity and low power\nconsumption device. Small cell NB-IoT is added as an attractive feature in 3GPP\nRelease 15. In this article, we provide an overview of this feature and try to\nshed light on major aspects of small cell deployment in NB-IoT systems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 21:25:26 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Abbasi", "Mahmoud", ""]]}, {"id": "1910.00731", "submitter": "Jaafar Elmirghani", "authors": "Sanaa Hamid Mohamed, Taisir E.H. El-Gorashi and Jaafar M.H. Elmirghani", "title": "A Survey of Big Data Machine Learning Applications Optimization in Cloud\n  Data Centers and Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey article reviews the challenges associated with deploying and\noptimizing big data applications and machine learning algorithms in cloud data\ncenters and networks. The MapReduce programming model and its widely-used\nopen-source platform; Hadoop, are enabling the development of a large number of\ncloud-based services and big data applications. MapReduce and Hadoop thus\nintroduce innovative, efficient, and accelerated intensive computations and\nanalytics. These services usually utilize commodity clusters within\ngeographically-distributed data centers and provide cost-effective and elastic\nsolutions. However, the increasing traffic between and within the data centers\nthat migrate, store, and process big data, is becoming a bottleneck that calls\nfor enhanced infrastructures capable of reducing the congestion and power\nconsumption. Moreover, enterprises with multiple tenants requesting various big\ndata services are challenged by the need to optimize leasing their resources at\nreduced running costs and power consumption while avoiding under or over\nutilization. In this survey, we present a summary of the characteristics of\nvarious big data programming models and applications and provide a review of\ncloud computing infrastructures, and related technologies such as\nvirtualization, and software-defined networking that increasingly support big\ndata systems. Moreover, we provide a brief review of data centers topologies,\nrouting protocols, and traffic characteristics, and emphasize the implications\nof big data on such cloud data centers and their supporting networks. Wide\nranging efforts were devoted to optimize systems that handle big data in terms\nof various applications performance metrics and/or infrastructure energy\nefficiency. Finally, some insights and future research directions are provided.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 08:05:34 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Mohamed", "Sanaa Hamid", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "1910.00772", "submitter": "Gang Wang", "authors": "Gang Wang, Yanyuan Qin", "title": "MAC Protocols for Wireless Mesh Networks with Multi-beam Antennas: A\n  Survey", "comments": "22 pages, 6 figures, Future of Information and Communication\n  Conference (FICC) 2019, https://doi.org/10.1007/978-3-030-12388-8_9", "journal-ref": "Future of Information and Communication Conference (FICC) 2019", "doi": "10.1007/978-3-030-12388-8_9", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-beam antenna technologies have provided lots of promising solutions to\nmany current challenges faced in wireless mesh networks. The antenna can\nestablish several beamformings simultaneously and initiate concurrent\ntransmissions or receptions using multiple beams, thereby increasing the\noverall throughput of the network transmission. Multi-beam antenna has the\nability to increase the spatial reuse, extend the transmission range, improve\nthe transmission reliability, as well as save the power consumption.\nTraditional Medium Access Control (MAC) protocols for wireless network largely\nrelied on the IEEE 802.11 Distributed Coordination Function(DCF) mechanism,\nhowever, IEEE 802.11 DCF cannot take the advantages of these unique\ncapabilities provided by multi-beam antennas. This paper surveys the MAC\nprotocols for wireless mesh networks with multi-beam antennas. The paper first\ndiscusses some basic information in designing multi-beam antenna system and MAC\nprotocols, and then presents the main challenges for the MAC protocols in\nwireless mesh networks compared with the traditional MAC protocols. A\nqualitative comparison of the existing MAC protocols is provided to highlight\ntheir novel features, which provides a reference for designing the new MAC\nprotocols. To provide some insights on future research, several open issues of\nMAC protocols are discussed for wireless mesh networks using multi-beam\nantennas.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 04:24:34 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Wang", "Gang", ""], ["Qin", "Yanyuan", ""]]}, {"id": "1910.00785", "submitter": "Ibrar Yaqoob", "authors": "Muhammad Imran, Latif U. Khan, Ibrar Yaqoob, Ejaz Ahmed, Muhammad\n  Ahsan Qureshi, Arif Ahmed", "title": "Energy Harvesting in 5G Networks: Taxonomy, Requirements, Challenges,\n  and Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consciousness of energy saving is increasing in fifth-generation (5G)\nwireless networks due to the high energy consumption issue. Energy harvesting\ntechnology is a possible appealing solution for ultimately prolonging the\nlifetime of devices and networks. Although considerable research efforts have\nbeen conducted in the context of using energy harvesting technology in 5G\nwireless networks, these efforts are in their infancy, and a tutorial on this\ntopic is still lacking. This study aims to discuss the beneficial role of\nenergy harvesting technology in 5G networks. We categorize and classify the\nliterature available on energy harvesting in 5G networks by devising a taxonomy\nbased on energy sources; energy harvesting devices, phases, and models; energy\nconversion methods, and energy propagation medium. The key requirements for\nenabling energy harvesting in 5G networks are also outlined. Several core\nresearch challenges that remain to be addressed are discussed. Furthermore,\nfuture research directions are provided.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 05:47:37 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Imran", "Muhammad", ""], ["Khan", "Latif U.", ""], ["Yaqoob", "Ibrar", ""], ["Ahmed", "Ejaz", ""], ["Qureshi", "Muhammad Ahsan", ""], ["Ahmed", "Arif", ""]]}, {"id": "1910.00818", "submitter": "Sebastian Schmitt", "authors": "Christopher Priester and Sebastian Schmitt and Tiago P. Peixoto", "title": "Limits and trade-offs of topological network robustness", "comments": null, "journal-ref": "PLoS ONE 9(9): e108215 (2014)", "doi": "10.1371/journal.pone.0108215", "report-no": null, "categories": "cs.NI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the trade-off between the robustness against random and\ntargeted removal of nodes from a network. To this end we utilize the stochastic\nblock model to study ensembles of infinitely large networks with arbitrary\nlarge-scale structures. We present results from numerical two-objective\noptimization simulations for networks with various fixed mean degree and number\nof blocks. The results provide strong evidence that three different blocks are\nsufficient to realize the best trade-off between the two measures of\nrobustness, i.e.\\ to obtain the complete front of Pareto-optimal networks. For\nall values of the mean degree, a characteristic three block structure emerges\nover large parts of the Pareto-optimal front. This structure can be often\ncharacterized as a core-periphery structure, composed of a group of core nodes\nwith high degree connected among themselves and to a periphery of low-degree\nnodes, in addition to a third group of nodes which is disconnected from the\nperiphery, and weakly connected to the core. Only at both extremes of the\nPareto-optimal front, corresponding to maximal robustness against random and\ntargeted node removal, a two-block core-periphery structure or a one-block\nfully random network are found, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 08:14:21 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Priester", "Christopher", ""], ["Schmitt", "Sebastian", ""], ["Peixoto", "Tiago P.", ""]]}, {"id": "1910.00916", "submitter": "Yu-Pin Hsu", "authors": "Yu-Pin Hsu, Yu-Chih Huang, and Shin-Lin Shieh", "title": "Scheduling Stochastic Real-Time Jobs in Unreliable Workers", "comments": "8 pages, technical report for the WCNC paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed computing network consisting of a master and\nmultiple workers processing tasks of different types. The master is running\nmultiple applications. Each application stochastically generates real-time jobs\nwith a strict job deadline, where each job is a collection of tasks of some\ntypes specified by the application. A real-time job is completed only when all\nits tasks are completed by the corresponding workers within the deadline.\nMoreover, we consider unreliable workers, whose processing speeds are\nuncertain. Because of the limited processing abilities of the workers, an\nalgorithm for scheduling the jobs in the workers is needed to maximize the\naverage number of completed jobs for each application. The scheduling problem\nis not only critical but also practical in distributed computing networks. In\nthis paper, we develop two scheduling algorithms, namely, a feasibility-optimal\nscheduling algorithm and an approximate scheduling algorithm. The\nfeasibility-optimal scheduling algorithm can fulfill the largest region of\napplications' requirements for the average number of completed jobs. However,\nthe feasibility-optimal scheduling algorithm suffers from high computational\ncomplexity when the number of applications is large. To address the issue, the\napproximate scheduling algorithm is proposed with a guaranteed approximation\nratio in the worst-case scenario. The approximate scheduling algorithm is also\nvalidated in the average-case scenario via computer simulations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 12:48:25 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 12:54:19 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 02:40:39 GMT"}, {"version": "v4", "created": "Fri, 25 Oct 2019 02:53:08 GMT"}, {"version": "v5", "created": "Thu, 30 Jan 2020 05:05:09 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Hsu", "Yu-Pin", ""], ["Huang", "Yu-Chih", ""], ["Shieh", "Shin-Lin", ""]]}, {"id": "1910.00967", "submitter": "Jorik Oostenbrink", "authors": "Mohammad Riftadi, Jorik Oostenbrink, Fernando Kuipers", "title": "GP4P4: Enabling Self-Programming Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in programmable switches have enabled network operators to\nbuild high-speed customized network functions. Although this is an important\nstep towards self-* networks, operators are now faced with the burden of\nlearning a new language and maintaining a repository of network function code.\nInspired by the Intent-Based Networking paradigm, we propose a new framework,\nGP4P4: a genetic programming approach able to autonomously generate programs\nfor P4-programmable switches directly from network intents. We demonstrate that\nGP4P4 is able to generate various small network functions in up to a few\nminutes; an important first step towards realizing the vision of `Self-Driving'\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:09:39 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Riftadi", "Mohammad", ""], ["Oostenbrink", "Jorik", ""], ["Kuipers", "Fernando", ""]]}, {"id": "1910.01092", "submitter": "Orestes Manzanilla-Salazar M.Sc.", "authors": "Orestes Manzanilla-Salazar, Filippo Malandra, Hakim Mellah, Constant\n  Wette and Brunilde Sanso", "title": "A Machine Learning framework for Sleeping Cell Detection in a Smart-city\n  IoT Telecommunications Infrastructure", "comments": "Submitted to the IEEE Access Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The smooth operation of largely deployed Internet of Things (IoT)\napplications will depend on, among other things, effective infrastructure\nfailure detection. Access failures in wireless network Base Stations (BSs)\nproduce a phenomenon called \"sleeping cells\", which can render a cell catatonic\nwithout triggering any alarms or provoking immediate effects on cell\nperformance, making them difficult to discover. To detect this kind of failure,\nwe propose a Machine Learning (ML) framework based on the use of Key\nPerformance Indicator (KPI) statistics from the BS under study, as well as\nthose of the neighboring BSs with propensity to have their performance affected\nby the failure. A simple way to define neighbors is to use adjacency in Voronoi\ndiagrams. In this paper, we propose a much more realistic approach based on the\nnature of radio-propagation and the way devices choose the BS to which they\nsend access requests. We gather data from large-scale simulators that use real\nlocation data for BSs and IoT devices and pose the detection problem as a\nsupervised binary classification problem. We measure the effects on the\ndetection performance by the size of time aggregations of the data, the level\nof traffic and the parameters of the neighborhood definition. The Extra Trees\nand Naive Bayes classifiers achieve Receiver Operating Characteristic (ROC)\nArea Under the Curve (AUC) scores of 0.996 and 0.993, respectively, with False\nPositive Rate (FPR) under 5 %. The proposed framework holds potential for other\npattern recognition tasks in smart-city wireless infrastructures, that would\nenable the monitoring, prediction and improvement of the Quality of Service\n(QoS) experienced by IoT applications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 17:17:22 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 18:47:28 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Manzanilla-Salazar", "Orestes", ""], ["Malandra", "Filippo", ""], ["Mellah", "Hakim", ""], ["Wette", "Constant", ""], ["Sanso", "Brunilde", ""]]}, {"id": "1910.01114", "submitter": "Vinayakumar R", "authors": "Shisrut Rawat, Aishwarya Srinivasan, and Vinayakumar R", "title": "Intrusion detection systems using classical machine learning techniques\n  versus integrated unsupervised feature learning and deep neural network", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security analysts and administrators face a lot of challenges to detect and\nprevent network intrusions in their organizations, and to prevent network\nbreaches, detecting the breach on time is crucial. Challenges arise while\ndetecting unforeseen attacks. This work includes a performance comparison of\nclassical machine learning approaches that require vast feature engineering,\nversus integrated unsupervised feature learning and deep neural networks on the\nNSL-KDD dataset. Various trials of experiments were run to identify suitable\nhyper-parameters and network configurations of machine learning models. The DNN\nusing 15 features extracted using Principal Component analysis was the most\neffective modeling method. The further analysis using the Software Defined\nNetworking features also presented a good accuracy using Deep Neural network.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 23:48:20 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Rawat", "Shisrut", ""], ["Srinivasan", "Aishwarya", ""], ["R", "Vinayakumar", ""]]}, {"id": "1910.01453", "submitter": "Hao Xu", "authors": "Hao Xu", "title": "D2D-LSTM based Prediction of the D2D Diffusion Path in Mobile Social\n  Networks", "comments": "9 pages, 10 fighures. arXiv admin note: text overlap with\n  arXiv:1705.09275 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, how to expand data transmission to reduce cell data and repeated\ncell transmission has received more and more research attention. In mobile\nsocial networks, content popularity prediction has always been an important\npart of traffic offloading and expanding data dissemination. However, current\nmainstream content popularity prediction methods only use the number of\ndownloads and shares or the distribution of user interests, which do not\nconsider important time and geographic location information in mobile social\nnetworks, and all of data is from OSN which is not same as MSN. In this work,\nwe propose D2D Long Short-Term Memory (D2D-LSTM), a deep neural network based\non LSTM, which is designed to predict a complete D2D diffusion path. Our work\nis the first attempt in the world to use real data of MSN to predict diffusion\npath with deep neural networks which conforms to the D2D structure. Compared to\nlinear sequence networks, only learn users' social features without time\ndistribution or GPS distribution and files' content features, our model can\npredict the propagation path more accurately (up to 85.858\\%) and can reach\nconvergence faster (less than 100 steps) because of the neural network that\nconforms to the D2D structure and combines user social features and files\nfeatures. Moreover, we can simulate generating a D2D propagation tree. After\nexperiment and comparison, it is found to be very similar to the ground-truth\ntrees. Finally, we define a user prototype refinement that can more accurately\ndescribe the propagation sharing habits of a prototype user (including content\npreferences, time preferences, and geographic location preferences), and\nexperimentally validate the predictions when the user prototype is added to\n1000 classes, it is almost identical to the 50 categories.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 03:03:09 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Xu", "Hao", ""]]}, {"id": "1910.01508", "submitter": "Jos\\'e Su\\'arez-Varela", "authors": "Krzysztof Rusek, Jos\\'e Su\\'arez-Varela, Paul Almasan, Pere\n  Barlet-Ros, Albert Cabellos-Aparicio", "title": "RouteNet: Leveraging Graph Neural Networks for network modeling and\n  optimization in SDN", "comments": "12 pages", "journal-ref": "IEEE Journal on Selected Areas in Communication (JSAC), vol. 38,\n  no. 10, pp. 2260-2270, 2020", "doi": "10.1109/JSAC.2020.3000405", "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network modeling is a key enabler to achieve efficient network operation in\nfuture self-driving Software-Defined Networks. However, we still lack\nfunctional network models able to produce accurate predictions of Key\nPerformance Indicators (KPI) such as delay, jitter or loss at limited cost. In\nthis paper we propose RouteNet, a novel network model based on Graph Neural\nNetwork (GNN) that is able to understand the complex relationship between\ntopology, routing, and input traffic to produce accurate estimates of the\nper-source/destination per-packet delay distribution and loss. RouteNet\nleverages the ability of GNNs to learn and model graph-structured information\nand as a result, our model is able to generalize over arbitrary topologies,\nrouting schemes and traffic intensity. In our evaluation, we show that RouteNet\nis able to predict accurately the delay distribution (mean delay and jitter)\nand loss even in topologies, routing and traffic unseen in the training (worst\ncase MRE=15.4%). Also, we present several use cases where we leverage the KPI\npredictions of our GNN model to achieve efficient routing optimization and\nnetwork planning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:26:28 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 17:06:04 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Rusek", "Krzysztof", ""], ["Su\u00e1rez-Varela", "Jos\u00e9", ""], ["Almasan", "Paul", ""], ["Barlet-Ros", "Pere", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "1910.01516", "submitter": "Jie Mei", "authors": "Jie Mei, Xianbin Wang, Kan Zheng", "title": "Intelligent Network Slicing for V2X Services Towards 5G", "comments": "19 pages (one column), 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefiting from the widely deployed LTE infrastructures, the fifth generation\n(5G) wireless networks have been becoming a critical enabler for the emerging\nvehicle-to-everything (V2X) communications. However, existing LTE networks\ncannot efficiently support stringent but dynamic requirements of V2X services.\nOne effective solution to overcome this challenge is network slicing, whereby\ndifferent services could be supported by logically separated networks. To\nmitigate the increasing complexity of network slicing in 5G, we propose to\nleverage the recent advancement of Machine Learning (ML) technologies for\nautomated network operation. Specifically, we propose intelligent network\nslicing architecture for V2X services, where network functions and\nmulti-dimensional network resources are virtualized and assigned to different\nnetwork slices. In achieving optimized slicing intelligently, several critical\ntechniques, including mobile data collection and ML algorithm design, are\ndiscussed to tackle the related challenges. Then, we develop a simulation\nplatform to illustrate the effectiveness of our proposed intelligent network\nslicing. With integration of 5G network slicing and ML-enabled technologies,\nthe QoS of V2X services is expected to be dramatically enhanced.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:30:59 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Mei", "Jie", ""], ["Wang", "Xianbin", ""], ["Zheng", "Kan", ""]]}, {"id": "1910.01601", "submitter": "Vahid Pourahmadi Dr.", "authors": "Pooya Khandel, Amir Hossein Rassafi, Vahid Pourahmadi, Saeed\n  Sharifian, and Rong Zheng", "title": "SensorDrop: A Reinforcement Learning Framework for Communication\n  Overhead Reduction on the Edge", "comments": "8 pages, 9 figures, Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In IoT solutions, it is usually desirable to collect data from a large number\nof distributed IoT sensors at a central node in the cloud for further\nprocessing. One of the main design challenges of such solutions is the high\ncommunication overhead between the sensors and the central node (especially for\nmultimedia data). In this paper, we aim to reduce the communication overhead\nand propose a method that is able to determine which sensors should send their\ndata to the central node and which to drop data. The idea is that some sensors\nmay have data which are correlated with others and some may have data that are\nnot essential for the operation to be performed at the central node. As such\ndecisions are application dependent and may change over time, they should be\nlearned during the operation of the system, for that we propose a method based\non Advantage Actor-Critic (A2C) reinforcement learning which gradually learns\nwhich sensor's data is cost-effective to be sent to the central node. The\nproposed approach has been evaluated on a multi-view multi-camera dataset, and\nwe observe a significant reduction in communication overhead with marginal\ndegradation in object classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:08:05 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Khandel", "Pooya", ""], ["Rassafi", "Amir Hossein", ""], ["Pourahmadi", "Vahid", ""], ["Sharifian", "Saeed", ""], ["Zheng", "Rong", ""]]}, {"id": "1910.01711", "submitter": "Xingqin Lin", "authors": "Kazuki Takeda, Huilin Xu, Taehyoung Kim, Karol Schober, and Xingqin\n  Lin", "title": "Understanding the Heart of the 5G Air Interface: An Overview of Physical\n  Downlink Control Channel for 5G New Radio (NR)", "comments": "8 pages, 5 figures, 1 table, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New Radio (NR) is a new radio air interface developed by the 3rd Generation\nPartnership Project (3GPP) for the fifth generation (5G) mobile communications\nsystem. With great flexibility, scalability, and efficiency, 5G is expected to\naddress a wide range of use-cases including enhanced mobile broadband (eMBB),\nultra-reliable low-latency communications (URLLC), and massive machine type\ncommunications (mMTC). The physical downlink control channel (PDCCH) in NR\ncarries Downlink Control Information (DCI). Understanding how PDCCH operates is\nkey to developing a good understanding of how information is communicated over\nNR. This paper provides an overview of the 5G NR PDCCH by describing its\nphysical layer structure, monitoring mechanisms, beamforming operation, and the\ncarried information. We also share various design rationales that influence NR\nstandardization.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 20:28:57 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Takeda", "Kazuki", ""], ["Xu", "Huilin", ""], ["Kim", "Taehyoung", ""], ["Schober", "Karol", ""], ["Lin", "Xingqin", ""]]}, {"id": "1910.01834", "submitter": "Joachim Neu", "authors": "Vivek Bagaria, Joachim Neu, David Tse", "title": "Boomerang: Redundancy Improves Latency and Throughput in Payment-Channel\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-51280-4_17", "report-no": null, "categories": "cs.CR cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-path routing schemes for payment-channel networks, Alice transfers\nfunds to Bob by splitting them into partial payments and routing them along\nmultiple paths. Undisclosed channel balances and mismatched transaction fees\ncause delays and failures on some payment paths. For atomic transfer schemes,\nthese straggling paths stall the whole transfer. We show that the latency of\ntransfers reduces when redundant payment paths are added. This frees up\nliquidity in payment channels and hence increases the throughput of the\nnetwork. We devise Boomerang, a generic technique to be used on top of\nmulti-path routing schemes to construct redundant payment paths free of\ncounterparty risk. In our experiments, applying Boomerang to a baseline routing\nscheme leads to 40% latency reduction and 2x throughput increase. We build on\nideas from publicly verifiable secret sharing, such that Alice learns a secret\nof Bob iff Bob overdraws funds from the redundant paths. Funds are forwarded\nusing Boomerang contracts, which allow Alice to revert the transfer iff she has\nlearned Bob's secret. We implement the Boomerang contract in Bitcoin Script.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 08:26:52 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 04:47:15 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Bagaria", "Vivek", ""], ["Neu", "Joachim", ""], ["Tse", "David", ""]]}, {"id": "1910.01869", "submitter": "Vicent Cholvi", "authors": "Vicent Cholvi and Juan Echag\\\"ue and Antonio Fern\\'andez Anta and\n  Christopher Thraves Caro", "title": "System Stability Under Adversarial Injection of Dependent Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider a computational model of a distributed system\nformed by a set of servers in which jobs, that are continuously arriving, have\nto be executed. Every job is formed by a set of dependent tasks (i.~e., each\ntask may have to wait for others to be completed before it can be started),\neach of which has to be executed in one of the servers. The arrival of jobs and\ntheir properties is assumed to be controlled by a bounded adversary, whose only\nrestriction is that it cannot overload any server. This model is a non-trivial\ngeneralization of the Adversarial Queuing Theory model of Borodin et al., and,\nlike that model, focuses on the stability of the system: whether the number of\njobs pending to be completed is bounded at all times. We show multiple results\nof stability and instability for this adversarial model under different\ncombinations of the scheduling policy used at the servers, the arrival rate,\nand the dependence between tasks in the jobs.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 11:03:24 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Cholvi", "Vicent", ""], ["Echag\u00fce", "Juan", ""], ["Anta", "Antonio Fern\u00e1ndez", ""], ["Caro", "Christopher Thraves", ""]]}, {"id": "1910.01881", "submitter": "Kyoomars Alizadeh Noghani", "authors": "Kyoomars Alizadeh Noghani, Andreas Kassler, Javid Taheri", "title": "On the Cost-Optimality Trade-off for Service Function Chain\n  Reconfiguration", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal placement of Virtual Network Functions (VNFs) in virtualized data\ncenters enhances the overall performance of Service Function Chains (SFCs) and\ndecreases the operational costs for mobile network operators. Maintaining an\noptimal placement of VNFs under changing load requires a dynamic\nreconfiguration that includes adding or removing VNF instances, changing the\nresource allocation of VNFs, and re-routing corresponding service flows.\nHowever, such reconfiguration may lead to notable service disruptions and\nimpose additional overhead on the VNF infrastructure, especially when\nreconfiguration entails state or VNF migration. On the other hand, not changing\nthe existing placement may lead to high operational costs. In this paper, we\ninvestigate the trade-off between the reconfiguration of SFCs and the\noptimality of the resulting placement and service flow (re)routing. We model\ndifferent reconfiguration costs related to the migration of stateful VNFs and\nsolve a joint optimization problem that aims to minimize both the total cost of\nthe VNF placement and the reconfiguration cost necessary for repairing a\nsuboptimal placement. Numerical results show that a small number of\nreconfiguration operations can significantly reduce the operational cost of the\nVNF infrastructure; however, too much reconfiguration may not pay off should\nheavy costs be involved.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 11:46:12 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Noghani", "Kyoomars Alizadeh", ""], ["Kassler", "Andreas", ""], ["Taheri", "Javid", ""]]}, {"id": "1910.01909", "submitter": "Ashwin Ganesan", "authors": "Ashwin Ganesan", "title": "On some distributed scheduling algorithms for wireless networks with\n  hypergraph interference models", "comments": "IEEE Transactions on Information Theory, accepted/to appear", "journal-ref": "IEEE Transactions on Information Theory, vol. 67, no. 5, pp.\n  2952-2957, May 2021", "doi": "10.1109/TIT.2021.3059719", "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that the performance of the maximal scheduling algorithm in\nwireless ad hoc networks under the hypergraph interference model can be further\naway from optimal than previously known. The exact worst-case performance of\nthis distributed, greedy scheduling algorithm is analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 08:01:54 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 14:41:24 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ganesan", "Ashwin", ""]]}, {"id": "1910.01910", "submitter": "Lou Salaun", "authors": "Lou Salaun (LTCI, LINCS), Marceau Coupechoux (LTCI), Chung Shue Chen\n  (LINCS)", "title": "Weighted Sum-Rate Maximization in Multi-Carrier NOMA with Cellular Power\n  Constraint", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.00510", "journal-ref": "IEEE INFOCOM, Apr 2019, Paris, France. pp.451-459", "doi": "10.1109/INFOCOM.2019.8737495", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-orthogonal multiple access (NOMA) has received significant attention for\nfuture wireless networks. NOMA outperforms orthogonal schemes, such as OFDMA,\nin terms of spectral efficiency and massive connectivity. The joint subcarrier\nand power allocation problem in NOMA is NP-hard to solve in general, due to\ncomplex impacts of signal superposition on each user's achievable data rates,\nas well as combinatorial constraints on the number of multiplexed users per\nsub-carrier to mitigate error propagation. In this family of problems, weighted\nsum-rate (WSR) is an important objective function as it can achieve different\ntradeoffs between sum-rate performance and user fairness. We propose a novel\napproach to solve the WSR maximization problem in multi-carrier NOMA with\ncellular power constraint. The problem is divided into two polynomial time\nsolvable sub-problems. First, the multi-carrier power control (given a fixed\nsubcarrier allocation) is non-convex. By taking advantage of its separability\nproperty, we design an optimal and low complexity algorithm (MCPC) based on\nprojected gradient descent. Secondly, the single-carrier user selection is a\nnon-convex mixed-integer problem that we solve using dynamic programming\n(SCUS). This work also aims to give an understanding on how each sub-problem's\nparticular structure can facilitate the algorithm design. In that respect, the\nabove MCPC and SCUS are basic building blocks that can be applied in a wide\nrange of resource allocation problems. Furthermore, we propose an efficient\nheuristic to solve the general WSR maximization problem by combining MCPC and\nSCUS. Numerical results show that it achieves near-optimal sum-rate with user\nfairness, as well as significant performance improvement over OMA.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 07:39:53 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Salaun", "Lou", "", "LTCI, LINCS"], ["Coupechoux", "Marceau", "", "LTCI"], ["Chen", "Chung Shue", "", "LINCS"]]}, {"id": "1910.02023", "submitter": "S. Mohammad Hosseini", "authors": "S.Mohammad Hosseini, Amirhossein Jahangir, Mehdi Kazemi", "title": "Digesting Network Traffic for Forensic Investigation Using Digital\n  Signal Processing Techniques", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics and Security (2019)", "doi": "10.1109/TIFS.2019.2915190", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important practices of cybercrime investigations is to search\na network traffic history for an excerpt of traffic, such as the disclosed\ninformation of an organization or a worm signature. In post-mortem\ninvestigations, criminals and targets are detected by attributing the excerpt\nto payloads of traffic flows. Since it is impossible to store the high volume\nof data related to long-term traffic history, payload attribution systems (PAS)\nbased on storing a compact digest of traffic using Bloom filters have been\npresented in the literature. In these systems, querying the stored digest for\nan excerpt results in a low number of suspects instead of certain criminals. In\nthis paper, we present a different PAS which is based on simple and widespread\ndigital signal processing techniques. Our traffic digesting scheme has been\ninspired by DSP-based compression algorithms. The proposed payload attribution\nsystem, named DSPAS, not only results in a low false positive rate but also\noutperforms previous schemes in response to wildcard queries which are\nessentially applicable for complex excerpts such as the signature of\npolymorphic worms. Our theoretical analysis and practical evaluations show that\nDSPAS results in a significantly lower false positive rate and also a lower\nprocessing time for wildcard queries in comparison to previous works. Moreover,\nour PAS can prevent a malicious insider from evading the PAS by its ability to\nfind strings similar to a queried excerpt.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:26:55 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Hosseini", "S. Mohammad", ""], ["Jahangir", "Amirhossein", ""], ["Kazemi", "Mehdi", ""]]}, {"id": "1910.02100", "submitter": "Abishek Sankararaman", "authors": "Abishek Sankararaman, Ayalvadi Ganesh, Sanjay Shakkottai", "title": "Social Learning in Multi Agent Multi Armed Bandits", "comments": "Minor Corrections from before", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI cs.SI math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a distributed version of the classical stochastic\nMulti-Arm Bandit (MAB) problem. Our setting consists of a large number of\nagents $n$ that collaboratively and simultaneously solve the same instance of\n$K$ armed MAB to minimize the average cumulative regret over all agents. The\nagents can communicate and collaborate among each other \\emph{only} through a\npairwise asynchronous gossip based protocol that exchange a limited number of\nbits. In our model, agents at each point decide on (i) which arm to play, (ii)\nwhether to, and if so (iii) what and whom to communicate with. Agents in our\nmodel are decentralized, namely their actions only depend on their observed\nhistory in the past.\n  We develop a novel algorithm in which agents, whenever they choose,\ncommunicate only arm-ids and not samples, with another agent chosen uniformly\nand independently at random. The per-agent regret scaling achieved by our\nalgorithm is $O \\left( \\frac{\\lceil\\frac{K}{n}\\rceil+\\log(n)}{\\Delta}\n  \\log(T) + \\frac{\\log^3(n) \\log \\log(n)}{\\Delta^2}\n  \\right)$. Furthermore, any agent in our algorithm communicates only a total\nof $\\Theta(\\log(T))$ times over a time interval of $T$.\n  We compare our results to two benchmarks - one where there is no\ncommunication among agents and one corresponding to complete interaction. We\nshow both theoretically and empirically, that our algorithm experiences a\nsignificant reduction both in per-agent regret when compared to the case when\nagents do not collaborate and in communication complexity when compared to the\nfull interaction setting which requires $T$ communication attempts by an agent\nover $T$ arm pulls.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 18:34:04 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 15:12:18 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 01:20:10 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Sankararaman", "Abishek", ""], ["Ganesh", "Ayalvadi", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1910.02146", "submitter": "Tobias Reiher", "authors": "Tobias Reiher, Alexander Senier, Jeronimo Castrillon, Thorsten Strufe", "title": "RecordFlux: Formal Message Specification and Generation of Verifiable\n  Binary Parsers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various vulnerabilities have been found in message parsers of protocol\nimplementations in the past. Even highly sensitive software components like TLS\nlibraries are affected regularly. Resulting issues range from denial-of-service\nattacks to the extraction of sensitive information. The complexity of protocols\nand imprecise specifications in natural language are the core reasons for\nsubtle bugs in implementations, which are hard to find. The lack of precise\nspecifications impedes formal verification.\n  In this paper, we propose a model and a corresponding domain-specific\nlanguage to formally specify message formats of existing real-world binary\nprotocols. A unique feature of the model is the capability to define\ninvariants, which specify relations and dependencies between message fields.\nFurthermore, the model allows defining the relation of messages between\ndifferent protocol layers and thus ensures correct interpretation of payload\ndata. We present a technique to derive verifiable parsers based on the model,\ngenerate efficient code for their implementation, and automatically prove the\nabsence of runtime errors. Examples of parser specifications for Ethernet and\nTLS demonstrate the applicability of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 17:19:25 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Reiher", "Tobias", ""], ["Senier", "Alexander", ""], ["Castrillon", "Jeronimo", ""], ["Strufe", "Thorsten", ""]]}, {"id": "1910.02214", "submitter": "Kaibin Huang", "authors": "Dongzhu Liu, Guangxu Zhu, Jun Zhang, and Kaibin Huang", "title": "Data-Importance Aware User Scheduling for Communication-Efficient Edge\n  Machine Learning", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prevalence of intelligent mobile applications, edge learning is\nemerging as a promising technology for powering fast intelligence acquisition\nfor edge devices from distributed data generated at the network edge. One\ncritical task of edge learning is to efficiently utilize the limited radio\nresource to acquire data samples for model training at an edge server. In this\npaper, we develop a novel user scheduling algorithm for data acquisition in\nedge learning, called (data) importance-aware scheduling. A key feature of this\nscheduling algorithm is that it takes into account the informativeness of data\nsamples, besides communication reliability. Specifically, the scheduling\ndecision is based on a data importance indicator (DII), elegantly incorporating\ntwo \"important\" metrics from communication and learning perspectives, i.e., the\nsignal-to-noise ratio (SNR) and data uncertainty. We first derive an explicit\nexpression for this indicator targeting the classic classifier of support\nvector machine (SVM), where the uncertainty of a data sample is measured by its\ndistance to the decision boundary. Then, the result is extended to\nconvolutional neural networks (CNN) by replacing the distance based uncertainty\nmeasure with the entropy. As demonstrated via experiments using real datasets,\nthe proposed importance-aware scheduling can exploit the two-fold multi-user\ndiversity, namely the diversity in both the multiuser channels and the\ndistributed data samples. This leads to faster model convergence than the\nconventional scheduling schemes that exploit only a single type of diversity.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 05:45:48 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Liu", "Dongzhu", ""], ["Zhu", "Guangxu", ""], ["Zhang", "Jun", ""], ["Huang", "Kaibin", ""]]}, {"id": "1910.02245", "submitter": "Stefan Nothaas", "authors": "Stefan Nothaas, Fabian Ruhland, Michael Sch\\\"ottner", "title": "A Benchmark to Evaluate InfiniBand Solutions for Java Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-latency network interconnects, such as InfiniBand, are commonly used in\nHPC centers and are even accessible with todays cloud providers offering\nequipped instances for rent. Most big data applications and frameworks are\nwritten in Java. But, the JVM environment alone does not provide interfaces to\ndirectly utilize InfiniBand networks.\n  In this paper, we present the ``Java InfiniBand Benchmark'' to evaluate the\ncurrently available (and supported) ``low-level'' solutions to utilize\nInfiniBand in Java. It evaluates socket- and verbs-based libraries using\ntypical network microbenchmarks regarding throughput and latency. Furthermore,\nwe present evaluation results of the solutions on two hardware configurations\nwith 56 Gbit/s and 100 Gbit/s InfiniBand NICs. With transparency often traded\nfor performance and vice versa, the benchmark helps developers with studying\nthe pros and cons of each solution and support them in their decision which\nsolution is more suitable for their existing or new use-case.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 10:42:20 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Nothaas", "Stefan", ""], ["Ruhland", "Fabian", ""], ["Sch\u00f6ttner", "Michael", ""]]}, {"id": "1910.02300", "submitter": "Ahmed Ibrahim Dr.", "authors": "Ahmed Ibrahim, Octavia A. Dobre, Telex M. N. Ngatched, and Ana Garcia\n  Armada", "title": "Bender's Decomposition for Optimization Design Problems in Communication\n  Networks", "comments": "Accepted in IEEE Network Magazine, Aug. 2019, Article No.:\n  NETWORK-19-00414.R1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various types of communication networks are constantly emerging to improve\nthe connectivity services and facilitate the interconnection of various types\nof devices. This involves the development of several technologies, such as\ndevice-to-device communications, wireless sensor networks and vehicular\ncommunications. The various services provided have heterogeneous requirements\non the quality metrics such as throughput, end-to-end latency and jitter.\nFurthermore, different network technologies have inherently heterogeneous\nrestrictions on resources, e.g., power, interference management requirements,\ncomputational capabilities, etc. As a result, different network operations such\nas spectrum management, routing, power control and offloading need to be\nperformed differently. Mathematical optimization techniques have always been at\nthe heart of such design problems to formulate and propose computationally\nefficient solution algorithms. One of the existing powerful techniques of\nmathematical optimization is Benders decomposition (BD), which is the focus of\nthis article. Here, we briefly review different BD variants that have been\napplied in various existing network types and different design problems. These\nmain variants are the classical, the combinatorial, the multi-stage, and the\ngeneralized BD. We discuss compelling BD applications for various network types\nincluding heterogeneous cellular networks, infrastructure wired wide area\nnetworks, smart grids, wireless sensor networks, and wireless local area\nnetworks. Mainly, our goal is to assist the readers in refining the motivation,\nproblem formulation, and methodology of this powerful optimization technique in\nthe context of future networks. We also discuss the BD challenges and the\nprospective ways these can be addressed when applied to communication networks'\ndesign problems.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 17:56:27 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ibrahim", "Ahmed", ""], ["Dobre", "Octavia A.", ""], ["Ngatched", "Telex M. N.", ""], ["Armada", "Ana Garcia", ""]]}, {"id": "1910.02350", "submitter": "Shahbaz Rezaei", "authors": "Shahbaz Rezaei, Bryce Kroencke and Xin Liu", "title": "Large-scale Mobile App Identification Using Deep Learning", "comments": null, "journal-ref": "IEEE Access 8 (2019) 348-362", "doi": "10.1109/ACCESS.2019.2962018", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many network services and tools (e.g. network monitors, malware-detection\nsystems, routing and billing policy enforcement modules in ISPs) depend on\nidentifying the type of traffic that passes through the network. With the\nwidespread use of mobile devices, the vast diversity of mobile apps, and the\nmassive adoption of encryption protocols (such as TLS), large-scale encrypted\ntraffic classification becomes increasingly difficult. In this paper, we\npropose a deep learning model for mobile app identification that works even\nwith encrypted traffic. The proposed model only needs the payload of the first\nfew packets for classification, and, hence, it is suitable even for\napplications that rely on early prediction, such as routing and QoS\nprovisioning. The deep model achieves between 84% to 98% accuracy for the\nidentification of 80 popular apps. We also perform occlusion analysis to bring\ninsight into what data is leaked from SSL/TLS protocol that allows accurate app\nidentification. Moreover, our traffic analysis shows that many apps generate\nnot only app-specific traffic, but also numerous ambiguous flows. Ambiguous\nflows are flows generated by common functionality modules, such as\nadvertisement and traffic analytics. Because such flows are common among many\ndifferent apps, identifying the source app that generates ambiguous flows is\nchallenging. To address this challenge, we propose a CNN+LSTM model that uses\nadjacent flows to learn the order and pattern of multiple flows, to better\nidentify the app that generates them. We show that such flow association\nconsiderably improves the accuracy, particularly for ambiguous flows.\nFurthermore, we show that our approach is robust to mixed traffic scenarios\nwhere some unrelated flows may appear in adjacent flows. To the best of our\nknowledge, this is the first work that identifies the source app for ambiguous\nflows.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 01:03:38 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 16:35:09 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Rezaei", "Shahbaz", ""], ["Kroencke", "Bryce", ""], ["Liu", "Xin", ""]]}, {"id": "1910.02353", "submitter": "Haoyue Tang", "authors": "Haoyue Tang, Jintao Wang, Philippe Ciblat, Jian Song", "title": "Optimizing Data Freshness in Time-Varying Wireless Networks with\n  Imperfect Channel State", "comments": "to be submitted to ICC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scenario where a base station (BS) attempts to collect fresh\ninformation from power constrained sensors over time-varying band-limited\nwireless channels. We characterize the data freshness through the recently\nproposed metric--the Age of Information. We consider a time-varying channel\nmodel with power adaptation. Unlike previous work, packet loss may happen due\nto imperfect channel estimation or decoding error. We propose an asymptotic\noptimal scheduling algorithm minimizing AoI performance and satisfying both\nbandwidth and power constraint in such networks. Numerical simulations show\nthat the proposed policy outperforms the greedy one, and we observe that\nsensors with poor channels are scheduled at higher AoI in order to limit the\npacket loss.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 01:39:08 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 01:49:17 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Tang", "Haoyue", ""], ["Wang", "Jintao", ""], ["Ciblat", "Philippe", ""], ["Song", "Jian", ""]]}, {"id": "1910.02397", "submitter": "Christian Koch", "authors": "Christian Koch, Arne-Tobias Rak, Michael Zink, Ralf Steinmetz, Amr\n  Rizk", "title": "Increasing the Quality of 360{\\deg} Video Streaming by Transitioning\n  between Viewport Quality Adaptation Mechanisms", "comments": "Our code: https://github.com/arizk/360transitions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Virtual reality has been gaining popularity in recent years caused by the\nproliferation of affordable consumer-grade devices such as Oculus Rift, HTC\nVive, and Samsung VR. Amongst the various VR applications, 360{\\deg} video\nstreaming is currently one of the most popular ones. It allows user to change\ntheir field-of-view (FoV) based on head movement, which enables them to freely\nselect an area anywhere from the sphere the video is (virtually) projected to.\nWhile 360{\\deg} video streaming offers new exciting ways of consuming content\nfor viewers, it poses a series of challenges to the systems that are\nresponsible for the distribution of such content from the origin to the viewer.\nOne challenge is the significantly increased bandwidth requirement for\nstreaming such content in real time. Recent research has shown that only\nstreaming the content that is in the user's FoV in high quality can lead to\nstrong bandwidth savings. This can be achieved by analyzing the viewers head\norientation and movement based on sensor information. Alternatively, historic\ninformation from users that watched the content in the past can be taken into\naccount to prefetch 360{\\deg} video data in high quality assuming the viewer\nwill direct the FoV to these areas. In this paper, we present a 360{\\deg} video\nstreaming system that transitions between sensor- and content-based predictive\nmechanisms. We evaluate the effects of this transition-based approach on the\nQuality of Experience (QoE) of such a VR streaming system and show that the\nperceived quality can be increased between 50\\% and 80\\% compared to systems\nthat only apply either one of the two approaches.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 08:36:28 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Koch", "Christian", ""], ["Rak", "Arne-Tobias", ""], ["Zink", "Michael", ""], ["Steinmetz", "Ralf", ""], ["Rizk", "Amr", ""]]}, {"id": "1910.02613", "submitter": "Weihan Chen", "authors": "Weihan Chen, Xia Yin, Zhiliang Wang, Xingang Shi", "title": "Placement and Routing Optimization Problem for Service Function Chain:\n  State of Art and Future Opportunities", "comments": "8 pages, 5 fingures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Functions Virtualization (NFV) allows implantation of network\nfunctions to be independent of dedicated hardware devices. Any series of\nservices can be represented by a service function chain which contains a set of\nvirtualized network functions in a specified order. From the perspective of\nnetwork performance optimization, the challenges of deploying service chain in\nnetwork is twofold: 1) the location of placing virtualized network functions\nand resources allocation scheme; and 2) routing policy for traffic flow among\ndifferent instances of network function. This article introduces service\nfunction chain related optimization problems, summarizes the optimization\nmotivation and mainstream algorithm of virtualized network functions deployment\nand traffic routing. We hope it can help readers to learn about the current\nresearch progress and make further innovation in this field.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 05:29:35 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Chen", "Weihan", ""], ["Yin", "Xia", ""], ["Wang", "Zhiliang", ""], ["Shi", "Xingang", ""]]}, {"id": "1910.02640", "submitter": "Liangping Ma", "authors": "Liangping Ma, Hae Chung, and Byung K Yi", "title": "Four-Dimension Cross Constellations with Gray Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a four-dimension (4D) cross constellation has been proposed, where a\n4D-vector is drawn from two $(3\\times 4^m)$-ary QAM constellations, in an\neffort to reduce the peak-to-average-power ratio (PAPR). We construct a\nbits-to-signal mapping and prove that it is a Gray mapping. Simulation results\nshow that the proposed modulation scheme is effective in reducing the PAPR\nwhile providing better error performance than existing 4D modulation schemes.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 07:21:37 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ma", "Liangping", ""], ["Chung", "Hae", ""], ["Yi", "Byung K", ""]]}, {"id": "1910.02847", "submitter": "J\\\"urgen D\\\"urrwang", "authors": "Marcel Rumez, J\\\"urgen D\\\"urrwang, Tim Brecht, Timo Steinshorn, Peter\n  Neugebauer, Reiner Kriesten, and Eric Sax", "title": "CAN Radar: Sensing Physical Devices in CAN Networks based on Time Domain\n  Reflectometry", "comments": "Submitted to conference", "journal-ref": null, "doi": "10.1109/VNC48660.2019.9062819", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of security vulnerabilities in automotive networks has already\nbeen shown by various publications in recent years. Due to the specification of\nthe Controller Area Network (CAN) as a broadcast medium without security\nmechanisms, attackers are able to read transmitted messages without being\nnoticed and to inject malicious messages. In order to detect potential\nattackers within a network or software system as early as possible, Intrusion\nDetection Systems (IDSs) are prevalent. Many approaches for vehicles are based\non techniques which are able to detect deviations from specified CAN network\nbehaviour regarding protocol or payload properties. However, it is challenging\nto detect attackers who secretly connect to CAN networks and do not actively\nparticipate in bus traffic. In this paper, we present an approach that is\ncapable of successfully detecting unknown CAN devices and determining the\ndistance (cable length) between the attacker device and our sensing unit based\non Time Domain Reflectometry (TDR) technique. We evaluated our approach on a\nreal vehicle network.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 15:18:06 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Rumez", "Marcel", ""], ["D\u00fcrrwang", "J\u00fcrgen", ""], ["Brecht", "Tim", ""], ["Steinshorn", "Timo", ""], ["Neugebauer", "Peter", ""], ["Kriesten", "Reiner", ""], ["Sax", "Eric", ""]]}, {"id": "1910.03057", "submitter": "Liangping Ma", "authors": "Liangping Ma, Tao Deng, and Alpaslan Demir", "title": "Cyclic Prefix Adaptation with Constant Overall Symbol Time for\n  DFT-spread-OFDM and OFDM", "comments": "Published at IEEE VTC-Spring Workshop on 5G New Air Interface, May\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For DFT-spread-OFDM or OFDM, if the delay spread varies in a wide range and\nthe symbol duration is relatively short, adapting the cyclic prefix (CP)\nduration rather than using a fixed one may significantly improve the spectral\nefficiency while preventing inter-symbol interference (ISI). In practice, it\nmay be beneficial to have a constant overall DFT-spread-OFDM/OFDM symbol time,\nwhich is the sum of the duration of a CP and the duration of a data portion. We\npropose to adapt the CP duration to the delay spread without changing the\noverall symbol time for DFT-spread-OFDM or OFDM, and address implementation\nchallenges. In particular, we propose changing the clocking rate of ADC and DAC\nor using a Farrow filter to reduce the computational complexity of\narbitrary-size DFT/IDFT resulting from the adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 20:01:02 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ma", "Liangping", ""], ["Deng", "Tao", ""], ["Demir", "Alpaslan", ""]]}, {"id": "1910.03139", "submitter": "Nitya Nand Dwivedi", "authors": "Taskeen Zaidi, Nitya Nand Dwivedi", "title": "Voice Packet Performance Estimation through Step Network Using OPNET", "comments": "2018 IEEE 3rd International Conference on Computing, Communication\n  and Security (ICCCS). arXiv admin note: text overlap with arXiv:1701.04792", "journal-ref": null, "doi": "10.1109/CCCS.2018.8586812", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  VoIP transfer voice over networks such as LAN. This technology is growing\nrapidly due to support of existing network infrastructure at low cost. Various\nsimulations have been done and it is observed that by increasing the VoIP\nclient, packet length and traffic arrival rate the performance of step network\naffected. In the current work packet dropped, packet received, voice traffic\nsent and end-to-end delay is estimated for various queuing disciplines like PQ,\nFIFO and WFQ. It is depicted that queuing disciplines effects the applications\nperformance and utilization of resources.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 17:46:03 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Zaidi", "Taskeen", ""], ["Dwivedi", "Nitya Nand", ""]]}, {"id": "1910.03280", "submitter": "Gabriele D'Angelo", "authors": "Mirko Zichichi, Stefano Ferretti, Gabriele D'Angelo", "title": "A Distributed Ledger Based Infrastructure for Smart Transportation\n  System and Social Good", "comments": "Proceedings of the IEEE Consumer Communications and Networking\n  Conference 2020 (CCNC 2020)", "journal-ref": null, "doi": "10.1109/CCNC46108.2020.9045640", "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a system architecture to promote the development of smart\ntransportation systems. Thanks to the use of distributed ledgers and related\ntechnologies, it is possible to create, store and share data generated by users\nthrough their sensors, while moving. In particular, IOTA and IPFS are used to\nstore and certify data (and their related metadata) coming from sensors or by\nthe users themselves. Ethereum is exploited as the smart contract platform that\ncoordinates the data sharing and provisioning. The necessary privacy guarantees\nare provided by the usage of Zero Knowledge Proof. We show some results\nobtained from some use case scenarios that demonstrate how such technologies\ncan be integrated to build novel smart services and to promote social good in\nuser mobility.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 08:53:18 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 06:19:41 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Zichichi", "Mirko", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "1910.03281", "submitter": "Gabriele D'Angelo", "authors": "Gyordan Caminati, Sara Kiade, Gabriele D'Angelo, Stefano Ferretti,\n  Vittorio Ghini", "title": "Fast Session Resumption in DTLS for Mobile Communications", "comments": "Proceedings of the IEEE Consumer Communications and Networking\n  Conference 2020 (CCNC 2020)", "journal-ref": null, "doi": "10.1109/CCNC46108.2020.9045119", "report-no": null, "categories": "cs.NI cs.DC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DTLS is a protocol that provides security guarantees to Internet\ncommunications. It can operate on top of both TCP and UDP transport protocols.\nThus, it is particularly suited for peer-to-peer and distributed multimedia\napplications. The same holds if the endpoints are mobile devices. In this\nscenario, mechanisms are needed to surmount possible network disconnections,\noften arising due to the mobility or the scarce resources of devices, that can\njeopardize the quality of the communications. Session resumption is thus a main\nissue to deal with. To this aim, we propose a fast reconnection scheme that\nemploys non-connected sockets to quickly resume DTLS communication sessions.\nThe proposed scheme is assessed in a performance evaluation that confirms its\nviability.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 08:56:05 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 06:22:48 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Caminati", "Gyordan", ""], ["Kiade", "Sara", ""], ["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""], ["Ghini", "Vittorio", ""]]}, {"id": "1910.03324", "submitter": "Cristian Hernandez Benet", "authors": "Cristian Hernandez Benet, Andreas J. Kassler", "title": "FlowDyn: Towards a Dynamic Flowlet Gap Detection using Programmable Data\n  Planes", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data center networks offer multiple disjoint paths between Top-of-Rack (ToR)\nswitches to connect server racks providing large bisection bandwidth. An\neffective load-balancing mechanism is required in order to fully utilize the\navailable capacity of the multiple paths. While packet-based load-balancing can\nachieve high utilization, it suffers from reordering. Flow-based load-balancing\nsuch as equal-cost multipath routing (ECMP) spreads traffic uniformly across\nmultiple paths leading to frequent hash collisions and suboptimal performance.\nFinally, flowlet based load-balancing such as CONGA or HULA splits flows into\nsmaller units, which are sent on different paths. Most flowlet based\nload-balancing schemes depend on a proper static setting of the flowlet gap,\nwhich decides when new flowlets are detected. While a too small gap may lead to\nreordering, a too large gap results in missed load-balancing opportunities. In\nthis paper, we propose FlowDyn, which dynamically adapts the flowlet gap to\nincrease the efficiency of the load-balancing schemes while avoiding the\nreordering problem. Using programmable data planes, FlowDyn uses active probes\ntogether with telemetry information to track path latency between different ToR\nswitches. FlowDyn calculates dynamically a suitable flowlet gap that can be\nused for flowlet based load-balancing mechanism. We evaluate FlowDyn\nextensively in simulation, showing that it achieves 3.19 times smaller flow\ncompletion time at 10% load and 1.16x at 90% load.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 10:32:09 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Benet", "Cristian Hernandez", ""], ["Kassler", "Andreas J.", ""]]}, {"id": "1910.03345", "submitter": "Aamir Mahmood", "authors": "Ra\\'ul Rond\\'on, Aamir Mahmood, Simone Grimaldi and Mikael Gidlund", "title": "Understanding the Performance of Bluetooth Mesh: Reliability, Delay and\n  Scalability Analysis", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article evaluates the quality-of-service performance and scalability of\nthe recently released Bluetooth Mesh protocol and provides general guidelines\non its use and configuration. Through extensive simulations, we analyzed the\nimpact of the configuration of all the different protocol's parameters on the\nend-to-end reliability, delay, and scalability. In particular, we focused on\nthe structure of the packet broadcast process, which takes place in time\nintervals known as \\textit{Advertising Events} and \\textit{Scanning Events}.\nResults indicate a high degree of interdependence among all the different\ntiming parameters involved in both the scanning and the advertising processes\nand show that the correct operation of the protocol greatly depends on the\ncompatibility between their configurations. We also demonstrated that\nintroducing randomization in these timing parameters, as well as varying the\nduration of the \\textit{Advertising Events}, reduces the drawbacks of the\nflooding propagation mechanism implemented by the protocol. Using data\ncollected from a real office environment, we also studied the behavior of the\nprotocol in the presence of WLAN interference. It was shown that Bluetooth Mesh\nis vulnerable to external interference, even when implementing the standardized\nlimitation of using only 3 out of the 40 Bluetooth Low Energy frequency\nchannels. We observed that the achievable average delay is relatively low, of\naround 250~ms for over 10 hops under the worst simulated network conditions.\nHowever, results proved that scalability is especially challenging for\nBluetooth Mesh since it is prone to broadcast storm, hindering the\ncommunication reliability for denser deployments.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 11:37:36 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Rond\u00f3n", "Ra\u00fal", ""], ["Mahmood", "Aamir", ""], ["Grimaldi", "Simone", ""], ["Gidlund", "Mikael", ""]]}, {"id": "1910.03478", "submitter": "Javier Cabrera ARteaga", "authors": "Javier Cabrera-Arteaga, Martin Monperrus and Benoit Baudry", "title": "Scalable Comparison of JavaScript V8 Bytecode Traces", "comments": "10 pages, 6 figures, 2 tables,", "journal-ref": "Proceedings of the SPLASH workshop on Virtual Machines and\n  Language Implementations (VMIL), 2019", "doi": "10.1145/3358504.3361228", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The comparison and alignment of runtime traces are essential, e.g., for\nsemantic analysis or debugging. However, naive sequence alignment algorithms\ncannot address the needs of the modern web: (i) the bytecode generation process\nof V8 is not deterministic; (ii) bytecode traces are large.\n  We present STRAC, a scalable and extensible tool tailored to compare bytecode\ntraces generated by the V8 JavaScript engine. Given two V8 bytecode traces and\na distance function between trace events, STRAC computes and provides the best\nalignment. The key insight is to split access between memory and disk. STRAC\ncan identify semantically equivalent web pages and is capable of processing\nhuge V8 bytecode traces whose order of magnitude matches today's web like\nhttps://2019.splashcon.org, which generates approx. 150k of V8 bytecode\ninstructions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:46:42 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Cabrera-Arteaga", "Javier", ""], ["Monperrus", "Martin", ""], ["Baudry", "Benoit", ""]]}, {"id": "1910.03510", "submitter": "Francesc Wilhelmi", "authors": "Francesc Wilhelmi, Sergio Barrachina-Mu\\~noz, Boris Bellalta, Cristina\n  Cano, Anders Jonsson and Vishnu Ram", "title": "A Flexible Machine Learning-Aware Architecture for Future WLANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lots of hopes have been placed on Machine Learning (ML) as a key enabler of\nfuture wireless networks. By taking advantage of large volumes of data, ML is\nexpected to deal with the ever-increasing complexity of networking problems.\nUnfortunately, current networks are not yet prepared to support the ensuing\nrequirements of ML-based applications in terms of data collection, processing,\nand output distribution. This article points out the architectural requirements\nthat are needed to pervasively include ML as part of future wireless networks\noperation. Specifically, we look into Wireless Local Area Networks (WLANs),\nwhich, due to their nature can be found in multiple forms, ranging from\ncloud-based to edge-computing-like deployments. In particular, we propose to\nadopt the International Telecommunications Union (ITU) unified architecture for\n5G and beyond. Based on ITU's architecture, we provide insights on the main\nrequirements and the major challenges of introducing ML to the multiple\nmodalities of WLANs. Finally, we showcase the superiority of the architecture\nthrough an ML-enabled use case for future networks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 16:14:07 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 09:37:12 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 09:11:55 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wilhelmi", "Francesc", ""], ["Barrachina-Mu\u00f1oz", "Sergio", ""], ["Bellalta", "Boris", ""], ["Cano", "Cristina", ""], ["Jonsson", "Anders", ""], ["Ram", "Vishnu", ""]]}, {"id": "1910.03564", "submitter": "Baturalp Buyukates", "authors": "Baturalp Buyukates and Sennur Ulukus", "title": "Timely Distributed Computation with Stragglers", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a status update system in which the update packets need to be\nprocessed to extract the embedded useful information. The source node sends the\nacquired information to a computation unit (CU) which consists of a master node\nand $n$ worker nodes. The master node distributes the received computation task\nto the worker nodes. Upon computation, the master node aggregates the results\nand sends them back to the source node to keep it \\emph{updated}. We\ninvestigate the age performance of uncoded and coded (repetition coded, MDS\ncoded, and multi-message MDS (MM-MDS) coded) schemes in the presence of\nstragglers under i.i.d.~exponential transmission delays and i.i.d~shifted\nexponential computation times. We show that asymptotically MM-MDS coded scheme\noutperforms the other schemes. Furthermore, we characterize the optimal codes\nsuch that the average age is minimized.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 17:52:19 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Buyukates", "Baturalp", ""], ["Ulukus", "Sennur", ""]]}, {"id": "1910.03611", "submitter": "Francesco Malandrino", "authors": "Francesco Malandrino and Carla Fabiana Chiasserini and Gil Einziger\n  and Gabriel Scalosub", "title": "Reducing Service Deployment Cost Through VNF Sharing", "comments": "IEEE/ACM Transactions on Networking. arXiv admin note: substantial\n  text overlap with arXiv:1904.00704", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to its computational and forwarding capabilities, the mobile network\ninfrastructure can support several third-party (\"vertical\") services, each\ncomposed of a graph of virtual (network) functions (VNFs). Importantly, one or\nmore VNFs are often common to multiple services, thus the services deployment\ncost could be reduced by letting the services share the same VNF instance\ninstead of devoting a separate instance to each service. By doing that,\nhowever, it is critical that the target KPI (key performance indicators) of all\nservices are met. To this end, we study the VNF sharing problem and make\ndecisions on (i) when sharing VNFs among multiple services is possible, (ii)\nhow to adapt the virtual machines running the shared VNFs to the combined load\nof the assigned services, and (iii) how to prioritize the services traffic\nwithin shared VNFs. All decisions aim to minimize the cost for the mobile\noperator, subject to requirements on end-to-end service performance, e.g.,\ntotal delay. Notably, we show that the aforementioned priorities should be\nmanaged dynamically and vary across VNFs. We then propose the FlexShare\nalgorithm to provide near-optimal VNF-sharing and priority assignment decisions\nin polynomial time. We prove that FlexShare is within a constant factor from\nthe optimum and, using real-world VNF graphs, we show that it consistently\noutperforms baseline solutions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 18:02:29 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Malandrino", "Francesco", ""], ["Chiasserini", "Carla Fabiana", ""], ["Einziger", "Gil", ""], ["Scalosub", "Gabriel", ""]]}, {"id": "1910.03811", "submitter": "Michele Polese", "authors": "Matteo Drago, Michele Polese, Stepan Kucera, Dmitry Kozlov, Vitalii\n  Kirillov, Michele Zorzi", "title": "QoS Provisioning in 60 GHz Communications by Physical and Transport\n  Layer Coordination", "comments": "To be presented at IEEE MASS 2019, 9 pages. Please cite it as Matteo\n  Drago, Michele Polese, Stepan Kucera, Dmitry Kozlov, Vitalii Kirillov,\n  Michele Zorzi, QoS Provisioning in 60 GHz Communications by Physical and\n  Transport Layer Coordination, IEEE 16th International Conference on Mobile Ad\n  Hoc and Sensor Systems (MASS), Monterey, CA, USA, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decades, technological developments in wireless communications\nhave been coupled with an increasing demand of mobile services. From real-time\napplications with focus on entertainment (e.g., high quality video streaming,\nvirtual and augmented reality), to industrial automation and security scenarios\n(e.g., video surveillance), the requirements are constantly pushing the limits\nof communication hardware and software. Communications at millimeter wave\nfrequencies could provide very high throughput and low latency, thanks to the\nlarge chunks of available bandwidth, but operating at such high frequencies\nintroduces new challenges in terms of channel reliability, which eventually\nimpact the overall end-to-end performance. In this paper, we introduce a proxy\nthat coordinates the physical and transport layers to seamlessly adapt to the\nvariable channel conditions and avoid performance degradation (i.e., latency\nspikes or low throughput). We study the performance of the proposed solution\nusing a simulated IEEE 802.11ad-compliant network, with the integration of\ninput traces generated from measurements from real devices, and show that the\nproposed proxy-based mechanism reduces the latency by up to 50% with respect to\nTCP CUBIC on a 60 GHz link.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 06:48:38 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Drago", "Matteo", ""], ["Polese", "Michele", ""], ["Kucera", "Stepan", ""], ["Kozlov", "Dmitry", ""], ["Kirillov", "Vitalii", ""], ["Zorzi", "Michele", ""]]}, {"id": "1910.03835", "submitter": "Zili Meng", "authors": "Zili Meng, Minhu Wang, Jiasong Bai, Mingwei Xu, Hongzi Mao, Hongxin Hu", "title": "Interpreting Deep Learning-Based Networking Systems", "comments": "To appear at ACM SIGCOMM 2020", "journal-ref": null, "doi": "10.1145/3387514.3405859", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many deep learning (DL)-based networking systems have demonstrated\nsuperior performance, the underlying Deep Neural Networks (DNNs) remain\nblackboxes and stay uninterpretable for network operators. The lack of\ninterpretability makes DL-based networking systems prohibitive to deploy in\npractice. In this paper, we propose Metis, a framework that provides\ninterpretability for two general categories of networking problems spanning\nlocal and global control. Accordingly, Metis introduces two different\ninterpretation methods based on decision tree and hypergraph, where it converts\nDNN policies to interpretable rule-based controllers and highlight critical\ncomponents based on analysis over hypergraph. We evaluate Metis over several\nstate-of-the-art DL-based networking systems and show that Metis provides\nhuman-readable interpretations while preserving nearly no degradation in\nperformance. We further present four concrete use cases of Metis, showcasing\nhow Metis helps network operators to design, debug, deploy, and ad-hoc adjust\nDL-based networking systems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 08:19:57 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 13:45:24 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 11:55:28 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Meng", "Zili", ""], ["Wang", "Minhu", ""], ["Bai", "Jiasong", ""], ["Xu", "Mingwei", ""], ["Mao", "Hongzi", ""], ["Hu", "Hongxin", ""]]}, {"id": "1910.04041", "submitter": "Ramy E. Ali", "authors": "Ramy E. Ali, Bilgehan Erman, Ejder Ba\\c{s}tu\\u{g} and Bruce Cilli", "title": "Hierarchical Deep Double Q-Routing", "comments": "IEEE ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.IT cs.LG cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a deep reinforcement learning approach applied to the\npacket routing problem with high-dimensional constraints instigated by dynamic\nand autonomous communication networks. Our approach is motivated by the fact\nthat centralized path calculation approaches are often not scalable, whereas\nthe distributed approaches with locally acting nodes are not fully aware of the\nend-to-end performance. We instead hierarchically distribute the path\ncalculation over designated nodes in the network while taking into account the\nend-to-end performance. Specifically, we develop a hierarchical\ncluster-oriented adaptive per-flow path calculation mechanism by leveraging the\nDeep Double Q-network (DDQN) algorithm, where the end-to-end paths are\ncalculated by the source nodes with the assistance of cluster (group) leaders\nat different hierarchical levels. In our approach, a deferred composite reward\nis designed to capture the end-to-end performance through a feedback signal\nfrom the source nodes to the group leaders and captures the local network\nperformance through the local resource assessments by the group leaders. This\napproach scales in large networks, adapts to the dynamic demand, utilizes the\nnetwork resources efficiently and can be applied to segment routing.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:03:07 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 19:15:59 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 20:41:06 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Ali", "Ramy E.", ""], ["Erman", "Bilgehan", ""], ["Ba\u015ftu\u011f", "Ejder", ""], ["Cilli", "Bruce", ""]]}, {"id": "1910.04054", "submitter": "Olivier Delalleau", "authors": "Viswanath Sivakumar, Olivier Delalleau, Tim Rockt\\\"aschel, Alexander\n  H. Miller, Heinrich K\\\"uttler, Nantas Nardelli, Mike Rabbat, Joelle Pineau,\n  Sebastian Riedel", "title": "MVFST-RL: An Asynchronous RL Framework for Congestion Control with\n  Delayed Actions", "comments": "Workshop on ML for Systems at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective network congestion control strategies are key to keeping the\nInternet (or any large computer network) operational. Network congestion\ncontrol has been dominated by hand-crafted heuristics for decades. Recently,\nReinforcementLearning (RL) has emerged as an alternative to automatically\noptimize such control strategies. Research so far has primarily considered RL\ninterfaces which block the sender while an agent considers its next action.\nThis is largely an artifact of building on top of frameworks designed for RL in\ngames (e.g. OpenAI Gym). However, this does not translate to real-world\nnetworking environments, where a network sender waiting on a policy without\nsending data leads to under-utilization of bandwidth. We instead propose to\nformulate congestion control with an asynchronous RL agent that handles delayed\nactions. We present MVFST-RL, a scalable framework for congestion control in\nthe QUIC transport protocol that leverages state-of-the-art in asynchronous RL\ntraining with off-policy correction. We analyze modeling improvements to\nmitigate the deviation from Markovian dynamics, and evaluate our method on\nemulated networks from the Pantheon benchmark platform. The source code is\npublicly available at https://github.com/facebookresearch/mvfst-rl.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:12:30 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 14:49:47 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 17:02:53 GMT"}, {"version": "v4", "created": "Wed, 26 May 2021 21:52:10 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Sivakumar", "Viswanath", ""], ["Delalleau", "Olivier", ""], ["Rockt\u00e4schel", "Tim", ""], ["Miller", "Alexander H.", ""], ["K\u00fcttler", "Heinrich", ""], ["Nardelli", "Nantas", ""], ["Rabbat", "Mike", ""], ["Pineau", "Joelle", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1910.04316", "submitter": "Muneeb Ul Hassan", "authors": "Muneeb Ul Hassan, Mubashir Husain Rehmani, Jinjun Chen", "title": "Differential Privacy in Blockchain Technology: A Futuristic Approach", "comments": "Submitted to Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain has received a widespread attention because of its decentralized,\ntamper-proof, and transparent nature. Blockchain works over the principle of\ndistributed, secured, and shared ledger, which is used to record, and track\ndata within a decentralized network. This technology has successfully replaced\ncertain systems of economic transactions in organizations and has the potential\nto overtake various industrial business models in future. Blockchain works over\npeer-to-peer (P2P) phenomenon for its operation and does not require any\ntrusted-third party authorization for data tracking and storage. The\ninformation stored in blockchain is distributed throughout the decentralized\nnetwork and is usually protected using cryptographic hash functions. Since the\nbeginning of blockchain technology, its use in different applications is\nincreasing exponentially, but this increased use has also raised some questions\nregarding privacy and security of data being stored in it. Protecting privacy\nof blockchain data using data perturbation strategy such as differential\nprivacy could be a novel approach to overcome privacy issues in blockchain. In\nthis article, we cover the topic of integration of differential privacy in each\nlayer of blockchain and in certain blockchain based scenarios. Moreover, we\nhighlight some future challenges and application scenarios in which integration\nof differential privacy in blockchain can produce fruitful results.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 01:00:07 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 10:29:22 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 11:19:31 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Hassan", "Muneeb Ul", ""], ["Rehmani", "Mubashir Husain", ""], ["Chen", "Jinjun", ""]]}, {"id": "1910.04325", "submitter": "Jonathan Adams", "authors": "Jonathan K Adams", "title": "WiFiCue: Public Wireless Access Security Assessment Tool", "comments": "SANS GIAC (GCIA) Gold Certification and RES 5500 Whitepaper, 21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public wireless access points are commonly provided by governments,\nbusinesses, schools and other organizations and provide access to the Internet\nfor numerous use cases and can present varying degrees of risk to users. While\nthere are steps that can be taken to mitigate public Wi-Fi risks, ranging from\navoidance to the application of end-to-end encryption, application specific\nencryption, and other technologies and tools, these options are not always\nviable. This paper examines risks associated with Wi-Fi from on a\nnetwork-by-network perspective. Recommender Systems are presented as part of a\nproposed mechanism for informing users of the risks of connecting to a specific\naccess point. Implementing prototype architecture for this purpose is examined.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 01:37:56 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Adams", "Jonathan K", ""]]}, {"id": "1910.04402", "submitter": "Vaibhav Kumar Gupta", "authors": "Vivek S. Borkar, Shantanu Choudhary, Vaibhav Kumar Gupta, Gaurav S.\n  Kasbekar", "title": "Scheduling in Wireless Networks with Spatial Reuse of Spectrum as\n  Restless Bandits", "comments": "Revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of scheduling packet transmissions with the aim of\nminimizing the energy consumption and data transmission delay of users in a\nwireless network in which spatial reuse of spectrum is employed. We approach\nthis problem using the theory of Whittle index for cost minimizing restless\nbandits, which has been used to effectively solve problems in a variety of\napplications. We design two Whittle index based policies the first by treating\nthe graph representing the network as a clique and the second based on\ninterference constraints derived from the original graph. We evaluate the\nperformance of these two policies via extensive simulations, in terms of\naverage cost and packets dropped, and show that they outperform the well-known\nSlotted ALOHA and maximum weight scheduling algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 07:37:11 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 06:43:42 GMT"}, {"version": "v3", "created": "Wed, 1 Jan 2020 05:04:45 GMT"}, {"version": "v4", "created": "Sat, 4 Jan 2020 05:02:02 GMT"}, {"version": "v5", "created": "Mon, 8 Jun 2020 11:16:47 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Borkar", "Vivek S.", ""], ["Choudhary", "Shantanu", ""], ["Gupta", "Vaibhav Kumar", ""], ["Kasbekar", "Gaurav S.", ""]]}, {"id": "1910.04617", "submitter": "Angelo Trotta", "authors": "Luca Sciullo, Cristiano Aguzzi, Lorenzo Gigli, Luca Roffia, Angelo\n  Trotta, Tullio Salmon Cinotti and Marco Di Felice", "title": "WoT Store: a Thing and Application Management Ecosystem for the W3C Web\n  of Things", "comments": "Second W3C Workshop on the Web of Things - The Open Web to Challenge\n  IoT Fragmentation - June 2019, Munich", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the next few years, the W3C Web of Things (WoT) platform will represent a\nreference solution toward the deployment of fully interoperable systems, hence\nunlocking the potential of the IoT paradigm on several use-cases characterized\nby the current fragmentation of devices and technologies. At the same time, the\nworlwide adoption of the W3C WoT architecture depends on many factors,\nincluding also the availability of support tools that might facilitate the\ndeployment of novel WoT applications or the integration with traditional IoT\nsystems. To this purpose, the paper presents the WoT Store, a complete software\nplatform enabling the discovery and management of W3C Things, the monitoring of\nits properties and events, and the invoking of actions, all within the same\ndashboard. In addition, the platform leverages on the semantic description of\neach Thing with the goal of easing and automatizing the installation and\nexecution of WoT applications, e.g. defining the behaviour of a Thing or\nimplementing mash-up operations from multiple Things. We sketch the main\nfeatures, the architecture and the prototypal implementation of the WoT Store.\nMoreover, we discuss the WoT Store capabilities on three IoT use-cases, i.e.\nindustry 4.0, smart agriculture and home automation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:46:26 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 16:16:35 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Sciullo", "Luca", ""], ["Aguzzi", "Cristiano", ""], ["Gigli", "Lorenzo", ""], ["Roffia", "Luca", ""], ["Trotta", "Angelo", ""], ["Cinotti", "Tullio Salmon", ""], ["Di Felice", "Marco", ""]]}, {"id": "1910.04882", "submitter": "Pritam Majumder", "authors": "Pritam Majumder, Sungkeun Kim, Jiayi Huang, Ki Hwan Yum, Eun Jung Kim", "title": "Remote Control: A Simple Deadlock Avoidance Scheme for Modular System on\n  Chip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase in design cost and complexity have motivated designers to adopt\nmodular design of System on Chip (SoC) by integrating independently designed\nsmall chiplets. However, it introduces new challenges for correctness\nvalidation, increasing chances of forming deadlock in the system involving\nmultiple chiplets. Although there have been many solutions available for\ndeadlock freedom in flat networks, the study on deadlock issue in chiplet-based\nsystems is still in its infancy. A recent study suggests adding extra turn\nrestrictions as a viable solution for this problem. However, imposing extra\nturn restrictions reduces chiplet design flexibility and interposer design\ncomplexity. In addition, it may lead to non-minimal route and traffic imbalance\nforming hotspots, resulting in high latency and low throughput.\n  We propose Remote Control (RC), a simple routing oblivious deadlock avoidance\nscheme. Our proposal is based on two key observations. First, packets with\ndestinations in the current chiplet are blocked by packets with destinations\noutside the chiplet. Second, deadlock always involves multiple boundary\nrouters. Hence, we segregate different traffics to alleviate mutual blocking at\nthe chiplet's boundary routers. Along with guarantee of deadlock freedom and\nperformance enhancements, our simple RC scheme also provides more routing\nflexibility to both chiplet and SoC designers, as compared to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 21:24:39 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Majumder", "Pritam", ""], ["Kim", "Sungkeun", ""], ["Huang", "Jiayi", ""], ["Yum", "Ki Hwan", ""], ["Kim", "Eun Jung", ""]]}, {"id": "1910.04969", "submitter": "Hamid Shiri", "authors": "Hamid Shiri, Jihong Park, Mehdi Bennis", "title": "Remote UAV Online Path Planning via Neural Network Based Opportunistic\n  Control", "comments": "5 pages, 2 figures; This work has been submitted to the IEEE for\n  possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter proposes a neural network (NN) aided remote unmanned aerial\nvehicle (UAV) online control algorithm, coined oHJB. By downloading a UAV's\nstate, a base station (BS) trains an HJB NN that solves the\nHamilton-Jacobi-Bellman equation (HJB) in real time, yielding the optimal\ncontrol action. Initially, the BS uploads this control action to the UAV. If\nthe HJB NN is sufficiently trained and the UAV is far away, the BS uploads the\nHJB NN model, enabling to locally carry out control decisions even when the\nconnection is lost. Simulations corroborate the effectiveness of oHJB in\nreducing the UAV's travel time and energy by utilizing the trade-off between\nuploading delays and control robustness in poor channel conditions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 04:40:57 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Shiri", "Hamid", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1910.05054", "submitter": "Weisi Guo", "authors": "Zhiyong Du, Yansha Deng, Weisi Guo, Arumugam Nallanathan, Qihui Wu", "title": "Green Deep Reinforcement Learning for Radio Resource Management:\n  Architecture, Algorithm Compression and Challenge", "comments": "under review in IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI heralds a step-change in the performance and capability of wireless\nnetworks and other critical infrastructures. However, it may also cause\nirreversible environmental damage due to their high energy consumption. Here,\nwe address this challenge in the context of 5G and beyond, where there is a\ncomplexity explosion in radio resource management (RRM). On the one hand, deep\nreinforcement learning (DRL) provides a powerful tool for scalable optimization\nfor high dimensional RRM problems in a dynamic environment. On the other hand,\nDRL algorithms consume a high amount of energy over time and risk compromising\nprogress made in green radio research. This paper reviews and analyzes how to\nachieve green DRL for RRM via both architecture and algorithm innovations.\nArchitecturally, a cloud based training and distributed decision-making DRL\nscheme is proposed, where RRM entities can make lightweight deep local\ndecisions whilst assisted by on-cloud training and updating. On the algorithm\nlevel, compression approaches are introduced for both deep neural networks and\nthe underlying Markov Decision Processes, enabling accurate low-dimensional\nrepresentations of challenges. To scale learning across geographic areas, a\nspatial transfer learning scheme is proposed to further promote the learning\nefficiency of distributed DRL entities by exploiting the traffic demand\ncorrelations. Together, our proposed architecture and algorithms provide a\nvision for green and on-demand DRL capability.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 09:51:15 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Du", "Zhiyong", ""], ["Deng", "Yansha", ""], ["Guo", "Weisi", ""], ["Nallanathan", "Arumugam", ""], ["Wu", "Qihui", ""]]}, {"id": "1910.05144", "submitter": "Zheng Chen", "authors": "Zheng Chen, Nikolaos Pappas, Emil Bj\\\"ornson, and Erik G. Larsson", "title": "Optimizing Information Freshness in a Multiple Access Channel with\n  Heterogeneous Devices", "comments": "13 pages, 8 figures, accepted for publication in IEEE Open Journal of\n  the Communications Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study age-optimal scheduling with stability constraints in a\nmultiple access channel with two heterogeneous source nodes transmitting to a\ncommon destination. The first node is connected to a power grid and it has\nrandomly arriving data packets. Another energy harvesting (EH) sensor monitors\na stochastic process and sends status updates to the destination. We formulate\nan optimization problem that aims at minimizing the average age of information\n(AoI) of the EH node subject to the queue stability condition of the\ngrid-connected node. First, we consider a Probabilistic Random Access (PRA)\npolicy where both nodes make independent transmission decisions based on some\nfixed probability distributions. We show that with this policy, the average AoI\nis equal to the average peak AoI, if the EH node only sends freshly generated\nsamples. In addition, we derive the optimal solution in closed form, which\nreveals some interesting properties of the considered system. Furthermore, we\nconsider a Drift-Plus-Penalty (DPP) policy and develop AoI-optimal and\npeak-AoI-optimal scheduling algorithms using the Lyapunov optimization theory.\nSimulation results show that the DPP policy outperforms the PRA policy in\nvarious scenarios, especially when the destination node has low multi-packet\nreception capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 13:39:58 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 20:41:50 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 10:45:01 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Chen", "Zheng", ""], ["Pappas", "Nikolaos", ""], ["Bj\u00f6rnson", "Emil", ""], ["Larsson", "Erik G.", ""]]}, {"id": "1910.05192", "submitter": "Myounggyu Won", "authors": "Myounggyu Won", "title": "L-Platooning: A Protocol for Managing a Long Platoon with DSRC", "comments": "Published in IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2021.3057956", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle platooning is an automated driving technology that enables a group of\nvehicles to travel very closely together as a single unit to improve fuel\nefficiency and driver safety and reduces CO2 emission. The significant benefits\nof platooning attracted huge interests from academia and industry, especially\nfrom logistics companies for utilizing platoons of \"long-body\" trailer trucks\nbecause of the huge cost savings. In this paper, we demonstrate that existing\nDSRC-based platooning solutions, however, fail to support formation of such\n\"long\" platoons consisting of typical trailer trucks because of the limited\ncommunication range of DSRC. To address this problem, we propose L-Platooning,\nthe first platooning protocol that enables seamless, reliable, and rapid\nformation of a long platoon. We introduce a novel concept called Virtual Leader\nthat refers to a vehicle that acts like a platoon leader to extend the coverage\nof the original platoon leader. A virtual leader election algorithm is\ndeveloped to effectively designate a virtual leader based on the novel metric\ncalled the Virtual Leader Quality Index (VLQI) which quantifies the\neffectiveness of a vehicle serving as a platoon leader. We also develop\nmechanisms for L-Platooning to support the vehicle join and leave maneuvers\nspecifically for a long platoon. Through extensive simulations using the\ncombination of Veins (Plexe) and SUMO, we demonstrate that L-Platooning enables\nlong-body trailer trucks to form a long platoon effectively and maintain the\ndesired inter-vehicle distance precisely. We also show that L-Platooning\nhandles seamlessly the vehicle join and leave maneuvers for a long platoon.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 13:57:51 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 22:46:41 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 21:19:13 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Won", "Myounggyu", ""]]}, {"id": "1910.05221", "submitter": "Yiding Yu", "authors": "Yiding Yu, Soung Chang Liew, Taotao Wang", "title": "Non-Uniform Time-Step Deep Q-Network for Carrier-Sense Multiple Access\n  in Heterogeneous Wireless Networks", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a new class of carrier-sense multiple access (CSMA)\nprotocols that employ deep reinforcement learning (DRL) techniques, referred to\nas carrier-sense deep-reinforcement learning multiple access (CS-DLMA). The\ngoal of CS-DLMA is to enable efficient and equitable spectrum sharing among a\ngroup of co-located heterogeneous wireless networks. Existing CSMA protocols,\nsuch as the medium access control (MAC) of WiFi, are designed for a homogeneous\nnetwork in which all nodes adopt the same protocol. Such protocols suffer from\nsevere performance degradation in a heterogeneous environment where there are\nnodes adopting other MAC protocols. CS-DLMA aims to circumvent this problem by\nmaking use of DRL. In particular, this paper adopts alpha-fairness as the\ngeneral objective of CS-DLMA. With alpha-fairness, CS-DLMA can achieve a range\nof different objectives when coexisting with other MACs by changing the value\nof alpha. A salient feature of CS-DLMA is that it can achieve these objectives\nwithout knowing the coexisting MACs through a learning process based on DRL.\nThe underpinning DRL technique in CS-DLMA is deep Q-network (DQN). However, the\nconventional DQN algorithms are not suitable for CS-DLMA due to their uniform\ntime-step assumption. In CSMA protocols, time steps are non-uniform in that the\ntime duration required for carrier sensing is smaller than the duration of data\ntransmission. This paper introduces a non-uniform time-step formulation of DQN\nto address this issue. Our simulation results show that CS-DLMA can achieve the\ngeneral alpha-fairness objective when coexisting with TDMA, ALOHA, and WiFi\nprotocols by adjusting its own transmission strategy. Interestingly, we also\nfind that CS-DLMA is more Pareto efficient than other CSMA protocols when\ncoexisting with WiFi.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 14:42:24 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Yu", "Yiding", ""], ["Liew", "Soung Chang", ""], ["Wang", "Taotao", ""]]}, {"id": "1910.05304", "submitter": "Soumen Kanrar", "authors": "Soumen Kanrar, Soamdeep Singha", "title": "Content Delivery Through Hybrid Architecture in Video on Demand System", "comments": "13 pages, 13 figures", "journal-ref": "Ingenierie des Systemes d'Information, ISSN: 1633-1311, Vol.24,\n  No.3, pp.289-301,2019", "doi": "10.18280/isi.240309", "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-Peer (P2P) network needs architectural modification for smooth and\nfast transportation of video content. The viewer imports chunk video objects\nthrough the proxy server. The enormous growth of user requests in a small\nsession of time creates huge load on the VOD system. The situation requires\neither the proxy server streamed video-content fully or partly to the viewers.\nThe missing chunk at the proxy server is imported from the connected peer\nnodes. Peers exchange chunks among themselves according to some chunk selection\npolicy. Peer node randomly contacts another peer to download a missing chunk\nfrom the buffers during each time slot. In video streaming, when the relevant\nframe is required at the viewer ends that should be available at the respective\nproxy server. The video watcher also initiates various types of interactive\noperations like a move forward or skips some finite number of frames that\ncreate congestion inside the VOD system. To elevate the situation it needs an\neffective content delivery mechanism for smooth transportation of content. The\nproposed hybrid architecture is composed of P2P and mesh architecture that\neffectively enhances the search mechanism and content transportation in the VOD\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:59:23 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Kanrar", "Soumen", ""], ["Singha", "Soamdeep", ""]]}, {"id": "1910.05305", "submitter": "Faris B Mismar", "authors": "Faris B. Mismar, Ahmad AlAmmouri, Ahmed Alkhateeb, Jeffrey G. Andrews,\n  Brian L. Evans", "title": "Deep Learning Predictive Band Switching in Wireless Networks", "comments": "31 pages, 15 figures, revised and resubmitted to IEEE Transactions on\n  Wireless Communications on October 2, 2019, March 9, 2020, July 2, 2020, and\n  September 1, 2020", "journal-ref": "2020 IEEE Transactions on Wireless Communications", "doi": "10.1109/TWC.2020.3023397", "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cellular systems, the user equipment (UE) can request a change in the\nfrequency band when its rate drops below a threshold on the current band. The\nUE is then instructed by the base station (BS) to measure the quality of\ncandidate bands, which requires a measurement gap in the data transmission,\nthus lowering the data rate. We propose an online-learning based band switching\napproach that does not require any measurement gap. Our proposed\nclassifier-based band switching policy instead exploits spatial and spectral\ncorrelation between radio frequency signals in different bands based on\nknowledge of the UE location. We focus on switching between a lower (e.g., 3.5\nGHz) band and a millimeter wave band (e.g., 28 GHz), and design and evaluate\ntwo classification models that are trained on a ray-tracing dataset. A key\ninsight is that measurement gaps are overkill, in that only the relative order\nof the bands is necessary for band selection, rather than a full channel\nestimate. Our proposed machine learning based policies achieve roughly 30%\nimprovement in mean effective rates over those of the industry standard policy,\nwhile achieving misclassification errors well below 0.5% and maintaining\nresilience against blockage uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:44:50 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 16:47:07 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 19:08:43 GMT"}, {"version": "v4", "created": "Tue, 1 Sep 2020 14:48:19 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mismar", "Faris B.", ""], ["AlAmmouri", "Ahmad", ""], ["Alkhateeb", "Ahmed", ""], ["Andrews", "Jeffrey G.", ""], ["Evans", "Brian L.", ""]]}, {"id": "1910.05306", "submitter": "Nasir Saeed", "authors": "Abdulkadir Celik, Nasir Saeed, Basem Shihada, Tareq Y. Al-Naffouri,\n  and Mohamed-Slim Alouini", "title": "A Software-Defined Opto-Acoustic Network Architecture for Internet of\n  Underwater Things", "comments": "Submitted to IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we envision a hybrid opto-acoustic network design for the\ninternet of underwater things (IoUT). Software-defined underwater networking\n(SDUN) is presented as an enabler of hybridizing benefits of optic and acoustic\nsystems and adapting IoUT nodes to the challenging and dynamically changing\nunderwater environment. We explain inextricably interwoven relations among\nfunctionalities of different layers and analyze their impacts on key network\nattributes. Network function virtualization (NFV) concept is then introduced to\nrealize application specific cross-layer protocol suites through an NFV\nmanagement and orchestration system. We finally discuss how SDUN and NFV can\nslice available network resources as per the diverging service demands of\ndifferent underwater applications. Such a revolutionary architectural paradigm\nshift is not only a cure for chronicle underwater networking problems but also\na way of smoothly integrating IoUT and IoT ecosystems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 12:40:14 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Celik", "Abdulkadir", ""], ["Saeed", "Nasir", ""], ["Shihada", "Basem", ""], ["Al-Naffouri", "Tareq Y.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1910.05307", "submitter": "Shadha Tabatabai", "authors": "Shadha Tabatabai, Ihab Mohammed, Ala Al-Fuqaha, and Junaid Qadir", "title": "Opportunistic Selection of Vehicular Data Brokers as Relay Nodes to the\n  Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) revolution and the development of smart\ncommunities have resulted in increased demand for bandwidth due to the rise in\nnetwork traffic. Instead of investing in expensive communications\ninfrastructure, some researchers have proposed leveraging Vehicular Ad-Hoc\nNetworks (VANETs) as the data communications infrastructure. However VANETs are\nnot cheap since they require the deployment of expensive Road Side Units (RSU)s\nacross smart communities. In this research, we propose an infrastructure-less\nsystem that opportunistically utilizes vehicles to serve as Local Community\nBrokers (LCBs) that effectively substitute RSUs for managing communications\nbetween smart devices and the cloud in support of smart community applications.\nWe propose an opportunistic algorithm that strives to select vehicles in order\nto maximize the LCBs' service time. The proposed opportunistic algorithm\nutilizes an ensemble of online selection algorithms by running all of them\ntogether in passive mode and selecting the one that has performed the best in\nrecent history. We evaluate our proposed algorithm using a dataset comprising\nreal taxi traces from the city of Shanghai in China and compare our algorithm\nagainst a baseline of 9 Threshold Based Online (TBO) algorithms. A number of\nexperiments are conducted and our results indicate that the proposed algorithm\nachieves up to 87% more service time with up to 10% fewer vehicle selections\ncompared to the best-performing existing TBO online algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 19:13:41 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Tabatabai", "Shadha", ""], ["Mohammed", "Ihab", ""], ["Al-Fuqaha", "Ala", ""], ["Qadir", "Junaid", ""]]}, {"id": "1910.05308", "submitter": "Mahadesh Panju", "authors": "Ramkumar Raghu, Pratheek Upadhyaya, Mahadesh Panju, Vaneet Aggarwal,\n  Vinod Sharma", "title": "Deep Reinforcement Learning Based Power control for Wireless Multicast\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multicast scheme recently proposed for a wireless downlink in\n[1]. It was shown earlier that power control can significantly improve its\nperformance. However for this system, obtaining optimal power control is\nintractable because of a very large state space. Therefore in this paper we use\ndeep reinforcement learning where we use function approximation of the\nQ-function via a deep neural network. We show that optimal power control can be\nlearnt for reasonably large systems via this approach. The average power\nconstraint is ensured via a Lagrange multiplier, which is also learnt. Finally,\nwe demonstrate that a slight modification of the learning algorithm allows the\noptimal control to track the time varying system statistics.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:08:09 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 01:12:09 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Raghu", "Ramkumar", ""], ["Upadhyaya", "Pratheek", ""], ["Panju", "Mahadesh", ""], ["Aggarwal", "Vaneet", ""], ["Sharma", "Vinod", ""]]}, {"id": "1910.05309", "submitter": "Chuan-Chi Lai", "authors": "Li-Chun Wang, Chuan-Chi Lai, Hong-Han Shuai, Hsin-Piao Lin, Chi-Yu Li,\n  Teng-Hu Cheng, Chiun-Hsun Chen", "title": "Communications and Networking Technologies for Intelligent Drone\n  Cruisers", "comments": "6 pages, 11 figures, accepted by 2019 IEEE Globecom Workshops (GC\n  Wkshps): IEEE GLOBECOM 2019 Workshop on Space-Ground Integrated Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future mobile communication networks require an Aerial Base Station (ABS)\nwith fast mobility and long-term hovering capabilities. At present, unmanned\naerial vehicles (UAV) or drones do not have long flight times and are mainly\nused for monitoring, surveillance, and image post-processing. On the other\nhand, the traditional airship is too large and not easy to take off and land.\nTherefore, we propose to develop an \"Artificial Intelligence (AI)\nDrone-Cruiser\" base station that can help 5G mobile communication systems and\nbeyond quickly recover the network after a disaster and handle the instant\ncommunications by the flash crowd. The drone-cruiser base station can overcome\nthe communications problem for three types of flash crowds, such as in\nstadiums, parades, and large plaza so that an appropriate number of aerial base\nstations can be accurately deployed to meet large and dynamic traffic demands.\nArtificial intelligence can solve these problems by analyzing the collected\ndata, and then adjust the system parameters in the framework of Self-Organizing\nNetwork (SON) to achieve the goals of self-configuration, self-optimization,\nand self-healing. With the help of AI technologies, 5G networks can become more\nintelligent. This paper aims to provide a new type of service, On-Demand Aerial\nBase Station as a Service. This work needs to overcome the following five\ntechnical challenges: innovative design of drone-cruisers for the long-time\nhovering, crowd estimation and prediction, rapid 3D wireless channel learning\nand modeling, 3D placement of aerial base stations and the integration of WiFi\nfront-haul and millimeter wave/WiGig back-haul networks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:22:29 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Wang", "Li-Chun", ""], ["Lai", "Chuan-Chi", ""], ["Shuai", "Hong-Han", ""], ["Lin", "Hsin-Piao", ""], ["Li", "Chi-Yu", ""], ["Cheng", "Teng-Hu", ""], ["Chen", "Chiun-Hsun", ""]]}, {"id": "1910.05310", "submitter": "Tu Nguyen", "authors": "Bing-Hong Liu, Van-Trung Pham, Tu N. Nguyen, Yi-Sheng Luo", "title": "A Heuristic for Maximizing the Lifetime of Data Aggregation in Wireless\n  Sensor Networks", "comments": "International Congress on Engineering and Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many researchers have studied efficiently gathering data in\nwireless sensor networks to minimize the total energy consumption when a fixed\nnumber of data are allowed to be aggregated into one packet. However,\nminimizing the total energy consumption does not imply the network lifetime is\nmaximized. In this paper, we study the problem of scheduling data aggregation\ntrees working for different time periods to maximize the network lifetime when\na fixed number of data are allowed to be aggregated into one packet. In\naddition, we propose a heuristic to balance the lifetime of nodes in data\naggregation trees such that the network lifetime is maximized. Simulation\nresults show that the proposed heuristic provides a good performance.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 03:20:14 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Liu", "Bing-Hong", ""], ["Pham", "Van-Trung", ""], ["Nguyen", "Tu N.", ""], ["Luo", "Yi-Sheng", ""]]}, {"id": "1910.05312", "submitter": "David Fiedler", "authors": "David Fiedler, Michal \\v{C}\\'ap, Jan Nykl, Pavol \\v{Z}ileck\\'y, and\n  Martin Schaefer", "title": "Map Matching Algorithm for Large-scale Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPS receivers embedded in cell phones and connected vehicles generate a\nseries of location measurements that can be used for various analytical\npurposes. A common pre-processing step of this data is the so-called map\nmatching. The goal of map matching is to infer the trajectory that the device\nfollowed in a road network from a potentially sparse series of noisy location\nmeasurements. Although accurate and robust map matching algorithms based on\nprobabilistic models exist, they are computationally heavy and thus impractical\nfor processing of large datasets. In this paper, we present a scalable\nmap-matching algorithm based on Dijkstra shortest path method, that is both\naccurate and applicable to large datasets. Our experiments on a\npublicly-available dataset showed that the proposed method achieves accuracy\nthat is comparable to that of the existing map matching methods using only a\nfraction of computational resources. In result, our algorithm can be used to\nefficiently process large datasets of noisy and potentially sparse location\ndata that would be unexploitable using existing techniques due to their high\ncomputational requirements.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 13:49:32 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Fiedler", "David", ""], ["\u010c\u00e1p", "Michal", ""], ["Nykl", "Jan", ""], ["\u017dileck\u00fd", "Pavol", ""], ["Schaefer", "Martin", ""]]}, {"id": "1910.05314", "submitter": "Florian Geissler", "authors": "Florian Geissler and Ralf Graefe", "title": "Optimized sensor placement for dependable roadside infrastructures", "comments": "6 pages, 5 figures; IEEE Intelligent transportation systems\n  conference 2019", "journal-ref": "2019 IEEE Intelligent Transportation Systems Conference (ITSC)", "doi": "10.1109/ITSC.2019.8917197", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-stage optimization method for efficient sensor deployment\nin traffic surveillance scenarios. Based on a genetic optimization scheme, our\nalgorithm places an optimal number of roadside sensors to obtain full road\ncoverage in the presence of obstacles and dynamic occlusions. The efficiency of\nthe procedure is demonstrated for selected, realistic road sections. Our\nanalysis helps to leverage the economic feasibility of distributed\ninfrastructure sensor networks with high perception quality.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 13:25:07 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Geissler", "Florian", ""], ["Graefe", "Ralf", ""]]}, {"id": "1910.05316", "submitter": "Xu Chen", "authors": "En Li and Liekang Zeng and Zhi Zhou and Xu Chen", "title": "Edge AI: On-Demand Accelerating Deep Neural Network Inference via Edge\n  Computing", "comments": "Accepted by IEEE Transactions on Wireless Communications, Sept 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a key technology of enabling Artificial Intelligence (AI) applications in\n5G era, Deep Neural Networks (DNNs) have quickly attracted widespread\nattention. However, it is challenging to run computation-intensive DNN-based\ntasks on mobile devices due to the limited computation resources. What's worse,\ntraditional cloud-assisted DNN inference is heavily hindered by the significant\nwide-area network latency, leading to poor real-time performance as well as low\nquality of user experience. To address these challenges, in this paper, we\npropose Edgent, a framework that leverages edge computing for DNN collaborative\ninference through device-edge synergy. Edgent exploits two design knobs: (1)\nDNN partitioning that adaptively partitions computation between device and edge\nfor purpose of coordinating the powerful cloud resource and the proximal edge\nresource for real-time DNN inference; (2) DNN right-sizing that further reduces\ncomputing latency via early exiting inference at an appropriate intermediate\nDNN layer. In addition, considering the potential network fluctuation in\nreal-world deployment, Edgentis properly design to specialize for both static\nand dynamic network environment. Specifically, in a static environment where\nthe bandwidth changes slowly, Edgent derives the best configurations with the\nassist of regression-based prediction models, while in a dynamic environment\nwhere the bandwidth varies dramatically, Edgent generates the best execution\nplan through the online change point detection algorithm that maps the current\nbandwidth state to the optimal configuration. We implement Edgent prototype\nbased on the Raspberry Pi and the desktop PC and the extensive experimental\nevaluations demonstrate Edgent's effectiveness in enabling on-demand\nlow-latency edge intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 00:53:44 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Li", "En", ""], ["Zeng", "Liekang", ""], ["Zhou", "Zhi", ""], ["Chen", "Xu", ""]]}, {"id": "1910.05317", "submitter": "Samar Elaraby", "authors": "Samar Elaraby and Sherif M. Abuelenin", "title": "Fading Improves Connectivity in Vehicular Ad-hoc Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectivity analysis is a crucial metric for network performance in\nvehicular ad-hoc networks (VANETs). Although VANET connectivity has been\nintensively studied and investigated under no-fading channel models for their\nsimplicity, these models do not represent real-world scenarios that suffer\nchannel impairments. The connectivity probability in a multipath propagation\nenvironment is too challenging to be caught by a closed formula due to the\nemerging complexity associated with the randomness in a fading channel. This\nleads to contradicting statements about the impact of fading on VANET\nconnectivity. In this paper, we numerically estimate the connectivity\nprobability using graph-based Monte-Carlo simulations aiming for better\nunderstanding of the connectivity in fading channels. The results show that\nRayleigh-fading channels reinforce the connectivity compared to no-fading\nmodels at the same level of transmitting power and vehicle densities. While\nthese findings may seem counterintuitive, they agree with similar behavior that\nwas reported earlier in other ad-hoc networks. Using simulations and stochastic\nanalysis, we thoroughly investigate this effect and provide an intuitive\ninterpretation of the positive impact of fading on connectivity.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 22:37:30 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 01:39:35 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Elaraby", "Samar", ""], ["Abuelenin", "Sherif M.", ""]]}, {"id": "1910.05433", "submitter": "Jie Su", "authors": "Bin Qian, Jie Su, Zhenyu Wen, Devki Nandan Jha, Yinhao Li, Yu Guan,\n  Deepak Puthal, Philip James, Renyu Yang, Albert Y. Zomaya, Omer Rana, Lizhe\n  Wang, Maciej Koutny, Rajiv Ranjan", "title": "Orchestrating the Development Lifecycle of Machine Learning-Based IoT\n  Applications: A Taxonomy and Survey", "comments": "50 pages, Accepted by ACM Computing Surveys (CSUR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) and Internet of Things (IoT) are complementary\nadvances: ML techniques unlock complete potentials of IoT with intelligence,\nand IoT applications increasingly feed data collected by sensors into ML\nmodels, thereby employing results to improve their business processes and\nservices. Hence, orchestrating ML pipelines that encompasses model training and\nimplication involved in holistic development lifecycle of an IoT application\noften leads to complex system integration. This paper provides a comprehensive\nand systematic survey on the development lifecycle of ML-based IoT application.\nWe outline core roadmap and taxonomy, and subsequently assess and compare\nexisting standard techniques used in individual stage.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 23:04:22 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 10:44:31 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 11:54:30 GMT"}, {"version": "v4", "created": "Sat, 9 May 2020 13:36:49 GMT"}, {"version": "v5", "created": "Fri, 29 May 2020 21:59:18 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Qian", "Bin", ""], ["Su", "Jie", ""], ["Wen", "Zhenyu", ""], ["Jha", "Devki Nandan", ""], ["Li", "Yinhao", ""], ["Guan", "Yu", ""], ["Puthal", "Deepak", ""], ["James", "Philip", ""], ["Yang", "Renyu", ""], ["Zomaya", "Albert Y.", ""], ["Rana", "Omer", ""], ["Wang", "Lizhe", ""], ["Koutny", "Maciej", ""], ["Ranjan", "Rajiv", ""]]}, {"id": "1910.05510", "submitter": "Ahmed Ahmed", "authors": "Ahmed B.Zaky, Joshua Zhexue Huang, KaishunWu and Basem M.ElHalawany", "title": "Generative Neural Network based Spectrum Sharing using Linear Sum\n  Assignment Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectrum management and resource allocation (RA) problems are challenging and\ncritical in a vast number of research areas such as wireless communications and\ncomputer networks. The traditional approaches for solving such problems usually\nconsume time and memory, especially for large size problems. Recently different\nmachine learning approaches have been considered as potential promising\ntechniques for combinatorial optimization problems, especially the generative\nmodel of the deep neural networks. In this work, we propose a resource\nallocation deep autoencoder network, as one of the promising generative models,\nfor enabling spectrum sharing in underlay device-to-device (D2D) communication\nby solving linear sum assignment problems (LSAPs). Specifically, we investigate\nthe performance of three different architectures for the conditional\nvariational autoencoders (CVAE). The three proposed architecture are the\nconvolutional neural network (CVAE-CNN) autoencoder, the feed-forward neural\nnetwork (CVAE-FNN) autoencoder, and the hybrid (H-CVAE) autoencoder. The\nsimulation results show that the proposed approach could be used as a\nreplacement of the conventional RA techniques, such as the Hungarian algorithm,\ndue to its ability to find solutions of LASPs of different sizes with high\naccuracy and very fast execution time. Moreover, the simulation results reveal\nthat the accuracy of the proposed hybrid autoencoder architecture outperforms\nthe other proposed architectures and the state-of-the-art DNN techniques.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 07:05:07 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Zaky", "Ahmed B.", ""], ["Huang", "Joshua Zhexue", ""], ["KaishunWu", "", ""], ["ElHalawany", "Basem M.", ""]]}, {"id": "1910.05578", "submitter": "Xijun Wang", "authors": "Chao Xu, Howard H. Yang, Xijun Wang, Tony Q. S. Quek", "title": "Optimizing Information Freshness in Computing enabled IoT Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2019.2947419", "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) has emerged as one of the key features of the next\ngeneration wireless networks, where timely delivery of status update packets is\nessential for many real-time IoT applications. To provide users with\ncontext-aware services and lighten the transmission burden, the raw data\nusually needs to be preprocessed before being transmitted to the destination.\nHowever, the effect of computing on the overall information freshness is not\nwell understood. In this work, we first develop an analytical framework to\ninvestigate the information freshness, in terms of peak age of information\n(PAoI), of a computing enabled IoT system with multiple sensors. Specifically,\nwe model the procedure of computing and transmission as a tandem queue, and\nderive the analytical expressions of the average PAoI for different sensors.\nBased on the theoretical results, we formulate a min-max optimization problem\nto minimize the maximum average PAoI of different sensors. We further design a\nderivative-free algorithm to find the optimal updating frequency, with which\nthe complexity for checking the convexity of the formulated problem or\nobtaining the derivatives of the object function can be largely reduced. The\naccuracy of our analysis and effectiveness of the proposed algorithm are\nverified with extensive simulation results.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 15:32:41 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xu", "Chao", ""], ["Yang", "Howard H.", ""], ["Wang", "Xijun", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "1910.05647", "submitter": "Haim Levy", "authors": "Anat Bremler-Barr, Haim Levy, Zohar Yakhini", "title": "IoT or NoT: Identifying IoT Devices in a ShortTime Scale", "comments": "9 pages in total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years the number of IoT devices in home networks has increased\ndramatically. Whenever a new device connects to the network, it must be quickly\nmanaged and secured using the relevant security mechanism or QoS policy. Thus a\nkey challenge is to distinguish between IoT and NoT devices in a matter of\nminutes. Unfortunately, there is no clear indication of whether a device in a\nnetwork is an IoT. In this paper, we propose different classifiers that\nidentify a device as IoT or non-IoT, in a short time scale, and with high\naccuracy.\n  Our classifiers were constructed using machine learning techniques on a seen\n(training) dataset and were tested on an unseen (test) dataset. They\nsuccessfully classified devices that were not in the seen dataset with accuracy\nabove 95%. The first classifier is a logistic regression classifier based on\ntraffic features. The second classifier is based on features we retrieve from\nDHCP packets. Finally, we present a unified classifier that leverages the\nadvantages of the other two classifiers. We focus on the home-network\nenvironment, but our classifiers are also applicable to enterprise networks.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 21:33:09 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Bremler-Barr", "Anat", ""], ["Levy", "Haim", ""], ["Yakhini", "Zohar", ""]]}, {"id": "1910.05765", "submitter": "Tugba Erpek", "authors": "Sohraab Soltani, Yalin E. Sagduyu, Raqibul Hasan, Kemal Davaslioglu,\n  Hongmei Deng, Tugba Erpek", "title": "Real-Time and Embedded Deep Learning on FPGA for RF Signal\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We designed and implemented a deep learning based RF signal classifier on the\nField Programmable Gate Array (FPGA) of an embedded software-defined radio\nplatform, DeepRadio, that classifies the signals received through the RF front\nend to different modulation types in real time and with low power. This\nclassifier implementation successfully captures complex characteristics of\nwireless signals to serve critical applications in wireless security and\ncommunications systems such as identifying spoofing signals in signal\nauthentication systems, detecting target emitters and jammers in electronic\nwarfare (EW) applications, discriminating primary and secondary users in\ncognitive radio networks, interference hunting, and adaptive modulation.\nEmpowered by low-power and low-latency embedded computing, the deep neural\nnetwork runs directly on the FPGA fabric of DeepRadio, while maintaining\nclassifier accuracy close to the software performance. We evaluated the\nperformance when another SDR (USRP) transmits signals with different modulation\ntypes at different power levels and DeepRadio receives the signals and\nclassifies them in real time on its FPGA. A smartphone with a mobile app is\nconnected to DeepRadio to initiate the experiment and visualize the\nclassification results. With real radio transmissions over the air, we show\nthat the classifier implemented on DeepRadio achieves high accuracy with low\nlatency (microsecond per sample) and low energy consumption (microJoule per\nsample), and this performance is not matched by other embedded platforms such\nas embedded graphics processing unit (GPU).\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 15:01:56 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Soltani", "Sohraab", ""], ["Sagduyu", "Yalin E.", ""], ["Hasan", "Raqibul", ""], ["Davaslioglu", "Kemal", ""], ["Deng", "Hongmei", ""], ["Erpek", "Tugba", ""]]}, {"id": "1910.05766", "submitter": "Tugba Erpek", "authors": "Nof Abuzainab, Tugba Erpek, Kemal Davaslioglu, Yalin E. Sagduyu, Yi\n  Shi, Sharon J. Mackey, Mitesh Patel, Frank Panettieri, Muhammad A. Qureshi,\n  Volkan Isler, Aylin Yener", "title": "QoS and Jamming-Aware Wireless Networking Using Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of quality of service (QoS) and jamming-aware communications is\nconsidered in an adversarial wireless network subject to external eavesdropping\nand jamming attacks. To ensure robust communication against jamming, an\ninterference-aware routing protocol is developed that allows nodes to avoid\ncommunication holes created by jamming attacks. Then, a distributed cooperation\nframework, based on deep reinforcement learning, is proposed that allows nodes\nto assess network conditions and make deep learning-driven, distributed, and\nreal-time decisions on whether to participate in data communications, defend\nthe network against jamming and eavesdropping attacks, or jam other\ntransmissions. The objective is to maximize the network performance that\nincorporates throughput, energy efficiency, delay, and security metrics.\nSimulation results show that the proposed jamming-aware routing approach is\nrobust against jamming and when throughput is prioritized, the proposed deep\nreinforcement learning approach can achieve significant (measured as\nthree-fold) increase in throughput, compared to a benchmark policy with fixed\nroles assigned to nodes.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 15:10:53 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Abuzainab", "Nof", ""], ["Erpek", "Tugba", ""], ["Davaslioglu", "Kemal", ""], ["Sagduyu", "Yalin E.", ""], ["Shi", "Yi", ""], ["Mackey", "Sharon J.", ""], ["Patel", "Mitesh", ""], ["Panettieri", "Frank", ""], ["Qureshi", "Muhammad A.", ""], ["Isler", "Volkan", ""], ["Yener", "Aylin", ""]]}, {"id": "1910.05783", "submitter": "Jaafar Elmirghani", "authors": "Haider Qays Al-Shammari, Ahmed Lawey, Taisir El-Gorashi and Jaafar M.\n  H. Elmirghani", "title": "Resilient Service Embedding In IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) has been applied to a large number of\nheterogeneous devices and is used in the deployment of a variety of\napplications on the basis of its distributed open architecture. The majority of\nthese IoT devices are battery-powered and are interconnected via a wireless\nnetwork. IoT devices may be used to carry out critical tasks. Thus, the IoT\nnetwork requires a resilient architecture that supports semantic search,\nfailure discovery, data recovery, and dynamic and autonomous network\nmaintenance. In this paper, we present a new resilience scheme for IoT\nnetworks. We evaluate the proposed scheme in terms of its power consumption and\ndata delivery time, and then compare the results with those of recent\nresilience schemes such as schemes based on redundancy and replication. The\nproposed framework was optimized using mixed integer linear programming and\nreal-time heuristics were developed, thus embedding a virtual layer into a\nphysical layer based on a service-oriented architecture (SOA). The proposed\nframework offers different combinations of packet resilience in terms of\nrecovering the lost data by using end- to-end mechanisms. We further analyzed\nthese schemes by investigating the power consumption, data delivery time, and\nnetwork overhead of these techniques. The results showed that the proposed\nsplitting technique enhanced the network performance by reducing the power\nconsumption and the data delivery time of service embedding by selecting\nenergy-efficient nodes and routes in IoT networks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 16:27:39 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Al-Shammari", "Haider Qays", ""], ["Lawey", "Ahmed", ""], ["El-Gorashi", "Taisir", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "1910.06258", "submitter": "Emil Saucan", "authors": "Emil Saucan, Areejit Samal and J\\\"urgen Jost", "title": "A Simple Differential Geometry for Networks and its Generalizations", "comments": "15 pages, 3 figures, To be appear in Proceedings of COMPLEX NETWORKS\n  COMPLEX NETWORKS AND THEIR APPLICATIONS VIII", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.NI cs.SI math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on two classical notions of curvature for curves in general metric\nspaces, namely the Menger and Haantjes curvatures, we introduce new definitions\nof sectional, Ricci and scalar curvature for networks and their higher\ndimensional counterparts. These new types of curvature, that apply to weighted\nand unweighted, directed or undirected networks, are far more intuitive and\neasier to compute, than other network curvatures. In particular, the proposed\ncurvatures based on the interpretation of Haantjes definition as geodesic\ncurvature, and derived via a fitting discrete Gauss-Bonnet Theorem, are quite\nflexible. We also propose even simpler and more intuitive substitutes of the\nHaantjes curvature, that allow for even faster and easier computations in\nlarge-scale networks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:37:29 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Saucan", "Emil", ""], ["Samal", "Areejit", ""], ["Jost", "J\u00fcrgen", ""]]}, {"id": "1910.06295", "submitter": "Florian Jacob", "authors": "Florian Jacob, Jan Grash\\\"ofer, Hannes Hartenstein", "title": "A Glimpse of the Matrix (Extended Version): Scalability Issues of a New\n  Message-Oriented Data Synchronization Middleware", "comments": "Extended tech report of the Poster Abstract\n  https://doi.org/10.1145/3366627.3368106 from Middleware 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Matrix is a new message-oriented data synchronization middleware, used as a\nfederated platform for near real-time decentralized applications. It features a\nnovel approach for inter-server communication based on synchronizing message\nhistory by using a replicated data structure. We measured the structure of\npublic parts in the Matrix federation as a basis to analyze the middleware's\nscalability. We confirm that users are currently cumulated on a single large\nserver, but find more small servers than expected. We then analyze network load\ndistribution in the measured structure and identify scalability issues of\nMatrix' group communication mechanism in structurally diverse federations.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 17:24:50 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 11:54:50 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Jacob", "Florian", ""], ["Grash\u00f6fer", "Jan", ""], ["Hartenstein", "Hannes", ""]]}, {"id": "1910.06299", "submitter": "Gamal Sallam", "authors": "Gamal Sallam, Zizhan Zheng, Bo Ji", "title": "Placement and Allocation of Virtual Network Functions: Multi-dimensional\n  Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network function virtualization (NFV) is an emerging design paradigm that\nreplaces physical middlebox devices with software modules running on general\npurpose commodity servers. While gradually transitioning to NFV, Internet\nservice providers face the problem of where to introduce NFV in order to make\nthe most benefit of that; here, we measure the benefit by the amount of traffic\nthat can be served in an NFV-enabled network. This problem is non-trivial as it\nis composed of two challenging subproblems: 1) placement of nodes to support\nvirtual network functions (referred to as VNF-nodes); 2) allocation of the\nVNF-nodes' resources to network flows. This problem has been studied for the\none-dimensional setting, where all network flows require one network function,\nwhich requires a unit of resource to process a unit of flow. In this work, we\nconsider the multi-dimensional setting, where flows can require multiple\nnetwork functions, which can also require a different amount of each resource\nto process a unit of flow. The multi-dimensional setting introduces new\nchallenges in addition to those of the one-dimensional setting (e.g.,\nNP-hardness and non-submodularity) and also makes the resource allocation\nsubproblem a multi-dimensional generalization of the generalized assignment\nproblem with assignment restrictions. To address these difficulties, we propose\na novel two-level relaxation method that allows us to draw a connection to the\nsequence submodular theory and utilize the property of sequence submodularity\nalong with the primal-dual technique to design two approximation algorithms. We\nfurther prove that the proposed algorithms have a non-trivial approximation\nratio that depends on the number of VNF-nodes, resources, and a measure of the\navailable resource compared to flow demand. Finally, we perform extensive\ntrace-driven simulations to show the effectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 17:27:59 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 22:39:43 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Sallam", "Gamal", ""], ["Zheng", "Zizhan", ""], ["Ji", "Bo", ""]]}, {"id": "1910.06619", "submitter": "Mahwish Amjad", "authors": "Mahwish Amjad and Faisal Iradat", "title": "An Active Network-Based Open Framework for IoT", "comments": "First we would like to implement the proposed technique", "journal-ref": "Wireless Communications and Mobile Computing Wireless\n  Communications and Mobile Computing, Volume 2019, Article ID 5741708, 8 pages", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Major benefits of wireless sensor nodes of IoT like low cost and easy\ndeployment are advocating their usage in variety of applications. Some of them\nare health monitoring, agriculture, environmental and habitant monitoring, and\nwater monitoring. These nodes are autonomous in nature. It follows that they\nlike to operate in a dynamic and adaptive network environment. So, the\ncommunication mechanism between IoT nodes must be robust and adaptive with\nrespect to the environmental change. Unfortunately, the traditional networking\narchitecture supports limited and fixed network computations. These limitations\ninhibit flexible and robust IoT nodes communication. In addition, the energy\nconsumption in communication nodes is high due to limited processing. To\naddress these issues, this paper gives rebirth to the active system. The\nproposed active network framework brings a novel integration of the active\nsystem with recent technologies (software-defined networking and network\nfunction virtualization). As a result of integration, the active system runs as\na network function virtualization under the control of software-defined\nnetworking. In our view, the amalgam of recent technologies with the active\nsystem will promote a robust and flexible IoT nodes communication along with\nreduced energy consumption. Moreover, various design benefits such as security,\nflexibility, usability, cost, and performance will be added to the system.\nAdditionally, the proposed framework is open and generalized. It can be\nextended to other networks such as mobile, satellite, and vehicular networks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 09:43:32 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 05:59:32 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 19:09:50 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Amjad", "Mahwish", ""], ["Iradat", "Faisal", ""]]}, {"id": "1910.06895", "submitter": "Yuedong Xu", "authors": "Zhihui Gao and Yunfan Gao and Sulei Wang and Dan Li and Yuedong Xu", "title": "CRISLoc: Reconstructable CSI Fingerprintingfor Indoor Smartphone\n  Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel state information (CSI) based fingerprinting for WIFI indoor\nlocalization has attracted lots of attention very recently.The frequency\ndiverse and temporally stable CSI better represents the location dependent\nchannel characteristics than the coarsereceived signal strength (RSS). However,\nthe acquisition of CSI requires the cooperation of access points (APs) and\ninvolves only dataframes, which imposes restrictions on real-world deployment.\nIn this paper, we present CRISLoc, the first CSI fingerprinting\nbasedlocalization prototype system using ubiquitous smartphones. CRISLoc\noperates in a completely passive mode, overhearing thepackets on-the-fly for\nhis own CSI acquisition. The smartphone CSI is sanitized via calibrating the\ndistortion enforced by WiFi amplifiercircuits. CRISLoc tackles the challenge of\naltered APs with a joint clustering and outlier detection method to find them.\nA novel transferlearning approach is proposed to reconstruct the\nhigh-dimensional CSI fingerprint database on the basis of the outdated\nfingerprintsand a few fresh measurements, and an enhanced KNN approach is\nproposed to pinpoint the location of a smartphone. Our studyreveals important\nproperties about the stability and sensitivity of smartphone CSI that has not\nbeen reported previously. Experimentalresults show that CRISLoc can achieve a\nmean error of around 0.29m in a6m times 8mresearch laboratory. The mean error\nincreases by 5.4 cm and 8.6 cm upon the movement of one and two APs, which\nvalidates the robustness of CRISLoc against environment changes.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 16:09:41 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 12:25:47 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gao", "Zhihui", ""], ["Gao", "Yunfan", ""], ["Wang", "Sulei", ""], ["Li", "Dan", ""], ["Xu", "Yuedong", ""]]}, {"id": "1910.06898", "submitter": "Mahdi Miraz", "authors": "Mahdi H. Miraz", "title": "Blockchain of Things (BCoT): The Fusion of Blockchain and IoT\n  Technologies", "comments": null, "journal-ref": "Blockchain of Things (BCoT): The Fusion of Blockchain and IoT\n  Technologies. In: Advanced Applications of Blockchain Technology. Studies in\n  Big Data, vol 60, Chapter 7, DOI: 10.1007/978-981-13-8775-3_7, 2019, Springer\n  Nature", "doi": "10.1007/978-981-13-8775-3_7", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain, as well as Internet of Things (IoT), is considered as two major\ndisruptive emerging technologies. However, both of them suffer from innate\ntechnological limitations to some extent. IoT requires strengthening its\nsecurity features while Blockchain inherently possesses them due to its\nextensive use of cryptographic mechanisms and Blockchain, in an inverted\nmanner, needs contributions from the distributed nodes for its P2P\n(Peer-to-Peer) consensus model while IoT rudimentarily embodies them within its\narchitecture. This chapter, therefore, acutely dissects the viability, along\nwith prospective challenges, of incorporating Blockchain with IoT\ntechnologies,inducing the notion of Blockchain of Things (BCoT), as well as the\nbenefits such consolidation can offer.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 03:31:01 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Miraz", "Mahdi H.", ""]]}, {"id": "1910.07187", "submitter": "Yong Niu", "authors": "Yibing Wang, Yong Niu, Hao Wu, Zhu Han, Bo Ai, Qi Wang", "title": "Sub-Channel Allocation for Device-to-Device Underlaying Full-Duplex\n  mmWave Small Cells using Coalition Formation Games", "comments": "15 pages, 11 figures, IEEE Transactions on Vehicular Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The small cells in millimeter wave (mmWave) have been utilized extensively\nfor the fifth generation (5G) mobile networks. And full-duplex (FD)\ncommunications become possible with the development of self-interference (SI)\ncancellation technology. In this paper, we focus on the optimal allocation of\nthe sub-channels in the small cells deployed densely underlying the mmWave\nnetworks. In order to improve the resource utilization and network capacity,\ndevice-to-device (D2D) communications are adopted in networks. For maximizing\nthe system throughput, we propose a cooperative sub-channel allocation approach\nbased on coalition formation game, and theoretically prove the convergence of\nthe proposed allocation algorithm. The utility of the coalition formation game\nis closely related to the sum system throughput in this paper, and each link\nmakes an individual decision to leave or join any coalition based on the\nprinciple of maximizing the utility. Besides, a threshold of the minimum\ntransmission rate is given to improve the system fairness. Through extensive\nsimulations, we demonstrate that our proposed scheme has a near-optimal\nperformance on sum throughput. In addition, we verify the low complexity of the\nproposed scheme by simulating the number of switch operations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 06:36:29 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Wang", "Yibing", ""], ["Niu", "Yong", ""], ["Wu", "Hao", ""], ["Han", "Zhu", ""], ["Ai", "Bo", ""], ["Wang", "Qi", ""]]}, {"id": "1910.07193", "submitter": "Yiqiang Sheng", "authors": "Yiqiang Sheng", "title": "Scalable Intelligence-Enabled Networking with Traffic Engineering in 5G\n  Scenarios for Future Audio-Visual-Tactile Internet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to improve future network performance, this paper proposes scalable\nintelligence-enabled networking (SIEN) with eliminating traffic redundancy for\naudio-visual-tactile Internet in 5G scenarios such as enhanced mobile\nbroadband, ultra-reliable and low latency communication, and massive\nmachine-type communication. The SIEN consists of an intelligent management\nplane (ImP), an intelligence-enabled plane (IeP), a control plane and a user\nplane. For the ImP, the containers with decision execution are constructed by a\nnovel graph algorithm to organize objects such as network elements and resource\npartitions. For the IeP, a novel learning system is designed with decision\nmaking using a congruity function for generalization and personalization in the\npresence of imbalanced, conflicting and partial data. For the control plane, a\nscheme of identifier-locator mapping is designed by referring to\ninformation-centric networking and software-defined networking. For the user\nplane, the registrations, requests and data are forwarded to implement the SIEN\nand test its performance. The evaluation shows the SIEN outperforms four\nstate-of-the-art techniques for redundant traffic reduction by up to 46.04%\nbased on a mix of assumption, simulation and proof-of-concept implementation\nfor audio-visual-tactile Internet multimedia service. To confirm the validity,\nthe best case and the worst case for traffic offloading are tested with the\ndata rate, the latency and the density. The evaluation only focused on the\nscalability issue, while the SIEN would be beneficial to improve more issues\nsuch as inter-domain security, ultra-low latency, on-demand mobility,\nmulti-homing routing, and cross-layer feature incongruity.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 07:22:16 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Sheng", "Yiqiang", ""]]}, {"id": "1910.07266", "submitter": "Camila Pontes MSc", "authors": "Camila Pontes, Manuela Souza, Jo\\~ao Gondim, Matt Bishop and Marcelo\n  Marotta", "title": "A new method for flow-based network intrusion detection using the\n  inverse Potts model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Intrusion Detection Systems (NIDS) play an important role as tools\nfor identifying potential network threats. In the context of ever-increasing\ntraffic volume on computer networks, flow-based NIDS arise as good solutions\nfor real-time traffic classification. In recent years, different flow-based\nclassifiers have been proposed using Machine Learning (ML) algorithms.\nNevertheless, classical ML-based classifiers have some limitations. For\ninstance, they require large amounts of labeled data for training, which might\nbe difficult to obtain. Additionally, most ML-based classifiers are not capable\nof domain adaptation, i.e. after being trained on an specific data\ndistribution, they are not general enough to be applied to other related data\ndistributions. And, finally, many of the models inferred by these algorithms\nare black boxes, which do not provide explainable results. To overcome these\nlimitations, we propose a new algorithm, called Energy-based Flow Classifier\n(EFC). This anomaly-based classifier uses inverse statistics to infer a\nstatistical model based on labeled benign examples. We show that EFC is capable\nof accurately performing binary flow classification and is more adaptable to\ndifferent data distributions than classical ML-based classifiers. Given the\npositive results obtained on three different datasets (CIDDS-001, CICIDS17 and\nCICDDoS19), we consider EFC to be a promising algorithm to perform robust\nflow-based traffic classification.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 10:36:23 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:36:53 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 22:27:35 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 11:57:04 GMT"}, {"version": "v5", "created": "Thu, 11 Mar 2021 00:10:29 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Pontes", "Camila", ""], ["Souza", "Manuela", ""], ["Gondim", "Jo\u00e3o", ""], ["Bishop", "Matt", ""], ["Marotta", "Marcelo", ""]]}, {"id": "1910.07322", "submitter": "Marco Giordani", "authors": "Federico Mason, Marco Giordani, Federico Chiariotti, Andrea Zanella,\n  Michele Zorzi", "title": "An Adaptive Broadcasting Strategy for Efficient Dynamic Mapping in\n  Vehicular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we face the issue of achieving an efficient dynamic mapping in\nvehicular networking scenarios, i.e., to obtain an accurate estimate of the\npositions and trajectories of connected vehicles in a certain area. State of\nthe art solutions are based on the periodic broadcasting of the position\ninformation of the network nodes, with an inter-transmission period set by a\ncongestion control scheme. However, the movements and maneuvers of vehicles can\noften be erratic, making transmitted data inaccurate or downright misleading.\nTo address this problem, we propose to adopt a dynamic transmission scheme\nbased on the actual positioning error, sending new data when the estimate\npasses a preset error threshold. Furthermore, the proposed method adapts the\nerror threshold to the operational context according to a congestion control\nalgorithm that limits the collision probability among broadcast packet\ntransmissions. This threshold-based strategy can reduce the network load by\navoiding the transmission of redundant messages, and is shown to improve the\noverall positioning accuracy by more than 20% in realistic urban scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 12:55:29 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Mason", "Federico", ""], ["Giordani", "Marco", ""], ["Chiariotti", "Federico", ""], ["Zanella", "Andrea", ""], ["Zorzi", "Michele", ""]]}, {"id": "1910.07361", "submitter": "Min Fu", "authors": "Min Fu, Yong Zhou, Yuanming Shi, and Khaled B. Letaief", "title": "Reconfigurable Intelligent Surface Empowered Downlink Non-Orthogonal\n  Multiple Access", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power-domain non-orthogonal multiple access (NOMA) has become a promising\ntechnology to exploit the new dimension of the power domain to enhance the\nspectral efficiency of wireless networks. However, most existing NOMA schemes\nrely on the strong assumption that users' channel gains are quite different,\nwhich may be invalid in practice. To unleash the potential of power-domain\nNOMA, we will propose a reconfigurable intelligent surface (RIS)-empowered NOMA\nnetwork to introduce desirable channel gain differences among the users by\nadjusting the phase shifts at RIS. Our goal is to minimize the total transmit\npower by jointly optimizing the beamforming vectors at the base station and the\nphase-shift matrix at the RIS. To address the highly coupled optimization\nvariables, we present an alternating optimization framework to decompose the\nnon-convex bi-quadratically constrained quadratic problem into two rank-one\nconstrained matrices optimization problems via matrix lifting. At the same\ntime, to accurately detect the feasibility of the non-convex rank-one\nconstraints and improve performance by avoiding early stopping in the\nalternating optimization procedure, we equivalently represent the rank-one\nconstraint as the difference between nuclear norm and spectral norm. A\ndifference-of-convex (DC) algorithm is further developed to solve the resulting\nDC programs via successive convex relaxation, followed by establishing the\nconvergence of the proposed DC-based alternating optimization method. We\nfurther propose an efficient user ordering scheme with closed-form expressions,\nconsidering both the channel conditions and users' target data rates.\nSimulation results will validate the effectiveness of deploying an RIS and the\nsuperiority of the proposed DC-based alternating optimization method in\nreducing the total transmit power.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 14:13:45 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 12:35:25 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 07:50:11 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Fu", "Min", ""], ["Zhou", "Yong", ""], ["Shi", "Yuanming", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "1910.07402", "submitter": "Jos\\'e \\'Angel Morell Mart\\'inez", "authors": "Jos\\'e \\'A. Morell, Andr\\'es Camero and Enrique Alba", "title": "JSDoop and TensorFlow.js: Volunteer Distributed Web Browser-Based Neural\n  Network Training", "comments": null, "journal-ref": "IEEE Access 7 (2019): 158671-158684", "doi": "10.1109/ACCESS.2019.2950287", "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2019, around 57\\% of the population of the world has broadband access to\nthe Internet. Moreover, there are 5.9 billion mobile broadband subscriptions,\ni.e., 1.3 subscriptions per user. So there is an enormous interconnected\ncomputational power held by users all around the world. Also, it is estimated\nthat Internet users spend more than six and a half hours online every day. But\nin spite of being a great amount of time, those resources are idle most of the\nday. Therefore, taking advantage of them presents an interesting opportunity.\nIn this study, we introduce JSDoop, a prototype implementation to profit from\nthis opportunity. In particular, we propose a volunteer web browser-based\nhigh-performance computing library. JSdoop divides a problem into tasks and\nuses different queues to distribute the computation. Then, volunteers access\nthe web page of the problem and start processing the tasks in their web\nbrowsers. We conducted a proof-of-concept using our proposal and TensorFlow.js\nto train a recurrent neural network that predicts text. We tested it in a\ncomputer cluster and with up to 32 volunteers. The experimental results show\nthat training a neural network in distributed web browsers is feasible and\naccurate, has a high scalability, and it is an interesting area for research.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 19:39:01 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Morell", "Jos\u00e9 \u00c1.", ""], ["Camero", "Andr\u00e9s", ""], ["Alba", "Enrique", ""]]}, {"id": "1910.07421", "submitter": "Paul Almasan", "authors": "Paul Almasan, Jos\\'e Su\\'arez-Varela, Arnau Badia-Sampera, Krzysztof\n  Rusek, Pere Barlet-Ros, Albert Cabellos-Aparicio", "title": "Deep Reinforcement Learning meets Graph Neural Networks: exploring a\n  routing optimization use case", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Deep Reinforcement Learning (DRL) have shown a significant\nimprovement in decision-making problems. The networking community has started\nto investigate how DRL can provide a new breed of solutions to relevant\noptimization problems, such as routing. However, most of the state-of-the-art\nDRL-based networking techniques fail to generalize, this means that they can\nonly operate over network topologies seen during training, but not over new\ntopologies. The reason behind this important limitation is that existing DRL\nnetworking solutions use standard neural networks (e.g., fully connected),\nwhich are unable to learn graph-structured information. In this paper we\npropose to use Graph Neural Networks (GNN) in combination with DRL. GNN have\nbeen recently proposed to model graphs, and our novel DRL+GNN architecture is\nable to learn, operate and generalize over arbitrary network topologies. To\nshowcase its generalization capabilities, we evaluate it on an Optical\nTransport Network (OTN) scenario, where the agent needs to allocate traffic\ndemands efficiently. Our results show that our DRL+GNN agent is able to achieve\noutstanding performance in topologies unseen during training.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:36:08 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 14:04:46 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Almasan", "Paul", ""], ["Su\u00e1rez-Varela", "Jos\u00e9", ""], ["Badia-Sampera", "Arnau", ""], ["Rusek", "Krzysztof", ""], ["Barlet-Ros", "Pere", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "1910.07652", "submitter": "Petros Spachos", "authors": "Marc Jayson Baucas and Petros Spachos", "title": "Using Cloud and Fog Computing for Large Scale IoT-based Urban Sound\n  Classification", "comments": null, "journal-ref": null, "doi": "10.1016/j.simpat.2019.102013", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) has become the forefront of bridging different\ntechnologies together. It brings rise to online computational services that\nmake mundane tasks convenient. However, the volume of devices connecting to the\nnetwork started to increase. In turn, services that thrived on centralized\nstorage are being strained and overloaded. As applications and software\nadvances, processing and computational power become a concern to technology\ncompanies. With data risks and large numbers of connected devices, cloud\ncomputing has become outdated. Devices are forced to commit unnecessary\nexpenses to stay relevant in the market due to the increase in software\ncomplexity. This need for change resulted in the introduction of edge\ncomputing. Edge computing distributes the computational strain between the\nserver and the devices. This contribution allows the cloud to accommodate more\nusers and devices are no longer in need to make significant changes to their\ndesign every so often. Many real-time applications have evolved to require high\namounts of processing power to execute. For example, sound classification comes\nwith massive computational needs due to its affiliation with neural networks\nand deep learning. This paper aims to create a feasible and deployable\nreal-time sound classification system. There were three configurations tested\nin this paper. The results of our experiments show that cloud computing and\nedge computing alone cannot cater to a technological market that is\nexponentially growing in size and complexity. However, the same results show\npromise in finding optimal configurations in terms of a combination of end\ndevice power consumption, application runtime and server latency to systems\ninstead of focusing on a single model. Overall, it is better to take into\nconsideration the strengths and weaknesses of each computing architecture.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 23:57:27 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Baucas", "Marc Jayson", ""], ["Spachos", "Petros", ""]]}, {"id": "1910.07698", "submitter": "Wenpin Tang", "authors": "Xin Guo, Fengmin Tang, Wenpin Tang", "title": "The Buckley-Osthus model and the block preferential attachment model:\n  statistical analysis and application", "comments": "12 pages, 2 figures, 4 tables. This paper is published by\n  http://proceedings.mlr.press/v119/tang20b.html", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning (ICML 2020), PMLR 119, 9377-9386", "doi": null, "report-no": null, "categories": "math.ST cs.NI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with statistical estimation of two preferential\nattachment models: the Buckley-Osthus model and the hierarchical preferential\nattachment model. We prove that the maximum likelihood estimates for both\nmodels are consistent. We perform simulation studies to corroborate our\ntheoretical findings. We also apply both models to study the evolution of a\nreal-world network. A list of open problems are presented.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 03:43:48 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 05:05:53 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Guo", "Xin", ""], ["Tang", "Fengmin", ""], ["Tang", "Wenpin", ""]]}, {"id": "1910.07729", "submitter": "Jan R\\\"uth", "authors": "Jan R\\\"uth and Konrad Wolsing and Klaus Wehrle and Oliver Hohlfeld", "title": "Perceiving QUIC: Do Users Notice or Even Care?", "comments": null, "journal-ref": "In CoNEXT '19: International Conference On Emerging Networking\n  Experiments And Technologies, December 9-12, 2019, Orlando, FL, USA. ACM, New\n  York, NY, USA, 7 pages", "doi": "10.1145/3359989.3365416", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  QUIC, as the foundation for HTTP/3, is becoming an Internet reality. A\nplethora of studies already show that QUIC excels beyond TCP+TLS+HTTP/2. Yet,\nthese studies compare a highly optimized QUIC Web stack against an unoptimized\nTCP-based stack. In this paper, we bring TCP up to speed to perform an\neye-level comparison. Instead of relying on technical metrics, we perform two\nextensive user studies to investigate QUIC's impact on the quality of\nexperience. First, we investigate if users can distinguish two protocol\nversions in a direct comparison, and we find that QUIC is indeed rated faster\nthan TCP and even a tuned TCP. Yet, our second study shows that this perceived\nperformance increase does mostly not matter to the users, and they rate QUIC\nand TCP indistinguishable.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 06:29:46 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["R\u00fcth", "Jan", ""], ["Wolsing", "Konrad", ""], ["Wehrle", "Klaus", ""], ["Hohlfeld", "Oliver", ""]]}, {"id": "1910.07743", "submitter": "Farideh Parastar", "authors": "Farideh Parastar, Shian J. Wang", "title": "Quality of Service in IEEE 802.11 WLANs: An Experimental Study", "comments": "6 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the IEEE 802.11 protocol is being widely used, it is not specifically\ndesigned to handle multimedia traffic, which covers an important portion of the\nInternet traffic today. Voice and video multicast streaming is inefficient, as\nthere is lack of transmission reliability in such approaches where delay is not\nguaranteed. In this work, we focus on the performance of Enhanced Distributed\nChannel Access (EDCA) mechanism proposed by IEEE 802.11e which provides traffic\nprioritization and since most of the previous works are done based on\nsimulation results, we test the performance of this protocol in a real platform\nusing sofware Defined Networks. We then validate the impact of different EDCA\nparameters ( e.g., AIFS and TXOP) by tuning them to see their impact on the\ndelay of the network and eventually on network traffic.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 07:16:56 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 15:50:53 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 21:54:02 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Parastar", "Farideh", ""], ["Wang", "Shian J.", ""]]}, {"id": "1910.07794", "submitter": "Mustafa Kishk", "authors": "Mohamed-Amine Lahmeri, Mustafa A. Kishk, Mohamed-Slim Alouini", "title": "Stochastic Geometry-Based Analysis of Airborne Base Stations with\n  Laser-powered UAVs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most promising solutions to the problem of limited flight time of\nunmanned aerial vehicles (UAVs), is providing the UAVs with power through laser\nbeams emitted from Laser Beam Directors (LBDs) deployed on the ground. In this\nletter, we study the performance of a laser-powered UAV-enabled communication\nsystem using tools from stochastic geometry. We first derive the energy\ncoverage probability, which is defined as the probability of the UAV receiving\nenough energy to ensure successful operation (hovering and communication). Our\nresults show that to ensure energy coverage, the distance between the UAV and\nits dedicated LBD must be below a certain threshold, for which we derive an\nexpression as a function of the system parameters. Considering simultaneous\ninformation and power transmission through the laser beam using power splitting\ntechnique, we also derive the joint energy and the Signal-to-noise Ratio (SNR)\ncoverage probability. The analytical and simulation results reveal some\ninteresting insights. For instance, our results show that we need at least 6\nLBDs/10km^2 to ensure a reliable performance in terms of energy coverage\nprobability.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 09:49:18 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Lahmeri", "Mohamed-Amine", ""], ["Kishk", "Mustafa A.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1910.07921", "submitter": "Devon Callahan", "authors": "Devon Callahan, Timothy Curry, Daniel Davidson, Heytem Zitoun,\n  Benjamin Fuller, Laurent Michel", "title": "FASHION: Functional and Attack graph Secured HybrId Optimization of\n  virtualized Networks", "comments": "13 pages plus references and appendix, 6 figures, submitted for\n  publication Oct 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining a resilient computer network is a delicate task with conflicting\npriorities. Flows should be served while controlling risk due to attackers.\nUpon publication of a vulnerability, administrators scramble to manually\nmitigate risk before a patch is available. Tools exist to check network\nreachability (Khurshid et al., NSDI 2013) and risk using (probabilistic) attack\ngraphs (Sheyner et al., IEEE S\\&P 2002). These tools are not designed to\nfashion configurations that simultaneously satisfy multiple properties.\n  We introduce FASHION: a linear optimizer that \\emph{fashions} network\nconfigurations to balance functionality and security requirements. FASHION\nformalizes functionality as a multi-commodity flow problem with\nside-constraints. FASHION formulates security as the average of 1) the risk of\nthe connected component in the attack graph and 2) the highest probability path\nin the attack graph. These measures approximate the risk in a probabilistic\nattack graph (Wang et al., Network Security Metrics 2017). FASHION outputs a\nset of software-defined networking rules consumable by a Frenetic controller\n(Foster et al., ICFP 2011). The approximation linearly combines two measures.\nOne measure is the impact of the set of nodes the attacker can reach in the\nattack graph (ignoring probability). The second is the maximum probability path\nin the attack graph.\n  FASHION is evaluated on data center networks with up to 649 devices, usually\noutputting a solution in under 30 minutes. FASHION allows an enterprise to\nautomatically reconfigure their network upon a change in functionality (shift\nin user demand) or security (publication or patching of a vulnerability).\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 13:56:16 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 17:16:13 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Callahan", "Devon", ""], ["Curry", "Timothy", ""], ["Davidson", "Daniel", ""], ["Zitoun", "Heytem", ""], ["Fuller", "Benjamin", ""], ["Michel", "Laurent", ""]]}, {"id": "1910.08229", "submitter": "Amir Behrouzi-Far", "authors": "Amir Behrouzi-Far, Ezhan Karasan", "title": "Dynamic Resource Allocation and Activity Management for Energy\n  Efficiency and Fairness in Heterogeneous Networks", "comments": "Accepted for oral presentation in IEICE SmartCom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher energy consumption of Heterogeneous Networks (HetNet), compared to\nMacro Only Networks (MONET), raises a great concern about the energy efficiency\nof HetNets. In this work we study a dynamic activation strategy, which changes\nthe state of small cells between Active and Idle according to the dynamically\nchanging user traffic, in order to increase the energy efficiency of HetNets.\nMoreover, we incorporate dynamic inter-tier bandwidth allocation to our model.\nThe proposed Dynamic Bandwidth Allocation and Dynamic Activation (DBADA)\nstrategy is applied in cell-edge deployment of small cells, where HotSpot\nregions are located far from the master base station. Our objective is to\nmaximize the sum utility of the network with minimum energy consumption. To\nensure proportional fairness among users, we used logarithmic utility function.\nTo evaluate the performance of the proposed strategy, the median, 10-percentile\nand the sum of users' data rates and the network energy consumption are\nevaluated by simulation. Our simulation results shows that the DBADA strategy\nimproves the energy consumed per unit of users' data rate by up to $25\\%$. It\nalso achieves lower energy consumption by at least $25\\%$, compared to always\nactive scenario for small cells.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 02:32:39 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Behrouzi-Far", "Amir", ""], ["Karasan", "Ezhan", ""]]}, {"id": "1910.08232", "submitter": "Shahzad Shahzad", "authors": "Shahzad and Eun-Sung Jung", "title": "FLIP:FLexible IoT Path Programming Framework for Large-scale IoT", "comments": "10 pages, 8 Figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increase in smart objects forming IoT fabric, it is inevitable\nto see billions of devices connected together, forming large-scale IoT\nnetworks. This expeditious increase in IoT devices is giving rise to increased\nuser requirements and network complexity. Collecting big data from these IoT\ndevices with optimal network utilization and simplicity is becoming more and\nmore challenging. This paper proposes FLIP- FLexible IoT Path Programming\nFramework for Large-scale IoT. The distinctive feature of FLIP is that it\nfocuses on the IoT fabric from the perspective of user requirements and uses\nSDN techniques along with DPI technology to efficiently fulfill the user\nrequirements and establish datapath in the network in an automated and\ndistributed manner. FLIP utilizes SDN structure to optimize network utilization\nthrough in-network computing and automated datapath establishment, also hiding\nnetwork complexity along the way. We evaluated our framework through\nexperiments, and results indicate that FLIP has the potential to fulfill user\nrequirements in an automated fashion and optimize network utilization.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 03:12:17 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Shahzad", "", ""], ["Jung", "Eun-Sung", ""]]}, {"id": "1910.08291", "submitter": "Tiankui Zhang", "authors": "Tiankui Zhang, Xinyuan Fang, Yuanwei Liu, Geoffrey Ye Li, and Wenjun\n  Xu", "title": "D2D-Enabled Mobile User Edge Caching: A Multi-Winner Auction Approach", "comments": "14 pages", "journal-ref": null, "doi": "10.1109/TVT.2019.2947334", "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In device-to-device (D2D)-enabled caching cellular networks, the user\nterminals (UTs) collaboratively store and share a large volume of popular\ncontents from the base station (BS) for traffic offloading and delivery delay\nreduction. In this article, the multi-winner auction based caching placement in\nD2D-enabled caching cellular networks is investigated for UT edge caching\nincentive and content caching redundancy reduction. Firstly, a multi-winner\nonce auction for UT edge caching is modeled which auctions multiple contents\nfor multiple UTs. Then the optimization problem for content caching revenue\nmaximization is formulated. Specifically, the \"cache conflict\" restriction\nrelationship among UTs is used as one of the constraints in the problem to\nreduce the content caching redundancy in a UT movement scenario. The problem is\nsolved by semidefinite programming (SDP) relaxation to obtain an approximate\noptimal caching placement. Moreover, the payment strategy of the auction is\ndeveloped as a Nash bargaining game for personal profit fairness among the UTs\nwho win the auction for content caching. Subsequently, a multi-winner once\nauction based caching (MOAC) placement algorithm is proposed. In addition, due\nto the high complexity of MOAC, we further propose a heuristic multi-winner\nrepeated auction based caching placement (MRAC) algorithm, which can greatly\nreduce the complexity with only tiny performance loss. Simulation results show\nthat the proposed algorithms can reduce the traffic load and average content\naccess delay effectively compared with the existing caching placement\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 07:44:13 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Zhang", "Tiankui", ""], ["Fang", "Xinyuan", ""], ["Liu", "Yuanwei", ""], ["Li", "Geoffrey Ye", ""], ["Xu", "Wenjun", ""]]}, {"id": "1910.08731", "submitter": "Reza Malekian Ph.D.", "authors": "Chao Sha, Chunhui Ren, Reza Malekian, Min Wu, Haiping Huang, Ning Ye", "title": "A Type of Virtual Force based Energy-hole Mitigation Strategy for Sensor\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JSEN.2019.2945595", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of Big Data and Mobile Internet, how to ensure the terminal\ndevices (e.g., sensor nodes) work steadily for a long time is one of the key\nissues to improve the efficiency of the whole network. However, a lot of facts\nhave shown that the unattended equipments are prone to failure due to energy\nexhaustion, physical damage and other reasons. This may result in the emergence\nof energy-hole, seriously affecting network performance and shortening its\nlifetime. To reduce data redundancy and avoid the generation of sensing blind\nareas, a type of Virtual Force based Energy-hole Mitigation strategy (VFEM) is\nproposed in this paper. Firstly, the virtual force (gravitation and repulsion)\nbetween nodes is introduced that makes nodes distribute as uniformly as\npossible. Secondly, in order to alleviate the \"energy-hole problem\", the\nnetwork is divided into several annuluses with the same width. Then, another\ntype of virtual force, named \"virtual gravity generated by annulus\", is\nproposed to further optimize the positions of nodes in each annulus. Finally,\nwith the help of the \"data forwarding area\", the optimal paths for data\nuploading can be selected out, which effectively balances energy consumption of\nnodes. Experiment results show that, VFEM has a relatively good performance on\npostponing the generation time of energy-holes as well as prolonging the\nnetwork lifetime compared with other typical energy-hole mitigation methods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 09:30:39 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Sha", "Chao", ""], ["Ren", "Chunhui", ""], ["Malekian", "Reza", ""], ["Wu", "Min", ""], ["Huang", "Haiping", ""], ["Ye", "Ning", ""]]}, {"id": "1910.08743", "submitter": "Kurian Polachan Mr", "authors": "Kurian Polachan, Joydeep Pal, Chandramani Singh, and Prabhakar T V", "title": "Quality of Control Assessment for Tactile Internet based Cyber-Physical\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evolve a methodology and define a metric to evaluate Tactile Internet\nbased Cyber-Physical Systems or Tactile Cyber-Physical Systems (TCPS). Towards\nthis goal, we adopt the step response analysis, a well-known control-theoretic\nmethod. The adoption includes replacing the human operator (or master) with a\ncontroller with known characteristics and analyzing its response to slave side\nstep disturbances. The resulting step response curves demonstrate that the\n\\textit{Quality of Control} (QoC) metric is sensitive to control loop\ninstabilities and serves as a good indicator of cybersickness experienced by\nhuman operators. We demonstrate the efficacy of the proposed methodology and\nmetric through experiments on a TCPS testbed. The experiments include assessing\nthe suitability of several access technologies, intercontinental links, network\ntopologies, network traffic conditions and testbed configurations. Further, we\nvalidate our claim of using QoC to predict and quantify cybersickness through\nexperiments on a teleoperation setup built using Mininet and VREP.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 10:46:03 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 14:55:04 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Polachan", "Kurian", ""], ["Pal", "Joydeep", ""], ["Singh", "Chandramani", ""], ["T", "Prabhakar", "V"]]}, {"id": "1910.08868", "submitter": "Mounia Hamidouche", "authors": "Mounia Hamidouche, Ejder Ba\\c{s}tu\\u{g}, Jihong Park, Laura\n  Cottatellucci, M\\'erouane Debbah", "title": "Downlink Performance of Dense Antenna Deployment: To Distribute or\n  Concentrate?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive multiple-input multiple-output (massive MIMO) and small cell\ndensification are complementary key 5G enablers. Given a fixed number of the\nentire base-station antennas per unit area, this paper fairly compares (i) to\ndeploy few base stations (BSs) and concentrate many antennas on each of them,\ni.e. massive MIMO, and (ii) to deploy more BSs equipped with few antennas, i.e.\nsmall cell densification. We observe that small cell densification always\noutperforms for both signal-to-interference ratio (SIR) coverage and energy\nefficiency (EE), when each BS serves multiple users via L number of sub-bands\n(multi-carrier transmission). Moreover, we also observe that larger L increases\nSIR coverage while decreasing EE, thus urging the necessity of optimal 5G\nnetwork design. These two observations are based on our novel closed-form SIR\ncoverage probability derivation using stochastic geometry, also validated via\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 01:13:47 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Hamidouche", "Mounia", ""], ["Ba\u015ftu\u011f", "Ejder", ""], ["Park", "Jihong", ""], ["Cottatellucci", "Laura", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "1910.09011", "submitter": "Yoad Zur", "authors": "Yoad Zur and Michael Segal", "title": "Improved solution to data gathering with mobile mule", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the problem of collecting protected data in ad-hoc\nsensor network using a mobile entity called MULE. The objective is to increase\ninformation survivability in the network. Sensors from all over the network,\nroute their sensing data through a data gathering tree, towards a particular\nnode, called the $sink$. In case of a failed sensor, all the aggregated data\nfrom the sensor and from its children is lost. In order to retrieve the lost\ndata, the MULE is required to travel among all the children of the failed\nsensor and to re-collect the data. There is a cost to travel between two points\nin the plane. We aim to minimize the MULE traveling cost, given that any sensor\ncan fail. In order to reduce the traveling cost, it is necessary to find the\noptimal data gathering tree and the MULE location. We are considering the\nproblem for the unit disk graphs (UDG) and Euclidean distance cost function. We\npropose a primal-dual algorithm that produces a\n$\\left(20+\\varepsilon\\right)$-approximate solution for the problem, where\n$\\varepsilon\\rightarrow0$ as the sensor network spreads over a larger area. The\nalgorithm requires $O\\left(n^{3}\\cdot\\varDelta\\left(G\\right)\\right)$ time to\nconstruct a gathering tree and to place the MULE, where\n$\\varDelta\\left(G\\right)$ is the maximum degree in the graph and $n$ is the\nnumber of nodes.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 16:25:56 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Zur", "Yoad", ""], ["Segal", "Michael", ""]]}, {"id": "1910.09091", "submitter": "Akshayaa Magesh", "authors": "Akshayaa Magesh and Venugopal V. Veeravalli", "title": "Multi-User MABs with User Dependent Rewards for Uncoordinated Spectrum\n  Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-user multi-armed bandits have emerged as a good model for uncoordinated\nspectrum access problems. In this paper we consider the scenario where users\ncannot communicate with each other. In addition, the environment may appear\ndifferently to different users, ${i.e.}$, the mean rewards as observed by\ndifferent users for the same channel may be different. With this setup, we\npresent a policy that achieves a regret of $O (\\log{T})$. This paper has been\naccepted at Asilomar Conference on Signals, Systems, and Computers 2019.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 00:32:58 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 21:36:49 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 18:58:41 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Magesh", "Akshayaa", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1910.09155", "submitter": "Srinivasan Iyengar", "authors": "Dhruv Agarwal, Srinivasan Iyengar, Manohar Swaminathan", "title": "Modulo: Drive-by Sensing at City-scale on the Cheap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Drive-by sensing is gaining popularity as an inexpensive way to perform\nfine-grained, city-scale, spatiotemporal monitoring of physical phenomena.\nPrior work explores several challenges in the design of low-cost sensors, the\nreliability of these sensors, and their application for specific use-cases like\npothole detection and pollution monitoring. However, the process of deployment\nof a drive-by sensing network at a city-scale is still unexplored. Despite the\nrise of ride-sharing services, there is still no way to optimally select\nvehicles from a fleet that can accomplish the sensing task by providing enough\ncoverage of the city. In this paper, we propose Modulo -- a system to bootstrap\ndrive-by sensing deployment by taking into consideration a variety of aspects\nsuch as spatiotemporal coverage, budget constraints. Further, Modulo is\nwell-suited to satisfy unique deployment constraints such as colocations with\nother sensors (needed for gas and PM sensor calibration), etc. We compare\nModulo with two baseline algorithms on real-world taxi and bus datasets. We\nfind that Modulo marginally outperforms the two baselines for datasets with\njust random-routes vehicles such as taxis. However, it significantly\noutperforms the baselines when a fleet comprises of both taxis and fixed-route\nvehicles such as public transport buses. Finally, we present a real-deployment\nthat uses Modulo to select vehicles for an air pollution sensing application.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 05:23:43 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Agarwal", "Dhruv", ""], ["Iyengar", "Srinivasan", ""], ["Swaminathan", "Manohar", ""]]}, {"id": "1910.09172", "submitter": "Cong Luong Nguyen", "authors": "Huy T. Nguyen, Nguyen Cong Luong, Jun Zhao, Chau Yuen, and Dusit\n  Niyato", "title": "Resource Allocation in Mobility-Aware Federated Learning Networks: A\n  Deep Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning allows mobile devices, i.e., workers, to use their local\ndata to collaboratively train a global model required by the model owner.\nFederated learning thus addresses the privacy issues of traditional machine\nlearning. However, federated learning faces the energy constraints of the\nworkers and the high network resource cost due to the fact that a number of\nglobal model transmissions may be required to achieve the target accuracy. To\naddress the energy constraint, a power beacon can be used that recharges energy\nto the workers. However, the model owner may need to pay an energy cost to the\npower beacon for the energy recharge. To address the high network resource\ncost, the model owner can use a WiFi channel, called default channel, for the\nglobal model transmissions. However, communication interruptions may occur due\nto the instability of the default channel quality. For this, special channels\nsuch as LTE channels can be used, but this incurs channel cost. As such, the\nproblem of the model owner is to decide amounts of energy recharged to the\nworkers and to choose channels used to transmit its global model to the workers\nto maximize the number of global model transmissions while minimizing the\nenergy and channel costs. This is challenging for the model owner under the\nuncertainty of the channel, energy and mobility states of the workers. In this\npaper, we thus propose to employ the Deep Q-Network (DQN) that enables the\nmodel owner to find the optimal decisions on the energy and the channels\nwithout any a priori network knowledge. Simulation results show that the\nproposed DQN always achieves better performance compared to the conventional\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 06:54:52 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Nguyen", "Huy T.", ""], ["Luong", "Nguyen Cong", ""], ["Zhao", "Jun", ""], ["Yuen", "Chau", ""], ["Niyato", "Dusit", ""]]}, {"id": "1910.09184", "submitter": "Wei Wang Dr.", "authors": "Shiyue He, Wei Wang, Hang Yang, Yang Cao, Tao jiang, Qian Zhang", "title": "State-Aware Rate Adaptation for UAVs by Incorporating On-Board Sensors", "comments": "To appear at IEEE Trans. Veh. Technol", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays unmanned aerial vehicles (UAVs) are being widely applied to a wealth\nof civil and military applications. Robust and high-throughput wireless\ncommunication is the crux of these UAV applications. Yet, air-to-ground links\nsuffer from time-varying channels induced by the agile mobility and dynamic\nenvironments. Rate adaptation algorithms are generally used to choose the\noptimal data rate based on the current channel conditions. State-of-the-art\napproaches leverage physical layer information for rate adaptation, and they\nwork well under certain conditions. However, the above protocols still have\nlimitation under constantly changing flight states and environments for\nair-to-ground links. To solve this problem, we propose StateRate, a\nstate-optimized rate adaptation algorithm that fully exploits the\ncharacteristics of UAV systems using a hybrid deep learning model. The key\nobservation is that the rate adaptation strategy needs to be adjusted according\nto motion-dependent channel models, which can be reflected by flight states. In\nthis work, the rate adaptation protocol is enhanced with the help of the\non-board sensors in UAVs. To make full use of the sensor data, we introduce a\nlearning-based prediction module by leveraging the internal state to\ndynamically store temporal features under variable flight states. We also\npresent an online learning algorithm by employing the pre-trained model that\nadapts the rate adaptation algorithm to different environments. We implement\nour algorithm on a commercial UAV platform and evaluate it in various\nenvironments. The results demonstrate that our system outperforms the\nbest-known rate adaptation algorithm up to 53% in terms of throughput when the\nvelocity is 2-6~m/s.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 07:36:08 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["He", "Shiyue", ""], ["Wang", "Wei", ""], ["Yang", "Hang", ""], ["Cao", "Yang", ""], ["jiang", "Tao", ""], ["Zhang", "Qian", ""]]}, {"id": "1910.09272", "submitter": "Maurantonio Caprolu", "authors": "Maurantonio Caprolu, Simone Raponi, Gabriele Oligeri, Roberto Di\n  Pietro", "title": "Cryptomining Makes Noise: a Machine Learning Approach for Cryptojacking\n  Detection", "comments": null, "journal-ref": null, "doi": "10.1016/j.comcom.2021.02.016", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new cybersecurity attack,where an adversary illicitly runs crypto-mining\nsoftware over the devices of unaware users, is emerging in both the literature\nand in the wild . This attack, known as cryptojacking, has proved to be very\neffective given the simplicity of running a crypto-client into a target device.\nSeveral countermeasures have recently been proposed, with different features\nand performance, but all characterized by a host-based architecture. This kind\nof solutions, designed to protect the individual user, are not suitable for\nefficiently protecting a corporate network, especially against insiders. In\nthis paper, we propose a network-based approach to detect and identify\ncrypto-clients activities by solely relying on the network traffic, even when\nencrypted. First, we provide a detailed analysis of the real network traces\ngenerated by three major cryptocurrencies, Bitcoin, Monero, and Bytecoin,\nconsidering both the normal traffic and the one shaped by a VPN. Then, we\npropose Crypto-Aegis, a Machine Learning (ML) based framework built over the\nresults of our investigation, aimed at detecting cryptocurrencies related\nactivities, e.g., pool mining, solo mining, and active full nodes. Our solution\nachieves a striking 0.96 of F1-score and 0.99 of AUC for the ROC, while\nenjoying a few other properties, such as device and infrastructure\nindependence. Given the extent and novelty of the addressed threat we believe\nthat our approach, supported by its excellent results, pave the way for further\nresearch in this area.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 11:49:41 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 13:59:13 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Caprolu", "Maurantonio", ""], ["Raponi", "Simone", ""], ["Oligeri", "Gabriele", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "1910.09651", "submitter": "Douglas Leith", "authors": "Francesco Gringoli, Douglas J. Leith", "title": "Low-Delay High-Rate Operation of 802.11ac WLAN Downlink: Nonlinear\n  Controller Analysis & Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a next generation edge architecture where traffic\nis routed via a proxy located close to the network edge (e.g. within a\ncloudlet). This creates freedom to implement new transport layer behaviour over\nthe wireless path between proxy and clients. We use this freedom to develop a\nnovel traffic shaping controller for the downlink in 802.11ac WLANs that\nadjusts the send rate to each WLAN client so as to maintain a target number of\npackets aggregated in each transmitted frame. In this way robust low-delay\noperation at high data rates becomes genuinely feasible across a wide range of\nnetwork conditions. Key to achieving robust operation is the design of an\nappropriate feedback controller, and it is this which is our focus. We develop\na novel nonlinear control design inspired by the solution to an associated\nproportional fair optimisation problem. The controller compensates for system\nnonlinearities and so can be used for the full envelope of operation. The\nrobust stability of the closed-loop system is analysed and the selection of\ncontrol design parameters discussed. We develop an implementation of the\nnonlinear control design and use this to present a performance evaluation using\nboth simulations and experimental measurements.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 21:03:09 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 11:22:41 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Gringoli", "Francesco", ""], ["Leith", "Douglas J.", ""]]}, {"id": "1910.09727", "submitter": "Hasan Al Maruf", "authors": "Youngmoon Lee, Hasan Al Maruf, Mosharaf Chowdhury, Asaf Cidon, Kang G.\n  Shin", "title": "Mitigating the Performance-Efficiency Tradeoff in Resilient Memory\n  Disaggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design and implementation of a low-latency, low-overhead, and\nhighly available resilient disaggregated cluster memory. Our proposed framework\ncan access erasure-coded remote memory within a single-digit {\\mu}s read/write\nlatency, significantly improving the performance-efficiency tradeoff over the\nstate-of-the-art - it performs similar to in-memory replication with 1.6x lower\nmemory overhead. We also propose a novel coding group placement algorithm for\nerasure-coded data, that provides load balancing while reducing the probability\nof data loss under correlated failures by an order of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 02:12:55 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 16:35:44 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lee", "Youngmoon", ""], ["Maruf", "Hasan Al", ""], ["Chowdhury", "Mosharaf", ""], ["Cidon", "Asaf", ""], ["Shin", "Kang G.", ""]]}, {"id": "1910.09787", "submitter": "Congcong Miao", "authors": "Congcong Miao and Jilong Wang and Shuying Zhuang and Changqing An", "title": "A Coordinated View of Cyberspace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyberspace is an online world created by growing network of computing and\ncommunication technologies. It is a virtual space of the Internet, paralleled\nto geographic space we are living on. As becoming a recognized component of our\nsociety, cyberspace gradually draws more attention in academic research. Many\nprior efforts have tried to represent and visualize cyberspace in geographic\ncoordinate system (GCS) and network coordinate system (NCS). However, there are\nsome disadvantages on these views. Firstly, mapping cyberspace in geographic\nspace only reveals a partial characteristics of cyberspace, especially\ngeographic characteristic of cyberspace. All what we could see is only the\ngeographic information of cyberspace and tip of the iceberg of cyberspace.\nSecondly, NCS is established according to network topology and maps the\nposition of each node in the coordinate system according to RTT (Round Trip\nTime) or network delays. However, this coordinate system changes dynamically\nwith RTT changes or host connection status, resulting in the coordinate system\nnot stable. Cyberspace, regarded as a second space in human life, is rather\ncomplex and multi-dimension. However, it is little known to us. It is in a\ngreat need of establishing its own coordinate system to tackle the challenging\ntask of efficiently visualizing complex multi-dimensional cyberspace and get to\nknow more about cyberspace. This paper aims to explore and visualize\ncyberspace. To best of our knowledge, we are firstly to establish a Cyberspace\nCoordination System (CyberCS) to represent and visualize cyberspace. CyberCS\nwill make the representation of cyberspace easier or more concrete which is\nsimilar to Fourier transform. With the help of CyberCS, different parts and\ndegrees of cyberspace are efficiently visualized and user can easily filter out\nthe specific details of interest.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 06:50:02 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Miao", "Congcong", ""], ["Wang", "Jilong", ""], ["Zhuang", "Shuying", ""], ["An", "Changqing", ""]]}, {"id": "1910.09793", "submitter": "Jobish John", "authors": "Jobish John, Gaurav S Kasbekar, and Maryam Shojaei Baghini", "title": "Maximum Lifetime Convergecast Tree in Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of building a maximum lifetime data collection tree for\nperiodic convergecast applications in wireless sensor networks. We\nexperimentally observe that if two nodes transmit same number of data packets,\nthe amount of energy consumption of the nodes is approximately the same even if\nthe payload lengths of the transmitted packets are different. This is because\nthe major energy consumption during a packet transmission arises from radio\nstart-up and medium access control overhead. Our formulated lifetime\nmaximization problem captures the energy expenditure due to message\ntransmissions/ receptions in terms of the number of data packets transmitted/\nreceived, in contrast to prior works, which consider the number of data units\n(amount of sensor data generated by a node) transmitted/ received. Variable\ntransmission power levels of the radio and accounting for the sensor energy\nconsumption are other factors that make our problem formulation different from\nthose in prior work. We prove that this problem is NP-complete and propose an\nalgorithm to solve it. The performance of the proposed algorithm is\nexperimentally evaluated using Jain's fairness index as a metric by\nimplementing it on an actual testbed consisting of 20 sensor nodes and compared\nwith those of the widely used shortest path tree (SPT) and random data\ncollection tree (RDCT) algorithms. The energy consumption of different nodes\nunder the proposed algorithm are shown to be more balanced than under SPT and\nRDCT algorithms. Also, the performance of the proposed algorithm in large\nnetworks is studied through simulations and is compared with those of the\nstate-of-the-art RaSMaLai algorithm, SPT, minimum spanning tree, and RDCT based\ndata collection schemes. Our simulations show that the proposed algorithm\nprovides a significantly higher network lifetime compared to all the other\nconsidered data collection approaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 06:59:03 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 03:44:13 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["John", "Jobish", ""], ["Kasbekar", "Gaurav S", ""], ["Baghini", "Maryam Shojaei", ""]]}, {"id": "1910.09818", "submitter": "Jobish John", "authors": "Jobish John, Gaurav S Kasbekar, Dinesh K Sharma, V. Ramulu, and Maryam\n  Shojaei Baghini", "title": "Design and Implementation of a Wireless SensorNetwork for Agricultural\n  Applications", "comments": null, "journal-ref": "EAI Endorsed Transactions on Internet of Things 4.16 (2018)", "doi": "10.4108/eai.13-7-2018.158420", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design and implementation of a shortest path tree based,\nenergy efficient data collection wireless sensor network to sense various\nparameters in an agricultural farm using in-house developed low cost sensors.\nNodes follow a synchronized, periodic sleep-wake up schedule to maximize the\nlifetime of the network. The implemented network consists of 24 sensor nodes in\na 3 acre maize farm and its performance is captured by 7 snooper nodes for\ndifferent data collection intervals: 10 minutes, 1 hour and 3 hours. The almost\nstatic nature of wireless links in the farm motivated us to use the same tree\nfor a long data collection period(3 days). The imbalance in energy consumption\nacross nodes is observed to be very small and the network architecture uses\neasy-to-implement protocols to perform different network activities including\nhandling of node failures. We present the results and analysis of extensive\ntests conducted on our implementation, which provide significant insights.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 08:14:43 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["John", "Jobish", ""], ["Kasbekar", "Gaurav S", ""], ["Sharma", "Dinesh K", ""], ["Ramulu", "V.", ""], ["Baghini", "Maryam Shojaei", ""]]}, {"id": "1910.09912", "submitter": "Mattia Lecci", "authors": "Paolo Testolina, Mattia Lecci, Michele Polese, Marco Giordani, Michele\n  Zorzi", "title": "Scalable and Accurate Modeling of the Millimeter Wave Channel", "comments": "6 pages, 7 figures. This paper has been accepted for presentation at\n  IEEE ICNC 2020. Copyright IEEE 2020. Please cite it as Paolo Testolina,\n  Mattia Lecci, Michele Polese, Marco Giordani, Michele Zorzi, Scalable and\n  Accurate Modeling of the Millimeter Wave Channel, IEEE International\n  Conference on Computing, Networking and Communications (ICNC), Big Island,\n  HI, 2020", "journal-ref": null, "doi": "10.1109/ICNC47757.2020.9049746", "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication at millimeter wave (mmWave) frequencies is one of the main\nnovelties introduced in the 5th generation (5G) of cellular networks. The\nopportunities and challenges associated with such high frequencies have\nstimulated a number of studies that rely on simulation for the evaluation of\nthe proposed solutions. The accuracy of simulations largely depends on that of\nthe channel model, but popular channel models for mmWaves, such as the Spatial\nChannel Models (SCMs), have high computational complexity and limit the\nscalability of the scenarios. This paper profiles the implementation of a\nwidely-used SCM model for mmWave frequencies, and proposes a simplified version\nof the 3GPP SCM that reduces the computation time by up to 12.5 times while\nproviding essentially the same distributions of several metrics, such as the\nSignal-to-Interference-plus-Noise Ratio (SINR) in large scale scenarios. We\nalso give insights on the use cases in which using a simplified model can still\nyield valid results.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:04:19 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Testolina", "Paolo", ""], ["Lecci", "Mattia", ""], ["Polese", "Michele", ""], ["Giordani", "Marco", ""], ["Zorzi", "Michele", ""]]}, {"id": "1910.09941", "submitter": "Michael Breza", "authors": "Alberto Spina, Michael Breza, Naranker Dulay, Julie McCann", "title": "XPC: Fast and Reliable Synchronous Transmission Protocols for 2-Phase\n  Commit and 3-Phase Commit", "comments": "13 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges for the engineering of wireless sensing systems\nis to improve the software abstractions and frameworks that are available to\nprogrammers while ensuring system reliability and efficiency. The distributed\nsystems community have developed a rich set of such abstractions for building\ndependable distributed systems connected using wired networks, however after 20\nyears research many of these elude wireless sensor systems. In this paper we\npresent X Process Commit (XPC) an atomic commit protocol framework that\nutilizes Synchronous Transmission (ST). We also introduce Hybrid, a technique\nthat allows us to exploit the advantages of the Glossy and Chaos Synchronous\nTransmission primitives to get lower latency and higher reliability than\neither. Using XPC and Hybrid we demonstrate how to build protocols for the\nclassical 2-phase and 3-phase commit abstractions and evaluate these\ndemonstrating significantly improved performance and reliability than the use\nof Glossy or Chaos individually as dissemination primitives. We address how we\novercame the timing challenges of bringing Glossy and Chaos together to form\nHybrid and through extensive experimentation demonstrate that it is robust to\nin-network radio interference caused by multiple sources. We are first to\npresent testbed results that show that Hybrid can provide almost 100%\nreliability in a network of nodes suffering from various levels of radio\ninterference.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:59:11 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Spina", "Alberto", ""], ["Breza", "Michael", ""], ["Dulay", "Naranker", ""], ["McCann", "Julie", ""]]}, {"id": "1910.10025", "submitter": "Belal Amro", "authors": "Belal Amro, Ahmed Abu Sabha, Ammar Qunaibi, Ibraheem Najjar", "title": "PAPG -- Personalized Anti-Phishing Guard", "comments": "13 pages, 8 figures. International Journal of Computing and Network\n  Technology - Jan 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security and privacy have been considered a corner stone in all electronic\ntransactions nowadays. People are becoming very cautious when conducting\nelectronic transactions over internet. One of the major issues that frightens\nthem is identity theft. Identity theft might be conducted using phishing\ntechniques that aims to trick the user to provide his credentials in a\nwell-organized tactic. Efforts have been done towards fighting against phishing\nattacks and hence identify theft. However, most of these efforts are either\ncomputationally exhaustive to the electronic device or depend on a third party\nto perform the task. In this paper, we propose a plugin called Personalized\nAnti-Phishing Guard - PAPG that is managed personally on the device and is used\nto guard the user against phishing attacks. The plugin maintains data locally\nand may not need to synchronize with a third party. Besides, PAPG depends on\nthe user's feedback to build the local knowledge base that is used to support\nthe decision. The user might also store his profile and reuse it with other\ndevices and from different locations without having to configure it again\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:01:36 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Amro", "Belal", ""], ["Sabha", "Ahmed Abu", ""], ["Qunaibi", "Ammar", ""], ["Najjar", "Ibraheem", ""]]}, {"id": "1910.10416", "submitter": "Ying Loong Lee", "authors": "Ying Loong Lee, Donghong Qin, Li-Chun Wang and Gek Hong (Allyson) Sim", "title": "6G Massive Radio Access Networks: Key Issues, Technologies, and Future\n  Challenges", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the emerging use cases in massive access future networks, there is\na need for technological advancements and evolutions for wireless\ncommunications beyond the fifth-generation (5G) networks. In particular, we\nenvisage the upcoming sixth-generation (6G) networks to consist of numerous\ndevices demanding extremely high-performance interconnections even under\nstrenuous scenarios such as diverse mobility, extreme density, and dynamic\nenvironment. To cater for such a demand, investigation on flexible and\nsustainable radio access network (RAN) techniques capable of supporting highly\ndiverse requirements and massive connectivity is of utmost importance. To this\nend, this paper first outlines the key driving applications for 6G, including\nsmart city and factory, which trigger the transformation of existing RAN\ntechniques. We then examine and provide in-depth discussions on several\ncritical performance requirements (i.e., the level of flexibility, the support\nfor massive interconnectivity, and energy efficiency), issues, enabling\ntechnologies, and challenges in designing 6G massive RANs. We conclude the\narticle by providing several artificial-intelligence-based approaches to\novercome future challenges.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 08:51:13 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Lee", "Ying Loong", "", "Allyson"], ["Qin", "Donghong", "", "Allyson"], ["Wang", "Li-Chun", "", "Allyson"], ["Hong", "Gek", "", "Allyson"], ["Sim", "", ""]]}, {"id": "1910.10438", "submitter": "Umur Karabulut", "authors": "Umur Karabulut, Ahmad Awada, Ingo Viering, Andre Noll Barreto, Gerhard\n  P. Fettweis", "title": "Low Complexity Channel Model for Mobility Investigations in 5G Networks", "comments": "8 pages, 6 figures, submitted to IEEE WCNC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter-wave has become an integral part of 5G networks to meet the\never-increasing demand for user data throughput. Employing higher carrier\nfrequencies introduces new challenges for the propagation channel such as\nhigher path loss and rapid signal degradations. On the other hand, higher\nfrequencies allow deployment of small-sized antenna elements that enable\nbeamforming. To investigate user mobility under these new propagation\nconditions, a proper model is needed that captures spatial and temporal\ncharacteristics of the channel in beamformed networks. Current channel models\nthat have been developed for 5G networks are computationally inefficient and\nlead to infeasible simulation time for most user mobility simulations. In this\npaper, we present a simplified channel model that captures the spatial and\ntemporal characteristics of the 5G propagation channel and runs in feasible\nsimulation time. To this end, coherence time and path diversity originating\nfrom fully fledged Geometry based Stochastic Channel Model (GSCM) are analyzed\nand adopted in Jakes channel model. Furthermore, the deviation of multipath\nbeamforming gain from single ray beamforming gain is analyzed and a regression\ncurve is obtained to be used in the system-level simulations. We show through\nsimulations that the proposed simplified channel model leads to mobility\nresults comparable to Jakes model for high path diversity. Moreover, the\nmulti-path beamforming gain increases the interference in the system and in\nturn number of mobility failures.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 09:55:55 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 14:19:36 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Karabulut", "Umur", ""], ["Awada", "Ahmad", ""], ["Viering", "Ingo", ""], ["Barreto", "Andre Noll", ""], ["Fettweis", "Gerhard P.", ""]]}, {"id": "1910.10441", "submitter": "Patrick P. C. Lee", "authors": "Lu Tang, Qun Huang, Patrick P. C. Lee", "title": "A Fast and Compact Invertible Sketch for Network-Wide Heavy Flow\n  Detection", "comments": "15 pages. Accepted by IEEE/ACM Transactions on Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast detection of heavy flows (e.g., heavy hitters and heavy changers) in\nmassive network traffic is challenging due to the stringent requirements of\nfast packet processing and limited resource availability. Invertible sketches\nare summary data structures that can recover heavy flows with small memory\nfootprints and bounded errors, yet existing invertible sketches incur high\nmemory access overhead that leads to performance degradation. We present\nMV-Sketch, a fast and compact invertible sketch that supports heavy flow\ndetection with small and static memory allocation. MV-Sketch tracks candidate\nheavy flows inside the sketch data structure via the idea of majority voting,\nsuch that it incurs small memory access overhead in both update and query\noperations, while achieving high detection accuracy. We present theoretical\nanalysis on the memory usage, performance, and accuracy of MV-Sketch in both\nlocal and network-wide scenarios. We further show how MV-Sketch can be\nimplemented and deployed on P4-based programmable switches subject to hardware\ndeployment constraints. We conduct evaluation in both software and hardware\nenvironments. Trace-driven evaluation in software shows that MV-Sketch achieves\nhigher accuracy than existing invertible sketches, with up to 3.38x throughput\ngain. We also show how to boost the performance of MV-Sketch with SIMD\ninstructions. Furthermore, we evaluate MV-Sketch on a Barefoot Tofino switch\nand show how MV-Sketch achieves line-rate measurement with limited hardware\nresource overhead.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 10:10:14 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 11:02:41 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Tang", "Lu", ""], ["Huang", "Qun", ""], ["Lee", "Patrick P. C.", ""]]}, {"id": "1910.10451", "submitter": "Manuel Steve Mbankeu Patchou", "authors": "Manuel Patchou and Benjamin Sliwa and Christian Wietfeld", "title": "Unmanned Aerial Vehicles in Logistics: Efficiency Gains and\n  Communication Performance of Hybrid Combinations of Ground and Aerial\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) have drastically gained popularity in various\nIntelligent Transportation System (ITS) applications to improve the safety and\nefficiency of transportation systems. In this context, the combination of\nground vehicles, such as delivery trucks, with drones to assist in the last\nmile pick-up and delivery of the parcels has been recently proposed. While\naerial vehicles promise increased efficiency based on flexible routes and\nparallelized operation, highly reliable wireless communication is also required\nfor the control and coordination of potentially many drones acting in a\nself-organized way. In this paper, we analyze the improvements procured by\ndrone usage in parcel delivery compared to traditional delivery and propose a\nsimulation framework to further quantify the efficiency gains of the parcel\ndelivery logistics and to analyze the performance of different wireless\ncommunications options. To this end, we consider a heterogeneous vehicle\nrouting problem with various constraints. We consider two approaches regarding\nthe dispatching and recovery of drones and evaluate their benefits as opposed\nto parcel delivery with a classic truck only. Furthermore, we compare two\nnetworking technologies for enabling coordination of the self-organizing teams\nof drones with a realistically modeled environment: one approach relying on\nbase station oriented Long Term Evolution (LTE) vs. a more decentralized\nCellular Vehicle-to-Everything (C-V2X) solution. The results show time savings\nof nearly 40% can be achieved through drone usage and that the negative impact\nof urban shadowing on network communications in the base station oriented LTE\napproach can be compensated by leveraging decentralized C-V2X communications\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 10:35:42 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 14:42:37 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Patchou", "Manuel", ""], ["Sliwa", "Benjamin", ""], ["Wietfeld", "Christian", ""]]}, {"id": "1910.10453", "submitter": "Jihong Park", "authors": "Anis Elgabli, Jihong Park, Amrit S. Bedi, Chaouki Ben Issaid, Mehdi\n  Bennis, Vaneet Aggarwal", "title": "Q-GADMM: Quantized Group ADMM for Communication Efficient Decentralized\n  Machine Learning", "comments": "19 pages, 8 figures; to appear in IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a communication-efficient decentralized machine\nlearning (ML) algorithm, coined quantized group ADMM (Q-GADMM). To reduce the\nnumber of communication links, every worker in Q-GADMM communicates only with\ntwo neighbors, while updating its model via the group alternating direction\nmethod of multipliers (GADMM). Moreover, each worker transmits the quantized\ndifference between its current model and its previously quantized model,\nthereby decreasing the communication payload size. However, due to the lack of\ncentralized entity in decentralized ML, the spatial sparsity and payload\ncompression may incur error propagation, hindering model training convergence.\nTo overcome this, we develop a novel stochastic quantization method to\nadaptively adjust model quantization levels and their probabilities, while\nproving the convergence of Q-GADMM for convex objective functions. Furthermore,\nto demonstrate the feasibility of Q-GADMM for non-convex and stochastic\nproblems, we propose quantized stochastic GADMM (Q-SGADMM) that incorporates\ndeep neural network architectures and stochastic sampling. Simulation results\ncorroborate that Q-GADMM significantly outperforms GADMM in terms of\ncommunication efficiency while achieving the same accuracy and convergence\nspeed for a linear regression task. Similarly, for an image classification task\nusing DNN, Q-SGADMM achieves significantly less total communication cost with\nidentical accuracy and convergence speed compared to its counterpart without\nquantization, i.e., stochastic GADMM (SGADMM).\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 10:47:06 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 13:40:21 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 17:31:00 GMT"}, {"version": "v4", "created": "Mon, 27 Jul 2020 19:33:13 GMT"}, {"version": "v5", "created": "Mon, 3 Aug 2020 09:37:46 GMT"}, {"version": "v6", "created": "Sat, 3 Oct 2020 18:28:18 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Elgabli", "Anis", ""], ["Park", "Jihong", ""], ["Bedi", "Amrit S.", ""], ["Issaid", "Chaouki Ben", ""], ["Bennis", "Mehdi", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1910.10604", "submitter": "Maximilian Bachl", "authors": "Maximilian Bachl, Joachim Fabini, Tanja Zseby", "title": "Cocoa: Congestion Control Aware Queuing", "comments": null, "journal-ref": "Buffer Sizing Workshop (BS'19), December 2-3, 2019, Stanford, CA,\n  USA", "doi": "10.1145/3375235.3375236", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent model-based congestion control algorithms such as BBR use repeated\nmeasurements at the endpoint to build a model of the network connection and use\nit to achieve optimal throughput with low queuing delay. Conversely, applying\nthis model-based approach to Active Queue Management (AQM) has so far received\nless attention. We propose the new AQM scheduler cocoa based on fair queuing,\nwhich adapts the buffer size depending on the needs of each flow without\nrequiring active participation from the endpoint. We implement this scheduler\nfor the Linux kernel and show that it interacts well with the most common\ncongestion control algorithms and can significantly increase throughput\ncompared to fair CoDel while avoiding overbuffering.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:14:19 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 17:47:29 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Bachl", "Maximilian", ""], ["Fabini", "Joachim", ""], ["Zseby", "Tanja", ""]]}, {"id": "1910.10695", "submitter": "Joan Pujol Roig", "authors": "Joan S Pujol Roig, David M. Gutierrez-Estevez and Deniz G\\\"und\\\"uz", "title": "Management and Orchestration of Virtual Network Functions via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Management and orchestration (MANO) of resources by virtual network functions\n(VNFs) represents one of the key challenges towards a fully virtualized network\narchitecture as envisaged by 5G standards. Current threshold-based policies\ninefficiently over-provision network resources and under-utilize available\nhardware, incurring high cost for network operators, and consequently, the\nusers. In this work, we present a MANO algorithm for VNFs allowing a central\nunit (CU) to learn to autonomously re-configure resources (processing power and\nstorage), deploy new VNF instances, or offload them to the cloud, depending on\nthe network conditions, available pool of resources, and the VNF requirements,\nwith the goal of minimizing a cost function that takes into account the\neconomical cost as well as latency and the quality-of-service (QoS) experienced\nby the users. First, we formulate the stochastic resource optimization problem\nas a parameterized action Markov decision process (PAMDP). Then, we propose a\nsolution based on deep reinforcement learning (DRL). More precisely, we present\na novel RL approach called, parameterized action twin (PAT) deterministic\npolicy gradient, which leverages an actor-critic architecture to learn to\nprovision resources to the VNFs in an online manner. Finally, we present\nnumerical performance results, and map them to 5G key performance indicators\n(KPIs). To the best of our knowledge, this is the first work that considers DRL\nfor MANO of VNFs' physical resources.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:52:26 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Roig", "Joan S Pujol", ""], ["Gutierrez-Estevez", "David M.", ""], ["G\u00fcnd\u00fcz", "Deniz", ""]]}, {"id": "1910.10766", "submitter": "Kemal Davaslioglu", "authors": "Kemal Davaslioglu and Yalin E. Sagduyu", "title": "Trojan Attacks on Wireless Signal Classification with Adversarial\n  Machine Learning", "comments": "2019 - IEEE International Symposium on Dynamic Spectrum Access\n  Networks (DySPAN) Workshop on Data-Driven Dynamic Spectrum Sharing, 6 pages,\n  7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Trojan (backdoor or trapdoor) attack that targets deep learning\napplications in wireless communications. A deep learning classifier is\nconsidered to classify wireless signals using raw (I/Q) samples as features and\nmodulation types as labels. An adversary slightly manipulates training data by\ninserting Trojans (i.e., triggers) to only few training data samples by\nmodifying their phases and changing the labels of these samples to a target\nlabel. This poisoned training data is used to train the deep learning\nclassifier. In test (inference) time, an adversary transmits signals with the\nsame phase shift that was added as a trigger during training. While the\nreceiver can accurately classify clean (unpoisoned) signals without triggers,\nit cannot reliably classify signals poisoned with triggers. This stealth attack\nremains hidden until activated by poisoned inputs (Trojans) to bypass a signal\nclassifier (e.g., for authentication). We show that this attack is successful\nover different channel conditions and cannot be mitigated by simply\npreprocessing the training and test data with random phase variations. To\ndetect this attack, activation based outlier detection is considered with\nstatistical as well as clustering techniques. We show that the latter one can\ndetect Trojan attacks even if few samples are poisoned.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 18:47:30 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Davaslioglu", "Kemal", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1910.10792", "submitter": "Safwan Alfattani", "authors": "Safwan Alfattani, Wael Jaafar, Halim Yanikomeroglu, Abbas Yongacoglu", "title": "Multi-UAV Data Collection Framework for Wireless Sensor Networks", "comments": "To be presented at 2019 IEEE Global Communications Conference\n  (Globecom)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a framework design for wireless sensor networks\nbased on multiple unmanned aerial vehicles (UAVs). Specifically, we aim to\nminimize deployment and operational costs, with respect to budget and power\nconstraints. To this end, we first optimize the number and locations of cluster\nheads (CHs) guaranteeing data collection from all sensors. Then, to minimize\nthe data collection flight time, we optimize the number and trajectories of\nUAVs. Accordingly, we distinguish two trajectory approaches: 1) where a UAV\nhovers exactly above the visited CH; and 2) where a UAV hovers within a range\nof the CH. The results of this include guidelines for data collection design.\nThe characteristics of sensor nodes' K-means clustering are then discussed.\nNext, we illustrate the performance of optimal and heuristic solutions for\ntrajectory planning. The genetic algorithm is shown to be near-optimal with\nonly $3.5\\%$ degradation. The impacts of the trajectory approach, environment,\nand UAVs' altitude are investigated. Finally, fairness of UAVs trajectories is\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 20:07:05 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 22:14:01 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Alfattani", "Safwan", ""], ["Jaafar", "Wael", ""], ["Yanikomeroglu", "Halim", ""], ["Yongacoglu", "Abbas", ""]]}, {"id": "1910.11002", "submitter": "Szymon Szott", "authors": "Jacek Wszo{\\l}ek, Szymon Ludyga, Wojciech Anzel, Szymon Szott", "title": "Revisiting LTE LAA: Channel Access, QoS, and Coexistence with WiFi", "comments": "7 pages, 4 figures, 2 tables", "journal-ref": "IEEE Communications Magazine, vol. 59, no. 2, pp. 91-97, February\n  2021", "doi": "10.1109/MCOM.001.2000595", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network operators are looking towards LTE License Assisted Access (LAA) as a\nmeans of extending capacity by offloading traffic to unlicensed bands. However,\noperation in these bands requires abiding to certain coexistence rules in terms\nof channel access. The description of these rules in existing literature is not\nalways in line with the latest standards. Therefore, in this paper, we clarify\nthe operation of LAA, focusing on channel access and methods of providing\nQuality of Service (QoS) support. In terms of coexistence, we evaluate the\nimpact of LAA under its various QoS settings on Wi-Fi performance in an\nexperimental testbed. Finally, we describe the upcoming research challenges for\nLTE-based technologies in unlicensed bands considering the latest developments.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 09:55:01 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 09:40:58 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 11:18:25 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 09:11:18 GMT"}, {"version": "v5", "created": "Wed, 16 Dec 2020 16:03:40 GMT"}, {"version": "v6", "created": "Wed, 24 Mar 2021 13:31:04 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Wszo\u0142ek", "Jacek", ""], ["Ludyga", "Szymon", ""], ["Anzel", "Wojciech", ""], ["Szott", "Szymon", ""]]}, {"id": "1910.11700", "submitter": "Siddhartha Borkotoky", "authors": "Siddhartha S. Borkotoky, Udo Schilcher, Christian Raffelsberger", "title": "Application-Layer Coding with Intermittent Feedback under Delay and\n  Duty-Cycle Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two application-layer coding schemes for delay-constrained\npoint-to-point packet communications with restrictions on the transmitter's\nmaximum duty-cycle. The schemes operate over GF(2) and utilize intermittently\navailable receiver feedback for erasure correction. Applications that will\nbenefit from the proposed schemes include wireless sensor networks in which\nenergy-constrained sensors must deliver readings to a gateway within a\ndeadline. Simulation results for independent Bernoulli erasure channels,\nGilbert-Elliott channels, and Long Range (LoRa) communications demonstrate\norders-of-magnitude reductions in the delivery failure rate as compared to\nfeedback-assisted repetition redundancy and a blind coding scheme that does not\nutilize feedback.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 13:10:38 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 08:01:12 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Borkotoky", "Siddhartha S.", ""], ["Schilcher", "Udo", ""], ["Raffelsberger", "Christian", ""]]}, {"id": "1910.11756", "submitter": "Sadaf Mustafiz", "authors": "Sadaf Mustafiz, Omar Hassane, Guillaume Dupont, Ferhat Khendek, Maria\n  Toeroe", "title": "Model-Driven Process Enactment for NFV Systems with MAPLE", "comments": "27 pages, 14 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Network Functions Virtualization (NFV) advent is making way for the rapid\ndeployment of network services (NS) for telecoms. Automation of network service\nmanagement is one of the main challenges currently faced by the NFV community.\nExplicitly defining a process for the design, deployment, and management of\nnetwork services and automating it is therefore highly desirable and beneficial\nfor NFV systems. The use of model-driven orchestration means has been advocated\nin this context. As part of this effort to support automated process execution,\nwe propose a process enactment approach with NFV systems as the target\napplication domain. Our process enactment approach is megamodel-based. An\nintegrated process modelling and enactment environment, MAPLE, has been built\ninto Papyrus for this purpose. Process modelling is carried out with UML\nactivity diagrams. The enactment environment transforms the process model to a\nmodel transformation chain, and then orchestrates it with the use of\nmegamodels. In this paper we present our approach and environment MAPLE, its\nrecent extension with new features as well as application to an enriched case\nstudy consisting of NS design and onboarding process.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 14:25:12 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Mustafiz", "Sadaf", ""], ["Hassane", "Omar", ""], ["Dupont", "Guillaume", ""], ["Khendek", "Ferhat", ""], ["Toeroe", "Maria", ""]]}, {"id": "1910.11890", "submitter": "Umur Karabulut", "authors": "Umur Karabulut and Ahmad Awada and Ingo Viering and Andre Noll Barreto\n  and Gerhard P. Fettweis", "title": "RACH Optimization with Decision Tree Based Supervised Learning for\n  Conditional Handover in 5G Beamformed Systems", "comments": "8 pages, 7 figures, submitted to IEEE Access", "journal-ref": "Access-2021-04237", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher frequencies that are introduced in 5G networks cause rapid signal\ndegradation and challenge user mobility. In recent studies, a conditional\nhandover procedure has been adopted for 5G networks to enhance user mobility\nrobustness. In this paper, mobility performance of the conditional handover is\nanalysed for 5G mm-Wave systems with beamforming. In addition, a resource\nefficient random access procedure is proposed that increases the chance of\ncontention-free random access during handover, which reduces signaling and\ninterruption time. Moreover, simple, yet, effective decision tree based\nsupervised learning method is proposed to minimize the handover failures that\nare caused by beam preparation phase of random access procedure. Results reveal\nthe trade-off between contention free random access and handover failures. It\nis also shown that the optimum operation point of random access is achievable\nwith proposed learning algorithm for conditional handover.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 18:08:10 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 16:08:18 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 21:37:22 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Karabulut", "Umur", ""], ["Awada", "Ahmad", ""], ["Viering", "Ingo", ""], ["Barreto", "Andre Noll", ""], ["Fettweis", "Gerhard P.", ""]]}, {"id": "1910.11916", "submitter": "Abu Sufian", "authors": "Anuradha Banerjee, Abu Sufian, Paramartha Dutta and M M Hafizur Rahman", "title": "Minus HELLO: HELLO Devoid Protocols for Energy Preservation in Mobile Ad\n  Hoc Networks", "comments": "33 pages, 20 figures, pre-print of under review manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile ad-hoc networks, nodes have to transmit HELLO or Route Maintenance\nmessages at regular intervals, and all nodes residing within its radio range,\nreply with an acknowledgment message informing their node identifier, current\nlocation, and radio-range. Regular transmitting these messages consume a\nsignificant amount of battery power in nodes, especially when the set of\ndown-link neighbors does not change over time and the radio-range of the sender\nnode is large. The present article focuses on this aspect and tries to\neliminate the number of HELLO messages in existing state-of-art protocols.\nAlso, it shortens radio-ranges of nodes whenever possible. Simulation results\nshow that the average lifetime of nodes greatly increases in proposed Minus\nHELLO devoid routing protocols along with a great increase in network\nthroughput. Also, the required number of route re-discovery reduces.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 19:56:27 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 10:28:53 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 18:44:02 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Banerjee", "Anuradha", ""], ["Sufian", "Abu", ""], ["Dutta", "Paramartha", ""], ["Rahman", "M M Hafizur", ""]]}, {"id": "1910.12000", "submitter": "Ankita Samaddar", "authors": "Ankita Samaddar, Arvind Easwaran, Rui Tan", "title": "SlotSwapper: A Schedule Randomization protocol for Real-Time\n  WirelessHART Networks", "comments": "RTN, ECRTS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Industrial process control systems are time-critical systems where reliable\ncommunications between sensors and actuators need to be guaranteed within\nstrict deadlines to maintain safe operation of all the components of the\nsystem. WirelessHART is the most widely adopted standard which serve as the\nmedium of communication in industrial setups due to its support for Time\nDivision Multiple Access (TDMA)based communication, multiple channels, channel\nhopping, centralized architecture, redundant routes and avoidance of spatial\nre-use of channels. However, the communication schedule in WirelessHART network\nis decided by a centralized network manager at the time of network\ninitialization and the same communication schedule repeats every hyper-period.\nDue to predictability in the time slots of the communication schedule, these\nsystems are vulnerable to timing attacks which eventually can disrupt the\nsafety of the system. In this work, we present a moving target defense\nmechanism, the SlotSwapper, which uses schedule randomization techniques to\nrandomize the time slots over a hyper-period schedule, while still preserving\nall the feasibility constraints of a real-time WirelessHART network and makes\nthe schedule uncertain every hyper-period. We tested the feasibility of the\ngenerated schedules on random topologies with 100 simulated motes in Cooja\nsimulator. We use schedule entropy to measure the confidentiality of our\nalgorithm in terms of randomness in the time slots of the generated schedules.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 05:31:13 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Samaddar", "Ankita", ""], ["Easwaran", "Arvind", ""], ["Tan", "Rui", ""]]}, {"id": "1910.12657", "submitter": "Furqan Jameel", "authors": "Khush Bakht, Furqan Jameel, Zain Ali, Wali Ullah Khan, Imran Khan,\n  Guftaar Ahmad Sardar Sidhu, and Jeong Woo Lee", "title": "Power Allocation and User Assignment Scheme for Beyond 5G Heterogeneous\n  Networks", "comments": "Beyond 5G, Cognitive Radio (CR), Dual Decomposition, User Fairness,\n  Heterogeneous Networks (HetNets)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue of spectrum scarcity in wireless networks is becoming prominent and\ncritical with each passing year. Although several promising solutions have been\nproposed to provide a solution to spectrum scarcity, most of them have many\nassociated tradeoffs. In this context, one of the emerging ideas relates to the\nutilization of cognitive radios (CR) for future heterogeneous networks\n(HetNets). This paper provides a marriage of two promising candidates (i.e., CR\nand HetNets) for beyond fifth generation (5G) wireless networks. More\nspecifically, a joint power allocation and user assignment solution for the\nmulti-user underlay CR-based HetNets has been proposed and evaluated. To\ncounter the limiting factors in these networks, the individual power of\ntransmitting nodes and interference temperature protection constraints of the\nprimary networks have been considered. An efficient solution is designed from\nthe dual decomposition approach, where the optimal user assignment is obtained\nfor the optimized power allocation at each node. The simulation results\nvalidate the superiority of the proposed optimization scheme against\nconventional baseline techniques.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 14:03:03 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Bakht", "Khush", ""], ["Jameel", "Furqan", ""], ["Ali", "Zain", ""], ["Khan", "Wali Ullah", ""], ["Khan", "Imran", ""], ["Sidhu", "Guftaar Ahmad Sardar", ""], ["Lee", "Jeong Woo", ""]]}, {"id": "1910.12714", "submitter": "Maxime Mouchet", "authors": "Maxime Mouchet (Lab-STICC, IMT Atlantique - INFO), Sandrine Vaton\n  (Lab-STICC, IMT Atlantique - INFO), Thierry Chonavel (Lab-STICC, IMT\n  Atlantique - SC), Emile Aben, Jasper den Hertog", "title": "Large-Scale Characterization and Segmentation of Internet Path Delays\n  with Infinite HMMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Round-Trip Times are one of the most commonly collected performance metrics\nin computer networks. Measurement platforms such as RIPE Atlas provide\nresearchers and network operators with an unprecedented amount of historical\nInternet delay measurements. It would be very useful to automate the processing\nof these measurements (statistical characterization of paths performance,\nchange detection, recognition of recurring patterns, etc.). Humans are pretty\ngood at finding patterns in network measurements but it can be difficult to\nautomate this to enable many time series being processed at the same time. In\nthis article we introduce a new model, the HDP-HMM or infinite hidden Markov\nmodel, whose performance in trace segmentation is very close to human\ncognition. This is obtained at the cost of a greater complexity and the\nambition of this article is to make the theory accessible to network monitoring\nand management researchers. We demonstrate that this model provides very\naccurate results on a labeled dataset and on RIPE Atlas and CAIDA MANIC data.\nThis method has been implemented in Atlas and we introduce the publicly\naccessible Web API.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:35:44 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mouchet", "Maxime", "", "Lab-STICC, IMT Atlantique - INFO"], ["Vaton", "Sandrine", "", "Lab-STICC, IMT Atlantique - INFO"], ["Chonavel", "Thierry", "", "Lab-STICC, IMT\n  Atlantique - SC"], ["Aben", "Emile", ""], ["Hertog", "Jasper den", ""]]}, {"id": "1910.12767", "submitter": "Beatriz Soret", "authors": "Beatriz Soret and Sucheta Ravikanti and Petar Popovski", "title": "Latency and timeliness in multi-hop satellite networks", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical definition of network delay has been recently augmented by the\nconcept of information timeliness, or Age of Information (AoI). We analyze the\nnetwork delay and the AoI in a multi-hop satellite network that relays status\nupdates from satellite 1, receiving uplink traffic from ground devices, to\nsatellite K, using K-2 intermediate satellite nodes. The last node, K, is the\nclosest satellite with connectivity to a ground station. The satellite\nformation is modeled as a queue network of M/M/1 systems connected in series.\nThe scenario is then generalized for the case in which all satellites receive\nuplink traffic from ground, and work at the same time as relays of the packets\nfrom the previous nodes. The results show that the minimum average AoI is\nexperienced at a decreasing system utilization when the number of nodes is\nincreased. Furthermore, unloading the first nodes of the chain reduces the\nqueueing time and therefore the average AoI. These findings provide insights\nfor designing multi-hop satellite networks for latency-sensitive applications.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 15:48:54 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 07:14:29 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Soret", "Beatriz", ""], ["Ravikanti", "Sucheta", ""], ["Popovski", "Petar", ""]]}, {"id": "1910.12806", "submitter": "Jinoh Kim", "authors": "Makiya Nakashima, Alex Sim, Youngsoo Kim, Jonghyun Kim, Jinoh Kim", "title": "An Ensemble Approach toward Automated Variable Selection for Network\n  Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While variable selection is essential to optimize the learning complexity by\nprioritizing features, automating the selection process is preferred since it\nrequires laborious efforts with intensive analysis otherwise. However, it is\nnot an easy task to enable the automation due to several reasons. First,\nselection techniques often need a condition to terminate the reduction process,\nfor example, by using a threshold or the number of features to stop, and\nsearching an adequate stopping condition is highly challenging. Second, it is\nuncertain that the reduced variable set would work well; our preliminary\nexperimental result shows that well-known selection techniques produce\ndifferent sets of variables as a result of reduction (even with the same\ntermination condition), and it is hard to estimate which of them would work the\nbest in future testing. In this paper, we demonstrate the potential power of\nour approach to the automation of selection process that incorporates\nwell-known selection methods identifying important variables. Our experimental\nresults with two public network traffic data (UNSW-NB15 and IDS2017) show that\nour proposed method identifies a small number of core variables, with which it\nis possible to approximate the performance to the one with the entire\nvariables.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:03:02 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Nakashima", "Makiya", ""], ["Sim", "Alex", ""], ["Kim", "Youngsoo", ""], ["Kim", "Jonghyun", ""], ["Kim", "Jinoh", ""]]}, {"id": "1910.12897", "submitter": "Maciej Besta", "authors": "Maciej Besta, Torsten Hoefler", "title": "Active Access: A Mechanism for High-Performance Distributed Data-Centric\n  Computations", "comments": null, "journal-ref": "Proceedings of the 29th ACM International Conference on\n  Supercomputing (ACM ICS'15), 2015", "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote memory access (RMA) is an emerging high-performance programming model\nthat uses RDMA hardware directly. Yet, accessing remote memories cannot invoke\nactivities at the target which complicates implementation and limits\nperformance of data-centric algorithms. We propose Active Access (AA), a\nmechanism that integrates well-known active messaging (AM) semantics with RMA\nto enable high-performance distributed data-centric computations. AA supports a\nnew programming model where the user specifies handlers that are triggered when\nincoming puts and gets reference designated addresses. AA is based on a set of\nextensions to the Input/Output Memory Management Unit (IOMMU), a unit that\nprovides high-performance hardware support for remapping I/O accesses to\nmemory. We illustrate that AA outperforms existing AM and RMA designs,\naccelerates various codes such as distributed hashtables or logging schemes,\nand enables new protocols such as incremental checkpointing for RMA.We also\ndiscuss how extended IOMMUs can support a virtualized global address space in a\ndistributed system that offers features known from on-node memory\nvirtualization. We expect that AA can enhance the design of HPC operating and\nruntime systems in large computing centers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:09:23 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 23:13:52 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Besta", "Maciej", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1910.13067", "submitter": "The Canh Dinh", "authors": "Canh T. Dinh, Nguyen H. Tran, Minh N. H. Nguyen, Choong Seon Hong, Wei\n  Bao, Albert Y. Zomaya, Vincent Gramoli", "title": "Federated Learning over Wireless Networks: Convergence Analysis and\n  Resource Allocation", "comments": null, "journal-ref": null, "doi": "10.1109/TNET.2020.3035770", "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is an increasing interest in a fast-growing machine learning technique\ncalled Federated Learning, in which the model training is distributed over\nmobile user equipments (UEs), exploiting UEs' local computation and training\ndata. Despite its advantages in data privacy-preserving, Federated Learning\n(FL) still has challenges in heterogeneity across UEs' data and physical\nresources. We first propose a FL algorithm which can handle the heterogeneous\nUEs' data challenge without further assumptions except strongly convex and\nsmooth loss functions. We provide the convergence rate characterizing the\ntrade-off between local computation rounds of UE to update its local model and\nglobal communication rounds to update the FL global model. We then employ the\nproposed FL algorithm in wireless networks as a resource allocation\noptimization problem that captures the trade-off between the FL convergence\nwall clock time and energy consumption of UEs with heterogeneous computing and\npower resources. Even though the wireless resource allocation problem of FL is\nnon-convex, we exploit this problem's structure to decompose it into three\nsub-problems and analyze their closed-form solutions as well as insights to\nproblem design. Finally, we illustrate the theoretical analysis for the new\nalgorithm with Tensorflow experiments and extensive numerical results for the\nwireless resource allocation sub-problems. The experiment results not only\nverify the theoretical convergence but also show that our proposed algorithm\noutperforms the vanilla FedAvg algorithm in terms of convergence rate and\ntesting accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 03:31:28 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 03:31:59 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 00:16:29 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 03:09:33 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Dinh", "Canh T.", ""], ["Tran", "Nguyen H.", ""], ["Nguyen", "Minh N. H.", ""], ["Hong", "Choong Seon", ""], ["Bao", "Wei", ""], ["Zomaya", "Albert Y.", ""], ["Gramoli", "Vincent", ""]]}, {"id": "1910.13194", "submitter": "Ghafour Ahani", "authors": "Ghafour Ahani and Di Yuan", "title": "Accounting for Information Freshness in Scheduling of Content Caching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of optimal scheduling of content\nplacement along time in a base station with limited cache capacity, taking into\naccount jointly the offloading effect and freshness of information. We model\noffloading based on popularity in terms of the number of requests and\ninformation freshness based on the notion of age of information (AoI). The\nobjective is to reduce the load of backhaul links as well as the AoI of\ncontents in the cache via a joint cost function. For the resulting optimization\nproblem, we prove its hardness via a reduction from the Partition problem.\nNext, via a mathematical reformulation, we derive a solution approach based on\ncolumn generation and a tailored rounding mechanism. Finally, we provide\nperformance evaluation results showing that our algorithm provides near-optimal\nsolutions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:06:00 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Ahani", "Ghafour", ""], ["Yuan", "Di", ""]]}, {"id": "1910.13216", "submitter": "Alexander P. Kartun-Giles MSci PhD", "authors": "Alexander P. Kartun-Giles, Konstantinos Koufos and Sunwoo Kim", "title": "Meta Distribution of SIR in Ultra-Dense Networks with Bipartite\n  Euclidean Matchings", "comments": "6 pages, 5 figures, accepted for the Communication Theory Symposium,\n  IEEE ICC2020, Dublin, Ireland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study how a bipartite Euclidean matching can be used to\ninvestigate the reliability of communication in interference-limited\nultra-dense networks. We do this by studying the corresponding statistics of\nthe meta distribution of the signal-to-interference ratio in a near-optimally\nshort, perfect, Euclidean distance edge-weighted, bipartite matching between\ntwo binomial point processes. This gives the proportion of point processes\nwhich have a reliable link near the origin, or, due to ergodicity, the\nproportion of all links, in one randomly selected point pattern, which are\nreliable. The new matching idea effectively leads to variable link distances, a\nfactor not typically incorporated in meta distribution studies. We ask how this\neffects its statistics, deriving the moments of the meta distribution,\ncomparing with Monte Carlo simulations, and analysing the key differences which\nappear, particularly the effects of the significantly different link distance\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:56:27 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 13:20:47 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Kartun-Giles", "Alexander P.", ""], ["Koufos", "Konstantinos", ""], ["Kim", "Sunwoo", ""]]}, {"id": "1910.13242", "submitter": "Muhammad Shahid Iqbal", "authors": "Muhammad Shahid Iqbal, Yalcin Sadi, Sinem Coleri", "title": "Throughput Maximization for Full Duplex Wireless Powered Communication\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a full duplex wireless powered communication\nnetwork where multiple users with RF energy harvesting capabilities communicate\nto a hybrid energy and information access point. An optimization framework is\nproposed with the objective of maximizing the sum throughput of the users\nsubject to energy causality and maximum transmit power constraints considering\na realistic energy harvesting model incorporating initial battery levels of the\nusers. The joint optimization of power control, time allocation and scheduling\nis mathematically formulated as a mixed integer non linear programming problem\nwhich is hard to solve for a global optimum. The optimal power and time\nallocation and scheduling decisions are investigated separately based on the\noptimality analysis on the optimization variables. Optimal power and time\nallocation problem is proven to be convex for a given transmission order. Based\non the derived optimality conditions, we propose a fast polynomial-time\ncomplexity heuristic algorithm. We illustrate that the proposed algorithm\nperforms very close-to-optimal while significantly outperforming an equal time\nallocation based scheduling scheme.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 13:10:15 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Iqbal", "Muhammad Shahid", ""], ["Sadi", "Yalcin", ""], ["Coleri", "Sinem", ""]]}, {"id": "1910.13312", "submitter": "Ismail Butun", "authors": "Ismail Butun, Patrik \\\"Osterberg, Houbing Song", "title": "Security of the Internet of Things: Vulnerabilities, Attacks and\n  Countermeasures", "comments": "25 pages, 3 figures, 4 tables, to be appear at IEEE Communications\n  Surveys & Tutorials in 2020", "journal-ref": "IEEE Communications Surveys & Tutorials; 13 November 2019", "doi": "10.1109/COMST.2019.2953364", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wireless Sensor Networks (WSNs) constitute one of the most promising\nthird-millennium technologies and have a wide range of applications in our\nsurrounding environment. The reason behind the vast adoption of WSNs in various\napplications is that they have tremendously appealing features, e.g., low\nproduction cost, low installation cost, unattended network operation,\nautonomous and longtime operation. WSNs have started to merge with the Internet\nof Things (IoT) through the introduction of Internet access capability in\nsensor nodes and sensing ability in Internet-connected devices. Thereby, the\nIoT is providing access to huge amount of data, collected by the WSNs, over the\nInternet. However, owing to the absence of a physical line-of-defense, i.e.\nthere is no dedicated infrastructure such as gateways to watch and observe the\nflowing information in the network, security of WSNs along with IoT is of a big\nconcern to the scientific community. Besides, recent integration and\ncollaboration of WSNs with IoT will open new challenges and problems in terms\nof security. Hence, this would be a nightmare for the individuals using these\nsystems as well as the security administrators who are managing those networks.\nTherefore, a detailed review of security attacks towards WSNs and IoT, along\nwith the techniques for prevention, detection, and mitigation of those attacks\nare provided in this paper. In this text, attacks are categorized and treated\ninto mainly two parts, most or all types of attacks towards WSNs and IoT are\ninvestigated under that umbrella: \"Passive Attacks\" and \"Active Attacks\".\nUnderstanding these attacks and their associated defense mechanisms will help\nto pave a secure path towards the proliferation and public acceptance of IoT\ntechnology.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:09:54 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Butun", "Ismail", ""], ["\u00d6sterberg", "Patrik", ""], ["Song", "Houbing", ""]]}, {"id": "1910.13315", "submitter": "Kemal Davaslioglu", "authors": "Kemal Davaslioglu, Sohraab Soltani, Tugba Erpek, Yalin E. Sagduyu", "title": "DeepWiFi: Cognitive WiFi with Deep Learning", "comments": "Accepted to IEEE Transactions on Mobile Computing, 17 pages\n  (including the Appendix), 23 figures, and 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the DeepWiFi protocol, which hardens the baseline WiFi (IEEE\n802.11ac) with deep learning and sustains high throughput by mitigating\nout-of-network interference. DeepWiFi is interoperable with baseline WiFi and\nbuilds upon the existing WiFi's PHY transceiver chain without changing the MAC\nframe format. Users run DeepWiFi for i) RF front end processing; ii) spectrum\nsensing and signal classification; iii) signal authentication; iv) channel\nselection and access; v) power control; vi) modulation and coding scheme (MCS)\nadaptation; and vii) routing. DeepWiFi mitigates the effects of probabilistic,\nsensing-based, and adaptive jammers. RF front end processing applies a deep\nlearning-based autoencoder to extract spectrum-representative features. Then a\ndeep neural network is trained to classify waveforms reliably as idle, WiFi, or\njammer. Utilizing channel labels, users effectively access idle or jammed\nchannels, while avoiding interference with legitimate WiFi transmissions\n(authenticated by machine learning-based RF fingerprinting) resulting in higher\nthroughput. Users optimize their transmit power for low probability of\nintercept/detection and their MCS to maximize link rates used by backpressure\nalgorithm for routing. Supported by embedded platform implementation, DeepWiFi\nprovides major throughput gains compared to baseline WiFi and another\njamming-resistant protocol, especially when channels are likely to be jammed\nand the signal-to-interference-plus-noise-ratio is low.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:14:11 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Davaslioglu", "Kemal", ""], ["Soltani", "Sohraab", ""], ["Erpek", "Tugba", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1910.13337", "submitter": "Friedrich Doku", "authors": "Friedrich Doku", "title": "Zephyr: Hiding Metadata in a Messaging System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Private messaging over internet related services is difficult to implement.\nRegular end-to-end encryption messaging systems are prone to man in the middle\nattacks and only hide messages but not the identity of its users. For example,\nWhatsApp offers a strong privacy guarantee but does not hide much Metadata\nbecause it uses end-to-end encryption. Other messaging systems such as Skype\ncan be monitored by government agencies and have backdoors implemented into its\nsoftware. Zephyr is an anonymous messaging system that protects the privacy of\nmessage contents and message metadata. Users that use Zephyr do not reveal who\nthey are talking to or the contents of their messages. The goal of Zephyr is to\ndecrease the amount of information being sent by the user and hide as much\nmetadata as possible.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 01:44:14 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Doku", "Friedrich", ""]]}, {"id": "1910.13502", "submitter": "Erdem Koyuncu", "authors": "Erdem Koyuncu", "title": "The Tradeoff Between Coverage and Computation in Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed edge computing scenario consisting of several\nwireless nodes that are located over an area of interest. Specifically, some of\nthe \"master\" nodes are tasked to sense the environment (e.g., by acquiring\nimages or videos via cameras) and process the corresponding sensory data, while\nthe other nodes are assigned as \"workers\" to help the computationally-intensive\nprocessing tasks of the masters. A new tradeoff that has not been previously\nexplored in the existing literature arises in such a formulation: On one hand,\none wishes to allocate as many master nodes as possible to cover a large area\nfor accurate monitoring. On the other hand, one also wishes to allocate as many\nworker nodes as possible to maximize the computation rate of the sensed data.\nIt is in the context of this tradeoff that this work is presented. By utilizing\nthe basic physical layer principles of wireless communication systems, we\nformulate and analyze the tradeoff between the coverage and computation\nperformance of spatial networks. We also present an algorithm to find the\noptimal tradeoff and demonstrate its performance through numerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 19:51:34 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Koyuncu", "Erdem", ""]]}, {"id": "1910.13537", "submitter": "Nirwan Ansari", "authors": "Qiang Liu, Tao Han, and Nirwan Ansari", "title": "Learning-Assisted Secure End-to-End Network Slicing for Cyber-Physical\n  Systems", "comments": "Accepted for publication in the special issue, Cyber Security Based\n  on Artificial Intelligence for Cyber-Physical Systems, in IEEE Network to\n  appear in May 2020", "journal-ref": null, "doi": null, "report-no": "TR-ANL-2019-002", "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a pressing need to interconnect physical systems such as power grid\nand vehicles for efficient management and safe operations. Owing to the diverse\nfeatures of physical systems, there is hardly a one-size-fits-all networking\nsolution for developing cyber-physical systems. Network slicing is a promising\ntechnology that allows network operators to create multiple virtual networks on\ntop of a shared network infrastructure. These virtual networks can be tailored\nto meet the requirements of different cyber-physical systems. However, it is\nchallenging to design secure network slicing solutions that can efficiently\ncreate end-to-end network slices for diverse cyber-physical systems. In this\narticle, we discuss the challenges and security issues of network slicing,\nstudy learning-assisted network slicing solutions, and analyze their\nperformance under the denial-of-service attack. We also present a design and\nimplementation of a small-scale testbed for evaluating the network slicing\nsolutions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 21:15:15 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Liu", "Qiang", ""], ["Han", "Tao", ""], ["Ansari", "Nirwan", ""]]}, {"id": "1910.13587", "submitter": "Mark Eisen", "authors": "Mark Eisen, Mohammad M. Rashid, Alejandro Ribeiro, Dave Cavalcanti", "title": "Scheduling Low Latency Traffic for Wireless Control Systems in 5G\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of allocating 5G radio resources over wireless\ncommunication links to control a series of independent low-latency wireless\ncontrol systems common in industrial settings. Each control system sends state\ninformation to the base station to compute control signals under tight latency\nrequirements. Such latency requirements can be met by restricting the uplink\ntraffic to a single subframe in each 5G frame, thus ensuring a millisecond\nlatency bound while leaving the remaining subframes available for scheduling\noverhead and coexisting broadband traffic. A linear assignment problem can be\nformulated to minimize the expected number of packet drops, but this alone is\nnot sufficient to achieve good performance. We propose an optimal scheduling\nwith respect to a control operation cost that allocates resources based on\ncurrent control system needs. The resulting control-aware scheduling method is\ntested in simulation experiments that show drastically improved performance in\n5G settings relative to control-agnostic scheduling under the proposed\ntime-sliced frame structure.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 00:03:56 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Eisen", "Mark", ""], ["Rashid", "Mohammad M.", ""], ["Ribeiro", "Alejandro", ""], ["Cavalcanti", "Dave", ""]]}, {"id": "1910.13625", "submitter": "Md Masuduzzaman", "authors": "Md Masuduzzaman, Ashik Mahmud, Anik Islam, and Md Mofijul Islam", "title": "Two Phase Authentication and VPN Based Secured Communication for IoT\n  Home Networks", "comments": "Paper has been accepted in 1st International Conference on Machine\n  Learning, Image Processing, Network Security and Data Sciences 3-4 March,\n  2019, NIT Kurukshetra, INDIA. It's in press now", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of technology, devices, which are considered\nnon-traditional in terms of internet capabilities, are now being embedded in\nmicroprocessors to communicate and these devices are known as IoT devices. This\ntechnology has enabled household devices to have the ability to communicate\nwith the internet and a network comprising of such device can create a home IoT\nnetwork. Such IoT devices are resource constrained and lack high-level security\nprotocols. Thus, security becomes a major issue for such network systems. One\nway to secure the networks is through reliable authentication protocols and\ndata transfer mechanism. As the household devices are controllable by the users\nremotely, they are accessed over the internet. Therefore, there should also be\na method to make the communication over the internet between IoT devices and\nthe users more secured. This paper proposes a two-phase authentication protocol\nfor authentication purposes and a VPN based secure channel creation for the\ncommunication of the devices in the network. Furthermore, the paper discusses\nthe Elliptic Curve Cryptography as a viable alternative to RSA for a more\nefficient Key exchange mechanism for low-powered IoT devices in the network.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 02:18:16 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Masuduzzaman", "Md", ""], ["Mahmud", "Ashik", ""], ["Islam", "Anik", ""], ["Islam", "Md Mofijul", ""]]}, {"id": "1910.13693", "submitter": "Yixue Hao", "authors": "Yixue Hao, Miao Li, Di Wu, Min Chen, Mohammad Mehedi Hassan, Giancarlo\n  Fortino", "title": "Human-Like Hybrid Caching in Software-defined Edge Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of Internet of Things (IoT) and communication\ntechnology, the number of next-generation IoT devices has increased\nexplosively, and the delay requirement for content requests is becoming\nprogressively higher. Fortunately, the edge-caching scheme can satisfy users'\ndemands for low latency of content. However, the existing caching schemes are\nnot smart enough. To address these challenges, we propose a human-like hybrid\ncaching architecture based on the software defined edge cloud, which\nsimultaneously considers the content popularity and the fine-grained user\ncharacteristics. Then, an optimization problem with a caching hit ratio as an\noptimization objective is formulated. To solve this problem, using\nreinforcement learning, we design a human-like hybrid caching algorithm.\nExtensive experiments show that compared with popular caching schemes,\nhuman-like hybrid caching schemes can improve the cache hit ratio by 20%.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 06:58:28 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Hao", "Yixue", ""], ["Li", "Miao", ""], ["Wu", "Di", ""], ["Chen", "Min", ""], ["Hassan", "Mohammad Mehedi", ""], ["Fortino", "Giancarlo", ""]]}, {"id": "1910.13744", "submitter": "Franco Minucci", "authors": "Evgenii Vinogradov, Franco Minucci, Sofie Pollin", "title": "Wireless communication for safe UAVs: From Long-Range Deconfliction to\n  short-range collision avoidance", "comments": null, "journal-ref": null, "doi": "10.1109/MVT.2020.2980014", "report-no": null, "categories": "eess.SY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small drones are becoming a part of our everyday life. They are used in a\nwide variety of commercial applications, and the number of drones in the air is\nsteadily growing. To ensure the safe operation of drones, traffic management\nrules must be designed and implemented by avionics and telecommunication\nexperts. In this article, we propose to establish a common terminology for\nthese two communities. We first describe the traffic management architecture\nand services. Next, we overview several approaches for defining the inter-drone\nseparation distances ensuring the safe operation. Moreover, we analyze which\nexisting technologies can be useful for each of these definitions. Finally, we\npresent measurement results indicating that our new Wi-Fi-based messaging\nscheme is a potentially useful tool for the drone traffic management system.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 09:58:44 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 16:54:23 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Vinogradov", "Evgenii", ""], ["Minucci", "Franco", ""], ["Pollin", "Sofie", ""]]}, {"id": "1910.13871", "submitter": "Jingzhou Sun", "authors": "Jingzhou Sun, Zhiyuan Jiang, Bhaskar Krishnamachari, Sheng Zhou,\n  Zhisheng Niu", "title": "Closed-Form Whittle's Index-Enabled Random Access for Timely Status\n  Update", "comments": "30 pages, 7 figures, submitted to IEEE Transactions on\n  Communications. arXiv admin note: substantial text overlap with\n  arXiv:1803.08189", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a star-topology wireless network for status update where a\ncentral node collects status data from a large number of distributed\nmachine-type terminals that share a wireless medium. The Age of Information\n(AoI) minimization scheduling problem is formulated by the restless multi-armed\nbandit. A widely-proven near-optimal solution, i.e., the Whittle's index, is\nderived in closed-form and the corresponding indexability is established. The\nindex is then generalized to incorporate stochastic, periodic packet arrivals\nand unreliable channels. Inspired by the index scheduling policies which\nachieve near-optimal AoI but require heavy signaling overhead, a\ncontention-based random access scheme, namely Index-Prioritized Random Access\n(IPRA), is further proposed. Based on IPRA, terminals that are not urgent to\nupdate, indicated by their indices, are barred access to the wireless medium,\nthus improving the access timeliness. A computer-based simulation shows that\nIPRA's performance is close to the optimal AoI in this setting and outperforms\nstandard random access schemes. Also, for applications with hard AoI deadlines,\nwe provide reliable deadline guarantee analysis. Closed-form achievable AoI\nstationary distributions under Bernoulli packet arrivals are derived such that\nAoI deadline with high reliability can be ensured by calculating the maximum\nnumber of supportable terminals and allocating system resources proportionally.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 09:06:11 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Sun", "Jingzhou", ""], ["Jiang", "Zhiyuan", ""], ["Krishnamachari", "Bhaskar", ""], ["Zhou", "Sheng", ""], ["Niu", "Zhisheng", ""]]}, {"id": "1910.13892", "submitter": "Volodymyr Sokolov", "authors": "Volodymyr Sokolov, Bohdan Vovkotrub, Yevhen Zotkin", "title": "Comparative Bandwidth Analysis of Low-Power Wireless IoT-Switches", "comments": "in Ukrainian", "journal-ref": "Cybersecurity: Education, Science, Technique (ISSN: 2663-4023),\n  no. 5, 2019", "doi": "10.28925/2663-4023.2019.5.1630", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The article presents the research and comparative analysis of the bandwidth\nof low-power wireless IoT devices as wireless switches. The following IoT\ndevices were investigated: Raspberry Pi 3 Model B and Raspberry Pi Zero W. The\nDS18B20 and INA219 sensors investigated and analyzed the dependence of FTP\nmultimedia data transmission speed on wireless Wi-Fi network on the temperature\nof the switch processor, temperature. The environment and the current and\nvoltage consumed by the switch. Advantages of sensors with GPIO interface over\nanalog meters for this experiment are revealed. Much of the work is devoted to\nthe development of automation of results from GPIO interfaces, which helped\neliminate human error and get more accurate metrics. Measurement automation was\ndeveloped using Python 3.7 programming language. Using the INA219 library we\nwere able to obtain current and voltage indicators from the ina219 board. To\nget temperature indicators sufficiently built into Python libraries to read\ntemperature files in Raspbian. The article focuses on the synchronicity of\nmeasurement results records for more accurate analysis. Therefore, an FTP\nclient was developed that measures the download speed of the file from the FTP\nserver and records the results simultaneously with temperature, current and\nvoltage measurements. To this end, attention is drawn to the multithreading in\nPython programming language and the transmission of commands using TCP sockets\nin that language. As a result, the dependence of the measured factors was\ncalculated using the Pearson correlation formula. These measurement factors\naffect the autonomy and energy consumption, which is very important for IoT\ndevices, and therefore, among the devices tested, recommendations were made\nregarding their choice when used depending on the conditions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:34:00 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Sokolov", "Volodymyr", ""], ["Vovkotrub", "Bohdan", ""], ["Zotkin", "Yevhen", ""]]}, {"id": "1910.13965", "submitter": "Javier Del Ser Dr.", "authors": "Giovanni Perrone, Massimo Vecchio, Javier Del Ser, Fabio Antonelli,\n  Vivart Kapoor", "title": "The Internet of Things: a Survey and Outlook", "comments": "34 pages, chapter included in the book \"Sensors in the Age of the\n  Internet of Things: Technologies and applications\", IET Library, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent history has witnessed disruptive advances in disciplines related\nto information and communication technologies that have laid a rich\ntechnological ecosystem for the growth and maturity of latent paradigms in this\ndomain. Among them, sensor networks have evolved from the originally conceived\nset-up where hundreds of nodes with sensing and actuating functionalities were\ndeployed to capture information from their environment and act accordingly\n(coining the so-called wireless sensor network concept) to the provision of\nsuch functionalities embedded in quotidian objects that communicate and work\ntogether to collaboratively accomplish complex tasks based on the information\nthey acquire by sensing the environment. This is nowadays a reality, embracing\nthe original idea of an Internet of things (IoT) forged in the late twentieth\ncentury, yet featuring unprecedented scales, capabilities and applications\nignited by new radio interfaces, communication protocols and intelligent\ndata-based models. This chapter examines the latest findings reported in the\nliterature around these topics, with a clear focus on IoT communications,\nprotocols and platforms, towards ultimately identifying opportunities and\ntrends that will be at the forefront of IoT-related research in the near\nfuture.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 16:34:30 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Perrone", "Giovanni", ""], ["Vecchio", "Massimo", ""], ["Del Ser", "Javier", ""], ["Antonelli", "Fabio", ""], ["Kapoor", "Vivart", ""]]}, {"id": "1910.14150", "submitter": "Liang Zhang", "authors": "Liang Zhang and Nirwan Ansari", "title": "Backhaul-aware Uplink Communications in Full-Duplex DBS-aided HetNets", "comments": "to be presented in IEEE GLOBECOM, Dec. 2019", "journal-ref": null, "doi": null, "report-no": "TR-ANL-2019-001", "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drone-mounted base stations (DBSs) are promising solutions to provide\nubiquitous connections to users and support many applications in the fifth\ngeneration of mobile networks while full duplex communications has the\npotential to improve the spectrum efficiency. In this paper, we have\ninvestigated the backhaul-aware uplink communications in a full-duplex\nDBS-aided HetNet (BUD) problem with the objective to maximize the total\nthroughput of the network, and this problem is decomposed into two\nsub-problems: the DBS Placement problem (including the vertical dimension and\nhorizontal dimensions) and the joint UE association, power and bandwidth\nassignment (Joint-UPB) problem. Since the BUD problem is NP-hard, we propose\napproximation algorithms to solve the sub-problems and another, named the\nAA-BUD algorithm, to solve the BUD problem with guaranteed performance. The\nperformance of the AA-BUD algorithm has been demonstrated via extensive\nsimulations, and it is superior to two benchmark algorithms with up to 45.8%\nthroughput improvement.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 21:44:58 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Zhang", "Liang", ""], ["Ansari", "Nirwan", ""]]}, {"id": "1910.14199", "submitter": "Xiangyue Meng", "authors": "Xiangyue Meng, Hazer Inaltekin, Brian Krongold", "title": "Deep Reinforcement Learning-Based Topology Optimization for\n  Self-Organized Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless sensor networks (WSNs) are the foundation of the Internet of Things\n(IoT), and in the era of the fifth generation of wireless communication\nnetworks, they are envisioned to be truly ubiquitous, reliable, scalable, and\nenergy efficient. To this end, topology control is an important mechanism to\nrealize self-organized WSNs that are capable of adapting to the dynamics of the\nenvironment. Topology optimization is combinatorial in nature, and generally is\nNP-hard to solve. Most existing algorithms leverage heuristic rules to reduce\nthe number of search candidates so as to obtain a suboptimal solution in a\ncertain sense. In this paper, we propose a deep reinforcement learning-based\ntopology optimization algorithm, a unified search framework, for self-organized\nenergy-efficient WSNs. Specifically, the proposed algorithm uses a deep neural\nnetwork to guide a Monte Carlo tree search to roll out simulations, and the\nresults from the tree search reinforce the learning of the neural network. In\naddition, the proposed algorithm is an anytime algorithm that keeps improving\nthe solution with an increasing amount of computing resources. Various\nsimulations show that the proposed algorithm achieves better performance as\ncompared to heuristic solutions, and is capable of adapting to environment and\nnetwork changes without restarting the algorithm from scratch.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 01:12:37 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Meng", "Xiangyue", ""], ["Inaltekin", "Hazer", ""], ["Krongold", "Brian", ""]]}, {"id": "1910.14253", "submitter": "Chao Ren", "authors": "Chao Ren and Haijun Zhang and Jingze Hou and others", "title": "Computation Resource Leasing for Priority Aggregation Local Computing\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large scale smart edge networks, computation resource is generally\nunderutilized due to the uneven distribution of computation resource in time\nand space domain. This may correspond to a simple fact that no device is\ncapable for 'storing' and 'exchanging' idle computation resource. Thus, this\npaper proposes a computation resource leasing (CRL) concept using priority as\nan intermediary to restore and exchange the permission for computation resource\nfor priority aggregation local computing network (PALCN). Each device in PALNC\nis able to gain priority as a reward for leasing its computing resource to\nothers. CRL also offers a priority oriented algorithm to match the computation\nrequest with idle source nodes and a priority management model. Our analysis\nand numerical results show that the system can efficiently utilize local idle\ncomputation sources over time and space domain and filtrate the big task that\nlocal computation can not finish.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 04:33:27 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Ren", "Chao", ""], ["Zhang", "Haijun", ""], ["Hou", "Jingze", ""], ["others", "", ""]]}, {"id": "1910.14367", "submitter": "Durgesh Singh", "authors": "Durgesh Singh, Arpan Chattopadhyay and Sasthi C. Ghosh", "title": "Distributed Relay Selection in Presence of Dynamic Obstacles in\n  Millimeter Wave D2D Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter wave (mmWave) device to device (D2D) communication is highly\nsusceptible to obstacles due to severe penetration losses and requires almost a\nline of sight (LOS) communication path. D2D channel condition is local to\ndevices/user equipments (UEs) and hence is \\textit{not} directly visible to the\nbase station (BS). Thus quality of the D2D channel needs to be propagated to BS\nby UEs which may incur some delay. Hence the solution provided by BS to UEs\nusing this gathered channel information might become less useful to establish\ncommunication due to moving obstacles. These types of obstacles might not be\nknown in advance and hence may cause unpredictable fluctuations to the D2D\nchannel quality. Hence we seek to learn the D2D channels using the finite\nhorizon partially observable Markov decision process (POMDP) framework to model\nthe uncertainty in such kind of network environments with dynamic obstacles.\nThe objective is to minimize delay when channel quality deteriorates, by making\nUEs choose locally the best possible decision between i) to continue on the\ncurrent relay link on which communication is taking place or ii) to switch to\nanother good relay by exploring other possible UEs in its locality. We derive\nan optimal threshold policy which tells the UE to take appropriate decision\nlocally. Later, we give a simplified and easy to implement stationary threshold\npolicy which counts the number of successive acknowledgement failures, based on\nwhich UE make appropriate decision locally. Through extensive simulation, we\ndemonstrate that our approach outperforms recent algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 10:55:02 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 13:43:34 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Singh", "Durgesh", ""], ["Chattopadhyay", "Arpan", ""], ["Ghosh", "Sasthi C.", ""]]}]