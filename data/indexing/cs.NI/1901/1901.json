[{"id": "1901.00038", "submitter": "Michael Freedman", "authors": "Matvey Arye, Siddhartha Sen, and Michael J. Freedman", "title": "Poor Video Streaming Performance Explained (and Fixed)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HTTP-based video streaming is a key application on the Internet today,\ncomprising the majority of Internet traffic today. Yet customers remain\ndissatisfied with video quality, resulting in lost revenue for content\nproviders. Recent studies have blamed this on the adaptive bitrate selection\n(ABR) algorithm used by client players, claiming it interacts poorly with TCP\nwhen the video buffer is full, which causes it to underestimate available\nnetwork bandwidth.\n  We show that the root cause of the problem lies in the data plane, and that\neven a perfect control plane (ABR) algorithm is not enough to guarantee video\nflows their fair share of network bandwidth. Namely, it is the sequential\ndownload of (small) video segments that is at fault, as they disrupt the normal\ninteraction between TCP congestion control and router queue occupancy. We\nanalytically derive the throughput of a video flow as a function of download\nsize and network conditions, and use this to develop an adaptive algorithm for\nselecting the download size. Combined with pipelining, our approach achieves\nnear-optimal throughput and fast bitrate adaptation, regardless of the control\nplane algorithm. We implement our approach as a DASH video player called\nSprint, and evaluate it against state-of-the-art proposals from the literature\nas well as deployed players from Netflix, Youtube, Hulu, and Amazon. Sprint\nconsistently achieves above 90% of its fair-share throughput, while the\nprevious state-of-the-art exhibits high variability (e.g., from 31% to close to\nfair share depending on the network conditions). Industry players often achieve\nbelow 50% of their fair share.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 20:45:12 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Arye", "Matvey", ""], ["Sen", "Siddhartha", ""], ["Freedman", "Michael J.", ""]]}, {"id": "1901.00132", "submitter": "Francesco Malandrino", "authors": "Francesco Malandrino, Carla Fabiana Chiasserini", "title": "5G Traffic Forecasting: If Verticals and Mobile Operators Cooperate", "comments": null, "journal-ref": "IEEE/IFIP WONS 2019", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 5G research, it is traditionally assumed that vertical industries (a.k.a\nverticals) set the performance requirements for the services they want to offer\nto mobile users, and the mobile operators alone are in charge of orchestrating\ntheir resources so as to meet such requirements. Motivated by the observation\nthat successful orchestration requires reliable traffic predictions, in this\npaper we investigate the effects of having the verticals, instead of the mobile\noperators, performing such predictions. Leveraging a real-world, large-scale,\ncrowd-sourced trace, we find that involving the verticals in the prediction\nprocess reduces the prediction errors and improves the quality of the resulting\norchestration decisions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 11:07:01 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Malandrino", "Francesco", ""], ["Chiasserini", "Carla Fabiana", ""]]}, {"id": "1901.00204", "submitter": "Ramin Hasibi", "authors": "Ramin Hasibi, Matin Shokri, Mehdi Dehghan", "title": "Augmentation Scheme for Dealing with Imbalanced Network Traffic\n  Classification Using Deep Learning", "comments": "Submitted to IFIP Networking 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important tasks in network management is identifying\ndifferent types of traffic flows. As a result, a type of management service,\ncalled Network Traffic Classifier (NTC), has been introduced. One type of NTCs\nthat has gained huge attention in recent years applies deep learning on packets\nin order to classify flows. Internet is an imbalanced environment i.e., some\nclasses of applications are a lot more populated than others e.g., HTTP.\nAdditionally, one of the challenges in deep learning methods is that they do\nnot perform well in imbalanced environments in terms of evaluation metrics such\nas precision, recall, and $\\mathrm{F_1}$ measure. In order to solve this\nproblem, we recommend the use of augmentation methods to balance the dataset.\nIn this paper, we propose a novel data augmentation approach based on the use\nof Long Short Term Memory (LSTM) networks for generating traffic flow patterns\nand Kernel Density Estimation (KDE) for replicating the numerical features of\neach class. First, we use the LSTM network in order to learn and generate the\nsequence of packets in a flow for classes with less population. Then, we\ncomplete the features of the sequence with generating random values based on\nthe distribution of a certain feature, which will be estimated using KDE.\nFinally, we compare the training of a Convolutional Recurrent Neural Network\n(CRNN) in large-scale imbalanced, sampled, and augmented datasets. The\ncontribution of our augmentation scheme is then evaluated on all of the\ndatasets through measurements of precision, recall, and F1 measure for every\nclass of application. The results demonstrate that our scheme is well suited\nfor network traffic flow datasets and improves the performance of deep learning\nalgorithms when it comes to above-mentioned metrics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 20:02:38 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Hasibi", "Ramin", ""], ["Shokri", "Matin", ""], ["Dehghan", "Mehdi", ""]]}, {"id": "1901.00233", "submitter": "Xiaohu Ge", "authors": "Heng Liu, Haoming Jia, Jiaqi Chen, Xiaohu Ge, Yonghui Li, Lin Tian,\n  Jinglin Shi", "title": "Computing Resource Allocation of Mobile Edge Computing Networks Based on\n  Potential Game Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing (MEC) networks are one of the key technologies for\nultra-reliability and low-latency communications. The computing resource\nallocation solution needs to be carefully designed to guarantee the computing\nresource efficiency of MEC networks. Based on the potential game theory, a\ncomputing resource allocation solution is proposed to reduce energy consumption\nand improve computing resource efficiency in MEC networks. The computing\nresource allocation solution includes two parts: the first part is the power\ncontrol scheme based on the potential game theory and the second part is the\ncomputing resource allocation scheme based on linear programming. The power\ncontrol scheme is to find a set of the transmission powers of base stations\n(BSs) that maximizes the potential function of MEC networks. The computing\nresource allocation scheme is to maximize the average computing resource\nallocation coefficient of the MEC networks based on the results of the power\ncontrol scheme. Compared with traditional solutions, simulation results\nindicate the computing resource utilization and energy efficiency of the\nproposed computing resource allocation solution are significantly improved.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 01:42:29 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Liu", "Heng", ""], ["Jia", "Haoming", ""], ["Chen", "Jiaqi", ""], ["Ge", "Xiaohu", ""], ["Li", "Yonghui", ""], ["Tian", "Lin", ""], ["Shi", "Jinglin", ""]]}, {"id": "1901.00236", "submitter": "Xiaohu Ge", "authors": "Yong Zhang, Bin Yang, Xiaohu Ge, Yonghui Li", "title": "Performance Analysis of Non-Orthogonal Multicast in Two-tier\n  Heterogeneous Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosive growth of mobile services, non-orthogonal\nbroadcast/multicast transmissions can effectively improves spectrum efficiency.\nNonorthogonal multiple access (NOMA) represents a paradigm shift from\nconventional orthogonal multiple-access (OMA) concepts and has been recognized\nas one of the key enabling technologies for fifth-generation (5G) mobile\nnetworks. In this paper, a two-tier heterogeneous network is studied, in which\nthe wireless signal power is partitioned by the NOMA scheme. Moreover, the\ncoverage probability, the average rate and the average QoE are derived to\nevaluate network performance. Simulation results show that compared with the\nOMA method, non-orthogonal broadcast/multicast method improve both the average\nuser rate and QoE in the two-tier heterogeneous network.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 01:50:52 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Zhang", "Yong", ""], ["Yang", "Bin", ""], ["Ge", "Xiaohu", ""], ["Li", "Yonghui", ""]]}, {"id": "1901.00244", "submitter": "Xiaohu Ge", "authors": "Kai Chen, Jing Yang, Xiaohu Ge, Yonghui Li, Lin Tian, Jinglin Shi", "title": "Energy Efficiency Optimization of Generalized Spatial Modulation with\n  Sub-Connected Hybrid Precoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy efficiency (EE) optimization of millimeter wave (mm-Wave) massive\nmultiple-input multiple-output (MIMO) systems is emerging as an important\nchallenge for the fifth generation (5G) mobile communication systems. However,\nthe power of radio frequency (RF) chains increases sharply due to the high\ncarrier frequency in mm-Wave massive MIMO systems. To overcome this issue, a\nnew energy efficiency optimization solution is proposed based on the structure\nof the generalized spatial modulation (GSM) and sub-connected hybrid precoding\n(HP). Moreover, the computation power of mm-Wave massive MIMO systems is\nconsidered for optimizing the EE. Simulation results indicate that the EE of\nthe GSM-HP scheme outperforms the full digital precoding (FDP) scheme in the\nmm-Wave massive MIMO scene, and 88\\% computation power can be saved by the\nproposed GSM-HP scheme.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 02:40:40 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Chen", "Kai", ""], ["Yang", "Jing", ""], ["Ge", "Xiaohu", ""], ["Li", "Yonghui", ""], ["Tian", "Lin", ""], ["Shi", "Jinglin", ""]]}, {"id": "1901.00302", "submitter": "Abolfazl Danayi", "authors": "Abolfazl Danayi and Saeed Sharifian", "title": "openCoT: The opensource Cloud of Things platform", "comments": "9 pages, 8 figures, GitHub link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to address the complexity and extensiveness of technology, Cloud\nComputing is utilized with four main service models. The most recent service\nmodel, function-as-a-service, enables developers to develop their application\nin a function-based structure and then deploy it to the Cloud. Using an optimum\nelastic auto-scaling, the performance of executing an application over FaaS\nCloud, overcomes the extra overhead and reduces the total cost. However,\nresearchers need a simple and well-documented FaaS Cloud manager in order to\nimplement their proposed Auto-scaling algorithms. In this paper, we represent\nthe openCoT platform and explain its building blocks and details. Experimental\nresults show that executing a function (invoking and passing arguments) and\nreturning the result using openCoT takes 21 ms over a remote connection. The\nsource code of openCoT is available in the GitHub repository of the project\n(\\code{www.github.com/adanayi/opencot}) for public usage.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 09:17:51 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Danayi", "Abolfazl", ""], ["Sharifian", "Saeed", ""]]}, {"id": "1901.00375", "submitter": "Laurent Decreusefond", "authors": "Ana\\\"is Vergne (LTCI), Laurent Decreusefond (LTCI), Philippe Martins\n  (LTCI)", "title": "Computing the $k$-coverage of a wireless network", "comments": "Valuetools 2019, Mar 2019, Palma de Mallorca, Spain. 2019. arXiv\n  admin note: text overlap with arXiv:1802.08442", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coverage is one of the main quality of service of a wirelessnetwork.\n$k$-coverage, that is to be covered simultaneously by $k$network nodes, is\nsynonym of reliability and numerous applicationssuch as multiple site MIMO\nfeatures, or handovers. We introduce here anew algorithm for computing the\n$k$-coverage of a wirelessnetwork. Our method is based on the observation that\n$k$-coverage canbe interpreted as $k$ layers of $1$-coverage, or simply\ncoverage. Weuse simplicial homology to compute the network's topology and\nareduction algorithm to indentify the layers of $1$-coverage. Weprovide figures\nand simulation results to illustrate our algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 17:52:53 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Vergne", "Ana\u00efs", "", "LTCI"], ["Decreusefond", "Laurent", "", "LTCI"], ["Martins", "Philippe", "", "LTCI"]]}, {"id": "1901.00406", "submitter": "Hao Wu", "authors": "Hao Wu, Hancheng Lu", "title": "Delay and Power Tradeoff with Consideration of Caching Capabilities in\n  Dense Wireless Networks", "comments": "30 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling caching capabilities in dense small cell networks (DSCNs) has a\ndirect impact on file delivery delay and power consumption. Most existing work\nstudied these two performance metrics separately in cache-enabled DSCNs.\nHowever, file delivery delay and power consumption are coupled with each other\nand cannot be minimized simultaneously. In this paper, we investigate the\noptimal tradoff between these two performance metrics. Firstly, we formulate\nthe joint file delivery delay and power consumption optimization (JDPO) problem\nwhere power control, user association and file placement are jointly\nconsidered. Then we convert it to a form that can be handled by Generalized\nBenders Decomposition (GDB). with GDB, we decompose the converted JDPO problem\ninto two smaller problems, i.e., primal problem related to power control and\nmaster problem related to user association and file placement. An iterative\nalgorithm is proposed and proved to be $\\epsilon$-optimal, in which the primal\nproblem and master problem are solved iteratively to approach the optimal\nsolution. To further reduce the complexity of the master problem, an\naccelerated algorithm based on semi-definite relaxation is proposed. Finally,\nthe simulation results demonstrate that the proposed algorithm can approach the\noptimal tradeoff between file delivery delay and power consumption.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 15:00:09 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 15:43:19 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 00:58:49 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Wu", "Hao", ""], ["Lu", "Hancheng", ""]]}, {"id": "1901.00511", "submitter": "Riham Elhabyan", "authors": "Riham Elhabyan, Wei Shi and Marc St-Hilaire", "title": "Coverage Protocols for Wireless Sensor Networks: Review and Future\n  Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coverage problem in wireless sensor networks (WSNs) can be generally\ndefined as a measure of how effectively a network field is monitored by its\nsensor nodes. This problem has attracted a lot of interest over the years and\nas a result, many coverage protocols were proposed. In this survey, we first\npropose a taxonomy for classifying coverage protocols in WSNs. Then, we\nclassify the coverage protocols into three categories (i.e. coverage aware\ndeployment protocols, sleep scheduling protocols for flat networks, and\ncluster-based sleep scheduling protocols) based on the network stage where the\ncoverage is optimized. For each category, relevant protocols are thoroughly\nreviewed and classified based on the adopted coverage techniques. Finally, we\ndiscuss open issues (and recommend future directions to resolve them)\nassociated with the design of realistic coverage protocols. Issues such as\nrealistic sensing models, realistic energy consumption models, realistic\nconnectivity models and sensor localization are covered.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 19:18:56 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Elhabyan", "Riham", ""], ["Shi", "Wei", ""], ["St-Hilaire", "Marc", ""]]}, {"id": "1901.00608", "submitter": "Suzhi Bi", "authors": "Xiaokang Wen, Suzhi Bi, Xiaohui Lin, Lina Yuan, and Juan Wang", "title": "Throughput Maximization for Ambient Backscatter Communication: A\n  Reinforcement Learning Approach", "comments": "The paper has been accepted by IEEE ITNEC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambient backscatter (AB) communication is an emerging wireless communication\ntechnology that enables wireless devices (WDs) to communicate without requiring\nactive radio transmission. In an AB communication system, a WD switches between\ncommunication and energy harvesting modes. The harvested energy is used to\npower the devices operations, e.g., circuit power consumption and sensing\noperation. In this paper, we focus on maximizing the throughput performance of\nAB communication system by adaptively selecting the operating mode under fading\nchannel environment. We model the problem as an infinite-horizon Markov\nDecision Process (MDP) and accordingly obtain the optimal mode switching policy\nby the value iteration algorithm given the channel distributions. Meanwhile,\nwhen the knowledge of channel distribution is absent, a Q-learning (QL) method\nis applied to explore a suboptimal strategy through device repeated interaction\nwith the environment. Finally, our simulations show that the proposed QL method\ncan achieve close-to-optimal throughput performance and significantly\noutperforms the other than representative benchmark methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 04:40:33 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Wen", "Xiaokang", ""], ["Bi", "Suzhi", ""], ["Lin", "Xiaohui", ""], ["Yuan", "Lina", ""], ["Wang", "Juan", ""]]}, {"id": "1901.00648", "submitter": "Yong Niu", "authors": "Haiyan Jiang, Yong Niu, Jiayi Zhang, Bo Ai, Zhangdui Zhong", "title": "Coalition Game based Full-duplex Concurrent Scheduling in Millimeter\n  Wave Wireless Backhaul Network", "comments": "11 pages, 16 figures, accepted by China Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of self-interference (SI) cancelation technology,\nfull-duplex (FD) communication becomes possible. FD communication can\ntheoretically double the spectral efficiency. When the time slot (TS) resources\nare limited and the number of flows is large, the scheduling mechanism of the\nflows becomes more important. Therefore, the effectiveness of FD scheduling\nmechanism for the flows is studied in millimeter wave wireless backhaul network\nwith the limited TS resources. We proposed a full duplex concurrent scheduling\nalgorithm based on coalition game (FDCG) to maximize the number of flows with\ntheir QoS requirements satisfied. We transformed the problem of maximizing the\nnumber of flows with their QoS requirements satisfied into the problem of\nmaximizing sum rate of concurrently scheduled flows in each slot. We obtained\nthe scheduled flows with maximum sum rate in first slot by using coalition\ngame.And then with certain restrictions, the maximum sum rate of concurrently\nscheduled flows can also be achieved in subsequent time slots. The simulation\nresults show that the proposed FDCG algorithm can achieve superior performance\nin terms of the number of flows that meet their QoS requirements and system\nthroughput compared with other three algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 08:21:06 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Jiang", "Haiyan", ""], ["Niu", "Yong", ""], ["Zhang", "Jiayi", ""], ["Ai", "Bo", ""], ["Zhong", "Zhangdui", ""]]}, {"id": "1901.00808", "submitter": "Haixia Peng", "authors": "Haixia Peng, Qiang Ye, Xuemin Shen", "title": "Spectrum Resource Management for Multi-Access Edge Computing in\n  Autonomous Vehicular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a dynamic spectrum management framework is proposed to improve\nspectrum resource utilization in a multi-access edge computing (MEC) in\nautonomous vehicular network (AVNET). To support the increasing data traffic\nand guarantee quality-of-service (QoS), spectrum slicing, spectrum allocating,\nand transmit power controlling are jointly considered. Accordingly, three\nnon-convex network utility maximization problems are formulated to slice\nspectrum among BSs, allocate spectrum among autonomous vehicles (AVs)\nassociated with a BS, and control transmit powers of BSs, respectively. Via\nlinear programming relaxation and first-order Taylor series approximation,\nthese problems are transformed into tractable forms and then are jointly solved\nthrough an alternate concave search (ACS) algorithm. As a result, optimal\nspectrum slicing ratios among BSs, optimal BS-vehicle association patterns,\noptimal fractions of spectrum resources allocated to AVs, and optimal transmit\npowers of BSs are obtained. Based on our simulation, a high aggregate network\nutility is achieved by the proposed spectrum management scheme compared with\ntwo existing schemes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 16:38:39 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Peng", "Haixia", ""], ["Ye", "Qiang", ""], ["Shen", "Xuemin", ""]]}, {"id": "1901.00936", "submitter": "Stefano Salsano", "authors": "Andrea Mayer, Stefano Salsano, Pier Luigi Ventre, Ahmed Abdelsalam,\n  Luca Chiaraviglio, Clarence Filsfils", "title": "An Efficient Linux Kernel Implementation of Service Function Chaining\n  for legacy VNFs based on IPv6 Segment Routing", "comments": "Paper accepted to 5th IEEE International Conference on Network\n  Softwarization (NetSoft 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the IPv6 Segment Routing (SRv6) technology for Service Function\nChaining of Virtual Network Functions (VNFs). Most of the VNFs are legacy VNFs\n(not aware of the SRv6 technology) and expect to process traditional IP\npackets. An SR proxy is needed to support them. We have extended the\nimplementation of SRv6 in the Linux kernel, realizing an SR-proxy, referred to\nas SRNK (SR-Proxy Native Kernel). The performance of the proposed solution\n(SRNKv1) has been evaluated, identifying a poor scalability with respect to the\nnumber of VNFs to be supported in a node. Therefore we provided a second design\n(SRNKv2), enhancing the Linux Policy Routing framework. The performance of\nSRNKv2 is independent from the number of supported VNFs in a node. We compared\nthe performance of SRNKv2 with a reference scenario not performing the\nencapsulation and decapsulation operation and demonstrated that the overhead of\nSRNKv2 is very small, on the order of 3.5%.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 22:58:58 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 23:03:12 GMT"}, {"version": "v3", "created": "Tue, 23 Jul 2019 23:10:00 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Mayer", "Andrea", ""], ["Salsano", "Stefano", ""], ["Ventre", "Pier Luigi", ""], ["Abdelsalam", "Ahmed", ""], ["Chiaraviglio", "Luca", ""], ["Filsfils", "Clarence", ""]]}, {"id": "1901.00963", "submitter": "Guidan Yao", "authors": "Guidan Yao, Morteza Hashemi, and Ness B. Shroff", "title": "Integrating Sub-6 GHz and Millimeter Wave to Combat Blockage:\n  Delay-Optimal Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter wave (mmWave) technologies have the potential to achieve very high\ndata rates, but suffer from intermittent connectivity. In this paper, we\nprovision an architecture to integrate sub-6 GHz and mmWave technologies, where\nwe incorporate the sub-6 GHz interface as a fallback data transfer mechanism to\ncombat blockage and intermittent connectivity of the mmWave communications. To\nthis end, we investigate the problem of scheduling data packets across the\nmmWave and sub-6 GHz interfaces such that the average delay of system is\nminimized. This problem can be formulated as Markov Decision Process. We first\ninvestigate the problem of discounted delay minimization, and prove that the\noptimal policy is of the threshold-type, i.e., data packets should always be\nrouted to the mmWave interface as long as the number of packets in the system\nis smaller than a threshold. Then, we show that the results of the discounted\ndelay problem hold for the average delay problem as well. Through numerical\nresults, we demonstrate that under heavy traffic, integrating sub-6 GHz with\nmmWave can reduce the average delay by up to 70%. Further, our scheduling\npolicy substantially reduces the delay over the celebrated MaxWeight policy.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 01:33:47 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 04:47:51 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Yao", "Guidan", ""], ["Hashemi", "Morteza", ""], ["Shroff", "Ness B.", ""]]}, {"id": "1901.01187", "submitter": "Nikolaos Thomos", "authors": "Jonnahtan Saltarin, Torsten Braun, Eirina Bourtsoulatze, and Nikolaos\n  Thomos", "title": "PopNetCod: A Popularity-based Caching Policy for Network Coding enabled\n  Named Data Networking", "comments": "presented at IFIP networking 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose PopNetCod, a popularity-based caching policy for\nnetwork coding enabled Named Data Networking. PopNetCod is a distributed\ncaching policy, in which each router measures the local popularity of the\ncontent objects by analyzing the requests that it receives. It then uses this\ninformation to decide which Data packets to cache or evict from its content\nstore. Since network coding is used, partial caching of content objects is\nsupported, which facilitates the management of the content store. The routers\ndecide the Data packets that they cache or evict in an online manner when they\nreceive requests for Data packets. This allows the most popular Data packets to\nbe cached closer to the network edges. The evaluation of PopNetCod shows an\nimproved cache-hit rate compared to the widely used Leave Copy Everywhere\nplacement policy and the Least Recently Used eviction policy. The improved\ncache-hit rate helps the clients to achieve higher goodput, while it also\nreduces the load on the source servers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 16:02:41 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Saltarin", "Jonnahtan", ""], ["Braun", "Torsten", ""], ["Bourtsoulatze", "Eirina", ""], ["Thomos", "Nikolaos", ""]]}, {"id": "1901.01443", "submitter": "Danish Sattar", "authors": "Danish Sattar and Ashraf Matrawy", "title": "Towards Secure Slicing: Using Slice Isolation to Mitigate DDoS Attacks\n  on 5G Core Network Slices", "comments": null, "journal-ref": "7th Annual IEEE Conference on Communications and Network Security\n  (CNS 2019), Washington, DC, USA, 10 - 12 June 2019", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a solution to proactively mitigate Distributed\nDenial-of-Service attacks in 5G core network slicing using slice isolation.\nNetwork slicing is one of the key technologies that allow 5G networks to offer\ndedicated resources to different industries (services). However, a Distributed\nDenial-of-Service attack could severely impact the performance and availability\nof the slices as they could share the same physical resources in a multi-tenant\nvirtualized networking infrastructure. Slice isolation is an essential\nrequirement for 5G network slicing.\n  In this paper, we use network isolation to tackle the challenging problem of\nDistributed Denial-of-Service attacks in 5G network slicing. We propose the use\nof a mathematical model that can provide on-demand slice isolation as well as\nguarantee end-to-end delay for 5G core network slices. We evaluate the proposed\nwork with a mix of simulation and experimental work. Our results show that the\nproposed isolation could mitigate Distributed Denial-of-Service attacks as well\nas increase the availability of the slices. We believe this work will encourage\nfurther research in securing 5G network slicing.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 17:34:37 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 22:15:26 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Sattar", "Danish", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "1901.01517", "submitter": "Qingkai Liang", "authors": "Qingkai Liang and Eytan Modiano", "title": "Optimal Network Control in Partially-Controllable Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of many optimal network control algorithms (e.g.,\nBackPressure) relies on the premise that all of the nodes are fully\ncontrollable. However, these algorithms may yield poor performance in a\npartially-controllable network where a subset of nodes are uncontrollable and\nuse some unknown policy. Such a partially-controllable model is of increasing\nimportance in real-world networked systems such as overlay-underlay networks.\nIn this paper, we design optimal network control algorithms that can stabilize\na partially-controllable network. We first study the scenario where\nuncontrollable nodes use a queue-agnostic policy, and propose a low-complexity\nthroughput-optimal algorithm, called Tracking-MaxWeight (TMW), which enhances\nthe original MaxWeight algorithm with an explicit learning of the policy used\nby uncontrollable nodes. Next, we investigate the scenario where uncontrollable\nnodes use a queue-dependent policy and the problem is formulated as an MDP with\nunknown queueing dynamics. We propose a new reinforcement learning algorithm,\ncalled Truncated Upper Confidence Reinforcement Learning (TUCRL), and prove\nthat TUCRL achieves tunable three-way tradeoffs between throughput, delay and\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 08:15:55 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Liang", "Qingkai", ""], ["Modiano", "Eytan", ""]]}, {"id": "1901.01531", "submitter": "Madanagopal Ramachandran", "authors": "Madanagopal Ramachandran and Krishna M. Sivalingam", "title": "Path Computation for Provisioning in Multi-Technology Multi-Layer\n  Transport Networks", "comments": "PCATN paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service providers employ different transport technologies like PDH,\nSDH/SONET, OTN, DWDM, Ethernet, MPLS-TP etc. to support different types of\ntraffic and service requirements. Dynamic service provisioning requires the use\nof on-line algorithms that automatically compute the path to be taken to\nsatisfy the given service request. A typical transport network element supports\nadaptation of multiple technologies and multiple layers of those technologies\nto carry the input traffic. Further, transport networks are deployed such that\nthey follow different topologies like linear, ring, mesh, protected linear,\ndual homing etc. in different layers. Path computation for service requests\nconsidering the above factors is the focus of this work, where a new mechanism\nfor building an auxiliary graph which models each layer as a node within each\nnetwork element and creates adaptation edges between them and also supports\ncreation of special edges to represent different types of topologies is\nproposed. Logical links that represent multiplexing or adaptation are also\ncreated in the auxiliary graph. Initial weight assignment scheme for\nnon-adaptation edges that consider both link distance and link capacity is\nproposed and three dynamic weight assignment functions that consider the\ncurrent utilization of the links are proposed. Path computation algorithms\nconsidering adaptation and topologies are proposed over the auxiliary graph\nstructure. The performance of the algorithms is evaluated and it is found that\nthe weighted number of requests accepted is higher and the weighted capacity\nprovisioned is lesser for one of the dynamic weight function and certain\ncombination of values proposed as part of the weight assignment.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 11:58:00 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Ramachandran", "Madanagopal", ""], ["Sivalingam", "Krishna M.", ""]]}, {"id": "1901.01603", "submitter": "Maria Papadopouli", "authors": "Maria Plakia and Evripides Tzamousis and Thomais Asvestopoulou and\n  Giorgos Pantermakis and Nick Filippakis and Henning Schulzrinne and Yana\n  Kane-Esrig and Maria Papadopouli", "title": "Should I stay or should I go: Analysis of the impact of application QoS\n  on user engagement in YouTube", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the quality of experience (QoE), especially under moderate to high\ntraffic demand, it is important to understand the impact of the network and\napplication QoS on user experience. This paper comparatively evaluates the\nimpact of impairments, their intensity and temporal dynamics, on user\nengagement in the context of video streaming. The analysis employed two large\nYouTube datasets. To characterize the user engagement and the impact of\nimpairments, several new metrics were defined. We assessed whether or not there\nis a statistically significant relationship between different types of\nimpairments and QoE and user engagement metrics, taking into account not only\nthe characteristics of the impairments but also the covariates of the session\n(e.g., video duration, mean datarate). After observing the relationships across\nthe entire dataset, we tested whether these relationships also persist under\nspecific conditions with respect to the covariates. The introduction of several\nnew metrics and of various covariates in the analysis are two innovative\naspects of this work. We found that the number of negative bitrate changes\n(BR-) is a stronger predictor of abandonment than rebufferrings (RB). Even\npositive bitrate changes (BR+) are associated with increases in abandonment.\nSpecifically, BR+ in low resolution sessions is not well received. Temporal\ndynamics of the impairments have also an impact: a BR- that follows much later\na RB appears to be perceived as a worse impairment than a BR- that occurs\nimmediately after a RB. These results can be used to guide the design of the\nvideo streaming adaptation as well as suggest which parameters should be varied\nin controlled field studies.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 20:48:45 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 16:40:31 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Plakia", "Maria", ""], ["Tzamousis", "Evripides", ""], ["Asvestopoulou", "Thomais", ""], ["Pantermakis", "Giorgos", ""], ["Filippakis", "Nick", ""], ["Schulzrinne", "Henning", ""], ["Kane-Esrig", "Yana", ""], ["Papadopouli", "Maria", ""]]}, {"id": "1901.01628", "submitter": "Yiying Zhang", "authors": "Shin-Yeh Tsai, Yiying Zhang", "title": "Building Atomic, Crash-Consistent Data Stores with Disaggregated\n  Persistent Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byte-addressable persistent memories (PM) has finally made their way into\nproduction. An important and pressing problem that follows is how to deploy\nthem in existing datacenters. One viable approach is to attach PM as\nself-contained devices to the network as disaggregated persistent memory, or\nDPM. DPM requires no changes to existing servers in datacenters; without the\nneed to include a processor, DPM devices are cheap to build; and by sharing DPM\nacross compute servers, they offer great elasticity and efficient resource\npacking.\n  This paper explores different ways to organize DPM and to build data stores\nwith DPM. Specifically, we propose three architectures of DPM: 1) compute nodes\ndirectly access DPM (DPM-Direct); 2) compute nodes send requests to a\ncoordinator server, which then accesses DPM to complete a request\n(DPM-Central); and 3) compute nodes directly access DPM for data operations and\ncommunicate with a global metadata server for the control plane (DPM-Sep).\nBased on these architectures, we built three atomic, crash-consistent data\nstores. We evaluated their performance, scalability, and CPU cost with\nmicro-benchmarks and YCSB. Our evaluation results show that DPM-Direct has\ngreat small-size read but poor write performance; DPM-Central has the best\nwrite performance when the scale of the cluster is small but performs poorly\nwhen the scale increases; and DPM-Sep performs well overall.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 00:02:22 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Tsai", "Shin-Yeh", ""], ["Zhang", "Yiying", ""]]}, {"id": "1901.01632", "submitter": "Yiying Zhang", "authors": "Ke Liu, Shin-Yeh Tsai, Yiying Zhang", "title": "ATP: a Datacenter Approximate Transmission Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many datacenter applications such as machine learning and streaming systems\ndo not need the complete set of data to perform their computation. Current\napproximate applications in datacenters run on a reliable network layer like\nTCP. To improve performance, they either let sender select a subset of data and\ntransmit them to the receiver or transmit all the data and let receiver drop\nsome of them. These approaches are network oblivious and unnecessarily transmit\nmore data, affecting both application runtime and network bandwidth usage. On\nthe other hand, running approximate application on a lossy network with UDP\ncannot guarantee the accuracy of application computation. We propose to run\napproximate applications on a lossy network and to allow packet loss in a\ncontrolled manner. Specifically, we designed a new network protocol called\nApproximate Transmission Protocol, or ATP, for datacenter approximate\napplications. ATP opportunistically exploits available network bandwidth as\nmuch as possible, while performing a loss-based rate control algorithm to avoid\nbandwidth waste and re-transmission. It also ensures bandwidth fair sharing\nacross flows and improves accurate applications' performance by leaving more\nswitch buffer space to accurate flows. We evaluated ATP with both simulation\nand real implementation using two macro-benchmarks and two real applications,\nApache Kafka and Flink. Our evaluation results show that ATP reduces\napplication runtime by 13.9% to 74.6% compared to a TCP-based solution that\ndrops packets at sender, and it improves accuracy by up to 94.0% compared to\nUDP.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 00:31:25 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Liu", "Ke", ""], ["Tsai", "Shin-Yeh", ""], ["Zhang", "Yiying", ""]]}, {"id": "1901.01704", "submitter": "Roberto Doriguzzi Corin", "authors": "Roberto Doriguzzi-Corin, Sandra Scott-Hayward, Domenico Siracusa,\n  Marco Savi, Elio Salvadori", "title": "Dynamic and Application-Aware Provisioning of Chained Virtual Security\n  Network Functions", "comments": null, "journal-ref": null, "doi": "10.1109/TNSM.2019.2941128", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising area of application for Network Function Virtualization is in\nnetwork security, where chains of Virtual Security Network Functions (VSNFs),\ni.e., security-specific virtual functions such as firewalls or Intrusion\nPrevention Systems, can be dynamically created and configured to inspect,\nfilter or monitor the network traffic. However, the traffic handled by VSNFs\ncould be sensitive to specific network requirements, such as minimum bandwidth\nor maximum end-to-end latency. Therefore, the decision on which VSNFs should\napply for a given application, where to place them and how to connect them,\nshould take such requirements into consideration. Otherwise, security services\ncould affect the quality of service experienced by customers. In this paper we\npropose PESS (Progressive Embedding of Security Services), a solution to\nefficiently deploy chains of virtualised security functions based on the\nsecurity requirements of individual applications and operators' policies, while\noptimizing resource utilization. We provide the PESS mathematical model and\nheuristic solution. Simulation results show that, compared to state-of-the-art\napplication-agnostic VSNF provisioning models, PESS reduces computational\nresource utilization by up to 50%, in different network scenarios. This result\nultimately leads to a higher number of provisioned security services and to up\nto a 40% reduction in end-to-end latency of application traffic.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 08:45:37 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 09:21:45 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 15:38:23 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 08:35:40 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Doriguzzi-Corin", "Roberto", ""], ["Scott-Hayward", "Sandra", ""], ["Siracusa", "Domenico", ""], ["Savi", "Marco", ""], ["Salvadori", "Elio", ""]]}, {"id": "1901.01744", "submitter": "Loreto Pescosolido", "authors": "Loreto Pescosolido, Marco Conti, Andrea Passarella", "title": "D2D Data Offloading in Vehicular Environments with Optimal Delivery Time\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the framework of a Device-to-Device (D2D) data offloading system for\ncellular networks, we propose a Content Delivery Management System (CDMS) in\nwhich the instant for transmitting a content to a requesting node, through a\nD2D communication, is selected to minimize the energy consumption required for\ntransmission. The proposed system is particularly fit to highly dynamic\nscenarios, such as vehicular networks, where the network topology changes at a\nrate which is comparable with the order of magnitude of the delay tolerance. We\npresent an analytical framework able to predict the system performance, in\nterms of energy consumption, using tools from the theory of point processes,\nvalidating it through simulations, and provide a thorough performance\nevaluation of the proposed CDMS, in terms of energy consumption and spectrum\nuse. Our performance analysis compares the energy consumption and spectrum use\nobtained with the proposed scheme with the performance of two benchmark\nsystems. The first one is a plain classic cellular scheme, the second is a D2D\ndata offloading scheme (that we proposed in previous works) in which the D2D\ntransmissions are performed as soon as there is a device with the required\ncontent within the maximum D2D transmission range...\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 10:50:15 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Pescosolido", "Loreto", ""], ["Conti", "Marco", ""], ["Passarella", "Andrea", ""]]}, {"id": "1901.01863", "submitter": "Viet-Hoang Tran", "authors": "Viet-Hoang Tran, Olivier Bonaventure", "title": "Beyond socket options: making the Linux TCP stack truly extensible", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transmission Control Protocol (TCP) is one of the most important\nprotocols in today's Internet. Its specification and implementations have been\nrefined for almost forty years. The Linux TCP stack is one of the most widely\nused TCP stacks given its utilisation on servers and Android smartphones and\ntablets. However, TCP and its implementations evolve very slowly. In this\npaper, we demonstrate how to leverage the eBPF virtual machine that is part of\nthe recent versions of the Linux kernel to make the TCP stack easier to extend.\n  We demonstrate a variety of use cases where the eBPF code is injected inside\na running kernel to update or tune the TCP implementation. We first implement\nthe TCP User Timeout Option. Then we propose a new option that enables a client\nto request a server to use a specific congestion control scheme. Our third\nextension is a TCP option that sets the initial congestion window. We then\ndemonstrate how eBPF code can be used to tune the acknowledgment strategy.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 15:04:27 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 07:44:26 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Tran", "Viet-Hoang", ""], ["Bonaventure", "Olivier", ""]]}, {"id": "1901.02111", "submitter": "Maryam Mohseni", "authors": "Maryam Mohseni, S. Alireza Banani, Andrew W. Eckford, Raviraj S. Adve", "title": "Scheduling for VoLTE: Resource Allocation Optimization and\n  Low-Complexity Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider scheduling and resource allocation in long-term evolution (LTE)\nnetworks across voice over LTE (VoLTE) and best-effort data users. The\ndifference between these two is that VoLTE users get scheduling priority to\nreceive their required quality of service. As we show, strict priority causes\ndata services to suffer. We propose new scheduling and resource allocation\nalgorithms to maximize the sum- or proportional fair (PF) throughout amongst\ndata users while meeting VoLTE demands. Essentially, we use VoLTE as an example\napplication with both a guaranteed bit-rate and strict application-specific\nrequirements. We first formulate and solve the frame-level optimization problem\nfor throughput maximization; however, this leads to an integer problem coupled\nacross the LTE transmission time intervals (TTIs). We then propose a TTI-level\nproblem to decouple scheduling across TTIs. Finally, we propose a heuristic,\nwith extremely low complexity. The formulations illustrate the detail required\nto realize resource allocation in an implemented standard. Numerical results\nshow that the performance of the TTI-level scheme is very close to that of the\nframe-level upper bound. Similarly, the heuristic scheme works well compared to\nTTI-level optimization and a baseline scheduling algorithm. Finally, we show\nthat our PF optimization retains the high fairness index characterizing\nPF-scheduling.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 00:16:38 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Mohseni", "Maryam", ""], ["Banani", "S. Alireza", ""], ["Eckford", "Andrew W.", ""], ["Adve", "Raviraj S.", ""]]}, {"id": "1901.02126", "submitter": "Yiming Miao", "authors": "Yixue Hao, Yiming Miao, Yuanwen Tian, Long Hu, M. Shamim Hossain,\n  Ghulam Muhammad, Syed Umar Amin", "title": "Smart-Edge-CoCaCo: AI-Enabled Smart Edge with Joint Computation,\n  Caching, and Communication in Heterogeneous IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of mobile communication technology, hardware, distributed\ncomputing, and artificial intelligence (AI) technology has promoted the\napplication of edge computing in the field of heterogeneous Internet of Things\n(IoT). In order to overcome the defects of the traditional cloud computing\nmodel in the era of big data. In this article, we first propose a new AIenabled\nsmart edge with heterogeneous IoT architecture which combines edge computing,\ncaching, and communication. Then, we propose the Smart-Edge-CoCaCo algorithm.\nTo minimize total delay and confirm the computation offloading decision,\nSmart-Edge-CoCaCo uses joint optimization of the wireless communication model,\nthe collaborative filter caching model in edge cloud, and the computation\noffloading model. Finally, we built an emotion interaction testbed to perform\ncomputational delay experiments in real environments. The experiment results\nshowed that the computation delay of the Smart-Edge-CoCaCo algorithm is lower\nthan that of traditional cloud computing model with the increase of computing\ntask data and the number of concurrent users.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 02:04:12 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Hao", "Yixue", ""], ["Miao", "Yiming", ""], ["Tian", "Yuanwen", ""], ["Hu", "Long", ""], ["Hossain", "M. Shamim", ""], ["Muhammad", "Ghulam", ""], ["Amin", "Syed Umar", ""]]}, {"id": "1901.02178", "submitter": "Vishrant Tripathi", "authors": "Vishrant Tripathi, Rajat Talak, Eytan Modiano", "title": "Age Optimal Information Gathering and Dissemination on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of timely exchange of updates between a central\nstation and a set of ground terminals $V$, via a mobile agent that traverses\nacross the ground terminals along a mobility graph $G = (V, E)$. We design the\ntrajectory of the mobile agent to minimize peak and average age of information\n(AoI), two newly proposed metrics for measuring timeliness of information. We\nconsider randomized trajectories, in which the mobile agent travels from\nterminal $i$ to terminal $j$ with probability $P_{i,j}$. For the information\ngathering problem, we show that a randomized trajectory is peak age optimal and\nfactor-$8\\mathcal{H}$ average age optimal, where $\\mathcal{H}$ is the mixing\ntime of the randomized trajectory on the mobility graph $G$. We also show that\nthe average age minimization problem is NP-hard. For the information\ndissemination problem, we prove that the same randomized trajectory is\nfactor-$O(\\mathcal{H})$ peak and average age optimal. Moreover, we propose an\nage-based trajectory, which utilizes information about current age at\nterminals, and show that it is factor-$2$ average age optimal in a symmetric\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 07:10:21 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Tripathi", "Vishrant", ""], ["Talak", "Rajat", ""], ["Modiano", "Eytan", ""]]}, {"id": "1901.02298", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Stefan Falten and Christian Wietfeld", "title": "Performance Evaluation and Optimization of B.A.T.M.A.N. V Routing for\n  Aerial and Ground-based Mobile Ad-hoc Networks", "comments": null, "journal-ref": "2019 IEEE 89th Vehicular Technology Conference (VTC2019-Spring)", "doi": "10.1109/VTCSpring.2019.8746361", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The provision of reliable and efficient end-to-end communication within\nground- and air-based mobile mesh networks is a major challenge for routing\nprotocols due to the mobility-related dynamics of the channel properties and\nthe resulting mesh network topology. In this paper, we evaluate the performance\nof the novel Better Approach To Mobile Adhoc Networking (B.A.T.M.A.N.) V\nrouting protocol for vehicular mesh networks and propose a mobility-predictive\nextension that explicitly addresses highly dynamic communication networks. In\norder to enable large-scale simulative analysis, we present an open source\nsimulation model, which is validated by field experiments. Within a\ncomprehensive evaluation campaign in Vehicle-to-Everything (V2X) and Unmanned\nAerial Vehicle (UAV) scenarios, it is shown that the predictive B.A.T.M.A.N.\nV-based approach is significantly better suited for maintaining reliable\nconnectivity within highly mobile mesh networks than established routing\nprotocols.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 13:33:16 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 07:36:35 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Falten", "Stefan", ""], ["Wietfeld", "Christian", ""]]}, {"id": "1901.02306", "submitter": "Evgenii Vinogradov A", "authors": "Evgenii Vinogradov, Hazem Sallouha, Sibren De Bast, Mohammad Mahdi\n  Azari, Sofie Pollin", "title": "Tutorial on UAV: A Blue Sky View on Wireless Communication", "comments": "42 pages, 32 Figures", "journal-ref": null, "doi": "10.13052/jmm1550-4646.1443", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing use of Unmanned Aerial Vehicles (UAVs) for various applications\nrequires ubiquitous and reliable connectivity for safe control and data\nexchange between these devices and ground terminals. Depending on the\napplication, UAV-mounted wireless equipment can either be an aerial user\nequipment (AUE) that co-exists with the terrestrial users, or it can be a part\nof wireless infrastructure providing a range of services to the ground users.\nFor instance, AUE can be used for real-time search and rescue and Aerial Base\nStation (ABS) can enhance coverage, capacity and energy efficiency of wireless\nnetworks. In both cases, UAV-based solutions are scalable, mobile, fast to\ndeploy. However, several technical challenges have to be addressed. In this\nwork, we present a tutorial on wireless communication with UAVs, taking into\naccount a wide range of potential applications. The main goal of this work is\nto provide a complete overview of the main scenarios (AUE and ABS), channel and\nperformance models, compare them, and discuss open research points. This work\ngives a comprehensive overview of the research done until now and depicts a\ncomprehensive picture to foster new ideas and solutions while avoiding\nduplication of past work. We start by discussing the open challenges of\nwireless communication with UAVs. To give answers to the posed questions, we\nfocus on the UAV communication basics, mainly providing the necessary channel\nmodeling background and giving guidelines on how various channel models should\nbe used. Next, theoretical, simulation- and measurement-based approaches, to\naddress the key challenges for AUE usage, are presented. Moreover, in this\nwork, we aim to provide a comprehensive overview on how UAV-mounted equipment\ncan be used as a part of a communication network. Based on the theoretical\nanalysis, we show how various network parameters can be optimized.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 13:43:51 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Vinogradov", "Evgenii", ""], ["Sallouha", "Hazem", ""], ["De Bast", "Sibren", ""], ["Azari", "Mohammad Mahdi", ""], ["Pollin", "Sofie", ""]]}, {"id": "1901.02572", "submitter": "Xinzhe Fu", "authors": "Xinzhe Fu, Eytan Modiano", "title": "Network Interdiction Using Adversarial Traffic Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional network interdiction refers to the problem of an interdictor\ntrying to reduce the throughput of network users by removing network edges. In\nthis paper, we propose a new paradigm for network interdiction that models\nscenarios, such as stealth DoS attack, where the interdiction is performed\nthrough injecting adversarial traffic flows. Under this paradigm, we first\nstudy the deterministic flow interdiction problem, where the interdictor has\nperfect knowledge of the operation of network users. We show that the problem\nis highly inapproximable on general networks and is NP-hard even when the\nnetwork is acyclic. We then propose an algorithm that achieves a logarithmic\napproximation ratio and quasi-polynomial time complexity for acyclic networks\nthrough harnessing the submodularity of the problem. Next, we investigate the\nrobust flow interdiction problem, which adopts the robust optimization\nframework to capture the case where definitive knowledge of the operation of\nnetwork users is not available. We design an approximation framework that\nintegrates the aforementioned algorithm, yielding a quasi-polynomial time\nprocedure with poly-logarithmic approximation ratio for the more challenging\nrobust flow interdiction. Finally, we evaluate the performance of the proposed\nalgorithms through simulations, showing that they can be efficiently\nimplemented and yield near-optimal solutions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 01:18:15 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Fu", "Xinzhe", ""], ["Modiano", "Eytan", ""]]}, {"id": "1901.02574", "submitter": "Raghunandan M Rao", "authors": "Raghunandan M. Rao, Vuk Marojevic, Jeffrey H. Reed", "title": "Analysis of Non-Pilot Interference on Link Adaptation and Latency in\n  Cellular Networks", "comments": "6 pages, 9 figures, accepted for publication at the 89th IEEE\n  Vehicular Technology Conference (IEEE VTC Spring 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern wireless systems such as the Long-Term Evolution (LTE) and 5G New\nRadio (5G NR) use pilot-aided SINR estimates to adapt the transmission mode and\nthe modulation and coding scheme (MCS) of data transmissions, maximizing the\nutility of the wireless channel capacity. However, when interference is\nlocalized exclusively on non-pilot resources, pilot-aided SINR estimates become\ninaccurate. We show that this leads to congestion due to retransmissions, and\nin the worst case, outage due to very high block error rate (BLER). We\ndemonstrate this behavior through numerical as well as experimental results\nwith the 4G LTE downlink, which show high BLER and significant throughput\ndetriment in the presence of non-pilot interference (NPI). To provide useful\ninsights on the impact of NPI on low-latency communications, we derive an\napproximate relation between the retransmission-induced latency and BLER. Our\nresults show that NPI can severely compromise low-latency applications such as\nvehicle-to-vehicle (V2V) communications and 5G NR. We identify robust link\nadaptation schemes as the key to reliable communications.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 01:24:35 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Rao", "Raghunandan M.", ""], ["Marojevic", "Vuk", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "1901.02585", "submitter": "Adib Rastegarnia", "authors": "Douglas Comer, Adib Rastegarnia", "title": "Externalization of Packet Processing in Software Defined Networking", "comments": "4 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current SDN controllers aggregate all control plane subsystems into a\nmonolithic program. A controller that follows the aggregated approach defines\nits own set of programming interfaces and services, making application\ndevelopment dependent on a particular SDN controller and restricting\nportability of management applications across controllers. We propose a new\narchitecture that disaggregates controller functionality and externalizes\npacket processing, a critical first step towards migrating from a centralized,\nmonolithic design to a decentralized microservice control plane architecture in\nwhich SDN controller functions are divided into a smaller, interconnected set.\nWe argue that dividing a monolithic controller into smaller pieces has\nadvantages.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 02:38:33 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Comer", "Douglas", ""], ["Rastegarnia", "Adib", ""]]}, {"id": "1901.02613", "submitter": "Ali Rahmati", "authors": "Ali Rahmati, Xiaofan He, Ismail Guvenc, and Huaiyu Dai", "title": "Dynamic Mobility-Aware Interference Avoidance for Aerial Base Stations\n  in Cognitive Radio Networks", "comments": "9 pages, 13 figures, to be presented in Proc. IEEE INFOCOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aerial base station (ABS) is a promising solution for public safety as it can\nbe deployed in coexistence with cellular networks to form a temporary\ncommunication network. However, the interference from the primary cellular\nnetwork may severely degrade the performance of an ABS network. With this\nconsideration, an adaptive dynamic interference avoidance scheme is proposed in\nthis work for ABSs coexisting with a primary network. In the proposed scheme,\nthe mobile ABSs can reconfigure their locations to mitigate the interference\nfrom the primary network, so as to better relay the data from the designated\nsource(s) to destination(s). To this end, the single/multi-commodity maximum\nflow problems are formulated and the weighted Cheeger constant is adopted as a\ncriterion to improve the maximum flow of the ABS network. In addition, a\ndistributed algorithm is proposed to compute the optimal ABS moving directions.\nMoreover, the trade-off between the maximum flow and the shortest path\ntrajectories is investigated and an energy-efficient approach is developed as\nwell. Simulation results show that the proposed approach is effective in\nimproving the maximum network flow and the energy-efficient approach can save\nup to 39% of the energy for the ABSs with marginal degradation in the maximum\nnetwork flow.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 06:24:08 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 19:05:19 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Rahmati", "Ali", ""], ["He", "Xiaofan", ""], ["Guvenc", "Ismail", ""], ["Dai", "Huaiyu", ""]]}, {"id": "1901.02636", "submitter": "Jianan Zhang", "authors": "Jianan Zhang, Hyang-Won Lee, Eytan Modiano", "title": "On the Robustness of Distributed Computing Networks", "comments": "International Conference on the Design of Reliable Communication\n  Networks (DRCN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flows in a distributed computing network require both transmission\nand processing, and can be interdicted by removing either communication or\ncomputation resources. We study the robustness of a distributed computing\nnetwork under the failures of communication links and computation nodes. We\ndefine cut metrics that measure the connectivity, and show a non-zero gap\nbetween the maximum flow and the minimum cut. Moreover, we study a network flow\ninterdiction problem that minimizes the maximum flow by removing communication\nand computation resources within a given budget. We develop mathematical\nprograms to compute the optimal interdiction, and polynomial-time approximation\nalgorithms that achieve near-optimal interdiction in simulation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 08:38:38 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 10:47:18 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Zhang", "Jianan", ""], ["Lee", "Hyang-Won", ""], ["Modiano", "Eytan", ""]]}, {"id": "1901.02651", "submitter": "Marcel von Maltitz", "authors": "Marcel von Maltitz, Dominik Bitzer, Georg Carle", "title": "Data Querying and Access Control for Secure Multiparty Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Internet of Things and smart environments data, collected from\ndistributed sensors, is typically stored and processed by a central middleware.\nThis allows applications to query the data they need for providing further\nservices. However, centralization of data causes several privacy threats: The\nmiddleware becomes a third party which has to be trusted, linkage and\ncorrelation of data from different context becomes possible and data subject\nlose control over their data.\n  Hence, other approaches than centralized processing should be considered.\nHere, Secure Multiparty Computation is a promising candidate for secure and\nprivacy-preserving computation happening close to the sources of the data.\n  In order to make SMC fit for application in these contexts, we extend SMC to\nact as a service: We provide elements which allow third parties to query\ncomputed data from a group of peers performing SMC. Furthermore, we establish\nfine-granular access control on the level of individual data queries, yielding\ndata protection of the computed results. By adding measures to inform data\nsources about requests and the usage of their data, we show how a fully\nprivacy-preserving service can be built on the foundation of SMC.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 09:55:58 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["von Maltitz", "Marcel", ""], ["Bitzer", "Dominik", ""], ["Carle", "Georg", ""]]}, {"id": "1901.02700", "submitter": "Maria Papadopouli", "authors": "Georgios Fortetsanakis and Maria Papadopouli", "title": "Multi-layer Game-Theoretical Analysis of Wireless Markets with Market\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New larger and more diverse wireless markets have emerged. Modelling them can\nbe challenging due to various business and network aspects. Existing models of\nwireless markets are either microscopic, focusing on a specific technical\naspect (e.g., network topology) at a fine scale or macroscopic modelling\nwireless markets at a large-scale, e.g., considering homogeneous populations.\nIn contrast to these approaches, this work develops a multi-layer\ngame-theoretical framework, which allows providers to model users at\nmultiple-level of detail by considering a different number of user\nsub-populations. It also models the mobility, traffic demand, and networks of\nproviders. A population game using Logit dynamics models the user selection of\nthe dataplan and provider, capturing the diversity in customer profile and\nrelaxing the assumption about the user rationality. It analytically computes\nthe equilibriums of users and providers and numerically evaluates the\nperformance of the market as a function of the traffic demand, the number of\navailable dataplans, and the knowledge about customer population. Significant\nbenefits in revenue can be achieved by a provider when it integrates more\ndetailed information about the user population. The number of disconnected\nusers also decreases. Moreover the availability of several dataplans further\nenhances the gains. The stronger the provider, the more prominent the benefits.\nHowever the benefits diminish when all the providers model the customer\npopulation at the same degree of detail due to an increased competition. The\nanalysis highlights the strategies of the providers depending on their\ncapacity, level of knowledge about the customer population, and traffic\nconditions. It illustrates how a provider changes its strategy under different\nconditions, focusing potentially on different customer segments and also the\npressure introduced by specific customer types.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 12:48:27 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Fortetsanakis", "Georgios", ""], ["Papadopouli", "Maria", ""]]}, {"id": "1901.02873", "submitter": "Omur Ozel", "authors": "Peng Zou and Omur Ozel and Suresh Subramaniam", "title": "Waiting before Serving: A Companion to Packet Management in Status\n  Update Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the potential of server waiting before packet\ntransmission in improving the Age of Information (AoI) in status update\nsystems. We consider a non-preemptive queue with Poisson arrivals and\nindependent general service distribution and we incorporate waiting before\nserving in two packet management schemes: M/GI/1/1 and M/GI/1/$2^*$. In\nM/GI/1/1 scheme, the server waits for a deterministic time immediately after a\npacket enters the server. In M/GI/1/$2^*$ scheme, depending on idle or busy\nsystem state, the server waits for a deterministic time before starting service\nof the packet. In both cases, if a potential newer arrival is captured existing\npacket is discarded. Different from most existing works, we analyze AoI\nevolution by indexing the incoming packets, which is enabled by an alternative\nmethod of partitioning the area under the evolution of instantaneous AoI to\ncalculate its time average. We obtain expressions for average and average peak\nAoI for both queueing disciplines with waiting. Our numerical results\ndemonstrate that waiting before service can bring significant improvement in\naverage age, particularly, for heavy-tailed service distributions. This\nimprovement comes at the expense of an increase in average peak AoI. We\nhighlight the trade-off between average and average peak AoI generated by\nwaiting before serving.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 18:46:44 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 14:54:46 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 16:31:08 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2019 14:32:30 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Zou", "Peng", ""], ["Ozel", "Omur", ""], ["Subramaniam", "Suresh", ""]]}, {"id": "1901.02929", "submitter": "Mark Berman", "authors": "Mark Berman, Timur Friedman, Abhimanyu Gosain, Kate Keahey, Rick\n  McGeer, Ingrid Moerman, Akihiro Nakao, Lucas Nussbaum, Kristin Rauschenbach,\n  Violet Syrotiuk, Malathi Veeraraghavan, Naoaki Yamanaka", "title": "Report of the Third Global Experimentation for Future Internet (GEFI\n  2018) Workshop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The third Global Experimentation for Future Internet (GEFI 2018) workshop was\nheld October 25-26, 2018 in Tokyo, Japan, hosted by the University of Tokyo. A\ntotal of forty-four participants attended, representing Belgium, Brazil, China,\nDenmark, France, Ireland, Japan, the Republic of Korea, and the United States.\nThe workshop employed a mixed format of presentations and open group\ndiscussions to advance multi-national coordination and interoperation of\nresearch infrastructure for advanced networking and computer science research.\n  Major topic areas included: softwareization and virtualization of radios and\nnetworks; testbed support for networking experiments; EdgeNet; a federated\ntestbed of elastic optical networks; and reproducibility in experimentation.\nWorkshop goals included both the formulation of specific new research\ncollaborations and strategies for coordination and interoperation of research\ntestbeds.\n  Workshop outcomes include a variety of new and ongoing collaborative efforts,\nranging from an agreement to pursue the development of optical \"white boxes\" in\nsupport of elastic optical testbeds to the identification of strategies for\neffective use of open-source software and hardware platforms in future research\ninfrastructure.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 21:03:17 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Berman", "Mark", ""], ["Friedman", "Timur", ""], ["Gosain", "Abhimanyu", ""], ["Keahey", "Kate", ""], ["McGeer", "Rick", ""], ["Moerman", "Ingrid", ""], ["Nakao", "Akihiro", ""], ["Nussbaum", "Lucas", ""], ["Rauschenbach", "Kristin", ""], ["Syrotiuk", "Violet", ""], ["Veeraraghavan", "Malathi", ""], ["Yamanaka", "Naoaki", ""]]}, {"id": "1901.03025", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Thomas Liebig and Tim Vranken and Michael\n  Schreckenberg and Christian Wietfeld", "title": "System-of-Systems Modeling, Analysis and Optimization of Hybrid\n  Vehicular Traffic", "comments": null, "journal-ref": "2019 IEEE International Systems Conference (SysCon)", "doi": "10.1109/SYSCON.2019.8836786", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the development of fully autonomous vehicles is one of the major\nresearch fields in the Intelligent Transportation Systems (ITSs) domain, the\nupcoming longterm transition period - the hybrid vehicular traffic - is often\nneglected. However, within the next decades, automotive systems with\nheterogeneous autonomy levels will share the same road network, resulting in\nnew problems for traffic management systems and communication network\ninfrastructure providers. In this paper, we identify key challenges of the\nupcoming hybrid traffic scenario and present a system-of-systems model, which\nbrings together approaches and methods from traffic modeling, data science, and\ncommunication engineering in order to allow data-driven traffic flow\noptimization. The proposed model consists of data acquisition, data transfer,\ndata analysis, and data exploitation and exploits real world sensor data as\nwell as simulative optimization methods. Based on the results of multiple case\nstudies, which focus on individual challenges (e.g., resource-efficient data\ntransfer and dynamic routing of vehicles), we point out approaches for using\nthe existing infrastructure with a higher grade of efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 06:01:18 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 07:28:01 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Liebig", "Thomas", ""], ["Vranken", "Tim", ""], ["Schreckenberg", "Michael", ""], ["Wietfeld", "Christian", ""]]}, {"id": "1901.03052", "submitter": "Richard Hill Prof", "authors": "Hussain Al-Aqrabi, Richard Hill", "title": "A Secure Connectivity Model for Internet of Things Analytics Service\n  Delivery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide scale interest and adoption of Internet of Things (IoT) technologies is\nfuelling innovation in the way individuals and even machines can interact to\nexchange knowledge. One area of particular interest is that of analytics. Ever\ndecreasing form factor hardware is enabling computation and data storage to be\nembedded into many different devices. The combination of network connectivity\nand emerging distributed models of service orchestration is allowing the\ncreation of new ways of measuring, monitoring and analysing performance. Using\nan approach inspired by the NIST seven layer model of cloud computing, we\npropose a model of connectivity that enables analytics services to be consumed\nacross individual system components that are distributed, such as those found\nin the IoT and Industrial IoT (IIoT) domains.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 08:29:47 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Al-Aqrabi", "Hussain", ""], ["Hill", "Richard", ""]]}, {"id": "1901.03137", "submitter": "Yu-Pin Hsu", "authors": "Yi-Hsuan Tseng and Yu-Pin Hsu", "title": "Online Energy-Efficient Scheduling for Timely Information Downloads in\n  Mobile Networks", "comments": "10 pages, technical report for the ISIT 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a mobile network where a mobile device is running an application\nthat requires timely information. The information at the device can be updated\nby downloading the latest information through neighboring access points. The\nfreshness of the information at the device is characterized by the recently\nproposed age of information. However, minimizing the age of information by\nfrequent downloading increases power consumption of the device. In this\ncontext, an energy-efficient scheduling algorithm for timely information\ndownloads is critical, especially for power-limited mobile devices. Moreover,\nunpredictable movement of the mobile device causes uncertainty of the channel\ndynamics, which is even non-stationary within a finite amount of time for\nrunning the application. Thus, in this paper we devise a randomized online\nscheduling algorithm for mobile devices, which can move arbitrarily and run the\napplication for any amount of time. We show that the expected total cost\nincurred by the proposed algorithm, including an age cost and a downloading\ncost, is (asymptotically) at most e/(e-1) ~ 1.58 times the minimum total cost\nachieved by an optimal offline scheduling algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 13:05:18 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2019 14:22:51 GMT"}, {"version": "v3", "created": "Wed, 16 Jan 2019 10:09:43 GMT"}, {"version": "v4", "created": "Mon, 29 Apr 2019 01:18:51 GMT"}, {"version": "v5", "created": "Tue, 30 Apr 2019 08:58:04 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Tseng", "Yi-Hsuan", ""], ["Hsu", "Yu-Pin", ""]]}, {"id": "1901.03215", "submitter": "Sergio Herrer\\'ia-Alonso", "authors": "Sergio Herrer\\'ia-Alonso, Miguel Rodr\\'iguez-P\\'erez, Manuel\n  Fern\\'andez-Veiga, C\\'andido L\\'opez-Garc\\'ia", "title": "Dynamic EEE Coalescing: Techniques and Bounds", "comments": "10 pages. To be published in IEEE Transactions on Green\n  Communications and Networking", "journal-ref": "IEEE Transactions on Green Communications and Networking. Volume:\n  3, Issue: 1, March 2019", "doi": "10.1109/TGCN.2019.2893105", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frame coalescing is one of the most efficient techniques to manage the low\npower idle (LPI) mode supported by Energy Efficient Ethernet (EEE) interfaces.\nThis technique enables EEE interfaces to remain in the LPI mode for a certain\namount of time upon the arrival of the first frame (time-based coalescing) or\nuntil a predefined amount of traffic accumulates in the transmission buffer\n(size-based coalescing). This paper provides new insights on the practical\nefficiency limits of both coalescing techniques. In particular, we derive the\nfundamental limits on the maximum energy savings considering a target average\nframe delay. Additionally, we present new open-loop adaptive variants of both\ntime-based and size-based coalescing techniques. These proposals dynamically\nadjust the length of the sleeping periods in accordance with actual traffic\nconditions to reduce energy consumption while keeping the average delay near a\npredefined value simultaneously. Analytical and simulation results show that\nthe energy consumption of both proposals is comparable to the fundamental\nlimits. Consequently, we recommend the usage of the time-based algorithm in\nmost scenarios because of its simplicity as well as its ability to bound the\nmaximum frame delay at the same time.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 15:20:58 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Herrer\u00eda-Alonso", "Sergio", ""], ["Rodr\u00edguez-P\u00e9rez", "Miguel", ""], ["Fern\u00e1ndez-Veiga", "Manuel", ""], ["L\u00f3pez-Garc\u00eda", "C\u00e1ndido", ""]]}, {"id": "1901.03239", "submitter": "Emilio Calvanese Strinati", "authors": "Emilio Calvanese Strinati, Sergio Barbarossa, Jos\\'e Luis\n  Gonzalez-Jimenez, Dimitri Kt\\'enas, Nicolas Cassiau, C\\'edric Dehos", "title": "6G: The Next Frontier", "comments": "This paper was submitted to IEEE Vehicular Technologies Magazine on\n  the 7th of January 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current development of 5G networks represents a breakthrough in the\ndesign of communication networks, for its ability to provide a single platform\nenabling a variety of different services, from enhanced mobile broadband\ncommunications, automated driving, Internet-of-Things, with its huge number of\nconnected devices, etc. Nevertheless, looking at the current development of\ntechnologies and new services, it is already possible to envision the need to\nmove beyond 5G with a new architecture incorporating new services and\ntechnologies. The goal of this paper is to motivate the need to move to a sixth\ngeneration (6G) of mobile communication networks, starting from a gap analysis\nof 5G, and predicting a new synthesis of near future services, like hologram\ninterfaces, ambient sensing intelligence, a pervasive introduction of\nartificial intelligence and the incorporation of technologies, like TeraHertz\n(THz) or Visible Light Communications (VLC), 3-dimensional coverage.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 16:03:17 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 12:29:00 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Strinati", "Emilio Calvanese", ""], ["Barbarossa", "Sergio", ""], ["Gonzalez-Jimenez", "Jos\u00e9 Luis", ""], ["Kt\u00e9nas", "Dimitri", ""], ["Cassiau", "Nicolas", ""], ["Dehos", "C\u00e9dric", ""]]}, {"id": "1901.03385", "submitter": "Milena Pinto", "authors": "Milena F. Pinto, Andr\\'e L. M. Marcato, Aur\\'elio G. Melo, Leonardo M.\n  Hon\\'orio, and Cristina Urdiales", "title": "A Framework for Analyzing Fog-Cloud Computing Cooperation Applied to\n  Information Processing of UAVs", "comments": "Volume 2019, Article ID 7497924, 14 pages", "journal-ref": "Wireless Communications and Mobile Computing, 2019", "doi": "10.1155/2019/7497924", "report-no": null, "categories": "cs.RO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are a relatively new technology. Their\napplication can often involve complex and unseen problems. For instance, they\ncan work in a cooperative-based environment under the supervision of a ground\nstation to speed up critical decision-making processes. However, the amount of\ninformation exchanged among the aircraft and ground station is limited by high\ndistances, low bandwidth size, restricted processing capability, and energy\nconstraints. These drawbacks restrain large-scale operations such as large area\ninspections. New distributed state-of-the-art processing architectures, such as\nfog computing, can improve latency, scalability, and efficiency to meet time\nconstraints via data acquisition, processing, and storage at different levels.\nUnder these amendments, this research work proposes a mathematical model to\nanalyze distribution-based UAVs topologies and a fog-cloud computing framework\nfor large-scale mission and search operations. The tests have successfully\npredicted latency and other operational constraints, allowing the analysis of\nfog-computing advantages over traditional cloud-computing architectures.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 20:55:21 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Pinto", "Milena F.", ""], ["Marcato", "Andr\u00e9 L. M.", ""], ["Melo", "Aur\u00e9lio G.", ""], ["Hon\u00f3rio", "Leonardo M.", ""], ["Urdiales", "Cristina", ""]]}, {"id": "1901.03404", "submitter": "Mallesham Dasari", "authors": "Dasari Mallesham, Christina Vlachou, Shruti Sanadhya, Pranjal Sahu,\n  Yang Qiu, Kyu-Han Kim, Samir R. Das", "title": "Handcrafted vs Deep Learning Classification for Scalable Video QoE\n  Modeling", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile video traffic is dominant in cellular and enterprise wireless\nnetworks. With the advent of diverse applications, network administrators face\nthe challenge to provide high QoE in the face of diverse wireless conditions\nand application contents. Yet, state-of-the-art networks lack analytics for\nQoE, as this requires support from the application or user feedback. While\nthere are existing techniques to map QoS to QoE by training machine learning\nmodels without requiring user feedback, these techniques are limited to only\nfew applications, due to insufficient QoE ground-truth annotation for ML. To\naddress these limitations, we focus on video telephony applications and model\nkey artefacts of spatial and temporal video QoE. Our key contribution is\ndesigning content- and device-independent metrics and training across diverse\nWiFi conditions. We show that our metrics achieve a median 90% accuracy by\ncomparing with mean-opinion-score from more than 200 users and 800 video\nsamples over three popular video telephony applications -- Skype, FaceTime and\nGoogle Hangouts. We further extend our metrics by using deep neural networks,\nmore specifically we use a combined CNN and LSTM model. We achieve a median\naccuracy of 95% by combining our QoE metrics with the deep learning model,\nwhich is a 38% improvement over the state-of-the-art well known techniques.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 21:33:19 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Mallesham", "Dasari", ""], ["Vlachou", "Christina", ""], ["Sanadhya", "Shruti", ""], ["Sahu", "Pranjal", ""], ["Qiu", "Yang", ""], ["Kim", "Kyu-Han", ""], ["Das", "Samir R.", ""]]}, {"id": "1901.03535", "submitter": "Savio Sciancalepore", "authors": "Savio Sciancalepore, Omar Adel Ibrahim, Gabriele Oligeri, Roberto Di\n  Pietro", "title": "PiNcH: an Effective, Efficient, and Robust Solution to Drone Detection\n  via Network Traffic Analysis", "comments": null, "journal-ref": "Computer Networks (COMNET), Elsevier, 2020", "doi": "10.1016/j.comnet.2019.107044", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose PiNcH, a methodology to detect the presence of a drone, its\ncurrent status, and its movements by leveraging just the communication traffic\nexchanged between the drone and its Remote Controller (RC). PiNcH is built\napplying standard classification algorithms to the eavesdropped traffic,\nanalyzing features such as packets inter-arrival time and size. PiNcH is fully\npassive and it requires just cheap and general-purpose hardware. To evaluate\nthe effectiveness of our solution, we collected real communication traces\noriginated by a drone running the widespread ArduCopter open-source firmware,\ncurrently mounted on-board of a wide range (30+) of commercial amateur drones.\nWe tested our solution against different publicly available wireless traces.\nThe results prove that PiNcH can efficiently and effectively: (i) identify the\npresence of the drone in several heterogeneous scenarios; (ii) identify the\ncurrent state of a powered-on drone, i.e., flying or lying on the ground; (iii)\ndiscriminate the movements of the drone; and, finally, (iv) enjoy a reduced\nupper bound on the time required to identify a drone with the requested level\nof assurance. The effectiveness of PiNcH has been also evaluated in the\npresence of both heavy packet loss and evasion attacks. In this latter case,\nthe adversary modifies on purpose the profile of the traffic of the drone-RC\nlink to avoid the detection. In both the cited cases, PiNcH continues enjoying\na remarkable performance. Further, the comparison against state of the art\nsolution confirms the superior performance of PiNcH in several scenarios. Note\nthat all the drone-controller generated data traces have been released as\nopen-source, to allow replicability and foster follow-up. Finally, the quality\nand viability of our solution, do prove that network traffic analysis can be\nsuccessfully adopted for drone identification and status discrimination.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 10:03:50 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 13:36:01 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Sciancalepore", "Savio", ""], ["Ibrahim", "Omar Adel", ""], ["Oligeri", "Gabriele", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "1901.03568", "submitter": "Jordi Pailliss\\'e Vilanova", "authors": "Jordi Paillisse and Jordi Subira and Albert Lopez and Alberto\n  Rodriguez-Natal and Vina Ermagan and Fabio Maino and Albert Cabellos", "title": "Distributed Access Control with Blockchain", "comments": "7 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The specification and enforcement of network-wide policies in a single\nadministrative domain is common in today's networks and considered as already\nresolved. However, this is not the case for multi-administrative domains, e.g.\namong different enterprises. In such situation, new problems arise that\nchallenge classical solutions such as PKIs, which suffer from scalability and\ngranularity concerns. In this paper, we present an extension to Group-Based\nPolicy -- a widely used network policy language -- for the aforementioned\nscenario. To do so, we take advantage of a permissioned blockchain\nimplementation (Hyperledger Fabric) to distribute access control policies in a\nsecure and auditable manner, preserving at the same time the independence of\neach organization. Network administrators specify polices that are rendered\ninto blockchain transactions. A LISP control plane (RFC 6830) allows routers\nperforming the access control to query the blockchain for authorizations. We\nhave implemented an end-to-end experimental prototype and evaluated it in terms\nof scalability and network latency.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 12:15:31 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Paillisse", "Jordi", ""], ["Subira", "Jordi", ""], ["Lopez", "Albert", ""], ["Rodriguez-Natal", "Alberto", ""], ["Ermagan", "Vina", ""], ["Maino", "Fabio", ""], ["Cabellos", "Albert", ""]]}, {"id": "1901.03641", "submitter": "Mehmet Ilter", "authors": "Mehmet Cagri Ilter, Halim Yanikomeroglu", "title": "Convolutionally Coded SNR-Adaptive Transmission for Low-Latency\n  Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fifth generation new radio aims to facilitate new use cases in wireless\ncommunications. Some of these new use cases have highly de-manding latency\nrequirements; many of the powerful forward error correction codes deployed in\ncurrent systems, such as the turbo and low-density parity-check codes, do not\nperform well when the low-latency requirement does not allow iterative\ndecoding. As such, there is a rejuvenated interest in noniterative/one-shot\ndecoding algorithms. Motivated by this, we propose a signal-to-noise\nratio-adaptive convolutionally coded system with optimized constellations\ndesigned specifically for a particular set of convolutional code parameters.\nNumerical results show that significant performance improvements in terms of\nbit-error-rate and spectral efficiency can be obtained compared to the\ntraditional adaptive modulation and coding systems inlow-latency\ncommunications.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 13:40:58 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Ilter", "Mehmet Cagri", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "1901.03683", "submitter": "Muhammad Shahwaiz Afaqui PhD", "authors": "M. Shahwaiz Afaqui, Cristina Cano, Vincent Kotzsch, Clemens Felber and\n  Walter Nitzold", "title": "Implementation of the 3GPP LTE-WLAN Interworking Protocols in NS-3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next generation wireless standard, called Fifth Generation (5G), is being\ndesigned to encompass Heterogeneous Networks (HetNets) architectures consisting\nof a single holistic network with Multiple Radio Access Technologies\n(Multi-RAT). Multiple connectivity protocols and spectrum would be managed from\na common core (management system) handling both: i) traditional macro cellular\nsystems (such as LTE), that can provide long-range, outdoor coverage, as well\nas ii) low-power wireless systems with high capacity (such as Wi-Fi), that can\nbe deployed to cater indoor traffic needs. 5G HetNets are expected to achieve\nubiquitous connectivity that would guarantee Quality of Service (QoS), Quality\nof Experience (QoE) along with efficient use of spectrum and energy at low\ncost. Tightly coupled LTE-Wi-Fi networks have emerged as one of the promising\nsolutions in the 5G era to boost network capacity and improve end user's\nquality of experience. LTE/Wi-Fi Link Aggregation (LWA) and LTE WLAN Radio\nLevel Integration with IPSec Tunnel (LWIP) are two approaches put forward by\nthe 3rd Generation Partnership Project (3GPP) to enable flexible, general, and\nscalable LTE-WLAN inter-working. These techniques enable operator-controlled\naccess of licensed and unlicensed spectrum and allow transparent access of\noperator's evolved core. The most important aspect of these techniques is that\nthey could be enabled with straightforward software upgrades and can utilize\nthe already existing Wi-Fi networks. This article presents and motivates the\ndesign details of LWA and LWIP protocols. We also present the first NS-3 LWA\nand LWIP implementations over Network Simulator 3 (NS-3). In particular, this\nwork focuses on the adaptation and concurrent usage of different NS-3 modules\nand protocols of different technologies to enable the support of these\ninterworking schemes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 18:41:00 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Afaqui", "M. Shahwaiz", ""], ["Cano", "Cristina", ""], ["Kotzsch", "Vincent", ""], ["Felber", "Clemens", ""], ["Nitzold", "Walter", ""]]}, {"id": "1901.03931", "submitter": "Gamal Sallam", "authors": "Gamal Sallam, Bo Ji", "title": "Joint Placement and Allocation of VNF Nodes with Budget and Capacity\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Network Function Virtualization (NFV), network services\nthat traditionally run on proprietary dedicated hardware can now be realized\nusing Virtual Network Functions (VNFs) that are hosted on general-purpose\ncommodity hardware. This new network paradigm offers a great flexibility to\nInternet service providers (ISPs) for efficiently operating their networks\n(collecting network statistics, enforcing management policies, etc.). However,\nintroducing NFV requires an investment to deploy VNFs at certain network nodes\n(called VNF-nodes), which has to account for practical constraints such as the\ndeployment budget and the VNF-node capacity. To that end, it is important to\ndesign a joint VNF-nodes placement and capacity allocation algorithm that can\nmaximize the total amount of network flows that are fully processed by the\nVNF-nodes while respecting such practical constraints. In contrast to most\nprior work that often neglects either the budget constraint or the capacity\nconstraint, we explicitly consider both of them. We prove that accounting for\nthese constraints introduces several new challenges. Specifically, we prove\nthat the studied problem is not only NP-hard but also non-submodular. To\naddress these challenges, we introduce a novel relaxation method such that the\nobjective function of the relaxed placement subproblem becomes submodular.\nLeveraging this useful submodular property, we propose two algorithms that\nachieve an approximation ratio of $\\frac{1}{2}(1-1/e)$ and $\\frac{1}{3}(1-1/e)$\nfor the original non-relaxed problem, respectively. Finally, we corroborate the\neffectiveness of the proposed algorithms through extensive evaluations using\ntrace-driven simulations.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 04:11:47 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 12:23:01 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 05:33:30 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Sallam", "Gamal", ""], ["Ji", "Bo", ""]]}, {"id": "1901.04017", "submitter": "Anna Kuznetsova", "authors": "Yuri Monakhov, Oleg Nikitin, Anna Kuznetsova, Alexey Kharlamov,\n  Alexandr Amochkin", "title": "A Machine-Synesthetic Approach To DDoS Network Attack Detection", "comments": "12 pages, 2 figures, 5 tables. Accepted to the Intelligent Systems\n  Conference (IntelliSys) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the authors' opinion, anomaly detection systems, or ADS, seem to be the\nmost perspective direction in the subject of attack detection, because these\nsystems can detect, among others, the unknown (zero-day) attacks. To detect\nanomalies, the authors propose to use machine synesthesia. In this case,\nmachine synesthesia is understood as an interface that allows using image\nclassification algorithms in the problem of detecting network anomalies, making\nit possible to use non-specialized image detection methods that have recently\nbeen widely and actively developed. The proposed approach is that the network\ntraffic data is \"projected\" into the image. It can be seen from the\nexperimental results that the proposed method for detecting anomalies shows\nhigh results in the detection of attacks. On a large sample, the value of the\ncomplex efficiency indicator reaches 97%.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 17:01:46 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 06:38:48 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Monakhov", "Yuri", ""], ["Nikitin", "Oleg", ""], ["Kuznetsova", "Anna", ""], ["Kharlamov", "Alexey", ""], ["Amochkin", "Alexandr", ""]]}, {"id": "1901.04081", "submitter": "Ansari Saleh Ahmar", "authors": "Akbar Iskandar, Elisabet Virma, Ansari Saleh Ahmar", "title": "Implementing DMZ in Improving Network Security of Web Testing in STMIK\n  AKBA", "comments": null, "journal-ref": "International Journal of Engineering & Technology (UEA), 7 (2.3)\n  (2018) 99-104", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The aims of this research are to design and to implement network security\nsystem in internal web testing using DeMilitarized Zone Method and Microtic\nRouter on Siakad server of STMIK AKBA. Data analysis techniques that possible\nto use is descriptive method. The significances of the study are 1) to avoid\nthe attack of cracker who intend to access the system without permissions and\n2) to improve network securityon web testing services on Siakad server of STMIK\nAKBA. The data are obtained by having literature review and observation.\nLiterature review assists the researchers to collect the theory on\nDeMilitarised Zone Method and the previous studies which were used as\ncomparison to the recent study. Obervation was carried out directly to the\nfield to observe the running system. Based on the results and discussion, it is\nshown that the aplication of DeMilitarized Zone Method on microtic can secure\nthe web testing on Siakad server of STMIK AKBA and can maintain the whole\nseries of online services that are available in the server.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 23:10:14 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Iskandar", "Akbar", ""], ["Virma", "Elisabet", ""], ["Ahmar", "Ansari Saleh", ""]]}, {"id": "1901.04092", "submitter": "Stratis Ioannidis", "authors": "Milad Mahdian and Armin Moharrer and Stratis Ioannidis and Edmund Yeh", "title": "Kelly Cache Networks", "comments": "This is the extended version of the Infocom 2019 paper with the same\n  title. The authors gratefully acknowledge support from National Science\n  Foundation grant NeTS-1718355, as well as from research grants by Intel Corp.\n  and Cisco Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study networks of M/M/1 queues in which nodes act as caches that store\nobjects. Exogenous requests for objects are routed towards nodes that store\nthem; as a result, object traffic in the network is determined not only by\ndemand but, crucially, by where objects are cached. We determine how to place\nobjects in caches to attain a certain design objective, such as, e.g.,\nminimizing network congestion or retrieval delays. We show that for a broad\nclass of objectives, including minimizing both the expected network delay and\nthe sum of network queue lengths, this optimization problem can be cast as an\nNP- hard submodular maximization problem. We show that so-called continuous\ngreedy algorithm attains a ratio arbitrarily close to $1 - 1/e \\approx 0.63$\nusing a deterministic estimation via a power series; this drastically reduces\nexecution time over prior art, which resorts to sampling. Finally, we show that\nour results generalize, beyond M/M/1 queues, to networks of M/M/k and symmetric\nM/D/1 queues.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 00:00:45 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 22:17:53 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Mahdian", "Milad", ""], ["Moharrer", "Armin", ""], ["Ioannidis", "Stratis", ""], ["Yeh", "Edmund", ""]]}, {"id": "1901.04167", "submitter": "Rajat Talak", "authors": "Rajat Talak and Eytan Modiano", "title": "Age-Delay Tradeoffs in Single Server Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information freshness and low latency communication is important to many\nemerging applications. While Age of Information (AoI) serves as a metric of\ninformation freshness, packet delay is a traditional metric of communication\nlatency. We prove that there is a natural tradeoff between the AoI and packet\ndelay. We consider a single server system, in which at most one update packet\ncan be serviced at a time. The system designer controls the order in which the\npackets get serviced and the service time distribution, with a given service\nrate. We analyze two tradeoff problems that minimize packet delay and the\nvariance in packet delay, respectively, subject to an average age constraint.\nWe prove a strong age-delay and age-delay variance tradeoff, wherein, as the\naverage age approaches its minimum, the delay and its variance approach\ninfinity. We show that the service time distribution that mininizes average\nage, must necessarily have an unbounded-second moment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 07:47:23 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Talak", "Rajat", ""], ["Modiano", "Eytan", ""]]}, {"id": "1901.04285", "submitter": "Paolo Ballarini", "authors": "Paolo Ballarini, Benoit Barbot, Nicolas Vasselin", "title": "Performance modelling of access control mechanisms for local and\n  vehicular wireless networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carrier sense multiple access collision avoidance (CSMA/CA) is the basic\nscheme upon which access to the shared medium is regulated in many wireless\nnetworks. With CSMA/CA a station willing to start a transmission has first to\nfind the channel free for a given duration otherwise it will go into\n\\emph{backoff}, i.e. refraining for transmitting for a randomly chosen delay.\nPerformance analysis of a wireless network employing CSMA/CA regulation is not\nan easy task: except for simple network configuration analytical solution of\nkey performance indicators (KPI) cannot be obtained hence one has to resort to\nformal modelling tools. In this paper we present a performance modelling study\ntargeting different kind of CSMA/CA based wireless networks, namely: the IEEE\n802.11 Wireless Local Area Networks (WLANs) and the 802.11p Vehicular Ad Hoc\nNetworks (VANETs), which extends 802.11 with priorities over packets. The\nmodelling framework we introduce allows for considering: i) an arbitrarily\nlarge number of stations, ii) different traffic conditions\n(saturated/non-saturated), iii) different hypothesis concerning the shared\nchannel (ideal/non-ideal). We apply statistical model checking to assess KPIs\nof different network configurations.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 12:00:25 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Ballarini", "Paolo", ""], ["Barbot", "Benoit", ""], ["Vasselin", "Nicolas", ""]]}, {"id": "1901.04290", "submitter": "Zhanyu Ma", "authors": "Qi Qi and Zhanyu Ma", "title": "Vehicular Edge Computing via Deep Reinforcement Learning", "comments": "Preliminary report of ongoing work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The smart vehicles construct Vehicle of Internet which can execute various\nintelligent services. Although the computation capability of the vehicle is\nlimited, multi-type of edge computing nodes provide heterogeneous resources for\nvehicular services.When offloading the complicated service to the vehicular\nedge computing node, the decision should consider numerous factors.The\noffloading decision work mostly formulate the decision to a resource scheduling\nproblem with single or multiple objective function and some constraints, and\nexplore customized heuristics algorithms. However, offloading multiple data\ndependency tasks in a service is a difficult decision, as an optimal solution\nmust understand the resource requirement, the access network, the user\nmobility, and importantly the data dependency. Inspired by recent advances in\nmachine learning, we propose a knowledge driven (KD) service offloading\ndecision framework for Vehicle of Internet, which provides the optimal policy\ndirectly from the environment. We formulate the offloading decision of\nmulti-task in a service as a long-term planning problem, and explores the\nrecent deep reinforcement learning to obtain the optimal solution. It considers\nthe future data dependency of the following tasks when making decision for a\ncurrent task from the learned offloading knowledge. Moreover, the framework\nsupports the pre-training at the powerful edge computing node and continually\nonline learning when the vehicular service is executed, so that it can adapt\nthe environment changes and learns policy that are sensible in hindsight. The\nsimulation results show that KD service offloading decision converges quickly,\nadapts to different conditions, and outperforms the greedy offloading decision\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 09:54:37 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 08:23:46 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 03:45:20 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Qi", "Qi", ""], ["Ma", "Zhanyu", ""]]}, {"id": "1901.04291", "submitter": "Xavier Timoneda", "authors": "Xavier Timoneda, Sergi Abadal, Antonio Franques, Dionysios Manessis,\n  Jin Zhou, Josep Torrellas, Eduard Alarc\\'on, Albert Cabellos-Aparicio", "title": "Engineer the Channel and Adapt to it: Enabling Wireless Intra-Chip\n  Communication", "comments": "12 pages, 10 figures. IEEE Transactions on Communications Journal,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitous multicore processors nowadays rely on an integrated\npacket-switched network for cores to exchange and share data. The performance\nof these intra-chip networks is a key determinant of the processor speed and,\nat high core counts, becomes an important bottleneck due to scalability issues.\nTo address this, several works propose the use of mm-wave wireless\ninterconnects for intra-chip communication and demonstrate that, thanks to\ntheir low-latency broadcast and system-level flexibility, this new paradigm\ncould break the scalability barriers of current multicore architectures.\nHowever, these same works assume 10+ Gb/s speeds and efficiencies close to 1\npJ/bit without a proper understanding on the wireless intra-chip channel. This\npaper first demonstrates that such assumptions do not hold in the context of\ncommercial chips by evaluating losses and dispersion in them. Then, we leverage\nthe system's monolithic nature to engineer the channel, this is, to optimize\nits frequency response by carefully choosing the chip package dimensions.\nFinally, we exploit the static nature of the channel to adapt to it, pushing\nefficiency-speed limits with simple tweaks at the physical layer. Our methods\nreduce the path loss and delay spread of a simulated commercial chip by 47 dB\nand 7.3x, respectively, enabling intra-chip wireless communications over 10\nGb/s and only 3.1 dB away from the dispersion-free case.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 23:51:10 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 10:42:29 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Timoneda", "Xavier", ""], ["Abadal", "Sergi", ""], ["Franques", "Antonio", ""], ["Manessis", "Dionysios", ""], ["Zhou", "Jin", ""], ["Torrellas", "Josep", ""], ["Alarc\u00f3n", "Eduard", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "1901.04292", "submitter": "Amin Azari", "authors": "Amin Azari, Mustafa Ozger, and Cicek Cavdar", "title": "Risk-Aware Resource Allocation for URLLC: Challenges and Strategies with\n  Machine Learning", "comments": "IEEE Communications Magazine, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supporting ultra-reliable low-latency communications (URLLC) is a major\nchallenge of 5G wireless networks. Stringent delay and reliability requirements\nneed to be satisfied for both scheduled and non-scheduled URLLC traffic to\nenable a diverse set of 5G applications. Although physical and media access\ncontrol layer solutions have been investigated to satisfy only scheduled URLLC\ntraffic, there is a lack of study on enabling transmission of non-scheduled\nURLLC traffic, especially in coexistence with the scheduled URLLC traffic.\nMachine learning (ML) is an important enabler for such a co-existence scenario\ndue to its ability to exploit spatial/temporal correlation in user behaviors\nand use of radio resources. Hence, in this paper, we first study the\ncoexistence design challenges, especially the radio resource management (RRM)\nproblem and propose a distributed risk-aware ML solution for RRM. The proposed\nsolution benefits from hybrid orthogonal/non-orthogonal radio resource slicing,\nand proactively regulates the spectrum needed for satisfying delay/reliability\nrequirement of each URLLC traffic type. A case study is introduced to\ninvestigate the potential of the proposed RRM in serving coexisting URLLC\ntraffic types. The results further provide insights on the benefits of\nleveraging intelligent RRM, e.g. a 75% increase in data rate with respect to\nthe conservative design approach for the scheduled traffic is achieved, while\nthe 99.99% reliability of both scheduled and nonscheduled traffic types is\nsatisfied.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 18:33:43 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Azari", "Amin", ""], ["Ozger", "Mustafa", ""], ["Cavdar", "Cicek", ""]]}, {"id": "1901.04295", "submitter": "Sihan Peng", "authors": "Damao Yang, Sihan Peng, He Huang, Hongliang Xue", "title": "On-Demand Video Dispatch Networks: A Scalable End-to-End Learning\n  Approach", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.SY eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a dispatch system to improve the peak service quality of video on\ndemand (VOD). Our system predicts the hot videos during the peak hours of the\nnext day based on the historical requests, and dispatches to the content\ndelivery networks (CDNs) at the previous off-peak time. In order to scale to\nbillions of videos, we build the system with two neural networks, one for video\nclustering and the other for dispatch policy developing. The clustering network\nemploys autoencoder layers and reduces the video number to a fixed value. The\npolicy network employs fully connected layers and ranks the clustered videos\nwith dispatch probabilities. The two networks are coupled with weight-sharing\ntemporal layers, which analyze the video request sequences with convolutional\nand recurrent modules. Therefore, the clustering and dispatch tasks are trained\nin an end-to-end mechanism. The real-world results show that our approach\nachieves an average prediction accuracy of 17%, compared with 3% from the\npresent baseline method, for the same amount of dispatches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 10:58:30 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Yang", "Damao", ""], ["Peng", "Sihan", ""], ["Huang", "He", ""], ["Xue", "Hongliang", ""]]}, {"id": "1901.04301", "submitter": "Shreesha Rao D. S.", "authors": "Govardan C., Sri Krishna Chaitanya K., Krishna Kumar Naik B., Shreesha\n  Rao D. S., Jagadeesh C., Gowrishankar R., Siva Sankara Sai S., Prabhat\n  Behere, Bhyri Sai Kishore", "title": "A Heuristic Algorithm for Network Optimization of OTN over DWDM Network", "comments": "Pages: 1-6, Published in: 2015 IEEE International Conference on\n  Advanced Networks and Telecommuncations Systems (ANTS), Date of Conference:\n  15-18 Dec. 2015, Publisher: IEEE, Electronic ISBN: 978-1-5090-0293-1, USB\n  ISBN:978-1-5090-0292-4", "journal-ref": null, "doi": "10.1109/ANTS.2015.7413606", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the network traffic has seen exponential increase, the revenues have\nnot maintained the same pace. New methods have to be explored to reduce this\ngap between traffic and revenue. One such method is convergence in networking\nlayers. In this work, we study the convergence of OTN and DWDM layer from a\nnetwork planning perspective. We compare the costs of planning networks without\nand with convergence and show that the multilayer planning offers least cost\nfor higher traffic volumes.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 10:31:29 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["C.", "Govardan", ""], ["K.", "Sri Krishna Chaitanya", ""], ["B.", "Krishna Kumar Naik", ""], ["S.", "Shreesha Rao D.", ""], ["C.", "Jagadeesh", ""], ["R.", "Gowrishankar", ""], ["S.", "Siva Sankara Sai", ""], ["Behere", "Prabhat", ""], ["Kishore", "Bhyri Sai", ""]]}, {"id": "1901.04319", "submitter": "Nane Kratzke", "authors": "Kennedy A. Torkura and Christoph Meinel and Nane Kratzke", "title": "Don't Wait to be Breached! Creating Asymmetric Uncertainty of Cloud\n  Applications via Moving Target Defenses", "comments": "Invited paper. arXiv admin note: substantial text overlap with\n  arXiv:1802.03565", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI cs.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Cloud applications expose - besides service endpoints - also potential or\nactual vulnerabilities. Therefore, cloud security engineering efforts focus on\nhardening the fortress walls but seldom assume that attacks may be successful.\nAt least against zero-day exploits, this approach is often toothless. Other\nthan most security approaches and comparable to biological systems we accept\nthat defensive \"walls\" can be breached at several layers. Instead of hardening\nthe \"fortress\" walls we propose to make use of an (additional) active and\nadaptive defense system to attack potential intruders - an immune system that\nis inspired by the concept of a moving target defense. This \"immune system\"\nworks on two layers. On the infrastructure layer, virtual machines are\ncontinuously regenerated (cell regeneration) to wipe out even undetected\nintruders. On the application level, the vertical and horizontal attack surface\nis continuously modified to circumvent successful replays of formerly scripted\nattacks. Our evaluations with two common cloud-native reference applications in\npopular cloud service infrastructures (Amazon Web Services, Google Compute\nEngine, Azure and OpenStack) show that it is technically possible to limit the\ntime of attackers acting undetected down to minutes. Further, more than 98% of\nan attack surface can be changed automatically and minimized which makes it\nhard for intruders to replay formerly successful scripted attacks. So, even if\nintruders get a foothold in the system, it is hard for them to maintain it.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 18:28:38 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Torkura", "Kennedy A.", ""], ["Meinel", "Christoph", ""], ["Kratzke", "Nane", ""]]}, {"id": "1901.04411", "submitter": "Marcin Nawrocki", "authors": "Marcin Nawrocki, Thomas C. Schmidt, Matthias W\\\"ahlisch", "title": "Uncovering Vulnerable Industrial Control Systems from the Internet Core", "comments": null, "journal-ref": "Proceedings of 17th IEEE/IFIP Network Operations and Management\n  Symposium (NOMS), 2020", "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial control systems (ICS) are managed remotely with the help of\ndedicated protocols that were originally designed to work in walled gardens.\nMany of these protocols have been adapted to Internet transport and support\nwide-area communication. ICS now exchange insecure traffic on an inter-domain\nlevel, putting at risk not only common critical infrastructure but also the\nInternet ecosystem (e.g., DRDoS~attacks).\n  In this paper, we uncover unprotected inter-domain ICS traffic at two central\nInternet vantage points, an IXP and an ISP. This traffic analysis is correlated\nwith data from honeypots and Internet-wide scans to separate industrial from\nnon-industrial ICS traffic. We provide an in-depth view on Internet-wide ICS\ncommunication. Our results can be used i) to create precise filters for\npotentially harmful non-industrial ICS traffic, and ii) to detect ICS sending\nunprotected inter-domain ICS traffic, being vulnerable to eavesdropping and\ntraffic manipulation attacks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 17:14:58 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 13:05:16 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Nawrocki", "Marcin", ""], ["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "1901.04957", "submitter": "Ehsan Mohammadpour", "authors": "Ehsan Mohammadpour, Eleni Stai, Jean-Yves Le Boudec", "title": "Improved Credit Bounds for the Credit-Based Shaper in Time-Sensitive\n  Networking", "comments": "4 pages, 0 figures, submitted", "journal-ref": null, "doi": "10.1109/LNET.2019.2925176", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Time-Sensitive Networking (TSN), it is important to formally prove per\nflow latency and backlog bounds. To this end, recent works apply network\ncalculus and obtain latency bounds from service curves. The latency component\nof such service curves is directly derived from upper bounds on the values of\nthe credit counters used by the Credit-Based Shaper (CBS), an essential\nbuilding-block of TSN. In this paper, we derive and formally prove credit upper\nbounds for CBS, which improve on existing bounds.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 18:02:23 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 16:29:15 GMT"}, {"version": "v3", "created": "Mon, 21 Jan 2019 16:52:19 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Mohammadpour", "Ehsan", ""], ["Stai", "Eleni", ""], ["Boudec", "Jean-Yves Le", ""]]}, {"id": "1901.05096", "submitter": "Zhiyuan Jiang", "authors": "Zhiyuan Jiang, Sheng Zhou", "title": "Status from a Random Field: How Densely Should One Update?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, status information of a general spatial process, in\ncontrast to a point information source, is of interest. In this paper, we\nconsider a system where status information is drawn from a random field and\ntransmitted to a fusion center through a wireless multiaccess channel. The\noptimal density of spatial sampling points to minimize the remote status\nestimation error is investigated. Assuming a one-dimensional Gauss Markov\nrandom field and an exponential correlation function, closed-form expressions\nof remote estimation error are obtained for First-Come First-Served (FCFS) and\nLast-Come First-Served (LCFS) service disciplines. The optimal spatial sampling\ndensity for the LCFS case is given explicitly. Simulation results are presented\nwhich agree with our analysis.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 01:01:06 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Jiang", "Zhiyuan", ""], ["Zhou", "Sheng", ""]]}, {"id": "1901.05279", "submitter": "Paolo Laffranchini", "authors": "Paolo Laffranchini, Luis Rodrigues, Marco Canini, Balachander\n  Krishnamurthy", "title": "Measurements As First-class Artifacts", "comments": "Infocom 2019 extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of programmable switches has sparked a significant amount of\nwork on new techniques to perform more powerful measurement tasks, for\ninstance, to obtain fine-grained traffic and performance statistics. Previous\nwork has focused on the efficiency of these measurements alone and has\nneglected flexibility, resulting in solutions that are hard to reuse or\nrepurpose and that often overlap in functionality or goals.\n  In this paper, we propose the use of a set of reusable primitive building\nblocks that can be composed to express measurement tasks in a concise and\nsimple way. We describe the rationale for the design of our primitives, that we\nhave named MAFIA (Measurements As FIrst-class Artifacts), and using several\nexamples we illustrate how they can be combined to realize a comprehensive\nrange of network measurement tasks. Writing MAFIA code does not require expert\nknowledge of low-level switch architecture details. Using a prototype\nimplementation of MAFIA, we demonstrate the applicability of our approach and\nshow that the use of our primitives results in compiled code that is comparable\nin size and resource usage with manually written specialized P4 code and can be\nrun in current hardware.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 13:48:24 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Laffranchini", "Paolo", ""], ["Rodrigues", "Luis", ""], ["Canini", "Marco", ""], ["Krishnamurthy", "Balachander", ""]]}, {"id": "1901.05347", "submitter": "Stefano Forti", "authors": "Stefano Forti and Gian-Luigi Ferrari and Antonio Brogi", "title": "Secure Cloud-Edge Deployments, with Trust", "comments": null, "journal-ref": "Future Generation Computer Systems, 2019", "doi": "10.1016/j.future.2019.08.020", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing the security level of IoT applications to be deployed to\nheterogeneous Cloud-Edge infrastructures operated by different providers is a\nnon-trivial task. In this article, we present a methodology that permits to\nexpress security requirements for IoT applications, as well as infrastructure\nsecurity capabilities, in a simple and declarative manner, and to automatically\nobtain an explainable assessment of the security level of the possible\napplication deployments. The methodology also considers the impact of trust\nrelations among different stakeholders using or managing Cloud-Edge\ninfrastructures. A lifelike example is used to showcase the prototyped\nimplementation of the methodology.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 15:31:41 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 07:04:29 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Forti", "Stefano", ""], ["Ferrari", "Gian-Luigi", ""], ["Brogi", "Antonio", ""]]}, {"id": "1901.05428", "submitter": "Omur Ozel", "authors": "Peng Zou and Omur Ozel and Suresh Subramaniam", "title": "Relative Age of Information: A New Metric for Status Update Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new data freshness metric, relative Age of\nInformation (rAoI), and examine it in a single server system with various\npacket management schemes. The (classical) AoI metric was introduced to measure\nthe staleness of status updates at the receiving end with respect to their\ngeneration at the source. This metric addresses systems where the timings of\nupdate generation at the source are absolute and can be designed separately or\njointly with the transmission schedules. In many decentralized applications,\ntransmission schedules are blind to update generation timing, and the\ntransmitter can know the timing of an update packet only after it arrives. As\nsuch, an update becomes stale after a new one arrives. The rAoI metric measures\nhow fresh the data is at the receiver with respect to the data at the\ntransmitter. It introduces a particularly explicit dependence on the arrival\nprocess in the evaluation of age. We investigate several queuing disciplines\nand provide closed form expressions for rAoI and numerical comparisons.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 18:35:37 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 18:52:54 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 17:13:10 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zou", "Peng", ""], ["Ozel", "Omur", ""], ["Subramaniam", "Suresh", ""]]}, {"id": "1901.05558", "submitter": "Md Lushanur Rahman", "authors": "Md. Lushanur Rahman, J. Andrew Zhang, Xiaojing Huang, Y. Jay Guo, and\n  Robert W. Heath Jr", "title": "Framework for a Perceptive Mobile Network using Joint Communication and\n  Radar Sensing", "comments": "14 pages, 12 figures, Journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a framework for a novel perceptive mobile/cellular\nnetwork that integrates radar sensing function into the mobile communication\nnetwork. We propose a unified system platform that enables downlink and uplink\nsensing, sharing the same transmitted signals with communications. We aim to\ntackle the fundamental sensing parameter estimation problem in perceptive\nmobile networks, by addressing two key challenges associated with sophisticated\nmobile signals and rich multipath in mobile networks. To extract sensing\nparameters from orthogonal frequency division multiple access (OFDMA) and\nspatial division multiple access (SDMA) communication signals, we propose two\napproaches to formulate it to problems that can be solved by compressive\nsensing techniques. Most sensing algorithms have limits on the number of\nmultipath signals for their inputs. To reduce the multipath signals, as well as\nremoving unwanted clutter signals, we propose a background subtraction method\nbased on simple recursive computation, and provide a closed-form expression for\nperformance characterization. The effectiveness of these methods is validated\nin simulations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 23:22:26 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Rahman", "Md. Lushanur", ""], ["Zhang", "J. Andrew", ""], ["Huang", "Xiaojing", ""], ["Guo", "Y. Jay", ""], ["Heath", "Robert W.", "Jr"]]}, {"id": "1901.05571", "submitter": "Jiawei Fei", "authors": "Jiawei Fei, Yang Shi, Qun Huang, Mei Wen", "title": "Metaflow: A DAG-Based Network Abstraction for Distributed Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, increasingly network scheduling techniques have been\nproposed to boost the distributed application performance. Flow-level metrics,\nsuch as flow completion time (FCT), are based on the abstraction of flows yet\nthey cannot capture the semantics of communication in a cluster application.\nBeing aware of this problem, coflow is proposed as a new network abstraction.\nHowever, it is insufficient to reveal the dependencies between computation and\ncommunication. As a result, the real application performance can be hurt,\nespecially in the absence of hard barriers. Based on the computation DAG of the\napplication, we propose an expressive abstraction namely metaflow that resides\nin the middle of the two extreme points of flows and coflows. Evaluation\nresults show that metaflow-based scheduling can outperform the coflow-based\nalgorithm by 1.78x.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 00:53:37 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Fei", "Jiawei", ""], ["Shi", "Yang", ""], ["Huang", "Qun", ""], ["Wen", "Mei", ""]]}, {"id": "1901.05712", "submitter": "Amr Rizk", "authors": "Bastian Alt, Trevor Ballard, Ralf Steinmetz, Heinz Koeppl, Amr Rizk", "title": "CBA: Contextual Quality Adaptation for Adaptive Bitrate Video Streaming\n  (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in quality adaptation algorithms leave adaptive bitrate (ABR)\nstreaming architectures at a crossroads: When determining the sustainable video\nquality one may either rely on the information gathered at the client vantage\npoint or on server and network assistance. The fundamental problem here is to\ndetermine how valuable either information is for the adaptation decision. This\nproblem becomes particularly hard in future Internet settings such as Named\nData Networking (NDN) where the notion of a network connection does not exist.\n  In this paper, we provide a fresh view on ABR quality adaptation for QoE\nmaximization, which we formalize as a decision problem under uncertainty, and\nfor which we contribute a sparse Bayesian contextual bandit algorithm denoted\nCBA. This allows taking high-dimensional streaming context information,\nincluding client-measured variables and network assistance, to find online the\nmost valuable information for the quality adaptation. Since sparse Bayesian\nestimation is computationally expensive, we develop a fast new inference scheme\nto support online video adaptation. We perform an extensive evaluation of our\nadaptation algorithm in the particularly challenging setting of NDN, where we\nuse an emulation testbed to demonstrate the efficacy of CBA compared to\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 10:10:30 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Alt", "Bastian", ""], ["Ballard", "Trevor", ""], ["Steinmetz", "Ralf", ""], ["Koeppl", "Heinz", ""], ["Rizk", "Amr", ""]]}, {"id": "1901.05741", "submitter": "Chenyu Huang", "authors": "Chenyu Huang, Zeyu Wang, Huangxun Chen, Qiwei Hu, Qian Zhang, Wei\n  Wang, Xia Guan", "title": "RepChain: A Reputation-based Secure, Fast and High Incentive Blockchain\n  System via Sharding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's blockchain system, designing a secure and high throughput\nblockchain on par with a centralized payment system is a difficult task.\nSharding is one of the most worthwhile emerging technologies for improving the\nsystem throughput while maintain high security level. However, previous\nsharding related designs have two main limitations: Firstly, the throughput of\ntheir random-based sharding system is not high enough as they did not leverage\nthe heterogeneity among validators. Secondly, to design an incentive mechanism\nto promote cooperation could incur a huge overhead on their system. In this\npaper, we propose RepChain, a reputation-based secure and fast blockchain\nsystem via sharding, which also provides high incentive to stimulate node\ncooperation. RepChain utilizes reputation to explicitly characterize the\nheterogeneity among the validators and lay the foundation for the incentive\nmechanism. We propose a new double-chain architecture which includes\ntransaction chain and reputation chain. For transaction chain, a Raft-based\nsynchronous consensus that can achieve high throughput has been presented. For\nreputation chain, the synchronous Byzantine fault tolerance that combines\ncollective signing has been utilized to achieve a consensus on both reputation\nscore and the related transaction blocks. It supports a high throughput\ntransaction chain with moderate generation speed. Moreover, we propose a\nreputation-based sharding and leader selection scheme. To analyze the security\nof RepChain, we propose a recursive formula to calculate the epoch security\nwithin only O(km^2) time. Furthermore, we implement and evaluate RepChain on\nthe Amazon Web Service platform. The results show our solution can enhance both\nthroughout and security level of the existing sharding-based blockchain system.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 11:49:31 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 05:11:09 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Huang", "Chenyu", ""], ["Wang", "Zeyu", ""], ["Chen", "Huangxun", ""], ["Hu", "Qiwei", ""], ["Zhang", "Qian", ""], ["Wang", "Wei", ""], ["Guan", "Xia", ""]]}, {"id": "1901.05748", "submitter": "Krzysztof Rusek", "authors": "Krzysztof Rusek and Piotr Cho{\\l}da", "title": "Message-Passing Neural Networks Learn Little's Law", "comments": "4 pages, 1 figure, 1 table, 1 algorith, Accepted for publication in\n  IEEE Communications letters if citing, please cite the IEEE paper", "journal-ref": "IEEE Communications Letters ( Volume: 23 , Issue: 2 , Feb. 2019 )", "doi": "10.1109/LCOMM.2018.2886259", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a solution to the problem of universal representation of\ngraphs exemplifying communication network topologies with the help of neural\nnetworks. The proposed approach is based on message-passing neural networks\n(MPNN). The approach enables us to represent topologies and operational aspects\nof networks. The usefulness of the solution is illustrated with a case study of\ndelay prediction in queuing networks. This shows that performance evaluation\ncan be provided without having to apply complex modeling. In consequence, the\nproposed solution makes it possible to effectively apply methods elaborated in\nthe field of machine learning in communications.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 12:08:42 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Rusek", "Krzysztof", ""], ["Cho\u0142da", "Piotr", ""]]}, {"id": "1901.05800", "submitter": "Francesco Bronzino", "authors": "Paul Schmitt, Francesco Bronzino, Sara Ayoubi, Guilherme Martins,\n  Renata Teixeira, Nick Feamster", "title": "Inferring Streaming Video Quality from Encrypted Traffic: Practical\n  Models and Deployment Experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring the quality of streaming video applications is important for\nInternet service providers, but the fact that most video streams are encrypted\nmakes it difficult to do so. We develop models that infer quality metrics (\\ie,\nstartup delay and resolution) for encrypted streaming video services. Our paper\nbuilds on previous work, but extends it in several ways. First, the model works\nin deployment settings where the video sessions and segments must be identified\nfrom a mix of traffic and the time precision of the collected traffic\nstatistics is more coarse (\\eg, due to aggregation). Second, we develop a\nsingle composite model that works for a range of different services (i.e.,\nNetflix, YouTube, Amazon, and Twitch), as opposed to just a single service.\nThird, unlike many previous models, the model performs predictions at finer\ngranularity (\\eg, the precise startup delay instead of just detecting short\nversus long delays) allowing to draw better conclusions on the ongoing\nstreaming quality. Fourth, we demonstrate the model is practical through a\n16-month deployment in 66 homes and provide new insights about the\nrelationships between Internet \"speed\" and the quality of the corresponding\nvideo streams, for a variety of services; we find that higher speeds provide\nonly minimal improvements to startup delay and resolution.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 14:18:51 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 16:59:14 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 09:48:55 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Schmitt", "Paul", ""], ["Bronzino", "Francesco", ""], ["Ayoubi", "Sara", ""], ["Martins", "Guilherme", ""], ["Teixeira", "Renata", ""], ["Feamster", "Nick", ""]]}, {"id": "1901.05831", "submitter": "Keunwoo Lim", "authors": "Keun-Woo Lim, Katarzyna Kapusta, Gerard Memmi, Woo-Sung Jung", "title": "Multi-hop Data Fragmentation in Unattended Wireless Sensor Networks", "comments": "12 pages, preliminary draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we analyze the advantages of multi-hop data fragmentation in\nunattended wireless sensor networks (UWSN) and propose a lightweight protocol\nto achieve it. UWSN has recently become an important aspect in various areas of\nsensor networks where real-time data collection is difficult to manage.\nHowever, the characteristics of UWSN also poses new problems especially in data\nprotection. For more efficient protection, data fragmentation has been proposed\nto fragment sensing data, which prevents attackers from successfully exploiting\nthe data. However, there are currently minimal work on the strategies of the\nplacement of fragments inside a sensor network. Through this work, we analyze\nthe effects of multi-hop fragment dispersal in relation to effectiveness of\ndata protection and energy consumption. Furthermore, we design a new routing\nalgorithm suitable for the energy-efficient placement of data fragments in\nUWSN. We utilize simulation-based modeling and testbed implementation via\nFIT/IoT-Lab to prove the effectiveness of our work.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 15:13:27 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Lim", "Keun-Woo", ""], ["Kapusta", "Katarzyna", ""], ["Memmi", "Gerard", ""], ["Jung", "Woo-Sung", ""]]}, {"id": "1901.05998", "submitter": "Konstantinos Psychas", "authors": "Konstantinos Psychas, Javad Ghaderi", "title": "Scheduling Jobs with Random Resource Requirements in Computing Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a natural scheduling problem which arises in many distributed\ncomputing frameworks. Jobs with diverse resource requirements (e.g. memory\nrequirements) arrive over time and must be served by a cluster of servers, each\nwith a finite resource capacity. To improve throughput and delay, the scheduler\ncan pack as many jobs as possible in the servers subject to their capacity\nconstraints. Motivated by the ever-increasing complexity of workloads in shared\nclusters, we consider a setting where the jobs' resource requirements belong to\na very large number of diverse types or, in the extreme, even infinitely many\ntypes, e.g. when resource requirements are drawn from an unknown distribution\nover a continuous support. The application of classical scheduling approaches\nthat crucially rely on a predefined finite set of types is discouraging in this\nhigh (or infinite) dimensional setting. We first characterize a fundamental\nlimit on the maximum throughput in such setting, and then develop oblivious\nscheduling algorithms that have low complexity and can achieve at least 1/2 and\n2/3 of the maximum throughput, without the knowledge of traffic or resource\nrequirement distribution. Extensive simulation results, using both synthetic\nand real traffic traces, are presented to verify the performance of our\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 20:17:33 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Psychas", "Konstantinos", ""], ["Ghaderi", "Javad", ""]]}, {"id": "1901.06134", "submitter": "Chenlu Xiang", "authors": "Shunqing Zhang, Chenlu Xiang, Shan Cao, Shugong Xu, Jiang Zhu", "title": "Dynamic Carrier and Power Amplifier Mapping for Energy Efficient\n  Multi-Carrier Wireless Communications", "comments": null, "journal-ref": null, "doi": "10.1109/ICC.2018.8422875", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid increasing demand of wireless transmission has incurred mobile\nbroadband to continuously evolve through multiple frequency bands, massive\nantennas and other multi-stream processing schemes. Together with the improved\ndata transmission rate, the power consumption for multi-carrier transmission\nand processing is proportionally increasing, which contradicts with the energy\nefficiency requirements of 5G wireless systems. To meet this challenge, multi\ncarrier power amplifier (MCPA) technology, e.g., to support multiple carriers\nthrough a single power amplifier, is widely deployed in practical. With massive\ncarriers required for 5G communication and limited number of carriers supported\nper MCPA, a natural question to ask is how to map those carriers into multiple\nMCPAs and whether we shall dynamically adjust this mapping relation. In this\npaper, we have theoretically formulated the dynamic carrier and MCPA mapping\nproblem to jointly optimize the traditional separated baseband and radio\nfrequency processing. On top of that, we have also proposed a low complexity\nalgorithm that can achieve most of the power saving with affordable\ncomputational time, if compared with the optimal exhaustive search based\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 08:51:30 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Zhang", "Shunqing", ""], ["Xiang", "Chenlu", ""], ["Cao", "Shan", ""], ["Xu", "Shugong", ""], ["Zhu", "Jiang", ""]]}, {"id": "1901.06207", "submitter": "Jie Xu", "authors": "Jie Xu", "title": "GPU based Real-time Super Hosts Detection at Distributed Edge Routers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The super host is a special host on the network which contacts with many\nother hosts during a certain time window. They play important roles in network\nresearches such as scanners detection, resource allocation, spam filtering and\nso on. How to find super hosts in real time is the foundation of these\napplications. In this paper, a novel algorithm, denoted as CBAA, is proposed to\nsolve this problem at edge routers. CBAA divides network traffic into different\nparts. A cube of bits array is devised to store hosts' linking information of\ndifferent traffic parts when scanning packets. At the end of each time window,\nCBAA restores super hosts very fast because there are only a fraction of super\nhosts in each traffic part. CBAA is also a parallel algorithm. It's easy to\ndeploy CBAA in GPU to deal with high-speed network traffic in real time.\nExperiments on a real-world core network prove the advantage of our algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 12:55:44 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Xu", "Jie", ""]]}, {"id": "1901.06236", "submitter": "Michael Kuperberg", "authors": "Michael Kuperberg, Daniel Kindler, Sabina Jeschke", "title": "Are Smart Contracts and Blockchains Suitable for Decentralized Railway\n  Control?", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional railway operations employ specialized software and hardware to\nensure safe and secure train operations. Track occupation and signaling are\ngoverned by central control offices, while trains (and their drivers) receive\ninstructions. To make this setup more dynamic, the train operations can be\ndecentralized by enabling the trains to find routes and make decisions which\nare safeguarded and protocolled in an auditable manner. In this paper, we\npresent the findings of a first-of-its-kind blockchain-based prototype\nimplementation for railway control, based on decentralization but also ensuring\nthat the overall system state remains conflict-free and safe. We also show how\na blockchain-based approach simplifies usage billing and enables a\ntrain-to-train/machine-to-machine economy. Finally, first ideas addressing the\nuse of blockchain as a life-cycle approach for condition based monitoring and\npredictive maintenance in train operations are outlined.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 14:01:59 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Kuperberg", "Michael", ""], ["Kindler", "Daniel", ""], ["Jeschke", "Sabina", ""]]}, {"id": "1901.06337", "submitter": "Osvaldo Simeone", "authors": "Petar Popovski and Osvaldo Simeone", "title": "Start Making Sense: Semantic Plane Filtering and Control for Post-5G\n  Connectivity", "comments": "Short position paper -- comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a short position paper that introduces the concepts of semantic plane\nfiltering and control for post-5G connectivity.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 16:49:49 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Popovski", "Petar", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "1901.06399", "submitter": "Bin Han", "authors": "Bin Han, Vincenzo Sciancalepore, Di Feng, Xavier Costa-Perez and Hans\n  D. Schotten", "title": "A Utility-Driven Multi-Queue Admission Control Solution for Network\n  Slicing", "comments": "In Proceedings of IEEE INFOCOM 2019 (the published version has a\n  minor flaw where the notation W_n is used both for waiting time and event of\n  joining queue, which has been corrected in this version of preprint)", "journal-ref": null, "doi": "10.1109/INFOCOM.2019.8737517", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of recent emerging technologies such as network function\nvirtualization (NFV) and network programmability (SDN) gave birth to the\nNetwork Slicing revolution. 5G networks consist of multi-tenant infrastructures\ncapable of offering leased network \"slices\" to new customers (e.g., vertical\nindustries) enabling a new telecom business model: Slice-as-aService (SlaaS).\nIn this paper, we aim i ) to study the slicing admission control problem by\nmeans of a multi-queuing system for heterogeneous tenant requests, ii ) to\nderive its statistical behavior model, and iii ) to provide a utility-based\nadmission control optimization. Our results analyze the capability of the\nproposed SlaaS system to be approximately Markovian and evaluate its\nperformance as compared to legacy solutions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 19:33:47 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 13:10:37 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Han", "Bin", ""], ["Sciancalepore", "Vincenzo", ""], ["Feng", "Di", ""], ["Costa-Perez", "Xavier", ""], ["Schotten", "Hans D.", ""]]}, {"id": "1901.06450", "submitter": "Maotong Xu", "authors": "Maotong Xu, Jelena Diakonikolas, Eytan Modiano, Suresh Subramaniam", "title": "A Hierarchical WDM-based Scalable Data Center Network Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive data centers are at the heart of the Internet. The rapid growth of\nInternet traffic and the abundance of rich data-driven applications have raised\nthe need for enormous network bandwidth. Towards meeting this growing traffic\ndemand, optical interconnects have gained significant attention, as they can\nprovide high throughput, low latency, and scalability. In particular, optical\nWavelength Division Multiplexing (WDM) provides the possibility to build data\ncenters comprising of millions of servers, while providing hundreds of terabits\nper second bandwidth.\n  In this paper, we propose a WDM-based Reconfigurable Hierarchical Optical\nData Center Architecture (RHODA) that can satisfy future Internet traffic\ndemands. To improve scalability, our DCN architecture is hierarchical, as it\ngroups server racks into clusters. Cluster membership is reconfigurable through\nthe use of optical switches. Each cluster enables heavy-traffic communication\namong the racks within. To support varying traffic patterns, the inter-cluster\nnetwork topology and link capacities are also reconfigurable, which is achieved\nthrough the use of optical space switches and Wavelength Selective Switches\n(WSSs). Our simulation results demonstrate that in terms of average hop\ndistance, RHODA outperforms OSA, FatTree and WaveCube by up to 81%, 66% and\n60%, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 01:23:35 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 02:15:38 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Xu", "Maotong", ""], ["Diakonikolas", "Jelena", ""], ["Modiano", "Eytan", ""], ["Subramaniam", "Suresh", ""]]}, {"id": "1901.06451", "submitter": "Maotong Xu", "authors": "Chong Liu, Maotong Xu, Suresh Subramaniam", "title": "A Reconfigurable High-Performance Optical Data Center Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Optical data center network architectures are becoming attractive because of\ntheir low energy consumption, large bandwidth, and low cabling complexity.\nIn\\cite{Xu1605:PODCA}, an AWGR-based passive optical data center architecture\n(PODCA) is presented. Compared with other optical data center architectures,\ne.g., DOS \\cite{ye2010scalable}, Proteus \\cite{singla2010proteus}, and Petabit\n\\cite{xia2010petabit}, PODCA can save up to 90$\\%$ on power consumption and\n88$\\%$ in cost. Also, average latency can be low as 9 $\\mu$s at close to\n100$\\%$ throughput. However, PODCA is not reconfigurable and cannot optimize\nthe network topology to dynamic traffic.\n  In this paper, we present a novel, scalable and flexible reconfigurable\narchitecture called RODCA. RODCA is built on and augments PODCA with a flexible\nlocalized intra-cluster optical network. With the reconfigurable intra-cluster\nnetwork, racks with mutually large traffic can be located within the same\ncluster, and share the large bandwidth of the intra-cluster network. We present\nan algorithm for DCN topology reconfiguration, and present simulation results\nto demonstrate the effectiveness of reconfiguration.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 01:31:39 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Liu", "Chong", ""], ["Xu", "Maotong", ""], ["Subramaniam", "Suresh", ""]]}, {"id": "1901.06637", "submitter": "Bin Li", "authors": "Bin Li, Zesong Fei, and Yan Zhang", "title": "UAV Communications for 5G and Beyond: Recent Advances and Future Trends", "comments": "53 pages, 9 figures", "journal-ref": null, "doi": "10.1109/JIOT.2018.2887086", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing ubiquitous connectivity to diverse device types is the key\nchallenge for 5G and beyond 5G (B5G). Unmanned aerial vehicles (UAVs) are\nexpected to be an important component of the upcoming wireless networks that\ncan potentially facilitate wireless broadcast and support high rate\ntransmissions. Compared to the communications with fixed infrastructure, UAV\nhas salient attributes, such as flexible deployment, strong line-of-sight (LoS)\nconnection links, and additional design degrees of freedom with the controlled\nmobility. In this paper, a comprehensive survey on UAV communication towards\n5G/B5G wireless networks is presented. We first briefly introduce essential\nbackground and the space-air-ground integrated networks, as well as discuss\nrelated research challenges faced by the emerging integrated network\narchitecture. We then provide an exhaustive review of various 5G techniques\nbased on UAV platforms, which we categorize by different domains including\nphysical layer, network layer, and joint communication, computing and caching.\nIn addition, a great number of open research problems are outlined and\nidentified as possible future research directions.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 07:53:08 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Li", "Bin", ""], ["Fei", "Zesong", ""], ["Zhang", "Yan", ""]]}, {"id": "1901.06699", "submitter": "Elisa Rojas", "authors": "Eder Leao Fernandes, Elisa Rojas, Joaquin Alvarez-Horcajo, Zoltan\n  Lajos Kis, Davide Sanvito, Nicola Bonelli, Carmelo Cascone and Christian\n  Esteve Rothenberg", "title": "The Road to BOFUSS: The Basic OpenFlow User-space Software Switch", "comments": "24 pages, 7 figures; submitted to Telecommunications Systems journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software switches are pivotal in the Software-Defined Networking (SDN)\nparadigm, particularly in the early phases of development, deployment and\ntesting. Currently, the most popular one is Open vSwitch (OVS), leveraged in\nmany production-based environments. However, due to its kernel-based nature,\nOVS is typically complex to modify when additional features or adaptation is\nrequired. To this regard, a simpler user-space is key to perform these\nmodifications.\n  In this article, we present a rich overview of BOFUSS, the basic OpenFlow\nuser-space software switch. BOFUSS has been widely used in the research\ncommunity for diverse reasons, but it lacked a proper reference document. For\nthis purpose, we describe the switch, its history, architecture, uses cases and\nevaluation, together with a survey of works that leverage this switch. The main\ngoal is to provide a comprehensive overview of the switch and its\ncharacteristics. Although the original BOFUSS is not expected to surpass the\nhigh performance of OVS, it is a useful complementary artifact that provides\nsome OpenFlow features missing in OVS and it can be easily modified for\nextended functionality. Moreover, enhancements provided by the BEBA project\nbrought the performance from BOFUSS close to OVS. In any case, this paper sheds\nlight to researchers looking for the trade-offs between performance and\ncustomization of BOFUSS.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 17:00:30 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Fernandes", "Eder Leao", ""], ["Rojas", "Elisa", ""], ["Alvarez-Horcajo", "Joaquin", ""], ["Kis", "Zoltan Lajos", ""], ["Sanvito", "Davide", ""], ["Bonelli", "Nicola", ""], ["Cascone", "Carmelo", ""], ["Rothenberg", "Christian Esteve", ""]]}, {"id": "1901.06786", "submitter": "Gayane Vardoyan", "authors": "Gayane Vardoyan, Saikat Guha, Philippe Nain, Don Towsley", "title": "On the Capacity Region of Bipartite and Tripartite Entanglement\n  Switching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a quantum switch serving a set of users. The function of the switch\nis to create bi- or tripartite entangled state among users at the highest\npossible rates at a fixed ratio. We model a set of randomized switching\npolicies. Discovering that some are better than others, we present analytical\nresults for the case where the switch stores one qubit per user, and find that\nthe best policies outperform a time division multiplexing (TDM) policy for\nsharing the switch between bipartite and tripartite state generation. This\nperformance improvement decreases as the number of users grows. The model is\neasily augmented to study the capacity region in the presence of qubit\ndecoherence, obtaining similar results. Moreover, decoherence appears to have\nlittle effect on capacity. We also study a smaller class of policies when the\nswitch stores two qubits per user.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 04:06:43 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 02:19:08 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 16:10:35 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Vardoyan", "Gayane", ""], ["Guha", "Saikat", ""], ["Nain", "Philippe", ""], ["Towsley", "Don", ""]]}, {"id": "1901.06867", "submitter": "Benjamin Finley", "authors": "Kalevi Kilkki and Benjamin Finley", "title": "In Search of Lost QoS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of quality of service (QoS) in communications networks has been the\ntarget of research for already several decades with tens of thousands of\npublished journal and conference papers. However, the practical introduction of\nQoS systems in commercial networks has been limited (with a preference for\nsimple overprovisioning). Despite this dissonance, most influential QoS papers\ndo not discuss this lack of penetration or challenge any of the common\nassumptions used to argue for QoS systems. So far, the few critical QoS papers\nhave had only a minor effect on QoS research and standardization. Therefore,\nthere is a serious risk that QoS will remain an academic research topic without\nsignificant practical relevance. To help elucidate these issues, in this work,\nwe first perform a comprehensive review of QoS including a general overview and\nan analysis of both influential and critical work from the past 30 years. We\nexamine properties such as citations, keywords, and author traits to show that\nQoS has passed through several distinct phases with different topics while\nmaintaining the overall attitude towards the role and objective of QoS systems.\nWe then discuss QoS as a social phenomenon and in the context of current\nnetworking standards. Finally, we propose a QoS scheme based on incentives that\navoids some of the problems identified in critical work, and we provide simple\nrecommendations for network operators. Overall, we hope to spark the community\nto take a fresh look at QoS.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 10:43:23 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Kilkki", "Kalevi", ""], ["Finley", "Benjamin", ""]]}, {"id": "1901.06977", "submitter": "Vitaly Petrov", "authors": "Aleksandr Ometov and Vitaly Petrov and Sergey Bezzateev and Sergey\n  Andreev and Yevgeni Koucheryavy and Mario Gerla", "title": "Challenges of Multi-Factor Authentication for Securing Advanced IoT\n  (A-IoT) Applications", "comments": "7 pages, 4 figures, 2 tables. The work has been accepted for\n  publication in IEEE Network, 2019. Copyright may be transferred without\n  notice, after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unprecedented proliferation of smart devices together with novel\ncommunication, computing, and control technologies have paved the way for the\nAdvanced Internet of Things~(A-IoT). This development involves new categories\nof capable devices, such as high-end wearables, smart vehicles, and consumer\ndrones aiming to enable efficient and collaborative utilization within the\nSmart City paradigm. While massive deployments of these objects may enrich\npeople's lives, unauthorized access to the said equipment is potentially\ndangerous. Hence, highly-secure human authentication mechanisms have to be\ndesigned. At the same time, human beings desire comfortable interaction with\ntheir owned devices on a daily basis, thus demanding the authentication\nprocedures to be seamless and user-friendly, mindful of the contemporary urban\ndynamics. In response to these unique challenges, this work advocates for the\nadoption of multi-factor authentication for A-IoT, such that multiple\nheterogeneous methods - both well-established and emerging - are combined\nintelligently to grant or deny access reliably. We thus discuss the pros and\ncons of various solutions as well as introduce tools to combine the\nauthentication factors, with an emphasis on challenging Smart City\nenvironments. We finally outline the open questions to shape future research\nefforts in this emerging field.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 15:57:03 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Ometov", "Aleksandr", ""], ["Petrov", "Vitaly", ""], ["Bezzateev", "Sergey", ""], ["Andreev", "Sergey", ""], ["Koucheryavy", "Yevgeni", ""], ["Gerla", "Mario", ""]]}, {"id": "1901.06980", "submitter": "Vitaly Petrov", "authors": "Vitaly Petrov and Gabor Fodor and Joonas Kokkoniemi and Dmitri\n  Moltchanov and Janne Lehtomaki and Sergey Andreev and Yevgeni Koucheryavy and\n  Markku Juntti and Mikko Valkama", "title": "On Unified Vehicular Communications and Radar Sensing in Millimeter-Wave\n  and Low Terahertz Bands", "comments": "8 pages, 5 figures, 1 table. The work has been accepted for\n  publication in IEEE Wireless Communications, 2019. Copyright may be\n  transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future smart vehicles will incorporate high-data-rate communications and\nhigh-resolution radar sensing capabilities operating in the millimeter-wave and\nhigher frequencies. These two systems are preparing to share and reuse a lot of\ncommon functionalities, such as steerable millimeter-wave antenna arrays.\nMotivated by this growing overlap, and advanced further by the space and cost\nconstraints, the vehicular community is pursuing a vision of unified vehicular\ncommunications and radar sensing, which represents a major paradigm shift for\nnext-generation connected and self-driving cars. This article outlines a path\nto materialize this decisive transformation. We begin by reviewing the latest\ndevelopments in hybrid vehicular communications and radar systems, and then\npropose a concept of unified channel access over millimeter-wave and higher\nfrequencies. Our supporting system-level performance characterization relies\nupon real-life measurements and massive ray-based modeling to confirm the\nsignificant improvements brought by our proposal to mitigating the interference\nand deafness effects. Since our results aim to open the door to unified\nvehicular communications and radar sensing, we conclude by outlining the\npotential research directions in this rapidly developing field.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 16:03:41 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Petrov", "Vitaly", ""], ["Fodor", "Gabor", ""], ["Kokkoniemi", "Joonas", ""], ["Moltchanov", "Dmitri", ""], ["Lehtomaki", "Janne", ""], ["Andreev", "Sergey", ""], ["Koucheryavy", "Yevgeni", ""], ["Juntti", "Markku", ""], ["Valkama", "Mikko", ""]]}, {"id": "1901.07006", "submitter": "Adnan Aijaz", "authors": "Jayashree Thota and Adnan Aijaz", "title": "On Performance Evaluation of Random Access Enhancements for 5G uRLLC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges in realizing ultra-reliable low-latency\ncommunications (uRLLC) for factories-of-the-future (FoF) applications is to\nenhance the cellular random access channel (RACH) procedure. The\nstate-of-the-art LTE RACH procedure does not fulfil the latency requirements\nfor envisioned FoF applications. Moreover, it becomes challenging due to\ncongestion and overloading from massive machine type communication (mMTC)\ndevices leading to collisions especially in a densely populated factory\nscenarios. The main objective of this paper is to conduct a comprehensive\nperformance evaluation of different random access (RA) enhancements for uRLLC\nover 5G wireless networks. Our performance evaluation is based on a realistic\nsystem-level simulator. The core enhancements considered in this work include\nearly data transmission (EDT), reserved preambles and the use of flexible\nphysical (PHY) layer numerology. We also propose three new RA enhancements for\nuRLLC. Performance evaluation demonstrates that the proposed RA enhancements\ncan fulfil the 3GPP control plane target of less than 10 ms latency with 99.99%\nreliability in factory environments.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 17:43:07 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Thota", "Jayashree", ""], ["Aijaz", "Adnan", ""]]}, {"id": "1901.07059", "submitter": "Hassan Habibi Gharakheili", "authors": "Xiaohong Deng, Yun Feng, Hassan Habibi Gharakheili, Vijay Sivaraman", "title": "Estimating Residential Broadband Capacity using Big Data from M-Lab", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing residential broadband capacity profiles across a population is of\ninterest to both consumers and regulators who want to compare or audit\nperformance of various broadband service offerings. Unfortunately, extracting\nbroadband capacity from speed tests in public datasets like M-Lab is\nchallenging because tests are indexed by client IP address which can be dynamic\nand/or obfuscated by NAT, and variable network conditions can affect\nmeasurements. This paper presents the first systematic effort to isolate\nhouseholds and extract their broadband capacity using 63 million speed test\nmeasurements recorded over a 12 month period in the M-Lab dataset. We first\nidentify a key parameter, the correlation between measured speed and congestion\ncount for a specific client IP address, as an indicator of whether the IP\naddress represents a single house, or a plurality of houses that may be\ndynamically sharing addresses or be aggregated behind a NAT. We then validate\nour approach by comparing to ground truth taken from a few known houses, and at\nlarger scale by checking internal consistency across ISPs and across months.\nLastly, we present results that isolate households and estimate their broadband\ncapacity based on measured data, and additionally reveal insights into the\nprevalence of NAT and variations in service capacity tiers across ISPs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 20:05:18 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Deng", "Xiaohong", ""], ["Feng", "Yun", ""], ["Gharakheili", "Hassan Habibi", ""], ["Sivaraman", "Vijay", ""]]}, {"id": "1901.07069", "submitter": "Bo Zhou", "authors": "Bo Zhou and Walid Saad", "title": "Minimum Age of Information in the Internet of Things with Non-uniform\n  Status Packet Sizes", "comments": "33 pages, 8 figures. Accepted by IEEE Transactions on Wireless\n  Communications. Corrected the typos in Fig.1 and Fig. 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a real-time Internet of Things (IoT) monitoring system is\nconsidered in which the IoT devices are scheduled to sample underlying physical\nprocesses and send the status updates to a common destination. In a real-world\nIoT, due to the possibly different dynamics of each physical process, the sizes\nof the status updates for different devices are often different and each status\nupdate typically requires multiple transmission slots. By taking into account\nsuch multi-time slot transmissions with non-uniform sizes of the status updates\nunder noisy channels, the problem of joint device scheduling and status\nsampling is studied in order to minimize the average age of information (AoI)\nat the destination. This stochastic problem is formulated as an infinite\nhorizon average cost Markov decision process (MDP). The monotonicity of the\nvalue function of the MDP is characterized and then used to show that the\noptimal scheduling and sampling policy is threshold-based with respect to the\nAoI at each device. To overcome the curse of dimensionality, a low-complexity\nsuboptimal policy is proposed through a semi-randomized base policy and linear\napproximated value functions. The proposed suboptimal policy is shown to\nexhibit a similar structure to the optimal policy, which provides a structural\nbase for its effective performance. A structure-aware algorithm is then\ndeveloped to obtain the suboptimal policy. The analytical results are further\nextended to the IoT monitoring system with random status update arrivals, for\nwhich, the optimal scheduling and sampling policy is also shown to be\nthreshold-based with the AoI at each device. Simulation results illustrate the\nstructures of the optimal policy and show a near-optimal AoI performance\nresulting from the proposed suboptimal solution approach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 20:29:28 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 15:24:02 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 18:33:30 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 16:07:20 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zhou", "Bo", ""], ["Saad", "Walid", ""]]}, {"id": "1901.07100", "submitter": "Ekram Hossain", "authors": "Yasser Al-Eryani and Ekram Hossain", "title": "Delta-OMA (D-OMA): A New Method for Massive Multiple Access in 6G", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new multiple access method, namely, delta-orthogonal multiple access\n(D-OMA) is introduced for massive access in future generation 6G cellular\nnetworks. D-OMA is based on the concept of distributed large coordinated\nmultipoint transmission-enabled non-orthogonal multiple access (NOMA) using\npartially overlapping sub-bands for NOMA clusters. Performance of this scheme\nis demonstrated in terms of outage capacity for different degrees of\noverlapping of NOMA sub-bands. D-OMA can also be used for enhanced security\nprovisioning in both uplink and downlink wireless access networks. Practical\nimplementation issues and open challenges for optimizing D-OMA are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 22:23:39 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Al-Eryani", "Yasser", ""], ["Hossain", "Ekram", ""]]}, {"id": "1901.07106", "submitter": "Ekram Hossain", "authors": "Ekram Hossain and Yasser Al-Eryani", "title": "Large-Scale NOMA: Promises for Massive Machine-Type Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate on large-scale deployment of non-orthogonal multiple access\n(NOMA) for improved spectral and power efficiency in cellular networks to\nprovide massive wireless connectivity (e.g. for machine-type communication\n[mMTC]). First, we describe the basics of single-antenna NOMA technology and\nits extension to co-located multiple-antenna NOMA as well as coordinated\nmultipoint transmission (CoMP)-enabled NOMA technologies. Then we discuss some\nof the practical challenges of large-scale deployment of NOMA such as the\ninter-NOMA-interference (INI), inter-cell interference, and hardware\nimplementation complexity. To this end, we present one key enabling technique\nto overcome the challenges of large-scale deployment of NOMA. Generally\nspeaking, for a feasible large-scale NOMA implementation, sophisticated\ndiversity enhancing techniques can be used to compensate for the degradation in\ncoding gain and to decrease the complexity resulting from excessive INI and\nincreased level of required successive interference cancellation (SIC).\nFurthermore, to massively extend NOMA over the network coverage area, NOMA\ntransmitters have to cooperate in a generalized manner to serve all nearby\nusers simultaneously.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 22:48:58 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Hossain", "Ekram", ""], ["Al-Eryani", "Yasser", ""]]}, {"id": "1901.07265", "submitter": "Torsten Zimmermann", "authors": "Jan R\\\"uth, Torsten Zimmermann, Oliver Hohlfeld", "title": "Hidden Treasures - Recycling Large-Scale Internet Measurements to Study\n  the Internet's Control Plane", "comments": "More information available at https://icmp.netray.io", "journal-ref": "Passive and Active Measurement Conference (PAM) 2019", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-wide scans are a common active measurement approach to study the\nInternet, e.g., studying security properties or protocol adoption. They involve\nprobing large address ranges (IPv4 or parts of IPv6) for specific ports or\nprotocols. Besides their primary use for probing (e.g., studying protocol\nadoption), we show that - at the same time - they provide valuable insights\ninto the Internet control plane informed by ICMP responses to these probes - a\ncurrently unexplored secondary use. We collect one week of ICMP responses\n(637.50M messages) to several Internet-wide ZMap scans covering multiple TCP\nand UDP ports as well as DNS-based scans covering > 50% of the domain name\nspace. This perspective enables us to study the Internet's control plane as a\nby-product of Internet measurements. We receive ICMP messages from ~171M\ndifferent IPs in roughly 53K different autonomous systems. Additionally, we\nuncover multiple control plane problems, e.g., we detect a plethora of outdated\nand misconfigured routers and uncover the presence of large-scale persistent\nrouting loops in IPv4.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 11:24:43 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["R\u00fcth", "Jan", ""], ["Zimmermann", "Torsten", ""], ["Hohlfeld", "Oliver", ""]]}, {"id": "1901.07287", "submitter": "Veljko Pejovic", "authors": "Veljko Pejovic, Ivan Majhen, Miha Janez, Blaz Zupan", "title": "RICERCANDO: Data Mining Toolkit for Mobile Broadband Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing reliance on mobile broadband (MBB) networks for communication,\nvehicle navigation, healthcare, and other critical purposes calls for improved\nmonitoring and troubleshooting of such networks. While recent advances in\nmonitoring with crowdsourced as well as network infrastructure-based methods\nallow us to tap into a number of performance metrics from all layers of\nnetworking, huge swaths of data remain poorly or completely unexplored due to a\nlack of tools suitable for rapid, interactive, and rigorous MBB data analysis.\nIn this paper we present RICERCANDO, a MBB data mining toolkit developed in a\nunique collaboration of networking and data mining experts. RICERCANDO consists\nof a preprocessing module that ensures that time-series data is stored in the\nmost appropriate form for mining, a rapid exploration module that enables\niterative analysis of time-series and geomobile data, so that anomalies are\ndetected and singled out, and the advanced mining module that lets the analyst\ndeduce root causes of observed anomalies. We implement and release RICERCANDO\nas open-source software, and validate its usability on case studies from MONROE\npan-European MBB measurement testbed.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 12:54:06 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Pejovic", "Veljko", ""], ["Majhen", "Ivan", ""], ["Janez", "Miha", ""], ["Zupan", "Blaz", ""]]}, {"id": "1901.07497", "submitter": "Jiaxiao Zheng", "authors": "Jiaxiao Zheng, Gustavo de Veciana", "title": "Elastic Multi-resource Network Slicing: Can Protection Lead to Improved\n  Performance?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to meet the performance/privacy requirements of future\ndata-intensive mobile applications, e.g., self-driving cars, mobile data\nanalytics, and AR/VR, service providers are expected to draw on shared\nstorage/computation/connectivity resources at the network \"edge\". To be\ncost-effective, a key functional requirement for such infrastructure is\nenabling the sharing of heterogeneous resources amongst tenants/service\nproviders supporting spatially varying and dynamic user demands. This paper\nproposes a resource allocation criterion, namely, Share Constrained Slicing\n(SCS), for slices allocated predefined shares of the network's resources, which\nextends the traditional alpha-fairness criterion, by striking a balance among\ninter- and intra-slice fairness vs. overall efficiency. We show that SCS has\nseveral desirable properties including slice-level protection, envyfreeness,\nand load driven elasticity. In practice, mobile users' dynamics could make the\ncost of implementing SCS high, so we discuss the feasibility of using a simpler\n(dynamically) weighted max-min as a surrogate resource allocation scheme. For a\nsetting with stochastic loads and elastic user requirements, we establish a\nsufficient condition for the stability of the associated coupled network\nsystem. Finally, and perhaps surprisingly, we show via extensive simulations\nthat while SCS (and/or the surrogate weighted max-min allocation) provides\ninter-slice protection, they can achieve improved job delay and/or perceived\nthroughput, as compared to other weighted max-min based allocation schemes\nwhose intra-slice weight allocation is not share-constrained, e.g., traditional\nmax-min or discriminatory processor sharing.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 18:16:25 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Zheng", "Jiaxiao", ""], ["de Veciana", "Gustavo", ""]]}, {"id": "1901.07531", "submitter": "Sebastian Trimpe", "authors": "Sebastian Trimpe and Dominik Baumann", "title": "Resource-aware IoT Control: Saving Communication through Predictive\n  Triggering", "comments": "16 pages, 15 figures, accepted article to appear in IEEE Internet of\n  Things Journal. arXiv admin note: text overlap with arXiv:1609.07534", "journal-ref": null, "doi": "10.1109/JIOT.2019.2894628", "report-no": null, "categories": "cs.SY cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) interconnects multiple physical devices in\nlarge-scale networks. When the 'things' coordinate decisions and act\ncollectively on shared information, feedback is introduced between them.\nMultiple feedback loops are thus closed over a shared, general-purpose network.\nTraditional feedback control is unsuitable for design of IoT control because it\nrelies on high-rate periodic communication and is ignorant of the shared\nnetwork resource. Therefore, recent event-based estimation methods are applied\nherein for resource-aware IoT control allowing agents to decide online whether\ncommunication with other agents is needed, or not. While this can reduce\nnetwork traffic significantly, a severe limitation of typical event-based\napproaches is the need for instantaneous triggering decisions that leave no\ntime to reallocate freed resources (e.g., communication slots), which hence\nremain unused. To address this problem, novel predictive and self triggering\nprotocols are proposed herein. From a unified Bayesian decision framework, two\nschemes are developed: self triggers that predict, at the current triggering\ninstant, the next one; and predictive triggers that check at every time step,\nwhether communication will be needed at a given prediction horizon. The\nsuitability of these triggers for feedback control is demonstrated in hardware\nexperiments on a cart-pole, and scalability is discussed with a multi-vehicle\nsimulation.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 21:45:55 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Trimpe", "Sebastian", ""], ["Baumann", "Dominik", ""]]}, {"id": "1901.07622", "submitter": "Thang X. Vu", "authors": "Thang X. Vu, Symeon Chatzinotas, Bjorn Ottersten", "title": "Blockchain-based Content Delivery Networks: Content Transparency Meets\n  User Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is a merging technology for decentralized management and data\nsecurity, which was first introduced as the core technology of cryptocurrency,\ne.g., Bitcoin. Since the first success in financial sector, blockchain has\nshown great potentials in various domains, e.g., internet of things and mobile\nnetworks. In this paper, we propose a novel blockchain-based architecture for\ncontent delivery networks (B-CDN), which exploits the advances of the\nblockchain technology to provide a decentralized and secure platform to connect\ncontent providers (CPs) with users. On one hand, the proposed B-CDN will\nleverage the registration and subscription of the users to different CPs, while\nguaranteeing the user privacy thanks to virtual identity provided by the\nblockchain network. On the other hand, the B-CDN creates a public immutable\ndatabase of the requested contents (from all CPs), based on which each CP can\nbetter evaluate the user preference on its contents. The benefits of B-CDN are\ndemonstrated via an edge-caching application, in which a feature-based caching\nalgorithm is proposed for all CPs. The proposed caching algorithm is verified\nwith the realistic Movielens dataset. A win-win relation between the CPs and\nusers is observed, where the B-CDN improves user quality of experience and\nreduces cost of delivering content for the CPs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 21:57:25 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Vu", "Thang X.", ""], ["Chatzinotas", "Symeon", ""], ["Ottersten", "Bjorn", ""]]}, {"id": "1901.07728", "submitter": "Aria HasanzadeZonuzy", "authors": "Aria HasanzadeZonuzy, I-Hong Hou and Srinivas Shakkottai", "title": "Broadcasting Real-Time Flows in Integrated Backhaul and Access 5G\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of broadcasting real-time flows in multi-hop\nwireless networks. We consider that each packet has a stringent deadline, and\neach node in the network obtains some utility based on the number of packets\ndelivered to it on time for each flow. We propose a distributed protocol, the\ndelegated-set routing (DSR) protocol, that incurs virtually no overhead of\ncoordination among nodes. We also develop distributed algorithms that aim to\nmaximize the total system utility under DSR. The utility of our DSR protocol\nand distributed algorithms are demonstrated by both theoretical analysis and\nsimulation results, where we show that our algorithms achieve better\nperformance even when compared against centralized throughput optimal policies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 05:18:34 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["HasanzadeZonuzy", "Aria", ""], ["Hou", "I-Hong", ""], ["Shakkottai", "Srinivas", ""]]}, {"id": "1901.07768", "submitter": "Anuja Meetoo Appavoo", "authors": "Anuja Meetoo Appavoo, Seth Gilbert, and Kian-Lee Tan", "title": "Cooperation Speeds Surfing: Use Co-Bandit!", "comments": "Full version of paper; Full version of submission \"submit/2535150\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the benefit of cooperation in adversarial bandit\nsettings. As a motivating example, we consider the problem of wireless network\nselection. Mobile devices are often required to choose the right network to\nassociate with for optimal performance, which is non-trivial. The excellent\ntheoretical properties of EXP3, a leading multi-armed bandit algorithm, suggest\nthat it should work well for this type of problem. Yet, it performs poorly in\npractice. A major limitation is its slow rate of stabilization. Bandit-style\nalgorithms perform better when global knowledge is available, i.e., when\ndevices receive feedback about all networks after each selection. But,\nunfortunately, communicating full information to all devices is expensive.\nTherefore, we address the question of how much information is adequate to\nachieve better performance. We propose Co-Bandit, a novel cooperative bandit\napproach, that allows devices to occasionally share their observations and\nforward feedback received from neighbors; hence, feedback may be received with\na delay. Devices perform network selection based on their own observation and\nfeedback from neighbors. As such, they speed up each other's rate of learning.\nWe prove that Co-Bandit is regret-minimizing and retains the convergence\nproperty of multiplicative weight update algorithms with full information.\nThrough simulation, we show that a very small amount of information, even with\na delay, is adequate to nudge each other to select the right network and yield\nsignificantly faster stabilization at the optimal state (about 630x faster than\nEXP3).\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 08:21:11 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Appavoo", "Anuja Meetoo", ""], ["Gilbert", "Seth", ""], ["Tan", "Kian-Lee", ""]]}, {"id": "1901.07947", "submitter": "Jithin Jagannath", "authors": "Jithin Jagannath and Nicholas Polosky and Anu Jagannath and Francesco\n  Restuccia and Tommaso Melodia", "title": "Machine Learning for Wireless Communications in the Internet of Things:\n  A Comprehensive Survey", "comments": "Ad Hoc Networks Journal", "journal-ref": null, "doi": "10.1016/j.adhoc.2019.101913", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is expected to require more effective and\nefficient wireless communications than ever before. For this reason, techniques\nsuch as spectrum sharing, dynamic spectrum access, extraction of signal\nintelligence and optimized routing will soon become essential components of the\nIoT wireless communication paradigm. Given that the majority of the IoT will be\ncomposed of tiny, mobile, and energy-constrained devices, traditional\ntechniques based on a priori network optimization may not be suitable, since\n(i) an accurate model of the environment may not be readily available in\npractical scenarios; (ii) the computational requirements of traditional\noptimization techniques may prove unbearable for IoT devices. To address the\nabove challenges, much research has been devoted to exploring the use of\nmachine learning to address problems in the IoT wireless communications domain.\n  This work provides a comprehensive survey of the state of the art in the\napplication of machine learning techniques to address key problems in IoT\nwireless communications with an emphasis on its ad hoc networking aspect.\nFirst, we present extensive background notions of machine learning techniques.\nThen, by adopting a bottom-up approach, we examine existing work on machine\nlearning for the IoT at the physical, data-link and network layer of the\nprotocol stack. Thereafter, we discuss directions taken by the community\ntowards hardware implementation to ensure the feasibility of these techniques.\nAdditionally, before concluding, we also provide a brief discussion of the\napplication of machine learning in IoT beyond wireless communication. Finally,\neach of these discussions is accompanied by a detailed analysis of the related\nopen problems and challenges.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 15:25:48 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 23:49:48 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Jagannath", "Jithin", ""], ["Polosky", "Nicholas", ""], ["Jagannath", "Anu", ""], ["Restuccia", "Francesco", ""], ["Melodia", "Tommaso", ""]]}, {"id": "1901.08113", "submitter": "Jos\\'e Su\\'arez-Varela", "authors": "Krzysztof Rusek, Jos\\'e Su\\'arez-Varela, Albert Mestres, Pere\n  Barlet-Ros and Albert Cabellos-Aparicio", "title": "Unveiling the potential of Graph Neural Networks for network modeling\n  and optimization in SDN", "comments": "12 pages", "journal-ref": "In Proceedings of the ACM Symposium on SDN Research (SOSR), pp.\n  140-151, 2019", "doi": "10.1145/3314148.3314357", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network modeling is a critical component for building self-driving\nSoftware-Defined Networks, particularly to find optimal routing schemes that\nmeet the goals set by administrators. However, existing modeling techniques do\nnot meet the requirements to provide accurate estimations of relevant\nperformance metrics such as delay and jitter. In this paper we propose a novel\nGraph Neural Network (GNN) model able to understand the complex relationship\nbetween topology, routing and input traffic to produce accurate estimates of\nthe per-source/destination pair mean delay and jitter. GNN are tailored to\nlearn and model information structured as graphs and as a result, our model is\nable to generalize over arbitrary topologies, routing schemes and variable\ntraffic intensity. In the paper we show that our model provides accurate\nestimates of delay and jitter (worst case $R^2=0.86$) when testing against\ntopologies, routing and traffic not seen during training. In addition, we\npresent the potential of the model for network operation by presenting several\nuse-cases that show its effective use in per-source/destination pair\ndelay/jitter routing optimization and its generalization capabilities by\nreasoning in topologies and routing schemes not seen during training.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 20:02:16 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 11:08:58 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 12:59:00 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Rusek", "Krzysztof", ""], ["Su\u00e1rez-Varela", "Jos\u00e9", ""], ["Mestres", "Albert", ""], ["Barlet-Ros", "Pere", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "1901.08151", "submitter": "Richard Hill Prof", "authors": "Hussain Al-Aqrabi, Lu Liu, Richard Hill, Nick Antonopoulos", "title": "Cloud BI: Future of Business Intelligence in the Cloud", "comments": "12 pages, Journal of Computer and System Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is gradually gaining popularity among businesses due to its\ndistinct advantages over self-hosted IT infrastructures. Business Intelligence\n(BI) is a highly resource intensive system requiring large-scale parallel\nprocessing and significant storage capacities to host data warehouses. In\nself-hosted environments it was feared that BI will eventually face a resource\ncrunch situation because it will not be feasible for companies to keep adding\nresources to host a neverending expansion of data warehouses and the online\nanalytical processing (OLAP) demands on the underlying networking. Cloud\ncomputing has instigated a new hope for future prospects of BI. However, how\nwill BI be implemented on cloud and how will the traffic and demand profile\nlook like? This research attempts to answer these key questions in regards to\ntaking BI to the cloud. The cloud hosting of BI has been demonstrated with the\nhelp of a simulation on OPNET comprising a cloud model with multiple OLAP\napplication servers applying parallel query loads on an array of servers\nhosting relational databases. The simulation results have reflected that true\nand extensible parallel processing of database servers on the cloud can\nefficiently process OLAP application demands on cloud computing. Hence, the BI\ndesigner needs to plan for a highly partitioned database running on massively\nparallel database servers in which, each server hosts at least one partition of\nthe underlying database serving the OLAP demands.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 22:11:24 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Al-Aqrabi", "Hussain", ""], ["Liu", "Lu", ""], ["Hill", "Richard", ""], ["Antonopoulos", "Nick", ""]]}, {"id": "1901.08200", "submitter": "Zaoxing Liu", "authors": "Zaoxing Liu, Zhihao Bai, Zhenming Liu, Xiaozhou Li, Changhoon Kim,\n  Vladimir Braverman, Xin Jin, Ion Stoica", "title": "DistCache: Provable Load Balancing for Large-Scale Storage Systems with\n  Distributed Caching", "comments": "Technical Report. Conference version accepted to USENIX FAST'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Load balancing is critical for distributed storage to meet strict\nservice-level objectives (SLOs). It has been shown that a fast cache can\nguarantee load balancing for a clustered storage system. However, when the\nsystem scales out to multiple clusters, the fast cache itself would become the\nbottleneck. Traditional mechanisms like cache partition and cache replication\neither result in load imbalance between cache nodes or have high overhead for\ncache coherence.\n  We present DistCache, a new distributed caching mechanism that provides\nprovable load balancing for large-scale storage systems. DistCache co-designs\ncache allocation with cache topology and query routing. The key idea is to\npartition the hot objects with independent hash functions between cache nodes\nin different layers, and to adaptively route queries with the\npower-of-two-choices. We prove that DistCache enables the cache throughput to\nincrease linearly with the number of cache nodes, by unifying techniques from\nexpander graphs, network flows, and queuing theory. DistCache is a general\nsolution that can be applied to many storage systems. We demonstrate the\nbenefits of DistCache by providing the design, implementation, and evaluation\nof the use case for emerging switch-based caching.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 02:23:36 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 20:03:14 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Liu", "Zaoxing", ""], ["Bai", "Zhihao", ""], ["Liu", "Zhenming", ""], ["Li", "Xiaozhou", ""], ["Kim", "Changhoon", ""], ["Braverman", "Vladimir", ""], ["Jin", "Xin", ""], ["Stoica", "Ion", ""]]}, {"id": "1901.08271", "submitter": "Yong Niu", "authors": "Yong Niu, Han Shi, Yong Li, Ruisi He, Zhangdui Zhong", "title": "Coalition Formation Games Based Sub-Channel Allocation for\n  Device-to-Device Underlay mmWave Small Cells", "comments": "4 pages, 2 figures, URSI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small cells in the millimeter wave band densely deployed underlying the\nmacrocell have been regarded as one of promising candidates for the next\ngeneration mobile networks. In the user intensive region, device-to-device\n(D2D) communication in physical proximity can save power and improve spectral\nefficiency. In this paper, we focus on the optimal sub-channel allocation for\naccess and D2D links in the scenario of densely deployed multiple mmWave small\ncells. The problem is modeled as a coalitional game to maximize the system sum\nrate of access and D2D links in the system. Then we propose a coalition\nformation game based algorithm for sub-channel allocation. Performance\nevaluation results demonstrate superior performance in terms of the system sum\nrate compared with other practical schemes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 08:13:58 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Niu", "Yong", ""], ["Shi", "Han", ""], ["Li", "Yong", ""], ["He", "Ruisi", ""], ["Zhong", "Zhangdui", ""]]}, {"id": "1901.08326", "submitter": "Mohamed Lamine Lamali", "authors": "Mohamed Lamine Lamali (LaBRI), Simon Lassourreuille (LaBRI), Stephan\n  Kunne (GALaC - LRI), Johanne Cohen (LRI)", "title": "A stack-vector routing protocol for automatic tunneling", "comments": null, "journal-ref": "IEEE INFOCOM 2019, Apr 2019, Paris, France.\n  https://infocom2019.ieee-infocom.org/", "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a network, a tunnel is a part of a path where a protocol is encapsulated\nin another one. A tunnel starts with an encapsulation and ends with the\ncorresponding decapsulation. Several tunnels can be nested at some stage,\nforming a protocol stack. Tunneling is very important nowadays and it is\ninvolved in several tasks: IPv4/IPv6 transition, VPNs, security (IPsec, onion\nrouting), etc. However, tunnel establishment is mainly performed manually or by\nscript, which present obvious scalability issues. Some works attempt to\nautomate a part of the process (e.g., TSP, ISATAP, etc.). However, the\ndetermination of the tunnel(s) endpoints is not fully automated, especially in\nthe case of an arbitrary number of nested tunnels. The lack of routing\nprotocols performing automatic tunneling is due to the unavailability of path\ncomputation algorithms taking into account encapsulations and decapsulations.\nThere is a polynomial centralized algorithm to perform the task. However, to\nthe best of our knowledge, no fully distributed path computation algorithm is\nknown. Here, we propose the first fully distributed algorithm for path\ncomputation with automatic tunneling, i.e., taking into account encapsulation,\ndecapsulation and conversion of protocols. Our algorithm is a generalization of\nthe distributed Bellman-Ford algorithm, where the distance vector is replaced\nby a protocol stack vector. This allows to know how to route a packet with some\nprotocol stack. We prove that the messages size of our algorithm is polynomial,\neven if the shortest path can be of exponential length. We also prove that the\nalgorithm converges after a polynomial number of steps in a synchronized\nsetting. We adapt our algorithm into a proto-protocol for routing with\nautomatic tunneling and we show its efficiency through simulations.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 10:08:18 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Lamali", "Mohamed Lamine", "", "LaBRI"], ["Lassourreuille", "Simon", "", "LaBRI"], ["Kunne", "Stephan", "", "GALaC - LRI"], ["Cohen", "Johanne", "", "LRI"]]}, {"id": "1901.08329", "submitter": "Yuanwei Liu", "authors": "Yuanwei Liu, Suzhi Bi, Zhiyuan Shi, and Lajos Hanzo", "title": "When Machine Learning Meets Big Data: A Wireless Communication\n  Perspective", "comments": "This article has been accepted by IEEE Vehicular Technology Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have witnessed an exponential growth in commercial data services, which\nhas lead to the 'big data era'. Machine learning, as one of the most promising\nartificial intelligence tools of analyzing the deluge of data, has been invoked\nin many research areas both in academia and industry. The aim of this article\nis twin-fold. Firstly, we briefly review big data analysis and machine\nlearning, along with their potential applications in next-generation wireless\nnetworks. The second goal is to invoke big data analysis to predict the\nrequirements of mobile users and to exploit it for improving the performance of\n\"social network-aware wireless\". More particularly, a unified big data aided\nmachine learning framework is proposed, which consists of feature extraction,\ndata modeling and prediction/online refinement. The main benefits of the\nproposed framework are that by relying on big data which reflects both the\nspectral and other challenging requirements of the users, we can refine the\nmotivation, problem formulations and methodology of powerful machine learning\nalgorithms in the context of wireless networks. In order to characterize the\nefficiency of the proposed framework, a pair of intelligent practical\napplications are provided as case studies: 1) To predict the positioning of\ndrone-mounted areal base stations (BSs) according to the specific tele-traffic\nrequirements by gleaning valuable data from social networks. 2) To predict the\ncontent caching requirements of BSs according to the users' preferences by\nmining data from social networks. Finally, open research opportunities are\nidentified for motivating future investigations.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 10:20:48 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 18:11:28 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Liu", "Yuanwei", ""], ["Bi", "Suzhi", ""], ["Shi", "Zhiyuan", ""], ["Hanzo", "Lajos", ""]]}, {"id": "1901.08577", "submitter": "Ahmed Arafa", "authors": "Ahmed Arafa, Jing Yang, Sennur Ulukus, H. Vincent Poor", "title": "Using Erasure Feedback for Online Timely Updating with an Energy\n  Harvesting Sensor", "comments": "To appear in the 2019 IEEE International Symposium on Information\n  Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A real-time status updating system is considered, in which an energy\nharvesting sensor is acquiring measurements regarding some physical phenomenon\nand sending them to a destination through an erasure channel. The setting is\nonline, in which energy arrives in units according to a Poisson process with\nunit rate, with arrival times being revealed causally over time. Energy is\nsaved in a unit-sized battery. The sensor is notified by the destination of\nwhether updates were erased via feedback. Updates need to reach the destination\nsuccessfully in a timely fashion, namely, such that the long term average age\nof information, defined as the time elapsed since the latest successful update\nhas reached the destination, is minimized. First, it is shown that the optimal\nstatus update policy has a renewal structure: successful update times should\nconstitute a renewal process. Then, threshold-greedy policies are investigated:\na new update is transmitted, following a successful one, only if the age of\ninformation grows above a certain threshold; and if it is erased, then all\nsubsequent update attempts are greedily scheduled whenever energy is available.\nThe optimal threshold-greedy policy is then analytically derived.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:52:38 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 17:54:48 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Arafa", "Ahmed", ""], ["Yang", "Jing", ""], ["Ulukus", "Sennur", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1901.08618", "submitter": "Shantanu Sharma", "authors": "Nisha Panwar, Shantanu Sharma, Guoxi Wang, Sharad Mehrotra, Nalini\n  Venkatasubramanian", "title": "Verifiable Round-Robin Scheme for Smart Homes", "comments": "Accepted in ACM Conference on Data and Application Security and\n  Privacy (CODASPY), 2019. 12 pages", "journal-ref": null, "doi": "10.1145/3292006.3300043", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in sensing, networking, and actuation technologies have resulted in\nthe IoT wave that is expected to revolutionize all aspects of modern society.\nThis paper focuses on the new challenges of privacy that arise in IoT in the\ncontext of smart homes. Specifically, the paper focuses on preventing the\nuser's privacy via inferences through channel and in-home device activities. We\npropose a method for securely scheduling the devices while decoupling the\ndevice and channels activities. The proposed solution avoids any attacks that\nmay reveal the coordinated schedule of the devices, and hence, also, assures\nthat inferences that may compromise individual's privacy are not leaked due to\ndevice and channel level activities. Our experiments also validate the proposed\napproach, and consequently, an adversary cannot infer device and channel\nactivities by just observing the network traffic.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 19:20:22 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Panwar", "Nisha", ""], ["Sharma", "Shantanu", ""], ["Wang", "Guoxi", ""], ["Mehrotra", "Sharad", ""], ["Venkatasubramanian", "Nalini", ""]]}, {"id": "1901.08872", "submitter": "Mohammad Irfan Khan", "authors": "Mohammad Irfan Khan, Fran\\c{c}ois-Xavier Aubet, Marc-Oliver Pahl,\n  J\\'er\\^ome H\\\"arri", "title": "Deep Learning-aided Application Scheduler for Vehicular Safety\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  802.11p based V2X communication uses stochastic medium access control, which\ncannot prevent broadcast packet collision, in particular during high channel\nload. Wireless congestion control has been designed to keep the channel load at\nan optimal point. However, vehicles' lack of precise and granular knowledge\nabout true channel activity, in time and space, makes it impossible to fully\navoid packet collisions. In this paper, we propose a machine learning approach\nusing deep neural network for learning the vehicles' transmit patterns, and as\nsuch predicting future channel activity in space and time. We evaluate the\nperformance of our proposal via simulation considering multiple safety-related\nV2X services involving heterogeneous transmit patterns. Our results show that\npredicting channel activity, and transmitting accordingly, reduces collisions\nand significantly improves communication performance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 13:49:21 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Khan", "Mohammad Irfan", ""], ["Aubet", "Fran\u00e7ois-Xavier", ""], ["Pahl", "Marc-Oliver", ""], ["H\u00e4rri", "J\u00e9r\u00f4me", ""]]}, {"id": "1901.08919", "submitter": "Gewu Bu", "authors": "Gewu Bu (NPA), Maria Potop-Butucaru (LINCS, MIMOVE, NPA), Mikael Rabie\n  (LIX)", "title": "Wireless Broadcast with short labelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the broadcast problem in wireless networks when the\nbroadcast is helped by a labelling scheme. We focus on two variants of\nbroadcast: broadcast without acknowledgment (i.e. the initiator of the\nbroadcast is not notified at the end of broadcast) and broadcast with\nacknowledgment. Our contribution is threefold. First, we improve in terms of\nmemory complexity a recent labelling-based broadcast scheme with acknowledgment\ndesigned for arbitrary networks.Second, we propose label optimal broadcast\nalgorithms in Level Separable Networks (a class of networks issued from recent\nstudies in Wireless Body Area Networks). In this class of networks we propose\nan acknowledgment-free broadcast strategy using 1-bit labels and broadcast with\nacknowledgment using 2-bits labels. In the class of level-separable networks,\nour algorithms finish within 2D rounds, where D is the eccentricity of the\nbroadcast initiator. Interestingly, the time complexity of broadcast in the\ncase of level-separable networks does not depend on the size of the network but\nrather on the initiator eccentricity which makes this class of graphs\ninteresting for further investigation. Finally, we study the hardness of\ndetermining that a graph is level separable. Our study shows that even though\nchecking that a separation is a level separation can be done in polynomial\ntime, determining that a graph has the level separable property is NP-complete.\nThis result opens interesting independent research directions.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 15:24:06 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 09:02:04 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 10:38:54 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Bu", "Gewu", "", "NPA"], ["Potop-Butucaru", "Maria", "", "LINCS, MIMOVE, NPA"], ["Rabie", "Mikael", "", "LIX"]]}, {"id": "1901.08936", "submitter": "Konstantinos Poularakis", "authors": "Konstantinos Poularakis, Qiaofeng Qin, Liang Ma, Sastry Kompella, Kin\n  K. Leung, Leandros Tassiulas", "title": "Learning the Optimal Synchronization Rates in Distributed SDN Control\n  Architectures", "comments": "IEEE Infocom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the early development of Software-Defined Network (SDN) technology,\nresearchers have been concerned with the idea of physical distribution of the\ncontrol plane to address scalability and reliability challenges of centralized\ndesigns. However, having multiple controllers managing the network while\nmaintaining a \"logically-centralized\" network view brings additional\nchallenges. One such challenge is how to coordinate the management decisions\nmade by the controllers which is usually achieved by disseminating\nsynchronization messages in a peer-to-peer manner. While there exist many\narchitectures and protocols to ensure synchronized network views and drive\ncoordination among controllers, there is no systematic methodology for deciding\nthe optimal frequency (or rate) of message dissemination. In this paper, we\nfill this gap by introducing the SDN synchronization problem: how often to\nsynchronize the network views for each controller pair. We consider two\ndifferent objectives; first, the maximization of the number of controller pairs\nthat are synchronized, and second, the maximization of the performance of\napplications of interest which may be affected by the synchronization rate.\nUsing techniques from knapsack optimization and learning theory, we derive\nalgorithms with provable performance guarantees for each objective. Evaluation\nresults demonstrate significant benefits over baseline schemes that synchronize\nall controller pairs at equal rate.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 15:48:03 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Poularakis", "Konstantinos", ""], ["Qin", "Qiaofeng", ""], ["Ma", "Liang", ""], ["Kompella", "Sastry", ""], ["Leung", "Kin K.", ""], ["Tassiulas", "Leandros", ""]]}, {"id": "1901.08946", "submitter": "Konstantinos Poularakis", "authors": "Konstantinos Poularakis, Jaime Llorca, Antonia M. Tulino, Ian Taylor,\n  and Leandros Tassiulas", "title": "Joint Service Placement and Request Routing in Multi-cell Mobile Edge\n  Computing Networks", "comments": "IEEE Infocom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of innovative mobile services such as augmented reality,\nnetworked gaming, and autonomous driving has spurred a growing need for\nlow-latency access to computing resources that cannot be met solely by existing\ncentralized cloud systems. Mobile Edge Computing (MEC) is expected to be an\neffective solution to meet the demand for low-latency services by enabling the\nexecution of computing tasks at the network-periphery, in proximity to\nend-users. While a number of recent studies have addressed the problem of\ndetermining the execution of service tasks and the routing of user requests to\ncorresponding edge servers, the focus has primarily been on the efficient\nutilization of computing resources, neglecting the fact that non-trivial\namounts of data need to be stored to enable service execution, and that many\nemerging services exhibit asymmetric bandwidth requirements. To fill this gap,\nwe study the joint optimization of service placement and request routing in\nMEC-enabled multi-cell networks with multidimensional\n(storage-computation-communication) constraints. We show that this problem\ngeneralizes several problems in literature and propose an algorithm that\nachieves close-to-optimal performance using randomized rounding. Evaluation\nresults demonstrate that our approach can effectively utilize the available\nresources to maximize the number of requests served by low-latency edge cloud\nservers.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 16:04:23 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Poularakis", "Konstantinos", ""], ["Llorca", "Jaime", ""], ["Tulino", "Antonia M.", ""], ["Taylor", "Ian", ""], ["Tassiulas", "Leandros", ""]]}, {"id": "1901.08967", "submitter": "Zhuojia Gu", "authors": "Zhuojia Gu, Hancheng Lu, Zuqing Zhu", "title": "On Throughput Optimization and Bound Analysis in Cache-Enabled\n  Fiber-Wireless Networks", "comments": "15 pages, 11 figures; published in IEEE Transactions on Vehicular\n  Technology", "journal-ref": null, "doi": "10.1109/TVT.2020.3000487", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the dense deployment of millimeter wave (mmWave) front ends and\npopularization of bandwidth-intensive applications, shared backhaul in\nfiber-wireless (FiWi) networks is still facing a bandwidth crunch. To alleviate\nthe backhaul pressure, in this paper, caching capability is enabled at the edge\nof FiWi networks, i.e., optical network unit access points (ONU-APs). On the\nother hand, as both power budget and backhaul bandwidth in FiWi networks are\nconstrained, it is challenging to properly leverage power for caching and that\nfor wireless transmission to achieve superior system performance. As caching\nhas a significant impact on resource allocation, we reconsider performance\noptimization and analysis in cache-enabled FiWi networks. Firstly, in the\ncache-enabled FiWi network with mmWave, we formulate the joint power allocation\nand caching problem, with the goal to maximize the downlink throughput. A\ntwo-stage algorithm is then proposed to solve the problem. Secondly, to\ninvestigate the theoretical capacity of the cache-enabled FiWi network with\nmmWave, we derive an upper bound of the downlink throughput by analyzing\nproperties of the average rate of wireless links. Particularly, we show that\nappropriate power allocation for wireless transmission and caching at ONU-APs\nis essential to achieve higher throughput. The numerical and simulation results\nvalidate our theoretical analysis and demonstrate the proposed algorithm can\napproach the analytical upper bound.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 12:10:09 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 02:54:32 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 05:03:32 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Gu", "Zhuojia", ""], ["Lu", "Hancheng", ""], ["Zhu", "Zuqing", ""]]}, {"id": "1901.09094", "submitter": "Dengwang Tang", "authors": "Dengwang Tang, Vijay G. Subramanian", "title": "Derandomized Load Balancing using Random Walks on Expander Graphs", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NI cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a computing center with a huge amount of machines, when a job arrives, a\ndispatcher need to decide which machine to route this job to based on limited\ninformation. A classical method, called the power-of-$d$ choices algorithm is\nto pick $d$ servers independently at random and dispatch the job to the least\nloaded server among the $d$ servers. In this paper, we analyze a low-randomness\nvariant of this dispatching scheme, where $d$ queues are sampled through $d$\nindependent non-backtracking random walks on a $k$-regular graph $G$. Under\ncertain assumptions of the graph $G$ we show that under this scheme, the\ndynamics of the queuing system converges to the same deterministic ordinary\ndifferential equation (ODE) for the power-of-$d$ choices scheme. We also show\nthat the system is stable under the proposed scheme, and the stationary\ndistribution of the system converges to the fixed point of the ODE.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 02:31:23 GMT"}, {"version": "v2", "created": "Sun, 21 Apr 2019 16:58:35 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Tang", "Dengwang", ""], ["Subramanian", "Vijay G.", ""]]}, {"id": "1901.09129", "submitter": "Xuan Li", "authors": "Xuan Li and Miao Jin", "title": "Optimal $k$-Coverage Charging Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless rechargeable sensor networks, consisting of sensor nodes with\nrechargeable batteries and mobile chargers to replenish their batteries, have\ngradually become a promising solution to the bottleneck of energy limitation\nthat hinders the wide deployment of wireless sensor networks (WSN). In this\npaper, we focus on the mobile charger scheduling and path optimization scenario\nin which the $k$-coverage ability of a network system needs to be maintained.\nWe formulate the optimal $k$-coverage charging problem of finding a feasible\npath for a mobile charger to charge a set of sensor nodes within their\nestimated charging deadlines under the constraint of maintaining the\n$k$-coverage ability of the network system, with an objective of minimizing the\nenergy consumption on traveling per tour. We show the hardness of the problem\nthat even finding a feasible path for the trivial case of the problem is an\nNP-complete one.\n  We model the problem and apply dynamic programming to design an algorithm\nthat finds an exact solution to the optimal $k$-coverage charging problem.\nHowever, the computational complexity is still prohibitive for large size\nnetworks. We then introduce Deep Q-learning, a reinforcement learning algorithm\nto tackle the problem.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 00:45:44 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 11:47:57 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Li", "Xuan", ""], ["Jin", "Miao", ""]]}, {"id": "1901.09165", "submitter": "Bo Bai", "authors": "Kai Lei, Meng Qin, Bo Bai, Gong Zhang, Min Yang", "title": "GCN-GAN: A Non-linear Temporal Link Prediction Model for Weighted\n  Dynamic Networks", "comments": "to appear in IEEE Infocom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we generally formulate the dynamics prediction problem of\nvarious network systems (e.g., the prediction of mobility, traffic and\ntopology) as the temporal link prediction task. Different from conventional\ntechniques of temporal link prediction that ignore the potential non-linear\ncharacteristics and the informative link weights in the dynamic network, we\nintroduce a novel non-linear model GCN-GAN to tackle the challenging temporal\nlink prediction task of weighted dynamic networks. The proposed model leverages\nthe benefits of the graph convolutional network (GCN), long short-term memory\n(LSTM) as well as the generative adversarial network (GAN). Thus, the dynamics,\ntopology structure and evolutionary patterns of weighted dynamic networks can\nbe fully exploited to improve the temporal link prediction performance.\nConcretely, we first utilize GCN to explore the local topological\ncharacteristics of each single snapshot and then employ LSTM to characterize\nthe evolving features of the dynamic networks. Moreover, GAN is used to enhance\nthe ability of the model to generate the next weighted network snapshot, which\ncan effectively tackle the sparsity and the wide-value-range problem of edge\nweights in real-life dynamic networks. To verify the model's effectiveness, we\nconduct extensive experiments on four datasets of different network systems and\napplication scenarios. The experimental results demonstrate that our model\nachieves impressive results compared to the state-of-the-art competitors.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 05:42:05 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Lei", "Kai", ""], ["Qin", "Meng", ""], ["Bai", "Bo", ""], ["Zhang", "Gong", ""], ["Yang", "Min", ""]]}, {"id": "1901.09177", "submitter": "Songyang Zhang", "authors": "Songyang Zhang and Weimin Lei", "title": "An Optimized BBR for Multipath Real Time Video Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multipath transmission scheme can work as an effective way to provide\nbetter quality of experiments to end users. Two key research points in the\nmultipath real time video transmission context are congestion control and\npacket scheduling. As Utility maximization theory shows, to provide better\nsatisfaction to end users is to provide higher throughput and lower\ntransmission delay. The congestion control is responsible to converge to the\nmaximum available bandwidth and avoid leading the network into congestion. A\ndelay response BBR (Delay-BBR) algorithm optimized for real time video\ntransmission is proposed, and the main idea is to reduce sending rate when the\nlink delay has exceeded certain threshold to let the intermediate routers drain\nthe occupied buffer. It can achieve better transmission delay and lower packet\nloss rate compared with QUIC-BBR and WebRTC-BBR by experiment. And a packet\nscheduling algorithm induced from Utility maximization theory works on top of\nthe congestion control algorithm is tested and achieves lower frame delivery\ndelay further compared with benchmark algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 08:25:48 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Zhang", "Songyang", ""], ["Lei", "Weimin", ""]]}, {"id": "1901.09236", "submitter": "Vishnu Vardhan Chetlur", "authors": "Vishnu Vardhan Chetlur and Harpreet S. Dhillon", "title": "Coverage and Rate Analysis of Downlink Cellular Vehicle-to-Everything\n  (C-V2X) Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the downlink coverage and rate analysis of a\ncellular vehicle-to-everything (C-V2X) communication network where the\nlocations of vehicular nodes and road side units (RSUs) are modeled as Cox\nprocesses driven by a Poisson line process (PLP) and the locations of cellular\nmacro base stations (MBSs) are modeled as a 2D Poisson point process (PPP).\nAssuming a fixed selection bias and maximum average received power based\nassociation, we compute the probability with which a {\\em typical receiver}, an\narbitrarily chosen receiving node, connects to a vehicular node or an RSU and a\ncellular MBS. For this setup, we derive the signal-to-interference ratio\n(SIR)-based coverage probability of the typical receiver. One of the key\nchallenges in the computation of coverage probability stems from the inclusion\nof shadowing effects. As the standard procedure of interpreting the shadowing\neffects as random displacement of the location of nodes is not directly\napplicable to the Cox process, we propose an approximation of the spatial model\ninspired by the asymptotic behavior of the Cox process. Using this asymptotic\ncharacterization, we derive the coverage probability in terms of the Laplace\ntransform of interference power distribution. Further, we compute the downlink\nrate coverage of the typical receiver by characterizing the load on the serving\nvehicular nodes or RSUs and serving MBSs. We also provide several key design\ninsights by studying the trends in the coverage probability and rate coverage\nas a function of network parameters. We observe that the improvement in rate\ncoverage obtained by increasing the density of MBSs can be equivalently\nachieved by tuning the selection bias appropriately without the need to deploy\nadditional MBSs.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 15:48:55 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Chetlur", "Vishnu Vardhan", ""], ["Dhillon", "Harpreet S.", ""]]}, {"id": "1901.09247", "submitter": "Tugba Erpek", "authors": "Yi Shi, Tugba Erpek, Yalin E. Sagduyu, and Jason H. Li", "title": "Spectrum Data Poisoning with Adversarial Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been widely applied in wireless communications. However,\nthe security aspects of machine learning in wireless applications have not been\nwell understood yet. We consider the case that a cognitive transmitter senses\nthe spectrum and transmits on idle channels determined by a machine learning\nalgorithm. We present an adversarial machine learning approach to launch a\nspectrum data poisoning attack by inferring the transmitter's behavior and\nattempting to falsify the spectrum sensing data over the air. For that purpose,\nthe adversary transmits for a short period of time when the channel is idle to\nmanipulate the input for the decision mechanism of the transmitter. The\ncognitive engine at the transmitter is a deep neural network model that\npredicts idle channels with minimum sensing error for data transmissions. The\ntransmitter collects spectrum sensing data and uses it as the input to its\nmachine learning algorithm. In the meantime, the adversary builds a cognitive\nengine using another deep neural network model to predict when the transmitter\nwill have a successful transmission based on its spectrum sensing data. The\nadversary then performs the over-the-air spectrum data poisoning attack, which\naims to change the channel occupancy status from idle to busy when the\ntransmitter is sensing, so that the transmitter is fooled into making incorrect\ntransmit decisions. This attack is more energy efficient and harder to detect\ncompared to jamming of data transmissions. We show that this attack is very\neffective and reduces the throughput of the transmitter substantially.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 17:15:39 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Shi", "Yi", ""], ["Erpek", "Tugba", ""], ["Sagduyu", "Yalin E.", ""], ["Li", "Jason H.", ""]]}, {"id": "1901.09307", "submitter": "Pengfei Wang", "authors": "Pengfei Wang, Zijie Zheng, Boya Di and Lingyang Song", "title": "HetMEC: Latency-optimal Task Assignment and Resource Allocation for\n  Heterogeneous Mobile Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by great demands on low-latency services of the edge devices (EDs),\nmobile edge computing (MEC) has been proposed to enable the computing\ncapacities at the edge of the radio access network. However, conventional MEC\nservers suffer disadvantages such as limited computing capacity, preventing the\ncomputation-intensive tasks to be processed in time. To relief this issue, we\npropose the heterogeneous MEC (HetMEC) where the data that cannot be timely\nprocessed at the edge are allowed be offloaded to the upper-layer MEC servers,\nand finally to the cloud center (CC) with more powerful computing capacity. We\ndesign the latency minimization algorithm by jointly coordinating the task\nassignment, computing and transmission resources among the EDs, multi-layer MEC\nservers, and the CC. Simulation results indicate that our proposed algorithm\ncan achieve a lower latency and higher processing rate than the conventional\nMEC scheme.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 03:07:41 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Wang", "Pengfei", ""], ["Zheng", "Zijie", ""], ["Di", "Boya", ""], ["Song", "Lingyang", ""]]}, {"id": "1901.09357", "submitter": "Abdulkadir Celik", "authors": "Abdulkadir Celik, Nasir Saeed, Basem Shihada, Tareq Y. Al-Naffouri,\n  Mohamed-Slim Alouini", "title": "End-to-End Performance Analysis of Underwater Optical Wireless Relaying\n  and Routing Techniques Under Location Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the contrary of low speed and high delay acoustic systems, underwater\noptical wireless communication (UOWC) can deliver a high speed and low latency\nservice at the expense of short communication ranges. Therefore, multihop\ncommunication is of utmost importance to improve degree of connectivity and\noverall performance of underwater optical wireless networks (UOWNs). In this\nregard, this paper investigates relaying and routing techniques and provides\ntheir end-to-end (E2E) performance analysis under the location uncertainty. To\nachieve robust and reliable links, we first consider adaptive beamwidths and\nderive the divergence angles under the absence and presence of a\npointing-acquisitioning-and-tracking (PAT) mechanism. Thereafter, important E2E\nperformance metrics (e.g., data rate, bit error rate, transmission power,\namplifier gain, etc.) are obtained for two potential relaying techniques;\ndecode & forward (DF) and optical amplify & forward (AF). We develop\ncentralized routing schemes for both relaying techniques to optimize E2E rate,\nbit error rate, and power consumption. Alternatively, a distributed routing\nprotocol, namely Light Path Routing (LiPaR), is proposed by leveraging the\nrange-beamwidth tradeoff of UOWCs. LiPaR is especially shown to be favorable\nwhen there is no PAT mechanism and available network information. In order to\nshow the benefits of multihop communications, extensive simulations are\nconducted to compare different routing and relaying schemes under different\nnetwork parameters and underwater environments.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 11:51:14 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Celik", "Abdulkadir", ""], ["Saeed", "Nasir", ""], ["Shihada", "Basem", ""], ["Al-Naffouri", "Tareq Y.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1901.09389", "submitter": "Narges Gholipoor", "authors": "Narges Gholipoor, Saeedeh Parsaeefard, Mohammad Reza Javan, Nader\n  Mokari, Hamid Saeedi, and Hossein Pishro-Nik", "title": "Cloud-based Queuing Model for Tactile Internet in Next Generation of RAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-low latency is the most important requirement of the Tactile Internet\n(TI), which is one of the proposed services for the next-generation wireless\nnetwork (NGWN), e.g., fifth generation (5G) network. In this paper, a new\nqueuing model for the TI is proposed for the cloud radio access network (CRAN)\narchitecture of the NGWN by applying power domain non-orthogonal multiple\naccess (PD-NOMA) technology. In this model, we consider both the radio remote\nhead (RRH) and baseband processing unit (BBU) queuing delays for each\nend-to-end (E2E) connection between a pair of tactile users. In our setup, to\nminimize the transmit power of users subject to guaranteeing an acceptable\ndelay of users, and fronthaul and access constraints, we formulate a resource\nallocation (RA) problem. Furthermore, we dynamically set the fronthaul and\naccess links to minimize the total transmit power. Given that the proposed RA\nproblem is highly non-convex, in order to solve it, we utilize diverse\ntransformation techniques such as successive convex approximation (SCA) and\ndifference of two convex functions (DC). Numerical results show that by dynamic\nadjustment of the access and fronthaul delays, transmit power reduces in\ncomparison with the fixed approach per each connection. Also, energy efficiency\nof orthogonal frequency division multiple access (OFDMA) and PD-NOMA are\ncompared for our setup.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 15:08:16 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 13:49:37 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 18:29:32 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Gholipoor", "Narges", ""], ["Parsaeefard", "Saeedeh", ""], ["Javan", "Mohammad Reza", ""], ["Mokari", "Nader", ""], ["Saeedi", "Hamid", ""], ["Pishro-Nik", "Hossein", ""]]}, {"id": "1901.09418", "submitter": "Kolar Purushothama Naveen", "authors": "K P Naveen and Rajesh Sundaresan", "title": "Double-Auction Mechanisms for Resource Trading Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a double-auction mechanism, which was recently proposed in the\ncontext of rate allocation in mobile data-offloading markets. Network operators\n(users) derive benefit from offloading their traffic to third party WiFi or\nfemtocell networks (link-suppliers). Link-suppliers experience costs for the\nadditional capacity that they provide. Users and link-suppliers (collectively\nreferred to as agents) have their pay-offs and cost functions as private\nknowledge. A network-manager decomposes the problem into a network problem and\nagent problems. The surrogate pay-offs and cost functions are modulated by the\nagents' bids. Agents' payoffs and costs are then determined by the allocations\nand prices set by the network-manager. Under this design, so long as the agents\ndo not anticipate the effect of their actions on the prices set by the\nnetwork-manager (i.e., price-taking agents), a competitive equilibrium exists\nas a solution to the network and agent problems, and this equilibrium optimizes\nthe sum utility of all agents. However, this design fails when the agents are\nall strategic (price-anticipating). Specifically, the presence of a strategic\nlink-supplier drives the system to an undesirable equilibrium with zero\nparticipation resulting in an efficiency loss of 100%. This is in stark\ncontrast to an earlier setting where the users alone are strategic but the\nlink-supplier is not - the efficiency loss is known to be at most 34%. The\npaper then proposes a Stackelberg game modification where the efficiency loss\ncan be characterized in terms of the link-supplier's cost function when the\nusers' pay-off functions are linear. Specifically, when the link-supplier's\ncost function is quadratic, the worst case efficiency loss is 25%. Further, the\nloss in efficiency improves for polynomial cost functions of higher degree.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 18:29:14 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 15:03:11 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Naveen", "K P", ""], ["Sundaresan", "Rajesh", ""]]}, {"id": "1901.09424", "submitter": "Ozan Alp Topal", "authors": "Ozan Alp Topal, Selen Gecgel, Ender Mete Eksioglu, Gunes Karabulut\n  Kurt", "title": "Identification of Smart Jammers: Learning based Approaches Using Wavelet\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart jammer nodes can disrupt communication between a transmitter and a\nreceiver in a wireless network, and they leave traces that are undetectable to\nclassical jammer identification techniques, hidden in the time-frequency plane.\nThese traces cannot be effectively identified through the use of the classical\nFourier transform based time-frequency transformation (TFT) techniques with a\nfixed resolution. Inspired by the adaptive resolution property provided by the\nwavelet transforms, in this paper, we propose a jammer identification\nmethodology that includes a pre-processing step to obtain a multi-resolution\nimage, followed by the use of a classifier. Support vector machine (SVM) and\ndeep convolutional neural network (DCNN) architectures are investigated as\nclassifiers to automatically extract the features of the transformed signals\nand to classify them. Three different jamming attacks are considered, the\nbarrage jamming that targets the complete transmission bandwidth, the\nsynchronization signal jamming attack that targets synchronization signals and\nthe reference signal jamming attack that targets the reference signals in an\nLTE downlink transmission scenario. The performance of the proposed approach is\ncompared with the classical Fourier transform based TFT techniques,\ndemonstrating the efficacy of the proposed approach in the presence of smart\njammers.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 19:37:45 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Topal", "Ozan Alp", ""], ["Gecgel", "Selen", ""], ["Eksioglu", "Ender Mete", ""], ["Kurt", "Gunes Karabulut", ""]]}, {"id": "1901.10021", "submitter": "Irmak Aykin", "authors": "Irmak Aykin and Ezhan Karasan", "title": "An Activity Management Algorithm for Improving Energy Efficiency of\n  Small Cell Base Stations in 5G Heterogeneous Networks", "comments": "Diss. bilkent university, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous networks (HetNets) are proposed in order to meet the increasing\ndemand for next generation cellular wireless networks, but they also increase\nthe energy consumption of the base stations. In this paper, an activity\nmanagement algorithm for improving the energy efficiency of HetNets is\nproposed. A smart sleep strategy is employed for the operator deployed pico\nbase stations to enter sleep and active modes. According to that strategy, when\nthe number of users exceeds the turn on threshold, the pico node becomes active\nand when the number of users drop below the turn off threshold, it goes into\nsleep mode. Mobile users dynamically enter and leave the cells, triggering the\nactivation and deactivation of pico base stations. The performance of the\nsystem is examined for three different cellular network architectures: cell on\nedge (COE), uniformly distributed cells (UDC) and macro cell only network\n(MoNet). Two different user distributions are considered: uniform and hotspot.\nThe effects of number of hotspot users and sleep energies of pico nodes on the\nenergy efficiency are also investigated. The proposed activity management\nalgorithm increases the energy efficiency, measured in bits/J, by $20\\%$. The\naverage bit rates achieved by HetNet users increase by $29\\%$ compared with the\nMoNet architecture. Thus, the proposed activity control algorithm increases the\nspectral efficiency of the network while consuming the energy more efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 22:37:47 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Aykin", "Irmak", ""], ["Karasan", "Ezhan", ""]]}, {"id": "1901.10048", "submitter": "Jingxin Wu", "authors": "Jingxin Wu", "title": "Resource Allocation in Multigranular Optical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thesis Statement: Cost-effective switching and spectrum utilization\nefficiency have become critical design considerations in optical networks. This\ndissertation provides in-depth exploration of these important aspects, and\nproposes effective techniques for low-cost switching architectures and resource\nallocation algorithms to facilitate the adoption of optical networks in the\nnear future.\n  The dramatic growth of Internet traffic brings challenges for optical network\ndesigners. The increasing traffic and bandwidth requirements mean that various\nresource allocation schemes to achieve different network design goals assume\ngreat importance. The general problem of resource allocation to lightpath\nrequests is a challenging problem.\n  An emerging technology of flexible and more fine-grained grid through the use\nof Optical Orthogonal Frequency Division Multiplexing (OOFDM) allows fiber\nbandwidth to be more suitably matched up with application requirements, thereby\nmaking the network more elastic than the conventional Wavelength Division\nMultiplexing (WDM) optical networks. Despite the advances of employing OOFDM\ntechnology in elastic optical networks (EONs), imminent fiber capacity\nexhaustion due to the ever-increasing demands means that multiple fibers per\nlink will be inevitable. While increasing the number of fibers boosts the\ncapacity of networks, there is a price to pay for it in the form of increased\nnumber of switch ports / complexity of switches. The huge amount of traffic\ndemands and thus high hardware requirements motivate multigranularity (such as\nwavebanding) to save costs in optical networks. This dissertation aims to\ntackle several types of resource allocation challenges in multi-granular\noptical networks to either improve the spectrum utilization or provide\ncost-effective switching techniques.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 00:30:34 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Wu", "Jingxin", ""]]}, {"id": "1901.10156", "submitter": "Benoit Donnet", "authors": "Yves Vanaubel, Jean-Romain Luttringer, Pascal M\\'erindol, Jean-Jacques\n  Pansiot, Benoit Donnet", "title": "TNT, Watch me Explode: A Light in the Dark for Revealing MPLS Tunnels", "comments": "TNT code, GNS3 scripts, data processing and analysis scripts, raw\n  data collected are available here:\n  http://www.montefiore.ulg.ac.be/~bdonnet/mpls", "journal-ref": "Published in Network Traffic Measurement and Analysis (TMA)\n  Conference 2019", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Internet topology discovery has been a recurrent research topic for nearly 20\nyears now. Usually, it works by sending hop-limited probes (i.e., traceroute)\ntowards a set of destinations to collect topological data in order to infer the\nInternet topology at a given scale (e.g., at the router or the AS level).\nHowever, traceroute comes with multiple limitations, in particular with layer-2\nclouds such as MPLS that might hide their content to traceroute exploration.\nThus, the resulting Internet topology data and models are incomplete and\ninaccurate.\n  In this paper, we introduce TNT (Trace the Naughty Tunnels), an extension to\nParis traceroute for revealing most (if not all) MPLS tunnels along a path. TNT\nworks in two basic stages. First, along with traceroute probes, it looks for\nevidences of the potential presence of hidden tunnels. Those evidences are\nsurprising patterns in the traceroute output, e.g., abrupt and significant TTL\nshifts. Second, if alarms are triggered due to the presence of such evidences,\nTNT launches additional and dedicated probing for possibly revealing the\ncontent of the hidden tunnel. We validate TNT through emulation with GNS3 and\ntune its parameters through a dedicated measurement campaign. We also largely\ndeploy TNT on the Archipelago platform and provide a quantification of tunnels,\nupdating so the state of the art vision of MPLS tunnels. Finally, TNT and its\nvalidation platform are fully and publicly available, as well as the collected\ndata and scripts used for processing data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 08:16:09 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 10:42:39 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Vanaubel", "Yves", ""], ["Luttringer", "Jean-Romain", ""], ["M\u00e9rindol", "Pascal", ""], ["Pansiot", "Jean-Jacques", ""], ["Donnet", "Benoit", ""]]}, {"id": "1901.10214", "submitter": "Rizanne Elbakly", "authors": "Rizanne Elbakly and Moustafa Youssef", "title": "Crescendo: An Infrastructure-free Ubiquitous Cellular Network-based\n  Localization System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A ubiquitous outdoor localization system that is easy to deploy and works\nequally well for all mobile devices is highly-desirable. The GPS, despite its\nhigh accuracy, cannot be reliably used for this purpose since it is not\navailable on low-end phones nor in areas with low satellite coverage. The\napplication of classical fingerprinting approaches, on the other hand, is\nprohibited by excessive maintenance and deployment costs. In this paper, we\npropose Crescendo, a cellular network-based outdoor localization system that\ndoes not require calibration or infrastructure support. Crescendo builds on\ntechniques borrowed from computational geometry to estimate the user's\nlocation. Specifically, given the network cells heard by the mobile device it\nleverages the Voronoi diagram of the network sites to provide an initial\nambiguity area and incrementally reduces this area by leveraging pairwise site\ncomparisons and visible cell information. Evaluation of Crescendo in both an\nurban and a rural area using real data shows median accuracies of 152m and\n224m, respectively. This is an improvement over classical techniques by at\nleast 18% and 15%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 10:46:20 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Elbakly", "Rizanne", ""], ["Youssef", "Moustafa", ""]]}, {"id": "1901.10274", "submitter": "Amjad Majid", "authors": "Amjad Yousef Majid, Michel Jansen, Guillermo Ortas Delgado, Kas{\\i}m\n  Sinan Y{\\i}ld{\\i}r{\\i}m, and Przemys{\\l}aw Pawe{\\l}czak", "title": "Multi-hop Backscatter Tag-to-Tag Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the performance of a backscatter tag-to-tag (T2T) multi-hop\nnetwork. For this, we developed a discrete component-based backscatter T2T\ntransceiver and a communication protocol suite. The protocol composed of a\nnovel (i) flooding-based link control tailored towards backscatter\ntransmission, and (ii) low-power listening MAC. The MAC design is based on the\nnew insight that backscatter reception is more energy costly than transmission.\nOur experiments show that multi-hopping extends the coverage of backscatter\nnetworks by enabling longer backward T2T links (tag far from the exciter\nsending to the tag close to the exciter). Four hops, for example, extend the\ncommunication range by a factor of two. Furthermore, we show that dead spots in\nmulti-hop T2T networks are far less significant than those in the single-hop\nT2T networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:28:02 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Majid", "Amjad Yousef", ""], ["Jansen", "Michel", ""], ["Delgado", "Guillermo Ortas", ""], ["Y\u0131ld\u0131r\u0131m", "Kas\u0131m Sinan", ""], ["Pawe\u0142czak", "Przemys\u0142aw", ""]]}, {"id": "1901.10388", "submitter": "Meng Zhang", "authors": "Meng Zhang and Jianwei Huang", "title": "Efficient Network Sharing with Asymmetric Constraint Information", "comments": "to appear in JSAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network sharing has become a key feature of various enablers of the next\ngeneration network, such as network function virtualization and fog computing\narchitectures. Network utility maximization (NUM) is a general framework for\nachieving fair, efficient, and cost-effective sharing of constrained network\nresources. When agents have asymmetric and private information, however, a\nfundamental economic challenge is how to solve the NUM Problem considering the\nself-interests of strategic agents. Many previous related works have proposed\neconomic mechanisms that can cope with agents' private utilities. However, the\nnetwork sharing paradigm introduces the issue of information asymmetries\nregarding constraints. The related literature largely neglected such an issue;\nlimited closely related studies provided solutions only applicable to specific\napplication scenarios. To tackle these issues, we propose the Decomposable NUM\n(DeNUM) Mechanism and the Dynamic DeNUM (DyDeNUM) Mechanism, the first\nmechanisms in the literature for solving NUM Problems considering private\nutility and constraint information. The key idea of both mechanisms is to\ndecentralize the decision process to agents, who will make resource allocation\ndecisions without the need of revealing private information to others. Under a\nmonitorable influence assumption, the DeNUM Mechanism yields the\nnetwork-utility maximizing solution at an equilibrium, and achieves other\ndesirable economic properties (such as individual rationality and budget\nbalance). We further establish the connection between the equilibrium structure\nand the primal-dual solution to a related optimization problem, based on which\nwe prove the convergence of the DeNUM Algorithm to an equilibrium. When the\nagents' influences are not monitorable, we propose the DyDeNUM Mechanism that\nyields the network-utility maximizing solution at the cost of the balanced\nbudget.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 16:54:06 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 13:11:14 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Zhang", "Meng", ""], ["Huang", "Jianwei", ""]]}, {"id": "1901.10441", "submitter": "Robert Beverly", "authors": "Robert Beverly and Mark Allman", "title": "An Internet Heartbeat", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining sound inferences over remote networks via active or passive\nmeasurements is difficult. Active measurement campaigns face challenges of\nload, coverage, and visibility. Passive measurements require a privileged\nvantage point. Even networks under our own control too often remain poorly\nunderstood and hard to diagnose. As a step toward the democratization of\nInternet measurement, we consider the inferential power possible were the\nnetwork to include a constant and predictable stream of dedicated lightweight\nmeasurement traffic. We posit an Internet \"heartbeat,\" which nodes periodically\nsend to random destinations, and show how aggregating heartbeats facilitates\nintrospection into parts of the network that are today generally obtuse. We\nexplore the design space of an Internet heartbeat, potential use cases,\nincentives, and paths to deployment.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 18:35:54 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Beverly", "Robert", ""], ["Allman", "Mark", ""]]}, {"id": "1901.10578", "submitter": "Solomia Fedushko", "authors": "Yuriy Syerov, Solomia Fedushko", "title": "The Computer-Linguistic Analysis of Socio-Demographic Profile of Virtual\n  Community Member", "comments": null, "journal-ref": "International Journal of Computer Science and Business\n  Informatics, 2013", "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers the current problem of investigation and development\nof computerlinguistic analysis of socio-demographic profile of virtual\ncommunity member. Webmembers' socio-demographic characteristics' profile\nvalidation based on analysis of sociodemographic characteristics. The\ntopicality of the paper is determined by the necessity to identify the\nweb-community member by means of computer-linguistic analysis of their\ninformation track. The formal model of basic socio-demographic characteristics\nof virtual communities' member is formed. The structural model of\nlingvo-communicative indicators of socio-demographic characteristics of the\nweb-members and common algorithm of the formation of lingvo-communicative\nindicators based on processing training sample are developed. Types of the\ncomputer-linguistic analysis of indicative characteristics are studied and\nclassifications of lingvo-communicative indicators of gender, age and sphere of\nactivities of web-community member is established. Also, the formal model of\nthe basic socio-demographic characteristics of web-communities' member is\nintroduced.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 20:27:30 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Syerov", "Yuriy", ""], ["Fedushko", "Solomia", ""]]}, {"id": "1901.10591", "submitter": "Taieb Hamza", "authors": "Taieb Hamza and Georges Kaddoum", "title": "Enhanced Minimal Scheduling Function for IEEE802.15.4e TSCH Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAC layer protocol design in a WSN is crucial due to the limitations on\nprocessing capacities and power of wireless sensors. The latest version of the\nIEEE 802.15.4, referenced to as IEEE 802.15.4e, was released by IEEE and\noutlines the mechanism of the Time Slotted Channel Hopping (TSCH). Hence,\n6TiSCH working group has released a distributed algorithm for neighbour nodes\nto agree on a communication pattern driven by a minimal scheduling function. A\nslotframe contains a specific number of time slots, which are scheduled based\non the application requirements and the routing topology. Sensors nodes use the\nschedule to determine when to transmit or to receive data. However, IEEE\n802.15.4e TSCH does not address the specifics on planning time slot scheduling.\nIn this paper, we propose a distributed Enhanced Minimal Scheduling Function\n(EMSF) based on the minimal scheduling function, which is compliant with\n802.15.4e TSCH. In this vein, we introduce a distributed algorithm based on a\nPoisson process to predict the following schedule requirements. Consequently,\nthe negotiation operations between pairs of nodes to agree about the schedule\nwill be reduced. As a result, EMSF decreases the exchanged overhead, the\nend-to-end latency and the packet queue length significantly. Preliminary\nsimulation results have confirmed that EMSF outperforms the 802.15.4e TSCH MSF\nscheduling algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 22:20:49 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Hamza", "Taieb", ""], ["Kaddoum", "Georges", ""]]}, {"id": "1901.10599", "submitter": "Daojing Guo", "authors": "Daojing Guo and I-Hong Hou", "title": "On the Credibility of Information Flows in Real-time Wireless Networks", "comments": "8 pages for WiOpt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a wireless network where multiple flows are delivering\nstatus updates about their respective information sources. An end user aims to\nmake accurate real-time estimations about the status of each information source\nusing its received packets. As the accuracy of estimation is most impacted by\nevents in the recent past, we propose to measure the credibility of an\ninformation flow by the number of timely deliveries in a window of the recent\npast, and say that a flow suffers from a loss-of-credibility (LoC) if this\nnumber is insufficient for the end user to make an accurate estimation.\n  We then study the problem of minimizing the system-wide LoC in wireless\nnetworks where each flow has different requirement and link quality. We show\nthat the problem of minimizing the system-wide LoC requires the control of\ntemporal variance of timely deliveries for each flow. This feature makes our\nproblem significantly different from other optimization problems that only\ninvolves the average of control variables. Surprisingly, we show that there\nexists a simple online scheduling algorithm that is near-optimal. Simulation\nresults show that our proposed algorithm is significantly better than other\nstate-of-the-art policies.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 22:52:46 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Guo", "Daojing", ""], ["Hou", "I-Hong", ""]]}, {"id": "1901.10646", "submitter": "Qizhen Li", "authors": "Qizhen Li", "title": "An Actor-Critic Reinforcement Learning Method for Computation Offloading\n  with Delay Constraints in Mobile Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a mobile edge computing system that provides\ncomputing services by cloud server and edge server collaboratively. The mobile\nedge computing can both reduce service delay and ease the load on the core\nnetwork. We model the problem of maximizing the average system revenues with\nthe average delay constraints for different priority service as a constrained\nsemi-Markov decision process (SMDP). We propose an actor-critic algorithm with\neligibility traces to solve the constrained SMDP. We use neural networks to\ntrain the policy parameters and the state value function's parameters to\ncontinuously improve the system performance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 02:24:08 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Li", "Qizhen", ""]]}, {"id": "1901.10664", "submitter": "Paul Emmerich", "authors": "Paul Emmerich, Maximilian Pudelko, Simon Bauer, Stefan Huber, Thomas\n  Zwickl, Georg Carle", "title": "User Space Network Drivers", "comments": "in ACM/IEEE Symposium on Architectures for Networking and\n  Communications Systems (ANCS 2019), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of user space packet processing frameworks like DPDK and netmap\nmakes low-level code more accessible to developers and researchers. Previously,\ndriver code was hidden in the kernel and rarely modified, or even looked at, by\ndevelopers working at higher layers. These barriers are gone nowadays, yet\ndevelopers still treat user space drivers as black-boxes magically accelerating\napplications. We want to change this: every researcher building high-speed\nnetwork applications should understand the intricacies of the underlying\ndrivers, especially if they impact performance. We present ixy, a user space\nnetwork driver designed for simplicity and educational purposes to show that\nfast packet IO is not black magic but careful engineering. ixy focuses on the\nbare essentials of user space packet processing: a packet forwarder including\nthe whole NIC driver uses less than 1,000 lines of C code.\n  This paper is partially written in tutorial style on the case study of our\nimplementations of drivers for both the Intel 82599 family and for virtual\nVirtIO NICs. The former allows us to reason about driver and framework\nperformance on a stripped-down implementation to assess individual\noptimizations in isolation. VirtIO support ensures that everyone can run it in\na virtual machine.\n  Our code is available as free and open source under the BSD license at\nhttps://github.com/emmericp/ixy\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 04:10:01 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 15:33:45 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Emmerich", "Paul", ""], ["Pudelko", "Maximilian", ""], ["Bauer", "Simon", ""], ["Huber", "Stefan", ""], ["Zwickl", "Thomas", ""], ["Carle", "Georg", ""]]}, {"id": "1901.10933", "submitter": "Poulmanogo Illy", "authors": "Poulmanogo Illy, Georges Kaddoum, Christian Miranda Moreira, Kuljeet\n  Kaur, Sahil Garg", "title": "Securing Fog-to-Things Environment Using Intrusion Detection System\n  Based On Ensemble Learning", "comments": "7 pages, 9 figures, IEEE Wireless Communications and Networking\n  Conference, Internet of Things, Intrusion detection systems", "journal-ref": "2019 IEEE Wireless Communications and Networking Conference (WCNC)", "doi": "10.1109/WCNC.2019.8885534", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing interest in the Internet of Things (IoT) applications is\nassociated with an augmented volume of security threats. In this vein, the\nIntrusion detection systems (IDS) have emerged as a viable solution for the\ndetection and prevention of malicious activities. Unlike the signature-based\ndetection approaches, machine learning-based solutions are a promising means\nfor detecting unknown attacks. However, the machine learning models need to be\naccurate enough to reduce the number of false alarms. More importantly, they\nneed to be trained and evaluated on realistic datasets such that their efficacy\ncan be validated on real-time deployments. Many solutions proposed in the\nliterature are reported to have high accuracy but are ineffective in real\napplications due to the non-representativity of the dataset used for training\nand evaluation of the underlying models. On the other hand, some of the\nexisting solutions overcome these challenges but yield low accuracy which\nhampers their implementation for commercial tools. These solutions are majorly\nbased on single learners and are therefore directly affected by the intrinsic\nlimitations of each learning algorithm. The novelty of this paper is to use the\nmost realistic dataset available for intrusion detection called NSL-KDD, and\ncombine multiple learners to build ensemble learners that increase the accuracy\nof the detection. Furthermore, a deployment architecture in a fog-to-things\nenvironment that employs two levels of classifications is proposed. In such\narchitecture, the first level performs an anomaly detection which reduces the\nlatency of the classification substantially, while the second level, executes\nattack classifications, enabling precise prevention measures. Finally, the\nexperimental results demonstrate the effectiveness of the proposed IDS in\ncomparison with the other state-of-the-arts on the NSL-KDD dataset.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 16:26:35 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Illy", "Poulmanogo", ""], ["Kaddoum", "Georges", ""], ["Moreira", "Christian Miranda", ""], ["Kaur", "Kuljeet", ""], ["Garg", "Sahil", ""]]}, {"id": "1901.11102", "submitter": "Derya Malak", "authors": "Derya Malak and Muriel M\\'edard and Edmund Yeh", "title": "Spatial Soft-Core Caching", "comments": "submitted, IEEE ISIT, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a decentralized spatial soft-core cache placement (SSCC) policy\nfor wireless networks. SSCC yields a spatially balanced sampling via negative\ndependence across caches, and can be tuned to satisfy cache size constraints\nwith high probability. Given a desired cache hit probability, we compare the\n95% confidence intervals of the required cache sizes for independent placement,\nhard-core placement and SSCC policies. We demonstrate that in terms of the\nrequired cache storage size, SSCC can provide up to more than 180% and 100%\ngains with respect to the independent and hard-core placement policies,\nrespectively. SSCC can be used to enable proximity-based applications such as\ndevice-to-device communications and peer-to-peer networking as it promotes the\nitem diversity and reciprocation among the nodes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 21:03:18 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Malak", "Derya", ""], ["M\u00e9dard", "Muriel", ""], ["Yeh", "Edmund", ""]]}, {"id": "1901.11133", "submitter": "Tao Li", "authors": "Jian Wang, Srinivas Peeta, Lili Lu, Tao Li", "title": "Multiclass Information Flow Propagation Control under Vehicle-to-Vehicle\n  Communication Environments", "comments": "Transportation Research Part B: Methodological, 2019", "journal-ref": null, "doi": "10.1016/j.trb.2019.09.005", "report-no": null, "categories": "cs.SY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing models for information flow propagation in a vehicle-to-vehicle\n(V2V) communications environment are descriptive. They lack capabilities to\ncontrol information flow, which may preclude their ability to meet application\nneeds, including the need to propagate different information types\nsimultaneously to different target locations within corresponding time delay\nbounds. This study proposes a queuing-based modeling approach to control the\npropagation of information flow of multiple classes. Two control parameters\nassociated with a vehicle are leveraged to control the propagation performance\nof different information classes. A two-layer model is developed to\ncharacterize the information flow propagation wave (IFPW) under the designed\nqueuing strategy. The upper layer is formulated as integro-differential\nequations to characterize the spatiotemporal information dissemination due to\nV2V communication. The lower layer characterizes the traffic flow dynamics\nusing the Lighthill-Whitham-Richards model. The analytical solution of the\nasymptotic density of informed vehicles and the necessary condition for\nexistence of the IFPW are derived for homogeneous traffic conditions. Numerical\nexperiments provide insights on the impact of the mean communication service\nrate on information spread and its spatial coverage. Further, a numerical\nsolution method is developed to solve the two-layer model, which aids in\nestimating the impacts of the control parameters in the queuing strategy on the\nIFPW speed under homogeneous and heterogeneous conditions. The proposed\nmodeling approach enables controlling the propagation of information of\ndifferent information classes to meet application needs, which can assist\ntraffic managers to design effective and efficient traffic management and\ncontrol strategies under V2V communications.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 01:26:44 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Wang", "Jian", ""], ["Peeta", "Srinivas", ""], ["Lu", "Lili", ""], ["Li", "Tao", ""]]}, {"id": "1901.11330", "submitter": "Ioana Suciu", "authors": "Ioana Suciu, Xavier Vilajosana, Ferran Adelantado", "title": "Aggressive Fragmentation Strategy for Enhanced Network Performance in\n  Dense LPWANs", "comments": "2018 IEEE 29th Annual International Symposium on Personal, Indoor and\n  Mobile Radio Communications (PIMRC)", "journal-ref": null, "doi": "10.1109/PIMRC.2018.8581051", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Low Power Wide Area Networks (LPWANs) are gaining ground in the IoT landscape\nand, in particular, for Industrial IoT applications. However, given the strict\nduty cycle restrictions (e.g. 1% in SubGHz bands) and the limited power supply\nof devices, requirements of some applications can not always be met. This paper\nanalyzes the potential of the combination of packet fragmentation -in the\ndirection of the IETF LPWAN working group- and negative group acknowledgement\n(NACK) in LoRaWAN networks, a widespread LPWAN technology. Results show that\nthe proposed strategy can lead to significant gains in terms of goodput and\nenergy efficiency under congested situations.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 12:35:17 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Suciu", "Ioana", ""], ["Vilajosana", "Xavier", ""], ["Adelantado", "Ferran", ""]]}, {"id": "1901.11509", "submitter": "Desong Bian", "authors": "Desong Bian, Murat Kuzlu, Manisa Pipattanasomporn, Saifur Rahman and\n  Di Shi", "title": "Performance Evaluation of Communication Technologies and Network\n  Structure for Smart Grid Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of an effective and reliable communication network supporting smart\ngrid applications requires a selection of appropriate communication\ntechnologies and protocols. The objective of this paper is to study and\nquantify the capabilities of an Advanced Metering Infrastructure (AMI) to\nsupport the simultaneous operation of major smart grid functions. These include\nsmart metering, price-induced controls, distribution automation, demand\nresponse and electric vehicle charging/discharging applications in terms of\nthroughput and latency. OPNET is used to simulate the performance of selected\ncommunication technologies and protocols. Research findings indicate that smart\ngrid applications can operate simultaneously by piggybacking on an existing AMI\ninfrastructure and still achieve their latency requirements.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:17:15 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Bian", "Desong", ""], ["Kuzlu", "Murat", ""], ["Pipattanasomporn", "Manisa", ""], ["Rahman", "Saifur", ""], ["Shi", "Di", ""]]}]