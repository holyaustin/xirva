[{"id": "2003.00059", "submitter": "Bin Hu", "authors": "Hamid Gharavi and Bin Hu", "title": "Deterministic Intra-Vehicle Communications: Timing and Synchronization", "comments": "6 pages, 7 figures, conference ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we power through to the future, in-vehicle communications reliance on\nspeed is becoming a challenging predicament. This is mainly due to the\never-increasing number of electronic control units (ECUs), which will continue\nto drain network capacity, hence further increasing bandwidth demand. For a\nwired network, a tradeoff between bandwidth requirement, reliability, and\ncost-effectiveness has been our main motivation in developing a high-speed\nnetwork architecture that is based on the integration of two time-triggered\nprotocols namely; Time Triggered Ethernet (TT-E) and Time Triggered Controller\nArea Network (TT-CAN). Therefore, as a visible example of an Internet of\nVehicles technology, we present a time triggered communication-based network\narchitecture. The new architecture can provide scalable integration of advanced\nfunctionalities, while maintaining safety and high reliability. To comply with\nthe bandwidth requirement, we consider high-speed TT-Ethernet as the main bus\n(i.e., backbone network) where sub-networks can use more cost-effective and\nlower bandwidth TT-CAN to communicate with other entities in the network via a\ngateway. The main challenge in the proposed network architecture has been to\nresolve interoperability between two entirely different time-triggered\nprotocols, especially in terms of timing and synchronization. In this paper, we\nfirst explore the main key drivers of the proposed architecture, which are\nbandwidth, reliability, and timeliness. We then demonstrate the effectiveness\nof our gateway design in providing full interoperability between the two\ntime-triggered protocols.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 20:47:20 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Gharavi", "Hamid", ""], ["Hu", "Bin", ""]]}, {"id": "2003.00118", "submitter": "Suat Mercan", "authors": "Dominik Danko, Suat Mercan, Mumin Cebe Kemal Akkaya", "title": "Assuring the Integrity of Videos from Wireless-based IoT Devices using\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology has drawn attention fromvarious communities. The\nunderlying consensus mechanism inBlockchain enables a myriad of applications\nfor the integrityassurance of stored data. In this paper, we utilize\nBlockchaintechnology to verify the authenticity of a video captured by\nastreaming IoT device for forensic investigation purposes. Theproposed approach\ncomputes the hash of video frames beforethey leave the IoT device and are\ntransferred to a remote basestation. To guarantee the transmission, we ensure\nthat this hashis sent through a TCP-based connection. The hash is then storedon\nmultiple nodes on a permissioned blockchain platform. Incase the video is\nmodified, the discrepancy will be detected byinvestigating the previously\nstored hash on the blockchain andcomparing it with the hash of the existing\nframe in question.In this work, we present the prototype as proof-of-concept\nwithexperiment results. The system has been tested on a RaspberryPi with\ndifferent quality of videos to evaluate performance. Theresults show that the\nconcept can be implemented with moderatevideo resolutions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 23:36:13 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Danko", "Dominik", ""], ["Mercan", "Suat", ""], ["Akkaya", "Mumin Cebe Kemal", ""]]}, {"id": "2003.00239", "submitter": "Cao Vien Phung", "authors": "Cao Vien Phung, Anna Engelmann, Thomas Kuerner and Admela Jukan", "title": "Improving THz Quality-of-Transmission with Systematic RLNC and Auxiliary\n  Channels", "comments": "7 pages, 6 figures, accepted at IEEE ICC'20 Workshop - TeraCom", "journal-ref": null, "doi": "10.1109/ICCWorkshops49005.2020.9145148", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel solution that can improve the quality of\nTHz transmission with systematic random linear network coding (sRLNC) and a\nlow-bitrate auxiliary channel. To minimize complexity of channel coding, we\ncomplement a generic low complexity FEC code by a low complexity sRLNC. To\nincrease the overall throughput of THz transmission, we propose to send the\nnative data and coding redundancy in parallel over 2 differently configured THz\nchannels, i.e., over 1 high bit rate main channel and 1 low bit rate low error\nrate auxiliary channel. The results show, that the main THz channel supported\nby low bit rate auxiliary channel can use a higher level modulation format and\nsent over longer distances with a higher throughput.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 11:34:36 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 16:13:10 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 08:22:39 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Phung", "Cao Vien", ""], ["Engelmann", "Anna", ""], ["Kuerner", "Thomas", ""], ["Jukan", "Admela", ""]]}, {"id": "2003.00243", "submitter": "Abanoub M. Girgis", "authors": "Abanoub M. Girgis, Jihong Park, Chen-Feng Liu, and Mehdi Bennis", "title": "Predictive Control and Communication Co-Design: A Gaussian Process\n  Regression Approach", "comments": "5 pages, 4 figures, submitted to IEEE SPAWC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Remote control over wireless connections is a key enabler for scalable\ncontrol systems consisting of multiple actuator-sensor pairs, i.e., control\nsystems, it entails two technical challenges. Due to the lack of wireless\nresources, only a limited number of control systems can be served, making the\nstate observations outdated. Further, even after scheduling, the state\nobservations received through wireless channels are distorted, hampering\ncontrol stability. To address these issues, in this article we propose a\nscheduling algorithm that guarantees the age-of-information (AoI) of the last\nreceived states. Meanwhile, for non-scheduled sensor-actuator pairs, we propose\na machine learning (ML) aided predictive control algorithm, in which states are\npredicted using a Gaussian process regression (GPR). Since the GPR prediction\ncredibility decreases with the AoI of the input data, both predictive control\nand AoI-based scheduler should be co-designed. Hence, we formulate a joint\nscheduling and transmission power optimization via the Lyapunov optimization\nframework. Numerical simulations corroborate that the proposed co-designed\npredictive control and AoI based scheduling achieves lower control errors,\ncompared to a benchmark scheme using a round-robin scheduler without state\nprediction.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 11:46:32 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Girgis", "Abanoub M.", ""], ["Park", "Jihong", ""], ["Liu", "Chen-Feng", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2003.00245", "submitter": "Cao Vien Phung", "authors": "Cao Vien Phung, Jasenka Dizdarevic and Admela Jukan", "title": "An Experimental Study of Network Coded REST HTTP in Dynamic IoT Systems", "comments": "7 pages, 5 figures, accepted at IEEE International Conference on\n  Communications (ICC), Dublin, Ireland, 2020", "journal-ref": null, "doi": "10.1109/ICC40277.2020.9149026", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  REST HTTP is the communication protocol of choice for software developers\ntoday. In IoT systems with unreliable connectivity, however, a stateless\nprotocol like REST HTTP needs to send a request message multiple times, and it\nonly stops the retransmissions when an acknowledgement arrives at the sender.\nIn our previous work, we studied the usage of random linear network coding\n(RLNC) for REST HTTP protocol to reducing the amount of unnecessarily\nretransmissions. In this paper, we experimentally validate the study and\nanalyze REST HTTP with and without RLNC in a simple testbed in dynamic IoT\nsystems. The measurements show notable improvements in bandwidth utilization in\nterms of reducing the retransmissions and delay when using network-coded REST\nHTTP.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 11:55:27 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 16:05:54 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Phung", "Cao Vien", ""], ["Dizdarevic", "Jasenka", ""], ["Jukan", "Admela", ""]]}, {"id": "2003.00294", "submitter": "Suat Mercan", "authors": "Suat Mercan, Enes Erdin, and Kemal Akkaya", "title": "Improving Sustainability of Cryptocurrency Payment Networks for IoT\n  Applications", "comments": null, "journal-ref": null, "doi": "10.1109/ICCWorkshops49005.2020.9145389", "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain-based cryptocurrencies received a lot of attention recently for\ntheir applications in many domains. IoT domain is one of such applications,\nwhich can utilize cryptocur-rencies for micro payments without compromising\ntheir payment privacy. However, long confirmation times of transactions and\nrelatively high fees hinder the adoption of cryptoccurency based\nmicro-payments. The payment channel networks is one of the proposed solutions\nto address these issue where nodes establish payment channels among themselves\nwithout writing on blockchain. IoT devices can benefit from such payment\nnetworks as long as they are capable of sustaining their overhead. Payment\nchannel networks pose unique characteristics as far as the routing problem is\nconcerned. Specifically, they should stay balanced to have a sustainable\nnetwork for maintaining payments for longer times, which is crucial for IoT\ndevices once they are deployed.In this paper, we present a payment channel\nnetwork design that aims to keep the channels balanced by using a common weight\npolicy across the network. We additionally propose using multi-point\nconnections to nodes for each IoT device for unbalanced payment scenarios. The\nexperiment results show that we can keep the channels in the network more\nequally balanced compared to the minimal fee approach. In addition, multiple\nconnections from IoT devices to nodes increase the success ratio significantly.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 16:33:25 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Mercan", "Suat", ""], ["Erdin", "Enes", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2003.00383", "submitter": "Xijun Wang", "authors": "Chao Xu, Xijun Wang, Howard H. Yang, Hongguang Sun, Tony Q. S. Quek", "title": "AoI and Energy Consumption Oriented Dynamic Status Updating in Caching\n  Enabled IoT Networks", "comments": "Accepted by IEEE INFOCOM 2020-AoI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caching has been regarded as a promising technique to alleviate energy\nconsumption of sensors in Internet of Things (IoT) networks by responding to\nusers' requests with the data packets stored in the edge caching node (ECN).\nFor real-time applications in caching enabled IoT networks, it is essential to\ndevelop dynamic status update strategies to strike a balance between the\ninformation freshness experienced by users and energy consumed by the sensor,\nwhich, however, is not well addressed. In this paper, we first depict the\nevolution of information freshness, in terms of age of information (AoI), at\neach user. Then, we formulate a dynamic status update optimization problem to\nminimize the expectation of a long term accumulative cost, which jointly\nconsiders the users' AoI and sensor's energy consumption. To solve this\nproblem, a Markov Decision Process (MDP) is formulated to cast the status\nupdating procedure, and a model-free reinforcement learning algorithm is\nproposed, with which the challenge brought by the unknown of the formulated\nMDP's dynamics can be addressed. Finally, simulations are conducted to validate\nthe convergence of our proposed algorithm and its effectiveness compared with\nthe zero-wait baseline policy.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 03:04:05 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xu", "Chao", ""], ["Wang", "Xijun", ""], ["Yang", "Howard H.", ""], ["Sun", "Hongguang", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2003.00384", "submitter": "Xijun Wang", "authors": "Wenrui Lin, Xijun Wang, Chao Xu, Xinghua Sun, Xiang Chen", "title": "Average Age of Changed Information in the Internet of Things", "comments": "Accepted by IEEE WCNC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The freshness of status updates is imperative in mission-critical Internet of\nthings (IoT) applications. Recently, Age of Information (AoI) has been proposed\nto measure the freshness of updates at the receiver. However, AoI only\ncharacterizes the freshness over time, but ignores the freshness in the\ncontent. In this paper, we introduce a new performance metric, Age of Changed\nInformation (AoCI), which captures both the passage of time and the change of\ninformation content. Also, we examine the AoCI in a time-slotted status update\nsystem, where a sensor samples the physical process and transmits the update\npackets with a cost. We formulate a Markov Decision Process (MDP) to find the\noptimal updating policy that minimizes the weighted sum of the AoCI and the\nupdate cost. Particularly, in a special case that the physical process is\nmodeled by a two-state discrete time Markov chain with equal transition\nprobability, we show that the optimal policy is of threshold type with respect\nto the AoCI and derive the closed-form of the threshold. Finally, simulations\nare conducted to exhibit the performance of the threshold policy and its\nsuperiority over the zero-wait baseline policy.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 03:05:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lin", "Wenrui", ""], ["Wang", "Xijun", ""], ["Xu", "Chao", ""], ["Sun", "Xinghua", ""], ["Chen", "Xiang", ""]]}, {"id": "2003.00391", "submitter": "Xijun Wang", "authors": "Mengjie Yi, Xijun Wang, Juan Liu, Yan Zhang, Bo Bai", "title": "Deep Reinforcement Learning for Fresh Data Collection in UAV-assisted\n  IoT Networks", "comments": "Accepted by IEEE INFOCOM 2020-AoI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the flexibility and low operational cost, dispatching unmanned aerial\nvehicles (UAVs) to collect information from distributed sensors is expected to\nbe a promising solution in Internet of Things (IoT), especially for\ntime-critical applications. How to maintain the information freshness is a\nchallenging issue. In this paper, we investigate the fresh data collection\nproblem in UAV-assisted IoT networks. Particularly, the UAV flies towards the\nsensors to collect status update packets within a given duration while\nmaintaining a non-negative residual energy. We formulate a Markov Decision\nProcess (MDP) to find the optimal flight trajectory of the UAV and transmission\nscheduling of the sensors that minimizes the weighted sum of the age of\ninformation (AoI). A UAV-assisted data collection algorithm based on deep\nreinforcement learning (DRL) is further proposed to overcome the curse of\ndimensionality. Extensive simulation results demonstrate that the proposed\nDRL-based algorithm can significantly reduce the weighted sum of the AoI\ncompared to other baseline algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 03:42:26 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Yi", "Mengjie", ""], ["Wang", "Xijun", ""], ["Liu", "Juan", ""], ["Zhang", "Yan", ""], ["Bai", "Bo", ""]]}, {"id": "2003.00474", "submitter": "Yue Xu", "authors": "Yue Xu, Feng Yin, Wenjun Xu, Chia-Han Lee, Jiaru Lin, Shuguang Cui", "title": "Scalable Learning Paradigms for Data-Driven Wireless Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The marriage of wireless big data and machine learning techniques\nrevolutionizes the wireless system by the data-driven philosophy. However, the\never exploding data volume and model complexity will limit centralized\nsolutions to learn and respond within a reasonable time. Therefore, scalability\nbecomes a critical issue to be solved. In this article, we aim to provide a\nsystematic discussion on the building blocks of scalable data-driven wireless\nnetworks. On one hand, we discuss the forward-looking architecture and\ncomputing framework of scalable data-driven systems from a global perspective.\nOn the other hand, we discuss the learning algorithms and model training\nstrategies performed at each individual node from a local perspective. We also\nhighlight several promising research directions in the context of scalable\ndata-driven wireless communications to inspire future research.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 12:13:58 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xu", "Yue", ""], ["Yin", "Feng", ""], ["Xu", "Wenjun", ""], ["Lee", "Chia-Han", ""], ["Lin", "Jiaru", ""], ["Cui", "Shuguang", ""]]}, {"id": "2003.00500", "submitter": "Seungmo Kim", "authors": "Seungmo Kim and Tsigigenet Dessalgn", "title": "Mitigation of Civilian-to-Military Interference in DSRC for Urban\n  Operations", "comments": null, "journal-ref": "The paper was presented at IEEE MILCOM 2019", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dedicated short-range communications (DSRC) attracts popularity in the\nmilitary applications thanks to its easiness in establishment, no need for paid\nsubscription, and wide compatibility with any other IEEE 802.11 standards. The\nmain challenge in DSRC is congestion due to existence of only 7 channels, which\nmay not be enough to accommodate the increased number of transmitters expected\nto be deployed in the near future. Recently, there are a myriad of urban\noperation scenarios for the military including urban warfare and humanitarian\nassistance/disaster relief (HA/DR). The key challenge is that the\ncommunications among the military vehicles can be interfered by civilian users.\nIt is the desire that the messages transmitted by the military vehicles hold a\nhigher significance so that they can avoid the interference coming from the\ncivilian users, which is not supported in the current version of DSRC. As a\nremedy, this paper proposes a protocol that prioritizes the military DSRC users\nwhile muffling the civilian DSRC users. Our results show that this\nprioritization method achieves higher communications performances for the\nmilitary DSRC users.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 15:11:15 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Kim", "Seungmo", ""], ["Dessalgn", "Tsigigenet", ""]]}, {"id": "2003.00645", "submitter": "Yusuke Koda", "authors": "Yusuke Koda, Jihong Park, Mehdi Bennis, Koji Yamamoto, Takayuki\n  Nishio, Masahiro Morikura", "title": "Communication-Efficient Multimodal Split Learning for mmWave Received\n  Power Prediction", "comments": "5 pages, 7 figures, to be published at IEEE Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this study is to improve the accuracy of millimeter wave received\npower prediction by utilizing camera images and radio frequency (RF) signals,\nwhile gathering image inputs in a communication-efficient and\nprivacy-preserving manner. To this end, we propose a distributed multimodal\nmachine learning (ML) framework, coined multimodal split learning (MultSL), in\nwhich a large neural network (NN) is split into two wirelessly connected\nsegments. The upper segment combines images and received powers for future\nreceived power prediction, whereas the lower segment extracts features from\ncamera images and compresses its output to reduce communication costs and\nprivacy leakage. Experimental evaluation corroborates that MultSL achieves\nhigher accuracy than the baselines utilizing either images or RF signals.\nRemarkably, without compromising accuracy, compressing the lower segment output\nby 16x yields 16x lower communication latency and 2.8% less privacy leakage\ncompared to the case without compression.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 03:58:35 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 03:17:30 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Koda", "Yusuke", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Yamamoto", "Koji", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""]]}, {"id": "2003.00713", "submitter": "Osama Bushnaq", "authors": "Osama M. Bushnaq, Mustafa A. Kishk, Abdulkadir \\c{C}elik, Mohamed-Slim\n  Alouini, Tareq Y. Al-Naffouri", "title": "Optimal Deployment of Tethered Drones for Maximum Cellular Coverage in\n  User Clusters", "comments": "Accepted at the IEEE Transaction on Wireless Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicle (UAV) assisted cellular communication is gaining\nsignificant interest recently. Although it offers several advantages over\nterrestrial communication, UAV communication suffers from two main\nshortcomings. The typical untethered UAV (uUAV) has a limited battery power\nsupply and therefore limited flying time, and it needs an extra wireless\nbackhaul link to connect users to the core network. In this paper, we propose\nthe utilization of the tethered UAV (tUAV) to assist the cellular network,\nwhere the tether provides power supply and connects the tUAV to the core\nnetwork through high capacity link. The tUAV however has a limited mobility due\nto the limited tether length. A stochastic geometry-based analysis is provided\nfor the coverage probability of an UAV-assisted cellular network where the\nmobile users located within a circular hot-spot. For that setup, we analyze and\ncompare two scenarios: (i) utilizing uUAV and (ii) utilizing tUAV, for\noffloading the terrestrial base station (TBS). We capture the aforementioned\nlimitations of each of the uUAV and the tUAV in our analysis. A novel user\nassociation analysis is provided given the TBS and the UAV locations. Next, we\nstudy the optimal locations of the uUAV and the tUAV to maximize the coverage\nprobability. Multiple useful insights are revealed. For instance, numerical\nresults show that tUAVs outperform uUAVs when the tether length is above 75 m,\ngiven that the uUAV is available for 80% of the time due to its battery\nlimitations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 08:37:07 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 07:02:13 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 13:58:06 GMT"}, {"version": "v4", "created": "Mon, 16 Nov 2020 19:29:48 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Bushnaq", "Osama M.", ""], ["Kishk", "Mustafa A.", ""], ["\u00c7elik", "Abdulkadir", ""], ["Alouini", "Mohamed-Slim", ""], ["Al-Naffouri", "Tareq Y.", ""]]}, {"id": "2003.00774", "submitter": "Juli\\'an Fern\\'andez-Navajas", "authors": "Pedro Forton, Jose M Saldana, Julian Fernandez-Navajas, Jose Ruiz-Mas", "title": "Interfaz Grafica para la Gestion SDWN de un Entorno WLAN", "comments": "in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a graphical interface for the management of a wireless\nlocal area network that integrates a set of coordinated Wi-Fi access points.\nThe interface interacts with a network application that is responsible for load\nbalancing and mobility management. The graphical application is able to obtain\nand display the information stored in a system that includes a number of access\npoints, and displays it in a friendly way for the network manager. Finally, the\napplication allows remote management of the system, adjusting its parameters or\nmaking transfers between access points.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 11:31:44 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 15:39:20 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Forton", "Pedro", ""], ["Saldana", "Jose M", ""], ["Fernandez-Navajas", "Julian", ""], ["Ruiz-Mas", "Jose", ""]]}, {"id": "2003.00829", "submitter": "Mohammad Sayad Haghighi", "authors": "Mohammad Sayad Haghighi", "title": "Critical Study of Markovian Approaches for Batch Arrival Modeling in\n  IEEE 802.15.4-based Networks", "comments": "This is a lightly updated version of a technical report published in\n  2013", "journal-ref": null, "doi": null, "report-no": "1204-495-2019", "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transient non-stationary nature of network reaction to batch arrivals has\nled to complex models in order to estimate the network quantities of interest.\nIn this report we focus on the IEEE 802.15.4 standard MAC layer and try to\ndeeply study the current approaches in modeling the network reaction to\none-shot data arrivals. In addition to the general description of models, we\nmention the positive and negative points in each case proposing possible\nalternations which could improve the accuracy of the models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:12:17 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Haghighi", "Mohammad Sayad", ""]]}, {"id": "2003.00860", "submitter": "Amir Mosavi Prof", "authors": "Aaqif Afzaal Abbasi, Shahab Shamshirband, Mohammed A. A. Al-qaness,\n  Almas Abbasi, Nashat T. AL-Jallad, Amir Mosavi", "title": "Resource-Aware Network Topology Management Framework", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloud infrastructure provides computing services where computing resources\ncan be adjusted on-demand. However, the adoption of cloud infrastructures\nbrings concerns like reliance on the service provider network, reliability,\ncompliance for service level agreements. Software-defined networking (SDN) is a\nnetworking concept that suggests the segregation of a network data plane from\nthe control plane. This concept improves networking behavior. In this paper, we\npresent an SDN-enabled resource-aware topology framework. The proposed\nframework employs SLA compliance, Path Computation Element (PCE) and shares\nfair loading to achieve better topology features. We also present an\nevaluation, showcasing the potential of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 11:53:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Abbasi", "Aaqif Afzaal", ""], ["Shamshirband", "Shahab", ""], ["Al-qaness", "Mohammed A. A.", ""], ["Abbasi", "Almas", ""], ["AL-Jallad", "Nashat T.", ""], ["Mosavi", "Amir", ""]]}, {"id": "2003.00866", "submitter": "Dinh Nguyen", "authors": "Dinh C. Nguyen, Peng Cheng, Ming Ding, David Lopez-Perez, Pubudu N.\n  Pathirana, Jun Li, Aruna Seneviratne, Yonghui Li, H. Vincent Poor", "title": "Enabling AI in Future Wireless Networks: A Data Life Cycle Perspective", "comments": "Accepted at the IEEE Communications Surveys & Tutorials, 42 pages", "journal-ref": null, "doi": "10.1109/COMST.2020.3024783", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have seen rapid deployment of mobile computing and Internet of\nThings (IoT) networks, which can be mostly attributed to the increasing\ncommunication and sensing capabilities of wireless systems. Big data analysis,\npervasive computing, and eventually artificial intelligence (AI) are envisaged\nto be deployed on top of the IoT and create a new world featured by data-driven\nAI. In this context, a novel paradigm of merging AI and wireless\ncommunications, called Wireless AI that pushes AI frontiers to the network\nedge, is widely regarded as a key enabler for future intelligent network\nevolution. To this end, we present a comprehensive survey of the latest studies\nin wireless AI from the data-driven perspective. Specifically, we first propose\na novel Wireless AI architecture that covers five key data-driven AI themes in\nwireless networks, including Sensing AI, Network Device AI, Access AI, User\nDevice AI and Data-provenance AI. Then, for each data-driven AI theme, we\npresent an overview on the use of AI approaches to solve the emerging\ndata-related problems and show how AI can empower wireless network\nfunctionalities. Particularly, compared to the other related survey papers, we\nprovide an in-depth discussion on the Wireless AI applications in various\ndata-driven domains wherein AI proves extremely useful for wireless network\ndesign and optimization. Finally, research challenges and future visions are\nalso discussed to spur further research in this promising area.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 23:38:07 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 09:08:18 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Nguyen", "Dinh C.", ""], ["Cheng", "Peng", ""], ["Ding", "Ming", ""], ["Lopez-Perez", "David", ""], ["Pathirana", "Pubudu N.", ""], ["Li", "Jun", ""], ["Seneviratne", "Aruna", ""], ["Li", "Yonghui", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2003.00869", "submitter": "Fateme Sarkohaki", "authors": "Fatemeh Sarkohaki, Reza Fotohi, Vahab Ashrafian", "title": "An Efficient Routing Protocol in Mobile Ad-hoc Networks by using\n  Artificial Immune System", "comments": "8 pages, 10 figures, journal", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications (IJACSA), 8(4), 554-561 (2017)", "doi": "10.14569/IJACSA.2017.080473", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characteristics of the mobile ad-hoc networks such as nodes high mobility and\nlimited energy are regarded as the routing challenges in these networks. OLSR\nprotocol is one of the routing protocols in mobile ad hoc network that selects\nthe shortest route between source and destination through Dijkstra's algorithm.\nHowever, OLSR suffers from a major problem. It does not consider parameters\nsuch as nodes energy level and links length in its route processing. This paper\nemploys the artificial immune system (AIS) to enhance efficiency of OLSR\nrouting protocol. The proposed algorithm, called AIS-OLSR, considers hop count,\nremaining energy in the intermediate nodes, and distance among node, which is\nrealized by negative selection and ClonalG algorithms of AIS. Widespread packet\n- level simulation in ns-2 environment, shows that AIS-OLSR outperforms OLSR\nand EA-OLSR in terms of packet delivery ratio, throughput, end-end delay and\nlifetime.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:56:08 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Sarkohaki", "Fatemeh", ""], ["Fotohi", "Reza", ""], ["Ashrafian", "Vahab", ""]]}, {"id": "2003.00870", "submitter": "Shahram Behzad", "authors": "Shahram Behzad, Reza Fotohi, Jaber Hosseini Balov, Mohammad Javad\n  Rabipour", "title": "An Artificial Immune Based Approach for Detection and Isolation\n  Misbehavior Attacks in Wireless Networks", "comments": "19 pages, 12 figures, Journal", "journal-ref": "JCP, 13(6), 705-720 (2018)", "doi": "10.17706/jcp.13.6.705-720", "report-no": null, "categories": "cs.NI cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MANETs (Mobile Ad-hoc Networks) is a temporal network, which is managed by\nautonomous nodes, which have the ability to communicate with each other without\nhaving fixed network infrastructure or any central base station. Due to some\nreasons such as dynamic changes of the network topology, trusting the nodes to\neach other, lack of fixed substructure for the analysis of nodes behaviors and\nloss of specific offensive lines, this type of networks is not supportive\nagainst malicious nodes attacks. One of these attacks is black hole attack. In\nthis attack, the malicious nodes absorb data packets and destroy them. Thus, it\nis essential to present an algorithm against the black hole attacks. This paper\nproposed a new approach, which improvement the security of DSR routing protocol\nto encounter the black hole attacks. This schema tries to identify malicious\nnodes according to nodes behaviors in a MANETs and isolate them from routing.\nThe proposed protocol, called AIS-DSR (Artificial Immune System DSR) employ AIS\n(Artificial Immune System) to defend against black hole attacks. AIS-DSR is\nevaluated through extensive simulations in the ns-2 environment. The results\nshow that AIS-DSR outperforms other existing solutions in terms of throughput,\nend-to-end delay, packets loss ratio and packets drop ratio.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:27:19 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Behzad", "Shahram", ""], ["Fotohi", "Reza", ""], ["Balov", "Jaber Hosseini", ""], ["Rabipour", "Mohammad Javad", ""]]}, {"id": "2003.00971", "submitter": "Philip Kulp", "authors": "Philip H. Kulp and Nikki E. Robinson", "title": "Graphing Website Relationships for Risk Prediction: Identifying Derived\n  Threats to Users Based on Known Indicators", "comments": "10 pages, 3 figures, 3 tables", "journal-ref": null, "doi": "10.1007/978-3-030-63089-8", "report-no": null, "categories": "cs.CR cs.DB cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypothesis for the study was that the relationship based on referrer\nlinks and the number of hops to a malicious site could indicate the risk to\nanother website. We chose Receiver Operating Characteristics (ROC) analysis as\nthe method of comparing true positive and false positive rates for captured web\ntraffic to test the predictive capabilities of our model. Known threat\nindicators were used as designators, and the Neo4j graph database was leveraged\nto map the relationships between other websites based on referring links. Using\nthe referring traffic, we mapped user visits across websites with a known\nrelationship to track the rate at which users progressed from a non-malicious\nwebsite to a known threat. The results were grouped by the hop distance from\nthe known threat to calculate the predictive rate. The results of the model\nproduced true positive rates between 58.59% and 63.45% and false positive rates\nbetween 7.42% to 37.50%, respectively. The true and false positive rates\nsuggest an improved performance based on the closer proximity from the known\nthreat, while an increased referring distance from the threat resulted in\nhigher rates of false positives.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 15:41:48 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Kulp", "Philip H.", ""], ["Robinson", "Nikki E.", ""]]}, {"id": "2003.01005", "submitter": "Md Ferdous Pervej", "authors": "Md Ferdous Pervej, Shih-Chun Lin", "title": "Eco-Vehicular Edge Networks for Connected Transportation: A Distributed\n  Multi-Agent Reinforcement Learning Approach", "comments": "Accepted for publication in VTC2020-Fall; the title is slightly\n  modified from the earlier versions to characterize this work more accurately", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an energy-efficient, software-defined vehicular edge\nnetwork for the growing intelligent connected transportation system. A joint\nuser-centric virtual cell formation and resource allocation problem is\ninvestigated to bring eco-solutions at the edge. This joint problem aims to\ncombat against the power-hungry edge nodes while maintaining assured\nreliability and data rate. More specifically, by prioritizing the downlink\ncommunication of dynamic eco-routing, highly mobile autonomous vehicles are\nserved with multiple low-powered access points (APs) simultaneously for\nubiquitous connectivity and guaranteed reliability of the network. The\nformulated optimization is exceptionally troublesome to solve within a\npolynomial time, due to its complicated combinatorial structure. Hence, a\ndistributed multi-agent reinforcement learning (D-MARL) algorithm is proposed\nfor eco-vehicular edges, where multiple agents cooperatively learn to receive\nthe best reward. First, the algorithm segments the centralized action space\ninto multiple smaller groups. Based on the model-free distributed Q learner,\neach edge agent takes its actions from the respective group. Also, in each\nlearning state, a software-defined controller chooses the global best action\nfrom individual bests of the distributed agents. Numerical results validate\nthat our learning solution achieves near-optimal performances within a small\nnumber of training episodes as compared with existing baselines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:34:14 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 19:40:22 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 06:01:46 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Pervej", "Md Ferdous", ""], ["Lin", "Shih-Chun", ""]]}, {"id": "2003.01107", "submitter": "Prajoy Podder", "authors": "Arnab Paul, Mamdudul Haque Khan, M. Muktadir Rahman, Tanvir Zaman\n  Khan, Prajoy Podder and Md. Yeasir Akram Khan", "title": "Reconfigurable Parallel Architecture of High Speed Round Robin Arbiter", "comments": "Published in 2015 International Conference on Electrical,\n  Electronics, Signals, Communication and Optimization (EESCO)", "journal-ref": "2015 International Conference on Electrical, Electronics, Signals,\n  Communication and Optimization (EESCO)", "doi": "10.1109/EESCO.2015.7253744", "report-no": "15438813", "categories": "cs.DC cs.NI cs.OS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With a view to managing the increasing traffic in computer networks, round\nrobin arbiter has been proposed to work with packet switching system to have\nincreased speed in providing access and scheduling. Round robin arbiter is a\ndoorway to a particular bus based on request along with equal priority and\ngives turns to devices connected to it in a cyclic order. Considering the rapid\ngrowth in computer networking and the emergence of computer automation which\nwill need much more access to the existing limited resources, this paper\nemphasizes on designing a reconfigurable round robin arbiter over FPGA which\ntakes parallel requests and processes them with high efficiency and less delay\nthan existing designs. Proposed round robin arbiter encounters with 4 to 12\ndevices. Results show that with 200% increment in the number of connected\ndevices, only 2.69% increment has been found in the delay. With less delay,\nproposed round robin arbiter exhibits high speed performance with higher\ntraffic, which is a new feature in comparison with the existing designs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 05:33:23 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Paul", "Arnab", ""], ["Khan", "Mamdudul Haque", ""], ["Rahman", "M. Muktadir", ""], ["Khan", "Tanvir Zaman", ""], ["Podder", "Prajoy", ""], ["Khan", "Md. Yeasir Akram", ""]]}, {"id": "2003.01310", "submitter": "Anirban Das", "authors": "Anirban Das, Shigeru Imai, Mike P. Wittie, Stacy Patterson", "title": "Performance Optimization for Edge-Cloud Serverless Platforms via Dynamic\n  Task Placement", "comments": "10 pages, 6 figures, 20th IEEE/ACM International Symposium on\n  Cluster, Cloud and Internet Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for performance optimization in serverless edge-cloud\nplatforms using dynamic task placement. We focus on applications for smart edge\ndevices, for example, smart cameras or speakers, that need to perform\nprocessing tasks on input data in real to near-real time. Our framework allows\nthe user to specify cost and latency requirements for each application task,\nand for each input, it determines whether to execute the task on the edge\ndevice or in the cloud. Further, for cloud executions, the framework identifies\nthe container resource configuration needed to satisfy the performance goals.\nWe have evaluated our framework in simulation using measurements collected from\nserverless applications in AWS Lambda and AWS Greengrass. In addition, we have\nimplemented a prototype of our framework that runs in these same platforms. In\nexperiments with our prototype, our models can predict average end-to-end\nlatency with less than 6% error, and we obtain almost three orders of magnitude\nreduction in end-to-end latency compared to edge-only execution.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 03:18:45 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 20:57:25 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Das", "Anirban", ""], ["Imai", "Shigeru", ""], ["Wittie", "Mike P.", ""], ["Patterson", "Stacy", ""]]}, {"id": "2003.01344", "submitter": "Haijian Sun", "authors": "Haijian Sun, Xiang Ma, Rose Qingyang Hu", "title": "Adaptive Federated Learning With Gradient Compression in Uplink NOMA", "comments": "submitted to IEEE for possible future publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging machine learning technique that\naggregates model attributes from a large number of distributed devices. Several\nunique features such as energy saving and privacy preserving make FL a highly\npromising learning approach for power-limited and privacy sensitive devices.\nAlthough distributed computing can lower down the information amount that needs\nto be uploaded, model updates in FL can still experience performance\nbottleneck, especially for updates via wireless connections. In this work, we\ninvestigate the performance of FL update with mobile edge devices that are\nconnected to the parameter server (PS) with practical wireless links, where\nuplink update from user to PS has very limited capacity. Different from the\nexisting works, we apply non-orthogonal multiple access (NOMA) together with\ngradient compression in the wireless uplink. Simulation results show that our\nproposed scheme can significantly reduce aggregation latency while achieving\nsimilar accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 05:33:02 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Sun", "Haijian", ""], ["Ma", "Xiang", ""], ["Hu", "Rose Qingyang", ""]]}, {"id": "2003.01391", "submitter": "Marco Giordani", "authors": "Matilde Boschiero, Marco Giordani, Michele Polese, Michele Zorzi", "title": "Coverage Analysis of UAVs in Millimeter Wave Networks: A Stochastic\n  Geometry Approach", "comments": "7 pages, 3 figures, 2 tables. Submitted to IWCMC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in robotics and communication technologies are paving the\nway towards the use of Unmanned Aerial Vehicles (UAVs) to provide ubiquitous\nconnectivity in public safety scenarios or in remote areas. The millimeter wave\n(mmWave) spectrum, in particular, has gained momentum since the huge amount of\nfree spectrum available at such frequencies can yield very high data rates. In\nthe UAV context, however, mmWave operations may incur severe signal attenuation\nand sensitivity to blockage, especially considering the very long transmission\ndistances involved. In this paper, we present a tractable stochastic analysis\nto characterize the coverage probability of UAV stations operating at mmWaves.\nWe exemplify some of the trade-offs to be considered when designing solutions\nfor millimeter wave (mmWave) scenarios, such as the beamforming configuration,\nand the UAV altitude and deployment.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 08:36:41 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Boschiero", "Matilde", ""], ["Giordani", "Marco", ""], ["Polese", "Michele", ""], ["Zorzi", "Michele", ""]]}, {"id": "2003.01394", "submitter": "Elene Anton", "authors": "Elene Anton (IRIT-RMESS, Toulouse INP), Urtzi Ayesta (IRIT-RMESS,\n  Toulouse INP, Ikerbasque, UPV/EHU), Matthieu Jonckheere, Ina Verloop\n  (IRIT-RMESS, Toulouse INP)", "title": "Improving the performance of heterogeneous data centers through\n  redundancy", "comments": null, "journal-ref": "Proceedings of the ACM on Measurement and Analysis of Computing\n  Systems , ACM, 2020, 4 (3), pp.1-29", "doi": "10.1145/3428333", "report-no": null, "categories": "cs.NI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the performance of redundancy in a multi-type job and multi-type\nserver system. We assume the job dispatcher is unaware of the servers'\ncapacities, and we set out to study under which circumstances redundancy\nimproves the performance. With redundancy an arriving job dispatches redundant\ncopies to all its compatible servers, and departs as soon as one of its copies\ncompletes service. As a benchmark comparison, we take the non-redundant system\nin which a job arrival is routed to only one randomly selected compatible\nserver. Service times are generally distributed and all copies of a job are\nidentical, i.e., have the same service requirement. In our first main result,\nwe characterize the sufficient and necessary stability conditions of the\nredundancy system. This condition coincides with that of a system where each\njob type only dispatches copies into its least-loaded servers, and those copies\nneed to be fully served. In our second result, we compare the stability regions\nof the system under redundancy to that of no redundancy. We show that if the\nserver's capacities are sufficiently heterogeneous, the stability region under\nredundancy can be much larger than that without redundancy. We apply the\ngeneral solution to particular classes of systems, including redundancy-d and\nnested models, to derive simple conditions on the degree of heterogeneity\nrequired for redundancy to improve the stability. As such, our result is the\nfirst in showing that redundancy can improve the stability and hence\nperformance of a system when copies are non-i.i.d..\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 08:58:23 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 15:58:15 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Anton", "Elene", "", "IRIT-RMESS, Toulouse INP"], ["Ayesta", "Urtzi", "", "IRIT-RMESS,\n  Toulouse INP, Ikerbasque, UPV/EHU"], ["Jonckheere", "Matthieu", "", "IRIT-RMESS, Toulouse INP"], ["Verloop", "Ina", "", "IRIT-RMESS, Toulouse INP"]]}, {"id": "2003.01492", "submitter": "Szymon Szott", "authors": "Witold Wydma\\'nski and Szymon Szott", "title": "Contention Window Optimization in IEEE 802.11ax Networks with Deep\n  Reinforcement Learning", "comments": "6 pages, 6 figures, accepted for IEEE WCNC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proper setting of contention window (CW) values has a significant impact\non the efficiency of Wi-Fi networks. Unfortunately, the standard method used by\n802.11 networks is not scalable enough to maintain stable throughput for an\nincreasing number of stations, yet it remains the default method of channel\naccess for 802.11ax single-user transmissions. Therefore, we propose a new\nmethod of CW control, which leverages deep reinforcement learning (DRL)\nprinciples to learn the correct settings under different network conditions.\nOur method, called centralized contention window optimization with DRL (CCOD),\nsupports two trainable control algorithms: deep Q-network (DQN) and deep\ndeterministic policy gradient (DDPG). We demonstrate through simulations that\nit offers efficiency close to optimal (even in dynamic topologies) while\nkeeping computational cost low.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 13:04:27 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 14:25:14 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 10:30:26 GMT"}, {"version": "v4", "created": "Fri, 22 Jan 2021 13:53:36 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Wydma\u0144ski", "Witold", ""], ["Szott", "Szymon", ""]]}, {"id": "2003.01570", "submitter": "Seungmo Kim", "authors": "John Verboom and Seungmo Kim", "title": "Stochastic Analysis on Downlink Performance of Coexistence between WiGig\n  and NR-U in 60 GHz Band", "comments": "This paper will be submitted to IEEE VTC 2020 Fall", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 60 GHz band (57-71 GHz) has been attracting considerable research\ninterest thanks to the bandwidth abundance and ruling as an unlicensed band.\nThe 60 GHz Wi-Fi (also known as WiGig) and 5G New Radio Unlicensed (NR-U) are\namong the key access technologies that will operate in the band. This paper\ninspects the downlink performance of the two technologies under\ninter-technology interference from each other in 60 GHz band. Based on a dense\nsmall-cell setting, this paper finds stochastic models for\nsignal-to-interference-plus-noise ratio (SINR) and data rate. Via simulations,\nthis paper discovers that the downlink SINR and data rate follow Gaussian\nmixture distributions with three modes representing (i) severely interfered,\n(ii) mildly interfered, and (iii) not interfered UEs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 03:08:38 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Verboom", "John", ""], ["Kim", "Seungmo", ""]]}, {"id": "2003.01648", "submitter": "Pedro Casas Dr.", "authors": "Alessandro D'Alconzo, Idilio Drago, Andrea Morichetta, Marco Mellia,\n  Pedro Casas", "title": "A Survey on Big Data for Network Traffic Monitoring and Analysis", "comments": null, "journal-ref": "IEEE Transactions on Network and Service Management, vol. 16, no.\n  3, pp. 800-813, Sept. 2019", "doi": "10.1109/TNSM.2019.2933358", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Traffic Monitoring and Analysis (NTMA) represents a key component for\nnetwork management, especially to guarantee the correct operation of\nlarge-scale networks such as the Internet. As the complexity of Internet\nservices and the volume of traffic continue to increase, it becomes difficult\nto design scalable NTMA applications. Applications such as traffic\nclassification and policing require real-time and scalable approaches. Anomaly\ndetection and security mechanisms require to quickly identify and react to\nunpredictable events while processing millions of heterogeneous events. At\nlast, the system has to collect, store, and process massive sets of historical\ndata for post-mortem analysis. Those are precisely the challenges faced by\ngeneral big data approaches: Volume, Velocity, Variety, and Veracity. This\nsurvey brings together NTMA and big data. We catalog previous work on NTMA that\nadopt big data approaches to understand to what extent the potential of big\ndata is being explored in NTMA. This survey mainly focuses on approaches and\ntechnologies to manage the big NTMA data, additionally briefly discussing big\ndata analytics (e.g., machine learning) for the sake of NTMA. Finally, we\nprovide guidelines for future work, discussing lessons learned, and research\ndirections.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 17:17:36 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["D'Alconzo", "Alessandro", ""], ["Drago", "Idilio", ""], ["Morichetta", "Andrea", ""], ["Mellia", "Marco", ""], ["Casas", "Pedro", ""]]}, {"id": "2003.01670", "submitter": "Pedro Casas Dr.", "authors": "Andrea Morichetta, Pedro Casas, Marco Mellia", "title": "EXPLAIN-IT: Towards Explainable AI for Unsupervised Network Traffic\n  Analysis", "comments": null, "journal-ref": "3rd ACM CoNEXT Workshop on Big DAta, Machine Learning and\n  Artificial Intelligence for Data Communication Networks (Big-DAMA 2019)", "doi": "10.1145/3359992.3366639", "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of unsupervised learning approaches, and in particular of\nclustering techniques, represents a powerful exploration means for the analysis\nof network measurements. Discovering underlying data characteristics, grouping\nsimilar measurements together, and identifying eventual patterns of interest\nare some of the applications which can be tackled through clustering. Being\nunsupervised, clustering does not always provide precise and clear insight into\nthe produced output, especially when the input data structure and distribution\nare complex and difficult to grasp. In this paper we introduce EXPLAIN-IT, a\nmethodology which deals with unlabeled data, creates meaningful clusters, and\nsuggests an explanation to the clustering results for the end-user. EXPLAIN-IT\nrelies on a novel explainable Artificial Intelligence (AI) approach, which\nallows to understand the reasons leading to a particular decision of a\nsupervised learning-based model, additionally extending its application to the\nunsupervised learning domain. We apply EXPLAIN-IT to the problem of YouTube\nvideo quality classification under encrypted traffic scenarios, showing\npromising results.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 17:54:41 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Morichetta", "Andrea", ""], ["Casas", "Pedro", ""], ["Mellia", "Marco", ""]]}, {"id": "2003.01841", "submitter": "Nishant Budhdev", "authors": "Nishant Budhdev, Mun Choon Chan, Tulika Mitra", "title": "IsoRAN: Isolation and Scaling for 5G RANvia User-Level Data Plane\n  Virtualization", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G presents a unique set of challenges for cellular network architecture. The\narchitecture needs to be versatile in order to handle a variety of use cases.\nWhile network slicing has been proposed as a way to provide such versatility,\nit is also important to ensure that slices do not adversely interfere with each\nother. In other words, isolation among network slices is needed. Additionally,\nthe large number of use cases also implies a large number of users, making it\nimperative that 5G architectures scale efficiently. In this paper we propose\nIsoRAN, which provides isolation and scaling along with the flexibility needed\nfor 5G architecture. In IsoRAN, users are processed by daemon threads in the\nCloud Radio Access Network (CRAN) architecture. Our design allows users from\ndifferent use cases to be executed, in a distributed manner, on the most\nefficient hardware to ensure that the Service Level Agreements (SLAs) are met\nwhile minimising power consumption. Our experiments show that IsoRAN handles\nusers with different SLA while providing isolation to reduce interference. This\nincreased isolation reduces the drop rate for different users from 42% to\nnearly 0% in some cases. Finally, we run large scale simulations on real traces\nto show the benefits for power consumption and cost reduction scale while\nincreasing the number of base stations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 00:39:59 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Budhdev", "Nishant", ""], ["Chan", "Mun Choon", ""], ["Mitra", "Tulika", ""]]}, {"id": "2003.01906", "submitter": "Yulin Shao", "authors": "Yulin Shao and Soung Chang Liew and Jiaxin Liang", "title": "Sporadic Ultra-Time-Critical Crowd Messaging in V2X", "comments": "40 pages, 14 figures, full-length version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Life-critical warning message, abbreviated as warning message, is a special\nevent-driven message that carries emergency warning information in\nVehicle-to-Everything (V2X). Three important characteristics that distinguish\nwarning messages from ordinary vehicular messages are sporadicity, crowding,\nand ultra-time-criticality. In other words, warning messages come only once in\na while in a sporadic manner; however, when they come, they tend to come as a\ncrowd and they need to be delivered in short order. This paper puts forth a\nmedium-access control (MAC) protocol for warning messages. To circumvent\npotential inefficiency arising from sporadicity, we propose an override network\narchitecture whereby warning messages are delivered on the spectrum of the\nordinary vehicular messages. Specifically, a vehicle with a warning message\nfirst sends an interrupt signal to pre-empt the transmission of ordinary\nmessages, so that the warning message can use the wireless spectrum originally\nallocated to ordinary messages. In this way, no exclusive spectrum resources\nneed to be pre-allocated to the sporadic warning messages. To meet the crowding\nand ultra-time-criticality aspects, we use advanced channel access techniques\nto ensure highly reliable delivery of warning messages within an ultra-short\ntime in the order of 10 ms. In short, the overall MAC protocol operates by\nmeans of interrupt-and-access.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 06:04:14 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 06:47:58 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 06:13:21 GMT"}, {"version": "v4", "created": "Tue, 4 Aug 2020 07:10:23 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Shao", "Yulin", ""], ["Liew", "Soung Chang", ""], ["Liang", "Jiaxin", ""]]}, {"id": "2003.02079", "submitter": "Patrick Seeling", "authors": "Frank H. P. Fitzek and Patrick Seeling", "title": "Why We Should NOT Talk about 6G", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While 5G mobile communication systems are currently in deployment,\nresearchers around the world have already started to discuss 6G technology and\nfunding agencies started their first programs with a 6G label. Although it may\nseem like a good idea from a historical point of view with returning\ngenerations every decade, this contribution will show that there is a great\nrisk of introducing 6G labels at this time. While the reasons to not talk about\n6G yet are manifold, some of the more dominant ones are i.) there exists a lack\nof real technology advancements introduced by a potential 6G system; ii.) the\nflexibility of the 5G communication system introduced by softwarization\nconcepts, such as in the Internet community, allows for daily updates; and\niii.) introducing widespread 6G discussions can have a negative impact on the\ndeployment and evolution of 5G with completely new business cases and customer\necosystems compared to its predecessors. Finally, as we do not believe that 5G\nis the end of our journey, we will provide an outlook on the future of mobile\ncommunication systems, independent of the current mainstream discussion.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 13:45:33 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Fitzek", "Frank H. P.", ""], ["Seeling", "Patrick", ""]]}, {"id": "2003.02108", "submitter": "Yusheng Xiang", "authors": "Yusheng Xiang, Tianqing Su, Xiaole Liu, Marcus Geimer", "title": "Realtime Estimation of IEEE 802.11p for Mobile working Machines\n  Communication respecting Delay and Packet Loss", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fleet management of mobile working machines with the help of connectivity\ncan increase not only safety but also productivity. However, rare mobile\nworking machines have taken advantage of V2X. Moreover, no one published the\nsimulation results that are suitable for evaluating the performance of the\nad-hoc network at a working site on the highway where is congested, with low\nmobility, and without building. In this paper, we suggested that IEEE 802.11p\nshould be implemented for fleet management, at least for the first version.\nFurthermore, we proposed an analytical model for machines to estimate the\nad-hoc network performance, i.e., the delay and the packet loss probability in\nreal-time based on the simulation results we made in ns3. The model of this\npaper can be further used for determining when shall ad-hoc or cellular network\nbe used in the corresponding scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 14:44:53 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 10:31:34 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 22:13:33 GMT"}, {"version": "v4", "created": "Thu, 23 Apr 2020 16:31:00 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Xiang", "Yusheng", ""], ["Su", "Tianqing", ""], ["Liu", "Xiaole", ""], ["Geimer", "Marcus", ""]]}, {"id": "2003.02196", "submitter": "Xinchen Wei", "authors": "Xinchen Wei (1), Haitham Al-Obiedollah (2), Kanapathippillai Cumanan\n  (1), Miao Zhang (1), Jie Tang (3), Wei Wang (4) and Octavia A. Dobre (5) ((1)\n  University of York, United Kingdom, (2) The Hashemite University, Jordan, (3)\n  South China University of Technology, China, (4) Nantong University, China,\n  (5) Memorial University, Canada)", "title": "Resource Allocation Technique for Hybrid TDMA-NOMA System with\n  Opportunistic Time Assignment", "comments": "6 pages, 4 figures, this paper will be presented in part at the IEEE\n  International Conference on Communications (ICC) Workshop, Dublin, Ireland,\n  June 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a resource allocation technique for a hybrid time\ndivision multiple access (TDMA) - non-orthogonal multiple access (NOMA) system\nwith opportunistic time assignment. In particular, the available transmission\ntime is divided into several time-slots, through which multiple users are\nserved by exploiting power-domain NOMA. To fully exploit underlying benefits of\nthis hybrid TDMA-NOMA system, we utilize the available resources efficiently by\njointly allocating transmit power and time-slots to several groups of users in\nthe system. Furthermore, these resources are allocated to maximize minimum rate\nof the users in the system. However, this max-min resource allocation problem\nis non-convex due to coupled design parameters of time and power allocations.\nHence, we exploit a novel second-order cone formulation to overcome this\nnon-convexity issue and develop an iterative algorithm to realize a solution to\nthe original max-min problem. Simulation results show that this joint resource\nallocation technique has a considerable performance enhancement in terms of\nboth minimum achieved rate and overall system throughput compared to that of\nthe conventional resource allocation technique where equal time-slots are\nassigned to the groups of users.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 17:09:49 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Wei", "Xinchen", ""], ["Al-Obiedollah", "Haitham", ""], ["Cumanan", "Kanapathippillai", ""], ["Zhang", "Miao", ""], ["Tang", "Jie", ""], ["Wang", "Wei", ""], ["Dobre", "Octavia A.", ""]]}, {"id": "2003.02235", "submitter": "Wei Sun", "authors": "Wei Sun", "title": "Towards High Throughput Wireless Network with Directional Antenna", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In indoor areas such as homes and offices, high throughput communication for\nmultiple devices is quickly becoming a necessity. Even though an access point\n(AP) mounted with an omni-directional antenna can cover a whole room, it cannot\nprovide connections with high throughput throughout the room. Therefore, we\npropose, \\emph DiRF, a directional antenna based wireless home network designed\nto achieve high throughput in indoor areas with densely deployed directional\nAPs. \\emph DiRF consists of a position based AP selection algorithm which can\ndecrease latency accumulation caused by frequent AP switching, and a downlink\npacket scheduler which can reduce the downlink packet retransmissions during AP\nswitching. We implement and evaluate \\emph DiRF with six commercial APs, each\nconnects with a single directional antenna. Our experiments show that \\emph\nDiRF achieves a $3.16\\times$ TCP throughput improvement, compared to the\nconventional scheme that only uses one AP mounted with one omni-directional\nantenna.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:23:40 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Sun", "Wei", ""]]}, {"id": "2003.02291", "submitter": "Bryan Ford", "authors": "Bryan Ford, Philipp Jovanovic, Ewa Syta", "title": "Que Sera Consensus: Simple Asynchronous Agreement with Private Coins and\n  Threshold Logical Clocks", "comments": "6 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly held that asynchronous consensus is much more complex,\ndifficult, and costly than partially-synchronous algorithms, especially without\nusing common coins. This paper challenges that conventional wisdom with que\nsera consensus QSC, an approach to consensus that cleanly decomposes the\nagreement problem from that of network asynchrony. QSC uses only private coins\nand reaches consensus in $O(1)$ expected communication rounds. It relies on\n\"lock-step\" synchronous broadcast, but can run atop a threshold logical clock\n(TLC) algorithm to time and pace partially-reliable communication atop an\nunderlying asynchronous network. This combination is arguably simpler than\npartially-synchronous consensus approaches like (Multi-)Paxos or Raft with\nleader election, and is more robust to slow leaders or targeted network\ndenial-of-service attacks. The simplest formulations of QSC atop TLC incur\nexpected $O(n^2)$ messages and $O(n^4)$ bits per agreement, or $O(n^3)$ bits\nwith straightforward optimizations. An on-demand implementation, in which\nclients act as \"natural leaders\" to execute the protocol atop stateful servers\nthat merely implement passive key-value stores, can achieve $O(n^2)$ expected\ncommunication bits per client-driven agreement.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 19:06:58 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Ford", "Bryan", ""], ["Jovanovic", "Philipp", ""], ["Syta", "Ewa", ""]]}, {"id": "2003.02368", "submitter": "Shay Vargaftik", "authors": "Shay Vargaftik, Isaac Keslassy, Ariel Orda", "title": "LSQ: Load Balancing in Large-Scale Heterogeneous Systems with Multiple\n  Dispatchers", "comments": "Preprint of this work has been available online since 27.12.2018.\n  This manuscript is an extended version of an IEEE/ACM ToN paper (submitted\n  15.4.2019, revised 12.8.2019, 19.11.2019, 9.1.2020, accepted 26.2.2020). It\n  is based on the Ph.D. thesis of Shay Vargaftik, submitted to the Technion in\n  Apr 2019$.$", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the efficiency and even the feasibility of traditional\nload-balancing policies are challenged by the rapid growth of cloud\ninfrastructure and the increasing levels of server heterogeneity. In such\nheterogeneous systems with many load-balancers, traditional solutions, such as\nJSQ, incur a prohibitively large communication overhead and detrimental incast\neffects due to herd behavior. Alternative low-communication policies, such as\nJSQ(d) and the recently proposed JIQ, are either unstable or provide poor\nperformance.\n  We introduce the Local Shortest Queue (LSQ) family of load balancing\nalgorithms. In these algorithms, each dispatcher maintains its own, local, and\npossibly outdated view of the server queue lengths, and keeps using JSQ on its\nlocal view. A small communication overhead is used infrequently to update this\nlocal view. We formally prove that as long as the error in these local\nestimates of the server queue lengths is bounded in expectation, the entire\nsystem is strongly stable. Finally, in simulations, we show how simple and\nstable LSQ policies exhibit appealing performance and significantly outperform\nexisting low-communication policies, while using an equivalent communication\nbudget. In particular, our simple policies often outperform even JSQ due to\ntheir reduction of herd behavior. We further show how, by relying on smart\nservers (i.e., advanced pull-based communication), we can further improve\nperformance and lower communication overhead.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 23:38:41 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 09:10:40 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Vargaftik", "Shay", ""], ["Keslassy", "Isaac", ""], ["Orda", "Ariel", ""]]}, {"id": "2003.02503", "submitter": "Dinesh Kumar", "authors": "Dinesh Kumar, Rajiv Kumar, Neeru Sharma", "title": "Dual link failure survivability with recovery time constraint: A\n  Parallel cross connection backup route recovery strategy", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a fast recovery strategy for a dual link failure\nin elastic optical network. The elastic optical network is a promising solution\nto meet the next generation higher bandwidth demand. The survivability of high\nspeed network is very crucial. As the network size increases the probability of\nthe dual link failure and node failure also increases. Here, we proposed a\nparallel cross connection backup recovery strategy for dual link failure in the\nnetwork. Proposed strategy shows lower bandwidth blocking probability (BBP),\nfast connection recovery, and bandwidth provisioning ratio when compared with\nthe existing shared path protection (SPP) and dedicated path protection (DPP)\napproaches. Simulation is performed on ARPANET and COST239 topology networks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 09:39:10 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Kumar", "Dinesh", ""], ["Kumar", "Rajiv", ""], ["Sharma", "Neeru", ""]]}, {"id": "2003.02512", "submitter": "Emmanouil Fountoulakis", "authors": "Emmanouil Fountoulakis, Nikolaos Pappas, Marian Codreanu, Anthony\n  Ephremides", "title": "Optimal Sampling Cost in Wireless Networks with Age of Information\n  Constraints", "comments": "Accepted in IEEE INFOCOM Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing the time average cost of sampling and\ntransmitting status updates by users over a wireless channel subject to average\nAge of Information constraints (AoI). Errors in the transmission may occur and\nthe scheduling algorithm has to decide if the users sample a new packet or\nattempt for retransmission of the packet sampled previously. The cost consists\nof both sampling and transmission costs. The sampling of a new packet after a\nfailure imposes an additional cost in the system. We formulate a stochastic\noptimization problem with time average cost in the objective under time average\nAoI constraints. To solve this problem, we apply tools from Lyapunov\noptimization theory and develop a dynamic algorithm that takes decisions in a\nslot-by-slot basis. The algorithm decides if a user: a) samples a new packet,\nb) transmits the old one, c) remains silent. We provide optimality guarantees\nof the algorithm and study its performance in terms of time average cost and\nAoI through simulation results.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 10:10:51 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Fountoulakis", "Emmanouil", ""], ["Pappas", "Nikolaos", ""], ["Codreanu", "Marian", ""], ["Ephremides", "Anthony", ""]]}, {"id": "2003.02651", "submitter": "Cristian Tatino", "authors": "Cristian Tatino, Nikolaos Pappas, Ilaria Malanchini, Lutz Ewe, and Di\n  Yuan", "title": "Learning-Based Link Scheduling in Millimeter-wave Multi-connectivity\n  Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-connectivity is emerging as a promising solution to provide reliable\ncommunications and seamless connectivity for the millimeter-wave frequency\nrange. Due to the blockage sensitivity at such high frequencies, connectivity\nwith multiple cells can drastically increase the network performance in terms\nof throughput and reliability. However, an inefficient link scheduling, i.e.,\nover and under-provisioning of connections, can lead either to high\ninterference and energy consumption or to unsatisfied user's quality of service\n(QoS) requirements. In this work, we present a learning-based solution that is\nable to learn and then to predict the optimal link scheduling to satisfy users'\nQoS requirements while avoiding communication interruptions. Moreover, we\ncompare the proposed approach with two base line methods and the genie-aided\nlink scheduling that assumes perfect channel knowledge. We show that the\nlearning-based solution approaches the optimum and outperforms the base line\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 12:42:21 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Tatino", "Cristian", ""], ["Pappas", "Nikolaos", ""], ["Malanchini", "Ilaria", ""], ["Ewe", "Lutz", ""], ["Yuan", "Di", ""]]}, {"id": "2003.02807", "submitter": "Shan Jaffry", "authors": "Shan Jaffry", "title": "Cellular Traffic Prediction with Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Autonomous prediction of traffic demand will be a key function in future\ncellular networks. In the past, researchers have used statistical methods such\nas Autoregressive integrated moving average (ARIMA) to provide traffic\npredictions. However, ARIMA based predictions fail to give an exact and\naccurate forecast for dynamic input quantities such as cellular traffic. More\nrecently, researchers have started to explore deep learning techniques, such\nas, recurrent neural networks (RNN) and long-short-term-memory (LSTM) to\nautonomously predict future cellular traffic. In this research, we have\ndesigned a LSTM based cellular traffic prediction model. We have compared the\nLSTM based prediction with the base line ARIMA model and vanilla feed-forward\nneural network (FFNN). The results show that LSTM and FFNN accurately predicted\nfuture cellular traffic. However, it was found that LSTM train the prediction\nmodel in much shorter time as compared to FFNN. Hence, we conclude that LSTM\nmodels can be effectively even used with small amount of training data which\nwill allow to timely predict future cellular traffic.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:16:49 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Jaffry", "Shan", ""]]}, {"id": "2003.02820", "submitter": "Mostafa Hadadian Nejad Yousefi", "authors": "Mostafa Hadadian Nejad Yousefi, Amirmasoud Ghiassi, Boshra Sadat\n  Hashemi, Maziar Goudarzi", "title": "Workload Scheduling on heterogeneous Mobile Edge Cloud in 5G networks to\n  Minimize SLA Violation", "comments": "12 pages, 8 figures, 4 tables contact: hadadian AT ce DOT sharif DOT\n  edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart devices have become an indispensable part of our lives and gain\nincreasing applicability in almost every area. Latency-aware applications such\nas Augmented Reality (AR), autonomous driving, and online gaming demand more\nresources such as network bandwidth and computational capabilities. Since the\ntraditional mobile networks cannot fulfill the required bandwidth and latency,\nMobile Edge Cloud (MEC) emerged to provide cloud computing capabilities in the\nproximity of users on 5G networks. In this paper, we consider a heterogeneous\nMEC network with numerous mobile users that send their tasks to MEC servers.\nEach task has a maximum acceptable response time. Non-uniform distribution of\nusers makes some MEC servers hotspots that cannot take more. A solution is to\nrelocate the tasks among MEC servers, called Workload Migration. We formulate\nthis problem of task scheduling as a mixed-integer non-linear optimization\nproblem to minimize the number of Service Level Agreement (SLA) violations.\nSince solving this optimization problem has high computational complexity, we\nintroduce a greedy algorithm called MESA, Migration Enabled Scheduling\nAlgorithm, which reaches a near-optimal solution quickly. Our experiments show\nthat in the term of SLA violation, MESA is only 8% and 11% far from the optimal\nchoice on the average and the worst-case, respectively. Moreover, the migration\nenabled solution can reduce SLA violations by about 30% compare to assigning\ntasks to MEC servers without migration.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:43:24 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 11:19:49 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Yousefi", "Mostafa Hadadian Nejad", ""], ["Ghiassi", "Amirmasoud", ""], ["Hashemi", "Boshra Sadat", ""], ["Goudarzi", "Maziar", ""]]}, {"id": "2003.03221", "submitter": "Dominik Scholz", "authors": "Dominik Scholz, Sebastian Gallenm\\\"uller, Henning Stubbe, Bassam\n  Jaber, Minoo Rouhi, Georg Carle", "title": "Me Love (SYN-)Cookies: SYN Flood Mitigation in Programmable Data Planes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SYN flood attack is a common attack strategy on the Internet, which tries\nto overload services with requests leading to a Denial-of-Service (DoS). Highly\nasymmetric costs for connection setup - putting the main burden on the attackee\n- make SYN flooding an efficient and popular DoS attack strategy. Abusing the\nwidely used TCP as an attack vector complicates the detection of malicious\ntraffic and its prevention utilizing naive connection blocking strategies.\nModern programmable data plane devices are capable of handling traffic in the\n10 Gbit/s range without overloading. We discuss how we can harness their\nperformance to defend entire networks against SYN flood attacks. Therefore, we\nanalyze different defense strategies, SYN authentication and SYN cookie, and\ndiscuss implementation difficulties when ported to different target data\nplanes: software, network processors, and FPGAs. We provide prototype\nimplementations and performance figures for all three platforms. Further, we\nfully disclose the artifacts leading to the experiments described in this work.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 14:02:34 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Scholz", "Dominik", ""], ["Gallenm\u00fcller", "Sebastian", ""], ["Stubbe", "Henning", ""], ["Jaber", "Bassam", ""], ["Rouhi", "Minoo", ""], ["Carle", "Georg", ""]]}, {"id": "2003.03320", "submitter": "Felix Sattler", "authors": "Felix Sattler, Thomas Wiegand, Wojciech Samek", "title": "Trends and Advancements in Deep Neural Network Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MM cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their great performance and scalability properties neural networks\nhave become ubiquitous building blocks of many applications. With the rise of\nmobile and IoT, these models now are also being increasingly applied in\ndistributed settings, where the owners of the data are separated by limited\ncommunication channels and privacy constraints. To address the challenges of\nthese distributed environments, a wide range of training and evaluation schemes\nhave been developed, which require the communication of neural network\nparametrizations. These novel approaches, which bring the \"intelligence to the\ndata\" have many advantages over traditional cloud solutions such as\nprivacy-preservation, increased security and device autonomy, communication\nefficiency and high training speed. This paper gives an overview over the\nrecent advancements and challenges in this new field of research at the\nintersection of machine learning and communications.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 17:34:15 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Sattler", "Felix", ""], ["Wiegand", "Thomas", ""], ["Samek", "Wojciech", ""]]}, {"id": "2003.03442", "submitter": "Martin Haenggi", "authors": "Martin Haenggi", "title": "SIR Analysis via Signal Fractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of signal-to-interference ratios (SIRs) in wireless networks is\ninstrumental to derive important performance metrics, including reliability,\nthroughput, and delay. While a host of results on SIR distributions are now\navailable, they are often not straightforwards to interpret, bound, visualize,\nand compare. In this letter, we offer an alternative path towards the analysis\nand visualization of the SIR distribution. The quantity at the core of this\napproach is the signal fraction (SF), which is the ratio of the signal power to\nthe total received power. A key advantage is that the SF is constrained to\n[0,1]. We exemplify the benefits of the SF-based approach by reviewing known\nresults for Poisson cellular networks. In the process, we derive new\napproximation and bounding techniques that are generally applicable.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 21:15:46 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Haenggi", "Martin", ""]]}, {"id": "2003.03575", "submitter": "Songyang Zhang", "authors": "Songyang Zhang", "title": "An Online Learning Based Path Selection for Multipath Video Telephony\n  Service in Overlay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even real time video telephony services have been pervasively applied,\nproviding satisfactory quality of experience to users is still a challenge task\nespecially in wireless networks. Multipath transmission is a promising solution\nto improve video quality by aggregating bandwidth. In existing multipath\ntransmission solutions, sender concurrently splits traffic on default routing\npaths and has no flexibility to select paths. When default paths fall into\nsevere congestion and the available bandwidth decreases, sender has to decrease\nvideo quality by reducing resolution or encoding bitrate. Deploying relay\nservers in current infrastructure to form overlay network provides path\ndiversity. An online learning approach based on multi-armed bandits is applied\nfor path selection to harvest maximum profit. Further, a congestion control\nalgorithm adapted from BBR is implemented to probe bandwidth and to avoid link\ncongestion. To maintain throughput stability and fairness, a smaller probe up\ngain value is used and the cycle length in bandwidth probe phase is randomized.\nTo reduce delay, the inflight packets will be reduced to match with the\nestimated bandwidth delay product in the probe down phase. Experiments are\nconducted to verify the effectiveness the proposed solution to improve\nthroughput and quality in video communication service.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 13:04:45 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Zhang", "Songyang", ""]]}, {"id": "2003.03584", "submitter": "Apostolos Galanopoulos", "authors": "A. Galanopoulos, V. Valls, G. Iosifidis, D. J. Leith", "title": "Measurement-driven Analysis of an Edge-Assisted Object Recognition\n  System", "comments": "7 pages, 9 figures. This paper has been accepted for publication in\n  the Proceedings of IEEE International Conference on Communications (ICC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an edge-assisted object recognition system with the aim of\nstudying the system-level trade-offs between end-to-end latency and object\nrecognition accuracy. We focus on developing techniques that optimize the\ntransmission delay of the system and demonstrate the effect of image encoding\nrate and neural network size on these two performance metrics. We explore\noptimal trade-offs between these metrics by measuring the performance of our\nreal time object recognition application. Our measurements reveal hitherto\nunknown parameter effects and sharp trade-offs, hence paving the road for\noptimizing this key service. Finally, we formulate two optimization problems\nusing our measurement-based models and following a Pareto analysis we find that\ncareful tuning of the system operation yields at least 33% better performance\nfor real time conditions, over the standard transmission method.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 14:53:10 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Galanopoulos", "A.", ""], ["Valls", "V.", ""], ["Iosifidis", "G.", ""], ["Leith", "D. J.", ""]]}, {"id": "2003.03588", "submitter": "Apostolos Galanopoulos", "authors": "A. Galanopoulos, A. G. Tasiopoulos, G. Iosifidis, T. Salonidis, D. J.\n  Leith", "title": "Improving IoT Analytics through Selective Edge Execution", "comments": "7 pages, 6 figures. This paper has been accepted for publication in\n  the Proceedings of IEEE International Conference on Communications (ICC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of emerging IoT applications rely on machine learning routines\nfor analyzing data. Executing such tasks at the user devices improves response\ntime and economizes network resources. However, due to power and computing\nlimitations, the devices often cannot support such resource-intensive routines\nand fail to accurately execute the analytics. In this work, we propose to\nimprove the performance of analytics by leveraging edge infrastructure. We\ndevise an algorithm that enables the IoT devices to execute their routines\nlocally; and then outsource them to cloudlet servers, only if they predict they\nwill gain a significant performance improvement. It uses an approximate dual\nsubgradient method, making minimal assumptions about the statistical properties\nof the system's parameters. Our analysis demonstrates that our proposed\nalgorithm can intelligently leverage the cloudlet, adapting to the service\nrequirements.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 15:02:23 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Galanopoulos", "A.", ""], ["Tasiopoulos", "A. G.", ""], ["Iosifidis", "G.", ""], ["Salonidis", "T.", ""], ["Leith", "D. J.", ""]]}, {"id": "2003.03674", "submitter": "Cao Vien Phung", "authors": "Cao Vien Phung, Anna Engelmann and Admela Jukan", "title": "Error Correction with Systematic RLNC in Multi-Channel THz Communication\n  Systems", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": "10.23919/MIPRO48935.2020.9245338", "report-no": null, "categories": "cs.NI cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The terahertz (THz) frequency band (0.3-10THz) has the advantage of large\navailable bandwidth and is a candidate to satisfy the ever increasing mobile\ntraffic in wireless communications. However, the THz channels are often\nabsorbed by molecules in the atmosphere, which can decrease the signal quality\nresulting in high bit error rate of received data. In this paper, we study the\nusage of systematic random linear network coding (sRLNC) for error correction\nin generic THz systems with with 2N parallel channels, whereby N main\nhigh-bitrate channels are used in parallel with N auxiliary channels with lower\nbit rate. The idea behind this approach is to use coded low-bit rate channels\nto carry redundant information from high-bit rate channels, and thus compensate\nfor errors in THz transmission. The analytical results evaluate and compare the\ndifferent scenarios of the THz system in term of the amount of coding\nredundancy, a code rate, transmission rate of auxiliary channels, the number of\nTHz channels, the modulation format and transmission distance as required\nsystem configurations for a fault tolerant THz transmission.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 22:41:00 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 16:20:15 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 08:11:44 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Phung", "Cao Vien", ""], ["Engelmann", "Anna", ""], ["Jukan", "Admela", ""]]}, {"id": "2003.03971", "submitter": "Xu Chen", "authors": "Qiong Wu and Muhong Wu and Xu Chen and Zhi Zhou and Kaiwen He and\n  Liang Chen", "title": "DeepCP: Deep Learning Driven Cascade Prediction Based Autonomous Content\n  Placement in Closed Social Network", "comments": "accepted by IEEE Journal on Selected Areas in Communications (JSAC),\n  March 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social networks (OSNs) are emerging as the most popular mainstream\nplatform for content cascade diffusion. In order to provide satisfactory\nquality of experience (QoE) for users in OSNs, much research dedicates to\nproactive content placement by using the propagation pattern, user's personal\nprofiles and social relationships in open social network scenarios (e.g.,\nTwitter and Weibo). In this paper, we take a new direction of popularity-aware\ncontent placement in a closed social network (e.g., WeChat Moment) where user's\nprivacy is highly enhanced. We propose a novel data-driven holistic deep\nlearning framework, namely DeepCP, for joint diffusion-aware cascade prediction\nand autonomous content placement without utilizing users' personal and social\ninformation. We first devise a time-window LSTM model for content popularity\nprediction and cascade geo-distribution estimation. Accordingly, we further\npropose a novel autonomous content placement mechanism CP-GAN which adopts the\ngenerative adversarial network (GAN) for agile placement decision making to\nreduce the content access latency and enhance users' QoE. We conduct extensive\nexperiments using cascade diffusion traces in WeChat Moment (WM). Evaluation\nresults corroborate that the proposed DeepCP framework can predict the content\npopularity with a high accuracy, generate efficient placement decision in a\nreal-time manner, and achieve significant content access latency reduction over\nexisting schemes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 08:52:53 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Wu", "Qiong", ""], ["Wu", "Muhong", ""], ["Chen", "Xu", ""], ["Zhou", "Zhi", ""], ["He", "Kaiwen", ""], ["Chen", "Liang", ""]]}, {"id": "2003.04079", "submitter": "Pedro Casas Dr.", "authors": "Gonzalo Mar\\'in, Pedro Casas, Germ\\'an Capdehourat", "title": "DeepMAL -- Deep Learning Models for Malware Traffic Detection and\n  Classification", "comments": "3rd International Data Science Conference (IDSC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust network security systems are essential to prevent and mitigate the\nharming effects of the ever-growing occurrence of network attacks. In recent\nyears, machine learning-based systems have gain popularity for network security\napplications, usually considering the application of shallow models, which rely\non the careful engineering of expert, handcrafted input features. The main\nlimitation of this approach is that handcrafted features can fail to perform\nwell under different scenarios and types of attacks. Deep Learning (DL) models\ncan solve this limitation using their ability to learn feature representations\nfrom raw, non-processed data. In this paper we explore the power of DL models\non the specific problem of detection and classification of malware network\ntraffic. As a major advantage with respect to the state of the art, we consider\nraw measurements coming directly from the stream of monitored bytes as input to\nthe proposed models, and evaluate different raw-traffic feature\nrepresentations, including packet and flow-level ones. We introduce DeepMAL, a\nDL model which is able to capture the underlying statistics of malicious\ntraffic, without any sort of expert handcrafted features. Using publicly\navailable traffic traces containing different families of malware traffic, we\nshow that DeepMAL can detect and classify malware flows with high accuracy,\noutperforming traditional, shallow-like models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 16:54:26 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 16:56:46 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Mar\u00edn", "Gonzalo", ""], ["Casas", "Pedro", ""], ["Capdehourat", "Germ\u00e1n", ""]]}, {"id": "2003.04080", "submitter": "Pedro Casas Dr.", "authors": "Pedro Casas", "title": "Two Decades of AI4NETS-AI/ML for Data Networks: Challenges & Research\n  Directions", "comments": null, "journal-ref": "5th IEEE/IFIP International Workshop on Analytics for Network and\n  Service Management (AnNet 2020)", "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of Artificial Intelligence (AI) -- and of Machine Learning\n(ML) as an approach to AI, has dramatically increased in the last few years,\ndue to its outstanding performance in various domains, notably in image, audio,\nand natural language processing. In these domains, AI success-stories are\nboosting the applied field. When it comes to AI/ML for data communication\nNetworks (AI4NETS), and despite the many attempts to turn networks into\nlearning agents, the successful application of AI/ML in networking is limited.\nThere is a strong resistance against AI/ML-based solutions, and a striking gap\nbetween the extensive academic research and the actual deployments of such\nAI/ML-based systems in operational environments. The truth is, there are still\nmany unsolved complex challenges associated to the analysis of networking data\nthrough AI/ML, which hinders its acceptability and adoption in the practice. In\nthis positioning paper I elaborate on the most important show-stoppers in\nAI4NETS, and present a research agenda to tackle some of these challenges,\nenabling a natural adoption of AI/ML for networking. In particular, I focus the\nfuture research in AI4NETS around three major pillars: (i) to make AI/ML\nimmediately applicable in networking problems through the concepts of effective\nlearning, turning it into a useful and reliable way to deal with complex\ndata-driven networking problems; (ii) to boost the adoption of AI/ML at the\nlarge scale by learning from the Internet-paradigm itself, conceiving novel\ndistributed and hierarchical learning approaches mimicking the distributed\ntopological principles and operation of the Internet itself; and (iii) to\nexploit the softwarization and distribution of networks to conceive\nAI/ML-defined Networks (AIDN), relying on the distributed generation and\nre-usage of knowledge through novel Knowledge Delivery Networks (KDNs).\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 00:36:17 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Casas", "Pedro", ""]]}, {"id": "2003.04251", "submitter": "Seungmo Kim", "authors": "Tsigigenet Dessalgn and Seungmo Kim", "title": "Danger Aware Vehicular Networking", "comments": null, "journal-ref": "This paper was presented at IEEE Southeastcon 2019", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IEEE 802.11p is one of the key technologies that enable Dedicated Short-Range\nCommunications (DSRC) in intelligent transportation system (ITS) for safety on\nthe road. The main challenge in vehicular communication is the large amount of\ndata to be processed. As vehicle density and velocity increases, the data to be\ntransmitted also increases. We proposed a protocol that reduces the number of\nmessages transmitted at a vehicle according to the level of danger that the\nvehicle experiences. The proposed protocol measures inter-vehicle distance, as\nthe representative of the danger of a vehicle, to determine the priority for\ntransmission. Our results show that this prioritization of transmissions\ndirectly reduces the number of transmitters at a time, and hence results in\nhigher performance in terms of key metrics--i.e., PDR, throughput, delay,\nprobabilities of channel busy and collision.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 16:50:05 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Dessalgn", "Tsigigenet", ""], ["Kim", "Seungmo", ""]]}, {"id": "2003.04354", "submitter": "Anirudh Paranjothi", "authors": "Anirudh Paranjothi", "title": "Performance Analysis of Message Dissemination Techniques in VANET using\n  Fog Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Vehicular Ad-hoc Networks (VANET) is a derived subclass of Mobile Ad-hoc\nNetworks (MANET) with vehicles as mobile nodes. VANET facilitate vehicles to\nshare safety and non-safety information through messages. Safety information\nincludes road accidents, natural hazards, roadblocks, etc. Non-safety\ninformation includes tolling information, traveler information, etc. The main\ngoal behind sharing this information is to enhance road safety and reduce road\naccidents by alerting the driver about the unexpected hazards. However, routing\nof messages in VANET is challenging due to packet delays arising from high\nmobility of vehicles, frequently changing topology and high density of\nvehicles, leading to frequent route breakages and packet losses. This report\nsummarizes the performance analysis of safety and non-safety message\ndissemination techniques in VANET based on the fog computing technique. Three\nmain metrics to improve the performance of message dissemination are: 1) delay,\n2) probability of message delivery, and 3) throughput. Analysis of such metrics\nplays an important role to improve the performance of existing message\ndissemination techniques. Simulations are usually conducted based on the\nmetrics using ns-2 and Java discrete event simulator. The above three\nperformance metrics and results published in literature help one to understand\nand increase the performance of various message dissemination techniques in a\nVANET environment.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 18:42:43 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Paranjothi", "Anirudh", ""]]}, {"id": "2003.04451", "submitter": "Hamid Shiri", "authors": "Hamid Shiri, Jihong Park, and Mehdi Bennis", "title": "Communication-Efficient Massive UAV Online Path Control: Federated\n  Learning Meets Mean-Field Game Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the control of a massive population of UAVs such as\ndrones. The straightforward method of control of UAVs by considering the\ninteractions among them to make a flock requires a huge inter-UAV communication\nwhich is impossible to implement in real-time applications. One method of\ncontrol is to apply the mean-field game (MFG) framework which substantially\nreduces communications among the UAVs. However, to realize this framework,\npowerful processors are required to obtain the control laws at different UAVs.\nThis requirement limits the usage of the MFG framework for real-time\napplications such as massive UAV control. Thus, a function approximator based\non neural networks (NN) is utilized to approximate the solutions of\nHamilton-Jacobi-Bellman (HJB) and Fokker-Planck-Kolmogorov (FPK) equations.\nNevertheless, using an approximate solution can violate the conditions for\nconvergence of the MFG framework. Therefore, the federated learning (FL)\napproach which can share the model parameters of NNs at drones, is proposed\nwith NN based MFG to satisfy the required conditions. The stability analysis of\nthe NN based MFG approach is presented and the performance of the proposed\nFL-MFG is elaborated by the simulations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 23:17:26 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 12:36:27 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Shiri", "Hamid", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2003.04551", "submitter": "Anupam Kumar Bairagi", "authors": "Anupam Kumar Bairagi, Md. Shirajum Munir, Madyan Alsenwi, Nguyen H.\n  Tran, Sultan S Alshamrani, Mehedi Masud, Zhu Han, and Choong Seon Hong", "title": "Coexistence Mechanism between eMBB and uRLLC in 5G Wireless Networks", "comments": "30 pages, 11 figures, IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  uRLLC and eMBB are two influential services of the emerging 5G cellular\nnetwork. Latency and reliability are major concerns for uRLLC applications,\nwhereas eMBB services claim for the maximum data rates. Owing to the trade-off\namong latency, reliability and spectral efficiency, sharing of radio resources\nbetween eMBB and uRLLC services, heads to a challenging scheduling dilemma. In\nthis paper, we study the co-scheduling problem of eMBB and uRLLC traffic based\nupon the puncturing technique. Precisely, we formulate an optimization problem\naiming to maximize the MEAR of eMBB UEs while fulfilling the provisions of the\nuRLLC traffic. We decompose the original problem into two sub-problems, namely\nscheduling problem of eMBB UEs and uRLLC UEs while prevailing objective\nunchanged. Radio resources are scheduled among the eMBB UEs on a time slot\nbasis, whereas it is handled for uRLLC UEs on a mini-slot basis. Moreover, for\nresolving the scheduling issue of eMBB UEs, we use PSUM based algorithm,\nwhereas the optimal TM is adopted for solving the same problem of uRLLC UEs.\nFurthermore, a heuristic algorithm is also provided to solve the first\nsub-problem with lower complexity. Finally, the significance of the proposed\napproach over other baseline approaches is established through numerical\nanalysis in terms of the MEAR and fairness scores of the eMBB UEs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 06:45:30 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Bairagi", "Anupam Kumar", ""], ["Munir", "Md. Shirajum", ""], ["Alsenwi", "Madyan", ""], ["Tran", "Nguyen H.", ""], ["Alshamrani", "Sultan S", ""], ["Masud", "Mehedi", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2003.04816", "submitter": "Sarder Fakhrul Abedin", "authors": "Sarder Fakhrul Abedin, Md. Shirajum Munir, Nguyen H. Tran, Zhu Han,\n  Choong Seon Hong", "title": "Data Freshness and Energy-Efficient UAV Navigation Optimization: A Deep\n  Reinforcement Learning Approach", "comments": "Submitted to IEEE Transactions on Intelligent Transportation Systems,\n  Special Issue on Unmanned Aircraft System Traffic Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design a navigation policy for multiple unmanned aerial\nvehicles (UAVs) where mobile base stations (BSs) are deployed to improve the\ndata freshness and connectivity to the Internet of Things (IoT) devices. First,\nwe formulate an energy-efficient trajectory optimization problem in which the\nobjective is to maximize the energy efficiency by optimizing the UAV-BS\ntrajectory policy. We also incorporate different contextual information such as\nenergy and age of information (AoI) constraints to ensure the data freshness at\nthe ground BS. Second, we propose an agile deep reinforcement learning with\nexperience replay model to solve the formulated problem concerning the\ncontextual constraints for the UAV-BS navigation. Moreover, the proposed\napproach is well-suited for solving the problem, since the state space of the\nproblem is extremely large and finding the best trajectory policy with useful\ncontextual features is too complex for the UAV-BSs. By applying the proposed\ntrained model, an effective real-time trajectory policy for the UAV-BSs\ncaptures the observable network states over time. Finally, the simulation\nresults illustrate the proposed approach is 3.6% and 3.13% more energy\nefficient than those of the greedy and baseline deep Q Network (DQN)\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:29:15 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Abedin", "Sarder Fakhrul", ""], ["Munir", "Md. Shirajum", ""], ["Tran", "Nguyen H.", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2003.04832", "submitter": "Solmaz Niknam", "authors": "Reza Barazideh and Omid Semiari and Solmaz Niknam and Balasubramaniam\n  Natarajan", "title": "Reinforcement Learning for Mitigating Intermittent Interference in\n  Terahertz Communication Networks", "comments": "2020 IEEE International Conference on Communications (ICC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging wireless services with extremely high data rate requirements, such\nas real-time extended reality applications, mandate novel solutions to further\nincrease the capacity of future wireless networks. In this regard, leveraging\nlarge available bandwidth at terahertz frequency bands is seen as a key\nenabler. To overcome the large propagation loss at these very high frequencies,\nit is inevitable to manage transmissions over highly directional links.\nHowever, uncoordinated directional transmissions by a large number of users can\ncause substantial interference in terahertz networks. While such interference\nwill be received over short random time intervals, the received power can be\nlarge. In this work, a new framework based on reinforcement learning is\nproposed that uses an adaptive multi-thresholding strategy to efficiently\ndetect and mitigate the intermittent interference from directional links in the\ntime domain. To find the optimal thresholds, the problem is formulated as a\nmultidimensional multi-armed bandit system. Then, an algorithm is proposed that\nallows the receiver to learn the optimal thresholds with very low complexity.\nAnother key advantage of the proposed approach is that it does not rely on any\nprior knowledge about the interference statistics, and hence, it is suitable\nfor interference mitigation in dynamic scenarios. Simulation results confirm\nthe superior bit-error-rate performance of the proposed method compared with\ntwo traditional time-domain interference mitigation approaches.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 16:28:45 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Barazideh", "Reza", ""], ["Semiari", "Omid", ""], ["Niknam", "Solmaz", ""], ["Natarajan", "Balasubramaniam", ""]]}, {"id": "2003.05111", "submitter": "Milad Ghaznavi", "authors": "Milad Ghaznavi, Ali Jose Mashtizadeh, Bernard Wong, and Raouf Boutaba", "title": "Constellation: A High Performance Geo-Distributed Middlebox Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Middleboxes are increasingly deployed across geographically distributed data\ncenters. In these scenarios, the WAN latency between different sites can\nsignificantly impact the performance of stateful middleboxes. The deployment of\nmiddleboxes across such infrastructures can even become impractical due to the\nhigh cost of remote state accesses.\n  We introduce Constellation, a framework for the geo distributed deployment of\nmiddleboxes. Constellation uses asynchronous replication of specialized state\nobjects to achieve high performance and scalability. The evaluation of our\nimplementation shows that, compared with the state-of-the-art [80],\nConstellation improves the throughput by a factor of 96 in wide area networks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 04:51:39 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Ghaznavi", "Milad", ""], ["Mashtizadeh", "Ali Jose", ""], ["Wong", "Bernard", ""], ["Boutaba", "Raouf", ""]]}, {"id": "2003.05208", "submitter": "Mohammad Ashraful Hoque", "authors": "Mohammad A. Hoque, Ashwin Rao, Sasu Tarkoma", "title": "In Situ Network and Application Performance Measurement on Android\n  Devices and the Imperfections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding network and application performance are essential for\ndebugging, improving user experience, and performance comparison. Meanwhile,\nmodern mobile systems are optimized for energy-efficient computation and\ncommunications that may limit the performance of network and applications. In\nrecent years, several tools have emerged that analyze network performance of\nmobile applications in~situ with the help of the VPN service. There is a\nlimited understanding of how these measurement tools and system optimizations\naffect the network and application performance. In this study, we first\ndemonstrate that mobile systems employ energy-aware system hardware tuning,\nwhich affects application performance and network throughput. We next show that\nthe VPN-based application performance measurement tools, such as Lumen,\nPrivacyGuard, and Video Optimizer, aid in ambiguous network performance\nmeasurements and degrade the application performance. Our findings suggest that\nsound application and network performance measurement on Android devices\nrequires a good understanding of the device, networks, measurement tools, and\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 10:42:40 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Hoque", "Mohammad A.", ""], ["Rao", "Ashwin", ""], ["Tarkoma", "Sasu", ""]]}, {"id": "2003.05239", "submitter": "Laszlo Gyongyosi", "authors": "Laszlo Gyongyosi, Sandor Imre", "title": "Entanglement Accessibility Measures for the Quantum Internet", "comments": null, "journal-ref": "Quantum Inf Process 19, 115 (2020)", "doi": "10.1007/s11128-020-2605-y", "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define metrics and measures to characterize the ratio of accessible\nquantum entanglement for complex network failures in the quantum Internet. A\ncomplex network failure models a situation in the quantum Internet in which a\nset of quantum nodes and a set of entangled connections become unavailable. A\ncomplex failure can cover a quantum memory failure, a physical link failure, an\neavesdropping activity, or any other random physical failure scenario. Here, we\ndefine the terms entanglement accessibility ratio, cumulative probability of\nentanglement accessibility ratio, probabilistic reduction of entanglement\naccessibility ratio, domain entanglement accessibility ratio, and occurrence\ncoefficient. The proposed methods can be applied to an arbitrary topology\nquantum network to extract relevant statistics and to handle the quantum\nnetwork failure scenarios in the quantum Internet.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 11:56:04 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Gyongyosi", "Laszlo", ""], ["Imre", "Sandor", ""]]}, {"id": "2003.05244", "submitter": "Laszlo Gyongyosi", "authors": "Laszlo Gyongyosi, Sandor Imre", "title": "Optimizing High-Efficiency Quantum Memory with Quantum Machine Learning\n  for Near-Term Quantum Devices", "comments": null, "journal-ref": "Sci Rep 10, 135 (2020)", "doi": "10.1038/s41598-019-56689-0", "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum memories are a fundamental of any global-scale quantum Internet,\nhigh-performance quantum networking and near-term quantum computers. A main\nproblem of quantum memories is the low retrieval efficiency of the quantum\nsystems from the quantum registers of the quantum memory. Here, we define a\nnovel quantum memory called high-retrieval-efficiency (HRE) quantum memory for\nnear-term quantum devices. An HRE quantum memory unit integrates local unitary\noperations on its hardware level for the optimization of the readout procedure\nand utilizes the advanced techniques of quantum machine learning. We define the\nintegrated unitary operations of an HRE quantum memory, prove the learning\nprocedure, and evaluate the achievable output signal-to-noise ratio values. We\nprove that the local unitaries of an HRE quantum memory achieve the\noptimization of the readout procedure in an unsupervised manner without the use\nof any labeled data or training sequences. We show that the readout procedure\nof an HRE quantum memory is realized in a completely blind manner without any\ninformation about the input quantum system or about the unknown quantum\noperation of the quantum register. We evaluate the retrieval efficiency of an\nHRE quantum memory and the output SNR (signal-to-noise ratio). The results are\nparticularly convenient for gate-model quantum computers and the near-term\nquantum devices of the quantum Internet.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 12:01:03 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Gyongyosi", "Laszlo", ""], ["Imre", "Sandor", ""]]}, {"id": "2003.05245", "submitter": "Laszlo Gyongyosi", "authors": "Laszlo Gyongyosi, Sandor Imre", "title": "Theory of Noise-Scaled Stability Bounds and Entanglement Rate\n  Maximization in the Quantum Internet", "comments": null, "journal-ref": "Sci Rep 10, 2745 (2020)", "doi": "10.1038/s41598-020-58200-6", "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crucial problems of the quantum Internet are the derivation of stability\nproperties of quantum repeaters and theory of entanglement rate maximization in\nan entangled network structure. The stability property of a quantum repeater\nentails that all incoming density matrices can be swapped with a target density\nmatrix. The strong stability of a quantum repeater implies stable entanglement\nswapping with the boundness of stored density matrices in the quantum memory\nand the boundness of delays. Here, a theoretical framework of noise-scaled\nstability analysis and entanglement rate maximization is conceived for the\nquantum Internet. We define the term of entanglement swapping set that models\nthe status of quantum memory of a quantum repeater with the stored density\nmatrices. We determine the optimal entanglement swapping method that maximizes\nthe entanglement rate of the quantum repeaters at the different entanglement\nswapping sets as function of the noise of the local memory and local\noperations. We prove the stability properties for non-complete entanglement\nswapping sets, complete entanglement swapping sets and perfect entanglement\nswapping sets. We prove the entanglement rates for the different entanglement\nswapping sets and noise levels. The results can be applied to the experimental\nquantum Internet.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 12:04:11 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Gyongyosi", "Laszlo", ""], ["Imre", "Sandor", ""]]}, {"id": "2003.05256", "submitter": "Renato Cruz", "authors": "Renato Cruz, Helder Fontes, Jos\\'e Ruela, Manuel Ricardo, Rui Campos", "title": "On the Reproduction of Real Wireless Channel Occupancy in ns-3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless networking R&D we typically depend on simulation and\nexperimentation to evaluate and validate new networking solutions. While\nsimulations allow full control over the scenario conditions, real-world\nexperiments are influenced by external random phenomena and may produce hardly\nrepeatable and reproducible results, impacting the validation of the solution\nunder evaluation. Previously, we have proposed the Trace-based Simulation (TS)\napproach to address the problem. TS uses traces of radio link quality and\nposition of nodes to accurately reproduce past experiments in ns-3. Yet, in its\ncurrent version, the TS approach is not compatible with scenarios where the\nradio spectrum is shared with concurrent networks, as it does not reproduce\ntheir channel occupancy. In this paper, we introduce the\nInterferencePropagationLossModel and a modified MacLow to allow reproducing the\nchannel occupancy experienced in past experiments. To validate the proposed\nmodels, the network throughput was measured in different experiments performed\nin the w-iLab.t testbed, controlling the channel occupancy introduced by\nconcurrent networks. The experimental results were then compared with the\nnetwork throughput achieved using the improved TS approach, the legacy TS\napproach, and pure simulation, validating the new proposed models and\nconfirming their relevance to reproduce experiments previously executed in real\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 12:32:15 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Cruz", "Renato", ""], ["Fontes", "Helder", ""], ["Ruela", "Jos\u00e9", ""], ["Ricardo", "Manuel", ""], ["Campos", "Rui", ""]]}, {"id": "2003.05290", "submitter": "Rentao Gu", "authors": "Rentao Gu, Zeyuan Yang, Yuefeng Ji", "title": "Machine Learning for Intelligent Optical Networks: A Comprehensive\n  Survey", "comments": null, "journal-ref": "Journal of Network and Computer Applications, Volume 157, May\n  2020, no.102576", "doi": "10.1016/j.jnca.2020.102576", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of Internet and communication systems, both in\nservices and technologies, communication networks have been suffering\nincreasing complexity. It is imperative to improve intelligence in\ncommunication network, and several aspects have been incorporating with\nArtificial Intelligence (AI) and Machine Learning (ML). Optical network, which\nplays an important role both in core and access network in communication\nnetworks, also faces great challenges of system complexity and the requirement\nof manual operations. To overcome the current limitations and address the\nissues of future optical networks, it is essential to deploy more intelligence\ncapability to enable autonomous and exible network operations. ML techniques\nare proved to have superiority on solving complex problems; and thus recently,\nML techniques have been used for many optical network applications. In this\npaper, a detailed survey of existing applications of ML for intelligent optical\nnetworks is presented. The applications of ML are classified in terms of their\nuse cases, which are categorized into optical network control and resource\nmanagement, and optical networks monitoring and survivability. The use cases\nare analyzed and compared according to the used ML techniques. Besides, a\ntutorial for ML applications is provided from the aspects of the introduction\nof common ML algorithms, paradigms of ML, and motivations of applying ML.\nLastly, challenges and possible solutions of ML application in optical networks\nare also discussed, which intends to inspire future innovations in leveraging\nML to build intelligent optical networks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 13:51:38 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Gu", "Rentao", ""], ["Yang", "Zeyuan", ""], ["Ji", "Yuefeng", ""]]}, {"id": "2003.05489", "submitter": "Thomas Gerard", "authors": "Thomas Gerard, Christopher Parsonson, Zacharaya Shabka, Polina Bayvel,\n  Domani\\c{c} Lavery, Georgios Zervas", "title": "SWIFT: Scalable Ultra-Wideband Sub-Nanosecond Wavelength Switching for\n  Data Centre Networks", "comments": "3 pages, 3 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a time-multiplexed DS-DBR/SOA-gated system to deliver low-power\nfast tuning across S-/C-/L-bands. Sub-ns switching is demonstrated, supporting\n122$\\times$50 GHz channels over 6.05 THz using AI techniques.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 19:05:24 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Gerard", "Thomas", ""], ["Parsonson", "Christopher", ""], ["Shabka", "Zacharaya", ""], ["Bayvel", "Polina", ""], ["Lavery", "Domani\u00e7", ""], ["Zervas", "Georgios", ""]]}, {"id": "2003.05685", "submitter": "Hamza Khan", "authors": "Hamza Khan, M. Majid Butt, Sumudu Samarakoon, Philippe Sehier, and\n  Mehdi Bennis", "title": "Deep Learning Assisted CSI Estimation for Joint URLLC and eMBB Resource\n  Allocation", "comments": "6 Pages, 5 Figures, Accepted for publication in: IEEE ICC 2020\n  Workshop on Ultra-high speed, Low latency and Massive Communication for\n  futuristic 6G Networks (ULMC6GN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-input multiple-output (MIMO) is a key for the fifth generation (5G)\nand beyond wireless communication systems owing to higher spectrum efficiency,\nspatial gains, and energy efficiency. Reaping the benefits of MIMO transmission\ncan be fully harnessed if the channel state information (CSI) is available at\nthe transmitter side. However, the acquisition of transmitter side CSI entails\nmany challenges. In this paper, we propose a deep learning assisted CSI\nestimation technique in highly mobile vehicular networks, based on the fact\nthat the propagation environment (scatterers, reflectors) is almost identical\nthereby allowing a data driven deep neural network (DNN) to learn the\nnon-linear CSI relations with negligible overhead. Moreover, we formulate and\nsolve a dynamic network slicing based resource allocation problem for vehicular\nuser equipments (VUEs) requesting enhanced mobile broadband (eMBB) and\nultra-reliable low latency (URLLC) traffic slices. The formulation considers a\nthreshold rate violation probability minimization for the eMBB slice while\nsatisfying a probabilistic threshold rate criterion for the URLLC slice.\nSimulation result shows that an overhead reduction of 50% can be achieved with\n12% increase in threshold violations compared to an ideal case with perfect CSI\nknowledge.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 10:00:08 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Khan", "Hamza", ""], ["Butt", "M. Majid", ""], ["Samarakoon", "Sumudu", ""], ["Sehier", "Philippe", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2003.05819", "submitter": "Antonio Albanese", "authors": "Antonio Albanese and Vincenzo Sciancalepore and Xavier Costa-P\\'erez", "title": "SARDO: An Automated Search-and-Rescue Drone-based Solution for Victims\n  Localization", "comments": null, "journal-ref": "IEEE Transactions on Mobile Computing ( Early Access ), 2021", "doi": "10.1109/TMC.2021.3051273", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural disasters affect millions of people every year. Finding missing\npersons in the shortest possible time is of crucial importance to reduce the\ndeath toll. This task is especially challenging when victims are sparsely\ndistributed in large and/or difficult-to-reach areas and cellular networks are\ndown. In this paper we present SARDO, a drone-based search and rescue solution\nthat exploits the high penetration rate of mobile phones in the society to\nlocalize missing people. SARDO is an autonomous, all-in-one drone-based mobile\nnetwork solution that does not require infrastructure support or mobile phones\nmodifications. It builds on novel concepts such as pseudo-trilateration\ncombined with machine-learning techniques to efficiently locate mobile phones\nin a given area. Our results, with a prototype implementation in a field-trial,\nshow that SARDO rapidly determines the location of mobile phones (~3 min/UE) in\na given area with an accuracy of few tens of meters and at a low battery\nconsumption cost (~5%). State-of-the-art localization solutions for disaster\nscenarios rely either on mobile infrastructure support or exploit onboard\ncameras for human/computer vision, IR, thermal-based localization. To the best\nof our knowledge, SARDO is the first drone-based cellular search-and-rescue\nsolution able to accurately localize missing victims through mobile phones.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 14:33:30 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Albanese", "Antonio", ""], ["Sciancalepore", "Vincenzo", ""], ["Costa-P\u00e9rez", "Xavier", ""]]}, {"id": "2003.05882", "submitter": "David Grimsman", "authors": "David Grimsman, Joao P Hespanha, Jason R Marden", "title": "Stackelberg Equilibria for Two-Player Network Routing Games on Parallel\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider a two-player zero-sum network routing game in which a router\nwants to maximize the amount of legitimate traffic that flows from a given\nsource node to a destination node and an attacker wants to block as much\nlegitimate traffic as possible by flooding the network with malicious traffic.\nWe address scenarios with asymmetric information, in which the router must\nreveal its policy before the attacker decides how to distribute the malicious\ntraffic among the network links, which is naturally modeled by the notion of\nStackelberg equilibria. The paper focuses on parallel networks, and includes\nthree main contributions: we show that computing the optimal attack policy\nagainst a given routing policy is an NP-hard problem; we establish conditions\nunder which the Stackelberg equilibria lead to no regret; and we provide a\nmetric that can be used to quantify how uncertainty about the attacker's\ncapabilities limits the router's performance.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 16:22:57 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Grimsman", "David", ""], ["Hespanha", "Joao P", ""], ["Marden", "Jason R", ""]]}, {"id": "2003.06013", "submitter": "Jeongsik Choi", "authors": "Jeongsik Choi and Yang-Seok Choi", "title": "Calibration-Free Positioning Technique Using Wi-Fi Ranging and Built-in\n  Sensors of Mobile Devices", "comments": "14 pages, 16 figures, demo video is available:\n  https://youtu.be/_FnznD1gxV0", "journal-ref": null, "doi": "10.1109/JIOT.2020.3004774", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As positioning solutions integrate multiple components to improve accuracy,\nthe number of parameters that require calibration has increased. This paper\nstudies a calibration-free positioning technique using Wi-Fi ranging and\npedestrian dead reckoning (PDR), where every parameter in the system is\noptimized in real-time. This significantly decreases the time and effort\nrequired to perform manual calibration procedures and enables the positioning\nsolution to achieve robust performance in various situations. Additionally,\nthis paper studies an efficient way of performing irregular Wi-Fi ranging\nprocedures to improve battery life and network performance of mobile devices.\nThe positioning performance of the proposed method was verified using a\nreal-time Android application on several mobile devices under a large indoor\noffice environment. Without any calibration, the proposed method achieved up to\n1.38 m average positioning accuracy for received signal strength (RSS)-based\nranging scenarios, which differs only by 30 cm from the benchmark assuming\nperfect calibration. In addition, the proposed method achieved up to 1.04 m\naccuracy for round trip time (RTT)-based ranging scenarios with a 40 MHz\nbandwidth configuration, which differs only by 10 cm from the benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 20:47:36 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 22:53:25 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Choi", "Jeongsik", ""], ["Choi", "Yang-Seok", ""]]}, {"id": "2003.06185", "submitter": "Martin Henze", "authors": "Dennis van der Velde, Martin Henze, Philipp Kathmann, Erik Wassermann,\n  Michael Andres, Detert Bracht, Raphael Ernst, George Hallak, Benedikt Klaer,\n  Philipp Linnartz, Benjamin Meyer, Simon Ofner, Tobias Pletzer, Richard\n  Sethmann", "title": "Methods for Actors in the Electric Power System to Prevent, Detect and\n  React to ICT Attacks and Failures", "comments": "6 pages, 4 figures, to be published in Proceedings of the 2020 6th\n  IEEE International Energy Conference (ENERGYCon)", "journal-ref": null, "doi": "10.1109/ENERGYCon48941.2020.9236523", "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental changes in power supply and increasing decentralization\nrequire more active grid operation and an increased integration of ICT at all\npower system actors. This trend raises complexity and increasingly leads to\ninteractions between primary grid operation and ICT as well as different power\nsystem actors. For example, virtual power plants control various assets in the\ndistribution grid via ICT to jointly market existing flexibilities. Failures of\nICT or targeted attacks can thus have serious effects on security of supply and\nsystem stability. This paper presents a holistic approach to providing methods\nspecifically for actors in the power system for prevention, detection, and\nreaction to ICT attacks and failures. The focus of our measures are solutions\nfor ICT monitoring, systems for the detection of ICT attacks and intrusions in\nthe process network, and the provision of actionable guidelines as well as a\npractice environment for the response to potential ICT security incidents.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 10:16:11 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["van der Velde", "Dennis", ""], ["Henze", "Martin", ""], ["Kathmann", "Philipp", ""], ["Wassermann", "Erik", ""], ["Andres", "Michael", ""], ["Bracht", "Detert", ""], ["Ernst", "Raphael", ""], ["Hallak", "George", ""], ["Klaer", "Benedikt", ""], ["Linnartz", "Philipp", ""], ["Meyer", "Benjamin", ""], ["Ofner", "Simon", ""], ["Pletzer", "Tobias", ""], ["Sethmann", "Richard", ""]]}, {"id": "2003.06197", "submitter": "Madhumitha Harishankar", "authors": "Madhumitha Harishankar, Dimitrios-Georgios Akestoridis, Sriram V.\n  Iyer, Aron Laszka, Carlee Joe-Wong, Patrick Tague", "title": "PayPlace: Secure and Flexible Operator-Mediated Payments in Blockchain\n  Marketplaces at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized marketplace applications demand fast, cheap and easy-to-use\ncryptocurrency payment mechanisms to facilitate high transaction volumes. The\nstandard solution for off-chain payments, state channels, are optimized for\nfrequent transactions between two entities and impose prohibitive liquidity and\ncapital requirements on payment senders for marketplace transactions. We\npropose PayPlace, a scalable off-chain protocol for payments between consumers\nand sellers. Using PayPlace, consumers establish a virtual unidirectional\npayment channel with an intermediary operator to pay for their transactions.\nUnlike state channels, however, the PayPlace operator can reference the\ncustodial funds accrued off-chain in these channels to in-turn make\ntamper-proof off-chain payments to merchants, without locking up corresponding\ncapital in channels with merchants. Our design ensures that new payments made\nto merchants are guaranteed to be safe once notarized and provably mitigates\nwell-known drawbacks in previous constructions like the data availability\nattack and ensures that neither consumers nor merchants need to be online to\nensure continued safety of their notarized funds. We show that the on-chain\nmonetary and computational costs for PayPlace is O(1) in the number of payment\ntransactions processed, and is near-constant in other parameters in most\nscenarios. PayPlace can hence scale the payment throughput for large-scale\nmarketplaces at no marginal cost and is orders of magnitude cheaper than the\nstate-of-art solution for non-pairwise off-chain payments, Zero Knowledge\nRollups.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 10:53:57 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 18:34:16 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 12:11:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Harishankar", "Madhumitha", ""], ["Akestoridis", "Dimitrios-Georgios", ""], ["Iyer", "Sriram V.", ""], ["Laszka", "Aron", ""], ["Joe-Wong", "Carlee", ""], ["Tague", "Patrick", ""]]}, {"id": "2003.06361", "submitter": "Xingqin Lin", "authors": "Xingqin Lin, Anders Furusk\\\"ar, Olof Liberg, Sebastian Euler", "title": "Sky High 5G: New Radio for Air-to-Ground Communications", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, mobile operators are starting to deploy Fifth-Generation (5G) networks\nto expand the coverage ubiquity of broadband wireless service. In contrast,\nin-flight connectivity remains limited and its quality of service does not\nalways meet the expectations. Embracing 5G New Radio (NR) in Air-to-Ground\n(A2G) communication systems can help narrow the gap between airborne and ground\nconnectivity. In this article, we focus on 5G NR based direct A2G\ncommunications. We first provide an overview of the existing A2G systems which\nare based on earlier generations of mobile technologies. Then we confirm the\nfeasibility of NR A2G systems with a performance study in a range of bands from\nbelow 7 GHz to millimeter wave frequencies. The results show that NR A2G\nsystems can provide significantly improved data rates for in-flight\nconnectivity. We also identify the major challenges associated with NR A2G\ncommunications, discuss enhancements to counteract the challenges, and point\nout fruitful avenues for future research.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 16:14:09 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Lin", "Xingqin", ""], ["Furusk\u00e4r", "Anders", ""], ["Liberg", "Olof", ""], ["Euler", "Sebastian", ""]]}, {"id": "2003.06397", "submitter": "Stephen DiAdamo", "authors": "Stephen DiAdamo, Janis N\\\"otzel, Benjamin Zanger, Mehmet Mert Be\\c{s}e", "title": "QuNetSim: A Software Framework for Quantum Networks", "comments": "11 pages, 6 figures. To appear in IEEE Transactions on Quantum\n  Engineering", "journal-ref": null, "doi": "10.1109/TQE.2021.3092395", "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As quantum internet technologies develop, the need for simulation software\nand education for quantum internet rises. QuNetSim aims to fill this need.\nQuNetSim is a Python software framework that can be used to simulate quantum\nnetworks up to the network layer. The goal of QuNetSim is to make it easier to\ninvestigate and test quantum networking protocols over various quantum network\nconfigurations and parameters. The framework incorporates many known quantum\nnetwork protocols so that users can quickly build simulations and beginners can\neasily learn to implement their own quantum networking protocols.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 17:36:29 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 10:09:11 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 10:17:56 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 08:47:20 GMT"}, {"version": "v5", "created": "Wed, 23 Jun 2021 12:58:11 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["DiAdamo", "Stephen", ""], ["N\u00f6tzel", "Janis", ""], ["Zanger", "Benjamin", ""], ["Be\u015fe", "Mehmet Mert", ""]]}, {"id": "2003.06477", "submitter": "Moritz Steiner", "authors": "Utkarsh Goel, Stephen Ludin, Moritz Steiner", "title": "Web Performance with Android's Battery-Saver Mode", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A Web browser utilizes a device's CPU to parse HTML, build a Document Object\nModel, a Cascading Style Sheets Object Model, and render trees, and parse,\ncompile, and execute computationally-heavy JavaScript. A powerful CPU is\nrequired to perform these tasks as quickly as possible and provide the user\nwith a great experience. However, increased CPU performance comes with\nincreased power consumption and reduced battery life on mobile devices. As an\noption to extend battery life, Android offers a battery-saver mode that when\nactivated, turns off the power-hungry and faster processor cores and turns on\nthe battery-conserving and slower processor cores on the device. The transition\nfrom using faster processor cores to using slower processor cores throttles the\nCPU clock speed on the device, and therefore impacts the webpage load process.\nWe utilize a large-scale data-set collected by a real user monitoring system of\na major content delivery network to investigate the impact of Android's\nbattery-saver mode on various mobile Web performance metrics. Our analysis\nsuggests that users of select smartphones of Huawei and Sony experience a\nsudden or gradual degradation in Web performance when battery-saver mode is\nactive. Battery-saver mode on newer flagship smartphones, however, does not\nimpact the mobile Web performance. Finally, we encourage for new website design\ngoals that treat slow (and throttled-CPU) devices kindly in favor of improving\nend-user experience and suggest that Web performance measurements should be\naware of user device battery charge levels to correctly associate Web\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 20:43:38 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Goel", "Utkarsh", ""], ["Ludin", "Stephen", ""], ["Steiner", "Moritz", ""]]}, {"id": "2003.06786", "submitter": "Christos Efrem", "authors": "Christos N. Efrem, Athanasios D. Panagopoulos", "title": "On the Computation and Approximation of Outage Probability in Satellite\n  Networks with Smart Gateway Diversity", "comments": "8 pages, 2 tables, 3 figures", "journal-ref": "IEEE Transactions on Aerospace and Electronic Systems, vol. 57,\n  no. 1, pp. 476-484, Feb. 2021", "doi": "10.1109/TAES.2020.3022437", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utilization of extremely high frequency (EHF) bands can achieve very high\nthroughput in satellite networks (SatNets). Nevertheless, the severe rain\nattenuation at EHF bands imposes strict limitations on the system availability.\nSmart gateway diversity (SGD) is considered indispensable in order to guarantee\nthe required availability with reasonable cost. In this context, we examine a\nload-sharing SGD (LS-SGD) architecture, which has been recently proposed in the\nliterature. For this diversity scheme, we define the system outage probability\n(SOP) using a rigorous probabilistic analysis based on the Poisson binomial\ndistribution (PBD), and taking into consideration the traffic demand as well as\nthe gateway (GW) capacity. Furthermore, we provide several methods for the\nexact and approximate calculation of SOP. As concerns the exact computation of\nSOP, a closed-form expression and an efficient algorithm based on a recursive\nformula are given, both with quadratic worst-case complexity in the number of\nGWs. Finally, the proposed approximation methods include well-known probability\ndistributions (binomial, Poisson, normal) and a Chernoff bound. According to\nthe numerical results, binomial and Poisson distributions are by far the most\naccurate approximation methods.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 10:01:56 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 09:59:51 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Efrem", "Christos N.", ""], ["Panagopoulos", "Athanasios D.", ""]]}, {"id": "2003.06834", "submitter": "Yunfei Meng", "authors": "Yunfei Meng, Zhiqiu Huang, Senzhang Wang, Guohua Shen, Changbo Ke", "title": "SOM-based DDoS Defense Mechanism using SDN for the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To effectively tackle the security threats towards the Internet of things, we\npropose a SOM-based DDoS defense mechanism using software-defined networking\n(SDN) in this paper. The main idea of the mechanism is to deploy a SDN-based\ngateway to protect the device services in the Internet of things. The gateway\nprovides DDoS defense mechanism based on SOM neural network. By means of\nSOM-based DDoS defense mechanism, the gateway can effectively identify the\nmalicious sensing devices in the IoT, and automatically block those malicious\ndevices after detecting them, so that it can effectively enforce the security\nand robustness of the system when it is under DDoS attacks. In order to\nvalidate the feasibility and effectiveness of the mechanism, we leverage POX\ncontroller and Mininet emulator to implement an experimental system, and\nfurther implement the aforementioned security enforcement mechanisms with\nPython. The final experimental results illustrate that the mechanism is truly\neffective under the different test scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 14:13:17 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 02:41:59 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Meng", "Yunfei", ""], ["Huang", "Zhiqiu", ""], ["Wang", "Senzhang", ""], ["Shen", "Guohua", ""], ["Ke", "Changbo", ""]]}, {"id": "2003.06884", "submitter": "Bryan Gingras MASc", "authors": "Bryan Gingras, Ali Pourranjbar, Georges Kaddoum", "title": "Collaborative Spectrum Sensing in Tactical Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose an algorithm for channel sensing, collaboration,\nand transmission for networks of Tactical Communication Systems that are facing\nintrusions from hostile Jammers. Members of the network begin by scanning the\nspectrum for Jammers, sharing this information with neighboring nodes, and\nmerging their respective sets of observation data into a decision vector\ncontaining the believed occupancy of each channel. A user can then use this\nvector to find a vacant channel for its transmission. We introduce the concept\nof nodes sharing these vectors with their peers, who then merge them into\nsuper-decision vectors, allowing each node to better identify and select\ntransmission channels. We consider fading scenarios that substantially limit\nthe reliability of the users' observations, unless they cooperate to increase\nthe trustworthiness of their sensing data. We propose a pseudo-random channel\nselection algorithm that strikes a balance between sensing reliability with the\nnumber of channels being sensed. Simulation results show that the proposed\nsystem improves the network's overall knowledge of the spectrum and the rate of\nJammer-free transmissions while limiting added computational complexity to the\nnodes of the network, despite the Jammers' unpredictable nature.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 18:17:25 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Gingras", "Bryan", ""], ["Pourranjbar", "Ali", ""], ["Kaddoum", "Georges", ""]]}, {"id": "2003.07015", "submitter": "Rohit Singh Mr", "authors": "Rohit Singh and Douglas Sicker", "title": "SHINE (Strategies for High-frequency INdoor Environments) with Efficient\n  THz-AP Placement", "comments": "7 pages, 11 figures, 1 table, To appear in IEEE 91st Vehicular\n  Technology Conference: VTC2020-Spring, W1: Terahertz Communication for Future\n  Wireless Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing demand for ultra-high throughput in ultra-dense networks might\ntake a toll on 5G capacity. Moreover, with Internet-of-Things (IoT) and the\ngrowing use-cases for indoor killer-applications, it will be necessary to look\nbeyond 5G technologies. One such promising technology is to move higher in the\nfrequencies, such as the THz ($300$ $GHz$-$10$ $THz$) spectrum. THz has a\nmassive number of greenfield-contiguous channels ranging from $10$ $GHz$ to\n$200$ $GHz$ (best case), which was not available in the traditional radio\nfrequency (RF) or millimeter wave (mmWave) bands. Although THz has immense\npotential to cater to such demands, it comes with numerous challenges revolving\naround hardware, link budget, mobility, blockages, scheduling, and deployment.\nTerahertz access points (THz-APs) are sensitive to deployment and can\ncritically impact a system\\textquotesingle s dynamics (i.e., coverage,\nthroughput, and efficiency). In this paper, we present Strategies for\nHigh-frequency INdoor Environments or SHINE, which focuses on efficient AP\ndeployment in the THz spectrum and draws motivation from approaches used indoor\nto improve lighting conditions. Due to THz\\textquotesingle s limited coverage\narea of a few meters, the number of THz-APs required to satisfy a densely\npopulated room will be higher compared to today's single router/box/AP model.\nThis increased number of THz-APs will not only increase the operational costs,\nbut also (in some cases) can make the system inefficient. Through SHINE, we\nexplore the deployment-related challenges and propose strategies to mitigate\nthe same.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 04:20:55 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Singh", "Rohit", ""], ["Sicker", "Douglas", ""]]}, {"id": "2003.07107", "submitter": "Guofa Cai", "authors": "Guofa Cai, Yi Fang, Pingping Chen, Guojun Han, Guoen Cai, and Yang\n  Song", "title": "Design of an MISO-SWIPT-Aided Code-Index Modulated Multi-Carrier M-DCSK\n  System for e-Health IoT", "comments": "14 pages, 12 figures, accepted by IEEE Journal on Selected Areas in\n  Communications, 2020.03.15", "journal-ref": "IEEE Journal on Selected Areas in Communications,2020.03.15", "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code index modulated multi-carrier M-ary differential chaos shift keying\n(CIM-MC-M-DCSK) system not only inherits low-power and low-complexity\nadvantages of the conventional DCSK system, but also significantly increases\nthe transmission rate. This feature is of particular importance to Internet of\nThings (IoT) with trillions of low-cost devices. In particular, for e-health\nIoT applications, an efficient transmission scheme is designed to solve the\nchallenge of the limited battery capacity for numerous user equipments served\nby one base station. In this paper, a new multiple-input-single-output\nsimultaneous wireless information and power transfer (MISO-SWIPT) scheme for\nCIM-MC-M-DCSK system is proposed by utilizing orthogonal characteristic of\nchaotic signals with different initial values. The proposed system adopts power\nsplitting mode, which is very promising for simultaneously providing energy and\ntransmitting information of the user equipments without any external power\nsupply. In particular, the new system can achieve desirable\nanti-multipath-fading capability without using channel estimator. Moreover, the\nanalytical bit-error-rate expression of the proposed system is derived over\nmultipath Rayleigh fading channels. Furthermore, the spectral efficiency and\nenergy efficiency of the proposed system are analyzed. Simulation results not\nonly validate the analytical expressions, but also demonstrate the superiority\nof the proposed system.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 10:51:06 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Cai", "Guofa", ""], ["Fang", "Yi", ""], ["Chen", "Pingping", ""], ["Han", "Guojun", ""], ["Cai", "Guoen", ""], ["Song", "Yang", ""]]}, {"id": "2003.07133", "submitter": "Anna Maria Mandalari", "authors": "Anna Maria Mandalari (1), Roman Kolcun (1), Hamed Haddadi (1), Daniel\n  J. Dubois (2) and David Choffnes (2) ((1) Imperial College London, (2)\n  Northeastern University)", "title": "Towards Automatic Identification and Blocking of Non-Critical IoT\n  Traffic Destinations", "comments": "5 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The consumer Internet of Things (IoT) space has experienced a significant\nrise in popularity in the recent years. From smart speakers, to baby monitors,\nand smart kettles and TVs, these devices are increasingly found in households\naround the world while users may be unaware of the risks associated with owning\nthese devices. Previous work showed that these devices can threaten\nindividuals' privacy and security by exposing information online to a large\nnumber of service providers and third party analytics services. Our analysis\nshows that many of these Internet connections (and the information they expose)\nare neither critical, nor even essential to the operation of these devices.\nHowever, automatically separating out critical from non-critical network\ntraffic for an IoT device is nontrivial, and requires expert analysis based on\nmanual experimentation in a controlled setting. In this paper, we investigate\nwhether it is possible to automatically classify network traffic destinations\nas either critical (essential for devices to function properly) or not, hence\nallowing the home gateway to act as a selective firewall to block undesired,\nnon-critical destinations. Our initial results demonstrate that some IoT\ndevices contact destinations that are not critical to their operation, and\nthere is no impact on device functionality if these destinations are blocked.\nWe take the first steps towards designing and evaluating IoTrimmer, a framework\nfor automated testing and analysis of various destinations contacted by\ndevices, and selectively blocking the ones that do not impact device\nfunctionality.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 11:53:52 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Mandalari", "Anna Maria", ""], ["Kolcun", "Roman", ""], ["Haddadi", "Hamed", ""], ["Dubois", "Daniel J.", ""], ["Choffnes", "David", ""]]}, {"id": "2003.07191", "submitter": "Monowar Hasan", "authors": "Monowar Hasan, Sibin Mohan, Takayuki Shimizu, and Hongsheng Lu", "title": "Securing Vehicle-to-Everything (V2X) Communication Platforms", "comments": "Accepted for publication, IEEE Transactions on Intelligent Vehicles,\n  March 2020. arXiv admin note: text overlap with arXiv:1610.06810 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicular wireless technology enables vehicles to exchange information\nat any time, from any place, to any network -- forms the vehicle-to-everything\n(V2X) communication platforms. Despite benefits, V2X applications also face\ngreat challenges to security and privacy -- a very valid concern since breaches\nare not uncommon in automotive communication networks and applications. In this\nsurvey, we provide an extensive overview of V2X ecosystem. We also review main\nsecurity/privacy issues, current standardization activities and existing\ndefense mechanisms proposed within the V2X domain. We then identified semantic\ngaps of existing security solutions and outline possible open issues.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 18:52:43 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hasan", "Monowar", ""], ["Mohan", "Sibin", ""], ["Shimizu", "Takayuki", ""], ["Lu", "Hongsheng", ""]]}, {"id": "2003.07262", "submitter": "Abdelhakim Hannousse", "authors": "Abdelhakim Hannousse, Salima Yahiouche", "title": "Securing Microservices and Microservice Architectures: A Systematic\n  Mapping Study", "comments": null, "journal-ref": "Computer Science Review 41C (2021) 100415", "doi": "10.1016/j.cosrev.2021.100415", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Microservice architectures (MSA) are becoming trending alternatives to\nexisting software development paradigms notably for developing complex and\ndistributed applications. Microservices emerged as an architectural design\npattern aiming to address the scalability and ease the maintenance of online\nservices. However, security breaches have increased threatening availability,\nintegrity and confidentiality of microservice-based systems. A growing body of\nliterature is found addressing security threats and security mechanisms to\nindividual microservices and microservice architectures. The aim of this study\nis to provide a helpful guide to developers about already recognized threats on\nmicroservices and how they can be detected, mitigated or prevented; we also aim\nto identify potential research gaps on securing MSA. In this paper, we conduct\na systematic mapping in order to categorize threats on MSA with their security\nproposals. Therefore, we extracted threats and details of proposed solutions\nreported in selected studies. Obtained results are used to design a lightweight\nontology for security patterns of MSA. The ontology can be queried to identify\nsource of threats, security mechanisms used to prevent each threat,\napplicability layer and validation techniques used for each mechanism. The\nsystematic search yielded 1067 studies of which 46 are selected as primary\nstudies. The results of the mapping revealed an unbalanced research focus in\nfavor of external attacks; auditing and enforcing access control are the most\ninvestigated techniques compared with prevention and mitigation. Additionally,\nwe found that most proposed solutions are soft-infrastructure applicable layer\ncompared with other layers such as communication and deployment. We also found\nthat performance analysis and case studies are the most used validation\ntechniques of security proposals.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 14:53:56 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 23:23:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Hannousse", "Abdelhakim", ""], ["Yahiouche", "Salima", ""]]}, {"id": "2003.07396", "submitter": "Moritz Steiner", "authors": "Utkarsh Goel, Moritz Steiner", "title": "System to Identify and Elide Superfluous JavaScript Code for Faster\n  Webpage Loads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many websites import large JavaScript (JS) libraries to customize and enhance\nuser experiences. Our data shows that many JS libraries are only partially\nutilized during a page load, and therefore, contain superfluous code that is\nnever executed. Many top-ranked websites contain up to hundreds of kilobytes of\ncompressed superfluous code and a JS resource on a median page contains 31%\nsuperfluous code. Superfluous JS code inflates the page weight, and thereby,\nthe time to download, parse, and compile a JS resource. It is therefore\nimportant to monitor the usage and optimize the payload of JS resources to\nimprove Web performance. However, given that the webpage design and\nfunctionality could depend on a user's preferences or device, among many other\nfactors, actively loading webpages in controlled environments cannot cover all\npossible conditions in which webpage content and functionality changes. In this\npaper, we show that passive measurement techniques, such as real user\nmonitoring systems (RUM), that monitor the performance of real user page loads\nunder different conditions can be leveraged to identify superfluous code. Using\na custom man-in-the-middle proxy (similar to a content delivery network's proxy\nserver), we designed a systematic approach for website developers that relies\non pages loaded by real users to passively identify superfluous code on JS\nresources. We then elide any superfluous code from JS resources before\nsubsequent page load requests. Our data shows that eliding superfluous JS code\nimproves the median page load time by 5% and by at least 10% for pages in the\nlong tail. Through results presented in this paper, we motivate for the need\nfor rigorous monitoring of the usage of JS resources under different real world\nconditions, with the goal to improve Web performance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:29:31 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Goel", "Utkarsh", ""], ["Steiner", "Moritz", ""]]}, {"id": "2003.07599", "submitter": "Xiaoli Xu", "authors": "Xiaoli Xu, Yong Zeng", "title": "Time-Weighted Coverage of Integrated Aerial and Ground Networks for\n  Post-Disaster Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new three dimensional (3D) networking\narchitecture with integrated aerial and ground base stations (BSs) for swift\npost-disaster communication recovery. By exploiting their respective advantages\nin terms of response time, coverage area, and operational duration, the\nproposed network is highly heterogeneous, consisting of sustained ground BSs,\nground-vehicle mounted BSs, dropping-off BSs and flying BSs. To reflect the\nimportance of swift communication recovery and the dynamics of coverage area in\npost-disaster scenarios, we propose a new performance metric called\n``time-weighted coverage}\", which is an integration of the achieved\ncommunication coverage area multiplied with a weighting function over time. By\nchoosing different weighting functions, the network deployment can be designed\nto achieve tradeoffs between the ``swift communication recovery\" and ``stable\ncommunication coverage\". Simulation results show that the proposed integrated\naerial and ground network has high implementation flexibility and it can\nsignificantly enhance the communication coverage compared with the conventional\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 09:29:45 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Xu", "Xiaoli", ""], ["Zeng", "Yong", ""]]}, {"id": "2003.07651", "submitter": "Madyan Alsenwi", "authors": "Madyan Alsenwi, Nguyen H. Tran, Mehdi Bennis, Shashi Raj Pandey,\n  Anupam Kumar Bairagi, and Choong Seon Hong", "title": "Intelligent Resource Slicing for eMBB and URLLC Coexistence in 5G and\n  Beyond: A Deep Reinforcement Learning Based Approach", "comments": "This work was submitted to the IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the resource slicing problem in a dynamic\nmultiplexing scenario of two distinct 5G services, namely Ultra-Reliable Low\nLatency Communications (URLLC) and enhanced Mobile BroadBand (eMBB). While eMBB\nservices focus on high data rates, URLLC is very strict in terms of latency and\nreliability. In view of this, the resource slicing problem is formulated as an\noptimization problem that aims at maximizing the eMBB data rate subject to a\nURLLC reliability constraint, while considering the variance of the eMBB data\nrate to reduce the impact of immediately scheduled URLLC traffic on the eMBB\nreliability. To solve the formulated problem, an optimization-aided Deep\nReinforcement Learning (DRL) based framework is proposed, including: 1) eMBB\nresource allocation phase, and 2) URLLC scheduling phase. In the first phase,\nthe optimization problem is decomposed into three subproblems and then each\nsubproblem is transformed into a convex form to obtain an approximate resource\nallocation solution. In the second phase, a DRL-based algorithm is proposed to\nintelligently distribute the incoming URLLC traffic among eMBB users.\nSimulation results show that our proposed approach can satisfy the stringent\nURLLC reliability while keeping the eMBB reliability higher than 90%.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 11:41:48 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 07:49:26 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 09:06:34 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Alsenwi", "Madyan", ""], ["Tran", "Nguyen H.", ""], ["Bennis", "Mehdi", ""], ["Pandey", "Shashi Raj", ""], ["Bairagi", "Anupam Kumar", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2003.07748", "submitter": "Lanfranco Zanzi", "authors": "Lanfranco Zanzi, Antonio Albanese, Vincenzo Sciancalepore, Xavier\n  Costa-Perez", "title": "NSBchain: A Secure Blockchain Framework for Network Slicing Brokerage", "comments": null, "journal-ref": null, "doi": "10.1109/ICC40277.2020.9149414", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of revolutionary technologies, such as virtualization and\nsoftwarization, a novel concept for 5G networks and beyond has been unveiled:\nNetwork Slicing. Initially driven by the research community, standardization\nbodies as 3GPP have embraced it as a promising solution to revolutionize the\ntraditional mobile telecommunication market by enabling new business models\nopportunities. Network Slicing is envisioned to open up the telecom market to\nnew players such as Industry Verticals, e.g. automotive, smart factories,\ne-health, etc. Given the large number of potential new business players, dubbed\nas network tenants, novel solutions are required to accommodate their needs in\na cost-efficient and secure manner. In this paper, we propose NSBchain, a novel\nnetwork slicing brokering (NSB) solution, which leverages on the widely adopted\nBlockchain technology to address the new business models needs beyond\ntraditional network sharing agreements. NSBchain defines a new entity, the\nIntermediate Broker (IB), which enables Infrastructure Providers (InPs) to\nallocate network resources to IBs through smart contracts and IBs to assign and\nre-distribute their resources among tenants in a secure, automated and scalable\nmanner. We conducted an extensive performance evaluation by means of an\nopen-source blockchain platform that proves the feasibility of our proposed\nframework considering a large number of tenants and two different consensus\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 14:39:19 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zanzi", "Lanfranco", ""], ["Albanese", "Antonio", ""], ["Sciancalepore", "Vincenzo", ""], ["Costa-Perez", "Xavier", ""]]}, {"id": "2003.08239", "submitter": "Jaafar Elmirghani", "authors": "Mohammed S. Hadi, Ahmed Q. Lawey, Taisir E. H. El-Gorashi, and Jaafar\n  M. H. Elmirghani", "title": "Patient-centric HetNets Powered by Machine Learning and Big Data\n  Analytics for 6G Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having a cognitive and self-optimizing network that proactively adapts not\nonly to channel conditions, but also according to its users needs can be one of\nthe highest forthcoming priorities of future 6G Heterogeneous Networks\n(HetNets). In this paper, we introduce an interdisciplinary approach linking\nthe concepts of e-healthcare, priority, big data analytics (BDA) and radio\nresource optimization in a multi-tier 5G network. We employ three machine\nlearning (ML) algorithms, namely, naive Bayesian (NB) classifier, logistic\nregression (LR), and decision tree (DT), working as an ensemble system to\nanalyze historical medical records of stroke out-patients (OPs) and readings\nfrom body-attached internet-of-things (IoT) sensors to predict the likelihood\nof an imminent stroke. We convert the stroke likelihood into a risk factor\nfunctioning as a priority in a mixed integer linear programming (MILP)\noptimization model. Hence, the task is to optimally allocate physical resource\nblocks (PRBs) to HetNet users while prioritizing OPs by granting them high gain\nPRBs according to the severity of their medical state. Thus, empowering the OPs\nto send their critical data to their healthcare provider with minimized delay.\nTo that end, two optimization approaches are proposed, a weighted sum rate\nmaximization (WSRMax) approach and a proportional fairness (PF) approach. The\nproposed approaches increased the OPs average signal to interference plus noise\n(SINR) by 57% and 95%, respectively. The WSRMax approach increased the system\ntotal SINR to a level higher than that of the PF approach, nevertheless, the PF\napproach yielded higher SINRs for the OPs, better fairness and a lower margin\nof error.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 14:27:06 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Hadi", "Mohammed S.", ""], ["Lawey", "Ahmed Q.", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2003.08304", "submitter": "Jie Li", "authors": "Jie Li, Yong Zhou, and He Chen", "title": "Age of Information for Multicast Transmission with Fixed and Random\n  Deadlines in IoT Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:2002.02125", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the multicast transmission of a real-time Internet\nof Things (IoT) system, where an access point (AP) transmits time-stamped\nstatus updates to multiple IoT devices. Different from the existing studies\nthat only considered multicast transmission without deadlines, we enforce a\ndeadline for the service time of each multicast status update, taking into\naccount both the fixed and randomly distributed deadlines. In particular, a\nstatus update is dropped when either its deadline expires or it is successfully\nreceived by a certain number of IoT devices. Considering deadlines is important\nfor many emerging IoT applications, where the outdated status updates are of no\nuse to IoT devices. We evaluate the timeliness of the status update delivery by\napplying a recently proposed metric, named the age of information (AoI), which\nis defined as the time elapsed since the generation of the most recently\nreceived status update. After deriving the distributions of the service time\nfor all possible reception outcomes at IoT devices, we manage to obtain the\nclosed-form expressions of both the average AoI and the average peak AoI.\nSimulations validate the performance analysis, which reveals that the multicast\ntransmission with deadlines achieves a lower average AoI than that without\ndeadlines and there exists an optimal value of the deadline that can minimize\nthe average (peak) AoI. Results also show that the fixed and random deadlines\nhave respective advantages in different deadline regimes.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 02:56:14 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Li", "Jie", ""], ["Zhou", "Yong", ""], ["Chen", "He", ""]]}, {"id": "2003.08372", "submitter": "Seyed Mohammadhossein Tabatabaee", "authors": "Seyed Mohammadhossein Tabatabaee, Jean-Yves Le Boudec, Marc Boyer", "title": "Interleaved Weighted Round-Robin: A Network Calculus Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted Round-Robin (WRR) is often used, due to its simplicity, for\nscheduling packets or tasks. With WRR, a number of packets equal to the weight\nallocated to a flow can be served consecutively, which leads to a bursty\nservice. Interleaved Weighted Round-Robin (IWRR) is a variant that mitigates\nthis effect. We are interested in finding bounds on worst-case delay obtained\nwith IWRR. To this end, we use a network calculus approach and find a strict\nservice curve for IWRR. The result is obtained using the pseudo-inverse of a\nfunction. We show that the strict service curve is the best obtainable one, and\nthat delay bounds derived from it are tight (i.e., worst-case) for flows of\npackets of constant size. Furthermore, the IWRR strict service curve dominates\nthe strict service curve for WRR that was previously published. We provide some\nnumerical examples to illustrate the reduction in worst-case delays caused by\nIWRR compared to WRR.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:50:08 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 17:41:41 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 17:25:04 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Tabatabaee", "Seyed Mohammadhossein", ""], ["Boudec", "Jean-Yves Le", ""], ["Boyer", "Marc", ""]]}, {"id": "2003.08458", "submitter": "Mauro Piva", "authors": "Andrea Coletta, Gaia Maselli, Mauro Piva, Domenicomichele Silvestri,\n  Francesco Restuccia", "title": "My SIM is Leaking My Data: Exposing Self-Login Privacy Breaches in\n  Smartphones", "comments": "Abstract and Template: typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We expose a new security leak for smartphone users, which allows to stole\nuser personal data by accessing the mobile operator user page when auto-login\nis employed. We show how any \"apparently\" genuine app can steal these data from\nsome mobile operators, affecting more than 80% of Italian mobile smartphones.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 20:16:50 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 10:35:08 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 20:55:01 GMT"}, {"version": "v4", "created": "Wed, 8 Apr 2020 14:01:02 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Coletta", "Andrea", ""], ["Maselli", "Gaia", ""], ["Piva", "Mauro", ""], ["Silvestri", "Domenicomichele", ""], ["Restuccia", "Francesco", ""]]}, {"id": "2003.08473", "submitter": "Nikolaos Thomos", "authors": "Pantelis Maniotis and Nikolaos Thomos", "title": "Viewport-Aware Deep Reinforcement Learning Approach for 360$^o$ Video\n  Caching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  360$^o$ video is an essential component of VR/AR/MR systems that provides\nimmersive experience to the users. However, 360$^o$ video is associated with\nhigh bandwidth requirements. The required bandwidth can be reduced by\nexploiting the fact that users are interested in viewing only a part of the\nvideo scene and that users request viewports that overlap with each other.\nMotivated by the findings of recent works where the benefits of caching video\ntiles at edge servers instead of caching entire 360$^o$ videos were shown, in\nthis paper, we introduce the concept of virtual viewports that have the same\nnumber of tiles with the original viewports. The tiles forming these viewports\nare the most popular ones for each video and are determined by the users'\nrequests. Then, we propose a proactive caching scheme that assumes unknown\nvideos' and viewports' popularity. Our scheme determines which videos to cache\nas well as which is the optimal virtual viewport per video. Virtual viewports\npermit to lower the dimensionality of the cache optimization problem. To solve\nthe problem, we first formulate the content placement of 360$^o$ videos in edge\ncache networks as a Markov Decision Process (MDP), and then we determine the\noptimal caching placement using the Deep Q-Network (DQN) algorithm. The\nproposed solution aims at maximizing the overall quality of the 360$^o$ videos\ndelivered to the end-users by caching the most popular 360$^o$ videos at base\nquality along with a virtual viewport in high quality. We extensively evaluate\nthe performance of the proposed system and compare it with that of known\nsystems such as LFU, LRU, FIFO, over both synthetic and real 360$^o$ video\ntraces. The results reveal the large benefits coming from proactive caching of\nvirtual viewports instead of the original ones in terms of the overall quality\nof the rendered viewports, the cache hit ratio, and the servicing cost.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 21:05:10 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 18:22:07 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Maniotis", "Pantelis", ""], ["Thomos", "Nikolaos", ""]]}, {"id": "2003.08611", "submitter": "Hossein Shokri Ghadikolaei", "authors": "Hossein S. Ghadikolaei, Hadi Ghauch, Gabor Fodor, Mikael Skoglund, and\n  Carlo Fischione", "title": "A Hybrid Model-based and Data-driven Approach to Spectrum Sharing in\n  mmWave Cellular Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TCCN.2020.2981031", "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-operator spectrum sharing in millimeter-wave bands has the potential of\nsubstantially increasing the spectrum utilization and providing a larger\nbandwidth to individual user equipment at the expense of increasing\ninter-operator interference. Unfortunately, traditional model-based spectrum\nsharing schemes make idealistic assumptions about inter-operator coordination\nmechanisms in terms of latency and protocol overhead, while being sensitive to\nmissing channel state information. In this paper, we propose hybrid model-based\nand data-driven multi-operator spectrum sharing mechanisms, which incorporate\nmodel-based beamforming and user association complemented by data-driven model\nrefinements. Our solution has the same computational complexity as a\nmodel-based approach but has the major advantage of having substantially less\nsignaling overhead. We discuss how limited channel state information and\nquantized codebook-based beamforming affect the learning and the spectrum\nsharing performance. We show that the proposed hybrid sharing scheme\nsignificantly improves spectrum utilization under realistic assumptions on\ninter-operator coordination and channel state information acquisition.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 07:34:56 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Ghadikolaei", "Hossein S.", ""], ["Ghauch", "Hadi", ""], ["Fodor", "Gabor", ""], ["Skoglund", "Mikael", ""], ["Fischione", "Carlo", ""]]}, {"id": "2003.08647", "submitter": "Sebastian Meiling", "authors": "Sebastian Meiling and Thomas C. Schmidt", "title": "LoRa in the Field: Insights from Networking the Smart City Hamburg with\n  RIOT", "comments": "6 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-connected sensors and actuators have scaled down to small embedded\ndevices such as wearables, and at the same time meet a massive deployment at\nthe Internet edge: the Internet of Things (IoT). Many of these IoT devices run\non low-power batteries and are forced to operate on very constrained resources,\nnamely slow CPUs, tiny memories, and low-power radios. Establishing a network\ninfrastructure that is energy efficient, wireless, and still covers a wide area\nis a larger challenge in this regime. LoRa is a low complexity long range radio\ntechnology, which tries to meet these challenges.With LoRaWAN a network model\nfor widespread deployment has been established, which enjoys open public\nLoRaWAN dissemination such as with the infrastructure of TheThingsNetwork. In\nthis paper, we report about our experiences with developing and deploying\nLoRa-based smart city applications as part of the MONICA project in Hamburg.\nOur contributions are twofold. First, we describe the design and implementation\nof end-to-end IoT applications based on the friendly IoT operating system RIOT.\nSecond, we report on measurements and evaluations of our large field trials\nduring several public events in the city of Hamburg. Our results show that\nLoRaWAN provides a suitable communication layer for a variety of Smart City\nuse-cases and IoT applications, but also identifies its limitations and\nweaknesses.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 09:47:40 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Meiling", "Sebastian", ""], ["Schmidt", "Thomas C.", ""]]}, {"id": "2003.08780", "submitter": "Yu Chen", "authors": "Yu Chen", "title": "End-to-End Delay Approximation in Packet-Switched Networks", "comments": "Submitted to the IEEE Transactions on Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I develop a generalized method to approximate end-to-end delay\n(average delay, jitter and density functions) in packet-switched networks\n(PSNs) of any size under 1) Kleinrock's independence assumption (KIA) and 2)\nwhen packet lengths are kept unchanged when they traverse from node to node in\na network, which is an Alternative to Kleinrock's independence assumption\n(AKIA). I introduce a new phase-type distribution $C(\\mathbf{p},\\boldsymbol\n\\theta)$; and then use results from the network flow theory and queueing theory\nto show that the end-to-end delay in PSNs under KIA and AKIA are two different\nrandom variables approximately described by $C(\\mathbf{p},\\boldsymbol \\theta)$.\nWhen PSNs have AKIA, I show from simulation that the method under AKIA\nsignificantly reduces end-to-end delay approximation errors and provides close\napproximation compared with the method under KIA.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 13:50:51 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 13:48:47 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Chen", "Yu", ""]]}, {"id": "2003.09257", "submitter": "Rahif Kassab", "authors": "Rahif Kassab, Andrea Munari, Federico Clazzer and Osvaldo Simeone", "title": "Uncoordinated Grant-Free Radio Access via Diversity for Critical and\n  Non-Critical IoT Services", "comments": "arXiv admin note: text overlap with arXiv:1909.10283", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication services with heterogeneous performance requirements are\nemerging as key use cases for 5G and beyond. This paper deals with the\ncoexistence of two service classes, i.e., critical service (CS) and\nnon-critical service (NCS) on a grant-free channel consisting of the radio\naccess and backhaul segments. On the radio access segment, Internet-of-Things\n(IoT) devices send packets to a set of non-cooperative access points (APs)\nusing slotted ALOHA (SA). The APs then forward correctly received messages to a\nbase station over a shared wireless backhaul segment adopting SA. The APs hence\nplay the role of low-complexity relays that improve space diversity and reduce\nperformance losses caused by interference on the access segment. We study first\na simplified erasure channel model, which is well suited for non-terrestrial\napplications. Then, in order to account for terrestrial scenarios, the impact\nof fading is considered. Throughput and packet success rate metrics are\nderived, and numerical results are provided to assess the performance\ntrade-offs between CS and NCS. Among the main conclusions, we show that\northogonal inter-service resource allocation is generally preferred for NCS\ndevices, while non-orthogonal protocols can improve the throughput and packet\nsuccess rate of CS devices for both terrestrial and non-terrestrial scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 10:57:03 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 14:57:33 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kassab", "Rahif", ""], ["Munari", "Andrea", ""], ["Clazzer", "Federico", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2003.09510", "submitter": "Alessandro Bazzi", "authors": "Alessandro Bazzi and Alberto Zanella and Ioannis Sarris and Vincent\n  Martinez", "title": "Co-channel Coexistence: Let ITS-G5 and Sidelink C-V2X Make Peace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, two technologies have been developed to enable direct\nexchange of information between vehicles. These technologies, currently seen as\nalternatives, are ITS-G5, as commonly referred in Europe, and sidelink\nLTE-vehicle-to-everything (LTE-V2X) (one of the solutions of the so-called\ncellular-V2X, C-V2X). For this reason, the attention has been mostly\nconcentrated on comparing them and remarking their strengths and weaknesses to\nmotivate a choice. Differently, in this work we focus on a scenario where both\nare used in the same area and using the same frequency channels, without the\nassistance from any infrastructure. Our results show that under co-channel\ncoexistence the range of ITS-G5 is severely degraded, while impact on LTE-V2X\nis marginal. Additionally, a mitigation method where the CAM data generation is\nconstrained to periodical intervals is shown to reduce the impact of co-channel\ncoexistence, with less degradation on ITS-G5 performance and even improvement\nfor LTE-V2X.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 21:47:01 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Bazzi", "Alessandro", ""], ["Zanella", "Alberto", ""], ["Sarris", "Ioannis", ""], ["Martinez", "Vincent", ""]]}, {"id": "2003.09574", "submitter": "Tristan Curry", "authors": "Tristan Curry, Robert Abbas", "title": "5G Coverage, Prediction, and Trial Measurements", "comments": "4 pages, 7 Figures, 2 Tables. Paper Co-written by Tristan Curry and\n  Robert Abbas, and edited by Tristan Curry", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When planning a 5G network in the sub-6GHz bands, similar cell planning\ntechniques to LTE can be applied. Looking at the Australian environment, the\nn78 band (3.3-3.8GHz TDD) is approximately 1GHz higher than the 2.6GHz band\nused in existing LTE networks. As a result, the coverage footprint can be\nsimilar, and therefore co-locating 5G NR (New Radio) on existing LTE base\nstations is a common strategy for initial network rollout. Any difference in\ncoverage can be compensated by beamforming gain, less downtilting, or\nincreasing the gNodeB's transmit power. This paper presents an initial link\nbudget for data services, provides a coverage prediction, and measurements for\na 5G NR NSA (Non Stand Alone) trial radiating at 3.5GHz with 60 MHz bandwidth.\nThe coverage prediction is generated using RF planning tool Atoll, which is\nthen compared to coverage measurements from the trial. These findings can be\nused to help plan a future 5G network in the Sydney metro area or similar\nenvironment.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 04:09:23 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Curry", "Tristan", ""], ["Abbas", "Robert", ""]]}, {"id": "2003.09662", "submitter": "Cristian Tatino", "authors": "Cristian Tatino, Nikolaos Pappas, and Di Yuan", "title": "Multi-Robot Association-Path Planning in Millimeter-Wave Industrial\n  Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive exploitation of robots for industry 4.0 needs advanced wireless\nsolutions that replace less flexible and more costly wired networks. In this\nregard, millimeter-waves (mm-waves) can provide high data rates, but they are\ncharacterized by a spotty coverage requiring dense radio deployments. In such\nscenarios, coverage holes and numerous handovers may decrease the communication\nthroughput and reliability. In contrast to conventional multi-robot path\nplanning (MPP), we define a type of multi-robot association-path planning\n(MAPP) problems aiming to jointly optimize the robots' paths and the\nrobots-access points (APs) associations. In MAPP, we focus on minimizing the\npath lengths as well as the number of handovers while sustaining connectivity.\nWe propose an algorithm that can solve MAPP in polynomial time and it is able\nto numerically approach the global optimum. We show that the proposed solution\nis able to guarantee network connectivity and to dramatically reduce the number\nof handovers in comparison to minimizing only the path lengths.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 13:48:30 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Tatino", "Cristian", ""], ["Pappas", "Nikolaos", ""], ["Yuan", "Di", ""]]}, {"id": "2003.09708", "submitter": "Dong Liu", "authors": "Dong Liu, Jianyu Zhao, Chenyang Yang, Lajos Hanzo", "title": "Accelerating Deep Reinforcement Learning With the Aid of Partial Model:\n  Energy-Efficient Predictive Video Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive power allocation is conceived for energy-efficient video streaming\nover mobile networks using deep reinforcement learning. The goal is to minimize\nthe accumulated energy consumption of each base station over a complete video\nstreaming session under the constraint that avoids video playback\ninterruptions. To handle the continuous state and action spaces, we resort to\ndeep deterministic policy gradient (DDPG) algorithm for solving the formulated\nproblem. In contrast to previous predictive power allocation policies that\nfirst predict future information with historical data and then optimize the\npower allocation based on the predicted information, the proposed policy\noperates in an on-line and end-to-end manner. By judiciously designing the\naction and state that only depend on slowly-varying average channel gains, we\nreduce the signaling overhead between the edge server and the base stations,\nand make it easier to learn a good policy. To further avoid playback\ninterruption throughout the learning process and improve the convergence speed,\nwe exploit the partially known model of the system dynamics by integrating the\nconcepts of safety layer, post-decision state, and virtual experiences into the\nbasic DDPG algorithm. Our simulation results show that the proposed policies\nconverge to the optimal policy that is derived based on perfect large-scale\nchannel prediction and outperform the first-predict-then-optimize policy in the\npresence of prediction errors. By harnessing the partially known model, the\nconvergence speed can be dramatically improved.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 17:36:53 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 01:30:00 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Liu", "Dong", ""], ["Zhao", "Jianyu", ""], ["Yang", "Chenyang", ""], ["Hanzo", "Lajos", ""]]}, {"id": "2003.09724", "submitter": "Seungmo Kim", "authors": "Seungmo Kim and Byung-Jun Kim", "title": "Prioritization of Basic Safety Message in DSRC Based on Distance to\n  Danger", "comments": "This manuscript will be submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many parties claim the technical significance of Dedicated Short-Range\nCommunications (DSRC) in intelligent transportation system (ITS) for promotion\nof transportation safety. The main challenge in this key vehicle-to-everything\n(V2X) standard is high odds of network congestion. Furthermore, in accordance\nwith a V2X network being inherently dynamic in key parameters such as vehicle\ndensity and velocity, the networking behavior of a DSRC system is usually\nhighly complicated to analyze. In addition, the United States Federal\nCommunications Commission (US FCC) recently announced the \"5.9 GHz band\nreform,\" which reduced the dedicated bandwidth for DSRC to 10 MHz from 75 MHz.\nMotivated from these, the necessity of \"lightening\" the networking load of a\nDSRC network has become essential to keep safety-related operations without\nperformance deterioration. To this end, this paper proposes a protocol that\nprioritizes transmission of a basic safety message (BSM) at a vehicle according\nto the level of danger that the vehicle experiences. The proposed protocol uses\nthe distance between a danger source and a vehicle as the metric to determine\nthe priority for transmission. Our results show that this protocol prioritizes\nthe transmission opportunity to dangerous vehicles, and hence results in higher\nperformance in terms of key metrics--i.e., average delay, throughput, and\ninter-reception time ($\\mathsf{IRT}$).\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 18:54:16 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 12:37:56 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kim", "Seungmo", ""], ["Kim", "Byung-Jun", ""]]}, {"id": "2003.09794", "submitter": "Flavio Esposito", "authors": "John Pasquesi, Flavio Esposito, Gianluca Davoli, Jenna Gorlewicz", "title": "Exploring Vibration-Defined Networking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network management community has explored and exploited light, copper,\nand several wireless spectra (including acoustics) as a medium to transfer\ncontrol or data traffic. Meanwhile, haptic technologies are being explored in\nend-user (wearable) devices, and Tactile Internet is being used merely as a\nmetaphor. However, with rare exceptions and for smaller scoped projects, to our\nknowledge, vibration has been largely untouched as networking communication\nmedia. In this paper, we share the lessons learned while creating and\noptimizing a pilot testbed that serves as an inexpensive starting point for the\nexploration of vibration-defined networking. We demonstrated the feasibility\n(but not yet the scalability) of vibrations as a tool for a few network\nmanagement mechanisms, such as resiliency, physical layer security, and as an\ninnovative method for teaching networking concepts to individuals with visual\nimpairments (VI). By demonstrating how vibrations could be programmable, we\npropose to the community a few open problems that could generate several\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 03:32:00 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Pasquesi", "John", ""], ["Esposito", "Flavio", ""], ["Davoli", "Gianluca", ""], ["Gorlewicz", "Jenna", ""]]}, {"id": "2003.09827", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Niko Piatkowski and Christian Wietfeld", "title": "The Channel as a Traffic Sensor: Vehicle Detection and Classification\n  based on Radio Fingerprinting", "comments": null, "journal-ref": "IEEE Internet of Things Journal 2020", "doi": "10.1109/JIOT.2020.2983207", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitously deployed Internet of Things (IoT)- based automatic vehicle\nclassification systems will catalyze data-driven traffic flow optimization in\nfuture smart cities and will transform the road infrastructure itself into a\ndynamically sensing Cyber-physical System (CPS). Although a wide range of\ndifferent traffic sensing systems has been proposed, the existing solutions are\nnot yet able to simultaneously satisfy the multitude of requirements, e.g.,\naccuracy, robustness, cost-efficiency, and privacy preservation. In this paper,\nwe present a novel approach, which exploits radio fingerprints -\nmultidimensional attenuation patterns of wireless signals - for accurate and\nrobust vehicle detection and classification. The proposed system can be\ndeployed in a highly cost-efficient manner as it relies on off-the-shelf\nembedded devices which are installed into existing delineator posts. In a\ncomprehensive field evaluation campaign, the performance of the radio\nfingerprinting-based approach is analyzed within an experimental live\ndeployment on a German highway, where it is able to achieve a binary\nclassification success ratio of more than 99% and an overall accuracy of 93.83%\nfor a classification task with seven different classes.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 06:52:38 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 08:42:41 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Piatkowski", "Niko", ""], ["Wietfeld", "Christian", ""]]}, {"id": "2003.09829", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Manuel Patchou and Karsten Heimann and Christian\n  Wietfeld", "title": "Simulating Hybrid Aerial- and Ground-based Vehicular Networks with ns-3\n  and LIMoSim", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating Unmanned Aerial Vehicles (UAVs) into future Intelligent\nTransportation Systems (ITSs) allows to exploit their unique mobility\npotentials for improving the performance of services such as near-field parcel\ndelivery, dynamic network provisioning, and aerial sensing. In order to provide\na controllable environment for the methodological performance analysis,\nsimulation frameworks need to support ground- and aerial-based mobility as well\nas the involved communication technologies. In this paper, we present the open\nsource Lightweight ICT-centric Mobility Simulation (LIMoSim) framework for\nsimulating hybrid vehicular networks within Network Simulator 3 (ns-3). LIMoSim\nimplements a shared codebase coupling approach which integrates all required\ncomponents in a single simulation process. The low-level mobility behaviors\nrely on well-known analytical models. Different case studies discussing\ncutting-edge communication technologies such as Cellular Vehicle-to-Everything\n(C-V2X) and millimeter Wave (mmWave) are presented in order to illustrate how\nthe proposed framework can be integrated into ns-3-based network simulation\nsetups.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 07:07:46 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Patchou", "Manuel", ""], ["Heimann", "Karsten", ""], ["Wietfeld", "Christian", ""]]}, {"id": "2003.09876", "submitter": "Xu Chen", "authors": "Deyin Liu and Xu Chen and Zhi Zhou and Qing Ling", "title": "HierTrain: Fast Hierarchical Edge AI Learning with Hybrid Parallelism in\n  Mobile-Edge-Cloud Computing", "comments": "Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, deep neural networks (DNNs) are the core enablers for many emerging\nedge AI applications. Conventional approaches to training DNNs are generally\nimplemented at central servers or cloud centers for centralized learning, which\nis typically time-consuming and resource-demanding due to the transmission of a\nlarge amount of data samples from the device to the remote cloud. To overcome\nthese disadvantages, we consider accelerating the learning process of DNNs on\nthe Mobile-Edge-Cloud Computing (MECC) paradigm. In this paper, we propose\nHierTrain, a hierarchical edge AI learning framework, which efficiently deploys\nthe DNN training task over the hierarchical MECC architecture. We develop a\nnovel \\textit{hybrid parallelism} method, which is the key to HierTrain, to\nadaptively assign the DNN model layers and the data samples across the three\nlevels of edge device, edge server and cloud center. We then formulate the\nproblem of scheduling the DNN training tasks at both layer-granularity and\nsample-granularity. Solving this optimization problem enables us to achieve the\nminimum training time. We further implement a hardware prototype consisting of\nan edge device, an edge server and a cloud server, and conduct extensive\nexperiments on it. Experimental results demonstrate that HierTrain can achieve\nup to 6.9x speedup compared to the cloud-based hierarchical training approach.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 12:40:06 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Liu", "Deyin", ""], ["Chen", "Xu", ""], ["Zhou", "Zhi", ""], ["Ling", "Qing", ""]]}, {"id": "2003.09979", "submitter": "Shan Jaffry", "authors": "Shan Jaffry, Rasheed Hussain, Xiang Gui, Syed Faraz Hasan", "title": "A Comprehensive Survey on Moving Networks", "comments": "This survey has been submitted to IEEE Communications Surveys &\n  Tutorials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unprecedented increase in the demand for mobile data, fuelled by new\nemerging applications such as HD video streaming and heightened online\nactivities has caused massive strain on the existing cellular networks. As a\nsolution, the 5G technology has been introduced to improve network performance\nthrough various innovative features such as mmWave spectrum and HetNets. In\nessence, HetNets include several small cells underlaid within macro-cell to\nserve densely populated regions. Recently, a mobile layer of HetNet has been\nunder consideration by the researchers and is often referred to as moving\nnetworks. Moving networks comprise of mobile cells that are primarily\nintroduced to improve QoS for commuting users inside public transport because\nthe QoS is deteriorated due to vehicular penetration losses. Furthermore, the\nusers inside fast moving public transport also exert excessive load on the core\nnetwork due to large group handovers. To this end, mobile cells will play a\ncrucial role in reducing overall handover count and will help in alleviating\nthese problems by decoupling in-vehicle users from the core network.\n  To date, remarkable research results have been achieved by the research\ncommunity in addressing challenges linked to moving networks. However, to the\nbest of our knowledge, a discussion on moving networks in a holistic way is\nmissing in the current literature. To fill the gap, in this paper, we\ncomprehensively survey moving networks. We cover the technological aspects and\ntheir applications in the futuristic applications. We also discuss the\nuse-cases and value additions that moving networks may bring to future cellular\narchitecture and identify the challenges associated with them. Based on the\nidentified challenges we discuss the future research directions.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 19:46:46 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Jaffry", "Shan", ""], ["Hussain", "Rasheed", ""], ["Gui", "Xiang", ""], ["Hasan", "Syed Faraz", ""]]}, {"id": "2003.10085", "submitter": "Raja Jurdak", "authors": "Raja Jurdak, Ali Dorri, Mahinda Vilathgamuwa", "title": "A Trusted and Privacy-preserving Internet of Mobile Energy", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth in distributed energy sources on power grids leads to\nincreasingly decentralised energy management systems for the prediction of\npower supply and demand and the dynamic setting of an energy price signal.\nWithin this emerging smart grid paradigm, electric vehicles can serve as\nconsumers, transporters, and providers of energy through two-way charging\nstations, which highlights a critical feedback loop between the movement\npatterns of these vehicles and the state of the energy grid. This paper\nproposes a vision for an Internet of Mobile Energy (IoME), where energy and\ninformation flow seamlessly across the power and transport sectors to enhance\nthe grid stability and end user welfare. We identify the key challenges of\ntrust, scalability, and privacy, particularly location and energy linking\nprivacy for EV owners, for realising the IoME vision. We propose an information\narchitecture for IoME that uses scalable blockchain to provide energy data\nintegrity and authenticity, and introduces one-time keys for public EV\ntransactions and a verifiable anonymous trip extraction method for EV users to\nshare their trip data while protecting their location privacy. We present an\nexample scenario that details the seamless and closed loop information flow\nacross the energy and transport sectors, along with a blockchain design and\ntransaction vocabulary for trusted decentralised transactions. We finally\ndiscuss the open challenges presented by IoME that can unlock significant\nbenefits to grid stability, innovation, and end user welfare.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 05:01:02 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 23:16:57 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 22:27:53 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2021 05:13:19 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Jurdak", "Raja", ""], ["Dorri", "Ali", ""], ["Vilathgamuwa", "Mahinda", ""]]}, {"id": "2003.10094", "submitter": "Kota Yamashita", "authors": "Kota Yamashita, Shotaro Kamiya, Koji Yamamoto, Yusuke Koda, Takayuki\n  Nishio, Masahiro Morikura", "title": "Penalized and Decentralized Contextual Bandit Learning for WLAN Channel\n  Allocation with Contention-Driven Feature Extraction", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-armed bandit (MAB)-based decentralized channel exploration framework\nboth adapting unknown traffics of neighboring access points (APs) and ensuring\nconvergence is proposed. As the throughput provided by a typical AP in wireless\nlocal area network (WLAN) is significantly affected by neighboring APs'\nchannels due to carrier sense operations, the neighbor awareness, i.e., being\naware of channels of neighboring APs, is valuable. The main scope of this paper\nis to incorporate this neighbor awareness into an MAB-based channel exploration\nas conventional MAB-based WLAN channel exploration schemes lacks this\nperspective. To this end, we propose contention-driven feature extraction\n(CDFE), which extracts the adjacency relation of a contention graph. This\nallows to formulate the traffic-adaptive channel exploration as contextual MAB\n(CMAB) problem with joint linear upper confidence bound (JLinUCB) exploration\nwhere the graph edge of the feature is leveraged as the weights of a linear\nthroughput estimator. Moreover, we address the problem of non-convergence --\nthe channel exploration cycle -- which is an inherent difficulty in selfish\ndecentralized learning. To prevent such a cycle, we propose a penalized JLinUCB\n(P-JLinUCB) based on the key idea of introducing a discount parameter to the\nreward for exploiting a different channel before and after the learning round.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 06:22:30 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 02:57:33 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 09:19:43 GMT"}, {"version": "v4", "created": "Thu, 24 Jun 2021 06:25:49 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Yamashita", "Kota", ""], ["Kamiya", "Shotaro", ""], ["Yamamoto", "Koji", ""], ["Koda", "Yusuke", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""]]}, {"id": "2003.10188", "submitter": "Adnan Aijaz", "authors": "Adnan Aijaz", "title": "High-Performance Industrial Wireless: Achieving Reliable and\n  Deterministic Connectivity over IEEE 802.11 WLANs", "comments": "accepted for IEEE journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication for control-centric industrial applications is characterized by\nthe requirements of very high reliability, very low and deterministic latency\nand high scalability. Typically, IEEE 802.11-based wireless local area networks\n(WLANs), also known as Wi-Fi networks, are deemed ineligible for industrial\ncontrol applications owing to insufficient reliability and non-deterministic\nlatency. This paper proposes a novel solution for providing reliable and\ndeterministic communication, through Wi-Fi, in industrial environments. The\nproposed solution, termed as \\textsf{HAR\\(^\\text{2}\\)D-Fi} (\\underline{H}ybrid\nchannel \\underline{A}ccess with \\underline{R}edundancy for \\underline{R}eliable\nand \\underline{D}eterministic Wi-\\underline{Fi}), adopts hybrid channel access\nmechanisms for achieving deterministic communication. It also provides temporal\nredundancy for enhanced reliability. \\textsf{HAR\\(^\\text{2}\\)D-Fi} implements\ndifferent medium access control (MAC) designs that build on the standard\nphysical (PHY) layer. Such designs can be classified into two categories: (a)\nMAC designs with pre-defined (physical) time-slotted schedule, and (b) MAC\ndesigns with virtual time-slotted schedule. Performance evaluation, based on\nanalysis and system-level simulations, demonstrates the viability of\n\\textsf{HAR\\(^\\text{2}\\)D-Fi} for control-centric industrial applications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 11:31:01 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Aijaz", "Adnan", ""]]}, {"id": "2003.10270", "submitter": "Christos Liaskos K.", "authors": "Christos Liaskos, Shuai Nie, Ageliki Tsioliaridou, Andreas\n  Pitsillides, Sotiris Ioannidis, Ian Akyildiz", "title": "Mobility-aware Beam Steering in Metasurface-based Programmable Wireless\n  Environments", "comments": "In proceedings of IEEE ICASSP 2020. This work was funded by the\n  European Union via the Horizon 2020: Future Emerging Topics call\n  (FETOPEN-RIA), grant EU736876, project VISORSURF (http://visorsurf.eu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programmable wireless environments (PWEs) utilize electromagnetic\nmetasurfaces to transform wireless propagation into a software-controlled\nresource. In this work we study the effects of user device mobility on the\nefficiency of PWEs. An analytical model is proposed, which describes the\npotential misalignment between user-emitted waves and the active PWE\nconfiguration, and can constitute the basis for studying queuing problems in\nPWEs. Subsequently, a novel, beam steering approach is proposed which can\neffectively mitigate the misalignment effects. Ray-tracing-based simulations\nevaluate the proposed scheme.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 13:26:30 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Liaskos", "Christos", ""], ["Nie", "Shuai", ""], ["Tsioliaridou", "Ageliki", ""], ["Pitsillides", "Andreas", ""], ["Ioannidis", "Sotiris", ""], ["Akyildiz", "Ian", ""]]}, {"id": "2003.10279", "submitter": "Roberto Morabito", "authors": "Roberto Morabito, Jaime Jim\\'enez", "title": "IETF protocol suite for the Internet of Things: Overview and Recent\n  Advancements", "comments": "The paper has been accepted for publication to IEEE Communications\n  Standards Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is a rapidly growing technological domain and the\neffort that many Standards Developing Organizations (SDOs) and alliances are\ndedicating to it is constantly increasing. The Internet Engineering Task Force\n(IETF) is certainly one of the most active SDOs operating in this broad domain.\nWith the aim of building a comprehensive, interoperable and streamlined IoT\nstack, several IETF working groups are developing protocols, in multiple\ntechnological domains, which are already nowadays very relevant to the IoT.\nThis article gives a concise but comprehensive survey of the IETF efforts in\nthe IoT. We discuss mainstream standardization and research activities, as well\nas other IETF-connected supporting initiatives provided still in the context of\nIoT.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 13:48:04 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 10:09:53 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Morabito", "Roberto", ""], ["Jim\u00e9nez", "Jaime", ""]]}, {"id": "2003.10538", "submitter": "Rong Du", "authors": "Rong Du, Sindri Magn\\'usson, Carlo Fischione", "title": "The Internet of Things as a Deep Neural Network", "comments": "3 figures, 1 table, 15 pages; The paper is under review in IEEE\n  Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task in the Internet of Things (IoT) is field monitoring, where\nmultiple IoT nodes take measurements and communicate them to the base station\nor the cloud for processing, inference, and analysis. This communication\nbecomes costly when the measurements are high-dimensional (e.g., videos or\ntime-series data). The IoT networks with limited bandwidth and low power\ndevices may not be able to support such frequent transmissions with high data\nrates. To ensure communication efficiency, this article proposes to model the\nmeasurement compression at IoT nodes and the inference at the base station or\ncloud as a deep neural network (DNN). We propose a new framework where the data\nto be transmitted from nodes are the intermediate outputs of a layer of the\nDNN. We show how to learn the model parameters of the DNN and study the\ntrade-off between the communication rate and the inference accuracy. The\nexperimental results show that we can save approximately 96% transmissions with\nonly a degradation of 2.5% in inference accuracy. Our findings have the\npotentiality to enable many new IoT data analysis applications generating large\namount of measurements.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 20:36:16 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Du", "Rong", ""], ["Magn\u00fasson", "Sindri", ""], ["Fischione", "Carlo", ""]]}, {"id": "2003.10605", "submitter": "Akshay Jain", "authors": "Akshay Jain, Elena Lopez-Aguilera, Ilker Demirkol", "title": "User Association and Resource Allocation in 5G (AURA-5G): A Joint\n  Optimization Framework", "comments": "Submitted to Elsevier Computer Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a novel application aware user association and\nresource allocation framework, i.e., AURA-5G, which utilizes a joint\noptimization strategy to accomplish the same. Concretely, our methodology\nconsiders all the real network constraints that will be prevalent in the 5G\nnetworks as well as practical deployment scenarios. Furthermore, AURA-5G, being\nan application aware framework, considers the resource requirements of both\neMBB and mMTC services whilst performing the optimization task. We have\ndemonstrated that our strategy performs significantly better than the baseline\nalgorithm, given any of the multiple combinations of network constraints\nexplored in this paper. In addition, we have also presented a novel\ncomputational complexity analysis for the AURA-5G framework as well as a\nsolvability and convergence time analysis. Such an analysis will be beneficial\nfor both industry and academia in determining the applicability and performance\nof the AURA-5G framework, given the scenario and constraints. Lastly, we have\nalso provisioned a short study on the aspect of network re-dimensioning,\nwherein we demonstrate the efficacy of the AURA-5G framework in providing\ninsights to the operators with regards to their deployment and how they can\nutilize it to optimize the performance of their networks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 01:30:40 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Jain", "Akshay", ""], ["Lopez-Aguilera", "Elena", ""], ["Demirkol", "Ilker", ""]]}, {"id": "2003.10620", "submitter": "Zhipeng Liu", "authors": "Zhipeng Liu, Yinhui Han, Jianwei Fan, Lin Zhang, Yunzhi Lin", "title": "Joint Optimization of Spectrum and Energy Efficiency Considering the\n  C-V2X Security: A Deep Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular vehicle-to-everything (C-V2X) communication, as a part of 5G\nwireless communication, has been considered one of the most significant\ntechniques for Smart City. Vehicles platooning is an application of Smart City\nthat improves traffic capacity and safety by C-V2X. However, different from\nvehicles platooning travelling on highways, C-V2X could be more easily\neavesdropped and the spectrum resource could be limited when they converge at\nan intersection. Satisfying the secrecy rate of C-V2X, how to increase the\nspectrum efficiency (SE) and energy efficiency (EE) in the platooning network\nis a big challenge. In this paper, to solve this problem, we propose a\nSecurity-Aware Approach to Enhancing SE and EE Based on Deep Reinforcement\nLearning, named SEED. The SEED formulates an objective optimization function\nconsidering both SE and EE, and the secrecy rate of C-V2X is treated as a\ncritical constraint of this function. The optimization problem is transformed\ninto the spectrum and transmission power selections of V2V and V2I links using\ndeep Q network (DQN). The heuristic result of SE and EE is obtained by the DQN\npolicy based on rewards. Finally, we simulate the traffic and communication\nenvironments using Python. The evaluation results demonstrate that the SEED\noutperforms the DQN-wopa algorithm and the baseline algorithm by 31.83 % and\n68.40 % in efficiency. Source code for the SEED is available at\nhttps://github.com/BandaidZ/OptimizationofSEandEEBasedonDRL.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 02:22:36 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Liu", "Zhipeng", ""], ["Han", "Yinhui", ""], ["Fan", "Jianwei", ""], ["Zhang", "Lin", ""], ["Lin", "Yunzhi", ""]]}, {"id": "2003.10643", "submitter": "Yoichi Matsuo", "authors": "Yoichi Matsuo, Tatsuaki Kimura and Ken Nishimatsu", "title": "DeepSIP: A System for Predicting Service Impact of Network Failure by\n  Temporal Multimodal CNN", "comments": "to appear in IEEE/IFIP International Workshop on Analytics for\n  Network and Service Management (AnNet 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a failure occurs in a network, network operators need to recognize\nservice impact, since service impact is essential information for handling\nfailures. In this paper, we propose Deep learning based Service Impact\nPrediction (DeepSIP), a system to predict the time to recovery from the failure\nand the loss of traffic volume due to the failure in a network element using a\ntemporal multimodal convolutional neural network (CNN). Since the time to\nrecovery is useful information for a service level agreement (SLA) and the loss\nof traffic volume is directly related to the severity of the failures, we\nregard these as the service impact. The service impact is challenging to\npredict, since a network element does not explicitly contain any information\nabout the service impact. Thus, we aim to predict the service impact from\nsyslog messages and traffic volume by extracting hidden information about\nfailures. To extract useful features for prediction from syslog messages and\ntraffic volume which are multimodal and strongly correlated, and have temporal\ndependencies, we use temporal multimodal CNN. We experimentally evaluated\nDeepSIP and DeepSIP reduced prediction error by approximately 50% in comparison\nwith other NN-based methods with a synthetic dataset.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 03:47:54 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Matsuo", "Yoichi", ""], ["Kimura", "Tatsuaki", ""], ["Nishimatsu", "Ken", ""]]}, {"id": "2003.10737", "submitter": "Yuben Qu", "authors": "Chao Dong, Yun Shen, Yuben Qu, Qihui Wu, Fan Wu, and Guihai Chen", "title": "UAVs as a Service: Boosting Edge Intelligence for Air-Ground Integrated\n  Networks", "comments": "12 pages, 6 figures, submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The air-ground integrated network is a key component of future sixth\ngeneration (6G) networks to support seamless and near-instant\nsuper-connectivity. There is a pressing need to intelligently provision various\nservices in 6G networks, which however is challenging. To meet this need, in\nthis article, we propose a novel architecture called UaaS (UAVs as a Service)\nfor the air-ground integrated network, featuring UAV as a key enabler to boost\nedge intelligence with the help of machine learning (ML) techniques. We\nenvision that the proposed UaaS architecture could intelligently provision\nwireless communication service, edge computing service, and edge caching\nservice by a network of UAVs, making full use of UAVs' flexible deployment and\ndiverse ML techniques. We also conduct a case study where UAVs participate in\nthe model training of distributed ML among multiple terrestrial users, whose\nresult shows that the model training is efficient with a negligible energy\nconsumption of UAVs, compared to the flight energy consumption. Finally, we\ndiscuss the challenges and open research issues in the UaaS.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 09:54:21 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Dong", "Chao", ""], ["Shen", "Yun", ""], ["Qu", "Yuben", ""], ["Wu", "Qihui", ""], ["Wu", "Fan", ""], ["Chen", "Guihai", ""]]}, {"id": "2003.10745", "submitter": "Kashyap Thimmaraju", "authors": "Kashyap Thimmaraju and Stefan Schmid", "title": "Towards Fine-Grained Billing For Cloud Networking", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit multi-tenant network virtualization in data centers, and make the\ncase for tenant-specific virtual switches. In particular, tenant-specific\nvirtual switches allow cloud providers to extend fine-grained billing (known,\ne.g., from serverless architectures) to the network, accounting not only for\nIO, but also CPU or energy. We sketch an architecture and present economical\nmotivation and recent technological enablers. We also find that virtual\nswitches today do not offer sufficient multi-tenancy and can introduce\nartificial performance bottlenecks, e.g., in load balancers. We conclude by\ndiscussing additional use cases for tentant-specific switches.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 10:06:06 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Thimmaraju", "Kashyap", ""], ["Schmid", "Stefan", ""]]}, {"id": "2003.10783", "submitter": "Kengo Tajiri", "authors": "Kengo Tajiri and Yasuhiro Ikeda and Yuusuke Nakano and Keishiro\n  Watanabe", "title": "Dividing Deep Learning Model for Continuous Anomaly Detection of\n  Inconsistent ICT Systems", "comments": "Accepted for IEEE/IFIP Network Operations and Management Symposium\n  2020 (NOMS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health monitoring is important for maintaining reliable information and\ncommunications technology (ICT) systems. Anomaly detection methods based on\nmachine learning, which train a model for describing \"normality\" are promising\nfor monitoring the state of ICT systems. However, these methods cannot be used\nwhen the type of monitored log data changes from that of training data due to\nthe replacement of certain equipment. Therefore, such methods may dismiss an\nanomaly that appears when log data changes. To solve this problem, we propose\nan ICT-systems-monitoring method with deep learning models divided based on the\ncorrelation of log data. We also propose an algorithm for extracting the\ncorrelations of log data from a deep learning model and separating log data\nbased on the correlation. When some of the log data changes, our method can\ncontinue health monitoring with the divided models which are not affected by\nchanges in the log data. We present the results from experiments involving\nbenchmark data and real log data, which indicate that our method using divided\nmodels does not decrease anomaly detection accuracy and a model for anomaly\ndetection can be divided to continue monitoring a network state even if some\nthe log data change.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 11:32:00 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Tajiri", "Kengo", ""], ["Ikeda", "Yasuhiro", ""], ["Nakano", "Yuusuke", ""], ["Watanabe", "Keishiro", ""]]}, {"id": "2003.10784", "submitter": "Hiroki Ikeuchi", "authors": "Hiroki Ikeuchi, Akio Watanabe, Tsutomu Hirao, Makoto Morishita,\n  Masaaki Nishino, Yoichi Matsuo, Keishiro Watanabe", "title": "Recovery command generation towards automatic recovery in ICT systems by\n  Seq2Seq learning", "comments": "accepted for IEEE/IFIP Network Operations and Management Symposium\n  2020 (NOMS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in scale and complexity of ICT systems, their operation\nincreasingly requires automatic recovery from failures. Although it has become\npossible to automatically detect anomalies and analyze root causes of failures\nwith current methods, making decisions on what commands should be executed to\nrecover from failures still depends on manual operation, which is quite\ntime-consuming. Toward automatic recovery, we propose a method of estimating\nrecovery commands by using Seq2Seq, a neural network model. This model learns\ncomplex relationships between logs obtained from equipment and recovery\ncommands that operators executed in the past. When a new failure occurs, our\nmethod estimates plausible commands that recover from the failure on the basis\nof collected logs. We conducted experiments using a synthetic dataset and\nrealistic OpenStack dataset, demonstrating that our method can estimate\nrecovery commands with high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 11:34:10 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Ikeuchi", "Hiroki", ""], ["Watanabe", "Akio", ""], ["Hirao", "Tsutomu", ""], ["Morishita", "Makoto", ""], ["Nishino", "Masaaki", ""], ["Matsuo", "Yoichi", ""], ["Watanabe", "Keishiro", ""]]}, {"id": "2003.10809", "submitter": "Ramy Amer Mr", "authors": "Ramy Amer and Hesham Elsawy and M. Majid Butt and Eduard A. Jorswieck,\n  and Mehdi Bennis and Nicola Marchetti", "title": "Optimized Caching and Spectrum Partitioning for D2D enabled Cellular\n  Systems with Clustered Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caching at mobile devices and leveraging device- to-device (D2D)\ncommunication are two promising approaches to support massive content delivery\nover wireless networks. The analysis of cache-enabled wireless networks is\nusually carried out by assuming that devices are uniformly distributed,\nhowever, in social networks, mobile devices are intrinsically grouped into\ndisjoint clusters. In this regards, this paper proposes a spatiotemporal\nmathematical model that tracks the service requests arrivals and account for\nthe clustered devices geometry. Two kinds of devices are assumed, particularly,\ncontent clients and content providers. Content providers are assumed to have a\nsurplus memory which is exploited to proactively cache contents from a known\nlibrary, following a random probabilistic caching scheme. Content clients can\nretrieve a requested content from the nearest content provider in their\nproximity (cluster), or, as a last resort, the base station (BS). The developed\nspatiotemporal model is leveraged to formulate a joint optimization problem of\nthe content caching and spectrum partitioning in order to minimize the average\nservice delay. Due to the high complexity of the optimization problem, the\ncaching and spectrum partitioning problems are decoupled and solved iteratively\nusing the block coordinate descent (BCD) optimization technique. To this end,\nan optimal and suboptimal solutions are obtained for the bandwidth partitioning\nand probabilistic caching subproblems, respectively. Numerical results\nhighlight the superiority of the proposed scheme over conventional caching\nschemes under equal and optimized bandwidth allocations. Particularly, it is\nshown that the average service delay is reduced by nearly 100% and 350%,\ncompared to the Zipf and uniform caching schemes under equal bandwidth\nallocations, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 12:53:14 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Amer", "Ramy", ""], ["Elsawy", "Hesham", ""], ["Butt", "M. Majid", ""], ["Jorswieck", "Eduard A.", ""], ["Bennis", "Mehdi", ""], ["Marchetti", "Nicola", ""]]}, {"id": "2003.10869", "submitter": "Matteo Pozza", "authors": "Matteo Pozza, Ashwin Rao, Diego Lugones, Sasu Tarkoma", "title": "FlexState: Enabling Innovation in Network Function State Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network function (NF) developers need to provide highly available solutions\nwith diverse packet processing features at line rate. A significant challenge\nin developing such functions is to build flexible software that can be adapted\nto different operating environments, vendors, and operator use-cases. Today,\nrefactoring NF software for specific scenarios can take months. Furthermore,\nnetwork operators are increasingly adopting fast-paced development practices\nfor continuous software delivery to gain market advantage, which imposes even\nshorter development cycles. A key aspect in NF design is state management,\nwhich can be optimized across deployments by carefully selecting the underlying\ndata store. However, migrating to a data store that suits a different use-case\nis time consuming because it requires code refactoring while revisiting its\napplication programming interfaces, APIs.\n  In this paper we introduce FlexState, a state management system that\ndecouples the NF packet processing logic from the data store that maintains its\nstate. The objective is to reduce code refactoring significantly by\nincorporating an abstraction layer that exposes various data stores as\nconfiguration alternatives. Experiments show that FlexState achieves\nsignificant flexibility in optimizing the NF state management across several\nscenarios with negligible overhead.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 14:23:31 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Pozza", "Matteo", ""], ["Rao", "Ashwin", ""], ["Lugones", "Diego", ""], ["Tarkoma", "Sasu", ""]]}, {"id": "2003.10877", "submitter": "Suat Mercan", "authors": "Suat Mercan, Enes Erdin, Kemal Akkaya", "title": "Improving Transaction Success Rate via Smart Gateway Selection in\n  Cryptocurrency Payment Channel Networks", "comments": "arXiv admin note: text overlap with arXiv:2003.00294", "journal-ref": null, "doi": "10.1109/ICBC48266.2020.9169458", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has experienced a vast interest in Blockchain-based\ncryptocurrencies with a specific focus on the applications of this technology.\nHowever, slow confirmation times of transactions and unforeseeable high fees\nhamper their wide adoption for micro-payments. The idea of establishing payment\nchannel networks is one of the many proposed solutions to address this\nscalability issue where nodes, by utilizing smart contracting, establish\npayment channels between each other and perform off-chain transactions.\nHowever, due to the way these channels are created, both sides have a certain\none-way capacity for making transactions. Consequently, if one sides exceeds\nthis one-way capacity, the channel becomes useless in that particular\ndirection, which causes failures of payments and eventually creates an\nimbalance in the overall network. To keep the payment channel network\nsustainable, in this paper, we aim to increase the overall success rate of\npayments by effectively exploiting the fact that end-users are usually\nconnected to the network at multiple points (i.e., gateways) any of which can\nbe used to initiate the payment. We propose an efficient method for selection\nof the gateway for a user by considering the gateway's inbound and outbound\npayment traffic ratio. We then augment this proposed method with split payment\ncapability to further increase success rate especially for large transactions.\nThe evaluation of the proposed method shows that compared to greedy and\nmaxflow-based approaches, we can achieve much higher success rates, which are\nfurther improved with split payments.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 18:17:07 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Mercan", "Suat", ""], ["Erdin", "Enes", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2003.10916", "submitter": "Xu Chen", "authors": "Rui Li and Qian Ma and Jie Gong and Zhi Zhou and Xu Chen", "title": "Age of Processing: Age-driven Status Sampling and Processing Offloading\n  for Edge Computing-enabled Real-time IoT Applications", "comments": "submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The freshness of status information is of great importance for time-critical\nInternet of Things (IoT) applications. A metric measuring status freshness is\nthe age-of-information (AoI), which captures the time elapsed from the status\nbeing generated at the source node (e.g., a sensor) to the latest status\nupdate.However, in intelligent IoT applications such as video surveillance, the\nstatus information is revealed after some computation intensive and\ntime-consuming data processing operations, which would affect the status\nfreshness. In this paper, we propose a novel metric, age-of-processing (AoP),\nto quantify such status freshness, which captures the time elapsed of the\nnewest received processed status data since it is generated. Compared with AoI,\nAoP further takes the data processing time into account. Since an IoT device\nhas limited computation and energy resource, the device can choose to offload\nthe data processing to the nearby edge server under constrained status sampling\nfrequency.We aim to minimize the average AoP in a long-term process by jointly\noptimizing the status sampling frequency and processing offloading policy. We\nformulate this online problem as an infinite-horizon constrained Markov\ndecision process (CMDP) with average reward criterion. We then transform the\nCMDP problem into an unconstrained Markov decision process (MDP) by leveraging\na Lagrangian method, and propose a Lagrangian transformation framework for the\noriginal CMDP problem. Furthermore, we integrate the framework with\nperturbation based refinement for achieving the optimal policy of the CMDP\nproblem. Extensive numerical evaluations show that the proposed algorithm\noutperforms the benchmarks, with an average AoP reduction up to 30%.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 15:12:56 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Li", "Rui", ""], ["Ma", "Qian", ""], ["Gong", "Jie", ""], ["Zhou", "Zhi", ""], ["Chen", "Xu", ""]]}, {"id": "2003.11003", "submitter": "Faroq Altam", "authors": "F. AL-Tam, N. Correia, J. Rodriguez", "title": "Learn to Schedule (LEASCH): A Deep reinforcement learning approach for\n  radio resource scheduling in the 5G MAC layer", "comments": "Submitted to IEEE ACCESS, 16 pages, 7 Figures", "journal-ref": "IEEE access 2020", "doi": "10.1109/ACCESS.2020.3000893", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network management tools are usually inherited from one generation to\nanother. This was successful since these tools have been kept in check and\nupdated regularly to fit new networking goals and service requirements.\nUnfortunately, new networking services will render this approach obsolete and\nhandcrafting new tools or upgrading the current ones may lead to complicated\nsystems that will be extremely difficult to maintain and improve. Fortunately,\nrecent advances in AI have provided new promising tools that can help solving\nmany network management problems. Following this interesting trend, the current\narticle presents LEASCH, a deep reinforcement learning model able to solve the\nradio resource scheduling problem in the MAC layer of 5G networks. LEASCH is\ndeveloped and trained in a sand-box and then deployed in a 5G network. The\nexperimental results validate the effectiveness of LEASCH compared to\nconventional baseline methods in many key performance indicators.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 17:45:53 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["AL-Tam", "F.", ""], ["Correia", "N.", ""], ["Rodriguez", "J.", ""]]}, {"id": "2003.11009", "submitter": "Sara Khosravi", "authors": "Sara Khosravi, Hossein S. Ghadikolaei, and Marina Petrova", "title": "Learning-based Handover in Mobile Millimeter-wave Networks", "comments": "in IEEE Transactions on Cognitive Communications and Networking", "journal-ref": null, "doi": "10.1109/TCCN.2020.3030964", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter-wave (mmWave) communication is considered as a key enabler of\nultra-high data rates in the future cellular and wireless networks. The need\nfor directional communication between base stations (BSs) and users in mmWave\nsystems, that is achieved through beamforming, increases the complexity of the\nchannel estimation. Moreover, in order to provide better coverage, dense\ndeployment of BSs is required which causes frequent handovers and increased\nassociation overhead. In this paper, we present an approach that jointly\naddresses the beamforming and handover problems. Our solution entails an\nefficient beamforming method with a minimum number of pilots and a\nlearning-based handover method supporting mobile scenarios. We use\nreinforcement learning algorithm to learn the optimal choices of the backup BSs\nin different locations of a mobile user. We show that our method provides high\nrate and reliability in all locations of the user's trajectory with a minimal\nnumber of handovers. Simulation results in an outdoor environment based on\ngeometric mmWave channel modeling and real building map data show the superior\nperformance of our proposed solution in achievable instantaneous rate and\ntrajectory rate.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 17:50:53 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 01:48:59 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Khosravi", "Sara", ""], ["Ghadikolaei", "Hossein S.", ""], ["Petrova", "Marina", ""]]}, {"id": "2003.11061", "submitter": "Ahmad Shabani Baghani", "authors": "Ahmad Shabani Baghani, Sonbol Rahimpour, and Majid Khabbazian", "title": "The DAO Induction Attack Against the RPL-based Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RPL is the emerging routing standard for low power and lossy networks (LLNs).\nLLN is a key component of the Internet of Things (IoT), hence its security is\nimperative for the age of IoT. In this work, we present the DAO induction\nattack, a novel attack against RPL. In this attack, a malicious insider or a\ncompromised node periodically increments its DTSN number. Each such increment\ncan trigger/induce a large number of control message transmissions in the\nnetwork. We show that this degrades the network performance in terms of\nend-to-end latency, packet loss ratio, and power consumption. To mitigate, we\npropose a lightweight solution to detect the DAO induction attack. Our solution\nimposes nearly no overhead on IoT devices, which is important as these devices\nare typically constrained in terms of power, memory and processing.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 18:31:42 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Baghani", "Ahmad Shabani", ""], ["Rahimpour", "Sonbol", ""], ["Khabbazian", "Majid", ""]]}, {"id": "2003.11078", "submitter": "Pantelis-Daniel Arapoglou", "authors": "Pantelis-Daniel Arapoglou, Stefano Cioni, Emiliano Re, Alberto Ginesi", "title": "Direct Access to 5G New Radio User Equipment from NGSO Satellites in\n  Millimeter Waves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next generation of terrestrial radio communications, so-called fifth\ngeneration (5G) New Radio (NR), beyond the traditional bands below 6 GHz, has\nbeen also specified to operate over millimeter waves (mmWaves), in the\nso-called Frequency Range 2 (FR2). Such frequency bands have been since decades\nthe natural habitat for fixed satellite services (FSS). In this new landscape,\nthis paper preliminary investigates the feasibility of non-geostationary orbit\n(NGSO) satellites directly accessing NR-enabled User Equipment (UE) in mmWaves,\nfrom a regulatory, UE characteristics, space segment, link budget and system\npoint of view. It also identifies future R and D needs in this area.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 19:07:07 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 11:24:34 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Arapoglou", "Pantelis-Daniel", ""], ["Cioni", "Stefano", ""], ["Re", "Emiliano", ""], ["Ginesi", "Alberto", ""]]}, {"id": "2003.11143", "submitter": "Jonathan Crussell", "authors": "Jonathan Crussell, David Fritz, Vince Urias", "title": "Automated Discovery for Emulytics", "comments": null, "journal-ref": null, "doi": null, "report-no": "SAND2020-3605 R", "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sandia has an extensive background in cybersecurity research and is currently\nextending its state-of-the-art modeling via emulation capability. However, a\nkey part of Sandia's modeling methodology is the discovery and specification of\nthe information-system under study, and the ability to recreate that\nspecification with the highest fidelity possible in order to extrapolate\nmeaningful results.\n  This work details a method to conduct information system discovery and\ndevelop tools to enable the creation of high-fidelity emulation models that can\nbe used to enable assessment of our infrastructure information system security\nposture and potential system impacts that could result from cyber threats. The\noutcome are a set of tools and techniques to go from network discovery of\noperational systems to emulating complex systems.\n  As a concrete usecase, we have applied these tools and techniques at\nSupercomputing 2016 to model SCinet, the world's largest research network. This\nmodel includes five routers and nearly 10,000 endpoints which we have launched\nin our emulation platform.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 23:01:14 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Crussell", "Jonathan", ""], ["Fritz", "David", ""], ["Urias", "Vince", ""]]}, {"id": "2003.11176", "submitter": "Aunas Manzoor", "authors": "Aunas Manzoor, S. M. Ahsan Kazmi, Shashi Raj Pandey, and Choong Seon\n  Hong", "title": "Contract-based Scheduling of URLLC Packets in Incumbent EMBB Traffic", "comments": "Submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the coexistence of ultra-reliable and low-latency communication\n(URLLC) and enhanced mobile broadband (eMBB) services on the same licensed\nspectrum has gained a lot of attention from both academia and industry.\nHowever, the coexistence of these services is not trivial due to the diverse\nmultiple access protocols, contrasting frame distributions in the existing\nnetwork, and the distinct quality of service requirements posed by these\nservices. Therefore, such coexistence drives towards a challenging resource\nscheduling problem. To address this problem, in this paper, we first\ninvestigate the possibilities of scheduling URLLC packets in incumbent eMBB\ntraffic. In this regard, we formulate an optimization problem for coexistence\nby dynamically adopting a superposition or puncturing scheme. In particular,\nthe aim is to provide spectrum access to the URLLC users while reducing the\nintervention on incumbent eMBB users. Next, we apply the one-to-one matching\ngame to find stable URLLC-eMBB pairs that can coexist on the same spectrum.\nThen, we apply the contract theory framework to design contracts for URLLC\nusers to adopt the superposition scheme. Simulation results reveal that the\nproposed contract-based scheduling scheme achieves up to 63% of the eMBB rate\nfor the \"No URLLC\" case compared to the \"Puncturing\" scheme.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 01:47:14 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 02:46:30 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Manzoor", "Aunas", ""], ["Kazmi", "S. M. Ahsan", ""], ["Pandey", "Shashi Raj", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2003.11198", "submitter": "Xiongfeng Guo", "authors": "Xiongfeng Guo, Tianhao Wu and Lin Zhang", "title": "Value-Decomposition Networks based Distributed Interference Control in\n  Multi-platoon Groupcast", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Platooning is considered one of the most representative 5G use cases. Due to\nthe small spacing within the platoon, the platoon needs more reliable\ntransmission to guarantee driving safety while improving fuel and driving\nefficiency. However, efficient resource allocation between platoons has been a\nchallenge, especially considering that the channel and power selected by each\nplatoon will affect other platoons. Therefore, platoons need to coordinate with\neach other to ensure the groupcast quality of each platoon. To solve these\nchallenges, we model the multi-platoon resource selection problem as Markov\ngames and then propose a distributed resource allocation algorithm based on\nValue-Decomposition Networks. Our scheme utilizes the historical data of each\nplatoon for centralized training. In distributed execution, agents only need\ntheir local observations to make decisions. At the same time, we decrease the\ntraining burden by sharing the neural network parameters. Simulation results\nshow that the proposed algorithm has excellent convergence. Compared with\nanother multi-agent algorithm (MARL) and random algorithm, our proposed\nsolution can dramatically reduce the probability of platoon groupcast failure\nand improve the quality of platoon groupcast.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 03:08:47 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Guo", "Xiongfeng", ""], ["Wu", "Tianhao", ""], ["Zhang", "Lin", ""]]}, {"id": "2003.11210", "submitter": "Yiding Yu", "authors": "Yiding Yu, Soung Chang Liew, and Taotao Wang", "title": "Multi-Agent Deep Reinforcement Learning Multiple Access for\n  Heterogeneous Wireless Networks with Imperfect Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a futuristic spectrum sharing paradigm for\nheterogeneous wireless networks with imperfect channels. In the heterogeneous\nnetworks, multiple wireless networks adopt different medium access control\n(MAC) protocols to share a common wireless spectrum and each network is unaware\nof the MACs of others. This paper aims to design a distributed deep\nreinforcement learning (DRL) based MAC protocol for a particular network, and\nthe objective of this network is to achieve a global $\\alpha$-fairness\nobjective. In the conventional DRL framework, feedback/reward given to the\nagent is always correctly received, so that the agent can optimize its strategy\nbased on the received reward. In our wireless application where the channels\nare noisy, the feedback/reward (i.e., the ACK packet) may be lost due to\nchannel noise and interference. Without correct feedback, the agent (i.e., the\nnetwork user) may fail to find a good solution. Moreover, in the distributed\nprotocol, each agent makes decisions on its own. It is a challenge to guarantee\nthat the multiple agents will make coherent decisions and work together to\nachieve the same objective, particularly in the face of imperfect feedback\nchannels. To tackle the challenge, we put forth (i) a feedback recovery\nmechanism to recover missing feedback information, and (ii) a two-stage action\nselection mechanism to aid coherent decision making to reduce transmission\ncollisions among the agents. Extensive simulation results demonstrate the\neffectiveness of these two mechanisms. Last but not least, we believe that the\nfeedback recovery mechanism and the two-stage action selection mechanism can\nalso be used in general distributed multi-agent reinforcement learning problems\nin which feedback information on rewards can be corrupted.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 04:19:44 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Yu", "Yiding", ""], ["Liew", "Soung Chang", ""], ["Wang", "Taotao", ""]]}, {"id": "2003.11343", "submitter": "Muhammad Mohtasim Sajjad", "authors": "Muhammad Mohtasim Sajjad, Carlos J. Bernardos, Dhammika Jayalath,\n  Yu-Chu Tian", "title": "Inter-Slice Mobility Management in 5G: Motivations, Standard Principles,\n  Challenges and Research Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobility management in a sliced 5G network introduces new and complex\nchallenges. In a network-sliced environment, user mobility has to be managed\nnot only among different base stations or access technologies, but also among\ndifferent slices. This motivates the need for new mobility management\nsolutions, which, by convention are required to be standards-compliant. This\narticle, presented as a tutorial, focuses on the problem of inter-slice\nmobility from the perspective of 3GPP standards for 5G. A detailed overview of\nthe relevant 3GPP standard principles is provided. Accordingly, the key\ntechnical gaps, challenges and the corresponding research directions are\nidentified towards achieving seamless inter-slice mobility within the current\n3GPP network slicing framework.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:55:32 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 22:31:45 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Sajjad", "Muhammad Mohtasim", ""], ["Bernardos", "Carlos J.", ""], ["Jayalath", "Dhammika", ""], ["Tian", "Yu-Chu", ""]]}, {"id": "2003.11761", "submitter": "Xiaoxiong Zhong", "authors": "Xiaoxiong Zhong, Li Li, Yuanping Zhang, Bin Zhang, Weizhe Zhang, and\n  Tingting Yang", "title": "OODT: Obstacle Aware Opportunistic Data Transmission for Cognitive Radio\n  Ad Hoc Networks", "comments": "14 pages, 19 figures, TOMM 2020", "journal-ref": "IEEE Transactions on Communications 2020", "doi": "10.1109/TCOMM.2020.2979976", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a large number of smart devices will be connected in\nInternet of Things (IoT) using an ad hoc network, which needs more frequency\nspectra. The cognitive radio (CR) technology can improve spectrum utilization\nin an opportunistic communication manner for IoT, forming a promising paradigm\nknown as cognitive radio ad hoc networks,CRAHNs. However, dynamic spectrum\navailability and mobile devices/persons make it difficult to develop an\nefficient data transmission scheme for CRAHNs under an obstacle environment.\nOpportunistic routing can leverage the broadcast nature of wireless channels to\nenhance network performance. Inspired by this, in this paper, we propose an\nObstacle aware Opportunistic Data Transmission scheme (OODT) in CRAHNs from a\ncomputational geometry perspective, considering energy efficiency and social\nfeatures. In the proposed scheme, we exploit a new routing metric, which is\nbased on an obstacle avoiding algorithm using a polygon boundary 1-searcher\ntechnology, and an auction model for selecting forwarding candidates. In\naddition, we prove that the candidate selection problem is NP-hard and propose\na heuristic algorithm for candidate selection. The simulation results show that\nthe proposed scheme can achieve better performance than existing schemes.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 06:52:52 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zhong", "Xiaoxiong", ""], ["Li", "Li", ""], ["Zhang", "Yuanping", ""], ["Zhang", "Bin", ""], ["Zhang", "Weizhe", ""], ["Yang", "Tingting", ""]]}, {"id": "2003.11903", "submitter": "Anika Schwind", "authors": "Anika Schwind, Florian Wamser, Tobias Ho{\\ss}feld, Stefan Wunderer,\n  Erik Tarnvik, Andy Hall", "title": "Crowdsourced Network Measurements in Germany: Mobile Internet Experience\n  from End User Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Collecting and analyzing meaningful data in mobile networks is the key to\nassessing network performance. Crowdsourced Network Measurements (CNMs) provide\ninsights beyond the network layer and offer performance and other measurements\nat the application and user-level towards Quality of Experience (QoE). In this\npaper, the mobile Internet experience for Germany is evaluated with the help of\ncrowdsourcing from the perspective of an end user. We statistically analyze a\ndataset with throughput measurements on the end device from Tutela Ltd., which\ncovers more than 2.5 million throughput tests across Germany from January to\nJuly 2019. We give insights into this emerging methodology and highlight the\nbenefits of this method. The paper contains statistics and conclusions for\nseveral large cities as well as regions in Germany compared to general\nstatements for Germany, since individual measurements and averages often only\nimprecisely reflect the situation. The goal is to give a holistic view of the\nperformance of the current mobile network in Germany. Reading this paper, it\nbecomes evident that reliable statements about the quality of the mobile\nnetwork for Germany depend on a large number of peculiarities in different\nregions with their own performance characteristics due to different network\ndeployments and population numbers.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 13:49:25 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Schwind", "Anika", ""], ["Wamser", "Florian", ""], ["Ho\u00dffeld", "Tobias", ""], ["Wunderer", "Stefan", ""], ["Tarnvik", "Erik", ""], ["Hall", "Andy", ""]]}, {"id": "2003.11999", "submitter": "Jose Moura", "authors": "Patricia Cardoso, Jose Moura, Rui Marinheiro", "title": "A Software-Defined Solution for Managing Fog Computing Resources in\n  Sensor Networks", "comments": "8 pages, 14 figures, 2 tables, 16 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast growth of Internet-connected embedded devices demands for new\ncapabilities at the network edge. These new capabilities are local processing,\nfast communications, and resource virtualization. The current work aims to\naddress the previous capabilities by designing and deploying a new proposal,\nwhich offers on-demand activation of offline IoT fog computing assets via a\nSoftware Defined Networking (SDN) based solution combined with containerization\nand sensor virtualization. We present and discuss performance and functional\noutcomes from emulated tests made on our proposal. Analysing the performance\nresults, the system latency has two parts. The first part is about the delay\ninduced by limitations on the networking resources. The second part of the\nsystem latency is due to the on-demand activation of the required processing\nresources, which are initially powered off towards a more sustainable system\noperation. In addition, analysing the functional results, when a real IoT\nprotocol is used, we evidence our proposal viability to be deployed with the\nnecessary orchestration in distributed scenarios involving embedded devices,\nactuators, controllers, and brokers at the network edge.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 16:04:22 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Cardoso", "Patricia", ""], ["Moura", "Jose", ""], ["Marinheiro", "Rui", ""]]}, {"id": "2003.12027", "submitter": "Arsenia (Ersi) Chorti", "authors": "Gustavo A. Nunez Segura, Sotiris Skaperas, Arsenia Chorti, Lefteris\n  Mamatas and Cintia Borges Margi", "title": "Denial of Service Attacks Detection in Software-Defined Wireless Sensor\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Software-defined networking (SDN) is a promising technology to overcome many\nchallenges in wireless sensor networks (WSN), particularly with respect to\nflexibility and reuse. Conversely, the centralization and the planes'\nseparation turn SDNs vulnerable to new security threats in the general context\nof distributed denial of service (DDoS) attacks. State-of-the-art approaches to\nidentify DDoS do not always take into consideration restrictions in typical\nWSNs e.g., computational complexity and power constraints, while further\nperformance improvement is always a target. The objective of this work is to\npropose a lightweight but very efficient DDoS attack detection approach using\nchange point analysis. Our approach has a high detection rate and linear\ncomplexity, so that it is suitable for WSNs. We demonstrate the performance of\nour detector in software-defined WSNs of 36 and 100 nodes with varying attack\nintensity (the number of attackers ranges from 5% to 20% of nodes). We use\nchange point detectors to monitor anomalies in two metrics: the data packets\ndelivery rate and the control packets overhead. Our results show that with\nincreasing intensity of attack, our approach can achieve a detection rate close\nto100% and that the type of attack can also be inferred.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 16:49:28 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Segura", "Gustavo A. Nunez", ""], ["Skaperas", "Sotiris", ""], ["Chorti", "Arsenia", ""], ["Mamatas", "Lefteris", ""], ["Margi", "Cintia Borges", ""]]}, {"id": "2003.12172", "submitter": "Dianlei Xu", "authors": "Dianlei Xu, Tong Li, Yong Li, Xiang Su, Sasu Tarkoma, Tao Jiang, Jon\n  Crowcroft, Pan Hui", "title": "Edge Intelligence: Architectures, Challenges, and Applications", "comments": "53 pages, 37 figures, survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge intelligence refers to a set of connected systems and devices for data\ncollection, caching, processing, and analysis in locations close to where data\nis captured based on artificial intelligence. The aim of edge intelligence is\nto enhance the quality and speed of data processing and protect the privacy and\nsecurity of the data. Although recently emerged, spanning the period from 2011\nto now, this field of research has shown explosive growth over the past five\nyears. In this paper, we present a thorough and comprehensive survey on the\nliterature surrounding edge intelligence. We first identify four fundamental\ncomponents of edge intelligence, namely edge caching, edge training, edge\ninference, and edge offloading, based on theoretical and practical results\npertaining to proposed and deployed systems. We then aim for a systematic\nclassification of the state of the solutions by examining research results and\nobservations for each of the four components and present a taxonomy that\nincludes practical problems, adopted techniques, and application goals. For\neach category, we elaborate, compare and analyse the literature from the\nperspectives of adopted techniques, objectives, performance, advantages and\ndrawbacks, etc. This survey article provides a comprehensive introduction to\nedge intelligence and its application areas. In addition, we summarise the\ndevelopment of the emerging research field and the current state-of-the-art and\ndiscuss the important open issues and possible theoretical and technical\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 22:24:56 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 14:40:56 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Xu", "Dianlei", ""], ["Li", "Tong", ""], ["Li", "Yong", ""], ["Su", "Xiang", ""], ["Tarkoma", "Sasu", ""], ["Jiang", "Tao", ""], ["Crowcroft", "Jon", ""], ["Hui", "Pan", ""]]}, {"id": "2003.12225", "submitter": "Masahito Hayashi", "authors": "Masahito Hayashi and Ning Cai", "title": "Asymptotically Secure Network Code for Active Attacks and its\n  Application to Network Quantum Key Distribution", "comments": "arXiv admin note: text overlap with arXiv:1703.00723", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When there exists a malicious attacker in the network, we need to be careful\nof eavesdropping and contamination. This problem is crucial for network\ncommunication when the network is realized by a partially trusted relay of\nquantum key distribution. We discuss the asymptotic rate in a linear network\nwith the secrecy and robustness conditions when the above type of attacker\nexists. Also, under the same setting, we discuss the asymptotic rate in a\nlinear network when we impose the secrecy condition alone. Then, we apply these\nresults to the network composed of a partially trusted relay of quantum key\ndistribution, which enables us to realize secure long-distance communication\nvia short-distance quantum key distribution.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 03:49:55 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Hayashi", "Masahito", ""], ["Cai", "Ning", ""]]}, {"id": "2003.12228", "submitter": "Yutao Jiao", "authors": "Yutao Jiao, Ping Wang, Dusit Niyato, Bin Lin, Dong In Kim", "title": "Mechanism Design for Wireless Powered Spatial Crowdsourcing Networks", "comments": "14 pages. arXiv admin note: substantial text overlap with\n  arXiv:1907.08927", "journal-ref": "in IEEE Transactions on Vehicular Technology, vol. 69, no. 1, pp.\n  920-934, Jan. 2020", "doi": "10.1109/TVT.2019.2952926", "report-no": null, "categories": "cs.GT cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless power transfer (WPT) is a promising technology to prolong the\nlifetime of the sensors and communication devices, i.e., workers, in completing\ncrowdsourcing tasks by providing continuous and cost-effective energy supplies.\nIn this paper, we propose a wireless powered spatial crowdsourcing framework\nwhich consists of two mutually dependent phases: task allocation phase and data\ncrowdsourcing phase. In the task allocation phase, we propose a Stackelberg\ngame based mechanism for the spatial crowdsourcing platform to efficiently\nallocate spatial tasks and wireless charging power to each worker. In the data\ncrowdsourcing phase, the workers may have an incentive to misreport its real\nworking location to improve its utility, which causes adverse effects to the\nspatial crowdsourcing platform. To address this issue, we present three\nstrategyproof deployment mechanisms for the spatial crowdsourcing platform to\nplace a mobile base station, e.g., vehicle or robot, which is responsible for\ntransferring the wireless power and collecting the crowdsourced data. As the\nbenchmark, we first apply the classical median mechanism and evaluate its\nworst-case performance. Then, we design a conventional strategyproof deployment\nmechanism to improve the expected utility of the spatial crowdsourcing platform\nunder the condition that the workers' locations follow a known geographical\ndistribution. For a more general case with only the historical location data\navailable, we propose a deep learning based strategyproof deployment mechanism\nto maximize the spatial crowdsourcing platform's utility. Extensive\nexperimental results based on synthetic and real-world datasets reveal the\neffectiveness of the proposed framework in allocating tasks and charging power\nto workers while avoiding the dishonest worker's manipulation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 04:10:06 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Jiao", "Yutao", ""], ["Wang", "Ping", ""], ["Niyato", "Dusit", ""], ["Lin", "Bin", ""], ["Kim", "Dong In", ""]]}, {"id": "2003.12258", "submitter": "Sayed Amir Hoseini", "authors": "Sayed Amir Hoseini, Jahan Hassan, Ayub Bokani, Salil S. Kanhere", "title": "Trajectory Optimization of Flying Energy Sources using Q-Learning to\n  Recharge Hotspot UAVs", "comments": null, "journal-ref": null, "doi": "10.1109/INFOCOMWKSHPS50562.2020.9162834", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the increasing popularity of commercial usage of UAVs or\ndrone-delivered services, their dependence on the limited-capacity on-board\nbatteries hinders their flight-time and mission continuity. As such, developing\nin-situ power transfer solutions for topping-up UAV batteries have the\npotential to extend their mission duration. In this paper, we study a scenario\nwhere UAVs are deployed as base stations (UAV-BS) providing wireless Hotspot\nservices to the ground nodes, while harvesting wireless energy from flying\nenergy sources. These energy sources are specialized UAVs (Charger or\ntransmitter UAVs, tUAVs), equipped with wireless power transmitting devices\nsuch as RF antennae. tUAVs have the flexibility to adjust their flight path to\nmaximize energy transfer. With the increasing number of UAV-BSs and\nenvironmental complexity, it is necessary to develop an intelligent trajectory\nselection procedure for tUAVs so as to optimize the energy transfer gain. In\nthis paper, we model the trajectory optimization of tUAVs as a Markov Decision\nProcess (MDP) problem and solve it using Q-Learning algorithm. Simulation\nresults confirm that the Q-Learning based optimized trajectory of the tUAVs\noutperforms two benchmark strategies, namely random path planning and static\nhovering of the tUAVs.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 07:09:42 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Hoseini", "Sayed Amir", ""], ["Hassan", "Jahan", ""], ["Bokani", "Ayub", ""], ["Kanhere", "Salil S.", ""]]}, {"id": "2003.12313", "submitter": "Sai Kireet Patri", "authors": "Sai Kireet Patri, Elena Grigoreva, Wolfgang Kellerer and Carmen Mas\n  Machuca", "title": "Rational Agent-Based Decision Algorithm for Strategic Converged Network\n  Migration Planning", "comments": null, "journal-ref": "Journal Of Optical Communications and Networking Volume 11, No. 7,\n  July 2019", "doi": "10.1364/JOCN.11.000371", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To keep up with constantly growing user demands for services with higher\nquality and bandwidth requirements, telecommunication operators are forced to\nupgrade their networks. This upgrade, or migration of the network to a new\ntechnology, is a complex strategic network planning problem that involves\ntechno-economic evaluations over multiple periods of time. The state-of-the-art\napproaches consider migrations to a concrete architecture and do not take\nuncertainties, such as user churn, into account. This results in migration cost\nunderestimations and profitability over-estimations. In this paper, we propose\na generic migration algorithm derived from a search based rational agent\ndecision process that can deal with uncertainties and provides the migration\npath using a maximized utility function. The algorithm maximizes the migration\nproject profitability, measured as accumulated Net Present Value (NPV). This\nflexible and generic methodology has been evaluated on the example of migration\nfrom existing copper networks to the future-proof Passive Optical Network (PON)\narchitectures. Our proposed flexible migration algorithm is validated over pure\nresidential and converged scenarios in a fully reproducible case study. The\nresults yield that the migration flexibility is a key to the profit\nmaximization.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 10:26:38 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Patri", "Sai Kireet", ""], ["Grigoreva", "Elena", ""], ["Kellerer", "Wolfgang", ""], ["Machuca", "Carmen Mas", ""]]}, {"id": "2003.12341", "submitter": "Martin Henze", "authors": "Linus Roepert, Markus Dahlmanns, Ina Berenice Fink, Jan Pennekamp,\n  Martin Henze", "title": "Assessing the Security of OPC UA Deployments", "comments": "2 pages, 1 figure, to be published in Proceedings of the 1st ITG\n  Workshop on IT Security (ITSec)", "journal-ref": null, "doi": "10.15496/publikation-41813", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the increasing security demands of industrial deployments, OPC UA\nis one of the first industrial protocols explicitly designed with security in\nmind. However, deploying it securely requires a thorough configuration of a\nwide range of options. Thus, assessing the security of OPC UA deployments and\ntheir configuration is necessary to ensure secure operation, most importantly\nconfidentiality and integrity of industrial processes. In this work, we present\nextensions to the popular Metasploit Framework to ease network-based security\nassessments of OPC UA deployments. To this end, we discuss methods to discover\nOPC UA servers, test their authentication, obtain their configuration, and\ncheck for vulnerabilities. Ultimately, our work enables operators to verify the\n(security) configuration of their systems and identify potential attack\nvectors.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 11:39:43 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Roepert", "Linus", ""], ["Dahlmanns", "Markus", ""], ["Fink", "Ina Berenice", ""], ["Pennekamp", "Jan", ""], ["Henze", "Martin", ""]]}, {"id": "2003.12439", "submitter": "Jun Liu", "authors": "Jiawei Wu, Jianxue Li, Yang Xiao, Jun Liu", "title": "Towards Cognitive Routing based on Deep Reinforcement Learning", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing is one of the key functions for stable operation of network\ninfrastructure. Nowadays, the rapid growth of network traffic volume and\nchanging of service requirements call for more intelligent routing methods than\nbefore. Towards this end, we propose a definition of cognitive routing and an\nimplementation approach based on Deep Reinforcement Learning (DRL). To\nfacilitate the research of DRL-based cognitive routing, we introduce a\nsimulator named RL4Net for DRL-based routing algorithm development and\nsimulation. Then, we design and implement a DDPG-based routing algorithm. The\nsimulation results on an example network topology show that the DDPG-based\nrouting algorithm achieves better performance than OSPF and random weight\nalgorithms. It demonstrate the preliminary feasibility and potential advantage\nof cognitive routing for future network.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 03:32:43 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Wu", "Jiawei", ""], ["Li", "Jianxue", ""], ["Xiao", "Yang", ""], ["Liu", "Jun", ""]]}, {"id": "2003.12527", "submitter": "H{\\aa}kan Johansson", "authors": "H. T. Johansson, A. Furufors, P. Klenze", "title": "Fakernet -- small and fast FPGA-based TCP and UDP communication", "comments": "12 pages, 11 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ins-det cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common theme of data acquisition systems is the transport of data from\ndigitising front-end modules to stable storage and online analysis. A good\nchoice today is to base this on the ubiquitous, commercially and cheaply\navailable Ethernet technology. A firmware building block to turn already the\nFPGA of front-end electronics into a TCP data source and UDP control interface\nusing a data-flow architecture is presented. The overall performance targets\nare to be able to saturate a 1 Gbps network link with outbound data, while\nusing few FPGA resources. The goal is to replace the use of custom data buses\nand protocols with ordinary Ethernet equipment. These objectives are achieved\nby being just-enough conforming, such that no special drivers are needed in the\nPC equipment interfacing with the here presented Fakernet system. An important\ndesign choice is to handle all packet-data internally as 16-bit words, thus\nreducing the clock-speed requirements. An advantageous circumstance is that\neven at 1 Gbps speeds, for local network segments, the round-trip times are\nusually well below 500 microseconds. Thus, less than 50 kiB of unacknowledged\ndata needs to be in-flight, allowing to saturate a network link without TCP\nwindow scaling. The Fakernet system has so far been shown to saturate a 100\nMbps link at 11.7 MB/s of TCP output data, and able to do 32-bit control\nregister accesses at over 450 kword/s.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 16:44:24 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Johansson", "H. T.", ""], ["Furufors", "A.", ""], ["Klenze", "P.", ""]]}, {"id": "2003.12631", "submitter": "Minghui LiWang", "authors": "Zhibin Gao, Minghui LiWang, Seyyedali Hosseinalipour, Huaiyu Dai,\n  Xianbin Wang", "title": "A Truthful Auction for Graph Job Allocation in Vehicular Cloud-assisted\n  Networks", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular cloud computing has emerged as a promising solution to fulfill\nusers' demands on processing computation-intensive applications in modern\ndriving environments. Such applications are commonly represented by graphs\nconsisting of components and edges. However, encouraging vehicles to share\nresources poses significant challenges owing to users' selfishness. In this\npaper, an auction-based graph job allocation problem is studied in vehicular\ncloud-assisted networks considering resource reutilization. Our goal is to map\neach buyer (component) to a feasible seller (virtual machine) while maximizing\nthe buyers' utility-of-service, which concerns the execution time and\ncommission cost. First, we formulate the auction-based graph job allocation as\nan integer programming (IP) problem. Then, a Vickrey-Clarke-Groves based\npayment rule is proposed which satisfies the desired economical properties,\ntruthfulness and individual rationality. We face two challenges: 1) the\nabove-mentioned IP problem is NP-hard; 2) one constraint associated with the IP\nproblem poses addressing the subgraph isomorphism problem. Thus, obtaining the\noptimal solution is practically infeasible in large-scale networks. Motivated\nby which, we develop a structure-preserved matching algorithm by maximizing the\nutility-of-service-gain, and the corresponding payment rule which offers\neconomical properties and low computation complexity. Extensive simulations\ndemonstrate that the proposed algorithm outperforms the benchmark methods\nconsidering various problem sizes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 20:43:19 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 02:38:00 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Gao", "Zhibin", ""], ["LiWang", "Minghui", ""], ["Hosseinalipour", "Seyyedali", ""], ["Dai", "Huaiyu", ""], ["Wang", "Xianbin", ""]]}, {"id": "2003.12671", "submitter": "Phuong-Duy Nguyen", "authors": "Phuong-Duy Nguyen and Long Bao Le", "title": "Joint Computation Offloading, SFC Placement, and Resource Allocation for\n  Multi-Site MEC Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network function Virtualization (NFV) and Mobile Edge Computing (MEC) are\npromising 5G technologies to support resource-demanding mobile applications. In\nNFV, one must process the service function chain (SFC) in which a set of\nnetwork functions must be executed in a specific order. Moreover, the MEC\ntechnology enables computation offloading of service requests from mobile users\nto remote servers to potentially reduce energy consumption and processing delay\nfor the mobile application. This paper considers the optimization of the\ncomputation offloading, resource allocation, and SFC placement in the\nmulti-site MEC system. Our design objective is to minimize the weighted\nnormalized energy consumption and computing cost subject to the maximum\ntolerable delay constraint. To solve the underlying mixed integer and\nnon-linear optimization problem, we employ the decomposition approach where we\niteratively optimize the computation offloading, SFC placement and computing\nresource allocation to obtain an efficient solution. Numerical results show the\nimpacts of different parameters on the system performance and the superior\nperformance of the proposed algorithm compared to benchmarking algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 00:27:07 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Nguyen", "Phuong-Duy", ""], ["Le", "Long Bao", ""]]}, {"id": "2003.12719", "submitter": "Junjie Yu", "authors": "Mingxiong Zhao, Jun-Jie Yu, Wen-Tao Li, Di Liu, Shaowen Yao, Wei Feng,\n  Changyang She, Tony Q. S. Quek", "title": "Energy-Aware Offloading in Time-Sensitive Networks with Mobile Edge\n  Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Edge Computing (MEC) enables rich services in close proximity to the\nend users to provide high quality of experience (QoE) and contributes to energy\nconservation compared with local computing, but results in increased\ncommunication latency. In this paper, we investigate how to jointly optimize\ntask offloading and resource allocation to minimize the energy consumption in\nan orthogonal frequency division multiple access-based MEC networks, where the\ntime-sensitive tasks can be processed at both local users and MEC server via\npartial offloading. Since the optimization variables of the problem are\nstrongly coupled, we first decompose the orignal problem into three subproblems\nnamed as offloading selection (PO ), transmission power optimization (PT ), and\nsubcarriers and computing resource allocation (PS ), and then propose an\niterative algorithm to deal with them in a sequence. To be specific, we derive\nthe closed-form solution for PO , employ the equivalent parametric convex\nprogramming to cope with the objective function which is in the form of sum of\nratios in PT , and deal with PS by an alternating way in the dual domain due to\nits NP-hardness. Simulation results demonstrate that the proposed algorithm\noutperforms the existing schemes.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 05:52:24 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Zhao", "Mingxiong", ""], ["Yu", "Jun-Jie", ""], ["Li", "Wen-Tao", ""], ["Liu", "Di", ""], ["Yao", "Shaowen", ""], ["Feng", "Wei", ""], ["She", "Changyang", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2003.12742", "submitter": "Tobias Hossfeld", "authors": "Tobias Hossfeld, Poul E. Heegaard, Martin Varela, Lea Skorin-Kapov,\n  Markus Fiedler", "title": "From QoS Distributions to QoE Distributions: a System's Perspective", "comments": "4th International Workshop on Quality of Experience Management (QoE\n  Management 2020), featured by IEEE Conference on Network Softwarization (IEEE\n  NetSoft 2020), Ghent, Belgium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of QoE management, network and service providers commonly rely\non models that map system QoS conditions (e.g., system response time, paket\nloss, etc.) to estimated end user QoE values. Observable QoS conditions in the\nsystem may be assumed to follow a certain distribution, meaning that different\nend users will experience different conditions. On the other hand, drawing from\nthe results of subjective user studies, we know that user diversity leads to\ndistributions of user scores for any given test conditions (in this case\nreferring to the QoS parameters of interest). Our previous studies have shown\nthat to correctly derive various QoE metrics (e.g., Mean Opinion Score (MOS),\nquantiles, probability of users rating \"good or better\", etc.) in a system\nunder given conditions, there is a need to consider rating distributions\nobtained from user studies, which are often times not available. In this paper\nwe extend these findings to show how to approximate user rating distributions\ngiven a QoS-to-MOS mapping function and second order statistics. Such a user\nrating distribution may then be combined with a QoS distribution observed in a\nsystem to finally derive corresponding distributions of QoE scores. We provide\ntwo examples to illustrate this process: 1) analytical results using a Web QoE\nmodel relating waiting times to QoE, and 2) numerical results using\nmeasurements relating packet losses to video stall pattern, which are in turn\nmapped to QoE estimates. The results in this paper provide a solution to the\nproblem of understanding the QoE distribution in a system, in cases where the\nnecessary data is not directly available in the form of models going beyond the\nMOS, or where the full details of subjective experiments are not available.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 08:31:30 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Hossfeld", "Tobias", ""], ["Heegaard", "Poul E.", ""], ["Varela", "Martin", ""], ["Skorin-Kapov", "Lea", ""], ["Fiedler", "Markus", ""]]}, {"id": "2003.12804", "submitter": "Junyao Guo", "authors": "Sihai Zhang, Junyao Guo, Tian Lan, Rui Sun, Jinkang Zhu", "title": "Real Entropy Can Also Predict Daily Voice Traffic for Wireless Network\n  Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice traffic prediction is significant for network deployment optimization\nthus to improve the network efficiency. The real entropy based theorectical\nbound and corresponding prediction models have demonstrated their success in\nmobility prediction. In this paper, the real entropy based predictability\nanalysis and prediction models are introduced into voice traffic prediction.\nFor this adoption, the traffic quantification methods is proposed and\ndiscussed. Based on the real world voice traffic data, the prediction accuracy\nof N-order Markov models, diffusion based model and MF model are presented,\namong which, 25-order Markov models performs best and approach close to the\nmaximum predictability. This work demonstrates that, the real entropy can also\npredict voice traffic well which broaden the understanding on the real entropy\nbased prediction theory.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 14:56:28 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Zhang", "Sihai", ""], ["Guo", "Junyao", ""], ["Lan", "Tian", ""], ["Sun", "Rui", ""], ["Zhu", "Jinkang", ""]]}, {"id": "2003.12846", "submitter": "Xiaoxiong Zhong", "authors": "Xiaoxiong Zhong, Xinghan Wang, Li Li, Yuanyuan Yang, Yang Qin,\n  Tingting Yang, Bin Zhang, Weizhe Zhang", "title": "CL-ADMM: A Cooperative Learning Based Optimization Framework for\n  Resource Management in MEC", "comments": "17 pages, 11 figures, submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of intelligent and efficient resource management\nframework in mobile edge computing (MEC), which can reduce delay and energy\nconsumption, featuring distributed optimization and efficient congestion\navoidance mechanism. In this paper, we present a Cooperative Learning framework\nfor resource management in MEC from an Alternating Direction Method of\nMultipliers (ADMM) perspective, called CL-ADMM framework. First, in order to\ncaching task efficiently in a group, a novel task popularity estimating scheme\nis proposed, which is based on semi-Markov process model, then a greedy task\ncooperative caching mechanism has been established, which can effectively\nreduce delay and energy consumption. Secondly, for addressing group congestion,\na dynamic task migration scheme based on cooperative improved Q-learning is\nproposed, which can effectively reduce delay and alleviate congestion. Thirdly,\nfor minimizing delay and energy consumption for resources allocation in a\ngroup, we formulate it as an optimization problem with a large number of\nvariables, and then exploit a novel ADMM based scheme to address this problem,\nwhich can reduce the complexity of problem with a new set of auxiliary\nvariables, these sub-problems are all convex problems, and can be solved by\nusing a primal-dual approach, guaranteeing its convergences. Then we prove that\nthe convergence by using Lyapunov theory. Numerical results demonstrate the\neffectiveness of the CL-ADMM and it can effectively reduce delay and energy\nconsumption for MEC.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 17:19:56 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 09:48:02 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 08:11:10 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zhong", "Xiaoxiong", ""], ["Wang", "Xinghan", ""], ["Li", "Li", ""], ["Yang", "Yuanyuan", ""], ["Qin", "Yang", ""], ["Yang", "Tingting", ""], ["Zhang", "Bin", ""], ["Zhang", "Weizhe", ""]]}, {"id": "2003.12911", "submitter": "Qiang Liu", "authors": "Qiang Liu, Tao Han, Ephraim Moges", "title": "EdgeSlice: Slicing Wireless Edge Computing Network with Decentralized\n  Deep Reinforcement Learning", "comments": "11 pages, 11 figures, accepted by IEEE ICDCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G and edge computing will serve various emerging use cases that have diverse\nrequirements of multiple resources, e.g., radio, transportation, and computing.\nNetwork slicing is a promising technology for creating virtual networks that\ncan be customized according to the requirements of different use cases.\nProvisioning network slices requires end-to-end resource orchestration which is\nchallenging. In this paper, we design a decentralized resource orchestration\nsystem named EdgeSlice for dynamic end-to-end network slicing. EdgeSlice\nintroduces a new decentralized deep reinforcement learning (D-DRL) method to\nefficiently orchestrate end-to-end resources. D-DRL is composed of a\nperformance coordinator and multiple orchestration agents. The performance\ncoordinator manages the resource orchestration policies in all the\norchestration agents to ensure the service level agreement (SLA) of network\nslices. The orchestration agent learns the resource demands of network slices\nand orchestrates the resource allocation accordingly to optimize the\nperformance of the slices under the constrained networking and computing\nresources. We design radio, transport and computing manager to enable dynamic\nconfiguration of end-to-end resources at runtime. We implement EdgeSlice on a\nprototype of the end-to-end wireless edge computing network with\nOpenAirInterface LTE network, OpenDayLight SDN switches, and CUDA GPU platform.\nThe performance of EdgeSlice is evaluated through both experiments and\ntrace-driven simulations. The evaluation results show that EdgeSlice achieves\nmuch improvement as compared to baseline in terms of performance, scalability,\ncompatibility.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 23:30:44 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Liu", "Qiang", ""], ["Han", "Tao", ""], ["Moges", "Ephraim", ""]]}, {"id": "2003.12920", "submitter": "Shajulin Benedict", "authors": "Shajulin Benedict, Rumaize P., Jaspreet Kaur", "title": "IoT Blockchain Solution for Air Quality Monitoring in SmartCities", "comments": "IEEE ANTS2019 Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT cloud enabled societal applications have dramatically increased in the\nrecent past due to the thrust for innovations, notably through startup\ninitiatives, in various sectors such as agriculture, healthcare, industry, and\nso forth. The existing IoT cloud solutions have led practitioners or\nresearchers to a haphazard clutter of serious security hazards and performance\ninefficiencies. This paper proposes a blockchain enabled IoT cloud\nimplementation to tackle the existing issues in smart cities. It particularly\nhighlights the implementation of chaincodes for air quality monitoring systems\nin SmartCities; the proposed architecture named as IoT enabled Blockchain for\nAir Quality Monitoring System (IB-AQMS) is illustrated using experiments.\nExperimental results were carried out and the findings were disclosed in the\npaper.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 01:44:22 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Benedict", "Shajulin", ""], ["P.", "Rumaize", ""], ["Kaur", "Jaspreet", ""]]}, {"id": "2003.13115", "submitter": "Arash Asadi", "authors": "Saeede Fattahi-Bafghi, Zolfa Zeinalpour-Yazdi, Arash Asadi", "title": "An Analytical Framework for mmWave-Enabled V2X Caching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles will rely heavily on vehicle-to-everything (V2X)\ncommunications to obtain a large amount of information required for navigation\nand road safety purposes. This can be achieved through: (i) leveraging\nmillimeter-wave (mmWave) frequencies to achieve multi- Gbps data rates, and\n(ii) exploiting the temporal and spatial correlation of vehicular contents to\noffload a portion of the traffic from the infrastructure via caching.\nCharacterizing such a system under mmWave directional beamforming, high\nvehicular mobility, channel fluctuations, and different caching strategies is a\ncomplex task. In this article, we propose the first stochastic geometry\nframework for caching in mmWave V2X networks, which is validated via rigorous\nMonte Carlo simulation. In addition to common parameters considered in\nstochastic geometry models, our derivations account for caching as well as the\nspeed and the trajectory of the vehicles. Furthermore, our evaluations provide\ninteresting design insights: (i) higher base station/vehicle densities does not\nnecessarily improve caching performance; (ii) although using a narrower beam\nleads to a higher SINR, it also reduces the connectivity probability; and (iii)\nV2X caching can be an inexpensive way of compensating some of the unwanted\nmmWave channel characteristics.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 19:12:15 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Fattahi-Bafghi", "Saeede", ""], ["Zeinalpour-Yazdi", "Zolfa", ""], ["Asadi", "Arash", ""]]}, {"id": "2003.13311", "submitter": "Hong-Ning Dai Prof.", "authors": "Yalin Liu, Hong-Ning Dai, Qubeijian Wang, Mahendra K. Shukla, Muhammad\n  Imran", "title": "Unmanned Aerial Vehicle for Internet of Everything: Opportunities and\n  Challenges", "comments": "21 pages, 9 figures", "journal-ref": "Computer Communications, 2020", "doi": "10.1016/j.comcom.2020.03.017", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent advances in information and communication technology (ICT) have\nfurther extended Internet of Things (IoT) from the sole \"things\" aspect to the\nomnipotent role of \"intelligent connection of things\". Meanwhile, the concept\nof internet of everything (IoE) is presented as such an omnipotent extension of\nIoT. However, the IoE realization meets critical challenges including the\nrestricted network coverage and the limited resource of existing network\ntechnologies. Recently, Unmanned Aerial Vehicles (UAVs) have attracted\nsignificant attentions attributed to their high mobility, low cost, and\nflexible deployment. Thus, UAVs may potentially overcome the challenges of IoE.\nThis article presents a comprehensive survey on opportunities and challenges of\nUAV-enabled IoE. We first present three critical expectations of IoE: 1)\nscalability requiring a scalable network architecture with ubiquitous coverage,\n2) intelligence requiring a global computing plane enabling intelligent things,\n3) diversity requiring provisions of diverse applications. Thereafter, we\nreview the enabling technologies to achieve these expectations and discuss four\nintrinsic constraints of IoE (i.e., coverage constraint, battery constraint,\ncomputing constraint, and security issues). We then present an overview of\nUAVs. We next discuss the opportunities brought by UAV to IoE. Additionally, we\nintroduce a UAV-enabled IoE (Ue-IoE) solution by exploiting UAVs's mobility, in\nwhich we show that Ue-IoE can greatly enhance the scalability, intelligence and\ndiversity of IoE. Finally, we outline the future directions in Ue-IoE.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:00:24 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 14:47:35 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Yalin", ""], ["Dai", "Hong-Ning", ""], ["Wang", "Qubeijian", ""], ["Shukla", "Mahendra K.", ""], ["Imran", "Muhammad", ""]]}, {"id": "2003.13314", "submitter": "Wenbo Wang", "authors": "Wenbo Wang, Amir Leshem, Dusit Niyato, Zhu Han", "title": "Decentralized Learning for Channel Allocation in IoT Networks over\n  Unlicensed Bandwidth as a Contextual Multi-player Multi-armed Bandit Game", "comments": "32 pages, 10 figures, submitted to IEEE TWC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a decentralized channel allocation problem in an ad-hoc Internet of\nThings network underlaying on the spectrum licensed to a primary cellular\nnetwork. In the considered network, the impoverished channel sensing/probing\ncapability and computational resource on the IoT devices make them difficult to\nacquire the detailed Channel State Information (CSI) for the shared multiple\nchannels. In practice, the unknown patterns of the primary users' transmission\nactivities and the time-varying CSI (e.g., due to small-scale fading or device\nmobility) also cause stochastic changes in the channel quality. Decentralized\nIoT links are thus expected to learn channel conditions online based on partial\nobservations, while acquiring no information about the channels that they are\nnot operating on. They also have to reach an efficient, collision-free solution\nof channel allocation with limited coordination. Our study maps this problem\ninto a contextual multi-player, multi-armed bandit game, and proposes a purely\ndecentralized, three-stage policy learning algorithm through trial-and-error.\nTheoretical analyses shows that the proposed scheme guarantees the IoT links to\njointly converge to the social optimal channel allocation with a sub-linear\n(i.e., polylogarithmic) regret with respect to the operational time.\nSimulations demonstrate that it strikes a good balance between efficiency and\nnetwork scalability when compared with the other state-of-the-art decentralized\nbandit algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:05:35 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 08:12:11 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 10:16:15 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Wenbo", ""], ["Leshem", "Amir", ""], ["Niyato", "Dusit", ""], ["Han", "Zhu", ""]]}, {"id": "2003.13319", "submitter": "Ivica Stipovic", "authors": "Ivica Stipovic", "title": "Analysis of an Extension Dynamic Name Service -- A discussion on DNS\n  compliance with RFC 6891", "comments": "4 pages, 3 figures, blog site\n  https://adenosine-phosphatase.blogspot.com/2020/03/dns-insights-udp-vs-tcp-and-edns.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Name Service (DNS) resolution is a mechanism that resolves the\nsymbolic names of networked devices to their corresponding Internet Protocol\n(IP) address. With the emergence of the document that describes an extension to\na DNS service definition, it was becoming apparent that DNS implementations\nwill need to comply with some modified DNS behaviour. One such modification is\nthat DNS continues to use the User Datagram Protocol (UDP) to transmit DNS\npayloads that are longer than 512 bytes. Until the emergence of the Extension\nDNS (EDNS) specification, DNS servers would switch over from UDP to\nTransmission Control Protocol (TCP) if the response payload was larger than 512\nbytes. With the new EDNS capability, it was required that DNS replies would\ncontinue to provide responses as UDP datagrams even though the response was\nlarger than 512 bytes. To the author's best knowledge, there are no academic\narticles dealing with the assessment of the DNS servers against EDNS\nspecification. This paper examines the level of compatibility for a number of\npublic DNS servers for some popular internet domains. It also explores\nbehaviour of some contemporary DNS implementations such as Microsoft Windows\n2012, 2016 and 2019 as well as Linux-based BIND in regards to the EDNS.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:11:34 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Stipovic", "Ivica", ""]]}, {"id": "2003.13416", "submitter": "Jianxiong Guo", "authors": "Jianxiong Guo, Xingjian Ding, Weili Wu", "title": "Combined Cooling, Heating, and Power System in Blockchain-Enabled Energy\n  Management", "comments": "in IEEE Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2020.3015980", "report-no": null, "categories": "eess.SP cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combined cooling, heating and power (CCHP) system is a typical\ndistributed, electricity-gas integrated energy scheme in a community. First, it\ngenerates electricity by use of gas, and then exploits the waste heat to supply\ncommunity with heat and cooling. In this paper, we consider a smart city\nconsisting of a number of communities (CCHPs) and an agent of power grid (APG),\nwhere CCHPs can sell energy to the APG according to its bid. To study all\nutilities of entities in such a city from energy trading, a noncooperative\nStackelberg game between APG and CCHPs is formulated. Here, the APG gives a bid\nfor buying the energy from CCHPs, then CCHPs respond to the APG with their\noptimal energy supply that maximizing their utilities according to this bid. We\nshow that the maximum profit to the APG and utilities to the CCHPs can be\nobtained at the Stackelberg equilibrium, which is guaranteed to exist and\nunique. Because the complete information about energy supply of each CCHP is\nunknown to the APG in advance, we propose a distributed algorithm that is able\nto find the point of equilibrium through a limited number of iterations. Taking\nprivacy protection and transaction security into consideration, we design a\nblockchain-enabled energy management system. This system is composed of\nInternet of Energy (IoE) sub-system and blockchain sub-system, where the\ninformation interactions as well as energy transactions between APG and CCHPs\ncan be carried out effectively and safely. Finally, security analysis and\nnumerical simulations show the effectiveness and accuracy of our proposed\nmechanism.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 05:37:05 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Guo", "Jianxiong", ""], ["Ding", "Xingjian", ""], ["Wu", "Weili", ""]]}, {"id": "2003.13489", "submitter": "Tianzhu Zhang", "authors": "Tianzhu Zhang, Leonardo Linguaglossa, Paolo Giaccone, Luigi Iannone,\n  James Roberts", "title": "Performance Benchmarking of State-of-the-Art Software Switches for NFV", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ultimate goal of replacing proprietary hardware appliances with\nVirtual Network Functions (VNFs) implemented in software, Network Function\nVirtualization (NFV) has been gaining popularity in the past few years.\nSoftware switches route traffic between VNFs and physical Network Interface\nCards (NICs). It is of paramount importance to compare the performance of\ndifferent switch designs and architectures. In this paper, we propose a\nmethodology to compare fairly and comprehensively the performance of software\nswitches. We first explore the design spaces of seven state-of-the-art software\nswitches and then compare their performance under four representative test\nscenarios. Each scenario corresponds to a specific case of routing NFV traffic\nbetween NICs and/or VNFs. In our experiments, we evaluate the throughput and\nlatency between VNFs in two of the most popular virtualization environments,\nnamely virtual machines (VMs) and containers. Our experimental results show\nthat no single software switch prevails in all scenarios. It is, therefore,\ncrucial to choose the most suitable solution for the given use case. At the\nsame time, the presented results and analysis provide a deeper insight into the\ndesign tradeoffs and identifies potential performance bottlenecks that could\ninspire new designs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 14:13:53 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 10:12:18 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 16:25:53 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 13:37:40 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Zhang", "Tianzhu", ""], ["Linguaglossa", "Leonardo", ""], ["Giaccone", "Paolo", ""], ["Iannone", "Luigi", ""], ["Roberts", "James", ""]]}, {"id": "2003.13499", "submitter": "Franco Minucci", "authors": "Franco Minucci, Evgenii Vinogradov and Sofie Pollin", "title": "Avoiding collisions at any (low) cost: ADS-B like position broadcast for\n  UAVs", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3007315", "report-no": null, "categories": "eess.SY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs), a.k.a. drones, are increasingly used for\ndifferent tasks. With more drones in the sky, the risk of accidents rises,\nsparkling the need for conflict management solutions. Aircraft use a system\ncalled Automatic Dependent System-Broadcast (ADS-B) to continuously broadcast\ntheir position and speed but this system is not suitable for small drones\nbecause of its cost, complexity and capacity limitations.\n  Broadband technologies such as Wi-Fi beacons are more suited for such dense\nscenarios, and they also offer the benefit of wide availability and low cost.\nThe main challenges for Wi-Fi are (a) the multi-channel nature of the\ntechnology makes transmitter and receiver coordination difficult, and (b)\nstandard chipsets are not designed for frequent broadcast transmission and\nreception. In this paper, we propose and analyze a multi-channel position\nbroadcast solution that is robust against jamming and achieves a reliable\nlocation update within 125~ms. In addition, we implement the protocol on\ninexpensive embedded Wi-Fi modules and analyze the hardware limitations of such\ndevices. Our conclusions are that even on the simplest Wi-Fi chipsets, our\nprotocol can be implemented to achieve a realistic location broadcast solution\nthat still perfectly mimics simulation and analytical results on the lab bench\nand still can achieve approximately 4~message/s throughput at a distance of\n900~m on flying UAVs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 14:23:24 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 06:44:18 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Minucci", "Franco", ""], ["Vinogradov", "Evgenii", ""], ["Pollin", "Sofie", ""]]}, {"id": "2003.13577", "submitter": "Omur Ozel", "authors": "Parisa Rafiee and Peng Zou and Omur Ozel and Suresh Subramaniam", "title": "Maintaining Information Freshness in Power-Efficient Status Update\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by emerging edge computing systems which consist of\nsensor nodes that acquire and process information and then transmit status\nupdates to an edge receiver for possible further processing. As power is a\nscarce resource at the sensor nodes, the system is modeled as a tandem\ncomputation-transmission queue with power-efficient computing. Jobs arrive at\nthe computation server with rate $\\lambda$ as a Poisson process with no\navailable data buffer. The computation server can be in one of three states:\n(i) OFF: the server is turned off and no jobs are observed or processed, (ii)\nON-Idle: the server is turned on but there is no job in the server, (iii)\nON-Busy: the server is turned on and a job is processed in the server. These\nstates cost zero, one and $p_c$ units of power, respectively. Under a long-term\npower constraint, the computation server switches from one state to another in\nsequence: first a deterministic $T_o$ time units in OFF state, then waiting for\na job arrival in ON-Idle state and then in ON-Busy state for an independent\nidentically distributed compute time duration. The transmission server has a\nsingle unit data buffer to save incoming packets and applies last come first\nserve with discarding as well as a packet deadline to discard a sitting packet\nfor maintaining information freshness, which is measured by the Age of\nInformation (AoI). Additionally, there is a monotonic functional relation\nbetween the mean time spent in ON-Busy state and the mean transmission time. We\nobtain closed-form expressions for average AoI and average peak AoI. Our\nnumerical results illustrate various regimes of operation for best AoI\nperformances optimized over packet deadlines with relation to power efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 15:52:16 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Rafiee", "Parisa", ""], ["Zou", "Peng", ""], ["Ozel", "Omur", ""], ["Subramaniam", "Suresh", ""]]}, {"id": "2003.13604", "submitter": "Elisa Bertino", "authors": "Elisa Bertino, Syed Rafiul Hussain, and Omar Chowdhury", "title": "5G Security and Privacy: A Research Roadmap", "comments": "A Computing Community Consortium (CCC) white paper, 8 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_1", "categories": "cs.CY cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular networks represent a critical infrastructure and their security is\nthus crucial. 5G - the latest generation of cellular networks - combines\ndifferent technologies to increase capacity, reduce latency, and save energy.\nDue to its complexity and scale, however, ensuring its security is extremely\nchallenging. In this white paper, we outline recent approaches supporting\nsystematic analyses of 4G LTE and 5G protocols and their related defenses and\nintroduce an initial security and privacy roadmap, covering different research\nchallenges, including formal and comprehensive analyses of cellular protocols\nas defined by the standardization groups, verification of the software\nimplementing the protocols, the design of robust defenses, and application and\ndevice security.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:36:43 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Bertino", "Elisa", ""], ["Hussain", "Syed Rafiul", ""], ["Chowdhury", "Omar", ""]]}, {"id": "2003.13618", "submitter": "Javad Ghofrani", "authors": "Javad Ghofrani, Paul Patoola, Daniel Richter, Dirk Reichelt", "title": "Conceptualizing A Configuration Service for Complex Automation Systems", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arrowhead Framework (AHF) is being developed to enable large-scale IoT based\nautomation by providing an interoperability layer for local clouds. This\nframework aims to create an abstract model for distributed, heterogeneous, and\nnon-linear systems. Managing the variability in such environments plays a key\nrole in handling complex automation tasks such as in smart production systems.\nHowever, there is no standard solution available for handling the variability\nand configuration specifications in such environments. In this paper, we\nanalyze the existing solutions for configuration management in industrial\nautomation frameworks and provide leverage points for a standardization\nframework for handling configurations of automated production systems based on\nthe concept of industrial internet of things.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:49:18 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Ghofrani", "Javad", ""], ["Patoola", "Paul", ""], ["Richter", "Daniel", ""], ["Reichelt", "Dirk", ""]]}, {"id": "2003.13652", "submitter": "Adam Dziedzic", "authors": "Adam Dziedzic, Vanlin Sathya, Muhammad Iqbal Rochman, Monisha Ghosh\n  and Sanjay Krishnan", "title": "Machine Learning enabled Spectrum Sharing in Dense LTE-U/Wi-Fi\n  Coexistence Scenarios", "comments": "Accepted at IEEE Open Journal of Vehicular Technology. arXiv admin\n  note: substantial text overlap with arXiv:1911.09292", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of Machine Learning (ML) techniques to complex engineering\nproblems has proved to be an attractive and efficient solution. ML has been\nsuccessfully applied to several practical tasks like image recognition,\nautomating industrial operations, etc. The promise of ML techniques in solving\nnon-linear problems influenced this work which aims to apply known ML\ntechniques and develop new ones for wireless spectrum sharing between Wi-Fi and\nLTE in the unlicensed spectrum. In this work, we focus on the LTE-Unlicensed\n(LTE-U) specification developed by the LTE-U Forum, which uses the duty-cycle\napproach for fair coexistence. The specification suggests reducing the duty\ncycle at the LTE-U base-station (BS) when the number of co-channel Wi-Fi basic\nservice sets (BSSs) increases from one to two or more. However, without\ndecoding the Wi-Fi packets, detecting the number of Wi-Fi BSSs operating on the\nchannel in real-time is a challenging problem. In this work, we demonstrate a\nnovel ML-based approach which solves this problem by using energy values\nobserved during the LTE-U OFF duration. It is relatively straightforward to\nobserve only the energy values during the LTE-U BS OFF time compared to\ndecoding the entire Wi-Fi packet, which would require a full Wi-Fi receiver at\nthe LTE-U base-station. We implement and validate the proposed ML-based\napproach by real-time experiments and demonstrate that there exist distinct\npatterns between the energy distributions between one and many Wi-Fi AP\ntransmissions. The proposed ML-based approach results in a higher accuracy\n(close to 99\\% in all cases) as compared to the existing auto-correlation (AC)\nand energy detection (ED) approaches.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 01:26:36 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Dziedzic", "Adam", ""], ["Sathya", "Vanlin", ""], ["Rochman", "Muhammad Iqbal", ""], ["Ghosh", "Monisha", ""], ["Krishnan", "Sanjay", ""]]}, {"id": "2003.13675", "submitter": "Monireh Mohebbi", "authors": "Monireh Mohebbi Moghaddam, Mohammad Hossein Manshaei, Mehdi Naderi\n  Soorki, Walid Saad, Maziar Goudarzi, and Dusit Niyato", "title": "On Coordination of Smart Grid and Cooperative Cloud Providers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative cloud providers in the form of cloud federations can potentially\nreduce their energy costs by exploiting electricity price fluctuations across\ndifferent locations. In this environment, on the one hand, the electricity\nprice has a significant influence on the federations formed, and, thus, on the\nprofit earned by the cloud providers, and on the other hand, the cloud\ncooperation has an inevitable impact on the performance of the smart grid. In\nthis regard, the interaction between independent cloud providers and the smart\ngrid is modeled as a two-stage Stackelberg game interleaved with a coalitional\ngame in this paper. In this game, in the first stage the smart grid, as a\nleader chooses a proper electricity pricing mechanism to maximize its own\nprofit. In the second stage, cloud providers cooperatively manage their\nworkload to minimize their electricity costs. Given the dynamic of cloud\nproviders in the federation formation process, an optimization model based on a\nconstrained Markov decision process (CMDP) has been used by the smart grid to\nachieve the optimal policy. Numerical results show that the proposed solution\nyields around 28% and 29% profit improvement on average for the smart grid, and\nthe cloud providers, respectively, compared to the noncooperative scheme\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:56:33 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Moghaddam", "Monireh Mohebbi", ""], ["Manshaei", "Mohammad Hossein", ""], ["Soorki", "Mehdi Naderi", ""], ["Saad", "Walid", ""], ["Goudarzi", "Maziar", ""], ["Niyato", "Dusit", ""]]}, {"id": "2003.13765", "submitter": "Ghassan Samara", "authors": "Ghassan Samara, Munir Al-okour", "title": "Optimal Number of Cluster Heads in Wireless Sensors Networks Based on\n  LEACH", "comments": "5 pages", "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering, ISSN 2278-3091, Volume 9, No.1, 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wireless Sensor Network (WSN) has been one of the leading research fields\nof wireless networks, particularly in recent year. Sensors are randomly\npositioned in the region, every node senses the surroundings and sends the data\ncollected to the cluster head (CH), which aggregates and transmits obtained\ninformation to the Base Station (BS). A non-rechargeable battery is included on\neach WSN node. The sensor energy and network life extension of WSN are the most\nimportant considerations in the academia and industry. And thus, many routing\nprotocols have been proposed to solve this issue, one of these is LEACH, the\nearly protocol that introduced the clustering idea to extend the life of the\nWSN. LEACH is affected by the number of heads of the Clusters as it is randomly\nselected, and this has an impact on network lifetime, furthermore, the nodes\nare randomly joined in each cluster, this means that some of the cluster heads\nwork more than others with fewer cluster nodes. In this paper, it is proposed\nan algorithm Maximum Optimal Number of Cluster Heads (MONCH) to identify the\noptimum cluster heads in WSN and to find which is the nearest one to BS and\nhelps to integrate nodes with the most appropriate cluster. The results show\nimproved energy consumption performance for the LEACH algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:53:54 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Samara", "Ghassan", ""], ["Al-okour", "Munir", ""]]}, {"id": "2003.13837", "submitter": "Rodolfo Valiente", "authors": "Hossein Nourkhiz Mahjoub, Arash Raftari, Rodolfo Valiente, Yaser P.\n  Fallah, Syed K. Mahmud", "title": "Representing Realistic Human Driver Behaviors using a Finite Size\n  Gaussian Process Kernel Bank", "comments": "Accepted in IEEE VNC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of cooperative vehicular applications is tightly dependent on\nthe reliability of the underneath Vehicle-to-Everything (V2X) communication\ntechnology. V2X standards, such as Dedicated Short-Range Communications (DSRC)\nand Cellular-V2X (C-V2X), which are passing their research phase before being\nmandated in the US, are supposed to serve as reliable circulatory systems for\nthe time-critical information in vehicular networks; however, they are still\nheavily suffering from scalability issues in real traffic scenarios. The\ntechnology-agnostic notion of Model-Based Communications (MBC) has been\nproposed in our previous works as a promising paradigm to address the\nscalability issue and its performance, while acquiring different modeling\nstrategies, has been vastly studied. In this work, the modeling capabilities of\na powerful non-parametric Bayesian inference scheme, i.e., Gaussian Processes\n(GPs), is investigated within the MBC context with more details. Our\nobservations reveal an important potential strength of GP-based MBC scheme,\ni.e., its capability of accurately modeling different driving behavioral\npatterns by utilizing only a limited size GP kernel bank. This interesting\naspect of integrating GP inference with MBC framework, which has been verified\nin this work using realistic driving data sets, introduces this architecture as\na strong and appealing candidate to address the scalability challenge. The\nresults confirm that our proposed approach over-performs the state of the art\nresearch in terms of the required communication rate and GP kernel bank size.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 21:56:20 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Mahjoub", "Hossein Nourkhiz", ""], ["Raftari", "Arash", ""], ["Valiente", "Rodolfo", ""], ["Fallah", "Yaser P.", ""], ["Mahmud", "Syed K.", ""]]}, {"id": "2003.13991", "submitter": "Sachin Goyal", "authors": "Pranav Sankhe, Saqib Azim, Sachin Goyal, Tanya Choudhary, Kumar\n  Appaiah, Sukumar Srikant", "title": "Indoor Distance Estimation using LSTMs over WLAN Network", "comments": "Published in IEEE 16th Workshop on Positioning, Navigation and\n  Communications (WPNC 2019, Germany)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Global Navigation Satellite Systems (GNSS) like GPS suffer from accuracy\ndegradation and are almost unavailable in indoor environments. Indoor\npositioning systems (IPS) based on WiFi signals have been gaining popularity.\nHowever, owing to the strong spatial and temporal variations of wireless\ncommunication channels in the indoor environment, the achieved accuracy of\nexisting IPS is around several tens of centimeters. We present the detailed\ndesign and implementation of a self-adaptive WiFi-based indoor distance\nestimation system using LSTMs. The system is novel in its method of estimating\nwith high accuracy the distance of an object by overcoming possible causes of\nchannel variations and is self-adaptive to the changing environmental and\nsurrounding conditions. The proposed design has been developed and physically\nrealized over a WiFi network consisting of ESP8266 (NodeMCU) devices. The\nexperiment were conducted in a real indoor environment while changing the\nsurroundings in order to establish the adaptability of the system. We introduce\nand compare different architectures for this task based on LSTMs, CNNs, and\nfully connected networks (FCNs). We show that the LSTM based model performs\nbetter among all the above-mentioned architectures by achieving an accuracy of\n5.85 cm with a confidence interval of 93% on the scale of (4.14 m * 2.86 m). To\nthe best of our knowledge, the proposed method outperforms other methods\nreported in the literature by a significant margin.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 07:13:05 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Sankhe", "Pranav", ""], ["Azim", "Saqib", ""], ["Goyal", "Sachin", ""], ["Choudhary", "Tanya", ""], ["Appaiah", "Kumar", ""], ["Srikant", "Sukumar", ""]]}, {"id": "2003.14100", "submitter": "Qiong Li", "authors": "Ya-Xing Wang, Qiong Li, Hao-Kun Mao, Qi Han, Fu-Rong Huang, Hong-Wei\n  Xu", "title": "Topological optimization of hybrid quantum key distribution networks", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing complexity of quantum key distribution (QKD) network\nstructures, aforehand topology design is of great significance to support a\nlarge-number of nodes over a large-spatial area. However, the exclusivity of\nquantum channels, the limitation of key generation capabilities, the variety of\nQKD protocols and the necessity of untrusted-relay selection, make the optimal\ntopology design a very complicated task. In this research, a hybrid QKD network\nis studied for the first time from the perspective of topology, by analyzing\nthe topological differences of various QKD protocols. In addition, to make full\nuse of hybrid networking, an analytical model for optimal topology calculation\nis proposed, to reach the goal of best secure communication service by\noptimizing the deployment of various QKD devices and the selection of\nuntrusted-relays under a given cost limit. Plentiful simulation results show\nthat hybrid networking and untrusted-relay selection can bring great\nperformance advantages, and then the universality and effectiveness of the\nproposed analytical model are verified.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 11:15:15 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 01:02:28 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Wang", "Ya-Xing", ""], ["Li", "Qiong", ""], ["Mao", "Hao-Kun", ""], ["Han", "Qi", ""], ["Huang", "Fu-Rong", ""], ["Xu", "Hong-Wei", ""]]}, {"id": "2003.14329", "submitter": "He Chen", "authors": "Zixiao Han, Jiaxin Liang, Yifan Gu, He Chen", "title": "Software-Defined Radio Implementation of Age-of-Information-Oriented\n  Random Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more emerging Internet of Things (IoT) applications involve status\nupdates, where various IoT devices monitor certain physical processes and\nreport their latest statuses to the relevant information fusion nodes. A new\nperformance measure, termed the age of information (AoI), has recently been\nproposed to quantify the information freshness in time-critical IoT\napplications. Due to a large number of devices in future IoT networks, the\ndecentralized channel access protocols (e.g. random access) are preferable\nthanks to their low network overhead. Built on the AoI concept, some recent\nefforts have developed several AoI-oriented ALOHA-like random access protocols\nfor boosting the network-wide information freshness. However, all relevant\nworks focused on theoretical designs and analysis. The development and\nimplementation of a working prototype to evaluate and further improve these\nrandom access protocols in practice have been largely overlooked. Motivated as\nsuch, we build a software-defined radio (SDR) prototype for testing and\ncomparing the performance of recently proposed AoI-oriented random access\nprotocols. To this end, we implement a time-slotted wireless system by devising\na simple yet effective over-the-air time synchronization scheme, in which\nbeacons that serve as reference timing packets are broadcast by an access point\nfrom time to time. For a complete working prototype, we also design the frame\nstructures of various packets exchanged within the system. Finally, we design a\nset of experiments, implement them on our prototype and test the considered\nalgorithms in an office environment.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:14:56 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Han", "Zixiao", ""], ["Liang", "Jiaxin", ""], ["Gu", "Yifan", ""], ["Chen", "He", ""]]}]