[{"id": "1906.00076", "submitter": "Tugba Erpek", "authors": "Yalin E. Sagduyu, Yi Shi, Tugba Erpek", "title": "IoT Network Security from the Perspective of Adversarial Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning finds rich applications in Internet of Things (IoT) networks\nsuch as information retrieval, traffic management, spectrum sensing, and signal\nauthentication. While there is a surge of interest to understand the security\nissues of machine learning, their implications have not been understood yet for\nwireless applications such as those in IoT systems that are susceptible to\nvarious attacks due the open and broadcast nature of wireless communications.\nTo support IoT systems with heterogeneous devices of different priorities, we\npresent new techniques built upon adversarial machine learning and apply them\nto three types of over-the-air (OTA) wireless attacks, namely jamming, spectrum\npoisoning, and priority violation attacks. By observing the spectrum, the\nadversary starts with an exploratory attack to infer the channel access\nalgorithm of an IoT transmitter by building a deep neural network classifier\nthat predicts the transmission outcomes. Based on these prediction results, the\nwireless attack continues to either jam data transmissions or manipulate\nsensing results over the air (by transmitting during the sensing phase) to fool\nthe transmitter into making wrong transmit decisions in the test phase\n(corresponding to an evasion attack). When the IoT transmitter collects sensing\nresults as training data to retrain its channel access algorithm, the adversary\nlaunches a causative attack to manipulate the input data to the transmitter\nover the air. We show that these attacks with different levels of energy\nconsumption and stealthiness lead to significant loss in throughput and success\nratio in wireless communications for IoT systems. Then we introduce a defense\nmechanism that systematically increases the uncertainty of the adversary at the\ninference stage and improves the performance. Results provide new insights on\nhow to attack and defend IoT networks using deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:54:54 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Sagduyu", "Yalin E.", ""], ["Shi", "Yi", ""], ["Erpek", "Tugba", ""]]}, {"id": "1906.00186", "submitter": "Yong Liu", "authors": "Yong Liu, Xuehan Chen, Lin X. Cai, Qingchun Chen, Ruoting Gong and\n  Dong Tang", "title": "On the Fairness Performance of NOMA-based Wireless Powered Communication\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The near-far problem causes severe throughput unfairness in wireless powered\ncommunication networks (WPCN). In this paper, we exploit non-orthogonal\nmultiple access (NOMA) technology and propose a fairness-aware NOMA-based\nscheduling scheme to mitigate the near-far effect and to enhance the max-min\nfairness. Specifically, we sort all users according to their channel conditions\nand divide them into two groups, the interference group with high channel gains\nand the noninterference group with low channel gains. The power station (PS)\nconcurrently transmits energy signals with the data transmissions of the users\nin the interference group. Thus, the users in the noninterference group can\nharvest more energy and achieve a higher throughput, while the users in the\ninterference group degrade their performance due to the interfering signals\nfrom the PS. We then apply order statistic theory to analyze the achievable\nrates of ordered users, based on which all users are appropriately grouped for\nNOMA transmission to achieve the max-min fairness of the system. Meanwhile, the\noptimal number of interfered users that determines the set of users in each\ngroup, is derived. Our simulation results validate the significant improvement\nof both network fairness and throughput via the fairness-aware NOMA-based\nscheduling scheme.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 08:57:51 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Liu", "Yong", ""], ["Chen", "Xuehan", ""], ["Cai", "Lin X.", ""], ["Chen", "Qingchun", ""], ["Gong", "Ruoting", ""], ["Tang", "Dong", ""]]}, {"id": "1906.00192", "submitter": "Sheng Zhou", "authors": "Xi Zheng, Sheng Zhou, Zhiyuan Jiang, Zhisheng Niu", "title": "Closed-Form Analysis of Non-Linear Age-of-Information in Status Updates\n  with an Energy Harvesting Transmitter", "comments": "Accepted by IEEE Transactions on Wireless Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely status updates are crucial to enabling applications in massive\nInternet of Things (IoT). This paper measures the data-freshness performance of\na status update system with an energy harvesting transmitter, considering the\nrandomness in information generation, transmission and energy harvesting. The\nperformance is evaluated by a non-linear function of age of information (AoI)\nthat is defined as the time elapsed since the generation of the most up-to-date\nstatus information at the receiver. The system is formulated as two queues with\nstatus packet generation and energy arrivals both assumed to be Poisson\nprocesses. With negligible service time, both First-Come-First-Served (FCFS)\nand Last-Come-First-Served (LCFS) disciplines for arbitrary buffer and battery\ncapacities are considered, and a method for calculating the average penalty\nwith non-linear penalty functions is proposed. The average AoI, the average\npenalty under exponential penalty function, and AoI's threshold violation\nprobability are obtained in closed form. When the service time is assumed to\nfollow exponential distribution, matrix geometric method is used to obtain the\naverage peak AoI. The results illustrate that under the FCFS discipline, the\nstatus update frequency needs to be carefully chosen according to the service\nrate and energy arrival rate in order to minimize the average penalty.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 09:32:29 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zheng", "Xi", ""], ["Zhou", "Sheng", ""], ["Jiang", "Zhiyuan", ""], ["Niu", "Zhisheng", ""]]}, {"id": "1906.00197", "submitter": "Stefano Forti", "authors": "Stefano Forti, Federica Paganelli, Antonio Brogi", "title": "Probabilistic QoS-aware Placement of VNF chains at the Edge", "comments": null, "journal-ref": "Theory and Practice of Logic Programming (2021)", "doi": "10.1017/S1471068421000016", "report-no": null, "categories": "cs.NI cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying IoT-enabled Virtual Network Function (VNF) chains to Cloud-Edge\ninfrastructures requires determining a placement for each VNF that satisfies\nall set deployment requirements as well as a software-defined routing of\ntraffic flows between consecutive functions that meets all set communication\nrequirements. In this article, we present a declarative solution, EdgeUsher, to\nthe problem of how to best place VNF chains to Cloud-Edge infrastructures.\nEdgeUsher can determine all eligible placements for a set of VNF chains to a\nCloud-Edge infrastructure so to satisfy all of their hardware, IoT, security,\nbandwidth, and latency requirements. It exploits probability distributions to\nmodel the dynamic variations in the available Cloud-Edge infrastructure, and to\nassess output eligible placements against those variations.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 10:08:01 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 17:10:48 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 13:15:15 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Forti", "Stefano", ""], ["Paganelli", "Federica", ""], ["Brogi", "Antonio", ""]]}, {"id": "1906.00245", "submitter": "Hong-Ning Dai Prof.", "authors": "Hong-Ning Dai and Zibin Zheng and Yan Zhang", "title": "Blockchain for Internet of Things: A Survey", "comments": "19 pages, 9 figures", "journal-ref": "IEEE Internet of Things Journal, Vol. 6, No. 5, Oct. 2019", "doi": "10.1109/JIOT.2019.2920987", "report-no": null, "categories": "cs.NI cs.DC cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Internet of Things (IoT) is reshaping the incumbent industry to smart\nindustry featured with data-driven decision-making. However, intrinsic features\nof IoT result in a number of challenges such as decentralization, poor\ninteroperability, privacy and security vulnerabilities. Blockchain technology\nbrings the opportunities in addressing the challenges of IoT. In this paper, we\ninvestigate the integration of blockchain technology with IoT. We name such\nsynthesis of blockchain and IoT as Blockchain of Things (BCoT). This paper\npresents an in-depth survey of BCoT and discusses the insights of this new\nparadigm. In particular, we first briefly introduce IoT and discuss the\nchallenges of IoT. Then we give an overview of blockchain technology. We next\nconcentrate on introducing the convergence of blockchain and IoT and presenting\nthe proposal of BCoT architecture. We further discuss the issues about using\nblockchain for 5G beyond in IoT as well as industrial applications of BCoT.\nFinally, we outline the open research directions in this promising area.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 15:33:47 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 14:43:45 GMT"}, {"version": "v3", "created": "Sun, 1 Sep 2019 11:38:39 GMT"}, {"version": "v4", "created": "Thu, 6 Feb 2020 03:54:19 GMT"}, {"version": "v5", "created": "Fri, 7 Feb 2020 02:24:50 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Dai", "Hong-Ning", ""], ["Zheng", "Zibin", ""], ["Zhang", "Yan", ""]]}, {"id": "1906.00284", "submitter": "Ehsan Aryafar", "authors": "Ehsan Aryafar, Alireza Keshavarz-Haddad, Carlee Joe-Wong", "title": "Proportional Fair RAT Aggregation in HetNets", "comments": "Extended version of the 31st International Teletraffic Congress (ITC\n  2019) conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneity in wireless network architectures (i.e., the coexistence of 3G,\nLTE, 5G, WiFi, etc.) has become a key component of current and future\ngeneration cellular networks. Simultaneous aggregation of each client's traffic\nacross multiple such radio access technologies (RATs) / base stations (BSs) can\nsignificantly increase the system throughput, and has become an important\nfeature of cellular standards on multi-RAT integration. Distributed algorithms\nthat can realize the full potential of this aggregation are thus of great\nimportance to operators. In this paper, we study the problem of resource\nallocation for multi-RAT traffic aggregation in HetNets (heterogeneous\nnetworks). Our goal is to ensure that the resources at each BS are allocated so\nthat the aggregate throughput achieved by each client across its RATs satisfies\na proportional fairness (PF) criterion. In particular, we provide a simple\ndistributed algorithm for resource allocation at each BS that extends the PF\nallocation algorithm for a single BS. Despite its simplicity and lack of\ncoordination across the BSs, we show that our algorithm converges to the\ndesired PF solution and provide (tight) bounds on its convergence speed. We\nalso study the characteristics of the optimal solution and use its properties\nto prove the optimality of our algorithm's outcomes.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 20:22:14 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Aryafar", "Ehsan", ""], ["Keshavarz-Haddad", "Alireza", ""], ["Joe-Wong", "Carlee", ""]]}, {"id": "1906.00374", "submitter": "Abuthahir A", "authors": "Abuthahir Abuthahir, Nizar Malangadan, Gaurav Raina", "title": "Effect of two forms of feedback on the performance of the Rate Control\n  Protocol (RCP)", "comments": null, "journal-ref": null, "doi": "10.1016/j.cnsns.2020.105225", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rate Control Protocol (RCP) uses explicit feedback from routers to\ncontrol network congestion. RCP estimates it's fair rate from two forms of\nfeedback: rate mismatch and queue size. An important design question that\nremains open in RCP is whether the presence of queue size feedback is helpful,\ngiven the presence of feedback from rate mismatch. The feedback from routers to\nend-systems is time delayed, and may introduce instabilities and complex\nnon-linear dynamics. Delay dynamical systems are often modeled using delay\ndifferential equations to facilitate a mathematical analysis of their\nperformance and dynamics. The RCP models with and without queue size feedback\ngive rise to two distinct non-linear delay differential equations. Earlier work\non this design question was based on methods of linear systems theory. For\nfurther progress, it is quite natural to employ nonlinear techniques. In this\nstudy, we approach this design question using tools from control and\nbifurcation theory. The analytical results reveal that the removal of queue\nfeedback could enhance both stability and convergence properties. Further,\nusing Poincar\\'{e} normal forms and center manifold theory, we investigate two\nnonlinear properties, namely, the type of Hopf bifurcation and the asymptotic\nstability of the bifurcating limit cycles. We show that the presence of queue\nfeedback in the RCP can lead to a sub-critical Hopf bifurcation, which would\ngive rise either to the onset of large amplitude limit cycles or to unstable\nlimit cycles. Whereas, in the absence of queue feedback, the Hopf bifurcation\nis always super-critical and the bifurcating limit cycles are stable. The\nanalysis is complemented with computations and some packet-level simulations as\nwell. In terms of design, our study suggests that the presence of both forms of\nfeedback may be detrimental to the performance of RCP.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 09:27:16 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Abuthahir", "Abuthahir", ""], ["Malangadan", "Nizar", ""], ["Raina", "Gaurav", ""]]}, {"id": "1906.00379", "submitter": "Aditya Mvs", "authors": "Aditya MVS, Harsh Pancholi, Priyanka P. and Gaurav S. Kasbekar", "title": "Beyond the VCG Mechanism: Truthful Reverse Auctions for Relay Selection\n  with High Data Rates, High Base Station Utility and Low Interference in D2D\n  Networks", "comments": "16 pages, 7 figures. Preliminary work published in Proc. of IEEE NCC\n  2017. Draft Submitted to IEEE TMC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Device-to-Device communication allows a cellular user (relay node) to relay\ndata between the base station (BS) and another cellular user (destination\nnode). We address the problem of designing reverse auctions to assign a relay\nnode to each destination node, when there are multiple potential relay nodes\nand multiple destination nodes, in the scenarios where the transmission powers\nof the relay nodes are: 1) fixed, 2) selected to achieve the data rates desired\nby destination nodes, and 3) selected so as to approximately maximize the BS's\nutility. We show that auctions based on the widely used Vickrey-Clarke-Groves\n(VCG) mechanism have several limitations in scenarios 1) and 2); also, in\nscenario 3), the VCG mechanism is not applicable. Hence, we propose novel\nreverse auctions for relay selection in each of the above three scenarios. We\nprove that all the proposed reverse auctions can be truthfully implemented as\nwell as satisfy the individual rationality property. Using numerical\ncomputations, we show that in scenarios 1) and 2), our proposed auctions\nsignificantly outperform the auctions based on the VCG mechanism in terms of\nthe data rates achieved by destination nodes, utility of the BS and/ or the\ninterference cost incurred to the BS.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 10:06:31 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["MVS", "Aditya", ""], ["Pancholi", "Harsh", ""], ["P.", "Priyanka", ""], ["Kasbekar", "Gaurav S.", ""]]}, {"id": "1906.00400", "submitter": "Jun Zhang", "authors": "Jun Zhang and Khaled B. Letaief", "title": "Mobile Edge Intelligence and Computing for the Internet of Vehicles", "comments": "18 pages, 6 figures, submitted to Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Vehicles (IoV) is an emerging paradigm, driven by recent\nadvancements in vehicular communications and networking. Advances in research\ncan now provide reliable communication links between vehicles, via\nvehicle-to-vehicle communications, and between vehicles and roadside\ninfrastructures, via vehicle-to-infrastructure communications. Meanwhile, the\ncapability and intelligence of vehicles are being rapidly enhanced, and this\nwill have the potential of supporting a plethora of new exciting applications,\nwhich will integrate fully autonomous vehicles, the Internet of Things (IoT),\nand the environment. These trends will bring about an era of intelligent IoV,\nwhich will heavily depend upon communications, computing, and data analytics\ntechnologies. To store and process the massive amount of data generated by\nintelligent IoV, onboard processing and Cloud computing will not be sufficient,\ndue to resource/power constraints and communication overhead/latency,\nrespectively. By deploying storage and computing resources at the wireless\nnetwork edge, e.g., radio access points, the edge information system (EIS),\nincluding edge caching, edge computing, and edge AI, will play a key role in\nthe future intelligent IoV. Such system will provide not only low-latency\ncontent delivery and computation services, but also localized data acquisition,\naggregation and processing. This article surveys the latest development in EIS\nfor intelligent IoV. Key design issues, methodologies and hardware platforms\nare introduced. In particular, typical use cases for intelligent vehicles are\nillustrated, including edge-assisted perception, mapping, and localization. In\naddition, various open research problems are identified.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 13:23:11 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zhang", "Jun", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "1906.00437", "submitter": "Seyed Amir Alavi", "authors": "Seyed Amir Alavi, Mehrnaz Javadipour, Kamyar Mehran", "title": "State Monitoring for Situational Awareness in Rural Microgrids Using the\n  IoT Infrastructure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an event-triggered estimation strategy and a data\ncollection architecture for situational awareness (SA) in microgrids. An\nestimation agent structure based on the event-triggered Kalman filter is\nproposed and implemented for state estimation layer of the SA using long range\nwide area network (LoRAWAN) protocol. A setup has been developed which can\nprovide enormous data collection capabilities from smart meters, in order to\nrealise an adequate SA level in microgrids. Thingsboard Internet of things\n(IoT) platform is used for the SA visualisation with a customised dashboard. It\nis shown by using the developed estimation strategy, an adequate level of SA\ncan be achieved with a minimum installation and communication cost to have an\naccurate average state estimation of the microgrid.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 16:26:56 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Alavi", "Seyed Amir", ""], ["Javadipour", "Mehrnaz", ""], ["Mehran", "Kamyar", ""]]}, {"id": "1906.00567", "submitter": "Aidin Ferdowsi", "authors": "Aidin Ferdowsi and Walid Saad", "title": "Generative Adversarial Networks for Distributed Intrusion Detection in\n  the Internet of Things", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reap the benefits of the Internet of Things (IoT), it is imperative to\nsecure the system against cyber attacks in order to enable mission critical and\nreal-time applications. To this end, intrusion detection systems (IDSs) have\nbeen widely used to detect anomalies caused by a cyber attacker in IoT systems.\nHowever, due to the large-scale nature of the IoT, an IDS must operate in a\ndistributed manner with minimum dependence on a central controller. Moreover,\nin many scenarios such as health and financial applications, the datasets are\nprivate and IoTDs may not intend to share such data. To this end, in this\npaper, a distributed generative adversarial network (GAN) is proposed to\nprovide a fully distributed IDS for the IoT so as to detect anomalous behavior\nwithout reliance on any centralized controller. In this architecture, every\nIoTD can monitor its own data as well as neighbor IoTDs to detect internal and\nexternal attacks. In addition, the proposed distributed IDS does not require\nsharing the datasets between the IoTDs, thus, it can be implemented in IoTs\nthat preserve the privacy of user data such as health monitoring systems or\nfinancial applications. It is shown analytically that the proposed distributed\nGAN has higher accuracy of detecting intrusion compared to a standalone IDS\nthat has access to only a single IoTD dataset. Simulation results show that,\nthe proposed distributed GAN-based IDS has up to 20% higher accuracy, 25%\nhigher precision, and 60% lower false positive rate compared to a standalone\nGAN-based IDS.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:32:46 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ferdowsi", "Aidin", ""], ["Saad", "Walid", ""]]}, {"id": "1906.00581", "submitter": "Pooja Vyavahare", "authors": "Pooja Vyavahare and D. Manjunath and Jayakrishnan Nair", "title": "Sponsored data with ISP competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the effect of sponsored data platforms when Internet service\nproviders (ISPs) compete for subscribers and content providers (CPs) compete\nfor a share of the bandwidth usage by the customers. Our analytical model is of\na full information, leader-follower game. ISPs lead and set prices for\nsponsorship. CPs then make the binary decision of sponsoring or not sponsoring\ntheir content on the ISPs. Lastly, based on both of these, users make a\ntwo-part decision of choosing the ISP to which they subscribe, and the amount\nof data to consume from each of the CPs through the chosen ISP. User\nconsumption is determined by a utility maximization framework, the sponsorship\ndecision is determined by a non-cooperative game between the CPs, and the ISPs\nset their prices to maximize their profit in response to the prices set by the\ncompeting ISP. We analyze the pricing dynamics of the prices set by the ISPs,\nthe sponsorship decisions that the CPs make and the market structure therein,\nand the surpluses of the ISPs, CPs, and users.\n  This is the first analysis of the effect sponsored data platforms in the\npresence of ISP competition. We show that inter-ISP competition does not\ninhibit ISPs from extracting a significant fraction of the CP surplus.\nMoreover, the ISPs often have an incentive to significantly skew the CP\nmarketplace in favor of the most profitable CP.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 05:27:28 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Vyavahare", "Pooja", ""], ["Manjunath", "D.", ""], ["Nair", "Jayakrishnan", ""]]}, {"id": "1906.00614", "submitter": "Lilian Besson", "authors": "Christophe Moy (IETR), Lilian Besson (IETR, SEQUEL)", "title": "Decentralized Spectrum Learning for IoT Wireless Networks Collision\n  Mitigation", "comments": null, "journal-ref": "ISIoT workshop, May 2019, Santorin, Greece", "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the principles and implementation results of\nreinforcement learning algorithms on IoT devices for radio collision mitigation\nin ISM unlicensed bands. Learning is here used to improve both the IoT network\ncapability to support a larger number of objects as well as the autonomy of IoT\ndevices. We first illustrate the efficiency of the proposed approach in a\nproof-of-concept based on USRP software radio platforms operating on real radio\nsignals. It shows how collisions with other RF signals present in the ISM band\nare diminished for a given IoT device. Then we describe the first\nimplementation of learning algorithms on LoRa devices operating in a real\nLoRaWAN network, that we named IoTligent. The proposed solution adds neither\nprocessing overhead so that it can be ran in the IoT devices, nor network\noverhead so that no change is required to LoRaWAN. Real life experiments have\nbeen done in a realistic LoRa network and they show that IoTligent device\nbattery life can be extended by a factor 2 in the scenarios we faced during our\nexperiment.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 07:50:29 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Moy", "Christophe", "", "IETR"], ["Besson", "Lilian", "", "IETR, SEQUEL"]]}, {"id": "1906.00679", "submitter": "Muhammad Usama", "authors": "Muhammad Usama, Junaid Qadir, Ala Al-Fuqaha, Mounir Hamdi", "title": "The Adversarial Machine Learning Conundrum: Can The Insecurity of ML\n  Become The Achilles' Heel of Cognitive Networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The holy grail of networking is to create \\textit{cognitive networks} that\norganize, manage, and drive themselves. Such a vision now seems attainable\nthanks in large part to the progress in the field of machine learning (ML),\nwhich has now already disrupted a number of industries and revolutionized\npractically all fields of research. But are the ML models foolproof and robust\nto security attacks to be in charge of managing the network? Unfortunately,\nmany modern ML models are easily misled by simple and easily-crafted\nadversarial perturbations, which does not bode well for the future of ML-based\ncognitive networks unless ML vulnerabilities for the cognitive networking\nenvironment are identified, addressed, and fixed. The purpose of this article\nis to highlight the problem of insecure ML and to sensitize the readers to the\ndanger of adversarial ML by showing how an easily-crafted adversarial ML\nexample can compromise the operations of the cognitive self-driving network. In\nthis paper, we demonstrate adversarial attacks on two simple yet representative\ncognitive networking applications (namely, intrusion detection and network\ntraffic classification). We also provide some guidelines to design secure ML\nmodels for cognitive networks that are robust to adversarial attacks on the ML\npipeline of cognitive networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 10:03:31 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""], ["Hamdi", "Mounir", ""]]}, {"id": "1906.00711", "submitter": "Suzhi Bi", "authors": "Suzhi Bi, Liang Huang, and Ying-Jun Angela Zhang", "title": "Joint Optimization of Service Caching Placement and Computation\n  Offloading in Mobile Edge Computing Systems", "comments": "The paper has been accepted for publication by IEEE Transactions on\n  Wireless Communications (April 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile edge computing (MEC) systems, edge service caching refers to\npre-storing the necessary programs for executing computation tasks at MEC\nservers. At resource-constrained edge servers, service caching placement is in\ngeneral a complicated problem that highly correlates to the offloading\ndecisions of computation tasks. In this paper, we consider a single edge server\nthat assists a mobile user (MU) in executing a sequence of computation tasks.\nIn particular, the MU can run its customized programs at the edge server, while\nthe server can selectively cache the previously generated programs for future\nservice reuse. To minimize the computation delay and energy consumption of the\nMU, we formulate a mixed integer non-linear programming (MINLP) that jointly\noptimizes the service caching placement, computation offloading, and system\nresource allocation. We first derive the closed-form expressions of the optimal\nresource allocation, and subsequently transform the MINLP into an equivalent\npure 0-1 integer linear programming (ILP). To further reduce the complexity in\nsolving the ILP, we exploit the underlying structures in optimal solutions, and\ndevise a reduced-complexity alternating minimization technique to update the\ncaching placement and offloading decision alternately. Simulations show that\nthe proposed techniques achieve substantial resource savings compared to other\nrepresentative benchmark methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 11:25:07 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 17:27:34 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 15:10:32 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Bi", "Suzhi", ""], ["Huang", "Liang", ""], ["Zhang", "Ying-Jun Angela", ""]]}, {"id": "1906.00740", "submitter": "Mathias Strufe", "authors": "Mathias Strufe, Michael Gundall, Hans D. Schotten, Christian Markwart,\n  Rakash S. Ganesan, Markus Aleksy", "title": "Design of a 5G Ready and Reliable Architecture for the Smart Factory of\n  the Future", "comments": "Submitted to 24. ITG Fachtagung Mobilkommunikation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing demands for highly individual products as well as for flexible\nproduction lines represent new challenges. To address these demands, future\nplants must be highly flexible and dynamically reconfigurable. Current systems\nare usually based on wired technologies for the connection of sensors,\nactuators, and controlling or monitoring devices that allow only very limited\ndynamics. New applications, such as the use of robots, drones, or\nreconfigurable production lines, require the exploitation of wireless\ncommunication technologies. However, current technologies are not able to meet\nthe high requirements in terms of latency, robustness, resilience and data\nrate. The introduction of the 5th generation (5G) cellular communication system\nwill meet these requirements for the first time. Besides the use of radio-based\nsolutions in new plants - so-called greenfield scenarios - deploying 5G also\nrepresents an efficient migration of existing plants - so-called brownfield\nscenarios - to Industry 4.0. In order to ensure that the challenging\nrequirements are indeed meet in practical deployments of the new 5G technology,\na tailor-made architecture is being developed within the Tactile Internet 4.0\n(TACNET 4.0) project. As a basis for the design of the architecture,\nrepresentative Industry 4.0 application scenarios, which are also be considered\nby the 3rd Generation Partnership Project (3GPP), were analyzed and compliance\nwith the latest developments in the relevant standardization is also our\ntarget. The paper gives an overview of the considered use cases as well as the\nrelevant reference architectures and the design process of the TACNET 4.0\narchitecture.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 15:01:33 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Strufe", "Mathias", ""], ["Gundall", "Michael", ""], ["Schotten", "Hans D.", ""], ["Markwart", "Christian", ""], ["Ganesan", "Rakash S.", ""], ["Aleksy", "Markus", ""]]}, {"id": "1906.00741", "submitter": "Shuping Dang", "authors": "Shuping Dang, Osama Amin, Basem Shihada, Mohamed-Slim Alouini", "title": "What should 6G be?", "comments": null, "journal-ref": "Nature Electronics, 2020", "doi": "10.1038/s41928-019-0355-6", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standardization of fifth generation (5G) communications has been\ncompleted, and the 5G network should be commercially launched in 2020. As a\nresult, the visioning and planning of sixth generation (6G) communications has\nbegun, with an aim to provide communication services for the future demands of\nthe 2030s. Here we provide a vision for 6G that could serve a research guide in\nthe post-5G era. We suggest that human-centric mobile communications will still\nbe the most important application of 6G and the 6G network should be human\ncentric. Thus, high security, secrecy, and privacy should be key features of 6G\nand should be given particular attention by the wireless research community. To\nsupport this vision, we provide a systematic framework in which potential\napplication scenarios of 6G are anticipated and subdivided. We subsequently\ndefine key potential features of 6G and discuss the required communication\ntechnologies. We also explore the issues beyond communication technologies that\ncould hamper research and deployment of 6G.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 12:37:55 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 15:46:19 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 05:31:17 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Dang", "Shuping", ""], ["Amin", "Osama", ""], ["Shihada", "Basem", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1906.00743", "submitter": "Nof Abuzainab", "authors": "Nof Abuzainab, Walid Saad and Allen B. MacKenzie", "title": "Distributed Uplink Power Control in an Ultra-Dense Millimeter Wave\n  Network: A Mean-field Game Approach", "comments": "IEEE Wireless Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel mean-field game framework is proposed for uplink power\ncontrol in an ultra-dense millimeter wave network. The proposed mean-field game\nconsiders the time evolution of the mobile users' orientations as well as the\nenergy available in their batteries, under adaptive user association. The\nobjective of each mobile user is then to find the optimal transmission power\nthat maximizes its energy efficiency. The expression of the energy efficiency\nis analytically derived for the realistic case of a finite size network.\nSimulation results show that the proposed approach yields gains of up to 24%,\nin terms of energy efficiency, compared to a baseline in which the nodes\ntransmit according to the path loss compensating power control policy.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 01:35:09 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Abuzainab", "Nof", ""], ["Saad", "Walid", ""], ["MacKenzie", "Allen B.", ""]]}, {"id": "1906.00749", "submitter": "Carla Mouradian", "authors": "Seyedeh Negar Afrasiabi, Somayeh Kianpisheh, Carla Mouradian, Roch H.\n  Glitho, Ashok Moghe", "title": "Application Components Migration in NFV-based Hybrid Cloud/Fog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog computing extends the cloud to the edge of the network, close to the\nend-users enabling the deployment of some application component in the fog\nwhile others in the cloud. Network Functions Virtualization (NFV) decouples the\nnetwork functions from the underlying hardware. In NFV settings, application\ncomponents can be implemented as sets of Virtual Network Functions (VNFs)\nchained in specific order representing VNF-Forwarding Graphs (VNF-FG). Many\nstudies have been carried out to map the VNF-FGs to cloud systems. However, in\nhybrid cloud/fog systems, an additional challenge arises. The mobility of fog\nnodes may cause high latency as the distance between the end-users and the\nnodes hosting the components increases. This may not be tolerable for some\napplications. In such cases, a prominent solution is to migrate application\ncomponents to a closer fog node. This paper focuses on application component\nmigration in NFV-based hybrid cloud/fog systems. The objective is to minimize\nthe aggregated makespan of the applications. The problem is modeled\nmathematically, and a heuristic is proposed to find the sub-optimal solution in\nan acceptable time. The heuristic aims at finding the optimal fog node in each\ntime-slot considering a pre-knowledge of the mobility models of the fog nodes.\nThe experiment's results show that our proposed solution improves the makespan\nand the number of migrations compared to random migration and No-migration.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 18:07:26 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Afrasiabi", "Seyedeh Negar", ""], ["Kianpisheh", "Somayeh", ""], ["Mouradian", "Carla", ""], ["Glitho", "Roch H.", ""], ["Moghe", "Ashok", ""]]}, {"id": "1906.00750", "submitter": "Elena Cipressi", "authors": "Elena Cipressi and Maria Luisa Merani", "title": "Effects of Packet Loss and Jitter on VoLTE Call Quality", "comments": "Paper accepted at CoNEXT 2018 Student Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work performs a preliminary, comparative analysis of the end-to-end\nquality guaranteed by Voice over LTE (VoLTE), examining several millions of\nVoLTE calls that employ two popular speech audio codecs, namely, Adaptive\nMulti-Rate (AMR) and Adaptive Multi-Rate WideBand (AMR-WB). To assess call\nquality, VQmon, an enhanced version of the standardized E-Model, is utilized.\nThe study reveals to what extent AMR-WB based calls are more robust against\nnetwork impairments than their narrowband counterparts; it further shows that\nthe dependence of call quality on the packet loss rate is approximately\nexponential when the AMR codec is used, whereas it is nearly linear for the\nAMR-WB codec.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 09:13:45 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cipressi", "Elena", ""], ["Merani", "Maria Luisa", ""]]}, {"id": "1906.00753", "submitter": "Usman Nazir", "authors": "Usman Nazir", "title": "Accurate Localization in Wireless Sensor Networks in the Presence of\n  Cross Technology Interference", "comments": null, "journal-ref": "26th International Conference on Neural Information Processing of\n  the Asia-Pacific Neural Network Society in Dec 2019", "doi": "10.1007/978-3-030-36802-9_36", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Localization of mobile nodes in a wireless sensor networks (WSNs) is an\nactive area of research. In this paper, we present a novel RSSI based\nlocalization algorithm for 802.15.4 (ZigBee) based WSNs. We propose and\nimplement a novel range based localization algorithm to minimize cross\ntechnology interference operating in the same band. The goal is to minimize the\nmean square error of the localization algorithm. Hardware implementation of the\nalgorithm is in agreement with ideal (no interference) simulation results where\nan accuracy of less than 0.5m has been achieved.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 18:50:50 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Nazir", "Usman", ""]]}, {"id": "1906.00759", "submitter": "Abu Sufian", "authors": "A. Sufian, A. Banerjee, P.Dutta", "title": "Fuzzy-Controlled Scheduling of Route-Request Packets (FSRR) in Mobile Ad\n  Hoc Networks", "comments": "6 pages, 4 figures", "journal-ref": "Indian Journal of Science and Technology, Vol 9(43), November 2016", "doi": "10.17485/ijst/2016/v9i43/104384", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ad hoc networks, the scheduling of route-request packets should be\ndifferent from that of message packets, because during transmission of message\npackets the location of the destination is known whereas in route discovery\nthis is not known in most of the cases. The router has to depend upon the last\nknown location, if any, of the destination to determine the center and radius\nof the circle that embeds all possible current position of the destination.\nRoute-request packets generated from the source are directed towards this\ncircle i.e., directional route discovery can be applied. Otherwise, when no\nearlier location of the destination is known the route-requested has to be\nbroadcast in the whole network consuming a significant amount of time than\ndirectional route discovery. The present article proposes fuzzy controlled\nscheduling of route-request packets in particular that greatly reduces the\naverage delay in route discovery in ad hoc networks.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 06:58:49 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Sufian", "A.", ""], ["Banerjee", "A.", ""], ["Dutta", "P.", ""]]}, {"id": "1906.00760", "submitter": "Abu Sufian", "authors": "A. Banerjee, P. Dutta, A. Sufian", "title": "Fuzzy Route Switching For Energy Preservation (FEP) in Ad Hoc Networks", "comments": "11 pages, 12 figures, 4 tables", "journal-ref": "Indian Journal of Science and Technology, Vol 9(43), November 2016", "doi": "10.17485/ijst/2016/v9i43/104383", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nodes in ad hoc networks have limited battery power. Hence they require an\nenergy-efficient technique to improve average network performance. Maintaining\nenergy-efficiency in ad hoc networks is really challenging because highest\nenergy efficiency is achieved if all the nodes are always switched off and\nenergy-efficiency will be minimum if all the nodes are fully operational i.e.\nalways turned-on. Energy preservation requires redirection of data packets\nthrough some other routes having good performance. This improves the data\npacket delivery ratio and the number of alive nodes decreasing the cost of\nmessages.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 06:23:35 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Banerjee", "A.", ""], ["Dutta", "P.", ""], ["Sufian", "A.", ""]]}, {"id": "1906.00767", "submitter": "Yue Xu", "authors": "Yue Xu and Wenjun Xu and Zhi Wang and Jiaru Lin and Shuguang Cui", "title": "Load Balancing for Ultra-Dense Networks: A Deep Reinforcement Learning\n  Based Approach", "comments": null, "journal-ref": "IEEE Internet of Things Journal, Volume: 6, Issue: 6, Dec. 2019", "doi": "10.1109/JIOT.2019.2935010", "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep reinforcement learning (DRL) based mobility\nload balancing (MLB) algorithm along with a two-layer architecture to solve the\nlarge-scale load balancing problem for ultra-dense networks (UDNs). Our\ncontribution is three-fold. First, this work proposes a two-layer architecture\nto solve the large-scale load balancing problem in a self-organized manner. The\nproposed architecture can alleviate the global traffic variations by\ndynamically grouping small cells into self-organized clusters according to\ntheir historical loads, and further adapt to local traffic variations through\nintra-cluster load balancing afterwards. Second, for the intra-cluster load\nbalancing, this paper proposes an off-policy DRL-based MLB algorithm to\nautonomously learn the optimal MLB policy under an asynchronous parallel\nlearning framework, without any prior knowledge assumed over the underlying UDN\nenvironments. Moreover, the algorithm enables joint exploration with multiple\nbehavior policies, such that the traditional MLB methods can be used to guide\nthe learning process thereby improving the learning efficiency and stability.\nThird, this work proposes an offline-evaluation based safeguard mechanism to\nensure that the online system can always operate with the optimal and\nwell-trained MLB policy, which not only stabilizes the online performance but\nalso enables the exploration beyond current policies to make full use of\nmachine learning in a safe way. Empirical results verify that the proposed\nframework outperforms the existing MLB methods in general UDN environments\nfeatured with irregular network topologies, coupled interferences, and random\nuser movements, in terms of the load balancing performance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:02:33 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 11:37:24 GMT"}, {"version": "v3", "created": "Sat, 10 Aug 2019 04:47:37 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xu", "Yue", ""], ["Xu", "Wenjun", ""], ["Wang", "Zhi", ""], ["Lin", "Jiaru", ""], ["Cui", "Shuguang", ""]]}, {"id": "1906.00776", "submitter": "Weisen Shi", "authors": "Weisen Shi, Junling Li, Nan Cheng, Feng Lyu, Yanpeng Dai, Haibo Zhou,\n  Xuemin (Sherman) Shen", "title": "3D Multi-Drone-Cell Trajectory Design for Efficient IoT Data Collection", "comments": "Accepted by IEEE ICC'19", "journal-ref": "ICC 2019 - 2019 IEEE International Conference on Communications\n  (ICC)", "doi": "10.1109/ICC.2019.8761719", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drone cell (DC) is an emerging technique to offer flexible and cost-effective\nwireless connections to collect Internet-of-things (IoT) data in uncovered\nareas of terrestrial networks. The flying trajectory of DC significantly\nimpacts the data collection performance. However, designing the trajectory is a\nchallenging issue due to the complicated 3D mobility of DC, unique DC-to-ground\n(D2G) channel features, limited DC-to-BS (D2B) backhaul link quality, etc. In\nthis paper, we propose a 3D DC trajectory design for the DC-assisted IoT data\ncollection where multiple DCs periodically fly over IoT devices and relay the\nIoT data to the base stations (BSs). The trajectory design is formulated as a\nmixed integer non-linear programming (MINLP) problem to minimize the average\nuser-to-DC (U2D) pathloss, considering the state-of-the-art practical D2G\nchannel model. We decouple the MINLP problem into multiple quasi-convex or\ninteger linear programming (ILP) sub-problems, which optimizes the user\nassociation, user scheduling, horizontal trajectories and DC flying altitudes\nof DCs, respectively. Then, a 3D multi-DC trajectory design algorithm is\ndeveloped to solve the MINLP problem, in which the sub-problems are optimized\niteratively through the block coordinate descent (BCD) method. Compared with\nthe static DC deployment, the proposed trajectory design can lower the average\nU2D pathloss by 10-15 dB, and reduce the standard deviation of U2D pathloss by\n56%, which indicates the improvements in both link quality and user fairness.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:24:20 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Shi", "Weisen", "", "Sherman"], ["Li", "Junling", "", "Sherman"], ["Cheng", "Nan", "", "Sherman"], ["Lyu", "Feng", "", "Sherman"], ["Dai", "Yanpeng", "", "Sherman"], ["Zhou", "Haibo", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""]]}, {"id": "1906.00777", "submitter": "Weisen Shi", "authors": "Weisen Shi, Junlng Li, Nan Cheng, Feng Lyu, Shan Zhang, Haibo Zhou,\n  Xuemin Shen", "title": "Multi-Drone 3D Trajectory Planning and Scheduling in Drone Assisted\n  Radio Access Networks", "comments": "Published on IEEE TVT", "journal-ref": "IEEE Transactions on Vehicular Technology, vol. 68, no. 8, pp.\n  8145-8158, Aug. 2019", "doi": "10.1109/TVT.2019.2925629", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drone base station (DBS) is a promising technique to extend wireless\nconnections for uncovered users of terrestrial radio access networks (RAN). To\nimprove user fairness and network performance, in this paper, we design 3D\ntrajectories of multiple DBSs in the drone assisted radio access networks\n(DA-RAN) where DBSs fly over associated areas of interests (AoIs) and relay\ncommunications between the base station (BS) and users in AoIs. We formulate\nthe multi-DBS 3D trajectory planning and scheduling as a mixed integer\nnon-linear programming (MINLP) problem with the objective of minimizing the\naverage DBS-to-user (D2U) pathloss. The 3D trajectory variations in both\nhorizontal and vertical directions, as well as the state-of-the-art DBS-related\nchannel models are considered in the formulation. To address the non-convexity\nand NP-hardness of the MINLP problem, we first decouple it into multiple\ninteger linear programming (ILP) and quasi-convex sub-problems in which AoI\nassociation, D2U communication scheduling, horizontal trajectories and flying\nheights of DBSs are respectively optimized. Then, we design a multi-DBS 3D\ntrajectory planning and scheduling algorithm to solve the sub-problems\niteratively based on the block coordinate descent (BCD) method. A k-means-based\ninitial trajectory generation and a search-based start slot scheduling are\nconsidered in the proposed algorithm to improve trajectory design performance\nand ensure inter-DBS distance constraint, respectively. Extensive simulations\nare conducted to investigate the impacts of DBS quantity, horizontal speed and\ninitial trajectory on the trajectory planning results. Compared with the static\nDBS deployment, the proposed trajectory planning can achieve 10-15 dB reduction\non average D2U pathloss, and reduce the D2U pathloss standard deviation by 68%,\nwhich indicate the improvements of network performance and user fairness.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:15:44 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 21:55:09 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Shi", "Weisen", ""], ["Li", "Junlng", ""], ["Cheng", "Nan", ""], ["Lyu", "Feng", ""], ["Zhang", "Shan", ""], ["Zhou", "Haibo", ""], ["Shen", "Xuemin", ""]]}, {"id": "1906.00863", "submitter": "Mouhammd Alkasassbeh Dr.", "authors": "Abdelrahman Manna, Mouhammd Alkasassbeh", "title": "Detecting network anomalies using machine learning and SNMP-MIB dataset\n  with IP group", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SNMP-MIB is a widely used approach that uses machine learning to classify\ndata and obtain results, but using SNMP-MIB huge dataset is not efficient and\nit is also time and resources consuming. In this paper, a REP Tree,\nJ48(Decision Tree) and Random Forest classifiers were used to train a model\nthat can detect the anomalies and predict the network attacks that my affect\nthe Internet Protocol(IP) group. This trained model can be used in the devices\nthat are used to detect the anomalies such as intrusion detection systems.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:07:24 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Manna", "Abdelrahman", ""], ["Alkasassbeh", "Mouhammd", ""]]}, {"id": "1906.00864", "submitter": "Mouhammd Alkasassbeh Dr.", "authors": "Yousef Khaled Shaheen, Mohammad Al Kasassbeh", "title": "A Proactive Design to Detect Denial of Service Attacks Using SNMP-MIB\n  ICMP Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denial of Service (DOS) attack is one of the most attack that attract the\ncyber criminals which aims to reduce the network performance from doing its\nintended functions. Moreover, DOS Attacks can cause a huge damage on the data\nConfidentiality, Integrity and Availability. This paper introduced a system\nthat detects the network traffic and varies the DOS attacks from normal traffic\nbased on an adopted dataset. The results had shown that the adopted algorithms\nwith the ICMP variables achieved a high accuracy percentage with approximately\n99.6 in detecting ICMP Echo attack, HTTP Flood Attack, and Slowloris attack.\nMoreover, the designed model succeeded with a rate of 100 in varying normal\ntraffic from various DOS attacks.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 18:39:08 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Shaheen", "Yousef Khaled", ""], ["Kasassbeh", "Mohammad Al", ""]]}, {"id": "1906.00865", "submitter": "Mouhammd Alkasassbeh Dr.", "authors": "Ghazi Al-Naymatm, Ahmed Hambouz, Mouhammd Alkasassbeh", "title": "Network Attacks Anomaly Detection Using SNMP MIB Interface Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many approaches have evolved to enhance network attacks detection anomaly\nusing SNMP-MIBs. Most of these approaches focus on machine learning algorithms\nwith a lot of SNMP-MIB database parameters, which may consume most of hardware\nresources (CPU, memory, and bandwidth). In this paper we introduce an efficient\ndetection model to detect network attacks anomaly using Lazy.IBk as a machine\nlearning classifier and Correlation, and ReliefF as attribute evaluators on\nSNMP-MIB interface parameters. This model achieved accurate results (100%) with\nminimal hardware resources consumption. Thus, this model can be adopted in\nintrusion detection system (IDS) to increase its performance and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:58:00 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 19:43:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Al-Naymatm", "Ghazi", ""], ["Hambouz", "Ahmed", ""], ["Alkasassbeh", "Mouhammd", ""]]}, {"id": "1906.00939", "submitter": "Panagiotis Papapetrou", "authors": "Amin Azari, Panagiotis Papapetrou, Stojan Denic, and Gunnar Peters", "title": "Cellular Traffic Prediction and Classification: a comparative evaluation\n  of LSTM and ARIMA", "comments": "arXiv admin note: text overlap with arXiv:1906.00951", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of user traffic in cellular networks has attracted profound\nattention for improving resource utilization. In this paper, we study the\nproblem of network traffic traffic prediction and classification by employing\nstandard machine learning and statistical learning time series prediction\nmethods, including long short-term memory (LSTM) and autoregressive integrated\nmoving average (ARIMA), respectively. We present an extensive experimental\nevaluation of the designed tools over a real network traffic dataset. Within\nthis analysis, we explore the impact of different parameters to the\neffectiveness of the predictions. We further extend our analysis to the problem\nof network traffic classification and prediction of traffic bursts. The\nresults, on the one hand, demonstrate superior performance of LSTM over ARIMA\nin general, especially when the length of the training time series is high\nenough, and it is augmented by a wisely-selected set of features. On the other\nhand, the results shed light on the circumstances in which, ARIMA performs\nclose to the optimal with lower complexity.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:31:16 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Azari", "Amin", ""], ["Papapetrou", "Panagiotis", ""], ["Denic", "Stojan", ""], ["Peters", "Gunnar", ""]]}, {"id": "1906.00951", "submitter": "Amin Azari", "authors": "Amin Azari, Panagiotis Papapetrou, Stojan Denic, and Gunnar Peters", "title": "User Traffic Prediction for Proactive Resource Management:\n  Learning-Powered Approaches", "comments": "arXiv admin note: text overlap with arXiv:1906.00939", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic prediction plays a vital role in efficient planning and usage of\nnetwork resources in wireless networks. While traffic prediction in wired\nnetworks is an established field, there is a lack of research on the analysis\nof traffic in cellular networks, especially in a content-blind manner at the\nuser level. Here, we shed light into this problem by designing traffic\nprediction tools that employ either statistical, rule-based, or deep machine\nlearning methods. First, we present an extensive experimental evaluation of the\ndesigned tools over a real traffic dataset. Within this analysis, the impact of\ndifferent parameters, such as length of prediction, feature set used in\nanalyses, and granularity of data, on accuracy of prediction are investigated.\nSecond, regarding the coupling observed between behavior of traffic and its\ngenerating application, we extend our analysis to the blind classification of\napplications generating the traffic based on the statistics of traffic\narrival/departure. The results demonstrate presence of a threshold number of\nprevious observations, beyond which, deep machine learning can outperform\nlinear statistical learning, and before which, statistical learning outperforms\ndeep learning approaches. Further analysis of this threshold value represents a\nstrong coupling between this threshold, the length of future prediction, and\nthe feature set in use. Finally, through a case study, we present how the\nexperienced delay could be decreased by traffic arrival prediction.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 13:56:51 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Azari", "Amin", ""], ["Papapetrou", "Panagiotis", ""], ["Denic", "Stojan", ""], ["Peters", "Gunnar", ""]]}, {"id": "1906.01099", "submitter": "Michele Polese", "authors": "Michele Polese, Marco Giordani, Tommaso Zugno, Arnab Roy, Sanjay\n  Goyal, Douglas Castor, Michele Zorzi", "title": "Integrated Access and Backhaul in 5G mmWave Networks: Potentials and\n  Challenges", "comments": "Submitted to IEEE Communications Magazine, 7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated Access and Backhaul (IAB) is being investigated as a means to\novercome deployment costs of ultra-dense 5G millimeter wave (mmWave) networks\nby realizing wireless backhaul links to relay the access traffic. For the\ndevelopment of these systems, however, it is fundamental to validate the\nperformance of IAB in realistic scenarios through end-to-end system level\nsimulations. In this paper, we shed light on the most recent standardization\nactivities on IAB, and compare architectures with and without IAB in mmWave\ndeployments. While it is well understood that IAB networks reduce deployment\ncosts by obviating the need to provide wired backhaul to each cellular\nbase-station, in this paper we demonstrate the cell-edge throughput advantage\noffered by IAB using end-to-end system level simulations. We further highlight\nsome research challenges associated with this architecture that will require\nfurther investigations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:05:21 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Polese", "Michele", ""], ["Giordani", "Marco", ""], ["Zugno", "Tommaso", ""], ["Roy", "Arnab", ""], ["Goyal", "Sanjay", ""], ["Castor", "Douglas", ""], ["Zorzi", "Michele", ""]]}, {"id": "1906.01113", "submitter": "Francis Yan", "authors": "Francis Y. Yan, Hudson Ayers, Chenzhi Zhu, Sadjad Fouladi, James Hong,\n  Keyi Zhang, Philip Levis, Keith Winstein", "title": "Learning in situ: a randomized experiment in video streaming", "comments": null, "journal-ref": "USENIX NSDI (2020) 495-511", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the results of a randomized controlled trial of video-streaming\nalgorithms for bitrate selection and network prediction. Over the last eight\nmonths, we have streamed 14.2 years of video to 56,000 users across the\nInternet. Sessions are randomized in blinded fashion among algorithms, and\nclient telemetry is recorded for analysis.\n  We found that in this real-world setting, it is difficult for sophisticated\nor machine-learned control schemes to outperform a \"simple\" scheme\n(buffer-based control), notwithstanding good performance in network emulators\nor simulators. We performed a statistical analysis and found that the\nvariability and heavy-tailed nature of network and algorithm behavior create\nhurdles for robust learned algorithms in this area.\n  We developed an ABR algorithm that robustly outperforms other schemes in\npractice, by combining classical control with a learned network predictor,\ntrained with supervised learning in situ on data from the real deployment\nenvironment.\n  To support further investigation, we are publishing an archive of traces and\nresults each day, and will open our ongoing study to the community. We welcome\nother researchers to use this platform to develop and validate new algorithms\nfor bitrate selection, network prediction, and congestion control.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:45:44 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 21:25:56 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Yan", "Francis Y.", ""], ["Ayers", "Hudson", ""], ["Zhu", "Chenzhi", ""], ["Fouladi", "Sadjad", ""], ["Hong", "James", ""], ["Zhang", "Keyi", ""], ["Levis", "Philip", ""], ["Winstein", "Keith", ""]]}, {"id": "1906.01188", "submitter": "Hao Guo", "authors": "Hao Guo and Wanxin Li and Mark Nejad and Chien-Chung Shen", "title": "Access Control for Electronic Health Records with Hybrid Blockchain-Edge\n  Architecture", "comments": "Accepted to Proc. of the IEEE 2nd International Conference on\n  Blockchain (Blockchain-2019), Atlanta, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global Electronic Health Record (EHR) market is growing dramatically and\nexpected to reach $39.7 billions by 2022. To safe-guard security and privacy of\nEHR, access control is an essential mechanism for managing EHR data. This paper\nproposes a hybrid architecture to facilitate access control of EHR data by\nusing both blockchain and edge node. Within the architecture, a\nblockchain-based controller manages identity and access control policies and\nserves as a tamper-proof log of access events. In addition, off-chain edge\nnodes store the EHR data and apply policies specified in Abbreviated Language\nFor Authorization (ALFA) to enforce attribute-based access control on EHR data\nin collaboration with the blockchain-based access control logs. We evaluate the\nproposed hybrid architecture by utilizing Hyperledger Composer Fabric\nblockchain to measure the performance of executing smart contracts and ACL\npolicies in terms of transaction processing time and response time against\nunauthorized data retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 04:01:08 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Guo", "Hao", ""], ["Li", "Wanxin", ""], ["Nejad", "Mark", ""], ["Shen", "Chien-Chung", ""]]}, {"id": "1906.01276", "submitter": "AKM Bahalul Haque", "authors": "AKM Bahalul Haque, Sharaban Tahura Nisa, Md. Amdadul Bari, Ayvee\n  Nusreen Anika", "title": "Anonymity Network Tor and Performance Analysis of ARANEA; an IOT Based\n  Privacy-Preserving Router", "comments": "16 Pages, 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There was a time when the word security was only confined to the physical\nprotection of things that were valuable which must be guarded against all the\nodds. Today, in a world where people can do things virtually have emerged the\nnecessity to protect the virtual world. Every single facet of our life is being\ncontrolled by the internet one way or another. There is no privacy in the\ncyberspace as the data which we are browsing on the internet is being monitored\non the other side by someone. Each work we are doing on the internet is getting\ntracked or the data are getting leaked without consent. To browse the internet\nsecurely we developed a router named Aranea which relates to the browser Tor.\nTor gives traffic anonymity and security. The Tor browser can be used in both\npositive and negative purpose. Tor encrypts data, it hides the location and\nidentity of the user, it hides the IP address of the device, it hides the\nnetwork traffic and many more. By using Tor browser each user can browse the\ninternet safely in the cyber world. Our goal is to create an additional\nsecurity bridge through the router Aranea for every user so that each user can\nsimply browse the internet anonymously.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 08:52:38 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Haque", "AKM Bahalul", ""], ["Nisa", "Sharaban Tahura", ""], ["Bari", "Md. Amdadul", ""], ["Anika", "Ayvee Nusreen", ""]]}, {"id": "1906.01602", "submitter": "Sarabjot Singh", "authors": "Sarabjot Singh", "title": "On Provisioning Cellular Networks for Distributed Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless traffic attributable to machine learning (ML) inference workloads is\nincreasing with the proliferation of applications and smart wireless devices\nleveraging ML inference. Owing to limited compute capabilities at these \"edge\"\ndevices, achieving high inference accuracy often requires coordination with a\nremote compute node or \"cloud\" over the wireless cellular network. The accuracy\nof this distributed inference is, thus, impacted by the communication rate and\nreliability offered by the cellular network. In this paper, an analytical\nframework is proposed to characterize inference accuracy as a function of\ncellular network design. Using the developed framework, it is shown that\ncellular network should be provisioned with a minimum density of access points\n(APs) to guarantee a target inference accuracy, and the inference accuracy\nachievable at asymptotically high AP density is limited by the air-interface\nbandwidth. Furthermore, the minimum accuracy required of edge inference to\ndeliver a target inference accuracy is shown to be inversely proportional to\nthe density of APs and the bandwidth.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:31:13 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Singh", "Sarabjot", ""]]}, {"id": "1906.01799", "submitter": "Pooja Gupta", "authors": "P. Gupta, S. Kanhere, R. Jurdak", "title": "A Decentralized IoT Data Marketplace", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an architecture for dynamic decentralized marketplace for\ntrading of Internet of Things data. To this end, we introduce a 3-tier\nframework which consists of provider, consumer and broker. The framework is\nrealized using multiple trustless broker which matches and selects potential\ndata provider based on the consumers requirements. Rather than using a\ncentralized server to manage the contract between provider and consumer, the\nframework leverages smart contract-based agreement for automatically enforcing\nthe terms of the contract to the involved parties.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 03:13:32 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Gupta", "P.", ""], ["Kanhere", "S.", ""], ["Jurdak", "R.", ""]]}, {"id": "1906.01810", "submitter": "Wei Li", "authors": "Long Hu, Wei Li, Jun Yang, Giancarlo Fortino, and Min Chen", "title": "A Sustainable Multi-modal Multi-layer Emotion-aware Service at the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited by the computational capabilities and battery energy of terminal\ndevices and network bandwidth, emotion recognition tasks fail to achieve good\ninteractive experience for users. The intolerable latency for users also\nseriously restricts the popularization of emotion recognition applications in\nthe edge environments such as fatigue detection in auto-driving. The\ndevelopment of edge computing provides a more sustainable solution for this\nproblem. Based on edge computing, this article proposes a multi-modal\nmulti-layer emotion-aware service (MULTI-EASE) architecture that considers\nuser's facial expression and voice as a multi-modal data source of emotion\nrecognition, and employs the intelligent terminal, edge server and cloud as\nmulti-layer execution environment. By analyzing the average delay of each task\nand the average energy consumption at the mobile device, we formulate a\ndelay-constrained energy minimization problem and perform a task scheduling\npolicy between multiple layers to reduce the end-to-end delay and energy\nconsumption by using an edge-based approach, further to improve the users'\nemotion interactive experience and achieve energy saving in edge computing.\nFinally, a prototype system is also implemented to validate the architecture of\nMULTI-EASE, the experimental results show that MULTI-EASE is a sustainable and\nefficient platform for emotion analysis applications, and also provide a\nvaluable reference for dynamic task scheduling under MULTI-EASE architecture.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 03:35:28 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Hu", "Long", ""], ["Li", "Wei", ""], ["Yang", "Jun", ""], ["Fortino", "Giancarlo", ""], ["Chen", "Min", ""]]}, {"id": "1906.02043", "submitter": "Anubhavnidhi Abhashkumar", "authors": "Anubhavnidhi Abhashkumar, Aaron Gember-Jacobson, Aditya Akella", "title": "Tiramisu: Fast and General Network Verification", "comments": "14 pages + Appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's distributed network control planes support multiple routing\nprotocols, filtering mechanisms, and route selection policies. These protocols\noperate at different layers, e.g. BGP operates at the EGP layer, OSPF at the\nIGP layer, and VLANs at layer 2. The behavior of a network's control plane\ndepends on how these protocols interact with each other. This makes network\nconfigurations highly complex and error-prone. State-of-the-art control plane\nverifiers are either too slow, or do not model certain features of the network.\nIn this paper, we propose a new multilayer hedge graph abstraction, Tiramisu,\nthat supports fast verification of the control plane. Tiramisu uses a\ncombination of graph traversal algorithms and ILPs (Integer Linear Programs) to\ncheck different network policies. We use Tiramisu to verify policies of various\nreal-world and synthetic configurations. Our experiments show that Tiramisu can\nverify any policy in < 0.08 s in small networks (~35 devices) and < 0.12 s in\nlarge networks (~160 devices), and it is 10-600X faster than state-of-the-art\nwithout losing generality.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:18:11 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Abhashkumar", "Anubhavnidhi", ""], ["Gember-Jacobson", "Aaron", ""], ["Akella", "Aditya", ""]]}, {"id": "1906.02254", "submitter": "Maxime Meyer", "authors": "Maxime Meyer, Elizabeth A. Quaglia, Ben Smyth", "title": "An Overview of GSMA's M2M Remote Provisioning Specification", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  M2M devices are ubiquitous, and there is a growing tendency to connect such\ndevices to mobile networks. Network operators are investigating new solutions\nto lower their costs and to address usability issues. Embedded SIM cards with\nremote provisioning capability are one of the most promising solutions. GSMA,\nthe leading consortium on mobile network standards, has proposed a\nspecification for such an embedded SIM card, called eUICC. The specification\ndescribes eUICC architecture and a remote provisioning mechanism. Embodiments\nof this specification have the potential to disrupt the telecommunications\nmarket: eUICCs will be shipped to device manufacturers and then remotely\nprovisioned with a subscription, whereas (currently) SIMs must be provisioned\nprior to shipping. In this article, we present a comprehensive overview of\nGSMA's specification and its motivation. In particular, we describe the\ntechnology and the protocols involved in remote provisioning.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 19:03:37 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Meyer", "Maxime", ""], ["Quaglia", "Elizabeth A.", ""], ["Smyth", "Ben", ""]]}, {"id": "1906.02491", "submitter": "Mehdi Naderi Soorki", "authors": "Mehdi Naderi Soorki and Walid Saad and Mehdi Bennis", "title": "Optimized Deployment of Millimeter Wave Networks for In-venue Regions\n  with Stochastic Users' Orientation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter wave (mmW) communication is a promising solution for providing\nhigh-capacity wireless network access. However, the benefits of mmW are limited\nby the fact that the channel between a mmW access point and the user equipment\ncan stochastically change due to severe blockage of mmW links by obstacles such\nas the human body. Thus, one main challenge of mmW network coverage is to\nenable directional line-of-sight links between access points and mobile\ndevices. In this paper, a novel framework is proposed for optimizing mmW\nnetwork coverage within hotspots and in-venue regions, while being cognizant of\nthe body blockage of the network's users. In the studied model, the locations\nof potential access points and users are assumed as predefined parameters while\nthe orientation of the users is assumed to be stochastic. Hence, a joint\nstochastic access point placement and beam steering problem subjected to\nstochastic users' body blockage is formulated, under desired network coverage\nconstraints. Then, a greedy algorithm is introduced to find an approximation\nsolution for the joint deployment and assignment problem using a new `size\nconstrained weighted set cover' approach. A closed-form expression for the\nratio between the optimal solution and approximate one (resulting from the\ngreedy algorithm) is analytically derived. The proposed algorithm is simulated\nfor three in-venue regions: the meeting room in the Alumni Assembly Hall of\nVirginia Tech, an airport gate, and one side of a stadium football. Simulation\nresults show that, in order to guarantee network coverage for different\nin-venue regions, the greedy algorithm uses at most three more access points\n(APs) compared to the optimal solution. The results also show that, due to the\nuse of the additional APs, the greedy algorithm will yield a network coverage\nup to 11.7 % better than the optimal, AP-minimizing solution.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 09:17:47 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Soorki", "Mehdi Naderi", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1906.02524", "submitter": "Audrey Wilmet", "authors": "Audrey Wilmet, Tiphaine Viard, Matthieu Latapy, Robin Lamarche-Perrin", "title": "Degree-based Outlier Detection within IP Traffic Modelled as a Link\n  Stream", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at precisely detecting and identifying anomalous events in IP\ntraffic. To this end, we adopt the link stream formalism which properly\ncaptures temporal and structural features of the data. Within this framework,\nwe focus on finding anomalous behaviours with respect to the degree of IP\naddresses over time. Due to diversity in IP profiles, this feature is typically\ndistributed heterogeneously, preventing us to directly find anomalies. To deal\nwith this challenge, we design a method to detect outliers as well as precisely\nidentify their cause in a sequence of similar heterogeneous distributions. We\napply it to several MAWI captures of IP traffic and we show that it succeeds in\ndetecting relevant patterns in terms of anomalous network activity.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 11:25:57 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wilmet", "Audrey", ""], ["Viard", "Tiphaine", ""], ["Latapy", "Matthieu", ""], ["Lamarche-Perrin", "Robin", ""]]}, {"id": "1906.02562", "submitter": "Osama Haq", "authors": "Osama Haq (1), Cody Doucette (2), John W. Byers (2), and Fahad R.\n  Dogar (1) ((1) Tufts University, (2) Boston University)", "title": "Judicious QoS using Cloud Overlays", "comments": "Compared to the previous version, we have made a number of changes,\n  including new experiments on RIPE ATLAS testbed to evaluate the feasibility\n  of our services, discussion on end-to-end working of the system, and several\n  other changes in writing to clarify ambiguities in design or positioning of\n  the work. arXiv admin note: substantial text overlap with arXiv:1812.10835", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the long-standing problem of providing network QoS to\napplications, and propose the concept of judicious QoS -- combining the\ncheaper, best effort IP service with the cloud, which offers a highly reliable\ninfrastructure and the ability to add in-network services, albeit at higher\ncost. Our proposed J-QoS framework offers a range of reliability services with\ndifferent cost vs. delay trade-offs, including: i) a forwarding service that\nforwards packets over the cloud overlay, ii) a caching service, which stores\npackets inside the cloud and allows them to be pulled in case of packet loss or\ndisruption on the Internet, and iii) a novel coding service that provides the\nleast expensive packet recovery option by combining packets of multiple\napplication streams and sending a small number of coded packets across the more\nexpensive cloud paths. We demonstrate the feasibility of these services using\nmeasurements from RIPE Atlas and a live deployment on PlanetLab. We also\nconsider case studies on how J-QoS works with services up and down the network\nstack, including Skype video conferencing, TCP-based web transfers, and\ncellular access networks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:10:27 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 02:30:37 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 23:34:35 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Haq", "Osama", "", "Tufts University"], ["Doucette", "Cody", "", "Boston University"], ["Byers", "John W.", "", "Boston University"], ["Dogar", "Fahad R.", "", "Tufts University"]]}, {"id": "1906.02628", "submitter": "Wanxin Li", "authors": "Wanxin Li, Mark Nejad, Rui Zhang", "title": "A Blockchain-Based Architecture for Traffic Signal Control Systems", "comments": "This paper has been accepted at IEEE International Congress on\n  Internet of Things (IEEE ICIOT 2019), Milan, Italy", "journal-ref": null, "doi": "10.1109/ICIOT.2019.00018", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever-growing incorporation of connected vehicle (CV) technologies into\nintelligent traffic signal control systems bring about significant data\nsecurity issues in the connected vehicular networks. This paper presents a\nnovel decentralized and secure by design architecture for connected vehicle\ndata security, which is based on the emerging blockchain paradigm. In a\nsimulation study, we applied this architecture to defend the Intelligent\nTraffic Signal System (I-SIG), a USDOT approved CV pilot program, against\ncongestion attacks. The results show the performance of the proposed\narchitecture for the traffic signal control system.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:02:52 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 03:31:39 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 17:34:02 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Li", "Wanxin", ""], ["Nejad", "Mark", ""], ["Zhang", "Rui", ""]]}, {"id": "1906.02836", "submitter": "R.Stuart Geiger", "authors": "R. Stuart Geiger, Yoon Jung Jeong, Emily Manders", "title": "Black-boxing the user: internet protocol over xylophone players (IPoXP)", "comments": null, "journal-ref": "In CHI 2012 Extended Abstracts on Human Factors in Computing\n  Systems (CHI EA 2012, alt.chi). ACM, New York, NY, USA, p. 71-80. DOI:\n  https://doi.org/10.1145/2212776.2212785", "doi": "10.1145/2212776.2212785", "report-no": null, "categories": "cs.HC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce IP over Xylophone Players (IPoXP), a novel Internet protocol\nbetween two computers using xylophone-based Arduino interfaces. In our\nimplementation, human operators are situated within the lowest layer of the\nnetwork, transmitting data between computers by striking designated keys. We\ndiscuss how IPoXP inverts the traditional mode of human-computer interaction,\nwith a computer using the human as an interface to communicate with another\ncomputer.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 22:15:05 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Geiger", "R. Stuart", ""], ["Jeong", "Yoon Jung", ""], ["Manders", "Emily", ""]]}, {"id": "1906.02871", "submitter": "Mengyuan Lee", "authors": "Mengyuan Lee, Guanding Yu, and Geoffrey Ye Li", "title": "Graph Embedding based Wireless Link Scheduling with Few Training Samples", "comments": "accepted by IEEE Transactions on Wireless Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link scheduling in device-to-device (D2D) networks is usually formulated as a\nnon-convex combinatorial problem, which is generally NP-hard and difficult to\nget the optimal solution. Traditional methods to solve this problem are mainly\nbased on mathematical optimization techniques, where accurate channel state\ninformation (CSI), usually obtained through channel estimation and feedback, is\nneeded. To overcome the high computational complexity of the traditional\nmethods and eliminate the costly channel estimation stage, machine leaning (ML)\nhas been introduced recently to address the wireless link scheduling problems.\nIn this paper, we propose a novel graph embedding based method for link\nscheduling in D2D networks. We first construct a fully-connected directed graph\nfor the D2D network, where each D2D pair is a node while interference links\namong D2D pairs are the edges. Then we compute a low-dimensional feature vector\nfor each node in the graph. The graph embedding process is based on the\ndistances of both communication and interference links, therefore without\nrequiring the accurate CSI. By utilizing a multi-layer classifier, a scheduling\nstrategy can be learned in a supervised manner based on the graph embedding\nresults for each node. We also propose an unsupervised manner to train the\ngraph embedding based method to further reinforce the scalability and\ngeneralizability and develop a K-nearest neighbor graph representation method\nto reduce the computational complexity. Extensive simulation demonstrates that\nthe proposed method is near-optimal compared with the existing state-of-art\nmethods but is with only hundreds of training samples. It is also competitive\nin terms of scalability and generalizability to more complicated scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 02:40:14 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 12:25:34 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 22:51:27 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Lee", "Mengyuan", ""], ["Yu", "Guanding", ""], ["Li", "Geoffrey Ye", ""]]}, {"id": "1906.02998", "submitter": "Marco Zennaro", "authors": "Ermanno Pietrosemoli, Marco Rainone and Marco Zennaro", "title": "On Extending the Wireless Communications Range of Weather Stations using\n  LoRaWAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumer grade weather stations typically involve transmitting sensor\ninformation to a digital console that provides readouts of the data being\ncollected. The wireless range of such system is confined to about 100 m, making\ntheir use limited to urban environments. We present a device that decodes the\ndata being sent by the weather station and forwards them using the emerging\nLoRaWAN technology. We designed the device keeping in mind the peculiar\nconditions of Developing Countries, in particular the low cost and low power\nrequirements. This allows interesting applications in the realm of disaster\nprevention and mitigation using a network of numerous weather stations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 10:17:45 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Pietrosemoli", "Ermanno", ""], ["Rainone", "Marco", ""], ["Zennaro", "Marco", ""]]}, {"id": "1906.03093", "submitter": "Mohammed Salem", "authors": "Mohammed A. Salem, Ibrahim F. Tarrad, Mohamed I. Youssef, Sherine M.\n  Abd El-Kader", "title": "QoS Categories Activeness-Aware Adaptive EDCA Algorithm for Dense IoT\n  Networks", "comments": "17 pages, 10 figures", "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC) vol. 11, No. 3, May 2019, pp. 67-83", "doi": "10.5121/ijcnc.2019.11305", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IEEE 802.11 networks have a great role to play in supporting and deploying of\nthe Internet of Things (IoT). The realization of IoT depends on the ability of\nthe network to handle a massive number of stations and transmissions, and to\nsupport Quality of Service (QoS). IEEE 802.11 networks enable the QoS by\napplying the Enhanced Distributed Channel Access (EDCA) with static parameters\nregardless of existing network capacity or which Access Category (AC) of QoS is\nalready active. Our objective in this paper is to improve the efficiency of the\nuplink access in 802.11 networks; therefore we proposed an algorithm called QoS\nCategories Activeness-Aware Adaptive EDCA Algorithm (QCAAAE) which adapts\nContention Window (CW) size, and Arbitration Inter-Frame Space Number (AIFSN)\nvalues depending on the number of associated Stations (STAs) and considering\nthe presence of each AC. For different traffic scenarios, the simulation\nresults confirm the outperformance of the proposed algorithm in terms of\nthroughput (increased on average 23%) and retransmission attempts rate\n(decreased on average 47%) considering acceptable delay for sensitive delay\nservices.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 13:41:11 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Salem", "Mohammed A.", ""], ["Tarrad", "Ibrahim F.", ""], ["Youssef", "Mohamed I.", ""], ["El-Kader", "Sherine M. Abd", ""]]}, {"id": "1906.03101", "submitter": "Jorge L\\'opez", "authors": "Igor Burdonov and Alexandre Kossachev and Nina Yevtushenko and Jorge\n  L\\'opez and Natalia Kushik and Djamal Zeghlache", "title": "Preventive Model-based Verification and Repairing for SDN Requests", "comments": "submitted to ICTSS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software Defined Networking (SDN) is a novel network management technology,\nwhich currently attracts a lot of attention due to the provided capabilities.\nRecently, different works have been devoted to testing / verifying the\n(correct) configurations of SDN data planes. In general, SDN forwarding devices\n(e.g., switches) route (steer) traffic according to the configured flow rules;\nthe latter identifies the set of virtual paths implemented in the data plane.\nIn this paper, we propose a novel preventive approach for verifying that no\nmisconfigurations (e.g., infinite loops), can occur given the requested set of\npaths. We discuss why such verification is essential, namely, how, when\nsynthesizing a set of data paths, other not requested and undesired data paths\n(including loops) may be unintentionally configured. Furthermore, we show that\nfor some cases the requested set of paths cannot be implemented without adding\nsuch undesired behavior, i.e., only a superset of the requested set can be\nimplemented. Correspondingly, we present a verification technique for detecting\nsuch issues of potential misconfigurations and estimate the complexity of the\nproposed method; its polynomial complexity highlights the applicability of the\nobtained results. Finally, we propose a technique for debugging and repairing a\nset of paths in such a way that the corrected set does not induce undesired\npaths into the data plane, if the latter is possible.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 13:52:06 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 15:27:30 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 16:09:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Burdonov", "Igor", ""], ["Kossachev", "Alexandre", ""], ["Yevtushenko", "Nina", ""], ["L\u00f3pez", "Jorge", ""], ["Kushik", "Natalia", ""], ["Zeghlache", "Djamal", ""]]}, {"id": "1906.03144", "submitter": "Jorge L\\'opez", "authors": "Jos\\'e Reyes, Jorge L\\'opez, and Djamal Zeghlache", "title": "Identifying Operational Data-paths in Software Defined Networking Driven\n  Data-planes", "comments": "Submitted preprint under revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose an approach that relies on distributed traffic\ngeneration and monitoring to identify the operational data-paths in a given\nSoftware Defined Networking (SDN) driven data-plane. We show that under certain\nassumptions, there exist necessary and sufficient conditions for formally\nguaranteeing that all operational data-paths are discovered using our approach.\nIn order to provide reliable communication within the SDN driven data-planes,\nassuring that the implemented data-paths are the requested (and expected) ones\nis necessary. This requires discovering the actual operational (running)\ndata-paths in the data-plane. In SDN, different applications may configure\ndifferent coexisting data-paths, the resulting data-paths a specific network\nflow traverses may not be the intended ones. Furthermore, the SDN components\nmay be defected or compromised. We focus on discovering the operational\ndata-paths on SDN driven data-planes. However, the proposed approach is\napplicable to any data-plane where the operational data-paths must be verified\nand / or certified. A data-path discovery toolkit has been implemented. We\ndescribe the corresponding set of tools, and showcase the obtained experimental\nresults that reveal inconsistencies in well-known SDN applications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 15:00:57 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Reyes", "Jos\u00e9", ""], ["L\u00f3pez", "Jorge", ""], ["Zeghlache", "Djamal", ""]]}, {"id": "1906.03147", "submitter": "Furqan Khan", "authors": "Furqan Hameed Khan and Marius Portmann", "title": "Joint QoS-control and Handover Optimization in Backhaul aware SDN-based\n  LTE Networks", "comments": "33 pages, 11 Figures. M. Wireless Netw (2019)", "journal-ref": null, "doi": "10.1007/s11276-019-02021-7", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future cellular networks will be dense and require key traffic management\ntechnologies for fine-grained network control. The problem gets more\ncomplicated in the presence of different network segments with bottleneck links\nlimiting the desired quality of service (QoS) delivery to the last mile user.\nIn this work, we first design a framework for software-defined cellular\nnetworks (SDCN) and then propose new mechanisms for management of QoS and\nnon-QoS users traffic considering both access and backhaul networks, jointly.\nThe overall SDN-LTE system and related approaches are developed and tested\nusing network simulator (ns-3) in different network environments. Especially,\nwhen the users are non-uniformly distributed, the results shows that compared\nto other approaches, the proposed load distribution algorithm enables at least\n6\\% and 23\\% increase in the average QoS user downlink (DL) throughput for all\nnetwork users and 40\\%-ile edge users, respectively. Also, the proposed system\nefficiently achieves desired QoS and handles the network congestion without\nincurring significant overhead.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 15:04:37 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Khan", "Furqan Hameed", ""], ["Portmann", "Marius", ""]]}, {"id": "1906.03172", "submitter": "Vasileios Kotronis", "authors": "Ilias Sfirakis and Vasileios Kotronis", "title": "Validating IP Prefixes and AS-Paths with Blockchains", "comments": "draft report on BGP blockchain PoC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks (Autonomous Systems-AS) allocate or revoke IP prefixes with the\nintervention of official Internet resource number authorities, and select and\nadvertise policy-compliant paths towards these prefixes using the inter-domain\nrouting system and its primary enabler, the Border Gateway Protocol (BGP).\nSecuring BGP has been a long-term objective of several research and industrial\nefforts during the last decades, that have culminated in the Resource Public\nKey Infrastructure (RPKI) for the cryptographic verification of prefix-to-AS\nassignments. However, there is still no widely adopted solution for securing IP\nprefixes and the (AS-)paths leading to them; approaches such as BGPsec have\nseen minuscule deployment. In this work, we design and implement a\nBlockchain-based system that (i) can be used to validate both of these resource\ntypes, (ii) can work passively and does not require any changes in the\ninter-domain routing system (BGP, RPKI), and (iii) can be combined with\ncurrently available systems for the detection and mitigation of routing\nattacks. We present early results and insights w.r.t. scalability.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 15:38:54 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Sfirakis", "Ilias", ""], ["Kotronis", "Vasileios", ""]]}, {"id": "1906.03458", "submitter": "Dominik Baumann", "authors": "Dominik Baumann, Fabian Mager, Marco Zimmerling, Sebastian Trimpe", "title": "Control-guided Communication: Efficient Resource Arbitration and\n  Allocation in Multi-hop Wireless Control Systems", "comments": "Accepted final version to appear in: IEEE Control Systems Letters", "journal-ref": null, "doi": "10.1109/LCSYS.2019.2922188", "report-no": null, "categories": "cs.SY cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In future autonomous systems, wireless multi-hop communication is key to\nenable collaboration among distributed agents at low cost and high flexibility.\nWhen many agents need to transmit information over the same wireless network,\ncommunication becomes a shared and contested resource. Event-triggered and\nself-triggered control account for this by transmitting data only when needed,\nenabling significant energy savings. However, a solution that brings those\nbenefits to multi-hop networks and can reallocate freed up bandwidth to\nadditional agents or data sources is still missing. To fill this gap, we\npropose control-guided communication, a novel co-design approach for\ndistributed self-triggered control over wireless multi-hop networks. The\ncontrol system informs the communication system of its transmission demands\nahead of time, and the communication system allocates resources accordingly.\nExperiments on a cyber-physical testbed show that multiple cart-poles can be\nsynchronized over wireless, while serving other traffic when resources are\navailable, or saving energy. These experiments are the first to demonstrate and\nevaluate distributed self-triggered control over low-power multi-hop wireless\nnetworks at update rates of tens of milliseconds.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 14:00:23 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Baumann", "Dominik", ""], ["Mager", "Fabian", ""], ["Zimmerling", "Marco", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1906.03567", "submitter": "Thai T. Vu", "authors": "Thai T. Vu, Diep N. Nguyen, Dinh Thai Hoang, Eryk Dutkiewicz, Thuy V.\n  Nguyen", "title": "Optimal Energy Efficiency with Delay Constraints for Multi-layer\n  Cooperative Fog Computing Networks", "comments": "Final revision submitted to IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a joint offloading and resource allocation framework for a\nmulti-layer cooperative fog computing network, aiming to minimize the total\nenergy consumption of multiple mobile devices subject to their service delay\nrequirements. The resulting optimization involves both binary (offloading\ndecisions) and real variables (resource allocations), making it an NP-hard and\ncomputationally intractable problem. To tackle it, we first propose an improved\nbranch-and-bound algorithm (IBBA) that is implemented in a centralized manner.\nHowever, due to the large size of the cooperative fog computing network, the\ncomputational complexity of the proposed IBBA is relatively high. To speed up\nthe optimal solution searching as well as to enable its distributed\nimplementation, we then leverage the unique structure of the underlying problem\nand the parallel processing at fog nodes. To that end, we propose a distributed\nframework, namely feasibility finding Benders decomposition (FFBD), that\ndecomposes the original problem into a master problem for the offloading\ndecision and subproblems for resource allocation. The master problem (MP) is\nthen equipped with powerful cutting-planes to exploit the fact of resource\nlimitation at fog nodes. The subproblems (SP) for resource allocation can find\ntheir closed-form solutions using our fast solution detection method. These\n(simpler) subproblems can then be solved in parallel at fog nodes. The\nnumerical results show that the FFBD always returns the optimal solution of the\nproblem with significantly less computation time (e.g., compared with the\ncentralized IBBA approach). The FFBD with the fast solution detection method,\nnamely FFBD-F, can reduce up to $60\\%$ and $90\\%$ of computation time,\nrespectively, compared with those of the conventional FFBD, namely FFBD-S, and\nIBBA.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 05:06:26 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 03:32:25 GMT"}, {"version": "v3", "created": "Sun, 23 Aug 2020 14:24:51 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Vu", "Thai T.", ""], ["Nguyen", "Diep N.", ""], ["Hoang", "Dinh Thai", ""], ["Dutkiewicz", "Eryk", ""], ["Nguyen", "Thuy V.", ""]]}, {"id": "1906.03587", "submitter": "Akshay Mete", "authors": "Akshay Mete, D. Manjunath, Jayakrishnan Nair and Balakrishna Prabhu", "title": "Partial Server Pooling in Redundancy Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial sharing allows providers to possibly pool a fraction of their\nresources when full pooling is not beneficial to them. Recent work in systems\nwithout sharing has shown that redundancy can improve performance considerably.\nIn this paper, we combine partial sharing and redundancy by developing partial\nsharing models for providers operating multi-server systems with redundancy.\nTwo M/M/N queues with redundant service models are considered. Copies of an\narriving job are placed in the queues of servers that can serve the job.\nPartial sharing models for cancel-on-complete and cancel-on-start redundancy\nmodels are developed. For cancel-on-complete, it is shown that the Pareto\nefficient region is the full pooling configuration. For a cancel-on-start\npolicy, we conjecture that the Pareto frontier is always non-empty and is such\nthat at least one of the two providers is sharing all of its resources. For\nthis system, using bargaining theory the sharing configuration that the\nproviders may use is determined. Mean response time and probability of waiting\nare the performance metrics considered.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 07:50:59 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Mete", "Akshay", ""], ["Manjunath", "D.", ""], ["Nair", "Jayakrishnan", ""], ["Prabhu", "Balakrishna", ""]]}, {"id": "1906.03623", "submitter": "Seyed Amir Alavi", "authors": "Seyed Amir Alavi, Kamyar Mehran, Yang Hao, Ardavan Rahimian, Hamed\n  Mirsaeedi, Vahid Vahidinasab", "title": "A Distributed Event-Triggered Control Strategy for DC Microgrids Based\n  on Publish-Subscribe Model Over Industrial Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TSG.2018.2856893", "report-no": null, "categories": "eess.SP cs.DC cs.MA cs.NI cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a complete design, analysis, and performance evaluation\nof a novel distributed event-triggered control and estimation strategy for DC\nmicrogrids. The primary objective of this work is to efficiently stabilize the\ngrid voltage, and to further balance the energy level of the energy storage\n(ES) systems. The locally-installed distributed controllers are utilised to\nreduce the number of transmitted packets and battery usage of the installed\nsensors, based on a proposed event-triggered communication scheme. Also, to\nreduce the network traffic, an optimal observer is employed which utilizes a\nmodified Kalman consensus filter (KCF) to estimate the state of the DC\nmicrogrid via the distributed sensors. Furthermore, in order to effectively\nprovide an intelligent data exchange mechanism for the proposed event-triggered\ncontroller, the publish-subscribe communication model is employed to setup a\ndistributed control infrastructure in industrial wireless sensor networks\n(WSNs). The performance of the proposed control and estimation strategy is\nvalidated via the simulations of a DC microgrid composed of renewable energy\nsources (RESs). The results confirm the appropriateness of the implemented\nstrategy for the optimal utilization of the advanced industrial network\narchitectures in the smart grids.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 11:45:40 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Alavi", "Seyed Amir", ""], ["Mehran", "Kamyar", ""], ["Hao", "Yang", ""], ["Rahimian", "Ardavan", ""], ["Mirsaeedi", "Hamed", ""], ["Vahidinasab", "Vahid", ""]]}, {"id": "1906.04219", "submitter": "Mohammad S Khan", "authors": "Anirudh Paranjothi, Mohammad S. Khan, Sherali Zeadally, Ajinkya Pawar,\n  David Hicks", "title": "GSTR: Secure Multi-hop Message Dissemination in Connected Vehicles using\n  Social Trust Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of connected vehicles paradigm has made secure communication a\nkey concern amongst the connected vehicles. Communication between the vehicles\nand Road Side Units (RSUs) is critical to disseminate message among the\nvehicles. We focus on secure message transmission in connected vehicles using\nmulti_hop social networks environment to deliver the message with varying\ntrustworthiness. We proposed a Geographic Social Trust Routing (GSTR) approach;\nmessages are propagated using multiple hops and by considering the various\navailable users in the vehicular network. GSTR is proposed in an application\nperspective with an assumption that the users are socially connected. The users\nare selected based on trustworthiness as defined by social connectivity. The\nroute to send a message is calculated based on the highest trust level of each\nnode by using the nodes social network connections along the path in the\nnetwork. GSTR determines the shortest route using the trusted nodes along the\nroute for message dissemination. GSTR is made delay tolerant by introducing\nmessage storage in the cloud if a trustworthy node is unavailable to deliver\nthe message. We compared the proposed approach with Geographic and Traffic Load\nbased Routing (GTLR), Greedy Perimeter Stateless Routing (GPSR), Trust-based\nGPSR (T_GPSR). The performance results obtained show that GSTR ensures\nefficient resource utilization, lower packet losses at high vehicle densities.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 18:29:47 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Paranjothi", "Anirudh", ""], ["Khan", "Mohammad S.", ""], ["Zeadally", "Sherali", ""], ["Pawar", "Ajinkya", ""], ["Hicks", "David", ""]]}, {"id": "1906.04256", "submitter": "Ahmed Elzanaty Dr.", "authors": "Marco Chiani, Ahmed Elzanaty", "title": "On the LoRa Modulation for IoT: Waveform Properties and Spectral\n  Analysis", "comments": "8 pages, 5 figures, accepted for publication in IEEE Internet of\n  Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2019.2919151", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important modulation technique for Internet of Things (IoT) is the one\nproposed by the LoRa allianceTM. In this paper we analyze the M-ary LoRa\nmodulation in the time and frequency domains. First, we provide the signal\ndescription in the time domain, and show that LoRa is a memoryless continuous\nphase modulation. The cross-correlation between the transmitted waveforms is\ndetermined, proving that LoRa can be considered approximately an orthogonal\nmodulation only for large M. Then, we investigate the spectral characteristics\nof the signal modulated by random data, obtaining a closed-form expression of\nthe spectrum in terms of Fresnel functions. Quite surprisingly, we found that\nLoRa has both continuous and discrete spectra, with the discrete spectrum\ncontaining exactly a fraction 1/M of the total signal power.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 20:06:29 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Chiani", "Marco", ""], ["Elzanaty", "Ahmed", ""]]}, {"id": "1906.04293", "submitter": "Ryan Kim", "authors": "Shouvik Musavvir, Anwesha Chatterjee, Ryan Gary Kim, Dae Hyun Kim,\n  Partha Pratim Pande", "title": "Inter-Tier Process Variation-Aware Monolithic 3D NoC Architectures", "comments": "Submitted to IEEE TVLSI (Under Review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monolithic 3D (M3D) technology enables high density integration, performance,\nand energy-efficiency by sequentially stacking tiers on top of each other.\nM3D-based network-on-chip (NoC) architectures can exploit these benefits by\nadopting tier partitioning for intra-router stages. However, conventional\nfabrication methods are infeasible for M3D-enabled designs due to temperature\nrelated issues. This has necessitated lower temperature and\ntemperature-resilient techniques for M3D fabrication, leading to inferior\nperformance of transistors in the top tier and interconnects in the bottom\ntier. The resulting inter-tier process variation leads to performance\ndegradation of M3D-enabled NoCs. In this work, we demonstrate that without\nconsidering inter-tier process variation, an M3D-enabled NoC architecture\noverestimates the energy-delay-product (EDP) on average by 50.8% for a set of\nSPLASH-2 and PARSEC benchmarks. As a countermeasure, we adopt a process\nvariation aware design approach. The proposed design and optimization method\ndistribute the intra-router stages and inter-router links among the tiers to\nmitigate the adverse effects of process variation. Experimental results show\nthat the NoC architecture under consideration improves the EDP by 27.4% on\naverage across all benchmarks compared to the process-oblivious design.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 22:01:04 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Musavvir", "Shouvik", ""], ["Chatterjee", "Anwesha", ""], ["Kim", "Ryan Gary", ""], ["Kim", "Dae Hyun", ""], ["Pande", "Partha Pratim", ""]]}, {"id": "1906.04426", "submitter": "Andreas Guillot", "authors": "Andreas Guillot, Romain Fontugne, Philipp Winter, Pascal Merindol,\n  Alistair King, Alberto Dainotti, Cristel Pelsser", "title": "Chocolatine: Outage Detection for Internet Background Radiation", "comments": "TMA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet is a complex ecosystem composed of thousands of Autonomous\nSystems (ASs) operated by independent organizations; each AS having a very\nlimited view outside its own network. These complexities and limitations impede\nnetwork operators to finely pinpoint the causes of service degradation or\ndisruption when the problem lies outside of their network. In this paper, we\npresent Chocolatine, a solution to detect remote connectivity loss using\nInternet Background Radiation (IBR) through a simple and efficient method. IBR\nis unidirectional unsolicited Internet traffic, which is easily observed by\nmonitoring unused address space. IBR features two remarkable properties: it is\noriginated worldwide, across diverse ASs, and it is incessant. We show that the\nnumber of IP addresses observed from an AS or a geographical area follows a\nperiodic pattern. Then, using Seasonal ARIMA to statistically model IBR data,\nwe predict the number of IPs for the next time window. Significant deviations\nfrom these predictions indicate an outage. We evaluated Chocolatine using data\nfrom the UCSD Network Telescope, operated by CAIDA, with a set of documented\noutages. Our experiments show that the proposed methodology achieves a good\ntrade-off between true-positive rate (90%) and false-positive rate (2%) and\nlargely outperforms CAIDA's own IBR-based detection method. Furthermore,\nperforming a comparison against other methods, i.e., with BGP monitoring and\nactive probing, we observe that Chocolatine shares a large common set of\noutages with them in addition to many specific outages that would otherwise go\nundetected.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 08:04:39 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 08:54:36 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Guillot", "Andreas", ""], ["Fontugne", "Romain", ""], ["Winter", "Philipp", ""], ["Merindol", "Pascal", ""], ["King", "Alistair", ""], ["Dainotti", "Alberto", ""], ["Pelsser", "Cristel", ""]]}, {"id": "1906.04488", "submitter": "Nicolas Skatchkovsky", "authors": "Nicolas Skatchkovsky and Osvaldo Simeone", "title": "Optimizing Pipelined Computation and Communication for\n  Latency-Constrained Edge Learning", "comments": "to be published in IEEE Communication Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a device that is connected to an edge processor via a communication\nchannel. The device holds local data that is to be offloaded to the edge\nprocessor so as to train a machine learning model, e.g., for regression or\nclassification. Transmission of the data to the learning processor, as well as\ntraining based on Stochastic Gradient Descent (SGD), must be both completed\nwithin a time limit. Assuming that communication and computation can be\npipelined, this letter investigates the optimal choice for the packet payload\nsize, given the overhead of each data packet transmission and the ratio between\nthe computation and the communication rates. This amounts to a tradeoff between\nbias and variance, since communicating the entire data set first reduces the\nbias of the training process but it may not leave sufficient time for learning.\nAnalytical bounds on the expected optimality gap are derived so as to enable an\neffective optimization, which is validated in numerical results.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:38:09 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 09:52:46 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Skatchkovsky", "Nicolas", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "1906.04494", "submitter": "Rizwan Ahmed Khan", "authors": "Anjum Nazir, Rizwan Ahmed Khan", "title": "Combinatorial Optimization based Feature Selection Method: A study on\n  Network Intrusion Detection", "comments": "Data is ambiguous and multi-dimensional and it is not possible to\n  update this article at the moment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advancements in computer networks and communication technologies like\nsoftware defined networks (SDN), Internet of things (IoT), microservices\narchitecture, cloud computing and network function virtualization (NFV) have\nopened new fronts and challenges for security experts to combat against modern\ncyberattacks. Relying on perimeter defense and signature-based network security\nsolutions like Intrusion Detection and Prevention Systems (IDS/IPS) have failed\nto deliver adequate level of security against new attack vectors such as\nadvance persistent threats, zero days, ransomware, botnets and other forms of\ntargeted attacks. Recent developments in machine learning and cognitive\ncomputing have shown great potential to detect unknown and new intrusion events\nwhere legacy misuse and anomaly based intrusion detection systems usually fail.\nIn this research study we applied state of the art machine learning algorithms\non UNSW-NB15 dataset for potential applicability to detect new attacks. We also\nproposed a novel wrapper based feature selection technique TS-RF using\nmetaheuristic Tabu Search (TS) algorithm and Random Forest (RF) ensemble\nclassifier. Results obtained by applying proposed feature selection technique\ni.e. TS-RF on UNSW-NB15 dataset show improvement in overall intrusion detection\naccuracy while it reduces computation complexity as it removes more than 60%\nfeatures.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:53:49 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 06:24:25 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 11:26:24 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Nazir", "Anjum", ""], ["Khan", "Rizwan Ahmed", ""]]}, {"id": "1906.04702", "submitter": "Jonas Fritzsch", "authors": "Jonas Fritzsch, Justus Bogner, Stefan Wagner, Alfred Zimmermann", "title": "Microservices Migration in Industry: Intentions, Strategies, and\n  Challenges", "comments": "11 pages, 3 tables, 2019 IEEE International Conference on Software\n  Maintenance and Evolution (ICSME)", "journal-ref": null, "doi": "10.1109/ICSME.2019.00081", "report-no": null, "categories": "cs.SE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To remain competitive in a fast changing environment, many companies started\nto migrate their legacy applications towards a Microservices architecture. Such\nextensive migration processes require careful planning and consideration of\nimplications and challenges likewise. In this regard, hands-on experiences from\nindustry practice are still rare. To fill this gap in scientific literature, we\ncontribute a qualitative study on intentions, strategies, and challenges in the\ncontext of migrations to Microservices. We investigated the migration process\nof 14 systems across different domains and sizes by conducting 16 in-depth\ninterviews with software professionals from 10 companies. We present a separate\ndescription of each case and summarize the most important findings. As primary\nmigration drivers, maintainability and scalability were identified. Due to the\nhigh complexity of their legacy systems, most companies preferred a rewrite\nusing current technologies over splitting up existing code bases. This was\noften caused by the absence of a suitable decomposition approach. As such,\nfinding the right service cut was a major technical challenge, next to building\nthe necessary expertise with new technologies. Organizational challenges were\nespecially related to large, traditional companies that simultaneously\nestablished agile processes. Initiating a mindset change and ensuring smooth\ncollaboration between teams were crucial for them. Future research on the\nevolution of software systems will in particular profit from the individual\ncases presented.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:07:56 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 19:05:22 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Fritzsch", "Jonas", ""], ["Bogner", "Justus", ""], ["Wagner", "Stefan", ""], ["Zimmermann", "Alfred", ""]]}, {"id": "1906.04753", "submitter": "Debopam Bhattacherjee", "authors": "Debopam Bhattacherjee, Muhammad Tirmazi and Ankit Singla", "title": "Measuring and exploiting the cloud consolidation of the Web", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present measurements showing that the top one million most popular Web\ndomains are reachable within 13ms (in the median) from a collective of just 12\ncloud data centers. We explore the consequences of this Web \"consolidation\",\nfocusing on its potential for speeding up the evolution of the Web. That most\npopular services reside in or near a small number of data centers implies that\nnew application and transport technologies can be rapidly deployed for these\nWeb services, without the involvement of their operators. We show how this may\nbe achieved by orchestrating a handful of reverse proxies deployed in the same\ndata centers, with new technologies deployed at these proxies being nearly as\neffective as deploying them directly to the Web servers. We present early\nmeasurements of this approach, demonstrating a >50% reduction in Web page load\ntimes for users with high latencies to Web servers. We also show that this\nmodel, using a small number of proxies, can be surprisingly competitive with\nextensive CDN deployments, especially in geographies with high last-mile\nlatencies.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 18:02:09 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Bhattacherjee", "Debopam", ""], ["Tirmazi", "Muhammad", ""], ["Singla", "Ankit", ""]]}, {"id": "1906.04803", "submitter": "Arliones Stevert Hoeller Junior", "authors": "Arliones Hoeller-Jr., Richard Demo Souza, Hirley Alves, Onel L.\n  Alcaraz L\\'opez, Samuel Montejo-S\\'anchez, Marcelo Eduardo Pellenz", "title": "Optimum LoRaWAN Configuration Under Wi-SUN Interference", "comments": "11 pages, 6 figures, published on IEEE Access", "journal-ref": "IEEE Access, vol. 7, pp. 170936-170948, 2019", "doi": "10.1109/ACCESS.2019.2955750", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart Utility Networks (SUN) rely on the Wireless-SUN (Wi-SUN) specification\nfor years. Recently practitioners and researchers have considered Low-Power\nWide-Area Networks (LPWAN) like LoRaWAN for SUN applications. With distinct\ntechnologies deployed in the same area and sharing unlicensed bands, one can\nexpect these networks to interfere with one another. This paper builds over a\nLoRaWAN model to optimize network parameters while accounting for\ninter-technology interference. Our analytic model accounts for the interference\nLoRaWAN receives from IEEE 802.15.4g networks, which forms the bottom layers of\nWi-SUN systems. We derive closed-form equations for the expected reliability of\nLoRaWAN in such scenarios. We set the model parameters with data from real\nmeasurements of the interplay among the technologies. Finally, we propose two\noptimization algorithms to determine the best LoRaWAN configurations, given a\ntargeted minimum reliability level. The algorithms maximize either\ncommunication range or the number of users given constraints on the minimum\nnumber of users, minimum communication range, and minimum reliability. We\nvalidate the models and algorithms through numerical analysis and simulations.\nThe proposed methods are useful tools for planning interference-limited\nnetworks with requirements of minimum reliability.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 20:24:20 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 14:56:29 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Hoeller-Jr.", "Arliones", ""], ["Souza", "Richard Demo", ""], ["Alves", "Hirley", ""], ["L\u00f3pez", "Onel L. Alcaraz", ""], ["Montejo-S\u00e1nchez", "Samuel", ""], ["Pellenz", "Marcelo Eduardo", ""]]}, {"id": "1906.04966", "submitter": "Hasina Rahman", "authors": "Hasina Rahman, Zeenat Rehena, Nandini Mukherjee", "title": "Sink Mobility To Ensure Coverage in Multi-Partitioned Wireless Sensor\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on WSNs show that use of mobile sink can prolong network\nlifetime. This paper demonstrates the advantages of the mobile sink in WSNs for\nincreasing their lifetime than static sink. A novel sink mobility with coverage\nalgorithm has been proposed here. During the movement of the sinks in the\nnetwork, they sojourn at different points in the network and collect data over\nthere. The direction of the movement of the sinks is determined by the\nalgorithm and sinks are mobile inside the network. This algorithm can also be\nused for multiple sinks partitioned network. Simulations has been carried out\nfor both mobile and static sinks to determine the average energy consumption of\nthe network. At the same time, it also determines the network lifetime in terms\nof number of rounds neighbor nodes of sink is alive and first node die of the\nnetwork. Our experiments show that mobile sinks outperform static sink in all\nscenarios. Furthermore, the proposed algorithm results in a good balancing of\nenergy depletion among the sensor nodes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 06:47:26 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Rahman", "Hasina", ""], ["Rehena", "Zeenat", ""], ["Mukherjee", "Nandini", ""]]}, {"id": "1906.04998", "submitter": "S. Mohammad Hosseini", "authors": "S. Mohammad Hosseini, Amirhossein Jahangir", "title": "An Effective Payload Attribution Scheme for Cybercriminal Detection\n  Using Compressed Bitmap Index Tables and Traffic Downsampling", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics and Security, 13.4,\n  2018", "doi": "10.1109/TIFS.2017.2769018", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payload attribution systems (PAS) are one of the most important tools of\nnetwork forensics for detecting an offender after the occurrence of a\ncybercrime. A PAS stores the network traffic history in order to detect the\nsource and destination pair of a certain data stream in case a malicious\nactivity occurs on the network. The huge volume of information that is daily\ntransferred in the network means that the data stored by a PAS must be as\ncompact and concise as possible. Moreover, the investigation of this large\nvolume of data for a malicious data stream must be handled within a reasonable\ntime. For this purpose, several techniques based on storing a digest of traffic\nusing Bloom filters have been proposed in the literature. The false positive\nrate of existing techniques for detecting cybercriminals is unacceptably high,\ni.e., many source and destination pairs are falsely determined as malicious,\nmaking it difficult to detect the true criminal. In order to ameliorate this\nproblem, we have proposed a solution based on compressed bitmap index tables\nand traffic downsampling. Our analytical evaluation and experimental results\nshow that the proposed method significantly reduces the false positive rate.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 08:26:12 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Hosseini", "S. Mohammad", ""], ["Jahangir", "Amirhossein", ""]]}, {"id": "1906.05023", "submitter": "Shuo Wan", "authors": "Shuo Wan, Jiaxun Lu, Pingyi Fan and Khaled B. Letaief", "title": "Towards Big data processing in IoT: Path Planning and Resource\n  Management of UAV Base Stations in Mobile-Edge Computing System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heavy data load and wide cover range have always been crucial problems for\nonline data processing in internet of things (IoT). Recently, mobile-edge\ncomputing (MEC) and unmanned aerial vehicle base stations (UAV-BSs) have\nemerged as promising techniques in IoT. In this paper, we propose a three-layer\nonline data processing network based on MEC technique. On the bottom layer, raw\ndata are generated by widely distributed sensors, which reflects local\ninformation. Upon them, unmanned aerial vehicle base stations (UAV-BSs) are\ndeployed as moving MEC servers, which collect data and conduct initial steps of\ndata processing. On top of them, a center cloud receives processed results and\nconducts further evaluation. As this is an online data processing system, the\nedge nodes should stabilize delay to ensure data freshness. Furthermore,\nlimited onboard energy poses constraints to edge processing capability. To\nsmartly manage network resources for saving energy and stabilizing delay, we\ndevelop an online determination policy based on Lyapunov Optimization. In cases\nof low data rate, it tends to reduce edge processor frequency for saving\nenergy. In the presence of high data rate, it will smartly allocate bandwidth\nfor edge data offloading. Meanwhile, hovering UAV-BSs bring a large and\nflexible service coverage, which results in the problem of effective path\nplanning. In this paper, we apply deep reinforcement learning and develop an\nonline path planning algorithm. Taking observations of around environment as\ninput, a CNN network is trained to predict the reward of each action. By\nsimulations, we validate its effectiveness in enhancing service coverage. The\nresult will contribute to big data processing in future IoT.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:21:41 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Wan", "Shuo", ""], ["Lu", "Jiaxun", ""], ["Fan", "Pingyi", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "1906.05069", "submitter": "Huifeng Zhang", "authors": "Huifeng Zhang, Xirong Xu, Jing Guo, Yuansheng Yang", "title": "Fault-Tolerant Path-Embedding of Twisted Hypercube-Like Networks THLNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The twisted hypercube-like networks($THLNs$) contain several important\nhypercube variants. This paper is concerned with the fault-tolerant\npath-embedding of $n$-dimensional($n$-$D$) $THLNs$. Let $G_n$ be an $n$-$D$\n$THLN$ and $F$ be a subset of $V(G_n)\\cup E(G_n)$ with $|F|\\leq n-2$. We show\nthat for arbitrary two different correct vertices $u$ and $v$, there is a\nfaultless path $P_{uv}$ of every length $l$ with $2^{n-1}-1\\leq l\\leq\n2^n-f_v-1-\\alpha$, where $\\alpha=0$ if vertices $u$ and $v$ form a normal\nvertex-pair and $\\alpha=1$ if vertices $u$ and $v$ form a weak vertex-pair in\n$G_n-F$($n\\geq5$).\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 11:50:42 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Zhang", "Huifeng", ""], ["Xu", "Xirong", ""], ["Guo", "Jing", ""], ["Yang", "Yuansheng", ""]]}, {"id": "1906.05083", "submitter": "Davide Magrin", "authors": "Davide Magrin, Martina Capuzzo, Andrea Zanella", "title": "A Thorough Study of LoRaWAN Performance Under Different Parameter\n  Settings", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2019.2946487", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LoRaWAN is an emerging Low-Power Wide Area Network (LPWAN) technology, which\nis gaining momentum thanks to its flexibility and ease of deployment.\nConversely to other LPWAN solutions, LoRaWAN indeed permits the configuration\nof several network parameters that affect different network performance\nindexes, such as energy efficiency, fairness, and capacity, in principle making\nit possible to adapt the network behavior to the specific requirements of the\napplication scenario. Unfortunately, the complex and sometimes elusive\ninteractions among the different network components make it rather difficult to\npredict the actual effect of a certain parameters setting, so that flexibility\ncan turn into a stumbling block if not deeply understood. In this paper we shed\nlight on such complex interactions, by observing and explaining the effect of\ndifferent parameters settings in some illustrative scenarios. The\nsimulation-based analysis reveals various trade-offs and highlights some\ninefficiencies in the design of the LoRaWAN standard. Furthermore, we show how\nsignificant performance gains can be obtained by wisely setting the system\nparameters, possibly in combination with some novel network management\npolicies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 12:25:29 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Magrin", "Davide", ""], ["Capuzzo", "Martina", ""], ["Zanella", "Andrea", ""]]}, {"id": "1906.05103", "submitter": "Gewu Bu", "authors": "Bruno Baynat (SU, LIP6, NPA), Gewu Bu (SU, LIP6, NPA), Maria\n  Potop-Butucaru (SU, LIP6, NPA, LINCS)", "title": "Markovian model for Broadcast in Wireless Body Area Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless body area networks became recently a vast field of investigation. A\nlarge amount of research in this field is dedicated to the evaluation of\nvarious communication protocols, e.g., broadcast or convergecast, against human\nbody mobility. Most of the time this evaluation is done via simulations and in\nmany situations only synthetic data is used for the human body mobility. In\nthis paper we propose for the first time in Wireless Body Area Networks a\nMarkovian analytical model specifically designed for WBAN networks. The main\nobjective of the model is to evaluate the efficiency of a multi-hop\ntransmission in the case of a diffusion-based broadcast protocol, with respect\nto various performance parameters (e.g., cover probability, average cover\nnumber, hitting probability or average cover time). We validate our model by\ncomparing its results to simulation and show its accuracy. Finally, but not\nleast, we show how our model can be used to analytically evaluate the trade-off\nbetween transmission power and redundancy, when the same message is broadcasted\nseveral times in order to increase the broadcast reliability while maintaining\na low transmission power.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 12:58:01 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Baynat", "Bruno", "", "SU, LIP6, NPA"], ["Bu", "Gewu", "", "SU, LIP6, NPA"], ["Potop-Butucaru", "Maria", "", "SU, LIP6, NPA, LINCS"]]}, {"id": "1906.05277", "submitter": "Nguyen Thanh Van", "authors": "Nguyen Thanh Van, Tran Ngoc Thinh and Le Thanh Sach", "title": "A Combination of Temporal Sequence Learning and Data Description for\n  Anomaly-based NIDS", "comments": "12 pages, 2 figures, 4 tables, International Journal of Network\n  Security & Its Applications (IJNSA)", "journal-ref": null, "doi": "10.5121/ijnsa.2019.11307", "report-no": "Vol. 11, No.3", "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through continuous observation and modeling of normal behavior in networks,\nAnomaly-based Network Intrusion Detection System (A-NIDS) offers a way to find\npossible threats via deviation from the normal model. The analysis of network\ntraffic based on the time series model has the advantage of exploiting the\nrelationship between packages within network traffic and observing trends of\nbehaviors over a period of time. It will generate new sequences with good\nfeatures that support anomaly detection in network traffic and provide the\nability to detect new attacks. Besides, an anomaly detection technique, which\nfocuses on the normal data and aims to build a description of it, will be an\neffective technique for anomaly detection in imbalanced data. In this paper, we\npropose a combination model of Long Short Term Memory (LSTM) architecture for\nprocessing time series and a data description Support Vector Data Description\n(SVDD) for anomaly detection in A-NIDS to obtain the advantages of them. This\nmodel helps parameters in LSTM and SVDD are jointly trained with the joint\noptimization method. Our experimental results with KDD99 dataset show that the\nproposed combined model obtains high performance in intrusion detection,\nespecially DoS and Probe attacks with 98.0% and 99.8%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 08:05:34 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Van", "Nguyen Thanh", ""], ["Thinh", "Tran Ngoc", ""], ["Sach", "Le Thanh", ""]]}, {"id": "1906.05554", "submitter": "Fabian Mager", "authors": "Fabian Mager, Dominik Baumann, Romain Jacob, Lothar Thiele, Sebastian\n  Trimpe, Marco Zimmerling", "title": "Demo Abstract: Fast Feedback Control and Coordination with Mode Changes\n  for Wireless Cyber-Physical Systems", "comments": "Proceedings of the 18th International Conference on Information\n  Processing in Sensor Networks (IPSN'19), April 16--18, 2019, Montreal, QC,\n  Canada", "journal-ref": null, "doi": "10.1145/3302506.3312483", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This abstract describes the first public demonstration of feedback control\nand coordination of multiple physical systems over a dynamic multi-hop\nlow-power wireless network with update intervals of tens of milliseconds. Our\nrunning system can dynamically change between different sets of application\ntasks (e.g., sensing, actuation, control) executing on the spatially\ndistributed embedded devices, while closed-loop stability is provably\nguaranteed even across those so-called mode changes. Moreover, any subset of\nthe devices can move freely, which does not affect closed-loop stability and\ncontrol performance as long as the wireless network remains connected.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 09:04:51 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Mager", "Fabian", ""], ["Baumann", "Dominik", ""], ["Jacob", "Romain", ""], ["Thiele", "Lothar", ""], ["Trimpe", "Sebastian", ""], ["Zimmerling", "Marco", ""]]}, {"id": "1906.05694", "submitter": "Yusuke Koda", "authors": "Yusuke Koda, Koji Yamamoto, Takayuki Nishio, Masahiro Morikura", "title": "Cooperative Sensing in Deep RL-Based Image-to-Decision Proactive\n  Handover for mmWave Networks", "comments": "arXiv admin note: text overlap with arXiv:1904.04585", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For reliable millimeter-wave (mmWave) networks, this paper proposes\ncooperative sensing with multi-camera operation in an image-to-decision\nproactive handover framework that directly maps images to a handover decision.\nIn the framework, camera images are utilized to allow for the prediction of\nblockage effects in a mmWave link, whereby a network controller triggers a\nhandover in a proactive fashion. Furthermore, direct mapping allows for the\nscalability of the number of pedestrians. This paper experimentally\ninvestigates the feasibility of adopting cooperative sensing with multiple\ncameras that can compensate for one another's blind spots. The optimal mapping\nis learned via deep reinforcement learning to resolve the high dimensionality\nof images from multiple cameras. An evaluation based on experimentally obtained\nimages and received powers verifies that a mapping that enhances channel\ncapacity can be learned in a multi-camera operation. The results indicate that\nour proposed framework with multi-camera operation outperforms a conventional\nframework with single-camera operation in terms of the average capacity.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 12:08:11 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Koda", "Yusuke", ""], ["Yamamoto", "Koji", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""]]}, {"id": "1906.05793", "submitter": "Juan Afanador", "authors": "Juan Afanador, Maria Araujo, Murilo Baptista, Nir Oren", "title": "Extending Eigentrust with the Max-Plus Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eigentrust is a simple and widely used algorithm, which quantifies trust\nbased on the repeated application of an update matrix to a vector of initial\ntrust values. In some cases, however, this procedure is rendered uninformative.\nHere, we characterise such situations and trace their origin to the algebraic\nconditions guaranteeing the convergence of the Power Method. We overcome the\nidentified limitations by extending Eigentrust's core ideas into the Max-Plus\nAlgebra. The empirical evaluation of our max-plus approach demonstrates\nimprovements over Eigentrust.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:28:02 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Afanador", "Juan", ""], ["Araujo", "Maria", ""], ["Baptista", "Murilo", ""], ["Oren", "Nir", ""]]}, {"id": "1906.06153", "submitter": "Abuthahir A", "authors": "Abuthahir Abuthahir, Gaurav Raina and Thomas Voice", "title": "Do we need two forms of feedback in the Rate Control Protocol (RCP)?", "comments": "arXiv admin note: substantial text overlap with arXiv:1906.00374", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is considerable interest in the networking community in explicit\ncongestion control as it may allow the design of a fair, stable, low loss, low\ndelay, and high utilization network. The Rate Control Protocol (RCP) is an\nexample of such a congestion control protocol. The current design of RCP\nsuggests that it should employ two forms of feedback; i.e. rate mismatch and\nqueue size, in order to manage its flow control algorithms. An outstanding\ndesign question in RCP is whether the presence of queue size feedback is useful\nor not, given feedback based on rate mismatch. In this paper, we address this\nquestion using tools from control and bifurcation theory. We linearize the\nactual non-linear system and analyze the local asymptotic stability, robust\nstability and rate of convergence of both the design choices, i.e., with and\nwithout queue size feedback. But such analyses do not offer clear design\nrecommendations on whether the queue feedback is useful or not. This motivates\na bifurcation-theoretic analysis where we have to take non-linear terms into\nconsideration, which helps to learn additional dynamical properties of the RCP\nsystem. In particular, we proceed to analyze two non-linear properties, namely,\nthe type of Hopf bifurcation and the asymptotic stability of the bifurcating\nlimit cycles. Analytical results reveal that the presence of queue feedback in\nRCP can induce a sub-critical Hopf bifurcation, which can lead to undesirable\nsystem behavior. Whereas, in the absence of queue feedback, the Hopf\nbifurcation is always super-critical where the bifurcating limit cycles are\nstable and of small amplitude. The analysis is corroborated by numerical\ncomputations and some packet-level simulations as well. Based on our work, the\nsuggestion for RCP is to only include feedback based on rate mismatch in the\ndesign of the protocol.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 10:57:43 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Abuthahir", "Abuthahir", ""], ["Raina", "Gaurav", ""], ["Voice", "Thomas", ""]]}, {"id": "1906.06172", "submitter": "Congzhe Cao", "authors": "Congzhe Cao, Duanshun Li and Ivan Fair", "title": "Deep Learning-Based Decoding of Constrained Sequence Codes", "comments": "12 pages, 9 figures, accepted by IEEE Journal on Selected Areas in\n  Communications (JSAC) - Machine Learning in Wireless Communications. arXiv\n  admin note: substantial text overlap with arXiv:1809.01859", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained sequence (CS) codes, including fixed-length CS codes and\nvariable-length CS codes, have been widely used in modern wireless\ncommunication and data storage systems. Sequences encoded with constrained\nsequence codes satisfy constraints imposed by the physical channel to enable\nefficient and reliable transmission of coded symbols. In this paper, we propose\nusing deep learning approaches to decode fixed-length and variable-length CS\ncodes. Traditional encoding and decoding of fixed-length CS codes rely on\nlook-up tables (LUTs), which is prone to errors that occur during transmission.\nWe introduce fixed-length constrained sequence decoding based on multiple layer\nperception (MLP) networks and convolutional neural networks (CNNs), and\ndemonstrate that we are able to achieve low bit error rates that are close to\nmaximum a posteriori probability (MAP) decoding as well as improve the system\nthroughput. Further, implementation of capacity-achieving fixed-length codes,\nwhere the complexity is prohibitively high with LUT decoding, becomes practical\nwith deep learning-based decoding. We then consider CNN-aided decoding of\nvariable-length CS codes. Different from conventional decoding where the\nreceived sequence is processed bit-by-bit, we propose using CNNs to perform\none-shot batch-processing of variable-length CS codes such that an entire batch\nis decoded at once, which improves the system throughput. Moreover, since the\nCNNs can exploit global information with batch-processing instead of only\nmaking use of local information as in conventional bit-by-bit processing, the\nerror rates can be reduced. We present simulation results that show excellent\nperformance with both fixed-length and variable-length CS codes that are used\nin the frontiers of wireless communication systems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 04:32:57 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Cao", "Congzhe", ""], ["Li", "Duanshun", ""], ["Fair", "Ivan", ""]]}, {"id": "1906.06184", "submitter": "Christian Esteve Rothenberg", "authors": "Samira Afzal and Vanessa Testoni and Christian Esteve Rothenberg and\n  Prakash Kolan and Imed Bouazizi", "title": "A Holistic Survey of Wireless Multipath Video Streaming", "comments": "42 pages. 13 figures. 9 Tables. Accepted for publication in IEEE\n  Communications Surveys and Tutorials, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of today's mobile devices are equipped with multiple network interfaces\nand one of the main bandwidth-hungry applications that would benefit from\nmultipath communications is wireless video streaming. However, most of current\ntransport protocols do not match the requirements of video streaming\napplications or are not designed to address relevant issues, such as delay\nconstraints, networks heterogeneity, and head-of-line blocking issues. This\narticle provides a holistic survey of multipath wireless video streaming,\nshedding light on the different alternatives from an end-to-end layered stack\nperspective, unveiling trade-offs of each approach and presenting a suitable\ntaxonomy to classify the state-of-the-art. Finally, we discuss open issues and\navenues for future work.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 12:55:47 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Afzal", "Samira", ""], ["Testoni", "Vanessa", ""], ["Rothenberg", "Christian Esteve", ""], ["Kolan", "Prakash", ""], ["Bouazizi", "Imed", ""]]}, {"id": "1906.06319", "submitter": "Ekram Hossain", "authors": "Siming Wang, Xumin Huang, Rong Yu, Yan Zhang, and Ekram Hossain", "title": "Permissioned Blockchain for Efficient and Secure Resource Sharing in\n  Vehicular Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast expanding scale of vehicular networks, vehicular edge computing\n(VEC) has emerged and attracted growing attention from both industry and\nacademia. Parked vehicles (PVs) have great potential to join vehicular networks\nfor sharing their idle computing and networking resources. However, due to the\nunderlying security and privacy threats, it is challenging to fairly motivate\nPVs for resource sharing in an efficient and secure way. In this paper, we\npropose a permissioned vehicular blockchain for secure and efficient resource\nsharing in VEC, namely, Parkingchain. We first design smart contract to achieve\nsecure resource sharing and efficient service provisioning between PVs and\nservice requesters (SRs). A multi-weight subjective logic based delegated\nByzantine Fault Tolerance (DBFT) consensus mechanism is presented to improve\nthe consensus process in Parkingchain. Further, we design a contract\ntheory-based incentive mechanism to model the interactions between SR and PVs\nunder asymmetric information scenario. Finally, numerical results demonstrate\nthat the proposed incentive mechanism is effective and efficient compared with\nexisting schemes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 17:50:51 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Wang", "Siming", ""], ["Huang", "Xumin", ""], ["Yu", "Rong", ""], ["Zhang", "Yan", ""], ["Hossain", "Ekram", ""]]}, {"id": "1906.06350", "submitter": "Ekram Hossain", "authors": "Ahmed Refaey, Karim Hammad, Sebastian Magierowski, and Ekram Hossain", "title": "A Blockchain Policy and Charging Control Framework for Roaming in\n  Cellular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a technology foundation of cryptocurrencies, blockchain enables\ndecentralized peer-to-peer trading through consensus mechanisms without the\ninvolvement of a third party. Blockchain has been regarded as an auspicious\ntechnology for future cellular networks. It is able to provide solutions to\nproblems related to mobile operators and user trust, embedded smart contracts,\nsecurity concerns, pricing (e.g. for roaming), etc. When applying blockchain to\ncellular networks, there are significant challenges in terms of deployment and\napplication, due to resource-constrained transactions. This article begins by\nintroducing the basic concept of blockchain and then moves on to illustrate its\nbenefits and limitations in the roaming system. Two models of roaming-based\nblockchain technologies are offered to show their suitability for cellular\nnetworks as opposed to traditional technology. Finally, potential issues and\nchallenges of roaming-based blockchains are addressed and evaluated using the\nroaming use case in the EU.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 18:07:00 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Refaey", "Ahmed", ""], ["Hammad", "Karim", ""], ["Magierowski", "Sebastian", ""], ["Hossain", "Ekram", ""]]}, {"id": "1906.06357", "submitter": "Ekram Hossain", "authors": "Tao Zhang, Kun Zhu, and Ekram Hossain", "title": "Data-Driven Machine Learning Techniques for Self-healing in Cellular\n  Wireless Networks: Challenges and Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For enabling automatic deployment and management of cellular networks, the\nconcept of self-organizing network (SON) was introduced. SON capabilities can\nenhance network performance, improve service quality, and reduce operational\nand capital expenditure (OPEX/CAPEX). As an important component in SON,\nself-healing is defined as a network paradigm where the faults of target\nnetworks are mitigated or recovered by automatically triggering a series of\nactions such as detection, diagnosis and compensation. Data-driven machine\nlearning has been recognized as a powerful tool to bring intelligence into\nnetwork and to realize self-healing. However, there are major challenges for\npractical applications of machine learning techniques for self-healing. In this\narticle, we first classify these challenges into five categories: 1) data\nimbalance, 2) data insufficiency, 3) cost insensitivity, 4) non-real-time\nresponse, and 5) multi-source data fusion. Then we provide potential technical\nsolutions to address these challenges. Furthermore, a case study of\ncost-sensitive fault detection with imbalanced data is provided to illustrate\nthe feasibility and effectiveness of the suggested solutions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 18:16:21 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhang", "Tao", ""], ["Zhu", "Kun", ""], ["Hossain", "Ekram", ""]]}, {"id": "1906.06388", "submitter": "Ashkan Aghdai", "authors": "Ashkan Aghdai, Kang Xi, H. Jonathan Chao", "title": "Intelligent Anomaly Detection and Mitigation in Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data centers play a key role in today's Internet. Cloud applications are\nmainly hosted on multi-tenant warehouse-scale data centers. Anomalies pose a\nserious threat to data centers' operations. If not controlled properly, a\nsimple anomaly can spread throughout the data center, resulting in a cascading\nfailure. Amazon AWS had been affected by such incidents recently. Although some\nsolutions are proposed to detect anomalies and prevent cascading failures, they\nmainly rely on application-specific metrics and case-based diagnosis to detect\nthe anomalies. Given the variety of applications on a multi-tenant data center,\nproposed solutions are not capable of detecting anomalies in a timely manner.\nIn this paper we design an application-agnostic anomaly detection scheme. More\nspecifically, our design uses a highly distributed data mining scheme over\nnetwork-level traffic metrics to detect anomalies. Once anomalies are detected,\nsimple actions are taken to mitigate the damage. This ensures that errors are\nconfined and prevents cascading failures before administrators intervene.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 20:18:54 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Aghdai", "Ashkan", ""], ["Xi", "Kang", ""], ["Chao", "H. Jonathan", ""]]}, {"id": "1906.06433", "submitter": "Christopher Mendoza", "authors": "Christopher Mendoza, Venkat Dasari, Michael P. McGarry", "title": "Detecting Network Soft-failures with the Network Link Outlier Factor\n  (NLOF)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe and experimentally evaluate the performance of our\nNetwork Link Outlier Factor (NLOF) for detecting soft-failures in communication\nnetworks. The NLOF is computed using the throughput values derived from NetFlow\nrecords. The flow throughput values are clustered in two stages, outlier values\nare determined within each cluster, and the flow outliers are used to compute\nthe outlier factor or score for each network link. When sampling NetFlow\nrecords across the full span of a network, NLOF enables the detection of\nsoft-failures across the span of the network; large NLOF scores correlate well\nwith links experiencing failure.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 23:34:17 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Mendoza", "Christopher", ""], ["Dasari", "Venkat", ""], ["McGarry", "Michael P.", ""]]}, {"id": "1906.06471", "submitter": "M Anandaraj", "authors": "M. Anandaraj, K. Selvaraj, P. Ganeshkumar, K. Rajkumar, S. Sriram", "title": "Genetic Algorithm Based Resource Minimization in Network Code Based\n  Peer-to-Peer Network", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block scheduling is difficult to implement in P2P network since there is no\ncentral coordinator. This problem can be solved by employing network coding\ntechnique which allows intermediate nodes to perform the coding operation\ninstead of conventional store and forward the received data. There is a general\nassumption in this area of research so far that a target download rate is\nalways attainable at every peer as long as coding operation is performed at all\nthe nodes in the network. An interesting study is made that a maximum download\nrate can be attained by performing the coding operation at relatively small\nportion of the network. The problem of finding the minimal set of node to\nperform the coding operation and links to carry the coded data is called as a\nnetwork code minimization problem (NCMP). It is proved to be NP hard problem.\nIt can be solved using genetic algorithm (GA) because GA can be used to solve\nthe diverse NP hard problem. A new NCMP model is proposed which considers both\nminimize the resources needed to perform coding operation and dynamic change in\nnetwork topology due to disconnection. Based on this new NCMP model, an\neffective and novel GA is proposed by implementing problem specific GA\noperators into the evolutionary process. There is an attempt to implement the\ndifferent compositions and several options of GA elements which worked well in\nmany other problems and pick the one that works best for this resource\nminimization problem. Our simulation results prove that the proposed system\noutperforms the random selection and coding at all possible node mechanisms in\nterms of both download time and system throughput.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 04:58:11 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 05:45:15 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 05:03:39 GMT"}, {"version": "v4", "created": "Sat, 1 Aug 2020 16:26:44 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Anandaraj", "M.", ""], ["Selvaraj", "K.", ""], ["Ganeshkumar", "P.", ""], ["Rajkumar", "K.", ""], ["Sriram", "S.", ""]]}, {"id": "1906.06500", "submitter": "Donghui Ding", "authors": "Donghui Ding, Xin Jiang, Jiaping Wang, Hao Wang, Xiaobing Zhang, Yi\n  Sun", "title": "Txilm: Lossy Block Compression with Salted Short Hashing", "comments": "5 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current blockchains are restricted by the low throughput. Aimed at this\nproblem, we propose Txilm, a protocol that compresses the size of transaction\npresentation in each block to save the bandwidth of the network. In this\nprotocol, a block carries short hashes of TXIDs instead of complete\ntransactions. Combined with the sorted transactions based on TXIDs, Txilm\nrealizes 80 times of data size reduction compared with the original\nblockchains. We also evaluate the probability of hash collisions, and provide\nmethods of resolving such collisions. Finally, we design strategies to protect\nagainst potential attacks on Txilm.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 08:53:48 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Ding", "Donghui", ""], ["Jiang", "Xin", ""], ["Wang", "Jiaping", ""], ["Wang", "Hao", ""], ["Zhang", "Xiaobing", ""], ["Sun", "Yi", ""]]}, {"id": "1906.06517", "submitter": "Gautam Srivastava", "authors": "Ashutosh Dhar Dwivedi, Lukas Malina, Petr Dzurenda, Gautam Srivastava", "title": "Optimized Blockchain Model for Internet of Things based Healthcare\n  Applications", "comments": "5 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:1806.00555 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There continues to be a recent push to taking the cryptocurrency based ledger\nsystem known as Blockchain and applying its techniques to non-financial\napplications. One of the main areas for application remains Internet of Things\n(IoT) as we see many areas of improvement as we move into an age of smart\ncities. In this paper, we examine an initial look at applying the key aspects\nof Blockchain to a health application network where patients health data can be\nused to create alerts important to authenticated healthcare providers in a\nsecure and private manner. This paper also presents the benefits and also\npractical obstacles of the blockchain-based security approaches in IoT.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 10:16:50 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Dwivedi", "Ashutosh Dhar", ""], ["Malina", "Lukas", ""], ["Dzurenda", "Petr", ""], ["Srivastava", "Gautam", ""]]}, {"id": "1906.06591", "submitter": "Dinesh Dash", "authors": "Dinesh Dash", "title": "Plane Sweep Algorithms for Data Collection in Wireless Sensor Network\n  using Mobile Sink", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usage of mobile sink(s) for data gathering in wireless sensor networks(WSNs)\nimproves the performance of WSNs in many respects such as power consumption,\nlifetime, etc. In some applications, the mobile sink $MS$ travels along a\npredefined path to collect data from the nearby sensors, which are referred as\nsub-sinks. Due to the slow speed of the $MS$, the data delivery latency is\nhigh. However, optimizing the {\\em data gathering schedule}, i.e. optimizing\nthe transmission schedule of the sub-sinks to the $MS$ and the movement speed\nof the $MS$ can reduce data gathering latency. We formulate two novel\noptimization problems for data gathering in minimum time. The first problem\ndetermines an optimal data gathering schedule of the $MS$ by controlling the\ndata transmission schedule and the speed of the $MS$, where the data\navailabilities of the sub-sinks are given. The second problem generalizes the\nfirst, where the data availabilities of the sub-sinks are unknown. Plane sweep\nalgorithms are proposed for finding optimal data gathering schedule and data\navailabilities of the sub-sinks. The performances of the proposed algorithms\nare evaluated through simulations. The simulation results reveal that the\noptimal distribution of data among the sub-sinks together with optimal data\ngathering schedule improves the data gathering time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 17:15:39 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Dash", "Dinesh", ""]]}, {"id": "1906.06643", "submitter": "Xinghua Sun", "authors": "Xinghua Sun, Lin Dai", "title": "Throughput Analysis of CSMA: Technical Report", "comments": "21 pages, 5 figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, the throughput performance of CSMA networks with\ntwo representative receiver structures, i.e., the collision model and the\ncapture model, is characterized and optimized. The analysis is further applied\nto an IEEE 802.11 network, which is a representative wireless network that\nadopts the CSMA mechanism, where the optimal initial backoff window sizes of\nnodes to achieve the maximum network throughput are derived and verified\nagainst simulation results.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 03:59:37 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Sun", "Xinghua", ""], ["Dai", "Lin", ""]]}, {"id": "1906.06653", "submitter": "Shijun Zhao", "authors": "Qianying Zhang, Shijun Zhao", "title": "A Comprehensive Formal Security Analysis and Revision of the Two-phase\n  Key Exchange Primitive of TPM 2.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Trusted Platform Module (TPM) version 2.0 provides a two-phase key\nexchange primitive which can be used to implement three widely-standardized\nauthenticated key exchange protocols: the Full Unified Model, the Full MQV, and\nthe SM2 key exchange protocols. However, vulnerabilities have been found in all\nof these protocols. Fortunately, it seems that the protections offered by TPM\nchips can mitigate these vulnerabilities. In this paper, we present a security\nmodel which captures TPM's protections on keys and protocols' computation\nenvironments and in which multiple protocols can be analyzed in a unified way.\nBased on the unified security model, we give the first formal security analysis\nof the key exchange primitive of TPM 2.0, and the analysis results show that,\nwith the help of hardware protections of TPM chips, the key exchange primitive\nindeed satisfies the well-defined security property of our security model, but\nunfortunately under some impractical limiting conditions, which would prevent\nthe application of the key exchange primitive in real-world networks. To make\nTPM 2.0 applicable to real-world networks, we present a revision of the key\nexchange primitive of TPM 2.0, which can be secure without the limiting\nconditions. We give a rigorous analysis of our revision, and the results show\nthat our revision achieves not only the basic security property of modern AKE\nsecurity models but also some further security properties.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 06:27:09 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 12:03:04 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhang", "Qianying", ""], ["Zhao", "Shijun", ""]]}, {"id": "1906.06738", "submitter": "Martin Maier", "authors": "Martin Maier and Amin Ebrahimzadeh", "title": "Toward the Internet of No Things: The Role of O2O Communications and\n  Extended Reality", "comments": "8 pages, 4 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future fully interconnected virtual reality (VR) systems and the Tactile\nInternet diminish the boundary between virtual (online) and real (offline)\nworlds, while extending the digital and physical capabilities of humans via\nedge computing and teleoperated robots, respectively. In this paper, we focus\non the Internet of No Things as an extension of immersive VR from virtual to\nreal environments, where human-intended Internet services - either digital or\nphysical - appear when needed and disappear when not needed. We first introduce\nthe concept of integrated online-to-offline (O2O) communications, which treats\nonline and offline channels as complementary to bridge the virtual and physical\nworlds and provide O2O multichannel experiences. We then elaborate on the\nemerging extended reality (XR), which brings the different forms of\nvirtual/augmented/mixed reality together to realize the entire\nreality-virtuality continuum and, more importantly, supports human-machine\ninteraction as envisioned by the Tactile Internet, while posing challenges to\nconventional handhelds, e.g., smartphones. Building on the so-called\ninvisible-to-visible (I2V) technology concept, we present our extrasensory\nperception network (ESPN) and investigate how O2O communications and XR can be\ncombined for the nonlocal extension of human \"sixth-sense\" experiences in space\nand time. We conclude by putting our ideas in perspective of the 6G vision.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 17:41:23 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Maier", "Martin", ""], ["Ebrahimzadeh", "Amin", ""]]}, {"id": "1906.06759", "submitter": "Gilsoo Lee", "authors": "Gilsoo Lee, Jihong Park, Walid Saad, Mehdi Bennis", "title": "Performance Analysis of Blockchain Systems with Wireless Mobile Miners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel framework that uses wireless mobile miners (MMs) for\ncomputation purposes in a blockchain system is proposed. In the introduced\nsystem, the blockchain ledger is located at the communication nodes (CNs), and\nthe MMs associated with CNs process the blockchain's proof-of-work (PoW)\ncomputation to verify the originality of the data. The MM that is the first to\nfinish its PoW will receive a reward by sending its computing result to the CNs\nthat are connected to other MMs. In the considered scenario, a blockchain\nforking event occurs if the MM having the shortest PoW delay fails to be the\nfirst to update its computing result to other MMs. To enable such mobile\noperations for a blockchain with minimum forking events, it is imperative to\nmaintain low-latency wireless communications between MMs and CNs. To analyze\nthe sensitivity of the system to latency, the probability of occurrence of a\nforking event is theoretically derived. The system is then designed so as to\ncompute the forked block's PoW again to recover from a forking event. For this\ncase, the average energy consumption of an MM is derived as a function of the\nsystem parameters such as the number of MMs and power consumed by the\ncomputing, transmission, and mobility processes of the MMs. Simulation results\nverify the analytical derivations and show that using a larger number of MMs\ncan reduce the energy consumption by up to 94.5% compared to a blockchain\nsystem with a single MM.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 19:49:43 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Lee", "Gilsoo", ""], ["Park", "Jihong", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1906.06774", "submitter": "Arash Bozorgchenani", "authors": "Mohsen Jahanshahi, Arash Bozorgchenani", "title": "Gateway Placement and Selection Solutions in WMNs: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the high demand of Internet access by users, and the tremendous\nsuccess of wireless technologies, Wireless Mesh Networks (WMNs) have become a\npromising solution. IGW Placement and Selection (GPS) are significantly\ninvestigated problems to achieve QoS requirements, network performance, and\nreduce deployment cost in WMNs. Best effort is made to classify different works\nin the literature based on network characteristics. At first, one of the most\nprincipal capabilities of WMNs, which is taking advantage of using multi-radio\nrouters in a multi-channel network, is studied. In this article, GPS protocols\nconsidering a definition of three types of WMN are investigated based on\nchannel-radio association including Single Radio Single Channel (SRSC), Single\nRadio Multi- Channel (SRMC), and Multi-Radio Multi-Channel (MRMC) WMNs.\nFurthermore, a classification regarding static and dynamic channel allocation\npolicies is derived. In addition, the reported works from the viewpoint of\nnetwork solutions are classified. The first perspective is: centralized,\ndistributed or hybrid architectures. Following this classification, the studies\nare categorized regarding optimization techniques, which are operation\nresearch-based solutions, heuristic algorithms, and meta-heuristic-based\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 21:20:33 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Jahanshahi", "Mohsen", ""], ["Bozorgchenani", "Arash", ""]]}, {"id": "1906.06901", "submitter": "Kaixuan Xing", "authors": "Hui Li, Jiangxing Wu, Kaixuan Xing, Peng Yi, Julong Lan, Xinsheng Ji,\n  Qinrang Liu, Shisheng Chen, Wei Liang, Jinwu Wei, Wei Li, Fusheng Zhu, Kaiyan\n  Tian, Jiang Zhu, Yiqin Lu, Ke Xu, Jiaxing Song, Yijun Liu, Junfeng Ma, Rui\n  Xu, Jianming Que, Weihao Yang, Weihao Miu, Zefeng Zheng, Guohua Wei, Jiuhua\n  Qi, Yongjie Bai, Chonghui Ning, Han Wang, Xinchun Zhang, Xin Yang, Jiansen\n  Huang, Sai Lv, Xinwei Liu, Gengxin Li", "title": "The Prototype of Decentralized Multilateral Co-Governing Post-IP\n  Internet Architecture and Its Testing on Operator Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet has become the most important infrastructure of modern society,\nwhile the existing IP network is unable to provide high-quality service. The\nunilateralism IP network is unable to satisfy the Co-managing and Co-governing\ndemands to Cyberspace for most Nations in the world as well. Facing this\nchallenge, we propose a novel Decentralized Multilateral Co-Governing Post-IP\nInternet architecture. To verify its effectiveness, we develop the prototype on\nthe operator's networks including China Mainland, Hong Kong, and Macao. The\nexperiments and testing results show that this architecture is feasible for\nco-existing of Content-Centric Networking and IP network, and it might become a\nChinese Solution to the world.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 08:44:19 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Li", "Hui", ""], ["Wu", "Jiangxing", ""], ["Xing", "Kaixuan", ""], ["Yi", "Peng", ""], ["Lan", "Julong", ""], ["Ji", "Xinsheng", ""], ["Liu", "Qinrang", ""], ["Chen", "Shisheng", ""], ["Liang", "Wei", ""], ["Wei", "Jinwu", ""], ["Li", "Wei", ""], ["Zhu", "Fusheng", ""], ["Tian", "Kaiyan", ""], ["Zhu", "Jiang", ""], ["Lu", "Yiqin", ""], ["Xu", "Ke", ""], ["Song", "Jiaxing", ""], ["Liu", "Yijun", ""], ["Ma", "Junfeng", ""], ["Xu", "Rui", ""], ["Que", "Jianming", ""], ["Yang", "Weihao", ""], ["Miu", "Weihao", ""], ["Zheng", "Zefeng", ""], ["Wei", "Guohua", ""], ["Qi", "Jiuhua", ""], ["Bai", "Yongjie", ""], ["Ning", "Chonghui", ""], ["Wang", "Han", ""], ["Zhang", "Xinchun", ""], ["Yang", "Xin", ""], ["Huang", "Jiansen", ""], ["Lv", "Sai", ""], ["Liu", "Xinwei", ""], ["Li", "Gengxin", ""]]}, {"id": "1906.07009", "submitter": "Miguel Sepulcre", "authors": "Miguel Sepulcre, Javier Gozalvez, M. Carmen Lucas-Esta\\~n", "title": "Power and Packet Rate Control for Vehicular Networks in\n  Multi-Application Scenarios", "comments": null, "journal-ref": "IEEE Transactions on Vehicular Technology, Volume 68, Issue 9, pp.\n  9029 - 9037, September 2019", "doi": "10.1109/TVT.2019.2922539", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular networks require vehicles to periodically transmit 1-hop broadcast\npackets in order to detect other vehicles in their local neighborhood. Many\nvehicular applications depend on the correct reception of these packets that\nare transmitted on a common control channel. Vehicles will actually be required\nto simultaneously execute multiple applications. The transmission of the\nbroadcast packets should hence be configured to satisfy the requirements of all\napplications while controlling the channel load. This can be challenging when\nvehicles simultaneously run multiple applications, and each application has\ndifferent requirements that vary with the vehicular context (e.g. speed and\ndensity). In this context, this paper proposes and evaluates different\ntechniques to dynamically adapt the rate and power of 1-hop broadcast packets\nper vehicle in multi-application scenarios. The proposed techniques are\ndesigned to satisfy the requirements of multiple simultaneous applications and\nreduce the channel load. The evaluation shows that the proposed techniques\nsignificantly decrease the channel load, and can better satisfy the\nrequirements of multiple applications compared to existing approaches, in\nparticular the Message Handler specified in the SAE J2735 DSRC Message Set\nDictionary.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 13:02:45 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 08:14:31 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Sepulcre", "Miguel", ""], ["Gozalvez", "Javier", ""], ["Lucas-Esta\u00f1", "M. Carmen", ""]]}, {"id": "1906.07063", "submitter": "Linh Nguyen PhD", "authors": "Linh Nguyen and Hoc T. Nguyen", "title": "Mobility based network lifetime in wireless sensor networks: A review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly emerging technologies in micro-electromechanical systems and\nwireless communications allows a mobile wireless sensor networks (MWSN) to be a\nmore and more powerful mean in many applications such as habitat and\nenvironmental monitoring, traffic observing, battlefield surveillance, smart\nhomes and smart cities. Nevertheless, due to sensor battery constraints,\nenergy-efficiently operating a MWSN is paramount importance in those\napplications; and a plethora of approaches have been proposed to elongate the\nnetwork longevity at most possible. Therefore, this paper provides a\ncomprehensive review on the developed methods that exploit mobility of sensor\nnodes and/or sink(s) to effectively maximize the lifetime of a MWSN. The survey\nsystematically classifies the algorithms into categories where the MWSN is\nequipped with mobile sensor nodes, one mobile sink or multiple mobile sinks.\nHow to drive the mobile sink(s) for energy efficiency in the network is also\nfully reviewed and reported.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 00:48:37 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 01:47:13 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Nguyen", "Linh", ""], ["Nguyen", "Hoc T.", ""]]}, {"id": "1906.07064", "submitter": "Kai Li", "authors": "Kai Li, Wei Ni, Eduardo Tovar", "title": "On-board Deep Q-Network for UAV-assisted Online Power Transfer and Data\n  Collection", "comments": "32 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) with Microwave Power Transfer (MPT)\ncapability provide a practical means to deploy a large number of wireless\npowered sensing devices into areas with no access to persistent power supplies.\nThe UAV can charge the sensing devices remotely and harvest their data. A key\nchallenge is online MPT and data collection in the presence of on-board control\nof a UAV (e.g., patrolling velocity) for preventing battery drainage and data\nqueue overflow of the sensing devices, while up-to-date knowledge on battery\nlevel and data queue of the devices is not available at the UAV. In this paper,\nan on-board deep Q-network is developed to minimize the overall data packet\nloss of the sensing devices, by optimally deciding the device to be charged and\ninterrogated for data collection, and the instantaneous patrolling velocity of\nthe UAV. Specifically, we formulate a Markov Decision Process (MDP) with the\nstates of battery level and data queue length of sensing devices, channel\nconditions, and waypoints given the trajectory of the UAV; and solve it\noptimally with Q-learning. Furthermore, we propose the on-board deep Q-network\nthat can enlarge the state space of the MDP, and a deep reinforcement learning\nbased scheduling algorithm that asymptotically derives the optimal solution\nonline, even when the UAV has only outdated knowledge on the MDP states.\nNumerical results demonstrate that the proposed deep reinforcement learning\nalgorithm reduces the packet loss by at least 69.2%, as compared to existing\nnon-learning greedy algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:41:36 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Li", "Kai", ""], ["Ni", "Wei", ""], ["Tovar", "Eduardo", ""]]}, {"id": "1906.07095", "submitter": "Sukhpreet Kaur Khangura", "authors": "Sukhpreet Kaur Khangura and Sami Ak{\\i}n", "title": "Measurement-based Online Available Bandwidth Estimation employing\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate and fast estimation of the available bandwidth in a network with\nvarying cross-traffic is a challenging task. The accepted probing tools, based\non the fluid-flow model of a bottleneck link with first-in, first-out\nmultiplexing, estimate the available bandwidth by measuring packet dispersions.\nThe estimation becomes more difficult if packet dispersions deviate from the\nassumptions of the fluid-flow model in the presence of non-fluid bursty\ncross-traffic, multiple bottleneck links, and inaccurate time-stamping. This\nmotivates us to explore the use of machine learning tools for available\nbandwidth estimation. Hence, we consider reinforcement learning and implement\nthe single-state multi-armed bandit technique, which follows the\n$\\epsilon$-greedy algorithm to find the available bandwidth. Our measurements\nand tests reveal that our proposed method identifies the available bandwidth\nwith high precision. Furthermore, our method converges to the available\nbandwidth under a variety of notoriously difficult conditions, such as heavy\ntraffic burstiness, different cross-traffic intensities, multiple bottleneck\nlinks, and in networks where the tight link and the bottleneck link are not\nsame. Compared to the piece-wise linear network a model-based direct probing\ntechnique that employs a Kalman filter, our method shows more accurate\nestimates and faster convergence in certain network scenarios and does not\nrequire measurement noise statistics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:02:10 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Khangura", "Sukhpreet Kaur", ""], ["Ak\u0131n", "Sami", ""]]}, {"id": "1906.07096", "submitter": "Arvind Chakrapani", "authors": "Arvind Chakrapani", "title": "NB-IoT Uplink Receiver Design and Performance Study", "comments": "Submitted to IEEE Internet of Things Journal", "journal-ref": "IEEE Internet of Things Journal March 2020", "doi": "10.1109/JIOT.2019.2957641", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LTE Narrowband Internet of Things (NB-IoT) is a 3GPP defined cellular\ntechnology that is designed to enable connectivity to many low-cost and low\npower/throughput IoT devices running delay-tolerant applications. NB-IoT can\ncoexist within LTE spectrum either in a standalone mode, in-band with LTE or in\nguard-band of LTE. With NB-IoT designed to operate in very low signal to noise\npower ratios, the uplink receiver design presents several challenges. In this\npaper the design and performance of a NB-IoT uplink receiver is studied in\ndetail. First, receiver design for NB-IoT uplink channels, with corresponding\nmathematical analysis, is presented. Specifically, it is shown how the\ntime/frequency structure of signals can be exploited to enhance the receiver\nperformance. Second, the performance of each channel is characterized with both\nlink level simulations and implementation on a commercially deployed\nQualcomm(registered) FSM(Trade Mark) platform [1]. Comparisons against the 3GPP\ndefined Radio Performance and Protocol aspect requirements are also provided.\nFinally, implementation details are addressed and discussions on proposed\nenhancements to NB-IoT in 3GPP Release 15 are provided. It is shown how the\nproposed receiver algorithms can be adopted to Release 15 enhancements with\nminor or no modifications. The work in this paper is of significance to system\ndesigners looking to implement efficient NB-IoT uplink receiver to coexist with\nlegacy LTE systems.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 23:34:35 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 22:16:08 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Chakrapani", "Arvind", ""]]}, {"id": "1906.07097", "submitter": "Chiara Pielli", "authors": "Chiara Pielli, Tanguy Ropitault, Nada Golmie, Michele Zorzi", "title": "An Analytical Model for CBAP Allocations in IEEE 802.11ad", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The IEEE 802.11ad standard extends WiFi operation to the millimeter wave\nfrequencies, and introduces novel features concerning both the physical (PHY)\nand Medium Access Control (MAC) layers. However, while there are extensive\nresearch efforts to develop mechanisms for establishing and maintaining\ndirectional links for mmWave communications, fewer works deal with transmission\nscheduling and the hybrid MAC introduced by the standard. The hybrid MAC layer\nprovides for two different kinds of resource allocations: Contention Based\nAccess Periods (CBAPs) and contention free Service Periods (SPs). In this\npaper, we propose a Markov Chain model to represent CBAPs, which takes into\naccount operation interruptions due to scheduled SPs and the deafness and\nhidden node problems that directional communication exacerbates. We also\npropose a mathematical analysis to assess interference among stations. We\nderive analytical expressions to assess the impact of various transmission\nparameters and of the Data Transmission Interval configuration on some key\nperformance metrics such as throughput, delay and packet dropping rate. This\ninformation may be used to efficiently design a transmission scheduler that\nallocates contention-based and contention-free periods based on the application\nrequirements.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 08:04:22 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Pielli", "Chiara", ""], ["Ropitault", "Tanguy", ""], ["Golmie", "Nada", ""], ["Zorzi", "Michele", ""]]}, {"id": "1906.07098", "submitter": "Gaetano Manzo", "authors": "Gaetano Manzo, Sebastian Otalora, Marco Ajmone Marsan, Torsten Braun,\n  Hung Nguyen, Gianluca Rizzo", "title": "DeepFloat: Resource-Efficient Dynamic Management of Vehicular Floating\n  Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opportunistic communications are expected to playa crucial role in enabling\ncontext-aware vehicular services. A widely investigated opportunistic\ncommunication paradigm for storing a piece of content probabilistically in a\ngeographica larea is Floating Content (FC). A key issue in the practical\ndeployment of FC is how to tune content replication and caching in a way which\nachieves a target performance (in terms of the mean fraction of users\npossessing the content in a given region of space) while minimizing the use of\nbandwidth and host memory. Fully distributed, distance-based approaches prove\nhighly inefficient, and may not meet the performance target,while centralized,\nmodel-based approaches do not perform well in realistic, inhomogeneous\nsettings. In this work, we present a data-driven centralized approach to\nresource-efficient, QoS-aware dynamic management of FC.We propose a Deep\nLearning strategy, which employs a Convolutional Neural Network (CNN) to\ncapture the relationships between patterns of users mobility, of content\ndiffusion and replication, and FC performance in terms of resource utilization\nand of content availability within a given area. Numerical evaluations show the\neffectiveness of our approach in deriving strategies which efficiently modulate\nthe FC operation in space and effectively adapt to mobility pattern changes\nover time.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 07:49:55 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Manzo", "Gaetano", ""], ["Otalora", "Sebastian", ""], ["Marsan", "Marco Ajmone", ""], ["Braun", "Torsten", ""], ["Nguyen", "Hung", ""], ["Rizzo", "Gianluca", ""]]}, {"id": "1906.07104", "submitter": "Sawood Alam", "authors": "Sawood Alam, Michele C. Weigle, Michael L. Nelson, Martin Klein, and\n  Herbert Van de Sompel", "title": "Supporting Web Archiving via Web Packaging", "comments": "This is a position paper accepted at the ESCAPE Workshop 2019.\n  https://www.iab.org/activities/workshops/escape-workshop/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe challenges related to web archiving, replaying archived web\nresources, and verifying their authenticity. We show that Web Packaging has\nsignificant potential to help address these challenges and identify areas in\nwhich changes are needed in order to fully realize that potential.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:12:46 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Alam", "Sawood", ""], ["Weigle", "Michele C.", ""], ["Nelson", "Michael L.", ""], ["Klein", "Martin", ""], ["Van de Sompel", "Herbert", ""]]}, {"id": "1906.07162", "submitter": "Gautam Srivastava", "authors": "Andrew Fisher, Gautam Srivastava, and Robert Bryce", "title": "MQTTg: An Android Implementation", "comments": "5 pages, 6 figures. arXiv admin note: substantial text overlap with\n  arXiv:1811.09706", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) age is upon us. As we look to build larger\nnetworks with more devices connected to the Internet, the need for lightweight\nprotocols that minimize the use of both energy and computation gain popularity.\nOne such protocol is Message Queue Telemetry Transport (MQTT). Since its\nintroduction in 1999, it has slowly increased in use cases and gained a huge\nspike in popularity since it was used in the popular messaging application\nFacebook Messenger. In our previous works, we focused on adding geolocation to\nMQTT, to help modernize the protocol into the IoT age. In this paper, we build\noff our previous work on MQTTg and build an IoT Android Application that can\npull geolocation information from the Operating System. We then use the\ngeolocation data to create geofences to help further tailor the use cases of\nMQTTg.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 19:06:47 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Fisher", "Andrew", ""], ["Srivastava", "Gautam", ""], ["Bryce", "Robert", ""]]}, {"id": "1906.07175", "submitter": "Ayush Kumar", "authors": "Ayush Kumar, Teng Joon Lim", "title": "A Secure Contained Testbed for Analyzing IoT Botnets", "comments": "arXiv admin note: text overlap with arXiv:1901.04805", "journal-ref": "Proceedings of Testbeds and Research Infrastructures for the\n  Development of Networks and Communications (TRIDENTCOM) 2018", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many security issues have come to the fore with the increasingly widespread\nadoption of Internet-of-Things (IoT) devices. The Mirai attack on Dyn DNS\nservice, in which vulnerable IoT devices such as IP cameras, DVRs and routers\nwere infected and used to propagate large-scale DDoS attacks, is one of the\nmore prominent recent examples. IoT botnets, consisting of\nhundreds-of-thousands of bots, are currently present ``in-the-wild'' at least\nand are only expected to grow in the future, with the potential to cause\nsignificant network downtimes and financial losses to network companies. We\npropose, therefore, to build testbeds for evaluating IoT botnets and design\nsuitable mitigation techniques against them. A DETERlab-based IoT botnet\ntestbed is presented in this work. The testbed is built in a secure contained\nenvironment and includes ancillary services such as DHCP, DNS as well as botnet\ninfrastructure including CnC and scanListen/loading servers. Developing an IoT\nbotnet testbed presented us with some unique challenges which are different\nfrom those encountered in non-IoT botnet testbeds and we highlight them in this\npaper. Further, we point out the important features of our testbed and\nillustrate some of its capabilities through experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 02:51:58 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Kumar", "Ayush", ""], ["Lim", "Teng Joon", ""]]}, {"id": "1906.07252", "submitter": "Siva Muruganathan", "authors": "Siva Muruganathan, Sebastian Faxer, Simon Jarmyr, Shiwei Gao, and\n  Mattias Frenne", "title": "On the System-level Performance of Coordinated Multi-point Transmission\n  Schemes in 5G NR Deployment Scenarios", "comments": "5 pages, 7 figures, submitted for conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the system-level performance of dynamic point\nselection (DPS) and non-coherent joint transmission (NC-JT) coordinated\nmulti-point transmission (CoMP) schemes under different 5G NR deployment\nscenarios using state-of-the-art system-level simulations. It is observed that\nat a mid-band carrier frequency, NC-JT does not provide performance gains over\nDPS or single transmission/reception point (TRP) transmission unless the\nchannel from a TRP is rank deficient. Therefore, benefits with NC-JT are more\nlikely to be found in indoor deployment scenarios where the TRPs are typically\nequipped with only 2 transmit antenna ports, whereas benefits are less likely\nto be observed in macro-cell deployments where TRPs typically have a larger\nnumber of antennas ports. It is further observed that NC-JT gains tend to\ndiminish with increasing system load, partly due to increased interference,\nwhich typically lowers the transmission rank.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:27:57 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Muruganathan", "Siva", ""], ["Faxer", "Sebastian", ""], ["Jarmyr", "Simon", ""], ["Gao", "Shiwei", ""], ["Frenne", "Mattias", ""]]}, {"id": "1906.07261", "submitter": "Abuthahir A", "authors": "Abuthahir Abuthahir and Gaurav Raina", "title": "Stability and non-linear dynamics of Dual congestion control schemes\n  with two delays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CD cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze some local stability and local bifurcation\nproperties of the Proportionally fair, TCP fair, and the Delay-based dual\nalgorithms in the presence of two distinct time delays. In particular, our\nfocus is on the interplay between different notions of fairness, stability, and\nbifurcation theoretic properties. Different notions of fairness give rise to\ndifferent non-linear models for the class of Dual algorithms. One can devise\nconditions for local stability, for each of these models, but such conditions\ndo not offer clear design recommendations on which fairness criteria is\ndesirable. With a bifurcation-theoretic analysis, we have to take non-linear\nterms into consideration, which helps to learn additional dynamical properties\nof the various systems. In the case of TCP fair and Delay dual algorithms, with\ntwo delays, we present evidence that they can undergo a sub-critical Hopf\nbifurcation, which has not been previously revealed through analysis of the\nsingle delay variants of these algorithms. A sub-critical Hopf bifurcation can\nresult in either large amplitude limit cycles or unstable limit cycles, and\nhence should be avoided in engineering applications. In the case of the\nProportionally fair algorithm, we provide strong evidence to suggest that all\none should expect is the occurrence of a super-critical Hopf bifurcation, which\nleads to stable limit cycles with small amplitude. Thus, from a design\nperspective, our analysis favors the use of Proportional fairness in the class\nof dual congestion control algorithms. To best of our knowledge, this is the\nfirst study that presents evidence to suggest that fluid models representing\nInternet congestion control algorithms may undergo a sub-critical Hopf\nbifurcation.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 16:33:57 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Abuthahir", "Abuthahir", ""], ["Raina", "Gaurav", ""]]}, {"id": "1906.07415", "submitter": "Jan R\\\"uth", "authors": "Konrad Wolsing and Jan R\\\"uth and Klaus Wehrle and Oliver Hohlfeld", "title": "A Performance Perspective on Web Optimized Protocol Stacks:\n  TCP+TLS+HTTP/2 vs. QUIC", "comments": null, "journal-ref": "In Proceedings of the Applied Networking Research Workshop (ANRW\n  '19), July 22, 2019, Montreal, QC, Canada", "doi": "10.1145/3340301.3341123", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing performance comparisons of QUIC and TCP compared an optimized QUIC\nto an unoptimized TCP stack. By neglecting available TCP improvements\ninherently included in QUIC, comparisons do not shed light on the performance\nof current web stacks. In this paper, we can show that tuning TCP parameters is\nnot negligible and directly yields significant improvements. Nevertheless, QUIC\nstill outperforms even our tuned variant of TCP. This performance advantage is\nmostly caused by QUIC's reduced RTT design during connection establishment,\nand, in case of lossy networks due to its ability to circumvent head-of-line\nblocking.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 07:26:22 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Wolsing", "Konrad", ""], ["R\u00fcth", "Jan", ""], ["Wehrle", "Klaus", ""], ["Hohlfeld", "Oliver", ""]]}, {"id": "1906.07578", "submitter": "Michele Scarpiniti Dr.", "authors": "Enzo Baccarelli, Michele Scarpiniti, Alireza Momenzadeh", "title": "EcoMobiFog -- Design and Dynamic Optimization of a 5G Mobile-Fog-Cloud\n  Multi-Tier Ecosystem for the Real-Time Distributed Execution of Stream\n  Applications", "comments": "This is a longer version of the published paper on IEEE Access", "journal-ref": "IEEE Access, Vol. 7, pp. 55565-55608, 2019", "doi": "10.1109/ACCESS.2019.2913564", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging 5G paradigm will enable multi-radio smartphones to run high-rate\nstream applications. However, since current smartphones remain resource and\nbattery-limited, the 5G era opens new challenges on how to actually support\nthese applications. In principle, the service orchestration capability of the\nFog and Cloud Computing paradigms could be an effective means of dynamically\nproviding resource-augmentation to smartphones. Motivated by these\nconsiderations, the peculiar focus of this paper is on the joint and adaptive\noptimization of the resource and task allocations of mobile stream applications\nin 5G-supported multi-tier Mobile-Fog-Cloud virtualized ecosystems. The\nobjective is the minimization of the computing-plus-network energy of the\noverall ecosystem under hard constraints on the minimum streaming rate and the\nmaximum computing-plus-networking resources. To this end: 1) we model the\ntarget ecosystem energy by explicitly accounting for the virtualized and\nmulti-core nature of the Fog/Cloud servers; 2) since the resulting problem is\nnon-convex and involves both continuous and discrete variables, we develop an\noptimality-preserving decomposition into the cascade of a (continuous) resource\nallocation sub-problem and a (discrete) task-allocation sub-problem; and 3) we\nnumerically solve the first sub-problem through a suitably designed set of\ngradient-based adaptive iterations, while we approach the solution of the\nsecond sub-problem by resorting to an ad-hoc-developed elitary Genetic\nalgorithm. Finally, we design the main blocks of EcoMobiFog, a technological\nvirtualized platform for supporting the developed solver. The extensive\nnumerical tests confirm that the energy-delay performance of the proposed\nsolving framework is typically within a few per-cent the benchmark one of the\nexhaustive search-based solution.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 13:45:57 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Baccarelli", "Enzo", ""], ["Scarpiniti", "Michele", ""], ["Momenzadeh", "Alireza", ""]]}, {"id": "1906.07674", "submitter": "Gioacchino Tangari", "authors": "Gioacchino Tangari, Alessandro Finamore, Diego Perino", "title": "Generalizing Critical Path Analysis on Mobile Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical Path Analysis (CPA) studies the delivery of webpages to identify\npage resources, their interrelations, as well as their impact on the page\nloading latency. Despite CPA being a generic methodology, its mechanisms have\nbeen applied only to browsers and web traffic, but those do not directly apply\nto study generic mobile apps. Likewise, web browsing represents only a small\nfraction of the overall mobile traffic. In this paper, we take a first step\ntowards filling this gap by exploring how CPA can be performed for generic\nmobile applications. We propose Mobile Critical Path Analysis (MCPA), a\nmethodology based on passive and active network measurements that is applicable\nto a broad set of apps to expose a fine-grained view of their traffic dynamics.\nWe validate MCPA on popular apps across different categories and usage\nscenarios. We show that MCPA can identify user interactions with mobile apps\nonly based on traffic monitoring, and the relevant network activities that are\nbottlenecks. Overall, we observe that apps spend 60% of time and 84% of bytes\non critical traffic on average, corresponding to +22% time and +13% bytes than\nwhat observed for browsing.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 16:27:16 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Tangari", "Gioacchino", ""], ["Finamore", "Alessandro", ""], ["Perino", "Diego", ""]]}, {"id": "1906.07718", "submitter": "Abuthahir Abuthahir", "authors": "Abuthahir and Gaurav Raina", "title": "Impact of queue feedback on the stability and dynamics of a Rate Control\n  Protocol (RCP) with two delays", "comments": "arXiv admin note: substantial text overlap with arXiv:1906.06153;\n  text overlap with arXiv:1906.00374, arXiv:1906.07261", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rate Control Protocol (RCP) uses feedback from routers to assign flows their\nfair rate. RCP estimates the fair rate using two forms of feedback: rate\nmismatch and queue size. An outstanding design question for RCP is whether the\nqueue size feedback is useful or not. To address this, we analyze stability and\nthe bifurcation properties of RCP in both the cases i.e., with and without\nqueue size feedback. The model considers flows with two different round-trip\ntimes, operating over a single bottleneck link. By using an exogenous\nbifurcation parameter, we show that the system loses stability via a Hopf\nbifurcation and hence we can expect a limit cycle branching from the fixed\npoint. We highlight that the presence of queue feedback can readily destabilize\nthe system. Using Poincar{\\`e} normal forms and the center manifold theorem, we\nshow that the Hopf bifurcation is super-critical in the case of RCP without\nqueue feedback. Whereas, in the presence of queue feedback, we show that the\nsystem can undergoes a sub-critical Hopf bifurcation for some parameter values.\nA sub-critical Hopf bifurcation can result in either large amplitude limit\ncycles or unstable limit cycles, and hence should be avoided in engineering\napplications. Thus, the presence of queue feedback would create adverse effects\non the stability of the emerging limit cycles. In essence, the analytical\nresults of RCP with two delays favor the design choice that uses feedback based\nonly on rate mismatch. The theoretical analysis is validated with numerical\ncomputations and some packet level simulations as well.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 11:05:14 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Abuthahir", "", ""], ["Raina", "Gaurav", ""]]}, {"id": "1906.07860", "submitter": "Lei Lei", "authors": "Lei Lei, Huijuan Xu, Xiong Xiong, Kan Zheng, Wei Xiang, and Xianbin\n  Wang", "title": "Multi-user Resource Control with Deep Reinforcement Learning in IoT Edge\n  Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By leveraging the concept of mobile edge computing (MEC), massive amount of\ndata generated by a large number of Internet of Things (IoT) devices could be\noffloaded to MEC server at the edge of wireless network for further\ncomputational intensive processing. However, due to the resource constraint of\nIoT devices and wireless network, both the communications and computation\nresources need to be allocated and scheduled efficiently for better system\nperformance. In this paper, we propose a joint computation offloading and\nmulti-user scheduling algorithm for IoT edge computing system to minimize the\nlong-term average weighted sum of delay and power consumption under stochastic\ntraffic arrival. We formulate the dynamic optimization problem as an\ninfinite-horizon average-reward continuous-time Markov decision process (CTMDP)\nmodel. One critical challenge in solving this MDP problem for the multi-user\nresource control is the curse-of-dimensionality problem, where the state space\nof the MDP model and the computation complexity increase exponentially with the\ngrowing number of users or IoT devices. In order to overcome this challenge, we\nuse the deep reinforcement learning (RL) techniques and propose a neural\nnetwork architecture to approximate the value functions for the post-decision\nsystem states. The designed algorithm to solve the CTMDP problem supports\nsemi-distributed auction-based implementation, where the IoT devices submit\nbids to the BS to make the resource control decisions centrally. Simulation\nresults show that the proposed algorithm provides significant performance\nimprovement over the baseline algorithms, and also outperforms the RL\nalgorithms based on other neural network architectures.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 00:29:06 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Lei", "Lei", ""], ["Xu", "Huijuan", ""], ["Xiong", "Xiong", ""], ["Zheng", "Kan", ""], ["Xiang", "Wei", ""], ["Wang", "Xianbin", ""]]}, {"id": "1906.08024", "submitter": "Omar Faqir", "authors": "Omar J. Faqir, Eric C. Kerrigan, Deniz G\\\"und\\\"uz, Yuanbo Nie", "title": "Joint Optimization of Transmission and Propulsion in UAV-Assisted\n  Communication Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.IT cs.NI cs.SY eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The communication energy in a wireless network of mobile autonomous agents\nshould be defined to include the propulsion energy as well as the transmission\nenergy used to facilitate information transfer. We therefore develop\ncommunicationtheoretic and Newtonian dynamic models of the communication and\nlocomotion expenditures of an unmanned aerial vehicle (UAV). These models are\nused to formulate a novel nonlinear optimal control problem (OCP) for arbitrary\nnetworks of autonomous agents. This is the first work to consider mobility as a\ndecision variable in UAV networks with multiple access channels. Where\npossible, we compare our results with known analytic solutions for particular\nsingle-hop network configurations. The OCP is then applied to a multiple-node\nUAV network for which previous results cannot be readily extended. Numerical\nresults demonstrate increased network capacity and communication energy savings\nupwards of 70% when compared to more naive communication policies.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 11:19:59 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Faqir", "Omar J.", ""], ["Kerrigan", "Eric C.", ""], ["G\u00fcnd\u00fcz", "Deniz", ""], ["Nie", "Yuanbo", ""]]}, {"id": "1906.08025", "submitter": "Rute C. Sofia", "authors": "Rute C. Sofia", "title": "A tool to estimate roaming behavior in wireless architectures", "comments": null, "journal-ref": "inProc. WWIC2015", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a software-based tool that tracks mobile node roaming\nand infers the time-to-handover as well as the preferential handover target,\nbased on behavior inference solely derived from regular usage data captured in\nvisited wireless networks. The paper presents the tool architecture;\ncomputational background for mobility estimation; operational guidelines\nconcerning how the tool is being used to track several aspects of roaming\nbehavior in the context of wireless networks. Target selection accuracy is\nvalidated having as baseline traces obtained in realistic scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 11:22:04 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Sofia", "Rute C.", ""]]}, {"id": "1906.08029", "submitter": "Rute C. Sofia", "authors": "Rute C. Sofia, Saeik Firdose, Luis A. Lopes, Waldir Moreira, Paulo\n  Mendes", "title": "NSense: A People-centric, non-intrusive Opportunistic Sensing Tool for\n  Contextualizing Nearness", "comments": null, "journal-ref": "inProc. IEEE Healthcom 2016: 2016 IEEE 18th International\n  Conference on eHealth Networking, Application, Services. Munich, September\n  2016", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of social well-being and context awareness several eHealth\napplications have been focused on tracking activities, such as sleep or\nspecific fitness habits, with the purpose of promoting physical well-being with\nincreasing success. Sensing technology can, however, be applied to improve\nsocial well-being, in addition to physical well-being. This paper addresses\nNSense, a tool that has been developed to capture and to infer social\ninteraction patterns aiming to assist in the promotion of social well-being.\nExperiments carried out under realistic settings validate the NSense\nperformance in terms of its capability to infer social interaction context\nbased on our proposed computational utility functions. Traces obtained during\nthe experiments are available via the CRAWDAD international trace repository.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 11:45:28 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Sofia", "Rute C.", ""], ["Firdose", "Saeik", ""], ["Lopes", "Luis A.", ""], ["Moreira", "Waldir", ""], ["Mendes", "Paulo", ""]]}, {"id": "1906.08063", "submitter": "Francesc Wilhelmi", "authors": "Francesc Wilhelmi, Sergio Barrachina-Mu\\~noz, Boris Bellalta", "title": "On the Performance of the Spatial Reuse Operation in IEEE 802.11ax WLANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Spatial Reuse (SR) operation included in the IEEE 802.11ax-2020 (11ax)\namendment aims at increasing the number of parallel transmissions in an\nOverlapping Basic Service Set (OBSS). However, many unknowns exist about the\nperformance gains that can be achieved through SR. In this paper, we provide a\nbrief introduction to the SR operation described in the IEEE 802.11ax (draft\nD4.0). Then, a simulation-based implementation is provided in order to explore\nthe performance gains of the SR operation. Our results show the potential of\nusing SR in different scenarios covering multiple network densities and traffic\nloads. In particular, we observe significant improvements on the channel\nutilization when applying SR with respect to the default configuration, thus\nallowing to increase the throughput and reduce the delay. Interestingly, the\nhighest improvements provided by the SR operation are observed in the most\npessimistic situations in terms of network density and traffic load.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 12:27:26 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 14:55:35 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 11:59:48 GMT"}, {"version": "v4", "created": "Tue, 17 Sep 2019 15:24:40 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wilhelmi", "Francesc", ""], ["Barrachina-Mu\u00f1oz", "Sergio", ""], ["Bellalta", "Boris", ""]]}, {"id": "1906.08177", "submitter": "Mehrdad Salimitari", "authors": "Mehrdad Salimitari, Mohsen Joneidi, and Mainak Chatterjee", "title": "AI-enabled Blockchain: An Outlier-aware Consensus Protocol for\n  Blockchain-based IoT Networks", "comments": "This paper is accepted in IEEE GLOBECOM 2019 for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new framework for a secure and robust consensus in blockchain-based IoT\nnetworks is proposed using machine learning. Hyperledger fabric, which is a\nblockchain platform developed as part of the Hyperledger project, though looks\nvery apt for IoT applications, has comparatively low tolerance for malicious\nactivities in an untrustworthy environment. To that end, we propose AI-enabled\nblockchain (AIBC) with a 2-step consensus protocol that uses an outlier\ndetection algorithm for consensus in an IoT network implemented on hyperledger\nfabric platform. The outlier-aware consensus protocol exploits a supervised\nmachine learning algorithm which detects anomaly activities via a learned\ndetector in the first step. Then, the data goes through the inherent Practical\nByzantine Fault Tolerance (PBFT) consensus protocol in the hyperledger fabric\nfor ledger update. We measure and report the performance of our framework with\nrespect to the various delay components. Results reveal that our implemented\nAIBC network (2-step consensus protocol) improves hyperledger fabric\nperformance in terms of fault tolerance by marginally compromising the delay\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 21:29:38 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 19:36:51 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Salimitari", "Mehrdad", ""], ["Joneidi", "Mohsen", ""], ["Chatterjee", "Mainak", ""]]}, {"id": "1906.08370", "submitter": "Mohammed Laroui", "authors": "Mohammed Laroui, Akrem Sellami, Boubakr Nour, Hassine Moungla, Hossam\n  Afifi, Sofiane B.Hacene", "title": "Driving Path Stability in VANETs", "comments": null, "journal-ref": null, "doi": "10.1109/GLOCOM.2018.8647450", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular Ad Hoc Network has attracted both research and industrial community\ndue to its benefits in facilitating human life and enhancing the security and\ncomfort. However, various issues have been faced in such networks such as\ninformation security, routing reliability, dynamic high mobility of vehicles,\nthat influence the stability of communication. To overcome this issue, it is\nnecessary to increase the routing protocols performances, by keeping only the\nstable path during the communication. The effective solutions that have been\ninvestigated in the literature are based on the link prediction to avoid broken\nlinks. In this paper, we propose a new solution based on machine learning\nconcept for link prediction, using LR and Support Vector Regression (SVR) which\nis a variant of the Support Vector Machine (SVM) algorithm. SVR allows\npredicting the movements of the vehicles in the network which gives us a\ndecision for the link state at a future time. We study the performance of SVR\nby comparing the generated prediction values against real movement traces of\ndifferent vehicles in various mobility scenarios, and to show the effectiveness\nof the proposed method, we calculate the error rate. Finally, we compare this\nnew SVR method with Lagrange interpolation solution.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 21:40:20 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Laroui", "Mohammed", ""], ["Sellami", "Akrem", ""], ["Nour", "Boubakr", ""], ["Moungla", "Hassine", ""], ["Afifi", "Hossam", ""], ["Hacene", "Sofiane B.", ""]]}, {"id": "1906.08452", "submitter": "Quoc-Viet Pham", "authors": "Quoc-Viet Pham, Fang Fang, Vu Nguyen Ha, Md. Jalil Piran, Mai Le, Long\n  Bao Le, Won-Joo Hwang, Zhiguo Ding", "title": "A Survey of Multi-Access Edge Computing in 5G and Beyond: Fundamentals,\n  Technology Integration, and State-of-the-Art", "comments": "43 pages, revised manuscript submitted to IEEE Communications Surveys\n  & Tutorials for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the emergence of new compute-intensive applications and the vision\nof the Internet of Things (IoT), it is foreseen that the emerging 5G network\nwill face an unprecedented increase in traffic volume and computation demands.\nHowever, end users mostly have limited storage capacities and finite processing\ncapabilities, thus how to run compute-intensive applications on\nresource-constrained users has recently become a natural concern. Mobile edge\ncomputing (MEC), a key technology in the emerging fifth generation (5G)\nnetwork, can optimize mobile resources by hosting compute-intensive\napplications, process large data before sending to the cloud, provide the cloud\ncomputing capabilities within the radio access network (RAN) in close proximity\nto mobile users, and offer context-aware services with the help of RAN\ninformation. Therefore, MEC enables a wide variety of applications, where the\nreal-time response is strictly required, e.g., driverless vehicles, augmented\nreality, robotics, and immerse media. Indeed, the paradigm shift from 4G to 5G\ncould become a reality with the advent of new technological concepts. The\nsuccessful realization of MEC in the 5G network is still in its infancy and\ndemands for constant efforts from both academic and industry communities. In\nthis survey, we first provide a holistic overview of MEC technology and its\npotential use cases and applications. Then, we outline up-to-date researches on\nthe integration of MEC with the new technologies that will be deployed in 5G\nand beyond. We also summarize testbeds and experimental evaluations, and open\nsource activities, for edge computing. We further summarize lessons learned\nfrom state-of-the-art research works as well as discuss challenges and\npotential future directions for MEC research.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 05:44:40 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 03:39:56 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Pham", "Quoc-Viet", ""], ["Fang", "Fang", ""], ["Ha", "Vu Nguyen", ""], ["Piran", "Md. Jalil", ""], ["Le", "Mai", ""], ["Le", "Long Bao", ""], ["Hwang", "Won-Joo", ""], ["Ding", "Zhiguo", ""]]}, {"id": "1906.08554", "submitter": "Tanweer Alam", "authors": "Tanweer Alam", "title": "Tactile Internet and its Contribution in the Development of Smart Cities", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Tactile Internet (TI) is an emerging technology next to the Internet of\nThings (IoT). It is a revolution to develop the smart cities, communities and\ncultures in the future. This technology will allow the real-time interaction\nbetween human and machines as well as machine-to-machine with the 1ms challenge\nto achieve in round trip latency. The term TI is defined by International\nTelecommunication Union (ITU) in August 2014. The TI provides fast, reliable,\nsecure and available internet network that is the requirements of the smart\ncities in 5G. Tactile internet can develop the part of world where the machines\nare strong and human are weak. It increases the power of machines so that the\nvalue of human power will increase automatically. In this framework, we have\npresented the idea of tactile internet for the next generation smart cities.\nThis research will provide a high-performance reliable framework for the\ninternet of smart devices to communicate with each other in a real-time (1ms\nround trip) using IEEE 1918.1 standard. The objective of this research is\nexpected to bring a new dimension in the research of the smart cities.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 11:00:55 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Alam", "Tanweer", ""]]}, {"id": "1906.08585", "submitter": "Luis Velasco", "authors": "D. King, A. Farrel, Emiko Nishida-King, R. Casellas, L. Velasco, R.\n  Nejabati, A. Lord", "title": "The dichotomy of distributed and centralized control: METRO-HAUL, when\n  control planes collide for 5G networks", "comments": null, "journal-ref": "Optical Switching and Networking, Volume 33, July 2019, Pages\n  49-55", "doi": "10.1016/j.osn.2018.11.002", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automating the provisioning of 5G services, deployed over a heterogeneous\ninfrastructure (in terms of domains, technologies, and management platforms),\nremains a complex task, yet driven by the constant need to provide end-to-end\nconnections at network slices at reducing costs and service deployment time. At\nthe same time, such services are increasingly conceived around interconnected\nfunctions and require allocation of computing, storage, and networking\nresources.\n  The METRO-HAUL 5G research initiative acknowledges the need for automation\nand strives to develop an orchestration platform for services and resources\nthat extends, integrates, and builds on top of existing approaches,\nmacroscopically adopting Transport Software Defined Networking principles, and\nleveraging the programmability and open control of Transport SDN.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 12:51:08 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["King", "D.", ""], ["Farrel", "A.", ""], ["Nishida-King", "Emiko", ""], ["Casellas", "R.", ""], ["Velasco", "L.", ""], ["Nejabati", "R.", ""], ["Lord", "A.", ""]]}, {"id": "1906.08609", "submitter": "Mayank Raikwar", "authors": "Mayank Raikwar, Danilo Gligoroski, Katina Kralevska", "title": "SoK of Used Cryptography in Blockchain", "comments": null, "journal-ref": "IEEE Access 7 (2019) 148550 - 148575", "doi": "10.1109/ACCESS.2019.2946983", "report-no": null, "categories": "cs.CR cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The underlying fundaments of blockchain are cryptography and cryptographic\nconcepts that provide reliable and secure decentralized solutions. Although\nmany recent papers study the use-cases of blockchain in different industrial\nareas, such as finance, health care, legal relations, IoT, information\nsecurity, and consensus building systems, only few studies scrutinize the\ncryptographic concepts used in blockchain. To the best of our knowledge, there\nis no Systematization of Knowledge (SoK) that gives a complete picture of the\nexisting cryptographic concepts which have been deployed or have the potential\nto be deployed in blockchain. In this paper, we thoroughly review and\nsystematize all cryptographic concepts which are already used in blockchain.\nAdditionally, we give a list of cryptographic concepts which have not yet been\napplied but have big potentials to improve the current blockchain solutions. We\nalso include possible instantiations of these cryptographic concepts in the\nblockchain domain. Last but not least, we explicitly postulate 21 challenging\nproblems that cryptographers interested in blockchain can work on.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 13:38:50 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 10:47:20 GMT"}, {"version": "v3", "created": "Mon, 2 Sep 2019 11:51:57 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Raikwar", "Mayank", ""], ["Gligoroski", "Danilo", ""], ["Kralevska", "Katina", ""]]}, {"id": "1906.08689", "submitter": "Zheng Wang", "authors": "Lu Yuan, Jie Ren, Ling Gao, Zhanyong Tang, Zheng Wang", "title": "Using Machine Learning to Optimize Web Interactions on Heterogeneous\n  Mobile Multi-cores", "comments": "Accepted to be published in IEEE ACCESS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The web has become a ubiquitous application development platform for mobile\nsystems. Yet, web access on mobile devices remains an energy-hungry activity.\nPrior work in the field mainly focuses on the initial page loading stage, but\nfails to exploit the opportunities for energy-efficiency optimization while the\nuser is interacting with a loaded page. This paper presents a novel approach\nfor performing energy optimization for interactive mobile web browsing. At the\nheart of our approach is a set of machine learning models, which estimate\n\\emph{at runtime} the frames per second for a given user interaction input by\nrunning the computation-intensive web render engine on a specific processor\ncore under a given clock speed. We use the learned predictive models as a\nutility function to quickly search for the optimal processor setting to\ncarefully trade responsive time for reduced energy consumption. We integrate\nour techniques to the open-source Chromium browser and apply it to two\nrepresentative mobile user events: scrolling and pinching (i.e., zoom in and\nout). We evaluate the developed system on the landing pages of the top-100\nhottest websites and two big.LITTLE heterogeneous mobile platforms. Our\nextensive experiments show that the proposed approach reduces the system-wide\nenergy consumption by over 36\\% on average and up to 70\\%. This translates to\nan over 17\\% improvement on energy-efficiency over a state-of-the-art\nevent-based web browser scheduler, but with significantly fewer violations on\nthe quality of service.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 15:21:09 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 16:07:13 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 13:11:49 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Yuan", "Lu", ""], ["Ren", "Jie", ""], ["Gao", "Ling", ""], ["Tang", "Zhanyong", ""], ["Wang", "Zheng", ""]]}, {"id": "1906.08844", "submitter": "Yusuf Secerdin", "authors": "Yusuf Secerdin, Murat Erkoc", "title": "Service Network Design Problem with Capacity-Demand Balancing", "comments": "61 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses developing cost-effective strategies to respond to\nexcessive demand in the service network design problem in a multi-period\nsetting. The common assumption states that the capacity of freight carriers'\nassets is capable of handling all of the forecasted demand; however, we assume\nthat there are certain periods such as holiday season in which excessive demand\nis observed. The demand strictly exceeds the carrier's capacity; even though,\nthe average demand can be still fulfilled throughout the year. In this sense,\nwe let the carrier has three options to respond to the demand: Dispersing the\ndemand with a penalty, leasing additional asset(s) temporarily, and outsourcing\nsome capacity. We propose a modeling and solution approach that jointly\nincorporates asset management and sizing, outsourcing (3PLs), and\nearliness/tardiness penalties. The objective is to minimize the overall\noperational costs by optimally selecting and scheduling the home fleet with\nrespect to 'demand shifting' choices, selecting services from third parties,\nand routing the commodities on the designed network. We propose an arc-based\nformulation as well as valid inequalities and present a comprehensive\ncomputational study on the randomly generated instances. The formulations with\nvalid inequalities (VIs) outperform the regular formulation in obtaining\ntighter lower bounds. One set of VIs can improve the CPU time elapsed by 25% on\nmedium-instances that can be solved optimally within the time limit.\nFurthermore, we develop a custom multi-phase dedicate-merge-and-mix algorithm\n(DMaM) to solve CSSND problem with an emphasis of obtaining solutions as\nhigh-quality as possible practically in a short time in the real world. DMaM\nhas a promising potential to obtain solutions especially for very large\ninstances whereas the commercial solver cannot initialize the B&B algorithm due\nto excessive memory usage.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 20:48:02 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Secerdin", "Yusuf", ""], ["Erkoc", "Murat", ""]]}, {"id": "1906.08971", "submitter": "Laurent Viennot", "authors": "Duc-Minh Phan, Laurent Viennot (GANG, IRIF, LINCS, UPD7)", "title": "Fast Public Transit Routing with Unrestricted Walking through Hub\n  Labeling", "comments": null, "journal-ref": "Special Event on Analysis of Experimental Algorithms (SEA2), Jun\n  2019, Kalamata, Greece", "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel technique for answering routing queries in public\ntransportation networks that allows unrestricted walking. We consider several\ntypes of queries: earliest arrival time, Pareto-optimal journeys regarding\narrival time, number of transfers and walking time, and profile, i.e. finding\nall Pareto-optimal journeys regarding travel time and arrival time in a given\ntime interval. Our techniques uses hub labeling to represent unlimited foot\ntransfers and can be adapted to both classical algorithms RAPTOR and CSA. We\nobtain significant speedup compared to the state-of-the-art approach based on\ncontraction hierarchies.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 06:25:10 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Phan", "Duc-Minh", "", "GANG, IRIF, LINCS, UPD7"], ["Viennot", "Laurent", "", "GANG, IRIF, LINCS, UPD7"]]}, {"id": "1906.08993", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Manuel Patchou and Christian Wietfeld", "title": "Lightweight Simulation of Hybrid Aerial- and Ground-based Vehicular\n  Communication Networks", "comments": null, "journal-ref": "2019 IEEE 90th Vehicular Technology Conference (VTC2019-Fall)", "doi": "10.1109/VTCFall.2019.8891340", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperating small-scale Unmanned Aerial Vehicles (UAVs) will open up new\napplication fields within next-generation Intelligent Transportation Sytems\n(ITSs), e.g., airborne near field delivery. In order to allow the exploitation\nof the potentials of hybrid vehicular scenarios, reliable and efficient\nbidirectional communication has to be guaranteed in highly dynamic\nenvironments. For addressing these novel challenges, we present a lightweight\nframework for integrated simulation of aerial and ground-based vehicular\nnetworks. Mobility and communication are natively brought together using a\nshared codebase coupling approach, which catalyzes the development of novel\ncontext-aware optimization methods that exploit interdependencies between both\ndomains. In a proof-of-concept evaluation, we analyze the exploitation of UAVs\nas local aerial sensors as well as aerial base stations. In addition, we\ncompare the performance of Long Term Evolution (LTE) and Cellular\nVehicle-to-Everything (C-V2X) for connecting the ground- and air-based\nvehicles.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 07:55:41 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 06:41:17 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Patchou", "Manuel", ""], ["Wietfeld", "Christian", ""]]}, {"id": "1906.09026", "submitter": "Ahmed Al Amin", "authors": "Ahmed Al Amin, Bhaskara Narottama, Soo Young Shin", "title": "Capacity Enhancement of Cooperative NOMA over Rician Fading Channels\n  with Orbital Angular Momentum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This letter proposes the usage of orbital angular momentum (OAM) for\ncooperative non-orthogonal multiple access (CNOMA) to enhance sum capacity (SC)\nfor the future cellular communication system. The proposed CNOMA-OAM scheme is\nanalyzed and compared with other schemes, i.e., conventional CNOMA,\nconventional orthogonal multiple access (OMA) with OAM. The impact of the power\nallocation factor for OAM beam over SC is also analyzed. The analytical result\nis justified by simulation results which demonstrate that the proposed\nCNOMA-OAM provides higher SC compared to other schemes.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 09:31:48 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Amin", "Ahmed Al", ""], ["Narottama", "Bhaskara", ""], ["Shin", "Soo Young", ""]]}, {"id": "1906.09037", "submitter": "Xintao Huan", "authors": "Xintao Huan, Kyeong Soo Kim, Sanghyuk Lee, Eng Gee Lim, Alan Marshall", "title": "A Beaconless Asymmetric Energy-Efficient Time Synchronization Scheme for\n  Resource-Constrained Multi-Hop Wireless Sensor Networks", "comments": "12 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing number of WSN deployments based on a large number of\nbattery-powered, low-cost sensor nodes, which are limited in their computing\nand power resources, puts the focus of WSN time synchronization research on\nthree major aspects, i.e., accuracy, energy consumption and computational\ncomplexity. In the literature, the latter two aspects have not received much\nattention compared to the accuracy of WSN time synchronization. Especially in\nmulti-hop WSNs, intermediate gateway nodes are overloaded with tasks for not\nonly relaying messages but also a variety of computations for their offspring\nnodes as well as themselves. Therefore, not only minimizing the energy\nconsumption but also lowering the computational complexity while maintaining\nthe synchronization accuracy is crucial to the design of time synchronization\nschemes for resource-constrained sensor nodes. In this paper, focusing on the\nthree aspects of WSN time synchronization, we introduce a framework of reverse\nasymmetric time synchronization for resource-constrained multi-hop WSNs and\npropose a beaconless energy-efficient time synchronization scheme based on\nreverse one-way message dissemination. Experimental results with a WSN testbed\nbased on TelosB motes running TinyOS demonstrate that the proposed scheme\nconserves up to 95% energy consumption compared to the flooding time\nsynchronization protocol while achieving microsecond-level synchronization\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 10:01:11 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Huan", "Xintao", ""], ["Kim", "Kyeong Soo", ""], ["Lee", "Sanghyuk", ""], ["Lim", "Eng Gee", ""], ["Marshall", "Alan", ""]]}, {"id": "1906.09039", "submitter": "Xintao Huan", "authors": "Xintao Huan, Kyeong Soo Kim", "title": "Optimal Message Bundling with Delay and Synchronization Constraints in\n  Wireless Sensor Networks", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message bundling is an effective way to reduce the energy consumption for\nmessage transmissions in wireless sensor networks. However, bundling more\nmessages could increase both end-to-end delay and message transmission\ninterval; the former needs to be maintained within a certain value for\ntime-sensitive applications like environmental monitoring, while the latter\naffects time synchronization accuracy when the bundling includes\nsynchronization messages as well. Taking as an example a novel time\nsynchronization scheme recently proposed for energy efficiency, we propose an\noptimal message bundling approach to reduce the message transmissions while\nmaintaining the user-defined requirements on end-to-end delay and time\nsynchronization accuracy. Through translating the objective of joint\nmaintenance to an integer linear programming problem, we compute a set of\noptimal bundling numbers for the sensor nodes to constrain their link-level\ndelays, thereby achieve and maintain the required end-to-end delay and\nsynchronization accuracy while the message transmission is minimized.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 10:09:05 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Huan", "Xintao", ""], ["Kim", "Kyeong Soo", ""]]}, {"id": "1906.09086", "submitter": "Fatima Haouari", "authors": "Fatima Haouari, Emna Baccour, Aiman Erbad, Amr Mohamed, and Mohsen\n  Guizani", "title": "QoE-Aware Resource Allocation for Crowdsourced Live Streaming: A Machine\n  Learning Approach", "comments": "This paper was accepted in the Proceedings of ICC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.HC cs.LG cs.MM cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the tremendous technological advancement of personal devices and\nthe prevalence of wireless mobile network accesses, the world has witnessed an\nexplosion in crowdsourced live streaming. Ensuring a better viewers quality of\nexperience (QoE) is the key to maximize the audiences number and increase\nstreaming providers' profits. This can be achieved by advocating a\ngeo-distributed cloud infrastructure to allocate the multimedia resources as\nclose as possible to viewers, in order to minimize the access delay and video\nstalls. Moreover, allocating the exact needed resources beforehand avoids\nover-provisioning, which may lead to significant costs by the service\nproviders. In the contrary, under-provisioning might cause significant delays\nto the viewers. In this paper, we introduce a prediction driven resource\nallocation framework, to maximize the QoE of viewers and minimize the resource\nallocation cost. First, by exploiting the viewers locations available in our\nunique dataset, we implement a machine learning model to predict the viewers\nnumber near each geo-distributed cloud site. Second, based on the predicted\nresults that showed to be close to the actual values, we formulate an\noptimization problem to proactively allocate resources at the viewers\nproximity. Additionally, we will present a trade-off between the video access\ndelay and the cost of resource allocation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 10:57:06 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Haouari", "Fatima", ""], ["Baccour", "Emna", ""], ["Erbad", "Aiman", ""], ["Mohamed", "Amr", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1906.09159", "submitter": "Ahmed Al Amin", "authors": "A.A.Amin, M.B.Uddin, S.Y.Shin", "title": "Performance Enhancement of Hybrid SWIPT Protocol for Cooperative NOMA\n  Downlink Transmission", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time splitting and power splitting incorporating, a hybrid Simultaneous\nWireless Information and Power Transfer (SWIPT) based cooperative\nNon-Orthogonal Multiple Access (CNOMA) protocol is considered in this paper.\nCell center user of the CNOMA system acts as a relay to enhance the reliability\nof the cell edge user (CEU). SWIPT is considered to empower the relay operation\nto avoid the battery draining issue. To enhance the system performance in terms\nof ergodic sum capacity (ESC) and outage probabilities (OP), an integration of\nCNOMA strategy and hybrid SWIPT protocol for the downlink (DL) transmission is\nproposed here. By utilizing the idle link of hybrid SWIPT protocol an enhanced\nhybrid SWIPT protocol is proposed here to enhance the performance of CNOMA DL\ntransmission. Moreover, Maximal ratio combining is utilized as a diversity\ncombining technique at CEU to enhance the performance as well. The performance\nof the proposed protocol is examined in terms of ergodic sum capacity, outage\nprobabilities and energy efficiency. Finally, the analytical results are\njustified by the Monte-Carlo simulation. Numerical results demonstrate that the\nproposed protocol with effective CNOMA strategy achieves superior performance\nthan HS-CNOMA with selection combining.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 14:16:19 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Amin", "A. A.", ""], ["Uddin", "M. B.", ""], ["Shin", "S. Y.", ""]]}, {"id": "1906.09298", "submitter": "Behrooz Makki", "authors": "Oumer Teyeb, Ajmal Muhammad, Gunnar Mildh, Erik Dahlman, Filip Barac,\n  Behrooz Makki", "title": "Integrated Access Backhauled Networks", "comments": "Accepted for presentation in IEEE VTC fall 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G is finally here. Initial deployments are already operational in several\nmajor cities and first 5G-capable devices are being released. Though it is not\nlimited only to millimeter wave deployments, the main promise of 5G lies in the\nutilization of the high bandwidth available at high frequencies. However,\nhigh-frequency deployments are coverage-limited and require denser placement of\nbase stations, which can increase the cost significantly. One of the main\ncontributing factors to the cost is fiber deployment. Integrated access\nbackhauling (IAB), where part of the wireless spectrum is used for the backhaul\nconnection of base stations instead of fiber, is an attractive solution that\ncould make dense deployments economically viable. With this main objective,\n3GPP is in the process of standardizing multi-hop IAB networks. This paper\nprovides an overview of the main features of the multi-hop IAB 3GPP rel-16\nstandard and the rationale behind the design choices.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 19:22:22 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 08:39:34 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Teyeb", "Oumer", ""], ["Muhammad", "Ajmal", ""], ["Mildh", "Gunnar", ""], ["Dahlman", "Erik", ""], ["Barac", "Filip", ""], ["Makki", "Behrooz", ""]]}, {"id": "1906.09355", "submitter": "Samaneh Berenjian", "authors": "Samaneh Berenjian, Saeed Hajizadeh, Reza Ebrahimi Atani", "title": "An Incentive Security Model to Provide Fairness for Peer-to-Peer\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-Peer networks are designed to rely on resources of their own users.\nTherefore, resource management plays an important role in P2P protocols.\nTherefore, resource management plays an important role in P2P protocols. Early\nP2P networks did not use proper mechanisms to manage fairness. However, after\nseeing difficulties and rise of freeloaders in networks like Gnutella, the\nimportance of providing fairness for users have become apparent. In this paper,\nwe propose an incentive based security model which leads to a network\ninfrastructure that lightens the work of Seeders and makes Leechers to\ncontribute more. This method is able to prevent betrayals in Leecher-to-Leecher\ntransactions and more importantly, helps Seeders to be treated more fairly.\nThis is what other incentive methods such as Bittorrent are incapable of doing.\nAdditionally, by getting help from cryptography and combining it with our\nmethod, it is also possible to achieve secure channels, immune to spying, next\nto a fair network. The simulation results clearly show that how our proposed\napproach can overcome free-riding issue. In addition, our findings revealed\nthat our approach is able to provide an appropriate level of fairness for the\nusers and can decrease the download time.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 00:01:36 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 16:27:27 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 21:37:17 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Berenjian", "Samaneh", ""], ["Hajizadeh", "Saeed", ""], ["Atani", "Reza Ebrahimi", ""]]}, {"id": "1906.09434", "submitter": "Min Fu", "authors": "Min Fu, Yong Zhou, and Yuanming Shi", "title": "Intelligent Reflecting Surface for Downlink Non-Orthogonal Multiple\n  Access Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent reflecting surface (IRS) has recently been recognized as a\npromising technology to enhance the energy and spectrum efficiency of wireless\nnetworks by controlling the wireless medium with the configurable\nelectromagnetic materials. In this paper, we consider the downlink transmit\npower minimization problem for a IRS-empowered non-orthogonal multiple access\n(NOMA) network by jointly optimizing the transmit beamformers at the BS and the\nphase shift matrix at the IRS. However, this problem turns out to be a highly\nintractable non-convex bi-quadratic programming problem, for which an\nalternative minimization framework is proposed via solving the non-convex\nquadratic programs alternatively. We further develop a novel\ndifference-of-convex (DC) programming algorithm to solve the resulting\nnon-convex quadratic programs efficiently by lifting the quadratic programs\ninto rank-one constrained matrix optimization problems, followed by\nrepresenting the non-convex rank function as a DC function. Simulation results\ndemonstrate the performance gains of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 11:17:22 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 13:24:00 GMT"}, {"version": "v3", "created": "Sat, 29 Jun 2019 07:12:59 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Fu", "Min", ""], ["Zhou", "Yong", ""], ["Shi", "Yuanming", ""]]}, {"id": "1906.09466", "submitter": "Dmitry Namiot", "authors": "Dmitry Namiot, Manfred Sneps-Sneppe", "title": "On proximity versus geo-information systems", "comments": "for conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the replacement of widely used models of\ngeo-information systems with a new conception based on network proximity.\nGeo-information systems have attracted great attention and demonstrated big\nprogress in recent times, especially for mobile services. We can point out many\nobjective reasons for this. On the one hand, users require services, mainly at\ntheir location, and on the other hand, location determination has become easy,\nespecially due to the proliferation of smartphones. But at the same time, the\nactual geo-calculation are not needed by most of these services. For the\nmajority of geo-services, geo-coordinates are used only for searching and\norganizing data. And the meaning of the service is to search for information\ntied to the current location of the requesting party. In other words, in most\ncases, service refers to data near the current location. So, our idea is to\nbuild services directly on assessing to proximity and completely bypass\ngeo-calculations. It also opens the way for completely new services that were\nimpossible or difficult to implement with geo-computations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 16:05:15 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Namiot", "Dmitry", ""], ["Sneps-Sneppe", "Manfred", ""]]}, {"id": "1906.09520", "submitter": "Behzad Khamidehi", "authors": "Behzad Khamidehi and Elvino S. Sousa", "title": "Power Efficient Trajectory Optimization for the Cellular-Connected\n  Aerial Vehicles", "comments": "6 pages, 5 figures, to be presented in IEEE PIMRC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aerial vehicles have recently attracted significant attention in a variety of\ncommercial and civilian applications due to their high mobility, flexible\ndeployment and cost-effectiveness. To leverage these promising features, the\naerial users have to satisfy two critical requirements: First, they have to\nmaintain a reliable communication link to the ground base stations (GBSs)\nthroughout their flights, to support command and control data flows. Second,\nthe aerial vehicles have to minimize their propulsion power consumption to\nremain functional until the end of their mission. In this paper, we study the\ntrajectory optimization problem for an aerial user flying over an area\nincluding a set of GBSs. The objective of this problem is to find the\ntrajectory of the aerial user so that the total propulsion-related power\nconsumption of the aerial user is minimized while a cellular-connectivity\nconstraint is satisfied. This problem is a non-convex mixed integer non-linear\nproblem and hence, it is challenging to find the solution. To deal with, first,\nthe problem is relaxed and reformulated to a more mathematically tractable\nform. Then, using successive convex approximation (SCA) technique, an iterative\nalgorithm is proposed to convert the problem into a sequence of convex problems\nwhich can be solved efficiently.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 23:12:42 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Khamidehi", "Behzad", ""], ["Sousa", "Elvino S.", ""]]}, {"id": "1906.09546", "submitter": "Val\\'erio Rosset", "authors": "Tiago V. Ortiz and Bruno Kimura and J\\'o Ueyama and Val\\'erio Rosset", "title": "Experimental Security Analysis of Controller Software in SDNs: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The software defined networking paradigm relies on the programmability of the\nnetwork to automatically perform management and reconfiguration tasks. The\nresult of adopting this programmability feature is twofold: first by designing\nnew solutions and, second, by concurrently making room for the exploitation of\nnew security threats. As a malfunction in the controller software may lead to a\ncollapse of the network, assessing the security of solutions before their\ndeployment, is a major concern in SDNs. In light of this, we have conducted a\ncomprehensive review of the literature on the experimental security analysis of\nthe control plane in SDNs, with an emphasis on vulnerabilities of the\ncontroller software. Additionally, we have introduced a taxonomy of the\ntechniques found in the literature with regard to the experimental security\nanalysis of SDN controller software. Furthermore, a comparative study has been\ncarried out of existing experimental approaches considering the security\nrequirements defined by the Open Network Foundation (ONF). As a result, we\nhighlighted that there is a need for a standardization of the methodologies\nemployed for automated security analysis, that can meet the appropriate\nrequirements, and support the development of reliable and secure software for\nSDNs.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 03:32:11 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Ortiz", "Tiago V.", ""], ["Kimura", "Bruno", ""], ["Ueyama", "J\u00f3", ""], ["Rosset", "Val\u00e9rio", ""]]}, {"id": "1906.09548", "submitter": "Phuong-Duy Nguyen", "authors": "Phuong-Duy Nguyen and Vu Nguyen Ha and Long Bao Le", "title": "Computation Offloading and Resource Allocation for Backhaul Limited\n  Cooperative MEC Systems", "comments": null, "journal-ref": null, "doi": "10.1109/VTCFall.2019.8891244", "report-no": null, "categories": "cs.DC cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we jointly optimize computation offloading and resource\nallocation to minimize the weighted sum of energy consumption of all mobile\nusers in a backhaul limited cooperative MEC system with multiple fog servers.\nConsidering the partial offloading strategy and TDMA transmission at each base\nstation, the underlying optimization problem with constraints on maximum task\nlatency and limited computation resource at mobile users and fog servers is\nnon-convex. We propose to convexify the problem exploiting the relationship\namong some optimization variables from which an optimal algorithm is proposed\nto solve the resulting problem. We then present numerical results to\ndemonstrate the significant gains of our proposed design compared to\nconventional designs without exploiting cooperation among fog servers and a\ngreedy algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 03:40:17 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Nguyen", "Phuong-Duy", ""], ["Ha", "Vu Nguyen", ""], ["Le", "Long Bao", ""]]}, {"id": "1906.09550", "submitter": "Behzad Khamidehi", "authors": "Behzad Khamidehi and Elvino S. Sousa", "title": "Reinforcement Learning-Based Trajectory Design for the Aerial Base\n  Stations", "comments": "6 pages, 3 figures, to be presented in IEEE PIMRC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the trajectory optimization problem for a multi-aerial base\nstation (ABS) communication network is investigated. The objective is to find\nthe trajectory of the ABSs so that the sum-rate of the users served by each ABS\nis maximized. To reach this goal, along with the optimal trajectory design,\noptimal power and sub-channel allocation is also of great importance to support\nthe users with the highest possible data rates. To solve this complicated\nproblem, we divide it into two sub-problems: ABS trajectory optimization\nsub-problem, and joint power and sub-channel assignment sub-problem. Then,\nbased on the Q-learning method, we develop a distributed algorithm which solves\nthese sub-problems efficiently, and does not need significant amount of\ninformation exchange between the ABSs and the core network. Simulation results\nshow that although Q-learning is a model-free reinforcement learning technique,\nit has a remarkable capability to train the ABSs to optimize their trajectories\nbased on the received reward signals, which carry decent information from the\ntopology of the network.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 04:08:33 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 05:28:34 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Khamidehi", "Behzad", ""], ["Sousa", "Elvino S.", ""]]}, {"id": "1906.09571", "submitter": "Zhentang Shao", "authors": "Ao Huang, Mengxing Huang, Zhentang Shao, Xu Zhang, Di Wu and Chunjie\n  Cao", "title": "A Practical Marine Wireless Sensor Network Monitoring System Based on\n  LoRa and MQTT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the advocacy of the international community, more and more research\ntopics have been built around the ocean. This paper proposed an implementation\nscheme of marine wireless sensor network monitoring system based on LoRa and\nMQTT. Different from the traditional network architecture, the system was\nconstructed by combining with two network forms, and according to their\nrespective characteristics, the overall design followed the transition from\nLoRa to MQTT. We first used LoRa to interconnect the sensor nodes with the\ngateway, and on this basis, the collected data was sent to the server\nvisualization platform through MQTT, the backend management server would\ncontinuously refresh the monitoring page. At the same time, the client could\nuse a browser-based web application to directly access and call data for global\nmaritime information monitoring. In the future, we will further improve the\nsystem and optimize the algorithm, to achieve more dimensions and deeper\nexploration of the underwater world.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 09:41:33 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Huang", "Ao", ""], ["Huang", "Mengxing", ""], ["Shao", "Zhentang", ""], ["Zhang", "Xu", ""], ["Wu", "Di", ""], ["Cao", "Chunjie", ""]]}, {"id": "1906.09655", "submitter": "Harald {\\O}verby", "authors": "Harald {\\O}verby", "title": "Traffic Load Uniformity in Optical Packet Switched Networks", "comments": "3 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A crucial issue in Optical Packet Switched (OPS) networks is packet loss due\nto contentions. In this paper we study how traffic load uniformity influences\nthe packet loss in a single OPS node. Traffic load uniformity is a measure of\nthe load asymmetry a specific output link in an OPS node receives from its\ninput sources. We develop analytical models based on the Engset traffic model.\nAs a major contribution of this paper, we show that an asymmetric traffic\npattern results in less packet loss compared to a symmetric traffic pattern for\na single output link in an OPS node.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 21:40:14 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["\u00d8verby", "Harald", ""]]}, {"id": "1906.09701", "submitter": "Hui-Ming Wang", "authors": "Hui-Ming Wang, Xu Zhang, and Jia-Cheng Jiang", "title": "UAV-Involved Wireless Physical-Layer Secure Communications: Overview and\n  Research Directions", "comments": "18 pages, 6 figures, accepted by IEEE Wireless Communications for\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their flexible deployment and on-demand mobility, small-scale unmanned\naerial vehicles (UAVs) are anticipated to be involved in widespread\ncommunication applications in the forthcoming fifth-generation (5G) networks.\nHowever, the confidentiality of UAV communication applications is vulnerable to\nsecurity threats due to the broadcast nature and dominant line-of-sight (LoS)\nchannel conditions, and physical-layer security (PLS) technique can be applied\nfor secrecy performance enhancement in such a context. On the other hand, it is\nalso promising to exploit UAVs to cooperatively protect secure communications.\nThis article provides an overview of the recent research efforts on\nUAV-involved secure communications at the physical layer. We focus on the\ndesign of secure transmission schemes according to different roles of UAVs and\nthe optimization of introduced degrees of freedom (DoFs) by the unique\ncharacteristics of UAVs. We also propose some future research directions on\nthis topic.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 03:17:38 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wang", "Hui-Ming", ""], ["Zhang", "Xu", ""], ["Jiang", "Jia-Cheng", ""]]}, {"id": "1906.09714", "submitter": "Aditya Vikram Singh", "authors": "Aditya V. Singh, Kunal N. Chaudhury", "title": "On Uniquely Registrable Networks", "comments": "10 pages, 8 figures, accepted for publication in the IEEE\n  Transactions on Network Science and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a network with $N$ nodes in $d$-dimensional Euclidean space, and $M$\nsubsets of these nodes $P_1,\\cdots,P_M$. Assume that the nodes in a given $P_i$\nare observed in a local coordinate system. The registration problem is to\ncompute the coordinates of the $N$ nodes in a global coordinate system, given\nthe information about $P_1,\\cdots,P_M$ and the corresponding local coordinates.\nThe network is said to be uniquely registrable if the global coordinates can be\ncomputed uniquely (modulo Euclidean transforms). We formulate a necessary and\nsufficient condition for a network to be uniquely registrable in terms of\nrigidity of the body graph of the network. A particularly simple\ncharacterization of unique registrability is obtained for planar networks.\nFurther, we show that $k$-vertex-connectivity of the body graph is equivalent\nto quasi $k$-connectivity of the bipartite correspondence graph of the network.\nAlong with results from rigidity theory, this helps us resolve a recent\nconjecture due to Sanyal et al. (IEEE TSP, 2017) that quasi $3$-connectivity of\nthe correspondence graph is both necessary and sufficient for unique\nregistrability in two dimensions. We present counterexamples demonstrating that\nwhile quasi $(d+1)$-connectivity is necessary for unique registrability in any\ndimension, it fails to be sufficient in three and higher dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 04:17:20 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Singh", "Aditya V.", ""], ["Chaudhury", "Kunal N.", ""]]}, {"id": "1906.09715", "submitter": "Ayush Kumar", "authors": "Ayush Kumar and Teng Joon Lim", "title": "EDIMA: Early Detection of IoT Malware Network Activity Using Machine\n  Learning Techniques", "comments": null, "journal-ref": "Proceedings of the IEEE 5th World Forum on Internet of Things\n  (WF-IoT) 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread adoption of Internet of Things has led to many security\nissues. Post the Mirai-based DDoS attack in 2016 which compromised IoT devices,\na host of new malware using Mirai's leaked source code and targeting IoT\ndevices have cropped up, e.g. Satori, Reaper, Amnesia, Masuta etc. These\nmalware exploit software vulnerabilities to infect IoT devices instead of open\nTELNET ports (like Mirai) making them more difficult to block using existing\nsolutions such as firewalls. In this research, we present EDIMA, a distributed\nmodular solution which can be used towards the detection of IoT malware network\nactivity in large-scale networks (e.g. ISP, enterprise networks) during the\nscanning/infecting phase rather than during an attack. EDIMA employs machine\nlearning algorithms for edge devices' traffic classification, a packet traffic\nfeature vector database, a policy module and an optional packet sub-sampling\nmodule. We evaluate the classification performance of EDIMA through testbed\nexperiments and present the results obtained.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 04:18:38 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Kumar", "Ayush", ""], ["Lim", "Teng Joon", ""]]}, {"id": "1906.09746", "submitter": "Nadege Varsier", "authors": "Sandrine Roblot, Mythri Hunukumbure, Nad\\`ege Varsier, Elena Santiago,\n  Yu Bao, Serge Langouet, Marie-H\\'el\\`ene Hamon, Sebastien Jeux", "title": "Techno-economic analyses for vertical use cases in the 5G domain", "comments": null, "journal-ref": "EuCNC ONE5G special session, Jun 2019, Valencia, Spain", "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides techno-economic analyses on the network deployments to\ncover 4 key verticals, under 5G-NR. These verticals, namely Automotive, Smart\ncity, Long range connectivity and Disaster and emergency support, were chosen\nto reflect the ONE5G project objective of investigating environments from\ndensely populated cities (''Megacity'') to large underserved areas. The work\npresented covers the network deployment framework including common\ncentralization strategies and the main cost factors. Initial results presented\nfor long range connectivity and emergency support networks provide the cost\ntrade-offs in different deployment options and cost sensitivity to some of the\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 06:59:17 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Roblot", "Sandrine", ""], ["Hunukumbure", "Mythri", ""], ["Varsier", "Nad\u00e8ge", ""], ["Santiago", "Elena", ""], ["Bao", "Yu", ""], ["Langouet", "Serge", ""], ["Hamon", "Marie-H\u00e9l\u00e8ne", ""], ["Jeux", "Sebastien", ""]]}, {"id": "1906.09779", "submitter": "Niklas Carlsson", "authors": "Niklas Carlsson and Derek Eager", "title": "Had You Looked Where I'm Looking: Cross-user Similarities in Viewing\n  Behavior for 360$^{\\circ}$ Video and Caching Implications", "comments": "13+ pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand and usage of 360$^{\\circ}$ video services are expected to\nincrease. However, despite these services being highly bandwidth intensive, not\nmuch is known about the potential value that basic bandwidth saving techniques\nsuch as server or edge-network on-demand caching (e.g., in a CDN) could have\nwhen used for delivery of such services. This problem is both important and\ncomplicated as client-side solutions have been developed that split the full\n360$^{\\circ}$ view into multiple tiles, and adapt the quality of the downloaded\ntiles based on the user's expected viewing direction and bandwidth conditions.\nTo better understand the potential bandwidth savings that caching-based\ntechniques may offer for this context, this paper presents the first\ncharacterization of the similarities in the viewing directions of users\nwatching the same 360$^{\\circ}$ video, the overlap in viewports of these users\n(the area of the full 360$^{\\circ}$ view they actually see), and the potential\ncache hit rates for different video categories, network conditions, and\naccuracy levels in the prediction of future viewing direction when prefetching.\nThe results provide substantial insight into the conditions under which overlap\ncan be considerable and caching effective, and can inform the design of new\ncaching system policies tailored for 360$^{\\circ}$ video.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:31:03 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Carlsson", "Niklas", ""], ["Eager", "Derek", ""]]}, {"id": "1906.09841", "submitter": "Tianle Liu", "authors": "Tianle Liu, Jun Tong, Qinghua Guo, Jiangtao Xi, Yanguang Yu, and\n  Zhitao Xiao", "title": "On the Performance of Massive MIMO Systems With Low-Resolution ADCs Over\n  Rician Fading Channels", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers uplink massive multiple-input multiple-output (MIMO)\nsystems with lowresolution analog-to-digital converters (ADCs) over Rician\nfading channels. Maximum-ratio-combining (MRC) and zero-forcing (ZF) receivers\nare considered under the assumption of perfect and imperfect channel state\ninformation (CSI). Low-resolution ADCs are considered for both data detection\nand channel estimation, and the resulting performance is analyzed. Asymptotic\napproximations of the spectrum efficiency (SE) for large systems are derived\nbased on random matrix theory. With these results, we can provide insights into\nthe trade-offs between the SE and the ADC resolution and study the influence of\nthe Rician K-factors on the performance. It is shown that a large value of\nK-factors may lead to better performance and alleviate the influence of\nquantization noise on channel estimation. Moreover, we investigate the power\nscaling laws for both receivers under imperfect CSI and it shows that when the\nnumber of base station (BS) antennas is very large, without loss of SE\nperformance, the transmission power can be scaled by the number of BS antennas\nfor both receivers while the overall performance is limited by the resolution\nof ADCs. The asymptotic analysis is validated by numerical results. Besides, it\nis also shown that the SE gap between the two receivers is narrowed down when\nthe K-factor is increased. We also show that ADCs with moderate resolutions\nlead to better energy efficiency (EE) than that with high-resolution or\nextremely low-resolution ADCs and using ZF receivers achieve higher EE as\ncompared with the MRC receivers.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 10:34:40 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Liu", "Tianle", ""], ["Tong", "Jun", ""], ["Guo", "Qinghua", ""], ["Xi", "Jiangtao", ""], ["Yu", "Yanguang", ""], ["Xiao", "Zhitao", ""]]}, {"id": "1906.09918", "submitter": "Furqan Jameel", "authors": "Furqan Jameel, Zheng Chang, Jun Huang, and Tapani Ristaniemi", "title": "Internet of Autonomous Vehicles: Architecture, Features, and\n  Socio-Technological Challenges", "comments": "11 Pages, 4 Figures, 2 Tables, IoV, IoAV, Autonomous Vehicles", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobility is the backbone of urban life and a vital economic factor in the\ndevelopment of the world. Rapid urbanization and the growth of mega-cities is\nbringing dramatic changes in the capabilities of vehicles. Innovative solutions\nlike autonomy, electrification, and connectivity are on the horizon. How, then,\nwe can provide ubiquitous connectivity to the legacy and autonomous vehicles?\nThis paper seeks to answer this question by combining recent leaps of\ninnovation in network virtualization with remarkable feats of wireless\ncommunications. To do so, this paper proposes a novel paradigm called the\nInternet of autonomous vehicles (IoAV). We begin painting the picture of IoAV\nby discussing the salient features, and applications of IoAV which is followed\nby a detailed discussion on the key enabling technologies. Next, we describe\nthe proposed layered architecture of IoAV and uncover some critical functions\nof each layer. This is followed by the performance evaluation of IoAV which\nshows the significant advantage of the proposed architecture in terms of\ntransmission time and energy consumption. Finally, to best capture the benefits\nof IoAV, we enumerate some social and technological challenges and explain how\nsome unresolved issues can disrupt the widespread use of autonomous vehicles in\nthe future.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 13:02:20 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Jameel", "Furqan", ""], ["Chang", "Zheng", ""], ["Huang", "Jun", ""], ["Ristaniemi", "Tapani", ""]]}, {"id": "1906.10203", "submitter": "MD Zadid Khan", "authors": "Zadid Khan, Mashrur Chowdhury, Mhafuzul Islam, Chin-Ya Huang and\n  Mizanur Rahman", "title": "Long Short-Term Memory Neural Networks for False Information Attack\n  Detection in Software-Defined In-Vehicle Network", "comments": "11 Pages, 6 Figures, 7 Tables, submitted for possible publication in\n  IEEE Transaction on Vehicular Technology, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modern vehicle contains many electronic control units (ECUs), which\ncommunicate with each other through the in-vehicle network to ensure vehicle\nsafety and performance. Emerging Connected and Automated Vehicles (CAVs) will\nhave more ECUs and coupling between them due to the vast array of additional\nsensors, advanced driving features and Vehicle-to-Everything (V2X)\nconnectivity. Due to the connectivity, CAVs will be more vulnerable to remote\nattackers. In this study, we developed a software-defined in-vehicle Ethernet\nnetworking system that provides security against false information attacks. We\nthen created an attack model and attack datasets for false information attacks\non brake-related ECUs. After analyzing the attack dataset, we found that the\nfeatures of the dataset are time-series that have sequential variation\npatterns. Therefore, we subsequently developed a long short term memory (LSTM)\nneural network based false information attack/anomaly detection model for the\nreal-time detection of anomalies within the in-vehicle network. This attack\ndetection model can detect false information with an accuracy, precision and\nrecall of 95%, 95% and 87%, respectively, while satisfying the real-time\ncommunication and computational requirements.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 19:54:49 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 17:33:46 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Khan", "Zadid", ""], ["Chowdhury", "Mashrur", ""], ["Islam", "Mhafuzul", ""], ["Huang", "Chin-Ya", ""], ["Rahman", "Mizanur", ""]]}, {"id": "1906.10265", "submitter": "Mubeen Zulfiqar", "authors": "Nashid Shahriar, Sepehr Taeb, Shihabur Rahman Chowdhury, Mubeen\n  Zulfiqar, Massimo Tornatore, Raouf Boutaba, Jeebak Mitra, Mahdi Hemmati", "title": "Reliable Slicing of 5G Transport Networks with Dedicated Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 5G networks, slicing allows partitioning of network resources to meet\nstringent end-to-end service requirements across multiple network segments,\nfrom access to transport. These requirements are shaping technical evolution in\neach of these segments. In particular, the transport segment is currently\nevolving in the direction of the so-called elastic optical networks (EONs), a\nnew generation of optical networks supporting a flexible optical-spectrum grid\nand novel elastic transponder capabilities. In this paper, we focus on the\nreliability of 5G transport-network slices in EON. Specifically, we consider\nthe problem of slicing 5G transport networks, i.e., establishing virtual\nnetworks on 5G transport, while providing dedicated protection. As dedicated\nprotection requires large amount of backup resources, our proposed solution\nincorporates two techniques to reduce backup resources: (i) bandwidth\nsqueezing, i.e., providing a reduced protection bandwidth with respect to the\noriginal request; and (ii) survivable multi-path provisioning. We leverage the\ncapability of EONs to fine tune spectrum allocation and adapt modulation format\nand Forward Error Correction (FEC) for allocating rightsize spectrum resources\nto network slices. Our numerical evaluation over realistic case-study network\ntopologies quantifies the spectrum savings achieved by employing EON over\ntraditional fixed-grid optical networks, and provides new insights on the\nimpact of bandwidth squeezing and multi-path provisioning on spectrum\nutilization.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 23:19:20 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Shahriar", "Nashid", ""], ["Taeb", "Sepehr", ""], ["Chowdhury", "Shihabur Rahman", ""], ["Zulfiqar", "Mubeen", ""], ["Tornatore", "Massimo", ""], ["Boutaba", "Raouf", ""], ["Mitra", "Jeebak", ""], ["Hemmati", "Mahdi", ""]]}, {"id": "1906.10266", "submitter": "Klaus Schneider", "authors": "Klaus Schneider, Beichuan Zhang, and Lotfi Benmohamed", "title": "Hop-by-Hop Multipath Routing: Choosing the Right Nexthop Set", "comments": "Find the source code here:\n  https://github.com/schneiderklaus/ndnSIM-routing", "journal-ref": null, "doi": null, "report-no": "NDN Technical Report, NDN-0067", "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet can be made more efficient and robust with hop-by-hop multipath\nrouting: Each router on the path can split packets between multiple nexthops in\norder to 1) avoid failed links and 2) reduce traffic on congested links. Before\ndeciding how to split traffic, one first needs to decide which nexthops to\nallow at each step. In this paper, we investigate the requirements and\ntrade-offs for making this choice.\n  Most related work chooses the viable nexthops by applying the \"Downward\nCriterion\", i.e., only adding nexthops that lead closer to the destination; or\nmore generally by creating a Directed Acyclic Graph (DAG) for each destination.\nWe show that a DAG's nexthop options are necessarily limited, and that, by\nusing certain links in both directions (per destination), we can add further\nnexthops while still avoiding loops. Our solution LFID (Loop-Free\nInport-Dependent) routing, though having a slightly higher time complexity,\nleads to both a higher number of and shorter potential paths than related work.\nLFID thus protects against a higher percentage of single and multiple failures\n(or congestions) and comes close to the performance of arbitrary source\nrouting.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 23:29:20 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Schneider", "Klaus", ""], ["Zhang", "Beichuan", ""], ["Benmohamed", "Lotfi", ""]]}, {"id": "1906.10370", "submitter": "Miguel Sepulcre", "authors": "Rafael Molina-Masegosa, Miguel Sepulcre and Javier Gozalvez", "title": "Geo-Based Scheduling for C-V2X Networks", "comments": null, "journal-ref": "IEEE Transactions on Vehicular Technology, Volume 68, Issue 9, pp.\n  8397 - 8407, September 2019", "doi": "10.1109/TVT.2019.2924698", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular Vehicle-to-Everything (C-V2X) networks can operate without cellular\ninfrastructure support. Vehicles can autonomously select their radio resources\nusing the sensing-based Semi-Persistent Scheduling (SPS) algorithm specified by\nthe Third Generation Partnership Project (3GPP). The sensing nature of the SPS\nscheme makes C-V2X communications prone to the well-known hidden-terminal\nproblem. To address this problem, this paper proposes a novel geo-based\nscheduling scheme that allows vehicles to autonomously select their radio\nresources based on the location and ordering of neighboring vehicles on the\nroad. The proposed scheme results in an implicit resource selection\ncoordination between vehicles (even with those outside the sensing range) that\nreduces packet collisions. This paper evaluates analytically and through\nsimulations the proposed scheduling scheme. The obtained results demonstrate\nthat it reduces packet collisions and significantly increases the C-V2X\nperformance compared to when using the sensing-based SPS scheme.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 08:12:28 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Molina-Masegosa", "Rafael", ""], ["Sepulcre", "Miguel", ""], ["Gozalvez", "Javier", ""]]}, {"id": "1906.10434", "submitter": "Xiaohu Ge", "authors": "Ran Zi, Jia Liu, Liang Gu, Xiaohu Ge", "title": "Enabling security and High Energy Efficiency in the Internet of Things\n  with Massive MIMO Hybrid Precoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the security of Internet of Things (IoT) has been an issue of great\nconcern. Physical layer security methods can help IoT networks achieve\ninformation-theoretical secrecy. Nevertheless, utilizing physical security\nmethods, such as artificial noise (AN) may cost extra power, which leads to low\nsecure energy efficiency. In this paper, the hybrid precoding technique is\nemployed to improve the secure energy efficiency of the IoT network. A secure\nenergy efficiency optimization problem is formulated for the IoT network. Due\nto the non-convexity of the problem and the feasible domain, the problem is\nfirstly transformed into a tractable suboptimal form. Then a secure hybrid\nprecoding energy efficient (SEEHP) algorithm is proposed to tackle the problem.\nNumerical results indicate that the proposed SEEHP algorithm achieves higher\nsecure energy efficiency compared with three existing physical layer security\nalgorithms, especially when the number of transmit antennas is large.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 10:18:59 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zi", "Ran", ""], ["Liu", "Jia", ""], ["Gu", "Liang", ""], ["Ge", "Xiaohu", ""]]}, {"id": "1906.10468", "submitter": "Adam Lev-Libfeld", "authors": "Adam Lev-Libfeld, Alexander Margolin", "title": "Fast Data: Moving beyond from Big Data's map-reduce", "comments": null, "journal-ref": "journal of geopython no. 1, jun 20 2016", "doi": null, "report-no": null, "categories": "cs.DC cs.GL cs.NI cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data may not be the solution many are looking for. The latest rise of Big\nData methods and systems is partly due to the new abilities these techniques\nprovide, partly to the simplicity of the software design and partly because the\nbuzzword itself has value to investors and clients. That said, popularity is\nnot a measure for suitability and the Big Data approach might not be the best\nsolution, or even an applicable one, to many common problems. Namely, time\ndependent problems whose solution may be bound or cached in any manner can\nbenefit greatly from moving to partly stateless, flow oriented functions and\ndata models. This paper presents such a model to substitute the traditional\nmap-shuffle-reduce models.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 12:13:27 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Lev-Libfeld", "Adam", ""], ["Margolin", "Alexander", ""]]}, {"id": "1906.10540", "submitter": "Zhentang Shao", "authors": "Zhen-tang Shao, Meng-xing Huang, Di Wu, Xu Zhang and Ao Huang", "title": "Design of a Simplified Wireless Sensor Network Node based on MQTT\n  Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MQTT protocol is a publish/subscribe message protocol based on TCP/IP\nprotocol. It has the characteristics of low power consumption, scalability,\nopenness and simplicity. HTTP protocol is an open and low-cost request/reply\nmessage protocol based on TCP/IP protocol. It is the main protocol of Internet\ncommunication, but it is not suitable for the environment of computing,\nprocessing and bandwidth limited. In this paper, a simplified wireless sensor\nnetwork node was designed based on MQTT protocol. The node was designed to use\nthe Arduino development environment and use the WiFi for networking. It has the\ncharacteristics of simple structure, low power consumption and so on. The\ndesign can be widely used in smart home, environmental monitoring and medical\napplications, and is the main contents of the Internet of things (IoT).\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 09:38:06 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Shao", "Zhen-tang", ""], ["Huang", "Meng-xing", ""], ["Wu", "Di", ""], ["Zhang", "Xu", ""], ["Huang", "Ao", ""]]}, {"id": "1906.10549", "submitter": "Emmanouil Fountoulakis", "authors": "Emmanouil Fountoulakis, Qi Liao, Nikolaos Pappas", "title": "An End-to-End Performance Analysis for Service Chaining in a Virtualized\n  Network", "comments": "30 pages. arXiv admin note: substantial text overlap with\n  arXiv:1811.02330", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future mobile networks supporting Internet of Things are expected to provide\nboth high throughput and low latency to user-specific services. One way to\novercome this challenge is to adopt Network Function Virtualization (NFV) and\nMulti-access Edge Computing (MEC). Besides latency constraints, these services\nmay have strict function chaining requirements. The distribution of network\nfunctions over different hosts and more flexible routing caused by service\nfunction chaining raise new challenges for end-to-end performance analysis. In\nthis paper, as a first step, we analyze an end-to-end communications system\nthat consists of both MEC servers and a server at the core network hosting\ndifferent types of virtual network functions. We develop a queueing model for\nthe performance analysis of the system consisting of both processing and\ntransmission flows. We propose a method in order to derive analytical\nexpressions of the performance metrics of interest. Then, we show how to apply\nthe similar method to an extended larger system and derive a stochastic model\nfor such systems. We observe that the simulation and analytical results\ncoincide. By evaluating the system under different scenarios, we provide\ninsights for the decision making on traffic flow control and its impact on\ncritical performance metrics.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 12:12:12 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Fountoulakis", "Emmanouil", ""], ["Liao", "Qi", ""], ["Pappas", "Nikolaos", ""]]}, {"id": "1906.10641", "submitter": "Anis Koubaa", "authors": "Anis Koubaa, Azza Allouch, Maram Alajlan, Yasir Javed, Abdelfettah\n  Belghith, Mohamed Khalgui", "title": "Micro Air Vehicle Link (MAVLink) in a Nutshell: A Survey", "comments": "Accepted in IEEE Access, June 2019", "journal-ref": "IEEE Access, 2019", "doi": null, "report-no": "RIOTU-TR-08", "categories": "cs.RO cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Micro Air Vehicle Link (MAVLink in short) is a communication protocol for\nunmanned systems (e.g., drones, robots). It specifies a comprehensive set of\nmessages exchanged between unmanned systems and ground stations. This protocol\nis used in major autopilot systems, mainly ArduPilot and PX4, and provides\npowerful features not only for monitoring and controlling unmanned systems\nmissions but also for their integration into the Internet. However, there is no\ntechnical survey and/or tutorial in the literature that presents these features\nor explains how to make use of them. Most of the references are online\ntutorials and basic technical reports, and none of them presents comprehensive\nand systematic coverage of the protocol. In this paper, we address this gap,\nand we propose an overview of the MAVLink protocol, the difference between its\nversions, and its potential in enabling Internet connectivity to unmanned\nsystems. We also discuss the security aspects of MAVLink. To the best of our\nknowledge, this is the first technical survey and tutorial on the MAVLink\nprotocol, which represents an important reference for unmanned systems users\nand developers.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 09:41:52 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Koubaa", "Anis", ""], ["Allouch", "Azza", ""], ["Alajlan", "Maram", ""], ["Javed", "Yasir", ""], ["Belghith", "Abdelfettah", ""], ["Khalgui", "Mohamed", ""]]}, {"id": "1906.10766", "submitter": "Cedric Westphal", "authors": "Richard Li, Kiran Makhijani, Hamed Yousefi, Cedric Westphal, Lijun\n  Dong, Tim Wauters, Filip De Turck", "title": "A Framework for Qualitative Communications Using Big Packet Protocol", "comments": "Accepted in NEAT workshop, ACM SIGCOMM, August 2019, Beijing, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current Internet architecture, a packet is a minimal or fundamental\nunit upon which different actions such as classification,forwarding, or\ndiscarding are performed by the network nodes.When faced with constrained or\npoor network conditions, a packet is subjected to undesirable drops and\nre-transmissions, resulting in unpredictable delays and subsequent traffic\noverheads in the network. Alternately, we introduce qualitative communication\nservices which allow partial, yet timely, delivery of a packet instead of\ndropping it entirely. These services allow breaking down packet payloads into\nsmaller units (called chunks), enabling much finer granularity of bandwidth\nutilization.\n  We propose Packet Wash as a new operation in forwarding nodes to support\nqualitative services. Upon packet error or network congestion, the forwarding\nnode selectively removes some chunk(s)from the payload based on the\nrelationship among the chunks or the individual significance level of each\nchunk. We also present a qualitative communication framework as well as a\nPacket Wash directive implemented in a newly evolved data plane\ntechnology,called Big Packet Protocol (BPP)\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 21:46:01 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Li", "Richard", ""], ["Makhijani", "Kiran", ""], ["Yousefi", "Hamed", ""], ["Westphal", "Cedric", ""], ["Dong", "Lijun", ""], ["Wauters", "Tim", ""], ["De Turck", "Filip", ""]]}, {"id": "1906.10860", "submitter": "Adam Lev-Libfeld", "authors": "Adam Lev-Libfeld", "title": "Lawn: an Unbound Low Latency Timer Data Structure for Large Scale, High\n  Throughput Systems", "comments": "6 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As demand for Real-Time applications rises among the general public, the\nimportance of enabling large-scale, unbound algorithms to solve conventional\nproblems with low to no latency is critical for product viability. Timer\nalgorithms are prevalent in the core mechanisms behind operating systems,\nnetwork protocol implementation, stream processing, and several database\ncapabilities. This paper presents a field-tested algorithm for low latency,\nunbound range timer structure, based upon the well excepted Timing Wheel\nalgorithm. Using a set of queues hashed by TTL, the algorithm allows for a\nsimpler implementation, minimal overhead no overflow and no performance\ndegradation in comparison to the current state of the algorithms under typical\nuse cases.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 06:16:13 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 09:50:24 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lev-Libfeld", "Adam", ""]]}, {"id": "1906.10878", "submitter": "Volodymyr Sokolov", "authors": "Mahyar TajDini and Volodymyr Sokolov and Volodymyr Buriachok", "title": "Men-in-the-Middle Attack Simulation on Low Energy Wireless Devices using\n  Software Define Radio", "comments": null, "journal-ref": "Mathematics. Information Technologies. Education (MoMLeT&DS), 2019", "doi": "10.5281/zenodo.3256223", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The article presents a method of organizing men-in-the-middle attack and\npenetration test on Bluetooth Low Energy devices and ZigBee packets using\nsoftware define radio with sniffing and spoofing packets, capture and analysis\ntechniques on wireless waves with the focus on Bluetooth. The paper contains\nthe analysis of the latest scientific work in this area, provides a comparative\nanalysis of SDRs and the rationale for the choice of hardware, gives the\nsequence of actions for collecting wireless data packets and data collection\nfrom ZigBee and BLE devices, and analyzes ways to improve captured wireless\npacket analysis techniques. For the study collected experimental setup, the\nresults of which are analyzed in real time. The collected wireless data packets\nare compared with those sent. The result of the experiment shows the weaknesses\nof local wireless networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 07:21:05 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["TajDini", "Mahyar", ""], ["Sokolov", "Volodymyr", ""], ["Buriachok", "Volodymyr", ""]]}, {"id": "1906.10885", "submitter": "Maciej Besta", "authors": "Maciej Besta, Marcel Schneider, Karolina Cynk, Marek Konieczny, Erik\n  Henriksson, Salvatore Di Girolamo, Ankit Singla, Torsten Hoefler", "title": "FatPaths: Routing in Supercomputers and Data Centers when Shortest Paths\n  Fall Short", "comments": null, "journal-ref": "Proceedings of the ACM/IEEE International Conference on High\n  Performance Computing, Networking, Storage and Analysis (SC20), November 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce FatPaths: a simple, generic, and robust routing architecture\nthat enables state-of-the-art low-diameter topologies such as Slim Fly to\nachieve unprecedented performance. FatPaths targets Ethernet stacks in both HPC\nsupercomputers as well as cloud data centers and clusters. FatPaths exposes and\nexploits the rich (\"fat\") diversity of both minimal and non-minimal paths for\nhigh-performance multi-pathing. Moreover, FatPaths uses a redesigned \"purified\"\ntransport layer that removes virtually all TCP performance issues (e.g., the\nslow start), and incorporates flowlet switching, a technique used to prevent\npacket reordering in TCP networks, to enable very simple and effective load\nbalancing. Our design enables recent low-diameter topologies to outperform\npowerful Clos designs, achieving 15% higher net throughput at 2x lower latency\nfor comparable cost. FatPaths will significantly accelerate Ethernet clusters\nthat form more than 50% of the Top500 list and it may become a standard routing\nscheme for modern topologies.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 07:39:35 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 15:54:29 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Besta", "Maciej", ""], ["Schneider", "Marcel", ""], ["Cynk", "Karolina", ""], ["Konieczny", "Marek", ""], ["Henriksson", "Erik", ""], ["Di Girolamo", "Salvatore", ""], ["Singla", "Ankit", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1906.10893", "submitter": "Yang Zhao", "authors": "Yang Zhao, Jun Zhao, Linshan Jiang, Rui Tan, Dusit Niyato, Zengxiang\n  Li, Lingjuan Lyu, Yingbo Liu", "title": "Privacy-Preserving Blockchain-Based Federated Learning for IoT Devices", "comments": "This paper appears in IEEE Internet of Things Journal (IoT-J)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Home appliance manufacturers strive to obtain feedback from users to improve\ntheir products and services to build a smart home system. To help manufacturers\ndevelop a smart home system, we design a federated learning (FL) system\nleveraging the reputation mechanism to assist home appliance manufacturers to\ntrain a machine learning model based on customers' data. Then, manufacturers\ncan predict customers' requirements and consumption behaviors in the future.\nThe working flow of the system includes two stages: in the first stage,\ncustomers train the initial model provided by the manufacturer using both the\nmobile phone and the mobile edge computing (MEC) server. Customers collect data\nfrom various home appliances using phones, and then they download and train the\ninitial model with their local data. After deriving local models, customers\nsign on their models and send them to the blockchain. In case customers or\nmanufacturers are malicious, we use the blockchain to replace the centralized\naggregator in the traditional FL system. Since records on the blockchain are\nuntampered, malicious customers or manufacturers' activities are traceable. In\nthe second stage, manufacturers select customers or organizations as miners for\ncalculating the averaged model using received models from customers. By the end\nof the crowdsourcing task, one of the miners, who is selected as the temporary\nleader, uploads the model to the blockchain. To protect customers' privacy and\nimprove the test accuracy, we enforce differential privacy on the extracted\nfeatures and propose a new normalization technique. We experimentally\ndemonstrate that our normalization technique outperforms batch normalization\nwhen features are under differential privacy protection. In addition, to\nattract more customers to participate in the crowdsourcing FL task, we design\nan incentive mechanism to award participants.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 07:53:13 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 16:18:12 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 12:44:38 GMT"}, {"version": "v4", "created": "Mon, 1 Feb 2021 11:25:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhao", "Yang", ""], ["Zhao", "Jun", ""], ["Jiang", "Linshan", ""], ["Tan", "Rui", ""], ["Niyato", "Dusit", ""], ["Li", "Zengxiang", ""], ["Lyu", "Lingjuan", ""], ["Liu", "Yingbo", ""]]}, {"id": "1906.10993", "submitter": "Idris Badmus Mr", "authors": "Idris Badmus, Marja Matinmikko-Blue, and Jaspreet Singh Walia", "title": "Network Slicing Management Technique for Local 5G Micro-Operator\n  Deployments", "comments": "Conference in Proc. of 2019 International Symposium on Wireless\n  Communication Systems (ISWCS) At Oulu, Finland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local 5G networks are expected to emerge to serve different vertical sectors\nspecific requirements. These networks can be deployed by traditional mobile\nnetwork operators or entrant local operators. With a large number of verticals\nwith different service requirements, while considering the network deployment\ncost in a single local area, it will not be economically feasible to deploy\nseparate networks for each vertical. Thus, locally deployed 5G networks (aka\nmicro operator networks) that can serve multiple verticals with multiple\ntenants in a location have gained increasing attention. Network slicing will\nenable a 5G micro-operator network to efficiently serve the multiple verticals\nand their tenants with different network requirements. This paper addresses how\nnetwork slicing management functions can be used to implement, orchestrate and\nmanage network slicing in different deployments of a local 5G micro-operator\nincluding the serving of closed, open and mixed customer groups. The paper\nproposes a descriptive technique by which different network slicing management\nfunctionalities defined by 3GPP can be used in coordination to create,\norchestrate and manage network slicing for different deployment scenarios of a\nmicro-operator. This is based on the network slice instance configuration type\nthat can exist for each scenario. A network slice formation sequence is\ndeveloped for the closed micro operator network to illustrate the tasks of the\nmanagement functions. The results indicate that network slicing management\nplays a key role in designing local 5G networks that can serve different\ncustomer groups in the verticals.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 11:50:22 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 10:33:19 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Badmus", "Idris", ""], ["Matinmikko-Blue", "Marja", ""], ["Walia", "Jaspreet Singh", ""]]}, {"id": "1906.11102", "submitter": "Onel Luis Alcaraz L\\'opez", "authors": "Onel L. Alcaraz L\\'opez, Hirley Alves, Pedro H. J. Nardelli, Matti\n  Latva-aho", "title": "Hybrid Resource Scheduling for Aggregation in Massive Machine-type\n  Communication Networks", "comments": "10 pags, 8 figs, accepted at Ad Hoc Networks journal. arXiv admin\n  note: text overlap with arXiv:1708.07691", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data aggregation is a promising approach to enable massive machine-type\ncommunication (mMTC). Here, we first characterize the aggregation phase where a\nmassive number of machine-type devices transmits to their respective\naggregator. By using non-orthogonal multiple access (NOMA), we present a hybrid\naccess scheme where several machine-type devices (MTDs) share the same\northogonal channel. Then, we assess the relaying phase where the aggregatted\ndata is forwarded to the base station. The system performance is investigated\nin terms of average number of MTDs that are simultaneously served under\nimperfect successive interference cancellation (SIC) at the aggregator for two\nscheduling schemes, namely random resource scheduling (RRS) and\nchannel-dependent resource scheduling (CRS), which is then used to assess the\nperformance of data forwarding phase.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 11:17:30 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["L\u00f3pez", "Onel L. Alcaraz", ""], ["Alves", "Hirley", ""], ["Nardelli", "Pedro H. J.", ""], ["Latva-aho", "Matti", ""]]}, {"id": "1906.11135", "submitter": "Fahad Qasmi", "authors": "Fahad Qasmi, Mohammad Shehab, Hirley Alves, and Matti Latva-aho", "title": "Fixed Rate Statistical QoS Provisioning for Markovian Sources in Machine\n  Type Communication", "comments": "arXiv admin note: text overlap with arXiv:1808.06839", "journal-ref": null, "doi": "10.1109/ISWCS.2019.8877299", "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the trade-off between reliability and latency in\nmachine type communication (MTC), which consists of single transmitter and\nreceiver in the presence of Rayleigh fading channel. We assume that the\ntransmitter does not know the channel conditions, therefore it would be\ntransmitting information over a fixed rate. The fixed rate transmission is\nmodeled as a two-state continuous-time Markov process, where the optimum\ntransmission rate is obtained. Moreover, we conduct a performance analysis for\ndifferent arrival traffic originated from MTC device via effective rate\ntransmission. We consider that the arrival traffic is modeled as a Markovian\nprocess namely Discrete-Time Markov process, Fluid Markov process, and Markov\nModulated Poisson process, under delay violation constraints. Using effective\nbandwidth and effective capacity theories, we evaluate the trade-off between\nreliability-latency and identify QoS (Quality of Service) requirement, and\nderive lower and upper bounds for the effective capacity subject to channel\nmemory decay rate limits.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 14:46:40 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Qasmi", "Fahad", ""], ["Shehab", "Mohammad", ""], ["Alves", "Hirley", ""], ["Latva-aho", "Matti", ""]]}, {"id": "1906.11402", "submitter": "Jie Feng", "authors": "Jie Feng, Yongpeng Wu, Guangtao Zhai, Ning Liu, and Wenjun Zhang", "title": "An Algorithm for Transmitting VR Video Based on Adaptive Modulation", "comments": "This paper contains 6 pages with 6 figures and has been accepted by\n  2019 IEEE/CIC International Conference on Communications in China (ICCC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual reality (VR) is making waves around the world recently. However,\ntraditional video streaming is not suitable for VR video because of the huge\nsize and view switch requirements of VR videos. Since the view of each user is\nlimited, it is unnecessary to send the whole 360-degree scene at high quality\nwhich can be a heavy burden for the transmission system. Assuming filed-of-view\n(FoV) of each user can be predicted with high probability, we can divide the\nvideo screen into partitions and send those partitions which will appear in FoV\nat high quality. Hence, we propose an novel strategy for VR video streaming.\nFirst, we define a quality-of-experience metric to measure the viewing\nexperience of users and define a channel model to reflect the fluctuation of\nthe wireless channel. Next, we formulate the optimization problem and find its\nfeasible solution by convex optimization. In order to improve bandwidth\nefficiency, we also add adaptive modulation to this part. Finally, we compare\nour algorithm with other VR streaming algorithm in the simulation. It turns out\nthat our algorithm outperforms other algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 00:54:02 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Feng", "Jie", ""], ["Wu", "Yongpeng", ""], ["Zhai", "Guangtao", ""], ["Liu", "Ning", ""], ["Zhang", "Wenjun", ""]]}, {"id": "1906.11427", "submitter": "Vishal Sharma", "authors": "Gaurav Choudhary, Jiyoon Kim, Vishal Sharma", "title": "Security of 5G-Mobile Backhaul Networks: A Survey", "comments": "30 pages, 6 figures, 6 tables, Journal of Wireless Mobile Networks,\n  Ubiquitous Computing, and Dependable Applications (JoWUA)", "journal-ref": "Journal of Wireless Mobile Networks, Ubiquitous Computing, and\n  Dependable Applications (JoWUA), 9:4 (Dec. 2018), pp. 41-70", "doi": "10.22667/JOWUA.2018.12.31.041", "report-no": null, "categories": "cs.NI cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid involution of the mobile generation with incipient data networking\ncapabilities and utilization has exponentially increased the data traffic\nvolumes. Such traffic drains various key issues in 5G mobile backhaul networks.\nSecurity of mobile backhaul is of utmost importance; however, there are a\nlimited number of articles, which have explored such a requirement. This paper\ndiscusses the potential design issues and key challenges of the secure 5G\nmobile backhaul architecture. The comparisons of the existing state-of-the-art\nsolutions for secure mobile backhaul, together with their major contributions\nhave been explored. Furthermore, the paper discussed various key issues related\nto Quality of Service (QoS), routing and scheduling, resource management,\ncapacity enhancement, latency, security-management, and handovers using\nmechanisms like Software Defined Networking and millimeter Wave technologies.\nMoreover, the trails of research challenges and future directions are\nadditionally presented.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 03:55:36 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Choudhary", "Gaurav", ""], ["Kim", "Jiyoon", ""], ["Sharma", "Vishal", ""]]}, {"id": "1906.11541", "submitter": "Elias Yaacoub", "authors": "Elias Yaacoub and Mohamed-Slim Alouini", "title": "A Key 6G Challenge and Opportunity -- Connecting the Remaining 4\n  Billions: A Survey on Rural Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Providing connectivity to around half of the World population living in rural\nor underprivileged areas is a tremendous challenge, but also a unique\nopportunity. In this paper, a survey of technologies for providing connectivity\nto rural areas, and that can help address this challenge, is provided.\nFronthaul and backhaul techniques are discussed. In addition, energy and cost\nefficiency of the studied technologies are analyzed. Typical application\nscenarios in rural areas are discussed, and several country-specific use cases\nare surveyed. Directions for future evolution of rural connectivity are\noutlined.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 10:37:29 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Yaacoub", "Elias", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1906.11559", "submitter": "Mustafa Kishk", "authors": "Mustafa A. Kishk, Ahmed Bader, and Mohamed-Slim Alouini", "title": "Aerial Base Stations Deployment in 6G Cellular Networks using Tethered\n  Drones: The Mobility and Endurance Trade-off", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airborne base stations (carried by drones) have a great potential to enhance\ncoverage and capacity of cellular networks. Multiple scenarios and use cases\nwill highly benefit from such technology such as (i) offloading terrestrial\nbase stations (BSs) in dense and urban areas, and (ii) providing coverage for\nrural areas. However, one of the main challenges facing the deployment of\nairborne BSs is the limited available energy at the drone, which limits the\nflight time. In fact, most of the currently used unmanned aerial vehicles\n(UAVs) can only operate for one hour maximum. This limits the performance of\nthe UAV-enabled cellular network due to the need to frequently visit the ground\nstation to recharge, leaving the UAV's coverage area temporarily out of\nservice. In this article, we propose a new UAV-enabled cellular network setup\nbased on tethered UAVs (TUAVs). In the proposed setup, the TUAV is connected to\na ground station (GS) through a tether, which provides the TUAV with both\nenergy and data. This enables a flight that can stay for days. We describe in\ndetail the components of the proposed system. Furthermore, we enlist the main\nadvantages of a TUAV-enabled cellular network compared to typical untethered\nUAVs. Next, we discuss the potential applications and use cases for TUAVs.\nFinally, we discuss the challenges, design considerations, and future research\ndirections to realize the proposed setup.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 11:35:04 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 21:11:28 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Kishk", "Mustafa A.", ""], ["Bader", "Ahmed", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1906.11596", "submitter": "Martin Reisslein", "authors": "Ahmed Nasrallah, Venkatraman Balasubramanian, Akhilesh Thyagaturu,\n  Martin Reisslein, Hesham ElBakoury", "title": "Reconfiguration Algorithms for High Precision Communications in Time\n  Sensitive Networks: Time-Aware Shaper Configuration with IEEE 802.1Qcc\n  (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As new networking paradigms emerge for different networking applications,\ne.g., cyber-physical systems, and different services are handled under a\nconverged data link technology, e.g., Ethernet, certain applications with\nmission critical traffic cannot coexist on the same physical networking\ninfrastructure using traditional Ethernet packet-switched networking protocols.\nThe IEEE 802.1Q Time Sensitive Networking (TSN) task group is developing\nprotocol standards to provide deterministic properties on Ethernet based\npacket-switched networks. In particular, the IEEE 802.1Qcc, centralized\nmanagement and control, and the IEEE 802.1Qbv, Time-Aware Shaper, can be used\nto manage and control scheduled traffic streams with periodic properties along\nwith best-effort traffic on the same network infrastructure. In this paper, we\ninvestigate the effects of using the IEEE 802.1Qcc management protocol to\naccurately and precisely configure TAS enabled switches (with transmission\nwindows governed by gate control lists (GCLs) with gate control entries (GCEs))\nensuring ultra-low latency, zero packet loss, and minimal jitter for scheduled\nTSN traffic. We examine both a centralized network/distributed user model\n(hybrid model) and a fully-distributed (decentralized) 802.1Qcc model on a\ntypical industrial control network with the goal of maximizing scheduled\ntraffic streams.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 12:55:17 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Nasrallah", "Ahmed", ""], ["Balasubramanian", "Venkatraman", ""], ["Thyagaturu", "Akhilesh", ""], ["Reisslein", "Martin", ""], ["ElBakoury", "Hesham", ""]]}, {"id": "1906.11922", "submitter": "Ghassan Samara", "authors": "Ghassan Samara", "title": "An Improved CF-MAC Protocol for VANET", "comments": "7 pages", "journal-ref": "International Journal of Electrical and Computer Engineering\n  (IJECE) Vol. 9, No. 4, August 2019, pp. 2668~2675 ISSN: 2088-8708", "doi": "10.11591/ijece.v9i4", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular Ad hoc Network (VANET) is one of the emerging research areas in the\nmobile computing field which is considered as a future technology and promising\ntopic in the computer science and computer networks. Which provides road\nsafety, updated traffic information, and infotainment. VANET consists of a\nlarge number of vehicles moving in high speeds while broadcasting important\ninformation like safety and control information which must be sent with high\npriority. Crowded networks like VANET having many vehicles competing to reserve\nthe channel to send critical information which may lead to high collision\nscenarios, and therefore, there must be a protocol to send this kind of\ninformation with high reliability, low data loss and with no collision. In this\nresearch a collision-free protocol will be proposed to manage the channel\naccess among competing vehicles to eliminate the collisions which occur rapidly\nin VANET especially in dense situations, the proposed protocol hereinafter will\nbe called (I-MAC) protocol expected to enhance the channel performance, achieve\nload balancing, fairness, and decrease message loss and enhance reliability,\nThe evaluation criteria will examine the channel throughput, message delay, and\nmessage loss; the results show that the overall channel performance with regard\nto collision and packet loss ratio is improved.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 10:51:02 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Samara", "Ghassan", ""]]}, {"id": "1906.11976", "submitter": "Jos\\'e Camacho", "authors": "Jos\\'e Camacho, Jos\\'e Manuel Garc\\'ia-Gim\\'enez, Noem\\'i Marta\n  Fuentes-Garc\\'ia, Gabriel Maci\\'a-Fern\\'andez", "title": "Multivariate Big Data Analysis for Intrusion Detection: 5 steps from the\n  haystack to the needle", "comments": null, "journal-ref": "Computers & Security, Volume 87, November 2019, 101603", "doi": "10.1016/j.cose.2019.101603", "report-no": null, "categories": "cs.NI cs.CR cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research literature on cybersecurity incident detection & response is\nvery rich in automatic detection methodologies, in particular those based on\nthe anomaly detection paradigm. However, very little attention has been devoted\nto the diagnosis ability of the methods, aimed to provide useful information on\nthe causes of a given detected anomaly. This information is of utmost\nimportance for the security team to reduce the time from detection to response.\nIn this paper, we present Multivariate Big Data Analysis (MBDA), a complete\nintrusion detection approach based on 5 steps to effectively handle massive\namounts of disparate data sources. The approach has been designed to deal with\nthe main characteristics of Big Data, that is, the high volume, velocity and\nvariety. The core of the approach is the Multivariate Statistical Network\nMonitoring (MSNM) technique proposed in a recent paper. Unlike in state of the\nart machine learning methodologies applied to the intrusion detection problem,\nwhen an anomaly is identified in MBDA the output of the system includes the\ndetail of the logs of raw information associated to this anomaly, so that the\nsecurity team can use this information to elucidate its root causes. MBDA is\nbased in two open software packages available in Github: the MEDA Toolbox and\nthe FCParser. We illustrate our approach with two case studies. The first one\ndemonstrates the application of MBDA to semistructured sources of information,\nusing the data from the VAST 2012 mini challenge 2. This complete case study is\nsupplied in a virtual machine available for download. In the second case study\nwe show the Big Data capabilities of the approach in data collected from a real\nnetwork with labeled attacks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 21:36:13 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Camacho", "Jos\u00e9", ""], ["Garc\u00eda-Gim\u00e9nez", "Jos\u00e9 Manuel", ""], ["Fuentes-Garc\u00eda", "Noem\u00ed Marta", ""], ["Maci\u00e1-Fern\u00e1ndez", "Gabriel", ""]]}, {"id": "1906.12001", "submitter": "Francesco Fraternali", "authors": "Francesco Fraternali", "title": "Towards Large-Scale Autonomous Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Sensor Networks (WSNs) have the goal of gathering data from the\nenvironment. The advent of the Internet of Things (IoT) drastically changed\nWSN's vision that, as never before, needs to expand and include hundreds or\nthousands of sensors. But to follow the current IoT trends new techniques need\nto be implemented since orders of thousands of sensor nodes are not manageable\nby today's WSNs systems that often rely on manual configuration and hence are\nnot practical. As an example, the replacement of batteries of thousand of nodes\ncould be extremely arduous or even impossible for structural health monitoring\nof civil infrastructures (i.e. bridges, towers). Hence, the solution to the\ngrowing burden of the system manager is automation, allowing the system to\ncheck its own status, to re-configure itself and fix the major problems in the\nnetwork whenever it is possible. In this paper, we present and discuss the main\nfeatures needed to achieve an autonomous large scale WSN. Furthermore, we\ncompare these features with the state of the art of real-world large scale WSN\ndeployments showing that further solutions are needed to drastically reduce\nhuman intervention while guaranteeing the main functionalities of the system.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 00:18:00 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Fraternali", "Francesco", ""]]}, {"id": "1906.12143", "submitter": "M. Aiman Ismail", "authors": "M. Aiman Ismail, Thomas C. Schmidt", "title": "A DTLS Abstraction Layer for the Recursive Networking Architecture in\n  RIOT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the Internet of Things (IoT), devices continuously communicate with each\nother, with a gateway, or other Internet nodes. Often devices are constrained\nand use insecure channels for their communication, which exposes them to a\nselection of attacks that may extract sensitive pieces of information or\nmanipulate dialogues for the purpose of sabotaging.\n  This paper presents a new layer in the RIOT networking architecture to\nseamlessly integrate secure communication between applications using DTLS. The\nlayer acts as a modular abstraction layer of the different DTLS\nimplementations, enabling swapping of the underlying implementation with just a\nfew lines of code. This paper also introduces credman, a new module to manage\ncredentials used for (D)TLS connections.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 11:34:47 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Ismail", "M. Aiman", ""], ["Schmidt", "Thomas C.", ""]]}]