[{"id": "2012.00116", "submitter": "Martin Strohmeier", "authors": "Matthias Sch\\\"afer, Martin Strohmeier, Mauro Leonardi, Vincent Lenders", "title": "LocaRDS: A Localization Reference Data Set", "comments": "10 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of wireless signals for purposes of localization enables a host of\napplications relating to the determination and verification of the positions of\nnetwork participants, ranging from radar to satellite navigation. Consequently,\nit has been a longstanding interest of theoretical and practical research in\nmobile networks and many solutions have been proposed in the scientific\nliterature. However, it is hard to assess the performance of these in the real\nworld and, more severely, to compare their advantages and disadvantages in a\ncontrolled scientific manner.\n  With this work, we attempt to improve the current state of the art in\nlocalization research and put it on a solid scientific grounding for the\nfuture. Concretely, we develop LocaRDS, an open reference dataset of real-world\ncrowdsourced flight data featuring more than 222 million measurements from over\n50 million transmissions recorded by 323 sensors. We show how LocaRDS can be\nused to test, analyze and directly compare different localization techniques\nand further demonstrate its effectiveness by examining the open question of the\naircraft localization problem in crowdsourced sensor networks. Finally, we\nprovide a working reference implementation for the aircraft localization\nproblem and a discussion of possible metrics for use with LocaRDS.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 21:37:57 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sch\u00e4fer", "Matthias", ""], ["Strohmeier", "Martin", ""], ["Leonardi", "Mauro", ""], ["Lenders", "Vincent", ""]]}, {"id": "2012.00143", "submitter": "Umair Mohammad", "authors": "Umair Mohammad, Sameh Sorour, Mohamed Hefeida", "title": "Task Allocation for Asynchronous Mobile Edge Learning with Delay and\n  Energy Constraints", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper extends the paradigm of \"mobile edge learning (MEL)\" by designing\nan optimal task allocation scheme for training a machine learning model in an\nasynchronous manner across mutiple edge nodes or learners connected via a\nresource-constrained wireless edge network. The optimization is done such that\nthe portion of the task allotted to each learner is completed within a given\nglobal delay constraint and a local maximum energy consumption limit. The time\nand energy consumed are related directly to the heterogeneous communication and\ncomputational capabilities of the learners; i.e. the proposed model is\nheterogeneity aware (HA). Because the resulting optimization is an NP-hard\nquadratically-constrained integer linear program (QCILP), a two-step\nsuggest-and-improve (SAI) solution is proposed based on using the solution of\nthe relaxed synchronous problem to obtain the solution to the asynchronous\nproblem. The proposed HA asynchronous (HA-Asyn) approach is compared against\nthe HA synchronous (HA-Sync) scheme and the heterogeneity unaware (HU) equal\nbatch allocation scheme. Results from a system of 20 learners tested for\nvarious completion time and energy consumption constraints show that the\nproposed HA-Asyn method works better than the HU synchronous/asynchronous\n(HU-Sync/Asyn) approach and can provide gains of up-to 25\\% compared to the\nHA-Sync scheme.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 22:45:59 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 18:01:02 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Mohammad", "Umair", ""], ["Sorour", "Sameh", ""], ["Hefeida", "Mohamed", ""]]}, {"id": "2012.00176", "submitter": "Clement Nyirenda", "authors": "Dineshan Subramoney, Clement N. Nyirenda", "title": "A Comparative Evaluation of Population-based Optimization Algorithms for\n  Workflow Scheduling in Cloud-Fog Environments", "comments": "8 pages", "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI)\n  (SSCI 2020)", "doi": null, "report-no": null, "categories": "cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a comparative evaluation of four population-based\noptimization algorithms for workflow scheduling in cloud-fog environments.\nThese algorithms are as follows: Particle Swarm Optimization (PSO), Genetic\nAlgorithm (GA), Differential Evolution (DE) and GA-PSO. This work also provides\nthe motivational groundwork for the weighted sum objective function for the\nworkflow scheduling problem and develops this function based on three\nobjectives: makespan, cost and energy. The recently proposed FogWorkflowSim is\nused as the simulation environment with the aforementioned objectives serving\nperformance metrics. Results show that hybrid combination of the GA-PSO\nalgorithm exhibits slightly better than the standard algorithms. Future work\nwill include expansion of the workflows used by increasing the number of tasks\nas well as adding some more workflows. The addition of some more objectives to\nthe weighted objective function will also be pursued\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 23:58:05 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 17:39:21 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Subramoney", "Dineshan", ""], ["Nyirenda", "Clement N.", ""]]}, {"id": "2012.00339", "submitter": "Ahmed M. A. Sayed", "authors": "Ahmed M. Abdelmoniem and Brahim Bensaou", "title": "Design and Implementation of Fair Congestion Control for Data Centers\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In data centers, the nature of the composite bursty traffic along with the\nsmall bandwidth-delay product and switch buffers lead to several congestion\nproblems that are not handled well by traditional congestion control mechanisms\nsuch as TCP. Existing work try to address the problem by modifying TCP to suit\nthe operational nature of data centers. This is practically feasible in private\nsettings, however, in public environments, such modifications are prohibited.\nTherefore, in this work, we design simple switch-based queue management to deal\nwith such congestion issues adequately. This approach entails no modification\nto the TCP sender and receiver algorithms which enables easy and seamless\ndeployment in public data centers. We present a theoretical analysis to show\nthe stability and effectiveness of the scheme. We also present, three different\nreal implementations (as a Linux kernel module and as an added feature to\nOpenvSwitch) and give numerical results from both NS-2 simulation and\nexperiments of real deployment in a small test-bed cluster to show its\neffectiveness in achieving high throughput overall, a good fairness and short\nflow completion times for delay-sensitive flows.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 08:46:24 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Abdelmoniem", "Ahmed M.", ""], ["Bensaou", "Brahim", ""]]}, {"id": "2012.00391", "submitter": "Yi Chu", "authors": "Yi Chu, Paul Mitchell, David Grace, Jonathan Roberts, Dominic White\n  and Tautvydas Mickus", "title": "IRIS: A Low Duty Cycle Cross-Layer Protocol for Long-Range Wireless\n  Sensor Networks with Low Power Budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a cross-layer protocol (IRIS) designed for long-range\npipeline Wireless Sensor Networks with extremely low power budget, typically\nseen in a range of monitoring applications. IRIS uses ping packets initiated by\na base station to travel through the multi-hop network and carry monitoring\ninformation. The protocol is able to operate with less than 1% duty cycle,\nthereby conforming to ISM band spectrum regulations in the 868MHz band. The\nduty cycle can be flexibly configured to meet other regulations/power budgets\nas well as to improve the route forming performance. Simulation results show\nguaranteed route formation in different network topologies with various\nprotocol configurations. System robustness against unreliable wireless\nconnections and node failures are also demonstrated by simulations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 10:40:44 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Chu", "Yi", ""], ["Mitchell", "Paul", ""], ["Grace", "David", ""], ["Roberts", "Jonathan", ""], ["White", "Dominic", ""], ["Mickus", "Tautvydas", ""]]}, {"id": "2012.00425", "submitter": "Shashi Raj Pandey", "authors": "Shashi Raj Pandey, Minh N.H. Nguyen, Tri Nguyen Dang, Nguyen H. Tran,\n  Kyi Thar, Zhu Han, Choong Seon Hong", "title": "Edge-assisted Democratized Learning Towards Federated Analytics", "comments": "Accepted for publication in IEEE Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2021.3085429", "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent take towards Federated Analytics (FA), which allows analytical\ninsights of distributed datasets, reuses the Federated Learning (FL)\ninfrastructure to evaluate the summary of model performances across the\ntraining devices. However, the current realization of FL adopts single\nserver-multiple client architecture with limited scope for FA, which often\nresults in learning models with poor generalization, i.e., an ability to handle\nnew/unseen data, for real-world applications. Moreover, a hierarchical FL\nstructure with distributed computing platforms demonstrates incoherent model\nperformances at different aggregation levels. Therefore, we need to design a\nrobust learning mechanism than the FL that (i) unleashes a viable\ninfrastructure for FA and (ii) trains learning models with better\ngeneralization capability. In this work, we adopt the novel democratized\nlearning (Dem-AI) principles and designs to meet these objectives. Firstly, we\nshow the hierarchical learning structure of the proposed edge-assisted\ndemocratized learning mechanism, namely Edge-DemLearn, as a practical framework\nto empower generalization capability in support of FA. Secondly, we validate\nEdge-DemLearn as a flexible model training mechanism to build a distributed\ncontrol and aggregation methodology in regions by leveraging the distributed\ncomputing infrastructure. The distributed edge computing servers construct\nregional models, minimize the communication loads, and ensure distributed data\nanalytic application's scalability. To that end, we adhere to a near-optimal\ntwo-sided many-to-one matching approach to handle the combinatorial constraints\nin Edge-DemLearn and solve it for fast knowledge acquisition with optimization\nof resource allocation and associations between multiple servers and devices.\nExtensive simulation results on real datasets demonstrate the effectiveness of\nthe proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 11:46:03 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 03:08:31 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 06:34:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Pandey", "Shashi Raj", ""], ["Nguyen", "Minh N. H.", ""], ["Dang", "Tri Nguyen", ""], ["Tran", "Nguyen H.", ""], ["Thar", "Kyi", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2012.00796", "submitter": "Lei Miao", "authors": "Lei Miao and Dingde Jiang", "title": "Wireless Secret Sharing Game between Two Legitimate Users and an\n  Eavesdropper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless secret sharing is crucial to information security in the era of\nInternet of Things. One method is to utilize the effect of the randomness of\nthe wireless channel in the data link layer to generate the common secret\nbetween two legitimate users Alice and Bob. This paper studies this secret\nsharing mechanism from the perspective of game theory. In particular, we\nformulate a non-cooperative zero-sum game between the legitimate users and an\neavesdropper Eve. In a symmetrical game where Eve has the same probability of\nsuccessfully receiving a packet from Alice and Bob when the transmission\ndistance is the same, we show that both pure and mixed strategy Nash equilibria\nexist. In an asymmetric game where Eve has different probabilities of\nsuccessfully receiving a packet from Alice and Bob, a pure strategy may not\nexist; in this case, we show how a mixed strategy Nash equilibrium can be\nfound.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 19:44:27 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 00:58:23 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Miao", "Lei", ""], ["Jiang", "Dingde", ""]]}, {"id": "2012.00826", "submitter": "Taoufik Yeferny", "authors": "Sofian Hamad, Taoufik Yeferny", "title": "A Chatbot for Information Security", "comments": null, "journal-ref": "IJCSNS International Journal of Computer Science and Network\n  Security, VOL.20 No.4, April 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Advancements in artificial intelligence (AI), speech recognition systems\n(ASR), and machine learning have enabled the development of intelligent\ncomputer programs called chatbots. Many chatbots have been proposed to provide\ndifferent services in many areas such as customer service, sales and marketing.\nHowever, the use of chatbot as advisers in the field of information security is\nnot yet considered. Furthermore, people, especially normal users who have no\ntechnical background, are unaware about many of aspects in information\nsecurity. Therefore, in this paper we proposed a chatbot that acts as an\nadviser in information security. The proposed adviser uses a knowledge base\nwith json file. Having such chatbot provides many features including raising\nthe awareness in field of information security by offering accurate advice,\nbased on different opinions from information security expertise, for many users\non different. Furthermore, this chatbot is currently deployed through Telegram\nplatform, which is one of widely used social network platforms. The deployment\nof the proposed chatbot over different platforms is considered as the future\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 21:20:35 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Hamad", "Sofian", ""], ["Yeferny", "Taoufik", ""]]}, {"id": "2012.00850", "submitter": "Mostafa Abdollahi", "authors": "Mostafa Abdollahi, Farshad Eshghi, Manoochehr Kelarestaghi, Mozafar\n  Bag-Mohammadi", "title": "Opportunistic Routing Metrics: A Timely One-Stop Tutorial Survey", "comments": "41 Pages, 28 figures", "journal-ref": "Journal of Network and computer applications 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-speed, low latency, and heterogeneity features of 5G, as the common\ndenominator of many emerging and classic wireless applications, have put\nwireless technology back in the spotlight. Continuous connectivity requirement\nin low-power and wide-reach networks underlines the need for more efficient\nrouting over scarce wireless resources, in multi-hp scenarios. In this regard,\nOpportunistic Routing (OR), which utilizes the broadcast nature of wireless\nmedia to provide transmission cooperation amongst a selected number of\noverhearing nodes, has become more promising than ever. Crucial to the overall\nnetwork performance, which nodes to participate and where they stand on the\ntransmission-priority hierarchy, are decided by user-defined OR metrics\nembedded in OR protocols. Therefore, the task of choosing or designing an\nappropriate OR metric is a critical one. The numerousness, proprietary\nnotations, and the objective variousness of OR metrics can cause the interested\nresearcher to lose insight and become overwhelmed, making the metric selection\nor design effort-intensive. While there are not any comprehensive OR metrics\nsurveys in the literature, those who partially address the subject are\nnon-exhaustive and lacking in detail. Furthermore, they offer limited insight\nregarding related taxonomy and future research recommendations. In this paper,\nstarting with a custom tutorial with a new look to OR and OR metrics, we devise\na new framework for OR metric design. Introducing a new taxonomy enables us to\ntake a structured, investigative, and comparative approach to OR metrics,\nsupported by extensive simulations. Exhaustive coverage of OR metrics,\nformulated in a unified notation, is presented with sufficient details.\nSelf-explanatory, easy-to-grasp, and visual-friendly quick references are\nprovided, which can be used independently from the rest of the paper.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 21:43:41 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Abdollahi", "Mostafa", ""], ["Eshghi", "Farshad", ""], ["Kelarestaghi", "Manoochehr", ""], ["Bag-Mohammadi", "Mozafar", ""]]}, {"id": "2012.00877", "submitter": "Weisheng Si", "authors": "Weisheng Si, Balume Mburano, Wei Xing Zheng, Tie Qiu", "title": "Measuring Network Robustness by Average Network Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Infrastructure networks such as the Internet backbone and power grids are\nessential for our everyday lives. With the prevalence of cyber-attacks on them,\nmeasuring their robustness has become an important issue. To date, many\nrobustness metrics have been proposed. It is desirable for a robustness metric\nto possess the following three properties: considering global network\ntopologies, strictly increasing upon link additions, and having a quadratic\ncomplexity in terms of the number of nodes on sparse networks. This paper\nproposes to use Average Network Flow (ANF) as a robustness metric, and proves\nthat it increases strictly, and gives an algorithm to compute ANF with a\nquadratic complexity by leveraging Gomory-Hu trees. Thus, with ANF\nintrinsically considering global network topologies, ANF is unveiled to be a\nnew robustness metric satisfying those three properties. Moreover, this paper\ncompares ANF with seven existing representative metrics, showing that each\nmetric has its own characteristics, so there is no silver bullet in measuring\nnetwork robustness and it is recommended to apply several metrics together to\ngain a comprehensive view. Finally, by experimenting on the scenarios in which\nnetwork topologies preserve the same numbers of nodes and links, some\ninteresting behaviors of robustness metrics are reported.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 22:48:09 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 04:11:46 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Si", "Weisheng", ""], ["Mburano", "Balume", ""], ["Zheng", "Wei Xing", ""], ["Qiu", "Tie", ""]]}, {"id": "2012.00941", "submitter": "Xiangqiang Gao", "authors": "Xiangqiang Gao, Rongke Liu (Senior Member, IEEE), and Aryan Kaushik\n  (Member, IEEE)", "title": "Virtual Network Function Placement in Satellite Edge Computing with a\n  Potential Game Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satellite networks, as a supplement to terrestrial networks, can provide\neffective computing services for Internet of Things (IoT) users in remote\nareas. Due to the resource limitation of satellites, such as in computing,\nstorage, and energy, a computation task from a IoT user can be divided into\nseveral parts and cooperatively accomplished by multiple satellites to improve\nthe overall operational efficiency of satellite networks. Network function\nvirtualization (NFV) is viewed as a new paradigm in allocating network\nresources on-demand. Satellite edge computing combined with the NFV technology\nis becoming an emerging topic. In this paper, we propose a potential game\napproach for virtual network function (VNF) placement in satellite edge\ncomputing. The VNF placement problem aims to maximize the number of allocated\nIoT users, while minimizing the overall deployment cost. We formulate the VNF\nplacement problem with maximum network payoff as a potential game and analyze\nthe problem by a game-theoretical approach. We implement a decentralized\nresource allocation algorithm based on a potential game (PGRA) to tackle the\nVNF placement problem by finding a Nash equilibrium. Finally, we conduct the\nexperiments to evaluate the performance of the proposed PGRA algorithm. The\nsimulation results show that the proposed PGRA algorithm can effectively\naddress the VNF placement problem in satellite edge computing.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 03:06:20 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 09:08:08 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 10:44:17 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Gao", "Xiangqiang", "", "Senior Member, IEEE"], ["Liu", "Rongke", "", "Senior Member, IEEE"], ["Kaushik", "Aryan", "", "Member, IEEE"]]}, {"id": "2012.00982", "submitter": "Yusuke Koda", "authors": "Yusuke Koda and Masao Shinzaki and Koji Yamamoto and Takayuki Nishio\n  and Masahiro Morikura and Yushi Shirato and Daisei Uchida and Naoki Kita", "title": "Millimeter Wave Communications on Overhead Messenger Wire: Deep\n  Reinforcement Learning-Based Predictive Beam Tracking", "comments": "12 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the feasibility of beam tracking against dynamics in\nmillimeter wave (mmWave) nodes placed on overhead messenger wires, including\nwind-forced perturbations and disturbances caused by impulsive forces to wires.\nOur main contribution is to answer whether or not historical positions and\nvelocities of a mmWave node is useful to track directional beams given the\ncomplicated on-wire dynamics. To this end, we implement beam-tracking based on\ndeep reinforcement learning (DRL) to learn the complicated relationships\nbetween the historical positions/velocities and appropriate beam steering\nangles. Our numerical evaluations yielded the following key insights: Against\nwind perturbations, an appropriate beam-tracking policy can be learned from the\nhistorical positions and velocities of a node. Meanwhile, against impulsive\nforces to the wire, the use of the position and velocity of the node is not\nnecessarily sufficient owing to the rapid displacement of the node. To solve\nthis, we propose to take advantage of the positional interaction on the wire by\nleveraging the positions/velocities of several points on the wire as state\ninformation in DRL. The results confirmed that this results in the avoidance of\nbeam misalignment, which would not be possible by using only the\nposition/velocity of the node.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 06:14:32 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Koda", "Yusuke", ""], ["Shinzaki", "Masao", ""], ["Yamamoto", "Koji", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""], ["Shirato", "Yushi", ""], ["Uchida", "Daisei", ""], ["Kita", "Naoki", ""]]}, {"id": "2012.01122", "submitter": "Qiong Wu", "authors": "Qiong Wu, Hanxu Liu, Ruhai Wang, Pingyi Fan, Qiang Fan, Zhengquan Li", "title": "Delay Sensitive Task Offloading in the 802.11p Based Vehicular Fog\n  Computing Systems", "comments": "This paper has been accepted by IEEE Internet of Things Journal.\n  Simulation codes have been provided at: https://github.com/qiongwu86/SMDP", "journal-ref": null, "doi": "10.1109/JIOT.2019.2953047", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular fog computing (VFC) is envisioned as a promising solution to\nprocess the explosive tasks in autonomous vehicular networks. In the VFC\nsystem, task offloading is the key technique to process the\ncomputation-intensive tasks efficiently. In the task offloading, the task is\ntransmitted to the VFC system according to the 802.11p standard and processed\nby the computation resources in the VFC system. The delay of task offloading,\nconsisting of the transmission delay and computing delay, is extremely critical\nespecially for some delay-sensitive applications. Furthermore, the long-term\nreward of the system (i.e., jointly considers the transmission delay, computing\ndelay, available resources, and diversity of vehicles and tasks) becomes a\nsignificantly important issue for providers. Thus, in this article, we propose\nan optimal task offloading scheme to maximize the long-term reward of the\nsystem where 802.11p is employed as the transmission protocol for the\ncommunications between vehicles. Specifically, a task offloading problem based\non a semi-Markov decision process (SMDP) is formulated. To solve this problem,\nwe utilize an iterative algorithm based on the Bellman equation to approach the\ndesired solution. The performance of the proposed scheme has been demonstrated\nby extensive numerical results.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 12:28:17 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Wu", "Qiong", ""], ["Liu", "Hanxu", ""], ["Wang", "Ruhai", ""], ["Fan", "Pingyi", ""], ["Fan", "Qiang", ""], ["Li", "Zhengquan", ""]]}, {"id": "2012.01174", "submitter": "Francesca Cuomo", "authors": "Pietro Spadaccino and Francesca Cuomo", "title": "Intrusion Detection Systems for IoT: opportunities and challenges\n  offered by Edge Computing", "comments": "Paper submitted for publication in the IEEE Communications Surveys &\n  Tutorials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key components of current cybersecurity methods are the Intrusion Detection\nSystems (IDSs) were different techniques and architectures are applied to\ndetect intrusions. IDSs can be based either on cross-checking monitored events\nwith a database of known intrusion experiences, known as signature-based, or on\nlearning the normal behavior of the system and reporting whether some anomalous\nevents occur, named anomaly-based. This work is dedicated to the application to\nthe Internet of Things (IoT) network where edge computing is used to support\nthe IDS implementation. New challenges that arise when deploying an IDS in an\nedge scenario are identified and remedies are proposed. We focus on\nanomaly-based IDSs, showing the main techniques that can be leveraged to detect\nanomalies and we present machine learning techniques and their application in\nthe context of an IDS, describing the expected advantages and disadvantages\nthat a specific technique could cause.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 13:07:27 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Spadaccino", "Pietro", ""], ["Cuomo", "Francesca", ""]]}, {"id": "2012.01228", "submitter": "Sifat Ibne Mushfique", "authors": "Sifat Ibne Mushfique, Ahmad Alsharoa and Murat Yuksel", "title": "MirrorVLC: Optimal Mirror Placement for Multi-Element VLC Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visible Light Communication (VLC) is a rapidly growing technology which can\nsupplement the current radio frequency (RF) based wireless communication\nsystems. VLC can play a huge part in solving the ever-increasing problem of\nspectrum scarcity because of the growing availability of Light Emitting Diodes\n(LEDs). One of the biggest advantages of VLC over other communication systems\nis that it can provide illumination and data communication simultaneously\nwithout needing any extra deployment. Although it is essential to provide data\nrate at a blazing speed to all the users nowadays, maintaining a satisfactory\nlevel in the distribution of lighting is also important. In this paper, we\npresent a novel approach of using mirrors to enhance the illumination\nuniformity and throughput of an indoor multi-element VLC system architecture.\nIn this approach, we improve the Signal-to-Interference plus Noise Ratio (SINR)\nof the system and overall illumination uniformity of the room by redirecting\nthe reflected LED beams on the walls to darker spots with the use of mirrors.\nWe formulate a joint optimization problem focusing on maximization of the SINR\nwhile maintaining a reasonable illumination uniformity across the room. We\npropose a two-stage solution of the optimization problem with optimization of\nillumination in the first stage and SINR at the second stage. We propose three\ndifferent heuristic solutions for the second stage and analyze the performance\nof them, which demonstrates the advantages of each heuristic for different\npossible scenarios. We also show that about threefold increase in average\nillumination and fourfold increase in average throughput can be achieved when\nthe mirror placement is applied which is a significant performance improvement.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 14:16:00 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Mushfique", "Sifat Ibne", ""], ["Alsharoa", "Ahmad", ""], ["Yuksel", "Murat", ""]]}, {"id": "2012.01263", "submitter": "Leonardo Bonati", "authors": "Leonardo Bonati, Salvatore D'Oro, Michele Polese, Stefano Basagni,\n  Tommaso Melodia", "title": "Intelligence and Learning in O-RAN for Data-driven NextG Cellular\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next Generation (NextG) cellular networks will be natively cloud-based and\nbuilt upon programmable, virtualized, and disaggregated architectures. The\nseparation of control functions from the hardware fabric and the introduction\nof standardized control interfaces will enable the definition of custom\nclosed-control loops, which will ultimately enable embedded intelligence and\nreal-time analytics, thus effectively realizing the vision of autonomous and\nself-optimizing networks. This article explores the disaggregated network\narchitecture proposed by the O-RAN Alliance as a key enabler of NextG networks.\nWithin this architectural context, we discuss the potential, the challenges,\nand the limitations of data-driven optimization approaches to network control\nover different timescales. We also present the first large-scale integration of\nO-RAN-compliant software components with an open-source full-stack softwarized\ncellular network. Experiments conducted on Colosseum, the world's largest\nwireless network emulator, demonstrate closed-loop integration of real-time\nanalytics and control through deep reinforcement learning agents. We also show\nthe feasibility of Radio Access Network (RAN) control through xApps running on\nthe near real-time RAN Intelligent Controller, to optimize the scheduling\npolicies of co-existing network slices, leveraging the O-RAN open interfaces to\ncollect data at the edge of the network.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 15:12:18 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 23:57:57 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bonati", "Leonardo", ""], ["D'Oro", "Salvatore", ""], ["Polese", "Michele", ""], ["Basagni", "Stefano", ""], ["Melodia", "Tommaso", ""]]}, {"id": "2012.01279", "submitter": "Zhou Zhou", "authors": "Zhou Zhou, Yan Xin, Hao Chen, Charlie Zhang, Lingjia Liu", "title": "Pareto Deterministic Policy Gradients and Its Application in 5G Massive\n  MIMO Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider jointly optimizing cell load balance and network\nthroughput via a reinforcement learning (RL) approach, where inter-cell\nhandover (i.e., user association assignment) and massive MIMO antenna tilting\nare configured as the RL policy to learn. Our rationale behind using RL is to\ncircumvent the challenges of analytically modeling user mobility and network\ndynamics. To accomplish this joint optimization, we integrate vector rewards\ninto the RL value network and conduct RL action via a separate policy network.\nWe name this method as Pareto deterministic policy gradients (PDPG). It is an\nactor-critic, model-free and deterministic policy algorithm which can handle\nthe coupling objectives with the following two merits: 1) It solves the\noptimization via leveraging the degree of freedom of vector reward as opposed\nto choosing handcrafted scalar-reward; 2) Cross-validation over multiple\npolicies can be significantly reduced. Accordingly, the RL enabled network\nbehaves in a self-organized way: It learns out the underlying user mobility\nthrough measurement history to proactively operate handover and antenna tilt\nwithout environment assumptions. Our numerical evaluation demonstrates that the\nintroduced RL method outperforms scalar-reward based approaches. Meanwhile, to\nbe self-contained, an ideal static optimization based brute-force search solver\nis included as a benchmark. The comparison shows that the RL approach performs\nas well as this ideal strategy, though the former one is constrained with\nlimited environment observations and lower action frequency, whereas the latter\nones have full access to the user mobility. The convergence of our introduced\napproach is also tested under different user mobility environment based on our\nmeasurement data from a real scenario.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 15:35:35 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Zhou", "Zhou", ""], ["Xin", "Yan", ""], ["Chen", "Hao", ""], ["Zhang", "Charlie", ""], ["Liu", "Lingjia", ""]]}, {"id": "2012.01373", "submitter": "Taoufik Yeferny", "authors": "Taoufik Yeferny, Sofian Hamad and Salem Belhaj", "title": "CDP: a Content Discovery Protocol for Mobile P2P Systems", "comments": null, "journal-ref": "IJCSNS International Journal of Computer Science and Network\n  Security, VOL.20 No.2, February 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The emergence of affordable wireless and mobile devices was a key step\ntowards deploying mobile peer-to-peer (P2P) systems. The latter allow users to\nshare and search diverse multimedia resources over Mobile Ad-hoc Networks\n(MANETs). Due to the nature of MANETs, P2P mobile systems brought up many new\nthriving challenges, in particular with regard to the content discovery issue.\nThus, the design of an efficient content discovery protocol has been of\nparamount importance. The thriving challenge is to (i) locate relevant peers\nsharing pertinent resources for users queries and then (ii) to ensure that\nthose peers would be reached by considering different MANET constraints (e.g.,\npeer mobility, battery energy, peer load, to cite a few). Even though the\nliterature witnesses a wealthy number of content discovery protocols, only few\nof them have considered the above-mentioned requirements. To overcome this\nshortage, we introduce in this paper an efficient Content Discovery Protocol\n(CDP) for P2P mobile systems. The idea underlying our proposal is to route\nusers queries to relevant peers that are (1) more suitable to answer the user\nquery according to its content, (2) more stable to relay query hits, (3) less\nloaded to avoid the network congestion issue and (4) having more battery\nlifetime to avoid the network partitioning issue. The performed experiments\nshow that CDP outperforms its competitor in terms of effectiveness and\nefficiency.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 13:03:41 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Yeferny", "Taoufik", ""], ["Hamad", "Sofian", ""], ["Belhaj", "Salem", ""]]}, {"id": "2012.01476", "submitter": "Sara Berri", "authors": "Sara Berri, Vineeth Varma, Samson Lasaulce, Mohammed Said Radjef,\n  Jamal Daafouz", "title": "Studying Node Cooperation in Reputation Based Packet Forwarding within\n  Mobile Ad hoc Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paradigm of mobile Ad hoc networks (MANET), forwarding packets\noriginating from other nodes requires cooperation among nodes. However, as each\nnode may not want to waste its energy, cooperative behavior can not be\nguaranteed. Therefore, it is necessary to implement some mechanism to avoid\nselfish behavior and to promote cooperation. In this paper, we propose a simple\nquid pro quo based reputation system, i.e., nodes that forward gain reputation,\nbut lose more reputation if they do not forward packets from cooperative users\n(determined based on reputation), and lose less reputation when they chose to\nnot forward packets from non-cooperative users. Under this framework, we model\nthe behavior of users as an evolutionary game and provide conditions that\nresult in cooperative behavior by studying the evolutionary stable states of\nthe proposed game. Numerical analysis is provided to study the resulting\nequilibria and to illustrate how the proposed model performs compared to\ntraditional models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 19:33:37 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Berri", "Sara", ""], ["Varma", "Vineeth", ""], ["Lasaulce", "Samson", ""], ["Radjef", "Mohammed Said", ""], ["Daafouz", "Jamal", ""]]}, {"id": "2012.01507", "submitter": "Sara Berri", "authors": "Sara Berri, Samson Lasaulce, Mohammed Said Radjef", "title": "Power control with partial observation in wireless ad hoc networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the well-known forwarder's dilemma is generalized by\naccounting for the presence of link quality fluctuations; the forwarder's\ndilemma is a four-node interaction model with two source nodes and two\ndestination nodes. It is known to be very useful to study ad hoc networks. To\ncharacterize the long-term utility region when the source nodes have to control\ntheir power with partial channel state information (CSI), we resort to a recent\nresult in Shannon theory. It is shown how to exploit this theoretical result to\nfind the long-term utility region and determine good power control policies.\nThis region is of prime importance since it provides the best performance\npossible for a given knowledge at the nodes. Numerical results provide several\nnew insights into the repeated forwarder's dilemma power control problem; for\ninstance, the knowledge of global CSI only brings a marginal performance\nimprovement with respect to the local CSI case.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 20:21:07 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Berri", "Sara", ""], ["Lasaulce", "Samson", ""], ["Radjef", "Mohammed Said", ""]]}, {"id": "2012.01517", "submitter": "Sara Berri", "authors": "Sara Berri, Samson Lasaulce, Mohammed Said Radjef", "title": "Efficient Packet Transmission in Wireless Ad Hoc Networks with Partially\n  Informed Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One formal way of studying cooperation and incentive mechanisms in wireless\nad hoc networks is to use game theory. In this respect, simple interaction\nmodels such as the forwarder's dilemma have been proposed and used\nsuccessfully. However, this type of models is not suited to account for\npossible fluctuations of the wireless links of the network. Additionally, it\ndoes not allow one to study the way a node transmits its own packets. At last,\nthe repeated game models used in the related literature do not allow the\nimportant scenario of nodes with partial information (about the link state and\nnodes actions) to be studied. One of the contributions of the present work is\nprecisely to provide a general approach to integrate all of these aspects.\nSecond, the best performance the nodes can achieve under partial information is\nfully characterized for a general form of utilities. Third, we derive an\nequilibrium transmission strategy which allows a node to adapt its transmit\npower levels and packet forwarding rate to link fluctuations and other nodes\nactions. The derived results are illustrated through a detailed numerical\nanalysis for a network model built from a generalized version of the\nforwarder's dilemma. The analysis shows in particular that the proposed\nstrategy is able to operate in presence of channel fluctuations and to perform\nsignificantly better than existing transmission mechanisms (e.g., in terms of\nconsumed network energy).\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 20:45:10 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Berri", "Sara", ""], ["Lasaulce", "Samson", ""], ["Radjef", "Mohammed Said", ""]]}, {"id": "2012.01812", "submitter": "Raphael Bialon", "authors": "Raphael Bialon", "title": "On Root Detection Strategies for Android Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Android operating system runs on the majority of smartphones nowadays.\nIts success is driven by its availability to a variety of smartphone hardware\nvendors on the one hand, and the customization possibilities given to its users\non the other hand. While other big smartphone operating systems restrict user\nconfiguration to a given set of functionality, Android users can leverage the\nwhole potential of their devices. This high degree of customization enabled by\na process called rooting, where the users escalate their privileges to those of\nthe operating system, introduces security, data integrity and privacy concerns.\nSeveral rooting detection mechanisms for Android devices already exist, aimed\nat different levels of detection. This paper introduces further strategies\nderived from the Linux ecosystem and outlines their usage on the Android\nplatform. In addition, we present a novel remote rooting detection approach\naimed at trust and integrity checks between devices in wireless networks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 10:40:15 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Bialon", "Raphael", ""]]}, {"id": "2012.01991", "submitter": "Wen Wu", "authors": "Wen Wu, Nan Chen, Conghao Zhou, Mushu Li, Xuemin Shen, Weihua Zhuang,\n  Xu Li", "title": "Dynamic RAN Slicing for Service-Oriented Vehicular Networks via\n  Constrained Learning", "comments": "JSAC, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a radio access network (RAN) slicing problem\nfor Internet of vehicles (IoV) services with different quality of service (QoS)\nrequirements, in which multiple logically-isolated slices are constructed on a\ncommon roadside network infrastructure. A dynamic RAN slicing framework is\npresented to dynamically allocate radio spectrum and computing resource, and\ndistribute computation workloads for the slices. To obtain an optimal RAN\nslicing policy for accommodating the spatial-temporal dynamics of vehicle\ntraffic density, we first formulate a constrained RAN slicing problem with the\nobjective to minimize long-term system cost. This problem cannot be directly\nsolved by traditional reinforcement learning (RL) algorithms due to complicated\ncoupled constraints among decisions. Therefore, we decouple the problem into a\nresource allocation subproblem and a workload distribution subproblem, and\npropose a two-layer constrained RL algorithm, named Resource Allocation and\nWorkload diStribution (RAWS) to solve them. Specifically, an outer layer first\nmakes the resource allocation decision via an RL algorithm, and then an inner\nlayer makes the workload distribution decision via an optimization subroutine.\nExtensive trace-driven simulations show that the RAWS effectively reduces the\nsystem cost while satisfying QoS requirements with a high probability, as\ncompared with benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 15:08:38 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Wu", "Wen", ""], ["Chen", "Nan", ""], ["Zhou", "Conghao", ""], ["Li", "Mushu", ""], ["Shen", "Xuemin", ""], ["Zhuang", "Weihua", ""], ["Li", "Xu", ""]]}, {"id": "2012.02131", "submitter": "Zaid Alzaid", "authors": "Zaid ALzaid, Xin Yuan, Saptarshi Bhowmik", "title": "Multi-Path Routing on the Jellyfish Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Jellyfish network has recently be proposed as an alternate to the\nfat-tree network as the interconnect for data centers and high performance\ncomputing clusters. Jellyfish adopts a random regular graph as its topology and\nhas been showed to be more cost-effective than fat-trees. Effective routing on\nJellyfish is challenging. It is known that shortest path routing and equal-cost\nmulti-path routing (ECMP) do not work well on Jellyfish. Existing schemes use\nvariations of k-shortest path routing (KSP). In this work, we study two routing\ncomponents for Jellyfish: path selection that decides the paths to route\ntraffic, and routing mechanisms that decide which path to be used for each\npacket. We show that the performance of the existing KSP can be significantly\nimproved by incorporating two heuristics, randomization and edge-disjointness.\nWe evaluate a range of routing mechanisms including traffic oblivious and\ntraffic adaptive schemes and identify an adaptive routing scheme that has\nsignificantly higher performance than others including the Universal Globally\nAdaptive Load-balance (UGAL) routing.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:10:06 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["ALzaid", "Zaid", ""], ["Yuan", "Xin", ""], ["Bhowmik", "Saptarshi", ""]]}, {"id": "2012.02136", "submitter": "Xingqin Lin", "authors": "Jonas Sedin, Luca Feltrin, and Xingqin Lin", "title": "Throughput and Capacity Evaluation of 5G New Radio Non-Terrestrial\n  Networks with LEO Satellites", "comments": "6 pages, 5 figures, accepted by IEEE Globecom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A non-terrestrial network (NTN), a term coined by the 3rd Generation\nPartnership Project (3GPP), refers to a network utilizing airborne or\nspaceborne payload for communication. The use of NTN has the potential of\nfacilitating providing connectivity to underserved areas. This has motivated\nthe work in 3GPP on evolving the fifth generation (5G) wireless access\ntechnology, known as new radio (NR), to support NTN. The broadband\nopportunities promised by NTN with low Earth orbit (LEO) satellites have\nattracted much attention, but the performance of LEO NTN using 5G NR has not\nbeen well studied. In this paper, we address this gap by analyzing and\nevaluating the throughput and capacity performance of LEO NTN. The evaluation\nresults show that the downlink capacity of a LEO satellite in S band with 30\nMHz bandwidth serving handheld terminal is about 600 Mbps and the downlink\ncapacity of a LEO satellite in Ka band with 400 MHz bandwidth serving very\nsmall aperture terminal (VSAT) is about 7 Gbps. For a LEO NTN similar to the\nKuiper project proposed by Amazon, we find that, due to the large cell sizes in\nthe LEO NTN, the area capacity density is moderate: 1-10 kbps/km$^2$ in the S\nband downlink and 14-120 kbps/km$^2$ in the Ka band downlink depending on\nlatitude.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:16:53 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Sedin", "Jonas", ""], ["Feltrin", "Luca", ""], ["Lin", "Xingqin", ""]]}, {"id": "2012.02160", "submitter": "Brian Kim", "authors": "Brian Kim and Yalin E. Sagduyu and Tugba Erpek and Kemal Davaslioglu\n  and Sennur Ulukus", "title": "Channel Effects on Surrogate Models of Adversarial Attacks against\n  Wireless Signal Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a wireless communication system that consists of a background\nemitter, a transmitter, and an adversary. The transmitter is equipped with a\ndeep neural network (DNN) classifier for detecting the ongoing transmissions\nfrom the background emitter and transmits a signal if the spectrum is idle.\nConcurrently, the adversary trains its own DNN classifier as the surrogate\nmodel by observing the spectrum to detect the ongoing transmissions of the\nbackground emitter and generate adversarial attacks to fool the transmitter\ninto misclassifying the channel as idle. This surrogate model may differ from\nthe transmitter's classifier significantly because the adversary and the\ntransmitter experience different channels from the background emitter and\ntherefore their classifiers are trained with different distributions of inputs.\nThis system model may represent a setting where the background emitter is a\nprimary user, the transmitter is a secondary user, and the adversary is trying\nto fool the secondary user to transmit even though the channel is occupied by\nthe primary user. We consider different topologies to investigate how different\nsurrogate models that are trained by the adversary (depending on the\ndifferences in channel effects experienced by the adversary) affect the\nperformance of the adversarial attack. The simulation results show that the\nsurrogate models that are trained with different distributions of\nchannel-induced inputs severely limit the attack performance and indicate that\nthe transferability of adversarial attacks is neither readily available nor\nstraightforward to achieve since surrogate models for wireless applications may\nsignificantly differ from the target model depending on channel effects.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:46:28 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 00:01:27 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Kim", "Brian", ""], ["Sagduyu", "Yalin E.", ""], ["Erpek", "Tugba", ""], ["Davaslioglu", "Kemal", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2012.02241", "submitter": "Quntao Zhuang", "authors": "Bingzhi Zhang and Quntao Zhuang", "title": "Quantum Internet under random breakdowns and intentional attacks", "comments": "5+3 pages, 10 figures. References fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum networks will play a key role in distributed quantum information\nprocessing. As the network size increases, network-level errors like random\nbreakdown and intentional attack are inevitable; therefore, it is important to\nunderstand the robustness of large-scale quantum networks, similar to what has\nbeen done for the classical counterpart -- the Internet. For exponential\nnetworks such as Waxman networks, errors simply re-parameterize the network and\nlead to a linear decrease of the quantum capacity with the probability of\nerror. The same linear decay happens for scale-free quantum networks under\nrandom breakdowns, despite the previously discovered robustness in terms of the\nconnectivity. In presence of attack, however, the capacity of scale-free\nquantum networks shows a sharp exponential decay with the increasing attack\nfraction. Our results apply to quantum internet based on fibers for all kinds\nof quantum communications and provide implications for the future construction\nof quantum networks with regard to its robustness.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 20:12:14 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 15:38:35 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Zhang", "Bingzhi", ""], ["Zhuang", "Quntao", ""]]}, {"id": "2012.02865", "submitter": "Seham Ebrahim", "authors": "Seham Muawadh Ali Ebrahim", "title": "Hybrid Chaotic Method for Medical Images Ciphering", "comments": null, "journal-ref": "International Journal of Network Security & Its Applications\n  (IJNSA) Vol.12, No.6, November 2020", "doi": "10.5121/ijnsa.2020.12601", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Healthcare is an essential application of e-services, where for diagnostic\ntesting, medical imaging acquiring, processing, analysis, storage, and\nprotection are used. Image ciphering during storage and transmission over the\nnetworks used has seen implemented using many types of ciphering algorithms for\nsecurity purpose. Current cyphering algorithms are classified into two types:\ntraditional classical cryptography using standard algorithms (DES, AES, IDEA,\nRC5, RSA, ...) and chaos cryptography using continuous (Chau, Rossler, Lorenz,\n...) or discreet (Logistics, Henon, ...) algorithms. The traditional algorithms\nhave struggled to combat image data as compared to regular textual data.\nWhereas, the chaotic algorithms are more efficient for image ciphering. The\nSignificance characteristics of chaos are its extreme sensitivity to initial\nconditions and algorithm parameters. In this paper, medical image security\nbased on hybrid/mixed chaotic algorithms is proposed. The proposed method is\nimplemented using MATLAB. Where the image of the Retina of the Eye to detect\nBlood Vessels is ciphered. The Pseudo-Random Numbers Generators (PRNGs) from\nthe different chaotic algorithms are implemented, and their statistical\nproperties are evaluated using the National Institute of Standards and\nTechnology NIST and other statistical test-suits. Then, these algorithms are\nused to secure the data, where the statistical properties of the cipher-text\nare also tested. We propose two PRNGs to increase the complexity of the PRNGs\nand to allow many of the NIST statistical tests to be passed: one based on\ntwo-hybrid mixed chaotic logistic maps and one based on two-hybrid mixed\nchaotic Henon maps, where each chaotic algorithm runs side-by-side and starts\nwith random initial conditions and parameters (encryption keys). The resulting\nhybrid PRNGs passed many of the NIST statistical test suits.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 21:52:21 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ebrahim", "Seham Muawadh Ali", ""]]}, {"id": "2012.02955", "submitter": "Avi Mohan", "authors": "Shivam Vinayak Vatsa, Avi Mohan and Anurag Kumar", "title": "Implementing QZMAC (a Decentralized Delay Optimal MAC) over 6TiSCH under\n  the Contiki OS in an IEEE 802.15.4 Network", "comments": "4 pages, 3 figures, Comsnets 2021 (submitted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the emerging delay-sensitive applications of the Internet of\nThings (IoT), there has been a resurgence of interest in developing medium\naccess control (MAC) protocols in a time-slotted framework. The\nresource-constrained, ad-hoc nature of wireless networks typical of the IoT\nalso forces the amount of control information exchanged across the network --\nrequired to make scheduling decisions -- to a minimum. In a previous article we\nproposed a protocol called QZMAC that (i) provides provably low mean delay,\n(ii) has distributed control (i.e., there is no central scheduler), and (iii)\ndoes not require explicit exchange of state information or control signals. In\nthe present article, we implement and demonstrate the performance of QZMAC on a\ntest bed consisting of CC2420 based Crossbow telosB motes, running the 6TiSCH\ncommunication stack on the Contiki operating system over the 2.4GHz ISM band.\nQZMAC achieves its near-optimal delay performance using a clever combination of\npolling and contention modes. We demonstrate the polling and the contention\nmodes of QZMAC separately. We use an Adaptive Synchronization Technique in our\nimplementation which we also demonstrate. Our network shows good delay\nperformance even in the presence of heavy interference from ambient WiFi\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 06:00:41 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Vatsa", "Shivam Vinayak", ""], ["Mohan", "Avi", ""], ["Kumar", "Anurag", ""]]}, {"id": "2012.03005", "submitter": "Kaiyang Liu", "authors": "Kaiyang Liu (University of Victoria and Central South University), Jun\n  Peng (Central South University), Jingrong Wang (University of Toronto), and\n  Jianping Pan (University of Victoria)", "title": "Optimal Caching for Low Latency in Distributed Coded Storage Systems", "comments": "12 pages, 13 figures, submitted to IEEE/ACM Transactions on\n  Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Erasure codes have been widely considered a promising solution to enhance\ndata reliability at low storage costs. However, in modern geo-distributed\nstorage systems, erasure codes may incur high data access latency as they\nrequire data retrieval from multiple remote storage nodes. This hinders the\nextensive application of erasure codes to data-intensive applications. This\npaper proposes novel caching schemes to achieve low latency in distributed\ncoded storage systems. Experiments based on Amazon Simple Storage Service\nconfirm the positive correlation between the latency and the physical distance\nof data retrieval. The average data access latency is used the performance\nmetric to quantify the benefits of caching. Assuming that the future data\npopularity and network latency information is available, an offline caching\nscheme is proposed to find the optimal caching solution. Guided by the optimal\nscheme, an online caching scheme is proposed according to the measured data\npopularity and network latency information in real time. Experiment results\ndemonstrate that the online scheme can approximate the optimal scheme well with\ndramatically reduced computation complexity.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 11:13:06 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Liu", "Kaiyang", "", "University of Victoria and Central South University"], ["Peng", "Jun", "", "Central South University"], ["Wang", "Jingrong", "", "University of Toronto"], ["Pan", "Jianping", "", "University of Victoria"]]}, {"id": "2012.03165", "submitter": "Jianbing Ni", "authors": "Jianbing Ni and Kuan Zhang and Athanasios V. Vasilakos", "title": "Security and Privacy for Mobile Edge Caching: Challenges and Solutions", "comments": "This article has been accepted by IEEE Wireless Communications\n  Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile edge caching is a promising technology for the next-generation mobile\nnetworks to effectively offer service environment and cloud-storage\ncapabilities at the edge of networks. By exploiting the storage and computing\nresources at the network edge, mobile edge caching can significantly reduce\nservice latency, decrease network load, and improve user experience. On the\nother hand, edge caching is subject to a number of threats regarding privacy\nviolation and security breach. In this article, we first introduce the\narchitecture of mobile edge caching, and address the key problems regarding\nwhy, where, what, and how to cache. Then, we examine the potential cyber\nthreats, including cache poisoning attacks, cache pollution attacks, cache\nside-channel attacks, and cache deception attacks, which result in huge\nconcerns about privacy, security, and trust in content placement, content\ndelivery, and content usage for mobile users, respectively. After that, we\npropose a service-oriented and location-based efficient key distribution\nprotocol (SOLEK) as an example in response to efficient and secure content\ndelivery in mobile edge caching. Finally, we discuss the potential techniques\nfor privacy-preserving content placement, efficient and secure content\ndelivery, and trustful content usage, which are expected to draw more attention\nand efforts into secure edge caching.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 02:53:22 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ni", "Jianbing", ""], ["Zhang", "Kuan", ""], ["Vasilakos", "Athanasios V.", ""]]}, {"id": "2012.03181", "submitter": "Sanket Kalamkar", "authors": "Sanket S. Kalamkar, Fran\\c{c}ois Baccelli, Fuad M. Abinader Jr.,\n  Andrea S. Marcano Fani, Luis G. Uzeda Garcia", "title": "Beam Management in 5G: A Stochastic Geometry Analysis", "comments": "This is an extended version of the paper that was accepted at IEEE\n  GLOBECOM 2020. Comments are welcome. arXiv admin note: text overlap with\n  arXiv:2006.05027", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Beam management is central in the operation of beamformed wireless cellular\nsystems such as 5G New Radio (NR) networks. Focusing the energy radiated to\nmobile terminals (MTs) by increasing the number of beams per cell increases\nsignal power and decreases interference, and has hence the potential to bring\nmajor improvements on area spectral efficiency (ASE). This paper proposes a\nfirst system-level stochastic geometry model encompassing major aspects of the\nbeam management problem: frequencies, antenna configurations, and propagation;\nphysical layer, wireless links, and coding; network geometry, interference, and\nresource sharing; sensing, signaling, and mobility management. This model leads\nto a simple analytical expression for the effective rate that the typical user\ngets in this context. This in turn allows one to find the number of beams per\ncell and per MT that maximizes the effective ASE by offering the best tradeoff\nbetween beamforming gains and beam management operational overheads and costs,\nfor a wide variety of 5G network scenarios including millimeter wave (mmWave)\nand sub-6 GHz. As part of the system-level analysis, we define and analyze\nseveral underlying new and fundamental performance metrics that are of\nindependent interest. The numerical results discuss the effects of different\nsystemic tradeoffs and performance optimizations of mmWave and sub-6 GHz 5G\ndeployments.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 04:14:55 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kalamkar", "Sanket S.", ""], ["Baccelli", "Fran\u00e7ois", ""], ["Abinader", "Fuad M.", "Jr."], ["Fani", "Andrea S. Marcano", ""], ["Garcia", "Luis G. Uzeda", ""]]}, {"id": "2012.03213", "submitter": "Turgay Pamuklu", "authors": "Turgay Pamuklu, Melike Erol-Kantarci, Cem Ersoy", "title": "Reinforcement Learning Based Dynamic Function Splitting in Disaggregated\n  Green Open RANs", "comments": "Accepted Paper. 20XX IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses, in any\n  current or future media, including reprinting/republishing this material for\n  advertising or promotional purposes, creating new collective works, for\n  resale or redistribution to servers or lists, or reuse of any copyrighted\n  component of this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing momentum around Open RAN (O-RAN) initiatives, performing\ndynamic Function Splitting (FS) in disaggregated and virtualized Radio Access\nNetworks (vRANs), in an efficient way, is becoming highly important. An equally\nimportant efficiency demand is emerging from the energy consumption dimension\nof the RAN hardware and software. Supplying the RAN with Renewable Energy\nSources (RESs) promises to boost the energy-efficiency. Yet, FS in such a\ndynamic setting, calls for intelligent mechanisms that can adapt to the varying\nconditions of the RES supply and the traffic load on the mobile network. In\nthis paper, we propose a reinforcement learning (RL)-based dynamic function\nsplitting (RLDFS) technique that decides on the function splits in an O-RAN to\nmake the best use of RES supply and minimize operator costs. We also formulate\nan operational expenditure minimization problem. We evaluate the performance of\nthe proposed approach on a real data set of solar irradiation and traffic rate\nvariations. Our results show that the proposed RLDFS method makes effective use\nof RES and reduces the cost of an MNO. We also investigate the impact of the\nsize of solar panels and batteries which may guide MNOs to decide on proper RES\nand battery sizing for their networks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 08:29:13 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 11:28:46 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Pamuklu", "Turgay", ""], ["Erol-Kantarci", "Melike", ""], ["Ersoy", "Cem", ""]]}, {"id": "2012.03257", "submitter": "Liekang Zeng", "authors": "Liekang Zeng, Xu Chen, Zhi Zhou, Lei Yang, Junshan Zhang", "title": "CoEdge: Cooperative DNN Inference with Adaptive Workload Partitioning\n  over Heterogeneous Edge Devices", "comments": "Accepted by IEEE/ACM Transactions on Networking, Nov. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence have driven increasing intelligent\napplications at the network edge, such as smart home, smart factory, and smart\ncity. To deploy computationally intensive Deep Neural Networks (DNNs) on\nresource-constrained edge devices, traditional approaches have relied on either\noffloading workload to the remote cloud or optimizing computation at the end\ndevice locally. However, the cloud-assisted approaches suffer from the\nunreliable and delay-significant wide-area network, and the local computing\napproaches are limited by the constrained computing capability. Towards\nhigh-performance edge intelligence, the cooperative execution mechanism offers\na new paradigm, which has attracted growing research interest recently. In this\npaper, we propose CoEdge, a distributed DNN computing system that orchestrates\ncooperative DNN inference over heterogeneous edge devices. CoEdge utilizes\navailable computation and communication resources at the edge and dynamically\npartitions the DNN inference workload adaptive to devices' computing\ncapabilities and network conditions. Experimental evaluations based on a\nrealistic prototype show that CoEdge outperforms status-quo approaches in\nsaving energy with close inference latency, achieving up to 25.5%~66.9% energy\nreduction for four widely-adopted CNN models.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 13:15:52 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zeng", "Liekang", ""], ["Chen", "Xu", ""], ["Zhou", "Zhi", ""], ["Yang", "Lei", ""], ["Zhang", "Junshan", ""]]}, {"id": "2012.03293", "submitter": "Walid Aljoby", "authors": "Walid Aljoby, Xin Wang, Dinil Mon Divakaran, Tom Z. J. Fu, Richard T.\n  B. Ma", "title": "DiffPerf: Towards Performance Differentiation and Optimization with SDN\n  Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continuing the current trend, Internet traffic is expected to grow\nsignificantly over the coming years, with video traffic consuming the biggest\nshare. On the one hand, this growth poses challenges to access providers (APs),\nwho have to upgrade their infrastructure to meet the growing traffic demands as\nwell as find new ways to monetize their network resources. On the other hand,\ndespite numerous optimizations of the underlying transport protocol, a user's\nutilization of network bandwidth and is thus the user's perceived quality still\nbeing largely affected by network latency and buffer size. To address both\nconcerns, we propose DiffPerf, a class-based differentiation framework, that,\nat a macroscopic level dynamically allocates bandwidth to service classes\npre-defined by the APs, and at a microscopic level statistically differentiates\nand isolates user flows to help them achieve better performance. We implement\nDiffPerf on OpenDaylight SDN controller and programmable Barefoot Tofino switch\nand evaluate it from an application perspective for MPEG-DASH video streaming.\nOur evaluations demonstrate the practicality and flexibility that DiffPerf\nprovides APs with capabilities through which a spectrum of qualities are\nprovisioned at multiple classes. Meanwhile, it assists in achieving better\nfairness and improving overall user's perceived quality within the same class.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 15:50:37 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Aljoby", "Walid", ""], ["Wang", "Xin", ""], ["Divakaran", "Dinil Mon", ""], ["Fu", "Tom Z. J.", ""], ["Ma", "Richard T. B.", ""]]}, {"id": "2012.03403", "submitter": "Changsheng You", "authors": "Changsheng You, Beixiong Zheng, and Rui Zhang", "title": "How to Deploy Intelligent Reflecting Surfaces in Wireless Network:\n  BS-side, User-side, or Both Sides?", "comments": "This article addresses the important issue of how to deploy IRSs in a\n  wireless network to achieve its optimum performance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The performance of wireless communication systems is fundamentally\nconstrained by the random and uncontrollable wireless channel. By leveraging\nthe recent advance in digitally-controlled metasurface, intelligent reflecting\nsurface (IRS) has emerged as a promising solution to enhance the wireless\nnetwork performance by smartly reconfiguring the radio propagation environment.\nDespite the substantial research on IRS-aided communications, this article\naddresses the important issue of how to deploy IRSs in a wireless network to\nachieve its optimum performance. We first compare the two conventional\nstrategies of deploying IRS at the side of base station or distributed users in\nterms of various communication performance metrics, and then propose a new\nhybrid IRS deployment strategy by combining their complementary advantages.\nMoreover, the main challenges in optimizing IRS deployment as well as their\npromising solutions are discussed. A case study is also presented to compare\nthe performance of different IRS deployment strategies and draw useful insights\nfor practical design.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 01:00:34 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 01:42:54 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["You", "Changsheng", ""], ["Zheng", "Beixiong", ""], ["Zhang", "Rui", ""]]}, {"id": "2012.03670", "submitter": "Umut Can Cabuk", "authors": "Umut Can Cabuk", "title": "Non-Repudiation for VoIP Communication in UMTS and LTE Networks", "comments": "Master's Thesis. Prepared in Fraunhofer SIT; defended in Aarhus\n  University, in 2015", "journal-ref": null, "doi": "10.13140/RG.2.2.14059.95526", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This thesis work presents an architectural design of a system to bring\nnon-repudiation concept into the IP based digital voice conversations (VoIP) in\nLTE and UMTS networks, using electronic signatures, by considering a\ncentralized approach. Moreover, functionalities and technical methods to\nsupport such a system are researched. Last but not least, ways to introduce\nthis system as a public and commercial service are discussed. Non-repudiation\nconcept provided by electronic signatures and related cryptographic functions,\nas introduced in this study, allow using digital records of these voice\nconversations as legally binding statements or proofs likewise and even instead\nof traditional wet signatures. The system is designed as a subsystem to IMS\nbased 3G and 4G networks and maximum compatibility with current configurations,\ncomponents and interfaces of these networks is intended. On the other hand\nnon-repudiation is achieved by special signature, storage and verification\nunits located in the IMS core network. Voice data is proposed to be processed\nin MRF unit of the IMS. Additionally, a USSD/USSI based special solution to\ninitiate these signed calls is developed. According to the proposed scheme;\nduring a signed call, two unidirectional voice streams originating from two\nparties of the call, which are transferred in IP and UDP encapsulated RTP\npackages, are received by the signature unit and interweaved using their\narrival times, so that they become a unified stream. Signature unit generates\nhashes of groups of received packages and signs them using PKI algorithms and\napplying hash/signature chaining to increase integrity protection and to\nempower non-repudiation. Then, it forwards packages and signature information\nto the storage unit. Storage unit keeps all the call records, signature data\nand metadata of these calls. Verification unit later gathers relevant data from\nthe storage unit...\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 23:40:26 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Cabuk", "Umut Can", ""]]}, {"id": "2012.03719", "submitter": "Valentin Poirot", "authors": "Valentin Poirot and Olaf Landsiedel", "title": "Dimmer: Self-Adaptive Network-Wide Flooding with Reinforcement Learning", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In low-power wireless networks, Synchronous transmissions (ST) protocols\nprovide high reliability and energy-efficiency in the presence of little or no\ninterference, while dependable ST protocols provide high reliability in harsher\nenvironments, through the use of custom rules, fixed configurations and higher\nretransmissions. Yet, such dependable solutions often trade energy-efficiency\nfor dependability, favoring wasting energy under normal conditions to survive\nhighly-interfered episodes. We argue that, complementary to their\ndependability, ST protocols should be adaptive: their wireless stack should (1)\ntackle external environment dynamics and (2) adapt to its topology over time.\n  We introduce Dimmer as a self-adaptive, all-to-all communication primitive.\nDimmer builds on LWB and uses Reinforcement Learning to tune its flooding\nparameters and match the current properties of the medium. By learning how to\nbehave from unlabeled traces, Dimmer adapts to different interference types and\npatterns, and is even able to tackle previously unseen interference. In\naddition, we share through Dimmer insights on how to efficiently design\nAI-based systems for constrained devices, and evaluate our protocol on two\ndeployments of 18 and 48 resource-constrained sensor nodes (4 MHz CPU, 10 kB\nRAM), showing it improves reliability under WiFi interference and IEEE 802.15.4\njamming, while turning superfluous transmitters off in the absence of\ndisturbances.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:19:33 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Poirot", "Valentin", ""], ["Landsiedel", "Olaf", ""]]}, {"id": "2012.03734", "submitter": "Anastasios Giovanidis", "authors": "Lin Chen and Anastasios Giovanidis and Wei Wang and Lin Shan", "title": "Sequential Resource Access: Theory and Algorithm", "comments": "10 pages double column, accepted paper at IEEE INFOCOM 2021. This is\n  the author-submitted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We formulate and analyze a generic sequential resource access problem arising\nin a variety of engineering fields, where a user disposes a number of\nheterogeneous computing, communication, or storage resources, each\ncharacterized by the probability of successfully executing the user's task and\nthe related access delay and cost, and seeks an optimal access strategy to\nmaximize her utility within a given time horizon, defined as the expected\nreward minus the access cost. We develop an algorithmic framework on the\n(near-)optimal sequential resource access strategy. We first prove that the\nproblem of finding an optimal strategy is NP-hard in general. Given the\nhardness result, we present a greedy strategy implementable in linear time, and\nestablish the closed-form sufficient condition for its optimality. We then\ndevelop a series of polynomial-time approximation algorithms achieving\n$(\\epsilon,\\delta)$-optimality, with the key component being a pruning process\neliminating dominated strategies and, thus maintaining polynomial time and\nspace overhead.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:33:44 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Chen", "Lin", ""], ["Giovanidis", "Anastasios", ""], ["Wang", "Wei", ""], ["Shan", "Lin", ""]]}, {"id": "2012.03776", "submitter": "Anastasios Giovanidis", "authors": "Theodoros Giannakas, Anastasios Giovanidis, Thrasyvoulos Spyropoulos", "title": "SOBA: Session optimal MDP-based network friendly recommendations", "comments": "10 pages double column, accepted at IEEE INFOCOM 2021. This is the\n  reviewed version submitted by the authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Caching content over CDNs or at the network edge has been solidified as a\nmeans to improve network cost and offer better streaming experience to users.\nFurthermore, nudging the users towards low-cost content has recently gained\nmomentum as a strategy to boost network performance. We focus on the problem of\noptimal policy design for Network Friendly Recommendations (NFR). We depart\nfrom recent modeling attempts, and propose a Markov Decision Process (MDP)\nformulation. MDPs offer a unified framework that can model a user with random\nsession length. As it turns out, many state-of-the-art approaches can be cast\nas subcases of our MDP formulation. Moreover, the approach offers flexibility\nto model users who are reactive to the quality of the received recommendations.\nIn terms of performance, for users consuming an arbitrary number of contents in\nsequence, we show theoretically and using extensive validation over real traces\nthat the MDP approach outperforms myopic algorithms both in session cost as\nwell as in offered recommendation quality. Finally, even compared to optimal\nstate-of-art algorithms targeting specific subcases, our MDP framework is\nsignificantly more efficient, speeding the execution time by a factor of 10,\nand enjoying better scaling with the content catalog and recommendation batch\nsizes.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:12:21 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Giannakas", "Theodoros", ""], ["Giovanidis", "Anastasios", ""], ["Spyropoulos", "Thrasyvoulos", ""]]}, {"id": "2012.04158", "submitter": "Hailiang Zhao", "authors": "Hailiang Zhao, Shuiguang Deng, Zijie Liu, Zhengzhe Xiang, Jianwei Yin", "title": "Placement is not Enough: Embedding with Proactive Stream Mapping on the\n  Heterogenous Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Edge computing is naturally suited to the applications generated by Internet\nof Things (IoT) nodes. The IoT applications generally take the form of directed\nacyclic graphs (DAGs), where vertices represent interdependent functions and\nedges represent data streams. The status quo of minimizing the makespan of the\nDAG motivates the study on optimal function placement. However, current\napproaches lose sight of proactively mapping the data streams to the physical\nlinks between the heterogenous edge servers, which could affect the makespan of\nDAGs significantly. To solve this problem, we study both function placement and\nstream mapping with data splitting simultaneously, and propose the algorithm\nDPE (Dynamic Programming-based Embedding). DPE is theoretically verified to\nachieve the global optimality of the embedding problem. The complexity analysis\nis also provided. Extensive experiments on Alibaba cluster trace dataset show\nthat DPE significantly outperforms two state-of-the-art joint function\nplacement and task scheduling algorithms in makespan by 43.19% and 40.71%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 01:46:31 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Zhao", "Hailiang", ""], ["Deng", "Shuiguang", ""], ["Liu", "Zijie", ""], ["Xiang", "Zhengzhe", ""], ["Yin", "Jianwei", ""]]}, {"id": "2012.04360", "submitter": "Sai Kireet Patri", "authors": "Sai Kireet Patri, Achim Autenrieth, J\\\"org-Peter Elbers, Carmen Mas\n  Machuca", "title": "Planning Optical Networks for Unexpected Traffic Growth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A lightpath configuration algorithm considering a multi-period traffic model\nis presented and evaluated to a realistic German core network\nstudy.~Strategically exploiting BVT excess capacity, we show that offered\ntraffic can be carried up to an additional five years in all traffic growth\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 11:15:14 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Patri", "Sai Kireet", ""], ["Autenrieth", "Achim", ""], ["Elbers", "J\u00f6rg-Peter", ""], ["Machuca", "Carmen Mas", ""]]}, {"id": "2012.04624", "submitter": "Spyridon Mastorakis", "authors": "Boubakr Nour and Hakima Khelifi and Rasheed Hussain and Spyridon\n  Mastorakis and Hassine Moungla", "title": "Access Control Mechanisms in Named Data Networks: A Comprehensive Survey", "comments": "This paper has been accepted for publication by the ACM Computing\n  Surveys. The final version will be published by the ACM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-Centric Networking (ICN) has recently emerged as a prominent\ncandidate for the Future Internet Architecture (FIA) that addresses existing\nissues with the host-centric communication model of the current TCP/IP-based\nInternet. Named Data Networking (NDN) is one of the most recent and active ICN\narchitectures that provides a clean slate approach for Internet communication.\nNDN provides intrinsic content security where security is directly provided to\nthe content instead of communication channel. Among other security aspects,\nAccess Control (AC) rules specify the privileges for the entities that can\naccess the content. In TCP/IP-based AC systems, due to the client-server\ncommunication model, the servers control which client can access a particular\ncontent. In contrast, ICN-based networks use content names to drive\ncommunication and decouple the content from its original location. This\nphenomenon leads to the loss of control over the content causing different\nchallenges for the realization of efficient AC mechanisms. To date,\nconsiderable efforts have been made to develop various AC mechanisms in NDN. In\nthis paper, we provide a detailed and comprehensive survey of the AC mechanisms\nin NDN. We follow a holistic approach towards AC in NDN where we first\nsummarize the ICN paradigm, describe the changes from channel-based security to\ncontent-based security and highlight different cryptographic algorithms and\nsecurity protocols in NDN. We then classify the existing AC mechanisms into two\nmain categories: Encryption-based AC and Encryption-independent AC. Each\ncategory has different classes based on the working principle of AC (e.g.,\nAttribute-based AC, Name-based AC, Identity-based AC, etc). Finally, we present\nthe lessons learned from the existing AC mechanisms and identify the challenges\nof NDN-based AC at large, highlighting future research directions for the\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 18:47:21 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Nour", "Boubakr", ""], ["Khelifi", "Hakima", ""], ["Hussain", "Rasheed", ""], ["Mastorakis", "Spyridon", ""], ["Moungla", "Hassine", ""]]}, {"id": "2012.04755", "submitter": "Thomas Sandholm", "authors": "Thomas Sandholm and Sayandev Mukherjee", "title": "A Multi-Armed Bandit-based Approach to Mobile Network Provider Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue for giving users the ability to lease bandwidth temporarily from any\nmobile network operator. We propose, prototype, and evaluate a spectrum market\nfor mobile network access, where multiple network operators offer blocks of\nbandwidth at specified prices for short-term leases to users, with autonomous\nagents on user devices making purchase decisions by trading off price,\nperformance, and budget constraints.\n  We show that the problem of provider selection can be formulated as a\nso-called Bandit problem. For the case where providers change prices\nsynchronously, we approach the problem through contextual multi-armed bandits\nand Reinforcement Learning methods like Q-learning either applied directly to\nthe bandit maximization problem or indirectly to approximate the Gittins\nindices that are known to yield the optimal provider selection policy. For a\nsimulated scenario corresponding to a practical use case, our agent shows a\n$20-41\\%$ QoE improvement over random provider selection under various demand,\nprice and mobility conditions.\n  We implemented a prototype spectrum market using LTE networks and eSIM\ntechology and deployed it on a testbed, using a blockchain to implement the\nledger where bandwidth purchase transactions are recorded. Experiments showed\nthat we can learn both user behavior and network performance efficiently, and\nrecorded $25-74\\%$ improvements in QoE under various competing agent scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 21:50:00 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 23:17:39 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Sandholm", "Thomas", ""], ["Mukherjee", "Sayandev", ""]]}, {"id": "2012.04770", "submitter": "Michael Specter", "authors": "John Meklenburg, Michael Specter, Michael Wentz, Hari Balakrishnan,\n  Anantha Chandrakasan, John Cohn, Gary Hatke, Louise Ivers, Ronald Rivest,\n  Gerald Jay Sussman, Daniel Weitzner", "title": "SonicPACT: An Ultrasonic Ranging Method for the Private Automated\n  Contact Tracing (PACT) Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Throughout the course of the COVID-19 pandemic, several countries have\ndeveloped and released contact tracing and exposure notification smartphone\napplications (apps) to help slow the spread of the disease. To support such\napps, Apple and Google have released Exposure Notification Application\nProgramming Interfaces (APIs) to infer device (user) proximity using Bluetooth\nLow Energy (BLE) beacons. The Private Automated Contact Tracing (PACT) team has\nshown that accurately estimating the distance between devices using only BLE\nradio signals is challenging. This paper describes the design and\nimplementation of the SonicPACT protocol to use near-ultrasonic signals on\ncommodity iOS and Android smartphones to estimate distances using\ntime-of-flight measurements. The protocol allows Android and iOS devices to\ninteroperate, augmenting and improving the current exposure notification APIs.\nOur initial experimental results are promising, suggesting that SonicPACT\nshould be considered for implementation by Apple and Google.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 22:33:39 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Meklenburg", "John", ""], ["Specter", "Michael", ""], ["Wentz", "Michael", ""], ["Balakrishnan", "Hari", ""], ["Chandrakasan", "Anantha", ""], ["Cohn", "John", ""], ["Hatke", "Gary", ""], ["Ivers", "Louise", ""], ["Rivest", "Ronald", ""], ["Sussman", "Gerald Jay", ""], ["Weitzner", "Daniel", ""]]}, {"id": "2012.04774", "submitter": "Biplav Choudhury", "authors": "Biplav Choudhury, Vijay K. Shah, Avik Dayal, and Jeffrey H. Reed", "title": "Joint Age of Information and Self Risk Assessment for Safer 802.11p\n  based V2V Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging 802.11p vehicle-to-vehicle (V2V) networks rely on periodic Basic\nSafety Messages (BSMs) to disseminate time-sensitive safety-critical\ninformation, such as vehicle position, speed, and heading -- that enables\nseveral safety applications and has the potential to improve on-road safety.\nDue to mobility, lack of global-knowledge and limited communication resources,\ndesigning an optimal BSM broadcast rate-control protocol is challenging.\nRecently, minimizing Age of Information (AoI) has gained momentum in designing\nBSM broadcast rate-control protocols. In this paper, we show that minimizing\nAoI solely does not always improve the safety of V2V networks. Specifically, we\npropose a novel metric, termed Trackability-aware Age of Information TAoI, that\nin addition to AoI, takes into account the self risk assessment of vehicles,\nquantified in terms of self tracking error (self-TE) -- which provides an\nindication of collision risk posed by the vehicle. Self-TE is defined as the\ndifference between the actual location of a certain vehicle and its\nself-estimated location. Our extensive experiments, based on realistic SUMO\ntraffic traces on top of ns-3 simulator, demonstrate that TAoI based\nrate-protocol significantly outperforms baseline AoI based rate protocol and\ndefault $10$ Hz broadcast rate in terms of safety performance, i.e., collision\nrisk, in all considered V2V settings.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 22:44:25 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 22:44:28 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Choudhury", "Biplav", ""], ["Shah", "Vijay K.", ""], ["Dayal", "Avik", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "2012.04840", "submitter": "Medhat Elsayed", "authors": "Medhat Elsayed, Melike Erol-Kantarci, Halim Yanikomeroglu", "title": "Transfer Reinforcement Learning for 5G-NR mm-Wave Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we aim at interference mitigation in 5G millimeter-Wave\n(mm-Wave) communications by employing beamforming and Non-Orthogonal Multiple\nAccess (NOMA) techniques with the aim of improving network's aggregate rate.\nDespite the potential capacity gains of mm-Wave and NOMA, many technical\nchallenges might hinder that performance gain. In particular, the performance\nof Successive Interference Cancellation (SIC) diminishes rapidly as the number\nof users increases per beam, which leads to higher intra-beam interference.\nFurthermore, intersection regions between adjacent cells give rise to\ninter-beam inter-cell interference. To mitigate both interference levels,\noptimal selection of the number of beams in addition to best allocation of\nusers to those beams is essential. In this paper, we address the problem of\njoint user-cell association and selection of number of beams for the purpose of\nmaximizing the aggregate network capacity. We propose three machine\nlearning-based algorithms; transfer Q-learning (TQL), Q-learning, and Best SINR\nassociation with Density-based Spatial Clustering of Applications with Noise\n(BSDC) algorithms and compare their performance under different scenarios.\nUnder mobility, TQL and Q-learning demonstrate 12% rate improvement over BSDC\nat the highest offered traffic load. For stationary scenarios, Q-learning and\nBSDC outperform TQL, however TQL achieves about 29% convergence speedup\ncompared to Q-learning.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 03:19:02 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Elsayed", "Medhat", ""], ["Erol-Kantarci", "Melike", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "2012.04861", "submitter": "Pedro Enrique Iturria Rivera Mr.", "authors": "Pedro Enrique Iturria Rivera, Shahram Mollahasani, Melike\n  Erol-Kantarci", "title": "Multi Agent Team Learning in Disaggregated Virtualized Open Radio Access\n  Networks (O-RAN)", "comments": "7 pages, 3 figures, 1 table, submitted to IEEE Wireless\n  Communications Magazine on Feb, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Starting from the Cloud Radio Access Network (C-RAN), continuing with the\nvirtual Radio Access Network (vRAN) and most recently with Open RAN (O-RAN)\ninitiative, Radio Access Network (RAN) architectures have significantly evolved\nin the past decade. In the last few years, the wireless industry has witnessed\na strong trend towards disaggregated, virtualized and open RANs, with numerous\ntests and deployments world wide. One unique aspect that motivates this paper\nis the availability of new opportunities that arise from using machine learning\nto optimize the RAN in closed-loop, i.e. without human intervention, where the\ncomplexity of disaggregation and virtualization makes well-known Self-Organized\nNetworking (SON) solutions inadequate. In our view, Multi-Agent Systems (MASs)\nwith team learning, can play an essential role in the control and coordination\nof controllers of O-RAN, i.e. near-real-time and non-real-time RAN Intelligent\nController (RIC). In this article, we first present the state-of-the-art\nresearch in multi-agent systems and team learning, then we provide an overview\nof the landscape in RAN disaggregation and virtualization, as well as O-RAN\nwhich emphasizes the open interfaces introduced by the O-RAN Alliance. We\npresent a case study for agent placement and the AI feedback required in O-RAN,\nand finally, we identify challenges and open issues to provide a roadmap for\nresearchers.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 04:47:07 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 03:41:10 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Rivera", "Pedro Enrique Iturria", ""], ["Mollahasani", "Shahram", ""], ["Erol-Kantarci", "Melike", ""]]}, {"id": "2012.04982", "submitter": "Manisha Luthra", "authors": "Manisha Luthra, Sebastian Hennig, Kamran Razavi, Lin Wang and Boris\n  Koldehofe", "title": "Operator as a Service: Stateful Serverless Complex Event Processing", "comments": "10 pages, Published in the Proceedings of the IEEE International\n  Conference on Big Data", "journal-ref": "2020 IEEE International Conference on Big Data (Big Data)", "doi": "10.1109/BigData50022.2020.9378142", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Complex Event Processing (CEP) is a powerful paradigm for scalable data\nmanagement that is employed in many real-world scenarios such as detecting\ncredit card fraud in banks. The so-called complex events are expressed using a\nspecification language that is typically implemented and executed on a specific\nruntime system. While the tight coupling of these two components has been\nregarded as the key for supporting CEP at high performance, such dependencies\npose several inherent challenges as follows. (1) Application development atop a\nCEP system requires extensive knowledge of how the runtime system operates,\nwhich is typically highly complex in nature. (2) The specification language\ndependence requires the need of domain experts and further restricts and\nsteepens the learning curve for application developers. In this paper, we\npropose CEPLESS, a scalable data management system that decouples the\nspecification from the runtime system by building on the principles of\nserverless computing. CEPLESS provides operator as a service and offers\nflexibility by enabling the development of CEP application in any specification\nlanguage while abstracting away the complexity of the CEP runtime system. As\npart of CEPLESS, we designed and evaluated novel mechanisms for in-memory\nprocessing and batching that enables the stateful processing of CEP operators\neven under high rates of ingested events. Our evaluation demonstrates that\nCEPLESS can be easily integrated into existing CEP systems like Apache Flink\nwhile attaining similar throughput under a high scale of events (up to 100K\nevents per second) and dynamic operator update in up to 238 ms.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 11:19:29 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 18:58:30 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 12:27:14 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Luthra", "Manisha", ""], ["Hennig", "Sebastian", ""], ["Razavi", "Kamran", ""], ["Wang", "Lin", ""], ["Koldehofe", "Boris", ""]]}, {"id": "2012.05003", "submitter": "Carlos Cilleruelo", "authors": "Carlos Cilleruelo, Luis de-Marcos, Javier Junquera-S\\'anchez and\n  Jos\\'e-Javier Mart\\'inez-Herr\\'aiz", "title": "Interconnection between darknets", "comments": null, "journal-ref": null, "doi": "10.1109/MIC.2020.3037723", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tor and i2p networks are two of the most popular darknets. Both darknets have\nbecome an area of illegal activities highlighting the necessity to study and\nanalyze them to identify and report illegal content to Law Enforcement Agencies\n(LEAs). This paper analyzes the connections between the Tor network and the i2p\nnetwork. We created the first dataset that combines information from Tor and\ni2p networks. The dataset contains more than 49k darknet services. The process\nof building and analyzing the dataset shows that it is not possible to explore\none of the networks without considering the other. Both networks work as an\necosystem and there are clear paths between them. Using graph analysis, we also\nidentified the most relevant domains, the prominent types of services in each\nnetwork, and their relations. Findings are relevant to LEAs and researchers\naiming to crawl and investigate i2p and Tor networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 12:30:23 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Cilleruelo", "Carlos", ""], ["de-Marcos", "Luis", ""], ["Junquera-S\u00e1nchez", "Javier", ""], ["Mart\u00ednez-Herr\u00e1iz", "Jos\u00e9-Javier", ""]]}, {"id": "2012.05070", "submitter": "Manisha Luthra", "authors": "Manisha Luthra, Johannes Pfannm\\\"uller, Boris Koldehofe, Jonas\n  H\\\"ochst, Artur Sterz, Rhaban Hark and Bernd Freisleben", "title": "Efficient Complex Event Processing in Information-centric Networking at\n  the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information-centric Networking (ICN) is an emerging Internet architecture\nthat offers promising features, such as in-network caching and named data\naddressing, to support the edge computing paradigm, in particular\nInternet-of-Things (IoT) applications. ICN can benefit from Complex Event\nProcessing (CEP), which is an in-network processing paradigm to specify and\nperform efficient query operations on data streams. However, integrating CEP\ninto ICN is a challenging task due to the following reasons: (1) typical ICN\narchitectures do not provide support for forwarding and processing continuous\ndata streams; (2) IoT applications often need short response times and require\nrobust event detection, which both are hard to accomplish using existing CEP\nsystems.\n  In this article, we present a novel network architecture, called INetCEP, for\nefficient CEP-based in-network processing as part of ICN. INetCEP enables\nefficient data processing in ICN by means of (1) a unified communication model\nthat supports continuous data streams, (2) a meta query language for CEP to\nspecify data processing operations in the data plane, and (3) query processing\nalgorithms to resolve the specified operations. Our experimental results for\ntwo IoT use cases and datasets show that INetCEP offers very short response\ntimes of up to 73 {\\mu}s under high workload and is more than 15X faster in\nterms of forwarding events than the state-of-the-art CEP system Flink.\nFurthermore, the delivery and processing of complex queries is around 32X\nfaster than Flink and more than 100X faster than a naive pull-based reference\napproach, while maintaining 100% accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 14:22:34 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 22:26:49 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Luthra", "Manisha", ""], ["Pfannm\u00fcller", "Johannes", ""], ["Koldehofe", "Boris", ""], ["H\u00f6chst", "Jonas", ""], ["Sterz", "Artur", ""], ["Hark", "Rhaban", ""], ["Freisleben", "Bernd", ""]]}, {"id": "2012.05109", "submitter": "Bo Zhou", "authors": "Bo Zhou and Walid Saad", "title": "Performance Analysis of Age of Information in Ultra-Dense Internet of\n  Things (IoT) Systems with Noisy Channels", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a dense Internet of Things (IoT) monitoring system is studied\nin which a large number of devices contend for transmitting timely status\npackets to their corresponding receivers over wireless noisy channels, using a\ncarrier sense multiple access (CSMA) scheme. When each device completes one\ntransmission, due to possible transmission failure, two cases with and without\ntransmission feedback to each device must be considered. Particularly, for the\ncase with no feedback, the device uses policy (I): It will go to an idle state\nand release the channel regardless of the outcome of the transmission. For the\ncase with perfect feedback, if the transmission succeeds, the device will go to\nan idle state, otherwise, it uses either policy (W), i.e., it will go to a\nwaiting state and re-contend for channel access; or it uses policy (S), i.e.,\nit will stay at a service state and occupy this channel to attempt another\ntransmission. For those three policies, the closed-form expressions of the\naverage age of information (AoI) of each device are characterized under schemes\nwith and without preemption in service. It is shown that, for each policy, the\nscheme with preemption in service always achieves a smaller average AoI,\ncompared with the scheme without preemption. Then, a mean-field approximation\napproach with guaranteed accuracy is developed to analyze the asymptotic\nperformance for the considered system with an infinite number of devices and\nthe effects of the system parameters on the average AoI are characterized.\nSimulation results show that the proposed mean-field approximation is accurate\neven for a small number of devices. The results also show that policy (S)\nachieves the smallest average AoI compared with policies (I) and (W), and the\naverage AoI does not always decrease with the arrival rate for all three\npolicies.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 15:30:07 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Zhou", "Bo", ""], ["Saad", "Walid", ""]]}, {"id": "2012.05137", "submitter": "Ekram Hossain", "authors": "Mohammad Salehi and Ekram Hossain", "title": "Federated Learning in Unreliable and Resource-Constrained Cellular\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With growth in the number of smart devices and advancements in their\nhardware, in recent years, data-driven machine learning techniques have drawn\nsignificant attention. However, due to privacy and communication issues, it is\nnot possible to collect this data at a centralized location. Federated learning\nis a machine learning setting where the centralized location trains a learning\nmodel over remote devices. Federated learning algorithms cannot be employed in\nthe real world scenarios unless they consider unreliable and\nresource-constrained nature of the wireless medium. In this paper, we propose a\nfederated learning algorithm that is suitable for cellular wireless networks.\nWe prove its convergence, and provide the optimal scheduling policy that\nmaximizes the convergence rate. We also study the effect of local computation\nsteps and communication steps on the convergence of the proposed algorithm. We\nprove, in practice, federated learning algorithms may solve a different problem\nthan the one that they have been employed for if the unreliability of wireless\nchannels is neglected. Finally, through numerous experiments on real and\nsynthetic datasets, we demonstrate the convergence of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 16:16:43 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Salehi", "Mohammad", ""], ["Hossain", "Ekram", ""]]}, {"id": "2012.05239", "submitter": "Manisha Luthra", "authors": "Manisha Luthra, Boris Koldehofe, Jonas H\\\"ochst, Patrick Lampe, Ali\n  Haider Rizvi, Ralf Kundel and Bernd Freisleben", "title": "INetCEP: In-Network Complex Event Processing for Information-Centric\n  Networking", "comments": "arXiv admin note: text overlap with arXiv:2012.05070", "journal-ref": "2019 ACM/IEEE Symposium on Architectures for Networking and\n  Communications Systems (ANCS), Cambridge, United Kingdom, 2019, pp. 1-13", "doi": "10.1109/ANCS.2019.8901877", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging network architectures like Information-centric Networking (ICN)\noffer simplicity in the data plane by addressing named data. Such flexibility\nopens up the possibility to move data processing inside network elements for\nhigh-performance computation, known as in-network processing. However, existing\nICN architectures are limited in terms of data plane programmability due to the\nlack of (i) in-network processing and (ii) data plane programming abstractions.\nSuch architectures can benefit from Complex Event Processing (CEP), an\nin-network processing paradigm to efficiently process data inside the data\nplane. Yet, it is extremely challenging to integrate CEP because the current\ncommunication model of ICN is limited to consumer-initiated interaction that\ncomes with significant overhead in a number of requests to process continuous\ndata streams. In contrast, a change to producer-initiated interaction, as\nfavored by CEP, imposes severe limitations for request-reply interactions. In\nthis paper, we propose an in-network CEP architecture, INetCEP that supports\nunified interaction patterns (consumer- and producer-initiated). In addition,\nwe provide a CEP query language and facilitate CEP operations while increasing\nthe range of applications that can be supported by ICN. We provide an\nopen-source implementation and evaluation of INetCEP over an ICN architecture,\nNamed Function Networking, and two applications: energy forecasting in smart\nhomes and a disaster scenario.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 14:56:01 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 18:52:48 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Luthra", "Manisha", ""], ["Koldehofe", "Boris", ""], ["H\u00f6chst", "Jonas", ""], ["Lampe", "Patrick", ""], ["Rizvi", "Ali Haider", ""], ["Kundel", "Ralf", ""], ["Freisleben", "Bernd", ""]]}, {"id": "2012.05266", "submitter": "Lorenzo Valerio", "authors": "Lorenzo Valerio, Andrea Passarella, Marco Conti", "title": "Optimising cost vs accuracy of decentralised analytics in fog computing\n  environments", "comments": "Submitted to IEEE TNSE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential growth of devices and data at the edges of the Internet is\nrising scalability and privacy concerns on approaches based exclusively on\nremote cloud platforms. Data gravity, a fundamental concept in Fog Computing,\npoints towards decentralisation of computation for data analysis, as a viable\nalternative to address those concerns. Decentralising AI tasks on several\ncooperative devices means identifying the optimal set of locations or\nCollection Points (CP for short) to use, in the continuum between full\ncentralisation (i.e., all data on a single device) and full decentralisation\n(i.e., data on source locations). We propose an analytical framework able to\nfind the optimal operating point in this continuum, linking the accuracy of the\nlearning task with the corresponding network and computational cost for moving\ndata and running the distributed training at the CPs. We show through\nsimulations that the model accurately predicts the optimal trade-off, quite\noften an intermediate point between full centralisation and full\ndecentralisation, showing also a significant cost saving w.r.t. both of them.\nFinally, the analytical model admits closed-form or numeric solutions, making\nit not only a performance evaluation instrument but also a design tool to\nconfigure a given distributed learning task optimally before its deployment.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 19:05:44 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 12:58:11 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Valerio", "Lorenzo", ""], ["Passarella", "Andrea", ""], ["Conti", "Marco", ""]]}, {"id": "2012.05490", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Cedrik Sch\\\"uler and Manuel Patchou and Christian\n  Wietfeld", "title": "PARRoT: Predictive Ad-hoc Routing Fueled by Reinforcement Learning and\n  Trajectory Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Swarms of collaborating Unmanned Aerial Vehicles (UAVs) that utilize ad-hoc\nnetworking technologies for coordinating their actions offer the potential to\ncatalyze emerging research fields such as autonomous exploration of disaster\nareas, demanddriven network provisioning, and near field packet delivery in\nIntelligent Transportation Systems (ITSs). As these mobile robotic networks are\ncharacterized by high grades of relative mobility, existing routing protocols\noften fail to adopt their decision making to the implied network topology\ndynamics. For addressing these challenges, we present Predictive Ad-hoc Routing\nfueled by Reinforcement learning and Trajectory knowledge (PARRoT) as a novel\nmachine learning-enabled routing protocol which exploits mobility control\ninformation for integrating knowledge about the future motion of the mobile\nagents into the routing process. The performance of the proposed routing\napproach is evaluated using comprehensive network simulation. In comparison to\nestablished routing protocols, PARRoT achieves a massively higher robustness\nand a significantly lower end-to-end latency.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 07:29:14 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Sch\u00fcler", "Cedrik", ""], ["Patchou", "Manuel", ""], ["Wietfeld", "Christian", ""]]}, {"id": "2012.05507", "submitter": "Ali Esswie Dr.", "authors": "Ali A. Esswie and Klaus I. Pedersen", "title": "Analysis of Outage Latency and Throughput Performance in Industrial\n  Factory 5G TDD Deployments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The fifth generation (5G) new radio supports a diversity of network\ndeployments. The industrial factory (InF) wireless automation use cases are\nemerging and drawing an increasing attention of the 5G new radio\nstandardization groups. Therefore, in this paper, we propose a service-aware\ntime division duplexing (TDD) frame selection framework for multi-traffic\ndeployments. We evaluate the performance of the InF network deployments with\nthe state-of-the-art 3GPP modeling assumptions. In particular, we consider the\ndynamic TDD mode along with optimized uplink power control settings.\nMulti-traffic coexistence scenarios are also incorporated such that quality of\nservice (QoS) aware dynamic user scheduling and TDD link selection are\nintroduced. Extensive system level simulations are performed in order to\nevaluate the performance of the proposed solutions, where the proposed\nQoS-aware scheme shows 68% URLLC outage latency reduction compared to the\nQoS-unaware solutions. Finally, the paper offers insightful conclusions and\ndesign recommendations on the TDD radio frame selection, uplink power control\nsettings and the best QoS-coexistence practices, in order to achieve a decent\nURLLC outage latency performance in the state-of-the-art InF deployments.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 08:27:51 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Esswie", "Ali A.", ""], ["Pedersen", "Klaus I.", ""]]}, {"id": "2012.05517", "submitter": "Quan Chen", "authors": "Quan Chen, Hai Zhu, Lei Yang, Xiaoqian Chen, Sofie Pollin, and Evgenii\n  Vinogradov", "title": "Edge Computing Assisted Autonomous Flight for UAV: Synergies between\n  Vision and Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous flight for UAVs relies on visual information for avoiding\nobstacles and ensuring a safe collision-free flight. In addition to visual\nclues, safe UAVs often need connectivity with the ground station. In this\npaper, we study the synergies between vision and communications for edge\ncomputing-enabled UAV flight. By proposing a framework of Edge Computing\nAssisted Autonomous Flight (ECAAF), we illustrate that vision and\ncommunications can interact with and assist each other with the aid of edge\ncomputing and offloading, and further speed up the UAV mission completion.\nECAAF consists of three functionalities that are discussed in detail: edge\ncomputing for 3D map acquisition, radio map construction from the 3D map, and\nonline trajectory planning. During ECAAF, the interactions of communication\ncapacity, video offloading, 3D map quality, and channel state of the trajectory\nform a positive feedback loop. Simulation results verify that the proposed\nmethod can improve mission performance by enhancing connectivity. Finally, we\nconclude with some future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 09:00:25 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Chen", "Quan", ""], ["Zhu", "Hai", ""], ["Yang", "Lei", ""], ["Chen", "Xiaoqian", ""], ["Pollin", "Sofie", ""], ["Vinogradov", "Evgenii", ""]]}, {"id": "2012.05520", "submitter": "Jingya Li", "authors": "Jingya Li, Demia Della Penda, Henrik Sahlin, Paul Schliwa-Bertling,\n  Mats Folke, Magnus Stattin", "title": "An Overview of 5G System Accessibility Differentiation and Control", "comments": "8 pages, 5 figures, 1 table, submitted to IEEE Communications\n  Standards Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  5G system is characterized by its capability to support a wide range of use\ncases and services. Supporting accessibility differentiation becomes therefore\nessential to preserve a stable network condition during high traffic load,\nwhile ensuring connection and service quality to prioritized devices and\nservices. In this article, we describe some use cases and requirements that\nimpact the 3GPP design of the 5G accessibility differentiation framework. We\nthen provide an overview of the supported mechanisms for accessibility\ndifferentiation and control in 5G Stand Alone (SA) system, including cell\nbarring and reservation, unified access control, paging control, random access\ncontrol and admission control. We discuss how these functionalities can be used\nto maintain the service quality and selectively limit the incoming traffic to\nthe network at high load situations, leveraging different connection-type\nindicators and connection-priority identifiers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 09:07:23 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 06:49:04 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Li", "Jingya", ""], ["Della Penda", "Demia", ""], ["Sahlin", "Henrik", ""], ["Schliwa-Bertling", "Paul", ""], ["Folke", "Mats", ""], ["Stattin", "Magnus", ""]]}, {"id": "2012.05829", "submitter": "Marceau Coupechoux", "authors": "Deepa Jagyasi and Marceau Coupechoux", "title": "Secure and Robust MIMO Transceiver for Multicast Mission Critical\n  Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Mission-critical communications (MCC) involve all communications between\npeople in charge of the safety of the civil society. MCC have unique\nrequirements that include improved reliability, security and group\ncommunication support. In this paper, we propose a secure and robust\nMultiple-Input-Multiple-Output (MIMO) transceiver, designed for multiple Base\nStations supporting multicast MCC in presence of multiple eavesdroppers. We\nformulate minimization problems with the Sum-Mean-Square-Error (SMSE) at\nlegitimate users as an objective function, and a lower bound for the MSE at\neavesdroppers as a constraint. Security is achieved thanks to physical layer\nsecurity mechanisms, namely MIMO beamforming and Artificial Noise (AN).\nReliability is achieved by designing a system which is robust to Channel State\nInformation errors. They can be of known distribution or norm-bounded. In the\nformer case, a coordinate descent algorithm is proposed to solve the problem.\nIn the latter case, we propose an worst-case based iterative algorithm.\nNumerical results at physical layer and system level reveal the crucial role of\nrobust designs for reliable MCC. We show the interest of both robust design and\nAN to improve the security gap. We show that full BS cooperation in preferred\nfor highly secured and reliable MCC but dynamic clustering allows to trade-off\nsecurity and reliability against capacity.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 17:09:33 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Jagyasi", "Deepa", ""], ["Coupechoux", "Marceau", ""]]}, {"id": "2012.05974", "submitter": "Michael Moy", "authors": "Michael Moy, Robert Cardona, Robert Green, Jacob Cleveland, Alan\n  Hylton, Robert Short", "title": "Path Optimization Sheaves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by efforts to incorporate sheaves into networking, we seek to\nreinterpret pathfinding algorithms in terms of cellular sheaves, using\nDijkstra's algorithm as an example. We construct sheaves on a graph with\ndistinguished source and sink vertices, in which paths are represented by\nsections. The first sheaf is a very general construction that can be applied to\nother algorithms, while the second is created specifically to capture the\ndecision making of Dijkstra's algorithm. In both cases, Dijkstra's algorithm\ncan be described as a systematic process of extending local sections to global\nsections. We discuss the relationship between the two sheaves and summarize how\nother pathfinding algorithms can be interpreted in a similar way. While the\nsheaves presented here address paths and pathfinding algorithms, we suggest\nthat future work could explore connections to other concepts from graph theory\nand other networking algorithms. This work was supported by the NASA Internship\nProject and SCaN Internship Project during the summer of 2020.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 20:59:27 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Moy", "Michael", ""], ["Cardona", "Robert", ""], ["Green", "Robert", ""], ["Cleveland", "Jacob", ""], ["Hylton", "Alan", ""], ["Short", "Robert", ""]]}, {"id": "2012.06001", "submitter": "Zaoxing Liu", "authors": "Zaoxing Liu, Hun Namkung, Anup Agarwal, Antonis Manousis, Peter\n  Steenkiste, Srinivasan Seshan, Vyas Sekar", "title": "Sketchy With a Chance of Adoption: Can Sketch-Based Telemetry Be Ready\n  for Prime Time?", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sketching algorithms or sketches have emerged as a promising alternative to\nthe traditional packet sampling-based network telemetry solutions. At a high\nlevel, they are attractive because of their high resource efficiency and\naccuracy guarantees. While there have been significant recent advances in\nvarious aspects of sketching for networking tasks, many fundamental challenges\nremain unsolved that are likely stumbling blocks for adoption. Our contribution\nin this paper is in identifying and formulating these research challenges\nacross the ecosystem encompassing network operators, platform\nvendors/developers, and algorithm designers. We hope that these serve as a\nnecessary fillip for the community to enable the broader adoption of\nsketch-based telemetry.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 22:28:51 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Liu", "Zaoxing", ""], ["Namkung", "Hun", ""], ["Agarwal", "Anup", ""], ["Manousis", "Antonis", ""], ["Steenkiste", "Peter", ""], ["Seshan", "Srinivasan", ""], ["Sekar", "Vyas", ""]]}, {"id": "2012.06118", "submitter": "Francisco Paiva Knebel", "authors": "Francisco Paiva Knebel, Juliano Araujo Wickboldt, Edison Pignaton de\n  Freitas", "title": "A Cloud-Fog Computing Architecture for Real-Time Digital Twins", "comments": "16 pages, 4 figures, 1 table, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Digital Twin systems are designed as two interconnected mirrored spaces, one\nreal and one virtual, each reflecting the other, sharing information, and\nmaking predictions based on analysis and simulations. The correct behavior of a\nreal-time Digital Twin depends not only on the logical results of computation\nbut also on the timing constraints. To cope with the large amounts of data that\nneed to be stored and analyzed, modern large scale Digital Twin deployments\noften rely on cloud-based architectures. A significant portion of the overall\nresponse time of a Digital Twin is spent on moving data from the edge to the\ncloud. Therefore, implementing Digital Twins using cloud-fog architectures\nemerges as an alternative to bring computing power closer to the edge, reducing\nlatency and allowing faster response times. This paper studies how suitable the\nuse of a cloud-fog architecture is to handle the real-time requirements of\nDigital Twins. Based on a realistic implementation and deployment of Digital\nTwin software components, it is possible to conclude that the distribution of\nDigital Twins in a fog computing setup can reduce response times, meeting its\nreal-time application requirements.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 04:29:52 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 18:12:13 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 06:38:30 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Knebel", "Francisco Paiva", ""], ["Wickboldt", "Juliano Araujo", ""], ["de Freitas", "Edison Pignaton", ""]]}, {"id": "2012.06182", "submitter": "Nasir Saeed", "authors": "Nasir Saeed, Heba Almorad, Hayssam Dahrouj, Tareq Y. Al-Naffouri, Jeff\n  S. Shamma, and Mohamed-Slim Alouini", "title": "Point-to-Point Communication in Integrated Satellite-Aerial Networks:\n  State-of-the-art and Future Challenges", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper overviews point-to-point (P2P) links for integrated\nsatellite-aerial networks, which are envisioned to be among the key enablers of\nthe sixth-generation (6G) of wireless networks vision. The paper first outlines\nthe unique characteristics of such integrated large-scale complex networks,\noften denoted by spatial networks, and focuses on two particular space-air\ninfrastructures, namely, satellites networks and high-altitude platforms\n(HAPs). The paper then classifies the connecting P2P communications links as\nsatellite-to-satellite links at the same layer (SSLL), satellite-to-satellite\nlinks at different layers (SSLD), and HAP-to-HAP links (HHL). The paper\noverviews each layer of such spatial networks separately, and highlights the\npossible natures of the connecting links (i.e., radio-frequency or free-space\noptics) with a dedicated overview to the existing link-budget results. The\npaper, afterwards, presents the prospective merit of realizing such an\nintegrated satellite-HAP network towards providing broadband services in\nunder-served and remote areas. Finally, the paper sheds light on several future\nresearch directions in the context of spatial networks, namely large-scale\nnetwork optimization, intelligent offloading, smart platforms, energy\nefficiency, multiple access schemes, and distributed spatial networks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 08:19:39 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Saeed", "Nasir", ""], ["Almorad", "Heba", ""], ["Dahrouj", "Hayssam", ""], ["Al-Naffouri", "Tareq Y.", ""], ["Shamma", "Jeff S.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2012.06198", "submitter": "Mohammadreza Doostmohammadian", "authors": "Mohammadreza Doostmohammadian, Hamid R. Rabiee", "title": "On the Observability and Controllability of Large-Scale IoT Networks:\n  Reducing Number of Unmatched Nodes via Link Addition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NI cs.SI cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study large-scale networks in terms of observability and\ncontrollability. In particular, we compare the number of unmatched nodes in two\nmain types of Scale-Free (SF) networks: the Barab{\\'a}si-Albert (BA) model and\nthe Holme-Kim (HK) model. Comparing the two models based on theory and\nsimulation, we discuss the possible relation between clustering coefficient and\nthe number of unmatched nodes. In this direction, we propose a new algorithm to\nreduce the number of unmatched nodes via link addition. The results are\nsignificant as one can reduce the number of unmatched nodes and therefore\nnumber of embedded sensors/actuators in, for example, an IoT network. This may\nsignificantly reduce the cost of controlling devices or monitoring cost in\nlarge-scale systems.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 09:10:51 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Doostmohammadian", "Mohammadreza", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "2012.06208", "submitter": "Lanfranco Zanzi", "authors": "Armin Okic, Lanfranco Zanzi, Vincenzo Sciancalepore, Alessandro\n  Redondi, Xavier Costa-Perez", "title": "$\\pi$-ROAD: a Learn-as-You-Go Framework for On-Demand Emergency Slices\n  in V2X Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vehicle-to-everything (V2X) is expected to become one of the main drivers of\n5G business in the near future. Dedicated \\emph{network slices} are envisioned\nto satisfy the stringent requirements of advanced V2X services, such as\nautonomous driving, aimed at drastically reducing road casualties. However, as\nV2X services become more mission-critical, new solutions need to be devised to\nguarantee their successful service delivery even in exceptional situations,\ne.g. road accidents, congestion, etc. In this context, we propose $\\pi$-ROAD, a\n\\emph{deep learning} framework to automatically learn regular mobile traffic\npatterns along roads, detect non-recurring events and classify them by severity\nlevel. $\\pi$-ROAD enables operators to \\emph{proactively} instantiate dedicated\n\\emph{Emergency Network Slices (ENS)} as needed while re-dimensioning the\nexisting slices according to their service criticality level. Our framework is\nvalidated by means of real mobile network traces collected within $400~km$ of a\nhighway in Europe and augmented with publicly available information on related\nroad events. Our results show that $\\pi$-ROAD successfully detects and\nclassifies non-recurring road events and reduces up to $30\\%$ the impact of ENS\non already running services.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 09:35:55 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Okic", "Armin", ""], ["Zanzi", "Lanfranco", ""], ["Sciancalepore", "Vincenzo", ""], ["Redondi", "Alessandro", ""], ["Costa-Perez", "Xavier", ""]]}, {"id": "2012.06433", "submitter": "Itamar Cohen", "authors": "Itamar Cohen", "title": "Advanced Algorithms in Heterogeneous and Uncertain Networking\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication networks are used today everywhere and on every scale: starting\nfrom small Internet of Things (IoT) networks at home, via campus and enterprise\nnetworks, and up to tier-one networks of Internet providers. Accordingly,\nnetwork devices should support a plethora of tasks with highly heterogeneous\ncharacteristics in terms of processing time, bandwidth energy consumption,\ndeadlines and so on. Evaluating these characteristics and the amount of\ncurrently available resources for handling them requires analyzing all the\narriving inputs, gathering information from numerous remote devices, and\nintegrating all this information. Performing all these tasks in real time is\nvery challenging in today's networking environments, which are characterized by\ntight bounds on the latency, and always-increasing data rates. Hence, network\nalgorithms should typically make decisions under uncertainty.\n  This work addresses optimizing performance in heterogeneous and uncertain\nnetworking environments. We begin by detailing the sources of heterogeneity and\nuncertainty and show that uncertainty appears in all layers of network design,\nincluding the time required to perform a task; the amount of available\nresources; and the expected gain from successfully completing a task. Next, we\nsurvey current solutions and show their limitations. Based on these insights we\ndevelop general design concepts to tackle heterogeneity and uncertainty, and\nthen use these concepts to design practical algorithms. For each of our\nalgorithms, we provide rigorous mathematical analysis, thus showing worst-case\nperformance guarantees. Finally, we implement and run the suggested algorithms\non various input traces, thus obtaining further insights as to our algorithmic\ndesign principles.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 15:50:00 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Cohen", "Itamar", ""]]}, {"id": "2012.06712", "submitter": "Mostafa Rahimi Azghadi", "authors": "Mohammad Jahanbakht, Wei Xiang, Lajos Hanzo, Mostafa Rahimi Azghadi", "title": "Internet of Underwater Things and Big Marine Data Analytics -- A\n  Comprehensive Survey", "comments": "54 pages, 11 figures, 19 tables, IEEE Communications Surveys &\n  Tutorials, peer-reviewed academic journal", "journal-ref": "IEEE Communications Surveys & Tutorials, 2021", "doi": "10.1109/COMST.2021.3053118", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Underwater Things (IoUT) is an emerging communication\necosystem developed for connecting underwater objects in maritime and\nunderwater environments. The IoUT technology is intricately linked with\nintelligent boats and ships, smart shores and oceans, automatic marine\ntransportations, positioning and navigation, underwater exploration, disaster\nprediction and prevention, as well as with intelligent monitoring and security.\nThe IoUT has an influence at various scales ranging from a small scientific\nobservatory, to a midsized harbor, and to covering global oceanic trade. The\nnetwork architecture of IoUT is intrinsically heterogeneous and should be\nsufficiently resilient to operate in harsh environments. This creates major\nchallenges in terms of underwater communications, whilst relying on limited\nenergy resources. Additionally, the volume, velocity, and variety of data\nproduced by sensors, hydrophones, and cameras in IoUT is enormous, giving rise\nto the concept of Big Marine Data (BMD), which has its own processing\nchallenges. Hence, conventional data processing techniques will falter, and\nbespoke Machine Learning (ML) solutions have to be employed for automatically\nlearning the specific BMD behavior and features facilitating knowledge\nextraction and decision support. The motivation of this paper is to\ncomprehensively survey the IoUT, BMD, and their synthesis. It also aims for\nexploring the nexus of BMD with ML. We set out from underwater data collection\nand then discuss the family of IoUT data communication techniques with an\nemphasis on the state-of-the-art research challenges. We then review the suite\nof ML solutions suitable for BMD handling and analytics. We treat the subject\ndeductively from an educational perspective, critically appraising the material\nsurveyed.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 03:31:55 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 03:11:11 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Jahanbakht", "Mohammad", ""], ["Xiang", "Wei", ""], ["Hanzo", "Lajos", ""], ["Azghadi", "Mostafa Rahimi", ""]]}, {"id": "2012.06739", "submitter": "Sandeep Chinchali", "authors": "Sandeep Chinchali, Evgenya Pergament, Manabu Nakanoya, Eyal Cidon,\n  Edward Zhang, Dinesh Bharadia, Marco Pavone, and Sachin Katti", "title": "Sampling Training Data for Continual Learning Between Robots and the\n  Cloud", "comments": "International Symposium on Experimental Robotics (ISER) 2020, Malta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.DC cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today's robotic fleets are increasingly measuring high-volume video and LIDAR\nsensory streams, which can be mined for valuable training data, such as rare\nscenes of road construction sites, to steadily improve robotic perception\nmodels. However, re-training perception models on growing volumes of rich\nsensory data in central compute servers (or the \"cloud\") places an enormous\ntime and cost burden on network transfer, cloud storage, human annotation, and\ncloud computing resources. Hence, we introduce HarvestNet, an intelligent\nsampling algorithm that resides on-board a robot and reduces system bottlenecks\nby only storing rare, useful events to steadily improve perception models\nre-trained in the cloud. HarvestNet significantly improves the accuracy of\nmachine-learning models on our novel dataset of road construction sites, field\ntesting of self-driving cars, and streaming face recognition, while reducing\ncloud storage, dataset annotation time, and cloud compute time by between\n65.7-81.3%. Further, it is between 1.05-2.58x more accurate than baseline\nalgorithms and scalably runs on embedded deep learning hardware. We provide a\nsuite of compute-efficient perception models for the Google Edge Tensor\nProcessing Unit (TPU), an extended technical report, and a novel video dataset\nto the research community at https://sites.google.com/view/harvestnet.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 05:52:33 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Chinchali", "Sandeep", ""], ["Pergament", "Evgenya", ""], ["Nakanoya", "Manabu", ""], ["Cidon", "Eyal", ""], ["Zhang", "Edward", ""], ["Bharadia", "Dinesh", ""], ["Pavone", "Marco", ""], ["Katti", "Sachin", ""]]}, {"id": "2012.06764", "submitter": "Stefan B\\\"auml", "authors": "Koji Azuma, Stefan B\\\"auml, Tim Coopmans, David Elkouss, Boxi Li", "title": "Tools for quantum network design", "comments": "31 pages, 6 figures. Minor corrections", "journal-ref": null, "doi": "10.1116/5.0024062", "report-no": null, "categories": "quant-ph cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum networks will enable the implementation of communication tasks with\nqualitative advantages with respect to the communication networks we know\ntoday. While it is expected that the first demonstrations of small scale\nquantum networks will take place in the near term, many challenges remain to\nscale them. To compare different solutions, optimize over parameter space and\ninform experiments, it is necessary to evaluate the performance of concrete\nquantum network scenarios. Here, we review the state of the art of tools for\nevaluating the performance of quantum networks. We present them from three\ndifferent angles: information-theoretic benchmarks, analytical tools, and\nsimulation.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 09:19:25 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 17:34:27 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Azuma", "Koji", ""], ["B\u00e4uml", "Stefan", ""], ["Coopmans", "Tim", ""], ["Elkouss", "David", ""], ["Li", "Boxi", ""]]}, {"id": "2012.06774", "submitter": "Martino Trevisan Dr", "authors": "Andrea Di Domenico, Gianluca Perna, Martino Trevisan, Luca Vassio,\n  Danilo Giordano", "title": "A network analysis on cloud gaming: Stadia, GeForce Now and PSNow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloud gaming is a new class of services that promises to revolutionize the\nvideogame market. It allows the user to play a videogame with basic equipment\nwhile using a remote server for the actual execution. The multimedia content is\nstreamed through the network from the server to the user. This service requires\nlow latency and a large bandwidth to work properly with low response time and\nhigh-definition video. Three of the leading tech companies, (Google, Sony and\nNVIDIA) entered this market with their own products, and others, like Microsoft\nand Amazon, are planning to launch their own platforms in the near future.\nHowever, these companies released so far little information about their cloud\ngaming operation and how they utilize the network. In this work, we study these\nnew cloud gaming services from the network point of view. We collect more than\n200 packet traces under different application settings and network conditions\nfor 3 cloud gaming services, namely Stadia from Google, GeForce Now from NVIDIA\nand PS Now from Sony. We analyze the employed protocols and the workload they\nimpose on the network. We find that GeForce Now and Stadia use the RTP protocol\nto stream the multimedia content, with the latter relying on the standard\nWebRTC APIs. They result in bandwidth-hungry and consume up to 45 Mbit/s,\ndepending on the network and video quality. PS Now instead uses only\nundocumented protocols and never exceeds 13 Mbit/s.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 09:51:30 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 17:07:07 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 14:52:48 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Di Domenico", "Andrea", ""], ["Perna", "Gianluca", ""], ["Trevisan", "Martino", ""], ["Vassio", "Luca", ""], ["Giordano", "Danilo", ""]]}, {"id": "2012.06816", "submitter": "Fangqi Li", "authors": "Fangqi Li", "title": "Evaluation and Comparison of Diffusion Models with Motif Features", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Diffusion models simulate the propagation of influence in networks. The\ndesign and evaluation of diffusion models has been subjective and empirical.\nWhen being applied to a network represented by a graph, the diffusion model\ngenerates a sequence of edges on which the influence flows, such sequence forms\na temporal network. In most scenarios, the statistical properties or the\ncharacteristics of a network are inferred by analyzing the temporal networks\ngenerated by diffusion models. To analyze real temporal networks, the motif has\nbeen proposed as a reliable feature. However, it is unclear how the network\ntopology and the diffusion model affect the motif feature of a generated\ntemporal network. In this paper, we adopt the motif feature to evaluate the\ntemporal graph generated by a diffusion model, thence the diffusion model\nitself. Two benchmarks for quantitively evaluating diffusion models with motif,\nstability and separability, are proposed and measured on numerous diffusion\nmodels. One motif-based metric is proposed to measure the similarity between\ndiffusion models. The experiments suggest that the motif of a generated\ntemporal network is dominated by the diffusion model, while the network\ntopology is almost ignored. This result indicates that more practical and\nreliable diffusion models have to be designed with delicacy in order to capture\nthe propagation patterns of real temporal networks.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 13:35:22 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Li", "Fangqi", ""]]}, {"id": "2012.06860", "submitter": "Chen-Feng Liu", "authors": "Yung-Lin Hsu, Chen-Feng Liu, Sumudu Samarakoon, Hung-Yu Wei, Mehdi\n  Bennis", "title": "Age-Optimal Power Allocation in Industrial IoT: A Risk-Sensitive\n  Federated Learning Approach", "comments": "Accepted in IEEE PIMRC 2021 with 6 pages and 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies a real-time environment monitoring scenario in the\nindustrial Internet of things, where wireless sensors proactively collect\nenvironmental data and transmit it to the controller. We adopt the notion of\nrisk-sensitivity in financial mathematics as the objective to jointly minimize\nthe mean, variance, and other higher-order statistics of the network energy\nconsumption subject to the constraints on the age of information (AoI)\nthreshold violation probability and the AoI exceedances over a pre-defined\nthreshold. We characterize the extreme AoI staleness using results in extreme\nvalue theory and propose a distributed power allocation approach by weaving in\ntogether principles of Lyapunov optimization and federated learning (FL).\nSimulation results demonstrate that the proposed FL-based distributed solution\nis on par with the centralized baseline while consuming 28.50% less system\nenergy and outperforms the other baselines.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 16:53:59 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 06:40:37 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hsu", "Yung-Lin", ""], ["Liu", "Chen-Feng", ""], ["Samarakoon", "Sumudu", ""], ["Wei", "Hung-Yu", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2012.06974", "submitter": "Bekir Sait Ciftler", "authors": "Noor Ali Al-Athba Al-Marri, Bekir Sait Ciftler, Mohamed Abdallah", "title": "Federated Mimic Learning for Privacy Preserving Intrusion Detection", "comments": "6 pages, 6 figures, accepted to Blackseacom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet of things (IoT) devices are prone to attacks due to the limitation\nof their privacy and security components. These attacks vary from exploiting\nbackdoors to disrupting the communication network of the devices. Intrusion\nDetection Systems (IDS) play an essential role in ensuring information privacy\nand security of IoT devices against these attacks. Recently, deep\nlearning-based IDS techniques are becoming more prominent due to their high\nclassification accuracy. However, conventional deep learning techniques\njeopardize user privacy due to the transfer of user data to a centralized\nserver. Federated learning (FL) is a popular privacy-preserving decentralized\nlearning method. FL enables training models locally at the edge devices and\ntransferring local models to a centralized server instead of transferring\nsensitive data. Nevertheless, FL can suffer from reverse engineering ML attacks\nthat can learn information about the user's data from model. To overcome the\nproblem of reverse engineering, mimic learning is another way to preserve the\nprivacy of ML-based IDS. In mimic learning, a student model is trained with the\npublic dataset, which is labeled with the teacher model that is trained by\nsensitive user data. In this work, we propose a novel approach that combines\nthe advantages of FL and mimic learning, namely federated mimic learning to\ncreate a distributed IDS while minimizing the risk of jeopardizing users'\nprivacy, and benchmark its performance compared to other ML-based IDS\ntechniques using NSL-KDD dataset. Our results show that we can achieve 98.11%\ndetection accuracy with federated mimic learning.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 06:09:11 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Al-Marri", "Noor Ali Al-Athba", ""], ["Ciftler", "Bekir Sait", ""], ["Abdallah", "Mohamed", ""]]}, {"id": "2012.06989", "submitter": "Furqan Khan", "authors": "Anees Al-Najjar, Furqan Hameed Khan, Marius Portmann", "title": "Network Traffic Control for Multi-homed End-hosts via SDN", "comments": "13 pages, 26 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Defined Networking (SDN) is an emerging technology of efficiently\ncontrolling and managing computer networks, such as in data centres, Wide Area\nNetworks (WANs), as well as in ubiquitous communication. In this paper, we\nexplore the idea of embedding the SDN components, represented by SDN controller\nand virtual switch, in end-hosts to improve network performance. In particular,\nwe consider load balancing across multiple network interfaces on end-hosts with\ndifferent link capacity scenarios. We have explored and implemented different\nSDN-based load balancing approaches based on OpenFlow software switches, and\nhave demonstrated the feasibility and the potential of this approach. The\nproposed system has been evaluated with multipath transmission control protocol\n(MPTCP). Our results demonstrated the potential of applying the SDN concepts on\nmulti-homed devices resulting in an increase in achieved throughput of 55\\%\ncompared to the legacy single network approach and 10\\% compared to the MPTCP.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 07:25:37 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Al-Najjar", "Anees", ""], ["Khan", "Furqan Hameed", ""], ["Portmann", "Marius", ""]]}, {"id": "2012.06992", "submitter": "Bo Yang", "authors": "Bo Yang, Xuelin Cao, Kai Xiong, Chau Yuen, Yong Liang Guan, Supeng\n  Leng, Lijun Qian, and Zhu Han", "title": "Edge Intelligence for Autonomous Driving in 6G Wireless System: Design\n  Challenges and Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a level-5 autonomous driving system, the autonomous driving vehicles (AVs)\nare expected to sense the surroundings via analyzing a large amount of data\ncaptured by a variety of onboard sensors in near-real-time. As a result,\nenormous computing costs will be introduced to the AVs for processing the tasks\nwith the deployed machine learning (ML) model, while the inference accuracy may\nnot be guaranteed. In this context, the advent of edge intelligence (EI) and\nsixth-generation (6G) wireless networking are expected to pave the way to more\nreliable and safer autonomous driving by providing multi-access edge computing\n(MEC) together with ML to AVs in close proximity. To realize this goal, we\npropose a two-tier EI-empowered autonomous driving framework. In the\nautonomous-vehicles tier, the autonomous vehicles are deployed with the shallow\nlayers by splitting the trained deep neural network model. In the\nedge-intelligence tier, an edge server is implemented with the remaining layers\n(also deep layers) and an appropriately trained multi-task learning (MTL)\nmodel. In particular, obtaining the optimal offloading strategy (including the\nbinary offloading decision and the computational resources allocation) can be\nformulated as a mixed-integer nonlinear programming (MINLP) problem, which is\nsolved via MTL in near-real-time with high accuracy. On another note, an\nedge-vehicle joint inference is proposed through neural network segmentation to\nachieve efficient online inference with data privacy-preserving and less\ncommunication delay. Experiments demonstrate the effectiveness of the proposed\nframework, and open research topics are finally listed.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 07:28:18 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Yang", "Bo", ""], ["Cao", "Xuelin", ""], ["Xiong", "Kai", ""], ["Yuen", "Chau", ""], ["Guan", "Yong Liang", ""], ["Leng", "Supeng", ""], ["Qian", "Lijun", ""], ["Han", "Zhu", ""]]}, {"id": "2012.07051", "submitter": "Prabhu Kaliyammal Thiruvasagam", "authors": "Prabhu Kaliyammal Thiruvasagam, Vijeth J. Kotagi, and C. Siva Ram\n  Murthy", "title": "A Reliability-Aware, Delay Guaranteed, and Resource Efficient Placement\n  of Service Function Chains in Softwarized 5G Networks", "comments": "17 pages", "journal-ref": null, "doi": "10.1109/TCC.2020.3020269", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Functions Virtualization (NFV) allows flexibility, scalability,\nagility, and easy manageability of networks by leveraging the features of\nvirtualization and cloud computing technologies. However, softwarization of\nnetwork functions imposes many challenges. Reliability and latency are major\nchallenges in NFV-enabled 5G networks that can lead to customer dissatisfaction\nand revenue loss. In general, redundancy is used to improve the reliability of\ncommunication services. However, redundancy requires the same amount of\nadditional resources and thus increases cost. In this work, we address the\nreliability-aware, delay guaranteed, and resource efficient Service Function\nChain (SFC) placement problem in softwarized 5G networks. First, we propose a\nnovel SFC subchaining method to enhance the reliability of an SFC without\nbackups. If reliability requirement is not met after subchaining method, we add\nbackups to VNFs to meet the reliability requirement. Then, we formulate the\nreliable SFC placement problem as an Integer Linear Programming (ILP) problem\nin order to solve it optimally. Owing to high computational complexity of the\nILP problem for solving large input instances, we propose a modified stable\nmatching algorithm to provide near-optimal solution in polynomial time. By\nextensive simulations we show that our proposed solutions consume lesser\nphysical resources compared to state-of-the-art solutions for provisioning\nreliable communication services.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 12:47:33 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Thiruvasagam", "Prabhu Kaliyammal", ""], ["Kotagi", "Vijeth J.", ""], ["Murthy", "C. Siva Ram", ""]]}, {"id": "2012.07224", "submitter": "Brian Mark", "authors": "Hanoch Lev-Ari, Yariv Ephraim, Brian L. Mark", "title": "Traffic Rate Network Tomography with Higher-Order Cumulants", "comments": "10 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network tomography aims at estimating source-destination traffic rates from\nlink traffic measurements. This inverse problem was formulated by Vardi in 1996\nfor Poisson traffic over networks operating under deterministic as well as\nrandom routing regimes. In this paper we expand Vardi's second-order moment\nmatching rate estimation approach to higher-order cumulant matching with the\ngoal of increasing the column rank of the mapping and consequently improving\nthe rate estimation accuracy. We develop a systematic set of linear cumulant\nmatching equations and express them compactly in terms of the Khatri-Rao\nproduct. Both least squares estimation and iterative minimum I-divergence\nestimation are considered. We develop an upper bound on the mean squared error\n(MSE) in least squares rate estimation from empirical cumulants. We demonstrate\nfor the NSFnet that supplementing Vardi's approach with third-order empirical\ncumulant reduces its averaged normalized MSE relative to the theoretical\nminimum of the second-order moment matching approach by about 12%-18%. This\nminimum MSE is obtained when Vardi's second-order moment matching approach is\nbased on the theoretical rather than the empirical moments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 02:51:47 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Lev-Ari", "Hanoch", ""], ["Ephraim", "Yariv", ""], ["Mark", "Brian L.", ""]]}, {"id": "2012.07279", "submitter": "Sohee Bae", "authors": "Sohee Bae, Seungyul Han, and Youngchul Sung", "title": "A Reinforcement Learning Formulation of the Lyapunov Optimization:\n  Application to Edge Computing Systems with Queue Stability", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a deep reinforcement learning (DRL)-based approach to the\nLyapunov optimization is considered to minimize the time-average penalty while\nmaintaining queue stability. A proper construction of state and action spaces\nis provided to form a proper Markov decision process (MDP) for the Lyapunov\noptimization. A condition for the reward function of reinforcement learning\n(RL) for queue stability is derived. Based on the analysis and practical RL\nwith reward discounting, a class of reward functions is proposed for the\nDRL-based approach to the Lyapunov optimization. The proposed DRL-based\napproach to the Lyapunov optimization does not required complicated\noptimization at each time step and operates with general non-convex and\ndiscontinuous penalty functions. Hence, it provides an alternative to the\nconventional drift-plus-penalty (DPP) algorithm for the Lyapunov optimization.\nThe proposed DRL-based approach is applied to resource allocation in edge\ncomputing systems with queue stability and numerical results demonstrate its\nsuccessful operation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 05:55:26 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 11:02:51 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Bae", "Sohee", ""], ["Han", "Seungyul", ""], ["Sung", "Youngchul", ""]]}, {"id": "2012.07450", "submitter": "Xu Chen", "authors": "Qiong Wu and Xu Chen and Zhi Zhou and Junshan Zhang", "title": "FedHome: Cloud-Edge based Personalized Federated Learning for In-Home\n  Health Monitoring", "comments": "Accepted by IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-home health monitoring has attracted great attention for the ageing\npopulation worldwide. With the abundant user health data accessed by Internet\nof Things (IoT) devices and recent development in machine learning, smart\nhealthcare has seen many successful stories. However, existing approaches for\nin-home health monitoring do not pay sufficient attention to user data privacy\nand thus are far from being ready for large-scale practical deployment. In this\npaper, we propose FedHome, a novel cloud-edge based federated learning\nframework for in-home health monitoring, which learns a shared global model in\nthe cloud from multiple homes at the network edges and achieves data privacy\nprotection by keeping user data locally. To cope with the imbalanced and\nnon-IID distribution inherent in user's monitoring data, we design a generative\nconvolutional autoencoder (GCAE), which aims to achieve accurate and\npersonalized health monitoring by refining the model with a generated\nclass-balanced dataset from user's personal data. Besides, GCAE is lightweight\nto transfer between the cloud and edges, which is useful to reduce the\ncommunication cost of federated learning in FedHome. Extensive experiments\nbased on realistic human activity recognition data traces corroborate that\nFedHome significantly outperforms existing widely-adopted methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 12:04:44 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wu", "Qiong", ""], ["Chen", "Xu", ""], ["Zhou", "Zhi", ""], ["Zhang", "Junshan", ""]]}, {"id": "2012.07451", "submitter": "Cristian Tatino", "authors": "Cristian Tatino, Nikolaos Pappas, and Di Yuan", "title": "QoS Aware Robot Trajectory Optimization with IRS-Assisted\n  Millimeter-Wave Communications", "comments": "arXiv admin note: substantial text overlap with arXiv:2010.14653", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the motion energy minimization problem for a wirelessly\nconnected robot using millimeter-wave (mm-wave) communications. These are\nassisted by an intelligent reflective surface (IRS) that enhances the coverage\nat such high frequencies characterized by high blockage sensitivity. The robot\nis subject to time and uplink communication quality of service (QoS)\nconstraints. This is a fundamental problem in fully automated factories that\ncharacterize Industry 4.0, where robots may have to perform tasks with given\ndeadlines while maximizing the battery autonomy and communication efficiency.\nTo account for the mutual dependence between robot position and communication\nQoS, we propose a joint optimization of robot trajectory and beamforming at the\nIRS and access point (AP). We present a solution that first exploits mm-wave\nchannel characteristics to decouple beamforming and trajectory optimization.\nThen, the latter is solved by a successive-convex optimization-based algorithm.\nThe algorithm takes into account the obstacles' positions and a radio map to\navoid collisions and poorly covered areas. We prove that the algorithm can\nconverge to a solution satisfying the Karush-Kuhn-Tucker (KKT) conditions. The\nsimulation results show a dramatic reduction of the motion energy consumption\nwith respect to methods that aim to find maximum-rate trajectories. Moreover,\nwe show how the IRS and the beamforming optimization improve the motion energy\nefficiency of the robot.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 12:05:22 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 17:57:18 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Tatino", "Cristian", ""], ["Pappas", "Nikolaos", ""], ["Yuan", "Di", ""]]}, {"id": "2012.07626", "submitter": "Linshan Jiang", "authors": "Linshan Jiang, Rui Tan, Xin Lou, Guosheng Lin", "title": "On Lightweight Privacy-Preserving Collaborative Learning for Internet of\n  Things by Independent Random Projections", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.05197", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The Internet of Things (IoT) will be a main data generation infrastructure\nfor achieving better system intelligence. This paper considers the design and\nimplementation of a practical privacy-preserving collaborative learning scheme,\nin which a curious learning coordinator trains a better machine learning model\nbased on the data samples contributed by a number of IoT objects, while the\nconfidentiality of the raw forms of the training data is protected against the\ncoordinator. Existing distributed machine learning and data encryption\napproaches incur significant computation and communication overhead, rendering\nthem ill-suited for resource-constrained IoT objects. We study an approach that\napplies independent random projection at each IoT object to obfuscate data and\ntrains a deep neural network at the coordinator based on the projected data\nfrom the IoT objects. This approach introduces light computation overhead to\nthe IoT objects and moves most workload to the coordinator that can have\nsufficient computing resources. Although the independent projections performed\nby the IoT objects address the potential collusion between the curious\ncoordinator and some compromised IoT objects, they significantly increase the\ncomplexity of the projected data. In this paper, we leverage the superior\nlearning capability of deep learning in capturing sophisticated patterns to\nmaintain good learning performance. The extensive comparative evaluation shows\nthat this approach outperforms other lightweight approaches that apply additive\nnoisification for differential privacy and/or support vector machines for\nlearning in the applications with light to moderate data pattern complexities.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 12:44:37 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Jiang", "Linshan", ""], ["Tan", "Rui", ""], ["Lou", "Xin", ""], ["Lin", "Guosheng", ""]]}, {"id": "2012.07695", "submitter": "Fabian Bustamante", "authors": "James Newman, Abbas Razaghpanah, Narseo Vallina-Rodriguez, Fabian E.\n  Bustamante, Mark Allman, Diego Perino, Alessandro Finamore", "title": "Back in control -- An extensible middle-box on your phone", "comments": "The paper is a position piece under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The closed design of mobile devices -- with the increased security and\nconsistent user interfaces -- is in large part responsible for their becoming\nthe dominant platform for accessing the Internet. These benefits, however, are\nnot without a cost. Their operation of mobile devices and their apps is not\neasy to understand by either users or operators. We argue for recovering\ntransparency and control on mobile devices through an extensible platform that\ncan intercept and modify traffic before leaving the device or, on arrival,\nbefore it reaches the operating system. Conceptually, this is the same view of\nthe traffic that a traditional middlebox would have at the far end of the first\nlink in the network path. We call this platform ``middlebox zero'' or MBZ. By\nbeing on-board, MBZ also leverages local context as it processes the traffic\nand complements the network-wide view of standard middleboxes. We discuss the\nchallenges of the MBZ approach, sketch a working design, and illustrate its\npotential with some concrete examples.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 16:46:07 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Newman", "James", ""], ["Razaghpanah", "Abbas", ""], ["Vallina-Rodriguez", "Narseo", ""], ["Bustamante", "Fabian E.", ""], ["Allman", "Mark", ""], ["Perino", "Diego", ""], ["Finamore", "Alessandro", ""]]}, {"id": "2012.07730", "submitter": "Shi Zhou Dr.", "authors": "Jie Li, Vasileios Giotsas, Shi Zhou", "title": "Anatomy of Multipath BGP Deployment in a Large ISP Network", "comments": "9 pages, 7 figures; TMA 2020 conference,\n  http://dl.ifip.org/db/conf/tma/tma2020/index.html", "journal-ref": "4th Network Traffic Measurement and Analysis Conference (TMA\n  2020), Berlin, June 10, 2020; Editors: Georgios Smaragdakis, Anja Feldmann,\n  Anna Brunstrom, Gareth Tyson; Publisher: IFIP Open Digital Library; ISBN:\n  978-3-903176-27-0", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Multipath routing is useful for networks to achieve load sharing among\nmultiple routing paths. Multipath BGP (MBGP) is a technique to realize\ninter-domain multipath routing by enabling a BGP router to install multiple\nequally-good routes to a destination prefix. Most of previous works did not\ndistinguish between intra-domain and inter-domain multipath routing. In this\npaper, we present a measurement study on the deployment of M-BGP in a large\nInternet service provider (ISP) network. Our method combines control-plane BGP\nmeasurements using Looking Glasses (LG), and data-plane traceroute measurements\nusing RIPE Atlas. We focus on Hurricane Electric (AS6939) because it is a\nglobal ISP that connects with hundreds of major exchange points and exchanges\nIP traffic with thousands of different networks. And more importantly, we find\nthat this ISP has by far the largest number of M-BGP deployments among\nautonomous systems with LG servers. Specifically, Hurricane Electric has\ndeployed M-BGP with 512 of its peering ASes at 58 PoPs around the world,\nincluding many top ASes and content providers. We also observe that most of its\nM-BGP deployments involve IXP interconnections. Our work provides insights into\nthe latest deployment of M-BGP in a major ISP network and it highlights the\ncharacteristics and effectiveness of M-BGP as a means to realize load sharing.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 17:26:47 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Li", "Jie", ""], ["Giotsas", "Vasileios", ""], ["Zhou", "Shi", ""]]}, {"id": "2012.07753", "submitter": "Zilong Liu", "authors": "Md. Noor-A-Rahim, Zilong Liu, Haeyoung Lee, M. Omar Khyam, Jianhua He,\n  Dirk Pesch, Klaus Moessner, Walid Saad, H. Vincent Poor", "title": "6G for Vehicle-to-Everything (V2X) Communications: Enabling\n  Technologies, Challenges, and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are on the cusp of a new era of connected autonomous vehicles with\nunprecedented user experiences, tremendously improved road safety and air\nquality, highly diverse transportation environments and use cases, as well as a\nplethora of advanced applications. Realizing this grand vision requires a\nsignificantly enhanced vehicle-to-everything (V2X) communication network which\nshould be extremely intelligent and capable of concurrently supporting\nhyper-fast, ultra-reliable, and low-latency massive information exchange. It is\nanticipated that the sixth-generation (6G) communication systems will fulfill\nthese requirements of the next-generation V2X. In this article, we outline a\nseries of key enabling technologies from a range of domains, such as new\nmaterials, algorithms, and system architectures. Aiming for truly intelligent\ntransportation systems, we envision that machine learning will play an\ninstrumental role for advanced vehicular communication and networking. To this\nend, we provide an overview on the recent advances of machine learning in 6G\nvehicular networks. To stimulate future research in this area, we discuss the\nstrength, open challenges, maturity, and enhancing areas of these technologies.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 17:49:00 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Noor-A-Rahim", "Md.", ""], ["Liu", "Zilong", ""], ["Lee", "Haeyoung", ""], ["Khyam", "M. Omar", ""], ["He", "Jianhua", ""], ["Pesch", "Dirk", ""], ["Moessner", "Klaus", ""], ["Saad", "Walid", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2012.07755", "submitter": "Archit Patke", "authors": "Archit Patke, Saurabh Jha, Haoran Qiu, Jim Brandt, Ann Gentile, Joe\n  Greenseid, Zbigniew Kalbarczyk, Ravishankar Iyer", "title": "Application-aware Congestion Mitigation for High-Performance Computing\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  High-performance computing (HPC) systems frequently experience congestion\nleading to significant application performance variation. However, the impact\nof congestion on application runtime differs from application to application\ndepending on their network characteristics (such as bandwidth and latency\nrequirements). We leverage this insight to develop Netscope, an automated\nML-driven framework that considers those network characteristics to dynamically\nmitigate congestion. We evaluate Netscope on four Cray Aries systems, including\na production supercomputer on real scientific applications. Netscope has a\nlower training cost and accurately estimates the impact of congestion on\napplication runtime with a correlation between 0.7and 0.9 for common scientific\napplications. Moreover, we find that Netscope reduces tail runtime variability\nby up to 14.9 times while improving median system utility by 12%.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 17:51:46 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 02:09:52 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Patke", "Archit", ""], ["Jha", "Saurabh", ""], ["Qiu", "Haoran", ""], ["Brandt", "Jim", ""], ["Gentile", "Ann", ""], ["Greenseid", "Joe", ""], ["Kalbarczyk", "Zbigniew", ""], ["Iyer", "Ravishankar", ""]]}, {"id": "2012.07944", "submitter": "Micah Sherr", "authors": "Rahel A. Fainchtein and Adam J. Aviv and Micah Sherr and Stephen\n  Ribaudo and Armaan Khullar", "title": "Holes in the Geofence: Privacy Vulnerabilities in \"Smart\" DNS Services", "comments": "To appear at: Rahel A. Fainchtein, Adam A. Aviv, Micah Sherr, Stephen\n  Ribaudo, and Armaan Khullar. Holes in the Geofence: Privacy Vulnerabilities\n  in \"Smart\" DNS Services. Proceedings on Privacy Enhancing Technologies\n  (PoPETS), July 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart DNS (SDNS) services advertise access to \"geofenced\" content (typically,\nvideo streaming sites such as Netflix or Hulu) that is normally inaccessible\nunless the client is within a prescribed geographic region. SDNS is simple to\nuse and involves no software installation. Instead, it requires only that users\nmodify their DNS settings to point to an SDNS resolver. The SDNS resolver\n\"smartly\" identifies geofenced domains and, in lieu of their proper DNS\nresolutions, returns IP addresses of proxy servers located within the geofence.\nThese servers then transparently proxy traffic between the users and their\nintended destinations, allowing for the bypass of these geographic\nrestrictions.\n  This paper presents the first academic study of SDNS services. We identify a\nnumber of serious and pervasive privacy vulnerabilities that expose information\nabout the users of these systems. These include architectural weaknesses that\nenable content providers to identify which requesting clients use SDNS. Worse,\nwe identify flaws in the design of some SDNS services that allow {\\em any}\narbitrary third party to enumerate these services' users (by IP address), even\nif said users are currently offline. We present mitigation strategies to these\nattacks that have been adopted by at least one SDNS provider in response to our\nfindings.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 21:19:37 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fainchtein", "Rahel A.", ""], ["Aviv", "Adam J.", ""], ["Sherr", "Micah", ""], ["Ribaudo", "Stephen", ""], ["Khullar", "Armaan", ""]]}, {"id": "2012.08285", "submitter": "Jakob Hoydis", "authors": "Jakob Hoydis, Fay\\c{c}al Ait Aoudia, Alvaro Valcarce, Harish\n  Viswanathan", "title": "Toward a 6G AI-Native Air Interface", "comments": "7 pages, 6 figures, accepted for publication in the IEEE\n  Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Each generation of cellular communication systems is marked by a defining\ndisruptive technology of its time, such as orthogonal frequency division\nmultiplexing (OFDM) for 4G or Massive multiple-input multiple-output (MIMO) for\n5G. Since artificial intelligence (AI) is the defining technology of our time,\nit is natural to ask what role it could play for 6G. While it is clear that 6G\nmust cater to the needs of large distributed learning systems, it is less\ncertain if AI will play a defining role in the design of 6G itself. The goal of\nthis article is to paint a vision of a new air interface which is partially\ndesigned by AI to enable optimized communication schemes for any hardware,\nradio environment, and application.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 13:46:04 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 09:21:45 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Hoydis", "Jakob", ""], ["Aoudia", "Fay\u00e7al Ait", ""], ["Valcarce", "Alvaro", ""], ["Viswanathan", "Harish", ""]]}, {"id": "2012.08336", "submitter": "Bing Luo", "authors": "Bing Luo, Xiang Li, Shiqiang Wang, Jianwei Huang, Leandros Tassiulas", "title": "Cost-Effective Federated Learning Design", "comments": "Accepted in IEEE INFOCOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a distributed learning paradigm that enables a\nlarge number of devices to collaboratively learn a model without sharing their\nraw data. Despite its practical efficiency and effectiveness, the iterative\non-device learning process incurs a considerable cost in terms of learning time\nand energy consumption, which depends crucially on the number of selected\nclients and the number of local iterations in each training round. In this\npaper, we analyze how to design adaptive FL that optimally chooses these\nessential control variables to minimize the total cost while ensuring\nconvergence. Theoretically, we analytically establish the relationship between\nthe total cost and the control variables with the convergence upper bound. To\nefficiently solve the cost minimization problem, we develop a low-cost\nsampling-based algorithm to learn the convergence related unknown parameters.\nWe derive important solution properties that effectively identify the design\nprinciples for different metric preferences. Practically, we evaluate our\ntheoretical results both in a simulated environment and on a hardware\nprototype. Experimental evidence verifies our derived properties and\ndemonstrates that our proposed solution achieves near-optimal performance for\nvarious datasets, different machine learning models, and heterogeneous system\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 14:45:11 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Luo", "Bing", ""], ["Li", "Xiang", ""], ["Wang", "Shiqiang", ""], ["Huang", "Jianwei", ""], ["Tassiulas", "Leandros", ""]]}, {"id": "2012.08356", "submitter": "Alexander Ivchenko Vladimirovich", "authors": "Raoul Nigmatullin, Alexander Ivchenko, Semyon Dorokhin", "title": "Differentiation of Sliding Rescaled Ranges: New Approach to Encrypted\n  and VPN Traffic Detection", "comments": "5 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new approach to traffic preprocessing called Differentiation of\nSliding Rescaled Ranges (DSRR) expanding the ideas laid down by H.E. Hurst. We\napply proposed approach on the characterizing encrypted and unencrypted traffic\non the well-known ISCXVPN2016 dataset. We deploy DSRR for flow-base features\nand then solve the task VPN vs nonVPN with basic machine learning models. With\nDSRR and Random Forest, we obtain 0.971 Precision, 0.969 Recall and improve\nthis result to 0.976 using statistical analysis of features in comparison with\nNeural Network approach that gives 0.93 Precision via 2D-CNN. The proposed\nmethod and the results can be found at\nhttps://github.com/AleksandrIvchenko/dsrr_vpn_nonvpn.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 13:19:45 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Nigmatullin", "Raoul", ""], ["Ivchenko", "Alexander", ""], ["Dorokhin", "Semyon", ""]]}, {"id": "2012.08677", "submitter": "Sheng Yue", "authors": "Sheng Yue, Ju Ren, Jiang Xin, Sen Lin, Junshan Zhang", "title": "Inexact-ADMM Based Federated Meta-Learning for Fast and Continual Edge\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3466772.3467038", "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to meet the requirements for performance, safety, and latency in\nmany IoT applications, intelligent decisions must be made right here right now\nat the network edge. However, the constrained resources and limited local data\namount pose significant challenges to the development of edge AI. To overcome\nthese challenges, we explore continual edge learning capable of leveraging the\nknowledge transfer from previous tasks. Aiming to achieve fast and continual\nedge learning, we propose a platform-aided federated meta-learning architecture\nwhere edge nodes collaboratively learn a meta-model, aided by the knowledge\ntransfer from prior tasks. The edge learning problem is cast as a regularized\noptimization problem, where the valuable knowledge learned from previous tasks\nis extracted as regularization. Then, we devise an ADMM based federated\nmeta-learning algorithm, namely ADMM-FedMeta, where ADMM offers a natural\nmechanism to decompose the original problem into many subproblems which can be\nsolved in parallel across edge nodes and the platform. Further, a variant of\ninexact-ADMM method is employed where the subproblems are `solved' via linear\napproximation as well as Hessian estimation to reduce the computational cost\nper round to $\\mathcal{O}(n)$. We provide a comprehensive analysis of\nADMM-FedMeta, in terms of the convergence properties, the rapid adaptation\nperformance, and the forgetting effect of prior knowledge transfer, for the\ngeneral non-convex case. Extensive experimental studies demonstrate the\neffectiveness and efficiency of ADMM-FedMeta, and showcase that it\nsubstantially outperforms the existing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 00:02:26 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 21:02:45 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 23:52:59 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Yue", "Sheng", ""], ["Ren", "Ju", ""], ["Xin", "Jiang", ""], ["Lin", "Sen", ""], ["Zhang", "Junshan", ""]]}, {"id": "2012.08679", "submitter": "Jin Wang", "authors": "Jin Wang, Jia Hu, and Geyong Min", "title": "Online Service Migration in Edge Computing with Incomplete Information:\n  A Deep Recurrent Actor-Critic Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-access Edge Computing (MEC) is an emerging computing paradigm that\nextends cloud computing to the network edge (e.g., base stations, MEC servers)\nto support resource-intensive applications on mobile devices. As a crucial\nproblem in MEC, service migration needs to decide where to migrate user\nservices for maintaining high Quality-of-Service (QoS), when users roam between\nMEC servers with limited coverage and capacity. However, finding an optimal\nmigration policy is intractable due to the highly dynamic MEC environment and\nuser mobility. Many existing works make centralized migration decisions based\non complete system-level information, which can be time-consuming and suffer\nfrom the scalability issue with the rapidly increasing number of mobile users.\nTo address these challenges, we propose a new learning-driven method, namely\nDeep Recurrent Actor-Critic based service Migration (DRACM), which is\nuser-centric and can make effective online migration decisions given incomplete\nsystem-level information. Specifically, the service migration problem is\nmodeled as a Partially Observable Markov Decision Process (POMDP). To solve the\nPOMDP, we design an encoder network that combines a Long Short-Term Memory\n(LSTM) and an embedding matrix for effective extraction of hidden information.\nWe then propose a tailored off-policy actor-critic algorithm with a clipped\nsurrogate objective for efficient training. Results from extensive experiments\nbased on real-world mobility traces demonstrate that our method consistently\noutperforms both the heuristic and state-of-the-art learning-driven algorithms,\nand achieves near-optimal results on various MEC scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 00:16:24 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 11:11:29 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 10:53:50 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Jin", ""], ["Hu", "Jia", ""], ["Min", "Geyong", ""]]}, {"id": "2012.08938", "submitter": "Weibin Meng", "authors": "Weibin Meng, Federico Zaiter, Yuheng Huang, Ying Liu, Shenglin Zhang,\n  Yuzhe Zhang, Yichen Zhu, Tianke Zhang, En Wang, Zuomin Ren, Feng Wang, Shimin\n  Tao, Dan Pei", "title": "Summarizing Unstructured Logs in Online Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logs are one of the most valuable data sources for managing large-scale\nonline services. After a failure is detected/diagnosed/predicted, operators\nstill have to inspect the raw logs to gain a summarized view before take\nactions. However, manual or rule-based log summarization has become inefficient\nand ineffective. In this work, we propose LogSummary, an automatic,\nunsupervised end-to-end log summarization framework for online services.\nLogSummary obtains the summarized triples of important logs for a given log\nsequence. It integrates a novel information extraction method taking both\nsemantic information and domain knowledge into consideration, with a new triple\nranking approach using the global knowledge learned from all logs. Given the\nlack of a publicly-available gold standard for log summarization, we have\nmanually labelled the summaries of four open-source log datasets and made them\npublicly available. The evaluation on these datasets as well as the case\nstudies on real-world logs demonstrate that LogSummary produces a highly\nrepresentative (average ROUGE F1 score of 0.741) summaries. We have packaged\nLogSummary into an open-source toolkit and hope that it can benefit for future\nNLP-powered summarization works.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 13:40:20 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Meng", "Weibin", ""], ["Zaiter", "Federico", ""], ["Huang", "Yuheng", ""], ["Liu", "Ying", ""], ["Zhang", "Shenglin", ""], ["Zhang", "Yuzhe", ""], ["Zhu", "Yichen", ""], ["Zhang", "Tianke", ""], ["Wang", "En", ""], ["Ren", "Zuomin", ""], ["Wang", "Feng", ""], ["Tao", "Shimin", ""], ["Pei", "Dan", ""]]}, {"id": "2012.09009", "submitter": "Baldomero Coll-Perales", "authors": "Baldomero Coll-Perales, Loreto Pescosolido, Javier Gozalvez, Andrea\n  Passarella, and Marco Conti", "title": "Next Generation Opportunistic Networking in Beyond 5G Networks", "comments": "17 pages, 6 figures", "journal-ref": "Ad Hoc Networks, Available online 11 December 2020", "doi": "10.1016/j.adhoc.2020.102392", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beyond 5G networks are expected to support massive traffic through\ndecentralized solutions and advanced networking mechanisms. This paper aims at\ncontributing towards this vision through the integration of device-centric\nwireless networks, including Device-to-Device (D2D) communications, and the\nNext Generation of Opportunistic networking (NGO). This integration offers\nmultiple communication modes such as opportunistic cellular and opportunistic\nD2D-aided communications. Previous studies have demonstrated the potential and\nbenefits of this integration in terms of energy efficiency, spectral efficiency\nand traffic offloading. We propose an integration of device-centric wireless\nnetworks and NGO that is not driven by a precise knowledge of the presence of\nthe links. The proposed technique utilizes a novel concept of graph to model\nthe evolution of the networking conditions and network connectivity.\nUncertainties and future conditions are included in the proposed graph model\nthrough anticipatory mobile networking to estimate the transmission energy cost\nof the different communication modes. Based on these estimates, the devices\nschedule their transmissions using the most efficient communication mode. These\ndecisions are later revisited in real-time using more precise knowledge about\nthe network state. The conducted evaluation shows that the proposed technique\nsignificantly reduces the energy consumption (from 60% to 90% depending on the\nscenario) compared to traditional single-hop cellular communications and\nperforms closely to an ideal oracle based system with full knowledge of present\nand future events. The transmission and computational overheads of the proposed\ntechnique show small impact on such energy gains.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 15:11:18 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 13:42:40 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Coll-Perales", "Baldomero", ""], ["Pescosolido", "Loreto", ""], ["Gozalvez", "Javier", ""], ["Passarella", "Andrea", ""], ["Conti", "Marco", ""]]}, {"id": "2012.09222", "submitter": "Xinzhe Fu", "authors": "Xinzhe Fu, Eytan Modiano", "title": "Learning-NUM: Network Utility Maximization with Unknown Utility\n  Functions and Queueing Delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network Utility Maximization (NUM) studies the problems of allocating traffic\nrates to network users in order to maximize the users' total utility subject to\nnetwork resource constraints. In this paper, we propose a new NUM framework,\nLearning-NUM, where the users' utility functions are unknown apriori and the\nutility function values of the traffic rates can be observed only after the\ncorresponding traffic is delivered to the destination, which means that the\nutility feedback experiences \\textit{queueing delay}.\n  The goal is to design a policy that gradually learns the utility functions\nand makes rate allocation and network scheduling/routing decisions so as to\nmaximize the total utility obtained over a finite time horizon $T$. In addition\nto unknown utility functions and stochastic constraints, a central challenge of\nour problem lies in the queueing delay of the observations, which may be\nunbounded and depends on the decisions of the policy.\n  We first show that the expected total utility obtained by the best dynamic\npolicy is upper bounded by the solution to a static optimization problem.\nWithout the presence of feedback delay, we design an algorithm based on the\nideas of gradient estimation and Max-Weight scheduling. To handle the feedback\ndelay, we embed the algorithm in a parallel-instance paradigm to form a policy\nthat achieves $\\tilde{O}(T^{3/4})$-regret, i.e., the difference between the\nexpected utility obtained by the best dynamic policy and our policy is in\n$\\tilde{O}(T^{3/4})$. Finally, to demonstrate the practical applicability of\nthe Learning-NUM framework, we apply it to three application scenarios\nincluding database query, job scheduling and video streaming. We further\nconduct simulations on the job scheduling application to evaluate the empirical\nperformance of our policy.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 19:36:25 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Fu", "Xinzhe", ""], ["Modiano", "Eytan", ""]]}, {"id": "2012.09381", "submitter": "Liang Ma", "authors": "Liang Ma, Ting He, Ananthram Swami, Don Towsley, Kin K. Leung", "title": "Node Failure Localization: Theorem Proof", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a technical report, containing all the theorem proofs in paper \"On\nOptimal Monitor Placement for Localizing Node Failures via Network Tomography\"\nby Liang Ma, Ting He, Ananthram Swami, Don Towsley, and Kin K. Leung, published\nin IFIP WG 7.3 Performance, 2015.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 03:41:26 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Ma", "Liang", ""], ["He", "Ting", ""], ["Swami", "Ananthram", ""], ["Towsley", "Don", ""], ["Leung", "Kin K.", ""]]}, {"id": "2012.09680", "submitter": "Davide Ferrari", "authors": "Davide Ferrari, Angela Sara Cacciapuoti, Michele Amoretti and Marcello\n  Caleffi", "title": "Compiler Design for Distributed Quantum Computing", "comments": null, "journal-ref": "IEEE Transactions on Quantum Engineering, vol. 2, pp. 1-20, 2021", "doi": "10.1109/TQE.2021.3053921", "report-no": null, "categories": "quant-ph cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed quantum computing architectures, with the network and\ncommunications functionalities provided by the Quantum Internet, remote quantum\nprocessing units (QPUs) can communicate and cooperate for executing\ncomputational tasks that single NISQ devices cannot handle by themselves. To\nthis aim, distributed quantum computing requires a new generation of quantum\ncompilers, for mapping any quantum algorithm to any distributed quantum\ncomputing architecture. With this perspective, in this paper, we first discuss\nthe main challenges arising with compiler design for distributed quantum\ncomputing. Then, we analytically derive an upper bound of the overhead induced\nby quantum compilation for distributed quantum computing. The derived bound\naccounts for the overhead induced by the underlying computing architecture as\nwell as the additional overhead induced by the sub-optimal quantum compiler --\nexpressly designed through the paper to achieve three key features, namely,\ngeneral-purpose, efficient and effective. Finally, we validate the analytical\nresults and we confirm the validity of the compiler design through an extensive\nperformance analysis.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 15:48:32 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ferrari", "Davide", ""], ["Cacciapuoti", "Angela Sara", ""], ["Amoretti", "Michele", ""], ["Caleffi", "Marcello", ""]]}, {"id": "2012.09850", "submitter": "Jan Janak", "authors": "Jessica De Oliveira Moreira, Amey Praveen Pasarkar, Wenjun Chen,\n  Wenkai Hu, Jan Janak, Henning Schulzrinne", "title": "Social Distancing and the Internet: What Can Network Performance\n  Measurements Tell Us?", "comments": "12 pages, submitted to TPRC48", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 pandemic and related restrictions forced many to work, learn,\nand socialize from home over the internet. There appears to be consensus that\ninternet infrastructure in the developed world handled the resulting traffic\nsurge well. In this paper, we study network measurement data collected by the\nFederal Communications Commission's Measuring Broadband America program before\nand during the pandemic in the United States (US). We analyze the data to\nunderstand the impact of lockdown orders on the performance of fixed broadband\ninternet infrastructure across the US, and also attempt to correlate internet\nusage patterns with the changing behavior of users during lockdown. We found\nthe key metrics such as change in data usage to be generally consistent with\nthe literature. Through additional analysis, we found differences between metro\nand rural areas, changes in weekday, weekend, and hourly internet usage\npatterns, and indications of network congestion for some users.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:59:05 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 01:13:50 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Moreira", "Jessica De Oliveira", ""], ["Pasarkar", "Amey Praveen", ""], ["Chen", "Wenjun", ""], ["Hu", "Wenkai", ""], ["Janak", "Jan", ""], ["Schulzrinne", "Henning", ""]]}, {"id": "2012.09959", "submitter": "Liang Ma", "authors": "Liang Ma, Ting He, Ananthram Swami, Don Towsley, Kin K. Leung", "title": "Failure Localization Capability: Theorem Proof and Evaluation", "comments": "Updated references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a technical report, containing all the theorem proofs and additional\nevaluations in paper \"Network Capability in Localizing Node Failures via\nEnd-to-end Path Measurements\" by Liang Ma, Ting He, Ananthram Swami, Don\nTowsley, and Kin K. Leung, published in IEEE/ACM Transactions on Networking,\nvol. 25, no. 1, pp. 434-450, 2017.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 22:34:01 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 22:23:06 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ma", "Liang", ""], ["He", "Ting", ""], ["Swami", "Ananthram", ""], ["Towsley", "Don", ""], ["Leung", "Kin K.", ""]]}, {"id": "2012.09964", "submitter": "Liang Ma", "authors": "Liang Ma, Ting He, Ananthram Swami, Don Towsley, Kin K. Leung, Jessica\n  Lowe", "title": "Fundamental Theories in Node Failure Localization", "comments": "arXiv admin note: text overlap with arXiv:2012.09959", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a technical report, containing all the theorem proofs in paper \"Node\nFailure Localization in Communication Networks via Network Tomography\" by Liang\nMa, Ting He, Ananthram Swami, Don Towsley, Kin K. Leung, and Jessica Lowe,\npublished in ITA Annual Fall Meeting, 2014.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 22:50:45 GMT"}], "update_date": "2020-12-28", "authors_parsed": [["Ma", "Liang", ""], ["He", "Ting", ""], ["Swami", "Ananthram", ""], ["Towsley", "Don", ""], ["Leung", "Kin K.", ""], ["Lowe", "Jessica", ""]]}, {"id": "2012.09972", "submitter": "Liang Ma", "authors": "Liang Ma, Ting He, Kin K. Leung, Ananthram Swami, Don Towsley", "title": "Link Identifiability with Two Monitors: Proof of Selected Theorems", "comments": "Auxiliary algorithms are removed from this report as they exist in\n  the main (IEEE Globecom'13) paper. arXiv admin note: substantial text overlap\n  with arXiv:2012.11378", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a technical report, containing all the theorem proofs in paper \"Link\nIdentifiability in Communication Networks with Two Monitors\" by Liang Ma, Ting\nHe, Kin K. Leung, Ananthram Swami, and Don Towsley, published in IEEE Globecom,\n2013.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 23:16:42 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 02:23:27 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ma", "Liang", ""], ["He", "Ting", ""], ["Leung", "Kin K.", ""], ["Swami", "Ananthram", ""], ["Towsley", "Don", ""]]}, {"id": "2012.09990", "submitter": "Won-Yong Shin", "authors": "Cong Tran, Dung D. Vu, Won-Yong Shin", "title": "An Improved Approach for Estimating Social POI Boundaries With Textual\n  Attributes on Social Media", "comments": "13 pages, 6 figures, 5 tables; to appear in the Knowledge-Based\n  Systems (Please cite our journal version that will appear in an upcoming\n  issue.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.DS cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been insufficiently explored how to perform density-based clustering\nby exploiting textual attributes on social media. In this paper, we aim at\ndiscovering a social point-of-interest (POI) boundary, formed as a convex\npolygon. More specifically, we present a new approach and algorithm, built upon\nour earlier work on social POI boundary estimation (SoBEst). This SoBEst\napproach takes into account both relevant and irrelevant records within a\ngeographic area, where relevant records contain a POI name or its variations in\ntheir text field. Our study is motivated by the following empirical\nobservation: a fixed representative coordinate of each POI that SoBEst\nbasically assumes may be far away from the centroid of the estimated social POI\nboundary for certain POIs. Thus, using SoBEst in such cases may possibly result\nin unsatisfactory performance on the boundary estimation quality (BEQ), which\nis expressed as a function of the $F$-measure. To solve this problem, we\nformulate a joint optimization problem of simultaneously finding the radius of\na circle and the POI's representative coordinate $c$ by allowing to update $c$.\nSubsequently, we design an iterative SoBEst (I-SoBEst) algorithm, which enables\nus to achieve a higher degree of BEQ for some POIs. The computational\ncomplexity of the proposed I-SoBEst algorithm is shown to scale linearly with\nthe number of records. We demonstrate the superiority of our algorithm over\ncompeting clustering methods including the original SoBEst.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 00:41:44 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Tran", "Cong", ""], ["Vu", "Dung D.", ""], ["Shin", "Won-Yong", ""]]}, {"id": "2012.10219", "submitter": "Fidan Mehmeti", "authors": "Fidan Mehmeti and Thomas F. La Porta", "title": "Resource Allocation for Improved User Experience with Live Video\n  Streaming in 5G", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Providing a high-quality real-time video streaming experience to mobile users\nis one of the biggest challenges in cellular networks. This is due to the need\nof these services for high rates with low variability, which is not easy to\naccomplish given the competition among (usually a high number of) users for\nconstrained network resources and the high variability of their channel\ncharacteristics. A way of improving the user experience is by exploiting their\nbuffers and the ability to provide a constant data rate to everyone, as one of\nthe features of 5G networks. However, the latter is not very efficient. To this\nend, in this paper we provide a theoretical-analysis framework for resource\nallocation in 5G networks that leads to an improved user experience when\nwatching live video. We do this by solving three problems, in which the\nobjectives are to provide the highest achievable video resolution to all\none-class and two-class users, and to maximize the number of users that\nexperience a given resolution. The analysis is validated by simulations that\nare run on traces. We also compare the performance of our approach against\nother techniques for different QoE metrics. Results show that the performance\ncan be improved by at least 15% with our approach.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 13:30:06 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 21:51:09 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 19:02:24 GMT"}, {"version": "v4", "created": "Sat, 29 May 2021 17:52:31 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mehmeti", "Fidan", ""], ["La Porta", "Thomas F.", ""]]}, {"id": "2012.10252", "submitter": "Qiang Liu", "authors": "Qiang Liu, Tao Han, Jiang (Linda) Xie, BaekGyu Kim", "title": "LiveMap: Real-Time Dynamic Map in Automotive Edge Computing", "comments": "This paper is accepted by INFOCOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous driving needs various line-of-sight sensors to perceive\nsurroundings that could be impaired under diverse environment uncertainties\nsuch as visual occlusion and extreme weather. To improve driving safety, we\nexplore to wirelessly share perception information among connected vehicles\nwithin automotive edge computing networks. Sharing massive perception data in\nreal time, however, is challenging under dynamic networking conditions and\nvarying computation workloads. In this paper, we propose LiveMap, a real-time\ndynamic map, that detects, matches, and tracks objects on the road with\ncrowdsourcing data from connected vehicles in sub-second. We develop the data\nplane of LiveMap that efficiently processes individual vehicle data with object\ndetection, projection, feature extraction, object matching, and effectively\nintegrates objects from multiple vehicles with object combination. We design\nthe control plane of LiveMap that allows adaptive offloading of vehicle\ncomputations, and develop an intelligent vehicle scheduling and offloading\nalgorithm to reduce the offloading latency of vehicles based on deep\nreinforcement learning (DRL) techniques. We implement LiveMap on a small-scale\ntestbed and develop a large-scale network simulator. We evaluate the\nperformance of LiveMap with both experiments and simulations, and the results\nshow LiveMap reduces 34.1% average latency than the baseline solution.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 15:00:49 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Liu", "Qiang", "", "Linda"], ["Han", "Tao", "", "Linda"], ["Jiang", "", "", "Linda"], ["Xie", "", ""], ["Kim", "BaekGyu", ""]]}, {"id": "2012.10468", "submitter": "Muhammad Bilal", "authors": "Zaiwar Ali, Sadia Khaf, Ziaul Haq Abba, Ghulam Abbas, Lei Jiao, Amna\n  Irshad, Kyung Sup Kwak, Muhammad Bilal", "title": "A Comprehensive Utility Function for Resource Allocation in Mobile Edge\n  Computing", "comments": "17 pages, 3 Figures, Published in Computers, Materials & Continua", "journal-ref": "Computers, Materials & Continua, Vol.66, No.2, 2021, pp.1461-1477", "doi": "10.32604/cmc.2020.013743", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In mobile edge computing (MEC), one of the important challenges is how much\nresources of which mobile edge server (MES) should be allocated to which user\nequipment (UE). The existing resource allocation schemes only consider CPU as\nthe requested resource and assume utility for MESs as either a random variable\nor dependent on the requested CPU only. This paper presents a novel\ncomprehensive utility function for resource allocation in MEC. The utility\nfunction considers the heterogeneous nature of applications that a UE offloads\nto MES. The proposed utility function considers all important parameters,\nincluding CPU, RAM, hard disk space, required time, and distance, to calculate\na more realistic utility value for MESs. Moreover, we improve upon some general\nalgorithms, used for resource allocation in MEC and cloud computing, by\nconsidering our proposed utility function. We name the improved versions of\nthese resource allocation schemes as comprehensive resource allocation schemes.\nThe UE requests are modeled to represent the amount of resources requested by\nthe UE as well as the time for which the UE has requested these resources. The\nutility function depends upon the UE requests and the distance between UEs and\nMES, and serves as a realistic means of comparison between different types of\nUE requests. Choosing (or selecting) an optimal MES with the optimal amount of\nresources to be allocated to each UE request is a challenging task. We show\nthat MES resource allocation is sub-optimal if CPU is the only resource\nconsidered. By taking into account the other resources, i.e., RAM, disk space,\nrequest time, and distance in the utility function, we demonstrate improvement\nin the resource allocation algorithms in terms of service rate, utility, and\nMES energy consumption.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 19:08:33 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ali", "Zaiwar", ""], ["Khaf", "Sadia", ""], ["Abba", "Ziaul Haq", ""], ["Abbas", "Ghulam", ""], ["Jiao", "Lei", ""], ["Irshad", "Amna", ""], ["Kwak", "Kyung Sup", ""], ["Bilal", "Muhammad", ""]]}, {"id": "2012.10652", "submitter": "Tristan Bruns", "authors": "Tristan Bruns", "title": "Network Reconnaissance in IPv6-based Residential Broadband Networks", "comments": "Master's thesis submitted at University of Bremen, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network scanning has been a widely used technique to gather information on\nthe Internet as a whole. The transition from IPv4 to IPv6 causes traditional\nnetwork scanning to become less useful. An increasing number of hosts is either\nIPv6-only or not publicly addressable via IPv4 due to the use of NAT, prompting\na need for network scanning techniques for the IPv6-based Internet. All current\napproaches to IPv6 network scanning make use of hitlists (lists of IPv6\naddresses to be scanned). A variety of methods for compiling hitlists have been\npresented, but they have a strong bias towards server hosts, and do not find\naddresses of client hosts -- smartphones, tablets, PCs, 'smart home' devices,\netc. -- in a significant amount. Client hosts are the majority of devices\nconnected to the Internet. Furthermore, when connected to a residential\nbroadband connection, they can exchange data at substantial speeds, making them\nattractive targets for botnets. Scanning residential broadband networks is\nchallenging because the active addresses are changing much more frequently than\naddresses of server hosts.\n  This master's thesis aims to adapt prior IPv6 network scanning techniques to\nresidential broadband networks. To this end, the following contributions are\nmade:\n  Description and evaluation of an IPv6 address space visualization method,\n  Introduction of the NTP Pool Project as a public and passive IPv6 hitlist\nsource detecting mostly client hosts, 'Smart Home' devices and CPEs,\n  Description of a scanning technique for Internet access provider networks,\n  Case study on the three major German residential broadband networks.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 10:38:42 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bruns", "Tristan", ""]]}, {"id": "2012.10690", "submitter": "Bruno Jos\\'e Olivieri de Souza", "authors": "Bruno Olivieri, Marcelo Paulon and Markus Endler", "title": "GrADyS: Exploring movement awareness for efficient routing in\n  Ground-and-Air Dynamic Sensor Networks", "comments": "16 pages presenting project GrADyS with drones/uav decentralized\n  coordination and BLE relay protocol. Tech report series Monografias em\n  Ci\\^encia da Computa\\c{c}\\~ao, November 2020, Dep. Inform\\'atica PUC-Rio,\n  ISSN 0103-9741", "journal-ref": null, "doi": null, "report-no": "MCC02/20", "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Several situations exist where a geographic region of some size needs to be\nscanned or monitored through many sensors. Still, it is either absolutely\nimpossible or prohibitively expensive to deploy and maintain wireless\ncommunication infrastructure for the distributed sensors. Either because the\nregion is hidden behind walls, not easily accessible, hard to get through, or\ninfected with some lethal bacteria or virus transmitter. In this case, the best\nis to scatter (disposable) sensors in the region and let them transmit the\ncollected sensor data by wireless means to an overflying UAV/drone. Which then\nphysically hauls the collected data from the monitored area to a central base\nstation that functions as a gateway to the Internet. The project GrADyS aims to\nresearch two sets of problems regarding such data collection. The former aims\nto coordinate several autonomous UAVs in a distributed manner to collect the\ngenerated data while relying only on ad-hoc communication. The latter aims to\ndevelop routing protocols to mesh networks Bluetooth Mesh's Low Power Nodes.\nBoth research lines already present preliminary results that are presented in\nthis paper.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 14:01:59 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 12:59:36 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Olivieri", "Bruno", ""], ["Paulon", "Marcelo", ""], ["Endler", "Markus", ""]]}, {"id": "2012.10937", "submitter": "Mohammed Hirzallah", "authors": "Mohammed Hirzallah, Marwan Krunz, Balkan Kecicioglu, Belal Hamzeh", "title": "5G New Radio Unlicensed: Challenges and Evaluation", "comments": "in IEEE Transactions on Cognitive Communications and Networking, 2020", "journal-ref": null, "doi": "10.1109/TCCN.2020.3041851", "report-no": "Report-no: UoA-ECE-20-01", "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  To meet the high demand for mobile data, the Third Generation Partnership\nProject (3GPP) established a set of standards known as 5G New Radio (5G NR).\nThe architecture of 5G NR includes a flexible radio access network and a core\nnetwork. 3GPP has also been working on a new radio access technology, called 5G\nNR Unlicensed (5G NR-U), which aims at extending 5G NR to unlicensed bands. In\nthis paper, we give an overview of the most recent 5G NR-U design elements and\ndiscuss potential concerns, including fair coexistence with other unlicensed\ntechnologies such as Wi-Fi. We use simulations to study coexistence between\nWi-Fi and 5G NR-U systems. Our evaluation indicates that NR-U often achieves\nhigher throughput and lower delay than Wi-Fi (802.11ac). The two systems\nexperience different buffer occupancies and spectrum utilization statistics. We\nalso discuss the improvements that NR-U offers over LTE Licensed Assisted\nAccess (LTE-LAA).\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 14:41:33 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Hirzallah", "Mohammed", ""], ["Krunz", "Marwan", ""], ["Kecicioglu", "Balkan", ""], ["Hamzeh", "Belal", ""]]}, {"id": "2012.11070", "submitter": "Rui Chen", "authors": "Rui Chen, Liang Li, Kaiping Xue, Chi Zhang, Lingjia Liu, Miao Pan", "title": "To Talk or to Work: Energy Efficient Federated Learning over Mobile\n  Devices via the Weight Quantization and 5G Transmission Co-Design", "comments": "submitted to MOBIHOC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a new paradigm for large-scale learning tasks\nacross mobile devices. However, practical FL deployment over resource\nconstrained mobile devices confronts multiple challenges. For example, it is\nnot clear how to establish an effective wireless network architecture to\nsupport FL over mobile devices. Besides, as modern machine learning models are\nmore and more complex, the local on-device training/intermediate model update\nin FL is becoming too power hungry/radio resource intensive for mobile devices\nto afford. To address those challenges, in this paper, we try to bridge another\nrecent surging technology, 5G, with FL, and develop a wireless transmission and\nweight quantization co-design for energy efficient FL over heterogeneous 5G\nmobile devices. Briefly, the 5G featured high data rate helps to relieve the\nsevere communication concern, and the multi-access edge computing (MEC) in 5G\nprovides a perfect network architecture to support FL. Under MEC architecture,\nwe develop flexible weight quantization schemes to facilitate the on-device\nlocal training over heterogeneous 5G mobile devices. Observed the fact that the\nenergy consumption of local computing is comparable to that of the model\nupdates via 5G transmissions, we formulate the energy efficient FL problem into\na mixed-integer programming problem to elaborately determine the quantization\nstrategies and allocate the wireless bandwidth for heterogeneous 5G mobile\ndevices. The goal is to minimize the overall FL energy consumption (computing +\n5G transmissions) over 5G mobile devices while guaranteeing learning\nperformance and training latency. Generalized Benders' Decomposition is applied\nto develop feasible solutions and extensive simulations are conducted to verify\nthe effectiveness of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 01:13:44 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Chen", "Rui", ""], ["Li", "Liang", ""], ["Xue", "Kaiping", ""], ["Zhang", "Chi", ""], ["Liu", "Lingjia", ""], ["Pan", "Miao", ""]]}, {"id": "2012.11206", "submitter": "Reza Malekian Ph.D.", "authors": "Nikheel Soni, Reza Malekian, Arnav Thakur", "title": "Edge Computing in Transportation: Security Issues and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the amount of data that needs to be processed in real-time due to recent\napplication developments increase, the need for a new computing paradigm is\nrequired. Edge computing resolves this issue by offloading computing resources\nrequired by intelligent transportation systems such as the Internet of Vehicles\nfrom the cloud closer to the end devices to improve performance however, it is\nsusceptible to security issues that make the transportation systems vulnerable\nto attackers. In addition to this, there are security issues in transportation\ntechnologies that impact the edge computing paradigm as well. This paper\npresents some of the main security issues and challenges that are present in\nedge computing, which are Distributed Denial of Service attacks, side channel\nattacks, malware injection attacks and authentication and authorization\nattacks, how these impact intelligent transportation systems and research being\ndone to help realize and mitigate these issues.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 09:41:05 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Soni", "Nikheel", ""], ["Malekian", "Reza", ""], ["Thakur", "Arnav", ""]]}, {"id": "2012.11325", "submitter": "Abdallah Moubayed", "authors": "MohammadNoor Injadat and Abdallah Moubayed and Abdallah Shami", "title": "Detecting Botnet Attacks in IoT Environments: An Optimized Machine\n  Learning Approach", "comments": "4 pages, 2 figures, 1 table, Accepted and presented at IEEE 32nd\n  International Conference on Microelectronics (IEEE-ICM2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased reliance on the Internet and the corresponding surge in\nconnectivity demand has led to a significant growth in Internet-of-Things (IoT)\ndevices. The continued deployment of IoT devices has in turn led to an increase\nin network attacks due to the larger number of potential attack surfaces as\nillustrated by the recent reports that IoT malware attacks increased by 215.7%\nfrom 10.3 million in 2017 to 32.7 million in 2018. This illustrates the\nincreased vulnerability and susceptibility of IoT devices and networks.\nTherefore, there is a need for proper effective and efficient attack detection\nand mitigation techniques in such environments. Machine learning (ML) has\nemerged as one potential solution due to the abundance of data generated and\navailable for IoT devices and networks. Hence, they have significant potential\nto be adopted for intrusion detection for IoT environments. To that end, this\npaper proposes an optimized ML-based framework consisting of a combination of\nBayesian optimization Gaussian Process (BO-GP) algorithm and decision tree (DT)\nclassification model to detect attacks on IoT devices in an effective and\nefficient manner. The performance of the proposed framework is evaluated using\nthe Bot-IoT-2018 dataset. Experimental results show that the proposed optimized\nframework has a high detection accuracy, precision, recall, and F-score,\nhighlighting its effectiveness and robustness for the detection of botnet\nattacks in IoT environments.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 16:39:55 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Moubayed", "Abdallah", ""], ["Shami", "Abdallah", ""]]}, {"id": "2012.11326", "submitter": "Abdallah Moubayed", "authors": "Abdallah Moubayed and MohammadNoor Injadat and Abdallah Shami", "title": "Optimized Random Forest Model for Botnet Detection Based on DNS Queries", "comments": "4 pages, 3 figures, 1 table, Accepted and presented in IEEE 32nd\n  International Conference on Microelectronics (IEEE-ICM2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Domain Name System (DNS) protocol plays a major role in today's Internet\nas it translates between website names and corresponding IP addresses. However,\ndue to the lack of processes for data integrity and origin authentication, the\nDNS protocol has several security vulnerabilities. This often leads to a\nvariety of cyber-attacks, including botnet network attacks. One promising\nsolution to detect DNS-based botnet attacks is adopting machine learning (ML)\nbased solutions. To that end, this paper proposes a novel optimized ML-based\nframework to detect botnets based on their corresponding DNS queries. More\nspecifically, the framework consists of using information gain as a feature\nselection method and genetic algorithm (GA) as a hyper-parameter optimization\nmodel to tune the parameters of a random forest (RF) classifier. The proposed\nframework is evaluated using a state-of-the-art TI-2016 DNS dataset.\nExperimental results show that the proposed optimized framework reduced the\nfeature set size by up to 60%. Moreover, it achieved a high detection accuracy,\nprecision, recall, and F-score compared to the default classifier. This\nhighlights the effectiveness and robustness of the proposed framework in\ndetecting botnet attacks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 16:34:11 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Moubayed", "Abdallah", ""], ["Injadat", "MohammadNoor", ""], ["Shami", "Abdallah", ""]]}, {"id": "2012.11354", "submitter": "Tommaso Zoppi Dr", "authors": "Tommaso Zoppi, Andrea ceccarelli, Tommaso Capecchi, Andrea Bondavalli", "title": "Unsupervised Anomaly Detectors to Detect Intrusions in the Current\n  Threat Landscape", "comments": "Will be published on ACM Transactions Data Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection aims at identifying unexpected fluctuations in the expected\nbehavior of a given system. It is acknowledged as a reliable answer to the\nidentification of zero-day attacks to such extent, several ML algorithms that\nsuit for binary classification have been proposed throughout years. However,\nthe experimental comparison of a wide pool of unsupervised algorithms for\nanomaly-based intrusion detection against a comprehensive set of attacks\ndatasets was not investigated yet. To fill such gap, we exercise seventeen\nunsupervised anomaly detection algorithms on eleven attack datasets. Results\nallow elaborating on a wide range of arguments, from the behavior of the\nindividual algorithm to the suitability of the datasets to anomaly detection.\nWe conclude that algorithms as Isolation Forests, One-Class Support Vector\nMachines and Self-Organizing Maps are more effective than their counterparts\nfor intrusion detection, while clustering algorithms represent a good\nalternative due to their low computational complexity. Further, we detail how\nattacks with unstable, distributed or non-repeatable behavior as Fuzzing, Worms\nand Botnets are more difficult to detect. Ultimately, we digress on\ncapabilities of algorithms in detecting anomalies generated by a wide pool of\nunknown attacks, showing that achieved metric scores do not vary with respect\nto identifying single attacks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 14:06:58 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Zoppi", "Tommaso", ""], ["ceccarelli", "Andrea", ""], ["Capecchi", "Tommaso", ""], ["Bondavalli", "Andrea", ""]]}, {"id": "2012.11378", "submitter": "Liang Ma", "authors": "Liang Ma, Ting He, Kin K. Leung, Ananthram Swami, Don Towsley", "title": "Partial Network Identifiability: Theorem Proof and Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a technical report, containing all the theorem proofs and additional\nevaluations in paper \"Monitor Placement for Maximal Identifiability in Network\nTomography\" by Liang Ma, Ting He, Kin K. Leung, Ananthram Swami, Don Towsley,\npublished in IEEE INFOCOM, 2014.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 23:34:39 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ma", "Liang", ""], ["He", "Ting", ""], ["Leung", "Kin K.", ""], ["Swami", "Ananthram", ""], ["Towsley", "Don", ""]]}, {"id": "2012.11504", "submitter": "Adnan Aijaz", "authors": "Adnan Aijaz, Aleksandar Stanoev", "title": "Closing the Loop: A High-Performance Connectivity Solution for Realizing\n  Wireless Closed-Loop Control in Industrial IoT Applications", "comments": "Accepted for publication in IEEE IoT Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance real-time wireless connectivity is at the heart of the\nIndustrial Internet-of-Things (IIoT). Realizing wireless closed-loop control is\ncrucial for various mission-critical IIoT systems. Existing wireless\ntechnologies fall short of meeting the stringent performance requirements of\nclosed-loop control. This paper presents a novel wireless solution, called\n\\textsf{GALLOP}, for realizing closed-loop control over multi-hop or single-hop\nnetworks. \\textsf{GALLOP} adopts a pragmatic design approach for addressing the\nchallenges of wireless closed-loop control. Key design aspects of\n\\textsf{GALLOP} include control-aware bi-directional scheduling for cyclic\nexchange, robust retransmission techniques based on cooperative multi-user\ndiversity and low-overhead signaling for scalable operation. \\textsf{GALLOP}\nhas been specifically designed for control loops that are closed over the whole\nnetwork with dynamics on the order of few milliseconds. Performance evaluation\nbased on extensive system-level simulations and hardware implementation on a\nBluetooth 5 testbed demonstrates that \\textsf{GALLOP} provides high-performance\nconnectivity with very low and deterministic latency, very high reliability and\nhigh scalability, to meet the stringent requirements of wireless closed-loop\ncontrol for versatile IIoT applications.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 17:24:05 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 14:19:47 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Aijaz", "Adnan", ""], ["Stanoev", "Aleksandar", ""]]}, {"id": "2012.11702", "submitter": "Mehrnoosh Shafiee", "authors": "Mehrnoosh Shafiee, Javad Ghaderi", "title": "Scheduling Coflows with Dependency Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Applications in data-parallel computing typically consist of multiple stages.\nIn each stage, a set of intermediate parallel data flows (Coflow) is produced\nand transferred between servers to enable starting of next stage. While there\nhas been much research on scheduling isolated coflows, the dependency between\ncoflows in multi-stage jobs has been largely ignored. In this paper, we\nconsider scheduling coflows of multi-stage jobs represented by general DAGs\n(Directed Acyclic Graphs) in a shared data center network, so as to minimize\nthe total weighted completion time of jobs. This problem is significantly more\nchallenging than the traditional coflow scheduling, as scheduling even a single\nmulti-stage job to minimize its completion time is shown to be NP-hard.\n  In this paper, we propose a polynomial-time algorithm with approximation\nratio of $O(\\mu\\log(m)/\\log(\\log(m)))$, where $\\mu$ is the maximum number of\ncoflows in a job and $m$ is the number of servers. For the special case that\nthe jobs' underlying dependency graphs are rooted trees, we modify the\nalgorithm and improve its approximation ratio. To verify the performance of our\nalgorithms, we present simulation results using real traffic traces that show\nup to $53 \\%$ improvement over the prior approach. We conclude the paper by\nproviding a result concerning an optimality gap for scheduling coflows with\ngeneral DAGs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 21:59:24 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Shafiee", "Mehrnoosh", ""], ["Ghaderi", "Javad", ""]]}, {"id": "2012.11723", "submitter": "Jean Walrand", "authors": "Jean Walrand, Max Turner, and Roy Myers", "title": "An Architecture for In-Vehicle Network", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As vehicles get equipped with increasingly complex sensors and processors,\nthe communication requirements become more demanding. Traditionally, vehicles\nhave used specialized networking technologies designed to guarantee bounded\nlatencies, such as the Controller Area Network (CAN) bus. Recently, some have\nused dedicated technologies to transport signals from cameras, lidars, radars,\nand ultrasonic sensors. In parallel, IEEE working groups are defining Ethernet\nstandards for time-sensitive networks (TSN). This paper describes an\nEthernet-based architecture with provable guaranteed performance and simple\nconfiguration that is suitable for supporting the communication requirements of\nmany vehicles.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 22:35:24 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Walrand", "Jean", ""], ["Turner", "Max", ""], ["Myers", "Roy", ""]]}, {"id": "2012.11783", "submitter": "Wei Cui", "authors": "Wei Cui and Wei Yu", "title": "Scalable Deep Reinforcement Learning for Routing and Spectrum Access in\n  Physical Layer", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel and scalable reinforcement learning approach for\nsimultaneous routing and spectrum access in wireless ad-hoc networks. In most\nprevious works on reinforcement learning for network optimization, routing and\nspectrum access are tackled as separate tasks; further, the wireless links in\nthe network are assumed to be fixed, and a different agent is trained for each\ntransmission node -- this limits scalability and generalizability. In this\npaper, we account for the inherent signal-to-interference-plus-noise ratio\n(SINR) in the physical layer and propose a more scalable approach in which a\nsingle agent is associated with each flow. Specifically, a single agent makes\nall routing and spectrum access decisions as it moves along the frontier nodes\nof each flow. The agent is trained according to the physical layer\ncharacteristics of the environment using the future bottleneck SINR as a novel\nreward definition. This allows a highly effective routing strategy based on the\ngeographic locations of the nodes in the wireless ad-hoc network. The proposed\ndeep reinforcement learning strategy is capable of accounting for the mutual\ninterference between the links. It learns to avoid interference by\nintelligently allocating spectrum slots and making routing decisions for the\nentire network in a scalable manner.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 01:47:20 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Cui", "Wei", ""], ["Yu", "Wei", ""]]}, {"id": "2012.11867", "submitter": "Inaam Ilahi", "authors": "Inaam Ilahi, Muhammad Usama, Muhammad Omer Farooq, Muhammad Umar\n  Janjua, and Junaid Qadir", "title": "Intelligent Resource Allocation in Dense LoRa Networks using Deep\n  Reinforcement Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The anticipated increase in the count of IoT devices in the coming years\nmotivates the development of efficient algorithms that can help in their\neffective management while keeping the power consumption low. In this paper, we\npropose LoRaDRL and provide a detailed performance evaluation. We propose a\nmulti-channel scheme for LoRaDRL. We perform extensive experiments, and our\nresults demonstrate that the proposed algorithm not only significantly improves\nlong-range wide area network (LoRaWAN)'s packet delivery ratio (PDR) but is\nalso able to support mobile end-devices (EDs) while ensuring lower power\nconsumption. Most previous works focus on proposing different MAC protocols for\nimproving the network capacity. We show that through the use of LoRaDRL, we can\nachieve the same efficiency with ALOHA while moving the complexity from EDs to\nthe gateway thus making the EDs simpler and cheaper. Furthermore, we test the\nperformance of LoRaDRL under large-scale frequency jamming attacks and show its\nadaptiveness to the changes in the environment. We show that LoRaDRL's output\nimproves the performance of state-of-the-art techniques resulting in some cases\nan improvement of more than 500% in terms of PDR compared to learning-based\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 07:41:47 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Ilahi", "Inaam", ""], ["Usama", "Muhammad", ""], ["Farooq", "Muhammad Omer", ""], ["Janjua", "Muhammad Umar", ""], ["Qadir", "Junaid", ""]]}, {"id": "2012.11943", "submitter": "Ze-Feng Gao", "authors": "Ze-Feng Gao, Xingwei Sun, Lan Gao, Junfeng Li and Zhong-Yi Lu", "title": "Compressing LSTM Networks by Matrix Product Operators", "comments": "2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI physics.comp-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) models are the building blocks of many\nstate-of-the-art algorithms for Natural Language Processing (NLP). But, there\nare a large number of parameters in an LSTM model. This usually brings out a\nlarge amount of memory space needed for operating an LSTM model. Thus, an LSTM\nmodel usually requires a large amount of computational resources for training\nand predicting new data, suffering from computational inefficiencies. Here we\npropose an alternative LSTM model to reduce the number of parameters\nsignificantly by representing the weight parameters based on matrix product\noperators (MPO), which are used to characterize the local correlation in\nquantum states in physics. We further experimentally compare the compressed\nmodels based the MPO-LSTM model and the pruning method on sequence\nclassification and sequence prediction tasks. The experimental results show\nthat our proposed MPO-based method outperforms the pruning method.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 11:50:06 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 10:48:12 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Gao", "Ze-Feng", ""], ["Sun", "Xingwei", ""], ["Gao", "Lan", ""], ["Li", "Junfeng", ""], ["Lu", "Zhong-Yi", ""]]}, {"id": "2012.11971", "submitter": "Sumudu Samarakoon Dr.", "authors": "Sumudu Samarakoon, Mehdi Bennis, Walid Saad, Merouane Debbah", "title": "Predictive Ultra-Reliable Communication: A Survival Analysis Perspective", "comments": "5 pages, 5 figures, Accepted for IEEE Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-reliable communication (URC) is a key enabler for supporting immersive\nand mission-critical 5G applications. Meeting the strict reliability\nrequirements of these applications is challenging due to the absence of\naccurate statistical models tailored to URC systems. In this letter, the\nwireless connectivity over dynamic channels is characterized via statistical\nlearning methods. In particular, model-based and data-driven learning\napproaches are proposed to estimate the non-blocking connectivity statistics\nover a set of training samples with no knowledge on the dynamic channel\nstatistics. Using principles of survival analysis, the reliability of wireless\nconnectivity is measured in terms of the probability of channel blocking\nevents. Moreover, the maximum transmission duration for a given reliable\nnon-blocking connectivity is predicted in conjunction with the confidence of\nthe inferred transmission duration. Results show that the accuracy of detecting\nchannel blocking events is higher using the model-based method for low to\nmoderate reliability targets requiring low sample complexity. In contrast, the\ndata-driven method shows higher detection accuracy for higher reliability\ntargets at the cost of 100$\\times$ sample complexity.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 12:50:07 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Samarakoon", "Sumudu", ""], ["Bennis", "Mehdi", ""], ["Saad", "Walid", ""], ["Debbah", "Merouane", ""]]}, {"id": "2012.12097", "submitter": "Babis Magoutas", "authors": "Matthias Prandtstetter, Clovis Seragiotto, Markus Straub, Babis\n  Magoutas, Efthimios Bothos, Luka Bradesko", "title": "Providing Intermodal Route Alternatives", "comments": "Proceedings of 7th Transport Research Arena TRA 2018, April 16-19,\n  2018, Vienna, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Within this paper, we present a novel routing algorithm capable of providing\nnot only truly intermodal routes but also coming up with route alternatives.\nThese route alternatives feature different route and mode choices while still\noptimizing the same objective function (e.g. travel time). We therefore,\nprovide a first presentation of the next generation routing service, which are\nfundamental for the introduction of Mobility-as-a-Service in the passenger\nsector or synchromodality in the freight transportation sector. We finally\nprovide a showcase of motorhome routing where the full potential of the\npresented routing algorithm is shown.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 16:51:31 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Prandtstetter", "Matthias", ""], ["Seragiotto", "Clovis", ""], ["Straub", "Markus", ""], ["Magoutas", "Babis", ""], ["Bothos", "Efthimios", ""], ["Bradesko", "Luka", ""]]}, {"id": "2012.12123", "submitter": "Deepika Mohan", "authors": "Deepika Mohan, G.G.Md.Nawaz Ali, Peter Han Joo Chong", "title": "Machine Learning Algorithm for NLOS Millimeter Wave in 5G V2X\n  Communication", "comments": "14 pages, 9 figures, conference 7th International conference on\n  Computer Networks and Communications (CCNET 2020), AIRCC Publishing\n  Corporation", "journal-ref": null, "doi": null, "report-no": "Volume 10, number 17", "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The 5G vehicle-to-everything (V2X) communication for autonomous and\nsemi-autonomous driving utilizes the wireless technology for communication and\nthe Millimeter Wave bands are widely implemented in this kind of vehicular\nnetwork application. The main purpose of this paper is to broadcast the\nmessages from the mmWave Base Station to vehicles at LOS (Line-of-sight) and\nNLOS (Non-LOS). Relay using Machine Learning (RML) algorithm is formulated to\ntrain the mmBS for identifying the blockages within its coverage area and\nbroadcast the messages to the vehicles at NLOS using a LOS nodes as a relay.\nThe transmission of information is faster with higher throughput and it covers\na wider bandwidth which is reused, therefore when performing machine learning\nwithin the coverage area of mmBS most of the vehicles in NLOS can be benefited.\nA unique method of relay mechanism combined with machine learning is proposed\nto communicate with mobile nodes at NLOS.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 11:41:09 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Mohan", "Deepika", ""], ["Ali", "G. G. Md. Nawaz", ""], ["Chong", "Peter Han Joo", ""]]}, {"id": "2012.12179", "submitter": "Anders E. Kal{\\o}r", "authors": "Anders E. Kal{\\o}r, Petar Popovski", "title": "Timely Monitoring of Dynamic Sources with Observations from Multiple\n  Wireless Sensors", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Age of Information (AoI) has recently received much attention due to its\nrelevance in IoT sensing and monitoring applications. In this paper, we\nconsider the problem of minimizing the AoI in a system in which a set of\nsources are observed by multiple sensors in a many-to-many relationship, and\nthe probability that a sensor observes a source depends on the state of the\nsource. This model represents many practical scenarios, such as the ones in\nwhich multiple cameras or microphones are deployed to monitor objects moving in\ncertain areas. We formulate the scheduling problem as a Markov Decision\nProcess, and show how the age-optimal scheduling policy can be obtained. We\nfurther consider partially observable variants of the problem, and devise\napproximate policies for large state spaces. Our evaluations show that the\napproximate policies work well in the considered scenarios, and that the fact\nthat sensors can observe multiple sources is beneficial, especially when there\nis high uncertainty of the source states.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 17:17:21 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Kal\u00f8r", "Anders E.", ""], ["Popovski", "Petar", ""]]}, {"id": "2012.12182", "submitter": "Gursel Serpen", "authors": "Gursel Serpen and Zhenning Gao", "title": "Reduced Complexity Simulation of Wireless Sensor Networks for\n  Application Development", "comments": "49 single-column and double spaced pages; 8 figures; and 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents an approach for low-cost simulation modeling for\napplication development for wireless sensor networks. Computational complexity\nof simulating wireless sensor networks can be very high and as such must be\ncarefully managed. Application-level code prototyping with reasonable accuracy\nand fidelity can be accomplished through simulation that models only the\neffects of the wireless and distributed computations which materialize mainly\nas delay and drop for the messages being exchanged among the motes. This\napproach employs the abstraction that all physical or communication and\nprotocol level operations can be represented in terms of their effects as\nmessage delay and drop at the application level for a wireless sensor network.\nThis study proposes that idea of empirical modeling of delay and drop and\nemploying those models to affect the reception times of wirelessly communicated\nmessages. It further proposes the delay and drop to be modeled as random\nvariables with probability distributions empirically approximated based on the\ndata reported in the literature. The proposed approach is demonstrated through\ndevelopment of a neural network application with neurons distributed across the\nmotes of a wireless sensor network. Delay and drop are incorporated into\nwireless communications, which carry neuron output values among motes. A set of\nclassification data sets from the Machine Learning Repository are employed to\ndemonstrate the performance of the proposed system in a comparative context\nwith the similar studies in the literature. Results and findings indicate that\nthe proposed approach of abstracting wireless sensor network operation in terms\nof message delay and drop at the application level is feasible to facilitate\ndevelopment of applications with competitive performance profiles while\nminimizing the spatio-temporal cost of simulation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 16:04:30 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Serpen", "Gursel", ""], ["Gao", "Zhenning", ""]]}, {"id": "2012.12190", "submitter": "Liang Ma", "authors": "Liang Ma, Ting He, Kin K. Leung, Ananthram Swami, Don Towsley", "title": "Identification of Additive Link Metrics: Proof of Selected Theorems", "comments": "References are updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a technical report, containing all the theorem proofs in the\nfollowing two papers: (1) Liang Ma, Ting He, Kin K. Leung, Ananthram Swami, and\nDon Towsley, \"Identifiability of Link Metrics Based on End-to-end Path\nMeasurements,\" in ACM IMC, 2013. (2) Liang Ma, Ting He, Kin K. Leung, Ananthram\nSwami, and Don Towsley, \"Inferring Link Metrics from End-to-end Path\nMeasurements: Identifiability and Monitor Placement,\" IEEE/ACM Transactions on\nNetworking, vol. 22, no. 4, pp. 1351-1368, 2014.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 00:09:39 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 16:22:17 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Ma", "Liang", ""], ["He", "Ting", ""], ["Leung", "Kin K.", ""], ["Swami", "Ananthram", ""], ["Towsley", "Don", ""]]}, {"id": "2012.12191", "submitter": "Liang Ma", "authors": "Liang Ma, Ting He, Kin K. Leung, Don Towsley, Ananthram Swami", "title": "Efficient Identification of Additive Link Metrics: Theorem Proof and\n  Evaluations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a technical report, containing all the theorem proofs and additional\nevaluations in paper \"Efficient Identification of Additive Link Metrics via\nNetwork Tomography\" by Liang Ma, Ting He, Kin K. Leung, Don Towsley, and\nAnanthram Swami, published in IEEE ICDCS, 2013.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 23:58:45 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Ma", "Liang", ""], ["He", "Ting", ""], ["Leung", "Kin K.", ""], ["Towsley", "Don", ""], ["Swami", "Ananthram", ""]]}, {"id": "2012.12362", "submitter": "Rolysent Paredes", "authors": "Rolysent K Paredes and Alexander A. Hernandez", "title": "Designing an Adaptive Bandwidth Management for Higher Education\n  Institutions", "comments": null, "journal-ref": null, "doi": "10.25147/ijcsr.2017.001.1.22", "report-no": null, "categories": "cs.NI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose: This study proposes an adaptive bandwidth management system which\ncan be explicitly used by educational institutions. The primary goal of the\nsystem is to increase the bandwidth of the users who access more on educational\nwebsites. Through this proposed bandwidth management, the users of the campus\nnetworks is encouraged to utilize the internet for educational purposes.\n  Method: The weblog from a university's pfSense proxy server was utilized and\nundergo Web Usage Mining (WUM) to determine the number of educational and\nnon-educational websites accessed by the users. Certain formulas were used in\nthe computation of the bandwidth which was dynamically assigned to the users. A\nprototyping technique was applied in developing adaptive bandwidth management\nsystem. The prototype was simulated and evaluated by experts in compliance with\nISO/IEC 14598-6 and ISO/IEC 9126-1 standards.\n  Results: This study found that the prototype is capable of adjusting the\nbandwidth of the network users dynamically. The users who browsed more on\neducational websites or contents were assigned with higher bandwidth compared\nto those who are not. Further, the evaluated prototype met the software\nstandards of ISO.\n  Conclusion: The proposed adaptive bandwidth management can contribute to the\ncontinuous development in the area of computer networking, especially in\ndesigning and managing campus networks. It also helps the network\nadministrators or IT managers in allocating bandwidth with minimal effort.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 11:59:29 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Paredes", "Rolysent K", ""], ["Hernandez", "Alexander A.", ""]]}, {"id": "2012.12419", "submitter": "Elyes Balti", "authors": "Yassine Maalej and Elyes Balti", "title": "CUDA-Accelerated Application Scheduling in Vehicular Clouds Under\n  Advanced Multichannel Operations in WAVE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel Advanced Activity-Aware (AAA) scheme to optimize\nand improve Multi-Channel Operations based on the IEEE 1609.4 standard in\nwireless access vehicular environments (WAVE). The proposed scheme relies on\nthe awareness of the vehicular safety load to dynamically find an optimal setup\nfor switching between service channel intervals (SCHI) and control channel\nintervals (CCHI). SCHI are chosen for non-critical applications (e.g.\ninfotainment), while CCHI are utilized for critical applications (e.g.\nsafety-related). We maximize the channel utilization without sacrificing other\napplication requirements such as latency and bandwidth. Our scheme is\nimplemented and evaluated network simulator-3 (NS3). We guarantee the default\nSynchronization Interval (SI), like implemented by the standard in vehicular ad\nhoc networks (VANETs), when tested on real-time simulations of vehicular cloud\n(VC) load and VANET setups using NS3. We also evaluate a Markov Decision\nProcess (MDP) based scheme and a fast greedy heuristic to optimize the problem\nof vehicular task placement with both IEEE 1609.4 and an opportunistic V2I\nversion of the proposed AAA scheme. Our solution offers the reward of the VC by\ntaking into account the overall utilization of the distributed virtualized VCs\nresources and vehicular bag-of-tasks (BOTs) placements both sequentially and in\nparallel. We present the simulation metrics proving that our proposed solution\nsignificantly improve the throughput and decreases the average delay of\nuploaded packets used for non-safety applications, while maintaining reliable\ncommunication (via CCHI) for safety-related applications similar to the IEEE\n1609.4 standard.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 23:49:05 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Maalej", "Yassine", ""], ["Balti", "Elyes", ""]]}, {"id": "2012.12434", "submitter": "Hongwei Zhang", "authors": "Matthias Sander-Frigau, Tianyi Zhang, Hongwei Zhang, Ahmed E. Kamal,\n  Arun K. Somani", "title": "Physical Wireless Resource Virtualization for Software-Defined\n  Whole-Stack Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": "Iowa State University Technical Report ISU-DNC-TR-20-02", "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Radio access network (RAN) virtualization is gaining more and more ground and\nexpected to re-architect the next-generation cellular networks. Existing RAN\nvirtualization studies and solutions have mostly focused on sharing\ncommunication capacity and tend to require the use of the same PHY and MAC\nlayers across network slices. This approach has not considered the scenarios\nwhere different slices require different PHY and MAC layers, for instance, for\nradically different services and for whole-stack research in wireless living\nlabs where novel PHY and MAC layers need to be deployed concurrently with\nexisting ones on the same physical infrastructure. To enable whole-stack\nslicing where different PHY and MAC layers may be deployed in different slices,\nwe develop PV-RAN, the first open-source virtual RAN platform that enables the\nsharing of the same SDR physical resources across multiple slices. Through API\nRemoting, PV-RAN enables running paravirtualized instances of OpenAirInterface\n(OAI) at different slices without requiring modifying OAI source code. PV-RAN\neffectively leverages the inter-domain communication mechanisms of Xen to\ntransport time-sensitive I/Q samples via shared memory, making the\nvirtualization overhead in communication almost negligible. We conduct detailed\nperformance benchmarking of PV-RAN and demonstrate its low overhead and high\nefficiency. We also integrate PV-RAN with the CyNet wireless living lab for\nsmart agriculture and transportation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 01:13:06 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Sander-Frigau", "Matthias", ""], ["Zhang", "Tianyi", ""], ["Zhang", "Hongwei", ""], ["Kamal", "Ahmed E.", ""], ["Somani", "Arun K.", ""]]}, {"id": "2012.12745", "submitter": "Faten Alenizi", "authors": "Faten Alenizi, Omer Rana", "title": "Minimising Delay and Energy in Online Dynamic Fog Systems", "comments": null, "journal-ref": "10th International Conference on Advances in Computing and\n  Information Technology (ACITY 2020)", "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The increasing use of Internet of Things (IoT) devices generates a greater\ndemand for data transfers and puts increased pressure on networks.\nAdditionally, connectivity to cloud services can be costly and inefficient. Fog\ncomputing provides resources in proximity to user devices to overcome these\ndrawbacks. However, optimisation of quality of service (QoS) in IoT\napplications and the management of fog resources are becoming challenging\nproblems. This paper describes a dynamic online offloading scheme in vehicular\ntraffic applications that require execution of delay-sensitive tasks. This\npaper proposes a combination of two algorithms: dynamic task scheduling (DTS)\nand dynamic energy control (DEC) that aim to minimise overall delay, enhance\nthroughput of user tasks and minimise energy consumption at the fog layer while\nmaximising the use of resource-constrained fog nodes. Compared to other\nschemes, our experimental results show that these algorithms can reduce the\ndelay by up to 80.79% and reduce energy consumption by up to 66.39% in fog\nnodes. Additionally, this approach enhances task execution throughput by\n40.88%.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 15:25:12 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Alenizi", "Faten", ""], ["Rana", "Omer", ""]]}, {"id": "2012.12958", "submitter": "Yasmine Saleh", "authors": "Yasmine N. M. Saleh, Claude C. Chibelushi, Ayman A. Abdel-Hamid and\n  Abdel-Hamid Soliman", "title": "Privacy Preservation for Wireless Sensor Networks in Healthcare: State\n  of the Art, and Open Research Challenges", "comments": "42 pages, 15 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of miniature biosensors has generated numerous opportunities for\ndeploying wireless sensor networks in healthcare. However, an important barrier\nis that acceptance by healthcare stakeholders is influenced by the\neffectiveness of privacy safeguards for personal and intimate information which\nis collected and transmitted over the air, within and beyond these networks. In\nparticular, these networks are progressing beyond traditional sensors, towards\nalso using multimedia sensors, which raise further privacy concerns.\nParadoxically, less research has addressed privacy protection, compared to\nsecurity. Nevertheless, privacy protection has gradually evolved from being\nassumed an implicit by-product of security measures, and it is maturing into a\nresearch concern in its own right. However, further technical and\nsocio-technical advances are needed. As a contribution towards galvanising\nfurther research, the hallmarks of this paper include: (i) a literature survey\nexplicitly anchored on privacy preservation, it is underpinned by untangling\nprivacy goals from security goals, to avoid mixing privacy and security\nconcerns, as is often the case in other papers; (ii) a critical survey of\nprivacy preservation services for wireless sensor networks in healthcare,\nincluding threat analysis and assessment methodologies; it also offers\nclassification trees for the multifaceted challenge of privacy protection in\nhealthcare, and for privacy threats, attacks and countermeasures; (iii) a\ndiscussion of technical advances complemented by reflection over the\nimplications of regulatory frameworks; (iv) a discussion of open research\nchallenges, leading onto offers of directions for future research towards\nunlocking the door onto privacy protection which is appropriate for healthcare\nin the twenty-first century.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 20:36:58 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Saleh", "Yasmine N. M.", ""], ["Chibelushi", "Claude C.", ""], ["Abdel-Hamid", "Ayman A.", ""], ["Soliman", "Abdel-Hamid", ""]]}, {"id": "2012.13146", "submitter": "Mohammed Hamzah Abed", "authors": "Muntasir Al-Asfoor, Mohammed Hamzah Abed", "title": "The effect of the toplolgy adaptation on search performance in overlay\n  network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The work presented in this research paper has focused on the effect of\nnetwork to-pology adaptation on search performance in peer to peer overlay\nnetwork. Guided search vs. blind search have been studied with the aim of\nimproving the search re-sults and decreasing the time a search message would\ntake to reach the destination. The network has been formulated as a\nbi-direction graph with vertices represent network nodes and edges represent\nconnections. The level of network subject of this study is on application\nlayer, that means two nodes are connected if they know each other contact\naddresses. A good example of this kind of network is the social network where\nall the lower layers are hidden from the end user. Two different search\nalgorithms have been studied under these circumstances, namely: depth first\nalgorithm and breadth first algorithm. Furthermore, the algorithms performance\nis examined under random topology (scale free network topology) and under\ntopology adaptation. A simulation scenario has been designed to investigate the\nfidelity of the system and study the suggested solutions. Simulation results\nhave shown that the search algorithms are performing better under topology\nadaptation in terms of re-sults quality and search time.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 07:26:38 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Al-Asfoor", "Muntasir", ""], ["Abed", "Mohammed Hamzah", ""]]}, {"id": "2012.13171", "submitter": "Jianwei Zhang", "authors": "Jianwei Zhang", "title": "Q-SR: An Extensible Optimization Framework for Segment Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segment routing (SR) combines the advantages of source routing supported by\ncentralized software-defined networking (SDN) paradigm and hop-by-hop routing\napplied in distributed IP network infrastructure. However, because of the\ncomputation inefficiency, it is nearly impossible to evaluate whether various\ntypes of networks will benefit from the SR with multiple segments using\nconventional approaches. In this paper, we propose a flexible $Q$-SR model as\nwell as its formulation in order to fully explore the potential of SR from an\nalgorithmic perspective. The model leads to a highly extensible framework to\ndesign and evaluate algorithms that can be adapted to various network\ntopologies and traffic matrices. For the offline setting, we develop a fully\npolynomial time approximation scheme (FPTAS) which can finds a\n$(1+\\omega)$-approximation solution for any specified $\\omega>0$ in time that\nis a polynomial function of the network size. To the best of our knowledge, the\nproposed FPTAS is the first algorithm that can compute arbitrarily accurate\nsolution. For the online setting, we develop an online primal-dual algorithm\nthat proves $O(1)$-competitive and violates link capacities by a factor of\n$O(\\log n)$, where $n$ is the node number. We also prove performance bounds for\nthe proposed algorithms. We conduct simulations on realistic topologies to\nvalidate SR parameters and algorithmic parameters in both offline and online\nscenarios.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 08:54:40 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Zhang", "Jianwei", ""]]}, {"id": "2012.13178", "submitter": "Mohammad Mahdi Tajiki", "authors": "Mohammad Mahdi Tajiki, Seyed Hesamedin Ghasemi Petroudi, Stefano\n  Salsano, Steve Uhlig, Ignacio Castro", "title": "Optimal Estimation of Link Delays based on End-to-End Active\n  Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current IP based networks support a wide range of delay-sensitive\napplications such as live video streaming of network gaming. Providing an\nadequate quality of experience to these applications is of paramount importance\nfor a network provider. The offered services are often regulated by tight\nService Level Agreements that needs to be continuously monitored. Since the\nfirst step to guarantee a metric is to measure it, delay measurement becomes a\nfundamental operation for a network provider. In many cases, the operator needs\nto measure the delay on all network links. We refer to the collection of all\nlink delays as the Link Delay Vector (LDV). Typical solutions to collect the\nLDV impose a substantial overhead on the network. In this paper, we propose a\nsolution to measure the LDV in real-time with a low-overhead approach. In\nparticular, we inject some flows into the network and infer the LDV based on\nthe delay of those flows. To this end, the monitoring flows and their paths\nshould be selected minimizing the network monitoring overhead. In this respect,\nthe challenging issue is to select a proper combination of flows such that by\nknowing their delay it is possible to solve a set of a linear equation and\nobtain a unique LDV. We first propose a mathematical formulation to select the\noptimal combination of flows, in form of ILP problem. Then we develop a\nheuristic algorithm to overcome the high computational complexity of existing\nILP solvers. As a further step, we propose a meta-heuristic algorithm to solve\nthe above-mentioned equations and infer the LDV. The challenging part of this\nstep is the volatility of link delays. The proposed solution is evaluated over\nreal-world emulated network topologies using the Mininet network emulator.\nEmulation results show the accuracy of the proposed solution with a negligible\nnetworking overhead in a real-time manner.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 09:49:58 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 09:53:39 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 10:51:38 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Tajiki", "Mohammad Mahdi", ""], ["Petroudi", "Seyed Hesamedin Ghasemi", ""], ["Salsano", "Stefano", ""], ["Uhlig", "Steve", ""], ["Castro", "Ignacio", ""]]}, {"id": "2012.13393", "submitter": "Melih Bastopcu", "authors": "Melih Bastopcu and Sennur Ulukus", "title": "Timely Tracking of Infection Status of Individuals in a Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IT cs.NI eess.SP math.IT physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider real-time timely tracking of infection status (e.g., covid-19) of\nindividuals in a population. In this work, a health care provider wants to\ndetect infected people as well as people who recovered from the disease as\nquickly as possible. In order to measure the timeliness of the tracking\nprocess, we use the long-term average difference between the actual infection\nstatus of the people and their real-time estimate by the health care provider\nbased on the most recent test results. We first find an analytical expression\nfor this average difference for given test rates, and given infection and\nrecovery rates of people. Next, we propose an alternating minimization based\nalgorithm to minimize this average difference. We observe that if the total\ntest rate is limited, instead of testing all members of the population equally,\nonly a portion of the population is tested based on their infection and\nrecovery rates. We also observe that increasing the total test rate helps track\nthe infection status better. In addition, an increased population size\nincreases diversity of people with different infection and recovery rates,\nwhich may be exploited to spend testing capacity more efficiently, thereby\nimproving the system performance. Finally, depending on the health care\nprovider's preferences, test rate allocation can be altered to detect either\nthe infected people or the recovered people more quickly.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 18:49:22 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Bastopcu", "Melih", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2012.13448", "submitter": "Halit Bugra Tulay", "authors": "Halit Bugra Tulay, Can Emre Koksal", "title": "Road Traffic Monitoring using DSRC Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of sensor technologies are nowadays used for traffic\nmonitoring applications. Since most of these technologies rely on wired\ninfrastructure, the installation and maintenance costs limit the deployment of\nthe traffic monitoring systems. In this paper, we introduce a traffic\nmonitoring approach that exploits dedicated short-range communications (DSRC)\nsignals sent in a vehicular network and machine learning techniques. We verify\nthe feasibility of the proposed approach with extensive simulations and\nreal-world experiments at an intersection. We first simulate wireless channels\nunder realistic traffic conditions using a ray-tracing simulator and a traffic\nsimulator. Next, we conduct experiments in a real-world environment and collect\nDSRC messages transmitted from a roadside unit (RSU). The results show that we\nare able to separate different traffic intensities with an accuracy of 96.3\\%\nand 87.6\\% on the simulation and experimental data, respectively. We also\nestimate the number of vehicles on the road with a weighted mean absolute\npercentage error (WMAPE) of 10.7\\% and 19.7\\% on simulation and experimental\ndata, respectively. The proposed approach is suitable to be deployed alongside\nthe current monitoring systems to improve the performance of the systems\nwithout requiring additional investment in infrastructure.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 21:25:51 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Tulay", "Halit Bugra", ""], ["Koksal", "Can Emre", ""]]}, {"id": "2012.13537", "submitter": "Huimei Han", "authors": "Huimei Han, Zan Li, Wenchao Zhai, Jun Zhao, Weidang Lu, Liping Qian", "title": "LSTM-Aided Hybrid Random Access Scheme for 6G MTC Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An LSTM-aided hybrid random access scheme (LSTMH-RA) is proposed to support\ndiverse quality of service (QoS) requirements in 6G machinetype communication\n(MTC) networks, where ultra-reliable low latency communications (URLLC) and\nmassive MTC (mMTC) devices coexist. This scheme allows URLLC devices to access\nthe network via a two-step contentionfree access procedure to satisfy latency\nand reliability access requirements, and mMTC devices to access the network via\na contention-based timing advance (TA)-aided access procedure to meet massive\naccess requirement. Furthermore, to reduce the latency of URLLC devices, we\npropose an attention-based LSTM prediction model to predict the number of\nactive URLLC devices, and thus determining the parameters of the multi-user\ndetection algorithm dynamically. We analyze the successful access probability\nof the LSTMH-RA scheme. Numerical results show that, compared to the benchmark\nschemes, the proposed LSTMH-RA scheme significantly improves the successful\naccess probability, and satisfies the diverse QoS requirements of URLLC and\nmMTC devices.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 07:37:52 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 08:19:34 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Han", "Huimei", ""], ["Li", "Zan", ""], ["Zhai", "Wenchao", ""], ["Zhao", "Jun", ""], ["Lu", "Weidang", ""], ["Qian", "Liping", ""]]}, {"id": "2012.13566", "submitter": "Dibakar Das", "authors": "Dibakar Das, Shiva Kumar Malapaka, Jyotsna Bapat, and Debabrata Das", "title": "A Proactive Connection Setup Mechanism for Large Quantum Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum networks use quantum mechanics properties of entanglement and\nteleportation to transfer data from one node to another. Hence, it is necessary\nto have an efficient mechanism to distribute entanglement among quantum network\nnodes. Most of research on entanglement distribution apply current state of\nnetwork and do not consider using historical data. This paper presents a novel\nway to quicken connection setup between two nodes using historical data and\nproactively distribute entanglement in quantum network. Results show, with\nquantum network size increase, the proposed approach improves success rate of\nconnection establishments.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 11:48:40 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Das", "Dibakar", ""], ["Malapaka", "Shiva Kumar", ""], ["Bapat", "Jyotsna", ""], ["Das", "Debabrata", ""]]}, {"id": "2012.13604", "submitter": "Abdallah Moubayed", "authors": "Abdallah Moubayed, MohammadNoor Injadat, Abdallah Shami, Hanan\n  Lutfiyya", "title": "DNS Typo-squatting Domain Detection: A Data Analytics & Machine Learning\n  Based Approach", "comments": "7 pages, 6 figures, 3 tables, published in 2018 IEEE Global\n  Communications Conference (GLOBECOM)", "journal-ref": "2018 IEEE Global Communications Conference (GLOBECOM), 2018, pp.\n  1-7", "doi": "10.1109/GLOCOM.2018.8647679", "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Name System (DNS) is a crucial component of current IP-based networks\nas it is the standard mechanism for name to IP resolution. However, due to its\nlack of data integrity and origin authentication processes, it is vulnerable to\na variety of attacks. One such attack is Typosquatting. Detecting this attack\nis particularly important as it can be a threat to corporate secrets and can be\nused to steal information or commit fraud. In this paper, a machine\nlearning-based approach is proposed to tackle the typosquatting vulnerability.\nTo that end, exploratory data analytics is first used to better understand the\ntrends observed in eight domain name-based extracted features. Furthermore, a\nmajority voting-based ensemble learning classifier built using five\nclassification algorithms is proposed that can detect suspicious domains with\nhigh accuracy. Moreover, the observed trends are validated by studying the same\nfeatures in an unlabeled dataset using K-means clustering algorithm and through\napplying the developed ensemble learning classifier. Results show that\nlegitimate domains have a smaller domain name length and fewer unique\ncharacters. Moreover, the developed ensemble learning classifier performs\nbetter in terms of accuracy, precision, and F-score. Furthermore, it is shown\nthat similar trends are observed when clustering is used. However, the number\nof domains identified as potentially suspicious is high. Hence, the ensemble\nlearning classifier is applied with results showing that the number of domains\nidentified as potentially suspicious is reduced by almost a factor of five\nwhile still maintaining the same trends in terms of features' statistics.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 16:51:30 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Moubayed", "Abdallah", ""], ["Injadat", "MohammadNoor", ""], ["Shami", "Abdallah", ""], ["Lutfiyya", "Hanan", ""]]}, {"id": "2012.13609", "submitter": "Ke Feng", "authors": "Ke Feng and Martin Haenggi", "title": "Joint Spatial-Propagation Modeling of Cellular Networks Based on the\n  Directional Radii of Poisson Voronoi Cells", "comments": "Accepted for publication in IEEE Transactions on Wireless\n  Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In coverage-oriented networks, base stations (BSs) are deployed in a way such\nthat users at the cell boundaries achieve sufficient signal strength. The shape\nand size of cells vary from BS to BS, since the large-scale signal propagation\nconditions differ in different geographical regions. This work proposes and\nstudies a joint spatial-propagation (JSP) model, which considers the\ncorrelation between cell radii and the large-scale signal propagation (captured\nby shadowing). We first introduce the notion of the directional radius of\nVoronoi cells, which has applications in cellular networks and beyond. The\ndirectional radius of a cell is defined as the distance from the nucleus to the\ncell boundary at an angle relative to the direction of a uniformly random\nlocation in the cell. We study the distribution of the radii in two types of\ncells in the Poisson Voronoi tessellations: the zero-cell, which contains the\norigin, and the typical cell. The results are applied to analyze the JSP model.\nWe show that, even though the Poisson point process (PPP) is often considered\nas a pessimistic spatial model for BS locations, the JSP model with the PPP\nachieves coverage performance close to the most optimistic one -- the standard\ntriangular lattice model. Further, we show that the network performance depends\ncritically on the variance of the large-scale path loss along the cell\nboundary.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 18:17:12 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 02:10:34 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 17:31:54 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Feng", "Ke", ""], ["Haenggi", "Martin", ""]]}, {"id": "2012.13641", "submitter": "Jianwei Zhang", "authors": "Jianwei Zhang", "title": "Extreme Flow Decomposition for Multi-Source Multicast with Intra-Session\n  Network Coding", "comments": "arXiv admin note: text overlap with arXiv:2012.13171", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network coding (NC), when combined with multipath routing, enables a linear\nprogramming (LP) formulation for a multi-source multicast with intra-session\nnetwork coding (MISNC) problem. However, it is still hard to solve using\nconventional methods due to the enormous scale of variables or constraints. In\nthis paper, we try to solve this problem in terms of throughput maximization\nfrom an algorithmic perspective. We propose a novel formulation based on the\nextereme flow decomposition technique, which facilitates the design and\nanalysis of approximation and online algorithms. For the offline scenario, we\ndevelop a fully polynomial time approximation scheme (FPTAS) which can find a\n$(1+\\omega )$-approximation solution for any specified $\\omega>0$. For the\nonline scenario, we develop an online primal-dual algorithm which proves\n$O(1)$-competitive and violates link capacities by a factor of $O(\\log m)$,\nwhere $m$ is the link number. The proposed algorithms share an elegant\nprimal-dual form and thereby have inherent advantages of simplicity,\nefficiency, and scalability. To better understand the advantages of the\nextereme flow decomposition approach, we devise delicate numerical examples on\nan extended butterfly network. We validate the effects of algorithmic\nparameters and make an interesting comparison between the proposed FPTAS and\nonline algorithm. The results show that the online algorithm has satisfactory\nperformance while keeping the overall link utilization acceptable compared with\nthe FPTAS.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 23:02:11 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zhang", "Jianwei", ""]]}, {"id": "2012.13663", "submitter": "Zhiyuan Jiang", "authors": "Zhiyuan Jiang", "title": "Analyzing Age of Information in Multiaccess Networks by Fluid Limits", "comments": "Extended version of a conference paper accepted to INFOCOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we adopt the fluid limits to analyze Age of Information (AoI)\nin a wireless multiaccess network with many users. We consider the case wherein\nusers have heterogeneous i.i.d. channel conditions and the statuses are\ngenerate-at-will. Convergence of the AoI occupancy measure to the fluid limit,\nrepresented by a Partial Derivative Equation (PDE), is proved within an\napproximation error inversely proportional to the number of users. Global\nconvergence to the equilibrium of the PDE, i.e., stationary AoI distribution,\nis also proved. Based on this framework, it is shown that an existing AoI lower\nbound in the literature is in fact asymptotically tight, and a simple threshold\npolicy, with the thresholds explicitly derived, achieves the optimum\nasymptotically. The proposed threshold-based policy is also much easier to\ndecentralize than the widely-known index-based policies which require comparing\nuser indices. To showcase the usability of the framework, we also use it to\nanalyze the average non-linear AoI functions (with power and logarithm forms)\nin wireless networks. Again, explicit optimal threshold-based policies are\nderived, and average age functions proven. Simulation results show that even\nwhen the number of users is limited, e.g., $10$, the proposed policy and\nanalysis are still effective.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 02:38:37 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jiang", "Zhiyuan", ""]]}, {"id": "2012.13698", "submitter": "Chen Avin", "authors": "Chen Avin", "title": "Arithmetic Binary Search Trees: Static Optimality in the Matching Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent developments in optical switching and reconfigurable\nnetwork design, we study dynamic binary search trees (BSTs) in the matching\nmodel. In the classical dynamic BST model, the cost of both link traversal and\nbasic reconfiguration (rotation) is $O(1)$. However, in the matching model, the\nBST is defined by two optical switches (that represent two matchings in an\nabstract way), and each switch (or matching) reconfiguration cost is $\\alpha$\nwhile a link traversal cost is still $O(1)$. In this work, we propose\nArithmetic BST (A-BST), a simple dynamic BST algorithm that is based on dynamic\nShannon-Fano-Elias coding, and show that A-BST is statically optimal for\nsequences of length $\\Omega(n \\alpha \\log \\alpha)$ where $n$ is the number of\nnodes (keys) in the tree.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 08:08:46 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Avin", "Chen", ""]]}, {"id": "2012.13756", "submitter": "Yuncong Hong", "authors": "Yuncong Hong, Bojie Lv, Rui Wang, Haisheng Tan, Zhenhua Han, Hao Zhou,\n  Francis C.M. Lau", "title": "Online Distributed Job Dispatching with Outdated and\n  Partially-Observable Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate online distributed job dispatching in an edge\ncomputing system residing in a Metropolitan Area Network (MAN). Specifically,\njob dispatchers are implemented on access points (APs) which collect jobs from\nmobile users and distribute each job to a server at the edge or the cloud. A\nsignaling mechanism with periodic broadcast is introduced to facilitate\ncooperation among APs. The transmission latency is non-negligible in MAN, which\nleads to outdated information sharing among APs. Moreover, the fully-observed\nsystem state is discouraged as reception of all broadcast is time consuming.\nTherefore, we formulate the distributed optimization of job dispatching\nstrategies among the APs as a Markov decision process with partial and outdated\nsystem state, i.e., partially observable Markov Decision Process (POMDP). The\nconventional solution for POMDP is impractical due to huge time complexity. We\npropose a novel low-complexity solution framework for distributed job\ndispatching, based on which the optimization of job dispatching policy can be\ndecoupled via an alternative policy iteration algorithm, so that the\ndistributed policy iteration of each AP can be made according to partial and\noutdated observation. A theoretical performance lower bound is proved for our\napproximate MDP solution. Furthermore, we conduct extensive simulations based\non the Google Cluster trace. The evaluation results show that our policy can\nachieve as high as $20.67\\%$ reduction in average job response time compared\nwith heuristic baselines, and our algorithm consistently performs well under\nvarious parameter settings.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 15:03:39 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Hong", "Yuncong", ""], ["Lv", "Bojie", ""], ["Wang", "Rui", ""], ["Tan", "Haisheng", ""], ["Han", "Zhenhua", ""], ["Zhou", "Hao", ""], ["Lau", "Francis C. M.", ""]]}, {"id": "2012.14108", "submitter": "Hailiang Zhao", "authors": "Hailiang Zhao, Shuiguang Deng, Zijie Liu, Zhengzhe Xiang, Jianwei Yin,\n  Schahram Dustdar, Albert Y. Zomaya", "title": "DPoS: Decentralized, Privacy-Preserving, and Low-Complexity Online\n  Slicing for Multi-Tenant Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Network slicing is the key to enable virtualized resource sharing among\nvertical industries in the era of 5G communication. Efficient resource\nallocation is of vital importance to realize network slicing in real-world\nbusiness scenarios. To deal with the high algorithm complexity, privacy\nleakage, and unrealistic offline setting of current network slicing algorithms,\nin this paper we propose a fully decentralized and low-complexity online\nalgorithm, DPoS, for multi-resource slicing. We first formulate the problem as\na global social welfare maximization problem. Next, we design the online\nalgorithm DPoS based on the primal-dual approach and posted price mechanism. In\nDPoS, each tenant is incentivized to make its own decision based on its true\npreferences without disclosing any private information to the mobile virtual\nnetwork operator and other tenants. We provide a rigorous theoretical analysis\nto show that DPoS has the optimal competitive ratio when the cost function of\neach resource is linear. Extensive simulation experiments are conducted to\nevaluate the performance of DPoS. The results show that DPoS can not only\nachieve close-to-offline-optimal performance, but also have low algorithmic\noverheads.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 06:21:37 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 12:35:27 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 04:04:37 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Zhao", "Hailiang", ""], ["Deng", "Shuiguang", ""], ["Liu", "Zijie", ""], ["Xiang", "Zhengzhe", ""], ["Yin", "Jianwei", ""], ["Dustdar", "Schahram", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "2012.14111", "submitter": "Adnan Iftekhar", "authors": "Mir Hassan, Chen Jincai, Adnan Iftekhar, Adnan Shehzad, Xiaohui Cui", "title": "Implementation of Security Systems for Detection and Prevention of Data\n  Loss/Leakage at Organization via Traffic Inspection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Loss/Leakage Prevention (DLP) continues to be the main issue for many\nlarge organizations. There are multiple numbers of emerging security attach\nscenarios and a limitless number of overcoming solutions. Today's enterprises'\nmajor concern is to protect confidential information because a leakage that\ncompromises confidential data means that sensitive information is in\ncompetitors' hands. Different data types need to be protected. However, our\nresearch is focused only on data in motion (DIM) i-e data transferred through\nthe network. The research and scenarios in this paper demonstrate a recent\nsurvey on information and data leakage incidents, which reveals its importance\nand also proposed a model solution that will offer the combination of previous\nmethodologies with a new way of pattern matching by advanced content checker\nbased on the use of machine learning to protect data within an organization and\nthen take actions accordingly. This paper also proposed a DLP deployment design\non the gateway level that shows how data is moving through intermediate\nchannels before reaching the final destination using the squid proxy server and\nICAP server.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 06:29:16 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Hassan", "Mir", ""], ["Jincai", "Chen", ""], ["Iftekhar", "Adnan", ""], ["Shehzad", "Adnan", ""], ["Cui", "Xiaohui", ""]]}, {"id": "2012.14112", "submitter": "William Wagner", "authors": "William Wagner", "title": "A Technological Perspective on Net Neutrality", "comments": "9 pages, 3 figures, 1 appendix, Keywords - Net Neutrality, Internet,\n  ISP, Provider, Government Regulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper serves as a brief technical examination of Net Neutrality and the\nInternet fundamentals relevant to the discussion. This document seeks to\nprovide sufficient technical perspective that it may inform the political and\neconomic debate surrounding the issue in the United States. Further, this\nresearch demonstrates that existing Internet economics are based strictly on\nusage, and that this model can account for all uses. Finally, I will argue that\nthere should be some legislation and regulation of ISPs with regard to Net\nNeutrality in the U.S.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 06:29:28 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 07:36:54 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Wagner", "William", ""]]}, {"id": "2012.14219", "submitter": "Antoine Kaufmann", "authors": "Hejing Li, Jialin Li, Keon Jang, Antoine Kaufmann", "title": "Reproducible Host Networking Evaluation with End-to-End Simulation", "comments": "15 pages, 10 figures, under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networking researchers are facing growing challenges in evaluating and\nreproducing results for modern network systems. As systems rely on closer\nintegration of system components and cross-layer optimizations in the pursuit\nof performance and efficiency, they are also increasingly tied to specific\nhardware and testbed properties. Combined with a trend towards heterogeneous\nhardware, such as protocol offloads, SmartNICs, and in-network accelerators,\nresearchers face the choice of either investing more and more time and\nresources into comparisons to prior work or, alternatively, lower the standards\nfor evaluation.\n  We aim to address this challenge by introducing SimBricks, a simulation\nframework that decouples networked systems from the physical testbed and\nenables reproducible end-to-end evaluation in simulation. Instead of\nreinventing the wheel, SimBricks is a modular framework for combining existing\ntried-and-true simulators for individual components, processor and memory, NIC,\nand network, into complete testbeds capable of running unmodified systems. In\nour evaluation, we reproduce key findings from prior work, including dctcp\ncongestion control, NOPaxos in-network consensus acceleration, and the Corundum\nFPGA NIC.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 13:03:04 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Li", "Hejing", ""], ["Li", "Jialin", ""], ["Jang", "Keon", ""], ["Kaufmann", "Antoine", ""]]}, {"id": "2012.14294", "submitter": "Alaa Awad Abdellatif", "authors": "Alaa Awad Abdellatif, Lutfi Samara, Amr Mohamed, Aiman Erbad, Carla\n  Fabiana Chiasserini, Mohsen Guizani, Mark Dennis O'Connor, and James Laughton", "title": "I-Health: Leveraging Edge Computing and Blockchain for Epidemic\n  Management", "comments": "A version of this paper has been submitted in IEEE Internet of Things\n  Journal. arXiv admin note: text overlap with arXiv:2006.10843", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epidemic situations typically demand intensive data collection and management\nfrom different locations/entities within a strict time constraint. Such demand\ncan be fulfilled by leveraging the intensive and easy deployment of the\nInternet of Things (IoT) devices. The management and containment of such\nsituations also rely on cross-organizational and national collaboration. Thus,\nthis paper proposes an Intelligent-Health (I-Health) system that aims to\naggregate diverse e-health entities in a unique national healthcare system by\nenabling swift, secure exchange and storage of medical data. In particular, we\ndesign an automated patients monitoring scheme, at the edge, which enables the\nprompt discovery, remote monitoring, and fast emergency response for critical\nmedical events, such as emerging epidemics. Furthermore, we develop a\nblockchain optimization model that aims to optimize medical data sharing\nbetween different health entities to provide effective and secure health\nservices. Finally, we show the effectiveness of our system, in adapting to\ndifferent critical events, while highlighting the benefits of the proposed\nI-Health system.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 23:41:00 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Abdellatif", "Alaa Awad", ""], ["Samara", "Lutfi", ""], ["Mohamed", "Amr", ""], ["Erbad", "Aiman", ""], ["Chiasserini", "Carla Fabiana", ""], ["Guizani", "Mohsen", ""], ["O'Connor", "Mark Dennis", ""], ["Laughton", "James", ""]]}, {"id": "2012.14337", "submitter": "Igor Kadota", "authors": "Igor Kadota, Muhammad Shahir Rahman, and Eytan Modiano", "title": "WiFresh: Age-of-Information from Theory to Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging applications, such as smart factories and fleets of drones,\nincreasingly rely on sharing time-sensitive information for monitoring and\ncontrol. In such application domains, it is essential to keep information\nfresh, as outdated information loses its value and can lead to system failures\nand safety risks. The Age-of-Information is a performance metric that captures\nhow fresh the information is from the perspective of the destination.\n  In this paper, we show that as the congestion in the wireless network\nincreases, the Age-of-Information degrades sharply, leading to outdated\ninformation at the destination. Leveraging years of theoretical research, we\npropose WiFresh: an unconventional architecture that achieves near optimal\ninformation freshness in wireless networks of any size, even when the network\nis overloaded. Our experimental results show that WiFresh can improve\ninformation freshness by two orders of magnitude when compared to an equivalent\nstandard WiFi network. We propose and realize two strategies for implementing\nWiFresh: one at the MAC layer using hardware-level programming and another at\nthe Application layer using Python.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 16:25:44 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Kadota", "Igor", ""], ["Rahman", "Muhammad Shahir", ""], ["Modiano", "Eytan", ""]]}, {"id": "2012.14350", "submitter": "Michele Polese", "authors": "Michele Polese, Francesco Restuccia, Tommaso Melodia", "title": "DeepBeam: Deep Waveform Learning for Coordination-Free Beam Management\n  in mmWave Networks", "comments": "10 pages, 15 figures. Please cite it as M. Polese, F. Restuccia, and\n  T. Melodia, \"DeepBeam: Deep Waveform Learning for Coordination-Free Beam\n  Management in mmWave Networks\", Proc. of ACM Intl. Symp. on Theory,\n  Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile\n  Computing (ACM MobiHoc), October 2021", "journal-ref": null, "doi": "10.1145/3466772.3467035", "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly directional millimeter wave (mmWave) radios need to perform beam\nmanagement to establish and maintain reliable links. To do so, existing\nsolutions mostly rely on explicit coordination between the transmitter (TX) and\nthe receiver (RX), which significantly reduces the airtime available for\ncommunication and further complicates the network protocol design. This paper\nadvances the state of the art by presenting DeepBeam, a framework for beam\nmanagement that does not require pilot sequences from the TX, nor any beam\nsweeping or synchronization from the RX. This is achieved by inferring (i) the\nAngle of Arrival (AoA) of the beam and (ii) the actual beam being used by the\ntransmitter through waveform-level deep learning on ongoing transmissions\nbetween the TX to other receivers. In this way, the RX can associate\nSignal-to-Noise-Ratio (SNR) levels to beams without explicit coordination with\nthe TX. This is possible because different beam patterns introduce different\nimpairments to the waveform, which can be subsequently learned by a\nconvolutional neural network (CNN). We conduct an extensive experimental data\ncollection campaign where we collect more than 4 TB of mmWave waveforms with\n(i) 4 phased array antennas at 60.48 GHz, (ii) 2 codebooks containing 24\none-dimensional beams and 12 two-dimensional beams; (iii) 3 receiver gains;\n(iv) 3 different AoAs; (v) multiple TX and RX locations. Moreover, we collect\nwaveform data with two custom-designed mmWave software-defined radios with\nfully-digital beamforming architectures at 58 GHz. Results show that DeepBeam\n(i) achieves accuracy of up to 96%, 84% and 77% with a 5-beam, 12-beam and\n24-beam codebook, respectively; (ii) reduces latency by up to 7x with respect\nto the 5G NR initial beam sweep in a default configuration and with a 12-beam\ncodebook. The waveform dataset and the full DeepBeam code repository are\npublicly available.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 16:40:07 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 19:41:45 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Polese", "Michele", ""], ["Restuccia", "Francesco", ""], ["Melodia", "Tommaso", ""]]}, {"id": "2012.14396", "submitter": "Bernardo Huberman", "authors": "Jing Wang and Bernardo Huberman", "title": "A Guide to Global Quantum Key Distribution Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe systems and methods for the deployment of global quantum key\ndistribution (QKD) networks covering transoceanic, long-haul, metro, and access\nsegments of the network. A comparative study of the state-of-the-art QKD\ntechnologies is carried out, including both terrestrial QKD via optical fibers\nand free-space optics, as well as spaceborne solutions via satellites. We\ncompare the pros and cons of various existing QKD technologies, including\nchannel loss, potential interference, distance, connection topology, deployment\ncost and requirements, as well as application scenarios. Technical selection\ncriteria and deployment requirements are developed for various different QKD\nsolutions in each segment of networks. For example, optical fiber-based QKD is\nsuitable for access networks due to its limited distance and compatibility with\npoint-to-multipoint (P2MP) topology; with the help of trusted relays, it can be\nextended to long-haul and metro networks. Spaceborne QKD on the other hand, has\nmuch smaller channel loss and extended transmission distance, which can be used\nfor transoceanic and long-haul networks exploiting satellite-based trusted\nrelays.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 18:21:10 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 04:01:15 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Wang", "Jing", ""], ["Huberman", "Bernardo", ""]]}, {"id": "2012.14454", "submitter": "Elias Vathias", "authors": "Elias Vathias, Stathes Hadjiefthymiades", "title": "A Stock Options Metaphor for Content Delivery Networks", "comments": "35 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The concept of Stock Options is used to address the scarcity of resources,\nnot adequately addressed by the previous tools of our Prediction Mechanism.\nUsing a Predictive Reservation Scheme, network and disk resources are being\nmonitored through well-established techniques (Kernel Regression Estimators) in\na given time frame. Next, an Secondary Market mechanism significantly improves\nthe efficiency and robustness of our Predictive Reservation Scheme by allowing\nthe fast exchange of unused (remaining) resources between the Origin Servers\n(CDN Clients). This exchange can happen, either by implementing socially\noptimal practices or by allowing automatic electronic auctions at the end of\nthe day or at shorter time intervals. Finally, we further enhance our\nPrediction Mechanism; Stock Options are obtained and exercised, depending on\nthe lack of resources at the end of day. As a result, Origin Servers may\nacquire resources (if required) at a normal price. The effectiveness of our\nmechanism further improves.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 19:23:26 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Vathias", "Elias", ""], ["Hadjiefthymiades", "Stathes", ""]]}, {"id": "2012.14635", "submitter": "Behnam Dezfouli", "authors": "Chia-Chi Li, Vikram K. Ramanna, Daniel Webber, Cole Hunter, Tyler\n  Hack, and Behnam Dezfouli", "title": "Sensifi: A Wireless Sensing System for Ultra-High-Rate Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": "SIOTLAB-2020-12-DEC", "categories": "cs.NI cs.OS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wireless Sensor Networks (WSNs) are being used in various applications such\nas structural health monitoring and industrial control. Since energy efficiency\nis one of the major design factors, the existing WSNs primarily rely on\nlow-power, low-rate wireless technologies such as 802.15.4 and Bluetooth. In\nthis paper, we strive to tackle the challenges of developing ultra-high-rate\nWSNs based on 802.11 (WiFi) standard by proposing Sensifi. As an illustrative\napplication of this system, we consider vibration test monitoring of spacecraft\nand identify system design requirements and challenges. Our main contributions\nare as follows. First, we propose packet encoding methods to reduce the\noverhead of assigning accurate timestamps to samples. Second, we propose energy\nefficiency methods to enhance the system's lifetime. Third, we reduce the\noverhead of processing outgoing packets through network stack to enhance\nsampling rate and mitigate sampling rate instability. Fourth, we study and\nreduce the delay of processing incoming packets through network stack to\nenhance the accuracy of time synchronization among nodes. Fifth, we propose a\nlow-power node design for ultra-high-rate applications. Sixth, we use our node\ndesign to empirically evaluate the system.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 07:17:38 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 00:16:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Li", "Chia-Chi", ""], ["Ramanna", "Vikram K.", ""], ["Webber", "Daniel", ""], ["Hunter", "Cole", ""], ["Hack", "Tyler", ""], ["Dezfouli", "Behnam", ""]]}, {"id": "2012.14687", "submitter": "Sidharth Sharma", "authors": "Aniruddha Kushwaha, Sidharth Sharma and Ashwin Gumaste", "title": "A Survey on Segment Routing with Emphasis on Use Cases in Large Provider\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segment routing is heralded as important technology innovation in large\nprovider networks. In the domain of large telecom service providers, segment\nrouting has the potential to be in the same league as MPLS and IPv6 as well as\npave a way towards the successful implementation of SDNs. In this regard, this\npaper is a survey on the existing segment routing work in the community. We\nbegin by describing how segment routing works, inclusive of the various\nbuilding blocks. The paper describes the segment routing architecture in terms\nof its positioning vis-a-vis existing networking technologies, as well as the\ndata-plane and the control plane. Label encoding techniques that are central\ntowards implementing segment routing are then discussed. In order to make\nsegment routing relevant to the current domain of providers, we postulate\nvarious use cases, their working and issues of interoperability. The paper also\nreviews the current set of segment routing implementation cases in the\nindustry. Thereafter we position segment routing among the various provider\nmanifestations.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 09:57:16 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kushwaha", "Aniruddha", ""], ["Sharma", "Sidharth", ""], ["Gumaste", "Ashwin", ""]]}, {"id": "2012.14695", "submitter": "Yuan Zheng", "authors": "Yuan Zheng, Suzhi Bi, Ying-Jun Angela Zhang, Xiaohui Lin, and Hui Wang", "title": "Joint Beamforming and Power Control for Throughput Maximization in\n  IRS-assisted MISO WPCNs", "comments": "The paper has been accepted by the IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligent reflecting surface (IRS) is an emerging technology to enhance the\nenergy- and spectrum-efficiency of wireless powered communication networks\n(WPCNs). In this paper, we investigate an IRS-assisted multiuser multiple-input\nsingle-output (MISO) WPCN, where the single-antenna wireless devices (WDs)\nharvest wireless energy in the downlink (DL) and transmit their information\nsimultaneously in the uplink (UL) to a common hybrid access point (HAP)\nequipped with multiple antennas. Our goal is to maximize the weighted sum rate\n(WSR) of all the energy-harvesting users. To make full use of the beamforming\ngain provided by both the HAP and the IRS, we jointly optimize the active\nbeamforming of the HAP and the reflecting coefficients (passive beamforming) of\nthe IRS in both DL and UL transmissions, as well as the transmit power of the\nWDs to mitigate the inter-user interference at the HAP. To tackle the\nchallenging optimization problem, we first consider fixing the passive\nbeamforming, and converting the remaining joint active beamforming and user\ntransmit power control problem into an equivalent weighted minimum mean square\nerror (WMMSE) problem, where we solve it using an efficient block-coordinate\ndescent (BCD) method. Then, we fix the active beamforming and user transmit\npower, and optimize the passive beamforming coefficients of the IRS in both the\nDL and UL using a semidefinite relaxation (SDR) method. Accordingly, we apply a\nblock-structured optimization (BSO) method to update the two sets of variables\nalternately. Numerical results show that the proposed joint optimization\nachieves significant performance gain over other representative benchmark\nmethods and effectively improves the throughput performance in multiuser MISO\nWPCNs.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 10:21:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zheng", "Yuan", ""], ["Bi", "Suzhi", ""], ["Zhang", "Ying-Jun Angela", ""], ["Lin", "Xiaohui", ""], ["Wang", "Hui", ""]]}, {"id": "2012.14716", "submitter": "Qianqian Pan", "authors": "Qianqian Pan, Jun Wu, Xi Zheng, Jianhua Li, Shenghong Li, Athanasios\n  V. Vasilakos", "title": "Leveraging AI and Intelligent Reflecting Surface for Energy-Efficient\n  Communication in 6G IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing data traffic, various delay-sensitive services, and the\nmassive deployment of energy-limited Internet of Things (IoT) devices have\nbrought huge challenges to the current communication networks, motivating\nacademia and industry to move to the sixth-generation (6G) network. With the\npowerful capability of data transmission and processing, 6G is considered as an\nenabler for IoT communication with low latency and energy cost. In this paper,\nwe propose an artificial intelligence (AI) and intelligent reflecting surface\n(IRS) empowered energy-efficiency communication system for 6G IoT. First, we\ndesign a smart and efficient communication architecture including the IRS-aided\ndata transmission and the AI-driven network resource management mechanisms.\nSecond, an energy efficiency-maximizing model under given transmission latency\nfor 6G IoT system is formulated, which jointly optimizes the settings of all\ncommunication participants, i.e. IoT transmission power, IRS-reflection phase\nshift, and BS detection matrix. Third, a deep reinforcement learning (DRL)\nempowered network resource control and allocation scheme is proposed to solve\nthe formulated optimization model. Based on the network and channel status, the\nDRL-enabled scheme facilities the energy-efficiency and low-latency\ncommunication. Finally, experimental results verified the effectiveness of our\nproposed communication system for 6G IoT.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 11:56:28 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pan", "Qianqian", ""], ["Wu", "Jun", ""], ["Zheng", "Xi", ""], ["Li", "Jianhua", ""], ["Li", "Shenghong", ""], ["Vasilakos", "Athanasios V.", ""]]}, {"id": "2012.14850", "submitter": "Celso Carvalho", "authors": "David Alan de Oliveira Ferreira, Celso Barbosa Carvalho, Edjair de\n  Souza Mota", "title": "Localizacao em ambientes internos utilizando redes Wi-Fi", "comments": "in Portuguese. Simposio Brasileiro de telecomunicacoes e\n  processamento de sinais, SBrT 2019. p. 1-5, Petropolis, RJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a localization method for indoor environments capable of\nimproving the location accuracy that is hampered by instability in RSSI of the\nIEEE 802.11 networks. The method employs the k-Nearest Neighbors (kNN)\nalgorithm and quartiles analysis in the data representation. The proposal had\nnull error with only four APs and 10 readings per sample of each AP with just\n0.69 second to locate. These values are important contributions, confirming\nthat the method is promising to locate objects in indoor environments.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 16:57:02 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ferreira", "David Alan de Oliveira", ""], ["Carvalho", "Celso Barbosa", ""], ["Mota", "Edjair de Souza", ""]]}, {"id": "2012.14922", "submitter": "Aly El Gamal", "authors": "Tolunay Seyfi, Ahmed P. Mohamed, Aly El Gamal", "title": "A Number Theoretic Approach for Fast Discovery of Single-Hop Wireless\n  Networks", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interference management has become a key factor in regulating transmissions\nin wireless communication networks. To support effective interference\nmanagement schemes, it can be essential to have prior knowledge about the\nnetwork topology. In this paper, we build on existing results in the literature\non the simulation of the message passing model, and present an efficient\nstrategy for fast discovery of the network topology during a pilot\ncommunication phase. More precisely, we investigate the minimum number of\ncommunication rounds that is needed to discover an arbitrary network topology\nwith a maximum number of links per receiver, while assuming a single-hop\nnetwork that is restricted to interference-avoidance based schemes in its pilot\nphase. We first ignore any interference cancellation strategy such that no\nreceiver can recognize, and cancel transmissions of, previously discovered\ntransmitters, and then capture the gains obtained through interference\ncancellation during the pilot phase. Our results evince how the required number\nof rounds scale in an approximately logarithmic fashion with practical values\nof the total number of users in the network, having a slope proportional to the\nnumber of interfering transmitters per receiver.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 19:39:26 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Seyfi", "Tolunay", ""], ["Mohamed", "Ahmed P.", ""], ["Gamal", "Aly El", ""]]}, {"id": "2012.14968", "submitter": "Themis Melissaris", "authors": "Themis Melissaris, Kelly Shaw, Margaret Martonosi", "title": "Optimizing IoT and Web Traffic Using Selective Edge Compression", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet of Things (IoT) devices and applications are generating and\ncommunicating vast quantities of data, and the rate of data collection is\nincreasing rapidly. These high communication volumes are challenging for\nenergy-constrained, data-capped, wireless mobile devices and networked sensors.\nCompression is commonly used to reduce web traffic, to save energy, and to make\nnetwork transfers faster. If not used judiciously, however, compression can\nhurt performance. This work proposes and evaluates mechanisms that employ\nselective compression at the network's edge, based on data characteristics and\nnetwork conditions. This approach (i) improves the performance of network\ntransfers in IoT environments, while (ii) providing significant data savings.\nWe demonstrate that our library speeds up web transfers by an average of 2.18x\nand 2.03x under fixed and dynamically changing network conditions respectively.\nFurthermore, it also provides consistent data savings, compacting data down to\n19% of the original data size.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 22:59:56 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Melissaris", "Themis", ""], ["Shaw", "Kelly", ""], ["Martonosi", "Margaret", ""]]}, {"id": "2012.14996", "submitter": "Taran Lynn", "authors": "Taran Lynn, Dipak Ghosal", "title": "TCP D*: A Low Latency First Congestion Control Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The choice of feedback mechanism between delay and packet loss has long been\na point of contention in TCP congestion control. This has partly been resolved,\nas it has become increasingly evident that delay based methods are needed to\nfacilitate modern interactive web applications. However, what has not been\nresolved is what control should be used, with the two candidates being the\ncongestion window and the pacing rate. BBR is a new delay based congestion\ncontrol algorithm that uses a pacing rate as its primary control and the\ncongestion window as a secondary control. We propose that a congestion window\nfirst algorithm might give more desirable performance characteristics in\nsituations where latency must be minimized even at the expense of some loss in\nthroughput. To evaluate this hypothesis we introduce a new congestion control\nalgorithm called TCP D*, which is a congestion window first algorithm that\nadopts BBR's approach of maximizing delivery rate while minimizing latency. In\nthis paper, we discuss the key features of this algorithm, discuss the\ndifferences and similarity to BBR, and present some preliminary results based\non a real implementation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 01:26:54 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lynn", "Taran", ""], ["Ghosal", "Dipak", ""]]}, {"id": "2012.15081", "submitter": "Mingqi Yuan", "authors": "Mingqi Yuan, Qi Cao, Man-on Pun, Yi Chen", "title": "Fairness-Oriented User Scheduling for Bursty Downlink Transmission Using\n  Multi-Agent Reinforcement Learning", "comments": "14 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.AI cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we develop practical user scheduling algorithms for downlink\nbursty traffic with emphasis on user fairness. In contrast to the conventional\nscheduling algorithms that either equally divides the transmission time slots\namong users or maximizing some ratios without physcial meanings, we propose to\nuse the 5%-tile user data rate (5TUDR) as the metric to evaluate user fairness.\nSince it is difficult to directly optimize 5TUDR, we first cast the problem\ninto the stochastic game framework and subsequently propose a Multi-Agent\nReinforcement Learning (MARL)-based algorithm to perform distributed\noptimization on the resource block group (RBG) allocation. Furthermore, each\nMARL agent is designed to take information measured by network counters from\nmultiple network layers (e.g. Channel Quality Indicator, Buffer size) as the\ninput states while the RBG allocation as action with a proposed reward function\ndesigned to maximize 5TUDR. Extensive simulation is performed to show that the\nproposed MARL-based scheduler can achieve fair scheduling while maintaining\ngood average network throughput as compared to conventional schedulers.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 08:41:51 GMT"}, {"version": "v10", "created": "Fri, 30 Apr 2021 08:09:39 GMT"}, {"version": "v11", "created": "Tue, 11 May 2021 13:51:29 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 02:55:02 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 03:14:17 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 16:00:14 GMT"}, {"version": "v5", "created": "Mon, 15 Feb 2021 16:53:45 GMT"}, {"version": "v6", "created": "Tue, 16 Feb 2021 06:06:10 GMT"}, {"version": "v7", "created": "Thu, 18 Feb 2021 02:30:27 GMT"}, {"version": "v8", "created": "Sun, 7 Mar 2021 12:20:34 GMT"}, {"version": "v9", "created": "Mon, 19 Apr 2021 07:08:08 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Yuan", "Mingqi", ""], ["Cao", "Qi", ""], ["Pun", "Man-on", ""], ["Chen", "Yi", ""]]}, {"id": "2012.15295", "submitter": "Yuankun Fu", "authors": "Yuankun Fu, Fengguang Song", "title": "SDN helps Big Data to optimize access to data", "comments": null, "journal-ref": "Big Data and Software Defined Networks, March, 2018", "doi": "10.1049/PBPC015E_ch14", "report-no": null, "categories": "cs.DC cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter introduces the state-of-the-art in the emerging area of\ncombining High Performance Computing (HPC) with Big Data Analysis. To\nunderstand the new area, the chapter first surveys the existing approaches to\nintegrating HPC with Big Data. Next, the chapter introduces several\noptimization solutions that focus on how to minimize the data transfer time\nfrom computation-intensive applications to analysis-intensive applications as\nwell as minimizing the end-to-end time-to-solution. The solutions utilize SDN\nto adaptively use both high speed interconnect network and high performance\nparallel file systems to optimize the application performance. A computational\nframework called DataBroker is designed and developed to enable a tight\nintegration of HPC with data analysis. Multiple types of experiments have been\nconducted to show different performance issues in both message passing and\nparallel file systems and to verify the effectiveness of the proposed research\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 19:33:13 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Fu", "Yuankun", ""], ["Song", "Fengguang", ""]]}, {"id": "2012.15405", "submitter": "Yong Xiao", "authors": "Guangming Shi, Yong Xiao, Yingyu Li, Xuemei Xie", "title": "From Semantic Communication to Semantic-aware Networking: Model,\n  Architecture, and Open Problems", "comments": "Accepted at the IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.SI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing communication systems are mainly built based on Shannon's\ninformation theory which deliberately ignores the semantic aspects of\ncommunication. The recent iteration of wireless technology, the so-called 5G\nand beyond, promises to support a plethora of services enabled by carefully\ntailored network capabilities based on the contents, requirements, as well as\nsemantics. This sparkled significant interest in the semantic communication, a\nnovel paradigm that involves the meaning of message into the communication. In\nthis article, we first review the classic semantic communication framework and\nthen summarize key challenges that hinder its popularity. We observe that some\nsemantic communication processes such as semantic detection, knowledge\nmodeling, and coordination, can be resource-consuming and inefficient,\nespecially for the communication between a single source and a destination. We\ntherefore propose a novel architecture based on federated edge intelligence for\nsupporting resource-efficient semantic-aware networking. Our architecture\nallows each user to offload the computationally intensive semantic encoding and\ndecoding tasks to the edge servers and protect its proprietary model-related\ninformation by coordinating via intermediate results. Our simulation result\nshows that the proposed architecture can reduce the resource consumption and\nsignificantly improve the communication efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 02:38:49 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 00:53:21 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Shi", "Guangming", ""], ["Xiao", "Yong", ""], ["Li", "Yingyu", ""], ["Xie", "Xuemei", ""]]}, {"id": "2012.15412", "submitter": "Agrim Gupta", "authors": "Agrim Gupta, Cedric Girerd, Manideep Dunna, Qiming Zhang, Raghav\n  Subbaraman, Tania Morimoto, Dinesh Bharadia", "title": "WiForce: Wireless Sensing and Localization of Contact Forces on a Space\n  Continuum", "comments": "18 Pages, 19 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Contact force is a natural way for humans to interact with the physical world\naround us. However, most of our interactions with the digital world are largely\nbased on a simple binary sense of touch (contact or no contact). Similarly,\nwhen interacting with robots to perform complex tasks, such as surgery, richer\nforce information that includes both magnitude and contact location is\nimportant for task performance. To address these challenges, we present the\ndesign and fabrication of WiForce which is a 'wireless' sensor, sentient to\ncontact force magnitude and location. WiForce achieves this by transducing\nforce magnitude and location, to phase changes of an incident RF signal of a\nbackscattering tag. The phase changes are thus modulated into the backscattered\nRF signal, which enables measurement of force magnitude and contact location by\ninferring the phases of the reflected RF signal. WiForce's sensor is designed\nto support wide-band frequencies all the way up to 3 GHz. We evaluate the force\nsensing wirelessly in different environments, including through phantom tissue,\nand achieve force accuracy of 0.3 N and contact location accuracy of 0.6 mm.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 02:51:01 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 02:22:03 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Gupta", "Agrim", ""], ["Girerd", "Cedric", ""], ["Dunna", "Manideep", ""], ["Zhang", "Qiming", ""], ["Subbaraman", "Raghav", ""], ["Morimoto", "Tania", ""], ["Bharadia", "Dinesh", ""]]}, {"id": "2012.15545", "submitter": "Md Ferdous Pervej", "authors": "Md Ferdous Pervej and Shih-Chun Lin", "title": "Vehicular Network Slicing for Reliable Access and Deadline-Constrained\n  Data Offloading: A Multi-Agent On-Device Learning Approach", "comments": "Submitted for possible journal publication, 15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.MA cs.SY eess.SP eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient data offloading plays a pivotal role in computational-intensive\nplatforms as data rate over wireless channels is fundamentally limited. On top\nof that, high mobility adds an extra burden in vehicular edge networks (VENs),\nbolstering the desire for efficient user-centric solutions. Therefore, unlike\nthe legacy inflexible network-centric approach, this paper exploits a\nsoftware-defined flexible, open, and programmable networking platform for an\nefficient user-centric, fast, reliable, and deadline-constrained offloading\nsolution in VENs. In the proposed model, each active vehicle user (VU) is\nserved from multiple low-powered access points (APs) by creating a noble\nvirtual cell (VC). A joint node association, power allocation, and distributed\nresource allocation problem is formulated. As centralized learning is not\npractical in many real-world problems, following the distributed nature of\nautonomous VUs, each VU is considered an edge learning agent. To that end,\nconsidering practical location-aware node associations, a joint radio and power\nresource allocation non-cooperative stochastic game is formulated. Leveraging\nreinforcement learning's (RL) efficacy, a multi-agent RL (MARL) solution is\nproposed where the edge learners aim to learn the Nash equilibrium (NE)\nstrategies to solve the game efficiently. Besides, real-world map data, with a\npractical microscopic mobility model, are used for the simulation. Results\nsuggest that the proposed user-centric approach can deliver remarkable\nperformances in VENs. Moreover, the proposed MARL solution delivers\nnear-optimal performances with approximately 3% collision probabilities in case\nof distributed random access in the uplink.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 11:15:10 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pervej", "Md Ferdous", ""], ["Lin", "Shih-Chun", ""]]}, {"id": "2012.15548", "submitter": "Nikolaos Pappas", "authors": "George Stamatakis, Nikolaos Pappas, Alexandros Fragkiadakis, Apostolos\n  Traganitis", "title": "Autonomous Maintenance in IoT Networks via AoI-driven Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) with its growing number of deployed devices and\napplications raises significant challenges for network maintenance procedures.\nIn this work, we formulate a problem of autonomous maintenance in IoT networks\nas a Partially Observable Markov Decision Process. Subsequently, we utilize\nDeep Reinforcement Learning algorithms (DRL) to train agents that decide if a\nmaintenance procedure is in order or not and, in the former case, the proper\ntype of maintenance needed. To avoid wasting the scarce resources of IoT\nnetworks we utilize the Age of Information (AoI) metric as a reward signal for\nthe training of the smart agents. AoI captures the freshness of the sensory\ndata which are transmitted by the IoT sensors as part of their normal service\nprovision. Numerical results indicate that AoI integrates enough information\nabout the past and present states of the system to be successfully used in the\ntraining of smart agents for the autonomous maintenance of the network.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 11:19:51 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Stamatakis", "George", ""], ["Pappas", "Nikolaos", ""], ["Fragkiadakis", "Alexandros", ""], ["Traganitis", "Apostolos", ""]]}, {"id": "2012.15700", "submitter": "Victoria Manfredi", "authors": "Victoria Manfredi, Alicia Wolfe, Bing Wang, Xiaolan Zhang", "title": "Relational Deep Reinforcement Learning for Routing in Wireless Networks", "comments": "11 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While routing in wireless networks has been studied extensively, existing\nprotocols are typically designed for a specific set of network conditions and\nso cannot accommodate any drastic changes in those conditions. For instance,\nprotocols designed for connected networks cannot be easily applied to\ndisconnected networks. In this paper, we develop a distributed routing strategy\nbased on deep reinforcement learning that generalizes to diverse traffic\npatterns, congestion levels, network connectivity, and link dynamics. We make\nthe following key innovations in our design: (i) the use of relational features\nas inputs to the deep neural network approximating the decision space, which\nenables our algorithm to generalize to diverse network conditions, (ii) the use\nof packet-centric decisions to transform the routing problem into an episodic\ntask by viewing packets, rather than wireless devices, as reinforcement\nlearning agents, which provides a natural way to propagate and model rewards\naccurately during learning, and (iii) the use of extended-time actions to model\nthe time spent by a packet waiting in a queue, which reduces the amount of\ntraining data needed and allows the learning algorithm to converge more\nquickly. We evaluate our routing algorithm using a packet-level simulator and\nshow that the policy our algorithm learns during training is able to generalize\nto larger and more congested networks, different topologies, and diverse link\ndynamics. Our algorithm outperforms shortest path and backpressure routing with\nrespect to packets delivered and delay per packet.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 16:28:21 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Manfredi", "Victoria", ""], ["Wolfe", "Alicia", ""], ["Wang", "Bing", ""], ["Zhang", "Xiaolan", ""]]}, {"id": "2012.15831", "submitter": "Baturalp Buyukates", "authors": "Baturalp Buyukates and Sennur Ulukus", "title": "Timely Communication in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a federated learning framework in which a parameter server (PS)\ntrains a global model by using $n$ clients without actually storing the client\ndata centrally at a cloud server. Focusing on a setting where the client\ndatasets are fast changing and highly temporal in nature, we investigate the\ntimeliness of model updates and propose a novel timely communication scheme.\nUnder the proposed scheme, at each iteration, the PS waits for $m$ available\nclients and sends them the current model. Then, the PS uses the local updates\nof the earliest $k$ out of $m$ clients to update the global model at each\niteration. We find the average age of information experienced by each client\nand numerically characterize the age-optimal $m$ and $k$ values for a given\n$n$. Our results indicate that, in addition to ensuring timeliness, the\nproposed communication scheme results in significantly smaller average\niteration times compared to random client selection without hurting the\nconvergence of the global learning task.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:52:08 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 16:59:25 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Buyukates", "Baturalp", ""], ["Ulukus", "Sennur", ""]]}]