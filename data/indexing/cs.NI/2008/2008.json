[{"id": "2008.00021", "submitter": "Batuhan Mekiker", "authors": "Batuhan Mekiker, Mike Wittie, Jefferson Jones and Michael Monaghan", "title": "Beartooth Relay Protocol: Supporting Real-Time Application Streams over\n  LoRa", "comments": "12 pages, submitted to AdHoc-Now 2020, for associated video, see\n  https://youtu.be/S8Jhx5T9rB4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The near-ubiquitous availability of wireless connectivity lets users take\nadvantage of a large variety of mobile applications. This connectivity\npredominantly comes as cellular and WiFi, limiting users to available\ninfrastructure. At the same time, commercial efforts for infrastructure-less\nconnectivity do not support mobile application traffic. In this paper, we\npresent a new LoRa radio and a relay protocol capable of supporting real-time\napplication traffic on point-to-point and multihop connection. Our solution has\nthe potential to extend mobile application functionality beyond infrastructure\ncoverage areas.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:13:09 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Mekiker", "Batuhan", ""], ["Wittie", "Mike", ""], ["Jones", "Jefferson", ""], ["Monaghan", "Michael", ""]]}, {"id": "2008.00083", "submitter": "Dongning Ma", "authors": "Dongning Ma", "title": "MiabNET: Message-in-a-bottle Protocol for MANET", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short paper, we propose MiabNET, a reactive protocol for Mobile\nAd-hoc Networks (MANET). This protocol leverages the concept of\n\"message-in-a-bottle\" to spread the routing information though the entire\nnetwork. The idea of the protocol is briefly described as below: if a node\nwould like to find a route to a destination node not in the routing table, it\nwill initialize a bottle and send this bottle to \\textbf{a random one} of its\nneighbors. If this neighbor does not have the route to the destination, it will\nsend the bottle to one of its random neighbors as well, until the bottle\nreaches the destination node.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 20:46:25 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Ma", "Dongning", ""]]}, {"id": "2008.00084", "submitter": "Junsung Choi", "authors": "Junsung Choi, Vuk Marojevic, Carl B. Dietrich, Jeffrey H. Reed, and\n  Seungyoung Ahn", "title": "Survey of Spectrum Regulation for Intelligent Transportation Systems", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3012788", "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As 5G communication technology develops, vehicular communications that\nrequire high reliability, low latency, and massive connectivity are drawing\nincreasing interest from those in academia and industry. Due to these\ndeveloping technologies, vehicular communication is not limited to vehicle\ncomponents in the forms of Vehicle-to-Vehicle (V2V) or\nVehicle-to-Infrastructure (V2I) networks, but has also been extended to connect\nwith others, such as pedestrians and cellular users. Dedicated Short-Range\nCommunications (DSRC) is the conventional vehicular communication standard for\nIntelligent Transportation Systems (ITS). More recently, the 3rd Generation\nPartnership Project introduced Cellular-Vehicle-to-Everything (C-V2X), a\ncompetitor to DSRC. Meanwhile, the Federal Communications Commission\n(FCC)issued a Notice of Proposed Rulemaking (NPRM) to consider deploying\nUnlicensed National Information Infrastructure (U-NII)devices in the ITS band\nwith two interference mitigation approaches: Detect-and-Vacate (DAV)and\nRe-channelization (Re-CH). With multiple standard options and interference\nmitigation approaches, numerous regulatory taxonomies can be identified and\nnotification of relevant technical challenges issued. However, these challenges\nare much broader than the current and future regulatory taxonomies pursued by\nthe different countries involved. Because their plans differ, the technical and\nregulatory challenges vary. This paper presents a literature survey about the\ntechnical challenges, the current and future ITS band usage plans, and the\nmajor research testbeds for the U.S., Europe, China, Korea, and Japan. This\nsurvey shows that the most likely deployment taxonomies are (1) DSRC, C-V2X,\nand Wi-Fi with Re-CH; (2) DSRC and C-V2X with interoperation, and (3) C-V2X\nonly. The most difficult technical challenge is the interoperability between\nthe Wi-Fi-like DSRC and 4G LTE-like C-V2X.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 13:00:58 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 00:56:26 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Choi", "Junsung", ""], ["Marojevic", "Vuk", ""], ["Dietrich", "Carl B.", ""], ["Reed", "Jeffrey H.", ""], ["Ahn", "Seungyoung", ""]]}, {"id": "2008.00085", "submitter": "Mehdi Imani", "authors": "Reza Amini, Mehdi Imani, Petio Ivanov Todorov, Maaruf Ali", "title": "Performance Evaluation of Orchestra Scheduling in Time Slotted Channel\n  Hopping Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we evaluate the performance of networks that use RPL (Routing\nProtocols for Low Power and Lossy Networks) with TSCH (Time Slotted Channel\nHopping) and Orchestra (an autonomous method for building the TSCH schedule).\nWe measure the performance in the transient state when a node dies (i.e.,\nremoved from the network) and determine how long it takes for the network to\ncome back to a stable RPL tree and also what the impact is with respect to\nenergy consumption. Our analysis shows that the Orchestra reduces the energy\nconsumption when the RPL is in a transient state, like in the case of when one\nof the nodes die. Furthermore, we calculate the energy consumption in the\ntransient state without using Orchestra, and then we make a comparison between\nboth outcomes. We show that Orchestra reduces energy consumption by up to\none-third compared to not using Orchestra.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 10:27:23 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Amini", "Reza", ""], ["Imani", "Mehdi", ""], ["Todorov", "Petio Ivanov", ""], ["Ali", "Maaruf", ""]]}, {"id": "2008.00086", "submitter": "Songyang Zhang", "authors": "Songyang Zhang", "title": "LearningCC: An online learning approach for congestion control", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, much effort has been devoted by researchers from both academia and\nindustry to develop novel congestion control methods. LearningCC is presented\nin this letter, in which the congestion control problem is solved by reinforce\nlearning approach. Instead of adjusting the congestion window with fixed\npolicy, there are serval options for an endpoint to choose. To predict the best\noption is a hard task. Each option is mapped as an arm of a bandit machine. The\nendpoint can learn to determine the optimal choice through trial and error\nmethod. Experiments are performed on ns3 platform to verify the effectiveness\nof LearningCC by comparing with other benchmark algorithms. Results indicate it\ncan achieve lower transmission delay than loss based algorithms. Especially, we\nfound LearningCC makes significant improvement in link suffering from random\nloss.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 06:51:34 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhang", "Songyang", ""]]}, {"id": "2008.00087", "submitter": "Muhammad Kamran Nishat", "authors": "Kamran Nishat, Omprakash Gnawali, and Ahmed Abdelhadi", "title": "Adaptive Bitrate Video Streaming for Wireless nodes: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's Internet, video is the most dominant application and in addition\nto this, wireless networks such as WiFi, Cellular, and Bluetooth have become\nubiquitous. Hence, most of the Internet traffic is video over wireless nodes.\nThere is a plethora of research to improve video streaming to achieve high\nQuality of Experience (QoE) over the Internet. Many of them focus on wireless\nnodes. Recent measurement studies often show QoE of video suffers in many\nwireless clients over the Internet. Recently, many research papers have\npresented models and schemes to optimize the Adaptive BitRate (ABR) based video\nstreaming for wireless and mobile users. In this survey, we present a\ncomprehensive overview of recent work in the area of Internet video specially\ndesigned for wireless network. Recent research has suggested that there are\nsome new challenges added by the connectivity of clients through wireless. Also\nthese challenges become more difficult to handle when these nodes are mobile.\nThis survey also discusses new potential areas of future research due to the\nincreasing scarcity of wireless spectrum.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 06:37:02 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Nishat", "Kamran", ""], ["Gnawali", "Omprakash", ""], ["Abdelhadi", "Ahmed", ""]]}, {"id": "2008.00088", "submitter": "Safa Otoum", "authors": "Safa Otoum and Burak Kantarci and Hussein Mouftah", "title": "A Comparative Study of AI-based Intrusion Detection Techniques in\n  Critical Infrastructures", "comments": "ACM Transaction on Internet Technology, 2020 22 pages, 11 Figures, 3\n  Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volunteer computing uses Internet-connected devices (laptops, PCs, smart\ndevices, etc.), in which their owners volunteer them as storage and computing\npower resources, has become an essential mechanism for resource management in\nnumerous applications. The growth of the volume and variety of data traffic in\nthe Internet leads to concerns on the robustness of cyberphysical systems\nespecially for critical infrastructures. Therefore, the implementation of an\nefficient Intrusion Detection System for gathering such sensory data has gained\nvital importance. In this paper, we present a comparative study of Artificial\nIntelligence (AI)-driven intrusion detection systems for wirelessly connected\nsensors that track crucial applications. Specifically, we present an in-depth\nanalysis of the use of machine learning, deep learning and reinforcement\nlearning solutions to recognize intrusive behavior in the collected traffic. We\nevaluate the proposed mechanisms by using KD'99 as real attack data-set in our\nsimulations. Results present the performance metrics for three different IDSs\nnamely the Adaptively Supervised and Clustered Hybrid IDS (ASCH-IDS),\nRestricted Boltzmann Machine-based Clustered IDS (RBC-IDS) and Q-learning based\nIDS (QL-IDS) to detect malicious behaviors. We also present the performance of\ndifferent reinforcement learning techniques such as\nState-Action-Reward-State-Action Learning (SARSA) and the Temporal Difference\nlearning (TD). Through simulations, we show that QL-IDS performs with 100%\ndetection rate while SARSA-IDS and TD-IDS perform at the order of 99.5%.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 20:55:57 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Otoum", "Safa", ""], ["Kantarci", "Burak", ""], ["Mouftah", "Hussein", ""]]}, {"id": "2008.00089", "submitter": "Mahboobeh Parsapoor", "authors": "Mahboobeh Parsapoor, Urban Bilstrup", "title": "A Centralized Channel Allocation Method in Clustered Ad Hoc Networks", "comments": "8 pages, 10 figures, one table, submitted to LCN 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cognitive radio networks (CRNs) is the next generation of wireless\ncommunication. This type of network requires efficent spectrum allocation\nmethods. This paper presents a new meta-heuristic evolutionary method for\nsolving the channel allocation problem in an ad hoc network context. The\nsuggested method is based on a graph-theoretic model and seeks a solution for\nthe spectrum allocation problem in a clustered ad hoc network topology.The\nmethod is referred to as imperialist competitive algorithm (ICA)and provides a\nscheme for allocating the available channels to cluster heads maximizing\nspectrum efficiency and minimizes co-channel interference. The suggested\nmethods are tested for several scenarios; the performance of the ICA-based\nscheme is compared with the genetic algorithm based scheme.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 19:07:21 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Parsapoor", "Mahboobeh", ""], ["Bilstrup", "Urban", ""]]}, {"id": "2008.00136", "submitter": "Ilia Shumailov", "authors": "Almos Zarandy, Ilia Shumailov, Ross Anderson", "title": "BatNet: Data transmission between smartphones over ultrasound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present BatNet, a data transmission mechanism using\nultrasound signals over the built-in speakers and microphones of smartphones.\nUsing phase shift keying with an 8-point constellation and frequencies between\n20--24kHz, it can transmit data at over 600bit/s up to 6m. The target\napplication is a censorship-resistant mesh network. We also evaluated it for\nCovid contact tracing but concluded that in this application ultrasonic\ncommunications do not appear to offer enough advantage over Bluetooth Low\nEnergy to be worth further development.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 00:49:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zarandy", "Almos", ""], ["Shumailov", "Ilia", ""], ["Anderson", "Ross", ""]]}, {"id": "2008.00156", "submitter": "Xi Huang", "authors": "Xi Huang and Ziyu Shao and Yang Yang", "title": "MIPS: Instance Placement for Stream Processing Systems based on Monte\n  Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream processing engines enable modern systems to conduct large-scale\nanalytics over unbounded data streams in real time. They often view an\napplication as a direct acyclic graph with streams flowing through pipelined\ninstances of various processing units. One key challenge that emerges is\ninstance placement, i.e., to decide the placement of instances across servers\nwith minimum traffic across servers and maximum resource utilization. The\nchallenge roots in not only its intrinsic complexity but also the impact\nbetween successive application deployments. Most updated engines such as Apache\nHeron exploits a more modularized scheduler design that decomposes the task\ninto two stages: One decides the instance-to-container mapping while the other\nfocuses on the container-to-server mapping that is delegated to standalone\nresource managers. The unaligned objectives and scheduler designs in the two\nstages may lead to long response times or low utilization. However, so far\nlittle work has appeared to address the challenge. Inspired by the recent\nsuccess of applications of Monte Carlo Tree Search (MCTS) methods in various\nfields, we develop a novel model to characterize such systems, formulate the\nproblem, and cast each stage of mapping into a sequential decision process. By\nadopting MCTS methods, we propose MIPS, an MCTS-based Instance Placement Scheme\nto decide the two-staged mapping in a timely yet efficient manner. In addition,\nwe discuss practical issues and refine MIPS to further improve its performance.\nResults from extensive simulations show, given mild-value of samples, MIPS\noutperforms existing schemes with a significant traffic reduction and\nutilization improvement. To our best knowledge, this paper is the first to\nstudy the two-staged mapping problem and to apply MCTS to solving the\nchallenge.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 03:05:45 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Huang", "Xi", ""], ["Shao", "Ziyu", ""], ["Yang", "Yang", ""]]}, {"id": "2008.00159", "submitter": "Xi Huang", "authors": "Xi Huang and Ziyu Shao and Yang Yang", "title": "POTUS: Predictive Online Tuple Scheduling for Data Stream Processing\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most online service providers deploy their own data stream processing systems\nin the cloud to conduct large-scale and real-time data analytics. However, such\nsystems, e.g., Apache Heron, often adopt naive scheduling schemes to distribute\ndata streams (in the units of tuples) among processing instances, which may\nresult in workload imbalance and system disruption. Hence, there still exists a\nmismatch between the temporal variations of data streams and such inflexible\nscheduling scheme designs. Besides, the fundamental benefits of predictive\nscheduling to data stream processing systems also remain unexplored. In this\npaper, we focus on the problem of tuple scheduling with predictive service in\nApache Heron. With a careful choice in the granularity of system modeling and\ndecision making, we formulate the problem as a stochastic network optimization\nproblem and propose POTUS, an online predictive scheduling scheme that aims to\nminimize the response time of data stream processing by steering data streams\nin a distributed fashion. Theoretical analysis and simulation results show that\nPOTUS achieves an ultra-low response time with queue stability guarantee.\nMoreover, POTUS only requires mild-value of future information to effectively\nreduce the response time, even with mis-prediction.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 03:18:16 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Huang", "Xi", ""], ["Shao", "Ziyu", ""], ["Yang", "Yang", ""]]}, {"id": "2008.00161", "submitter": "Xi Huang", "authors": "Xi Huang and Shuang Zhao and Xin Gao and Ziyu Shao and Hua Qian and\n  Yang Yang", "title": "Online User-AP Association with Predictive Scheduling in Wireless\n  Caching Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For wireless caching networks, the scheme design for content delivery is\nnon-trivial in the face of the following tradeoff. On one hand, to optimize\noverall throughput, users can associate their nearby APs with great channel\ncapacities; however, this may lead to unstable queue backlogs on APs and\nprolong request delays. On the other hand, to ensure queue stability, some\nusers may have to associate APs with inferior channel states, which would incur\nthroughput loss. Moreover, for such systems, how to conduct predictive\nscheduling to reduce delays and the fundamental limits of its benefits remain\nunexplored. In this paper, we formulate the problem of online user-AP\nassociation and resource allocation for content delivery with predictive\nscheduling under a fixed content placement as a stochastic network optimization\nproblem. By exploiting its unique structure, we transform the problem into a\nseries of modular maximization sub-problems with matroid constraints. Then we\ndevise PUARA, a Predictive User-AP Association and Resource Allocation scheme\nwhich achieves a provably near-optimal throughput with queue stability. Our\ntheoretical analysis and simulation results show that PUARA can not only\nperform a tunable control between throughput maximization and queue stability\nbut also incur a notable delay reduction with predicted information.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 03:37:41 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Huang", "Xi", ""], ["Zhao", "Shuang", ""], ["Gao", "Xin", ""], ["Shao", "Ziyu", ""], ["Qian", "Hua", ""], ["Yang", "Yang", ""]]}, {"id": "2008.00196", "submitter": "Xin Gao", "authors": "Xin Gao, Xi Huang, Yinxu Tang, Ziyu Shao, Yang Yang", "title": "History-Aware Online Cache Placement in Fog-Assisted IoT Systems: An\n  Integration of Learning and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Fog-assisted IoT systems, it is a common practice to cache popular content\nat the network edge to achieve high quality of service. Due to uncertainties in\npractice such as unknown file popularities, cache placement scheme design is\nstill an open problem with unresolved challenges: 1) how to maintain\ntime-averaged storage costs under budgets, 2) how to incorporate online\nlearning to aid cache placement to minimize performance loss (a.k.a. regret),\nand 3) how to exploit offline historical information to further reduce regret.\nIn this paper, we formulate the cache placement problem with unknown file\npopularities as a constrained combinatorial multi-armed bandit (CMAB) problem.\nTo solve the problem, we employ virtual queue techniques to manage\ntime-averaged storage cost constraints, and adopt history-aware bandit learning\nmethods to integrate offline historical information into the online learning\nprocedure to handle the exploration-exploitation tradeoff. With an effective\ncombination of online control and history-aware online learning, we devise a\nCache Placement scheme with History-aware Bandit Learning called CPHBL. Our\ntheoretical analysis and simulations show that CPHBL achieves a sublinear\ntime-averaged regret bound. Moreover, the simulation results verify CPHBL's\nadvantage over the deep reinforcement learning based approach.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:13:39 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 07:44:54 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Gao", "Xin", ""], ["Huang", "Xi", ""], ["Tang", "Yinxu", ""], ["Shao", "Ziyu", ""], ["Yang", "Yang", ""]]}, {"id": "2008.00199", "submitter": "Xin Gao", "authors": "Xin Gao, Xi Huang, Ziyu Shao, Yang Yang", "title": "Green Offloading in Fog-Assisted IoT Systems: An Online Perspective\n  Integrating Learning and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fog-assisted IoT systems, it is a common practice to offload tasks from\nIoT devices to their nearby fog nodes to reduce task processing latencies and\nenergy consumptions. However, the design of online energy-efficient scheme is\nstill an open problem because of various uncertainties in system dynamics such\nas processing capacities and transmission rates. Moreover, the decision-making\nprocess is constrained by resource limits on fog nodes and IoT devices, making\nthe design even more complicated. In this paper, we formulate such a task\noffloading problem with unknown system dynamics as a combinatorial multi-armed\nbandit (CMAB) problem with long-term constraints on time-averaged energy\nconsumptions. Through an effective integration of online learning and online\ncontrol, we propose a \\textit{Learning-Aided Green Offloading} (LAGO) scheme.\nIn LAGO, we employ bandit learning methods to handle the\nexploitation-exploration tradeoff and utilize virtual queue techniques to deal\nwith the long-term constraints. Our theoretical analysis shows that LAGO can\nreduce the average task latency with a tunable sublinear regret bound over a\nfinite time horizon and satisfy the long-term time-averaged energy constraints.\nWe conduct extensive simulations to verify such theoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:27:24 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gao", "Xin", ""], ["Huang", "Xi", ""], ["Shao", "Ziyu", ""], ["Yang", "Yang", ""]]}, {"id": "2008.00204", "submitter": "Xin Gao", "authors": "Xin Gao, Xi Huang, Simeng Bian, Ziyu Shao, Yang Yang", "title": "PORA: Predictive Offloading and Resource Allocation in Dynamic Fog\n  Computing Systems", "comments": null, "journal-ref": "IEEE Internet of Things Journal, vol. 7, no. 1, pp. 72-87, 2020", "doi": "10.1109/JIOT.2019.2945066", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-tiered fog computing systems, to accelerate the processing of\ncomputation-intensive tasks for real-time IoT applications, resource-limited\nIoT devices can offload part of their workloads to nearby fog nodes, whereafter\nsuch workloads may be offloaded to upper-tier fog nodes with greater\ncomputation capacities. Such hierarchical offloading, though promising to\nshorten processing latencies, may also induce excessive power consumptions and\nlatencies for wireless transmissions. With the temporal variation of various\nsystem dynamics, such a trade-off makes it rather challenging to conduct\neffective and online offloading decision making. Meanwhile, the fundamental\nbenefits of predictive offloading to fog computing systems still remain\nunexplored. In this paper, we focus on the problem of dynamic offloading and\nresource allocation with traffic prediction in multi-tiered fog computing\nsystems. By formulating the problem as a stochastic network optimization\nproblem, we aim to minimize the time-average power consumptions with stability\nguarantee for all queues in the system. We exploit unique problem structures\nand propose PORA, an efficient and distributed predictive offloading and\nresource allocation scheme for multi-tiered fog computing systems. Our\ntheoretical analysis and simulation results show that PORA incurs near-optimal\npower consumptions with queue stability guarantee. Furthermore, PORA requires\nonly mild-value of predictive information to achieve a notable latency\nreduction, even with prediction errors.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:49:58 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 08:10:43 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Gao", "Xin", ""], ["Huang", "Xi", ""], ["Bian", "Simeng", ""], ["Shao", "Ziyu", ""], ["Yang", "Yang", ""]]}, {"id": "2008.00207", "submitter": "Simeng Bian", "authors": "Simeng Bian, Xi Huang, Ziyu Shao", "title": "Online Task Scheduling for Fog Computing with Multi-Resource Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fog computing systems, one key challenge is online task scheduling, i.e.,\nto decide the resource allocation for tasks that are continuously generated\nfrom end devices. The design is challenging because of various uncertainties\nmanifested in fog computing systems; e.g., tasks' resource demands remain\nunknown before their actual arrivals. Recent works have applied deep\nreinforcement learning (DRL) techniques to conduct online task scheduling and\nimprove various objectives. However, they overlook the multi-resource fairness\nfor different tasks, which is key to achieving fair resource sharing among\ntasks but in general non-trivial to achieve. Thusly, it is still an open\nproblem to design an online task scheduling scheme with multi-resource\nfairness. In this paper, we address the above challenges. Particularly, by\nleveraging DRL techniques and adopting the idea of dominant resource fairness\n(DRF), we propose FairTS, an online task scheduling scheme that learns directly\nfrom experience to effectively shorten average task slowdown while ensuring\nmulti-resource fairness among tasks. Simulation results show that FairTS\noutperforms state-of-the-art schemes with an ultra-low task slowdown and better\nresource fairness.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:57:40 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Bian", "Simeng", ""], ["Huang", "Xi", ""], ["Shao", "Ziyu", ""]]}, {"id": "2008.00208", "submitter": "Simeng Bian", "authors": "Simeng Bian, Xi Huang, Ziyu Shao, Xin Gao, Yang Yang", "title": "Service Chain Composition with Failures in NFV Systems: A Game-Theoretic\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For state-of-the-art network function virtualization (NFV) systems, it\nremains a key challenge to conduct effective service chain composition for\ndifferent network services (NSs) with ultra-low request latencies and minimum\nnetwork congestion. To this end, existing solutions often require full\nknowledge of the network state, while ignoring the privacy issues and\noverlooking the non-cooperative behaviors of users. What is more, they may fall\nshort in the face of unexpected failures such as user unavailability and\nvirtual machine breakdown. In this paper, we formulate the problem of service\nchain composition in NFV systems with failures as a non-cooperative game. By\nshowing that such a game is a weighted potential game and exploiting the unique\nproblem structure, we propose two effective distributed schemes that guide the\nservice chain compositions of different NSs towards the Nash equilibrium (NE)\nstate with both near-optimal latencies and minimum congestion. Besides, we\ndevelop two novel learning-aided schemes as comparisons, which are based on\ndeep reinforcement learning (DRL) and Monte Carlo tree search (MCTS)\ntechniques, respectively. Our theoretical analysis and simulation results\ndemonstrate the effectiveness of our proposed schemes, as well as the\nadaptivity when faced with failures.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:58:14 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Bian", "Simeng", ""], ["Huang", "Xi", ""], ["Shao", "Ziyu", ""], ["Gao", "Xin", ""], ["Yang", "Yang", ""]]}, {"id": "2008.00307", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Chad Meiners, Chansup Byun, Sarah McGuire, Timothy\n  Davis, William Arcand, Jonathan Bernays, David Bestor, William Bergeron,\n  Vijay Gadepally, Raul Harnasch, Matthew Hubbell, Micheal Houle, Micheal\n  Jones, Andrew Kirby, Anna Klein, Lauren Milechin, Julie Mullen, Andrew Prout,\n  Albert Reuther, Antonio Rosa, Siddharth Samsi, Doug Stetson, Adam Tse,\n  Charles Yee, Peter Michaleas", "title": "Multi-Temporal Analysis and Scaling Relations of 100,000,000,000 Network\n  Packets", "comments": "6 pages, 6 figures,3 tables, 49 references, accepted to IEEE HPEC\n  2020", "journal-ref": null, "doi": "10.1109/HPEC43674.2020.9286235", "report-no": null, "categories": "cs.NI cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our society has never been more dependent on computer networks. Effective\nutilization of networks requires a detailed understanding of the normal\nbackground behaviors of network traffic. Large-scale measurements of networks\nare computationally challenging. Building on prior work in interactive\nsupercomputing and GraphBLAS hypersparse hierarchical traffic matrices, we have\ndeveloped an efficient method for computing a wide variety of streaming network\nquantities on diverse time scales. Applying these methods to 100,000,000,000\nanonymized source-destination pairs collected at a network gateway reveals many\npreviously unobserved scaling relationships. These observations provide new\ninsights into normal network background traffic that could be used for anomaly\ndetection, AI feature engineering, and testing theoretical models of streaming\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 17:56:56 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Kepner", "Jeremy", ""], ["Meiners", "Chad", ""], ["Byun", "Chansup", ""], ["McGuire", "Sarah", ""], ["Davis", "Timothy", ""], ["Arcand", "William", ""], ["Bernays", "Jonathan", ""], ["Bestor", "David", ""], ["Bergeron", "William", ""], ["Gadepally", "Vijay", ""], ["Harnasch", "Raul", ""], ["Hubbell", "Matthew", ""], ["Houle", "Micheal", ""], ["Jones", "Micheal", ""], ["Kirby", "Andrew", ""], ["Klein", "Anna", ""], ["Milechin", "Lauren", ""], ["Mullen", "Julie", ""], ["Prout", "Andrew", ""], ["Reuther", "Albert", ""], ["Rosa", "Antonio", ""], ["Samsi", "Siddharth", ""], ["Stetson", "Doug", ""], ["Tse", "Adam", ""], ["Yee", "Charles", ""], ["Michaleas", "Peter", ""]]}, {"id": "2008.00905", "submitter": "Shenghe Xu", "authors": "Shenghe Xu, Murali Kodialam, T.V. Lakshman and Shivendra Panwar", "title": "Learning Based Methods for Traffic Matrix Estimation from Link\n  Measurements", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network traffic demand matrix is a critical input for capacity planning,\nanomaly detection and many other network management related tasks. The demand\nmatrix is often computed from link load measurements. The traffic matrix (TM)\nestimation problem is the determination of the traffic demand matrix from link\nload measurements. The relationship between the link loads and the traffic\nmatrix that generated the link load can be modeled as an under-determined\nlinear system and has multiple feasible solutions. Therefore, prior knowledge\nof the traffic demand pattern has to be used in order to find a potentially\nfeasible demand matrix. In this paper, we consider the TM estimation problem\nwhere we have information about the distribution of the demand sizes. This\ninformation can be obtained from the analysis of a few traffic matrices\nmeasured in the past or from operator experience. We develop an iterative\nprojection based algorithm for the solution of this problem. If large number of\npast traffic matrices are accessible, we propose a Generative Adversarial\nNetwork (GAN) based approach for solving the problem. We compare the strengths\nof the two approaches and evaluate their performance for several networks using\nvarying amounts of past data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 14:34:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Xu", "Shenghe", ""], ["Kodialam", "Murali", ""], ["Lakshman", "T. V.", ""], ["Panwar", "Shivendra", ""]]}, {"id": "2008.00937", "submitter": "Dimitrios Michael Manias", "authors": "Dimitrios Michael Manias and Abdallah Shami", "title": "The Need for Advanced Intelligence in NFV Management and Orchestration", "comments": "To Appear in IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the constant demand for connectivity at an all-time high, Network\nService Providers (NSPs) are required to optimize their networks to cope with\nrising capital and operational expenditures required to meet the growing\nconnectivity demand. A solution to this challenge was presented through Network\nFunction Virtualization (NFV). As network complexity increases and futuristic\nnetworks take shape, NSPs are required to incorporate an increasing amount of\noperational efficiency into their NFV-enabled networks. One such technique is\nMachine Learning (ML), which has been applied to various entities in\nNFV-enabled networks, most notably in the NFV Orchestrator. While traditional\nML provides tremendous operational efficiencies, including real-time and\nhigh-volume data processing, challenges such as privacy, security, scalability,\ntransferability, and concept drift hinder its widespread implementation.\nThrough the adoption of Advanced Intelligence techniques such as Reinforcement\nLearning and Federated Learning, NSPs can leverage the benefits of traditional\nML while simultaneously addressing the major challenges traditionally\nassociated with it. This work presents the benefits of adopting these advanced\ntechniques, provides a list of potential use cases and research topics, and\nproposes a bottom-up micro-functionality approach to applying these methods of\nAdvanced Intelligence to NFV Management and Orchestration.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:17:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Manias", "Dimitrios Michael", ""], ["Shami", "Abdallah", ""]]}, {"id": "2008.00958", "submitter": "Sohini Roy", "authors": "Sohini Roy", "title": "SSGMT: A Secure Smart Grid Monitoring Technique", "comments": "7 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:2005.13093", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Critical infrastructure systems like power grid require an improved critical\nin-formation infrastructure (CII) that can not only help in monitoring of the\ncrit-ical entities but also take part in failure analysis and self-healing.\nEfficient designing of a CII is challenging as each kind of communication\ntechnology has its own advantages and disadvantages. Wired networks are highly\nscala-ble and secure, but they are neither cost effective nor dynamic in\nnature. Wireless communication technologies on the other hand are easy to\ndeploy, low cost etc. but they are vulnerable to cyber-attacks. In order to\noptimize cost, power consumption, dynamic nature, accuracy and scalability a\nhybrid communication network is designed in this paper where a portion of the\ncommunication network is built using wireless sensor networks (WSN) and the\nrest is a wired network of fiber optic channels. To offer seamless opera-tion\nof the hybrid communication network and provide security a Secure Smart Grid\nMonitoring Technique (SSGMT) is also proposed. The perfor-mance of the proposed\nhybrid CII for the generation and transmission sys-tem of power grid coupled\nwith the SSGMT during different cyber-attacks is tested using NS2 simulator.\nThe simulation results show that the SSGMT for a joint power communication\nnetwork of IEEE 118-Bus system performs better than the prevailing wireless\nCIIs like Lo-ADI and Modified AODV.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 23:24:12 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Roy", "Sohini", ""]]}, {"id": "2008.00989", "submitter": "Micah Beck", "authors": "Micah Beck and Terry Moore", "title": "Exposed Buffer Architecture for Continuum Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exposed Buffer Architecture addresses the problem of creating a programmable\nservice platform for the digital continuum by reexamining the particular form\nof virtualization that is inherent to the Internet architecture. In the\nInternet stack below the Network Layer, the Link layer models services that are\nlocal to network nodes, or that connect them in local area networks.\nAggregating these low level resources in the implementation of IP to create\nwide area services serves two different purposes: 1) It virtualizes local\nservices, enabling interoperability through the adoption of a common model, and\n2) It hides the topology of local infrastructure. The main premise of\nExposedBuffer Architecture is that we can separate these two tasks, addressing\nthe first with an invariant system model that provides a highly general,\nprogrammable platform for transcontinuum services, enabling a variety of\napproach to address the second.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:18:05 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 02:45:55 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Beck", "Micah", ""], ["Moore", "Terry", ""]]}, {"id": "2008.01000", "submitter": "Hao Yin", "authors": "Hao Yin, Xiaojun Guo, Pengyu Liu, Xiaojun Hei, Yayu Gao", "title": "Predicting Channel Quality Indicators for 5G Downlink Scheduling in a\n  Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G networks provide more bandwidth and more complex control to enhance user's\nexperiences, while also requiring a more accurate estimation of the\ncommunication channels compared with previous mobile networks. In this paper,\nwe propose a channel quality indicator (CQI) prediction method in a deep\nlearning approach in that a Long Short-Term Memory (LSTM) algorithm. An online\ntraining module is introduced for the downlink scheduling in the 5G New Radio\n(NR) system, to reduce the negative impact of outdated CQI for communication\ndegradation, especially in high-speed mobility scenarios. First, we analyze the\nimpact of outdated CQI in the downlink scheduling of the 5G NR system. Then, we\ndesign a data generation and online training module to evaluate our prediction\nmethod in ns-3. The simulation results show that the proposed LSTM method\noutperforms the Feedforward Neural Networks (FNN) method on improving the\nsystem performance of the downlink transmission. Our study may provide insights\ninto designing new deep learning algorithms to enhance the network performance\nof the 5G NR system.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:38:28 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yin", "Hao", ""], ["Guo", "Xiaojun", ""], ["Liu", "Pengyu", ""], ["Hei", "Xiaojun", ""], ["Gao", "Yayu", ""]]}, {"id": "2008.01267", "submitter": "Vishnu Vardhan Chetlur", "authors": "Vishnu Vardhan Chetlur and Harpreet S. Dhillon", "title": "On the Load Distribution of Vehicular Users Modeled by a Poisson Line\n  Cox Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we characterize the load on the cellular macro base stations\n(MBSs) due to vehicular users modeled by a Poisson line Cox process (PLCP).\nModeling the locations of MBSs by a homogeneous 2D Poisson point process (PPP),\nwe first characterize the total chord length distribution of the lines of the\nPoisson line process (PLP) intersecting the typical Poisson Voronoi (PV) cell.\nUsing this result, we derive the exact probability mass function (PMF) of the\nload on the typical MBS. Considering the computational complexity of this\nexpression, we propose an easy-to-use approximation for the PMF that is also\nremarkably accurate. Building on this result, we also compute the PMF of the\nload on the tagged MBS that serves the typical vehicular user. This result\nenables the characterization of the rate coverage of the typical receiver in\nthe network, which is also included as a useful case study.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 01:41:18 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Chetlur", "Vishnu Vardhan", ""], ["Dhillon", "Harpreet S.", ""]]}, {"id": "2008.01427", "submitter": "Borja Martinez", "authors": "Borja Martinez, Cristina Cano, Xavier Vilajosana", "title": "Debunking Wireless Sensor Networks Myths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we revisit Wireless Sensor Networks from a contemporary\nperspective, after the surge of the Internet of Things. First, we analyze the\nevolution of distributed monitoring applications, which we consider inherited\nfrom the early idea of collaborative sensor networks. Second, we evaluate,\nwithin the current context of networked objects, the level of adoption of\nlow-power multi-hop wireless, a technology pivotal to the Wireless Sensor\nNetwork paradigm. This article assesses the transformation of this technology\nin its integration into the Internet of Things, identifying outdated\nrequirements and providing a critical view on future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 09:26:39 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Martinez", "Borja", ""], ["Cano", "Cristina", ""], ["Vilajosana", "Xavier", ""]]}, {"id": "2008.01528", "submitter": "Thomas Stahlbuhk", "authors": "Thomas Stahlbuhk, Brooke Shrader and Eytan Modiano", "title": "Throughput Maximization in Uncooperative Spectrum Sharing Networks", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughput-optimal transmission scheduling in wireless networks has been a\nwell considered problem in the literature, and the method for achieving\noptimality, MaxWeight scheduling, has been known for several decades. This\nalgorithm achieves optimality by adaptively scheduling transmissions relative\nto each user's stochastic traffic demands. To implement the method, users must\nreport their queue backlogs to the network controller and must rapidly respond\nto the resulting resource allocations. However, many currently-deployed\nwireless systems are not able to perform these tasks and instead expect to\noccupy a fixed assignment of resources. To accommodate these limitations,\nadaptive scheduling algorithms need to interactively estimate these\nuncooperative users' queue backlogs and make scheduling decisions to account\nfor their predicted behavior. In this work, we address the problem of\nscheduling with uncooperative legacy systems by developing algorithms to\naccomplish these tasks. We begin by formulating the problem of inferring the\nuncooperative systems' queue backlogs as a partially observable Markov decision\nprocess and proceed to show how our resulting learning algorithms can be\nsuccessfully used in a queue-length-based scheduling policy. Our theoretical\nanalysis characterizes the throughput-stability region of the network and is\nverified using simulation results.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:42:00 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Stahlbuhk", "Thomas", ""], ["Shrader", "Brooke", ""], ["Modiano", "Eytan", ""]]}, {"id": "2008.01553", "submitter": "Mingjin Zhang", "authors": "Lei Yang, Yanyan Lu, Jiannong Cao, Jiaming Huang, Mingjin Zhang", "title": "E-Tree Learning: A Novel Decentralized Model Learning Framework for Edge\n  AI", "comments": "IEEE Internet of Things Journal, 2020", "journal-ref": null, "doi": "10.1109/JIOT.2021.3052195", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, AI models are trained on the central cloud with data collected\nfrom end devices. This leads to high communication cost, long response time and\nprivacy concerns. Recently Edge empowered AI, namely Edge AI, has been proposed\nto support AI model learning and deployment at the network edge closer to the\ndata sources. Existing research including federated learning adopts a\ncentralized architecture for model learning where a central server aggregates\nthe model updates from the clients/workers. The centralized architecture has\ndrawbacks such as performance bottleneck, poor scalability and single point of\nfailure. In this paper, we propose a novel decentralized model learning\napproach, namely E-Tree, which makes use of a well-designed tree structure\nimposed on the edge devices. The tree structure and the locations and orders of\naggregation on the tree are optimally designed to improve the training\nconvergency and model accuracy. In particular, we design an efficient device\nclustering algorithm, named by KMA, for E-Tree by taking into account the data\ndistribution on the devices as well as the the network distance. Evaluation\nresults show E-Tree significantly outperforms the benchmark approaches such as\nfederated learning and Gossip learning under NonIID data in terms of model\naccuracy and convergency.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:59:29 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 05:15:24 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Yang", "Lei", ""], ["Lu", "Yanyan", ""], ["Cao", "Jiannong", ""], ["Huang", "Jiaming", ""], ["Zhang", "Mingjin", ""]]}, {"id": "2008.01628", "submitter": "Mona Ghassemian", "authors": "Mona Ghassemian, Paul Muschamp, Dan Warren", "title": "Experience Building A 5G Testbed Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 5G VINNI testbed infrastructure project provides 5G facilities for\npan-European services. Within the project, the UK site is one of the 5G-VINNI\nfacilities that targets developing a flexible and dynamic test environment\nwhich can be adapted to meet requirements from H2020 funded projects as well as\nexternal trials, to enable vertical industries to assess 5G networks in the\ncontext of advanced digital use cases. In this paper, we present a full\noverview of the 5G test infrastructure developed at the UK 5G VINNI facility,\nincluding backhaul, edge, slicing, interworking and validation. This work\npresents an operator's experience in setting up a testbed facility and in\nengaging with different verticals conducting their research projects using the\n5G facility, and the results and benefits to the industry. Furthermore, the\nlessons learned from the design, installation, operation and experimentation\nphases of the project are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:18:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ghassemian", "Mona", ""], ["Muschamp", "Paul", ""], ["Warren", "Dan", ""]]}, {"id": "2008.01646", "submitter": "Xi Huang", "authors": "Xi Huang and Yinxu Tang and Ziyu Shao and Yang Yang and Hong Xu", "title": "Joint Switch-Controller Association and Control Devolution for SDN\n  Systems: An Integration of Online Control and Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In software-defined networking (SDN) systems, it is a common practice to\nadopt a multi-controller design and control devolution techniques to improve\nthe performance of the control plane. However, in such systems, the\ndecision-making for joint switch-controller association and control devolution\noften involves various uncertainties, e.g., the temporal variations of\ncontroller accessibility, and computation and communication costs of switches.\nIn practice, statistics of such uncertainties are unattainable and need to be\nlearned in an online fashion, calling for an integrated design of learning and\ncontrol. In this paper, we formulate a stochastic network optimization problem\nthat aims to minimize time-average system costs and ensure queue stability. By\ntransforming the problem into a combinatorial multi-armed bandit problem with\nlong-term stability constraints, we adopt bandit learning methods and optimal\ncontrol techniques to handle the exploration-exploitation tradeoff and\nlong-term stability constraints, respectively. Through an integrated design of\nonline learning and online control, we propose an effective Learning-Aided\nSwitch-Controller Association and Control Devolution (LASAC) scheme. Our\ntheoretical analysis and simulation results show that LASAC achieves a tunable\ntradeoff between queue stability and system cost reduction with a sublinear\ntime-averaged regret bound over a finite time horizon.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 03:46:31 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Huang", "Xi", ""], ["Tang", "Yinxu", ""], ["Shao", "Ziyu", ""], ["Yang", "Yang", ""], ["Xu", "Hong", ""]]}, {"id": "2008.01647", "submitter": "Xi Huang", "authors": "Xi Huang and Simeng Bian and Xin Gao and Weijie Wu and Ziyu Shao and\n  Yang Yang and John C.S. Lui", "title": "Online VNF Chaining and Predictive Scheduling: Optimality and Trade-offs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For NFV systems, the key design space includes the function chaining for\nnetwork requests and resource scheduling for servers. The problem is\nchallenging since NFV systems usually require multiple (often conflicting)\ndesign objectives and the computational efficiency of real-time decision making\nwith limited information. Furthermore, the benefits of predictive scheduling to\nNFV systems still remain unexplored. In this paper, we propose POSCARS, an\nefficient predictive and online service chaining and resource scheduling scheme\nthat achieves tunable trade-offs among various system metrics with queue\nstability guarantee. Through a careful choice of granularity in system\nmodeling, we acquire a better understanding of the trade-offs in our design\nspace. By a non-trivial transformation, we decouple the complex optimization\nproblem into a series of online sub-problems to achieve the optimality with\nonly limited information. By employing randomized load balancing techniques, we\npropose three variants of POSCARS to reduce the overheads of decision making.\nTheoretical analysis and simulations show that POSCARS and its variants require\nonly mild-value of future information to achieve near-optimal system cost with\nan ultra-low request response time.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 03:58:13 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Huang", "Xi", ""], ["Bian", "Simeng", ""], ["Gao", "Xin", ""], ["Wu", "Weijie", ""], ["Shao", "Ziyu", ""], ["Yang", "Yang", ""], ["Lui", "John C. S.", ""]]}, {"id": "2008.01648", "submitter": "Xi Huang", "authors": "Xi Huang and Simeng Bian and Ziyu Shao and Hong Xu", "title": "Predictive Switch-Controller Association and Control Devolution for SDN\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For software-defined networking (SDN) systems, to enhance the scalability and\nreliability of control plane, existing solutions adopt either multi-controller\ndesign with static switch-controller associations, or static control devolution\nby delegating certain request processing back to switches. Such solutions can\nfall short in face of temporal variations of request traffics, incurring\nconsiderable local computation costs on switches and their communication costs\nto controllers. So far, it still remains an open problem to develop a joint\nonline scheme that conducts dynamic switch-controller association and dynamic\ncontrol devolution. In addition, the fundamental benefits of predictive\nscheduling to SDN systems still remain unexplored. In this paper, we identify\nthe non-trivial trade-off in such a joint design and formulate a stochastic\nnetwork optimization problem that aims to minimize time-averaged total system\ncosts and ensure long-term queue stability. By exploiting the unique problem\nstructure, we devise a predictive online switch-controller association and\ncontrol devolution (POSCAD) scheme, which solves the problem through a series\nof online distributed decision making. Theoretical analysis shows that without\nprediction, POSCAD can achieve near-optimal total system costs with a tunable\ntrade-off for queue stability. With prediction, POSCAD can achieve even better\nperformance with shorter latencies. We conduct extensive simulations to\nevaluate POSCAD. Notably, with mild-value of future information, POSCAD incurs\na significant reduction in request latencies, even when faced with prediction\nerrors.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:41:42 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Huang", "Xi", ""], ["Bian", "Simeng", ""], ["Shao", "Ziyu", ""], ["Xu", "Hong", ""]]}, {"id": "2008.02005", "submitter": "Andrey Belogaev", "authors": "Andrey Belogaev, Evgeny Khorov, Artem Krasilon, Andrey Lyakhov", "title": "Analytical Study of Incremental Approach for Information Dissemination\n  in Wireless Networks", "comments": "Conference Wireless Days (WD) 2018", "journal-ref": null, "doi": "10.1109/WD.2018.8361712", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scenarios, control information dissemination becomes a bottleneck,\nwhich limits the scalability and the performance of wireless networks. Such a\nproblem is especially crucial in mobile ad hoc networks, dense networks,\nnetworks of vehicles and drones, sensor networks. In other words, this problem\noccurs in any scenario with frequent changes in topology or interference level\non one side and with strong requirements on delay, reliability, power\nconsumption, or capacity on the other side. If the control information changes\npartially, it may be worth sending only differential updates instead of\nmessages containing full information to reduce overhead. However, such an\napproach needs accurate tuning of dissemination parameters, since it is\nnecessary to guarantee information relevance in error-prone wireless networks.\nIn the paper, we provide a deep study of two approaches for generating\ndifferential updates - namely, incremental and cumulative - and compare their\nefficiency. We show that the incremental approach allows significantly reducing\nthe amount of generated control information compared to the cumulative one,\nwhile providing the same level of information relevance. We develop an\nanalytical model for the incremental approach and propose an algorithm which\nallows tuning its parameters, depending on the number of nodes in the network,\ntheir mobility, and wireless channel quality. Using the developed analytical\nmodel, we show that the incremental approach is very useful for static dense\nnetwork deployments and networks with low and medium mobility, since it allows\nus to significantly reduce the amount of control information compared to the\nclassical full dump approach.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 09:03:59 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Belogaev", "Andrey", ""], ["Khorov", "Evgeny", ""], ["Krasilon", "Artem", ""], ["Lyakhov", "Andrey", ""]]}, {"id": "2008.02083", "submitter": "Hitesh Tewari", "authors": "Raman Singh, Andrew Donegan, Hitesh Tewari", "title": "Framework for a Decentralized Web", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, we have witnessed the Internet becoming increasingly\ncentralized in the hands of a small number of giant technology firms, that\ncontrol many of the most popular applications and the content they host on\ntheir platforms. In addition, in the majority of instances today, access to the\nInternet is usually provided through local internet service providers (ISPs) in\neach country. Governments in different jurisdictions can exert pressure on\nthese technology firms and ISPs to enforce restrictions on Internet usage by\ntheir citizens, such as the blocking access to certain sites and/or content. In\nthis paper, we present a promising new approach to circumventing some of these\nissues. Our decentralized web (DWeb) proposal makes use of a mesh network to\nconnect community based routers. In addition, objects on the DWeb are indexed\nusing Bblockchain technology, which allows for secure storage of immutable\nobject references, and integrity checking of the data being served to users.\nOur DWeb design is also capable of operating during network partitions, and is\nable to quickly re-synchronize with the larger network once connectivity has\nbeen restored.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:39:10 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 17:16:04 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 16:48:52 GMT"}, {"version": "v4", "created": "Wed, 14 Oct 2020 16:59:24 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Singh", "Raman", ""], ["Donegan", "Andrew", ""], ["Tewari", "Hitesh", ""]]}, {"id": "2008.02100", "submitter": "Raghunandan M Rao", "authors": "Raghunandan M. Rao, Harpreet S. Dhillon, Vuk Marojevic, Jeffrey H.\n  Reed", "title": "Underlay Radar-Massive MIMO Spectrum Sharing: Modeling Fundamentals and\n  Performance Analysis", "comments": "This arXiv manuscript subsumes the contents of the conference paper\n  presented at the 2019 IEEE Global Communications Conference (Globecom),\n  Waikoloa, HI. The conference version is available at arXiv:1907.09536", "journal-ref": null, "doi": "10.1109/TWC.2021.3081458", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study underlay radar-massive MIMO cellular coexistence in\nLoS/near-LoS channels, where both systems have 3D beamforming capabilities.\nUsing mathematical tools from stochastic geometry, we derive an upper bound on\nthe average interference power at the radar due to the 3D massive MIMO cellular\ndownlink under the worst-case `cell-edge beamforming' conditions. To overcome\nthe technical challenges imposed by asymmetric and arbitrarily large cells, we\ndevise a novel construction in which each Poisson Voronoi (PV) cell is bounded\nby its circumcircle to bound the effect of the random cell shapes on average\ninterference. Since this model is intractable for further analysis due to the\ncorrelation between adjacent PV cells' shapes and sizes, we propose a tractable\nnominal interference model, where we model each PV cell as a circular disk with\nan area equal to the average area of the typical cell. We quantify the gap in\nthe average interference power between these two models and show that the upper\nbound is tight for realistic deployment parameters. We also compare them with a\nmore practical but intractable MU-MIMO scheduling model to show that our\nworst-case interference models show the same trends and do not deviate\nsignificantly from realistic scheduler models. Under the nominal interference\nmodel, we characterize the interference distribution using the dominant\ninterferer approximation by deriving the equi-interference contour expression\nwhen the typical receiver uses 3D beamforming. Finally, we use tractable\nexpressions for the interference distribution to characterize radar's spatial\nprobability of false alarm/detection in a quasi-static target tracking\nscenario. Our results reveal useful trends in the average interference as a\nfunction of the deployment parameters (BS density, exclusion zone radius,\nantenna height, transmit power of each BS, etc.).\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 02:37:10 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 19:54:02 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Rao", "Raghunandan M.", ""], ["Dhillon", "Harpreet S.", ""], ["Marojevic", "Vuk", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "2008.02213", "submitter": "Tianyu Cui", "authors": "Tianyu Cui, Gang Xiong, Gaopeng Gou, Junzheng Shi and Wei Xia", "title": "6VecLM: Language Modeling in Vector Space for IPv6 Target Generation", "comments": "The paper has been accepted at the European Conference on Machine\n  Learning and Principles and Practice of Knowledge Discovery in Databases\n  (ECMLPKDD 2020) (https://ecmlpkdd2020.net/programme/accepted/#ADSTab)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast IPv6 scanning is challenging in the field of network measurement as it\nrequires exploring the whole IPv6 address space but limited by current\ncomputational power. Researchers propose to obtain possible active target\ncandidate sets to probe by algorithmically analyzing the active seed sets.\nHowever, IPv6 addresses lack semantic information and contain numerous\naddressing schemes, leading to the difficulty of designing effective\nalgorithms. In this paper, we introduce our approach 6VecLM to explore\nachieving such target generation algorithms. The architecture can map addresses\ninto a vector space to interpret semantic relationships and uses a Transformer\nnetwork to build IPv6 language models for predicting address sequence.\nExperiments indicate that our approach can perform semantic classification on\naddress space. By adding a new generation approach, our model possesses a\ncontrollable word innovation capability compared to conventional language\nmodels. The work outperformed the state-of-the-art target generation algorithms\non two active address datasets by reaching more quality candidate sets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:26:50 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Cui", "Tianyu", ""], ["Xiong", "Gang", ""], ["Gou", "Gaopeng", ""], ["Shi", "Junzheng", ""], ["Xia", "Wei", ""]]}, {"id": "2008.02327", "submitter": "MohammadNoor Injadat", "authors": "MohammadNoor Injadat, Fadi Salo, Ali Bou Nassif, Aleksander Essex,\n  Abdallah Shami", "title": "Bayesian Optimization with Machine Learning Algorithms Towards Anomaly\n  Detection", "comments": "6 pages, 7 Figures, 2 tables, Published in 2018 IEEE Global\n  Communications Conference (GLOBECOM)", "journal-ref": null, "doi": "10.1109/GLOCOM.2018.8647714", "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network attacks have been very prevalent as their rate is growing\ntremendously. Both organization and individuals are now concerned about their\nconfidentiality, integrity and availability of their critical information which\nare often impacted by network attacks. To that end, several previous machine\nlearning-based intrusion detection methods have been developed to secure\nnetwork infrastructure from such attacks. In this paper, an effective anomaly\ndetection framework is proposed utilizing Bayesian Optimization technique to\ntune the parameters of Support Vector Machine with Gaussian Kernel (SVM-RBF),\nRandom Forest (RF), and k-Nearest Neighbor (k-NN) algorithms. The performance\nof the considered algorithms is evaluated using the ISCX 2012 dataset.\nExperimental results show the effectiveness of the proposed framework in term\nof accuracy rate, precision, low-false alarm rate, and recall.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 19:29:35 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Salo", "Fadi", ""], ["Nassif", "Ali Bou", ""], ["Essex", "Aleksander", ""], ["Shami", "Abdallah", ""]]}, {"id": "2008.02522", "submitter": "Sayantan Guha", "authors": "Sayantan Guha and Adel Alshamrani", "title": "Attaining High Bandwidth In Cloud Computing Through SDN-enabled\n  Multi-tree Multicast", "comments": "7 pages. Published with International Journal of Computer Trends and\n  Technology (IJCTT)\"", "journal-ref": "International Journal of Computer Trends and Technology 68.3\n  (2020):92-98", "doi": "10.14445/22312803/IJCTT-V68I3P119", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving high bandwidth utilization in cloud computing is essential for\nbetter network performance. However, it is difficult to attain high bandwidth\nutilization in cloud computing due to the complex and distributed natures of\ncloud computing resources. Recently, a growing demand for multicast\ntransmission is perceived in cloud computing, due to the explosive growth of\nmulti-point communication applications, such as video conferencing, online\ngaming, etc. Nonetheless, the inherent complexity in multicast routing in cloud\ncomputing, existing multicast plans failed to produce effective and efficient\nprotocol schemes, which limits the application of multicast communication on\nthe Internet. In this paper, a technique is proposed in how the newly developed\nnetwork architecture, Software Defined Network (SDN), can promote the design of\nthe multicast protocol and improve the performance of the multicast\ntransmission in the cloud computing. The approach is to use the SDN-cloud\nComputing-enabled multicast communication scheme with ultra-high bandwidth\nutilization. The bandwidth utilization is enhanced by measuring various routing\ntrees for each multicast transmission session and distributing the traffic load\nover all available routes in the cloud computing resources. The SDN is utilized\nto tackle with various design hurdles in the cloud computing, including both\nthe current ones with the conventional multicast pattern and the newly emerged\nones with multi-tree multicast. The prototype implementation and experiments\ndemonstrate the performance enhancement of the proposed approach in the cloud\ncomputing in compared to conventional single-tree multicast designs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 08:45:26 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Guha", "Sayantan", ""], ["Alshamrani", "Adel", ""]]}, {"id": "2008.02599", "submitter": "Jun Liu", "authors": "Jun Liu, Weitao Xu, Sanjay Jha, Wen Hu", "title": "Nephalai: Towards LPWAN C-RAN with Physical Layer Compression", "comments": "14 pages, 14 figures, Mobicom 2020", "journal-ref": null, "doi": "10.1145/3372224.3419193", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Nephalai, a Compressive Sensing-based Cloud Radio Access Network\n(C-RAN), to reduce the uplink bit rate of the physical layer (PHY) between the\ngateways and the cloud server for multi-channel LPWANs. Recent research shows\nthat single-channel LPWANs suffer from scalability issues. While multiple\nchannels improve these issues, data transmission is expensive. Furthermore,\nrecent research has shown that jointly decoding raw physical layers that are\noffloaded by LPWAN gateways in the cloud can improve the signal-to-noise ratio\n(SNR) of week radio signals. However, when it comes to multiple channels, this\napproach requires high bandwidth of network infrastructure to transport a large\namount of PHY samples from gateways to the cloud server, which results in\nnetwork congestion and high cost due to Internet data usage. In order to reduce\nthe operation's bandwidth, we propose a novel LPWAN packet acquisition\nmechanism based on Compressive Sensing with a custom design dictionary that\nexploits the structure of LPWAN packets, reduces the bit rate of samples on\neach gateway, and demodulates PHY in the cloud with (joint) sparse\napproximation. Moreover, we propose an adaptive compression method that takes\nthe Spreading Factor (SF) and SNR into account. Our empirical evaluation shows\nthat up to 93.7% PHY samples can be reduced by Nephalai when SF = 9 and SNR is\nhigh without degradation in the packet reception rate (PRR). With four\ngateways, 1.7x PRR can be achieved with 87.5% PHY samples compressed, which can\nextend the battery lifetime of embedded IoT devices to 1.7.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:09:47 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 00:57:27 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Liu", "Jun", ""], ["Xu", "Weitao", ""], ["Jha", "Sanjay", ""], ["Hu", "Wen", ""]]}, {"id": "2008.02608", "submitter": "Jihong Park", "authors": "Jihong Park, Sumudu Samarakoon, Anis Elgabli, Joongheon Kim, Mehdi\n  Bennis, Seong-Lyun Kim, M\\'erouane Debbah", "title": "Communication-Efficient and Distributed Learning Over Wireless Networks:\n  Principles and Applications", "comments": "20 pages, 14 figures; This article has been submitted to IEEE for\n  possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is a promising enabler for the fifth generation (5G)\ncommunication systems and beyond. By imbuing intelligence into the network\nedge, edge nodes can proactively carry out decision-making, and thereby react\nto local environmental changes and disturbances while experiencing zero\ncommunication latency. To achieve this goal, it is essential to cater for high\nML inference accuracy at scale under time-varying channel and network dynamics,\nby continuously exchanging fresh data and ML model updates in a distributed\nway. Taming this new kind of data traffic boils down to improving the\ncommunication efficiency of distributed learning by optimizing communication\npayload types, transmission techniques, and scheduling, as well as ML\narchitectures, algorithms, and data processing methods. To this end, this\narticle aims to provide a holistic overview of relevant communication and ML\nprinciples, and thereby present communication-efficient and distributed\nlearning frameworks with selected use cases.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:37:14 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Park", "Jihong", ""], ["Samarakoon", "Sumudu", ""], ["Elgabli", "Anis", ""], ["Kim", "Joongheon", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "2008.02666", "submitter": "Dmitry Bankov", "authors": "Evgeny Avdotin, Dmitry Bankov, Evgeny Khorov, Andrey Lyakhov", "title": "Enabling Massive Real-Time Applications in IEEE 802.11be Networks", "comments": null, "journal-ref": "2019 IEEE 30th Annual International Symposium on Personal, Indoor\n  and Mobile Radio Communications (PIMRC)", "doi": "10.1109/PIMRC.2019.8904271", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next generation Wi-Fi networks are expected to support real-time applications\nthat impose strict requirements on the packet transmission delay and packet\nloss ratio. Such applications form an essential target for the future Wi-Fi\nstandard, namely IEEE 802.11be, the development process of which started in\n2019. A promising way to provide efficient real-time communications in 802.11be\nnetworks requires some modification of the uplink OFDMA feature originally\nintroduced in the IEEE 802.11ax amendment to the Wi-Fi standard. This feature\nallows the access point to reserve channel resources for upcoming urgent\ntransmissions. The paper explains why uplink OFDMA random access of 802.11ax\ndoes not perfectly fit the requirements of real-time applications and proposes\nan easy-to-implement modification of the channel access rules for future\n802.11be networks. With extensive simulation, it is shown that this\nmodification together with a new resource allocation algorithm outperforms the\nexisting ways to support real-time applications, especially for a heavy load\nand a high number of users. In particular, they provide extremely low delays\nfor real-time traffic, while the throughput for non-real-time traffic is\nreduced insignificantly.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:57:05 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Avdotin", "Evgeny", ""], ["Bankov", "Dmitry", ""], ["Khorov", "Evgeny", ""], ["Lyakhov", "Andrey", ""]]}, {"id": "2008.02695", "submitter": "Jordan Holland", "authors": "Jordan Holland, Paul Schmitt, Nick Feamster, Prateek Mittal", "title": "New Directions in Automated Traffic Analysis", "comments": "18 pages, 9 tables, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the use of machine learning for many network traffic analysis tasks\nin security, from application identification to intrusion detection, the\naspects of the machine learning pipeline that ultimately determine the\nperformance of the model -- feature selection and representation, model\nselection, and parameter tuning -- remain manual and painstaking. This paper\npresents a method to automate many aspects of traffic analysis, making it\neasier to apply machine learning techniques to a wider variety of traffic\nanalysis tasks. We introduce nPrint, a tool that generates a unified packet\nrepresentation that is amenable for representation learning and model training.\nWe integrate nPrint with automated machine learning (AutoML), resulting in\nnPrintML, a public system that largely eliminates feature extraction and model\ntuning for a wide variety of traffic analysis tasks. We have evaluated nPrintML\non eight separate traffic analysis tasks and released nPrint, nPrintML and the\ncorresponding datasets from our evaluation to enable future work to extend\nthese methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 14:53:26 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 15:16:07 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 19:45:23 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 16:36:15 GMT"}, {"version": "v5", "created": "Thu, 13 May 2021 16:01:30 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Holland", "Jordan", ""], ["Schmitt", "Paul", ""], ["Feamster", "Nick", ""], ["Mittal", "Prateek", ""]]}, {"id": "2008.02697", "submitter": "Dmitry Bankov", "authors": "Dmitry Bankov, Evgeny Khorov, Andrey Lyakhov, Ekaterina Stepanova", "title": "Clock Drift Impact on Target Wake Time in IEEE 802.11ax/ah Networks", "comments": null, "journal-ref": "2018 Engineering and Telecommunication (EnT-MIPT)", "doi": "10.1109/EnT-MIPT.2018.00014", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Internet of Things scenarios, it is crucially important to provide low\nenergy consumption of client devices. To address this challenge, new Wi-Fi\nstandards introduce the Target Wake Time (TWT) mechanism. With TWT, devices\ntransmit their data according to a schedule and move to the doze state\nafterwards. The main problem of this mechanism is the clock drift phenomenon,\nbecause of which the devices cease to strictly comply with the schedule. As a\nresult, they can miss the scheduled transmission time, which increases active\ntime and thus power consumption. The paper investigates uplink transmission\nwith two different TWT operation modes. With the first mode, a sensor transmits\na packet to the access point (AP) after waking up, using the random channel\naccess. With the second mode, the AP polls stations and they can transmit a\npacket only after receiving a trigger frame from the AP. For both modes, the\npaper studies how the average transmission time, the packet loss rate and the\naverage energy consumption depend on the different TWT parameters. It is shown\nthat when configured to guarantee the given packet loss rate, the first mode\nprovides lower transmission time, while the second mode provides lower energy\nconsumption.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 14:58:55 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Bankov", "Dmitry", ""], ["Khorov", "Evgeny", ""], ["Lyakhov", "Andrey", ""], ["Stepanova", "Ekaterina", ""]]}, {"id": "2008.02701", "submitter": "Dmitry Bankov", "authors": "Dmitry Bankov, Evgeny Khorov, Andrey Lyakhov, Mark Sandal", "title": "Enabling Low Latency Communications in Wi-Fi Networks", "comments": null, "journal-ref": "2018 IEEE 29th Annual International Symposium on Personal, Indoor\n  and Mobile Radio Communications (PIMRC)", "doi": "10.1109/PIMRC.2018.8580914", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra Reliable Low Latency Communications (URLLC) is an important challenge\nfor the next generation wireless networks, which poses very strict requirements\nto the delay and packet loss ratio. Satisfaction is hardly possible without\nintroducing additional functionality to the existing communication\ntechnologies. In the paper, we propose and study an approach to enable URLLC in\nWi-Fi networks by exploiting an additional radio similar to that of IEEE\n802.11ba. With extensive simulation, we show that our approach allows\ndecreasing the delay by orders of magnitude, while the throughput of non-URLLC\ndevices is reduced insignificantly.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:09:39 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Bankov", "Dmitry", ""], ["Khorov", "Evgeny", ""], ["Lyakhov", "Andrey", ""], ["Sandal", "Mark", ""]]}, {"id": "2008.02752", "submitter": "Chavoosh Ghasemi", "authors": "Chavoosh Ghasemi and Hamed Yousefi and Beichuan Zhang", "title": "Internet-Scale Video Streaming over NDN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in Information-Centric Networking (ICN) and Named Data Networking\n(NDN) has produced many protocol designs and software prototypes, but they need\nto be validated and evaluated by real usage on the Internet, which is also\ncritical to the realization of the ICN/NDN vision in the long-run. This paper\npresents the first Internet-scale adaptive video streaming service over NDN,\nwhich allows regular users to watch videos using NDN technology with no\nsoftware installation or manual configuration. Since mid-2019, the official NDN\nwebsite has started using our service to deliver its videos to Internet users\nover the global NDN testbed, showcasing the feasibility of NDN. We conduct\nreal-world experiments on the NDN testbed to validate the proper implementation\nof the client, network, and server sides of the proposed system and also\nevaluate the performance of our video streaming service.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:37:52 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Ghasemi", "Chavoosh", ""], ["Yousefi", "Hamed", ""], ["Zhang", "Beichuan", ""]]}, {"id": "2008.02815", "submitter": "Adrian Garcia-Rodriguez", "authors": "Adrian Garcia-Rodriguez, David Lopez-Perez, Lorenzo Galati-Giordano,\n  Giovanni Geraci", "title": "IEEE 802.11be: Wi-Fi 7 Strikes Back", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As hordes of data-hungry devices challenge its current capabilities, Wi-Fi\nstrikes back with 802.11be, alias Wi-Fi 7. This brand-new amendment promises a\n(r)evolution of unlicensed wireless connectivity as we know it. With its\nstandardisation process being consolidated, we provide an updated digest of\n802.11be essential features, vouching for multi-AP coordination as a must-have\nfor critical and latency-sensitive applications. We then get down to the\nnitty-gritty of one of its most enticing implementations-coordinated\nbeamforming-, for which our standard-compliant simulations confirm near-tenfold\nreductions in worst-case delays.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 18:00:10 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Garcia-Rodriguez", "Adrian", ""], ["Lopez-Perez", "David", ""], ["Galati-Giordano", "Lorenzo", ""], ["Geraci", "Giovanni", ""]]}, {"id": "2008.02988", "submitter": "Tao Yu", "authors": "Tao Yu, Shunqing Zhang, Xiaojing Chen, Shugong Xu", "title": "An Analytical Framework for Delay Optimal Mobile Edge Deployment in\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging edge caching provides an effective way to reduce service delay\nfor mobile users. However, due to high deployment cost of edge hosts, a\npractical problem is how to achieve minimum delay under a proper edge\ndeployment strategy. In this letter, we provide an analytical framework for\ndelay optimal mobile edge deployment in a partially connected wireless network,\nwhere the request files can be cached at the edge hosts and cooperatively\ntransmitted through multiple base stations. In order to deal with the\nheterogeneous transmission requirements, we separate the entire transmission\ninto backhaul and wireless phases, and propose average user normalized delivery\ntime (AUNDT) as the performance metric. On top of that, we characterize the\ntrade-off relations between the proposed AUNDT and other network deployment\nparameters. Using the proposed analytical framework, we are able to provide the\noptimal mobile edge deployment strategy in terms of AUNDT, which provides a\nuseful guideline for future mobile edge deployment.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 04:35:18 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Yu", "Tao", ""], ["Zhang", "Shunqing", ""], ["Chen", "Xiaojing", ""], ["Xu", "Shugong", ""]]}, {"id": "2008.03066", "submitter": "Babar Shahzaad", "authors": "Babar Shahzaad, Athman Bouguettaya, Sajib Mistry", "title": "A Game-Theoretic Drone-as-a-Service Composition for Delivery", "comments": "5 pages, 3 figures. This is an accepted paper and it is going to\n  appear in the Proceedings of the 2020 IEEE International Conference on Web\n  Services (IEEE ICWS 2020) affiliated with the 2020 IEEE World Congress on\n  Services (IEEE SERVICES 2020), Beijing, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel game-theoretic approach for drone service composition\nconsidering recharging constraints. We design a non-cooperative game model for\ndrone services. We propose a non-cooperative game algorithm for the selection\nand composition of optimal drone services. We conduct several experiments on a\nreal drone dataset to demonstrate the efficiency of our proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 09:58:58 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Shahzaad", "Babar", ""], ["Bouguettaya", "Athman", ""], ["Mistry", "Sajib", ""]]}, {"id": "2008.03075", "submitter": "Ehsan Mohammadpour", "authors": "Ehsan Mohammadpour, Jean-Yves Le Boudec", "title": "On Packet Reordering in Time-Sensitive Networks", "comments": "24 pages, 8 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-sensitive networks (IEEE TSN or IETF DetNet) may tolerate some packet\nreordering. Re-sequencing buffers are then used to provide in-order delivery,\nthe parameters of which (timeout, buffer size) may affect worst-case delay and\ndelay jitter. There is so far no precise understanding of per-flow reordering\nmetrics nor of the dimensioning of re-sequencing buffers in order to provide\nworst-case guarantees, as required in such networks. First, we show that a\npreviously proposed per-flow metric, reordering late time offset (RTO),\ndetermines the timeout value. If the network is lossless, another previously\ndefined metric, the reordering byte offset (RBO), determines the required\nbuffer. If packet losses cannot be ignored, the required buffer may be larger\nthan RBO, and depends on jitter, an arrival curve of the flow at its source,\nand the timeout. Then we develop a calculus to compute the RTO for a flow path;\nthe method uses a novel relation with jitter and arrival curve, together with a\ndecomposition of the path into non order-preserving and order-preserving\nelements. We also analyse the effect of re-sequencing buffers on worst-case\ndelay, jitter and propagation of arrival curves. We show in particular that, in\na lossless (but non order-preserving) network, re-sequencing is \"for free\",\nnamely, it does not increase worst-case delay nor jitter, whereas in a lossy\nnetwork, re-sequencing increases the worst-case delay and jitter. We apply the\nanalysis to evaluate the performance impact of placing re-sequencing buffers at\nintermediate points and illustrate the results on two industrial test cases.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:27:54 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 12:14:29 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 08:23:54 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 09:35:40 GMT"}, {"version": "v5", "created": "Tue, 27 Apr 2021 11:14:11 GMT"}, {"version": "v6", "created": "Mon, 21 Jun 2021 08:26:03 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Mohammadpour", "Ehsan", ""], ["Boudec", "Jean-Yves Le", ""]]}, {"id": "2008.03140", "submitter": "Dmitry Bankov", "authors": "Dmitry Bankov, Evgeny Khorov, Andrey Lyakhov", "title": "Mathematical model of LoRaWAN channel access with capture effect", "comments": "arXiv admin note: text overlap with arXiv:2004.07645", "journal-ref": "2017 IEEE 28th Annual International Symposium on Personal, Indoor,\n  and Mobile Radio Communications (PIMRC)", "doi": "10.1109/PIMRC.2017.8292748", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LoRaWAN is a promising low power long range wireless communications\ntechnology for the Internet of Things. An important feature of LoRaWAN gateways\nis related to so-called capture effect: under some conditions the gateway may\ncorrectly receive a frame even if it overlaps with other ones. In this paper,\nwe develop a pioneering mathematical model of a LoRaWAN network which allows\nfinding network capacity and transmission reliability taking into account the\ncapture effect.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 14:42:24 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Bankov", "Dmitry", ""], ["Khorov", "Evgeny", ""], ["Lyakhov", "Andrey", ""]]}, {"id": "2008.03210", "submitter": "Abhishek Kulkarni", "authors": "Abhishek N. Kulkarni and Jie Fu", "title": "A Theory of Hypergames on Graphs for Synthesizing Dynamic Cyber Defense\n  with Deception", "comments": "32 pages, 10 figures, 2 tables, Accepted Book Chapter in \"Game Theory\n  and Machine Learning for Cyber Security\" by Wiley-IEEE press, Editors:\n  Charles A. Kamhoua, Christopher D. Kiekintveld, Fei Fang, Quanyan Zhu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we present an approach using formal methods to synthesize\nreactive defense strategy in a cyber network, equipped with a set of decoy\nsystems. We first generalize formal graphical security models--attack\ngraphs--to incorporate defender's countermeasures in a game-theoretic model,\ncalled an attack-defend game on graph. This game captures the dynamic\ninteractions between the defender and the attacker and their defense/attack\nobjectives in formal logic. Then, we introduce a class of hypergames to model\nasymmetric information created by decoys in the attacker-defender interactions.\nGiven qualitative security specifications in formal logic, we show that the\nsolution concepts from hypergames and reactive synthesis in formal methods can\nbe extended to synthesize effective dynamic defense strategy using cyber\ndeception. The strategy takes the advantages of the misperception of the\nattacker to ensure security specification is satisfied, which may not be\nsatisfiable when the information is symmetric.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 14:59:28 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Kulkarni", "Abhishek N.", ""], ["Fu", "Jie", ""]]}, {"id": "2008.03252", "submitter": "Abdulmalik Alwarafy", "authors": "Abdulmalik Alwarafy, Khaled A. Al-Thelaya, Mohamed Abdallah (Senior\n  Member, IEEE), Jens Schneider, and Mounir Hamdi (Fellow Member, IEEE)", "title": "A Survey on Security and Privacy Issues in Edge Computing-Assisted\n  Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is an innovative paradigm envisioned to provide\nmassive applications that are now part of our daily lives. Millions of smart\ndevices are deployed within complex networks to provide vibrant functionalities\nincluding communications, monitoring, and controlling of critical\ninfrastructures. However, this massive growth of IoT devices and the\ncorresponding huge data traffic generated at the edge of the network created\nadditional burdens on the state-of-the-art centralized cloud computing paradigm\ndue to the bandwidth and resources scarcity. Hence, edge computing (EC) is\nemerging as an innovative strategy that brings data processing and storage near\nto the end users, leading to what is called EC-assisted IoT. Although this\nparadigm provides unique features and enhanced quality of service (QoS), it\nalso introduces huge risks in data security and privacy aspects. This paper\nconducts a comprehensive survey on security and privacy issues in the context\nof EC-assisted IoT. In particular, we first present an overview of EC-assisted\nIoT including definitions, applications, architecture, advantages, and\nchallenges. Second, we define security and privacy in the context of\nEC-assisted IoT. Then, we extensively discuss the major classifications of\nattacks in EC-assisted IoT and provide possible solutions and countermeasures\nalong with the related research efforts. After that, we further classify some\nsecurity and privacy issues as discussed in the literature based on security\nservices and based on security objectives and functions. Finally, several open\nchallenges and future research directions for secure EC-assisted IoT paradigm\nare also extensively provided.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 20:24:55 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Alwarafy", "Abdulmalik", "", "Senior\n  Member, IEEE"], ["Al-Thelaya", "Khaled A.", "", "Senior\n  Member, IEEE"], ["Abdallah", "Mohamed", "", "Senior\n  Member, IEEE"], ["Schneider", "Jens", "", "Fellow Member, IEEE"], ["Hamdi", "Mounir", "", "Fellow Member, IEEE"]]}, {"id": "2008.03254", "submitter": "Kyle MacMillan", "authors": "Kyle MacMillan, Jordan Holland, Prateek Mittal", "title": "Evaluating Snowflake as an Indistinguishable Censorship Circumvention\n  Tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tor is the most well-known tool for circumventing censorship. Unfortunately,\nTor traffic has been shown to be detectable using deep-packet inspection.\nWebRTC is a popular web frame-work that enables browser-to-browser connections.\nSnowflake is a novel pluggable transport that leverages WebRTC to connect Tor\nclients to the Tor network. In theory, Snowflake was created to be\nindistinguishable from other WebRTC services. In this paper, we evaluate the\nindistinguishability of Snowflake. We collect over 6,500 DTLS handshakes from\nSnowflake, Facebook Messenger, Google Hangouts, and Discord WebRTC connections\nand show that Snowflake is identifiable among these applications with 100%\naccuracy. We show that several features, including the extensions offered and\nthe number of packets in the handshake, distinguish Snowflake among these\nservices. Finally, we suggest recommendations for improving identification\nresistance in Snowflake. We have made the dataset publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 17:36:22 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 21:57:38 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 15:08:49 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["MacMillan", "Kyle", ""], ["Holland", "Jordan", ""], ["Mittal", "Prateek", ""]]}, {"id": "2008.03297", "submitter": "MohammadNoor Injadat", "authors": "MohammadNoor Injadat, Abdallah Moubayed, Ali Bou Nassif, Abdallah\n  Shami", "title": "Multi-Stage Optimized Machine Learning Framework for Network Intrusion\n  Detection", "comments": "14 Pages, 13 Figures, 4 tables, Published IEEE Transactions on\n  Network and Service Management ( Early Access )", "journal-ref": "Electronic ISSN: 1932-4537", "doi": "10.1109/TNSM.2020.3014929", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-security garnered significant attention due to the increased dependency\nof individuals and organizations on the Internet and their concern about the\nsecurity and privacy of their online activities. Several previous machine\nlearning (ML)-based network intrusion detection systems (NIDSs) have been\ndeveloped to protect against malicious online behavior. This paper proposes a\nnovel multi-stage optimized ML-based NIDS framework that reduces computational\ncomplexity while maintaining its detection performance. This work studies the\nimpact of oversampling techniques on the models' training sample size and\ndetermines the minimal suitable training sample size. Furthermore, it compares\nbetween two feature selection techniques, information gain and\ncorrelation-based, and explores their effect on detection performance and time\ncomplexity. Moreover, different ML hyper-parameter optimization techniques are\ninvestigated to enhance the NIDS's performance. The performance of the proposed\nframework is evaluated using two recent intrusion detection datasets, the\nCICIDS 2017 and the UNSW-NB 2015 datasets. Experimental results show that the\nproposed model significantly reduces the required training sample size (up to\n74%) and feature set size (up to 50%). Moreover, the model performance is\nenhanced with hyper-parameter optimization with detection accuracies over 99%\nfor both datasets, outperforming recent literature works by 1-2% higher\naccuracy and 1-2% lower false alarm rate.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:18:00 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Moubayed", "Abdallah", ""], ["Nassif", "Ali Bou", ""], ["Shami", "Abdallah", ""]]}, {"id": "2008.03299", "submitter": "Steve Huntsman", "authors": "Steve Huntsman, Jimmy Palladino, Michael Robinson", "title": "Topology in cyber research", "comments": "29 pages. arXiv admin note: text overlap with arXiv:1607.06022", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.NI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an idiosyncratic overview of applications of topology to cyber\nresearch, spanning the analysis of variables/assignments and control flow in\ncomputer programs, a brief sketch of topological data analysis in one\ndimension, and the use of sheaves to analyze wireless networks.\n  The text is from a chapter in the forthcoming book Mathematics in Cyber\nResearch, to be published by Taylor and Francis.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 02:38:47 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Huntsman", "Steve", ""], ["Palladino", "Jimmy", ""], ["Robinson", "Michael", ""]]}, {"id": "2008.03453", "submitter": "Mahdi Zaman", "authors": "Md Saifuddin, Mahdi Zaman, Behrad Toghi, Yaser P Fallah, Jayanthi Rao", "title": "Performance Analysis of Cellular-V2X with Adaptive and Selective Power\n  Control", "comments": "7 pages, 7 figures, accepted in IEEE CAVS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LTE based Cellular Vehicle-To-Everything (C-V2X) allows vehicles to\ncommunicate with each other directly without the need for infrastructure and is\nexpected to be a critical enabler for connected and autonomous vehicles. V2X\ncommunication based safety applications are built on periodic broadcast of\nbasic safety messages with vehicle state information. Vehicles use this\ninformation to identify collision threats and take appropriate countermeasures.\nAs the vehicle density increases, these broadcasts can congest the\ncommunication channel resulting in increased packet loss; fundamentally\nimpacting the ability to identify threats in a timely manner. To address this\nissue, it is important to incorporate a congestion control mechanism.\nCongestion management scheme based on rate and power control has proved to be\neffective for DSRC. In this paper, we investigate the suitability of similar\ncongestion control to C-V2X with particular focus on transmit power control. In\nour evaluation, we include periodic basic safety messages and high priority\nevent messages that are generated when an event such as hard braking occurs.\nOur study reveals that while power control does not improve packet delivery\nperformance of basic safety messages, it is beneficial to high priority event\nmessage delivery. In this paper, we investigate the reasons for this behavior\nusing simulations and analysis.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 06:14:19 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Saifuddin", "Md", ""], ["Zaman", "Mahdi", ""], ["Toghi", "Behrad", ""], ["Fallah", "Yaser P", ""], ["Rao", "Jayanthi", ""]]}, {"id": "2008.03497", "submitter": "Jaafar Elmirghani", "authors": "Sanaa Hamid Mohamed, Ali Hammadi, Taisir E.H. El-Gorashi, Jaafar\n  Mohamed Hashim Elmirghani", "title": "Optimizing Co-flows Scheduling and Routing in Data Centre Networks for\n  Big Data Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper optimizes the scheduling and routing of the co-flows of MapReduce\nshuffling phase in state-of-the-art and proposed Passive Optical Networking\n(PON)-based Data Centre Network (DCN) architectures. A time-slotted Mixed\nInteger Linear Programming (MILP) model is developed and used for the\noptimization with the objective of minimizing either the total energy\nconsumption or the completion time. The DCN architectures include four\nstate-of-the-art electronic switching architectures which are spine-leaf,\nFat-tree, BCube, and DCell data centres. The proposed PON-based DCN\narchitectures include two designs that utilize ports in Optical Line Terminal\n(OLT) line cards for inter and possibly intra data centre networking in\naddition to passive interconnects for the intra data centre networking between\ndifferent PON groups (i.e. racks) within a PON cell (i.e. number of PON groups\nconnected to a single OLT port). The first design is a switch-centric design\nthat uses two Arrayed Waveguide Grating Routers (AWGRs) and the second is a\nserver-centric design. The study also considers different traffic patterns\ndefined according to the distribution of map and reduce tasks in the servers\nand data skewness.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 11:32:09 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mohamed", "Sanaa Hamid", ""], ["Hammadi", "Ali", ""], ["El-Gorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar Mohamed Hashim", ""]]}, {"id": "2008.03677", "submitter": "Mohammad Hashemi", "authors": "Mohammad J. Hashemi, Eric Keller", "title": "Enhancing Robustness Against Adversarial Examples in Network Intrusion\n  Detection Systems", "comments": "Submitted to 6th IEEE Conference on Network Functions Virtualization\n  and Software Defined Networks (IEEE NFV-SDN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase of cyber attacks in both the numbers and varieties in recent\nyears demands to build a more sophisticated network intrusion detection system\n(NIDS). These NIDS perform better when they can monitor all the traffic\ntraversing through the network like when being deployed on a Software-Defined\nNetwork (SDN). Because of the inability to detect zero-day attacks,\nsignature-based NIDS which were traditionally used for detecting malicious\ntraffic are beginning to get replaced by anomaly-based NIDS built on neural\nnetworks. However, recently it has been shown that such NIDS have their own\ndrawback namely being vulnerable to the adversarial example attack. Moreover,\nthey were mostly evaluated on the old datasets which don't represent the\nvariety of attacks network systems might face these days. In this paper, we\npresent Reconstruction from Partial Observation (RePO) as a new mechanism to\nbuild an NIDS with the help of denoising autoencoders capable of detecting\ndifferent types of network attacks in a low false alert setting with an\nenhanced robustness against adversarial example attack. Our evaluation\nconducted on a dataset with a variety of network attacks shows denoising\nautoencoders can improve detection of malicious traffic by up to 29% in a\nnormal setting and by up to 45% in an adversarial setting compared to other\nrecently proposed anomaly detectors.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 07:04:06 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hashemi", "Mohammad J.", ""], ["Keller", "Eric", ""]]}, {"id": "2008.03990", "submitter": "He Huang", "authors": "He Huang, Su Hu, Chaowei Yuan", "title": "Cooperative Communications for Internet of Everything in B5G/6G Hybrid\n  and Ubiquitous Networks: Foundation, Further Optimization and Solutions", "comments": "This paper has some flaws that should be modified, so we want to\n  withdraw it firstly!", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cooperative Communications (CC) has been one of most critical communication\ntechnologies which plays a founding role on Internet of Everything in B5G/6G\nnetworks. As 5G communications standard is gradually established recently, core\ncommunications technologies with CC are further studied to significantly\nimprove communication quality and develop new communications scenarios for\nB5G/6G ubiquitous networks. Considering that CC has been regarded as foundation\ntheory which widely exists in future multiple B5G/6G hybrid scenarios, such as,\nCognitive Internet of Things (CIOT) networks, UAVs communications,\nair-space-ground of integrated networks, underwater acoustic communication and\nso on, besides it is closely combined with other key technologies, for\nexamples, Massive MIMO, NOMA, Full-duplex transmission, Polar code and so on.\nHence, in this paper we review foundation of CC for Internet of Everything in\nB5G/6G multiple heterogeneous CC networks, and compare fundamental CC\nalgorithms to reveal key of performance improvement. Furthermore we propose\nthat collective communications ideology is theory of foundation to realize\ncommunications for arbitrary two points as source/destination devices, sensors,\nrelays, IOT nodes and so on in future.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:43:04 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 07:38:08 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 13:19:06 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Huang", "He", ""], ["Hu", "Su", ""], ["Yuan", "Chaowei", ""]]}, {"id": "2008.04004", "submitter": "Jaafar Elmirghani", "authors": "Barzan A. Yosuf, Amal A. Alahmadi, T. E. H. El-Gorashi and Jaafar M.\n  H. Elmirghani", "title": "Cloud Fog Architectures in 6G Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior to the advent of the cloud, storage and processing services were\naccommodated by specialized hardware, however, this approach introduced a\nnumber of challenges in terms of scalability, energy efficiency, and cost. Then\ncame the concept of cloud computing, where to some extent, the issue of massive\nstorage and computation was dealt with by centralized data centers that are\naccessed via the core network. The cloud has remained with us thus far,\nhowever, this has introduced further challenges among which, latency and energy\nefficiency are of the pinnacle. With the increase in embedded devices\nintelligence came the concept of the Fog. The availability of massive numbers\nof storage and computational devices at the edge of the network, where some are\nowned and deployed by the end-users themselves but most by service operators.\nThis means that cloud services are pushed further out from the core towards the\nedge of the network, hence reduced latency is achieved. Fog nodes are massively\ndistributed in the network, some benefit from wired connections, and others are\nconnected via wireless links. The question of where to allocate services\nremains an important task and requires extensive attention. This chapter\nintroduces and evaluates cloud fog architectures in 6G networks paying special\nattention to latency, energy efficiency, scalability, and the trade-offs\nbetween distributed and centralized processing resources.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 10:15:40 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Yosuf", "Barzan A.", ""], ["Alahmadi", "Amal A.", ""], ["El-Gorashi", "T. E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2008.04028", "submitter": "Pedro Henrique Juliano Nardelli", "authors": "Chris Giotitsas, Pedro H. J. Nardelli, Vasilis Kostakis, Arun\n  Narayanan", "title": "From private to public governance: The case for reconfiguring energy\n  systems as a commons", "comments": "Accepted to publication at Energy Research & Social Science\n  (Elsevier)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discussions around the unsustainability of the dominant socio-economic\nstructures have yet to produce solutions to address the escalating problems we\nface as a species. Such discussions, this paper argues, are hindered by the\nlimited scope of the proposed solutions within a business-as-usual context as\nwell as by the underlying technological rationale upon which these solutions\nare developed. In this paper, we conceptualize a radical sustainable\nalternative to the energy conundrum based on an emerging mode of production and\na commons-based political economy. We propose a commons-oriented Energy\nInternet as a potential system for energy production and consumption, which may\nbe better suited to tackle the current issues society faces. We conclude by\nreferring to some of the challenges that the implementation of such a proposal\nwould entail.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 11:13:44 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Giotitsas", "Chris", ""], ["Nardelli", "Pedro H. J.", ""], ["Kostakis", "Vasilis", ""], ["Narayanan", "Arun", ""]]}, {"id": "2008.04088", "submitter": "Luc Le Magoarou", "authors": "Taha Yassine (IRT b-com, Hypermedia), Luc Le Magoarou (IRT b-com,\n  Hypermedia)", "title": "mpNet: variable depth unfolded neural network for massive MIMO channel\n  estimation", "comments": "arXiv admin note: text overlap with arXiv:2004.14615", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive MIMO communication systems have a huge potential both in terms of\ndata rate and energy efficiency, although channel estimation becomes\nchallenging for a large number of antennas. Using a physical model allows to\nease the problem by injecting a priori information based on the physics of\npropagation. However, such a model rests on simplifying assumptions and\nrequires to know precisely the configuration of the system, which is\nunrealistic in practice. In this paper we present mpNet, an unfolded neural\nnetwork specifically designed for massive MIMO channel estimation. It is\ntrained online in an unsupervised way. Moreover, mpNet is computationally\nefficient and automatically adapts its depth to the SNR. The method we propose\nadds flexibility to physical channel models by allowing a base station to\nautomatically correct its channel estimation algorithm based on incoming data,\nwithout the need for a separate offline training phase. It is applied to\nrealistic millimeter wave channels and shows great performance, achieving a\nchannel estimation error almost as low as one would get with a perfectly\ncalibrated system. It also allows incident detection and automatic correction,\nmaking the base station resilient and able to automatically adapt to changes in\nits environment.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:23:44 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 11:44:11 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Yassine", "Taha", "", "IRT b-com, Hypermedia"], ["Magoarou", "Luc Le", "", "IRT b-com,\n  Hypermedia"]]}, {"id": "2008.04105", "submitter": "Dagnachew Azene Temesgene", "authors": "Dagnachew Azene Temesgene, Marco Miozzo, Deniz G\\\"und\\\"uz and Paolo\n  Dini", "title": "Distributed Deep Reinforcement Learning for Functional Split Control in\n  Energy Harvesting Virtualized Small Cells", "comments": "Submitted to IEEE transaction on sustainable computing. arXiv admin\n  note: text overlap with arXiv:1906.05735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To meet the growing quest for enhanced network capacity, mobile network\noperators (MNOs) are deploying dense infrastructures of small cells. This, in\nturn, increases the power consumption of mobile networks, thus impacting the\nenvironment. As a result, we have seen a recent trend of powering mobile\nnetworks with harvested ambient energy to achieve both environmental and cost\nbenefits. In this paper, we consider a network of virtualized small cells\n(vSCs) powered by energy harvesters and equipped with rechargeable batteries,\nwhich can opportunistically offload baseband (BB) functions to a grid-connected\nedge server depending on their energy availability. We formulate the\ncorresponding grid energy and traffic drop rate minimization problem, and\npropose a distributed deep reinforcement learning (DDRL) solution. Coordination\namong vSCs is enabled via the exchange of battery state information. The\nevaluation of the network performance in terms of grid energy consumption and\ntraffic drop rate confirms that enabling coordination among the vSCs via\nknowledge exchange achieves a performance close to the optimal. Numerical\nresults also confirm that the proposed DDRL solution provides higher network\nperformance, better adaptation to the changing environment, and higher cost\nsavings with respect to a tabular multi-agent reinforcement learning (MRL)\nsolution used as a benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:27:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Temesgene", "Dagnachew Azene", ""], ["Miozzo", "Marco", ""], ["G\u00fcnd\u00fcz", "Deniz", ""], ["Dini", "Paolo", ""]]}, {"id": "2008.04128", "submitter": "Junchen Jiang", "authors": "Junchen Jiang, Siddhartha Sen", "title": "A New Abstraction for Internet QoE Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A perennial quest in networking research is how to achieve higher quality of\nexperience (QoE) for users without incurring more resources. This work revisits\nan important yet often overlooked piece of the puzzle: what should the QoE\nabstraction be? A QoE abstraction is a representation of application quality\nthat describes how decisions affect QoE. The conventional wisdom has relied on\ndeveloping hand-crafted quality metrics (e.g., video rebuffering events, web\npage loading time) that are specialized to each application, content, and\nsetting. We argue that in many cases, it maybe fundamentally hard to capture a\nuser's perception of quality using a list of handcrafted metrics, and that\nexpanding the metric list may lead to unnecessary complexity in the QoE model\nwithout a commensurate gain. Instead, we advocate for a new approach based on a\nnew QoE abstraction called visual rendering. Rather than a list of metrics, we\nmodel the process of quality perception as a user watching a continuous \"video\"\n(visual rendering) of all the pixels on their screen. The key advantage of\nvisual rendering is that it captures the full experience of a user with the\nsame abstraction for all applications. This new abstraction opens new\nopportunities (e.g., the possibility of end-to-end deep learning models that\ninfer QoE directly from a visual rendering) but it also gives rise to new\nresearch challenges (e.g., how to emulate the effect on visual rendering of an\napplication decision). This paper makes the case for visual rendering as a\nunifying abstraction for Internet QoE and outlines a new research agenda to\nunleash its opportunities.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:40:57 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Jiang", "Junchen", ""], ["Sen", "Siddhartha", ""]]}, {"id": "2008.04454", "submitter": "Jarallah Alqahtani", "authors": "Jarallah Alqahtani, Bechir Hamdaoui", "title": "Bert: Scalable Source Routed Multicast for Cloud Data Centers", "comments": null, "journal-ref": "IEEE IWCMC 1752--1757 (2020)", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional IP multicast routing is not suitable for cloud data center (DC)\nnetworks due to the need for supporting large numbers of groups with large\ngroup sizes. State-of-the-art DC multicast routing approaches aim to overcome\nthe scalability issues by, for instance, taking advantage of the symmetry of DC\ntopologies and the programmability of DC switches to compactly encode multicast\ngroup information inside packets, thereby reducing the overhead resulting from\nthe need to store the states of flows at the network switches. However,\nalthough these scale well with the number of multicast groups, they do not do\nso with group sizes, and as a result, they yield substantial traffic control\noverhead and network congestion. In this paper, we present Bert, a scalable,\nsource-initiated DC multicast routing approach that scales well with both the\nnumber and the size of multicast groups, and does so through clustering, by\ndividing the members of the multicast group into a set of clusters with each\ncluster employing its own forwarding rules. Compared to the state-of-the-art\napproach, Bert yields much lesser traffic control overhead by significantly\nreducing the packet header sizes and the number of extra packet transmissions,\nresulting from the need for compacting forwarding rules across the switches.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 23:30:52 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Alqahtani", "Jarallah", ""], ["Hamdaoui", "Bechir", ""]]}, {"id": "2008.04601", "submitter": "Keyang Liu", "authors": "Keyang Liu, Yukio Ohsawa", "title": "Improving Blockchain scalability based on one-time cross-chain contract\n  and gossip network", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a novel solution that provides secure interoperability\nfor blockchains, which improves the overall scalability of the whole blockchain\nnetwork. In our solution, a cross-chain task will build a one-time\ncross-blockchain contract. Each blockchain system can follow the contract to\ncomplete or this task. The result of tasks is bound with the system, hence can\nbe anchored to all other blockchain systems through the gossip network. This\nwork shows our result can provide linear scalability for the whole system and\nachieve consistency among honest systems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 09:35:14 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 15:32:56 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Liu", "Keyang", ""], ["Ohsawa", "Yukio", ""]]}, {"id": "2008.04651", "submitter": "Feng Xia", "authors": "Behrouz Jedari, Feng Xia, Zhaolong Ning", "title": "A Survey on Human-centric Communications in Non-cooperative Wireless\n  Relay Networks", "comments": "31 pages, 9 figures", "journal-ref": "IEEE Communications Surveys & Tutorials, 20(2): 914-944, 2018", "doi": "10.1109/COMST.2018.2791428", "report-no": null, "categories": "cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of data delivery in wireless relay networks (WRNs), such as\ndelay-tolerant networks and device-to-device communications heavily relies on\nthe cooperation of mobile nodes (i.e., users and their carried devices).\nHowever, selfish nodes may refuse to relay data to others or share their\nresources with them due to various reasons, such as resource limitations or\nsocial preferences. Meanwhile, misbehaving nodes can launch different types of\ninternal attacks (e.g., blackhole and trust-related attacks) to disrupt the\nnormal operation of the network. Numerous mechanisms have been recently\nproposed to establish secure and efficient communications in WRNs in the\npresence of selfish and malicious nodes (referred as non-cooperative WRNs). In\nthis paper, we present an in-depth survey on human-centric communication\nchallenges and solutions in the non-cooperative WRNs that focuses on: (1) an\noverview of the non-cooperative WRNs and introduction to various types of node\nselfish and malicious behaviors, (2) the impact analysis of node selfish and\nmalicious behaviors on the performance of data forwarding and distribution, (3)\nselfish and malicious node detection and defense systems, and (4) incentive\nmechanisms. Finally, we discuss several open problems and future research\nchallenges.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:43:08 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Jedari", "Behrouz", ""], ["Xia", "Feng", ""], ["Ning", "Zhaolong", ""]]}, {"id": "2008.04654", "submitter": "Feng Xia", "authors": "Feng Xia, Li Liu, Behrouz Jedari, and Sajal K. Das", "title": "PIS: A Multi-dimensional Routing Protocol for Socially-aware Networking", "comments": "13 pages, 13 figures", "journal-ref": "IEEE Transactions on Mobile Computing, 15(11): 2825-2836, 2016", "doi": "10.1109/TMC.2016.2517649", "report-no": null, "categories": "cs.SI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Socially-aware networking is an emerging paradigm for intermittently\nconnected networks consisting of mobile users with social relationships and\ncharacteristics. In this setting, humans are the main carriers of mobile\ndevices. Hence, their connections, social features, and behaviors can be\nexploited to improve the performance of data forwarding protocols. In this\npaper, we first explore the impact of three social features, namely physical\nproximity, user interests, and social relationship on users' daily routines.\nThen, we propose a multi-dimensional routing protocol called\nProximity-Interest-Social (PIS) protocol in which the three different social\ndimensions are integrated into a unified distance function in order to select\noptimal intermediate data carriers. PIS protocol utilizes a time slot\nmanagement mechanism to discover users' movement similarities in different time\nperiods during a day. We compare the performance of PIS to Epidemic, PROPHET,\nand SimBet routing protocols using SIGCOMM09 and INFOCOM06 data sets. The\nexperiment results show that PIS outperforms other benchmark routing protocols\nwith the highest data delivery ratio with a low communication overhead.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:44:47 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Xia", "Feng", ""], ["Liu", "Li", ""], ["Jedari", "Behrouz", ""], ["Das", "Sajal K.", ""]]}, {"id": "2008.04687", "submitter": "Junchen Jiang", "authors": "Xu Zhang, Yiyang Ou, Siddhartha Sen, Junchen Jiang", "title": "SENSEI: Aligning Video Streaming Quality with Dynamic User Sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to improve video streaming by leveraging a simple\nobservation: users are more sensitive to low quality in certain parts of a\nvideo than in others. For instance, rebuffering during key moments of a sports\nvideo (e.g., before a goal is scored) is more annoying than rebuffering during\nnormal gameplay. Such dynamic quality sensitivity, however, is rarely captured\nby current approaches, which predict QoE (quality-of-experience) using\none-size-fits-all heuristics that are too simplistic to understand the nuances\nof video content. Instead of proposing yet another heuristic, we take a\ndifferent approach: we run a separate crowdsourcing experiment for each video\nto derive users' quality sensitivity at different parts of the video. Of\ncourse, the cost of doing this at scale can be prohibitive, but we show that\ncareful experiment design combined with a suite of pruning techniques can make\nthe cost negligible compared to how much content providers invest in content\ngeneration and distribution. Our ability to accurately profile time-varying\nuser sensitivity inspires a new approach: dynamically aligning higher (lower)\nquality with higher (lower) sensitivity periods. We present a new video\nstreaming system called SENSEI that incorporates dynamic quality sensitivity\ninto existing quality adaptation algorithms. We apply SENSEI to two\nstate-of-the-art adaptation algorithms. SENSEI can take seemingly unusual\nactions: e.g., lowering bitrate (or initiating a rebuffering event) even when\nbandwidth is sufficient so that it can maintain a higher bitrate without\nrebuffering when quality sensitivity becomes higher in the near future.\nCompared to state-of-the-art approaches, SENSEI improves QoE by 15.1% or\nachieves the same QoE with 26.8% less bandwidth on average.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 13:18:29 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhang", "Xu", ""], ["Ou", "Yiyang", ""], ["Sen", "Siddhartha", ""], ["Jiang", "Junchen", ""]]}, {"id": "2008.04866", "submitter": "Adnan Aijaz", "authors": "Jaya Thota, Adnan Aijaz", "title": "Demo: Slicing-Enabled Private 4G/5G Network for Industrial Wireless\n  Applications", "comments": "accepted for ACM MobiCom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Private deployments of 4G and 5G networks in industrial environments are\nbeneficial from various aspects. Private 4G/5G networks typically face the\nchallenge of supporting heterogeneous industrial applications. This technology\ndemonstration highlights the importance of network slicing in private 4G/5G\nnetworks. It shows that network slicing is crucial for performance guarantees\nin multi-service co-existence scenarios. With network slicing, our private\n4G/5G network successfully supports closed-loop control, event-driven control\nand video streaming applications.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:15:59 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Thota", "Jaya", ""], ["Aijaz", "Adnan", ""]]}, {"id": "2008.05042", "submitter": "Basheer Qolomany", "authors": "Basheer Qolomany, Ihab Mohammed, Ala Al-Fuqaha, Mohsen Guizan, Junaid\n  Qadir", "title": "Trust-Based Cloud Machine Learning Model Selection For Industrial IoT\n  and Smart City Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With Machine Learning (ML) services now used in a number of mission-critical\nhuman-facing domains, ensuring the integrity and trustworthiness of ML models\nbecomes all-important. In this work, we consider the paradigm where cloud\nservice providers collect big data from resource-constrained devices for\nbuilding ML-based prediction models that are then sent back to be run locally\non the intermittently-connected resource-constrained devices. Our proposed\nsolution comprises an intelligent polynomial-time heuristic that maximizes the\nlevel of trust of ML models by selecting and switching between a subset of the\nML models from a superset of models in order to maximize the trustworthiness\nwhile respecting the given reconfiguration budget/rate and reducing the cloud\ncommunication overhead. We evaluate the performance of our proposed heuristic\nusing two case studies. First, we consider Industrial IoT (IIoT) services, and\nas a proxy for this setting, we use the turbofan engine degradation simulation\ndataset to predict the remaining useful life of an engine. Our results in this\nsetting show that the trust level of the selected models is 0.49% to 3.17% less\ncompared to the results obtained using Integer Linear Programming (ILP).\nSecond, we consider Smart Cities services, and as a proxy of this setting, we\nuse an experimental transportation dataset to predict the number of cars. Our\nresults show that the selected model's trust level is 0.7% to 2.53% less\ncompared to the results obtained using ILP. We also show that our proposed\nheuristic achieves an optimal competitive ratio in a polynomial-time\napproximation scheme for the problem.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 23:58:03 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Qolomany", "Basheer", ""], ["Mohammed", "Ihab", ""], ["Al-Fuqaha", "Ala", ""], ["Guizan", "Mohsen", ""], ["Qadir", "Junaid", ""]]}, {"id": "2008.05043", "submitter": "Xiaoping Wu", "authors": "Hengnian Qi, Xiaoping Wu, and Naixue Xiong", "title": "An Intelligent Prediction System for Mobile Source Localization Using\n  Time Delay Measurements", "comments": "12 pages,9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we introduce an intelligent prediction system for mobile\nsource localization in industrial Internet of things. The position and velocity\nof mobile source are jointly predicted by using Time Delay (TD) measurements in\nthe intelligent system. To predict the position and velocity, the Relaxed\nSemi-Definite Programming (RSDP) algorithm is firstly designed by dropping the\nrank-one constraint. However, dropping the rank-one constraint leads to produce\na suboptimal solution. To improve the performance, we further put forward a\nPenalty Function Semi-Definite Programming (PF-SDP) method to obtain the\nrank-one solution of the optimization problem by introducing the penalty terms.\nThen an Adaptive Penalty Function Semi-Definite Programming (APF-SDP) algorithm\nis also proposed to avoid the excessive penalty by adaptively choosing the\npenalty coefficient. We conduct experiments in both a simulation environment\nand a real system to demonstrate the effectiveness of the proposed method. The\nresults have demonstrated that the proposed intelligent APF-SDP algorithm\noutperforms the PF-SDP in terms of the position and velocity estimation whether\nthe noise level is large or not.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 00:20:18 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Qi", "Hengnian", ""], ["Wu", "Xiaoping", ""], ["Xiong", "Naixue", ""]]}, {"id": "2008.05232", "submitter": "Gregor Cerar", "authors": "Gregor Cerar, Halil Yetgin, Bla\\v{z} Bertalani\\v{c}, Carolina Fortuna", "title": "Learning to Detect Anomalous Wireless Links in IoT Networks", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3039333", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After decades of research, the Internet of Things (IoT) is finally permeating\nreal-life and helps improve the efficiency of infrastructures and processes as\nwell as our health. As a massive number of IoT devices are deployed, they\nnaturally incur great operational costs to ensure intended operations. To\neffectively handle such intended operations in massive IoT networks, automatic\ndetection of malfunctioning, namely anomaly detection, becomes a critical but\nchallenging task. In this paper, motivated by a real-world experimental IoT\ndeployment, we introduce four types of wireless network anomalies that are\nidentified at the link layer. We study the performance of threshold- and\nmachine learning (ML)-based classifiers to automatically detect these\nanomalies. We examine the relative performance of three supervised and three\nunsupervised ML techniques on both non-encoded and encoded (autoencoder)\nfeature representations. Our results demonstrate that; i) selected supervised\napproaches are able to detect anomalies with F1 scores of above 0.98, while\nunsupervised ones are also capable of detecting the said anomalies with F1\nscores of, on average, 0.90, and ii) OC-SVM outperforms all the other\nunsupervised ML approaches reaching at F1 scores of 0.99 for SuddenD, 0.95 for\nSuddenR, 0.93 for InstaD and 0.95 for SlowD.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:03:57 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 20:38:50 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Cerar", "Gregor", ""], ["Yetgin", "Halil", ""], ["Bertalani\u010d", "Bla\u017e", ""], ["Fortuna", "Carolina", ""]]}, {"id": "2008.05241", "submitter": "Markus Heinrich", "authors": "Markus Heinrich, Arwed G\\\"olz, Tolga Arul, Stefan Katzenbeisser", "title": "Rule-based Anomaly Detection for Railway Signalling Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a rule-based anomaly detection system for railway signalling that\nmitigates attacks by a Dolev-Yao attacker who is able to inject control\ncommands and to perform semantic attacks. The system as well mitigates the\neffects of a compromised signal box that an attacker uses to issue licit but\nmistimed control messages. We consider an attacker that could cause train\nderailments and collisions, if our countermeasure is not employed. We apply\nsafety principles of railway operation to a distributed anomaly detection\nsystem that inspects incoming commands on the signals and points. The proposed\nanomaly detection system detects all attacks of our model without producing\nfalse positives, while it requires only a small amount of overhead in terms of\nnetwork communication and latency compared to normal train operation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:21:23 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Heinrich", "Markus", ""], ["G\u00f6lz", "Arwed", ""], ["Arul", "Tolga", ""], ["Katzenbeisser", "Stefan", ""]]}, {"id": "2008.05255", "submitter": "Jiangkai Wu", "authors": "Zichuan Xu, Jiangkai Wu, Qiufen Xia, Pan Zhou, Jiankang Ren, Huizhi\n  Liang", "title": "Identity-Aware Attribute Recognition via Real-Time Distributed Inference\n  in Mobile Edge Clouds", "comments": "9 pages, 8 figures, Proceedings of the 28th ACM International\n  Conference on Multimedia (ACM MM'20), Seattle, WA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of deep learning technologies, attribute recognition and\nperson re-identification (re-ID) have attracted extensive attention and\nachieved continuous improvement via executing computing-intensive deep neural\nnetworks in cloud datacenters. However, the datacenter deployment cannot meet\nthe real-time requirement of attribute recognition and person re-ID, due to the\nprohibitive delay of backhaul networks and large data transmissions from\ncameras to datacenters. A feasible solution thus is to employ mobile edge\nclouds (MEC) within the proximity of cameras and enable distributed inference.\nIn this paper, we design novel models for pedestrian attribute recognition with\nre-ID in an MEC-enabled camera monitoring system. We also investigate the\nproblem of distributed inference in the MEC-enabled camera network. To this\nend, we first propose a novel inference framework with a set of distributed\nmodules, by jointly considering the attribute recognition and person re-ID. We\nthen devise a learning-based algorithm for the distributions of the modules of\nthe proposed distributed inference framework, considering the dynamic\nMEC-enabled camera network with uncertainties. We finally evaluate the\nperformance of the proposed algorithm by both simulations with real datasets\nand system implementation in a real testbed. Evaluation results show that the\nperformance of the proposed algorithm with distributed inference framework is\npromising, by reaching the accuracies of attribute recognition and person\nidentification up to 92.9% and 96.6% respectively, and significantly reducing\nthe inference delay by at least 40.6% compared with existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 12:03:27 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Xu", "Zichuan", ""], ["Wu", "Jiangkai", ""], ["Xia", "Qiufen", ""], ["Zhou", "Pan", ""], ["Ren", "Jiankang", ""], ["Liang", "Huizhi", ""]]}, {"id": "2008.05394", "submitter": "Feng Xia", "authors": "Feng Xia, Hannan Bin Liaqat, Jing Deng, Jiafu Wan, Sajal K. Das", "title": "Overhead Control with Reliable Transmission of Popular Packets in Ad-Hoc\n  Social Networks", "comments": "14 pages, 8 figures", "journal-ref": "IEEE Transactions on Vehicular Technology, 65(9): 7647-7661, Sept\n  2016", "doi": "10.1109/TVT.2015.2484418", "report-no": null, "categories": "cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable social connectivity and transmission of data for popular nodes is\nvital in multihop Ad-hoc Social Networks (ASNETs). In this networking paradigm,\ntransmission unreliability could be caused by multiple social applications\nrunning on a single node. This leads to contentions among nodes and connection\npaths. In addition, congestions can be the result of multiple senders\ntransmitting data to a single receiver and every sender waiting for a positive\nacknowledgment to move on. Therefore, traditional Transmission Control Protocol\n(TCP) performs poorly in ASNETs, due to the fact that the available bandwidth\nis shared among nodes using round trip time and the acknowledgment is provided\nindividually to every data packet. To solve these issues, we propose a\ntechnique, called Overhead Control with Reliable Transmission of Popular\nPackets in Ad-Hoc Social Networks (RTPS), which improves transmission\nreliability by assigning bandwidth to users based on their popularity levels:\nextra bandwidth is assigned to the nodes with higher popularity and their\nacknowledgments are sent with higher priority. In addition, RTPS further\nreduces contentions and packet losses by delaying acknowledgment packet\ntransmissions. Our detailed investigations demonstrate the excellent\nperformance of RTPS in terms of throughput latency and overhead with different\nhop-distances and different numbers of concurrent TCP flows.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:45:07 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Xia", "Feng", ""], ["Liaqat", "Hannan Bin", ""], ["Deng", "Jing", ""], ["Wan", "Jiafu", ""], ["Das", "Sajal K.", ""]]}, {"id": "2008.05395", "submitter": "Feng Xia", "authors": "Feng Xia, Hannan Bin Liaqat, Ahmedin Mohammed Ahmed, Li Liu, Jianhua\n  Ma, Runhe Huang, Amr Tolba", "title": "User Popularity-based Packet Scheduling for Congestion Control in Ad-hoc\n  Social Networks", "comments": "18 pages, 8 figures", "journal-ref": "Journal of Computer and System Sciences, Vol.82, No.1, 2016, pp.\n  93-112", "doi": "10.1016/j.jcss.2015.07.002", "report-no": null, "categories": "cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional ad-hoc network packet scheduling schemes cannot fulfill the\nrequirements of proximity-based ad-hoc social networks (ASNETs) and they do not\nbehave properly in congested environments. To address this issue, we propose a\nuser popularity-based packet scheduling scheme for congestion control in ASNETs\ncalled Pop-aware. The proposed algorithm exploits social popularity of sender\nnodes to prioritize all incoming flows. Pop-aware also provides fairness of\nservice received by each flow. We evaluate the performance of Pop-aware through\na series of simulations. In comparison with some existing scheduling\nalgorithms, Pop-aware performs better in terms of control overhead, total\noverhead, average throughput, packet loss rate, packet delivery rate and\naverage delay.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:45:29 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Xia", "Feng", ""], ["Liaqat", "Hannan Bin", ""], ["Ahmed", "Ahmedin Mohammed", ""], ["Liu", "Li", ""], ["Ma", "Jianhua", ""], ["Huang", "Runhe", ""], ["Tolba", "Amr", ""]]}, {"id": "2008.05509", "submitter": "Lisandro Granville", "authors": "Arthur Selle Jacobs, Ricardo Jos\\'e Pfitscher, Ronaldo Alves Ferreira,\n  Lisandro Zambenedetti Granville", "title": "Refining Network Intents for Self-Driving Networks", "comments": "9 pages, 5 figures, 3 listings, 1 grammar", "journal-ref": "ACM SIGCOMM Computer Communication Review (CCR), vol. 48, issue 5,\n  p. 55-63, October 2018", "doi": "10.1145/3310165.3310173", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence (AI) offer an opportunity for the\nadoption of self-driving networks. However, network operators or home-network\nusers still do not have the right tools to exploit these new advancements in\nAI, since they have to rely on low-level languages to specify network policies.\nIntent-based networking (IBN) allows operators to specify high-level policies\nthat dictate how the network should behave without worrying how they are\ntranslated into configuration commands in the network devices. However, the\nexisting research proposals for IBN fail to exploit the knowledge and feedback\nfrom the network operator to validate or improve the translation of intents. In\nthis paper, we introduce a novel intent-refinement process that uses machine\nlearning and feedback from the operator to translate the operator's utterances\ninto network configurations. Our refinement process uses a sequence-to-sequence\nlearning model to extract intents from natural language and the feedback from\nthe operator to improve learning. The key insight of our process is an\nintermediate representation that resembles natural language that is suitable to\ncollect feedback from the operator but is structured enough to facilitate\nprecise translations. Our prototype interacts with a network operator using\nnatural language and translates the operator input to the intermediate\nrepresentation before translating to SDN rules. Our experimental results show\nthat our process achieves a correlation coefficient squared (i.e., R-squared)\nof 0.99 for a dataset with 5000 entries and the operator feedback significantly\nimproves the accuracy of our model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 18:13:43 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Jacobs", "Arthur Selle", ""], ["Pfitscher", "Ricardo Jos\u00e9", ""], ["Ferreira", "Ronaldo Alves", ""], ["Granville", "Lisandro Zambenedetti", ""]]}, {"id": "2008.05611", "submitter": "Feng Xia", "authors": "Poria Pirozmand, Guowei Wu, Behrouz Jedari, Feng Xia", "title": "Human Mobility in Opportunistic Networks: Characteristics, Models and\n  Prediction Methods", "comments": "18 pages, 1 figure", "journal-ref": "Journal of Network and Computer Applications, Volume 42, June 2014", "doi": "10.1016/j.jnca.2014.03.007", "report-no": null, "categories": "cs.SI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opportunistic networks (OppNets) are modern types of intermittently connected\nnetworks in which mobile users communicate with each other via their\nshort-range devices to share data among interested observers. In this setting,\nhumans are the main carriers of mobile devices. As such, this mobility can be\nexploited by retrieving inherent user habits, interests, and social features\nfor the simulation and evaluation of various scenarios. Several research\nchallenges concerning human mobility in OppNets have been explored in the\nliterature recently. In this paper, we present a thorough survey of human\nmobility issues in three main groups (1) mobility characteristics, (2) mobility\nmodels and traces, and (3) mobility prediction techniques. Firstly, spatial,\ntemporal, and connectivity properties of human motion are explored. Secondly,\nreal mobility traces which have been captured using Bluetooth/Wi-Fi\ntechnologies or location-based social networks are summarized. Furthermore,\nsimulation-based mobility models are categorized and state-of-the art articles\nin each category are highlighted. Thirdly, new human mobility prediction\ntechniques which aim to forecast the three aspects of human mobility, i.e.,\nusers' next walks, stay duration and contact opportunities are studied\ncomparatively. To conclude, some major open issues are outlined.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 04:01:38 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Pirozmand", "Poria", ""], ["Wu", "Guowei", ""], ["Jedari", "Behrouz", ""], ["Xia", "Feng", ""]]}, {"id": "2008.05791", "submitter": "Soumyabrata Dev", "authors": "Mahmoud Said Elsayed, Nhien-An Le-Khac, Soumyabrata Dev, and Anca\n  Delia Jurcut", "title": "Detecting Abnormal Traffic in Large-Scale Networks", "comments": "Published in Proc. IEEE International Symposium on Networks,\n  Computers and Communications (ISNCC)2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid technological advancements, organizations need to rapidly\nscale up their information technology (IT) infrastructure viz. hardware,\nsoftware, and services, at a low cost. However, the dynamic growth in the\nnetwork services and applications creates security vulnerabilities and new\nrisks that can be exploited by various attacks. For example, User to Root (U2R)\nand Remote to Local (R2L) attack categories can cause a significant damage and\nparalyze the entire network system. Such attacks are not easy to detect due to\nthe high degree of similarity to normal traffic. While network anomaly\ndetection systems are being widely used to classify and detect malicious\ntraffic, there are many challenges to discover and identify the minority\nattacks in imbalanced datasets. In this paper, we provide a detailed and\nsystematic analysis of the existing Machine Learning (ML) approaches that can\ntackle most of these attacks. Furthermore, we propose a Deep Learning (DL)\nbased framework using Long Short Term Memory (LSTM) autoencoder that can\naccurately detect malicious traffics in network traffic. We perform our\nexperiments in a publicly available dataset of Intrusion Detection Systems\n(IDSs). We obtain a significant improvement in attack detection, as compared to\nother benchmarking methods. Hence, our method provides great confidence in\nsecuring these networks from malicious traffic.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:08:27 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Elsayed", "Mahmoud Said", ""], ["Le-Khac", "Nhien-An", ""], ["Dev", "Soumyabrata", ""], ["Jurcut", "Anca Delia", ""]]}, {"id": "2008.05851", "submitter": "Feng Xia", "authors": "Feng Xia, Fangwei Ding, Jie Li, Xiangjie Kong, Laurence T. Yang,\n  Jianhua Ma", "title": "Phone2Cloud: Exploiting Computation Offloading for Energy Saving on\n  Smartphones in Mobile Cloud Computing", "comments": "16 pages, 13 figures", "journal-ref": "Information Systems Frontiers, 16(1): 95-111, 2014", "doi": "10.1007/s10796-013-9458-1", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With prosperity of applications on smartphones, energy saving for smartphones\nhas drawn increasing attention. In this paper we devise Phone2Cloud, a\ncomputation offloading-based system for energy saving on smartphones in the\ncontext of mobile cloud computing. Phone2Cloud offloads computation of an\napplication running on smartphones to the cloud. The objective is to improve\nenergy efficiency of smartphones and at the same time, enhance the\napplication's performance through reducing its execution time. In this way, the\nuser's experience can be improved. We implement the prototype of Phone2Cloud on\nAndroid and Hadoop environment. Two sets of experiments, including application\nexperiments and scenario experiments, are conducted to evaluate the system. The\nexperimental results show that Phone2Cloud can effectively save energy for\nsmartphones and reduce the application's execution time.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 04:13:41 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Xia", "Feng", ""], ["Ding", "Fangwei", ""], ["Li", "Jie", ""], ["Kong", "Xiangjie", ""], ["Yang", "Laurence T.", ""], ["Ma", "Jianhua", ""]]}, {"id": "2008.05852", "submitter": "Feng Xia", "authors": "Feng Xia, Xuhai Zhao, Jianhui Zhang, Jianhua Ma, Xiangjie Kong", "title": "BeeCup: A Bio-Inspired Energy-Efficient Clustering Protocol for Mobile\n  Learning", "comments": "22 pages, 16 figures", "journal-ref": "Future Generation Computer Systems, 37: 449-460, 2014", "doi": "10.1016/j.future.2013.12.030", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices have become a popular tool for ubiquitous learning in recent\nyears. Multiple mobile users can be connected via ad hoc networks for the\npurpose of learning. In this context, due to limited battery capacity, energy\nefficiency of mobile devices becomes a very important factor that remarkably\naffects the user experience of mobile learning. Based on the artificial bee\ncolony (ABC) algorithm, we propose a new clustering protocol, namely BeeCup, to\nsave the energy of mobile devices while guaranteeing the quality of learning.\nThe BeeCup protocol takes advantage of biologically-inspired computation, with\nfocus on improving the energy efficiency of mobile devices. It first estimates\nthe number of cluster heads (CHs) adaptively according to the network scale,\nand then selects the CHs by employing the ABC algorithm. In case some CHs\nconsume energy excessively, clusters will be dynamically updated to keep energy\nconsumption balanced within the whole network. Simulation results demonstrate\nthe effectiveness and superiority of the proposed protocol.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 04:05:51 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Xia", "Feng", ""], ["Zhao", "Xuhai", ""], ["Zhang", "Jianhui", ""], ["Ma", "Jianhua", ""], ["Kong", "Xiangjie", ""]]}, {"id": "2008.06149", "submitter": "Vasileios Klimis", "authors": "Vasileios Klimis, George Parisis, Bernhard Reus", "title": "Model Checking Software-Defined Networks with Flow Entries that Time Out", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined networking (SDN) enables advanced operation and management\nof network deployments through (virtually) centralised, programmable\ncontrollers, which deploy network functionality by installing rules in the flow\ntables of network switches. Although this is a powerful abstraction, buggy\ncontroller functionality could lead to severe service disruption and security\nloopholes, motivating the need for (semi-)automated tools to find, or even\nverify absence of, bugs. Model checking SDNs has been proposed in the\nliterature, but none of the existing approaches can support dynamic network\ndeployments, where flow entries expire due to timeouts. This is necessary for\nautomatically refreshing (and eliminating stale) state in the network (termed\nas soft-state in the network protocol design nomenclature), which is important\nfor scaling up applications or recovering from failures. In this paper, we\nextend our model (MoCS) to deal with timeouts of flow table entries, thus\nsupporting soft state in the network. Optimisations are proposed that are\ntailored to this extension. We evaluate the performance of the proposed model\nin UPPAAL using a load balancer and firewall in network topologies of varying\nsize.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 00:56:43 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Klimis", "Vasileios", ""], ["Parisis", "George", ""], ["Reus", "Bernhard", ""]]}, {"id": "2008.06302", "submitter": "Arash Bozorgchenani", "authors": "Arash Bozorgchenani, Setareh Maghsudi, Daniele Tarchi, Ekram Hossain", "title": "Computation Offloading in Heterogeneous Vehicular Edge Networks: On-line\n  and Off-policy Bandit Solutions", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid advancement in vehicular communications and intelligent\ntransportation systems technologies, task offloading in vehicular networking\nscenarios is emerging as a promising, yet challenging, paradigm in mobile edge\ncomputing. In this paper, we study the computation offloading problem from\nmobile vehicles/users, more specifically, the network- and base station\nselection problem, in a heterogeneous Vehicular Edge Computing (VEC) scenario,\nwhere networks have different traffic loads. In a fast-varying vehicular\nenvironment, the latency in computation offloading that arises as a result of\nnetwork congestion (e.g. at the edge computing servers co-located with the base\nstations) is a key performance metric. However, due to the non-stationary\nproperty of such environments, predicting network congestion is an involved\ntask. To address this challenge, we propose an on-line algorithm and an\noff-policy learning algorithm based on bandit theory. To dynamically select the\nleast congested network in a piece-wise stationary environment, from the\noffloading history, these algorithms learn the latency that the offloaded tasks\nexperience. In addition, to minimize the task loss due to the mobility of the\nvehicles, we develop a method for base station selection and a relaying\nmechanism in the chosen network based on the sojourn time of the vehicles.\nThrough extensive numerical analysis, we demonstrate that the proposed\nlearning-based solutions adapt to the traffic changes of the network by\nselecting the least congested network. Moreover, the proposed approaches\nimprove the latency of offloaded tasks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:48:13 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Bozorgchenani", "Arash", ""], ["Maghsudi", "Setareh", ""], ["Tarchi", "Daniele", ""], ["Hossain", "Ekram", ""]]}, {"id": "2008.06568", "submitter": "MD Zadid Khan", "authors": "Zadid Khan, Sakib Mahmud Khan, Mashrur Chowdhury, Mizanur Rahman, and\n  Mhafuzul Islam", "title": "An Evaluation Framework of End-to-End 5G Millimeter Wave Communication\n  for Connected Vehicle Applications", "comments": "18 pages, 9 figures, 1 table, submitted for publication as\n  presentation or journal paper at transportation research board 2021 (TRB\n  2021). arXiv admin note: text overlap with arXiv:1808.04517", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The internet-of-things (IoT) environment connects different intelligent\ndevices together and enables seamless data communication between the connected\ndevices. Connected vehicles (CVs) are one of the primary example of the IoT,\nand the efficient, reliable, and safe operation of CVs demands a reliable\nwireless communication system, which can ensure high throughput and low\ncommunication latency. The 5G millimeter wave (5G mmWave) wireless\ncommunication network offers such benefits, which can be the enabler of CV\napplications, especially for dense urban areas with high number of CVs. In this\nstudy, we present a simulation-based evaluation framework of end-to-end 5G\nmmWave communication for CV applications. In addition, we compare the 5G mmWave\nwith the Dedicated Short Range Communication (DSRC) technology for a CV\napplication. The simulation framework is developed using two simulators, a\nnetwork simulator and a traffic simulator. In order to develop the framework in\nthis study, we have used Network Simulator 3 (ns-3) and SUMO, an open-source\nmicroscopic roadway traffic simulator. We have used end-to-end latency, packet\nloss and throughput as the performance evaluation metrics. We have found that\nfor dense urban areas, 5G mmWave can achieve higher throughput, lower latency\nand lower data loss compared to DSRC. 5G mmWave can support CV applications\nwith high throughput requirement on the downlink data flow. Through further\ninvestigation, we have found that the performance of 5G mmWave is significantly\nimpacted by the penetration level of CVs, maximum CV speed, and CV application\nrequirements.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 20:27:14 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Khan", "Zadid", ""], ["Khan", "Sakib Mahmud", ""], ["Chowdhury", "Mashrur", ""], ["Rahman", "Mizanur", ""], ["Islam", "Mhafuzul", ""]]}, {"id": "2008.06601", "submitter": "Omid Halimi Milani", "authors": "Omid Halimi Milani, S. Ahmad Motamedi and Saeed Sharifian", "title": "Intelligent Service Selection in a Multi-dimensional Environment of\n  Cloud Providers for IoT stream Data through cloudlets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expansion of the Internet of Things(IoT) services and a huge amount of\ndata generated by different sensors, signify the importance of cloud computing\nservices like Storage as a Service more than ever. IoT traffic imposes such\nextra constraints on the cloud storage service as sensor data preprocessing\ncapability and load-balancing between data centers and servers in each data\ncenter. Also, it should be allegiant to the Quality of Service (QoS). The\nhybrid MWG algorithm has been proposed in this work, which considers different\nobjectives such as energy, processing time, transmission time, and load\nbalancing in both Fog and Cloud Layer. The MATLAB script is used to simulate\nand implement our algorithms, and services of different servers, e.g. Amazon,\nDropbox, Google Drive, etc. have been considered. The MWG has 7%, 13%, and 25%\nimprovement in comparison with MOWCA, KGA, and NSGAII in metric of spacing,\nrespectively. Moreover, the MWG has 4%, 4.7%, and 7.3% optimization in metric\nof quality in comparison to MOWCA, KGA, and NSGAII, respectively. The overall\noptimization shows that the MWG algorithm has 7.8%, 17%, and 21.6% better\nperformance in comparison with MOWCA, KGA, and NSGAII in the obtained best\nresult by considering different objectives, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 23:15:32 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 22:22:42 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Milani", "Omid Halimi", ""], ["Motamedi", "S. Ahmad", ""], ["Sharifian", "Saeed", ""]]}, {"id": "2008.06641", "submitter": "Xinyu Huang", "authors": "Xinyu Huang, Lijun He, Wanyue Zhang", "title": "Vehicle Speed Aware Computing Task Offloading and Resource Allocation\n  Based on Multi-Agent Reinforcement Learning in a Vehicular Edge Computing\n  Network", "comments": "8 pages, 6 figures, Accepted by IEEE International Conference on Edge\n  Computing 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For in-vehicle application, the vehicles with different speeds have different\ndelay requirements. However, vehicle speeds have not been extensively explored,\nwhich may cause mismatching between vehicle speed and its allocated computation\nand wireless resource. In this paper, we propose a vehicle speed aware task\noffloading and resource allocation strategy, to decrease the energy cost of\nexecuting tasks without exceeding the delay constraint. First, we establish the\nvehicle speed aware delay constraint model based on different speeds and task\ntypes. Then, the delay and energy cost of task execution in VEC server and\nlocal terminal are calculated. Next, we formulate a joint optimization of task\noffloading and resource allocation to minimize vehicles' energy cost subject to\ndelay constraints. MADDPG method is employed to obtain offloading and resource\nallocation strategy. Simulation results show that our algorithm can achieve\nsuperior performance on energy cost and task completion delay.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 03:44:05 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 14:45:28 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Huang", "Xinyu", ""], ["He", "Lijun", ""], ["Zhang", "Wanyue", ""]]}, {"id": "2008.06708", "submitter": "Daniel Semrau", "authors": "Daniel Semrau and Shahzaib Durrani and Georgios Zervas and Robert I.\n  Killey and Polina Bayvel", "title": "On the Relationship Between Network Topology and Throughput in Mesh\n  Optical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The relationship between topology and network throughput of\narbitrarily-connected mesh networks is studied. Taking into account nonlinear\nchannel properties, it is shown that throughput decreases logarithmically with\nphysical network size with minor dependence on network ellipticity.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 11:50:11 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Semrau", "Daniel", ""], ["Durrani", "Shahzaib", ""], ["Zervas", "Georgios", ""], ["Killey", "Robert I.", ""], ["Bayvel", "Polina", ""]]}, {"id": "2008.06823", "submitter": "Neil J. Gunther", "authors": "Neil J. Gunther", "title": "Erlang Redux: An Ansatz Method for Solving the M/M/m Queue", "comments": "13 pages, 7 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This exposition presents a novel approach to solving an M/M/m queue for the\nwaiting time and the residence time. The motivation comes from an algebraic\nsolution for the residence time of the M/M/1 queue. The key idea is the\nintroduction of an ansatz transformation, defined in terms of the Erlang B\nfunction, that avoids the more opaque derivation based on applied probability\ntheory. The only prerequisite is an elementary knowledge of the Poisson\ndistribution, which is already necessary for understanding the M/M/1 queue. The\napproach described here supersedes our earlier approximate morphing\ntransformation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 02:50:19 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Gunther", "Neil J.", ""]]}, {"id": "2008.06890", "submitter": "Gaurav Kasbekar", "authors": "Adhirath Kabra, Sumit Kumar, Gaurav S. Kasbekar", "title": "Efficient, Flexible and Secure Group Key Management Protocol for Dynamic\n  IoT Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Internet of Things (IoT) scenarios require communication to and data\nacquisition from multiple devices with similar functionalities. For such\nscenarios, group communication in the form of multicasting and broadcasting has\nproven to be effective. Group Key Management (GKM) involves the handling,\nrevocation, updation and distribution of cryptographic keys to members of\nvarious groups. Classical GKM schemes perform inefficiently in dynamic IoT\nenvironments, which are those wherein nodes frequently leave or join a network\nor migrate from one group to another over time. Recently, the `GroupIt' scheme\nhas been proposed for GKM in dynamic IoT environments. However, this scheme has\nseveral limitations such as vulnerability to collusion attacks, the use of\ncomputationally expensive asymmetric encryption and threats to the backward\nsecrecy of the system. In this paper, we present a highly efficient and secure\nGKM protocol for dynamic IoT settings, which maintains forward and backward\nsecrecy at all times. Our proposed protocol uses only symmetric encryption, and\nis completely resistant to collusion attacks. Also, our protocol is highly\nflexible and can handle several new scenarios in which device or user dynamics\nmay take place, e.g., allowing a device group to join or leave the network or\ncreation or dissolution of a user group, which are not handled by schemes\nproposed in prior literature. We evaluate the performance of the proposed\nprotocol via extensive mathematical analysis and numerical computations, and\nshow that it outperforms the GroupIt scheme in terms of the communication and\ncomputation costs incurred by users and devices.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 11:56:30 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Kabra", "Adhirath", ""], ["Kumar", "Sumit", ""], ["Kasbekar", "Gaurav S.", ""]]}, {"id": "2008.06915", "submitter": "Zhuojia Gu", "authors": "Zhuojia Gu, Hancheng Lu, Ming Zhang, Haizhou Sun, Chang Wen Chen", "title": "Association and Caching in Relay-Assisted mmWave Networks: From A\n  Stochastic Geometry Perspective", "comments": "34 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited backhaul bandwidth and blockage effects are two main factors limiting\nthe practical deployment of millimeter wave (mmWave) networks. To tackle these\nissues, we study the feasibility of relaying as well as caching in mmWave\nnetworks. A user association and relaying (UAR) criterion dependent on both\ncaching status and maximum biased received power is proposed by considering the\nspatial correlation caused by the coexistence of base stations (BSs) and relay\nnodes (RNs). A joint UAR and caching placement problem is then formulated to\nmaximize the backhaul offloading traffic. Using stochastic geometry tools, we\ndecouple the joint UAR and caching placement problem by analyzing the\nrelationship between UAR probabilities and caching placement probabilities. We\nthen optimize the transformed caching placement problem based on polyblock\nouter approximation by exploiting the monotonic property in the general case\nand utilizing convex optimization in the noise-limited case. Accordingly, we\npropose a BS and RN selection algorithm where caching status at BSs and maximum\nbiased received power are jointly considered. Experimental results demonstrate\na significant enhancement of backhaul offloading using the proposed algorithms,\nand show that deploying more RNs and increasing cache size in mmWave networks\nis a more cost-effective alternative than increasing BS density to achieve\nsimilar backhaul offloading performance.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 14:21:40 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 07:39:46 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gu", "Zhuojia", ""], ["Lu", "Hancheng", ""], ["Zhang", "Ming", ""], ["Sun", "Haizhou", ""], ["Chen", "Chang Wen", ""]]}, {"id": "2008.07011", "submitter": "Qahhar M Qadir", "authors": "Qahhar Muhammad Qadir, Alexander A.Kist, and Zhongwei Zhang", "title": "A Novel Traffic Rate Measurement Algorithm for QoE-Aware Video Admission\n  Control", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": "10.1109/TMM.2015.2416637", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the inevitable dominance of video traffic on the Internet, providing\nperceptually good video quality is becoming a challenging task. This is partly\ndue to the bursty nature of video traffic, changing network conditions and\nlimitations of network transport protocols. This growth of video traffic has\nmade Quality of Experience (QoE) of the end user the focus of the research\ncommunity. In contrast, Internet service providers are concerned about\nmaximizing revenue by accepting as many sessions as possible, as long as\ncustomers remain satisfied. However, there is still no entirely satisfactory\nadmission algorithm for flows with variable rate. The trade-off between the\nnumber of sessions and perceived QoE can be optimized by exploiting the bursty\nnature of video traffic. This paper proposes a novel algorithm to determine the\nupper limit of the aggregate video rate that can exceed the available bandwidth\nwithout degrading the QoE of accepted video sessions. A parameter $\\beta$ that\ndefines the exceedable limit is defined. The proposed algorithm results in\naccepting more sessions without compromising the QoE of on-going video\nsessions. Thus it contributes to the optimization of the QoE-Session trade-off\nin support of the expected growth of video traffic on the Internet.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 22:03:21 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Qadir", "Qahhar Muhammad", ""], ["Kist", "Alexander A.", ""], ["Zhang", "Zhongwei", ""]]}, {"id": "2008.07076", "submitter": "Vipin Singh Sehrawat", "authors": "Vipin Singh Sehrawat, Yogendra Shah, Vinod Kumar Choyi, Alec\n  Brusilovsky and Samir Ferdi", "title": "Certificate and Signature Free Anonymity for V2V Communications", "comments": "This is the full version of the paper that appeared in 2017 IEEE\n  Vehicular Networking Conference (VNC), pp. 139-146. DOI:\n  10.1109/VNC.2017.8275624", "journal-ref": "IEEE Vehicular Networking Conference (VNC), pp. 139-146, 2017", "doi": "10.1109/VNC.2017.8275624", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymity is a desirable feature for vehicle-to-vehicle (V2V) communications,\nbut it conflicts with other requirements such as non-repudiation and\nrevocation. Existing, pseudonym-based V2V communications schemes rely on\ncertificate generation and signature verification. These schemes require\ncumbersome key management, frequent updating of certificate chains and other\ncostly procedures such as cryptographic pairings. In this paper, we present\nnovel V2V communications schemes, that provide authentication, authorization,\nanonymity, non-repudiation, replay protection, pseudonym revocation, and\nforward secrecy without relying on traditional certificate generation and\nsignature verification. Security and privacy of our schemes rely on hard\nproblems in number theory. Furthermore, our schemes guarantee security and\nprivacy in the presence of subsets of colluding malicious parties, provided\nthat the cardinality of such sets is below a fixed threshold.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 03:52:33 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sehrawat", "Vipin Singh", ""], ["Shah", "Yogendra", ""], ["Choyi", "Vinod Kumar", ""], ["Brusilovsky", "Alec", ""], ["Ferdi", "Samir", ""]]}, {"id": "2008.07083", "submitter": "Haneul Ko", "authors": "Seung Wook Kim, Keunsoo Ko, Haneul Ko, Victor C. M. Leung", "title": "Edge Network-Assisted Real-Time Object Detection Framework for\n  Autonomous Driving", "comments": "This paper will be published in IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles (AVs) can achieve the desired results within a short\nduration by offloading tasks even requiring high computational power (e.g.,\nobject detection (OD)) to edge clouds. However, although edge clouds are\nexploited, real-time OD cannot always be guaranteed due to dynamic channel\nquality. To mitigate this problem, we propose an edge network-assisted\nreal-time OD framework~(EODF). In an EODF, AVs extract the region of\ninterests~(RoIs) of the captured image when the channel quality is not\nsufficiently good for supporting real-time OD. Then, AVs compress the image\ndata on the basis of the RoIs and transmit the compressed one to the edge\ncloud. In so doing, real-time OD can be achieved owing to the reduced\ntransmission latency. To verify the feasibility of our framework, we evaluate\nthe probability that the results of OD are not received within the inter-frame\nduration (i.e., outage probability) and their accuracy. From the evaluation, we\ndemonstrate that the proposed EODF provides the results to AVs in real-time and\nachieves satisfactory accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:35:20 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Kim", "Seung Wook", ""], ["Ko", "Keunsoo", ""], ["Ko", "Haneul", ""], ["Leung", "Victor C. M.", ""]]}, {"id": "2008.07096", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Manuel Patchou and Christian Wietfeld", "title": "The Best of Both Worlds: Hybrid Data-Driven and Model-Based Vehicular\n  Network Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the end-to-end behavior of novel mobile communication methods\nin concrete evaluation scenarios frequently results in a methodological\ndilemma: Real world measurement campaigns are highly time-consuming and lack of\na controllable environment, the derivation of analytical models is often not\npossible due to the immense system complexity, system-level network simulations\nimply simplifications that result in significant derivations to the real world\nobservations. In this paper, we present a hybrid simulation approach which\nbrings together model-based mobility simulation, multi-dimensional Radio\nEnvironmental Maps (REMs) for efficient maintenance of radio propagation data,\nand Data-driven Network Simulation (DDNS) for fast and accurate analysis of the\nend-to-end behavior of mobile networks. For the validation, we analyze an\nopportunistic vehicular data transfer use-case and compare the proposed method\nto real world measurements and a corresponding simulation setup in Network\nSimulator 3 (ns-3). In comparison to the latter, the proposed method is not\nonly able to better mimic the real world behavior, it also achieves a 300 times\nhigher computational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 05:37:45 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Patchou", "Manuel", ""], ["Wietfeld", "Christian", ""]]}, {"id": "2008.07105", "submitter": "Wanqing Tu", "authors": "Wanqing Tu", "title": "An Efficient Transition Algorithm For Seamless Drone Multicasting", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many drone-related applications (e.g., drone-aided video capture, drone\ntraffic and safety management) require group communications between drones to\nefficiently disseminate data or reliably deliver critical information, making\nuse of the line-of-sight coverage of drones to realise services that ground\ndevices may not be capable of. This paper studies highperformance yet\nresource-efficient mobile drone multicasting via trajectory adjustment. We\nfirst analyse the trajectory adjustment condition to determine whether a\nstraight-line trajectory is fully covered by the multicast or not, by\nconducting simple computation tasks and with controlled overhead traffic. We\nthen propose the trajectory adjustment scheme to provide a new trajectory with\ncontrolled travel distances. The ETTA algorithm is finally presented to apply\nthe trajectory adjustment condition and scheme to a drone transiting between\nforwarders whose coverage do not overlap. The algorithm relies on multicasting\nforwarders, instead of additional transition forwarders, to fully cover the\nadjusted trajectory, helping to control interference and network traffic load.\nOur NS2 simulation results demonstrate that ETTA, as compared to other mobile\nmulticasts, can achieve guaranteed performance for drone receivers in a\nmulticast with heavier traffic loads.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 06:06:36 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Tu", "Wanqing", ""]]}, {"id": "2008.07162", "submitter": "Vilho Raisanen", "authors": "Vilho Raisanen, Mohammed Elbamby, Dmitry Petrov", "title": "Cross-stakeholder service orchestration for B5G through capability\n  provisioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-stakeholder service orchestration is a generalization of 5G network\nslices which has potential to increase business agility in Beyond 5G (B5G). An\narchitectural framework is proposed which enables domain operators to expose\ntheir functionalities towards E2E services as capabilities. Capability\norchestration is proposed as a mechanism for exposure. The use of intent-based\nmanagement for communicating domain owner's business goals to capability\norchestration is analyzed. The combination of business goal input and\ncapability orchestration provides a basis for agile monetization of domain\nresources for domain owners, and a building block for rich end-to-end B5G\nservices.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 08:57:32 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Raisanen", "Vilho", ""], ["Elbamby", "Mohammed", ""], ["Petrov", "Dmitry", ""]]}, {"id": "2008.07225", "submitter": "Pooyan Safari", "authors": "Pooyan Safari, Behnam Shariati, Johannes Karl Fischer", "title": "Privacy-Preserving Distributed Learning Framework for 6G Telecom\n  Ecosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a privacy-preserving distributed learning framework for telecom\necosystems in the 6G-era that enables the vision of shared ownership and\ngovernance of ML models, while protecting the privacy of the data owners. We\ndemonstrate its benefits by applying it to the use-case of Quality of\nTransmission (QoT) estimation in multi-domain multi-vendor optical networks,\nwhere no data of individual domains is shared with the network management\nsystem (NMS).\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 11:16:44 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Safari", "Pooyan", ""], ["Shariati", "Behnam", ""], ["Fischer", "Johannes Karl", ""]]}, {"id": "2008.07235", "submitter": "Yantong Wang", "authors": "Yantong Wang, Vasilis Friderikos", "title": "A Survey of Deep Learning for Data Caching in Edge Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of edge caching provision in emerging 5G and beyond mobile\nnetworks is a promising method to deal both with the traffic congestion problem\nin the core network as well as reducing latency to access popular content. In\nthat respect end user demand for popular content can be satisfied by\nproactively caching it at the network edge, i.e, at close proximity to the\nusers. In addition to model based caching schemes learning-based edge caching\noptimizations has recently attracted significant attention and the aim\nhereafter is to capture these recent advances for both model based and data\ndriven techniques in the area of proactive caching. This paper summarizes the\nutilization of deep learning for data caching in edge network. We first outline\nthe typical research topics in content caching and formulate a taxonomy based\non network hierarchical structure. Then, a number of key types of deep learning\nalgorithms are presented, ranging from supervised learning to unsupervised\nlearning as well as reinforcement learning. Furthermore, a comparison of\nstate-of-the-art literature is provided from the aspects of caching topics and\ndeep learning methods. Finally, we discuss research challenges and future\ndirections of applying deep learning for caching\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:02:32 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Wang", "Yantong", ""], ["Friderikos", "Vasilis", ""]]}, {"id": "2008.07255", "submitter": "Subhadeep Sahoo", "authors": "Subhadeep Sahoo (Chongqing University of Posts and Telecommunications,\n  China)", "title": "Research on Survivability Strategies of Virtual Network", "comments": "Master Degree Thesis at Chongqing University of Posts and\n  Telecommunications", "journal-ref": null, "doi": "10.1016/j.yofte.2019.102084; 10.1109/TSP49548.2020.9163586;\n  10.1109/JIOT.2019.2963319", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization facilitates heterogeneous cloud applications to share the same\nphysical infrastructure with admirable flexibility, while resource efficiency\nand survivability are critical concerns for virtual network embedding (VNE). As\nmore and more internet applications migrate to the cloud, the resource\nefficiency and the survivability of VNs, such as single link failure or\nlarge-scale disaster survivability, have become crucial issues. Separating the\nVNE problem into node and link mapping sub-problems without coordination might\ncause a high embedding cost. This dissertation presents two independent\napproaches to solve the aforementioned challenges. First, we study two-stage\ncoordinated survivable VNE (SVNE) problem and propose an adaptive path\nsplitting based SVNE (APSS) scheme. We first develop a concise anchor node\nstrategy to restrict the solution space of the candidate substrate nodes, which\ncoordinates node mapping with link mapping to limit the distance spans of the\nvirtual links. Then, we employ an adaptive path splitting policy to provide\nfull protection against single-link failures with partial backup resource, and\ndesign an agile frequency slot windows choosing mechanism to mitigate the\nspectrum fragmentation for link resource efficiency. Simulation results\ndemonstrate that the proposed APSS scheme can achieve satisfactory performance\nin terms of spectrum utilization and blocking ratio. Second, we propose a\nsynchronous evacuation strategy for VNs with dual virtual machines (VMs) inside\na disaster risk zone (DRZ), which suffer higher risks than the VNs with single.\nThe evacuation strategy exploits post-copy technique to sustain the online\nservice alive and enhances synchronous VM migrations to shorten the dual-VM\nevacuation time. Numerical results show that the proposed strategy can\noutperform the best-effort scheme in terms of average and total evacuation\ntimes of dual-VMs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:37:51 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Sahoo", "Subhadeep", "", "Chongqing University of Posts and Telecommunications,\n  China"]]}, {"id": "2008.07286", "submitter": "Carlos Bendicho PhD", "authors": "Carlos Bendicho", "title": "Model for Techno-Economic Assessment of Access Technologies. Doctoral\n  Dissertation for PhD, Telecommunications Engineering (EECS)", "comments": "188 pages, 30 figures, 56 tables, PhD Thesis, delivered in Dec. 2015,\n  defended in Feb. 2016. Confidential chapters 3 and 4 excluded. English\n  Translation. Original in Spanish available at University of the Basque\n  Country official repository: https://addi.ehu.es/handle/10810/24669 *Total\n  Spanish + English versions: 382 pages in arXiv: 2008.07286v3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This doctoral dissertation shows State of the Art of techno-economic modeling\nfor access network technologies, presents the characteristics a universal\ntechno-economic model should have, and shows a classification and analysis of\ntechno-economic models in the literature based on such characteristics. In\norder to reduce the gap detected in the literature, the author defines and\ndevelops a Universal Techno-Economic Model called UTEM and the corresponding\nmethodology to industrialize techno-economic assessment in multiple domains\nconsidering all market players perspectives, also suitable for technological\nconsulting and currently available for all industry stakeholders under specific\nlicense of use.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 15:21:23 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 22:16:51 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 16:12:59 GMT"}, {"version": "v4", "created": "Wed, 21 Apr 2021 21:23:52 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Bendicho", "Carlos", ""]]}, {"id": "2008.07323", "submitter": "Florian Meyer", "authors": "Florian Meyer, Ivonne Mantilla-Gonz\\'alez and Volker Turau", "title": "New CAP Reduction Mechanisms for IEEE 802.15.4 DSME to Support\n  Fluctuating Traffic in IoT Systems", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2015, the IEEE 802.15.4 standard was expanded by the Deterministic and\nSynchronous Multi-Channel Extension (DSME) to increase reliability, scalability\nand energy-efficiency in industrial applications. The extension offers a\nTDMA/FDMA-based channel access, where time is divided into two alternating\nphases, a contention access period (CAP) and a contention free period (CFP).\nDuring the CAP, transmission slots can be allocated offering an exclusive\naccess to the shared medium during the CFP. The fraction $\\tau$ of CFP's time\nslots in a dataframe is a critical value, because it directly influences\nagility and throughput. A high throughput demands that the CFP is much longer\nthan the CAP, i.e., a high value of the fraction $\\tau$, because application\ndata is only sent during the CFP. High agility is given if the expected waiting\ntime to send a CAP message is short and that the length of the CAPs are\nsufficiently long to accommodate necessary (de)allocations of GTSs, i.e., a low\nvalue of the fraction $\\tau$. Once DSME is configured according to the needs of\nan application, the fraction $\\tau$ can only assume one of two values and\ncannot be changed at run-time. In this paper, we propose two extensions of DSME\nthat allow to adopt $\\tau$ to the current traffic pattern. We show\ntheoretically and through simulations that the proposed extensions provide a\nhigh degree of responsiveness to traffic fluctuations while keeping the\nthroughput high.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:59:59 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 08:09:35 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 07:02:59 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Meyer", "Florian", ""], ["Mantilla-Gonz\u00e1lez", "Ivonne", ""], ["Turau", "Volker", ""]]}, {"id": "2008.07438", "submitter": "Jiangbin Lyu Dr.", "authors": "Jiangbin Lyu, Dan Yu and Liqun Fu", "title": "Analysis and Optimization for Large-Scale LoRa Networks: Throughput\n  Fairness and Scalability", "comments": "Propose stochastic geometry-based framework for modeling/analyzing\n  large-scale LoRa networks with channel fading/aggregate interference/packet\n  overlapping/multi-GW reception. Jointly optimize SF/Tx-power/duty-cycle based\n  on channel statistics and UE distribution, achieving both fairness and power\n  savings while improving cell-edge throughput and spatial (sum) throughput for\n  the majority of UEs. arXiv admin note: substantial text overlap with\n  arXiv:1904.12300", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI cs.SY eess.SY math.IT math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With growing popularity, LoRa networks are pivotally enabling Long Range\nconnectivity to low-cost and power-constrained user equipments (UEs). Due to\nits wide coverage area, a critical issue is to effectively allocate wireless\nresources to support potentially massive UEs while resolving the prominent\nnear-far fairness problem in the LoRa network, which is challenging due to the\nlack of tractable analytical model and its practical requirement for\nlow-complexity and low-overhead design. To achieve massive connectivity with\nfairness, we aim to maximize the minimum throughput of all UEs, and propose\nhigh-level policies of joint spreading factor (SF) allocation, power control,\nand duty cycle adjustment based only on average channel statistics and spatial\nUE distribution. By leveraging on the Poisson rain model along with tailored\nmodifications to our considered LoRa network under both single-cell and\nmulti-cell setups, we are able to account for channel fading, aggregate\ninterference, accurate packet overlapping, and/or multi-gateway packet\nreception, and still obtain tractable and accurate formulas for the packet\nsuccess probability and hence throughput. We further propose an iterative\nbalancing (IB) method to allocate the SFs in the cell such that the overall\nmax-min throughput can be achieved. Numerical results show that the proposed\nscheme with optimized design greatly alleviates the near-far fairness issue and\nalso reduces the spatial power consumption, while significantly improving the\ncell-edge throughput as well as the spatial (sum) throughput for the majority\nof UEs, especially for large-scale LoRa networks with massive UEs and high\ngateway density.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 15:56:43 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 09:17:23 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Lyu", "Jiangbin", ""], ["Yu", "Dan", ""], ["Fu", "Liqun", ""]]}, {"id": "2008.07482", "submitter": "Eloise De Carvalho Rodrigues", "authors": "Eloise de Carvalho Rodrigues, Adrian Garcia-Rodriguez, Lorenzo Galati\n  Giordano, and Giovanni Geraci", "title": "On the Latency of IEEE 802.11ax WLANs with Parameterized Spatial Reuse", "comments": "Accepted to IEEE Globecom 2020, SAC - Access Networks and Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we evaluate the performance of the parameterized spatial\nreuse (PSR) framework of IEEE 802.11ax, mainly focusing on its impact on\ntransmission latency. Based on detailed standard-compliant system-level\nsimulations, we provide a realistic analysis of the effects of PSR considering\ndifferent scenario densities, traffic loads, and access points (APs) antenna\ncapabilities to quantify its performance gains under various scenarios. Our\nresults show that, in medium-density scenarios, PSR can offer up to a 3.8x\nreduction in the 5% worst-case latencies for delay-sensitive stations with\nrespect to an 802.11ax system without PSR. Moreover, our study demonstrates\nthat, for low-latency communications, providing the network with PSR\ncapabilities may be an appealing alternative to the deployment of more costly\nmulti-antenna APs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:17:48 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Rodrigues", "Eloise de Carvalho", ""], ["Garcia-Rodriguez", "Adrian", ""], ["Giordano", "Lorenzo Galati", ""], ["Geraci", "Giovanni", ""]]}, {"id": "2008.07492", "submitter": "Laksh Bhatia", "authors": "Laksh Bhatia, Ivana Tomi\\'c, Anqi Fu, Michael Breza, Julie A. McCann", "title": "Control Communication Co-Design for Wide Area Cyber-Physical Systems", "comments": "Accepted for publication at ACM Transactions on Cyber-Physical\n  Systems", "journal-ref": null, "doi": "10.1145/3418528", "report-no": null, "categories": "eess.SY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide Area Cyber-Physical Systems (WA-CPSs) are a class of control systems\nthat integrate low-powered sensors, heterogeneous actuators and computer\ncontrollers into large infrastructure that span multi-kilometre distances.\nCurrent wireless communication technologies are incapable of meeting the\ncommunication requirements of range and bounded delays needed for the control\nof WA-CPSs. To solve this problem, we use a Control-Communication Co-design\napproach for WA-CPSs, that we refer to as the $C^3$ approach, to design a novel\nLow-Power Wide Area (LPWA) MAC protocol called \\textit{Ctrl-MAC} and its\nassociated event-triggered controller that can guarantee the closed-loop\nstability of a WA-CPS. This is the first paper to show that LPWA wireless\ncommunication technologies can support the control of WA-CPSs. LPWA\ntechnologies are designed to support one-way communication for monitoring and\nare not appropriate for control. We present this work using an example of a\nwater distribution network application which we evaluate both through a\nco-simulator (modelling both physical and cyber subsystems) and testbed\ndeployments. Our evaluation demonstrates full control stability, with up to\n$50$\\% better packet delivery ratios and $80$\\% less average end-to-end delays\nwhen compared to a state of the art LPWA technology. We also evaluate our\nscheme against an idealised, wired, centralised, control architecture and show\nthat the controller maintains stability and the overshoots remain within\nbounds.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:35:41 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Bhatia", "Laksh", ""], ["Tomi\u0107", "Ivana", ""], ["Fu", "Anqi", ""], ["Breza", "Michael", ""], ["McCann", "Julie A.", ""]]}, {"id": "2008.07561", "submitter": "Cheng-Shang Chang", "authors": "Che-Hao Yu, Lin Huang, Cheng-Shang Chang, and Duan-Shin Lee", "title": "Poisson Receivers: a Probabilistic Framework for Analyzing Coded Random\n  Access", "comments": null, "journal-ref": "IEEE/ACM Transactions on Networking, Volume: 29, Issue: 2, pp. 862\n  - 875, April 2021", "doi": "10.1109/TNET.2021.3050485", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a probabilistic framework for analyzing coded\nrandom access. Our framework is based on a new abstract receiver (decoder),\ncalled a Poisson receiver, that is characterized by a success probability\nfunction of a tagged packet subject to a Poisson offered load. We show that\nvarious coded slotted ALOHA (CSA) systems are Poisson receivers. Moreover,\nPoisson receivers have two elegant closure properties: (i) Poisson receivers\nwith packet routing are still Poisson receivers, and (ii) Poisson receivers\nwith packet coding are still Poisson receivers. These two closure properties\nenable us to use smaller Poisson receivers as building blocks for analyzing a\nlarger Poisson receiver. As such, we can analyze complicated systems that are\nnot possible by the classical tree evaluation method. In particular, for CSA\nsystems with both spatial diversity and temporal diversity, we can use the\nframework of Poisson receivers to compute the exact (asymptotic) throughput. We\ndemonstrate that our framework can be used to provide differentiated services\nbetween ultra-reliable low-latency communication (URLLC) traffic and enhanced\nmobile broadband (eMBB) traffic. By conducting extensive simulations, we also\nverify that our theoretical results match extremely well with the simulation\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 18:16:42 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Yu", "Che-Hao", ""], ["Huang", "Lin", ""], ["Chang", "Cheng-Shang", ""], ["Lee", "Duan-Shin", ""]]}, {"id": "2008.07699", "submitter": "Alexey Ivanov", "authors": "Alexey Ivanov", "title": "Evaluating BBRv2 on the Dropbox Edge Network", "comments": "7 pages, 15 figures, netdev 0x14 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Nowadays, loss-based TCP congestion controls in general and CUBIC\nspecifically became the de facto standard for the Internet. BBR congestion\ncontrol challenges the loss-based approach by modeling the network based on\nestimated bandwidth and round-trip time. At Dropbox, we've been using BBRv1\nsince 2017 and are accustomed to its pros and cons. BBRv2 introduces a set of\nimprovements to network modeling (explicit loss targets and inflight limits)\nand fairness (differential probing and headroom for new flows.) In this paper,\nwe go over experimental data gathered on the Dropbox Edge Network. We compare\nBBRv2 to BBRv1 and CUBIC showing that BBRv2 is a definite improvement over both\nof them. We also show that BBRv2 experimental results match its theoretical\ndesign principles.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:13:45 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 06:17:27 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Ivanov", "Alexey", ""]]}, {"id": "2008.07721", "submitter": "Massieh Kordi Boroujeny", "authors": "Massieh Kordi Boroujeny, Brian L. Mark", "title": "Design of a Stochastic Traffic Regulator for End-to-End Network Delay\n  Guarantees", "comments": "26 pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing end-to-end network delay guarantees in packet-switched networks\nsuch as the Internet is highly desirable for mission-critical and\ndelay-sensitive data transmission, yet it remains a challenging open problem.\nDue to the looseness of the deterministic bounds, various frameworks for\nstochastic network calculus have been proposed to provide tighter,\nprobabilistic bounds on network delay, at least in theory. However, little\nattention has been devoted to the problem of regulating traffic according to\nstochastic burstiness bounds, which is necessary in order to guarantee the\ndelay bounds in practice. We design and analyze a stochastic traffic regulator\nthat can be used in conjunction with results from stochastic network calculus\nto provide probabilistic guarantees on end-to-end network delay. Numerical\nresults are provided to demonstrate the performance of the proposed traffic\nregulator.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 03:27:32 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Boroujeny", "Massieh Kordi", ""], ["Mark", "Brian L.", ""]]}, {"id": "2008.07747", "submitter": "Benjamin Sliwa", "authors": "Jakob Thrane and Benjamin Sliwa and Christian Wietfeld and Henrik\n  Christiansen", "title": "Deep Learning-based Signal Strength Prediction Using Geographical Images\n  and Expert Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for accurate prediction of radio signal quality parameters are\ncrucial for optimization of mobile networks, and a necessity for future\nautonomous driving solutions. The power-distance relation of current empirical\nmodels struggles with describing the specific local geo-statistics that\ninfluence signal quality parameters. The use of empirical models commonly\nresults in an over- or under-estimation of the signal quality parameters and\nrequire additional calibration studies. In this paper, we present a novel\nmodel-aided deep learning approach for path loss prediction, which implicitly\nextracts radio propagation characteristics from top-view geographical images of\nthe receiver location. In a comprehensive evaluation campaign, we apply the\nproposed method on an extensive real-world data set consisting of five\ndifferent scenarios and more than 125.000 individual measurements. It is found\nthat 1) the novel approach reduces the average prediction error by up to 53% in\ncomparison to ray-tracing techniques, 2) A distance of 250-300 meters spanned\nby the images offer the necessary level of detail, 3) Predictions with a\nroot-mean-squared error of approximately 6 dB is achieved across inherently\ndifferent data sources.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 05:24:00 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Thrane", "Jakob", ""], ["Sliwa", "Benjamin", ""], ["Wietfeld", "Christian", ""], ["Christiansen", "Henrik", ""]]}, {"id": "2008.07821", "submitter": "Michele Albano", "authors": "Michele Albano, Matteo Mordacchini, Laura Ricci", "title": "AoI-based Multicast Routing over Voronoi Overlays with Minimal Overhead", "comments": "Submitted to: IEEE Access; CodeOcean: DOI:10.24433/CO.1722184.v1;\n  code: https://github.com/michelealbano/mabravo", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3023479", "report-no": null, "categories": "cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing pervasive and ubiquitous presence of devices at the edge of\nthe Internet is creating new scenarios for the emergence of novel services and\napplications. This is particularly true for location- and context-aware\nservices. These services call for new decentralized, self-organizing\ncommunication schemes that are able to face issues related to demanding\nresource consumption constraints, while ensuring efficient locality-based\ninformation dissemination and querying. Voronoi-based communication techniques\nare among the most widely used solutions in this field. However, when used for\nforwarding messages inside closed areas of the network (called Areas of\nInterest, AoIs), these solutions generally require a significant overhead in\nterms of redundant and/or unnecessary communications. This fact negatively\nimpacts both the devices' resource consumption levels, as well as the network\nbandwidth usage. In order to eliminate all unnecessary communications, in this\npaper we present the MABRAVO (Multicast Algorithm for Broadcast and Routing\nover AoIs in Voronoi Overlays) protocol suite. MABRAVO allows to forward\ninformation within an AoI in a Voronoi network using only local information,\nreaching all the devices in the area, and using the lowest possible number of\nmessages, i.e., just one message for each node included in the AoI. The paper\npresents the mathematical and algorithmic descriptions of MABRAVO, as well as\nexperimental findings of its performance, showing its ability to reduce\ncommunication costs to the strictly minimum required.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 09:30:53 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Albano", "Michele", ""], ["Mordacchini", "Matteo", ""], ["Ricci", "Laura", ""]]}, {"id": "2008.08014", "submitter": "Harry Halpin", "authors": "Harry Halpin", "title": "Deconstructing the Decentralization Trilemma", "comments": "Prepublication of paper to be presented at SECRYPT 2020", "journal-ref": "Proceedings of SECRYPT (2020) 505-512", "doi": "10.5220/0009892405050512", "report-no": null, "categories": "cs.NI cs.SE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of applications at this moment rely on centralized servers\nto relay messages between clients, where these servers are considered trusted\nthird-parties. With the rise of blockchain technologies over the last few\nyears, there has been a move away from both centralized servers and traditional\nfederated models to more decentralized peer-to-peer alternatives. However,\nthere appears to be a trilemma between security, scalability, and\ndecentralization in blockchain-based systems. Deconstructing this trilemma\nusing well-known threat models, we define a typology of centralized, federated,\nand decentralized architectures. Each of the different architectures has this\ntrilemma play out differently. Facing a possible decentralized future, we\noutline seven hard problems facing decentralization and theorize that the\ndifferences between centralized, federated, and decentralized architectures\ndepend on differing social interpretations of trust.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:34:33 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Halpin", "Harry", ""]]}, {"id": "2008.08074", "submitter": "Sohini Roy", "authors": "Sohini Roy and Arunabha Sen", "title": "Identification of the K-most Vulnerable Entities in a Smart Grid System", "comments": "6 pages, 4 figures, Accepted for publication in CommNet 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A smart grid system can be considered as a multi-layered network with power\nnetwork in one layer and communication network in the other. The entities in\nboth the layers exhibit complex intra-and-interdependencies between them. A\nreliable decision making by the smart grid operator is contingent upon correct\nanalysis of such dependencies between its entities and also on accurate\nidentification of the most critical entities in the system. The Modified\nImplicative Interdependency Model (MIIM) [1] successfully captures such\ndependencies using multi-valued Boolean Logic based equations called\nInterdependency Relations (IDRs) after most of the existing models made failed\nattempts in doing that. In this paper, for any given integer K, this model is\nused to identify the K-most vulnerable entities in a smart grid, failure of\nwhich can maximize the network damage. Owing to the problem being NP complete,\nan Integer Linear Programming (ILP) based solution is given here. Validation of\nthe model [1] and the results of the ILP based solution is done by simulating a\nsmart grid system of IEEE 14-Bus using MATPOWER and Java Network Simulator\n(JNS). Simulation results prove that not only the model MIIM [1] is correct but\nalso it can predict the network damage for failure of K-most vulnerable\nentities more accurately than its predecessor Implicative Interdependency Model\n(IIM) [2].\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:55:20 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Roy", "Sohini", ""], ["Sen", "Arunabha", ""]]}, {"id": "2008.08200", "submitter": "Muhammad Umar Bin Farooq", "authors": "Muhammad Umar Bin Farooq, Marvin Manalastas, Waseem Raza, Aneeqa Ijaz,\n  Syed Muhammad Asad Zaidi, Adnan Abu-Dayya and Ali Imran", "title": "Data Driven Optimization of Inter-Frequency Mobility Parameters for\n  Emerging Multi-band Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Densification and multi-band operation in 5G and beyond pose an unprecedented\nchallenge for mobility management, particularly for inter-frequency handovers.\nThe challenge is aggravated by the fact that the impact of key inter-frequency\nmobility parameters, namely A5 time to trigger (TTT), A5 threshold1 and A5\nthreshold2 on the system's performance is not fully understood. These\nparameters are fixed to a gold standard value or adjusted through hit and\ntrial. This paper presents a first study to analyze and optimize A5 parameters\nfor jointly maximizing two key performance indicators (KPIs): Reference signal\nreceived power (RSRP) and handover success rate (HOSR). As analytical modeling\ncannot capture the system-level complexity, a data driven approach is used. By\ndeveloping XGBoost based model, that outperforms other models in terms of\naccuracy, we first analyze the concurrent impact of the three parameters on the\ntwo KPIs. The results reveal three key insights: 1) there exist optimal\nparameter values for each KPI; 2) these optimal values do not necessarily\nbelong to the current gold standard; 3) the optimal parameter values for the\ntwo KPIs do not overlap. We then leverage the Sobol variance-based sensitivity\nanalysis to draw some insights which can be used to avoid the parametric\nconflict while jointly maximizing both KPIs. We formulate the joint RSRP and\nHOSR optimization problem, show that it is non-convex and solve it using the\ngenetic algorithm (GA). Comparison with the brute force-based results show that\nthe proposed data driven GA-aided solution is 48x faster with negligible loss\nin optimality.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 00:05:57 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Farooq", "Muhammad Umar Bin", ""], ["Manalastas", "Marvin", ""], ["Raza", "Waseem", ""], ["Ijaz", "Aneeqa", ""], ["Zaidi", "Syed Muhammad Asad", ""], ["Abu-Dayya", "Adnan", ""], ["Imran", "Ali", ""]]}, {"id": "2008.08264", "submitter": "Quoc-Viet Pham", "authors": "Quoc-Viet Pham and Nhan Thanh Nguyen and Thien Huynh-The and Long Bao\n  Le and Kyungchun Lee and Won-Joo Hwang", "title": "Intelligent Radio Signal Processing: A Survey", "comments": "Accepted for publication. Copyright may be transferred without\n  notice, after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent signal processing for wireless communications is a vital task in\nmodern wireless systems, but it faces new challenges because of network\nheterogeneity, diverse service requirements, a massive number of connections,\nand various radio characteristics. Owing to recent advancements in big data and\ncomputing technologies, artificial intelligence (AI) has become a useful tool\nfor radio signal processing and has enabled the realization of intelligent\nradio signal processing. This survey covers four intelligent signal processing\ntopics for the wireless physical layer, including modulation classification,\nsignal detection, beamforming, and channel estimation. In particular, each\ntheme is presented in a dedicated section, starting with the most fundamental\nprinciples, followed by a review of up-to-date studies and a summary. To\nprovide the necessary background, we first present a brief overview of AI\ntechniques such as machine learning, deep learning, and federated learning.\nFinally, we highlight a number of research challenges and future directions in\nthe area of intelligent radio signal processing. We expect this survey to be a\ngood source of information for anyone interested in intelligent radio signal\nprocessing, and the perspectives we provide therein will stimulate many more\nnovel ideas and contributions in the future.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 05:06:31 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 12:15:29 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 00:48:27 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Pham", "Quoc-Viet", ""], ["Nguyen", "Nhan Thanh", ""], ["Huynh-The", "Thien", ""], ["Le", "Long Bao", ""], ["Lee", "Kyungchun", ""], ["Hwang", "Won-Joo", ""]]}, {"id": "2008.08330", "submitter": "Junjie Tan", "authors": "Junjie Tan, Ying-Chang Liang, Nguyen Cong Luong, Dusit Niyato", "title": "Toward Smart Security Enhancement of Federated Learning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As traditional centralized learning networks (CLNs) are facing increasing\nchallenges in terms of privacy preservation, communication overheads, and\nscalability, federated learning networks (FLNs) have been proposed as a\npromising alternative paradigm to support the training of machine learning (ML)\nmodels. In contrast to the centralized data storage and processing in CLNs,\nFLNs exploit a number of edge devices (EDs) to store data and perform training\ndistributively. In this way, the EDs in FLNs can keep training data locally,\nwhich preserves privacy and reduces communication overheads. However, since the\nmodel training within FLNs relies on the contribution of all EDs, the training\nprocess can be disrupted if some of the EDs upload incorrect or falsified\ntraining results, i.e., poisoning attacks. In this paper, we review the\nvulnerabilities of FLNs, and particularly give an overview of poisoning attacks\nand mainstream countermeasures. Nevertheless, the existing countermeasures can\nonly provide passive protection and fail to consider the training fees paid for\nthe contributions of the EDs, resulting in a unnecessarily high training cost.\nHence, we present a smart security enhancement framework for FLNs. In\nparticular, a verify-before-aggregate (VBA) procedure is developed to identify\nand remove the non-benign training results from the EDs. Afterward, deep\nreinforcement learning (DRL) is applied to learn the behaving patterns of the\nEDs and to actively select the EDs that can provide benign training results and\ncharge low training fees. Simulation results reveal that the proposed framework\ncan protect FLNs effectively and efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:46:39 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Tan", "Junjie", ""], ["Liang", "Ying-Chang", ""], ["Luong", "Nguyen Cong", ""], ["Niyato", "Dusit", ""]]}, {"id": "2008.08339", "submitter": "Wazen Shbair", "authors": "Wazen M. Shbair, Thibault Cholez, Jerome Francois, Isabelle Chrisment", "title": "A Survey of HTTPS Traffic and Services Identification Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HTTPS is quickly rising alongside the need of Internet users to benefit from\nsecurity and privacy when accessing the Web, and it becomes the predominant\napplication protocol on the Internet. This migration towards a secure Web using\nHTTPS comes with important challenges related to the management of HTTPS\ntraffic to guarantee basic network properties such as security, QoS,\nreliability, etc. But encryption undermines the effectiveness of standard\nmonitoring techniques and makes it difficult for ISPs and network\nadministrators to properly identify and manage the services behind HTTPS\ntraffic. This survey details the techniques used to monitor HTTPS traffic, from\nthe most basic level of protocol identification (TLS, HTTPS), to the finest\nidentification of precise services. We show that protocol identification is\nwell mastered while more precise levels keep being challenging despite recent\nadvances. We also describe practical solutions that lead us to discuss the\ntrade-off between security and privacy and the research directions to guarantee\nboth of them.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 09:04:15 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Shbair", "Wazen M.", ""], ["Cholez", "Thibault", ""], ["Francois", "Jerome", ""], ["Chrisment", "Isabelle", ""]]}, {"id": "2008.08412", "submitter": "Saar Tochner", "authors": "Maya Dotan, Yvonne-Anne Pignolet, Stefan Schmid, Saar Tochner and Aviv\n  Zohar", "title": "Survey on Cryptocurrency Networking: Context, State-of-the-Art,\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies such as Bitcoin are realized using distributed systems and\nhence critically rely on the performance and security of the interconnecting\nnetwork. The requirements on these networks and their usage, however can differ\nsignificantly from traditional communication networks, with implications on all\nlayers of the protocol stack. This paper is motivated by these differences, and\nin particular by the observation that many fundamental design aspects of these\nnetworks are not well-understood today. In order to support the networking\ncommunity to contribute to this emerging application domain, we present a\nstructured overview of the field, from topology and neighbor discovery to block\nand transaction propagation. In particular, we provide the context,\nhighlighting differences and commonalities with traditional networks, review\nthe state-of-the-art, and identify open research challenges. Our paper can\nhence also be seen as a call-to-arms to improve the foundation on top of which\ncryptocurrencies are built.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:02:37 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Dotan", "Maya", ""], ["Pignolet", "Yvonne-Anne", ""], ["Schmid", "Stefan", ""], ["Tochner", "Saar", ""], ["Zohar", "Aviv", ""]]}, {"id": "2008.08639", "submitter": "Qahhar M Qadir", "authors": "Qahhar Muhammad Qadir, Tarik A. Rashid, Nawzad K. Al-Salihi, Birzo\n  Ismael, Alexander A. Kist and Zhongwei Zhang", "title": "Low Power Wide Area Networks: A Survey of Enabling Technologies,\n  Applications and Interoperability Needs", "comments": "22 pages, 5 figures", "journal-ref": "IEEE Access, vol. 6, pp. 77 454-77 473, 2018", "doi": "10.1109/ACCESS.2018.2883151", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low power wide area (LPWA) technologies are strongly recommended as the\nunderlying networks for Internet of things (IoT) applications. They offer\nattractive features, including wide-range coverage, long battery life and low\ndata rates. This paper reviews the current trends in this technology, with an\nemphasis on the services it provides and the challenges it faces. The\nindustrial paradigms for LPWA implementation are presented. Compared with other\nwork in the field, this survey focuses on the need for integration among\ndifferent LPWA technologies and recommends the appropriate LPWA solutions for a\nwide range of IoT application and service use-cases. Opportunities created by\nthese technologies in the market are also analyzed. The latest research efforts\nto investigate and improve the operation of LPWA networks are also compared and\nclassified to enable researchers to quickly get up to speed on the current\nstatus of this technology. Finally, challenges facing LPWA are identified and\ndirections for future research are recommended.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 19:17:46 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Qadir", "Qahhar Muhammad", ""], ["Rashid", "Tarik A.", ""], ["Al-Salihi", "Nawzad K.", ""], ["Ismael", "Birzo", ""], ["Kist", "Alexander A.", ""], ["Zhang", "Zhongwei", ""]]}, {"id": "2008.08697", "submitter": "Debobroto Das Robin", "authors": "Debobroto Das Robin, Dr. Javed I. Khan", "title": "Toward an Abstract Model of Programmable Data Plane Devices", "comments": "17 pages , 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SDN divides the networking landscape into 2 parts: control and data plane.\nSDN expanded it's foot mark starting with OpenFlow based highly flexible\ncontrol plane and rigid data plane. Innovation and improvement in hardware\ndesign and development is bringing various new architectures for data plane.\nData plane is becoming more programmable then ever before. A common abstract\nmodel of data plane is required to develop complex application over these\nheterogeneous data plane devices. It can also provide insight about performance\noptimization and bench-marking of programmable data plane devices. Moreover, to\nunderstand and utilize data plane's programmability, a detailed structural\nanalysis and an identifiable matrix to compare different devices are required.\nIn this work, an improved and structured abstract model of the programmable\ndata plane devices is presented and features of its components are discussed in\ndetail. Several commercially available programmable data plane devices are also\ncompared based on those features.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 22:54:15 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Robin", "Debobroto Das", ""], ["Khan", "Dr. Javed I.", ""]]}, {"id": "2008.08761", "submitter": "Jianxiong Guo", "authors": "Jianxiong Guo, Xingjian Ding, Weili Wu", "title": "Reliable Traffic Monitoring Mechanisms Based on Blockchain in Vehicular\n  Networks", "comments": "in IEEE Transactions on Reliability", "journal-ref": null, "doi": "10.1109/TR.2020.3046556", "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real-time traffic monitoring is a fundamental mission in a smart city to\nunderstand traffic conditions and avoid dangerous incidents. In this paper, we\npropose a reliable and efficient traffic monitoring system that integrates\nblockchain and the Internet of vehicles technologies effectively. It can\ncrowdsource its tasks of traffic information collection to vehicles that run on\nthe road instead of installing cameras in every corner. First, we design a\nlightweight blockchain-based information trading framework to model the\ninteractions between traffic administration and vehicles. It guarantees\nreliability, efficiency, and security during executing trading. Second, we\ndefine the utility functions for the entities in this system and come up with a\nbudgeted auction mechanism that motivates vehicles to undertake the collection\ntasks actively. In our algorithm, it not only ensures that the total payment to\nthe selected vehicles does not exceed a given budget, but also maintains the\ntruthfulness of auction process that avoids some vehicles to offer unreal bids\nfor getting greater utilities. Finally, we conduct a group of numerical\nsimulations to evaluate the reliability of our trading framework and\nperformance of our algorithms, whose results demonstrate their correctness and\nefficiency perfectly.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 04:00:00 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Guo", "Jianxiong", ""], ["Ding", "Xingjian", ""], ["Wu", "Weili", ""]]}, {"id": "2008.08886", "submitter": "Daniele De Sensi PhD", "authors": "Daniele De Sensi, Salvatore Di Girolamo, Kim H. McMahon, Duncan\n  Roweth, Torsten Hoefler", "title": "An In-Depth Analysis of the Slingshot Interconnect", "comments": "To be published in Proceedings of The International Conference for\n  High Performance Computing Networking, Storage, and Analysis (SC '20) (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interconnect is one of the most critical components in large scale\ncomputing systems, and its impact on the performance of applications is going\nto increase with the system size. In this paper, we will describe Slingshot, an\ninterconnection network for large scale computing systems. Slingshot is based\non high-radix switches, which allow building exascale and hyperscale\ndatacenters networks with at most three switch-to-switch hops. Moreover,\nSlingshot provides efficient adaptive routing and congestion control\nalgorithms, and highly tunable traffic classes. Slingshot uses an optimized\nEthernet protocol, which allows it to be interoperable with standard Ethernet\ndevices while providing high performance to HPC applications. We analyze the\nextent to which Slingshot provides these features, evaluating it on\nmicrobenchmarks and on several applications from the datacenter and AI worlds,\nas well as on HPC applications. We find that applications running on Slingshot\nare less affected by congestion compared to previous generation networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 10:55:27 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["De Sensi", "Daniele", ""], ["Di Girolamo", "Salvatore", ""], ["McMahon", "Kim H.", ""], ["Roweth", "Duncan", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2008.08900", "submitter": "Mozhgan Bayat", "authors": "Mozhgan Bayat and Kai Wan and Giuseppe Caire", "title": "Coded Caching over Multicast Routing Networks", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coded caching scheme originally proposed by Maddah-Ali and Niesen (MAN)\ntransmits coded multicast messages from a server to users equipped with caches\nvia a capacitated shared-link and was shown to be information theoretically\noptimal within a constant multiplicative factor. This work extends the MAN\nscheme to a class of two-hop wired-wireless networks including one server\nconnected via fronthaul links to a layer of $H$ helper nodes (access\npoints/base stations), which in turns communicate via a wireless access network\nto $K$ users, each equipped with its own cache. Two variants are considered,\nwhich differ in the modeling of the access segment. Both models should be\nregarded as abstractions at the network layer for physical scenarios such as\nlocal area networks and cellular networks, spatially distributed over a certain\ncoverage area. The key focus of our approach consists of routing MAN-type\nmulticast messages through the network and formulating the optimal routing\nscheme as an optimization problem that can be solved exactly or for which we\ngive powerful heuristic algorithms. Our approach solves at once many of the\nopen practical problems identified as stumbling blocks for the application of\ncoded caching in practical scenarios, namely: asynchronous streaming sessions,\nfinite file size, scalability of the scheme to large and spatially distributed\nnetworks, user mobility and random activity (users joining and leaving the\nsystem at arbitrary times), decentralized prefetching of the cache contents,\nend-to-end encryption of HTTPS requests, which renders the helper nodes\noblivious of the user demands.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 11:37:21 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Bayat", "Mozhgan", ""], ["Wan", "Kai", ""], ["Caire", "Giuseppe", ""]]}, {"id": "2008.08973", "submitter": "Evita Bakopoulou", "authors": "Evita Bakopoulou, Anastasia Shuba, Athina Markopoulou", "title": "Exposures Exposed: A Measurement and User Study to Assess Mobile Data\n  Privacy in Context", "comments": "arXiv admin note: text overlap with arXiv:1803.01261", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices have access to personal, potentially sensitive data, and there\nis a large number of mobile applications and third-party libraries that\ntransmit this information over the network to remote servers (including app\ndeveloper servers and third party servers). In this paper, we are interested in\nbetter understanding of not just the extent of personally identifiable\ninformation (PII) exposure, but also its context i.e., functionality of the\napp, destination server, encryption used, etc.) and the risk perceived by\nmobile users today. To that end we take two steps. First, we perform a\nmeasurement study: we collect a new dataset via manual and automatic testing\nand capture the exposure of 16 PII types from 400 most popular Android apps. We\nanalyze these exposures and provide insights into the extent and patterns of\nmobile apps sharing PII, which can be later used for prediction and prevention.\nSecond, we perform a user study with 220 participants on Amazon Mechanical\nTurk: we summarize the results of the measurement study in categories, present\nthem in a realistic context, and assess users' understanding, concern, and\nwillingness to take action. To the best of our knowledge, our user study is the\nfirst to collect and analyze user input in such fine granularity and on actual\n(not just potential or permitted) privacy exposures on mobile devices. Although\nmany users did not initially understand the full implications of their PII\nbeing exposed, after being better informed through the study, they became\nappreciative and interested in better privacy practices.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 02:42:30 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Bakopoulou", "Evita", ""], ["Shuba", "Anastasia", ""], ["Markopoulou", "Athina", ""]]}, {"id": "2008.09019", "submitter": "Abusayeed Saifullah", "authors": "Sezana Fahmida, Venkata P Modekurthy, Mahbubur Rahman, Abusayeed\n  Saifullah, Marco Brocanelli", "title": "Long-Lived LoRa: Prolonging the Lifetime of a LoRa Network", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prolonging the network lifetime is a major consideration in many Internet of\nThings applications. In this paper, we study maximizing the network lifetime of\nan energy-harvesting LoRa network. Such a network is characterized by\nheterogeneous recharging capabilities across the nodes that is not taken into\naccount in existing work. We propose a link-layer protocol to achieve a\nlong-lived LoRa network which dynamically enables the nodes with depleting\nbatteries to exploit the superfluous energy of the neighboring nodes with\naffluent batteries by letting a depleting node offload its packets to an\naffluent node. By exploiting the LoRa's capability of adjusting multiple\ntransmission parameters, we enable low-cost offloading by depleting nodes\ninstead of high-cost direct forwarding. Such offloading requires\nsynchronization of wake-up times as well as transmission parameters between the\ntwo nodes which also need to be selected dynamically. The proposed protocol\naddresses these challenges and prolongs the lifetime of a LoRa network through\nthree novel techniques. (1) We propose a lightweight medium access control\nprotocol for peer-to-peer communication to enable packet offloading which\ncircumvents the synchronization overhead between the two nodes. (2) We propose\nan intuitive heuristic method for effective parameter selections for different\nmodes (conventional vs. offloading). (3) We analyze the energy overhead of\noffloading and, based on it, the protocol dynamically selects affluent and\ndepleting nodes while ensuring that an affluent node is not overwhelmed by the\ndepleting ones. Simulations in NS-3 as well as real experiments show that our\nprotocol can increase the network lifetime up to $4$ times while maintaining\nthe same throughput compared to traditional LoRa network.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 15:16:59 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Fahmida", "Sezana", ""], ["Modekurthy", "Venkata P", ""], ["Rahman", "Mahbubur", ""], ["Saifullah", "Abusayeed", ""], ["Brocanelli", "Marco", ""]]}, {"id": "2008.09156", "submitter": "Qahhar M Qadir", "authors": "Qahhar Muhammad Qadir, Alexander A. Kist, and Zhongwei Zhang", "title": "Mechanisms for QoE optimisation of Video Traffic: A review paper", "comments": "18 pages, 7 figures", "journal-ref": "Australasian Journal of Information, Communication Technology and\n  Applications. 1 (2) (2015) 1-18", "doi": "10.17972/ajicta2015117", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transmission of video traffic over the Internet has grown exponentially in\nthe past few years with no sign of waning. This increasing demand for video\nservices has changed user expectation of quality. Various mechanisms have been\nproposed to optimise the Quality of Experience (QoE) of end users video.\nStudying these approaches are necessary for new methods to be proposed or\ncombination of existing ones to be tailored. We discuss challenges facing the\noptimisation of QoE for video traffic in this paper. It surveys and classifies\nthese mechanisms based on their functions. The limitation of each of them is\nidentified and future directions are highlighted.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:57:24 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Qadir", "Qahhar Muhammad", ""], ["Kist", "Alexander A.", ""], ["Zhang", "Zhongwei", ""]]}, {"id": "2008.09190", "submitter": "Qahhar M Qadir", "authors": "Qahhar Muhammad Qadir, Alexander A. Kist and Zhongwei Zhang", "title": "A quality of experience-aware cross-layer architecture for optimizing\n  video streaming services", "comments": "15 pages, 13 figures", "journal-ref": "Computer Networks, vol. 102, pp. 38-49, 2016", "doi": "10.1016/j.comnet.2016.02.030", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The popularity of the video services on the Internet has evolved various\nmechanisms that target the Quality of Experience (QoE) optimization of video\ntraffic. The video quality has been enhanced through adapting the sending\nbitrates. However, rate adaptation alone is not sufficient for maintaining a\ngood video QoE when congestion occurs. This paper presents a cross-layer\narchitecture for video streaming that is QoE-aware. It combines adaptation\ncapabilities of video applications and QoE-aware admission control to optimize\nthe trade-off relationship between QoE and the number of admitted sessions.\nSimulation results showed the efficiency of the proposed architecture in terms\nof QoE and number of sessions compared to two other architectures (adaptive\narchitecture and non-adaptive architecture).\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 20:14:02 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Qadir", "Qahhar Muhammad", ""], ["Kist", "Alexander A.", ""], ["Zhang", "Zhongwei", ""]]}, {"id": "2008.09214", "submitter": "Octav Chipara", "authors": "Ryan Brummet, Md Kowsar Hossain, Octav Chipara, Ted Herman, David E.\n  Steward", "title": "Recorp: Receiver-Oriented Policies for Industrial Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future Industrial Internet-of-Things (IIoT) systems will require wireless\nsolutions to connect sensors, actuators, and controllers as part of high data\nrate feedback-control loops over real-time flows. A key challenge in such\nnetworks is to provide predictable performance and adaptability in response to\nlink quality variations. We address this challenge by developing RECeiver\nORiented Policies (Recorp), which leverages the stability of IIoT workloads by\ncombining offline policy synthesis and run-time adaptation. Compared to\nschedules that service a single flow in a slot, Recorp policies share slots\namong multiple flows by assigning a coordinator and a list of flows that may be\nserviced in the same slot. At run-time, the coordinator will execute one of the\nflows depending on which flows the coordinator has already received. A salient\nfeature of Recorp is that it provides predictable performance: a policy meets\nthe end-to-end reliability and deadline of flows when the link quality exceeds\na user-specified threshold. Experiments show that across IIoT workloads,\npolicies provided a median increase of 50% to 142% in real-time capacity and a\nmedian decrease of 27% to 70% in worst-case latency when schedules and policies\nare configured to meet an end-to-end reliability of 99%.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 21:41:13 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 17:02:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Brummet", "Ryan", ""], ["Hossain", "Md Kowsar", ""], ["Chipara", "Octav", ""], ["Herman", "Ted", ""], ["Steward", "David E.", ""]]}, {"id": "2008.09336", "submitter": "Francesco Malandrino", "authors": "Francesco Malandrino and Carla Fabiana Chiasserini and Gian Michele\n  Dell'Aera", "title": "An Edge-powered Approach to Assisted Driving", "comments": "GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automotive services for connected vehicles are one of the main fields of\napplication for new-generation mobile networks as well as for the edge\ncomputing paradigm. In this paper, we investigate a system architecture that\nintegrates the distributed vehicular network with the network edge, with the\naim to optimize the vehicle travel times. We then present a queue-based system\nmodel that permits the optimization of the vehicle flows, and we show its\napplicability to two relevant services, namely, lane change/merge\n(representative of cooperative assisted driving) and navigation. Furthermore,\nwe introduce an efficient algorithm called Bottleneck Hunting (BH), able to\nformulate high-quality flow policies in linear time. We assess the performance\nof the proposed system architecture and of BH through a comprehensive and\nrealistic simulation framework, combining ns-3 and SUMO. The results, derived\nunder real-world scenarios, show that our solution provides much shorter travel\ntimes than when decisions are made by individual vehicles.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 07:03:15 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Malandrino", "Francesco", ""], ["Chiasserini", "Carla Fabiana", ""], ["Dell'Aera", "Gian Michele", ""]]}, {"id": "2008.09339", "submitter": "Ayyoob Hamza", "authors": "Ayyoob Hamza, Hassan Habibi Gharakheili, Vijay Sivaraman", "title": "IoT Network Security: Requirements, Threats, and Countermeasures", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT devices are increasingly utilized in critical infrastructure,\nenterprises, and households. There are several sophisticated cyber-attacks that\nhave been reported and many networks have proven vulnerable to both active and\npassive attacks by leaking private information, allowing unauthorized access,\nand being open to denial of service attacks.\n  This paper aims firstly, to assist network operators to understand the need\nfor an IoT network security solution, and then secondly, to survey IoT network\nattack vectors, cyber threats, and countermeasures with a focus on improving\nthe robustness of existing security solutions. Our first contribution\nhighlights viewpoints on IoT security from the perspective of stakeholders such\nas manufacturers, service providers, consumers, and authorities. We discuss the\ndifferences between IoT and IT systems, the need for IoT security solutions,\nand we highlight the key components required for IoT network security system\narchitecture. For our second contribution, we survey the types of IoT attacks\nby grouping them based on their impact. We discuss various attack techniques,\nthreats, and shortfalls of existing countermeasures with an intention to enable\nfuture research into improving IoT network security.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 07:19:32 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Hamza", "Ayyoob", ""], ["Gharakheili", "Hassan Habibi", ""], ["Sivaraman", "Vijay", ""]]}, {"id": "2008.09438", "submitter": "Ayt\\\"ul Bozkurt", "authors": "Ayt\\\"ul Bozkurt", "title": "Analytical models and performance evaluation of\n  vehicular-to-infrastructure networks with optimal retransmission number", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vehicle-to-infrastructure and vehicle-to-vehicle communications has been\nintroduced to provide high rate Internet connectivity to vehicles to meet the\nubiquitous coverage and increasing high-data rate internet and multimedia\ndemands by utilizing the 802.11 access points (APs) used along the roadside. In\norder to evaluate the performance of vehicular networks over WLAN, in this\npaper, we investigate the transmisison and network performance of vehicles that\npass through AP by condidering contention nature of vehicles over 802.11 WLANs.\nFirstly, we derived an analytical traffic model to obtain the number of\nvehicles under transmision range of an AP. Then, incorporating vehicle traffic\nmodel with Markov chain model and for arrival packets, MG1K queuing system, we\ndeveloped a model evaluating the performance of DCF mechanism with an optimal\nretransmission number. Based on traffic model, we also derived the probability\nof mean arrival rate to AP. A distinctive aspect of our work is that it\nincorporates both vehicular traffic model and backoff procedure with M/G/1/K\nqueuing model to investigate the impact of various traffic load conditions and\nsystem parameters on the vehicular network system. Based on our model, we show\nthat the delay and througput performance of the system reduces with the\nincreasing vehicle velocity due to optimal retransmision number m, which is\nadaptively adjusted in the network with vehicle mobility.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 12:08:45 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Bozkurt", "Ayt\u00fcl", ""]]}, {"id": "2008.09462", "submitter": "Xiyu Wang", "authors": "Xiyu Wang, H\\\"useyin Yi\\u{g}itler, Ruifeng Duan, Estifanos Yohannes\n  Menta, Riku J\\\"antti", "title": "Coherent Multi-antenna Receiver for BPSK-modulated Ambient Backscatter\n  Tags", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambient Backscatter Communication (AmBC) is an emerging communication\ntechnology that can enable green Internet-of-Things deployments. The widespread\nacceptance of this paradigm is limited by low Signal-to-Interference-Plus-Noise\nRatio (SINR) of the signal impinging on the receiver antenna due to the strong\ndirect path interference and unknown ambient signal. The adverse impact of\nthese two factors can be mitigated by using non-coherent multi-antenna\nreceivers, which is known to require higher SINR to reach Bit-Error-Rate (BER)\nperformance of coherent receivers. However, in literature, coherent receivers\nfor AmBC systems are little-studied because of unknown ambient signal, unknown\nlocation of AmBC tags, and varying channel conditions. In this paper, a\ncoherent multi-antenna receiver, which does not require a prior information of\nthe ambient signal, for decoding Binary-Phase-shift-Keying (BPSK) modulated\nsignal is presented. The performance of the proposed receiver is compared with\nthe ideal coherent receiver that has a perfect phase information, and also with\nthe performance of non-coherent receiver, which assumes distributions for\nambient signal and phase offset caused by excess length of the backscatter\npath. Comparative simulation results show the designed receiver can achieve the\nsame BER-performance of the ideal coherent receiver with 1-dB more SINR, which\ncorresponds to 5-dB or more gain with respect to non-coherent reception of\nOn-Off-Keying modulated signals. Variation of the detection performance with\nthe tag location shows that the coverage area is in the close vicinity of the\ntransmitter and a larger region around the receiver, which is consistent with\nthe theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:19:46 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Wang", "Xiyu", ""], ["Yi\u011fitler", "H\u00fcseyin", ""], ["Duan", "Ruifeng", ""], ["Menta", "Estifanos Yohannes", ""], ["J\u00e4ntti", "Riku", ""]]}, {"id": "2008.09504", "submitter": "Junjie Yu", "authors": "JunJie Yu, Han Wang, Mingxiong Zhao, WenTao Li, HuiQi Bao, Li Yin, Mi\n  Wu", "title": "Energy Minimization for Mobile Edge Computing Networks with\n  Time-Sensitive Constraints", "comments": "IEEE GLOBECOM 2020. arXiv admin note: substantial text overlap with\n  arXiv:2003.12719", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing (MEC) provides users with a high quality experience\n(QoE) by placing servers with rich services close to the end users. Compared\nwith local computing, MEC can contribute to energy saving, but results in\nincreased communication latency. In this paper, we jointly optimize task\noffloading and resource allocation to minimize the energy consumption in an\northogonal frequency division multiple access (OFDMA)-based MEC networks, where\nthe time-sensitive tasks can be processed at both local users and MEC server\nvia partial offloading. Since the optimization variables of the problem are\nstrongly coupled, we first decompose the original problem into two subproblems\nnamed as offloading selection (PO), and subcarriers and computing resource\nallocation (PS), and then propose an iterative algorithm to deal with them in a\nsequence. To be specific, we derive the closed-form solution for PO, and deal\nwith PS by an alternating way in the dual domain due to its NP-hardness.\nSimulation results demonstrate\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:03:24 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Yu", "JunJie", ""], ["Wang", "Han", ""], ["Zhao", "Mingxiong", ""], ["Li", "WenTao", ""], ["Bao", "HuiQi", ""], ["Yin", "Li", ""], ["Wu", "Mi", ""]]}, {"id": "2008.09519", "submitter": "Chuan-Chi Lai", "authors": "Chuan-Chi Lai, Li-Chun Wang, Zhu Han", "title": "The Coverage Overlapping Problem of Serving Arbitrary Crowds in 3D Drone\n  Cellular Networks", "comments": "18 pages, 10 figures, to appear in IEEE Transactions on Mobile\n  Computing. arXiv admin note: text overlap with arXiv:1909.11554", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing coverage for flash crowds is an important application for drone\nbase stations (DBSs). However, any arbitrary crowd is likely to be distributed\nat a high density. Under the condition for each DBS to serve the same number of\nground users, multiple DBSs may be placed at the same horizontal location but\ndifferent altitudes and will cause severe co-channel interference, to which we\nrefer as the coverage overlapping problem. To solve this problem, we then\nproposed the data-driven 3D placement (DDP) and the enhanced DDP (eDDP)\nalgorithms. The proposed DDP and eDDP can effectively find the appropriate\nnumber, altitude, location, and coverage of DBSs in the serving area in\npolynomial time to maximize the system sum rate and guarantee the minimum data\nrate requirement of the user equipment. The simulation results show that,\ncompared with the balanced k-means approach, the proposed eDDP can increase the\nsystem sum rate by 200% and reduce the computation time by 50%. In particular,\neDDP can effectively reduce the occurrence of the coverage overlapping problem\nand then outperform DDP by about 100% in terms of system sum rate.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:55:19 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Lai", "Chuan-Chi", ""], ["Wang", "Li-Chun", ""], ["Han", "Zhu", ""]]}, {"id": "2008.09523", "submitter": "Xiyu Wang", "authors": "Xiyu Wang, H\\\"useyin Yi\\u{g}itler, Riku J\\\"antti", "title": "Optimum Multi-Antenna Ambient Backscatter Receiver for General\n  Binary-Modulated Signal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambient backscatter communication (AmBC) is becoming increasingly popular for\nenabling green communication amidst the continual development of the\nInternet-of-things paradigm. Efforts have been put into backscatter signal\ndetection as the detection performance is limited by the low\nsignal-to-interference-plus-noise ratio (SINR) of the signal at the receiver.\nThe low SINR can be improved by adopting a multi-antenna receiver. In this\npaper, the optimum multi-antenna receiver that does not impose any constraints\non the types of binary modulation performed by the backscatter device and the\nwaveform used by the ambient source system is studied. The proposed receiver\nowns a simple structure formed by two beamformers. Bit error rate (BER)\nperformances of the optimum receiver are derived under constant-amplitude\nambient signal and Gaussian-distributed ambient signal. Moreover, to facilitate\nthe implementation of the optimum receiver, a simplified receiver is proposed\nand practical approximations to required beamformers are provided. The derived\noptimum receiver avoids the complex direct path interference cancellation and\ncoherent reception, but exploits the fact that backscatter signal changes the\ncomposite channel impinging at the receiver and the directivity of receiver\nantenna array. Comparative simulation results show that the performance of the\noptimum receiver achieves the same performance as the coherent receiver even\nthough it realizes non-coherent reception. The studied receivers provide high\nflexibility for implementing simple and low-cost receivers in different AmBC\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:56:25 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Wang", "Xiyu", ""], ["Yi\u011fitler", "H\u00fcseyin", ""], ["J\u00e4ntti", "Riku", ""]]}, {"id": "2008.09559", "submitter": "Paresh Saxena", "authors": "Paresh Saxena, Mandan Naresh, Manik Gupta, Anirudh Achanta, Sastri\n  Kota and Smrati Gupta", "title": "NANCY: Neural Adaptive Network Coding methodologY for video distribution\n  over wireless networks", "comments": "Accepted in Globecom, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents NANCY, a system that generates adaptive bit rates (ABR)\nfor video and adaptive network coding rates (ANCR) using reinforcement learning\n(RL) for video distribution over wireless networks. NANCY trains a neural\nnetwork model with rewards formulated as quality of experience (QoE) metrics.\nIt performs joint optimization in order to select: (i) adaptive bit rates for\nfuture video chunks to counter variations in available bandwidth and (ii)\nadaptive network coding rates to encode the video chunk slices to counter\npacket losses in wireless networks. We present the design and implementation of\nNANCY, and evaluate its performance compared to state-of-the-art video rate\nadaptation algorithms including Pensieve and robustMPC. Our results show that\nNANCY provides 29.91% and 60.34% higher average QoE than Pensieve and\nrobustMPC, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 15:55:32 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Saxena", "Paresh", ""], ["Naresh", "Mandan", ""], ["Gupta", "Manik", ""], ["Achanta", "Anirudh", ""], ["Kota", "Sastri", ""], ["Gupta", "Smrati", ""]]}, {"id": "2008.09590", "submitter": "Majid Raeis", "authors": "Majid Raeis, Ali Tizghadam and Alberto Leon-Garcia", "title": "Reinforcement Learning-based Admission Control in Delay-sensitive\n  Service Systems", "comments": "7 pages, to be presented at IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring quality of service (QoS) guarantees in service systems is a\nchallenging task, particularly when the system is composed of more fine-grained\nservices, such as service function chains. An important QoS metric in service\nsystems is the end-to-end delay, which becomes even more important in\ndelay-sensitive applications, where the jobs must be completed within a time\ndeadline. Admission control is one way of providing end-to-end delay guarantee,\nwhere the controller accepts a job only if it has a high probability of meeting\nthe deadline. In this paper, we propose a reinforcement learning-based\nadmission controller that guarantees a probabilistic upper-bound on the\nend-to-end delay of the service system, while minimizes the probability of\nunnecessary rejections. Our controller only uses the queue length information\nof the network and requires no knowledge about the network topology or system\nparameters. Since long-term performance metrics are of great importance in\nservice systems, we take an average-reward reinforcement learning approach,\nwhich is well suited to infinite horizon problems. Our evaluations verify that\nthe proposed RL-based admission controller is capable of providing\nprobabilistic bounds on the end-to-end delay of the network, without using\nsystem model information.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 17:33:55 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Raeis", "Majid", ""], ["Tizghadam", "Ali", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "2008.09601", "submitter": "Houssam Kayyali", "authors": "Sam Kayyali", "title": "Resource Management and Quality of Service Provisioning in 5G Cellular\n  Networks", "comments": "21 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the commercial launch of 5G technologies and fast pace of expansion of\ncellular network infrastructure, it is expected that cellular and mobile\nnetworks traffic will exponentially increase. In addition, new services are\nexpected to spread widely, such as the Internet of Things connected to mobile\nnetworks. This will add additional burden in terms of traffic load. As a\nresult, some studies suggest that mobile traffic may increase more than 1000\ntimes compared to the amount of traffic that is generated nowadays. This means\nthat network resources for mobile services must be managed and controlled in a\nsmart way, because resources are always limited, but the demand for services\nand the need for keeping user equipment always connected to mobile networks can\nbe considered unlimited, leaving gap between huge service demands and available\nresources. In order to narrow this gap, major consideration should be given to\nthe management of network resources to avoid network congestion and performance\ndegradation during peak hour/s and traffic spikes, and allow access to network\nservices to more customers when demand is high. On the other hand, guaranteeing\nquality of service requirements for the wide range of new services is another\nchallenge that must be met in 5G networks. In this paper we will review 5G\nnetworks characteristics and specifications, then carry out a survey on\nresource management and QoS provisioning to improve and manage resource\nutilization in 5G networks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 17:53:43 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Kayyali", "Sam", ""]]}, {"id": "2008.09841", "submitter": "Christian Killer", "authors": "Christian Killer, Lucas Thorbecke, Bruno Rodrigues, Eder Scheid,\n  Muriel Franco, Burkhard Stiller", "title": "Proverum: A Hybrid Public Verifiability and Decentralized Identity\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust in electoral processes is fundamental for democracies. Further, the\nidentity management of citizen data is crucial, because final tallies cannot be\nguaranteed without the assurance that every final vote was cast by an eligible\nvoter. In order to establish a basis for a hybrid public verifiability of\nvoting, this work (1) introduces Proverum, an approach combining a private\nenvironment based on private permissioned Distributed Ledgers with a public\nenvironment based on public Blockchains, (2) describes the application of the\nProverum architecture to the Swiss Remote Postal Voting system, mitigating\nthreats present in the current system, and (3) addresses successfully the\ndecentralized identity management in a federalistic state.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 13:53:55 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Killer", "Christian", ""], ["Thorbecke", "Lucas", ""], ["Rodrigues", "Bruno", ""], ["Scheid", "Eder", ""], ["Franco", "Muriel", ""], ["Stiller", "Burkhard", ""]]}, {"id": "2008.09933", "submitter": "Hong-Ning Dai Prof.", "authors": "Hong-Ning Dai and Muhammad Imran and Noman Haider", "title": "Blockchain-enabled Internet of Medical Things to Combat COVID-19", "comments": "7 pages, 4 figures, 1 table", "journal-ref": "IEEE Internet of Things Magazine, 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We are experiencing an unprecedented healthcare crisis caused by\nnewly-discovered corona-virus disease (COVID-19). The outbreaks of COVID-19\nreveal the frailties of existing healthcare systems. Therefore, the digital\ntransformation of healthcare systems becomes an inevitable trend. During this\nprocess, the Internet of Medical Things (IoMT) plays a crucial role while\nintrinsic vulnerabilities of security and privacy deter the wide adoption of\nIoMT. In this article, we present a blockchain-enabled IoMT to address the\nsecurity and privacy concerns of IoMT systems. We also discuss the solutions\nbrought by blockchain-enabled IoMT to COVID-19 from five different\nperspectives. Moreover, we outline the open challenges and future directions of\nblockchain-enabled IoMT.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 00:46:03 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Dai", "Hong-Ning", ""], ["Imran", "Muhammad", ""], ["Haider", "Noman", ""]]}, {"id": "2008.09959", "submitter": "Christina Chaccour", "authors": "Christina Chaccour and Walid Saad", "title": "On the Ruin of Age of Information in Augmented Reality over Wireless\n  Terahertz (THz) Networks", "comments": "6 pages. Accepted for presentation at the IEEE Global Communications\n  Conference (Globecom), Taipei, Taiwan, Dec. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guaranteeing fresh and reliable information for augmented reality (AR)\nservices is a key challenge to enable a real-time experience and sustain a high\nquality of physical experience (QoPE) for the users. In this paper, a terahertz\n(THz) cellular network is used to exchange rate-hungry AR content. For this\nnetwork, guaranteeing an instantaneous low peak age of information (PAoI) is\nnecessary to overcome the uncertainty stemming from the THz channel. In\nparticular, a novel economic concept, namely, the risk of ruin is proposed to\nexamine the probability of occurrence of rare, but extremely high PAoI that can\njeopardize the operation of the AR service. To assess the severity of these\nhazards, the cumulative distribution function (CDF) of the PAoI is derived for\ntwo different scheduling policies. This CDF is then used to find the\nprobability of maximum severity of ruin PAoI. Furthermore, to provide long term\ninsights about the AR content's age, the average PAoI of the overall system is\nalso derived. Simulation results show that an increase in the number of users\nwill positively impact the PAoI in both the expected and worst-case scenarios.\nMeanwhile, an increase in the bandwidth reduces the average PAoI but leads to a\ndecline in the severity of ruin performance. The results also show that a\nsystem with preemptive last come first served (LCFS) queues of limited size\nbuffers have a better ruin performance (12% increase in the probability of\nguaranteeing a less severe PAoI while increasing the number of users), whereas\nfirst come first served (FCFS) queues of limited buffers lead to a better\naverage PAoI performance (45% lower PAoI as we increase the bandwidth).\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 05:08:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Chaccour", "Christina", ""], ["Saad", "Walid", ""]]}, {"id": "2008.10107", "submitter": "Qahhar M Qadir", "authors": "Qahhar Muhammad Qadir, Alexander A. Kist and Zhongwei Zhang", "title": "Optimization of Quality of Experience for Video Traffic", "comments": "5 pages, 9 figures", "journal-ref": "22nd International Conference on Telecommunications (ICT), pp.\n  408-412, 2015", "doi": "10.1109/ICT.2015.7124720", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid shift toward video on-demand and real time information systems has\naffected mobile as well as wired networks. The research community has placed a\nstrong focus on optimizing the Quality of Experience (QoE) of video traffic,\nmainly because video is popular among Internet users. Techniques have been\nproposed in different directions towards improvement of the perception of video\nusers. This paper investigates the performance of a novel cross-layer\narchitecture for optimizing the QoE of video traffic. The proposed architecture\nis compared to two other architectures; non-adaptive and adaptive. For the\nformer, video traffic is sent without adaptation, whereas for the later video\nsources adapt their transmission rate. Both are compared in terms of the mean\nopinion score of video sessions, number of sessions, delay, packet drop ratio,\njitter and utilization. The results from extensive simulations show that the\nproposed architecture outperforms the non-adaptive and adaptive architectures\nfor video traffic.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 21:07:33 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Qadir", "Qahhar Muhammad", ""], ["Kist", "Alexander A.", ""], ["Zhang", "Zhongwei", ""]]}, {"id": "2008.10210", "submitter": "JaeYoung Hwang", "authors": "JaeYoung Hwang, Lionel Nkenyereye, NakMyoung Sung, JaeHo Kim, and\n  JaeSeung Song", "title": "IoT service slicing and task offloading for edge computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of IoT technology, various domains such as smart\nfactories, smart cities and smart cars use the IoT to provide value-added\nservices. In addition, technologies such as MEC and network slicing provide\nanother opportunity for the IoT to support more advanced and real-time services\nthat could not have been previously supported. However, the simple integration\nof such technologies into the IoT does not take full advantage of MEC and\nnetwork slicing or the reduction of latency and traffic prioritization,\nrespectively. Therefore, there is a strong need for an efficient integration\nmechanism for IoT platforms to maximize the benefit of using such technologies.\nIn this article, we introduce a novel architectural framework that enables the\nvirtualization of an IoT platform with minimum functions to support specific\nIoT services and host the instance in an edge node, close to the end-user. As\nthe instance provides its service at the edge node where the MEC node and\nnetwork slice are located, the traffic for the end-user does not need to\ntraverse back to the cloud. This architecture guarantees not only low latency\nbut also efficient management of IoT services at the edge node. To show the\nfeasibility of the proposed architecture, we conduct an experimental evaluation\nby comparing the transmission time of both IoT services running on the central\ncloud and those using sliced IoT functions in the edge gateway. The results\nshow that the proposed architecture provides two times faster transmission time\nthan that from the conventional cloud-based IoT platform.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 06:13:21 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Hwang", "JaeYoung", ""], ["Nkenyereye", "Lionel", ""], ["Sung", "NakMyoung", ""], ["Kim", "JaeHo", ""], ["Song", "JaeSeung", ""]]}, {"id": "2008.10357", "submitter": "Qahhar M Qadir", "authors": "Safeen Qadir, Alexander A. Kist and Zhongwei Zhang", "title": "QoE-aware cross-layer architecture for video traffic over Internet", "comments": "6 pages, 6 pages", "journal-ref": "Region 10 Symposium 2014 IEEE, pp. 522-526, Apr. 2014", "doi": "10.1109/TENCONSpring.2014.6863089", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of video applications and video capable devices have\ncontributed substantially to the increase of video traffic on Internet. New\nmechanisms recommending video rate adaptation towards delivering enhanced\nQuality of Experience (QoE) at the same time making room for more sessions.\nThis paper introduces a cross-layer QoE-aware architecture for video traffic\nover the Internet. It proposes that video sources at the application layer\nadapt their rate to the network environment by controlling their transmitted\nbit rate dynamically; and the edge of network at the network layer protects the\nquality of the active video sessions by controlling the acceptance of new\nsession through a video-aware admission control. In particular, it will seek\nthe most efficient way of accepting new video session and adapting transmission\nrates to free up resources for more session while maintaining the QoE of active\nsessions. The proposed framework will contribute to the preparation for the\nextreme growth of video traffic in the foreseeable future. Simulation results\nshow that the proposed cross-layer architecture guarantees the QoE for the\nadmitted sessions and utilizes the link more efficiently comparing to the rate\nadaptation only architecture.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 12:15:35 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Qadir", "Safeen", ""], ["Kist", "Alexander A.", ""], ["Zhang", "Zhongwei", ""]]}, {"id": "2008.10406", "submitter": "Ido Zoref", "authors": "Ido Zoref and Ariel Orda", "title": "An Efficient Algorithm for Finding Sets of Optimal Routes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several important routing contexts it is required to identify a set of\nroutes, each of which optimizes a different criterion. For instance, in the\ncontext of vehicle routing, one route would minimize the total distance\ntraveled, while other routes would also consider the total travel time or the\ntotal incurred cost, or combinations thereof. In general, providing such a set\nof diverse routes is obtained by finding optimal routes with respect to\ndifferent sets of weights on the network edges. This can be simply achieved by\nconsecutively executing a standard shortest path algorithm. However, in the\ncase of a large number of weight sets, this may require an excessively large\nnumber of executions of such an algorithm, thus incurring a prohibitively large\nrunning time.\n  We indicate that, quite often, the different edge weights reflect different\ncombinations of some \"raw\" performance metrics (e.g., delay, cost). In such\ncases, there is an inherent dependency among the different weights of the same\nedge. This may well result in some similarity among the shortest routes, each\nof which being optimal with respect to a specific set of weights. In this\nstudy, we aim to exploit such similarity in order to improve the performance of\nthe solution scheme.\n  Specifically, we contemplate edge weights that are obtained through different\nlinear combinations of some (``raw'') edge performance metrics. We establish\nand validate a novel algorithm that efficiently computes a shortest path for\neach set of edge weights. We demonstrate that, under reasonable assumptions,\nthe algorithm significantly outperforms the standard approach. Similarly to the\nstandard approach, the algorithm iteratively searches for routes, one per set\nof edge weights; however, instead of executing each iteration independently, it\nreduces the average running time by skillfully sharing information among the\niterations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:06:33 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zoref", "Ido", ""], ["Orda", "Ariel", ""]]}, {"id": "2008.10441", "submitter": "Juan Ospina", "authors": "Colin Ogilvie, Juan Ospina, Charalambos Konstantinou, Tuyen Vu, Mark\n  Stanovich, Karl Schoder, and Mischa Steurer", "title": "Modeling Communication Networks in a Real-Time Simulation Environment\n  for Evaluating Controls of Shipboard Power Systems", "comments": "7 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest by the U.S. Navy in the development and deployment of advanced\ncontrols in future shipboard platforms has motivated the development of the\nControls Evaluation Framework (CEF) for use in investigating dynamics present\nin complex automated systems. This paper reports on the implementation and\ninvestigation of a communication network component within the CEF. This\nimplementation is designed to augment the CEF's available feature set,\npermitting the exploration of various communication conditions on advanced\ncontrol performance. Results obtained from controller hardware-in-the-loop\ntesting are presented and analyzed to demonstrate performance characteristics\npertaining to the implemented module.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 17:44:03 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ogilvie", "Colin", ""], ["Ospina", "Juan", ""], ["Konstantinou", "Charalambos", ""], ["Vu", "Tuyen", ""], ["Stanovich", "Mark", ""], ["Schoder", "Karl", ""], ["Steurer", "Mischa", ""]]}, {"id": "2008.10448", "submitter": "Feng Xia", "authors": "Hannan Bin Liaqat, Feng Xia, Jianhua Ma, Laurence Tianruo Yang,\n  Ahmedin Mohammed Ahmed, and Nana Yaw Asabere", "title": "Social-Similarity-aware TCP with Collision Avoidance in Ad-hoc Social\n  Networks", "comments": "10 pages, 10 figures", "journal-ref": "IEEE Systems Journal, vol. 9, no.4, pp: 1273-1284, 2015", "doi": "10.1109/JSYST.2014.2305191", "report-no": null, "categories": "cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ad-hoc Social Network (ASNET), which explores social connectivity between\nusers of mobile devices, is becoming one of the most important forms of today's\ninternet. In this context, maximum bandwidth utilization of intermediate nodes\nin resource scarce environments is one of the challenging tasks. Traditional\nTransport Control Protocol (TCP) uses the round trip time mechanism for sharing\nbandwidth resources between users. However, it does not explore socially-aware\nproperties between nodes and cannot differentiate effectively between various\ntypes of packet losses in wireless networks. In this paper, a socially-aware\ncongestion avoidance protocol, namely TIBIAS, which takes advantage of\nsimilarity matching social properties among intermediate nodes, is proposed to\nimprove the resource efficiency of ASNETs. TIBIAS performs efficient data\ntransfer over TCP. During the course of bandwidth resource allocation, it gives\nhigh priority for maximally matched interest similarity between different TCP\nconnections on ASNET links. TIBIAS does not require any modification at lower\nlayers or on receiver nodes. Experimental results show that TIBIAS performs\nbetter as compared against existing protocols, in terms of link utilization,\nunnecessary reduction of the congestion window, throughput and retransmission\nratio.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:46:13 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liaqat", "Hannan Bin", ""], ["Xia", "Feng", ""], ["Ma", "Jianhua", ""], ["Yang", "Laurence Tianruo", ""], ["Ahmed", "Ahmedin Mohammed", ""], ["Asabere", "Nana Yaw", ""]]}, {"id": "2008.10449", "submitter": "Feng Xia", "authors": "Feng Xia, Qiuyuan Yang, Jie Li, Jiannong Cao, Li Liu, Ahmedin Mohammed\n  Ahmed", "title": "Data Dissemination Using Interest Tree in Socially Aware Networking", "comments": "13 pages, 9 figures", "journal-ref": "Computer Networks, Vol. 91, November 2015, pp: 495-507", "doi": "10.1016/j.comnet.2015.08.047", "report-no": null, "categories": "cs.SI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Socially aware networking (SAN) exploits social characteristics of mobile\nusers to streamline data dissemination protocols in opportunistic environments.\nExisting protocols in this area utilized various social features such as user\ninterests, social similarity, and community structure to improve the\nperformance of data dissemination. However, the interrelationship between user\ninterests and its impact on the efficiency of data dissemination has not been\nexplored sufficiently. In this paper, we analyze various kinds of relationships\nbetween user interests and model them using a layer-based structure in order to\nform social communities in SAN paradigm. We propose Int-Tree, an Interest-Tree\nbased scheme which uses the relationship between user interests to improve the\nperformance of data dissemination. The core of Int-Tree is the interest-tree, a\ntree-based community structure that combines two social features, i.e. density\nof a community and social tie, to support data dissemination. The simulation\nresults show that Int-Tree achieves higher delivery ratio, lower overhead, in\ncomparison to two benchmark protocols, PROPHET and Epidemic routing. In\naddition, Int-Tree can perform with 1.36 hop counts in average, and tolerable\nlatency in terms of buffer size, time to live (TTL) and simulation duration.\nFinally, Int-Tree keeps stable performance with various parameters.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:45:52 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Xia", "Feng", ""], ["Yang", "Qiuyuan", ""], ["Li", "Jie", ""], ["Cao", "Jiannong", ""], ["Liu", "Li", ""], ["Ahmed", "Ahmedin Mohammed", ""]]}, {"id": "2008.10470", "submitter": "Qahhar M Qadir", "authors": "Safeen Qadir and Alexander A. Kist", "title": "Video-aware measurement-based admission control", "comments": "5 pages, 5 figures", "journal-ref": "in IEEE 2013 Australasian Telecommunication Networks and\n  Applications Conference, ATNAC 2013, Christchurch, New Zealand, Nov. 2013", "doi": "10.1109/ATNAC.2013.6705377", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using instantaneous aggregate arrival rate as an admission control parameter\nwill contribute to either bandwidth under-utilization or over-utilization.\nBeing bursty in nature and variable in rate, video flows might encode any rate\nbetween a range of minimum and maximum values. At the time the decision is\nmade, if the measured rate is at the minimum value, the bandwidth might be\nover-utilized due to accepting more sessions than the link can accommodate. In\ncontrast, it might be under-utilized if the measured rate is at the maximum\nvalue due to rejecting more sessions than the link can accommodate. The\nburstiness can be taken into account by considering the past history of the\ntraffic. This paper investigates the suitability of the average aggregate\narrival rate instead of the instantaneous aggregate arrival rate for video\nadmission decisions. It establishes a mathematical model to predict the\nrelationship between the two rates. Simulation results confirm that the average\naggregate arrival rate is a more efficient decision factor for a small number\nof flows. Although it has no additional advantage for moderate and large number\nof flows, it still can stabilize the admission decision by smoothing the\nburstiness of a set of the instantaneous rates (within the measurement period)\nover a period of time.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 14:18:40 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Qadir", "Safeen", ""], ["Kist", "Alexander A.", ""]]}, {"id": "2008.10497", "submitter": "Pouyan Fotouhi Tehrani", "authors": "Pouyan Fotouhi Tehrani, Eric Osterweil, Jochen H. Schiller, Thomas C.\n  Schmidt, Matthias W\\\"ahlisch", "title": "Security of Alerting Authorities in the WWW: Measuring Namespaces,\n  DNSSEC, and Web PKI", "comments": "12 pages and 8 figures", "journal-ref": "Proceedings of the Web Conference 2021 (WWW '21)", "doi": "10.1145/3442381.3450033", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During disasters, crisis, and emergencies the public relies on online\nservices provided by official authorities to receive timely alerts, trustworthy\ninformation, and access to relief programs. It is therefore crucial for the\nauthorities to reduce risks when accessing their online services. This includes\ncatering to secure identification of service, secure resolution of name to\nnetwork service, and content security and privacy as a minimum base for\ntrustworthy communication.\n  In this paper, we take a first look at Alerting Authorities (AA) in the US\nand investigate security measures related to trustworthy and secure\ncommunication. We study the domain namespace structure, DNSSEC penetration, and\nweb certificates. We introduce an integrative threat model to better understand\nwhether and how the online presence and services of AAs are harmed. As an\nillustrative example, we investigate 1,388 Alerting Authorities. We observe\npartial heightened security relative to the global Internet trends, yet find\ncause for concern as about 78% of service providers fail to deploy measures of\ntrustworthy service provision. Our analysis shows two major shortcomings.\nFirst, how the DNS ecosystem is leveraged: about 50% of organizations do not\nown their dedicated domain names and are dependent on others, 55% opt for\nunrestricted-use namespaces, which simplifies phishing, and less than 4% of\nunique AA domain names are secured by DNSSEC, which can lead to DNS poisoning\nand possibly to certificate misissuance. Second, how Web PKI certificates are\nutilized: 15% of all hosts provide none or invalid certificates, thus cannot\ncater to confidentiality and data integrity, 64% of the hosts provide domain\nvalidation certification that lack any identity information, and shared\ncertificates have gained on popularity, which leads to fate-sharing and can be\na cause for instability.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:02:09 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 21:12:42 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 08:44:09 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Tehrani", "Pouyan Fotouhi", ""], ["Osterweil", "Eric", ""], ["Schiller", "Jochen H.", ""], ["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "2008.10535", "submitter": "Kiichi Tokuyama", "authors": "Kiichi Tokuyama, Tatsuaki Kimura, and Naoto Miyoshi", "title": "Time-based Handover Skipping in Cellular Networks: Spatially Stochastic\n  Modeling and Analysis", "comments": "28 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handover (HO) management has attracted attention of research in the context\nof wireless cellular communication networks. One crucial problem of HO\nmanagement is to deal with increasing HOs experienced by a mobile user. To\naddress this problem, HO skipping techniques have been studied in recent years.\nIn this paper, we propose a novel HO skipping scheme, namely, time-based HO\nskipping. In the proposed scheme, HOs of a user are controlled by a certain\nfixed period of time, which we call skipping time. The skipping time can be\nmanaged as a system parameter, thereby enabling flexible operation of HO\nskipping. We analyze the transmission performance of the proposed scheme on the\nbasis of a stochastic geometry approach. In the scenario where a user performs\nthe time-based HO skipping, we derive the analytical expressions for two\nperformance metrics: the HO rate and the expected data rate. The analysis\nresults demonstrate that the scenario with the time-based HO skipping\noutperforms the scenario without HO skipping particularly when the user moves\nfast. Furthermore, we reveal that there is a unique optimal skipping time\nmaximizing the transmission performance, which we obtain approximately.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:16:46 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Tokuyama", "Kiichi", ""], ["Kimura", "Tatsuaki", ""], ["Miyoshi", "Naoto", ""]]}, {"id": "2008.10670", "submitter": "Konstantinos Koufos", "authors": "Konstantinos Koufos, Harpreet S. Dhillon, Mehrdad Dianati and Carl P.\n  Dettmann", "title": "On the $k$ Nearest-Neighbor Path Distance from the Typical Intersection\n  in the Manhattan Poisson Line Cox Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a Cox point process driven by the Manhattan\nPoisson line process. We calculate the exact cumulative distribution function\n(CDF) of the path distance (L1 norm) between a randomly selected intersection\nand the $k$-th nearest node of the Cox process. The CDF is expressed as a sum\nover the integer partition function $p\\!\\left(k\\right)$, which allows us to\nnumerically evaluate the CDF in a simple manner for practical values of $k$.\nThese distance distributions can be used to study the $k$-coverage of broadcast\nsignals transmitted from a \\ac{RSU} located at an intersection in intelligent\ntransport systems (ITS). Also, they can be insightful for network dimensioning\nin vehicle-to-everything (V2X) systems, because they can yield the exact\ndistribution of network load within a cell, provided that the \\ac{RSU} is\nplaced at an intersection. Finally, they can find useful applications in other\nbranches of science like spatial databases, emergency response planning, and\ndistricting. We corroborate the applicability of our distance distribution\nmodel using the map of an urban area.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 19:30:08 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 23:40:05 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Koufos", "Konstantinos", ""], ["Dhillon", "Harpreet S.", ""], ["Dianati", "Mehrdad", ""], ["Dettmann", "Carl P.", ""]]}, {"id": "2008.10928", "submitter": "Meysam Nasimi", "authors": "Meysam Nasimi, Mohammad Asif Habibi, and Hans D. Schotten", "title": "Platoon--assisted Vehicular Cloud in VANET: Vision and Challenges", "comments": "This paper presented in European Symposium on Computer and\n  Communications (ESCC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NI cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent connected vehicles equipped with wireless sensors, intelligent\ncontrol system, and communication devices are expected to commercially launch\nand emerge on road in short-term. These smart vehicles are able to\npartially/fully drive themselves; collect data from sensors, make and execute\ndecisions based on that data; communicate with other vehicles, pedestrians, and\nnodes installed on the road; and provide infotainment and value-added services,\nsuch as broadband transmission of ultra-high definition video, files/apps\ndownloading and uploading, online gaming, access to social media, audio/video\nconference streaming (office-in-car), live TV streaming, etc.; and so on. In\naddition, it is also possible for autonomous vehicles to form a \"platoon\" on\nroad; maintaining close proximity in order to reduce the consumption of fuel\nand/or emission of gas, decrease costs, increase safety, and enhance the\nefficiency of the legacy transportation system. These emerging vehicular\napplications demand a large amount of computing and communication capacity to\nexcel in their compute-intensive and latency-sensitive tasks. Based on these\nfacts, the authors of this paper presented a visionary concept --\n\"platoon-assisted vehicular cloud\" -- that exploits underutilized resources in\nplatoons to augment vehicular cloud aiming to provide cost-effective and\non-demand computing resources. Moreover, the authors presented three potential\nscenarios and explained the exploitation of platoon resources and roadside\ninfrastructure to facilitate new applications. Besides system design, the paper\ndid also summarize a number of open research challenges with the purpose of\nmotivating new advances and potential solutions to this field.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 10:17:13 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Nasimi", "Meysam", ""], ["Habibi", "Mohammad Asif", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2008.10941", "submitter": "Shuji Ohira", "authors": "Shuji Ohira, Araya Kibrom Desta, Tomoya Kitagawa, Ismail Arai,\n  Kazutoshi Fujikawa", "title": "Divider: Delay-Time Based Sender Identification in Automotive Networks", "comments": "8 pages, 7 figures, IEEE 44th Annual Computer Software and\n  Applications Conference (COMPSAC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controller Area Network (CAN) is one of the in-vehicle network protocols that\nis used to communicate among Electronic Control Units (ECUs) and has been\nde-facto standard. CAN is simple and has several vulnerabilities such as unable\nto distinguish spoofing messages because it does not support any authentication\nor sender identification properties. In previous work, some voltage-based\nmethods to identify the sender node have been proposed. The methods can\nidentify ECUs with high accuracy. However, the accuracy of source\nidentification depends on a feature that is extracted from a continuous\nfunction of voltage use sampling. In general, as the sampling rate increases,\nthe accuracy of identification is improved. Though the amount of data used for\nthe identification increases too. Hence, it is desired to create an Intrusion\nDetection System (IDS) that identifies ECUs using few sampling features as\nthere is a limited computing resource in vehicles. In this paper, we propose a\ndelay-time based sender identification method of ECUs. We confirm that the\nproposed method achieved a true positive rate of 96.7% in CAN bus prototype\nagainst spoofing attack from a compromised ECU, detecting spoofing attack from\nan unmonitored ECU with a true positive rate of 98.0% in real-vehicle.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 11:23:56 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 04:55:45 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ohira", "Shuji", ""], ["Desta", "Araya Kibrom", ""], ["Kitagawa", "Tomoya", ""], ["Arai", "Ismail", ""], ["Fujikawa", "Kazutoshi", ""]]}, {"id": "2008.10956", "submitter": "Estefania Recayte", "authors": "Estefania Recayte and Andrea Munari and Federico Clazzer", "title": "Grant-Free Access: Machine Learning for Detection of Short Packets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the use of machine learning methods as an efficient\nalternative to correlation in performing packet detection. Targeting\nsatellite-based massive machine type communications and internet of things\nscenarios, our focus is on a common channel shared among a large number of\nterminals via a fully asynchronous ALOHA protocol to attempt delivery of short\ndata packets. In this setup, we test the performance of two algorithms, neural\nnetworks and random forest, which are shown to provide substantial improvements\nover {traditional} techniques. Excellent performance is demonstrated in terms\nof detection and false alarm probability also in the presence of collisions\namong user transmissions. The ability of machine learning to extract further\ninformation from incoming signals is also studied, discussing the possibility\nto classify detected preambles based on the level of interference they undergo.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 12:20:51 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Recayte", "Estefania", ""], ["Munari", "Andrea", ""], ["Clazzer", "Federico", ""]]}, {"id": "2008.10959", "submitter": "Oliver Gasser", "authors": "Anja Feldmann, Oliver Gasser, Franziska Lichtblau, Enric Pujol, Ingmar\n  Poese, Christoph Dietzel, Daniel Wagner, Matthias Wichtlhuber, Juan Tapiador,\n  Narseo Vallina-Rodriguez, Oliver Hohlfeld, Georgios Smaragdakis", "title": "The Lockdown Effect: Implications of the COVID-19 Pandemic on Internet\n  Traffic", "comments": null, "journal-ref": "Proceedings of the 2020 Internet Measurement Conference (IMC '20)", "doi": "10.1145/3419394.3423658", "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the COVID-19 pandemic, many governments imposed lock downs that forced\nhundreds of millions of citizens to stay at home. The implementation of\nconfinement measures increased Internet traffic demands of residential users,\nin particular, for remote working, entertainment, commerce, and education,\nwhich, as a result, caused traffic shifts in the Internet core. In this paper,\nusing data from a diverse set of vantage points (one ISP, three IXPs, and one\nmetropolitan educational network), we examine the effect of these lockdowns on\ntraffic shifts. We find that the traffic volume increased by 15-20% almost\nwithin a week--while overall still modest, this constitutes a large increase\nwithin this short time period. However, despite this surge, we observe that the\nInternet infrastructure is able to handle the new volume, as most traffic\nshifts occur outside of traditional peak hours. When looking directly at the\ntraffic sources, it turns out that, while hypergiants still contribute a\nsignificant fraction of traffic, we see (1) a higher increase in traffic of\nnon-hypergiants, and (2) traffic increases in applications that people use when\nat home, such as Web conferencing, VPN, and gaming. While many networks see\nincreased traffic demands, in particular, those providing services to\nresidential users, academic networks experience major overall decreases. Yet,\nin these networks, we can observe substantial increases when considering\napplications associated to remote working and lecturing.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 12:32:59 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 13:23:56 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 15:36:25 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Feldmann", "Anja", ""], ["Gasser", "Oliver", ""], ["Lichtblau", "Franziska", ""], ["Pujol", "Enric", ""], ["Poese", "Ingmar", ""], ["Dietzel", "Christoph", ""], ["Wagner", "Daniel", ""], ["Wichtlhuber", "Matthias", ""], ["Tapiador", "Juan", ""], ["Vallina-Rodriguez", "Narseo", ""], ["Hohlfeld", "Oliver", ""], ["Smaragdakis", "Georgios", ""]]}, {"id": "2008.11006", "submitter": "Marco Mezzavilla", "authors": "William Xia, Sundeep Rangan, Marco Mezzavilla, Angel Lozano, Giovanni\n  Geraci, Vasilii Semkin, Giuseppe Loianno", "title": "Millimeter Wave Channel Modeling via Generative Neural Networks", "comments": "Submitted to IEEE GLOBECOM 2020 Workshop on Wireless Propagation\n  Channels for 5G and B5G", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical channel models are instrumental to design and evaluate wireless\ncommunication systems. In the millimeter wave bands, such models become acutely\nchallenging; they must capture the delay, directions, and path gains, for each\nlink and with high resolution. This paper presents a general modeling\nmethodology based on training generative neural networks from data. The\nproposed generative model consists of a two-stage structure that first predicts\nthe state of each link (line-of-sight, non-line-of-sight, or outage), and\nsubsequently feeds this state into a conditional variational autoencoder that\ngenerates the path losses, delays, and angles of arrival and departure for all\nits propagation paths. Importantly, minimal prior assumptions are made,\nenabling the model to capture complex relationships within the data. The\nmethodology is demonstrated for 28GHz air-to-ground channels in an urban\nenvironment, with training datasets produced by means of ray tracing.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 13:45:13 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Xia", "William", ""], ["Rangan", "Sundeep", ""], ["Mezzavilla", "Marco", ""], ["Lozano", "Angel", ""], ["Geraci", "Giovanni", ""], ["Semkin", "Vasilii", ""], ["Loianno", "Giuseppe", ""]]}, {"id": "2008.11265", "submitter": "Morteza Hashemi", "authors": "Luyao Shang, Morteza Hashemi, Taejoon Kim, Erik Perrins", "title": "Delay-Efficient and Reliable Data Relaying in Ultra Dense Networks using\n  Rateless Codes", "comments": "Accepted for presentation at the IEEE Global Communications\n  Conference (GLOBECOM) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of delay-efficient and reliable data delivery in\nultra-dense networks (UDNs) that constitute macro base stations (MBSs), small\nbase stations (SBSs), and mobile users. Considering a two-hop data delivery\nsystem, we propose a partial decode-and-forward (PDF) relaying strategy\ntogether with a simple and intuitive amicable encoding scheme for rateless\ncodes to significantly improve user experience in terms of end-to-end delay.\nSimulation results verify that our amicable encoding scheme is efficient in\nimproving the intermediate performance of rateless codes. It also verifies that\nour proposed PDF significantly improves the performance of the\ndecode-and-forward (DF) strategy, and that PDF is much more robust against\nchannel degradation. Overall, the proposed strategy and encoding scheme are\nefficient towards delay-sensitive data delivery in the UDN scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 20:44:52 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Shang", "Luyao", ""], ["Hashemi", "Morteza", ""], ["Kim", "Taejoon", ""], ["Perrins", "Erik", ""]]}, {"id": "2008.11439", "submitter": "Changsheng You", "authors": "Changsheng You, Beixiong Zheng, and Rui Zhang", "title": "Wireless Communication via Double IRS: Channel Estimation and Passive\n  Beamforming Designs", "comments": "Submitted to IEEE for possible publication. This paper considers a\n  new double-IRS aided communication system and studies its channel estimation\n  and passive beamforming designs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this letter, we study efficient channel estimation and passive beamforming\ndesigns for a double-intelligent reflecting surface (IRS) aided single-user\ncommunication system, where a user communicates with an access point (AP) via\nthe cascaded user-IRS 1-IRS 2-AP double-reflection link. First, a general\nchannel estimation scheme is proposed for the system under any arbitrary\ninter-IRS channel, where all coefficients of the cascaded channel are\nestimated. Next, for the typical scenario with a line-of-sight (LoS)-dominant\ninter-IRS channel, we propose another customized scheme to estimate two\nsignature vectors of the rank-one cascaded channel with significantly less\nchannel training time than the first scheme. For the two proposed channel\nestimation schemes, we further optimize their corresponding cooperative passive\nbeamforming for data transmission to maximize the achievable rate with the\ntraining overhead and channel estimation error taken into account. Numerical\nresults show that deploying two cooperative IRSs with the proposed channel\nestimation and passive beamforming designs achieves significant rate\nenhancement as compared to the conventional case of single IRS deployment.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 08:25:19 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["You", "Changsheng", ""], ["Zheng", "Beixiong", ""], ["Zhang", "Rui", ""]]}, {"id": "2008.11621", "submitter": "Xiaowen Ye", "authors": "Xiaowen Ye, Yiding Yu, Liqun Fu", "title": "The optimal network throughputs when the model-aware node coexists with\n  other nodes using different MAC protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this document, we give the optimal network throughput when the DR-DLMA\nnode (see our paper for definition) coexists with the nodes using other\nprotocol (e.g., TDMA and/or ALOHA). Then we use the optimal network throughput\nas the benchmark for our paper. The simulation results in our paper\ndemonstrated that the DR-DLMA node can achieve performance similar to that of\nthe model-aware node.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:02:10 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Ye", "Xiaowen", ""], ["Yu", "Yiding", ""], ["Fu", "Liqun", ""]]}, {"id": "2008.11803", "submitter": "Abdullah Yousafzai", "authors": "Abdullah Yousafzai and Choong Seon Hong", "title": "SmartSON:A Smart contract driven incentive management framework for\n  Self-Organizing Networks", "comments": "Incentive Management Framework for Self Organizing Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a self-organizing collaborative computing network with\nan approach to enhance the expectation of a collaborating node for joining the\nself-organizing network. The proposed approach relies on Ethereum\ncryptocurrency and Smart Contract to enhance the expectation of collaborating\nnodes by monetizing the services provided to the self-organizing network.\nFurthermore, an escrow based smart contract is formalized in the proposed\nframework to sustains the monetary trust issue between collaborating nodes. The\nproposed scheme can enforce an autonomic incentive management mechanism to any\ntype of self-organizing networks such as self-organizing clouds, ad-hoc\nnetworks, self-organizing federated cloud networks, self-organizing federated\nlearning networks, and self-organizing D2D networks to name a few. Considering\nthe distributed nature of these self-organizing networks and the Ethereum\nblockchain network, a distributed agent-based methodology is materialized in\nthe proposed framework. Following this, a proof of concept implementation for\nthe general case of a self-organizing cloud is presented. Lastly, the article\nprovides some insights into possible future directions using the proposed\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:41:22 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Yousafzai", "Abdullah", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2008.11959", "submitter": "Mattia Lecci", "authors": "Salman Mohebi, Mattia Lecci, Andrea Zanella, Michele Zorzi", "title": "The challenges of Scheduling and Resource Allocation in IEEE 802.11ad/ay", "comments": "4 pages, 3 figures. Please cite it as: S. Mohebi, M. Lecci, A.\n  Zanella, M. Zorzi, \"The challenges of Scheduling and Resource Allocation in\n  IEEE 802.11ad/ay,\" in 18th Mediterranean Communication and Computer\n  Networking Conference (MedComNet), Arona, Italy, Jun. 2020", "journal-ref": null, "doi": "10.1109/MedComNet49392.2020.9191491", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IEEE 802.11ad WiFi amendment enables short-range multi-gigabit\ncommunications in the unlicensed 60~GHz spectrum, unlocking new interesting\napplications such as wireless Augmented and Virtual Reality. The\ncharacteristics of the mmWave band and directional communications allow\nincreasing the system throughput by scheduling pairs of nodes with low\ncross-interfering channels in the same time-frequency slot. On the other hand,\nthis requires significantly more signaling overhead. Furthermore, IEEE 802.11ad\nintroduces a hybrid MAC characterized by two different channel access\nmechanisms: contention-based and contention-free access periods. The\ncoexistence of both access period types and the directionality typical of\nmmWave increase the channel access and scheduling complexity in IEEE 802.11ad\ncompared to previous WiFi versions. Hence, to provide the Quality of Service\n(QoS) performance required by demanding applications, a proper resource\nscheduling mechanism that takes into account both directional communications\nand the newly added features of this WiFi amendment is needed. In this paper,\nwe present a brief but comprehensive review of the open problems and challenges\nassociated with channel access in IEEE 802.11ad and propose a workflow to\ntackle them via both heuristic and learning-based methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 07:28:28 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Mohebi", "Salman", ""], ["Lecci", "Mattia", ""], ["Zanella", "Andrea", ""], ["Zorzi", "Michele", ""]]}, {"id": "2008.11978", "submitter": "Sergio Barrachina-Mu\\~noz Mr.", "authors": "Sergio Barrachina-Mu\\~noz, Boris Bellalta, Edward Knightly", "title": "Wi-Fi All-Channel Analyzer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present WACA, the first system to simultaneously measure\nthe energy in all 24 Wi-Fi channels that allow channel bonding at 5 GHz with\nmicrosecond scale granularity. With WACA, we perform a first-of-its-kind\nmeasurement campaign in areas including urban hotspots, residential\nneighborhoods, universities, and a sold-out stadium with 98,000 fans and 12,000\nsimultaneous Wi-Fi connections. The gathered dataset is a unique asset to find\ninsights otherwise not possible in the context of multi-channel technologies\nlike Wi-Fi. To show its potential, we compare the performance of contiguous and\nnon-contiguous channel bonding using a trace-driven framework. We show that\nwhile non-contiguous outperforms contiguous channel bonding's throughput,\noccasionally bigger by a factor of 5, their average throughputs are similar.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 08:08:53 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Barrachina-Mu\u00f1oz", "Sergio", ""], ["Bellalta", "Boris", ""], ["Knightly", "Edward", ""]]}, {"id": "2008.12086", "submitter": "Jakob Struye", "authors": "Jakob Struye, Filip Lemic and Jeroen Famaey", "title": "Towards Ultra-Low-Latency mmWave Wi-Fi for Multi-User Interactive\n  Virtual Reality", "comments": "Published at 2020 IEEE Global Communications Conference (GLOBECOM)", "journal-ref": "GLOBECOM 2020 - 2020 IEEE Global Communications Conference (2020)\n  1-6", "doi": "10.1109/GLOBECOM42002.2020.9322284", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for cables with high-fidelity Virtual Reality (VR) headsets remains\na stumbling block on the path towards interactive multi-user VR. Due to strict\nlatency constraints, designing fully wireless headsets is challenging, with the\nfew commercially available solutions being expensive. These solutions use\nproprietary millimeter wave (mmWave) communications technologies, as extremely\nhigh frequencies are needed to meet the throughput and latency requirements of\nVR applications. In this work, we investigate whether such a system could be\nbuilt using specification-compliant IEEE 802.11ad hardware, which would\nsignificantly reduce the cost of wireless mmWave VR solutions. We present a\ntheoretical framework to calculate attainable live VR video bitrates for\ndifferent IEEE 802.11ad channel access methods, using 1 or more head-mounted\ndisplays connected to a single Access Point (AP). Using the ns-3 simulator, we\nvalidate our theoretical framework, and demonstrate that a properly configured\nIEEE 802.11ad AP can support at least 8 headsets receiving a 4K video stream\nfor each eye, with transmission latency under 1 millisecond.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 12:34:01 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 15:03:24 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Struye", "Jakob", ""], ["Lemic", "Filip", ""], ["Famaey", "Jeroen", ""]]}, {"id": "2008.12507", "submitter": "Onel Luis Alcaraz L\\'opez", "authors": "Onel L. A. L\\'opez, Francisco A. Monteiro, Hirley Alves, Rui Zhang,\n  Matti Latva-aho", "title": "A Low-Complexity Beamforming Design for Multiuser Wireless Energy\n  Transfer", "comments": "4 figures, 1 algorithm, accepted for publication in IEEE Wireless\n  Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless energy transfer (WET) is a green enabler of low-power Internet of\nThings (IoT). Therein, traditional optimization schemes relying on full channel\nstate information (CSI) are often too costly to implement due to excessive\nenergy consumption and high processing complexity. This letter proposes a\nsimple, yet effective, energy beamforming scheme that allows a multi-antenna\npower beacon (PB) to fairly power a set of IoT devices by only relying on the\nfirst-order statistics of the channels. In addition to low complexity, the\nproposed scheme performs favorably as compared to benchmarking schemes and its\nperformance improves as the number of PB's antennas increases. Finally, it is\nshown that further performance improvement can be achieved through proper\nangular rotations of the PB.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 07:04:43 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["L\u00f3pez", "Onel L. A.", ""], ["Monteiro", "Francisco A.", ""], ["Alves", "Hirley", ""], ["Zhang", "Rui", ""], ["Latva-aho", "Matti", ""]]}, {"id": "2008.12569", "submitter": "Pavlos Charalampidis", "authors": "Pavlos Charalampidis and Alexandros Fragkiadakis", "title": "When Distributed Ledger Technology meets Internet of Things -- Benefits\n  and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest from both the academia and industry to employ\ndistributed ledger technology in the Internet-of-Things domain for addressing\nsecurity-related and performance challenges. Distributed ledger technology\nenables non-trusted entities to communicate and reach consensus in a fully\ndistributed manner through a cryptographically secure and immutable ledger.\nHowever, significant challenges arise mainly related to transaction processing\nspeed and user privacy. This work explores the interplay between\nInternet-of-Things and distributed ledger technology, analysing the fundamental\ncharacteristics of this technology and discussing the related benefits and\nchallenges.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:26:59 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Charalampidis", "Pavlos", ""], ["Fragkiadakis", "Alexandros", ""]]}, {"id": "2008.12707", "submitter": "Francisco Maturana", "authors": "Francisco Maturana and K. V. Rashmi", "title": "Bandwidth Cost of Code Conversions in Distributed Storage: Fundamental\n  Limits and Optimal Constructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Erasure codes have become an integral part of distributed storage systems as\na tool for providing data reliability and durability under the constant threat\nof device failures. In such systems, an $[n, k]$ code over a finite field\n$\\mathbb{F}_q$ encodes $k$ message symbols into $n$ codeword symbols from\n$\\mathbb{F}_q$ which are then stored on $n$ different nodes in the system.\nRecent work has shown that significant savings in storage space can be obtained\nby tuning $n$ and $k$ to variations in device failure rates. Such a tuning\nnecessitates code conversion: the process of converting already encoded data\nunder an initial $[n^I, k^I]$ code to its equivalent under a final $[n^F, k^F]$\ncode. The default approach to conversion is to reencode data, which places\nsignificant burden on system resources. Convertible codes are a recently\nproposed class of codes for enabling resource-efficient conversions. Existing\nwork on convertible codes has focused on minimizing access cost, i.e., the\nnumber of code symbols accessed during conversion. Bandwidth, which corresponds\nto the amount of data read and transferred, is another important resource to\noptimize.\n  In this paper, we initiate the study on the fundamental limits on bandwidth\nused during code conversion and present constructions for bandwidth-optimal\nconvertible codes. First, we model the code conversion problem using network\ninformation flow graphs with variable capacity edges. Second, focusing on MDS\ncodes and an important parameter regime called the merge regime, we derive\ntight lower bounds on the bandwidth cost of conversion. The derived bounds show\nthat bandwidth cost can be significantly reduced even in regimes where access\ncost cannot be reduced as compared to the default approach. Third, we present a\nnew construction for MDS convertible codes which matches the proposed lower\nbound and is thus bandwidth-optimal during conversion.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 15:39:43 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Maturana", "Francisco", ""], ["Rashmi", "K. V.", ""]]}, {"id": "2008.12767", "submitter": "Bashir Mohammed", "authors": "Tanwi Mallick, Mariam Kiran, Bashir Mohammed, Prasanna Balaprakash", "title": "Dynamic Graph Neural Network for Traffic Forecasting in Wide Area\n  Networks", "comments": "10 Pages, 11 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wide area networking infrastructures (WANs), particularly science and\nresearch WANs, are the backbone for moving large volumes of scientific data\nbetween experimental facilities and data centers. With demands growing at\nexponential rates, these networks are struggling to cope with large data\nvolumes, real-time responses, and overall network performance. Network\noperators are increasingly looking for innovative ways to manage the limited\nunderlying network resources. Forecasting network traffic is a critical\ncapability for proactive resource management, congestion mitigation, and\ndedicated transfer provisioning. To this end, we propose a nonautoregressive\ngraph-based neural network for multistep network traffic forecasting.\nSpecifically, we develop a dynamic variant of diffusion convolutional recurrent\nneural networks to forecast traffic in research WANs. We evaluate the efficacy\nof our approach on real traffic from ESnet, the U.S. Department of Energy's\ndedicated science network. Our results show that compared to classical\nforecasting methods, our approach explicitly learns the dynamic nature of\nspatiotemporal traffic patterns, showing significant improvements in\nforecasting accuracy. Our technique can surpass existing statistical and deep\nlearning approaches by achieving approximately 20% mean absolute percentage\nerror for multiple hours of forecasts despite dynamic network traffic settings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:47:11 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Mallick", "Tanwi", ""], ["Kiran", "Mariam", ""], ["Mohammed", "Bashir", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "2008.12845", "submitter": "Mahbubur Rahman", "authors": "Mahbubur Rahman", "title": "Low-Power Wide-Area Network Design", "comments": "Ph.D. Thesis, Wayne State University, pp. 1--226, August 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LPWAN is an enabling technology for long-range, low-power, and low-cost\nIoT/CPS applications. Recently, multiple LPWAN technologies have been developed\nthat operate in the licensed (e.g., 5G) and ISM (e.g., LoRa) bands. To avoid\nthe crowd in the ISM band and the cost of the licensed band, we propose a novel\nLPWAN called Sensor Network Over White Spaces (SNOW) by utilizing the TV white\nspaces. Specifically, we design, develop, and experiment SNOW, which is highly\nscalable, energy-efficient, and has a long communication range. SNOW achieves\nscalability and energy efficiency by enabling concurrent packets reception at a\nBS using a single radio from numerous sensors and concurrent packets\ntransmission to numerous sensors from the BS using a single radio,\nsimultaneously, which we achieve by proposing a distributed implementation of\nOFDM. To enable the low-cost and scalable SNOW deployment in practical\napplications, we implement SNOW using the low-cost and small form-factored COTS\ndevices, where we address multiple practical challenges including the high\npeak-to-average power ratio, channel state estimation, and carrier offset\nestimation. Also, we propose an adaptive transmission power protocol to handle\nthe near-far power problem. To enable connecting tens of thousands of nodes\nover hundreds of kilometers, we further propose a network architecture called\nSNOW-tree through a seamless integration of multiple SNOWs where they form a\ntree structure and are under the same management/control. We address the intra-\nand inter-SNOW interferences by formulating a constrained optimization problem\ncalled the scalability optimization problem (SOP) whose objective is to\nmaximize scalability by managing the spectrum sharing across the SNOWs. By\nproving the NP-hardness of SOP, we then propose two polynomial-time methods to\nsolve it: a greedy heuristic algorithm and a 1/2-approximation algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 21:12:54 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Rahman", "Mahbubur", ""]]}, {"id": "2008.12858", "submitter": "Hongzi Mao", "authors": "Hongzi Mao, Shannon Chen, Drew Dimmery, Shaun Singh, Drew Blaisdell,\n  Yuandong Tian, Mohammad Alizadeh, Eytan Bakshy", "title": "Real-world Video Adaptation with Reinforcement Learning", "comments": "Reinforcement Learning for Real Life (RL4RealLife) Workshop in the\n  36th International Conference on Machine Learning, Long Beach, California,\n  USA, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Client-side video players employ adaptive bitrate (ABR) algorithms to\noptimize user quality of experience (QoE). We evaluate recently proposed\nRL-based ABR methods in Facebook's web-based video streaming platform.\nReal-world ABR contains several challenges that requires customized designs\nbeyond off-the-shelf RL algorithms -- we implement a scalable neural network\narchitecture that supports videos with arbitrary bitrate encodings; we design a\ntraining method to cope with the variance resulting from the stochasticity in\nnetwork conditions; and we leverage constrained Bayesian optimization for\nreward shaping in order to optimize the conflicting QoE objectives. In a\nweek-long worldwide deployment with more than 30 million video streaming\nsessions, our RL approach outperforms the existing human-engineered ABR\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 21:44:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Mao", "Hongzi", ""], ["Chen", "Shannon", ""], ["Dimmery", "Drew", ""], ["Singh", "Shaun", ""], ["Blaisdell", "Drew", ""], ["Tian", "Yuandong", ""], ["Alizadeh", "Mohammad", ""], ["Bakshy", "Eytan", ""]]}, {"id": "2008.12881", "submitter": "Leandro Bertholdo", "authors": "Leandro M. Bertholdo, Joao M. Ceron, Wouter B. de Vries, Ricardo de O.\n  Schmitt, Lisandro Zambenedetti Granville, Roland van Rijswijk-Deij, Aiko Pras", "title": "Tangled: A Cooperative Anycast Testbed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anycast routing is an area of studies that has been attracting interest of\nseveral researchers in recent years. Most anycast studies conducted in the past\nrelied on coarse measurement data, mainly due to the lack of infrastructure\nwhere it is possible to test and collect data at same time. In this paper we\npresent Tangled, an anycast test environment where researchers can run\nexperiments and better understand the impacts of their proposals on a global\ninfrastructure connected to the Internet.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 00:06:42 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Bertholdo", "Leandro M.", ""], ["Ceron", "Joao M.", ""], ["de Vries", "Wouter B.", ""], ["Schmitt", "Ricardo de O.", ""], ["Granville", "Lisandro Zambenedetti", ""], ["van Rijswijk-Deij", "Roland", ""], ["Pras", "Aiko", ""]]}, {"id": "2008.12895", "submitter": "Nafees Mansoor PhD", "authors": "Sharmin Akter, Mohammad Shahriar Rahman and Nafees Mansoor", "title": "An Efficient Routing Protocol for Secured Communication in Cognitive\n  Radio Sensor Networks", "comments": null, "journal-ref": "2020 IEEE Region 10 Symposium (TENSYMP), 5-7 June 2020", "doi": null, "report-no": null, "categories": "cs.NI cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an efficient reactive routing protocol considering the\nmobility and the reliability of a node in Cognitive Radio Sensor Networks\n(CRSNs). The proposed protocol accommodates the dynamic behavior of the\nspectrum availability and selects a stable transmission path from a source node\nto the destination. Outlined as a weighted graph problem, the proposed protocol\nmeasures the weight for an edge the measuring the mobility patterns of the\nnodes and channel availability. Furthermore, the mobility pattern of a node is\ndefined in the proposed routing protocol from the viewpoint of distance, speed,\ndirection, and node's reliability. Besides, the spectrum awareness in the\nproposed protocol is measured over the number of shared common channels and the\nchannel quality. It is anticipated that the proposed protocol shows efficient\nrouting performance by selecting stable and secured paths from source to\ndestination. Simulation is carried out to assess the performance of the\nprotocol where it is witnessed that the proposed routing protocol outperforms\nexisting ones.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 02:45:44 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Akter", "Sharmin", ""], ["Rahman", "Mohammad Shahriar", ""], ["Mansoor", "Nafees", ""]]}, {"id": "2008.13300", "submitter": "Michael Luby", "authors": "Michael Luby", "title": "SOPI design and analysis for LDN", "comments": "This is a companion paper to the LDN paper that appears in ACM ICN\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Liquid Data Networking (LDN) is an ICN architecture that is designed to\nenable the benefits of erasure-code enabled object delivery. A primary\ncontribution of LDN is the introduction of SOPIs, which enables client s to\nconcurrently download encoded data for the same object from multiple edge\nnodes, optimizes caching efficiency, and enables seamless mobility. This paper\nprovides an enhanced design and analysis of SOPI s.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 00:16:20 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 00:04:23 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Luby", "Michael", ""]]}, {"id": "2008.13453", "submitter": "Yuming Jiang", "authors": "Yordanos Tibebu Woldeyohannes, Besmir Tola, Yuming Jiang, K. K.\n  Ramakrishnan", "title": "CoShare: An Efficient Approach for Redundancy Allocation in NFV", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An appealing feature of Network Function Virtualization (NFV) is that in an\nNFV-based network, a network function (NF) instance may be placed at any node.\nThis, on the one hand, offers great flexibility in redundancy allocation to\nmeet the availability requirements of flows; on the other hand, it makes the\nchallenge unique and difficult. One particular highlight is that there is\ninherent correlation among nodes due to the structure of the network, implying\nthat special care is needed for redundancy allocation in NFV-based networks. To\nthis aim, a novel approach, called CoShare, is proposed. Originally, its design\ntakes into consideration the effect of network structural dependency. In\naddition, to efficiently make use of resources, CoShare proposes the idea of\nshared reservation, where multiple flows may be allowed to share the same\nreserved backup capacity at an NF instance. Furthermore, CoShare factors in the\nheterogeneity in nodes, NF instances and availability requirements of flows in\nthe design. The results from a number of experiments conducted using realistic\nnetwork topologies show that CoShare is able to meet diverse availability\nrequirements in a resource-efficient manner, requiring less resource overbuild\nthan using the idea of dedicated reservation commonly adopted for redundancy\nallocation in NFV.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 09:33:45 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Woldeyohannes", "Yordanos Tibebu", ""], ["Tola", "Besmir", ""], ["Jiang", "Yuming", ""], ["Ramakrishnan", "K. K.", ""]]}]