[{"id": "2001.00066", "submitter": "Julian Enoch", "authors": "Julian Enoch", "title": "Nested Column Generation decomposition for solving the Routing and\n  Spectrum Allocation problem in Elastic Optical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the continued growth of Internet traffic, and the scarcity of the\noptical spectrum, there is a continuous need to optimize the usage of this\nresource. In the process of provisioning elastic optical networks using the\nflexible frequency grid paradigm, telecommunication operators must deal with a\ncombinatorial optimization problem that is NP-complete namely the Routing and\nSpectrum Allocation(RSA) problem. Following on our previous study, where we\nused Integer Linear Programming, and proposed a Column Generation algorithm\nbased on a Lightpath decomposition, which proved to be the most efficient so\nfar, we now consider the traditional Configuration decomposition that has been\nstudied in other works in the past. In the process, we created an new\nmathematical model using two variable sets instead of a single variable set.\nEqually important,we independently rediscovered the Nested Column Generation\ntechnique, and we used it to propose an algorithm that led to a considerable\nimprovement on the previous algorithms that use the same Configuration\ndecomposition. When compared to the latest such existing study, our algorithm\nachieved an accuracy gap of 1% as opposed to 14.3% for the previous study, and\na running time two orders of magnitude faster on average.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 20:14:55 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 16:10:24 GMT"}], "update_date": "2020-01-21", "authors_parsed": [["Enoch", "Julian", ""]]}, {"id": "2001.00087", "submitter": "Yu Luo", "authors": "Yu Luo, Lina Pu", "title": "Practical Issues of Energy Harvesting and Data Transmissions in\n  Sustainable IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sustainable Internet of Things (IoT) is becoming a promising solution for\nthe green living and smart industries. In this article, we investigate the\npractical issues in the radio energy harvesting and data communication systems\nthrough extensive field experiments. A number of important characteristics of\nenergy harvesting circuits and communication modules have been studied,\nincluding the non-linear energy consumption of the communication system\nrelative to the transmission power, the wake-up time associated with the\npayload, and the varying system power during consecutive packet transmissions.\nIn order to improve the efficiency of energy harvest and energy utilization, we\npropose a new model to accurately describe the energy harvesting process and\nthe power consumption for sustainable IoT devices. Experiments are performed\nusing commercial IoT devices and RF energy harvesters to verify the accuracy of\nthe proposed model. The experiment results show that the new model matches the\nperformance of sustainable IoT devices very well in the real scenario.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 21:48:20 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Luo", "Yu", ""], ["Pu", "Lina", ""]]}, {"id": "2001.00103", "submitter": "Farid Nait-Abdesselam", "authors": "Farid Na\\\"it-Abdesselam, Ahmad Alsharoa, Mohamed Selim, Daji Qiao,\n  Ahmed E. Kamal", "title": "D3S: A Framework for Enabling Unmanned Aerial Vehicles as a Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the use of UAVs to provide wireless connectivity\nservices, for example after failures of wireless network components or to\nsimply provide additional bandwidth on demand, and introduce the concept of\nUAVs as a service (UaaS). To facilitate UaaS, we introduce a novel framework,\ndubbed D3S, which consists of four phases: demand, decision, deployment, and\nservice. The main objective of this framework is to develop efficient and\nrealistic solutions to implement these four phases. The technical problems\ninclude determining the type and number of UAVs to be deployed, and also their\nfinal locations (e.g., hovering or on-ground), which is important for serving\ncertain applications. These questions will be part of the decision phase. They\nalso include trajectory planning of UAVs when they have to travel between\ncharging stations and deployment locations and may have to do this several\ntimes. These questions will be part of the deployment phase. The service phase\nincludes the implementation of the backbone communication and data routing\nbetween UAVs and between UAVs and ground control stations.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 22:49:20 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Na\u00eft-Abdesselam", "Farid", ""], ["Alsharoa", "Ahmad", ""], ["Selim", "Mohamed", ""], ["Qiao", "Daji", ""], ["Kamal", "Ahmed E.", ""]]}, {"id": "2001.00112", "submitter": "Soheil Abbasloo", "authors": "Soheil Abbasloo, H. Jonathan Chao", "title": "SharpEdge: An Asynchronous and Core-Agnostic Solution to Guarantee\n  Bounded-Delays", "comments": null, "journal-ref": "CCF Transactions of Networking 2020", "doi": "10.1007/s42045-020-00032-z", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the key properties that a network should have to provide\nbounded-delay guarantees for the packets? In this paper, we attempt to answer\nthis question. To that end, we explore the theory of bounded-delay networks and\nprovide the necessary and the sufficient conditions required to have\ndeterministic bounded-delays in the network. We prove that as long as a network\nis work-conserving, independent of the packet scheduling and queue management\nalgorithms used in the switches, it is sufficient to shape the\ntraffic~\\textit{properly} at the edge of the network to meet hard\nbounded-delays in the network. Using the derived theorems, we present\nSharpEdge, a novel design to meet deterministic bounded-delays in the network.\nTo the best of our knowledge, SharpEdge is the first scheme that can meet all\nfollowing key properties: 1) it supports coexistence of different classes of\ntraffic, while it can guarantee their different required bounded-delays 2) it\ndoes not require any changes in the core of the network, 3) it supports both\nperiodic and bursty traffic patterns, and 4) it does not require any time\nsynchronization between network devices.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 23:59:39 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 15:54:38 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Abbasloo", "Soheil", ""], ["Chao", "H. Jonathan", ""]]}, {"id": "2001.00182", "submitter": "Francesco Malandrino", "authors": "Christian Vitale and Carla Fabiana Chiasserini and Francesco\n  Malandrino and Senay Semu Tadesse", "title": "Characterizing Delay and Control Traffic of the Cellular MME with IoT\n  Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main use cases for advanced cellular networks is represented by\nmassive Internet-of-things (MIoT), i.e., an enormous number of IoT devices that\ntransmit data toward the cellular network infrastructure. To make cellular MIoT\na reality, data transfer and control procedures specifically designed for the\nsupport of IoT are needed. For this reason, 3GPP has introduced the Control\nPlane Cellular IoT optimization, which foresees a simplified bearer\ninstantiation, with the Mobility Management Entity (MME) handling both control\nand data traffic. The performance of the MME has therefore become critical, and\nproperly scaling its computational capability can determine the ability of the\nwhole network to tackle MIoT effectively. In particular, considering\nvirtualized networks and the need for an efficient allocation of computing\nresources, it is paramount to characterize the MME performance as the MIoT\ntraffic load changes. We address this need by presenting compact, closed-form\nexpressions linking the number of IoT sources with the rate at which bearers\nare requested, and such a rate with the delay incurred by the IoT data. We show\nthat our analysis, supported by testbed experiments and verified through\nlarge-scale simulations, represents a valuable tool to make effective scaling\ndecisions in virtualized cellular core networks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 10:14:54 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Vitale", "Christian", ""], ["Chiasserini", "Carla Fabiana", ""], ["Malandrino", "Francesco", ""], ["Tadesse", "Senay Semu", ""]]}, {"id": "2001.00243", "submitter": "Mahbubur Rahman", "authors": "Mahbubur Rahman and Abusayeed Saifullah", "title": "Integrating Low-Power Wide-Area Networks for Enhanced Scalability and\n  Extended Coverage", "comments": "IEEE/ACM Transactions on Networking", "journal-ref": null, "doi": "10.1109/TNET.2020.2963886", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-Power Wide-Area Networks (LPWANs) are evolving as an enabling technology\nfor Internet-of-Things (IoT) due to their capability of communicating over long\ndistances at very low transmission power. Existing LPWAN technologies, however,\nface limitations in meeting scalability and covering very wide areas which make\ntheir adoption challenging for future IoT applications, especially in\ninfrastructure-limited rural areas. To address this limitation, in this paper,\nwe consider achieving scal-ability and extended coverage by integrating\nmultiple LPWANs. SNOW (Sensor Network Over White Spaces), a recently proposed\nLPWAN architecture over the TV white spaces, has demonstrated its advantages\nover existing LPWANs in performance and energy-efficiency. In this paper, we\npropose to scale up LPWANs through a seamless integration of multiple SNOWs\nwhich enables concurrent inter-SNOW and intra-SNOW communications. We then\nformulate the tradeoff between scalability and inter-SNOW interference as a\nconstrained optimization problem whose objective is to maximize scalability by\nmanaging white space spectrum sharing across multiple SNOWs. We also prove the\nNP-hardness of this problem. To this extent, We propose an intuitive\npolynomial-time heuristic algorithm for solving the scalability optimization\nproblem which is highly efficient in practice. For the sake of theoretical\nbound, we also propose a simple polynomial-time 1/2-approximation algorithm for\nthe scalability optimization problem. Hardware experiments through deployment\nin an area of (25x15)sq. km as well as large scale simulations demonstrate the\neffectiveness of our algorithms and feasibility of achieving scalability\nthrough seamless integration of SNOWs with high reliability, low latency, and\nenergy efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:14:16 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Rahman", "Mahbubur", ""], ["Saifullah", "Abusayeed", ""]]}, {"id": "2001.00259", "submitter": "Ghafour Ahani", "authors": "Ghafour Ahani and Di Yuan", "title": "Optimal Scheduling of Content Caching Subject to Deadline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content caching at the edge of network is a promising technique to alleviate\nthe burden of backhaul networks. In this paper, we consider content caching\nalong time in a base station with limited cache capacity. As the popularity of\ncontents may vary over time, the contents of cache need to be updated\naccordingly. In addition, a requested content may have a delivery deadline\nwithin which the content need to be obtained. Motivated by these, we address\noptimal scheduling of content caching in a time-slotted system under delivery\ndeadline and cache capacity constraints. The objective is to minimize a cost\nfunction that captures the load of backhaul links. For our optimization problem\nwe prove its NP-hardness via a reduction from the Partition problem. For\nproblem solving, via a mathematical reformulation, we develop a solution\napproach based on repeatedly applying a column generation algorithm and a\nproblem-tailored rounding algorithm. In addition, two greedy algorithms are\ndeveloped based on existing algorithms from the literature. Finally, we present\nextensive simulations that verify the effectiveness of our solution approach in\nobtaining near-to-optimal solutions in comparison to greedy algorithms. The\nsolutions obtained from our solution approach are within 1% from the global\noptimum.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 18:15:01 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 19:50:12 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ahani", "Ghafour", ""], ["Yuan", "Di", ""]]}, {"id": "2001.00392", "submitter": "Marc Carrascosa", "authors": "Marc Carrascosa and Boris Bellalta", "title": "Multi-Armed Bandits for Decentralized AP selection in Enterprise WLANs", "comments": null, "journal-ref": "Computer Communications, Volume 159, 1 June 2020, Pages 108-123", "doi": "10.1016/j.comcom.2020.05.023", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WiFi densification leads to the existence of multiple overlapping coverage\nareas, which allows user stations (STAs) to choose between different Access\nPoints (APs). The standard WiFi association method makes the STAs select the AP\nwith the strongest signal, which in many cases leads to underutilization of\nsome APs while overcrowding others. To mitigate this situation, Reinforcement\nLearning techniques such as Multi-Armed Bandits can be used to dynamically\nlearn the optimal mapping between APs and STAs, and so redistribute the STAs\namong the available APs accordingly. This is an especially challenging problem\nsince the network response observed by a given STA depends on the behavior of\nthe others, and so it is very difficult to predict without a global view of the\nnetwork.\n  In this paper, we focus on solving this problem in a decentralized way, where\nSTAs independently explore the different APs inside their coverage range, and\nselect the one that better satisfy their needs. To do it, we propose a novel\napproach called Opportunistic epsilon-greedy with Stickiness that halts the\nexploration when a suitable AP is found, only resuming the exploration after\nseveral unsatisfactory association rounds. With this approach, we reduce\nsignificantly the network response dynamics, improving the ability of the STAs\nto find a solution faster, as well as achieving a more efficient use of the\nnetwork resources.\n  We investigate how the characteristics of the scenario (position of the APs\nand STAs, traffic loads, and channel allocation strategies) impact the learning\nprocess and the achievable performance. We also show that not all the STAs have\nto implement the proposed solution to improve their performance. Finally, we\nstudy the case where stations arrive progressively to the system, showing that\nthe considered approach is also suitable in such a non-stationary set-up.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 11:15:43 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 11:32:33 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Carrascosa", "Marc", ""], ["Bellalta", "Boris", ""]]}, {"id": "2001.00567", "submitter": "Faheem Zafari", "authors": "Faheem Zafari, Kin K. Leung, Don Towsley, Prithwish Basu, Ananthram\n  Swami and Jian Li", "title": "Let's Share: A Game-Theoretic Framework for Resource Sharing in Mobile\n  Edge Clouds", "comments": "The paper is currently under review in IEEE Transactions on Network\n  and Service Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing seeks to provide resources to different delay-sensitive\napplications. This is a challenging problem as an edge cloud-service provider\nmay not have sufficient resources to satisfy all resource requests.\nFurthermore, allocating available resources optimally to different applications\nis also challenging. Resource sharing among different edge cloud-service\nproviders can address the aforementioned limitation as certain service\nproviders may have resources available that can be ``rented'' by other service\nproviders. However, edge cloud service providers can have different objectives\nor \\emph{utilities}. Therefore, there is a need for an efficient and effective\nmechanism to share resources among service providers, while considering the\ndifferent objectives of various providers. We model resource sharing as a\nmulti-objective optimization problem and present a solution framework based on\n\\emph{Cooperative Game Theory} (CGT). We consider the strategy where each\nservice provider allocates resources to its native applications first and\nshares the remaining resources with applications from other service providers.\nWe prove that for a monotonic, non-decreasing utility function, the game is\ncanonical and convex. Hence, the \\emph{core} is not empty and the grand\ncoalition is stable. We propose two algorithms \\emph{Game-theoretic Pareto\noptimal allocation} (GPOA) and \\emph{Polyandrous-Polygamous Matching based\nPareto Optimal Allocation} (PPMPOA) that provide allocations from the core.\nHence the obtained allocations are \\emph{Pareto} optimal and the grand\ncoalition of all the service providers is stable. Experimental results confirm\nthat our proposed resource sharing framework improves utilities of edge\ncloud-service providers and application request satisfaction.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:58:26 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Zafari", "Faheem", ""], ["Leung", "Kin K.", ""], ["Towsley", "Don", ""], ["Basu", "Prithwish", ""], ["Swami", "Ananthram", ""], ["Li", "Jian", ""]]}, {"id": "2001.00977", "submitter": "Muhammad Majid Butt", "authors": "M Majid Butt, Anil Rao, Daejung Yoon", "title": "RF Fingerprinting and Deep Learning Assisted UE Positioning in 5G", "comments": "submitted to ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate user equipment (UE) positioning assisted by deep\nlearning (DL) in 5G and beyond networks. As compared to state of the art\npositioning algorithms used in today's networks, radio signal fingerprinting\nand machine learning (ML) assisted positioning requires smaller additional\nfeedback overhead; and the positioning estimates are made directly inside the\nradio access network (RAN), thereby assisting in radio resource management. The\nconventional positioning algorithms will be used as back-up for the\nenvironments with high variability in conditions; but ML-assisted positioning\nserves as more efficient and simpler technique to provide better or similar\npositioning accuracy. In this regard, we study ML-assisted positioning methods\nand evaluate their performance using system level simulations for an outdoor\nscenario in Lincoln park Chicago. The study is based on the use of raytracing\ntools, a 3GPP 5G NR compliant system level simulator and DL framework to\nestimate positioning accuracy of the UE. The use of raytracing tool and system\nlevel simulator helps avoid expensive drive test measurements in practical\nscenarios. Our proposed mechanism is a first step towards more proactive\nmobility management in future networks. We evaluate and compare performance of\nvarious DL models and show mean positioning error in the range of 1-1.5m for\nthe best DL configuration with appropriate system feature-modeling.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 20:31:53 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Butt", "M Majid", ""], ["Rao", "Anil", ""], ["Yoon", "Daejung", ""]]}, {"id": "2001.01122", "submitter": "Omur Ozel", "authors": "Omur Ozel", "title": "Timely Status Updating Through Intermittent Sensing and Transmission", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel intermittent status updating model where an energy\nharvesting node with an intermittent energy source performs status updating to\na receiver through non-preemptive sensing and transmission operations. Each\noperation costs a single energy recharge of the node and the node cannot\nharvest energy while in operation. The sensing time for each update is\nindependent with a general distribution. The transmission queue has a single\nserver receiving packets generated after sensing operation, general service\ntime distribution and a single data buffer to save the latest arriving update\npacket. Once energy is harvested, the node has to decide whether to activate\nsensing to generate a new update or transmission to send the existing update\n(if any) to the receiver. We prove that average peak age of information (AoI)\nat the receiver is minimized by a threshold-based stopping rule that accepts\nonly young packets to the transmission server. We then use this result to\naddress average AoI optimization over the considered stopping rules through\nnovel hybrid waiting and thresholding schemes. Our numerical results show the\nimprovements in average AoI maintained by hybrid schemes.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 20:16:31 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 16:36:55 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 19:16:46 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Ozel", "Omur", ""]]}, {"id": "2001.01133", "submitter": "Mohamed Elsharnouby", "authors": "Mohamed Elsharnouby", "title": "Search techniques in peer to peer networks", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.20219.05926", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Peer to peer (P2P) networks are an overlay on IP network of the internet and\nthey can shape the future of computing by their involvement in distributed\nsystems with the increased of use of low priced personal computers to form big\nclusters of distributed systems. An important problem for P2P networks and\nmodels is searching for data in the network which can be the basis of any\nservice that uses such a network. Here we explore the major types of P2P\nnetworks and their solution to such a problem and we explore improvements that\nhappened to these networks to be more appealing for commercial usage by\noffering features of load balancing, scalability, self organization and fault\ntolerance.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 22:05:43 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Elsharnouby", "Mohamed", ""]]}, {"id": "2001.01358", "submitter": "Wei Feng", "authors": "Hongxin Wei, Wei Feng, Chi Zhang, Yunfei Chen, Yuguang Fang, and Ning\n  Ge", "title": "Creating Efficient Blockchains for the Internet of Things by Coordinated\n  Satellite-Terrestrial Networks", "comments": "8 pages, 5 figures", "journal-ref": "IEEE Wireless Communications ( Volume: 27, Issue: 3, June 2020)", "doi": "10.1109/MNET.001.1900326", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain has emerged as a promising technology that can guarantee data\nconsistency and integrity among distributed participants. It has been used in\nmany applications of the Internet of Things (IoT). However, since IoT\napplications often introduce a massive number of devices into blockchain\nsystems, the efficiency of the blockchain becomes a serious problem. In this\narticle, we analyze the key factors affecting the efficiency of blockchain.\nUnlike most existing solutions that handle this from the computing perspective,\nwe consider the problem from the communication perspective. Particularly, we\npropose a coordinated satellite-terrestrial network to create efficient\nblockchains. We also derive a network scheduling strategy for the proposed\narchitecture. Simulation results demonstrate that the proposed system can\nsupport blockchains for higher efficiency. Moreover, several open research\nissues and design challenges will be discussed.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 01:54:57 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Wei", "Hongxin", ""], ["Feng", "Wei", ""], ["Zhang", "Chi", ""], ["Chen", "Yunfei", ""], ["Fang", "Yuguang", ""], ["Ge", "Ning", ""]]}, {"id": "2001.01402", "submitter": "Jiaxiao Zheng", "authors": "Jiaxiao Zheng and Gustavo de Veciana and Albert Banchs", "title": "Constrained Network Slicing Games: Achieving service guarantees and\n  network efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing is a key capability for next generation mobile networks. It\nenables one to cost effectively customize logical networks over a shared\ninfrastructure. A critical component of network slicing is resource allocation,\nwhich needs to ensure that slices receive the resources needed to support their\nmobiles/services while optimizing network efficiency. In this paper, we propose\na novel approach to slice-based resource allocation named Guaranteed seRvice\nEfficient nETwork slicing (GREET). The underlying concept is to set up a\nconstrained resource allocation game, where (i) slices unilaterally optimize\ntheir allocations to best meet their (dynamic) customer loads, while (ii)\nconstraints are imposed to guarantee that, if they wish so, slices receive a\npre-agreed share of the network resources. The resulting game is a variation of\nthe well-known Fisher market, where slices are provided a budget to contend for\nnetwork resources (as in a traditional Fisher market), but (unlike a Fisher\nmarket) prices are constrained for some resources to provide the desired\nguarantees. In this way, GREET combines the advantages of a share-based\napproach (high efficiency by flexible sharing) and reservation-based ones\n(which provide guarantees by assigning a fixed amount of resources). We\ncharacterize the Nash equilibrium, best response dynamics, and propose a\npractical slice strategy with provable convergence properties. Extensive\nsimulations exhibit substantial improvements over network slicing\nstate-of-the-art benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 05:15:43 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zheng", "Jiaxiao", ""], ["de Veciana", "Gustavo", ""], ["Banchs", "Albert", ""]]}, {"id": "2001.01406", "submitter": "Ravi Shankar Mr", "authors": "Ravi Shankar, Lokesh Bhardwaj, Ritesh Kumar Mishra", "title": "Analysis of Selective-Decode and Forward Relaying Protocol Over kappa-mu\n  Fading Channel Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine the performance of selective-decode and forward\n(S-DF) relay systems over kappa-mu fading channel condition. We discuss about\nthe probability density function (PDF), system model, and cumulative\ndistribution function (CDF) of kappa-mu distributed envelope and signal to\nnoise ratio (SNR) and the techniques to generate samples that follow kappa-mu\ndistribution. Specifically, we consider the case where the source-to-relay\n(SR), relay-to-destination (RD) and source-to-destination (SD) link is subject\nto the independent and identically distributed (i.i.d.) kappa-mu fading. From\nthe simulation results, the enhancement in the symbol error rate (SER) with a\nstronger line of sight (LOS) component is observed. This shows that S-DF\nrelaying systems can perform well even in the non-fading or LOS conditions.\nMonte Carlo simulations are conducted for various values of fading parameters\nand the outcomes closely match with theoretical outcomes which validate the\nderivations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 05:24:20 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Shankar", "Ravi", ""], ["Bhardwaj", "Lokesh", ""], ["Mishra", "Ritesh Kumar", ""]]}, {"id": "2001.01553", "submitter": "Ke Zhang", "authors": "Abhijeet Bhorkar, Ke Zhang, Jin Wang", "title": "DeepAuto: A Hierarchical Deep Learning Framework for Real-Time\n  Prediction in Cellular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate real-time forecasting of key performance indicators (KPIs) is an\nessential requirement for various LTE/5G radio access network (RAN) automation.\nHowever, an accurate prediction can be very challenging in large-scale cellular\nenvironments due to complex spatio-temporal dynamics, network configuration\nchanges and unavailability of real-time network data. In this work, we\nintroduce a reusable analytics framework that enables real-time KPI prediction\nusing a hierarchical deep learning architecture. Our prediction approach,\nnamely DeepAuto, stacks multiple long short-term memory (LSTM) networks\nhorizontally to capture instantaneous, periodic and seasonal patterns in KPI\ntime-series. It further merge with feed-forward networks to learn the impact of\nnetwork configurations and other external factors. We validate the approach by\npredicting two important KPIs, including cell load and radio channel quality,\nusing large-scale real network streaming measurement data from the operator.\nFor cell load prediction, DeepAuto model showed up to 15% improvement in Root\nMean Square Error (RMSE) compared to naive method of using recent measurements\nfor short-term horizon and up to 32% improvement for longer-term prediction.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 03:36:57 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Bhorkar", "Abhijeet", ""], ["Zhang", "Ke", ""], ["Wang", "Jin", ""]]}, {"id": "2001.01561", "submitter": "Muhammad Junaid Farooq", "authors": "Muhammad Junaid Farooq and Quanyan Zhu", "title": "PhD Forum: Enabling Autonomic IoT for Smart Urban Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of autonomous cyber-physical systems (CPS) and advances\ntowards the fifth generation (5G) of wireless technology is promising to\nrevolutionize many industry verticals such as Healthcare, Transportation,\nEnergy, Retail Services, Building Automation, Education, etc., leading to the\nrealization of the smart city paradigm. The Internet of Things (IoT), enables\npowerful and unprecedented capabilities for intelligent and autonomous\noperation. We leverage ideas from Network Science, Optimization & Decision\nTheory, Incentive Mechanism Design, and Data Science/Machine Learning to\nachieve key design goals, in IoT-enabled urban systems, such as efficiency,\nsecurity & resilience, and economics.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 20:59:06 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Farooq", "Muhammad Junaid", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2001.01626", "submitter": "Wilder Castellanos", "authors": "Kevin Delgadillo, Cesar Rodriguez, Wilder Castellanos and Hector\n  Guarnizo", "title": "Performance Evaluation of a Substrate Integrated Waveguide Antenna for\n  Vehicular Networks", "comments": "30 pages, in Spanish, 15 figures, inclusion in conference proceedings\n  \"Tecnologia e Innovacion en Ingenieria\" del Congreso Internacional de\n  Tecnologia, Ingenieria e Innovacion CITII-2017, en la Universidad de San\n  Buenaventura, sede Bogota. Colombia. ISBN 978-958-8928-72-2", "journal-ref": "Tecnologia e Innovacion en la Ingenieria. 1st Edition (2018)\n  438-467. Bogota, Colombia. Editorial Bonaventuriana. ISBN 978-958-8928-72-2", "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design and evaluation of a Substrate Integrated\nWaveguide (SIW) antenna operating at 2.4 GHz. This antenna was designed as a\npossible solution for the implementation of the vehicular networks (VANETs).\nThe main advantages of the SIW antennas, such as their simplicity, small size\nand low cost, make this kind of antennas particularly suitable for using in\nwireless nodes where the size is a critical factor. For example, in Vehicular\nNetworks (VANETs) which is one of the most promising wireless communication\nsystems. We present in this paper the design of the SIW antenna using the\nsoftware ANSYS HFSS as well as the results of the assessment of some parameters\nlike the radiation pattern, operation frequency and bandwidth. Also, we present\nthe simulation of a VANET that include the designed parameters of the SIW\nantenna in order to evaluate its integration into the vehicular nodes. This\nsimulation was performed in the NS2 simulator and some network performance\nmetrics, like packet delay and the packet loss rate, were evaluated. Other\nadditional software, for example MOVE and SUMO, were also used to generate the\nroutes and the movement of the vehicles\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 22:37:02 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Delgadillo", "Kevin", ""], ["Rodriguez", "Cesar", ""], ["Castellanos", "Wilder", ""], ["Guarnizo", "Hector", ""]]}, {"id": "2001.01770", "submitter": "Vineet Gokhale", "authors": "J.P. Verburg, H.J.C. Kroep, V. Gokhale, R. Venkatesha Prasad, and V.\n  Rao", "title": "Setting the Yardstick: A Quantitative Metric for Effectively Measuring\n  Tactile Internet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next frontier in communications is teleoperation -- manipulation and\ncontrol of remote environments. Compared to conventional networked\napplications, teleoperation poses widely different requirements, ultra-low\nlatency (ULL) being the primary one. Teleoperation, along with a host of other\napplications requiring ULL communication, is termed as Tactile Internet (TI). A\nsignificant redesign of conventional networking techniques is necessary to\nrealize TI applications. Further, these advancements can be evaluated only when\nmeaningful performance metrics are available. However, existing TI performance\nmetrics fall severely short of comprehensively characterizing TI performance.\nIn this paper, we take the first step towards bridging this gap. To this end,\nwe propose a method that captures the fine-grained performance of TI in terms\nof delay and precision. We take Dynamic Time Warping (DTW) as the basis of our\nwork and identify whether it is sufficient in characterizing TI systems. We\nrefine DTW by developing a framework called Effective Time- and Value-Offset\n(ETVO) that extracts fine-grained time and value offsets between input and\noutput signals of TI. Using ETVO, we present two quantitative metrics for TI --\nEffective Delay-Derivative (EDD) and Effective Root Mean Square Error. Through\nrigorous experiments conducted on a realistic TI setup, we demonstrate the\npotential of the proposed metrics to precisely characterize TI interactions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 20:31:44 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 09:27:25 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Verburg", "J. P.", ""], ["Kroep", "H. J. C.", ""], ["Gokhale", "V.", ""], ["Prasad", "R. Venkatesha", ""], ["Rao", "V.", ""]]}, {"id": "2001.01911", "submitter": "Bekir Sait Ciftler", "authors": "Bekir Sait Ciftler, Abdullatif Albaseer, Noureddine Lasla, Mohamed\n  Abdallah", "title": "Federated Learning for Localization: A Privacy-Preserving Crowdsourcing\n  Method", "comments": "6 pages, An improved version of this manuscript in review for IEEE\n  ICC ANLN Workshops 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Received Signal Strength (RSS) fingerprint-based localization has attracted a\nlot of research effort and cultivated many commercial applications of\nlocation-based services due to its low cost and ease of implementation. Many\nstudies are exploring the use of deep learning (DL) algorithms for\nlocalization. DL's ability to extract features and to classify autonomously\nmakes it an attractive solution for fingerprint-based localization. These\nsolutions require frequent retraining of DL models with vast amounts of\nmeasurements. Although crowdsourcing is an excellent way to gather immense\namounts of data, it jeopardizes the privacy of participants, as it requires to\ncollect labeled data at a centralized server. Recently, federated learning has\nemerged as a practical concept in solving the privacy preservation issue of\ncrowdsourcing participants by performing model training at the edge devices in\na decentralized manner; the participants do not expose their data anymore to a\ncentralized server. This paper presents a novel method utilizing federated\nlearning to improve the accuracy of RSS fingerprint-based localization while\npreserving the privacy of the crowdsourcing participants. Employing federated\nlearning allows ensuring \\emph{preserving the privacy of user data} while\nenabling an adequate localization performance with experimental data captured\nin real-world settings. The proposed method improved localization accuracy by\n1.8 meters when used as a booster for centralized learning and achieved\nsatisfactory localization accuracy when used standalone.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 07:02:32 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 10:17:12 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Ciftler", "Bekir Sait", ""], ["Albaseer", "Abdullatif", ""], ["Lasla", "Noureddine", ""], ["Abdallah", "Mohamed", ""]]}, {"id": "2001.01980", "submitter": "Oscar Adamuz-Hinojosa", "authors": "Oscar Adamuz-Hinojosa, Pablo Mu\\~noz, Pablo Ameigeiras, Juan M.\n  Lopez-Soler", "title": "Sharing gNB components in RAN slicing: A perspective from 3GPP/NFV\n  standards", "comments": "Article accepted for publication in IEEE Conference on Standards and\n  Networking (CSCN) 2019", "journal-ref": null, "doi": "10.1109/CSCN.2019.8931318", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To implement the next Generation NodeBs (gNBs) that are present in every\nRadio Access Network (RAN) slice subnet, Network Function Virtualization (NFV)\nenables the deployment of some of the gNB components as Virtual Networks\nFunctions (VNFs). Deploying individual VNF instances for these components could\nguarantee the customization of each RAN slice subnet. However, due to the\nmultiplicity of VNFs, the required amount of virtual resources will be greater\ncompared to the case where a single VNF instance carries the aggregated traffic\nof all the RAN slice subnets. Sharing gNB components between RAN slice subnets\ncould optimize the trade-off between customization, isolation and resource\nutilization. In this article, we shed light on the key aspects in the Third\nGeneration Partnership Project (3GPP)/NFV standards for sharing gNB components.\nFirst, we identify four possible scenarios for sharing gNB components. Then, we\nanalyze the impact of sharing on the customization level of each RAN slice\nsubnet. Later, we determine the main factors that enable isolation between RAN\nslice subnets. Finally, we propose a 3GPP/NFV-based description model to define\nthe lifecycle management of shared gNB components\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 11:35:53 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Adamuz-Hinojosa", "Oscar", ""], ["Mu\u00f1oz", "Pablo", ""], ["Ameigeiras", "Pablo", ""], ["Lopez-Soler", "Juan M.", ""]]}, {"id": "2001.02088", "submitter": "Dalton Valadares", "authors": "Dalton C\\'ezane Gomes Valadares, Joseana Mac\\^edo Fechine R\\'egis de\n  Ara\\'ujo, Marco Aur\\'elio Spohn, Angelo Perkusich, Kyller Costa Gorg\\^onio\n  and Elmar Uwe Kurt Melcher", "title": "802.11g Signal Strength Evaluation in an Industrial Environment", "comments": "This is an extended version of the AINA2019 paper: \"Towards 802.11g\n  Signal Strength Estimation in an Industrial Environment: a Practical Study\".\n  Submitted to: Elsevier Internet of Things - Engineering Cyber Physical Human\n  Systems (ISSN 2542-6605)", "journal-ref": "Elsevier Internet of Things - Engineering Cyber Physical Human\n  Systems 2020 (ISSN 2542-6605):\n  https://www.journals.elsevier.com/internet-of-things", "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advances in wireless network technologies and Industrial Internet of\nThings (IIoT) devices are easing the establishment of what is called Industry\n4.0. For the industrial environments, the wireless networks are more suitable\nmainly due to their great flexibility, low deployment cost and for being less\ninvasive. Although new wireless protocols are emerging or being updated,\nchanges in existing industries generally can lead to large expenditures. As the\nwell known and accepted IEEE 802.11g standard, mostly used in residential and\ncommercial applications, has a low deployment and maintenance cost, many\nindustries also decide to adopt it. In this scenario, there is a need to\nevaluate the signal quality to better design the network infrastructure in\norder to obtain good communication coverage. In this work, we present a\npractical study about the 802.11g signal strength in a thermoelectric power\nplant. We collected signal strength values in different points along the engine\nroom and compared our measured values with the estimated ones through the\nLog-Distance Path Loss model. We concluded that it is possible to use this\nmodel in an industrial environment to estimate signal strength with a low error\nby choosing the right propagation (path loss) exponent.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 15:00:53 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Valadares", "Dalton C\u00e9zane Gomes", ""], ["de Ara\u00fajo", "Joseana Mac\u00eado Fechine R\u00e9gis", ""], ["Spohn", "Marco Aur\u00e9lio", ""], ["Perkusich", "Angelo", ""], ["Gorg\u00f4nio", "Kyller Costa", ""], ["Melcher", "Elmar Uwe Kurt", ""]]}, {"id": "2001.02163", "submitter": "Che Zhang", "authors": "Che Zhang, Shiwei Zhang, Bo Jin, Weichao Li, Zhen Wang, Qing Li, Yi\n  Wang", "title": "A3: An Automatic Topology-Aware Malfunction Detection and Fixation\n  System in Data Center Networks", "comments": "The poster version is published as a SIGCOMM 2019 poster, and the 5\n  pages' version is under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link failures and cable miswirings are not uncommon in building data center\nnetworks, which prevents the existing automatic address configuration methods\nfrom functioning correctly. However, accurately detecting such malfunctions is\nnot an easy task because there could be no observable node degree changes.\nFixing or correcting such malfunctions is even harder as almost no work can\nprovide accurate fixation suggestions now.\n  To solve the problems, we design and implement A3, an automatic\ntopology-aware malfunction detection and fixation system. A3 innovatively\nformulates the problem of finding minimal fixation to the problem of computing\nminimum graph difference (NP-hard) and solves it in O(k^6) and O(k^3) for any\nless than k/2 and k/4 undirected link malfunctions for FatTree, respectively.\nOur evaluation demonstrates that for less than k/2 undirected link\nmalfunctions, A3 is 100% accurate for malfunction detection and provides the\nminimum fixation result. For greater or equal to k/2 undirected link\nmalfunctions, A3 still has accuracy of about 100% and provides the near optimal\nfixation result.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 16:44:50 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Zhang", "Che", ""], ["Zhang", "Shiwei", ""], ["Jin", "Bo", ""], ["Li", "Weichao", ""], ["Wang", "Zhen", ""], ["Li", "Qing", ""], ["Wang", "Yi", ""]]}, {"id": "2001.02349", "submitter": "Yicheng Xu", "authors": "Yicheng Xu, Vincent Chau, Chenchen Wu, Yong Zhang, Yifei Zou", "title": "Online Joint Placement and Allocation of Virtual Network Functions with\n  Heterogeneous Servers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Function Virtualization (NFV) is a promising virtualization\ntechnology that has the potential to significantly reduce the expenses and\nimprove the service agility. NFV makes it possible for Internet Service\nProviders (ISPs) to employ various Virtual Network Functions (VNFs) without\ninstalling new equipments. One of the most attractive approaches in NFV\ntechnology is a so-called Joint Placement and Allocation of Virtual Network\nFunctions (JPA-VNF) which considers the balance between VNF investment with\nQuality of Services (QoS). We introduce a novel capability function to measure\nthe potential of locating VNF instances for each server in the proposed OJPA-HS\nmodel. This model allows the servers in the network to be heterogeneous, at the\nsame time combines and generalizes many classical JPA-VNF models. Despite its\nNP-hardness, we present a provable best-possible deterministic online algorithm\nbased on dynamic programming (DP). To conquer the high complexity of DP, we\npropose two additional randomized heuristics, the Las Vegas (LV) and Monte\nCarlo (MC) randomized algorithms, which performs even as good as DP with much\nsmaller complexity. Besides, MC is a promising heuristic in practice as it has\nthe advantage to deal with big data environment. Extensive numerical\nexperiments are constructed for the proposed algorithms in the paper.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 03:07:34 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Xu", "Yicheng", ""], ["Chau", "Vincent", ""], ["Wu", "Chenchen", ""], ["Zhang", "Yong", ""], ["Zou", "Yifei", ""]]}, {"id": "2001.02396", "submitter": "Petros Spachos", "authors": "Andrew Mackey, Petros Spachos, Liang Song and Konstantinos Plataniotis", "title": "Improving BLE Beacon Proximity Estimation Accuracy through Bayesian\n  Filtering", "comments": null, "journal-ref": "JIOT.2020.2965583", "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interconnectedness of all things is continuously expanding which has\nallowed every individual to increase their level of interaction with their\nsurroundings. Internet of Things (IoT) devices are used in a plethora of\ncontext-aware application such as Proximity-Based Services (PBS), and\nLocation-Based Services (LBS). For these systems to perform, it is essential to\nhave reliable hardware and predict a user's position in the area with high\naccuracy in order to differentiate between individuals in a small area. A\nvariety of wireless solutions that utilize Received Signal Strength Indicators\n(RSSI) have been proposed to provide PBS and LBS for indoor environments,\nthough each solution presents its own drawbacks. In this work, Bluetooth Low\nEnergy (BLE) beacons are examined in terms of their accuracy in proximity\nestimation. Specifically, a mobile application is developed along with three\nBayesian filtering techniques to improve the BLE beacon proximity estimation\naccuracy. This includes a Kalman filter, a particle filter, and a\nNon-parametric Information (NI) filter. Since the RSSI is heavily influenced by\nthe environment, experiments were conducted to examine the performance of\nbeacons from three popular vendors in two different environments. The error is\ncompared in terms of Mean Absolute Error (MAE) and Root Mean Squared Error\n(RMSE). According to the experimental results, Bayesian filters can improve\nproximity estimation accuracy up to 30 % in comparison with traditional\nfiltering, when the beacon and the receiver are within 3 m.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 07:00:52 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mackey", "Andrew", ""], ["Spachos", "Petros", ""], ["Song", "Liang", ""], ["Plataniotis", "Konstantinos", ""]]}, {"id": "2001.02482", "submitter": "Qian Wang", "authors": "Qian Wang, He Chen, Yifan Gu, Yonghui Li, Branka Vucetic", "title": "Minimizing the Age of Information of Cognitive Radio-Based IoT Systems\n  Under A Collision Constraint", "comments": "30 pages. This work has been submitted to the IEEE for possible\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a cognitive radio-based IoT monitoring system,\nconsisting of an IoT device that aims to update its measurement to a\ndestination using cognitive radio technique. Specifically, the IoT device as a\nsecondary user (SIoT), seeks and exploits the spectrum opportunities of the\nlicensed band vacated by its primary user (PU) to deliver status updates\nwithout causing visible effects to the licensed operation. In this context, the\nSIoT should carefully make use of the licensed band and schedule when to\ntransmit to maintain the timeliness of the status update. We adopt a recent\nmetric, Age of Information (AoI), to characterize the timeliness of the status\nupdate of the SIoT. We aim to minimize the long-term average AoI of the SIoT\nwhile satisfying the collision constraint imposed by the PU by formulating a\nconstrained Markov decision process (CMDP) problem. We first prove the\nexistence of optimal stationary policy of the CMDP problem. The optimal\nstationary policy (termed age-optimal policy) is shown to be a randomized\nsimple policy that randomizes between two deterministic policies with a fixed\nprobability. We prove that the two deterministic policies have a threshold\nstructure and further derive the closed-form expression of average AoI and\ncollision probability for the deterministic threshold-structured policy by\nconducting Markov Chain analysis. The analytical expression offers an efficient\nway to calculate the threshold and randomization probability to form the\nage-optimal policy. For comparison, we also consider the throughput\nmaximization policy (termed throughput-optimal policy) and analyze the average\nAoI performance under the throughput-optimal policy in the considered system.\nNumerical simulations show the superiority of the derived age-optimal policy\nover the throughput-optimal policy. We also unveil the impacts of various\nsystem parameters on the corresponding optimal policy and the resultant average\nAoI.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 12:41:47 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Wang", "Qian", ""], ["Chen", "He", ""], ["Gu", "Yifan", ""], ["Li", "Yonghui", ""], ["Vucetic", "Branka", ""]]}, {"id": "2001.02564", "submitter": "Maximilian Hils", "authors": "Maximilian Hils, Rainer B\\\"ohme", "title": "Watching the Weak Link into Your Home: An Inspection and Monitoring\n  Toolkit for TR-069", "comments": "Full Version. Abridged Conference Version to be published (ACNS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TR-069 is a standard for the remote management of end-user devices by service\nproviders. Despite being implemented in nearly a billion devices, almost no\nresearch has been published on the security and privacy aspects of TR-069. The\nfirst contribution of this paper is a study of the TR-069 ecosystem and\ntechniques to inspect TR-069 communication. We find that the majority of\nanalyzed providers do not use recommended security measures, such as TLS.\nSecond, we present a TR-069 honeyclient to both analyze TR-069 behavior of\nproviders and test configuration servers for security vulnerabilities. We find\nthat popular open-source configuration servers use insecure methods to\nauthenticate clients. TR-069 implementations based on these servers expose, for\ninstance, their users' internet telephony credentials. Third, we develop\ncomponents for a distributed system to continuously monitor activities in\nproviders' TR-069 deployments. Our setup consists of inexpensive hardware\nsensors deployed on customer premises and centralized log collectors. We\nperform real-world measurements and find that the purported security benefits\nof TR-069 are not realized as providers' firmware update processes are lacking.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 15:17:38 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Hils", "Maximilian", ""], ["B\u00f6hme", "Rainer", ""]]}, {"id": "2001.02704", "submitter": "Emmanuel Lochin", "authors": "J\\'er\\^ome Lacan and Emmanuel Lochin", "title": "XOR-based Source Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a XOR-based source routing (XSR) scheme as a novel approach to\nenable fast forwarding and low-latency communications. XSR uses linear encoding\noperation to both 1)~build the path labels of unicast and multicast data\ntransfers; 2)~perform fast computational efficient routing decisions compared\nto standard table lookup procedure without any packet modification all along\nthe path. XSR specifically focuses on decreasing the complexity of forwarding\nrouter operations. This allows packet switches (e.g, link-layer switch or\nrouter) to perform only simple linear operations over a binary vector label\nwhich embeds the path. XSR provides the building blocks to speed up the\nforwarding plane and can be applied to different data planes such as MPLS or\nIPv6. Compared to recent approaches based on modular arithmetic, XSR computes\nthe smallest label possible and presents strong scalable properties allowing to\nbe deployed over any kind of core vendor or datacenter networks. At last but\nnot least, the same computed label can be used interchangeably to cross the\npath forward or reverse in the context of unicast communication.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 19:08:49 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Lacan", "J\u00e9r\u00f4me", ""], ["Lochin", "Emmanuel", ""]]}, {"id": "2001.02757", "submitter": "Hongzhi Chen", "authors": "Hongzhi Chen, De Mi, Manuel Fuentes, Eduardo Garro, Jose Luis Carcel,\n  Belkacem Mouhouche, Pei Xiao and Rahim Tafazolli", "title": "On the Performance of PDCCH in LTE and 5G New Radio", "comments": "Globecomm 2018 workshop, 6 pages, 7 figs", "journal-ref": null, "doi": "10.1109/GLOCOMW.2018.8644128", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  5G New Radio (NR) Release 15 has been specified in June 2018. It introduces\nnumerous changes and potential improvements for physical layer data\ntransmissions, although only point-to-point (PTP) communications are\nconsidered. In order to use physical data channels such as the Physical\nDownlink Shared Channel (PDSCH), it is essential to guarantee a successful\ntransmission of control information via the Physical Downlink Control Channel\n(PDCCH). Taking into account these two aspects, in this paper, we first analyze\nthe PDCCH processing chain in NR PTP as well as in the state-of-the-art Long\nTerm Evolution (LTE) point-to-multipoint (PTM) solution, i.e., evolved\nMultimedia Broadcast Multicast Service (eMBMS). Then, via link level\nsimulations, we compare the performance of the two technologies, observing the\nBit/Block Error Rate (BER/BLER) for various scenarios. The objective is to\nidentify the performance gap brought by physical layer changes in NR PDCCH as\nwell as provide insightful guidelines on the control channel configuration\ntowards NR PTM scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 14:09:21 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Chen", "Hongzhi", ""], ["Mi", "De", ""], ["Fuentes", "Manuel", ""], ["Garro", "Eduardo", ""], ["Carcel", "Jose Luis", ""], ["Mouhouche", "Belkacem", ""], ["Xiao", "Pei", ""], ["Tafazolli", "Rahim", ""]]}, {"id": "2001.02758", "submitter": "Hongzhi Chen", "authors": "Hongzhi Chen, De Mi, Manuel Fuentes, David Vargas, Eduardo Garro, Jose\n  Luis Carcel, Belkacem Mouhouche, Pei Xiao and Rahim Tafazolli", "title": "Pioneering Studies on LTE eMBMS: Towards 5G Point-to-Multipoint\n  Transmissions", "comments": "SAM 2018, 5 pages, 4 figs", "journal-ref": null, "doi": "10.1109/SAM.2018.8448955", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The first 5G (5th generation wireless systems) New Radio Release-15 was\nrecently completed. However, the specification only considers the use of\nunicast technologies and the extension to point-to-multipoint (PTM) scenarios\nis not yet considered. To this end, we first present in this work a technical\noverview of the state-of-the-art LTE (Long Term Evolution) PTM technology,\ni.e., eMBMS (evolved Multimedia Broadcast Multicast Services), and investigate\nthe physical layer performance via link-level simulations. Then based on the\nsimulation analysis, we discuss potential improvements for the two current\neMBMS solutions, i.e., MBSFN (MBMS over Single Frequency Networks) and SC-PTM\n(Single-Cell PTM). This work explicitly focus on equipping the current eMBMS\nsolutions with 5G candidate techniques, e.g., multiple antennas and millimeter\nwave, and its potentials to meet the requirements of next generation PTM\ntransmissions.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:21:40 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Chen", "Hongzhi", ""], ["Mi", "De", ""], ["Fuentes", "Manuel", ""], ["Vargas", "David", ""], ["Garro", "Eduardo", ""], ["Carcel", "Jose Luis", ""], ["Mouhouche", "Belkacem", ""], ["Xiao", "Pei", ""], ["Tafazolli", "Rahim", ""]]}, {"id": "2001.02759", "submitter": "Ran Liu", "authors": "Ran Liu, Sumudu Hasala Marakkalage, Madhushanka Padmal,\n  Thiruketheeswaran Shaganan, Chau Yuen, Yong Liang Guan, U-Xuan Tan", "title": "Collaborative SLAM based on Wifi Fingerprint Similarity and Motion\n  Information", "comments": "Accepted at IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous localization and mapping (SLAM) has been extensively researched\nin past years particularly with regard to range-based or visual-based sensors.\nInstead of deploying dedicated devices that use visual features, it is more\npragmatic to exploit the radio features to achieve this task, due to their\nubiquitous nature and the widespread deployment of Wi-Fi wireless network. This\npaper presents a novel approach for collaborative simultaneous localization and\nradio fingerprint mapping (C-SLAM-RF) in large unknown indoor environments. The\nproposed system uses received signal strengths (RSS) from Wi-Fi access points\n(AP) in the existing infrastructure and pedestrian dead reckoning (PDR) from a\nsmart phone, without a prior knowledge about map or distribution of AP in the\nenvironment. We claim a loop closure based on the similarity of the two radio\nfingerprints. To further improve the performance, we incorporate the turning\nmotion and assign a small uncertainty value to a loop closure if a matched\nturning is identified. The experiment was done in an area of 130 meters by 70\nmeters and the results show that our proposed system is capable of estimating\nthe tracks of four users with an accuracy of 0.6 meters with Tango-based PDR\nand 4.76 meters with a step counter-based PDR.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 05:08:31 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Liu", "Ran", ""], ["Marakkalage", "Sumudu Hasala", ""], ["Padmal", "Madhushanka", ""], ["Shaganan", "Thiruketheeswaran", ""], ["Yuen", "Chau", ""], ["Guan", "Yong Liang", ""], ["Tan", "U-Xuan", ""]]}, {"id": "2001.02760", "submitter": "Abhaykumar Kumbhar", "authors": "Abhaykumar Kumbhar, Hamidullah Binol, Simran Singh, Ismail Guvenc,\n  Kemal Akkaya", "title": "Heuristic Approach for Jointly Optimizing FeICIC and UAV Locations in\n  Multi-Tier LTE-Advanced Public Safety HetNet", "comments": "Submitted at IET Cyber-Systems and Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UAV enabled communications and networking can enhance wireless connectivity\nand support emerging services. However, this would require system-level\nunderstanding to modify and extend the existing terrestrial network\ninfrastructure. In this paper, we integrate UAVs both as user equipment and\nbase stations into existing LTE-Advanced heterogeneous network (HetNet) and\nprovide system-level insights of this three-tier LTE-Advanced air-ground HetNet\n(AG-HetNet). This AG-HetNet leverages cell range expansion (CRE), ICIC, 3D\nbeamforming, and enhanced support for UAVs. Using system-level understanding\nand through brute-force technique and heuristics algorithms, we evaluate the\nperformance of AG-HetNet in terms of fifth percentile spectral efficiency\n(5pSE) and coverage probability. We compare 5pSE and coverage probability, when\naerial base-stations (UABS) are deployed on a fixed hexagonal grid and when\ntheir locations are optimized using genetic algorithm (GA) and elitist harmony\nsearch algorithm based on genetic algorithm (eHSGA). Our simulation results\nshow the heuristic algorithms outperform the brute-force technique and achieve\nbetter peak values of coverage probability and 5pSE. Simulation results also\nshow that trade-off exists between peak values and computation time when using\nheuristic algorithms. Furthermore, the three-tier hierarchical structuring of\nFeICIC provides considerably better 5pSE and coverage probability than eICIC.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 14:22:29 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Kumbhar", "Abhaykumar", ""], ["Binol", "Hamidullah", ""], ["Singh", "Simran", ""], ["Guvenc", "Ismail", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2001.02761", "submitter": "Ahmed A. Mawgoud", "authors": "Ahmed A Mawgoud, Mohamed Hamed Taha, Nour Eldeen Khalifa", "title": "QoS Provision for Controlling Energy Consumption in Ad-hoc Wireless\n  Sensor Networks", "comments": null, "journal-ref": "ICIC Express Letters, Volume 14, Number 8, August 2020,761--767", "doi": "10.24507/icicel.14.08.761", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adhoc wireless sensor network is an architecture of connected nodes, each\nnode has its main elements such as sensors, computation and communications\ncapabilities. Adhoc WSNs restrained energy sources result in a shorter lifetime\nof the sensor network and inefficient topology. In this paper, a new approach\nfor saving and energy controlling is introduced using quality of service, the\nmain reason is to reduce the nodes energy through discovering the best optimum\nroute that meets quality of service requirements; quality of service technique\nis used to find the optimum methodology for nodes packets transmission and\nenergy consumption.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:20:47 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Mawgoud", "Ahmed A", ""], ["Taha", "Mohamed Hamed", ""], ["Khalifa", "Nour Eldeen", ""]]}, {"id": "2001.02942", "submitter": "Ziyao Zhang Mr.", "authors": "Liang Ma and Ziyao Zhang and Mudhakar Srivatsa", "title": "Neural Network Tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network tomography, a classic research problem in the realm of network\nmonitoring, refers to the methodology of inferring unmeasured network\nattributes using selected end-to-end path measurements. In the research\ncommunity, network tomography is generally investigated under the assumptions\nof known network topology, correlated path measurements, bounded number of\nfaulty nodes/links, or even special network protocol support. The applicability\nof network tomography is considerably constrained by these strong assumptions,\nwhich therefore frequently position it in the theoretical world. In this\nregard, we revisit network tomography from the practical perspective by\nestablishing a generic framework that does not rely on any of these assumptions\nor the types of performance metrics. Given only the end-to-end path performance\nmetrics of sampled node pairs, the proposed framework, NeuTomography, utilizes\ndeep neural network and data augmentation to predict the unmeasured performance\nmetrics via learning non-linear relationships between node pairs and underlying\nunknown topological/routing properties. In addition, NeuTomography can be\nemployed to reconstruct the original network topology, which is critical to\nmost network planning tasks. Extensive experiments using real network data show\nthat comparing to baseline solutions, NeuTomography can predict network\ncharacteristics and reconstruct network topologies with significantly higher\naccuracy and robustness using only limited measurement data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 12:19:26 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ma", "Liang", ""], ["Zhang", "Ziyao", ""], ["Srivatsa", "Mudhakar", ""]]}, {"id": "2001.02951", "submitter": "Melissa Licciardello", "authors": "Melissa Licciardello, Maximilian Gr\\\"uner, Ankit Singla", "title": "Understanding video streaming algorithms in the wild", "comments": "Accepted to PAM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While video streaming algorithms are a hot research area, with interesting\nnew approaches proposed every few months, little is known about the behavior of\nthe streaming algorithms deployed across large online streaming platforms that\naccount for a substantial fraction of Internet traffic. We thus study adaptive\nbitrate streaming algorithms in use at 10 such video platforms with diverse\ntarget audiences. We collect traces of each video player's response to\ncontrolled variations in network bandwidth, and examine the algorithmic\nbehavior: how risk averse is an algorithm in terms of target buffer; how long\ndoes it takes to reach a stable state after startup; how reactive is it in\nattempting to match bandwidth versus operating stably; how efficiently does it\nuse the available network bandwidth; etc. We find that deployed algorithms\nexhibit a wide spectrum of behaviors across these axes, indicating the lack of\na consensus one-size-fits-all solution. We also find evidence that most\ndeployed algorithms are tuned towards stable behavior rather than fast\nadaptation to bandwidth variations, some are tuned towards a visual perception\nmetric rather than a bitrate-based metric, and many leave a surprisingly large\namount of the available bandwidth unused.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 12:47:06 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Licciardello", "Melissa", ""], ["Gr\u00fcner", "Maximilian", ""], ["Singla", "Ankit", ""]]}, {"id": "2001.02974", "submitter": "Barzan Yosuf Mr", "authors": "Barzan A. Yosuf, M. Musa, Taisir Elgorashi, Jaafar Elmirghani", "title": "Energy Efficient Distributed Processing for IoT", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the entire IoT-fog-cloud architecture is modelled, the service\nplacement problem is optimized through Mixed Integer Linear Programming (MILP)\nand the total power consumption is jointly minimized for processing and\nnetworking. Four aspects of IoT service placements are examined: 1)\nnon-splittable services, 2) splittable services, 3) inter-service processing\noverhead for sub-service synchronization and 4) deployment of special-purpose\ncloud data centers (SP-DCs). The results showed that for a capacitated problem,\nservice splitting introduces power consumption savings of up to 86% compared to\n46% with non-splittable services in relation to processing in general-purpose\ndata centers (GP-DCs). Moreover, it is observed that the inter sub-service\nprocessing overhead has a great influence on the total number of service\nsplits. However much insignificant the ratio of the processing overhead, the\nresults showed that this is not a trivial matter and hence much attention needs\nto paid to this area in order to make the best use of the resources that are\navailable in the edge of the network. Moreover, the optimization results showed\nthat, for very high demands, power savings of up to 50% could be achieved with\nSP-DCs compared to 30% with GP-DCs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 13:42:49 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Yosuf", "Barzan A.", ""], ["Musa", "M.", ""], ["Elgorashi", "Taisir", ""], ["Elmirghani", "Jaafar", ""]]}, {"id": "2001.02997", "submitter": "Esther Max-Onakpoya", "authors": "Esther Max-Onakpoya, Oluwashina Madamori, Corey Baker", "title": "Utilizing Opportunistic Social Networks for Remote Patient Monitoring in\n  Rural Areas", "comments": "4 pages. arXiv admin note: substantial text overlap with\n  arXiv:1905.05342", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Internet connectivity for remote patient monitoring is often\nunsuitable for rural communities where Internet infrastructure is lacking, and\npower outages are frequent. This paper explores the rural connectivity problem\nin the context of remote patient monitoring and analyzes the feasibility of\nutilizing a delay tolerant network (DTN) architecture that leverages the social\nbehaviors of rural community members to enable out-of-range monitoring of\npatients in rural communities without local transportation systems. The\nfeasibility is characterized using delivery latency and delivery rate with the\nnumber of participants and the number of sources as variables. The architecture\nis evaluated for Owingsville, KY using U.S. Census Bureau, the National Cancer\nInstitute's, and IPUMS ATUS sample data. The findings show that within a 24\nhour window, there is an exponential relationship between the number of\nparticipants in the network and the delivery rate with a minimal delivery of\n38.7%, a maximal delivery rate of a 100% and an overall average delivery rate\nof 89.8%.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 19:27:53 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Max-Onakpoya", "Esther", ""], ["Madamori", "Oluwashina", ""], ["Baker", "Corey", ""]]}, {"id": "2001.03314", "submitter": "Van Mao Ngo", "authors": "Mao V. Ngo, Hakima Chaouchi, Tie Luo, Tony Q.S. Quek", "title": "Adaptive Anomaly Detection for IoT Data in Hierarchical Edge Computing", "comments": "To be published in the AAAI Workshop on Artificial Intelligence of\n  Things (AIoT), Feb 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep neural networks (DNN) greatly bolster real-time detection of\nanomalous IoT data. However, IoT devices can barely afford complex DNN models\ndue to limited computational power and energy supply. While one can offload\nanomaly detection tasks to the cloud, it incurs long delay and requires large\nbandwidth when thousands of IoT devices stream data to the cloud concurrently.\nIn this paper, we propose an adaptive anomaly detection approach for\nhierarchical edge computing (HEC) systems to solve this problem. Specifically,\nwe first construct three anomaly detection DNN models of increasing complexity,\nand associate them with the three layers of HEC from bottom to top, i.e., IoT\ndevices, edge servers, and cloud. Then, we design an adaptive scheme to select\none of the models based on the contextual information extracted from input\ndata, to perform anomaly detection. The selection is formulated as a contextual\nbandit problem and is characterized by a single-step Markov decision process,\nwith an objective of achieving high detection accuracy and low detection delay\nsimultaneously. We evaluate our proposed approach using a real IoT dataset, and\ndemonstrate that it reduces detection delay by 84% while maintaining almost the\nsame accuracy as compared to offloading detection tasks to the cloud. In\naddition, our evaluation also shows that it outperforms other baseline schemes.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 05:29:17 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Ngo", "Mao V.", ""], ["Chaouchi", "Hakima", ""], ["Luo", "Tie", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2001.03321", "submitter": "Milad Ghaznavi", "authors": "Milad Ghaznavi, Elaheh Jalalpour, Bernard Wong, Raouf Boutaba, Ali\n  Jose Mashtizadeh", "title": "Fault Tolerance for Service Function Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enterprise network traffic typically traverses a sequence of middleboxes\nforming a service function chain, or simply a chain. Tolerating failures when\nthey occur along chains is imperative to the availability and reliability of\nenterprise applications. Making a chain fault-tolerant is challenging since, in\nthe event of failures, the state of faulty middleboxes must be correctly and\nquickly recovered while providing high throughput and low latency.\n  In this paper, we introduce FTC, novel system design and protocol for\nfault-tolerant service function chaining. FTC provides strong consistency with\nup to f middlebox failures for chains of length f+1 or longer without requiring\ndedicated replica nodes. In FTC, state updates caused by packet processing at a\nmiddlebox are collected, piggybacked into the packet, and sent along the chain\nto be replicated. The evaluation of our FTC implementation shows that compared\nwith the state of art [46], FTC improves throughput by 2-3.5x for a chain of\ntwo to five middleboxes.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 06:20:26 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 22:47:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Ghaznavi", "Milad", ""], ["Jalalpour", "Elaheh", ""], ["Wong", "Bernard", ""], ["Boutaba", "Raouf", ""], ["Mashtizadeh", "Ali Jose", ""]]}, {"id": "2001.03336", "submitter": "Cong Luong Nguyen", "authors": "Tran The Anh, Nguyen Cong Luong, Zehui Xiong, Dusit Niyato, and Dong\n  In Kim", "title": "Joint Time Scheduling and Transaction Fee Selection in Blockchain-based\n  RF-Powered Backscatter Cognitive Radio Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a new framework called blockchain-based Radio\nFrequency (RF)-powered backscatter cognitive radio network. In the framework,\nIoT devices as secondary transmitters transmit their sensing data to a\nsecondary gateway by using the RF-powered backscatter cognitive radio\ntechnology. The data collected at the gateway is then sent to a blockchain\nnetwork for further verification, storage and processing. As such, the\nframework enables the IoT system to simultaneously optimize the spectrum usage\nand maximize the energy efficiency. Moreover, the framework ensures that the\ndata collected from the IoT devices is verified, stored and processed in a\ndecentralized but in a trusted manner. To achieve the goal, we formulate a\nstochastic optimization problem for the gateway under the dynamics of the\nprimary channel, the uncertainty of the IoT devices, and the unpredictability\nof the blockchain environment. In the problem, the gateway jointly decides (i)\nthe time scheduling, i.e., the energy harvesting time, backscatter time, and\ntransmission time, among the IoT devices, (ii) the blockchain network, and\n(iii) the transaction fee rate to maximize the network throughput while\nminimizing the cost. To solve the stochastic optimization problem, we then\npropose to employ, evaluate, and assess the Deep Reinforcement Learning (DRL)\nwith Dueling Double Deep Q-Networks (D3QN) to derive the optimal policy for the\ngateway. The simulation results clearly show that the proposed solution\noutperforms the conventional baseline approaches such as the conventional\nQ-Learning algorithm and non-learning algorithms in terms of network throughput\nand convergence speed. Furthermore, the proposed solution guarantees that the\ndata is stored in the blockchain network at a reasonable cost.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 08:13:38 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Anh", "Tran The", ""], ["Luong", "Nguyen Cong", ""], ["Xiong", "Zehui", ""], ["Niyato", "Dusit", ""], ["Kim", "Dong In", ""]]}, {"id": "2001.03645", "submitter": "Eugene Grayver", "authors": "Eugene Grayver and Alexander Utter", "title": "Extreme Software Defined Radio -- GHz in Real Time", "comments": "Accepted to 2020 IEEE Aerospace Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software defined radio is a widely accepted paradigm for design of\nreconfigurable modems. The continuing march of Moore's law makes real-time\nsignal processing on general purpose processors feasible for a large set of\nwaveforms. Data rates in the low Mbps can be processed on low-power ARM\nprocessors, and much higher data rates can be supported on large x86\nprocessors. The advantages of all-software development (vs. FPGA/DSP/GPU) are\ncompelling: much wider pool of talent, lower development time and cost, and\neasier maintenance and porting. However, very high-rate systems (above 100\nMbps) are still firmly in the domain of custom and semi-custom hardware (mostly\nFPGAs). In this paper we describe an architecture and testbed for an SDR that\ncan be easily scaled to support over 3 GHz of bandwidth and data rate up to 10\nGbps. The paper covers a novel technique to parallelize typically serial\nalgorithms for phase and symbol tracking, followed by a discussion of data\ndistribution for a massively parallel architecture. We provide a brief\ndescription of a mixed-signal front end and conclude with measurement results.\nTo the best of the author's knowledge, the system described in this paper is an\norder of magnitude faster than any prior published result.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 19:41:37 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Grayver", "Eugene", ""], ["Utter", "Alexander", ""]]}, {"id": "2001.03665", "submitter": "Vahid Shah-Mansouri Dr.", "authors": "Ali Parchekani, Salar Nouri Naghadeh, and Vahid Shah-Mansouri", "title": "Classification of Traffic Using Neural Networks by Rejecting: a Novel\n  Approach in Classifying VPN Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flows are set of packets transferring between a client and a server\nwith the same set of source and destination IP and port numbers. Traffic\nclassification is referred to as the task of categorizing traffic flows into\napplication-aware classes such as chats, streaming, VoIP, etc. Classification\ncan be used for several purposes including policy enforcement and control or\nQoS management. In this paper, we introduce a novel end-to-end traffic\nclassification method to distinguish between traffic classes including VPN\ntraffic. Classification of VPN traffic is not trivial using traditional\nclassification approaches due to its encrypted nature. We utilize two\nwell-known neural networks, namely multi-layer perceptron and recurrent neural\nnetwork focused on two metrics: class scores and distance from the center of\nthe classes. Such approaches combined extraction, selection, and classification\nfunctionality into a single end-to-end system to systematically learn the\nnon-linear relationship between input and predicted performance. Therefore, we\ncould distinguish VPN traffics from Non-VPN traffics by rejecting the unrelated\nfeatures of the VPN class. Moreover, obtain the application of Non-VPN traffics\nat the same time. The approach is evaluated using the general traffic dataset\nISCX VPN-nonVPN and the acquired real dataset. The results of the analysis\ndemonstrate that our proposed model fulfills the realistic project's criterion\nfor precision.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 21:01:22 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Parchekani", "Ali", ""], ["Naghadeh", "Salar Nouri", ""], ["Shah-Mansouri", "Vahid", ""]]}, {"id": "2001.03835", "submitter": "Xianzhe Xu", "authors": "Xianzhe Xu, Meixia Tao, Cong Shen", "title": "Collaborative Multi-Agent Multi-Armed Bandit Learning for Small-Cell\n  Caching", "comments": "15 pages, 11 figures,accepted by IEEE Transcations on Wireless\n  Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates learning-based caching in small-cell networks (SCNs)\nwhen user preference is unknown. The goal is to optimize the cache placement in\neach small base station (SBS) for minimizing the system long-term transmission\ndelay. We model this sequential multi-agent decision making problem in a\nmulti-agent multi-armed bandit (MAMAB) perspective. Rather than estimating user\npreference first and then optimizing the cache strategy, we propose several\nMAMAB-based algorithms to directly learn the cache strategy online in both\nstationary and non-stationary environment. In the stationary environment, we\nfirst propose two high-complexity agent-based collaborative MAMAB algorithms\nwith performance guarantee. Then we propose a low-complexity distributed MAMAB\nwhich ignores the SBS coordination. To achieve a better balance between SBS\ncoordination gain and computational complexity, we develop an edge-based\ncollaborative MAMAB with the coordination graph edge-based reward assignment\nmethod. In the non-stationary environment, we modify the MAMAB-based algorithms\nproposed in the stationary environment by proposing a practical initialization\nmethod and designing new perturbed terms to adapt to the dynamic environment.\nSimulation results are provided to validate the effectiveness of our proposed\nalgorithms. The effects of different parameters on caching performance are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 03:02:38 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 05:50:05 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Xu", "Xianzhe", ""], ["Tao", "Meixia", ""], ["Shen", "Cong", ""]]}, {"id": "2001.03836", "submitter": "Xin Zhang", "authors": "Xin Zhang, Minghong Fang, Jia Liu, and Zhengyuan Zhu", "title": "Private and Communication-Efficient Edge Learning: A Sparse Differential\n  Gaussian-Masking Distributed SGD Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rise of machine learning (ML) and the proliferation of smart mobile\ndevices, recent years have witnessed a surge of interest in performing ML in\nwireless edge networks. In this paper, we consider the problem of jointly\nimproving data privacy and communication efficiency of distributed edge\nlearning, both of which are critical performance metrics in wireless edge\nnetwork computing. Toward this end, we propose a new decentralized stochastic\ngradient method with sparse differential Gaussian-masked stochastic gradients\n(SDM-DSGD) for non-convex distributed edge learning. Our main contributions are\nthree-fold: i) We theoretically establish the privacy and communication\nefficiency performance guarantee of our SDM-DSGD method, which outperforms all\nexisting works; ii) We show that SDM-DSGD improves the fundamental\ntraining-privacy trade-off by {\\em two orders of magnitude} compared with the\nstate-of-the-art. iii) We reveal theoretical insights and offer practical\ndesign guidelines for the interactions between privacy preservation and\ncommunication efficiency, two conflicting performance goals. We conduct\nextensive experiments with a variety of learning models on MNIST and CIFAR-10\ndatasets to verify our theoretical findings. Collectively, our results\ncontribute to the theory and algorithm design for distributed edge learning.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 03:04:45 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 01:49:58 GMT"}, {"version": "v3", "created": "Sun, 19 Jan 2020 16:14:42 GMT"}, {"version": "v4", "created": "Sat, 28 Mar 2020 15:20:20 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Zhang", "Xin", ""], ["Fang", "Minghong", ""], ["Liu", "Jia", ""], ["Zhu", "Zhengyuan", ""]]}, {"id": "2001.03977", "submitter": "Amin Farajzadeh", "authors": "Amin Farajzadeh and Ozgur Ercetin and Halim Yanikomeroglu", "title": "Mobility-assisted Over-the-Air Computation for Backscatter Sensor\n  Networks", "comments": "4 Pages, 3 figures", "journal-ref": "IEEE Wireless Communications Letters (Early Access), January 2020", "doi": "10.1109/LWC.2020.2965515", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future intelligent systems will consist of a massive number of battery-less\nsensors, where quick and accurate aggregation of sensor data will be of\nparamount importance. Over-the-air computation (AirComp) is a promising\ntechnology wherein sensors concurrently transmit their measurements over the\nwireless channel, and a reader receives the noisy version of a function of\nmeasurements due to the superposition property. A key challenge in AirComp is\nthe accurate power alignment of individual transmissions, addressed previously\nby using conventional precoding methods. In this paper, we investigate a\nUAVenabled backscatter communication framework, wherein UAV acts both as a\npower emitter and reader. The mobility of the reader is leveraged to replace\nthe complicated precoding at sensors, where UAV first collects sum channel\ngains in the first flyover, and then, use these to estimate the actual\naggregated sensor data in the second flyover. Our results demonstrate\nimprovements of up to 10 dB in MSE compared to that of a benchmark case where\nUAV is incognizant of sum channel gains.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 18:48:08 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Farajzadeh", "Amin", ""], ["Ercetin", "Ozgur", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "2001.04014", "submitter": "Minsung Kim", "authors": "Minsung Kim, Davide Venturelli, Kyle Jamieson", "title": "Leveraging Quantum Annealing for Large MIMO Processing in Centralized\n  Radio Access Networks", "comments": "https://dl.acm.org/doi/10.1145/3341302.3342072", "journal-ref": "Proceedings of the ACM Special Interest Group on Data\n  Communication. 2019. 241-255", "doi": "10.1145/3341302.3342072", "report-no": null, "categories": "cs.NI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User demand for increasing amounts of wireless capacity continues to outpace\nsupply, and so to meet this demand, significant progress has been made in new\nMIMO wireless physical layer techniques. Higher-performance systems now remain\nimpractical largely only because their algorithms are extremely computationally\ndemanding. For optimal performance, an amount of computation that increases at\nan exponential rate both with the number of users and with the data rate of\neach user is often required. The base station's computational capacity is thus\nbecoming one of the key limiting factors on wireless capacity. QuAMax is the\nfirst large MIMO centralized radio access network design to address this issue\nby leveraging quantum annealing on the problem. We have implemented QuAMax on\nthe 2,031 qubit D-Wave 2000Q quantum annealer, the state-of-the-art in the\nfield. Our experimental results evaluate that implementation on real and\nsynthetic MIMO channel traces, showing that 10~$\\mu$s of compute time on the\n2000Q can enable 48 user, 48 AP antenna BPSK communication at 20 dB SNR with a\nbit error rate of $10^{-6}$ and a 1,500 byte frame error rate of $10^{-4}$.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 23:51:37 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Kim", "Minsung", ""], ["Venturelli", "Davide", ""], ["Jamieson", "Kyle", ""]]}, {"id": "2001.04042", "submitter": "Qian Wang", "authors": "Qian Wang, He Chen, Yonghui Li, Branka Vucetic", "title": "Minimizing Age of Information via Hybrid NOMA/OMA", "comments": "7 pages. This work has been submitted to the IEEE for possible\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a wireless network with a base station (BS) conducting\ntimely transmission to two clients in a slotted manner via hybrid\nnon-orthogonal multiple access (NOMA)/orthogonal multiple access (OMA).\nSpecifically, the BS is able to adaptively switch between NOMA and OMA for the\ndownlink transmission to minimize the information freshness, characterized by\nAge of Information (AoI), of the network. If the BS chooses OMA, it can only\nserve one client within a time slot and should decide which client to serve; if\nthe BS chooses NOMA, it can serve both clients simultaneously and should decide\nthe power allocated to each client. To minimize the weighted sum of expected\nAoI of the network, we formulate a Markov Decision Process (MDP) problem and\ndevelop an optimal policy for the BS to decide whether to use NOMA or OMA for\neach downlink transmission based on the instantaneous AoI of both clients. We\nprove the existence of optimal stationary and deterministic policy, and perform\naction elimination to reduce the action space for lower computation complexity.\nThe optimal policy is shown to have a switching-type property with obvious\ndecision switching boundaries. A suboptimal policy with lower computation\ncomplexity is also devised, which can achieve near-optimal performance\naccording to our simulation results. The performance of different policies\nunder different system settings is compared and analyzed in numerical results\nto provide useful insights for practical system designs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 02:57:53 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Wang", "Qian", ""], ["Chen", "He", ""], ["Li", "Yonghui", ""], ["Vucetic", "Branka", ""]]}, {"id": "2001.04049", "submitter": "Tianxiang Tan", "authors": "Tianxiang Tan and Guohong Cao", "title": "FastVA: Deep Learning Video Analytics Through Edge Processing and NPU in\n  Mobile", "comments": "10 pages, 11 figures, INFOCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mobile applications have been developed to apply deep learning for video\nanalytics. Although these advanced deep learning models can provide us with\nbetter results, they also suffer from the high computational overhead which\nmeans longer delay and more energy consumption when running on mobile\ndevices.To address this issue, we propose a framework called FastVA, which\nsupports deep learning video analytics through edge processing and Neural\nProcessing Unit (NPU) in mobile. The major challenge is to determine when to\noffload the computation and when to use NPU. Based on the processing time and\naccuracy requirement of the mobile application, we study two problems:\nMax-Accuracy where the goal is to maximize the accuracy under some time\nconstraints, and Max-Utility where the goal is to maximize the utility which is\na weighted function of processing time and accuracy. We formulate them as\ninteger programming problems and propose heuristics based solutions. We have\nimplemented FastVA on smartphones and demonstrated its effectiveness through\nextensive evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 03:42:07 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Tan", "Tianxiang", ""], ["Cao", "Guohong", ""]]}, {"id": "2001.04057", "submitter": "Sid Chi-Kin Chau", "authors": "Ivan Wang-Hei Ho, Sid Chi-Kin Chau, Elmer R. Magsino, Kanghao Jia", "title": "Efficient 3D Road Map Data Exchange for Intelligent Vehicles in\n  Vehicular Fog Networks", "comments": "This paper appears in IEEE Transactions on Vehicular Technology", "journal-ref": "IEEE Transactions on Vehicular Technology, Vol 69, Issue 3,\n  pp3151-3165, March 2020", "doi": "10.1109/TVT.2019.2963346", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through connecting intelligent vehicles as well as the roadside\ninfrastructure, the perception range of vehicles can be significantly extended,\nand hidden objects at blind spots can be efficiently detected and avoided. To\nrealize this, accurate road map data must be downloaded in real time to these\nintelligent vehicles for navigation and localization purposes. Besides, the\ncloud must be updated with dynamic changes that happened in the road network.\nThese involve the transmissions of high-definition 3D road map data for\naccurately representing the physical environments. In this work, we propose\nsolutions under the fog computing architecture in a heterogeneous vehicular\nnetwork to optimize data exchange among intelligent vehicles, the roadside\ninfrastructure, as well as regional databases. Specifically, the efficiency of\n3D road map data dissemination at roadside fog nodes is achieved by exploiting\nindex coding techniques to reduce the overall data load, while opportunistic\nscheduling of heterogeneous transmissions can be done to judiciously manage\nnetwork resources and minimize operating cost. In addition, 3D point cloud\ncoding and hashing techniques are applied to expedite the updates of various\ndynamic changes in the network. We empirically evaluate the proposed solutions\nbased on real-world mobility traces of vehicles and 3D LIght Detection And\nRanging (LIDAR) data of city streets. The proposed system is also implemented\nin a multi-robotic testbed for practical evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 04:26:52 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Ho", "Ivan Wang-Hei", ""], ["Chau", "Sid Chi-Kin", ""], ["Magsino", "Elmer R.", ""], ["Jia", "Kanghao", ""]]}, {"id": "2001.04084", "submitter": "Bohai Li", "authors": "Bohai Li, He Chen, Yong Zhou, Yonghui Li", "title": "Age-Oriented Opportunistic Relaying in Cooperative Status Update Systems\n  with Stochastic Arrivals", "comments": "7 pages. This work has been submitted to the IEEE for possible\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a cooperative status update system with a source aiming\nto send randomly generated status updates to a designated destination as timely\nas possible with the help of a relay. We adopt a recently proposed concept, Age\nof Information (AoI), to characterize the timeliness of the status updates. We\npropose an age-oriented opportunistic relaying (AoR) protocol to reduce the AoI\nof the considered system. Specifically, the relay opportunistically replaces\nthe source to retransmit the successfully received status updates that have not\nbeen correctly delivered to the destination, but the retransmission of the\nrelay can be preempted by the arrival of a new status update at the source. By\ncarefully analyzing the evolution of AoI, we derive a closed-form expression of\nthe average AoI for the proposed AoR protocol. We further minimize the average\nAoI by optimizing the generation probability of the status updates at the\nsource. Simulation results validate our theoretical analysis and demonstrate\nthat the average AoI performance of the proposed AoR protocol is superior to\nthat of the non-cooperative system.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 07:13:07 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Li", "Bohai", ""], ["Chen", "He", ""], ["Zhou", "Yong", ""], ["Li", "Yonghui", ""]]}, {"id": "2001.04161", "submitter": "Peng Yang", "authors": "Peng Yang, Xing Xi, Tony Q. S. Quek, Jingxuan Chen, Xianbin Cao,\n  Dapeng Wu", "title": "RAN Slicing for Massive IoT and Bursty URLLC Service Multiplexing:\n  Analysis and Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future wireless networks are envisioned to serve massive Internet of things\n(mIoT) via some radio access technologies, where the random access channel\n(RACH) procedure should be exploited for IoT devices to access the networks.\nHowever, the theoretical analysis of the RACH procedure for massive IoT devices\nis challenging. To address this challenge, we first correlate the RACH request\nof an IoT device with the status of its maintained queue and analyze the\nevolution of the queue status. Based on the analysis result, we then derive the\nclosed-form expression of the random access (RA) success probability, which is\na significant indicator characterizing the RACH procedure of the device.\nBesides, considering the agreement on converging different services onto a\nshared infrastructure, we investigate the RAN slicing for mIoT and bursty\nultra-reliable and low latency communications (URLLC) service multiplexing.\nSpecifically, we formulate the RAN slicing problem as an optimization one to\nmaximize the total RA success probabilities of all IoT devices and provide\nURLLC services for URLLC devices in an energy-efficient way. A slice resource\noptimization (SRO) algorithm exploiting relaxation and approximation with\nprovable tightness and error bound is then proposed to mitigate the\noptimization problem. Simulation results demonstrate that the proposed SRO\nalgorithm can effectively implement the service multiplexing of mIoT and bursty\nURLLC traffic.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 11:13:54 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 08:28:09 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 17:12:20 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Yang", "Peng", ""], ["Xi", "Xing", ""], ["Quek", "Tony Q. S.", ""], ["Chen", "Jingxuan", ""], ["Cao", "Xianbin", ""], ["Wu", "Dapeng", ""]]}, {"id": "2001.04229", "submitter": "Faheem Zafari", "authors": "Faheem Zafari, Prithwish Basu, Kin K. Leung, Jian Li, Ananthram Swami\n  and Don Towsley", "title": "Resource Sharing in the Edge: A Distributed Bargaining-Theoretic\n  Approach", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing demand for edge computing resources, particularly due to\nincreasing popularity of Internet of Things (IoT), and distributed machine/deep\nlearning applications poses a significant challenge. On the one hand, certain\nedge service providers (ESPs) may not have sufficient resources to satisfy\ntheir applications according to the associated service-level agreements. On the\nother hand, some ESPs may have additional unused resources. In this paper, we\npropose a resource-sharing framework that allows different ESPs to optimally\nutilize their resources and improve the satisfaction level of applications\nsubject to constraints such as communication cost for sharing resources across\nESPs. Our framework considers that different ESPs have their own objectives for\nutilizing their resources, thus resulting in a multi-objective optimization\nproblem. We present an $N$-person \\emph{Nash Bargaining Solution} (NBS) for\nresource allocation and sharing among ESPs with \\emph{Pareto} optimality\nguarantee. Furthermore, we propose a \\emph{distributed}, primal-dual algorithm\nto obtain the NBS by proving that the strong-duality property holds for the\nresultant resource sharing optimization problem.\n  Using synthetic and real-world data traces, we show numerically that the\nproposed NBS based framework not only enhances the ability to satisfy\napplications' resource demands, but also improves utilities of different ESPs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:26:05 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 01:27:00 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 11:33:41 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Zafari", "Faheem", ""], ["Basu", "Prithwish", ""], ["Leung", "Kin K.", ""], ["Li", "Jian", ""], ["Swami", "Ananthram", ""], ["Towsley", "Don", ""]]}, {"id": "2001.04259", "submitter": "Ambuj Varshney", "authors": "Ambuj Varshney, Andreas Soleiman, Thiemo Voigt", "title": "TunnelScatter: Low Power Communication for Sensor Tags using Tunnel\n  Diodes", "comments": "This paper was presented at ACM MobiCom 2019", "journal-ref": null, "doi": "10.1145/3300061.3345451", "report-no": null, "categories": "cs.NI cs.ET eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to extremely low power consumption, backscatter has become the\ntransmission mechanism of choice for battery-free devices that operate on\nharvested energy. However, a limitation of recent backscatter systems is that\nthe communication range scales with the strength of the ambient carrier\nsignal(ACS). This means that to achieve a long range, a backscatter tag needs\nto reflect a strong ACS, which in practice means that it needs to be close to\nan ACS emitter. We present TunnelScatter, a mechanism that overcomes this\nlimitation. TunnelScatter uses a tunnel diode-based radio frequency oscillator\nto enable transmissions when there is no ACS, and the same oscillator as a\nreflection amplifier to support backscatter transmissions when the ACS is weak.\nOur results show that even without an ACS, TunnelScatter is able to transmit\nthrough several walls covering a distance of 18 meter while consuming a peak\nbiasing power of 57 microwatts. Based on TunnelScatter, we design battery-free\nsensor tags, called TunnelTags, that can sense physical phenomena and transmit\nthem using the TunnelScatter mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:14:09 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Varshney", "Ambuj", ""], ["Soleiman", "Andreas", ""], ["Voigt", "Thiemo", ""]]}, {"id": "2001.04319", "submitter": "Nikita Korzhitskii", "authors": "Nikita Korzhitskii, Niklas Carlsson", "title": "Characterizing the Root Landscape of Certificate Transparency Logs", "comments": "9 pages", "journal-ref": "In proceedings of 2020 IFIP Networking Conference (Networking)", "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet security and privacy stand on the trustworthiness of public\ncertificates signed by Certificate Authorities (CAs). However, software\nproducts do not trust the same CAs and therefore maintain different root\nstores, each typically containing hundreds of trusted roots capable of issuing\n\"trusted\" certificates for any domain. Incidents with misissued certificates\nmotivated Google to implement and enforce Certificate Transparency (CT). CT\nlogs archive certificates in a public, auditable and append-only manner. The\nadoption of CT changed the trust landscape. As a part of this change, CT logs\nstarted to maintain their own root lists and log certificates that chain back\nto one of the trusted roots. In this paper, we present the first\ncharacterization of this emerging CT root store landscape, as well as the tool\nthat we developed for data collection, visualization, and analysis of the root\nstores. We compare the logs' root stores and quantify their changes with\nrespect to both each other and the root stores of major software vendors, look\nat evolving vendor CT policies, and show that root store mismanagement may be\nlinked to log misbehavior. Finally, we present and discuss the results of a\nsurvey that we have sent to the log operators participating in Apple's and\nGoogle's CT log programs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:56:42 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 15:57:53 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Korzhitskii", "Nikita", ""], ["Carlsson", "Niklas", ""]]}, {"id": "2001.04561", "submitter": "Merima Kulin", "authors": "Merima Kulin, Tarik Kazaz, Ingrid Moerman, Eli de Poorter", "title": "A survey on Machine Learning-based Performance Improvement of Wireless\n  Networks: PHY, MAC and Network layer", "comments": "35 pages, survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a systematic and comprehensive survey that reviews the\nlatest research efforts focused on machine learning (ML) based performance\nimprovement of wireless networks, while considering all layers of the protocol\nstack (PHY, MAC and network). First, the related work and paper contributions\nare discussed, followed by providing the necessary background on data-driven\napproaches and machine learning for non-machine learning experts to understand\nall discussed techniques. Then, a comprehensive review is presented on works\nemploying ML-based approaches to optimize the wireless communication parameters\nsettings to achieve improved network quality-of-service (QoS) and\nquality-of-experience (QoE). We first categorize these works into: radio\nanalysis, MAC analysis and network prediction approaches, followed by\nsubcategories within each. Finally, open challenges and broader perspectives\nare discussed.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:33:29 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 14:44:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Kulin", "Merima", ""], ["Kazaz", "Tarik", ""], ["Moerman", "Ingrid", ""], ["de Poorter", "Eli", ""]]}, {"id": "2001.04699", "submitter": "Mohammadreza Doostmohammadian", "authors": "Mohammadreza Doostmohammadian", "title": "Recovering the Structural Observability of Composite Networks via\n  Cartesian Product", "comments": null, "journal-ref": "IEEE Transactions on signal and information processing over\n  networks, 2020", "doi": null, "report-no": null, "categories": "eess.SY cs.NI cs.SI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observability is a fundamental concept in system inference and estimation.\nThis paper is focused on structural observability analysis of Cartesian product\nnetworks. Cartesian product networks emerge in variety of applications\nincluding in parallel and distributed systems. We provide a structural approach\nto extend the structural observability of the constituent networks (referred as\nthe factor networks) to that of the Cartesian product network. The structural\napproach is based on graph theory and is generic. We introduce certain\nstructures which are tightly related to structural observability of networks,\nnamely parent Strongly-Connected-Component (parent SCC), parent node, and\ncontractions. The results show that for particular type of networks (e.g. the\nnetworks containing contractions) the structural observability of the factor\nnetwork can be recovered via Cartesian product. In other words, if one of the\nfactor networks is structurally rank-deficient, using the other factor network\ncontaining a spanning cycle family, then the Cartesian product of the two\nnwtworks is structurally full-rank. We define certain network structures for\nstructural observability recovery. On the other hand, we derive the number of\nobserver nodes--the node whose state is measured by an output-- in the\nCartesian product network based on the number of observer nodes in the factor\nnetworks. An example illustrates the graph-theoretic analysis in the paper.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:20:03 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Doostmohammadian", "Mohammadreza", ""]]}, {"id": "2001.04779", "submitter": "Sandra Lagen", "authors": "Natale Patriciello, Sanjay Goyal, Sandra Lagen, Lorenza Giupponi,\n  Biljana Bojovic, Alpaslan Demir, Mihaela Beluri", "title": "NR-U and WiGig Coexistence in 60 GHz Bands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In December 2019, the 3GPP defined the road-map for Release-17, which\nincludes new features on the operation of New Radio (NR) in millimeter-wave\nbands with highly directional communications systems, i.e., up to 52.6 GHz. In\nthis paper, a system-level simulation based study on the coexistence of\nNR-based access to unlicensed spectrum (NR-U) and an IEEE technology, i.e.,\n802.11ad Wireless Gigabit (WiGig), at 60 GHz bands is conducted. For NR-U, an\nextension of NR Release-15 based model is used such that the 60 GHz regulatory\nrequirements are satisfied. First, the design and capabilities of the developed\nopen source ns-3 based simulator are presented and then end-to-end performance\nresults of coexistence with different channel access mechanisms for NR-U in a\n3GPP indoor scenario are discussed. It is shown that NR-U with\nListen-Before-Talk channel access mechanism does not have any adverse impact on\nWiGig performance in terms of throughput and latency, which demonstrates that\nNR-U design fulfills the fairness coexistence objective, i.e., NR-U and WiGig\ncoexistence is proven to be feasible.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:53:49 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 15:23:40 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Patriciello", "Natale", ""], ["Goyal", "Sanjay", ""], ["Lagen", "Sandra", ""], ["Giupponi", "Lorenza", ""], ["Bojovic", "Biljana", ""], ["Demir", "Alpaslan", ""], ["Beluri", "Mihaela", ""]]}, {"id": "2001.04780", "submitter": "He Chen", "authors": "He Chen, Yifan Gu, Soung-Chang Liew", "title": "Age-of-Information Dependent Random Access for Massive IoT Networks", "comments": "Accepted to appear at INFOCOM 2020 Workshop on Age of Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the most well-known application of the Internet of Things (IoT), remote\nmonitoring is now pervasive. In these monitoring applications, information\nusually has a higher value when it is fresher. A new metric, termed the age of\ninformation (AoI), has recently been proposed to quantify the information\nfreshness in various IoT applications. This paper concentrates on the design\nand analysis of age-oriented random access for massive IoT networks.\nSpecifically, we devise a new stationary threshold-based age-dependent random\naccess (ADRA) protocol, in which each IoT device accesses the channel with a\ncertain probability only when its instantaneous AoI exceeds a predetermined\nthreshold. We manage to evaluate the average AoI of the proposed ADRA protocol\nmathematically by decoupling the tangled AoI evolution of multiple IoT devices\nand modeling the decoupled AoI evolution of each device as a Discrete-Time\nMarkov Chain. Simulation results validate our theoretical analysis and affirm\nthe superior age performance of the proposed ADRA protocol over the\nstate-of-the-art age-oriented random access schemes.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:54:32 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 04:21:37 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chen", "He", ""], ["Gu", "Yifan", ""], ["Liew", "Soung-Chang", ""]]}, {"id": "2001.05009", "submitter": "Mahdi Jafari Siavoshani", "authors": "Mahdi Soltani, Mahdi Jafari Siavoshani, Amir Hossein Jahangir", "title": "A Content-Based Deep Intrusion Detection System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By growing the number of Internet users and the prevalence of web\napplications, we have to deal with very complex software and applications in\nthe network. This results in an increasing number of new vulnerabilities in the\nsystems, which consequently leads to an increase in the cyber and, in\nparticular, zero-day attacks. The cost of generating appropriate signatures for\nthese attacks is a potential motive for using machine learning-based\nmethodologies. Although there exist many studies on the use of learning-based\nmethods for attack detection, they generally use extracted features and\noverlook raw contents. This approach can lessen the performance of detection\nsystems against content-based attacks like SQL injection, Cross-site Scripting\n(XSS), and various viruses.\n  As a new paradigm, in this work, we propose a scheme, called deep intrusion\ndetection (DID) system that uses the pure content of traffic flows in addition\nto traffic metadata in the learning and detection phases. To this end, we\nemploy deep learning techniques recently developed in the machine learning\ncommunity. Due to the inherent nature of deep learning, it can process high\ndimensional data content and, accordingly, discover the sophisticated relations\nbetween the auto extracted features of the traffic. To evaluate the proposed\nDID system, we use the ISCX IDS 2017 dataset. The evaluation metrics, such as\nprecision and recall, reach $0.992$ and $0.998$, respectively, which show the\nhigh performance of the proposed DID method.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:08:57 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Soltani", "Mahdi", ""], ["Siavoshani", "Mahdi Jafari", ""], ["Jahangir", "Amir Hossein", ""]]}, {"id": "2001.05091", "submitter": "Jaafar Elmirghani", "authors": "Hatem Alharbi, Taisir E.H. Elgorashi and Jaafar M.H. Elmirghani", "title": "Energy Efficient Virtual Machines Placement over Cloud-Fog Network\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog computing is an emerging paradigm that aims to improve the efficiency and\nQoS of cloud computing by extending the cloud to the edge of the network. This\npaper develops a comprehensive energy efficiency analysis framework based on\nmathematical modeling and heuristics to study the offloading of virtual machine\n(VM) services from the cloud to the fog. The analysis addresses the impact of\ndifferent factors including the traffic between the VM and its users, the VM\nworkload, the workload versus number of users profile and the proximity of fog\nnodes to users. Overall, the power consumption can be reduced if the VM users\ntraffic is high and/or the VMs have a linear power profile. In such a linear\nprofile case, the creation of multiple VM replicas does not increase the\ncomputing power consumption significantly (there may be a slight increase due\nto idle / baseline power consumption) if the number of users remains constant,\nhowever the VM replicas can be brought closer to the end users, thus reducing\nthe transport network power consumption. In our scenario, the optimum placement\nof VMs over a cloud-fog architecture significantly decreased the total power\nconsumption by 56% and 64% under high user data rates compared to optimized\ndistributed clouds placement and placement in the existing AT&T network cloud\nlocations, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 00:48:53 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Alharbi", "Hatem", ""], ["Elgorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2001.05146", "submitter": "Christos Tsanikidis", "authors": "Christos Tsanikidis, Javad Ghaderi", "title": "On the Power of Randomization for Scheduling Real-Time Traffic in\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of scheduling real-time traffic in\nwireless networks under a conflict-graph interference model and single-hop\ntraffic. The objective is to guarantee that at least a certain fraction of\npackets of each link are delivered within their deadlines, which is referred to\nas delivery ratio. This problem has been studied before under restrictive\nframe-based traffic models, or greedy maximal scheduling schemes like LDF\n(Largest-Deficit First) that provide poor delivery ratio for general traffic\npatterns. In this paper, we pursue a different approach through randomization\nover the choice of maximal links that can transmit at each time. We design\nrandomized policies in collocated networks, multi-partite networks, and general\nnetworks, that can achieve delivery ratios much higher than what is achievable\nby LDF. Further, our results apply to traffic (arrival and deadline) processes\nthat evolve as positive recurrent Markov Chains. Hence, this work is an\nimprovement with respect to both efficiency and traffic assumptions compared to\nthe past work. We further present extensive simulation results over various\ntraffic patterns and interference graphs to illustrate the gains of our\nrandomized policies over LDF variants.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 06:28:10 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Tsanikidis", "Christos", ""], ["Ghaderi", "Javad", ""]]}, {"id": "2001.05158", "submitter": "Pargorn Puttapirat", "authors": "Pargorn Puttapirat, Haichuan Zhang, Jingyi Deng, Yuxin Dong, Jiangbo\n  Shi, Hongyu He, Zeyu Gao, Chunbao Wang, Xiangrong Zhang, Chen Li", "title": "OpenHI2 -- Open source histopathological image platform", "comments": "Preprint version accepted to AIPath2019 workshop at BIBM2019. 6\n  pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.NI eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transition from conventional to digital pathology requires a new category of\nbiomedical informatic infrastructure which could facilitate delicate\npathological routine. Pathological diagnoses are sensitive to many external\nfactors and is known to be subjective. Only systems that can meet strict\nrequirements in pathology would be able to run along pathological routines and\neventually digitized the study area, and the developed platform should comply\nwith existing pathological routines and international standards. Currently,\nthere are a number of available software tools which can perform\nhistopathological tasks including virtual slide viewing, annotating, and basic\nimage analysis, however, none of them can serve as a digital platform for\npathology. Here we describe OpenHI2, an enhanced version Open Histopathological\nImage platform which is capable of supporting all basic pathological tasks and\nfile formats; ready to be deployed in medical institutions on a standard server\nenvironment or cloud computing infrastructure. In this paper, we also describe\nthe development decisions for the platform and propose solutions to overcome\ntechnical challenges so that OpenHI2 could be used as a platform for\nhistopathological images. Further addition can be made to the platform since\neach component is modularized and fully documented. OpenHI2 is free,\nopen-source, and available at https://gitlab.com/BioAI/OpenHI.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 07:29:29 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Puttapirat", "Pargorn", ""], ["Zhang", "Haichuan", ""], ["Deng", "Jingyi", ""], ["Dong", "Yuxin", ""], ["Shi", "Jiangbo", ""], ["He", "Hongyu", ""], ["Gao", "Zeyu", ""], ["Wang", "Chunbao", ""], ["Zhang", "Xiangrong", ""], ["Li", "Chen", ""]]}, {"id": "2001.05232", "submitter": "Iacovos Ioannou I.I.", "authors": "Iacovos Ioannou, Vasos Vassiliou, Christophoros Christophorou, and\n  Andreas Pitsillides", "title": "Distributed Artificial Intelligence Solution for D2D Communication in 5G\n  Networks", "comments": "10 pages,9 figures", "journal-ref": null, "doi": "10.1109/JSYST.2020.2979044.", "report-no": null, "categories": "cs.NI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Device to Device (D2D) Communication is one of the technology components of\nthe evolving 5G architecture, as it promises improvements in energy efficiency,\nspectral efficiency, overall system capacity, and higher data rates. The above\nnoted improvements in network performance spearheaded a vast amount of research\nin D2D, which have identified significant challenges that need to be addressed\nbefore realizing their full potential in emerging 5G Networks. Towards this\nend, this paper proposes the use of a distributed intelligent approach to\ncontrol the generation of D2D networks. More precisely, the proposed approach\nuses Belief-Desire-Intention (BDI) intelligent agents with extended\ncapabilities (BDIx) to manage each D2D node independently and autonomously,\nwithout the help of the Base Station. The paper includes detailed algorithmic\ndescription for the decision of transmission mode, which maximizes the data\nrate, minimizes the power consumptions, while taking into consideration the\ncomputational load. Simulations show the applicability of BDI agents in jointly\nsolving D2D challenges.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 11:02:58 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 13:50:40 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ioannou", "Iacovos", ""], ["Vassiliou", "Vasos", ""], ["Christophorou", "Christophoros", ""], ["Pitsillides", "Andreas", ""]]}, {"id": "2001.05257", "submitter": "Carlos Borrego", "authors": "Mari Carmen de Toro and Carlos Borrego", "title": "A Software-Defined Networking approach for congestion control in\n  Opportunistic Networking", "comments": "6 pages, 2 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The short-term adoption of opportunistic networks (OppNet) depends on\nimproving the current performance of this type of network. Software-Defined\nNetworks (SDN) architecture is used by Internet applications with high resource\ndemand. SDN technology improves network performance by programmatically\nmanaging the network configuration by using a control layer. In this paper, we\npropose that OppNet nodes use a control layer to get an overview of the whole\nnetwork and use this knowledge to apply policies to get a better performance of\nthe network. As a use case for our experimentation, we have focused on\nimproving congestion control in OppNet with a control layer that dynamically\nregulates the replication degree used by forwarding algorithms. We have\ncompared the performance of our proposal with two different configurations of\nthe OppNet, over two community scenarios based on real mobility traces. The\nresults of the test prove that our SDN-like approach overruns the other two\napproaches in terms of delivery ratio and latency time performance.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:03:47 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["de Toro", "Mari Carmen", ""], ["Borrego", "Carlos", ""]]}, {"id": "2001.05276", "submitter": "Jo Inge Arnes Mr.", "authors": "Jo Inge Arnes and Randi Karlsen", "title": "Cloudless Friend-to-Friend Middleware for Smartphones", "comments": "ICETE 2018: E-Business and Telecommunications pp 199-218. Part of the\n  Communications in Computer and Information Science book series (CCIS, volume\n  1118). The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-34866-3_10", "journal-ref": "In: Obaidat M. (eds) E-Business and Telecommunications. ICETE\n  2018. Communications in Computer and Information Science, vol 1118. Springer,\n  Cham (2019)", "doi": "10.1007/978-3-030-34866-3_10", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using smartphones for peer-to-peer communication over the Internet is\ndifficult without the aid of centralized services. These centralized services,\nwhich usually reside in the cloud, are necessary for brokering communication\nbetween peers, and all communication must pass through them. A reason for this\nis that smartphones lack publicly reachable IP addresses. Also, because people\ncarry their smartphones with them, smartphones will often disconnect from one\nnetwork and connect to another. Smartphones can also go offline. Additionally,\na network of trusted peers (or friends) requires a directory of known peers,\nauthentication mechanisms, and secure communication channels. In this paper, we\npropose a peer-to-peer middleware that provides these features without the need\nfor centralized services.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:48:22 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Arnes", "Jo Inge", ""], ["Karlsen", "Randi", ""]]}, {"id": "2001.05321", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Christian Wietfeld", "title": "A Reinforcement Learning Approach for Efficient Opportunistic\n  Vehicle-to-Cloud Data Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular crowdsensing is anticipated to become a key catalyst for\ndata-driven optimization in the Intelligent Transportation System (ITS) domain.\nYet, the expected growth in massive Machine-type Communication (mMTC) caused by\nvehicle-to-cloud transmissions will confront the cellular network\ninfrastructure with great capacity-related challenges. A cognitive way for\nachieving relief without introducing additional physical infrastructure is the\napplication of opportunistic data transfer for delay-tolerant applications.\nHereby, the clients schedule their data transmissions in a channel-aware manner\nin order to avoid retransmissions and interference with other cell users. In\nthis paper, we introduce a novel approach for this type of resourceaware data\ntransfer which brings together supervised learning for network quality\nprediction with reinforcement learningbased decision making. The performance\nevaluation is carried out using data-driven network simulation and real world\nexperiments in the public cellular networks of multiple Mobile Network\nOperators (MNOs) in different scenarios. The proposed transmission scheme\nsignificantly outperforms state-of-the-art probabilistic approaches in most\nscenarios and achieves data rate improvements of up to 181% in uplink and up to\n270% in downlink transmission direction in comparison to conventional periodic\ndata transfer.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:36:36 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Wietfeld", "Christian", ""]]}, {"id": "2001.05452", "submitter": "Abishek Sankararaman", "authors": "Ronshee Chawla, Abishek Sankararaman, Ayalvadi Ganesh, Sanjay\n  Shakkottai", "title": "The Gossiping Insert-Eliminate Algorithm for Multi-Agent Bandits", "comments": "To Appear in AISTATS 2020. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a decentralized multi-agent Multi Armed Bandit (MAB) setup\nconsisting of $N$ agents, solving the same MAB instance to minimize individual\ncumulative regret. In our model, agents collaborate by exchanging messages\nthrough pairwise gossip style communications on an arbitrary connected graph.\nWe develop two novel algorithms, where each agent only plays from a subset of\nall the arms. Agents use the communication medium to recommend only arm-IDs\n(not samples), and thus update the set of arms from which they play. We\nestablish that, if agents communicate $\\Omega(\\log(T))$ times through any\nconnected pairwise gossip mechanism, then every agent's regret is a factor of\norder $N$ smaller compared to the case of no collaborations. Furthermore, we\nshow that the communication constraints only have a second order effect on the\nregret of our algorithm. We then analyze this second order term of the regret\nto derive bounds on the regret-communication tradeoffs. Finally, we empirically\nevaluate our algorithm and conclude that the insights are fundamental and not\nartifacts of our bounds. We also show a lower bound which gives that the regret\nscaling obtained by our algorithm cannot be improved even in the absence of any\ncommunication constraints. Our results thus demonstrate that even a minimal\nlevel of collaboration among agents greatly reduces regret for all agents.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 17:49:29 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 00:09:46 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 21:11:46 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chawla", "Ronshee", ""], ["Sankararaman", "Abishek", ""], ["Ganesh", "Ayalvadi", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2001.05707", "submitter": "Mohamed Abushwereb", "authors": "Mohamed Abushwereb, Muhannad Mustafa, Mouhammd Al-kasassbeh, Malik\n  Qasaimeh", "title": "Attack based DoS attack detection using multiple classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most common internet attacks causing significant economic losses\nin recent years is the Denial of Service (DoS) flooding attack. As a\ncountermeasure, intrusion detection systems equipped with machine learning\nclassification algorithms were developed to detect anomalies in network\ntraffic. These classification algorithms had varying degrees of success,\ndepending on the type of DoS attack used. In this paper, we use an SNMP-MIB\ndataset from real testbed to explore the most prominent DoS attacks and the\nchances of their detection based on the classification algorithm used. The\nresults show that most DOS attacks used nowadays can be detected with high\naccuracy using machine learning classification techniques based on features\nprovided by SNMP-MIB. We also conclude that of all the attacks we studied, the\nSlowloris attack had the highest detection rate, on the other hand TCP-SYN had\nthe lowest detection rate throughout all classification techniques, despite\nbeing one of the most used DoS attacks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 09:20:04 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Abushwereb", "Mohamed", ""], ["Mustafa", "Muhannad", ""], ["Al-kasassbeh", "Mouhammd", ""], ["Qasaimeh", "Malik", ""]]}, {"id": "2001.05713", "submitter": "Guangxu Zhu", "authors": "Guangxu Zhu, Yuqing Du, Deniz Gunduz, and Kaibin Huang", "title": "One-Bit Over-the-Air Aggregation for Communication-Efficient Federated\n  Edge Learning: Design and Convergence Analysis", "comments": "to appear in IEEE Transactions on Wireless Communications, the open\n  source codes are available at\n  https://github.com/BornHater/One-bit-over-the-air-computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated edge learning (FEEL) is a popular framework for model training at\nan edge server using data distributed at edge devices (e.g., smart-phones and\nsensors) without compromising their privacy. In the FEEL framework, edge\ndevices periodically transmit high-dimensional stochastic gradients to the edge\nserver, where these gradients are aggregated and used to update a global model.\nWhen the edge devices share the same communication medium, the multiple access\nchannel (MAC) from the devices to the edge server induces a communication\nbottleneck. To overcome this bottleneck, an efficient broadband analog\ntransmission scheme has been recently proposed, featuring the aggregation of\nanalog modulated gradients (or local models) via the waveform-superposition\nproperty of the wireless medium. However, the assumed linear analog modulation\nmakes it difficult to deploy this technique in modern wireless systems that\nexclusively use digital modulation. To address this issue, we propose in this\nwork a novel digital version of broadband over-the-air aggregation, called\none-bit broadband digital aggregation (OBDA). The new scheme features one-bit\ngradient quantization followed by digital quadrature amplitude modulation (QAM)\nat edge devices and over-the-air majority-voting based decoding at edge server.\nWe provide a comprehensive analysis of the effects of wireless channel\nhostilities (channel noise, fading, and channel estimation errors) on the\nconvergence rate of the proposed FEEL scheme. The analysis shows that the\nhostilities slow down the convergence of the learning process by introducing a\nscaling factor and a bias term into the gradient norm. However, we show that\nall the negative effects vanish as the number of participating devices grows,\nbut at a different rate for each type of channel hostility.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 09:42:04 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 15:24:32 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Zhu", "Guangxu", ""], ["Du", "Yuqing", ""], ["Gunduz", "Deniz", ""], ["Huang", "Kaibin", ""]]}, {"id": "2001.05779", "submitter": "Liesbet Van der Perre", "authors": "Liesbet Van der Perre, Erik G. Larsson, Fredrik Tufvesson, Lieven De\n  Strycker, Emil Bj\\\"ornson, Ove Edfors", "title": "RadioWeaves for efficient connectivity: analysis andimpact of\n  constraints in actual deployments", "comments": "Presented at Asilomar 2019, publication in conference proceedings\n  accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new type of wireless access infras-tructure consisting of a\nfabric of dispersed electronic circuitsand antennas that collectively function\nas a massive, distributed antenna array. We have chosen to name this new\nwireless infrastructure 'RadioWeaves' and anticipate they can be integrated\ninto indoor and outdoor walls, furniture, and otherobjects, rendering them a\nnatural part of the environment. Technologically, RadioWeaves will deploy\ndistributed arrays to create both favorable propagation and antenna array\ninteraction. The technology leverages on the ideas of large-scale intelligent\nsurfaces and cell-free wireless access. Offering close to the service\nconnectivity and computing, new grades in energy efficiency,reliability, and\nlow latency can be reached. The new concept moreover can be scaled up easily to\noffer a very high capacity inspecific areas demanding so. In this paper we\nanticipate how two different demanding use cases can be served well by a\ndedicated RadioWeaves deployment: a crowd scenario and a highly reflective\nfactory environment. A practical approach towards a RadioWeaves prototype,\nintegrating dispersed electronics invisibly in a room environment, is\nintroduced. We outline diverse R\\&D challenges that need to be addressed to\nrealize the great potential of the RadioWeaves technology.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 13:09:43 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Van der Perre", "Liesbet", ""], ["Larsson", "Erik G.", ""], ["Tufvesson", "Fredrik", ""], ["De Strycker", "Lieven", ""], ["Bj\u00f6rnson", "Emil", ""], ["Edfors", "Ove", ""]]}, {"id": "2001.05939", "submitter": "Mohammed Salman", "authors": "Mohammed Salman, Bin Wang", "title": "A New Software Framework for Traffic Engineering: Path Cardinality and\n  the Effect of Multipath on Residual Capacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new traffic engineering (TE) software framework\nto analyze, configure, and optimize (with the aid of a linear programming\nsolver) a network for service provisioning. The developed software tool is\nbased on our new data-driven traffic engineering approach that analyzes a large\nvolume of network configuration data generated given the user input. By\nanalyzing the data, one can then make efficient decisions later when designing\na traffic engineering solution. We focus on three well-known traffic\nengineering objective functions: minimum cost routing (MCR), load balancing\n(LB), and average delay (AD). With this new tool, one can answer numerous\ntraffic engineering questions. For example, what are the differences among the\nthree objective functions? What is the impact of an objective function on link\nutilization? How many candidate paths are enough to achieve optimality or\nnear-optimality with respect to a specific objective. This new software tool\nallows us to conveniently perform various experiments and visualize the results\nfor performance analysis. As case studies, this paper presents examples that\nanswer the questions for two traffic engineering problems: (1) how many paths\nare required to obtain a solution that is within a few percent from the optimal\nsolution and whether that number is fixed for any network size? (2) how the\nchoice of single-path/multi-path routing affects the load in the network? For\nthe first problem, it turns out that the number of paths needed to achieve\noptimality increases as the number of links in the network increases.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 17:03:51 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Salman", "Mohammed", ""], ["Wang", "Bin", ""]]}, {"id": "2001.06056", "submitter": "Karol Rydzewski", "authors": "Jerzy Konorski and Karol Rydzewski", "title": "Nodal cooperation equilibrium analysis in multihop wireless ad hoc\n  networks with a reputation system", "comments": "presented at International Conference on Mathematical Methods,\n  Models, and Architectures for Computer Network Security; 12 pages; 2 figures;\n  keywords: wireless environment, multihop network, utility, cost,\n  reputation,cooperation, strategy, security", "journal-ref": "MMM-ACNS 2017. Lecture Notes in Computer Science, vol 10446.\n  Springer", "doi": "10.1007/978-3-319-65127-9_11", "report-no": null, "categories": "cs.NI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the concerns of cooperation security, this work examines\nselected principles of state-of-the-art reputation systems for multihop adhoc\nnetworks and their impact upon optimal strategies for rational nodes. An\nanalytic framework is proposed and used for identification of effective\ncooperation-enforcement schemes. It is pointed out that an optimum rather than\nhigh reputation can be expected to be sought by rational nodes.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:08:15 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Konorski", "Jerzy", ""], ["Rydzewski", "Karol", ""]]}, {"id": "2001.06182", "submitter": "Pier Luigi Ventre", "authors": "Ahmed Abdelsalam, Pier Luigi Ventre, Carmine Scarpitta, Andrea Mayer,\n  Stefano Salsano, Pablo Camarillo, Francois Clad, Clarence Filsfils", "title": "SRPerf: a Performance Evaluation Framework for IPv6 Segment Routing", "comments": "Submitted paper under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segment Routing is a form of loose source routing. It provides the ability to\ninclude a list of instructions (called segments), in the packet headers. The\nSegment Routing architecture has been first implemented with the MPLS dataplane\nand then, quite recently, with the IPv6 dataplane (SRv6). IPv6 Segment Routing\n(SRv6) is a promising solution to support advanced services such as Traffic\nEngineering, Service Function Chaining, Virtual Private Networks, and Load\nBalancing. The SRv6 data-plane is supported in many different software\nforwarding engines including the Linux kernel and VPP software router, as well\nas in hardware devices. In this paper, we present SRPerf, a performance\nevaluation framework for software and hardware implementations of SRv6. SRPerf\nis able to perform different benchmarking tests such as throughput and latency.\nFor throughput tests, we use the Partial Drop Rate (PDR) to characterize a\nsystem under test. The architecture of SRPerf can be easily extended to support\nnew benchmarking methodologies as well as different SRv6 implementations. We\nhave used SRPerf to evaluate the performance of the SRv6 implementation in the\nLinux kernel and in VPP. SRPerf is a valuable tool in the context of software\nforwarding engines where new features can be added at fast pace, as it helps\nexperimenters to validate their work. In particular, we describe how we have\nleveraged SRPerf to validate the implementation of some SRv6 behaviors that\nwere missing or wrongly implemented in the Linux kernel mainline.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 08:02:31 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 15:01:38 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Abdelsalam", "Ahmed", ""], ["Ventre", "Pier Luigi", ""], ["Scarpitta", "Carmine", ""], ["Mayer", "Andrea", ""], ["Salsano", "Stefano", ""], ["Camarillo", "Pablo", ""], ["Clad", "Francois", ""], ["Filsfils", "Clarence", ""]]}, {"id": "2001.06288", "submitter": "Abdallah Moubayed", "authors": "Abdallah Moubayed, Abdallah Shami, Parisa Heidari, Adel Larabi,\n  Richard Brunner", "title": "Edge-enabled V2X Service Placement for Intelligent Transportation\n  Systems", "comments": "13 pages, 16 figures (including 5 bio pictures), accepted and to be\n  published in IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": "10.1109/TMC.2020.2965929", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle-to-everything (V2X) communication and services have been garnering\nsignificant interest from different stakeholders as part of future intelligent\ntransportation systems (ITSs). This is due to the many benefits they offer.\nHowever, many of these services have stringent performance requirements,\nparticularly in terms of the delay/latency. Multi-access/mobile edge computing\n(MEC) has been proposed as a potential solution for such services by bringing\nthem closer to vehicles. Yet, this introduces a new set of challenges such as\nwhere to place these V2X services, especially given the limit computation\nresources available at edge nodes. To that end, this work formulates the\nproblem of optimal V2X service placement (OVSP) in a hybrid core/edge\nenvironment as a binary integer linear programming problem. To the best of our\nknowledge, no previous work considered the V2X service placement problem while\ntaking into consideration the computational resource availability at the nodes.\nMoreover, a low-complexity greedy-based heuristic algorithm named \"Greedy V2X\nService Placement Algorithm\" (G-VSPA) was developed to solve this problem.\nSimulation results show that the OVSP model successfully guarantees and\nmaintains the QoS requirements of all the different V2X services. Additionally,\nit is observed that the proposed G-VSPA algorithm achieves close to optimal\nperformance while having lower complexity.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:21:20 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Moubayed", "Abdallah", ""], ["Shami", "Abdallah", ""], ["Heidari", "Parisa", ""], ["Larabi", "Adel", ""], ["Brunner", "Richard", ""]]}, {"id": "2001.06309", "submitter": "Antoine Delplace", "authors": "Antoine Delplace, Sheryl Hermoso and Kristofer Anandita", "title": "Cyber Attack Detection thanks to Machine Learning Algorithms", "comments": "46 pages, 38 figures, project report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity attacks are growing both in frequency and sophistication over\nthe years. This increasing sophistication and complexity call for more\nadvancement and continuous innovation in defensive strategies. Traditional\nmethods of intrusion detection and deep packet inspection, while still largely\nused and recommended, are no longer sufficient to meet the demands of growing\nsecurity threats. As computing power increases and cost drops, Machine Learning\nis seen as an alternative method or an additional mechanism to defend against\nmalwares, botnets, and other attacks. This paper explores Machine Learning as a\nviable solution by examining its capabilities to classify malicious traffic in\na network.\n  First, a strong data analysis is performed resulting in 22 extracted features\nfrom the initial Netflow datasets. All these features are then compared with\none another through a feature selection process. Then, our approach analyzes\nfive different machine learning algorithms against NetFlow dataset containing\ncommon botnets. The Random Forest Classifier succeeds in detecting more than\n95% of the botnets in 8 out of 13 scenarios and more than 55% in the most\ndifficult datasets. Finally, insight is given to improve and generalize the\nresults, especially through a bootstrapping technique.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 13:52:12 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Delplace", "Antoine", ""], ["Hermoso", "Sheryl", ""], ["Anandita", "Kristofer", ""]]}, {"id": "2001.06328", "submitter": "Jaafar Elmirghani", "authors": "Hatem A. Alharbi, Taisir E.H. Elgorashi and Jaafar M.H. Elmirghani", "title": "Energy Efficient Cloud-Fog Architecture", "comments": "arXiv admin note: text overlap with arXiv:2001.05091", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancements of cloud computing came as a radical transformation in the\nway Information and Communication Technology (ICT) services are deployed and\nmaintained. Cloud computing provides ubiquitous on-demand access to an\nInternet-based pool of processing, storage, and communication resources offered\nto a large set of geographically distributed users. As the cloud computing\ninfrastructure grows and demand increases, the need for a new breed of\non-demand computing that can efficiently maintain Quality of Service (QoS)\nrequirements has increased. Fog computing was proposed to address the\nlimitations of cloud computing, in terms of delay and high bandwidth\nrequirements, by extending the on-demand resources of clouds to the edge of the\nnetwork bringing them closer to the users. The massive growth and wide use of\ncloud-fog services have created serious power consumption concerns. This\narticle delves into the energy consumption of cloud-fog services by raising\nheadline questions related to; how significant the problem itself is, how\ndifferent conditions/scenarios affect the energy consumption of the\narchitecture, and how to orchestrate the use of the architecture in an\nenergy-efficient manner. We start by summarizing the cloud-fog architecture\nincluding different communication and computing layers. Additionally, we give a\nbrief overview of the role of Virtual Machine (VM) placement in optimally using\ncloud-fog resources in a dynamic manner. Then, we present the problem of energy\nefficient VMs placement and provide numerical results.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 00:54:08 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Alharbi", "Hatem A.", ""], ["Elgorashi", "Taisir E. H.", ""], ["Elmirghani", "Jaafar M. H.", ""]]}, {"id": "2001.06351", "submitter": "George Iosifidis Dr", "authors": "Georgios Paschos, Apostolos Destounis, and George Iosifidis", "title": "Online Convex Optimization for Caching Networks", "comments": "To appear in IEEE/ACM Transactions on Networking. arXiv admin note:\n  substantial text overlap with arXiv:1912.12339", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of wireless edge caching when file popularity is unknown\nand possibly non-stationary. A bank of $J$ caches receives file requests and a\nutility is accrued for each request depending on the serving cache. The network\ndecides dynamically which files to store at each cache and how to route them,\nin order to maximize total utility. The request sequence is assumed to be drawn\nfrom an arbitrary distribution, thus capturing time-variance, temporal, or\nspatial locality of requests. For this challenging setting, we propose the\n\\emph{Bipartite Supergradient Caching Algorithm} (BSCA) which provably exhibits\nno regret ($R_T/T \\to 0$). That is, as the time horizon $T$ increases, BSCA\nachieves the same performance with the cache configuration that we would have\nchosen knowing all future requests. The learning rate of the algorithm is\ncharacterized by its regret expression, found to be $R_T=O(\\sqrt{JT})$, which\nis independent of the content catalog size. For the single-cache case, we prove\nthat this is the lowest attainable bound. BSCA requires at each step $J$\nprojections on intersections of boxes and simplices, for which we propose a\ntailored algorithm. Our model is the first that draws a connection between the\nnetwork caching problem and Online Convex Optimization, and we demonstrate its\ngenerality by discussing various practical extensions and presenting a\ntrace-driven comparison with state-of-the-art competitors.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 13:09:45 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Paschos", "Georgios", ""], ["Destounis", "Apostolos", ""], ["Iosifidis", "George", ""]]}, {"id": "2001.06420", "submitter": "Enrico Cambiaso", "authors": "Maurizio Aiello, Enrico Cambiaso, Roberto Canonico, Leonardo Maccari,\n  Marco Mellia, Antonio Pescap\\`e, Ivan Vaccari", "title": "IPPO: A Privacy-Aware Architecture for Decentralized Data-sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online trackers personalize ads campaigns, exponentially increasing their\nefficacy compared to traditional channels. The downside of this is that\nthousands of mostly unknown systems own our profiles and violate our privacy\nwithout our awareness. IPPO turns the table and re-empower users of their data,\nthrough anonymised data publishing via a Blockchain-based Decentralized Data\nMarketplace. We also propose a service based on machine learning and big data\nanalytics to automatically identify web trackers and build Privacy Labels\n(PLs), based on the nutrition labels concept. This paper describes the\nmotivation, the vision, the architecture and the research challenges related to\nIPPO.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 16:34:31 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Aiello", "Maurizio", ""], ["Cambiaso", "Enrico", ""], ["Canonico", "Roberto", ""], ["Maccari", "Leonardo", ""], ["Mellia", "Marco", ""], ["Pescap\u00e8", "Antonio", ""], ["Vaccari", "Ivan", ""]]}, {"id": "2001.06443", "submitter": "Hongyu Jin", "authors": "Hongyu Jin and Panos Papadimitratos", "title": "Scaling VANET Security Through Cooperative Message Verification", "comments": "2015 IEEE Vehicular Networking Conference (VNC), Kyoto, 2015", "journal-ref": null, "doi": "10.1109/VNC.2015.7385588", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  VANET security introduces significant processing overhead for\nresource-constrained On-Board Units (OBUs). Here, we propose a novel scheme\nthat allows secure Vehicular Communication (VC) systems to scale well beyond\nnetwork densities for which existing optimization approaches could be workable,\nwithout compromising security (and privacy).\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 17:36:03 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Jin", "Hongyu", ""], ["Papadimitratos", "Panos", ""]]}, {"id": "2001.06610", "submitter": "Sohini Roy", "authors": "Sohini Roy, Harish Chandrasekaran, Anamitra Pal, Arunabha Sen", "title": "A New Model to Analyze Power and Communication System Intra-and-Inter\n  Dependencies", "comments": "8 pages. Accepted for publication in SusTech 2020 : 2020 IEEE\n  Conference on Technologies for Sustainability", "journal-ref": null, "doi": "10.1109/SusTech47890.2020.9150529", "report-no": null, "categories": "cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliable and resilient operation of the smart grid necessitates a clear\nunderstanding of the intra-and-inter dependencies of its power and\ncommunication systems. This understanding can only be achieved by accurately\ndepicting the interactions between the different components of these two\nsystems. This paper presents a model, called modified implicative\ninterdependency model (MIIM), for capturing these interactions. Data obtained\nfrom a power utility in the U.S. Southwest is used to ensure the validity of\nthe model. The performance of the model for a specific power system application\nnamely, state estimation, is demonstrated using the IEEE 118-bus system. The\nresults indicate that the proposed model is more accurate than its predecessor,\nthe implicative interdependency model (IIM) [1], in predicting the system state\nin case of failures in the power and/or communication systems.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 06:14:40 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Roy", "Sohini", ""], ["Chandrasekaran", "Harish", ""], ["Pal", "Anamitra", ""], ["Sen", "Arunabha", ""]]}, {"id": "2001.06901", "submitter": "Mounir Bensalem", "authors": "Mounir Bensalem, Jasenka Dizdarevi\\'c and Admela Jukan", "title": "Modeling of Deep Neural Network (DNN) Placement and Inference in Edge\n  Computing", "comments": null, "journal-ref": "IEEE ICC 2020 Workshop - Edge Machine Learning for 5G Mobile\n  Networks and Beyond, Dublin, Ireland, 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the edge computing becoming an increasingly adopted concept in system\narchitectures, it is expected its utilization will be additionally heightened\nwhen combined with deep learning (DL) techniques. The idea behind integrating\ndemanding processing algorithms in Internet of Things (IoT) and edge devices,\nsuch as Deep Neural Network (DNN), has in large measure benefited from the\ndevelopment of edge computing hardware, as well as from adapting the algorithms\nfor use in resource constrained IoT devices. Surprisingly, there are no models\nyet to optimally place and use machine learning in edge computing. In this\npaper, we propose the first model of optimal placement of Deep Neural Network\n(DNN) Placement and Inference in edge computing. We present a mathematical\nformulation to the DNN Model Variant Selection and Placement (MVSP) problem\nconsidering the inference latency of different model-variants, communication\nlatency between nodes, and utilization cost of edge computing nodes. We\nevaluate our model numerically, and show that for low load increasing model\nco-location decreases the average latency by 33% of millisecond-scale per\nrequest, and for high load, by 21%.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 20:51:37 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Bensalem", "Mounir", ""], ["Dizdarevi\u0107", "Jasenka", ""], ["Jukan", "Admela", ""]]}, {"id": "2001.07031", "submitter": "Anubhab Banerjee", "authors": "Anubhab Banerjee, Stephen S. Mwanje, and Georg Carle", "title": "On the Necessity and Design of Coordination Mechanism for Cognitive\n  Autonomous Networks", "comments": "submitted to AnNet 2020 (https://annet2020.loria.fr/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive Autonomous Networks (CAN) are promoted to advance Self Organizing\nNetwork (SON), replacing rule-based SON Functions (SFs) with Cognitive\nFunctions (CFs), which learn optimal behavior by interacting with the network.\nAs in SON, CFs do encounter conflicts due to overlap in parameters or\nobjectives. However, owing to the non-deterministic behavior of CFs, these\nconflicts cannot be resolved using rulebased methods and new solutions are\nrequired. This paper investigates the CF deployments with and without a\ncoordination mechanism, and proves both heuristically and mathematically that a\ncoordination mechanism is required. Using a two-CF Multi-Agent-System model\nwith the possible types of conflicts, we show that the challenge is a typical\nbargaining problem, for which the optimal response is the Nash bargaining\nSolution (NBS). We use NBS to propose a coordination mechanism design that is\ncapable of resolving the conflicts and show via simulations how implementation\nof the proposed solution is feasible in real life scenario.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 09:31:17 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Banerjee", "Anubhab", ""], ["Mwanje", "Stephen S.", ""], ["Carle", "Georg", ""]]}, {"id": "2001.07170", "submitter": "Tobias Meuser", "authors": "Tobias Meuser, Oluwasegun Taiwo Ojo, Daniel Bischoff, Antonio\n  Fern\\'andez Anta, Ioannis Stavrakakis, Ralf Steinmetz", "title": "Hide Me: Enabling Location Privacy in Heterogeneous Vehicular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To support location-based services, vehicles must share their location with a\nserver to receive relevant data, compromising their (location) privacy. To\nalleviate this privacy compromise, the vehicle's location can be obfuscated by\nadding artificial noise. Under limited available bandwidth, and since the area\nincluding the vehicle's location increases with the noise, the server will\nprovide fewer data relevant to the vehicle's true location, reducing the\neffectiveness of a location-based service. To alleviate this problem, we\npropose that data relevant to a vehicle is also provided through direct, ad hoc\ncommunication by neighboring vehicles. Through such Vehicle-to-Vehicle (V2V)\ncooperation, the impact of location obfuscation is mitigated. Since vehicles\nsubscribe to data of (location-dependent) impact values, neighboring vehicles\nwill subscribe to largely overlapping sets of data, reducing the benefit of V2V\ncooperation. To increase such benefit, we develop and study a non-cooperative\ngame determining the data that a vehicle should subscribe to, aiming at\nmaximizing its utilization while considering the participating (neighboring)\nvehicles. Our analysis and results show that the proposed V2V cooperation and\nderived strategy lead to significant performance increase compared to\nnon-cooperative approaches and largely alleviates the impact of privacy on\nlocation-based services.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 16:57:34 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Meuser", "Tobias", ""], ["Ojo", "Oluwasegun Taiwo", ""], ["Bischoff", "Daniel", ""], ["Anta", "Antonio Fern\u00e1ndez", ""], ["Stavrakakis", "Ioannis", ""], ["Steinmetz", "Ralf", ""]]}, {"id": "2001.07238", "submitter": "Muhammad Bilal", "authors": "Ajmal Khan, Adnan Munir, Zeeshan Kaleem, Farman Ullah, Muhammad Bilal,\n  Lewis Nkenyereye, Shahen Shah, Long D. Nguyen, S. M. Riazul Islam and\n  Kyung-Sup Kwak", "title": "RDSP: Rapidly Deployable Wireless Ad Hoc System for Post-Disaster\n  Management", "comments": "23 pages, 12 figures, accepted for publication in Sensors 2020", "journal-ref": null, "doi": "10.3390/s20020548", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In post-disaster scenarios, such as after floods, earthquakes, and in war\nzones, the cellular communication infrastructure may be destroyed or seriously\ndisrupted. In such emergency scenarios, it becomes very important for first aid\nresponders to communicate with other rescue teams in order to provide feedback\nto both the central office and the disaster survivors. To address this issue,\nrapidly deployable systems are required to re-establish connectivity and assist\nusers and first responders in the region of incident. In this work, we describe\nthe design, implementation, and evaluation of a rapidly deployable system for\nfirst response applications in post-disaster situations, named RDSP. The\nproposed system helps early rescue responders and victims by sharing their\nlocation information to remotely located servers by utilizing a novel routing\nscheme. This novel routing scheme consists of the Dynamic ID Assignment (DIA)\nalgorithm and the Minimum Maximum Neighbor (MMN) algorithm. The DIA algorithm\nis used by relay devices to dynamically select their IDs on the basis of all\nthe available IDs of networks. Whereas, the MMN algorithm is used by the client\nand relay devices to dynamically select their next neighbor relays for the\ntransmission of messages. The RDSP contains three devices; the client device\nsends the victim's location information to the server, the relay device relays\ninformation between client and server device, the server device receives\nmessages from the client device to alert the rescue team. We deployed and\nevaluated our system in the outdoor environment of the university campus. The\nexperimental results show that the RDSP system reduces the message delivery\ndelay and improves the message delivery ratio with lower communication\noverhead.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 20:22:37 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Khan", "Ajmal", ""], ["Munir", "Adnan", ""], ["Kaleem", "Zeeshan", ""], ["Ullah", "Farman", ""], ["Bilal", "Muhammad", ""], ["Nkenyereye", "Lewis", ""], ["Shah", "Shahen", ""], ["Nguyen", "Long D.", ""], ["Islam", "S. M. Riazul", ""], ["Kwak", "Kyung-Sup", ""]]}, {"id": "2001.07266", "submitter": "Petros Spachos", "authors": "Andrew Mackey, Petros Spachos, Konstantinos N. Plataniotis", "title": "Smart Parking System Based on Bluetooth Low Energy Beacons with Particle\n  Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban centers and dense populations are expanding, hence, there is a growing\ndemand for novel applications to aid in planning and optimization. In this\nwork, a smart parking system that operates both indoor and outdoor is\nintroduced. The system is based on Bluetooth Low Energy (BLE) beacons and uses\nparticle filtering to improve its accuracy. Through simple BLE connectivity\nwith smartphones, an intuitive parking system is designed and deployed. The\nproposed system pairs each spot with a unique BLE beacon, providing users with\nguidance to free parking spaces and a secure and automated payment scheme based\non real-time usage of the parking space. Three sets of experiments were\nconducted to examine different aspects of the system. A particle filter is\nimplemented in order to increase the system performance and improve the\ncredence of the results. Through extensive experimentation in both indoor and\noutdoor parking spaces, the system was able to correctly predict which spot the\nuser has parked in, as well as estimate the distance of the user from the\nbeacon.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 22:13:21 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mackey", "Andrew", ""], ["Spachos", "Petros", ""], ["Plataniotis", "Konstantinos N.", ""]]}, {"id": "2001.07334", "submitter": "Lalhruaizela Chhangte", "authors": "Lalhruaizela Chhangte, Emanuele Viterbo, D Manjunath, and Nikhil\n  Karamchandani", "title": "Online Caching and Coding at the WiFi Edge: Gains and Tradeoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video content delivery at the wireless edge continues to be challenged by\ninsufficient bandwidth and highly dynamic user behavior which affects both\neffective throughput and latency. Caching at the network edge and coded\ntransmissions have been found to improve user performance of video content\ndelivery. The cache at the wireless edge stations (BSs, APs) and at the users'\nend devices can be populated by pre-caching content or by using online caching\npolicies. In this paper, we propose a system where content is cached at the\nuser of a WiFi network via online caching policies, and coded delivery is\nemployed by the WiFi AP to deliver the requested content to the user\npopulation. The content of the cache at the user serves as side information for\nindex coding. We also propose the LFU-Index cache replacement policy at the\nuser that demonstrably improves index coding opportunities at the WiFi AP for\nthe proposed system. Through an extensive simulation study, we determine the\ngains achieved by caching and index by coding. Next, we analyze the tradeoffs\nbetween them in terms of data transmitted, latency, and throughput for\ndifferent content request behaviors from the users. We also show that the\nproposed cache replacement policy performs better than traditional cache\nreplacement policies like LRU and LFU.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 04:09:53 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chhangte", "Lalhruaizela", ""], ["Viterbo", "Emanuele", ""], ["Manjunath", "D", ""], ["Karamchandani", "Nikhil", ""]]}, {"id": "2001.07644", "submitter": "Xiaoran Fan", "authors": "Xiaoran Fan, Longfei Shangguan, Richard Howard, Yanyong Zhang, Yao\n  Peng, Jie Xiong, Yunfei Ma, Xiang-Yang Li", "title": "Towards Flexible Wireless Charging for Medical Implants Using\n  Distributed Antenna System", "comments": "In MobiCom 2020: The 26th Annual International Conference on Mobile\n  Computing and Networking, London, 15 pages", "journal-ref": null, "doi": "10.1145/3372224.3380899", "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the design, implementation and evaluation of In-N-Out, a\nsoftware-hardware solution for far-field wireless power transfer. In-N-Out can\ncontinuously charge a medical implant residing in deep tissues at near-optimal\nbeamforming power, even when the implant moves around inside the human body. To\naccomplish this, we exploit the unique energy ball pattern of distributed\nantenna array and devise a backscatter-assisted beamforming algorithm that can\nconcentrate RF energy on a tiny spot surrounding the medical implant.\nMeanwhile, the power levels on other body parts stay in low level, reducing the\nrisk of overheating. We prototype In-N-Out on 21 software-defined radios and a\nprinted circuit board (PCB). Extensive experiments demonstrate that In-N-Out\nachieves 0.37~mW average charging power inside a 10~cm-thick pork belly, which\nis sufficient to wirelessly power a range of commercial medical devices. Our\nhead-to-head comparison with the state-of-the-art approach shows that In-N-Out\nachieves 5.4$\\times$--18.1$\\times$ power gain when the implant is stationary,\nand 5.3$\\times$--7.4$\\times$ power gain when the implant is in motion.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:47:14 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 01:40:10 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Fan", "Xiaoran", ""], ["Shangguan", "Longfei", ""], ["Howard", "Richard", ""], ["Zhang", "Yanyong", ""], ["Peng", "Yao", ""], ["Xiong", "Jie", ""], ["Ma", "Yunfei", ""], ["Li", "Xiang-Yang", ""]]}, {"id": "2001.07670", "submitter": "Paolo Giaccone", "authors": "German Sviridov, Marco Bonola, Angelo Tulumello, Paolo Giaccone,\n  Andrea Bianco, and Giuseppe Bianchi", "title": "LOcAl DEcisions on Replicated States (LOADER) in programmable data\n  planes: programming abstraction and experimental evaluation", "comments": null, "journal-ref": "Computer Networks (Elsevier), 2020", "doi": "10.1016/j.comnet.2020.107637", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programmable data planes recently emerged as a prominent innovation in\nSoftware Defined Networking (SDN), by permitting support of stateful flow\nprocessing functions over hardware network switches specifically designed for\nnetwork processing. Unlike early SDN solutions such as OpenFlow, modern\nstateful data planes permit to keep (and dynamically update) local per-flow\nstates inside network switches, thus dramatically improving reactiveness of\nnetwork applications to state changes. Still, also in stateful data planes, the\ncontrol and update of non-local states is assumed to be completely delegated to\na centralized controller and thus accessed only at the price of extra delay.\n  Our LOADER proposal aims at contrasting the apparent dichotomy between local\nstates and global states. We do so by introducing a new possibility: permit to\ntake localized (in-switch) decisions not only on local states but also on\nreplicated global states, thus providing support for network-wide applications\nwithout incurring the drawbacks of classical approaches. To this purpose, i) we\nprovide high-level programming abstractions devised to define the states and\nthe update logic of a generic network-wide application, and ii) we detail the\nunderlying low level state management and replication mechanisms. We then show\nLOADER's independence of the stateful data plane technology employed, by\nimplementing it over two distinct stateful data planes (P4 switches and OPP -\nOpen Packet Processor - switches), and by experimentally validating both\nimplementations in an emulated testbed using a simple distributed\nDeny-of-Service (DoS) detection application.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 17:48:14 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 08:55:18 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 15:27:00 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Sviridov", "German", ""], ["Bonola", "Marco", ""], ["Tulumello", "Angelo", ""], ["Giaccone", "Paolo", ""], ["Bianco", "Andrea", ""], ["Bianchi", "Giuseppe", ""]]}, {"id": "2001.07686", "submitter": "Petros Spachos", "authors": "Petros Spachos, Konstantinos N. Plataniotis", "title": "BLE Beacons for Indoor Positioning at an Interactive IoT-Based Smart\n  Museum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) can enable smart infrastructures to provide\nadvanced services to the users. New technological advancement can improve our\neveryday life, even simple tasks as a visit to the museum. In this paper, an\nindoor localization system is presented, to enhance the user experience in a\nmuseum. In particular, the proposed system relies on Bluetooth Low Energy (BLE)\nbeacons proximity and localization capabilities to automatically provide the\nusers with cultural contents related to the observed artworks. At the same\ntime, an RSS-based technique is used to estimate the location of the visitor in\nthe museum. An Android application is developed to estimate the distance from\nthe exhibits and collect useful analytics regarding each visit and provide a\nrecommendation to the users. Moreover, the application implements a simple\nKalman filter in the smartphone, without the need of the Cloud, to improve\nlocalization precision and accuracy. Experimental results on distance\nestimation, location, and detection accuracy show that BLE beacon is a\npromising solution for an interactive smart museum. The proposed system has\nbeen designed to be easily extensible to the IoT technologies and its\neffectiveness has been evaluated through experimentation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 18:33:41 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Spachos", "Petros", ""], ["Plataniotis", "Konstantinos N.", ""]]}, {"id": "2001.07698", "submitter": "Bernardo Huberman", "authors": "Qi Zhou, Jingjie Zhu, Junwen Zhang, Zhensheng Jia, Bernardo Huberman\n  and Gee-Kung Chang", "title": "Intelligent Bandwidth Allocation for Latency Management in NG-EPON using\n  Reinforcement Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel intelligent bandwidth allocation scheme in NG-EPON using\nreinforcement learning is proposed and demonstrated for latency management. We\nverify the capability of the proposed scheme under both fixed and dynamic\ntraffic loads scenarios to achieve <1ms average latency. The RL agent\ndemonstrates an efficient intelligent mechanism to manage the latency, which\nprovides a promising IBA solution for the next-generation access network.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 18:58:56 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhou", "Qi", ""], ["Zhu", "Jingjie", ""], ["Zhang", "Junwen", ""], ["Jia", "Zhensheng", ""], ["Huberman", "Bernardo", ""], ["Chang", "Gee-Kung", ""]]}, {"id": "2001.07784", "submitter": "Michael Dinitz", "authors": "Michael Dinitz and Benjamin Moseley", "title": "Scheduling for Weighted Flow and Completion Times in Reconfigurable\n  Networks", "comments": "10 pages. Appears in INFOCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New optical technologies offer the ability to reconfigure network topologies\ndynamically, rather than setting them once and for all. This is true in both\noptical wide area networks (optical WANs) and in datacenters, despite the many\ndifferences between these two settings. Because of these new technologies,\nthere has been a surge of both practical and theoretical research on algorithms\nto take advantage of them. In particular, Jia et al. [INFOCOM '17] designed\nonline scheduling algorithms for dynamically reconfigurable topologies for both\nthe makespan and sum of completion times objectives. In this paper, we work in\nthe same setting but study an objective that is more meaningful in an online\nsetting: the sum of flow times. The flow time of a job is the total amount of\ntime that it spends in the system, which may be considerably smaller than its\ncompletion time if it is released late. We provide competitive algorithms for\nthe online setting with speed augmentation, and also give a lower bound proving\nthat speed augmentation is in fact necessary. As a side effect of our\ntechniques, we also improve and generalize the results of Jia et al. on\ncompletion times by giving an $O(1)$-competitive algorithm for arbitrary sizes\nand release times even when nodes have different degree bounds, and moreover\nallow for the weighted sum of completion times (or flow times).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 21:31:54 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Dinitz", "Michael", ""], ["Moseley", "Benjamin", ""]]}, {"id": "2001.07787", "submitter": "Dimitrios Michael Manias", "authors": "Dimitrios Michael Manias, Manar Jammal, Hassan Hawilo, Abdallah Shami,\n  Parisa Heidari, Adel Larabi, Richard Brunner", "title": "Machine Learning for Performance-Aware Virtual Network Function\n  Placement", "comments": "6 pages, 6 figures, 1 table, 9 equations, 18 references, Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing demand for data connectivity, network service providers are\nfaced with the task of reducing their capital and operational expenses while\nsimultaneously improving network performance and addressing the increased\nconnectivity demand. Although Network Function Virtualization (NFV) has been\nidentified as a solution, several challenges must be addressed to ensure its\nfeasibility. In this paper, we address the Virtual Network Function (VNF)\nplacement problem by developing a machine learning decision tree model that\nlearns from the effective placement of the various VNF instances forming a\nService Function Chain (SFC). The model takes several performance-related\nfeatures from the network as an input and selects the placement of the various\nVNF instances on network servers with the objective of minimizing the delay\nbetween dependent VNF instances. The benefits of using machine learning are\nrealized by moving away from a complex mathematical modelling of the system and\ntowards a data-based understanding of the system. Using the Evolved Packet Core\n(EPC) as a use case, we evaluate our model on different data center networks\nand compare it to the BACON algorithm in terms of the delay between\ninterconnected components and the total delay across the SFC. Furthermore, a\ntime complexity analysis is performed to show the effectiveness of the model in\nNFV applications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:08:39 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Manias", "Dimitrios Michael", ""], ["Jammal", "Manar", ""], ["Hawilo", "Hassan", ""], ["Shami", "Abdallah", ""], ["Heidari", "Parisa", ""], ["Larabi", "Adel", ""], ["Brunner", "Richard", ""]]}, {"id": "2001.07817", "submitter": "Maria Apostolaki", "authors": "Maria Apostolaki, Ankit Singla, Laurent Vanbever", "title": "Performance-Driven Internet Path Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet routing can often be sub-optimal, with the chosen routes providing\nworse performance than other available policy-compliant routes. This stems from\nthe lack of visibility into route performance at the network layer. While this\nis an old problem, we argue that recent advances in programmable hardware\nfinally open up the possibility of performance-aware routing in a deployable,\nBGP-compatible manner. We introduce ROUTESCOUT, a hybrid hardware/software\nsystem supporting performance-based routing at ISP scale. In the data plane,\nROUTESCOUT leverages P4-enabled hardware to monitor performance across\npolicy-compliant route choices for each destination, at line-rate and with a\nsmall memory footprint. ROUTESCOUT's control plane then asynchronously pulls\naggregated performance metrics to synthesize a performance-aware forwarding\npolicy. We show that ROUTESCOUT can monitor performance across most of an ISP's\ntraffic, using only 4 MB of memory. Further, its control can flexibly satisfy a\nvariety of operator objectives, with sub-second operating times.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 23:51:17 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 21:34:35 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Apostolaki", "Maria", ""], ["Singla", "Ankit", ""], ["Vanbever", "Laurent", ""]]}, {"id": "2001.07828", "submitter": "Ahmed Badawy", "authors": "Ahmed Badawy, Ahmed El Shafie and Tamer Khattab", "title": "On the Performance of Quickest Detection Spectrum Sensing: The Case of\n  Cumulative Sum", "comments": "This paper is accepted for publication in IEEE Communication Letters\n  Jan 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quickest change detection (QCD) is a fundamental problem in many\napplications. Given a sequence of measurements that exhibits two different\ndistributions around a certain flipping point, the goal is to detect the change\nin distribution around the flipping point as quickly as possible. The QCD\nproblem appears in many practical applications, e.g., quality control, power\nsystem line outage detection, spectrum reuse, and resource allocation and\nscheduling. In this paper, we focus on spectrum sensing as our application\nsince it is a critical process for proper functionality of cognitive radio\nnetworks. Relying on the cumulative sum (CUSUM), we derive the probability of\ndetection and the probability of false alarm of CUSUM based spectrum sensing.\nWe show the correctness of our derivations using numerical simulations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 00:31:41 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Badawy", "Ahmed", ""], ["Shafie", "Ahmed El", ""], ["Khattab", "Tamer", ""]]}, {"id": "2001.07845", "submitter": "Mingzhe Chen", "authors": "Mingzhe Chen, H. Vincent Poor, Walid Saad, and Shuguang Cui", "title": "Convergence Time Optimization for Federated Learning over Wireless\n  Networks", "comments": "This paper has been accepted in the IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the convergence time of federated learning (FL), when deployed\nover a realistic wireless network, is studied. In particular, a wireless\nnetwork is considered in which wireless users transmit their local FL models\n(trained using their locally collected data) to a base station (BS). The BS,\nacting as a central controller, generates a global FL model using the received\nlocal FL models and broadcasts it back to all users. Due to the limited number\nof resource blocks (RBs) in a wireless network, only a subset of users can be\nselected to transmit their local FL model parameters to the BS at each learning\nstep. Moreover, since each user has unique training data samples, the BS\nprefers to include all local user FL models to generate a converged global FL\nmodel. Hence, the FL performance and convergence time will be significantly\naffected by the user selection scheme. Therefore, it is necessary to design an\nappropriate user selection scheme that enables users of higher importance to be\nselected more frequently. This joint learning, wireless resource allocation,\nand user selection problem is formulated as an optimization problem whose goal\nis to minimize the FL convergence time while optimizing the FL performance. To\nsolve this problem, a probabilistic user selection scheme is proposed such that\nthe BS is connected to the users whose local FL models have significant effects\non its global FL model with high probabilities. Given the user selection\npolicy, the uplink RB allocation can be determined. To further reduce the FL\nconvergence time, artificial neural networks (ANNs) are used to estimate the\nlocal FL models of the users that are not allocated any RBs for local FL model\ntransmission at each given learning step, which enables the BS to enhance its\nglobal FL model and improve the FL convergence speed and performance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 01:55:12 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 13:28:33 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Chen", "Mingzhe", ""], ["Poor", "H. Vincent", ""], ["Saad", "Walid", ""], ["Cui", "Shuguang", ""]]}, {"id": "2001.07852", "submitter": "Sheng Cheng", "authors": "Sheng Cheng, Han Hu, Xinggong Zhang, Zongming Guo", "title": "DeepRS: Deep-learning Based Network-Adaptive FEC for Real-Time Video\n  Communications", "comments": "Accepted by ISCAS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes an innovative approach to handle packet loss in real-time\nvideo streaming scenarios in a more sophisticated way -- Predicting packet loss\npattern on time field by deep learning model.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 02:17:09 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Cheng", "Sheng", ""], ["Hu", "Han", ""], ["Zhang", "Xinggong", ""], ["Guo", "Zongming", ""]]}, {"id": "2001.07915", "submitter": "Hamza Khan", "authors": "Hamza Khan, Anis Elgabli, Sumudu Samarakoon, Mehdi Bennis, and Choong\n  Seon Hong", "title": "Reinforcement Learning Based Vehicle-cell Association Algorithm for\n  Highly Mobile Millimeter Wave Communication", "comments": "13 pages, 14 figures", "journal-ref": "IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING, VOL.\n  5, NO. 4, DECEMBER 2019", "doi": "10.1109/TCCN.2019.2941191", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle-to-everything (V2X) communication is a growing area of communication\nwith a variety of use cases. This paper investigates the problem of\nvehicle-cell association in millimeter wave (mmWave) communication networks.\nThe aim is to maximize the time average rate per vehicular user (VUE) while\nensuring a target minimum rate for all VUEs with low signaling overhead. We\nfirst formulate the user (vehicle) association problem as a discrete non-convex\noptimization problem. Then, by leveraging tools from machine learning,\nspecifically distributed deep reinforcement learning (DDRL) and the\nasynchronous actor critic algorithm (A3C), we propose a low complexity\nalgorithm that approximates the solution of the proposed optimization problem.\nThe proposed DDRL-based algorithm endows every road side unit (RSU) with a\nlocal RL agent that selects a local action based on the observed input state.\nActions of different RSUs are forwarded to a central entity, that computes a\nglobal reward which is then fed back to RSUs. It is shown that each\nindependently trained RL performs the vehicle-RSU association action with low\ncontrol overhead and less computational complexity compared to running an\nonline complex algorithm to solve the non-convex optimization problem. Finally,\nsimulation results show that the proposed solution achieves up to 15\\% gains in\nterms of sum rate and 20\\% reduction in VUE outages compared to several\nbaseline designs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 08:51:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Khan", "Hamza", ""], ["Elgabli", "Anis", ""], ["Samarakoon", "Sumudu", ""], ["Bennis", "Mehdi", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2001.07964", "submitter": "Sla{\\dj}ana Jo\\v{s}ilo", "authors": "Sla{\\dj}ana Jo\\v{s}ilo, Gy\\\"orgy D\\'an", "title": "Joint Wireless and Edge Computing Resource Management with Dynamic\n  Network Slice Selection", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing is a promising approach for enabling low latency computation\noffloading in edge computing systems. In this paper, we consider an edge\ncomputing system under network slicing in which the wireless devices generate\nlatency sensitive computational tasks. We address the problem of joint dynamic\nassignment of computational tasks to slices, management of radio resources\nacross slices and management of radio and computing resources within slices. We\nformulate the Joint Slice Selection and Edge Resource Management(JSS-ERM)\nproblem as a mixed-integer problem with the objective to minimize the\ncompletion time of computational tasks. We show that the JSS-ERM problem is\nNP-hard and develop an approximation algorithm with bounded approximation ratio\nbased on a game theoretic treatment of the problem. We provide extensive\nsimulation results to show that network slicing can improve the system\nperformance compared to no slicing and that the proposed solution can achieve\nsignificant gains compared to the equal slicing policy. Our results also show\nthat the computational complexity of the proposed algorithm is approximately\nlinear in the number of devices.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 11:34:17 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Jo\u0161ilo", "Sla\u0111ana", ""], ["D\u00e1n", "Gy\u00f6rgy", ""]]}, {"id": "2001.07974", "submitter": "Bin Han", "authors": "Bin Han and Hans D. Schotten", "title": "Machine Learning for Network Slicing Resource Management: A\n  Comprehensive Survey", "comments": "To appear in ZTE Communications, 2020", "journal-ref": "ZTE Communications, 68(4), 2019", "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging technology of multi-tenancy network slicing is considered as an\nessential feature of 5G cellular networks. It provides network slices as a new\ntype of public cloud services, and therewith increases the service flexibility\nand enhances the network resource efficiency. Meanwhile, it raises new\nchallenges of network resource management. A number of various methods have\nbeen proposed over the recent past years, in which machine learning and\nartificial intelligence techniques are widely deployed. In this article, we\nprovide a survey to existing approaches of network slicing resource management,\nwith a highlight on the roles played by machine learning in them.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 11:55:29 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Han", "Bin", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2001.08023", "submitter": "Cenk G\\\"undo\\u{g}an", "authors": "Cenk G\\\"undo\\u{g}an, Christian Ams\\\"uss, Thomas C. Schmidt, Matthias\n  W\\\"ahlisch", "title": "IoT Content Object Security with OSCORE and NDN: A First Experimental\n  Comparison", "comments": null, "journal-ref": "Proceedings of IFIP Networking 2020", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging Internet of Things (IoT) challenges the end-to-end transport of\nthe Internet by low power lossy links and gateways that perform protocol\ntranslations. Protocols such as CoAP or MQTT-SN are degraded by the overhead of\nDTLS sessions, which in common deployment protect content transfer only up to\nthe gateway. To preserve content security end-to-end via gateways and proxies,\nthe IETF recently developed Object Security for Constrained RESTful\nEnvironments (OSCORE), which extends CoAP with content object security features\ncommonly known from Information Centric Networks (ICN).\n  This paper presents a comparative analysis of protocol stacks that protect\nrequest-response transactions. We measure protocol performances of CoAP over\nDTLS, OSCORE, and the information-centric Named Data Networking (NDN) protocol\non a large-scale IoT testbed in single- and multi-hop scenarios. Our findings\nindicate that (a) OSCORE improves on CoAP over DTLS in error-prone wireless\nregimes due to omitting the overhead of maintaining security sessions at\nendpoints, and (b) NDN attains superior robustness and reliability due to its\nintrinsic network caches and hop-wise retransmissions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:09:16 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 18:02:19 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["G\u00fcndo\u011fan", "Cenk", ""], ["Ams\u00fcss", "Christian", ""], ["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "2001.08068", "submitter": "Alessandro Bazzi", "authors": "Alessandro Bazzi, Thomas Blazek, Michele Menarini, Barbara M. Masini,\n  Alberto Zanella, Christoph Mecklenbrauker, Golsa Ghiaasi", "title": "A Hardware-in-the-Loop Evaluation of the Impact of the V2X Channel on\n  the Traffic-Safety Versus Efficiency Trade-offs", "comments": null, "journal-ref": null, "doi": "10.23919/EuCAP48036.2020.9135714", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicles are increasingly becoming connected and short-range wireless\ncommunications promise to introduce a radical change in the drivers' behaviors.\nAmong the main use cases, the intersection management is surely one of those\nthat could mostly impact on both traffic safety and efficiency. In this work,\nwe consider an intersection collision warning application and exploit an\nhardware-in-the-loop (HIL) platform to verify the impact on the risk of\naccidents as well as the average time to travel a given distance. Besides\nincluding real ITS-G5 compliant message exchanges, the platform also includes a\nchannel emulator with real signals. Results show that the risk of collisions\ncan be drastically reduced, with an overall trade-off between safety and\ntraffic efficiency. At the same time, it is shown that the presence of real\nchannel conditions cannot guarantee the same condition of zero-risk as with\nideal channel propagation, remarking the importance of channel conditions and\nsignal processing.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:30:56 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Bazzi", "Alessandro", ""], ["Blazek", "Thomas", ""], ["Menarini", "Michele", ""], ["Masini", "Barbara M.", ""], ["Zanella", "Alberto", ""], ["Mecklenbrauker", "Christoph", ""], ["Ghiaasi", "Golsa", ""]]}, {"id": "2001.08159", "submitter": "Cheng-Xiang Wang", "authors": "Cheng-Xiang Wang, Marco Di Renzo, Slawomir Sta\\'nczak, Sen Wang and\n  Erik G. Larsson", "title": "Artificial Intelligence Enabled Wireless Networking for 5G and Beyond:\n  Recent Advances and Future Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fifth generation (5G) wireless communication networks are currently being\ndeployed, and beyond 5G (B5G) networks are expected to be developed over the\nnext decade. Artificial intelligence (AI) technologies and, in particular,\nmachine learning (ML) have the potential to efficiently solve the unstructured\nand seemingly intractable problems by involving large amounts of data that need\nto be dealt with in B5G. This article studies how AI and ML can be leveraged\nfor the design and operation of B5G networks. We first provide a comprehensive\nsurvey of recent advances and future challenges that result from bringing AI/ML\ntechnologies into B5G wireless networks. Our survey touches different aspects\nof wireless network design and optimization, including channel measurements,\nmodeling, and estimation, physical-layer research, and network management and\noptimization. Then, ML algorithms and applications to B5G networks are\nreviewed, followed by an overview of standard developments of applying AI/ML\nalgorithms to B5G networks. We conclude this study by the future challenges on\napplying AI/ML to B5G networks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 04:09:26 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Wang", "Cheng-Xiang", ""], ["Di Renzo", "Marco", ""], ["Sta\u0144czak", "Slawomir", ""], ["Wang", "Sen", ""], ["Larsson", "Erik G.", ""]]}, {"id": "2001.08160", "submitter": "Joberto Martins Prof. Dr.", "authors": "Yanny Moscovits and Eliseu Torres and Joberto S. B. Martins", "title": "Managing IEC 61850 Message Exchange for SDN-Controlled Cognitive\n  Communication Resource Allocation in the Smart Grid", "comments": "8 pages, 4 figures, 8th International Workshop on ADVANCEs in ICT\n  Infrastructures and Services (ADVANCE 2020)", "journal-ref": "8th International Workshop on ADVANCEs in ICT Infrastructures and\n  Services - ADVANCE 2020", "doi": "10.5281/zenodo.3581404", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The IEC 61850 standard is being largely used in the Smart Grid (SG) context\nmainly due to its ability to address communication, interoperability and\nmigration issues. IEC 61850 currently aims at internal substation\ncommunication. Nevertheless, there is a demand to generalize its use for\ndistributed SG systems like Home Energy Management Systems (HEMS) and Advanced\nMonitoring Infrastructure (AMI) Communication which potentially involves\ndistributed substations or distributed SG components. IEC 61850- based systems\nrequire constrained timing requirements for communication and the common\napproach is to allocate static link bandwidth resources leading in some cases\nto over dimensioning. This paper presents the Substation Cognitive\nCommunication Resource Management (IC2RM), that aims the management of\nbandwidth allocation for IEC messages using a cognitive approach for its\nprovisioning and the SDN/OpenFlow for its deployment. By dynamically deploying\nbandwidth for IEC messages, IC2RM optimizes links between SG substations and\nsystems and potentially reduces the operational costs (OPEX).\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 14:56:54 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Moscovits", "Yanny", ""], ["Torres", "Eliseu", ""], ["Martins", "Joberto S. B.", ""]]}, {"id": "2001.08162", "submitter": "Samaneh Aghashahi", "authors": "Samaneh Aghashahi, Ghasem Mirjalily, Aliakber Tadaion", "title": "Cross Layer Design for Maximizing Network Utility in Multiple Gateways\n  Wireless Mesh Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of network utility maximization in multiple\ngateways wireless mesh networks by considering Signal to Interference plus\nNoise Ratio (SINR) as the interference model. The aim is a cross layer design\nthat considers joint rate control, traffic splitting, routing, scheduling, link\nrate allocation and power control to formulate the network utility maximization\nproblem. As this problem is computationally complex, we propose the Joint\ndynamic Gateway selection, link Rate allocation and Power control (JGRP)\nalgorithm based on the differential backlog as a sub-optimal solution. This\nalgorithm first constructs the initial network topology, and then in each time\nslot, determines the generation rate and destination gateway of each traffic\nflow, simultaneously. The other main task of this algorithm is joint routing,\nscheduling, links rate allocation and node power allocation in each time slot.\nMoreover, for improving the fairness, we propose some new parameters instead of\nthe differential backlog in JGRP algorithm. Simulation results show that using\nthe proposed parameters in JGRP algorithm improves fairness from throughput and\ndelay point of views.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 13:53:19 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Aghashahi", "Samaneh", ""], ["Mirjalily", "Ghasem", ""], ["Tadaion", "Aliakber", ""]]}, {"id": "2001.08163", "submitter": "Petros Spachos", "authors": "Evan Fallis, Petros Spachos, Stefano Gregori", "title": "A Power-Efficient Audio Acquisition System for Smart City Applications", "comments": null, "journal-ref": null, "doi": "10.1016/j.iot.2019.100155", "report-no": null, "categories": "cs.NI cs.SD cs.SI eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic noise has adverse effects on human activities. Aside from hearing\nimpairment and stress-related illnesses, it can also interfere with spoken\ncommunication, reduce human performance and affect the quality of life. As\nurbanization is intensifying, the potential benefits of reducing noise\npollution in smart-city environments are extensive. Noise levels can be\ncollected and analyzed using a wireless sensor network which can monitor the\nnoise level by using microphones. However, every wireless system struggles in\nterms of the battery requirements needed for continuous data collection and\nmonitoring. In this paper, the design of a testbed for a smart microphone\nsystem is presented. To save power, a microcontroller and an Analog-to-Digital\nConverter (ADC) dynamically switch between high and low power modes in response\nto environmental noise. Specifically, the high powered components are triggered\nby a spike in the acoustic noise level. Three wireless technologies, WiFi (2.4\nGHz), Bluetooth Low Energy (BLE) 4.0 and Zigbee were examined. According to the\nresults, the power consumption of a node can be lowered by 97% when idle based\non the testbed.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 18:35:14 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Fallis", "Evan", ""], ["Spachos", "Petros", ""], ["Gregori", "Stefano", ""]]}, {"id": "2001.08164", "submitter": "Dawit Hadush Hailu", "authors": "Dawit Hadush Hailu, Gebrehiwet Gebrekrstos Lema and Gebremichael T.\n  Tesfamariam", "title": "A Simulation Based Performance Evaluation of Optical Ethernet Switch", "comments": "arXiv admin note: text overlap with arXiv:1911.07614", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of several new Cloud Radio Access Network (C-RAN)\ntechnologies, todays networking environment is dramatically altered and is\nexperiencing a rapid transformation. One of the most important is Ethernet\nbased C-RAN, in support of which many products such as optical Ethernet\nswitches have recently appeared on the market. This paper presents the\nperformance analysis of such switches with respect to Packet Loss Ratio (PLR),\nLatency and Packet Delay Variation (PDV). We employed the Simula based on\nDiscrete Event Modelling on Simula (DEMOS), a context class for discrete event\nsimulation to simulate a cut-through optical Ethernet switch under two types of\ntraffics: High priority (HP) traffic and Low priority (LP) traffic. In this\nway, the paper evaluates the optical Ethernet switch performance\nquantitatively. The results obtained from the simulator showed that the high\nquality of service was reflected on HP traffic and the low quality of service\nin LP traffic. Hence, HP traffic can be used for transporting Radio over\nEthernet (RoE) traffic while LP traffic can used for transporting time\ninsensitive application. It is also found that HP traffic experiences a PDV\nequals to the duration of maximum sized LP traffic in Optical Ethernet switch.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 07:11:36 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Hailu", "Dawit Hadush", ""], ["Lema", "Gebrehiwet Gebrekrstos", ""], ["Tesfamariam", "Gebremichael T.", ""]]}, {"id": "2001.08165", "submitter": "Dinh Nguyen", "authors": "Dinh C Nguyen, Pubudu N Pathirana, Ming Ding, Aruna Seneviratne", "title": "Blockchain as a Service for Multi-Access Edge Computing: A Deep\n  Reinforcement Learning Approach", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, blockchain has gained momentum in the academic community thanks to\nits decentralization, immutability, transparency and security. As an emerging\nparadigm, Multi-access Edge Computing (MEC) has been widely used to provide\ncomputation and storage resources to mobile user equipments (UE) at the edge of\nthe network for improving the performance of mobile applications. In this\npaper, we propose a novel blockchain-based MEC architecture where UEs can\noffload their computation tasks to the MEC servers. In particular, a blockchain\nnetwork is deployed and hosted on the MEC platform as Blockchain as a Service\n(BaaS) that supports smart contract-based resource trading and transaction\nmining services for mobile task offloading. To enhance the performance of the\nblockchain-empowered MEC system, we propose a joint scheme of computation\noffloading and blockchain mining. Accordingly, an optimization problem is\nformulated to maximize edge service revenue and blockchain mining reward while\nminimizing the service computation latency with respect to constraints of user\nservice demands and hash power resource. We then propose a novel Deep\nReinforcement Learning (DRL) approach using a double deep Q-network (DQN)\nalgorithm to solve the proposed problem. Numerical results demonstrate that the\nproposed scheme outperforms the other baseline methods in terms of better\nsystem utility with computational efficiency. Experiment results also verify\nthat the trading contract design is efficient with low operation cost, showing\nthe feasibility of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 06:34:13 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Nguyen", "Dinh C", ""], ["Pathirana", "Pubudu N", ""], ["Ding", "Ming", ""], ["Seneviratne", "Aruna", ""]]}, {"id": "2001.08168", "submitter": "Jean Michel De Souza Sant'Ana", "authors": "Jean Michel de Souza Sant'Ana, Arliones Hoeller, Richard Demo Souza,\n  Samuel Montejo-S\\'anchez, Hirley Alves, and Mario de Noronha Neto", "title": "Hybrid Coded Replication in LoRa Networks", "comments": "9 pages, 4 figures, to be published in IEEE Transactions on\n  Industrial Informatics", "journal-ref": null, "doi": "10.1109/TII.2020.2966120", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low Power Wide Area Networks (LPWAN) are wireless connectivity solutions for\nInternet-of-Things (IoT) applications, including industrial automation. Among\nthe several LPWAN technologies, LoRaWAN has been extensively addressed by the\nresearch community and the industry. However, the reliability and scalability\nof LoRaWAN are still uncertain. One of the techniques to increase the\nreliability of LoRaWAN is message replication, which exploits time diversity.\nThis paper proposes a novel hybrid coded message replication scheme that\ninterleaves simple repetition and a recently proposed coded replication method.\nWe analyze the optimization of the proposed scheme under minimum reliability\nrequirements and show that it enhances the network performance without\nrequiring additional transmit power compared to the competing replication\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:31:48 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Sant'Ana", "Jean Michel de Souza", ""], ["Hoeller", "Arliones", ""], ["Souza", "Richard Demo", ""], ["Montejo-S\u00e1nchez", "Samuel", ""], ["Alves", "Hirley", ""], ["Neto", "Mario de Noronha", ""]]}, {"id": "2001.08171", "submitter": "Wilder Castellanos", "authors": "Jose Macias, Harold Pinilla, Wilder Castellanos, Jose Alvarado and\n  Andres S\\'anchez", "title": "Design and Implementation of a Multiprotocol IoT Gateway", "comments": "20 pages, in Spanish. 15 figures. Work presented in XIV International\n  Conference of Electronics, Control and Telecommunications (CIECT). Bogota.\n  Colombia. 2019 Proceedings: Transformacion digital incluyente para el avance\n  tecnologico y social ISBN: 978-958-44-5254-2 VOL.13", "journal-ref": "Proceedings of the XIV International Conference of Electronics,\n  Control and Telecommunications (CIECT). 179-198. ISBN 978-958-44-5254-2\n  (2019)", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the coming years, the interconnection of a large number of devices is\nexpected, which will lead to a new form of interaction between the real and the\nvirtual world. In this promising scenario, known as the Internet of Things, it\nis expected that different objects, such as sensors, industrial robots, cars,\nappliances, will be connected to the Internet. One of the main challenges of\nthe Internet of Things is the interoperability of highly heterogeneous devices,\nmainly in terms of the communication capabilities and network protocols used.\nAs consequence, the interconnection model of the different devices involves an\nintermediary device, known as gateway. This gateway is a centralized element\nfor the management of the devices that make up an IoT application. In addition,\nit is essential for the transmission of information to the Internet, especially\nwhen many IoT devices are not IP-based. This paper describes the implementation\nof an IoT gateway that allows the exchange of data through different wireless\ntechnologies and forwarding of such data to the Internet. The proposed gateway\nhas important advantages such as: supporting for multiprotocol\ninterconnectivity; remote configuration of wireless nodes for sensor and\nactuators management; a flexible algorithm to translate the data obtained by\nsensors into a uniform format for transmission to a cloud server; low energy\nconsumption due to efficient data transfer over the MQTT protocol. In order to\ndemonstrate the usefulness of the developed gateway, a proof-of-concept test\nwas implemented. The implemented scenario consists of 2 wireless nodes\nresponsible for sensing environmental variables and transmitting data to the\ngateway node through different communication protocols. The obtained results\nshow the feasibility for simultaneous data transmission from the remote\nwireless nodes to the gateway.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 21:26:12 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Macias", "Jose", ""], ["Pinilla", "Harold", ""], ["Castellanos", "Wilder", ""], ["Alvarado", "Jose", ""], ["S\u00e1nchez", "Andres", ""]]}, {"id": "2001.08172", "submitter": "Xuwei Xue", "authors": "Xuwei Xue, Fu Wang, Fernando Agraz, Albert Pag\\`es, Bitao Pan, Fulong\n  Yan, Xiaotao Guo, Salvatore Spadaro, Nicola Calabretta", "title": "SDN-controlled and Orchestrated OPSquare DCN Enabling Automatic Network\n  Slicing with Differentiated QoS Provisioning", "comments": null, "journal-ref": "Journal of Lightwave Technology, 2020", "doi": "10.1109/JLT.2020.2965640", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose and experimentally assess the automatic and flexible\nNSs configurations of optical OPSquare DCN controlled and orchestrated by an\nextended SDN control plane for multi-tenant applications with differentiated\nQoS provisioning. Optical Flow Control (OFC) protocol has been developed to\nprevent packet losses at switch sides caused by packet contentions.Based on the\ncollected resource topology of data plane, the optical network slices can be\ndynamically provisioned and automatically reconfigured by the SDN control\nplane. Meanwhile, experimental results validate that the priority assignment of\napplication flows supplies dynamic QoS performance to various slices running\napplications with specific requirements in terms of packet loss and\ntransmission latency. In addition, the capability of exposing traffic\nstatistics information of data plane to SDN control plane enables the\nimplementation of load balancing algorithms further improving the network\nperformance with high QoS. No packet loss and less than 4.8 us server-to-server\nlatency can be guaranteed for the sliced network with highest priority at a\nload of 0.5.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 16:56:38 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Xue", "Xuwei", ""], ["Wang", "Fu", ""], ["Agraz", "Fernando", ""], ["Pag\u00e8s", "Albert", ""], ["Pan", "Bitao", ""], ["Yan", "Fulong", ""], ["Guo", "Xiaotao", ""], ["Spadaro", "Salvatore", ""], ["Calabretta", "Nicola", ""]]}, {"id": "2001.08253", "submitter": "Soheil Abbasloo", "authors": "Soheil Abbasloo, Yang Xu, H. Jonathan Chao", "title": "To schedule or not to schedule: when no-scheduling can beat the\n  best-known flow scheduling algorithm in datacenter networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional wisdom for minimizing the average flow completion time (AFCT) in\nthe datacenter network (DCN), where flow sizes are highly variable, would\nsuggest scheduling every individual flow. However, we show that considering\nscheduling delay (including scheduler's computational and communication\ndelays), serving most of the flows without any scheduling and only in\nfirst-come-first-served (FCFS) manner significantly improves their performance\neven when it is compared to the shortest remaining processing time (SRPT)-known\nas optimum algorithm when scheduling delay is zero. To do so, we only require\nto have two coarse classes of flows categorized based on flows' sizes\n(1st-class including flows smaller than a threshold, H, and 2nd-class including\nothers) and serve 1st-class flows always before serving 2nd-class ones. To show\nthat, we take SRPT scheduling algorithm accompanied by the global knowledge of\nflows, formulate impact of scheduling delay on its performance, and prove that\nfor any flow size distribution and network load (<1), there is always a\nthreshold, H, which guarantees 1st-class flows achieve lower AFCT under FCFS\ncompared to SRPT. Our numerically calculated results and extensive flow-level\nsimulations show that on average, more than 90% of flows could be in 1st-class\nand consequently do not require any scheduling.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 19:57:20 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Abbasloo", "Soheil", ""], ["Xu", "Yang", ""], ["Chao", "H. Jonathan", ""]]}, {"id": "2001.08259", "submitter": "Rafia Malik", "authors": "Rafia Malik and Mai Vu", "title": "Energy-Efficient Offloading in Delay-Constrained Massive MIMO Enabled\n  Edge Network Using Data Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a wireless edge-computing system which allows multiple users to\nsimultaneously offload computation-intensive tasks to multiple massive-MIMO\naccess points, each with a collocated multi-access edge computing (MEC) server.\nMassive-MIMO enables simultaneous uplink transmissions from all users,\nsignificantly shortening the data offloading time compared to sequential\nprotocols, and makes the three phases of data offloading, computing, and\ndownloading have comparable durations. Based on this three-phase structure, we\nformulate a novel problem to minimize a weighted sum of the energy consumption\nat both the users and the MEC server under a round-trip latency constraint,\nusing a combination of data partitioning, transmit power control and CPU\nfrequency scaling at both the user and server ends. We design a novel nested\nprimal-dual algorithm using two different methods to solve this problem\nefficiently. Optimized solutions show that for larger requests, more data is\noffloaded to the MECs to reduce local computation time in order to meet the\nlatency constraint, despite higher energy cost of wireless transmissions.\nMassive-MIMO channel estimation errors under pilot contamination also causes\nmore data to be offloaded to the MECs. Compared to binary offloading, partial\noffloading with data partitioning is superior and leads to significant\nreduction in the overall energy consumption.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:18:46 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 22:56:16 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Malik", "Rafia", ""], ["Vu", "Mai", ""]]}, {"id": "2001.08288", "submitter": "M. Hammad Mazhar", "authors": "M. Hammad Mazhar and Zubair Shafiq", "title": "Characterizing Smart Home IoT Traffic in the Wild", "comments": "13 pages, to be published in IoTDI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the smart home IoT ecosystem flourishes, it is imperative to gain a better\nunderstanding of the unique challenges it poses in terms of management,\nsecurity, and privacy. Prior studies are limited because they examine smart\nhome IoT devices in testbed environments or at a small scale. To address this\ngap, we present a measurement study of smart home IoT devices in the wild by\ninstrumenting home gateways and passively collecting real-world network traffic\nlogs from more than 200 homes across a large metropolitan area in the United\nStates. We characterize smart home IoT traffic in terms of its volume, temporal\npatterns, and external endpoints along with focusing on certain security and\nprivacy concerns. We first show that traffic characteristics reflect the\nfunctionality of smart home IoT devices such as smart TVs generating high\nvolume traffic to content streaming services following diurnal patterns\nassociated with human activity. While the smart home IoT ecosystem seems\nfragmented, our analysis reveals that it is mostly centralized due to its\nreliance on a few popular cloud and DNS services. Our findings also highlight\nseveral interesting security and privacy concerns in smart home IoT ecosystem\nsuch as the need to improve policy-based access control for IoT traffic, lack\nof use of application layer encryption, and prevalence of third-party\nadvertising and tracking services. Our findings have important implications for\nfuture research on improving management, security, and privacy of the smart\nhome IoT ecosystem.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 21:29:05 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 16:54:08 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 00:13:40 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Mazhar", "M. Hammad", ""], ["Shafiq", "Zubair", ""]]}, {"id": "2001.08489", "submitter": "Piotr Gawlowicz", "authors": "Piotr Gaw{\\l}owicz and Elnaz Alizadeh Jarchlo and Anatolij Zubow", "title": "WoV: WiFi-based VLC testbed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a complete Visible Light Communications (VLC) transceiver system\nconsisting of low-cost Commercial-Off-The-Shelf (COTS) components. In\nparticular, we show that COTS IEEE 802.11n (WiFi) devices can be used so that\nthe physical and data link layers of radio frequency (RF) WiFi, i.e. 2.4 GHz,\nare reused for VLC. Moreover, as WiFi is fully integrated with the Linux\nsystem, higher protocols from network to transport and application layer can be\nused and tested in VLC-related experiments. Our approach has the advantage that\na VLC experimenter can fully focus on VLC-related low-level aspects like the\ndesign of novel VLC front-ends, e.g. LED drivers, lenses, and photodetectors\nand test their impact directly on the full network protocol stack in an\nend-to-end manner with real applications like adaptive video streaming. We\npresent first results from experiments using our prototype showing the\nperformance of unidirectional VLC transmission. Here we analyze the distortions\nintroduced as well as the relationship between signal strength on frame error\nrate for different MCS and the maximum communication distance. Experimental\nresults reveal that a data rate of up to 150 Mbps is possible over short\nranges.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 13:13:29 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Gaw\u0142owicz", "Piotr", ""], ["Jarchlo", "Elnaz Alizadeh", ""], ["Zubow", "Anatolij", ""]]}, {"id": "2001.08495", "submitter": "Alessandro Bazzi", "authors": "Alessandro Bazzi", "title": "Congestion Control Mechanisms in IEEE 802.11p and Sidelink C-V2X", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected vehicles are expected to play a major role in the next future to\nimprove safety and traffic efficiency on the road and short-range technologies\nhave been defined to enable the direct exchange of information. To this aim,\ntwo solutions are currently the subject of a debate that goes beyond the\ntechnician, i.e., IEEE 802.11p and sidelink cellular-vehicle-to-anything\n(C-V2X). Tested and mature for deployment the first, possibly more efficient\nthe second. In both cases, one of the main aspects is the management of channel\ncongestions, which can cause serious packet losses and have a critical impact\non the reliability of applications. Congestions can be managed through\ndifferent approaches, including the control of transmission power, packet\ngeneration frequency, and the adopted modulation and coding scheme. Congestion\nmanagement has been well studied in IEEE 802.11p, with consolidated algorithms\nincluded in the standards, whereas it appears somehow as a new topic looking at\nC-V2X. In this work, a review of the main congestion control mechanisms and a\ndiscussion of their applicability and efficiency in the two technologies is\nprovided. This topic is addressed without focusing on specific algorithms and\nwith the aim to provide general guidelines as a starting point for new\nproposals.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 13:36:50 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Bazzi", "Alessandro", ""]]}, {"id": "2001.08541", "submitter": "Tao Zhou", "authors": "Tianlong Fan, Linyuan L\\\"u, Dinghua Shi, Tao Zhou", "title": "Characterizing cycle structure in complex networks", "comments": "35 pages, 26 figures and 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.NI math.CO physics.data-an", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cycle is the simplest structure that brings redundant paths in network\nconnectivity and feedback effects in network dynamics. Focusing on cycle\nstructure, this paper defines a new matrix, named cycle number matrix, to\nrepresent cycle information of a network, and an index, named cycle ratio, to\nquantify the node importance. Experiments on real networks suggest that cycle\nratio contains rich information in addition to well-known benchmark indices,\nfor example, the node rankings by cycle ratio are largely different from\nrankings by degree, H-index, coreness, betweenness and articulation ranking,\nwhile the rankings by degree, H-index, coreness are very similar to each other.\nExtensive experiments on identifying vital nodes that maintain network\nconnectivity, facilitate network synchronization and maximize the early reach\nof spreading show that cycle ratio is competitive to betweenness and overall\nbetter than other benchmarks. We believe the in-depth analyses on cycle\nstructure may yield novel insights, metrics, models and algorithms for network\nscience.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 02:20:03 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 23:40:14 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Fan", "Tianlong", ""], ["L\u00fc", "Linyuan", ""], ["Shi", "Dinghua", ""], ["Zhou", "Tao", ""]]}, {"id": "2001.08557", "submitter": "Marco Zimmerling", "authors": "Marco Zimmerling, Luca Mottola, Silvia Santini", "title": "Synchronous Transmissions in Low-Power Wireless: A Survey of\n  Communication Protocols and Network Services", "comments": "Submitted to ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-power wireless communication is a central building block of\nCyber-physical Systems and the Internet of Things. Conventional low-power\nwireless protocols make avoiding packet collisions a cornerstone design choice.\nThe concept of synchronous transmissions challenges this view. As collisions\nare not necessarily destructive, under specific circumstances, commodity\nlow-power wireless radios are often able to receive useful information even in\nthe presence of superimposed signals from different transmitters. We survey the\ngrowing number of protocols that exploit synchronous transmissions for higher\nrobustness and efficiency as well as unprecedented functionality and\nversatility compared to conventional designs. The illustration of protocols\nbased on synchronous transmissions is cast in a conceptional framework we\nestablish, with the goal of highlighting differences and similarities among the\nproposed solutions. We conclude the paper with a discussion on open research\nquestions in this field.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 14:34:55 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 09:10:53 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zimmerling", "Marco", ""], ["Mottola", "Luca", ""], ["Santini", "Silvia", ""]]}, {"id": "2001.08585", "submitter": "Salman Haider", "authors": "Salman Haider, Usman Saeed, Jawad Ashraf, Dr. Fareeha Zafar", "title": "Explosive Material Detection and Security Alert System (e-DASS)", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The terrorism rate in Pakistan becomes higher even after the advancement of\ninformation technology. Especially APS Attack and numerous other in different\npart of country. The root cause of such attacks as according to our research is\nas: terrorists utilizing the benefit of lack of a full proof security check\nsystem. Traditional explosive detection systems are large in size, expensive\nand require manual attention. These systems are not much useful due to its\npublic visibility intruder or terrorists can easily bypass the system using\nanother route. This term paper is mainly focusing on explosive material\ndetection using IoT with WSN. Explosive Material Detection and security alert\nsystem (e-DASS) consists of several hundreds of nodes depending upon the\ngeographical area we are going to cover. Each node should be able to\ncommunicate with the other node and update the information if necessary.\nTracking of the target can be done in an easier and faster way because all the\nnodes are synchronized. (e-DASS) is a power efficient explosive detection\nsystem. Most of the times nodes will be in the idle state, unless and until\npositive presence of an explosive is found.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 08:09:04 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Haider", "Salman", ""], ["Saeed", "Usman", ""], ["Ashraf", "Jawad", ""], ["Zafar", "Dr. Fareeha", ""]]}, {"id": "2001.08586", "submitter": "Issam Damaj", "authors": "Issam Damaj (1), Safaa Kasbah (2) ((1) Rafik Hariri University, (2)\n  Lebanese American University)", "title": "Integrated Mobile Solutions in an Internet-of-Things Development Model", "comments": "31 pages, 16 figures, 3 tables", "journal-ref": "EAI/Springer Innovations in Communications and Computing,\n  Springer, Netherlands, (2019)3-31", "doi": "10.1007/978-3-319-93491-4_1", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet-of-Things (IoT) is a revolutionary technology that is rapidly\nchanging the world. IoT systems strive to provide automated solutions for\nalmost every life aspect; traditional devices are becoming connected,\nubiquitous, pervasive, wireless, context-aware, smart, controlled through\nmobile solutions, to name but a few. IoT devices can now be found in our\napartments, places of work, cars, buildings, and in almost every aspect of\nlife. In this investigation, we propose an IoT system Development Model (IDM).\nThe proposed IDM enables the development of IoT systems from concept to\nprototyping. The model comprises concept refinement pyramids, decision trees,\nrealistic constraint lists, architecture and organization diagrams,\ncommunication interface patterns, use cases, and menus of analysis metrics and\nevaluation indicators. The investigation confirms that the proposed model\nenjoys several properties, such as, clarity, conciseness, thoroughness,\nproductivity, etc. The model is deployed for a variety of systems that belong\nto heterogeneous areas of application; the model is proven to be effective in\napplication and successful in integrating mobile solutions. This chapter\nincludes the presentation of the IDM submodels, the reasoning about their\nusefulness, and the technical developments of several systems. The chapter\nincludes thorough discussions, analysis of the model usability and application,\nand in-depth evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 17:56:37 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Damaj", "Issam", ""], ["Kasbah", "Safaa", ""]]}, {"id": "2001.08684", "submitter": "Erik Rye", "authors": "Erik C. Rye, Robert Beverly", "title": "Discovering the IPv6 Network Periphery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of discovering the IPv6 network periphery, i.e., the\nlast hop router connecting endhosts in the IPv6 Internet. Finding the IPv6\nperiphery using active probing is challenging due to the IPv6 address space\nsize, wide variety of provider addressing and subnetting schemes, and\nincomplete topology traces. As such, existing topology mapping systems can miss\nthe large footprint of the IPv6 periphery, disadvantaging applications ranging\nfrom IPv6 census studies to geolocation and network resilience. We introduce\n\"edgy,\" an approach to explicitly discover the IPv6 network periphery, and use\nit to find >~64M IPv6 periphery router addresses and >~87M links to these last\nhops -- several orders of magnitude more than in currently available IPv6\ntopologies. Further, only 0.2% of edgy's discovered addresses are known to\nexisting IPv6 hitlists.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:27:36 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 18:30:08 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Rye", "Erik C.", ""], ["Beverly", "Robert", ""]]}, {"id": "2001.08847", "submitter": "Rong Du", "authors": "Rong Du, Hossein Shokri Ghadikolaei, and Carlo Fischione", "title": "Wirelessly-powered Sensor Networks Power Allocation for Channel\n  Estimation and Energy Beamforming", "comments": "The paper has been accepted in IEEE Transactions on Wireless\n  Communications on Jan. 19th, 2020. 7 figures, 35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wirelessly-powered sensor networks (WPSNs) are becoming increasingly\nimportant in different monitoring applications. We consider a WPSN where a\nmultiple-antenna base station, which is dedicated for energy transmission,\nsends pilot signals to estimate the channel state information and consequently\nshapes the energy beams toward the sensor nodes. Given a fixed energy budget at\nthe base station, in this paper, we investigate the novel problem of optimally\nallocating the power for the channel estimation and for the energy\ntransmission. We formulate this non-convex optimization problem for general\nchannel estimation and beamforming schemes that satisfy some qualification\nconditions. We provide a new solution approach and a performance analysis in\nterms of optimality and complexity. We also present a closed-form solution for\nthe case where the channels are estimated based on a least square channel\nestimation and a maximum ratio transmit beamforming scheme. The analysis and\nsimulations indicate a significant gain in terms of the network sensing rate,\ncompared to the fixed power allocation, and the importance of improving the\nchannel estimation efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 23:25:50 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Du", "Rong", ""], ["Ghadikolaei", "Hossein Shokri", ""], ["Fischione", "Carlo", ""]]}, {"id": "2001.08883", "submitter": "Tugba Erpek", "authors": "Yalin E. Sagduyu, Yi Shi, Tugba Erpek, William Headley, Bryse Flowers,\n  George Stantchev, Zhuo Lu", "title": "When Wireless Security Meets Machine Learning: Motivation, Challenges,\n  and Research Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless systems are vulnerable to various attacks such as jamming and\neavesdropping due to the shared and broadcast nature of wireless medium. To\nsupport both attack and defense strategies, machine learning (ML) provides\nautomated means to learn from and adapt to wireless communication\ncharacteristics that are hard to capture by hand-crafted features and models.\nThis article discusses motivation, background, and scope of research efforts\nthat bridge ML and wireless security. Motivated by research directions surveyed\nin the context of ML for wireless security, ML-based attack and defense\nsolutions and emerging adversarial ML techniques in the wireless domain are\nidentified along with a roadmap to foster research efforts in bridging ML and\nwireless security.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 05:07:39 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Sagduyu", "Yalin E.", ""], ["Shi", "Yi", ""], ["Erpek", "Tugba", ""], ["Headley", "William", ""], ["Flowers", "Bryse", ""], ["Stantchev", "George", ""], ["Lu", "Zhuo", ""]]}, {"id": "2001.08901", "submitter": "Nguyen Phong Hoang", "authors": "Nguyen Phong Hoang, Ivan Lin, Seyedhamed Ghavamnia, Michalis\n  Polychronakis", "title": "K-resolver: Towards Decentralizing Encrypted DNS Resolution", "comments": "NDSS Workshop on Measurements, Attacks, and Defenses for the Web\n  (MADWeb) 2020", "journal-ref": null, "doi": "10.14722/madweb.2020.23009", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Centralized DNS over HTTPS/TLS (DoH/DoT) resolution, which has started being\ndeployed by major hosting providers and web browsers, has sparked controversy\namong Internet activists and privacy advocates due to several privacy concerns.\nThis design decision causes the trace of all DNS resolutions to be exposed to a\nthird-party resolver, different than the one specified by the user's access\nnetwork. In this work we propose K-resolver, a DNS resolution mechanism that\ndisperses DNS queries across multiple DoH resolvers, reducing the amount of\ninformation about a user's browsing activity exposed to each individual\nresolver. As a result, none of the resolvers can learn a user's entire web\nbrowsing history. We have implemented a prototype of our approach for Mozilla\nFirefox, and used it to evaluate the performance of web page load time compared\nto the default centralized DoH approach. While our K-resolver mechanism has\nsome effect on DNS resolution time and web page load time, we show that this is\nmainly due to the geographical location of the selected DoH servers. When more\nwell-provisioned anycast servers are available, our approach incurs negligible\noverhead while improving user privacy.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 07:02:33 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 01:53:38 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Hoang", "Nguyen Phong", ""], ["Lin", "Ivan", ""], ["Ghavamnia", "Seyedhamed", ""], ["Polychronakis", "Michalis", ""]]}, {"id": "2001.08993", "submitter": "Ahmed Youssef", "authors": "Ahmed E. Youssef", "title": "A Framework for Cloud Security Risk Management Based on the Business\n  Objectives of Organizations", "comments": null, "journal-ref": "International Journal of Advanced Computer Science and\n  Applications(IJACSA), Vol.10, No.12, pp. 186-194,2019", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security is considered one of the top ranked risks of Cloud Computing (CC)\ndue to the outsourcing of sensitive data onto a third party. In addition, the\ncomplexity of the cloud model results in a large number of heterogeneous\nsecurity controls that must be consistently managed. Hence, no matter how\nstrongly the cloud model is secured, organizations continue suffering from lack\nof trust on CC and remain uncertain about its security risk consequences.\nTraditional risk management frameworks do not consider the impact of CC\nsecurity risks on the business objectives of the organizations. In this paper,\nwe propose a novel Cloud Security Risk Management Framework (CSRMF) that helps\norganizations adopting CC identify, analyze, evaluate, and mitigate security\nrisks in their Cloud platforms. Unlike traditional risk management frameworks,\nCSRMF is driven by the business objectives of the organizations. It allows any\norganization adopting CC to be aware of cloud security risks and align their\nlow-level management decisions according to high-level business objectives. In\nessence, it is designed to address impacts of cloud-specific security risks\ninto business objectives in a given organization. Consequently, organizations\nare able to conduct a cost-value analysis regarding the adoption of CC\ntechnology and gain an adequate level of confidence in Cloud technology. On the\nother hand, Cloud Service Providers (CSP) are able to improve productivity and\nprofitability by managing cloud-related risks. The proposed framework has been\nvalidated and evaluated through a use-case scenario.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:46:38 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Youssef", "Ahmed E.", ""]]}, {"id": "2001.09018", "submitter": "Gabriele D'Angelo", "authors": "Mirko Zichichi, Stefano Ferretti, Gabriele D'Angelo", "title": "Are Distributed Ledger Technologies Ready for Smart Transportation\n  Systems?", "comments": "Proceedings of the 3rd Workshop on Cryptocurrencies and Blockchains\n  for Distributed Systems (CryBlock 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to understand whether Distributed Ledger\nTechnologies (DLTs) are ready to support complex services, such as those\nrelated to Intelligent Transportation Systems (ITS). In smart transportation\nservices, a huge amount of sensed data is generated by a multitude of vehicles.\nWhile DLTs provide very interesting features, such as immutability,\ntraceability and verifiability of data, some doubts on the scalability and\nresponsiveness of these technologies appear to be well-founded. We propose an\narchitecture for ITS that resorts to DLT features. Moreover, we provide\nexperimental results of a real test-bed over IOTA, a promising DLT for IoT.\nResults clearly show that, while the viability of the proposal cannot be\nrejected, further work is needed on the responsiveness of DLT infrastructures.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:32:07 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 12:14:48 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Zichichi", "Mirko", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "2001.09070", "submitter": "Blesson Varghese", "authors": "Arkadiusz Madej and Nan Wang and Nikolaos Athanasopoulos and Rajiv\n  Ranjan and Blesson Varghese", "title": "Priority-based Fair Scheduling in Edge Computing", "comments": "10 pages; accepted to IEEE Int. Conf. on Fog and Edge Computing\n  (ICFEC), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduling is important in Edge computing. In contrast to the Cloud, Edge\nresources are hardware limited and cannot support workload-driven\ninfrastructure scaling. Hence, resource allocation and scheduling for the Edge\nrequires a fresh perspective. Existing Edge scheduling research assumes\navailability of all needed resources whenever a job request is made. This paper\nchallenges that assumption, since not all job requests from a Cloud server can\nbe scheduled on an Edge node. Thus, guaranteeing fairness among the clients\n(Cloud servers offloading jobs) while accounting for priorities of the jobs\nbecomes a critical task. This paper presents four scheduling techniques, the\nfirst is a naive first come first serve strategy and further proposes three\nstrategies, namely a client fair, priority fair, and hybrid that accounts for\nthe fairness of both clients and job priorities. An evaluation on a target\nplatform under three different scenarios, namely equal, random, and Gaussian\njob distributions is presented. The experimental studies highlight the low\noverheads and the distribution of scheduled jobs on the Edge node when compared\nto the naive strategy. The results confirm the superior performance of the\nhybrid strategy and showcase the feasibility of fair schedulers for Edge\ncomputing.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 16:13:10 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Madej", "Arkadiusz", ""], ["Wang", "Nan", ""], ["Athanasopoulos", "Nikolaos", ""], ["Ranjan", "Rajiv", ""], ["Varghese", "Blesson", ""]]}, {"id": "2001.09090", "submitter": "Mahieddine Djoudi", "authors": "Saddek Benabied, Abdelhafid Zitouni (LIRE), Mahieddine Djoudi\n  (TECHN\\'E - EA 6316)", "title": "A Cloud Security Framework Based on Trust Model and Mobile Agent", "comments": null, "journal-ref": "2015 International Conference on Cloud Technologies and\n  Applications (CloudTech), Jun 2015, Marrakech, France. pp.1-8", "doi": "10.1109/CloudTech.2015.7336962", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing as a potential paradigm offers tremendous advantages to\nenterprises. With the cloud computing, the market's entrance time is reduced,\ncomputing capabilities is augmented and computing power is really limitless.\nUsually, to use the full power of cloud computing, cloud users has to rely on\nexternal cloud service provider for managing their data. Nevertheless, the\nmanagement of data and services are probably not fully trustworthy. Hence, data\nowners are uncomfortable to place their sensitive data outside their own system\n.i.e., in the cloud. Bringing transparency, trustworthiness and security in the\ncloud model, in order to fulfill client's requirements are still ongoing. To\nachieve this goal, our paper introduces two levels security framework: Cloud\nService Provider (CSP) and Cloud Service User (CSU). Each level is responsible\nfor a particular task of the security. The CSU level includes a proxy agent and\na trust agent, dealing with the first verification. Then a second verification\nis performed at the CSP level. The framework incorporates a trust model to\nmonitor users' behaviors. The use of mobile agents will exploit their intrinsic\nfeatures such as mobility, deliberate localization and secure communication\nchannel provision. This model aims to protect user's sensitive information from\nother internal or external users and hackers. Moreover, it can detect policy\nbreaches, where the users are notified in order to take necessary actions when\nmalicious access or malicious activity would occur.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:26:24 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Benabied", "Saddek", "", "LIRE"], ["Zitouni", "Abdelhafid", "", "LIRE"], ["Djoudi", "Mahieddine", "", "TECHN\u00c9 - EA 6316"]]}, {"id": "2001.09105", "submitter": "Sami Ben Mariem", "authors": "Sami Ben Mariem, Pedro Casas, Matteo Romiti, Benoit Donnet, Rainer\n  St\\\"utz, Bernhard Haslhofer", "title": "All that Glitters is not Bitcoin -- Unveiling the Centralized Nature of\n  the BTC (IP) Network", "comments": "IEEE/IFIP Network Operations and Management Symposium 2020", "journal-ref": "NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management\n  Symposium", "doi": "10.1109/NOMS47738.2020.9110354", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains are typically managed by peer-to-peer (P2P) networks providing\nthe support and substrate to the so-called distributed ledger (DLT), a\nreplicated, shared, and synchronized data structure, geographically spread\nacross multiple nodes. The Bitcoin (BTC) blockchain is by far the most well\nknown DLT, used to record transactions among peers, based on the BTC digital\ncurrency. In this paper, we focus on the network side of the BTC P2P network,\nanalyzing its nodes from a purely network measurements-based approach. We\npresent a BTC crawler able to discover and track the BTC P2P network through\nactive measurements, and use it to analyze its main properties. Through the\ncombined analysis of multiple snapshots of the BTC network as well as by using\nother publicly available data sources on the BTC network and DLT, we unveil the\nBTC P2P network, locate its active nodes, study their performance, and track\nthe evolution of the network over the past two years. Among other relevant\nfindings, we show that (i) the size of the BTC network has remained almost\nconstant during the last 12 months - since the major BTC price drop in early\n2018, (ii) most of the BTC P2P network resides in US and EU countries, and\n(iii) despite this western network locality, most of the mining activity and\ncorresponding revenue is controlled by major mining pools located in China. By\nadditionally analyzing the distribution of BTC coins among independent BTC\nentities (i.e., single BTC addresses or groups of BTC addresses controlled by\nthe same actor), we also conclude that (iv) BTC is very far from being the\ndecentralized and uncontrolled system it is so much advertised to be, with only\n4.5% of all the BTC entities holding about 85% of all circulating BTC coins.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 17:14:52 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 10:30:22 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Mariem", "Sami Ben", ""], ["Casas", "Pedro", ""], ["Romiti", "Matteo", ""], ["Donnet", "Benoit", ""], ["St\u00fctz", "Rainer", ""], ["Haslhofer", "Bernhard", ""]]}, {"id": "2001.09223", "submitter": "Kezhi Wang", "authors": "Feibo Jiang, Kezhi Wang, Li Dong, Cunhua Pan, Kun Yang", "title": "Stacked Auto Encoder Based Deep Reinforcement Learning for Online\n  Resource Scheduling in Large-Scale MEC Networks", "comments": "Accepted by IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An online resource scheduling framework is proposed for minimizing the sum of\nweighted task latency for all the Internet of things (IoT) users, by optimizing\noffloading decision, transmission power and resource allocation in the\nlarge-scale mobile edge computing (MEC) system. Towards this end, a deep\nreinforcement learning (DRL) based solution is proposed, which includes the\nfollowing components. Firstly, a related and regularized stacked auto encoder\n(2r-SAE) with unsupervised learning is applied to perform data compression and\nrepresentation for high dimensional channel quality information (CQI) data,\nwhich can reduce the state space for DRL. Secondly, we present an adaptive\nsimulated annealing based approach (ASA) as the action search method of DRL, in\nwhich an adaptive h-mutation is used to guide the search direction and an\nadaptive iteration is proposed to enhance the search efficiency during the DRL\nprocess. Thirdly, a preserved and prioritized experience replay (2p-ER) is\nintroduced to assist the DRL to train the policy network and find the optimal\noffloading policy. Numerical results are provided to demonstrate that the\nproposed algorithm can achieve near-optimal performance while significantly\ndecreasing the computational time compared with existing benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 23:01:15 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 21:47:24 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Jiang", "Feibo", ""], ["Wang", "Kezhi", ""], ["Dong", "Li", ""], ["Pan", "Cunhua", ""], ["Yang", "Kun", ""]]}, {"id": "2001.09276", "submitter": "Yong Xiao", "authors": "Yong Xiao and Marwan Krunz and Tao Shu", "title": "Multi-operator Network Sharing for Massive IoT", "comments": "Published at IEEE Communication Magazine, vol. 57, no. 4, pp. 96-101,\n  April 2019", "journal-ref": "IEEE Communication Magazine, vol. 57, no. 4, pp. 96-101, April\n  2019", "doi": "10.1109/MCOM.2019.1800272", "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent study predicts that by 2020 up to 50 billion IoT devices will be\nconnected to the Internet, straining the capacity of wireless network that has\nalready been overloaded with data-hungry mobile applications, such as\nhigh-definition video streaming and virtual reality(VR)/augmented reality(AR).\nHow to accommodate the demand for both massive scale of IoT devices and\nhigh-speed cellular services in the physically limited spectrum without\nsignificantly increasing the operational and infrastructure costs is one of the\nmain challenges for operators. In this article, we introduce a new\nmulti-operator network sharing framework that supports the coexistence of IoT\nand high-speed cellular services. Our framework is based on the radio access\nnetwork (RAN) sharing architecture recently introduced by 3GPP as a promising\nsolution for operators to improve their resource utilization and reduce the\nsystem roll-out cost. We evaluate the performance of our proposed framework\nusing the real base station location data in the city of Dublin collected from\ntwo major operators in Ireland. Numerical results show that our proposed\nframework can almost double the total number of IoT devices that can be\nsupported and coexist with other cellular services compared with the case\nwithout network sharing.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 08:16:28 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Xiao", "Yong", ""], ["Krunz", "Marwan", ""], ["Shu", "Tao", ""]]}, {"id": "2001.09335", "submitter": "Mattia Lecci", "authors": "Mattia Lecci, Paolo Testolina, Mattia Rebato, Alberto Testolin,\n  Michele Zorzi", "title": "Machine Learning-aided Design of Thinned Antenna Arrays for Optimized\n  Network Level Performance", "comments": "5 pages, 7 figures. This paper has been presented at EuCAP 2020.\n  Copyright IEEE 2020. Please cite it as: M. Lecci, P. Testolina, M. Rebato, A.\n  Testolin, and M. Zorzi, \"Machine Learning-aided Design of Thinned Antenna\n  Arrays for Optimized Network Level Performance,\" 14th European Conference on\n  Antennas and Propagation (EuCAP 2020), Copenhagen, Mar. 2020", "journal-ref": null, "doi": "10.23919/EuCAP48036.2020.9135310", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of millimeter wave (mmWave) communications, the combination\nof a detailed 5G network simulator with an accurate antenna radiation model is\nrequired to analyze the realistic performance of complex cellular scenarios.\nHowever, due to the complexity of both electromagnetic and network models, the\ndesign and optimization of antenna arrays is generally infeasible due to the\nrequired computational resources and simulation time. In this paper, we propose\na Machine Learning framework that enables a simulation-based optimization of\nthe antenna design. We show how learning methods are able to emulate a complex\nsimulator with a modest dataset obtained from it, enabling a global numerical\noptimization over a vast multi-dimensional parameter space in a reasonable\namount of time. Overall, our results show that the proposed methodology can be\nsuccessfully applied to the optimization of thinned antenna arrays.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:34:32 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 13:12:47 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Lecci", "Mattia", ""], ["Testolina", "Paolo", ""], ["Rebato", "Mattia", ""], ["Testolin", "Alberto", ""], ["Zorzi", "Michele", ""]]}, {"id": "2001.09452", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Robert Falkenberg and Christian Wietfeld", "title": "Towards Cooperative Data Rate Prediction for Future Mobile and Vehicular\n  6G Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based data rate prediction is one of the key drivers for\nanticipatory mobile networking with applications such as dynamic Radio Access\nTechnology (RAT) selection, opportunistic data transfer, and predictive\ncaching. User Equipment (UE)-based prediction approaches that rely on passive\nmeasurements of network quality indicators have successfully been applied to\nforecast the throughput of vehicular data transmissions. However, the\nachievable prediction accuracy is limited as the UE is unaware of the current\nnetwork load. To overcome this issue, we propose a cooperative data rate\nprediction approach which brings together knowledge from the client and network\ndomains. In a real world proof-of-concept evaluation, we utilize the Software\nDefined Radio (SDR)-based control channel sniffer FALCON in order to mimic the\nbehavior of a possible network-assisted information provisioning within future\n6G networks. The results show that the proposed cooperative prediction approach\nis able to reduce the average prediction error by up to 30%. With respect to\nthe ongoing standardization efforts regarding the implementation of\nintelligence for network management, we argue that future 6G networks should go\nbeyond network-focused approaches and actively provide load information to the\nUEs in order to fuel pervasive machine learning and catalyze UE-based network\noptimization techniques.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 13:14:04 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Falkenberg", "Robert", ""], ["Wietfeld", "Christian", ""]]}, {"id": "2001.09592", "submitter": "Kaled Alshmrany", "authors": "Kaled Alshmrany and Lucas Cordeiro", "title": "Finding Security Vulnerabilities in Network Protocol Implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementations of network protocols are often prone to vulnerabilities\ncaused by developers' mistakes when accessing memory regions and dealing with\narithmetic operations. Finding practical approaches for checking the security\nof network protocol implementations has proven to be a challenging problem. The\nmain reason is that the protocol software state-space is too large to be\nexplored. Here we propose a novel verification approach that combines fuzzing\nwith symbolic execution to verify intricate properties in network protocol\nimplementations. We use fuzzing for an initial exploration of the network\nprotocol, while symbolic execution explores both the program paths and protocol\nstates, which were uncovered by fuzzing. From this combination, we\nautomatically generate high-coverage test input packets for a network protocol\nimplementation. We surveyed various approaches based on fuzzing and symbolic\nexecution to understand how these techniques can be effectively combined and\nthen choose a suitable tool to develop further our model on top of it. In our\npreliminary evaluation, we used ESBMC, Map2Check, and KLEE as software\nverifiers and SPIKE as fuzzer to check their suitability to verify our network\nprotocol implementations. Our experimental results show that ESBMC can be\nfurther developed within our verification framework called \\textit{FuSeBMC}, to\nefficiently and effectively detect intricate security vulnerabilities in\nnetwork protocol implementations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 05:49:32 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Alshmrany", "Kaled", ""], ["Cordeiro", "Lucas", ""]]}, {"id": "2001.09673", "submitter": "Idris Badmus Mr", "authors": "Idris Badmus, Abdelquoddouss Laghrissi, Marja Matinmikko-Blue and Ari\n  Pouttu", "title": "Identifying Requirements Affecting Latency in a Softwarized Network for\n  Future 5G and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of a softwarized network leveraging technologies such as SDN and\nNFV comes with different merits such as decreased Operational Expenses (OPEX)\nand less dependency on underlying hardware components. With the amount of\nincreased flexibility, reconfigurability and programmability attributed to\nfuture technologies (i.e. 5G and beyond), and towards the complete network\nvirtualization and softwarization, a new set of requirements or parameters can\nbe identified affecting the latency in a virtualized network. In this paper, we\nidentify different latency requirements for a virtualized network. These\nrequirements include the Virtual Network Function (VNF) deployment time,\nestablishment or connection time and application instantiation time. We further\ntest how some factors such as VNFs resource usage, the applications running\nwithin the VNF and the shared status of the VNF, coordinately affect the\nidentified latency requirement for a virtualized network. Experimentally, for\nperformance analysis, we deploy a softwarized network based on the ETSI NFV\narchitecture, using open source tools. The results show that the new set of\nlatency requirements is relevant for consideration in order to achieve an\noverall ultra reliable low latency and how different the factors can affect\nthese new requirements, especially in the core network. Furthermore, the result\nof our performance analysis proves the trade off between latency of a\nvirtualized network and the resource usage of the VNFs\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 10:35:58 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Badmus", "Idris", ""], ["Laghrissi", "Abdelquoddouss", ""], ["Matinmikko-Blue", "Marja", ""], ["Pouttu", "Ari", ""]]}, {"id": "2001.09683", "submitter": "Jihong Park", "authors": "Jihong Park, Sumudu Samarakoon, Hamid Shiri, Mohamed K. Abdel-Aziz,\n  Takayuki Nishio, Anis Elgabli, Mehdi Bennis", "title": "Extreme URLLC: Vision, Challenges, and Key Enablers", "comments": "7 pages, 6 figures; This work has been submitted to the IEEE for\n  possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Notwithstanding the significant traction gained by ultra-reliable and\nlow-latency communication (URLLC) in both academia and 3GPP standardization,\nfundamentals of URLLC remain elusive. Meanwhile, new immersive and high-stake\ncontrol applications with much stricter reliability, latency and scalability\nrequirements are posing unprecedented challenges in terms of system design and\nalgorithmic solutions. This article aspires at providing a fresh and in-depth\nlook into URLLC by first examining the limitations of 5G URLLC, and putting\nforward key research directions for the next generation of URLLC, coined\neXtreme ultra-reliable and low-latency communication (xURLLC). xURLLC is\nunderpinned by three core concepts: (1) it leverages recent advances in machine\nlearning (ML) for faster and reliable data-driven predictions; (2) it fuses\nboth radio frequency (RF) and non-RF modalities for modeling and combating rare\nevents without sacrificing spectral efficiency; and (3) it underscores the much\nneeded joint communication and control co-design, as opposed to the\ncommunication-centric 5G URLLC. The intent of this article is to spearhead\nbeyond-5G/6G mission-critical applications by laying out a holistic vision of\nxURLLC, its research challenges and enabling technologies, while providing key\ninsights grounded in selected use cases.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 10:50:57 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Park", "Jihong", ""], ["Samarakoon", "Sumudu", ""], ["Shiri", "Hamid", ""], ["Abdel-Aziz", "Mohamed K.", ""], ["Nishio", "Takayuki", ""], ["Elgabli", "Anis", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2001.09697", "submitter": "Borja Molina Coronado", "authors": "Borja Molina-Coronado and Usue Mori and Alexander Mendiburu and Jos\\'e\n  Miguel-Alonso", "title": "Survey of Network Intrusion Detection Methods from the Perspective of\n  the Knowledge Discovery in Databases Process", "comments": null, "journal-ref": null, "doi": "10.1109/TNSM.2020.3016246", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of cyberattacks which target information and communication\nsystems has been a focus of the research community for years. Network intrusion\ndetection is a complex problem which presents a diverse number of challenges.\nMany attacks currently remain undetected, while newer ones emerge due to the\nproliferation of connected devices and the evolution of communication\ntechnology. In this survey, we review the methods that have been applied to\nnetwork data with the purpose of developing an intrusion detector, but contrary\nto previous reviews in the area, we analyze them from the perspective of the\nKnowledge Discovery in Databases (KDD) process. As such, we discuss the\ntechniques used for the capture, preparation and transformation of the data, as\nwell as, the data mining and evaluation methods. In addition, we also present\nthe characteristics and motivations behind the use of each of these techniques\nand propose more adequate and up-to-date taxonomies and definitions for\nintrusion detectors based on the terminology used in the area of data mining\nand KDD. Special importance is given to the evaluation procedures followed to\nassess the different detectors, discussing their applicability in current real\nnetworks. Finally, as a result of this literature review, we investigate some\nopen issues which will need to be considered for further research in the area\nof network security.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:21:05 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Molina-Coronado", "Borja", ""], ["Mori", "Usue", ""], ["Mendiburu", "Alexander", ""], ["Miguel-Alonso", "Jos\u00e9", ""]]}, {"id": "2001.09707", "submitter": "Dimitri Staessens", "authors": "Dimitri Staessens and Sander Vrijders", "title": "Design of the Ouroboros packet network", "comments": "Submitted for possible publication in J.ACM 49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 5-layer TCP and 7-layer OSI models are taught as high-level frameworks in\nwhich the various protocols that are used in computer networks operate.\n  These models provide valid insights in the organization of network\nfunctionalities and protocols; however, the difficulties to fit some crucial\ntechnologies within them hints that they don't provide a complete model for the\norganization of -- and relationships between -- different mechanisms in a\ncomputer network. Recently, a recursive model for computer networks was\nproposed, which organizes networks in layers that conceptually provide the same\nmechanisms through a common interface. Instead of defined by function, these\nlayers are distinguished by scope.\n  We report our research on a model for computer networks. Following a rigorous\nregime alternating design with the evaluation of its implications in an\nimplementation, we converged on a recursive architecture, named Ouroboros. One\nof our main main objectives was to disentangle the fundamental mechanisms that\nare found in computer networks as much as possible. Its distinguishing feature\nis the separation of unicast and broadcast as different mechanisms, giving rise\nto two different types of layers. These unicast and broadcast layers can easily\nbe spotted in today's networks.\n  This article presents the concepts underpinning Ouroboros, details its\norganization and interfaces, and introduces the free software prototype. We\nhope the insights it provides can guide future network design and\nimplementation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:57:05 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Staessens", "Dimitri", ""], ["Vrijders", "Sander", ""]]}, {"id": "2001.09823", "submitter": "Danish Sattar", "authors": "Danish Sattar and Ashraf Matrawy", "title": "Proactive Allocation as Defense for Malicious Co-residency in Sliced 5G\n  Core Networks", "comments": "arXiv admin note: text overlap with arXiv:1901.01443", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious co-residency in virtualized networks poses a real threat. The\nnext-generation mobile networks heavily rely on virtualized infrastructure, and\nnetwork slicing has emerged as a key enabler to support different virtualized\nservices and applications in the 5G network. However, allocating network slices\nefficiently while providing a minimum guaranteed level of service as well as\nproviding defense against the threat of malicious co-residency in a mobile core\nis challenging. To address this question, in our previous work, we proposed an\noptimization model to allocate slices. In this work, we analyze the defense\nagainst the malicious co-residency using our optimization-based allocation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 14:34:44 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Sattar", "Danish", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "2001.09975", "submitter": "Melih Bastopcu", "authors": "Melih Bastopcu and Baturalp Buyukates and Sennur Ulukus", "title": "Optimal Selective Encoding for Timely Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a system in which an information source generates independent and\nidentically distributed status update packets from an observed phenomenon that\ntakes $n$ possible values based on a given pmf. These update packets are\nencoded at the transmitter node to be sent to the receiver node. Instead of\nencoding all $n$ possible realizations, the transmitter node only encodes the\nmost probable $k$ realizations and disregards whenever a realization from the\nremaining $n-k$ values occurs. We find the average age and determine the\nage-optimal real codeword lengths such that the average age at the receiver\nnode is minimized. Through numerical evaluations for arbitrary pmfs, we show\nthat this selective encoding policy results in a lower average age than\nencoding every realization and find the age-optimal $k$. We also analyze a\nrandomized selective encoding policy in which the remaining $n-k$ realizations\nare encoded and sent with a certain probability to further inform the receiver\nat the expense of longer codewords for the selected $k$ realizations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:50:56 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bastopcu", "Melih", ""], ["Buyukates", "Baturalp", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2001.10022", "submitter": "Miguel Isabel", "authors": "Elvira Albert, Miguel G\\'omez-Zamalloa, Miguel Isabel, Albert Rubio,\n  Matteo Sammartino, Alexandra Silva", "title": "Actor-Based Model Checking for SDN Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-Defined Networking (SDN) is a networking paradigm that has become\nincreasingly popular in the last decade. The unprecedented control over the\nglobal behavior of the network it provides opens a range of new opportunities\nfor formal methods and much work has appeared in the last few years on\nproviding bridges between SDN and verification. This article advances this\nresearch line and provides a link between SDN and traditional work on formal\nmethods for verification of concurrent and distributed software---actor-based\nmodelling. We show how SDN programs can be seamlessly modelled using\n\\emph{actors}, and thus existing advanced model checking techniques developed\nfor actors can be directly applied to verify a range of properties of SDN\nnetworks, including consistency of flow tables, violation of safety policies,\nand forwarding loops. Our model checker for SDN networks is available through\nan online web interface, that also provides the SDN actor-models for a number\nof well-known SDN benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 19:06:29 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Albert", "Elvira", ""], ["G\u00f3mez-Zamalloa", "Miguel", ""], ["Isabel", "Miguel", ""], ["Rubio", "Albert", ""], ["Sammartino", "Matteo", ""], ["Silva", "Alexandra", ""]]}, {"id": "2001.10165", "submitter": "Rakesh Kumar Jha Dr", "authors": "Sanjeev Singh and Rakesh Kumar Jha", "title": "A Survey on Software Defined Networking: Architecture for Next\n  Generation Network", "comments": "53", "journal-ref": "J Netw Syst Manage, 2017", "doi": "10.1007/s10922-016-9393-9", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The evolution of software defined networking (SDN) has played a significant\nrole in the development of next-generation networks (NGN). SDN as a\nprogrammable network having service provisioning on the fly has induced a keen\ninterest both in academic world and industry. In this article, a comprehensive\nsurvey is presented on SDN advancement over conventional network. The paper\ncovers historical evolution in relation to SDN, functional architecture of the\nSDN and its related technologies, and OpenFlow standards/protocols, including\nthe basic concept of interfacing of OpenFlow with network elements (NEs) such\nas optical switches. In addition a selective architecture survey has been\nconducted. Our proposed architecture on software defined heterogeneous network,\npoints towards new technology enabling the opening of new vistas in the domain\nof network technology, which will facilitate in handling of huge internet\ntraffic and helps infrastructure and service providers to customize their\nresources dynamically. Besides, current research projects and various\nactivities as being carried out to standardize SDN as NGN by different standard\ndevelopment organizations (SODs) have been duly elaborated to judge how this\ntechnology moves towards standardization.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 04:28:31 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Singh", "Sanjeev", ""], ["Jha", "Rakesh Kumar", ""]]}, {"id": "2001.10189", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Nico Piatkowski and Christian Wietfeld", "title": "LIMITS: Lightweight Machine Learning for IoT Systems with Resource\n  Limitations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting big data knowledge on small devices will pave the way for building\ntruly cognitive Internet of Things (IoT) systems. Although machine learning has\nled to great advancements for IoT-based data analytics, there remains a huge\nmethodological gap for the deployment phase of trained machine learning models.\nFor given resource-constrained platforms such as Microcontroller Units (MCUs),\nmodel choice and parametrization are typically performed based on heuristics or\nanalytical models. However, these approaches are only able to provide rough\nestimates of the required system resources as they do not consider the\ninterplay of hardware, compiler specific optimizations, and code dependencies.\nIn this paper, we present the novel open source framework LIghtweight Machine\nlearning for IoT Systems (LIMITS), which applies a platform-in-the-loop\napproach explicitly considering the actual compilation toolchain of the target\nIoT platform. LIMITS focuses on high level tasks such as experiment automation,\nplatform-specific code generation, and sweet spot determination. The solid\nfoundations of validated low-level model implementations are provided by the\ncoupled well-established data analysis framework Waikato Environment for\nKnowledge Analysis (WEKA). We apply and validate LIMITS in two case studies\nfocusing on cellular data rate prediction and radio-based vehicle\nclassification, where we compare different learning models and real world IoT\nplatforms with memory constraints from 16 kB to 4 MB and demonstrate its\npotential to catalyze the development of machine learning enabled IoT systems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 06:34:35 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Piatkowski", "Nico", ""], ["Wietfeld", "Christian", ""]]}, {"id": "2001.10199", "submitter": "Yong Xiao", "authors": "Yong Xiao and Marwan Krunz", "title": "Distributed Optimization for Energy-efficient Fog Computing in the\n  Tactile Internet", "comments": null, "journal-ref": "Published at IEEE Journal on Selected Areas in Communications,\n  vol. 36, no. 11, pp. 2390 - 2400, November 2018", "doi": "10.1109/JSAC.2018.2872287", "report-no": null, "categories": "cs.NI cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile Internet is an emerging concept that focuses on supporting\nhigh-fidelity, ultra-responsive, and widely available human-to-machine\ninteractions. To reduce the transmission latency and alleviate Internet\ncongestion, fog computing has been advocated as an important component of the\nTactile Internet. In this paper, we focus on energy-efficient design of fog\ncomputing networks that support low-latency Tactile Internet applications. We\ninvestigate two performance metrics: Service response time of end-users and\npower usage efficiency of fog nodes. We quantify the fundamental tradeoff\nbetween these two metrics and then extend our analysis to fog computing\nnetworks involving cooperation between fog nodes. We introduce a novel\ncooperative fog computing concept, referred to as offload forwarding, in which\na set of fog nodes with different computing and energy resources can cooperate\nwith each other. The objective of this cooperation is to balance the workload\nprocessed by different fog nodes, further reduce the service response time, and\nimprove the efficiency of power usage. We develop a distributed optimization\nframework based on dual decomposition to achieve the optimal tradeoff. Our\nframework does not require fog nodes to disclose their private information nor\nconduct back-and-forth negotiations with each other. Two distributed\noptimization algorithms are proposed. One is based on the subgradient method\nwith dual decomposition and the other is based on distributed ADMM-VS. We prove\nthat both algorithms can achieve the optimal workload allocation that minimizes\nthe response time under the given power efficiency constraints of fog nodes.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 07:44:10 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Xiao", "Yong", ""], ["Krunz", "Marwan", ""]]}, {"id": "2001.10202", "submitter": "Sheng Zhou", "authors": "Xi Zheng, Sheng Zhou, Zhisheng Niu", "title": "Beyond Age: Urgency of Information for Timeliness Guarantee in Status\n  Update Systems", "comments": "6 pages, 3 figures, to appear in 6G Summit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely status updating is crucial for future applications that involve remote\nmonitoring and control, such as autonomous driving and Industrial Internet of\nThings (IIoT). Age of Information (AoI) has been proposed to measure the\nfreshness of status updates. However, it is incapable of capturing critical\nsystematic context information that indicates the time-varying importance of\nstatus information, and the dynamic evolution of status. In this paper, we\npropose a context-based metric, namely the Urgency of Information (UoI), to\nevaluate the timeliness of status updates. Compared to AoI, the new metric\nincorporates both time-varying context information and dynamic status\nevolution, which enables the analysis on context-based adaptive status update\nschemes, as well as more effective remote monitoring and control. The\nminimization of average UoI for a status update terminal with an updating\nfrequency constraint is investigated, and an update-index-based adaptive scheme\nis proposed. Simulation results show that the proposed scheme achieves a\nnear-optimal performance with a low computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 08:06:16 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Zheng", "Xi", ""], ["Zhou", "Sheng", ""], ["Niu", "Zhisheng", ""]]}, {"id": "2001.10242", "submitter": "Yao Zhao", "authors": "Yao Zhao, Bo Zhou, Walid Saad, Xiliang Luo", "title": "Age of Information Analysis for Dynamic Spectrum Sharing", "comments": "5 pages, 3 figures, accepted by The 7th IEEE Global Conference on\n  Signal and Information Processing (GlobalSIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely information updates are critical to time-sensitive applications in\nnetworked monitoring and control systems. In this paper, the problem of\nreal-time status update is considered for a cognitive radio network (CRN), in\nwhich the secondary user (SU) can relay the status packets from the primary\nuser (PU) to the destination. In the considered CRN, the SU has opportunities\nto access the spectrum owned by the PU to send its own status packets to the\ndestination. The freshness of information is measured by the age of information\n(AoI) metric. The problem of minimizing the average AoI and energy consumption\nby developing new optimal status update and packet relaying schemes for the SU\nis addressed under an average AoI constraint for the PU. This problem is\nformulated as a constrained Markov decision process (CMDP). The monotonic and\ndecomposable properties of the value function are characterized and then used\nto show that the optimal update and relaying policy is threshold-based with\nrespect to the AoI of the SU. These structures reveal a tradeoff between the\nAoI of the SU and the energy consumption as well as between the AoI of the SU\nand the AoI of the PU. An asymptotically optimal algorithm is proposed.\nNumerical results are then used to show the effectiveness of the proposed\npolicy.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 10:11:51 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Zhao", "Yao", ""], ["Zhou", "Bo", ""], ["Saad", "Walid", ""], ["Luo", "Xiliang", ""]]}, {"id": "2001.10296", "submitter": "Yong Xiao", "authors": "Yong Xiao and Mohammed Hirzallah and Marwan Krunz", "title": "Distributed Resource Allocation for Network Slicing over Licensed and\n  Unlicensed Bands", "comments": null, "journal-ref": "Published at IEEE Journal on Selected Areas in Communications,\n  vol. 36, no. 10, pp. 2260 - 2274, October 2018", "doi": "10.1109/JSAC.2018.2869964", "report-no": null, "categories": "cs.NI cs.IT cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing is considered one of the key enabling technologies for 5G due\nto its ability to customize and \"slice\" a common resource to support diverse\nservices and verticals.This paper introduces a novel inter-operator network\nslicing framework in which multiple mobile network operators (MNOs) can\ncoordinate and jointly slice their accessible spectrum resources in both\nlicensed and unlicensed bands. For licensed band slicing, we propose an\ninter-operator spectrum aggregation method that allows two or more MNOs to\ncooperate and share their licensed bands to support a common set of service\ntypes. We then consider the sharing of unlicensed bands. Because all MNOs enjoy\nequal rights to accessing these bands, we introduce the concept of right\nsharing for MNOs to share and trade their spectrum access rights. We develop a\n{\\em modified back-of-the-envelope (mBoE) method} for MNOs to evaluate their\n{\\em Value-of-Rights (VoR)} when coexisting with other wireless technologies. A\n{\\em network slicing game} based on the overlapping coalition formation game is\nformulated to investigate cooperation between MNOs. We prove that our proposed\ngame always has at least one stable slicing structure that maximizes the social\nwelfare. To implement our proposed framework without requiring MNOs to reveal\nprivate information to other MNOs, we develop a distributed algorithm called\nD-ADMM-PVS. Performance evaluation of our proposed framework is provided using\na discrete-event simulator that is driven by real MNO deployment scenarios\nbased on over 400 base station locations deployed by two primary cellular\noperators in the city of Dublin.Numerical results show that our proposed\nframework can almost double the capacity for all supported services for each\nMNO in an urban setting.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 12:52:16 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Xiao", "Yong", ""], ["Hirzallah", "Mohammed", ""], ["Krunz", "Marwan", ""]]}, {"id": "2001.10300", "submitter": "Yong Xiao", "authors": "Yong Xiao and Marwan Krunz", "title": "Dynamic Network Slicing for Scalable Fog Computing Systems with Energy\n  Harvesting", "comments": null, "journal-ref": "Published at IEEE Journal on Selected Areas in Communications,\n  vol. 36, no. 12, pp. 2640 - 2654, December 2018", "doi": "10.1109/JSAC.2018.2871292", "report-no": null, "categories": "cs.NI cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies fog computing systems, in which cloud data centers can be\nsupplemented by a large number of fog nodes deployed in a wide geographical\narea. Each node relies on harvested energy from the surrounding environment to\nprovide computational services to local users. We propose the concept of\ndynamic network slicing in which a regional orchestrator coordinates workload\ndistribution among local fog nodes, providing partitions/slices of energy and\ncomputational resources to support a specific type of service with certain\nquality-of-service (QoS) guarantees. The resources allocated to each slice can\nbe dynamically adjusted according to service demands and energy availability. A\nstochastic overlapping coalition-formation game is developed to investigate\ndistributed cooperation and joint network slicing between fog nodes under\nrandomly fluctuating energy harvesting and workload arrival processes. We\nobserve that the overall processing capacity of the fog computing network can\nbe improved by allowing fog nodes to maintain a belief function about the\nunknown state and the private information of other nodes. An algorithm based on\na belief-state partially observable Markov decision process (B-POMDP) is\nproposed to achieve the optimal resource slicing structure among all fog nodes.\nWe describe how to implement our proposed dynamic network slicing within the\n3GPP network sharing architecture, and evaluate the performance of our proposed\nframework using the real BS location data of a real cellular system with over\n200 BSs deployed in the city of Dublin. Our numerical results show that our\nframework can significantly improve the workload processing capability of fog\ncomputing networks. In particular, even when each fog node can coordinate only\nwith its closest neighbor, the total amount of workload processed by fog nodes\ncan be almost doubled under certain scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 12:59:52 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Xiao", "Yong", ""], ["Krunz", "Marwan", ""]]}, {"id": "2001.10589", "submitter": "Mahdi Miraz", "authors": "Mahdi H. Miraz and Maaruf Ali", "title": "Blockchain Enabled Smart Contract Based Applications: Deficiencies with\n  the Software Development Life Cycle Models", "comments": null, "journal-ref": "Baltica Journal, Vol. 33, Issue 1, 20th January 2020, ISSN:\n  0067-3064, pp. 101-116, Available:\n  http://www.balticajournal.com/baltica/index.php/jTracker/index/IL1qQ", "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent popularity of Blockchain and other Distributed Ledger\nTechnologies (DLT), blockchain enabled smart contract applications has\nattracted increased research focus. However, the immutability of the blocks,\nwhere the smart contracts are stored, causes conflicts with the traditional\nSoftware Development Life Cycle (SDLC) models usually followed by software\nengineers. This clearly shows the unsuitability of the application of SDLC in\ndesigning blockchain enabled smart contract based applications. This research\narticle addresses this current problem by first exploring the six traditional\nSDLC models, clearly identifying the conflicts in a table with the application\nof smart contracts and advocates that there is an urgent need to develop new\nstandard model(s) to address the arising issues. The concept of both block\nimmutability and contract is introduced. This is further set in a historical\ncontext from legacy smart contracts and blockchain enabled smart contracts\nextending to the difference between \"shallow smart contracts\" and \"deep smart\ncontracts\". To conclude, the traditional SDLC models are unsuitable for\nblockchain enabled smart contract-based applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 03:48:46 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Miraz", "Mahdi H.", ""], ["Ali", "Maaruf", ""]]}, {"id": "2001.10632", "submitter": "Arunan Sivanathan", "authors": "Arunan Sivanathan", "title": "IoT Behavioral Monitoring via Network Traffic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart homes, enterprises, and cities are increasingly being equipped with a\nplethora of Internet of Things (IoT), ranging from smart-lights to security\ncameras. While IoT networks have the potential to benefit our lives, they\ncreate privacy and security challenges not seen with traditional IT networks.\nDue to the lack of visibility, operators of such smart environments are not\noften aware of their IoT assets, let alone whether each IoT device is\nfunctioning properly safe from cyber-attacks. This thesis is the culmination of\nour efforts to develop techniques to profile the network behavioral pattern of\nIoTs, automate IoT classification, deduce their operating context, and detect\nanomalous behavior indicative of cyber-attacks.\n  We begin this thesis by surveying IoT ecosystem, while reviewing current\napproaches to vulnerability assessments, intrusion detection, and behavioral\nmonitoring. For our first contribution, we collect traffic traces and\ncharacterize the network behavior of IoT devices via attributes from traffic\npatterns. We develop a robust machine learning-based inference engine trained\nwith these attributes and demonstrate real-time classification of 28 IoT\ndevices with over 99% accuracy. Our second contribution enhances the\nclassification by reducing the cost of attribute extraction while also\nidentifying IoT device states. Prototype implementation and evaluation\ndemonstrate the ability of our supervised machine learning method to detect\nbehavioral changes for five IoT devices. Our third and final contribution\ndevelops a modularized unsupervised inference engine that dynamically\naccommodates the addition of new IoT devices and/or updates to existing ones,\nwithout requiring system-wide retraining of the model. We demonstrate via\nexperiments that our model can automatically detect attacks and firmware\nchanges in ten IoT devices with over 94% accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 23:13:12 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Sivanathan", "Arunan", ""]]}, {"id": "2001.10728", "submitter": "He Chen", "authors": "He Chen, Zheng Dong, Jian-Kang Zhang, Branka Vucetic", "title": "Design of Non-orthogonal and Noncoherent Massive MIMO for Scalable URLLC\n  Beyond 5G", "comments": "arXiv admin note: text overlap with arXiv:1903.01642", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is to design and optimize a non-orthogonal and noncoherent massive\nmultiple-input multiple-output (MIMO) framework towards enabling scalable\nultra-reliable low-latency communications (sURLLC) in wireless systems beyond\n5G. In this framework, the huge diversity gain associated with the large-scale\nantenna array in massive MIMO systems is leveraged to ensure ultrahigh\nreliability. To reduce the overhead and latency induced by the channel\nestimation process, we advocate the noncoherent communication technique which\ndoes not need the knowledge of instantaneous channel state information (CSI)\nbut only depends on the large-scale fading coefficients for information\ndecoding. To boost the scalability of the system considered, we enable the\nnon-orthogonal channel access of multiple users by devising a new differential\nmodulation scheme to assure that each transmitted signal matrix can be uniquely\ndetermined in the noise-free case and be reliably estimated in noisy cases when\nthe antenna array size is scaled up. The key idea is to make the transmitted\nsignals from multiple users be superimposed properly over the air such that\nwhen the sum-signal is correctly detected, the signals sent by all users can be\nuniquely determined. To further improve the average error performance when the\narray antenna number is large, we propose a max-min Kullback-Leibler (KL)\ndivergence-based design by jointly optimizing the transmitted powers of all\nusers and the sub-constellation assignment among them. Simulation results show\nthat the proposed design significantly outperforms the existing max-min\nEuclidean distance-based counterpart in terms of error performance. Moreover,\nour proposed approach also has a better error performance than the conventional\ncoherent zero-forcing (ZF) receiver with orthogonal channel training,\nparticularly for cell-edge users.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 08:55:00 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 11:08:15 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Chen", "He", ""], ["Dong", "Zheng", ""], ["Zhang", "Jian-Kang", ""], ["Vucetic", "Branka", ""]]}, {"id": "2001.10766", "submitter": "Mustafa Kishk", "authors": "Mustafa A. Kishk and Mohamed-Slim Alouini", "title": "Exploiting Randomly-located Blockages for Large-Scale Deployment of\n  Intelligent Surfaces", "comments": "Accepted in IEEE Journal on Selected Areas in Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the promising technologies for the next generation wireless networks\nis the reconfigurable intelligent surfaces (RISs). This technology provides\nplanar surfaces the capability to manipulate the reflected waves of impinging\nsignals, which leads to a more controllable wireless environment. One potential\nuse case of such technology is providing indirect line-of-sight (LoS) links\nbetween mobile users and base stations (BSs) which do not have direct LoS\nchannels. Objects that act as blockages for the communication links, such as\nbuildings or trees, can be equipped with RISs to enhance the coverage\nprobability of the cellular network through providing extra indirect LoS-links.\nIn this paper, we use tools from stochastic geometry to study the effect of\nlarge-scale deployment of RISs on the performance of cellular networks. In\nparticular, we model the blockages using the line Boolean model. For this\nsetup, we study how equipping a subset of the blockages with RISs will enhance\nthe performance of the cellular network. We first derive the ratio of the\nblind-spots to the total area. Next, we derive the probability that a typical\nmobile user associates with a BS using an RIS. Finally, we derive the\nprobability distribution of the path-loss between the typical user and its\nassociated BS. We draw multiple useful system-level insights from the proposed\nanalysis. For instance, we show that deployment of RISs highly improves the\ncoverage regions of the BSs. Furthermore, we show that to ensure that the ratio\nof blind-spots to the total area is below 10^5, the required density of RISs\nincreases from just 6 RISs/km2 when the density of the blockages is 300\nblockage/km^2 to 490 RISs/km^2 when the density of the blockages is 700\nblockage/km^2.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 11:41:52 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 10:17:37 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 14:13:10 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Kishk", "Mustafa A.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2001.10845", "submitter": "Jun Zhao", "authors": "Yulan Gao, Chao Yong, Zehui Xiong, Dusit Niyato, Yue Xiao, Jun Zhao", "title": "Reconfigurable Intelligent Surface for MISO Systems with Proportional\n  Rate Constraints", "comments": "This paper appears in the Proceedings of IEEE International\n  Conference on Communications (ICC) 2020. Please feel free to contact us for\n  questions or remarks", "journal-ref": "Proceedings of IEEE International Conference on Communications\n  (ICC) 2020", "doi": null, "report-no": null, "categories": "cs.IT cs.NI cs.PF eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the system spectral efficiency (SE) in reconfigurable\nintelligent surface (RIS)-aided multiuser multiple-input single-output (MISO)\nsystems, where RIS can reconfigure the propagation environment via a large\nnumber of controllable and intelligent phase shifters. In order to explore the\nsystem SE performance behavior with user proportional fairness for such a\nsystem, an optimization problem is formulated to maximize the SE by jointly\nconsidering the power allocation at the base station (BS) and phase shift at\nthe RIS, under nonlinear proportional rate fairness constraints. To solve the\nnonconvex optimization problem, an effective solution is developed, which\ncapitalizes on an iterative algorithm with closed-form expressions, i.e.,\nalternatively optimizing the transmit power at the BS and the reflecting phase\nshift at the RIS. Numerical simulations are provided to validate the\ntheoretical analysis and assess the performance of the proposed alternative\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 14:01:54 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Gao", "Yulan", ""], ["Yong", "Chao", ""], ["Xiong", "Zehui", ""], ["Niyato", "Dusit", ""], ["Xiao", "Yue", ""], ["Zhao", "Jun", ""]]}, {"id": "2001.10946", "submitter": "Quan Chen", "authors": "Quan Chen, Jianming Guo, Lei Yang, Xianfeng Liu and Xiaoqian Chen", "title": "Topology Virtualization and Dynamics Shielding Method for LEO Satellite\n  Networks", "comments": "5 pages, 8 figures and 2 tables", "journal-ref": null, "doi": "10.1109/LCOMM.2019.2958132", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual Node (VN) method is widely adopted to handle satellite network\ntopological dynamics. However, conventional VN method is insufficient when\nearth rotation and inter-plane phase difference are considered. An improved VN\nmethod based on Celestial Sphere Division is proposed to overcome the defects\nof the conventional method. An optimized inter-satellite link connecting mode\nis derived to achieve maximal available links. The optimal VN division solution\nand addressing scheme are designed to generate a nearly static virtual network\nand solve the asynchronous switches caused by inter-plane phase difference.\nComparison results demonstrate the advantages of proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:37:49 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Chen", "Quan", ""], ["Guo", "Jianming", ""], ["Yang", "Lei", ""], ["Liu", "Xianfeng", ""], ["Chen", "Xiaoqian", ""]]}, {"id": "2001.11014", "submitter": "Melih Bastopcu", "authors": "Melih Bastopcu and Sennur Ulukus", "title": "Partial Updates: Losing Information for Freshness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an information updating system where a source produces updates as\nrequested by a transmitter. The transmitter further processes these updates in\norder to generate $partial$ $updates$, which have smaller information compared\nto the original updates, to be sent to a receiver. We study the problem of\ngenerating partial updates, and finding their corresponding real-valued\ncodeword lengths, in order to minimize the average age experienced by the\nreceiver, while maintaining a desired level of mutual information between the\noriginal and partial updates. This problem is NP hard. We relax the problem and\ndevelop an alternating minimization based iterative algorithm that generates a\npmf for the partial updates, and the corresponding age-optimal real-valued\ncodeword length for each update. We observe that there is a tradeoff between\nthe attained average age and the mutual information between the original and\npartial updates.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:50:03 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Bastopcu", "Melih", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2001.11162", "submitter": "Bo Zhou", "authors": "Bo Zhou and Walid Saad", "title": "On the Age of Information in Internet of Things Systems with Correlated\n  Devices", "comments": "Withdrawn from CISS 2020, as it has been cancelled due to the\n  COVID-19 outbreak", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a real-time Internet of Things (IoT) monitoring system is\nconsidered in which multiple IoT devices must transmit timely updates on the\nstatus information of a common underlying physical process to a common\ndestination. In particular, a real-world IoT scenario is considered in which\nmultiple (partially) observed status information by different IoT devices are\nrequired at the destination, so that the real-time status of the physical\nprocess can be properly re-constructed. By taking into account such correlated\nstatus information at the IoT devices, the problem of IoT device scheduling is\nstudied in order to jointly minimize the average age of information (AoI) at\nthe destination and the average energy cost at the IoT devices. Particularly,\ntwo types of IoT devices are considered: Type-I devices whose status updates\nrandomly arrive and type-II devices whose status updates can be\ngenerated-at-will with an associated sampling cost. This stochastic problem is\nformulated as an infinite horizon average cost Markov decision process (MDP).\nThe optimal scheduling policy is shown to be threshold-based with respect to\nthe AoI at the destination, and the threshold is non-increasing with the\nchannel condition of each device. For a special case in which all devices are\ntype-II, the original MDP can be reduced to an MDP with much smaller state and\naction spaces. The optimal policy is further shown to have a similar\nthreshold-based structure and the threshold is non-decreasing with an energy\ncost function of the devices. Simulation results illustrate the structure of\nthe optimal policy and show the effectiveness of the optimal policy compared\nwith a myopic baseline policy.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 03:35:02 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 01:10:40 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 15:47:18 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Zhou", "Bo", ""], ["Saad", "Walid", ""]]}, {"id": "2001.11167", "submitter": "Rohit Singh Mr", "authors": "Rohit Singh and Douglas Sicker", "title": "An Analytical Model for Efficient Indoor THz Access Point Deployment", "comments": "8 pages, 14 figures, 3 Tables, Accepted at IEEE Wireless\n  Communications and Networking Conference (WCNC) 2020, 6-9 April 2020, Seoul,\n  South Korea", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-densification of user equipment (UE) and access points (APs) are\nanticipated to take a toll on the future spectrum needs. Higher frequency\nbands, such as mmWave ($30$-$300GHz$) and THz spectrum ($0.3$-$10THz$), can be\nused to cater to the high-throughput needs of ultra-dense networks. These\nhigh-frequency bands have a tremendous amount of \\textit{green-filed contiguous\nspectrum}, ranging in hundreds of $GHz$. However, these bands, especially the\nTHz bands, face numerous challenges, such as high spreading, absorption, and\npenetration losses. To combat these challenges, the THz-APs need to be either\nequipped with high transmit power, high antenna gains (i.e., narrow antenna\nbeams), or limit the communication to short-ranges. All of these factors are\nbounded due to technical or economic challenges, which will result in a\n\\textit{\"distance-power dilemma\"} while deciding on the deployment strategy of\nTHz-APs. In this paper, we present an analytical model to deploy THz-APs in an\nindoor setting efficiently. We further show through extensive numerical\nanalysis, the optimal number of APs and optimal room length for different\nblocks of the THz spectrum. Furthermore, these THz-APs need to be efficiently\npacked to avoid outages due to handoffs, which can add more complexity to the\ndilemma. To mitigate the packing problem, we propose two solutions over the\noptimal solution: (a) Radius Increase, and (b) Repeater Assistance, and present\nan analytical model for each.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 03:51:24 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Singh", "Rohit", ""], ["Sicker", "Douglas", ""]]}, {"id": "2001.11208", "submitter": "Israel Leyva-Mayorga", "authors": "Israel Leyva-Mayorga, Radoslaw Kotaba, Fresia Maria, and Petar\n  Popovski", "title": "Wireless Mesh Networking with Devices Equipped with Multi-Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless connectivity is rapidly becoming ubiquitous and affordable. As a\nconsequence, most wireless devices are nowadays equipped with\nmulti-connectivity, that is, availability of multiple radio access technologies\n(RATs). Each of these RATs has different characteristics that can be suitably\nutilized for different connectivity tasks. For example, a long-range low-rate\nRAT can be used for topology management and coordination, whereas a short-range\nhigh-rate RAT for data transmission. In this paper, we introduce a distributed\nconsensus protocol for the hierarchical organization of Wireless Mesh Networks\n(WMNs) with devices using multiple RATs. Our protocol considers three\nhierarchical roles after the initial setup: Master, cluster head (CH), and\ncluster member (CM). The Master coordinates the use of all RATs, whereas the\nCHs coordinate all but the RAT with the longest transmission range. The initial\nsetup takes place immediately after powering on the devices, after which the\ndevices self-organize in a distributed manner by means of a consensus to elect\nthe Masters and CHs. The resulting interconnected structure is based on the\nconnectivity graphs created with the different RATs. The distributed consensus\nprotocol operates with a minimal amount of network information and demonstrates\nhigh networking performance.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 08:38:11 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Leyva-Mayorga", "Israel", ""], ["Kotaba", "Radoslaw", ""], ["Maria", "Fresia", ""], ["Popovski", "Petar", ""]]}, {"id": "2001.11370", "submitter": "Steffen Lindner", "authors": "Steffen Lindner and Daniel Merling and Marco H\\\"aberle and Michael\n  Menth", "title": "P4-Protect: 1+1 Path Protection for P4", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  1+1 protection is a method to secure traffic between two nodes against\nfailures in between. The sending node duplicates the traffic and forwards it\nover two disjoint paths. The receiving node assures that only a single copy of\nthe traffic is further forwarded to its destination. In contrast to other\nprotection schemes, this method prevents almost any packet loss in case of\nfailures. 1+1 protection is usually applied on the optical layer, on Ethernet,\nor on MPLS.\n  In this work we propose the application of 1+1 for P4-based IP networks. We\ndefine an 1+1 protection header for that purpose. We describe the behavior of\nsending and receiving nodes and provide a P4-based implementation for the BMv2\nsoftware switch and the hardware switch Tofino Edgecore Wedge 100BF-32X. We\nillustrate how to secure traffic, e.g. individual TCP flows, on the Internet\nwith this approach. Finally, we present performance results showing that the\nP4-based implementation efficiently works on the Tofino Edgecore Wedge\n100BF-32X.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 14:51:32 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 14:44:44 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Lindner", "Steffen", ""], ["Merling", "Daniel", ""], ["H\u00e4berle", "Marco", ""], ["Menth", "Michael", ""]]}, {"id": "2001.11500", "submitter": "Melih Bastopcu", "authors": "Melih Bastopcu and Sennur Ulukus", "title": "Who Should Google Scholar Update More Often?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a resource-constrained updater, such as Google Scholar, which\nwishes to update the citation records of a group of researchers, who have\ndifferent mean citation rates (and optionally, different importance\ncoefficients), in such a way to keep the overall citation index as up to date\nas possible. The updater is resource-constrained and cannot update citations of\nall researchers all the time. In particular, it is subject to a total update\nrate constraint that it needs to distribute among individual researchers. We\nuse a metric similar to the age of information: the long-term average\ndifference between the actual citation numbers and the citation numbers\naccording to the latest updates. We show that, in order to minimize this\ndifference metric, the updater should allocate its total update capacity to\nresearchers proportional to the $square$ $roots$ of their mean citation rates.\nThat is, more prolific researchers should be updated more often, but there are\ndiminishing returns due to the concavity of the square root function. More\ngenerally, our paper addresses the problem of optimal operation of a\nresource-constrained sampler that wishes to track multiple independent counting\nprocesses in a way that is as up to date as possible.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 18:51:01 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 19:34:14 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bastopcu", "Melih", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2001.11565", "submitter": "Ke Li Kl", "authors": "Joseph Billingsley, Ke Li, Wang Miao, Geyong Min, Nektarios Georgalas", "title": "Routing-Led Placement of VNFs in Arbitrary Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever increasing demand for computing resources has led to the creation of\nhyperscale datacentres with tens of thousands of servers. As demand continues\nto rise, new technologies must be incorporated to ensure high quality services\ncan be provided without the damaging environmental impact of high energy\nconsumption. Virtualisation technology such as network function virtualisation\n(NFV) allows for the creation of services by connecting component parts known\nas virtual network functions (VNFs). VNFs cam be used to maximally utilise\navailable datacentre resources by optimising the placement and routes of VNFs,\nto maintain a high quality of service whilst minimising energy costs. Current\nresearch on this problem has focussed on placing VNFs and considered routing as\na secondary concern. In this work we argue that the opposite approach, a\nrouting-led approach is preferable. We propose a novel routing-led algorithm\nand analyse each of the component parts over a range of different topologies on\nproblems with up to 16000 variables and compare its performance against a\ntraditional placement based algorithm. Empirical results show that our\nrouting-led algorithm can produce significantly better, faster solutions to\nlarge problem instances on a range of datacentre topologies.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:06:15 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Billingsley", "Joseph", ""], ["Li", "Ke", ""], ["Miao", "Wang", ""], ["Min", "Geyong", ""], ["Georgalas", "Nektarios", ""]]}, {"id": "2001.11567", "submitter": "Shuvam Chakraborty", "authors": "Shuvam Chakraborty, Hesham Mohammed, Dola Saha", "title": "Learning from Peers at the Wireless Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last mile connection is dominated by wireless links where heterogeneous\nnodes share the limited and already crowded electromagnetic spectrum. Current\ncontention based decentralized wireless access system is reactive in nature to\nmitigate the interference. In this paper, we propose to use neural networks to\nlearn and predict spectrum availability in a collaborative manner such that its\navailability can be predicted with a high accuracy to maximize wireless access\nand minimize interference between simultaneous links. Edge nodes have a wide\nrange of sensing and computation capabilities, while often using different\noperator networks, who might be reluctant to share their models. Hence, we\nintroduce a peer to peer Federated Learning model, where a local model is\ntrained based on the sensing results of each node and shared among its peers to\ncreate a global model. The need for a base station or access point to act as\ncentralized parameter server is replaced by empowering the edge nodes as\naggregators of the local models and minimizing the communication overhead for\nmodel transmission. We generate wireless channel access data, which is used to\ntrain the local models. Simulation results for both local and global models\nshow over 95% accuracy in predicting channel opportunities in various network\ntopology.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:11:13 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Chakraborty", "Shuvam", ""], ["Mohammed", "Hesham", ""], ["Saha", "Dola", ""]]}, {"id": "2001.11574", "submitter": "Dong Ma", "authors": "Dong Ma, Yuezhong Wu, Ming Ding, Mahbub Hassan, Wen Hu", "title": "Skin-MIMO: Vibration-based MIMO Communication over Human Skin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the feasibility of Multiple-Input-Multiple-Output (MIMO)\ncommunication through vibrations over human skin. Using off-the-shelf motors\nand piezo transducers as vibration transmitters and receivers, respectively, we\nbuild a 2x2 MIMO testbed to collect and analyze vibration signals from real\nsubjects. Our analysis reveals that there exist multiple independent vibration\nchannels between a pair of transmitter and receiver, confirming the feasibility\nof MIMO. Unfortunately, the slow ramping of mechanical motors and rapidly\nchanging skin channels make it impractical for conventional channel sounding\nbased channel state information (CSI) acquisition, which is critical for\nachieving MIMO capacity gains. To solve this problem, we propose Skin-MIMO, a\ndeep learning based CSI acquisition technique to accurately predict CSI\nentirely based on inertial sensor (accelerometer and gyroscope) measurements at\nthe transmitter, thus obviating the need for channel sounding. Based on\nexperimental vibration data, we show that Skin-MIMO can improve MIMO capacity\nby a factor of 2.3 compared to Single-Input-Single-Output (SISO) or open-loop\nMIMO, which do not have access to CSI. A surprising finding is that gyroscope,\nwhich measures the angular velocity, is found to be superior in predicting skin\nvibrations than accelerometer, which measures linear acceleration and used\nwidely in previous research for vibration communications over solid objects.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:33:02 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Ma", "Dong", ""], ["Wu", "Yuezhong", ""], ["Ding", "Ming", ""], ["Hassan", "Mahbub", ""], ["Hu", "Wen", ""]]}, {"id": "2001.11783", "submitter": "Yi Zhong", "authors": "Yi Zhong, Guoqiang Mao, Xiaohu Ge, Fu-Chun Zheng", "title": "Spatio-temporal Modeling for Massive and Sporadic Access", "comments": "IEEE Journal on Selected Areas in Communications, accepted to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vision for smart city imperiously appeals to the implementation of\nInternet-of-Things (IoT), some features of which, such as massive access and\nbursty short packet transmissions, require new methods to enable the cellular\nsystem to seamlessly support its integration. Rigorous theoretical analysis is\nindispensable to obtain constructive insight for the networking design of\nmassive access. In this paper, we propose and define the notion of massive and\nsporadic access (MSA) to quantitatively describe the massive access of IoT\ndevices. We evaluate the temporal correlation of interference and successful\ntransmission events, and verify that such correlation is negligible in the\nscenario of MSA. In view of this, in order to resolve the difficulty in any\nprecise spatio-temporal analysis where complex interactions persist among the\nqueues, we propose an approximation that all nodes are moving so fast that\ntheir locations are independent at different time slots. Furthermore, we\ncompare the original static network and the equivalent network with high\nmobility to demonstrate the effectiveness of the proposed approximation\napproach. The proposed approach is promising for providing a convenient and\ngeneral solution to evaluate and design the IoT network with massive and\nsporadic access.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:00:47 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 10:32:20 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Zhong", "Yi", ""], ["Mao", "Guoqiang", ""], ["Ge", "Xiaohu", ""], ["Zheng", "Fu-Chun", ""]]}, {"id": "2001.11961", "submitter": "Yung-Fu Chen", "authors": "Yung-Fu Chen and Anish Arora", "title": "Middle-mile Network Optimization in Rural Wireless Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The status quo of limited broadband connectivity in rural areas motivates the\nneed for fielding alternatives such as long-distance wireless mesh networks. A\nkey aspect of fielding wireless meshes cost-effectively is planning how to\nconnect the last-mile networks to the core network service providers (i.e., the\nnetwork between the edge access terminals and the landline / optical fiber\nterminals) with minimal infrastructure cost and throughput constraints. This\nso-called middle-mile network optimization, which includes topology\nconstruction, tower height assignment, antenna and orientation selection, as\nwell as transmit power assignment, is known to be a computationally hard\nproblem.\n  In this paper, we provide the first polynomial time approximation solution\nfor a generalized version of the middle-mile network optimization problem,\nwherein point-to-point (i.e., WiFi p2p) links are deployed to bridge last-mile\nnetworks. Our solution has a cost performance ratio of\n$O(\\ln{|A|}+\\frac{|B|}{|A|}+\\frac{|A|+|B|}{\\gamma})$, where A and B\nrespectively denote the number of terminals and non-terminals and $\\gamma$ is\nthe ratio of $\\frac{link\\ capacity}{terminal\\ demand}$. Furthermore, our\nsolution extends to hybrid networks, i.e., point-to-multipoint (i.e., WiFi\np2mp) or omnidirectional (i.e., TV White Space) can serve as hyperlinks in\naddition to point-to-point links, to further reduce the cost of wireless links.\nWe provide a complementary heuristic for our middle-mile network optimization\nsolution that adds hyperlinks if and only if they reduce the cost.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 17:24:23 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 13:11:03 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Chen", "Yung-Fu", ""], ["Arora", "Anish", ""]]}, {"id": "2001.11963", "submitter": "Liangping Ma", "authors": "Liangping Ma, John Kaewell", "title": "Fast Monte Carlo Dropout and Error Correction for Radio Transmitter\n  Classification", "comments": "Work completed in October, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo dropout may effectively capture model uncertainty in deep\nlearning, where a measure of uncertainty is obtained by using multiple\ninstances of dropout at test time. However, Monte Carlo dropout is applied\nacross the whole network and thus significantly increases the computational\ncomplexity, proportional to the number of instances. To reduce the\ncomputational complexity, at test time we enable dropout layers only near the\noutput of the neural network and reuse the computation from prior layers while\nkeeping, if any, other dropout layers disabled. Additionally, we leverage the\nside information about the ideal distributions for various input samples to do\n`error correction' on the predictions. We apply these techniques to the radio\nfrequency (RF) transmitter classification problem and show that the proposed\nalgorithm is able to provide better prediction uncertainty than the simple\nensemble average algorithm and can be used to effectively identify transmitters\nthat are not in the training data set while correctly classifying transmitters\nit has been trained on.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 17:26:13 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Ma", "Liangping", ""], ["Kaewell", "John", ""]]}]