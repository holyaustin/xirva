[{"id": "1908.00080", "submitter": "Faraz Hussain", "authors": "M.G. Sarwar Murshed, Christopher Murphy, Daqing Hou, Nazar Khan,\n  Ganesh Ananthanarayanan, Faraz Hussain", "title": "Machine Learning at the Network Edge: A Survey", "comments": "35 pages, 4 figures; restructured text to combine ML/DL into a single\n  section; updated tables/figures; added a new table summarizing major ML edge\n  applications, fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource-constrained IoT devices, such as sensors and actuators, have become\nubiquitous in recent years. This has led to the generation of large quantities\nof data in real-time, which is an appealing target for AI systems. However,\ndeploying machine learning models on such end-devices is nearly impossible. A\ntypical solution involves offloading data to external computing systems (such\nas cloud servers) for further processing but this worsens latency, leads to\nincreased communication costs, and adds to privacy concerns. To address this\nissue, efforts have been made to place additional computing devices at the edge\nof the network, i.e close to the IoT devices where the data is generated.\nDeploying machine learning systems on such edge computing devices alleviates\nthe above issues by allowing computations to be performed close to the data\nsources. This survey describes major research efforts where machine learning\nsystems have been deployed at the edge of computer networks, focusing on the\noperational aspects including compression techniques, tools, frameworks, and\nhardware used in successful applications of intelligent edge systems.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 20:23:00 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 18:55:40 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 23:00:32 GMT"}, {"version": "v4", "created": "Sun, 23 May 2021 19:52:16 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Murshed", "M. G. Sarwar", ""], ["Murphy", "Christopher", ""], ["Hou", "Daqing", ""], ["Khan", "Nazar", ""], ["Ananthanarayanan", "Ganesh", ""], ["Hussain", "Faraz", ""]]}, {"id": "1908.00418", "submitter": "Yang Xin", "authors": "Hui Li, Jiangxing Wu, Xin Yang, Han Wang, Julong Lan, Ke Xu, Yunyong\n  Zhang, Jinwu Wei, Shisheng Chen, Wei Liang, Fusheng Zhu, Yiqin Lu, Wai Ho\n  Mow, Yeung Wai-Ho, Zefeng Zheng, Peng Yi, Xinsheng Ji, Qinrang Liu, Wei Li,\n  Kaiyan Tian, Jiang Zhu, Jiaxing Song, Yijun Liu, Junfeng Ma, Jiawei Hu, Rui\n  Xu, Jiansen Huang, Guohua Wei, Jiuhua Qi, Ting Huang, Kaixuan Xing", "title": "MIN: Co-Governing Multi-Identifier Network Architecture and its\n  Prototype on Operator's Network", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IP protocol is the core of TCP/IP network layer. However, since IP address\nand its Domain Name are allocated and managed by a single agency, there are\nrisks of centralization. The semantic overload of IP address also reduces its\nscalability and mobility, which further hinders the security.\n  This paper proposes a co-governing Multi-Identifier Network (MIN)\narchitecture that constructs a network layer with parallel coexistence of\nmultiple identifiers, including identity, content, geographic information, and\nIP address. On the management plane, we develop an efficient management system\nusing consortium blockchain with voting consensus, so the network can\nsimultaneously manage and support by hundreds or thousands of nodes with high\nthroughput. On the data plane, we propose an algorithm merging hash table and\nprefix tree (HTP) for FIB, which avoids the false-negative error and can\ninter-translate different identifiers with tens of billions of entries.\nFurther, we propose a scheme to transport IP packets using CCN as a tunnel for\nsupporting progressive deployment. We deployed the prototype of MIN to the\nlargest operators' network in Mainland China, Hongkong and Macao, and\ndemonstrated that the network can register identifier under co-governing\nconsensus algorithm, support VoD service very well.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 14:12:27 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Li", "Hui", ""], ["Wu", "Jiangxing", ""], ["Yang", "Xin", ""], ["Wang", "Han", ""], ["Lan", "Julong", ""], ["Xu", "Ke", ""], ["Zhang", "Yunyong", ""], ["Wei", "Jinwu", ""], ["Chen", "Shisheng", ""], ["Liang", "Wei", ""], ["Zhu", "Fusheng", ""], ["Lu", "Yiqin", ""], ["Mow", "Wai Ho", ""], ["Wai-Ho", "Yeung", ""], ["Zheng", "Zefeng", ""], ["Yi", "Peng", ""], ["Ji", "Xinsheng", ""], ["Liu", "Qinrang", ""], ["Li", "Wei", ""], ["Tian", "Kaiyan", ""], ["Zhu", "Jiang", ""], ["Song", "Jiaxing", ""], ["Liu", "Yijun", ""], ["Ma", "Junfeng", ""], ["Hu", "Jiawei", ""], ["Xu", "Rui", ""], ["Huang", "Jiansen", ""], ["Wei", "Guohua", ""], ["Qi", "Jiuhua", ""], ["Huang", "Ting", ""], ["Xing", "Kaixuan", ""]]}, {"id": "1908.00635", "submitter": "Muhammad Usama", "authors": "Muhammad Usama, Junaid Qadir, and Ala Al-Fuqaha", "title": "Black-box Adversarial ML Attack on Modulation Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many deep neural networks (DNN) based modulation classification\nschemes have been proposed in the literature. We have evaluated the robustness\nof two famous such modulation classifiers (based on the techniques of\nconvolutional neural networks and long short term memory) against adversarial\nmachine learning attacks in black-box settings. We have used Carlini \\& Wagner\n(C-W) attack for performing the adversarial attack. To the best of our\nknowledge, the robustness of these modulation classifiers has not been\nevaluated through C-W attack before. Our results clearly indicate that\nstate-of-art deep machine learning-based modulation classifiers are not robust\nagainst adversarial attacks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 21:20:38 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1908.00953", "submitter": "Soheil Abbasloo", "authors": "Soheil Abbasloo, H. Jonathan Chao", "title": "Bounding Queue Delay in Cellular Networks to Support Ultra-Low Latency\n  Applications", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the current active queue management (AQM) designs have major issues\nincluding severe hardship of being tuned for highly fluctuated cellular access\nlink bandwidths. Consequently, most of the cellular network providers either\ngive up using AQMs or use conservative offline configurations for them.\nHowever, these choices will significantly impact the performance of the\nemerging interactive and highly delay sensitive applications such as virtual\nreality and vehicle-to-vehicle communications.\n  Therefore, in this paper, we investigate the problems of existing AQM schemes\nand show that they are not suitable options to support ultra-low latency\napplications in a highly dynamic network such as current and future cellular\nnetworks. Moreover, we believe that achieving good performance does not\nnecessarily come from complex drop rate calculation algorithms or complicated\nAQM techniques. Consequently, we propose BoDe an extremely simple and\ndeployment friendly AQM scheme to bound the queuing delay of served packets and\nsupport ultra-low latency applications.\n  We have evaluated BoDe in extensive trace-based evaluations using cellular\ntraces from 3 different service providers in the US and compared its\nperformance with state-of-the-art AQM designs including CoDel and PIE under a\nvariety of streaming applications, video conferencing applications, and various\nrecently proposed TCP protocols. Results show that despite BoDe's simple\ndesign, it outperforms other schemes and achieves significantly lower queuing\ndelay in all tested scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 16:55:03 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Abbasloo", "Soheil", ""], ["Chao", "H. Jonathan", ""]]}, {"id": "1908.01119", "submitter": "Rahul  Singh", "authors": "Rahul Singh, Gopal Krishna Kamath and P. R. Kumar", "title": "Optimal Information Updating based on Value of Information", "comments": "Accepted in Allerton 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of how to optimally schedule data packets over an\nunreliable channel in order to minimize the estimation error of a\nsimple-to-implement remote linear estimator using a constant \"Kalman'' gain to\ntrack the state of a Gauss Markov process. The remote estimator receives\ntime-stamped data packets which contain noisy observations of the process.\nAdditionally, they also contain the information about the \"quality'' of the\nsensor\\ source, i.e., the variance of the observation noise that was used to\ngenerate the packet. In order to minimize the estimation error, the scheduler\nneeds to use both while prioritizing packet transmissions. It is shown that a\nsimple index rule that calculates the value of information (VoI) of each\npacket, and then schedules the packet with the largest current value of VoI, is\noptimal. The VoI of a packet decreases with its age, and increases with the\nprecision of the source. Thus, we conclude that, for constant filter gains, a\npolicy which minimizes the age of information does not necessarily maximize the\nestimator performance.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 04:54:48 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Singh", "Rahul", ""], ["Kamath", "Gopal Krishna", ""], ["Kumar", "P. R.", ""]]}, {"id": "1908.01334", "submitter": "Haoyue Tang", "authors": "Haoyue Tang, Jintao Wang, Linqi Song, Jian Song", "title": "Scheduling to Minimize Age of Information in Multi-State Time-Varying\n  Networks with Power Constraints", "comments": "To appear in part in Allerton 2019, fix typos in the proof of Theorem\n  3, thanks to Mr. Jingzhou Sun", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how to collect fresh data in time-varying networks\nwith power constrained users. We measure data freshness from the perspective of\nthe central controller by using the metric Age of Information, namely the time\nelapsed since the generation time-stamp of the freshest information. We wonder\nwhat is the minimum AoI performance the network can achieve and how to design\nscheduling algorithms to approach it. To answer these questions when scheduling\ndecisions are restricted to bandwidth constraint, we first decouple the\nmulti-user scheduling problem into a single user constrained Markov decision\nprocess (CMDP) through relaxation of the hard bandwidth constraint. Next we\nexploit the threshold structure of the optimal policy for the decoupled single\nuser CMDP and obtain the optimum solution through linear programming (LP).\nFinally, an asymptotic optimal truncated policy that can satisfy the hard\nbandwidth constraint is built upon the optimal solution to each of the\ndecoupled single-user sub-problem. The performance is verified through\nsimulations. Our investigation shows that to obtain a small AoI performance,\nthe scheduler exploits good channels to schedule users supported by limited\npower. Users equipped with enough transmission power are updated in a timely\nmanner such that the bandwidth constraint can be satisfied.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 12:50:01 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 14:34:17 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 16:28:15 GMT"}, {"version": "v4", "created": "Sun, 8 Sep 2019 03:16:13 GMT"}, {"version": "v5", "created": "Thu, 31 Oct 2019 13:27:56 GMT"}, {"version": "v6", "created": "Tue, 26 Nov 2019 03:51:15 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Tang", "Haoyue", ""], ["Wang", "Jintao", ""], ["Song", "Linqi", ""], ["Song", "Jian", ""]]}, {"id": "1908.01405", "submitter": "Qiao Kang", "authors": "Qiao Kang, Lei Xue, Adam Morrison, Yuxin Tang, Ang Chen, Xiapu Luo", "title": "Programmable In-Network Security for Context-aware BYOD Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bring Your Own Device (BYOD) has become the new norm in enterprise networks,\nbut BYOD security remains a top concern. Context-aware security, which enforces\naccess control based on dynamic runtime context, holds much promise. Recent\nwork has developed SDN solutions to collect device context for network-wide\naccess control in a central controller. However, the central controller poses a\nbottleneck that can become an attack target, and processing context changes at\nremote software has low agility.\n  We present a new paradigm, programmable in-network security (Poise), which is\nenabled by the emergence of programmable switches. At the heart of Poise is a\nnovel switch primitive, which can be programmed to support a wide range of\ncontext-aware policies in hardware. Users of Poise specify concise policies,\nand Poise compiles them into different instantiations of the security primitive\nin P4. Compared to centralized SDN defenses, Poise is resilient to control\nplane saturation attacks, and it dramatically increases defense agility.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 21:49:02 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kang", "Qiao", ""], ["Xue", "Lei", ""], ["Morrison", "Adam", ""], ["Tang", "Yuxin", ""], ["Chen", "Ang", ""], ["Luo", "Xiapu", ""]]}, {"id": "1908.01475", "submitter": "Gholamreza Kakamanshadi", "authors": "Gholamreza Kakamanshadi, Savita Gupta and Sukhwinder Singh", "title": "Fuzzy informer homed routing protocol for wireless sensor network", "comments": "18 pages,13 Figures, 7 Tables", "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC), 2019", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wireless sensor network consists of several sensor nodes. Sensor nodes\ncollaborate to collect meaningful environmental information and send them to\nthe base station. During these processes, nodes are prone to failure, due to\nthe energy depletion, hardware or software failure, etc. Therefore, fault\ntolerance and energy efficiency are two important objectives for reliable\npacket delivery. To address these objectives a novel method called fuzzy\ninformer homed routing protocol is introduced. The proposed method tries to\ndistribute the workload between every sensor node. A fuzzy logic approach is\nused to handle uncertainties in cluster head communication range estimation.\nThe simulation results show that the proposed method can significantly reduce\nenergy consumption as compared with IHR and DHR protocols. Furthermore, results\nrevealed that it performs better than IHR and DHR protocols in terms of first\nnode dead and half of the nodes alive, throughput and total remaining energy.\nIt is concluded that the proposed protocol is a stable and energy efficient\nfault tolerance algorithm for wireless sensor networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 05:36:55 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kakamanshadi", "Gholamreza", ""], ["Gupta", "Savita", ""], ["Singh", "Sukhwinder", ""]]}, {"id": "1908.01503", "submitter": "Onur Ayan", "authors": "Onur Ayan and Mikhail Vilgelm and Wolfgang Kellerer", "title": "Optimal Scheduling for Discounted Age Penalty Minimization in Multi-Loop\n  Networked Control", "comments": "Accepted to IEEE Consumer Communications & Networking Conference\n  (CCNC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Age-of-information (AoI) is a metric quantifying information freshness at the\nreceiver. Since AoI combines packet generation frequency, packet loss, and\ndelay into a single metric, it has received a lot of research attention as an\ninterface between communication network and application. In this work, we apply\nAoI to the problem of wireless scheduling for multi-loop networked control\nsystems (NCS), i.e., feedback control loops closed over a shared wireless\nnetwork. We model the scheduling problem as a Markov decision process (MDP)\nwith AoI as its observable states and derive a relation of control system error\nand AoI. We further derive a stationary scheduling policy to minimize control\nerror over an infinite horizon. We show that our scheduler outperforms the\nstate-of-the-art scheduling policies for NCS. To the best of our knowledge,\nthis is the first work proposing an AoI-based wireless scheduling policy that\nminimizes the control error over an infinite horizon for multi-loop NCS.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 07:58:19 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 11:21:31 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 09:48:21 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Ayan", "Onur", ""], ["Vilgelm", "Mikhail", ""], ["Kellerer", "Wolfgang", ""]]}, {"id": "1908.01834", "submitter": "Vojislav B. Mi\\v{s}i\\'c", "authors": "M. Zulfiker Ali and Jelena Mi\\v{s}i\\'c and Vojislav B. Mi\\v{s}i\\'c", "title": "Performance analysis of IEEE 802.11ax heterogeneous network in the\n  presence of hidden terminals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance improvement has been among the foci of all previous amendments of\nIEEE 802.11 protocol. In addition, the draft high efficiency (HE) amendment\nIEEE 802.11ax, proposed by TGax, aims at increasing network performance. One of\nthe main obstacles to improving spectral and power efficiency is the presence\nof hidden terminals which degrade throughput, in particular in uplink\ntransmission. IEEE 802.11ax does provide mechanisms such as trigger based\nuplink transmission that mitigate this degradation to some extent, but are\nincapable of eliminating it, esp. at high arrival rates. To combat the hidden\nterminal problem, we propose to increase the carrier sensing threshold (CSTH)\nof STAs during association with an HE access point. Our results confirm that\nthe proposed mechanism can lead to significant reduction of collision\nprobability in uplink transmission.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 20:14:35 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Ali", "M. Zulfiker", ""], ["Mi\u0161i\u0107", "Jelena", ""], ["Mi\u0161i\u0107", "Vojislav B.", ""]]}, {"id": "1908.01889", "submitter": "Shouqian Shi", "authors": "Shouqian Shi, Chen Qian, Ye Yu, Xin Li, Ying Zhang and Xiaozhou Li", "title": "Concury: A Fast and Light-weighted Software Load Balancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A load balancer (LB) is a vital network function for cloud services to\nbalance the load amongst resources. Stateful software LBs that run on commodity\nservers provides flexibility, cost-efficiency, and packet consistency. However\ncurrent designs have two main limitations: 1) states are stored as digests\nwhich may cause packet inconsistency due to digest collisions; 2) the data\nplane needs to update for every new connection, and frequent updates hurt\nthroughput and packet consistency. In this work, we present a new software\nstateful LB called Concury, which is the first solution to solve these\nproblems. The key innovation of Concury is an algorithmic approach to store and\nlook up large network states with frequent connection arrivals, which is\nsuccinct in memory cost, consistent under network changes, and incurs\ninfrequent data plane updates. The evaluation results show that the Concury\nalgorithm provides 4x throughput and consumes less memory compared to other LB\nalgorithms, while providing weighted load balancing and false-hit freedom, for\nboth real and synthetic data center traffic. We implement Concury as a\nprototype system deployed in CloudLab and show that the throughput of Concury\non a single thread can reach 62.5% of the maximum capacity of two 10GbE NICs\nand that on two threads can reach the maximum capacity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 22:33:34 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Shi", "Shouqian", ""], ["Qian", "Chen", ""], ["Yu", "Ye", ""], ["Li", "Xin", ""], ["Zhang", "Ying", ""], ["Li", "Xiaozhou", ""]]}, {"id": "1908.02108", "submitter": "Michael May", "authors": "Michael J. May, Kevin D. Lux, Carl A. Gunter", "title": "WSEmail: A Retrospective on a System for Secure Internet Messaging Based\n  on Web Services", "comments": "18 pages, 17 figures, followup work to WSEmail: Secure Internet\n  Messaging Based on Web Services in IEEE International Conference on Web\n  Services (ICWS) 2005. Extended version of article to appear in Service\n  Oriented Computing and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web services offer an opportunity to redesign a variety of older systems to\nexploit the advantages of a flexible, extensible, secure set of standards. In\nthis work we revisit WSEmail, a system proposed over ten years ago to improve\nemail by redesigning it as a family of web services. WSEmail offers an\nalternative vision of how instant messaging and email services could have\nevolved, offering security, extensibility, and openness in a distributed\nenvironment instead of the hardened walled gardens that today's rich messaging\nsystems have become. WSEmail's architecture, especially its automatic plug-in\ndownload feature allows for rich extensions without changing the base protocol\nor libraries. We demonstrate WSEmail's flexibility using three business use\ncases: secure channel instant messaging, business workflows with routed forms,\nand on-demand attachments. Since increased flexibility often mitigates against\nsecurity and performance, we designed WSEmail with security in mind and\nformally proved the security of one of its core protocols (on-demand\nattachments) using the TulaFale and ProVerif automated proof tools. We provide\nperformance measurements for WSEmail functions in a prototype we implemented\nusing .NET. Our experiments show a latency of about a quarter of a second per\ntransaction under load.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 12:38:50 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 14:49:04 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["May", "Michael J.", ""], ["Lux", "Kevin D.", ""], ["Gunter", "Carl A.", ""]]}, {"id": "1908.02118", "submitter": "Gorby Kabasele Ndonda", "authors": "Gorby Kabasele Ndonda and Ramin Sadre", "title": "A Public Network Trace of a Control and Automation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing number of attacks against automation systems such as SCADA and\ntheir network infrastructure have demonstrated that there is a need to secure\nthose systems. Unfortunately, directly applying existing ICT security\nmechanisms to automation systems is hard due to constraints of the latter, such\nas availability requirements or limitations of the hardware. Thus, the solution\nprivileged by researchers is the use of network-based intrusion detection\nsystems (N-IDS). One of the issue that many researchers encounter is how to\nvalidate and evaluate their N-IDS. Having access to a real and large automation\nsystems for experimentation is almost impossible as companies are not inclined\nto give access to their systems due to obvious concerns. The few public traffic\ndatasets that could be used for off-line experiments are either synthetic or\ncollected at small testbeds. In this paper, we will describe and characterize a\npublic traffic dataset collected at the HVAC management system of a university\ncampus. Although the dataset contains only packet headers, we believe that it\ncan help researchers, in particular designers of flow-based IDS, to validate\ntheir solutions under more realistic conditions. The traces can be found on\nhttps://github.com/gkabasele/HVAC_Traces.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:09:04 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Ndonda", "Gorby Kabasele", ""], ["Sadre", "Ramin", ""]]}, {"id": "1908.02227", "submitter": "Andrey Belogaev", "authors": "Andrey Belogaev, Evgeny Khorov, Artem Krasilov, Dmitri Shmelkin and\n  Suwen Tang", "title": "Conservative Link Adaptation for Ultra Reliable Low Latency\n  Communications", "comments": "BlackSeaCom'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra reliable low latency communications (URLLC) is one of the most\npromising and demanding services in 5G systems. This service requires very low\nlatency of less than $1-10$ ms and very high transmission reliability: the\nacceptable packet loss ratio is about $10^{-5}$. To satisfy such strict\nrequirements, many issues shall be solved. This paper focuses on the link\nadaptation problem, i.e., the selection of a modulation and coding scheme (MCS)\nfor transmission based on the received channel quality indicator (CQI) reports.\nOn the one hand, link adaptation should select a robust MCS to provide high\nreliability. On the other hand, it should select the highest possible MCS to\nreduce channel resource consumption. The paper shows that even for one URLLC\nuser, link adaptation is still a challenging problem, especially in\nhighly-variant channels. To solve this problem, a conservative link adaptation\nalgorithm is designed. The algorithm estimates the strongest channel\ndegradation at the time moment of the actual packet transmission and selects an\nMCS taking into account the worst degradation. The obtained results show that\nthe proposed algorithm is efficient in terms of both the packet loss ratio and\nthe channel resource consumption.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 15:55:45 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Belogaev", "Andrey", ""], ["Khorov", "Evgeny", ""], ["Krasilov", "Artem", ""], ["Shmelkin", "Dmitri", ""], ["Tang", "Suwen", ""]]}, {"id": "1908.02261", "submitter": "Nikolaos Laoutaris", "authors": "Costas Iordanou, Georgios Smaragdakis, Nikolaos Laoutaris", "title": "Who's Tracking Sensitive Domains?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We turn our attention to the elephant in the room of data protection, which\nis none other than the simple and obvious question: \"Who's tracking sensitive\ndomains?\". Despite a fast-growing amount of work on more complex facets of the\ninterplay between privacy and the business models of the Web, the obvious\nquestion of who collects data on domains where most people would prefer not be\nseen, has received rather limited attention. First, we develop a methodology\nfor automatically annotating websites that belong to a sensitive category, e.g.\nas defined by the General Data Protection Regulation (GDPR). Then, we extract\nthe third party tracking services included directly, or via recursive\ninclusions, by the above mentioned sites. Having analyzed around 30k sensitive\ndomains, we show that such domains are tracked, albeit less intensely than the\nmainstream ones. Looking in detail at the tracking services operating on them,\nwe find well known names, as well as some less known ones, including some\nspecializing on specific sensitive categories.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 17:19:36 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Iordanou", "Costas", ""], ["Smaragdakis", "Georgios", ""], ["Laoutaris", "Nikolaos", ""]]}, {"id": "1908.02270", "submitter": "Tianchi Huang", "authors": "Tianchi Huang, Chao Zhou, Rui-Xiao Zhang, Chenglei Wu, Xin Yao, Lifeng\n  Sun", "title": "Comyco: Quality-Aware Adaptive Video Streaming via Imitation Learning", "comments": "ACM Multimedia 2019", "journal-ref": null, "doi": "10.1145/3343031.3351014", "report-no": null, "categories": "cs.MM cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based Adaptive Bit Rate~(ABR) method, aiming to learn outstanding\nstrategies without any presumptions, has become one of the research hotspots\nfor adaptive streaming. However, it typically suffers from several issues,\ni.e., low sample efficiency and lack of awareness of the video quality\ninformation. In this paper, we propose Comyco, a video quality-aware ABR\napproach that enormously improves the learning-based methods by tackling the\nabove issues. Comyco trains the policy via imitating expert trajectories given\nby the instant solver, which can not only avoid redundant exploration but also\nmake better use of the collected samples. Meanwhile, Comyco attempts to pick\nthe chunk with higher perceptual video qualities rather than video bitrates. To\nachieve this, we construct Comyco's neural network architecture, video datasets\nand QoE metrics with video quality features. Using trace-driven and real-world\nexperiments, we demonstrate significant improvements of Comyco's sample\nefficiency in comparison to prior work, with 1700x improvements in terms of the\nnumber of samples required and 16x improvements on training time required.\nMoreover, results illustrate that Comyco outperforms previously proposed\nmethods, with the improvements on average QoE of 7.5% - 16.79%. Especially,\nComyco also surpasses state-of-the-art approach Pensieve by 7.37% on average\nvideo quality under the same rebuffering time.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 17:48:46 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 07:54:23 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Huang", "Tianchi", ""], ["Zhou", "Chao", ""], ["Zhang", "Rui-Xiao", ""], ["Wu", "Chenglei", ""], ["Yao", "Xin", ""], ["Sun", "Lifeng", ""]]}, {"id": "1908.02798", "submitter": "Emmanuel Luj\\'an", "authors": "Emmanuel Luj\\'an, Juan A. Zuloaga Mellino, Alejandro D. Otero,\n  Leonardo Rey Vega, Cecilia G. Galarza and Esteban E. Mocskos", "title": "Extreme coverage in 5G Narrowband IoT: a LUT-based strategy to optimize\n  shared channels", "comments": "Paper accepted at IEEE IoT Journal", "journal-ref": null, "doi": "10.1109/JIOT.2019.2959552", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in IoT is providing communication support to an\nincreasing number of connected devices. In recent years, narrowband radio\ntechnology has emerged to address this situation: Narrowband Internet of Things\n(NB-IoT), which is now part of 5G. Supporting massive connectivity becomes\nparticularly demanding in extreme coverage scenarios such as underground or\ndeep inside buildings sites. We propose a novel strategy for these situations\nfocused on optimizing NB-IoT shared channels through the selection of link\nparameters: modulation and coding scheme, as well as the number of repetitions.\nThese parameters are established by the base station (BS) for each block\ntransmitted until reaching a target block error rate (BLER_t ). A wrong\nselection of these magnitudes leads to radio resource waste and a decrease in\nthe number of possible concurrent connections. Specifically, our strategy is\nbased on a look-up table (LUT) scheme which is used for rapidly delivering the\noptimal link parameters given a target QoS. To validate our proposal, we\ncompare with alternative strategies using an open source NB-IoT uplink\nsimulator. The experiments are based on transmitting blocks of 256 bits using\nan AWGN channel over the NPUSCH. Results show that, especially under extreme\nconditions, only a few options for link parameters are available, favoring\nrobustness against measurement uncertainties. Our strategy minimizes resource\nusage in all scenarios of acknowledged mode and remarkably reduces losses in\nthe unacknowledged mode, presenting also substantial gains in performance. We\nexpect to influence future BS software design and implementation, favoring\nconnection support under extreme environments.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 18:58:26 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 13:59:14 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Luj\u00e1n", "Emmanuel", ""], ["Mellino", "Juan A. Zuloaga", ""], ["Otero", "Alejandro D.", ""], ["Vega", "Leonardo Rey", ""], ["Galarza", "Cecilia G.", ""], ["Mocskos", "Esteban E.", ""]]}, {"id": "1908.03242", "submitter": "Muntasir Raihan Rahman", "authors": "Jaehoon Koo, Veena B. Mendiratta, Muntasir Raihan Rahman, Anwar Walid", "title": "Deep Reinforcement Learning for Network Slicing with Heterogeneous\n  Resource Requirements and Time Varying Traffic Dynamics", "comments": "A shorter version will appear in the 15th International Conference on\n  Network and Service Management (CNSM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient network slicing is vital to deal with the highly variable and\ndynamic characteristics of network traffic generated by a varied range of\napplications. The problem is made more challenging with the advent of new\ntechnologies such as 5G and new architectures such as SDN and NFV. Network\nslicing addresses a challenging dynamic network resource allocation problem\nwhere a single network infrastructure is divided into (virtual) multiple slices\nto meet the demands of different users with varying requirements, the main\nchallenges being --- the traffic arrival characteristics and the job resource\nrequirements (e.g., compute, memory and bandwidth resources) for each slice can\nbe highly dynamic. Traditional model-based optimization or queueing theoretic\nmodeling becomes intractable with the high reliability, and stringent bandwidth\nand latency requirements imposed by 5G technologies. In addition these\napproaches lack adaptivity in dynamic environments. We propose a deep\nreinforcement learning approach to address this dynamic coupled resource\nallocation problem. Model evaluation using both synthetic simulation data and\nreal workload driven traces demonstrates that our deep reinforcement learning\nsolution improves overall resource utilization, latency performance, and\ndemands satisfied as compared to a baseline equal-slicing strategy.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 19:28:37 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Koo", "Jaehoon", ""], ["Mendiratta", "Veena B.", ""], ["Rahman", "Muntasir Raihan", ""], ["Walid", "Anwar", ""]]}, {"id": "1908.03271", "submitter": "Qianqian Zhang", "authors": "Qianqian Zhang, Walid Saad, Mehdi Bennis", "title": "Reflections in the Sky: Millimeter Wave Communication with UAV-Carried\n  Intelligent Reflectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel approach that uses an unmanned aerial vehicle\n(UAV)-carried intelligent reflector (IR) is proposed to enhance the performance\nof millimeter wave (mmW) networks. In particular, the UAV-IR is used to\nintelligently reflect mmW beamforming signals from a base station towards a\nmobile outdoor user, while harvesting energy from mmW signals to power the IR.\nTo maintain a line-of-sight (LOS) channel, a reinforcement learning (RL)\napproach, based on Q-learning and neural networks, is proposed to model the\npropagation environment, such that the location and reflection coefficient of\nthe UAV-IR can be optimized to maximize the downlink transmission capacity.\nSimulation results show a significant advantage for using a UAV-IR over a\nstatic IR, in terms of the average data rate and the achievable downlink LOS\nprobability. The results also show that the RL-based deployment of the UAV-IR\nfurther improves the network performance, relative to a scheme without\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 21:44:26 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 19:07:10 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Zhang", "Qianqian", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1908.03297", "submitter": "Wei Wang Dr.", "authors": "Shengkai Zhang, Wei Wang, Sheyang Tang, Shi Jin, and Tao Jiang", "title": "Localizing Backscatters by a Single Robot With Zero Start-up Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the rapid proliferation of low-power backscatter\ntechnologies that realize the ubiquitous and long-term connectivity to empower\nsmart cities and smart homes. Localizing such low-power backscatter tags is\ncrucial for IoT-based smart services. However, current backscatter localization\nsystems require prior knowledge of the site, either a map or landmarks with\nknown positions, increasing the deployment cost. To empower universal\nlocalization service, this paper presents Rover, an indoor localization system\nthat simultaneously localizes multiple backscatter tags with zero start-up cost\nusing a robot equipped with inertial sensors. Rover runs in a joint\noptimization framework, fusing WiFi-based positioning measurements with\ninertial measurements to simultaneously estimate the locations of both the\nrobot and the connected tags. Our design addresses practical issues such as the\ninterference among multiple tags and the real-time processing for solving the\nSLAM problem. We prototype Rover using off-the-shelf WiFi chips and customized\nbackscatter tags. Our experiments show that Rover achieves localization\naccuracies of 39.3 cm for the robot and 74.6 cm for the tags.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 03:36:47 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Zhang", "Shengkai", ""], ["Wang", "Wei", ""], ["Tang", "Sheyang", ""], ["Jin", "Shi", ""], ["Jiang", "Tao", ""]]}, {"id": "1908.03398", "submitter": "Bo Wei", "authors": "Bo Wei, Kai Li, Chengwen Luo, Weitao Xu, Jin Zhang", "title": "No Need of Data Pre-processing: A General Framework for Radio-Based\n  Device-Free Context Awareness", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Device-free context awareness is important to many applications. There are\ntwo broadly used approaches for device-free context awareness, i.e. video-based\nand radio-based. Video-based applications can deliver good performance, but\nprivacy is a serious concern. Radio-based context awareness has drawn\nresearchers attention instead because it does not violate privacy and radio\nsignal can penetrate obstacles. Recently, deep learning has been introduced\ninto radio-based device-free context awareness and helps boost the recognition\naccuracy. The present works design explicit methods for each radio based\napplication. They also use one additional step to extract features before\nconducting classification and exploit deep learning as a classification tool.\nThe additional initial data processing step introduces unnecessary noise and\ninformation loss. Without initial data processing, it is, however, challenging\nto explore patterns of raw signals. In this paper, we are the first to propose\nan innovative deep learning based general framework for both signal processing\nand classification. The key novelty of this paper is that the framework can be\ngeneralised for all the radio-based context awareness applications. We also\neliminate the additional effort to extract features from raw radio signals. We\nconduct extensive evaluations to show the superior performance of our proposed\nmethod and its generalisation.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 10:14:42 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Wei", "Bo", ""], ["Li", "Kai", ""], ["Luo", "Chengwen", ""], ["Xu", "Weitao", ""], ["Zhang", "Jin", ""]]}, {"id": "1908.03447", "submitter": "Liang Wang", "authors": "Liang Wang, Hao Ye, Le Liang, Geoffrey Ye Li", "title": "Learn to Allocate Resources in Vehicular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation has a direct and profound impact on the performance of\nvehicle-to-everything (V2X) networks. Considering the dynamic nature of\nvehicular environments, it is appealing to devise a decentralized strategy to\nperform effective resource sharing. In this paper, we exploit deep learning to\npromote coordination among multiple vehicles and propose a hybrid architecture\nconsisting of centralized decision making and distributed resource sharing to\nmaximize the long-term sum rate of all vehicles. To reduce the network\nsignaling overhead, each vehicle uses a deep neural network to compress its own\nobserved information that is thereafter fed back to the centralized\ndecision-making unit, which employs a deep Q-network to allocate resources and\nthen sends the decision results to all vehicles. We further adopt a\nquantization layer for each vehicle that learns to quantize the continuous\nfeedback. Extensive simulation results demonstrate that the proposed hybrid\narchitecture can achieve near-optimal performance. Meanwhile, there exists an\noptimal number of continuous feedback and binary feedback, respectively.\nBesides, this architecture is robust to different feedback intervals, input\nnoise, and feedback noise.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:41:33 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Wang", "Liang", ""], ["Ye", "Hao", ""], ["Liang", "Le", ""], ["Li", "Geoffrey Ye", ""]]}, {"id": "1908.03536", "submitter": "Sergio L\\'opez Bernal", "authors": "Sergio L\\'opez Bernal, Alberto Huertas Celdr\\'an, Gregorio Mart\\'inez\n  P\\'erez, Michael Taynnan Barros, Sasitharan Balasubramaniam", "title": "Security in Brain-Computer Interfaces: State-of-the-art, opportunities,\n  and future challenges", "comments": null, "journal-ref": null, "doi": "10.1145/3427376", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  BCIs have significantly improved the patients' quality of life by restoring\ndamaged hearing, sight, and movement capabilities. After evolving their\napplication scenarios, the current trend of BCI is to enable new innovative\nbrain-to-brain and brain-to-the-Internet communication paradigms. This\ntechnological advancement generates opportunities for attackers since users'\npersonal information and physical integrity could be under tremendous risk.\nThis work presents the existing versions of the BCI life-cycle and homogenizes\nthem in a new approach that overcomes current limitations. After that, we offer\na qualitative characterization of the security attacks affecting each phase of\nthe BCI cycle to analyze their impacts and countermeasures documented in the\nliterature. Finally, we reflect on lessons learned, highlighting research\ntrends and future challenges concerning security on BCIs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 16:55:09 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 18:35:35 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 09:04:54 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Bernal", "Sergio L\u00f3pez", ""], ["Celdr\u00e1n", "Alberto Huertas", ""], ["P\u00e9rez", "Gregorio Mart\u00ednez", ""], ["Barros", "Michael Taynnan", ""], ["Balasubramaniam", "Sasitharan", ""]]}, {"id": "1908.03803", "submitter": "Alexander Krotov", "authors": "Evgeny Khorov, Anton Kiryanov, Alexander Krotov", "title": "Cloud-based Management of Energy-Efficient Dense IEEE 802.11ax Networks", "comments": null, "journal-ref": "2019 IEEE International Black Sea Conference on Communications and\n  Networking (BlackSeaCom)", "doi": "10.1109/BlackSeaCom.2019.8812787", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, the number of devices connected to the Internet by\nWi-Fi has grown significantly. A high density of both the client devices and\nthe hot spots posed new challenges related to providing the desired quality of\nservice in the current and emerging scenarios. To cope with the negative\neffects caused by network densification, modern Wi-Fi is becoming more and more\ncentralized. To improve network efficiency, today many new Wi-Fi deployments\nare under control of management systems that optimize network parameters in a\ncentralized manner. In the paper, for such a cloud management system, we\ndevelop an algorithm which aims at maximizing energy efficiency and also keeps\nfairness among clients. For that, we design an objective function and solve an\noptimization problem using the branch and bound approach. To evaluate the\nefficiency of the developed solution, we implement it in the NS-3 simulator and\ncompare with existing solutions and legacy behavior.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 20:43:00 GMT"}, {"version": "v2", "created": "Sat, 31 Aug 2019 21:44:47 GMT"}, {"version": "v3", "created": "Sun, 24 Nov 2019 15:10:17 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Khorov", "Evgeny", ""], ["Kiryanov", "Anton", ""], ["Krotov", "Alexander", ""]]}, {"id": "1908.04047", "submitter": "Ahmadreza Montazerolghaem", "authors": "Ahmadreza Montazerolghaem", "title": "SIP Server Load Balancing Based on SDN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session Initiation Protocol (SIP) grows for VoIP applications, and faces\nchallenges including security and overload. On the other hand, the new concept\nof Software-defined Networking (SDN) has made great changes in the networked\nworld. SDN is the idea of separating the control plane from the network\ninfrastructure that can bring several benefits. We used this idea to provide a\nnew architecture for SIP networks. Moreover, for the load distribution\nchallenge in these networks, a framework based on SDN was offered, in which the\nload balancing and network management can be easily done by a central\ncontroller considering the network status. Unlike the traditional methods, in\nthis framework, there is no need to change the infrastructures like SIP servers\nor SIP load balancer to implement the distribution method. Also, several types\nof load distribution algorithms can be performed as software in the controller.\nWe were able to achieve the desired results by simulating the three methods\nbased on the proposed framework in Mininet.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 08:18:45 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Montazerolghaem", "Ahmadreza", ""]]}, {"id": "1908.04374", "submitter": "Xinhao Deng", "authors": "Shu Yang and Laizhong Cui and Xinhao Deng and Qi Li and Yulei Wu and\n  Mingwei Xu and Dan Wang and Jianping Wu", "title": "Two Dimensional Router: Design and Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher dimensional classification has attracted more attentions with\nincreasing demands for more flexible services in the Internet. In this paper,\nwe present the design and implementation of a two dimensional router (TwoD\nrouter), that makes forwarding decisions based on both destination and source\naddresses. This TwoD router is also a key element in our current effort towards\ntwo dimensional IP routing. With one more dimension, the forwarding table will\ngrow explosively given a straightforward implementation. As a result, it is\nimpossible to fit the forwarding table to the current TCAM, which is the de\nfacto standard despite its limited capacity. To solve the explosion problem, we\npropose a forwarding table structure with a novel separation of TCAM and SRAM.\nAs such, we move the redundancies in expensive TCAM to cheaper SRAM, while the\nlookup speed is comparable with conventional routers. We also design the\nincremental update algorithms that minimize the number of accesses to memory.\nWe evaluate our design with a real implementation on a commercial router,\nBit-Engine 12004, with real data sets. Our design does not need new devices,\nwhich is favorable for adoption. The results also show that the performance of\nour TwoD router is promising.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 20:44:58 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Yang", "Shu", ""], ["Cui", "Laizhong", ""], ["Deng", "Xinhao", ""], ["Li", "Qi", ""], ["Wu", "Yulei", ""], ["Xu", "Mingwei", ""], ["Wang", "Dan", ""], ["Wu", "Jianping", ""]]}, {"id": "1908.04376", "submitter": "Grzegorz Cisek", "authors": "Grzegorz Cisek and Tomasz P. Zielinski", "title": "Prototyping Software Transceiver for the 5G New Radio Physical Uplink\n  Shared Channel", "comments": "Conference: Signal Processing Symposium (SPSympo), Cracow, Poland,\n  17-19 Sep. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G New Radio (NR) is an emerging radio access technology, which is planned to\nsucceed 4G Long Term Evolution (LTE) as global standard of cellular\ncommunications in the upcoming years. This paper considers a digital signal\nprocessing model and a software implementation of a complete transceiver chain\nof the Physical Uplink Shared Channel (PUSCH) defined by the version 15 of the\n3GPP standard, consisting of both baseband transmitter and receiver chains on a\nphysical layer level. The BLER performance of the prototype system\nimplementation under AWGN and Rayleigh fading channel conditions is evaluated.\nMoreover, the source code of high-level numerical model was made available\nonline on a public repository by the authors. In the paper's tutorial part, the\naspects of the 5G NR standard are reviewed and their impact on different\nfunctional building blocks of the system is discussed, including\nsynchronization, channel estimation, equalization, soft-bit demodulation and\nLDPC encoding/decoding. A review of State-of-Art algorithms that can be\nutilized to increase the performance of the system is provided together with a\nguidelines for practical implementations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 20:48:07 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Cisek", "Grzegorz", ""], ["Zielinski", "Tomasz P.", ""]]}, {"id": "1908.04484", "submitter": "C. H. Huck Yang", "authors": "Sheng-Chun Kao, Chao-Han Huck Yang, Pin-Yu Chen, Xiaoli Ma, Tushar\n  Krishna", "title": "Reinforcement Learning based Interconnection Routing for Adaptive\n  Traffic Optimization", "comments": null, "journal-ref": null, "doi": "10.1145/3313231.335236", "report-no": null, "categories": "cs.NI cs.AI cs.AR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Machine Learning (ML) techniques to design and optimize computer\narchitectures is a promising research direction. Optimizing the runtime\nperformance of a Network-on-Chip (NoC) necessitates a continuous learning\nframework. In this work, we demonstrate the promise of applying reinforcement\nlearning (RL) to optimize NoC runtime performance. We present three RL-based\nmethods for learning optimal routing algorithms. The experimental results show\nthe algorithms can successfully learn a near-optimal solution across different\nenvironment states. Reproducible Code:\ngithub.com/huckiyang/interconnect-routing-gym\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 04:35:40 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Kao", "Sheng-Chun", ""], ["Yang", "Chao-Han Huck", ""], ["Chen", "Pin-Yu", ""], ["Ma", "Xiaoli", ""], ["Krishna", "Tushar", ""]]}, {"id": "1908.04518", "submitter": "Usama Naseer", "authors": "Usama Naseer, Theophilus Benson", "title": "ConfigTron: Tackling network diversity with heterogeneous configurations", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web serving protocol stack is constantly changing and evolving to tackle\ntechnological shifts in networking infrastructure and website complexity. As a\nresult of this evolution, the web serving stack includes a plethora of\nprotocols and configuration parameters that enable the web serving stack to\naddress a variety of realistic network conditions. Yet, today, most content\nproviders have adopted a \"one-size-fits-all\" approach to configuring the\nnetworking stack of their user facing web servers (or at best employ moderate\ntuning), despite the significant diversity in end-user networks and devices. In\nthis paper, we revisit this problem and ask a more fundamental question: Are\nthere benefits to tuning the network stack? If so, what system design choices\nand algorithmic ensembles are required to enable modern content provider to\ndynamically and flexibly tune their protocol stacks. We demonstrate through\nsubstantial empirical evidence that this \"one-size-fits-all\" approach results\nin sub-optimal performance and argue for a novel framework that extends\nexisting CDN architectures to provide programmatic control over the\nconfiguration options of the CDN serving stack. We designed ConfigTron a\ndata-driven framework that leverages data from all connections to identify\ntheir network characteristics and learn the optimal configuration parameters to\nimprove end-user performance. ConfigTron uses contextual multi-arm bandit-based\nlearning algorithm to find optimal configurations in minimal time, enabling a\ncontent providers to systematically explore heterogeneous configurations while\nimproving end-user page load time by as much as 19% (upto 750ms) on median.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 07:16:59 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Naseer", "Usama", ""], ["Benson", "Theophilus", ""]]}, {"id": "1908.04574", "submitter": "Erik Sy", "authors": "Erik Sy", "title": "Enhanced Performance and Privacy via Resolver-Less DNS", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain name resolution into IP addresses can significantly delay\nconnection establishments on the web. Moreover, the common use of recursive DNS\nresolvers presents a privacy risk as they can closely monitor the user's\nbrowsing activities. In this paper, we present a novel HTTP response header\nallowing web server to provide their clients with relevant DNS records. Our\nresults indicate, that this resolver-less DNS mechanism allows user agents to\nsave the DNS lookup time for subsequent connection establishments. We find,\nthat this proposal saves at least 80ms per DNS lookup for the one percent of\nusers having the longest round-trip times towards their recursive resolver.\nFurthermore, our proposal decreases the number of DNS lookups and thus improves\nthe privacy posture of the user towards the used recursive resolver. Comparing\nthe security guarantees of the traditional DNS to our proposal, we find that\nresolver-less DNS achieves at least the same security properties. In detail, it\neven improves the user's resilience against censorship through tampered DNS\nresolvers.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 11:00:09 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Sy", "Erik", ""]]}, {"id": "1908.04606", "submitter": "Seung-Woo Ko", "authors": "Seung-Woo Ko, Hyukjin Chae, Kaifeng Han, Seungmin Lee, Dong-Wook Seo,\n  and Kaibin Huang", "title": "V2X-Based Vehicular Positioning: Opportunities, Challenges, and Future\n  Directions", "comments": "This work has been submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle-to-Everything (V2X) will create many new opportunities in the area of\nwireless communications, while its feasibility on enabling vehicular\npositioning has not been explored yet. Vehicular positioning is a crucial\noperation for autonomous driving. Its complexity and stringent safety\nrequirement render conventional technologies like RADAR and LIDAR inadequate.\nThis article aims at investigating whether V2X can help vehicular positioning\nfrom different perspectives. We first explain V2X's critical advantages over\nother approaches and suggest new scenarios of V2X-based vehicular positioning.\nThen we review the state-of-the-art positioning techniques discussed in the\nongoing 3GPP standardization and point out their limitations. Lastly, some\npromising research directions for V2X-based vehicular positioning are\npresented, which shed light on realizing fully autonomous driving by overcoming\nthe current barriers.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 12:34:59 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 07:49:40 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ko", "Seung-Woo", ""], ["Chae", "Hyukjin", ""], ["Han", "Kaifeng", ""], ["Lee", "Seungmin", ""], ["Seo", "Dong-Wook", ""], ["Huang", "Kaibin", ""]]}, {"id": "1908.04824", "submitter": "Matthew Turner", "authors": "Matthew Turner, Hana Khamfroush", "title": "Meeting QoS of Users in a Edge to Cloud Platform via Optimally Placing\n  Services and Scheduling Tasks", "comments": "6 Pages, 6 Figures, submitted to ICNC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of service placement and task scheduling on\na three-tiered edge-to-cloud platform when user requests must be met by a\ncertain deadline. Time-sensitive applications (e.g., augmented reality, gaming,\nreal-time video analysis) have tight constraints that must be met. With\nmultiple possible computation centers, the \"where\" and \"when\" of solving these\nrequests becomes paramount when meeting their deadlines. We formulate the\nproblem of meeting users' deadlines while minimizing the total cost of the\nedge-to-cloud service provider as an Integer Linear Programming (ILP) problem.\nWe show the NP-hardness of this problem, and propose two heuristics based on\nmaking decisions on a local vs global scale. We vary the number of users, the\nQoS constraint, and the cost difference between remote cloud and cloudlets(edge\nclouds), and run multiple Monte-Carlo runs for each case. Our simulation\nresults show that the proposed heuristics are performing close to optimal while\nreducing the complexity.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 18:55:29 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Turner", "Matthew", ""], ["Khamfroush", "Hana", ""]]}, {"id": "1908.05055", "submitter": "Emma Fitzgerald", "authors": "Emma Fitzgerald, Micha{\\l} Pi\\'oro, Artur Tomaszewski", "title": "Network Lifetime Maximization in Wireless Mesh Networks for\n  Machine-to-Machine Communication", "comments": "Ad Hoc Networks, in press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present new optimization formulations for maximizing the\nnetwork lifetime in wireless mesh networks performing data aggregation and\ndissemination for machine-to-machine communication in the Internet of Things.\nWe focus on heterogeneous networks in which multiple applications co-exist and\nnodes may take on different roles for different applications. Moreover, we\naddress network reconfiguration as a means to increase the network lifetime, in\nkeeping with the current trend towards software defined networks and network\nfunction virtualization. To test our optimization formulations, we conducted a\nnumerical study using randomly-generated mesh networks from 10 to 30 nodes, and\nshowed that the network lifetime can be increased using network reconfiguration\nby up to 75% over a single, minimal-energy configuration. Further, our\nsolutions are feasible to implement in practical scenarios: only few\nconfigurations are needed, thus requiring little storage for a standalone\nnetwork, and the synchronization and signalling needed to switch configurations\nis low relative to each configuration's operating time.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 10:05:02 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Fitzgerald", "Emma", ""], ["Pi\u00f3ro", "Micha\u0142", ""], ["Tomaszewski", "Artur", ""]]}, {"id": "1908.05077", "submitter": "Jose Moura", "authors": "Jose Moura and David Hutchison", "title": "Fog Computing Systems: State of the Art, Research Issues and Future\n  Trends, with a Focus on Resilience", "comments": "38 pages, 3 figures, 5 tables, 192 references, this version was\n  resubmitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many future innovative computing services will use Fog Computing Systems\n(FCS), integrated with Internet of Things (IoT) resources. These new services,\nbuilt on the convergence of several distinct technologies, need to fulfil\ntime-sensitive functions, provide variable levels of integration with their\nenvironment, and incorporate data storage, computation, communications,\nsensing, and control. There are, however, significant problems to be solved\nbefore such systems can be considered fit for purpose. The high heterogeneity,\ncomplexity, and dynamics of these resource-constrained systems bring new\nchallenges to their robust and reliable operation, which implies the need for\nintegral resilience management strategies. This paper surveys the state of the\nart in the relevant fields, and discusses the research issues and future trends\nthat are emerging. We envisage future applications that have very stringent\nrequirements, notably high-precision latency and synchronization between a\nlarge set of flows, where FCSs are key to supporting them. Thus, we hope to\nprovide new insights into the design and management of resilient FCSs that are\nformed by IoT devices, edge computer servers and wireless sensor networks;\nthese systems can be modelled using Game Theory, and flexibly programmed with\nthe latest software and virtualization platforms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 11:30:07 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 16:15:32 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 17:46:37 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 15:44:38 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Moura", "Jose", ""], ["Hutchison", "David", ""]]}, {"id": "1908.05310", "submitter": "Ruffin White", "authors": "Ruffin White and Gianluca Caiazza and Chenxu Jiang and Xinyue Ou and\n  Zhiyue Yang and Agostino Cortesi and Henrik Christensen", "title": "Network Reconnaissance and Vulnerability Excavation of Secure DDS\n  Systems", "comments": "10 pages, 7 figures, 1 algorithm, 10 sections plus references", "journal-ref": "Workshop on Software Security for Internet of Things (SSIoT) at\n  IEEE EuroS&P 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution Service (DDS) is a realtime peer-to-peer protocol that serves as\na scalable middleware between distributed networked systems found in many\nIndustrial IoT domains such as automotive, medical, energy, and defense. Since\nthe initial ratification of the standard, specifications have introduced a\nSecurity Model and Service Plugin Interface (SPI) architecture, facilitating\nauthenticated encryption and data centric access control while preserving\ninteroperable data exchange. However, as Secure DDS v1.1, the default plugin\nspecifications presently exchanges digitally signed capability lists of both\nparticipants in the clear during the crypto handshake for permission\nattestation; thus breaching confidentiality of the context of the connection.\nIn this work, we present an attacker model that makes use of network\nreconnaissance afforded by this leaked context in conjunction with formal\nverification and model checking to arbitrarily reason about the underlying\ntopology and reachability of information flow, enabling targeted attacks such\nas selective denial of service, adversarial partitioning of the data bus, or\nvulnerability excavation of vendor implementations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:53:08 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["White", "Ruffin", ""], ["Caiazza", "Gianluca", ""], ["Jiang", "Chenxu", ""], ["Ou", "Xinyue", ""], ["Yang", "Zhiyue", ""], ["Cortesi", "Agostino", ""], ["Christensen", "Henrik", ""]]}, {"id": "1908.05513", "submitter": "Onel Luis Alcaraz L\\'opez", "authors": "Onel L. A. L\\'opez, Hirley Alves, Matti Latva-aho", "title": "Distributed Rate Control in Downlink NOMA Networks with Reliability\n  Constraints", "comments": "14 pages, 10 figures, accepted at IEEE TWC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-orthogonal multiple access (NOMA) has been identified as a promising\ntechnology for future wireless systems due to its performance gains in spectral\nefficiency when compared to conventional orthogonal schemes (OMA). This gain\ncan be easily translated to an increasing number of served users, but imposes a\nchallenge in the system reliability which is of vital importance for new\nservices and applications of coming cellular systems. To cope with these issues\nwe propose a NOMA rate control strategy that makes use only of topological\ncharacteristics of the scenario and the reliability constraint. We attain the\nnecessary conditions so that NOMA overcomes the OMA alternative, while we\ndiscuss the optimum allocation strategies for the 2-user NOMA setup when\noperating with equal rate or maximum sum-rate goals. In such scenario we show\nthat the user with the largest target error probability times the ratio between\nthe average receive signal power and the average interference power, should be\nscheduled to be decoded first for optimum performance. We compare numerically\nthe performance of our allocation scheme with its ideal counterpart requiring\nfull CSI at the BSs and infinitely long blocklength, and show how the gap\nincreases as the reliability constraint becomes more stringent. Results also\nevidence the benefits of NOMA when the co-interference can be efficiently\ncanceled, specially when the goal is to maximize the sum-rate.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 12:25:21 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["L\u00f3pez", "Onel L. A.", ""], ["Alves", "Hirley", ""], ["Latva-aho", "Matti", ""]]}, {"id": "1908.05895", "submitter": "Jihong Park", "authors": "Jihong Park, Shiqiang Wang, Anis Elgabli, Seungeun Oh, Eunjeong Jeong,\n  Han Cha, Hyesung Kim, Seong-Lyun Kim, Mehdi Bennis", "title": "Distilling On-Device Intelligence at the Network Edge", "comments": "7 pages, 6 figures; This work has been submitted to the IEEE for\n  possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Devices at the edge of wireless networks are the last mile data sources for\nmachine learning (ML). As opposed to traditional ready-made public datasets,\nthese user-generated private datasets reflect the freshest local environments\nin real time. They are thus indispensable for enabling mission-critical\nintelligent systems, ranging from fog radio access networks (RANs) to\ndriverless cars and e-Health wearables. This article focuses on how to distill\nhigh-quality on-device ML models using fog computing, from such user-generated\nprivate data dispersed across wirelessly connected devices. To this end, we\nintroduce communication-efficient and privacy-preserving distributed ML\nframeworks, termed fog ML (FML), wherein on-device ML models are trained by\nexchanging model parameters, model outputs, and surrogate data. We then present\nadvanced FML frameworks addressing wireless RAN characteristics, limited\non-device resources, and imbalanced data distributions. Our study suggests that\nthe full potential of FML can be reached by co-designing communication and\ndistributed ML operations while accounting for heterogeneous hardware\nspecifications, data characteristics, and user requirements.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 09:01:26 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Park", "Jihong", ""], ["Wang", "Shiqiang", ""], ["Elgabli", "Anis", ""], ["Oh", "Seungeun", ""], ["Jeong", "Eunjeong", ""], ["Cha", "Han", ""], ["Kim", "Hyesung", ""], ["Kim", "Seong-Lyun", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1908.05905", "submitter": "Omar Sami Oubbati", "authors": "Omar Sami Oubbati and Noureddine Chaib and Abderrahmane Lakas and\n  Salim Bitam", "title": "On-Demand Routing for Urban VANETs using Cooperating UAVs", "comments": "6 pages, 7 figures, conference", "journal-ref": "2018 International Conference on Smart Communications in Network\n  Technologies (SaCoNeT)", "doi": "10.1109/SaCoNeT.2018.8585453", "report-no": null, "categories": "cs.NI cs.IT cs.SI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular ad hoc networks (VANETs) are characterized by frequent routing path\nfailures due to the high mobility caused by the sudden changes of the direction\nof vehicles. The routing paths between two different vehicles should be\nestablished with this challenge in mind. Stability and connectedness are a\nmandatory condition to ensure a robust and reliable data delivery. The idea\nbehind this work is to exploit a new reactive routing technique to provide\nregulated and well-connected routing paths. Unmanned Aerial Vehicles (UAVs) or\nwhat are referred to as drones can be both involved in the discovery process\nand be full members in these discovered paths in order to avoid possible\ndisconnections on the ground when the network is sparsely connected. The\ndifferent tests of this technique are performed based on NS-2 simulator and the\noutcomes are compared with those of related on-demand routing protocols\ndedicated for VANETs. Interesting results are distinguished showing a reduced\nend-to-end delay and a high delivery ratio, which proving that this\nheterogeneous communication between vehicles and UAVs is able to extend the\nnetwork connectivity.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 09:21:05 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Oubbati", "Omar Sami", ""], ["Chaib", "Noureddine", ""], ["Lakas", "Abderrahmane", ""], ["Bitam", "Salim", ""]]}, {"id": "1908.05946", "submitter": "Vitaly Petrov", "authors": "Vitaly Petrov and Dmitri Moltchanov and Sergey Andreev and Robert W.\n  Heath Jr", "title": "Analysis of Intelligent Vehicular Relaying in Urban 5G+ Millimeter-Wave\n  Cellular Deployments", "comments": "6 pages, 8 figures. The paper has been accepted for IEEE GLOBECOM\n  2019. Copyright may be transferred without notice, after which this version\n  may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability of smarter networked devices to dynamically select appropriate\nradio connectivity options is especially important in the emerging\nmillimeter-wave (mmWave) systems to mitigate abrupt link blockage in complex\nenvironments. To enrich the levels of diversity, mobile mmWave relays can be\nemployed for improved connection reliability. These are considered by 3GPP for\non-demand densification on top of the static mmWave infrastructure. However,\nperformance dynamics of mobile mmWave relaying is not nearly well explored,\nespecially in realistic conditions, such as urban vehicular scenarios. In this\npaper, we develop a mathematical framework for the performance evaluation of\nmmWave vehicular relaying in a typical street deployment. We analyze and\ncompare alternative connectivity strategies by quantifying the performance\ngains made available to smart devices in the presence of mmWave relays. We\nidentify situations where the use of mmWave vehicular relaying is particularly\nbeneficial. Our methodology and results can support further standardization and\ndeployment of mmWave relaying in more intelligent 5G+ \"all-mmWave\" cellular\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 12:28:28 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Petrov", "Vitaly", ""], ["Moltchanov", "Dmitri", ""], ["Andreev", "Sergey", ""], ["Heath", "Robert W.", "Jr"]]}, {"id": "1908.06152", "submitter": "Xingqin Lin", "authors": "Xingqin Lin", "title": "Debunking Seven Myths about 5G New Radio", "comments": "8 pages, 4 figures, 1 table, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New radio (NR) is a new wireless access technology developed as part of the\nfifth-generation (5G) of mobile communications to support a wide range of\nservices, devices, and deployments. NR features spectrum flexibility,\nultra-lean design, forward compatibility, low latency support, and advanced\nantenna technologies. There has been excitement about NR, sometimes clouded by\nconfusion. This article is an attempt to summarize and overview the key\nfeatures of NR by debunking seven of the more popular myths and revealing what\nNR really is. The seven topics include spectrum, flexible waveform and multiple\naccess, LTE-NR interworking and coexistence, low latency support, massive\nmachine type communications, non-terrestrial communications, and beyond radio.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 20:16:22 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Lin", "Xingqin", ""]]}, {"id": "1908.06367", "submitter": "Mohamed A. Abd-Elmagid", "authors": "Mohamed A. Abd-Elmagid, Harpreet S. Dhillon, Nikolaos Pappas", "title": "A Reinforcement Learning Framework for Optimizing Age-of-Information in\n  RF-powered Communication Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a real-time monitoring system in which multiple\nsource nodes are responsible for sending update packets to a common destination\nnode in order to maintain the freshness of information at the destination.\nSince it may not always be feasible to replace or recharge batteries in all\nsource nodes, we consider that the nodes are powered through wireless energy\ntransfer (WET) by the destination. For this system setup, we investigate the\noptimal online sampling policy (referred to as the age-optimal policy) that\njointly optimizes WET and scheduling of update packet transmissions with the\nobjective of minimizing the long-term average weighted sum of\nAge-of-Information (AoI) values for different physical processes (observed by\nthe source nodes) at the destination node, referred to as the sum-AoI. To solve\nthis optimization problem, we first model this setup as an average cost Markov\ndecision process (MDP). Due to the extreme curse of dimensionality in the state\nspace of the formulated MDP, classical reinforcement learning algorithms are no\nlonger applicable to our problem. Motivated by this, we propose a deep\nreinforcement learning (DRL) algorithm that can learn the age-optimal policy in\na computationally-efficient manner. We further characterize the structural\nproperties of the age-optimal policy analytically, and demonstrate that it has\na threshold-based structure with respect to the AoI values for different\nprocesses. We extend our analysis to characterize the structural properties of\nthe policy that maximizes average throughput for our system setup, referred to\nas the throughput-optimal policy. Afterwards, we analytically demonstrate that\nthe structures of the age-optimal and throughput-optimal policies are\ndifferent. We also numerically demonstrate these structures as well as the\nimpact of system design parameters on the optimal achievable average weighted\nsum-AoI.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 03:23:07 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Abd-Elmagid", "Mohamed A.", ""], ["Dhillon", "Harpreet S.", ""], ["Pappas", "Nikolaos", ""]]}, {"id": "1908.06434", "submitter": "Nikita Stepanov", "authors": "Maxim S. Ilderyakov and Nikita V. Stepanov", "title": "Using a small number of devices to experimentally estimate the packet\n  delivery ratio on a lorawan network with a large number of end devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the proposed methodology for conducting experiments on a small\nnumber of devices for evaluating systems with a large number of devices. A\nsoftware package for assessing the performance of LPWAN (Long Range Wide Area\nNetworks, LoRaWAN) networks is presented. An example of the operation of this\nsoftware system as applied to the LoRaWAN network for estimating the\nprobability of message delivery from a number of devices to a base station when\nimplementing this technique is shown. This technique can be used to evaluate\nthe performance of other LPWAN networks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 12:47:58 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ilderyakov", "Maxim S.", ""], ["Stepanov", "Nikita V.", ""]]}, {"id": "1908.06595", "submitter": "Xianzhe Xu", "authors": "Xianzhe Xu and Meixia Tao", "title": "Modeling, Analysis, and Optimization of Caching in Multi-Antenna\n  Small-Cell Networks", "comments": "15 pages, 10 figures, accepted by Transcation on Wireless\n  Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In traditional cache-enabled small-cell networks (SCNs), a user can suffer\nstrong interference due to contentcentric base station association. This may\ndegenerate the advantage of collaborative content caching among multiple small\nbase stations (SBSs), including probabilistic caching and coded caching. In\nthis work, we tackle this issue by deploying multiple antennas at each SBS for\ninterference management. Two types of beamforming are considered. One is\nmatched-filter (MF) to strengthen the effective channel gain of the desired\nsignal, and the other is zero-forcing (ZF) to cancel interference within a\nselected SBS cooperation group. We apply these two beamforming techniques in\nboth probabilistic caching and coded caching, and conduct performance analysis\nusing stochastic geometry. We obtain exact and approximate compact integral\nexpressions of system performances measured by average fractional offloaded\ntraffic (AFOT) and average ergodic spectral efficiency (AESE). Based on these\nexpressions, we then optimize the caching parameters for AFOT or AESE\nmaximization. For probabilistic caching, optimal caching solutions are\nobtained. For coded caching, an efficient greedy-based algorithm is proposed.\nNumerical results show that multiple antennas can boost the advantage of\nprobabilistic caching and coded caching over the traditional most popular\ncaching with the proper use of beamforming.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 05:09:39 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Xu", "Xianzhe", ""], ["Tao", "Meixia", ""]]}, {"id": "1908.06659", "submitter": "Mahdieh Ahmadi", "authors": "Mahdieh Ahmadi, James Roberts, Emilio Leonardi, Ali Movaghar", "title": "Cache Subsidies for an Optimal Memory for Bandwidth Tradeoff in the\n  Access Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the cost of the access network could be considerably reduced by the use\nof caching, this is not currently happening because content providers (CPs),\nwho alone have the detailed demand data required for optimal content placement,\nhave no natural incentive to use them to minimize access network operator (ANO)\nexpenditure. We argue that ANOs should therefore provide such an incentive in\nthe form of direct subsidies paid to the CPs in proportion to the realized\nsavings. We apply coalition game theory to design the required subsidy\nframework and propose a distributed algorithm, based on Lagrangian\ndecomposition, allowing ANOs and CPs to collectively realize the optimal memory\nfor bandwidth tradeoff. The considered access network is a cache hierarchy with\nper-CP central office caches, accessed by all ANOs, at the apex, and per-ANO\ndedicated bandwidth and storage resources at the lower levels, including\nwireless base stations, that must be shared by multiple CPs.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:27:23 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ahmadi", "Mahdieh", ""], ["Roberts", "James", ""], ["Leonardi", "Emilio", ""], ["Movaghar", "Ali", ""]]}, {"id": "1908.06842", "submitter": "Furqan Jameel", "authors": "Furqan Jameel, Muhammad Awais Javed, Duy T. Ngo", "title": "Performance Analysis of Cooperative V2V and V2I Communications under\n  Correlated Fading", "comments": "Internet of Vehicles (IoV), Vehicular communication, Antenna\n  correlation, Stackelberg game, Vehicle-to-infrastructure (V2I),\n  Vehicle-to-vehicle (V2V), Game theory, Cooperative vehicular networks", "journal-ref": "IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, 2019", "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative vehicular networks will play a vital role in the coming years to\nimplement various intelligent transportation-related applications. Both\nvehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications\nwill be needed to reliably disseminate information in a vehicular network. In\nthis regard, a roadside unit (RSU) equipped with multiple antennas can improve\nthe network capacity. While the traditional approaches assume antennas to\nexperience independent fading, we consider a more practical uplink scenario\nwhere antennas at the RSU experience correlated fading. In particular, we\nevaluate the packet error probability for two renowned antenna correlation\nmodels, i.e., constant correlation (CC) and exponential correlation (EC). We\nalso consider intermediate cooperative vehicles for reliable communication\nbetween the source vehicle and the RSU. Here, we derive closed-form expressions\nfor packet error probability which help quantify the performance variations due\nto fading parameter, correlation coefficients and the number of intermediate\nhelper vehicles. To evaluate the optimal transmit power in this network\nscenario, we formulate a Stackelberg game, wherein, the source vehicle is\ntreated as a buyer and the helper vehicles are the sellers. The optimal\nsolutions for the asking price and the transmit power are devised which\nmaximize the utility functions of helper vehicles and the source vehicle,\nrespectively. We verify our mathematical derivations by extensive simulations\nin MATLAB.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 11:15:05 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Jameel", "Furqan", ""], ["Javed", "Muhammad Awais", ""], ["Ngo", "Duy T.", ""]]}, {"id": "1908.06866", "submitter": "Anver Hisham", "authors": "Anver Hisham, Erik G. Str\\\"om, Fredrik Br\\\"annstr\\\"om", "title": "Radio Resource Management for V2V Multihop Communication Considering\n  Adjacent Channel Interference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper investigate joint scheduling and power control for V2V multicast\nallowing multihop communication. The effects of both co-channel interference\nand adjacent channel interference are considered. First, we solve the problem\nwith the objective of maximizing the throughput and connectivity of vehicles in\nthe network. Then extend the same problem formulation to include the objective\nof minimizing the latency and the average age of information (AoI), which is\nthe age of the latest received message. In order to account for fairness, we\nalso show the problem formulation to maximize the worst-case throughput and\nconnectivity. All the problems are formulated as mixed Boolean linear\nprogramming problems, which allows computation of optimal solutions.\nFurthermore, we consider the error probability of a link failure in all the\nproblem formulations and accommodate the probability requirements for\nsatisfying a certain throughput/connectivity/latency/AoI. In order to support a\nlarge V2V network, a clustering algorithm is proposed whose computational\ncomplexity scale well with the network size. To handle the case of zero channel\ninformation at the scheduler, a multihop distributed scheduling scheme is\nproposed.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 11:25:27 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Hisham", "Anver", ""], ["Str\u00f6m", "Erik G.", ""], ["Br\u00e4nnstr\u00f6m", "Fredrik", ""]]}, {"id": "1908.07228", "submitter": "Paolo Giaccone", "authors": "Ahsan Mahmood, Claudio Casetti, Carla Fabiana Chiasserini, Paolo\n  Giaccone, Jerome Haerri", "title": "The RICH Prefetching in Edge Caches for In-Order Delivery to Connected\n  Cars", "comments": null, "journal-ref": "IEEE Transactions on Vehicular Technology, vol. 68, no. 1, pp.\n  4-18, Jan. 2019", "doi": "10.1109/TVT.2018.2879850", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content caching on the edge of 5G networks is an emerging and critical\nfeature to quench the thirst for content of future connected cars. However, the\ntight packaging of 5G cells, the finite storage capacity at the edge, and the\nneed for content availability while driving motivate the need to develop smart\nedge caching strategies adapted to the mobility characteristics of connected\ncars. In this paper, we propose a scheme called RICH (RoadsIde CacHe), which\noptimally caches content at edge nodes where connected vehicles require it\nmost. In particular, our scheme is designed to ensure in-order delivery of\ncontent chunks to end users. Unlike blind popularity decisions, the\nprobabilistic caching used by RICH accounts for the user mobility information\nthat the system can realistically acquire. Furthermore, we provide a complete\nsystem architecture and define the protocols through which the different system\nentities can interact. We assess the performance of our approach against\nstate-of-the-art solutions, under realistic mobility datasets and system\nscenarios. Our RICH edge caching scheme improves significantly the content\navailability at the caches and reduces the required backhaul bandwidth, with\nbeneficial effects for both the end users and the network operators.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 08:57:31 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Mahmood", "Ahsan", ""], ["Casetti", "Claudio", ""], ["Chiasserini", "Carla Fabiana", ""], ["Giaccone", "Paolo", ""], ["Haerri", "Jerome", ""]]}, {"id": "1908.07240", "submitter": "Justin Iurman", "authors": "Justin Iurman, Benoit Donnet and Frank Brockners", "title": "Implementation of IOAM for IPv6 in the Linux Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-situ Operations, Administration, and Maintenance (IOAM) is currently under\nstandardization at the IETF. It allows for collecting telemetry and operational\ninformation along a path, within the data packet, as part of an existing\n(possibly additional) header. This paper discusses the very first\nimplementation of IOAM for the Linux kernel with IPv6 as encapsulation\nprotocol. We also propose a first preliminary evaluation of our implementation\nunder a controlled environment. Our IOAM implementation is available as open\nsource.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 09:33:40 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Iurman", "Justin", ""], ["Donnet", "Benoit", ""], ["Brockners", "Frank", ""]]}, {"id": "1908.07326", "submitter": "Xianfu Chen", "authors": "Xianfu Chen and Zhifeng Zhao and Celimuge Wu and Tao Chen and Honggang\n  Zhang and Mehdi Bennis", "title": "Secrecy Preserving in Stochastic Resource Orchestration for\n  Multi-Tenancy Network Slicing", "comments": "Accepted to Proc. IEEE GLOBECOM 2019. arXiv admin note: text overlap\n  with arXiv:1807.09350", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Network slicing is a proposing technology to support diverse services from\nmobile users (MUs) over a common physical network infrastructure. In this\npaper, we consider radio access network (RAN)-only slicing, where the physical\nRAN is tailored to accommodate both computation and communication\nfunctionalities. Multiple service providers (SPs, i.e., multiple tenants)\ncompete with each other to bid for a limited number of channels across the\nscheduling slots, aiming to provide their subscribed MUs the opportunities to\naccess the RAN slices. An eavesdropper overhears data transmissions from the\nMUs. We model the interactions among the non-cooperative SPs as a stochastic\ngame, in which the objective of a SP is to optimize its own expected long-term\npayoff performance. To approximate the Nash equilibrium solutions, we first\nconstruct an abstract stochastic game using the channel auction outcomes. Then\nwe linearly decompose the per-SP Markov decision process to simplify the\ndecision-makings and derive a deep reinforcement learning based scheme to\napproach the optimal abstract control policies. TensorFlow-based experiments\nverify that the proposed scheme outperforms the three baselines and yields the\nbest performance in average utility per MU per scheduling slot.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 13:11:00 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Chen", "Xianfu", ""], ["Zhao", "Zhifeng", ""], ["Wu", "Celimuge", ""], ["Chen", "Tao", ""], ["Zhang", "Honggang", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1908.07328", "submitter": "Soumen Kanrar", "authors": "Soumen Kanrar", "title": "Traffic Analysis for Storage Finding in Video on Demand System", "comments": "10 pages, 9 figures", "journal-ref": "Research Journal of Information Technology, ISSN 1815-7432, Year:\n  2017 | Volume: 9 | Issue: 2 | Page No.: 74-83", "doi": "10.3923/rjit.2017.74.83", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature survey typically predicated sharp growth for IP-based video\ntraffic i.e., 30% or more annually. For the Internet TV in mobile networks,\nvideo traffic growth rate is expected to rise 80% or more. These high growth\nrates of video traffic will account for a large portion of the bandwidth. The\nperformance of video-on-demand system during real-time data streaming greatly\ndepends on the session oriented data-storage finding in the mass scale\ndistributed storage architecture. At the storage end, data is broken up into\nmanageable chunks of data packets, which could be smoothly, deliver over the\nInternet. The objective of this study was to present the necessity of traffic\ncontrol and traffic analysis methodology in the video on demand system to\nminimize the hop count for finding exact media storage to retrieve video chunk\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 07:36:33 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Kanrar", "Soumen", ""]]}, {"id": "1908.07329", "submitter": "Daniel Canedo", "authors": "Daniel Rosa Can\\^edo and Alexandre Ricardo Soares Romariz", "title": "Data Analysis of Wireless Networks Using Classification Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last decade, there has been a great technological advance in the\ninfrastructure of mobile technologies. The increase in the use of wireless\nlocal area networks and the use of satellite services are also noticed. The\nhigh utilization rate of mobile devices for various purposes makes clear the\nneed to track wireless networks to ensure the integrity and confidentiality of\nthe information transmitted. Therefore, it is necessary to quickly and\nefficiently identify the normal and abnormal traffic of such networks, so that\nadministrators can take action. This work aims to analyze classification\ntechniques in relation to data from Wireless Networks, using some classes of\nanomalies pre-established according to some defined criteria of the MAC layer.\nFor data analysis, WEKA Data Mining software (Waikato Environment for Knowledge\nAnalysis) is used. The classification algorithms present a success rate in the\nclassification of viable data, being indicated in the use of intrusion\ndetection systems for wireless networks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:16:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Can\u00eado", "Daniel Rosa", ""], ["Romariz", "Alexandre Ricardo Soares", ""]]}, {"id": "1908.07334", "submitter": "Qi Chen", "authors": "Qi Chen, Qing Yang", "title": "Understanding Relative Network Delay inMicro-Energy Harvesting Wireless\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micro-energy harvesting wireless network (MEHWN) enables a perpetual network\ndeployment that cannot be achieved in traditional battery-operated\ncounterparts. Despite its sustainability, end-to-end delay in an MEHWN could be\nvery large, due to the large waiting delay on each hop in the network. In this\nwork, we consider an MEHWN where every node constantly switches between on and\noff states, due to the limited amount of harvested energy. The network delay of\nan MEHWN is not well understood because of the energy uncertainty,\nasynchronized working schedules, and complex network topology in an MEHWN. To\nclose this research gap, we define the relative network delay as the ratio\nbetween end-to-end delay and distance. Compared to previous works, we are able\nto identify a closed-form expression of the lower bound and a tighter upper\nbound of the relative network delay. The theoretical findings are verified in\nsimulations. Our theoretical analysis deepens the understanding about the\ninterplay of network delay, energy harvesting rate, and node density in an\nMEHWN.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 23:36:21 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Chen", "Qi", ""], ["Yang", "Qing", ""]]}, {"id": "1908.07335", "submitter": "Md Jalil Piran Prof.", "authors": "Md. Jalil Piran, Doug Young Suh", "title": "Learning-Driven Wireless Communications, towards 6G", "comments": null, "journal-ref": "2019 International Conference on Computing, Electronics &\n  Communications Engineering (iCCECE)", "doi": "10.1109/iCCECE46942.2019.8941882", "report-no": "19276363", "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fifth generation (5G) of wireless communication is in its infancy, and\nits evolving versions will be launched over the coming years. However,\naccording to exposing the inherent constraints of 5G and the emerging\napplications and services with stringent requirements e.g. latency, energy/bit,\ntraffic capacity, peak data rate, and reliability, telecom researchers are\nturning their attention to conceptualize the next generation of wireless\ncommunications, i.e. 6G. In this paper, we investigate 6G challenges,\nrequirements, and trends. Furthermore, we discuss how artificial intelligence\n(AI) techniques can contribute to 6G. Based on the requirements and solutions,\nwe identify some new fascinating services and use-cases of 6G, which can not be\nsupported by 5G appropriately. Moreover, we explain some research directions\nthat lead to the successful conceptualization and implementation of 6G.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 06:07:44 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Piran", "Md. Jalil", ""], ["Suh", "Doug Young", ""]]}, {"id": "1908.07337", "submitter": "Shree Krishna Sharma", "authors": "Shree Krishna Sharma, Isaac Woungang, Alagan Anpalagan, and Symeon\n  Chatzinotas", "title": "Towards Tactile Internet in Beyond 5G Era: Recent Advances, Current\n  Issues and Future Directions", "comments": "40 pages, 4 figures, 8 tables, submitted to IEEE Journal", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2980369", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile Internet (TI) is envisioned to create a paradigm shift from the\ncontent-oriented communications to steer/control-based communications by\nenabling real-time transmission of haptic information (i.e., touch, actuation,\nmotion, vibration, surface texture) over Internet in addition to the\nconventional audiovisual and data traffics. This emerging TI technology is\nexpected to create numerous opportunities for technology markets in a wide\nvariety of applications ranging from teleoperation systems and AR/VR to\nautomotive safety and eHealthcare towards addressing the complex problems of\nhuman society. However, the realization of TI over wireless media in the\nupcoming 5G and beyond networks creates various non-conventional communication\nchallenges and stringent requirements. To this end, this paper aims to provide\na holistic view on wireless TI along with a thorough review of the existing\nliterature, to identify and analyze the involved technical issues, to highlight\npotential solutions and to propose future research directions. First, starting\nwith the vision of TI and recent advances and a review of related\nsurvey/overview articles, we present a generalized framework for wireless TI in\nthe Beyond 5G Era including a TI architecture, main technical requirements, key\napplication areas and potential enabling technologies. Subsequently, we provide\na comprehensive review of the existing TI works by broadly categorizing them\ninto three main paradigms; namely, haptic communications, wireless AR/VR, and\nautonomous, intelligent and cooperative mobility systems. Next, potential\nenabling technologies across physical/MAC and network layers are identified and\ndiscussed in detail. Also, security and privacy issues of TI applications are\ndiscussed along with some promising enablers. Finally, we present some open\nresearch challenges and recommend promising future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 17:34:06 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Sharma", "Shree Krishna", ""], ["Woungang", "Isaac", ""], ["Anpalagan", "Alagan", ""], ["Chatzinotas", "Symeon", ""]]}, {"id": "1908.07370", "submitter": "Tahsina Farah Sanam", "authors": "Tahsina Farah Sanam, Hana Godrich", "title": "A Multi-View Discriminant Learning Approach for Indoor Localization\n  Using Bimodal Features of CSI", "comments": "12 pages,12 figures, Journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of location-based services, indoor localization is attracting\ngreat interests as it facilitates further ubiquitous environments.\nSpecifically, device free localization using wireless signals is getting\nincreased attention as human location is estimated using its impact on the\nsurrounding wireless signals without any active device tagged with subject. In\nthis paper, we propose MuDLoc, the first multi-view discriminant learning\napproach for device free indoor localization using both amplitude and phase\nfeatures of Channel State Information (CSI) from multiple APs. Multi-view\nlearning is an emerging technique in machine learning which improve performance\nby utilizing diversity from different view data. In MuDLoc, the localization is\nmodeled as a pattern matching problem, where the target location is predicted\nbased on similarity measure of CSI features of an unknown location with those\nof the training locations. MuDLoc implements Generalized Inter-view and\nIntra-view Discriminant Correlation Analysis (GI$^{2}$DCA), a discriminative\nfeature extraction approach using multi-view CSIs. It incorporates inter-view\nand intra-view class associations while maximizing pairwise correlations across\nmulti-view data sets. A similarity measure is performed to find the best match\nto localize a subject. Experimental results from two cluttered environments\nshow that MuDLoc can estimate location with high accuracy which outperforms\nother benchmark approaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 18:49:25 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Sanam", "Tahsina Farah", ""], ["Godrich", "Hana", ""]]}, {"id": "1908.07503", "submitter": "Aldebaro Klautau", "authors": "Igor Trindade, Cleverson Nahum, Camila Novaes, Daniel Cederholm,\n  Gyanesh Patra and Aldebaro Klautau", "title": "C-RAN Virtualization with OpenAirInterface", "comments": "2 pages, XXXVII Simp\\'osio Brasileiro De Telecomunica\\C{C}\\~Oes E\n  Processamento De Sinais - SBrT2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  C-RAN virtualization is a research topic with great interest since it allows\nto share baseband processing resources.Therefore, in this work, we report the\nimplementation of a virtualized LTE testbed environment of C-RAN by integrating\nthe OpenAirInterface (OAI) with Docker. Using the test bed,we conducted a\nworkload study to understand the computation resource demand of C-RAN software.\nVirtualization in containers has proven to be effective in creating a\nfunctional 4G network which achieves realistic results to facilitate research.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 17:28:09 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Trindade", "Igor", ""], ["Nahum", "Cleverson", ""], ["Novaes", "Camila", ""], ["Cederholm", "Daniel", ""], ["Patra", "Gyanesh", ""], ["Klautau", "Aldebaro", ""]]}, {"id": "1908.07592", "submitter": "Cenk G\\\"undo\\u{g}an", "authors": "Cenk G\\\"undo\\u{g}an, Jakob Pfender, Michael Frey, Thomas C. Schmidt,\n  Felix Shzu-Juraschek, Matthias W\\\"ahlisch", "title": "Gain More for Less: The Surprising Benefits of QoS Management in\n  Constrained NDN Networks", "comments": null, "journal-ref": "Proceedings of ACM ICN 2019", "doi": "10.1145/3357150.3357404", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality of Service (QoS) in the IP world mainly manages forwarding resources,\ni.e., link capacities and buffer spaces. In addition, Information Centric\nNetworking (ICN) offers resource dimensions such as in-network caches and\nforwarding state. In constrained wireless networks, these resources are scarce\nwith a potentially high impact due to lossy radio transmission. In this paper,\nwe explore the two basic service qualities (i) prompt and (ii) reliable traffic\nforwarding for the case of NDN. The resources we take into account are\nforwarding and queuing priorities, as well as the utilization of caches and of\nforwarding state space. We treat QoS resources not only in isolation, but\ncorrelate their use on local nodes and between network members. Network-wide\ncoordination is based on simple, predefined QoS code points. Our findings\nindicate that coordinated QoS management in ICN is more than the sum of its\nparts and exceeds the impact QoS can have in the IP world.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:12:38 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["G\u00fcndo\u011fan", "Cenk", ""], ["Pfender", "Jakob", ""], ["Frey", "Michael", ""], ["Schmidt", "Thomas C.", ""], ["Shzu-Juraschek", "Felix", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "1908.07653", "submitter": "Hazrat Ali", "authors": "Kashif Sultan, Hazrat Ali, Haris Anwaar, Kabo Poloko Nkabiti, Adeel\n  Ahamd, Zhongshan Zhang", "title": "Understanding and Partitioning Mobile Traffic using Internet Activity\n  Records Data -- A Spatiotemporal Approach", "comments": "2019 28th Wireless and Optical Communications Conference (WOCC)", "journal-ref": null, "doi": "10.1109/WOCC.2019.8770653", "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The internet activity records (IARs) of a mobile cellular network posses\nsignificant information which can be exploited to identify the network's\nefficacy and the mobile users' behavior. In this work, we extract useful\ninformation from the IAR data and identify a healthy predictability of\nspatio-temporal pattern within the network traffic. The information extracted\nis helpful for network operators to plan effective network configuration and\nperform management and optimization of network's resources. We report\nexperimentation on spatiotemporal analysis of IAR data of the Telecom Italia.\nBased on this, we present mobile traffic partitioning scheme. Experimental\nresults of the proposed model is helpful in modelling and partitioning of\nnetwork traffic patterns.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 06:29:44 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Sultan", "Kashif", ""], ["Ali", "Hazrat", ""], ["Anwaar", "Haris", ""], ["Nkabiti", "Kabo Poloko", ""], ["Ahamd", "Adeel", ""], ["Zhang", "Zhongshan", ""]]}, {"id": "1908.07782", "submitter": "Chenghao Hu", "authors": "Chenghao Hu, Jingyan Jiang, Zhi Wang", "title": "Decentralized Federated Learning: A Segmented Gossip Approach", "comments": "Accepted to the 1st International Workshop on Federated Machine\n  Learning for User Privacy and Data Confidentiality (FML'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging concern about data privacy and security has motivated the\nproposal of federated learning, which allows nodes to only synchronize the\nlocally-trained models instead their own original data. Conventional federated\nlearning architecture, inherited from the parameter server design, relies on\nhighly centralized topologies and the assumption of large nodes-to-server\nbandwidths. However, in real-world federated learning scenarios the network\ncapacities between nodes are highly uniformly distributed and smaller than that\nin a datacenter. It is of great challenges for conventional federated learning\napproaches to efficiently utilize network capacities between nodes. In this\npaper, we propose a model segment level decentralized federated learning to\ntackle this problem. In particular, we propose a segmented gossip approach,\nwhich not only makes full utilization of node-to-node bandwidth, but also has\ngood training convergence. The experimental results show that even the training\ntime can be highly reduced as compared to centralized federated learning.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 10:21:43 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Hu", "Chenghao", ""], ["Jiang", "Jingyan", ""], ["Wang", "Zhi", ""]]}, {"id": "1908.07828", "submitter": "Muhammad Junaid Farooq", "authors": "Muhammad Junaid Farooq, Quanyan Zhu", "title": "IoT Supply Chain Security: Overview, Challenges, and the Road Ahead", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply chain is emerging as the next frontier of threats in the rapidly\nevolving IoT ecosystem. It is fundamentally more complex compared to\ntraditional ICT systems. We analyze supply chain risks in IoT systems and their\nunique aspects, discuss research challenges in supply chain security, and\nidentify future research directions.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 21:47:41 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Farooq", "Muhammad Junaid", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1908.07903", "submitter": "Mohamed Musa", "authors": "Mohamed Musa, Taisir Elgorashi, and Jaafar Elmirghani", "title": "Energy Efficient Routing and Network Coding in Core Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose network coding as an energy efficient data transmission technique\nin core networks with non-bypass and bypass routing approaches. The improvement\nin energy efficiency is achieved through reduction in the traffic flows passing\nthrough intermediate nodes. A mixed integer linear program (MILP) is developed\nto optimize the use of network resources, and the results show that our\nproposed network coding approach introduces up to 33% power savings for the\nnon-bypass case compared with the conventional architectures. For the bypass\ncase, 28% power savings are obtained considering futuristic network components\npower consumption. A heuristic based on the minimum hop count routing shows\npower savings comparable to the MILP results. Furthermore, we study how the\nchange in network topology affects the savings produced by network coding. The\nresults show that the savings are proportional to the average hop count of the\nnetwork topology. We also derive power consumption analytic bounds and closed\nform expressions for networks that implement network coding and thus also\nverify the results obtained by the MILP model.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 15:01:28 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Musa", "Mohamed", ""], ["Elgorashi", "Taisir", ""], ["Elmirghani", "Jaafar", ""]]}, {"id": "1908.07951", "submitter": "Vincent Lee", "authors": "Vincent Lee and Dominic OBrien", "title": "Secure practical indoor optical wireless communications using quantum\n  key distribution", "comments": "Page 10, experimental results. Authors decision to revisit and\n  resolve orders of magnitude discrepancy", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Quantum Key Distribution (QKD) can guarantee security for practical indoor\noptical wireless environments. The key challenges are to mitigate artificial\nlighting and ambient light at the receiver. A new spectral region for QKD is\nproposed and an ideal QKD link model is simulated with experimental ambient\nlight power measurements. Simulation, modelling, and analysis indicates that\nthe carbon dioxide and water absorption band (1370 nm) is a new wavelength\nregion for QKD operation in indoor optical wireless environments. For a\nfeasible QKD link, approximately 20 dB of signal to noise ratio (SNR) is\nrequired and a maximum quantum bit error rate (QBER) of 11% when using the BB84\nprotocol. Links in the new spectral region with a FOV of several degrees are\nfeasible, depending on available components.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 00:51:50 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 01:37:07 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 17:07:02 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Lee", "Vincent", ""], ["OBrien", "Dominic", ""]]}, {"id": "1908.08229", "submitter": "Ahmed Elbery Dr", "authors": "Ahmed Elbery, Hesham Rakha, Mustafa ElNainay", "title": "Vehicular Communication and Mobility Sustainability: the Mutual Impacts\n  in Large-scale Smart Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Transportation Systems (ITSs) is the backbone of transportation\nservices in smart cities. ITSs produce better-informed decisions using\nreal-time data gathered from connected vehicles. In ITSs, Vehicular Ad hoc\nNetwork (VANET) is a communication infrastructure responsible for exchanging\ndata between vehicles and Traffic Management Centers (TMC). VANET performance\n(packet delay and drop rate) can affect the performance of ITS applications.\nFurthermore, the distribution of communicating vehicles affects the VANET\nperformance. So, capturing this mutual impact between communication and\ntransportation is crucial to understanding the behavior of ITS applications.\nThus, this paper focuses on studying the mutual impact of VANET communication\nand mobility in city-level ITSs. We first introduce a new scalable and\ncomputationally fast framework for modeling large-scale ITSs including\ncommunication and mobility. In the proposed framework, we develop and validate\na new mathematical model for the IEEE 802.11p MAC protocol which can capture\nthe behavior of medium access and queuing process. This MAC model is then\nintegrated within a microscopic traffic simulator to accurately simulate\nvehicle mobility. This integrated framework can accurately capture the\nmobility, communication, and the spatiotemporal impacts in large-scale ITSs.\nSecondly, the proposed framework is used to study the impact of communication\non eco-routing navigation performance in a real large-scale network with real\ncalibrated vehicular traffic. The paper demonstrates that communication\nperformance can significantly degrade the performance of the dynamic\neco-routing navigation when the traffic density is high. It also shows that the\nfuel consumption can be increased due to lack of communication reliability.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 07:14:29 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Elbery", "Ahmed", ""], ["Rakha", "Hesham", ""], ["ElNainay", "Mustafa", ""]]}, {"id": "1908.08338", "submitter": "Tania Panayiotou", "authors": "Tania Panayiotou, Giannis Savva, Ioannis Tomkos, Georgios Ellinas", "title": "Centralized and Distributed Machine Learning-Based QoT Estimation for\n  Sliceable Optical Networks", "comments": "accepted for presentation at the IEEE GLOBECOM 2019", "journal-ref": null, "doi": "10.1109/GLOBECOM38437.2019.9013962", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic network slicing has emerged as a promising and fundamental framework\nfor meeting 5G's diverse use cases. As machine learning (ML) is expected to\nplay a pivotal role in the efficient control and management of these networks,\nin this work we examine the ML-based Quality-of-Transmission (QoT) estimation\nproblem under the dynamic network slicing context, where each slice has to meet\na different QoT requirement. We examine ML-based QoT frameworks with the aim of\nfinding QoT model/s that are fine-tuned according to the diverse QoT\nrequirements. Centralized and distributed frameworks are examined and compared\naccording to their accuracy and training time. We show that the distributed QoT\nmodels outperform the centralized QoT model, especially as the number of\ndiverse QoT requirements increases.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:38:54 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 11:22:57 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Panayiotou", "Tania", ""], ["Savva", "Giannis", ""], ["Tomkos", "Ioannis", ""], ["Ellinas", "Georgios", ""]]}, {"id": "1908.08576", "submitter": "Yu Ye", "authors": "Yu Ye, Ming Xiao, Mikael Skoglund", "title": "Mobility-aware Content Preference Learning in Decentralized Caching\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the drastic increase of mobile traffic, wireless caching is proposed\nto serve repeated requests for content download. To determine the caching\nscheme for decentralized caching networks, the content preference learning\nproblem based on mobility prediction is studied. We first formulate preference\nprediction as a decentralized regularized multi-task learning (DRMTL) problem\nwithout considering the mobility of mobile terminals (MTs). The problem is\nsolved by a hybrid Jacobian and Gauss-Seidel proximal multi-block alternating\ndirection method (ADMM) based algorithm, which is proven to conditionally\nconverge to the optimal solution with a rate $O(1/k)$. Then we use the tool of\n\\textit{Markov renewal process} to predict the moving path and sojourn time for\nMTs, and integrate the mobility pattern with the DRMTL model by reweighting the\ntraining samples and introducing a transfer penalty in the objective. We solve\nthe problem and prove that the developed algorithm has the same convergence\nproperty but with different conditions. Through simulation we show the\nconvergence analysis on proposed algorithms. Our real trace driven experiments\nillustrate that the mobility-aware DRMTL model can provide a more accurate\nprediction on geography preference than DRMTL model. Besides, the hit ratio\nachieved by most popular proactive caching (MPC) policy with preference\npredicted by mobility-aware DRMTL outperforms the MPC with preference from\nDRMTL and random caching (RC) schemes.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:52:17 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Ye", "Yu", ""], ["Xiao", "Ming", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1908.08590", "submitter": "Salvatore Di Girolamo", "authors": "Salvatore Di Girolamo, Konstantin Taranov, Andreas Kurth, Michael\n  Schaffner, Timo Schneider, Jakub Ber\\'anek, Maciej Besta, Luca Benini, Duncan\n  Roweth, Torsten Hoefler", "title": "Network-Accelerated Non-Contiguous Memory Transfers", "comments": "In Proceedings of the International Conference for High Performance\n  Computing, Networking, Storage and Analysis (SC19), Nov. 2019", "journal-ref": null, "doi": "10.1145/3295500.3356189", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications often communicate data that is non-contiguous in the send- or\nthe receive-buffer, e.g., when exchanging a column of a matrix stored in\nrow-major order. While non-contiguous transfers are well supported in HPC\n(e.g., MPI derived datatypes), they can still be up to 5x slower than\ncontiguous transfers of the same size. As we enter the era of network\nacceleration, we need to investigate which tasks to offload to the NIC: In this\nwork we argue that non-contiguous memory transfers can be transparently\nnetworkaccelerated, truly achieving zero-copy communications. We implement and\nextend sPIN, a packet streaming processor, within a Portals 4 NIC SST model,\nand evaluate strategies for NIC-offloaded processing of MPI datatypes, ranging\nfrom datatype-specific handlers to general solutions for any MPI datatype. We\ndemonstrate up to 10x speedup in the unpack throughput of real applications,\ndemonstrating that non-contiguous memory transfers are a first-class candidate\nfor network acceleration.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 20:52:23 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Di Girolamo", "Salvatore", ""], ["Taranov", "Konstantin", ""], ["Kurth", "Andreas", ""], ["Schaffner", "Michael", ""], ["Schneider", "Timo", ""], ["Ber\u00e1nek", "Jakub", ""], ["Besta", "Maciej", ""], ["Benini", "Luca", ""], ["Roweth", "Duncan", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1908.08866", "submitter": "Ajay Bhardwaj", "authors": "Ajay Bhardwaj and Samar Agnihotri", "title": "Multiple D2D Multicasts in Underlay Cellular Networks", "comments": "34 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multicasting for disseminating popular data is an interesting solution for\nimproving the energy and spectral efficiencies of cellular networks. To improve\nthe achievable performance of such networks, underlay device-to-device (D2D)\nmulticast communication offers a practical solution. However, despite\nsignificant potential for providing higher throughput and lower delay,\nimplementing underlay D2D multicast communication poses several challenges,\nsuch as mutual interference among cellular users (CUs) and D2D multicast groups\n(MGs), and overhead signaling to provide channel state information, that may\nlimit potential gains. We study a scenario where multiple D2D multicast groups\nmay share a CU's uplink channel. We formulate an optimization problem to\nmaximize the achievable system throughput while fulfilling quality of service\n(QoS) requirements of every CU and D2D MGs, subject to their corresponding\nmaximum transmit power constraints. The formulated optimization problem is an\ninstance of mixed integer non-linear programming (MINLP) problem, which is\ncomputationally intractable, in general. Therefore, to find a feasible\nsolution, we propose a pragmatic two-step process of channel allocation and\npower allocation. In the first-step, we propose a channel allocation algorithm,\nwhich determines the subset of MGs that may share a channel subject to criteria\nbased on two different parameters: interference and outage probabilities. Then,\nwe propose an algorithm to allocate power to these MG subsets that maximizes\nthe system throughput, while satisfying transmit power constraint. Numerical\nresults show the efficacy of proposed approach in terms of higher achievable\nsum throughput and better spectrum efficiency with respect to various existing\nschemes.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 15:27:48 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 07:27:23 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Bhardwaj", "Ajay", ""], ["Agnihotri", "Samar", ""]]}, {"id": "1908.08872", "submitter": "Roman Kovalchukov", "authors": "Roman Kovalchukov, Dmitri Moltchanov, Yuliya Gaidamaka and Ekaterina\n  Bobrikova", "title": "An Accurate Approximation of Resource Request Distributions in\n  Millimeter Wave 3GPP New Radio Systems", "comments": "The 19th International Conference on Next Generation Wired/Wireless\n  Networks and Systems (New2An 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently standardized millimeter wave-based 3GPP New Radio technology is\nexpected to become an enabler for both enhanced Mobile Broadband (eMBB) and\nultra-reliable low latency communication (URLLC) services specified to future\n5G systems. One of the first steps in mathematical modeling of such systems is\nthe characterization of the session resource request probability mass function\n(pmf) as a function of the channel conditions, cell size, application demands,\nuser location and system parameters including modulation and coding schemes\nemployed at the air interface. Unfortunately, this pmf cannot be expressed via\nelementary functions. In this paper, we develop an accurate approximation of\nthe sought pmf. First, we show that Normal distribution provides a fairly\naccurate approximation to the cumulative distribution function (CDF) of the\nsignal-to-noise ratio for communication systems operating in the millimeter\nfrequency band, further allowing evaluating the resource request pmf via error\nfunction. We also investigate the impact of shadow fading on the resource\nrequest pmf.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 15:38:10 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Kovalchukov", "Roman", ""], ["Moltchanov", "Dmitri", ""], ["Gaidamaka", "Yuliya", ""], ["Bobrikova", "Ekaterina", ""]]}, {"id": "1908.08900", "submitter": "Grzegorz Cisek", "authors": "Grzegorz Cisek and Tomasz P. Zieli\\'nski", "title": "Frequency-Domain Modeling of OFDM Transmission with Insufficient Cyclic\n  Prefix using Toeplitz Matrices", "comments": "Conference: IEEE VTC-Fall 2018, 5 pages, 3 figures", "journal-ref": "In proc. IEEE 88th Vehicular Technology Conference (VTC-Fall),\n  Chicago, USA, 27-30 August 2018", "doi": "10.1109/VTCFall.2018.8690835", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel mathematical framework is proposed to model Intersymbol Interference\n(ISI) phenomenon in wireless communication systems based on Orthogonal\nFrequency Division Multiplexing (OFDM) with or without cyclic prefix. The\nframework is based on a new formula to calculate the Fast Fourier Transform\n(FFT) of a triangular Toeplitz matrix, which is derived and proven in this\npaper. It is shown that distortion inducted by the ISI from a given subcarrier\nis the most significant for the closest subcarriers and the contribution decays\nas the distance between subcarriers grows. According to numerical experiments,\nknowledge of ISI coefficients concentrated around the diagonal of Channel\nFrequency Response (CFR) matrix improves the receiver's error floor\nsignificantly. The potential use of the framework for real-time frequency\ndomain channel simulation was also investigated and demonstrated to be more\nefficient than conventional time domain Tapped Delay Line (TDL) model when a\nnumber of simulated users is high.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 16:49:36 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Cisek", "Grzegorz", ""], ["Zieli\u0144ski", "Tomasz P.", ""]]}, {"id": "1908.08921", "submitter": "Roberto Morabito", "authors": "Edgar Ramos, Roberto Morabito", "title": "Intelligence Stratum for IoT. Architecture Requirements and Functions", "comments": "This article has been accepted for publication in the 17th IEEE\n  International Conference on Pervasive Intelligence and Computing (PICom 2019)\n  Copyright 2019 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Artificial Intelligence (AI) is becoming increasingly pervasive\nand relevant in many different application areas. Researchers are putting a\nconsiderable effort to take full advantage of the power of AI, while trying to\novercome the technical challenges that are intrinsically linked to almost any\ndomain area of application, such as the Internet of Things (IoT). One of the\nbiggest problems related to the use of AI in IoT is related to the difficulty\nof coping with the wide variety of protocols and software technologies used, as\nwell as with the heterogeneity of the hardware resources consuming the AI. The\nscattered IoT landscape accentuates the limitations on interoperability,\nespecially visible in the deployment of AI, affecting the seamless AI\nlife-cycle management as well. In this paper, it is discussed how to enable AI\ndistribution in IoT by introducing a layered intelligence architecture that\naims to face the undertaken challenges taking into account the special\nrequirements of nowadays IoT networks. It describes the main characteristics of\nthe new paradigm architecture, highlighting what are the implications of its\nadoption from use cases perspective and their requirements. Finally, a set of\nopen technical and research challenges are enumerated to reach the full\npotential of the intelligence distribution's vision.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 13:53:49 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Ramos", "Edgar", ""], ["Morabito", "Roberto", ""]]}, {"id": "1908.08922", "submitter": "Roberto Morabito", "authors": "Edgar Ramos, Roberto Morabito, and Jani-Pekka Kainulainen", "title": "Distributing Intelligence to the Edge and Beyond", "comments": "This article has been accepted for publication in IEEE Computational\n  Intelligence Magazine (Copyright IEEE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Intelligence (MI) technologies have revolutionized the design and\napplications of computational intelligence systems, by introducing remarkable\nscientific and technological enhancements across domains. MI can improve\nInternet of Things (IoT) in several ways, such as optimizing the management of\nlarge volumes of data or improving automation and transmission in large-scale\nIoT deployments. When considering MI in the IoT context, MI services deployment\nmust account for the latency demands and network bandwidth requirements. To\nthis extent, moving the intelligence towards the IoT end-device aims to address\nsuch requirements and introduces the notion of Distributed MI (D-MI) also in\nthe IoT context. However, current D-MI deployments are limited by the lack of\nMI interoperability. Currently, the intelligence is tightly bound to the\napplication that exploits it, limiting the provisioning of that specific\nintelligence service to additional applications. The objective of this article\nis to propose a novel approach to cope with such constraints. It focuses on\ndecoupling the intelligence from the application by revising the traditional\ndevice's stack and introducing an intelligence layer that provides services to\nthe overlying application layer. This paradigm aims to provide final users with\nmore control and accessibility of intelligence services by boosting providers'\nincentives to develop solutions that could theoretically reach any device.\nBased on the definition of this emerging paradigm, we explore several aspects\nrelated to the intelligence distribution and its impact in the whole MI\necosystem.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 13:48:09 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Ramos", "Edgar", ""], ["Morabito", "Roberto", ""], ["Kainulainen", "Jani-Pekka", ""]]}, {"id": "1908.09002", "submitter": "Chris Xiaoxuan Lu", "authors": "Chris Xiaoxuan Lu, Xuan Kan, Bowen Du, Changhao Chen, Hongkai Wen,\n  Andrew Markham, Niki Trigoni and John Stankovic", "title": "Autonomous Learning for Face Recognition in the Wild via Ambient\n  Wireless Cues", "comments": "11 pages, accepted in the Web Conference (WWW'2019)", "journal-ref": null, "doi": "10.1145/3308558.3313398", "report-no": null, "categories": "cs.CV cs.LG cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Facial recognition is a key enabling component for emerging Internet of\nThings (IoT) services such as smart homes or responsive offices. Through the\nuse of deep neural networks, facial recognition has achieved excellent\nperformance. However, this is only possibly when trained with hundreds of\nimages of each user in different viewing and lighting conditions. Clearly, this\nlevel of effort in enrolment and labelling is impossible for wide-spread\ndeployment and adoption. Inspired by the fact that most people carry smart\nwireless devices with them, e.g. smartphones, we propose to use this wireless\nidentifier as a supervisory label. This allows us to curate a dataset of facial\nimages that are unique to a certain domain e.g. a set of people in a particular\noffice. This custom corpus can then be used to finetune existing pre-trained\nmodels e.g. FaceNet. However, due to the vagaries of wireless propagation in\nbuildings, the supervisory labels are noisy and weak.We propose a novel\ntechnique, AutoTune, which learns and refines the association between a face\nand wireless identifier over time, by increasing the inter-cluster separation\nand minimizing the intra-cluster distance. Through extensive experiments with\nmultiple users on two sites, we demonstrate the ability of AutoTune to design\nan environment-specific, continually evolving facial recognition system with\nentirely no user effort.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:39:09 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Lu", "Chris Xiaoxuan", ""], ["Kan", "Xuan", ""], ["Du", "Bowen", ""], ["Chen", "Changhao", ""], ["Wen", "Hongkai", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""], ["Stankovic", "John", ""]]}, {"id": "1908.09042", "submitter": "Hamed Rahimi", "authors": "Parsa Rajabzadeh, Amin Pishevar and Hamed Rahimi", "title": "SIDLE: Semantically Intelligent Distributed Leader Election Algorithm\n  for Wireless Sensor Networks", "comments": "The First International Conference of Smart City, 2019, Apadana\n  University, Shiraz, Iran\n  https://www.civilica.com/Paper-SMARTCITYC01-SMARTCITYC01_100.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the deployment of a group of Wireless Sensor and\nActuator Network (WSAN) for Internet of Thing (IoT) systems in rural regions\ndeployed by a drone dropping sensors and actuators at a certain position as a\nmesh of a hexagonal form. Nodes are heterogeneous in hardware and functionality\nthus not all nodes are able to transfer data directly to the base station.\nPrimitive ones are only capable of collecting local data. However, ones that\nare more sophisticated are equipped with long-range radio telemetry and more\ncomputational power. Power optimization is one of the crucial factors in\ndesigning WSANs. Total power consumption must be minimized, as sensors are\nself-managed. It is not feasible to collect sensors on time bases and recharge\nthe batteries. Therefore, energy consumption optimization and harvesting green\nenergy are other factors that are considered. In this regard, protocols are\ndesigned in a way to support such requirements. The preprocessed data are first\ncollected and combined by the leaders at each hexagonal cell. Then, the\ninformation packets are sent to the head clusters. Consequently, head clusters\nreprocess the received information and depict a better global view of the zone,\nusing a variety of the received information. Finally, the processed information\nis sent to the nearest base station or a mobile drone.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 22:19:15 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 21:06:30 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Rajabzadeh", "Parsa", ""], ["Pishevar", "Amin", ""], ["Rahimi", "Hamed", ""]]}, {"id": "1908.09047", "submitter": "Rohit Singh Mr", "authors": "Rohit Singh and Douglas Sicker", "title": "Parameter Modeling for Small-Scale Mobility in Indoor THz Communication", "comments": "To appear in IEEE GLOBECOM 2019. The document has 6 pages, 16\n  figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite such challenges as high path loss and equipment cost, THz\ncommunication is becoming one of the potentially viable means through which\nultra-high data rate can be achieved. To compensate for the high path loss, we\npresent parameter modeling for indoor THz communication. To maximize efficient\nand opportunistic use of resources, we analyze the potential workarounds for a\nsingle access point to satisfy most of the mobile terminals by varying such\nparameters as humidity, distance, frequency windows, beamwidths, antenna\nplacement, and user mobility type. One promising parameter is antenna\nbeamwidth, where narrower beams results in higher antenna gain. However, this\ncan lead to \"\\textit{beamwidth dilemma}\" scenario, where narrower beamwidth can\nresult in significant outages due to device mobility and orientation. In this\npaper, we address this challenge by presenting a mobility model that performs\nan extensive analysis of different human mobility scenarios, where each\nscenario has different data rate demands and movement patterns. We observe that\nfor mobile users, there are optimal beamwidths that are affected by the\nmobility type (high mobility, constrained mobility, and low mobility) and AP\nplacement.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 22:46:12 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Singh", "Rohit", ""], ["Sicker", "Douglas", ""]]}, {"id": "1908.09068", "submitter": "Alex Horn", "authors": "Alex Horn and Ali Kheradmand and Mukul R. Prasad", "title": "A Precise and Expressive Lattice-theoretical Framework for Efficient\n  Network Verification", "comments": "ICNP'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network verification promises to detect errors, such as black holes and\nforwarding loops, by logically analyzing the control or data plane. To do so\nefficiently, the state-of-the-art (e.g., Veriflow) partitions packet headers\nwith identical forwarding behavior into the same packet equivalence class\n(PEC).\n  Recently, Yang and Lam showed how to construct the minimal set of PECs,\ncalled atomic predicates. Their construction uses Binary Decision Diagrams\n(BDDs). However, BDDs have been shown to incur significant overhead per packet\nheader bit, performing poorly when analyzing large-scale data centers. The\noverhead of atomic predicates prompted ddNF to devise a specialized data\nstructure of Ternary Bit Vectors (TBV) instead.\n  However, TBVs are strictly less expressive than BDDs. Moreover, unlike atomic\npredicates, ddNF's set of PECs is not minimal. We show that ddNF's\nnon-minimality is due to empty PECs. In addition, empty PECs are shown to\ntrigger wrong analysis results. This reveals an inherent tension between\nprecision, expressiveness and performance in formal network verification.\n  Our paper resolves this tension through a new lattice-theoretical\nPEC-construction algorithm, #PEC, that advances the field as follows: (i) #PEC\ncan encode more kinds of forwarding rules (e.g., ip-tables) than ddNF and\nVeriflow, (ii) #PEC verifies a wider class of errors (e.g., shadowed rules)\nthan ddNF, and (iii) on a broad range of real-world datasets, #PEC is 10X\nfaster than atomic predicates. By achieving precision, expressiveness and\nperformance, this paper answers a longstanding quest that has spanned three\ngenerations of formal network analysis techniques.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 01:31:57 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Horn", "Alex", ""], ["Kheradmand", "Ali", ""], ["Prasad", "Mukul R.", ""]]}, {"id": "1908.09070", "submitter": "Max Noormohammadpour", "authors": "Max Noormohammadpour, Ajitesh Srivastava, Cauligi S. Raghavendra", "title": "Optimizing Inter-Datacenter Tail Flow Completion Times using Best\n  Worst-case Routing", "comments": "Accepted for publication in the 2019 57th Annual Allerton Conference\n  on Communication, Control, and Computing (Allerton)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow routing over inter-datacenter networks is a well-known problem where the\nnetwork assigns a path to a newly arriving flow potentially according to the\nnetwork conditions and the properties of the new flow. An essential system-wide\nperformance metric for a routing algorithm is the flow completion times, which\naffect the performance of applications running across multiple datacenters.\nCurrent static and dynamic routing approaches do not take advantage of flow\nsize information in routing, which is practical in a controlled environment\nsuch as inter-datacenter networks that are managed by the datacenter operators.\nIn this paper, we discuss Best Worst-case Routing (BWR), which aims at\noptimizing the tail completion times of long-running flows over\ninter-datacenter networks with non-uniform link capacities. Since finding the\npath with the best worst-case completion time for a new flow is NP-Hard, we\ninvestigate two heuristics, BWRH and BWRHF, which use two different upper\nbounds on the worst-case completion times for routing. We evaluate BWRH and\nBWRHF against several real WAN topologies and multiple traffic patterns.\nAlthough BWRH better models the BWR problem, BWRH and BWRHF show negligible\ndifference across various system-wide performance metrics, while BWRHF being\nsignificantly faster. Furthermore, we show that compared to other popular\nrouting heuristics, BWRHF can reduce the mean and tail flow completion times by\nover $1.5\\times$ and $2\\times$, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 02:04:37 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Noormohammadpour", "Max", ""], ["Srivastava", "Ajitesh", ""], ["Raghavendra", "Cauligi S.", ""]]}, {"id": "1908.09088", "submitter": "Felix Hamza-Lup", "authors": "Paul N. Borza, Mihai Machedon-Pisu, Felix G. Hamza-Lup", "title": "Design of Wireless Sensors for IoT with Energy Storage and Communication\n  Channel Heterogeneity", "comments": null, "journal-ref": "MDPI Journal (2019)", "doi": "10.3390/s19153364", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Wireless Sensors (AWSs) are at the core of every Wireless Sensor\nNetwork (WSN). Current AWS technology allows the development of many IoT-based\napplications, ranging from military to bioengineering and from industry to\neducation. The energy optimization of AWSs depends mainly on: Structural,\nfunctional, and application specifications. The holistic design methodology\naddresses all the factors mentioned above. In this sense, we propose an\noriginal solution based on a novel architecture that duplicates the\ntransceivers and also the power source using a hybrid storage system. By\nidentifying the consumption needs of the transceivers, an appropriate\nmethodology for sizing and controlling the power flow for the power source is\nproposed. The paper emphasizes the fusion between information, communication,\nand energy consumption of the AWS in terms of spectrum information through a\nset of transceiver testing scenarios, identifying the main factors that\ninfluence the sensor node design and their inter-dependencies. Optimization of\nthe system considers all these factors obtaining an energy efficient AWS,\npaving the way towards autonomous sensors by adding an energy harvesting\nelement to them.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 03:54:36 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Borza", "Paul N.", ""], ["Machedon-Pisu", "Mihai", ""], ["Hamza-Lup", "Felix G.", ""]]}, {"id": "1908.09271", "submitter": "Joachim Neu", "authors": "Joachim Neu, Muriel M\\'edard", "title": "Babel Storage: Uncoordinated Content Delivery from Multiple Coded\n  Storage Systems", "comments": null, "journal-ref": null, "doi": "10.1109/GLOBECOM38437.2019.9013383", "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In future content-centric networks, content is identified independently of\nits location. From an end-user's perspective, individual storage systems\ndissolve into a seemingly omnipresent structureless `storage fog'. Content\nshould be delivered oblivious of the network topology, using multiple storage\nsystems simultaneously, and at minimal coordination overhead. Prior works have\naddressed the advantages of error correction coding for distributed storage and\ncontent delivery separately. This work takes a comprehensive approach to\nhighlighting the tradeoff between storage overhead and transmission overhead in\nuncoordinated content delivery from multiple coded storage systems.\n  Our contribution is twofold. First, we characterize the tradeoff between\nstorage and transmission overhead when all participating storage systems employ\nthe same code. Second, we show that the resulting stark inefficiencies can be\navoided when storage systems use diverse codes. What is more, such code\ndiversity is not just technically desirable, but presumably will be the reality\nin the increasingly heterogeneous networks of the future. To this end, we show\nthat a mix of Reed-Solomon, low-density parity-check and random linear network\ncodes achieves close-to-optimal performance at minimal coordination and\noperational overhead.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 08:15:13 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Neu", "Joachim", ""], ["M\u00e9dard", "Muriel", ""]]}, {"id": "1908.09334", "submitter": "Suzhi Bi", "authors": "Binqi He, Suzhi Bi, Hong Xing, and Xiaohui Lin", "title": "Collaborative Computation Offloading in Wireless Powered Mobile-Edge\n  Computing Systems", "comments": "The paper is accepted for publication by IEEE GLOBECOM 2019, at\n  Waikoloa, HI, USA, in Dec. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a novel user cooperation model in a wireless powered\nmobile edge computing system where two wireless users harvest wireless power\ntransferred by one energy node and can offload part of their computation tasks\nto an edge server (ES) for remote execution. In particular, we consider that\nthe direct communication link between one user to the ES is blocked, such that\nthe other user acts as a relay to forward its offloading data to the server.\nMeanwhile, instead of forwarding all the received task data, we also allow the\nhelping user to compute part of the received task locally to reduce the\npotentially high energy and time cost on task offloading to the ES. Our aim is\nto maximize the amount of data that can be processed within a given time frame\nof the two users by jointly optimizing the amount of task data computed at each\ndevice (users and ES), the system time allocation, the transmit power and CPU\nfrequency of the users. We propose an efficient method to find the optimal\nsolution and show that the proposed user cooperation can effectively enhance\nthe computation performance of the system compared to other representative\nbenchmark methods under different scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 14:13:26 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 16:13:56 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["He", "Binqi", ""], ["Bi", "Suzhi", ""], ["Xing", "Hong", ""], ["Lin", "Xiaohui", ""]]}, {"id": "1908.09501", "submitter": "Nasir Saeed", "authors": "Nasir Saeed, Ahmed Elzanaty, Heba Almorad, Hayssam Dahrouj, Tareq Y.\n  Al-Naffouri, Mohamed-Slim Alouini", "title": "CubeSat Communications: Recent Advances and Future Challenges", "comments": "Accepted in IEEE Communications Surveys and Tutorials", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the increasing number of space-related applications, research in the\nemerging space industry is becoming more and more attractive. One compelling\narea of current space research is the design of miniaturized satellites, known\nas CubeSats, which are enticing because of their numerous applications and low\ndesign-and-deployment cost. The new paradigm of connected space through\nCubeSats makes possible a wide range of applications, such as Earth remote\nsensing, space exploration, and rural connectivity. CubeSats further provide a\ncomplementary connectivity solution to the pervasive Internet of Things (IoT)\nnetworks, leading to a globally connected cyber-physical system. This paper\npresents a holistic overview of various aspects of CubeSat missions and\nprovides a thorough review of the topic from both academic and industrial\nperspectives. We further present recent advances in the area of CubeSat\ncommunications, with an emphasis on constellation-and-coverage issues, channel\nmodeling, modulation and coding, and networking. Finally, we identify several\nfuture research directions for CubeSat communications, including Internet of\nspace things, low-power long-range networks, and machine learning for CubeSat\nresource allocation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 07:19:15 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 11:47:53 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Saeed", "Nasir", ""], ["Elzanaty", "Ahmed", ""], ["Almorad", "Heba", ""], ["Dahrouj", "Hayssam", ""], ["Al-Naffouri", "Tareq Y.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1908.09505", "submitter": "Peter Kietzmann", "authors": "Hauke Petersen, Peter Kietzmann, Cenk G\\\"undo\\u{g}an, Thomas C.\n  Schmidt, Matthias W\\\"ahlisch", "title": "Bluetooth Mesh under the Microscope: How much ICN is Inside?", "comments": null, "journal-ref": "Proceedings of ACM ICN 2019", "doi": "10.1145/3357150.3357398", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bluetooth (BT) mesh is a new mode of BT operation for low-energy devices that\noffers group-based publish-subscribe as a network service with additional\ncaching capabilities. These features resemble concepts of information-centric\nnetworking (ICN), and the analogy to ICN has been repeatedly drawn in the BT\ncommunity. In this paper, we compare BT mesh with ICN both conceptually and in\nreal-world experiments. We contrast both architectures and their design\ndecisions in detail. Experiments are performed on an IoT testbed using NDN/CCNx\nand BT mesh on constrained RIOT nodes. Our findings indicate significant\ndifferences both in concepts and in real-world performance. Supported by new\ninsights, we identify synergies and sketch a design of a BT-ICN that benefits\nfrom both worlds.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 07:34:00 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Petersen", "Hauke", ""], ["Kietzmann", "Peter", ""], ["G\u00fcndo\u011fan", "Cenk", ""], ["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "1908.09577", "submitter": "Leonardo Aniello Dr.", "authors": "Michael O'Sullivan, Leonardo Aniello, Vladimiro Sassone", "title": "A Methodology to Select Topology Generators for WANET Simulations\n  (Extended Version)", "comments": "18 pages (2 pages of references), 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many academic and industrial research works on WANETs rely on simulations, at\nleast in the first stages, to obtain preliminary results to be subsequently\nvalidated in real settings. Topology generators (TG) are commonly used to\ngenerate the initial placement of nodes in artificial WANET topologies, where\nthose simulations take place. The significance of these experiments heavily\ndepends on the representativeness of artificial topologies. Indeed, if they\nwere not drawn fairly, obtained results would apply only to a subset of\npossible configurations, hence they would lack of the appropriate generality\nrequired to port them to the real world. Although using many TGs could mitigate\nthis issue by generating topologies in several different ways, that would\nentail a significant additional effort. Hence, the problem arises of what TGs\nto choose, among a number of available generators, to maximise the\nrepresentativeness of generated topologies and reduce the number of TGs to use.\n  In this paper, we address that problem by investigating the presence of bias\nin the initial placement of nodes in artificial WANET topologies produced by\ndifferent TGs. We propose a methodology to assess such bias and introduce two\nmetrics to quantify the diversity of the topologies generated by a TG with\nrespect to all the available TGs, which can be used to select what TGs to use.\nWe carry out experiments on three well-known TGs, namely BRITE, NPART and\nGT-ITM. Obtained results show that using the artificial networks produced by a\nsingle TG can introduce bias.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 10:07:00 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["O'Sullivan", "Michael", ""], ["Aniello", "Leonardo", ""], ["Sassone", "Vladimiro", ""]]}, {"id": "1908.09646", "submitter": "Philipp Meyer", "authors": "Philipp Meyer, Timo H\\\"ackel, Franz Korf, Thomas C. Schmidt", "title": "DoS Protection through Credit Based Metering -- Simulation-Based\n  Evaluation for Time-Sensitive Networking in Cars", "comments": "If you cite this paper, please use the original reference: P. Meyer,\n  T. H\\\"ackel, F. Korf, and T. C. Schmidt. DoS Protection through Credit Based\n  Metering - Simulation Based Evaluation for Time-Sensitive Networking in Cars.\n  In: \\emph{Proceedings of the 6th International OMNeT++ Community Summit}.\n  September, 2019, Easychair", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethernet is the most promising solution to reduce complexity and enhance the\nbandwidth in the next generation in-car networks. Dedicated Ethernet protocols\nenable the real-time aspects in such networks. One promising candidate is the\nIEEE 802.1Q Time-Sensitive Networking protocol suite. Common Ethernet\ntechnologies, however, increases the vulnerability of the car infrastructure as\nthey widen the attack surface for many components. In this paper proposes an\nIEEE 802.1Qci based algorithm that on the one hand, protects against DoS\nattacks by metering incoming Ethernet frames. On the other hand, it adapts to\nthe behavior of the Credit Based Shaping algorithm, which was standardized for\nAudio/Video Bridging, the predecessor of Time-Sensitive Networking. A\nsimulation of this proposed Credit Based Metering algorithm evaluates the\nconcept.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 12:36:48 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 12:00:15 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Meyer", "Philipp", ""], ["H\u00e4ckel", "Timo", ""], ["Korf", "Franz", ""], ["Schmidt", "Thomas C.", ""]]}, {"id": "1908.09649", "submitter": "Timo H\\\"ackel", "authors": "Timo H\\\"ackel and Philipp Meyer and Franz Korf and Thomas C. Schmidt", "title": "SDN4CoRE: A Simulation Model for Software-Defined Networking for\n  Communication over Real-Time Ethernet", "comments": "If you cite this paper, please use the original reference: T.\n  H\\\"ackel, P. Meyer, F. Korf, and T. C. Schmidt. SDN4CoRE: A Simulation Model\n  for Software-Defined Networking for Communication over Real-Time Ethernet.\n  In: Proceedings of the 6th International OMNeT++ Community Summit. September,\n  2019, Easychair", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethernet has become the next standard for automotive and industrial\nautomation networks. Standard extensions such as IEEE 802.1Q Time-Sensitive\nNetworking (TSN) have been proven to meet the real-time and robustness\nrequirements of these environments. Augmenting the TSN switching by\nSoftware-Defined Networking functions promises additional benefits: A\nprogramming option for TSN devices can add much value to the resilience,\nsecurity, and adaptivity of the environment. Network simulation allows to model\nhighly complex networks before assembly and is an essential process for the\ndesign and validation of future networks. Still, a simulation environment that\nsupports programmable real-time networks is missing. This paper fills the gap\nby sharing our simulation model for Software-Defined Networking for\nCommunication over Real-Time Ethernet (SDN4CoRE) and present initial results in\nmodeling programmable real-time networks. In a case study, we show that\nSDN4CoRE can simulate complex programmable real-time networks and allows for\ntesting and verifying the programming of real-time devices.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 12:39:43 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["H\u00e4ckel", "Timo", ""], ["Meyer", "Philipp", ""], ["Korf", "Franz", ""], ["Schmidt", "Thomas C.", ""]]}, {"id": "1908.09765", "submitter": "Yunchou Xing", "authors": "Yunchou Xing, Ojas Kanhere, Shihao Ju, and Theodore S. Rappaport", "title": "Indoor Wireless Channel Properties at Millimeter Wave and Sub-Terahertz\n  Frequencies", "comments": "6 pages, 5 figures, Globecom conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides indoor reflection, scattering, transmission, and\nlarge-scale path loss measurements and models, which describe the main\npropagation mechanisms at millimeter wave and Terahertz frequencies. Channel\nproperties for common building materials (drywall and clear glass) are\ncarefully studied at 28, 73, and 140 GHz using a wideband sliding correlation\nbased channel sounder system with rotatable narrow-beam horn antennas.\nReflection coefficient is shown to linearly increase as the incident angle\nincreases, and lower reflection loss (e.g., stronger reflections) are observed\nas frequencies increase for a given incident angle. Although backscatter from\ndrywall is present at 28, 73, and 140 GHz, smooth surfaces (like drywall) are\nshown to be modeled as a simple reflected surface, since the scattered power is\n20 dB or more below the reflected power over the measured range of frequency\nand angles. Partition loss tends to increase with frequency, but the amount of\nloss is material dependent. Both clear glass and drywall are shown to induce a\ndepolarizing effect, which becomes more prominent as frequency increases.\nIndoor propagation measurements and large-scale indoor path loss models at 140\nGHz are provided, revealing similar path loss exponent and shadow fading as\nobserved at 28 and 73 GHz. The measurements and models in this paper can be\nused for future wireless system design and other applications within buildings\nfor frequencies above 100 GHz.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:05:50 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 16:00:25 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Xing", "Yunchou", ""], ["Kanhere", "Ojas", ""], ["Ju", "Shihao", ""], ["Rappaport", "Theodore S.", ""]]}, {"id": "1908.09766", "submitter": "Thu Huong Truong", "authors": "Hong Thinh Pham, Ngoc Nam Pham, Huu Thanh Nguyen, Alan Marshall, Thu\n  Huong Truong", "title": "A Hybrid of Adaptation and Dynamic Routing based on SDN for Improving\n  QoE in HTTP Adaptive VBR Video Streaming", "comments": "14 pages, 17 figures, IJCSNS International Journal of Computer\n  Science and Network Security,\n  http://paper.ijcsns.org/07_book/201907/20190708.pdf", "journal-ref": "VOL.19 No.7, July 2019", "doi": null, "report-no": null, "categories": "cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, HTTP Adaptive Streaming HAS has received significant attention from\nboth industry and academia based on its ability to enhancing media streaming\nservices over the Internet. Recent research solutions that have tried to\nimprove HAS by adaptation at the client side only may not be completely\neffective without interacting with routing decisions in the upper layers. In\nthis paper, we address the aforementioned issue by proposing a dynamic\nbandwidth allocation and management architecture for streaming video flows to\nimprove users satisfaction. We also introduce an initial cross layer hybrid\nmethod that combines quality adaptation of variable bitrate video streaming\nover the HTTP protocol at the client side and SDN based dynamical routing. This\nscheme is enabled by the Software Defined Networking architecture that is now\nbeing considered as an emerging paradigm that disassociates the forwarding\nprocess from the routing process. SDN brings flexibility and the ability to\nflexibly change routing solutions, in turn resulting in dynamically improving\nthe services provided in the application layer. Our experimental results show\nthat the proposed solution offers significantly higher overall bitrates as well\nas smoother viewing experience than existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:06:53 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Pham", "Hong Thinh", ""], ["Pham", "Ngoc Nam", ""], ["Nguyen", "Huu Thanh", ""], ["Marshall", "Alan", ""], ["Truong", "Thu Huong", ""]]}, {"id": "1908.09927", "submitter": "Andr\\'e Z\\'uquete", "authors": "Nuno Marques, Andr\\'e Z\\'uquete, Jo\\~ao Paulo Barraca", "title": "Integration of the Captive Portal paradigm with the 802.1X architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a scenario where hotspot wireless networks are increasingly being used,\nand given the amount of sensitive information exchanged on Internet\ninteractions, there is the need to implement security mechanisms that guarantee\ndata confidentiality and integrity in such networks, as well as the\nauthenticity of the hotspot providers.\n  However, many hotspots today use Captive Portals, which rely on\nauthentication through Web pages (thus, an application-level authentication\napproach) instead of a link-layer approach. The consequence of this is that\nthere is no security in the wireless link to the hotspot (it has to be provided\nat upper protocol layers), and is cumbersome to manage wireless access profiles\n(we need special applications or browsers' add-ons to do that).\n  This work exposes the weaknesses of the Captive Portals' paradigm, which does\nnot follow a unique nor standard approach, and describes a solution that\nintends to suppress them, based on the 802.1X architecture. This solution uses\na new EAP-compliant protocol that is able to integrate an HTTP-based\nregistration or authentication with a Captive Portal within the 802.1X\nauthentication framework.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 21:24:01 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Marques", "Nuno", ""], ["Z\u00faquete", "Andr\u00e9", ""], ["Barraca", "Jo\u00e3o Paulo", ""]]}, {"id": "1908.09991", "submitter": "Lorenzo Di Gregorio", "authors": "Lorenzo Di Gregorio, Valerio Frascolla", "title": "Handover Optimality in Heterogeneous Networks", "comments": "accepted by IEEE 5G World Forum 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new theoretical framework for optimal handover\nprocedures in heterogeneous networks by devising the novel fractional Gittins\nindices, which are dynamical priorities whose values can be statically\nassociated to the decision states of evolving processes representing handover\nalternatives. The simple policy of activating at any time the one process\ncurrently at highest priority optimizes the bandwidth of a handover, if all\nother inactive processes remain idle. However, numerical evidence shows that in\npractice this condition can be relaxed for a wide range of handover models,\nbecause the bandwidth actually achieved by the policy never deviates for more\nthan 12% from the optimally achievable bandwidth and remains in median within a\ndeviation of 2% from this optimum.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 02:28:18 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 16:58:30 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Di Gregorio", "Lorenzo", ""], ["Frascolla", "Valerio", ""]]}, {"id": "1908.10086", "submitter": "Klaus-Tycho Foerster", "authors": "Klaus-Tycho Foerster, Stefan Schmid", "title": "Distributed Consistent Network Updates in SDNs: Local Verification for\n  Global Guarantees", "comments": "Appears in IEEE NCA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While SDNs enable more flexible and adaptive network operations, (logically)\ncentralized reconfigurations introduce overheads and delays, which can limit\nnetwork reactivity. This paper initiates the study of a more distributed\napproach, in which the consistent network updates are implemented by the\nswitches and routers directly in the data plane. In particular, our approach\nleverages concepts from local proof labeling systems, which allows the data\nplane elements to locally check network properties, and we show that this is\nsufficient to obtain global network guarantees. We demonstrate our approach\nconsidering three fundamental use cases, and analyze its benefits in terms of\nperformance and fault-tolerance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 08:52:36 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Foerster", "Klaus-Tycho", ""], ["Schmid", "Stefan", ""]]}, {"id": "1908.10097", "submitter": "Xiaohu Ge", "authors": "Yuna Jiang, Xiaohu Ge, Yi Zhong, Guoqiang Mao, Yonghui Li", "title": "A New Small-World IoT Routing Mechanism based on Cayley Graphs", "comments": "12 pages,11 figures,journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of low-power Internet of Things (IoT) devices will be\nwidely deployed in the near future. Considering the short-range communication\nof low-power devices, multi-hop transmissions will become an important\ntransmission mechanism in IoT networks. It is crucial for lowpower devices to\ntransmit data over long distances via multihop in a low-delay and reliable way.\nSmall-world characteristics of networks indicate that the network has an\nadvantage of a small Average Shortest-path Length (ASL) and a high Average\nClustering Coefficient (ACC). In this paper, a new IoT routing mechanism\nconsidering small-world characteristics is proposed to reduce the delay and\nimprove the reliability. The ASL and ACC are derived for performance analysis\nof small-world characteristics in IoT networks based on Cayley graphs. Besides,\nthe reliability and delay models are proposed for Small-World IoT based on\nCayley grapHs (SWITCH). Simulation results demonstrate that SWITCH has lower\ndelay and better reliability than that of conventional Nearest Neighboring\nRouting (NNR). Moreover, the maximum delay of SWITCH is reduced by 50.6%\ncompared with that by NNR.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 09:21:43 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Jiang", "Yuna", ""], ["Ge", "Xiaohu", ""], ["Zhong", "Yi", ""], ["Mao", "Guoqiang", ""], ["Li", "Yonghui", ""]]}, {"id": "1908.10141", "submitter": "Sebastian Henningsen", "authors": "Sebastian Henningsen, Daniel Teunis, Martin Florian, Bj\\\"orn\n  Scheuermann", "title": "Eclipsing Ethereum Peers with False Friends", "comments": "Extended version of the original publication in: 2019 IEEE European\n  Symposium on Security and Privacy Workshops (EuroS&PW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum is a decentralized Blockchain system that supports the execution of\nTuring-complete smart contracts. Although the security of the Ethereum\necosystem has been studied in the past, the network layer has been mostly\nneglected. We show that Go Ethereum (Geth), the most widely used Ethereum\nimplementation, is vulnerable to eclipse attacks, effectively circumventing\nrecently introduced (Geth v1.8.0) security enhancements. We responsibly\ndisclosed the vulnerability to core Ethereum developers; the corresponding\ncountermeasures to our attack where incorporated into the v1.9.0 release of\nGeth. Our false friends attack exploits the Kademlia-inspired peer discovery\nlogic used by Geth and enables a low-resource eclipsing of long-running, remote\nvictim nodes. An adversary only needs two hosts in distinct /24 subnets to\nlaunch the eclipse, which can then be leveraged to filter the victim's view of\nthe Blockchain. We discuss fundamental properties of Geth's node discovery\nlogic that enable the false friends attack, as well as proposed and implemented\ncountermeasures.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 11:36:14 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Henningsen", "Sebastian", ""], ["Teunis", "Daniel", ""], ["Florian", "Martin", ""], ["Scheuermann", "Bj\u00f6rn", ""]]}, {"id": "1908.10237", "submitter": "Jonas H\\\"ochst", "authors": "Alvar Penning, Lars Baumg\\\"artner, Jonas H\\\"ochst, Artur Sterz, Mira\n  Mezini, Bernd Freisleben", "title": "DTN7: An Open-Source Disruption-tolerant Networking Implementation of\n  Bundle Protocol 7", "comments": "18th International Conference on Ad Hoc Networks and Wireless\n  (AdHoc-Now 2019)", "journal-ref": "ADHOC-NOW 2019: Ad-Hoc, Mobile, and Wireless Networks pp 196-209", "doi": "10.1007/978-3-030-31831-4_14", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In disruption-tolerant networking (DTN), data is transmitted in a\nstore-carry-forward fashion from network node to network node. In this paper,\nwe present an open source DTN implementation, called DTN7, of the recently\nreleased Bundle Protocol Version 7 (draft version 13). DTN7 is written in Go\nand provides features like memory safety and concurrent execution. With its\nmodular design and interchangeable components, DTN7 facilitates DTN research\nand application development. Furthermore, we present results of a comparative\nexperimental evaluation of DTN7 and other DTN systems including Serval,\nIBR-DTN, and Forban. Our results indicate that DTN7 is a flexible and efficient\nopen-source multi-platform implementation of the most recent Bundle Protocol\nVersion 7.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:37:53 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Penning", "Alvar", ""], ["Baumg\u00e4rtner", "Lars", ""], ["H\u00f6chst", "Jonas", ""], ["Sterz", "Artur", ""], ["Mezini", "Mira", ""], ["Freisleben", "Bernd", ""]]}, {"id": "1908.10351", "submitter": "Monireh Ghasri", "authors": "Monireh Allah Gholi Ghasri, Ali Mohammad Afshin Hemmatyar, Siavash\n  Bayat, Mostafa Mahdieh", "title": "Novel Relay Selection Algorithms for Machine-to-Machine Communications\n  with Static RF Interface Usage", "comments": "51 pages, 17 figures", "journal-ref": "IEEE Access (Early Access Article), 2020", "doi": "10.1109/ACCESS.2020.3031814", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Machine-to-Machine (M2M) communications have been introduced to improve the\ncommunication capacity in dense wireless networks. One of the most important\nconcerns for network designers is maintaining the high performance of the\nnetwork when the quality of connections between sources and their destinations\nis poor. Thus the careful selection of relays between data sources and their\ndestinations is a very important issue. The possibility of simultaneous use of\ndifferent Radio Frequency (RF) interfaces for transmitting data, which\ncommunication devices are equipped with them, can increase the capacity of data\ntransmission over the network. In this paper, two novel M2M relay selection\nalgorithms are proposed, named as Optimal Relay Selection Algorithm (ORSA) and\nMatching based Relay Selection Algorithm (MRSA). ORSA is a centralized\nalgorithm for the optimal selection of relays by transforming the main problem\nto a k-cardinality assignment problem that can be solved using the Hungarian\nalgorithm. MRSA is a distributed algorithm that leverages concepts from\nmatching theory to provide a stable solution for the relay selection problem.\nIn both proposed algorithms static RF interfaces usage is applied to enable\nsimultaneous use of different interfaces for data transmission. The simulations\nshow that ORSA is optimally solving the relay selection problem. MRSA has an\noptimal stable result, that when there is no restriction on the number of\nchannels, is only about 1% lower than ORSA. Besides, MRSA provides better\nresults than direct transmission Without any Relay Selection Algorithm (WRSA)\nand Random Relay Selection Algorithm (RRSA), about 15% and 98%, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 23:21:13 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 11:49:07 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 17:50:23 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ghasri", "Monireh Allah Gholi", ""], ["Hemmatyar", "Ali Mohammad Afshin", ""], ["Bayat", "Siavash", ""], ["Mahdieh", "Mostafa", ""]]}, {"id": "1908.10438", "submitter": "Vishrant Tripathi", "authors": "Vishrant Tripathi and Eytan Modiano", "title": "A Whittle Index Approach to Minimizing Functions of Age of Information", "comments": "Accepted for Allerton'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a setting where multiple active sources send real-time updates\nover a single-hop wireless broadcast network to a monitoring station. Our goal\nis to design a scheduling policy that minimizes the time-average of general\nnon-decreasing cost functions of Age of Information.\n  We use a Whittle index based approach to find low complexity scheduling\npolicies that have good performance, for reliable as well as unreliable\nchannels. We prove that for a system with two sources, having possibly\ndifferent cost functions and reliable channels, the Whittle index policy is\nexactly optimal. For reliable channels, we also derive structural properties of\nan optimal policy, that suggest that the performance of the Whittle index\npolicy may be close to optimal in general. These results might also be of\nindependent interest in the study of restless multi-armed bandit problems with\nsimilar underlying structure. Finally, we provide simulations comparing the\nWhittle index policy with optimal scheduling policies found using dynamic\nprogramming, which support our results.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 19:56:26 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Tripathi", "Vishrant", ""], ["Modiano", "Eytan", ""]]}, {"id": "1908.10679", "submitter": "Zhou Qin", "authors": "Ao Li, Zhou Qin, Runshi Liu, Yiqun Yang, Dong Li", "title": "Spam Review Detection with Graph Convolutional Networks", "comments": "Accepted at CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3357820", "report-no": null, "categories": "cs.IR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customers make a lot of reviews on online shopping websites every day, e.g.,\nAmazon and Taobao. Reviews affect the buying decisions of customers, meanwhile,\nattract lots of spammers aiming at misleading buyers. Xianyu, the largest\nsecond-hand goods app in China, suffering from spam reviews. The anti-spam\nsystem of Xianyu faces two major challenges: scalability of the data and\nadversarial actions taken by spammers. In this paper, we present our technical\nsolutions to address these challenges. We propose a large-scale anti-spam\nmethod based on graph convolutional networks (GCN) for detecting spam\nadvertisements at Xianyu, named GCN-based Anti-Spam (GAS) model. In this model,\na heterogeneous graph and a homogeneous graph are integrated to capture the\nlocal context and global context of a comment. Offline experiments show that\nthe proposed method is superior to our baseline model in which the information\nof reviews, features of users and items being reviewed are utilized.\nFurthermore, we deploy our system to process million-scale data daily at\nXianyu. The online performance also demonstrates the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:44:16 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Li", "Ao", ""], ["Qin", "Zhou", ""], ["Liu", "Runshi", ""], ["Yang", "Yiqun", ""], ["Li", "Dong", ""]]}, {"id": "1908.10739", "submitter": "Hasan Burhan Beytur", "authors": "Hasan Burhan Beytur, Sajjad Baghaee, Elif Uysal", "title": "Towards AoI-aware Smart IoT Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Age of Information (AoI) has gained importance as a Key Performance Indicator\n(KPI) for characterizing the freshness of information in information-update\nsystems and time-critical applications. Recent theoretical research on the\ntopic has generated significant understanding of how various algorithms perform\nin terms of this metric on various system models and networking scenarios. In\nthis paper, by the help of the theoretical results, we analyzed the AoI\nbehavior on real-life networks, using our two test-beds, addressing IoT\nnetworks and regular computers. Excessive number of AoI measurements are\nprovided for variations of transport protocols such as TCP, UDP and web-socket,\non wired and wireless links. Practical issues such as synchronization and\nselection of hardware along with transport protocol, and their effects on AoI\nare discussed. The results provide insight toward application and transport\nlayer mechanisms for optimizing AoI in real-life networks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:14:09 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Beytur", "Hasan Burhan", ""], ["Baghaee", "Sajjad", ""], ["Uysal", "Elif", ""]]}, {"id": "1908.10758", "submitter": "Takaaki Matsuo", "authors": "Takaaki Matsuo", "title": "Simulation of a Dynamic, RuleSet-based Quantum Network", "comments": "arXiv admin note: text overlap with arXiv:1904.08605", "journal-ref": "Master's thesis, Keio University, July 2019", "doi": null, "report-no": null, "categories": "quant-ph cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similar to the classical Internet, the quantum Internet will require\nknowledge regarding link qualities used for purposes such as optimal route\nselection. This is commonly accomplished by performing link-level tomography\nwith or without purification -- a.k.a. quantum link bootstrapping. Meanwhile,\nthe gate selection and the resource (Bell pair) selection for a task must be\ncoordinated beforehand. This thesis introduces the RuleSet-based communication\nprotocol aimed for supporting the autonomous coordination of quantum operations\namong distant nodes, with minimal classical packet transmission. This thesis\nalso discusses the RuleSet-based quantum link bootstrapping protocol, which\nconsists of recurrent purifications and link-level tomography, evaluated over a\nMarkov-Chain Monte-Carlo simulation with noisy systems modeled on real world\nquality hardware. Given a 10km MeetInTheMiddle based two-node system, each with\n100 memory qubits ideally connected to the optical fiber, the Recurrent Single\nselection - Single error purification (RSs-Sp) protocol is capable of improving\nthe fidelity from an average input $F_{r}=0.675$ to approximately\n$F_{r}=0.865$. The system gets noisier with longer channels, in which case\nerrors may develop faster than the purification gain. For a noisier system with\na longer channel length, the double selection-based purification shows an\nadvantage for improving the fidelity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 07:59:53 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Matsuo", "Takaaki", ""]]}, {"id": "1908.10980", "submitter": "Fernando Farias N. N.", "authors": "Fernando N. N. Farias, Ant\\^onio de O. Junior, Leonardo B. da Costa,\n  Billy A. Pinheiro, Ant\\^onio J. G. Abel\\'em", "title": "vSDNEmul: A Software-Defined Network Emulator Based on Container\n  Virtualization", "comments": null, "journal-ref": "International Journal of Simulation Systems, Science & Technology\n  Volume 20, Number 4, August 2019", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main issue related to Software-Defined Network emulators is how to\nreplicate real behavior in experiments. Mininet and others SDN emulators have\nan architecture that limits both the scope of experiments and the fidelity of\nnetworking tests. Consequently, the serialization, contention, and load of\nbackground processes may produce delays that compromise the operation of events\nsuch as transmitting a packet or completing a computation, possibly\ninvalidating the performance evaluation of a network emulation. To address\nthese problems, this paper presents vSDNEmul, a network emulator based on\nDocker container virtualization. Different from Mininet, vSDNEmul isolates each\nnode in a container and interconnects the nodes through virtual or tunnel\nlinks. By using containers, vSDNEmul allows autonomous and flexible creation of\nindependent network elements, resulting in more realistic emulations. This\npaper reports performance evaluations comparing vSDNEmul and Mininet. The\nresults obtained with the vSDNEmul emulator are more realistic and present\nhigher accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 22:48:15 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Farias", "Fernando N. N.", ""], ["Junior", "Ant\u00f4nio de O.", ""], ["da Costa", "Leonardo B.", ""], ["Pinheiro", "Billy A.", ""], ["Abel\u00e9m", "Ant\u00f4nio J. G.", ""]]}, {"id": "1908.11131", "submitter": "Max Noormohammadpour", "authors": "Mohammad Noormohammadpour", "title": "On Efficient Data Transfers Across Geographically Dispersed Datacenters", "comments": "PhD Thesis, Ming Hsieh Department of Electrical Engineering,\n  University Of Southern California", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As applications become more distributed to improve user experience and offer\nhigher availability, businesses rely on geographically dispersed datacenters\nthat host such applications more than ever. Dedicated inter-datacenter networks\nhave been built that provide high visibility into the network status and\nflexible control over traffic forwarding to offer quality communication across\nthe instances of applications hosted on many datacenters. These networks are\nrelatively small, with tens to hundreds of nodes and are managed by the same\norganization that operates the datacenters which make centralized traffic\nengineering feasible. Using coordinated data transmission from the services and\nrouting over the inter-datacenter network, one can optimize the network\nperformance according to a variety of utility functions that take into account\ndata transfer deadlines, network capacity consumption, and transfer completion\ntimes.\n  In this dissertation, we study techniques and algorithms for fast and\nefficient data transfers across geographically dispersed datacenters over the\ninter-datacenter networks. We discuss different forms and properties of\ninter-datacenter transfers and present a generalized optimization framework to\nmaximize an operator selected utility function. Next, in the several chapters\nthat follow, we study, in detail, the problems of admission control for\ntransfers with deadlines and inter-datacenter multicast transfers. For the\nadmission control problem, our solutions offer significant speed up in the\nadmission control process while offering almost identical performance in the\ntotal traffic admitted into the network. For the bulk multicasting problem, our\ntechniques enable significant performance gain in receiver completion times\nwith low computational complexity, which makes them highly applicable to\ninter-datacenter networks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 09:58:39 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Noormohammadpour", "Mohammad", ""]]}, {"id": "1908.11151", "submitter": "Miguel Sepulcre", "authors": "Gokulnath Thandavarayan, Miguel Sepulcre, Javier Gozalvez", "title": "Generation of Cooperative Perception Messages for Connected and\n  Automated Vehicles", "comments": null, "journal-ref": "IEEE Transactions on Vehicular Technology, November 2020", "doi": "10.1109/TVT.2020.3036165", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected and Automated Vehicles (CAVs) utilize a variety of onboard sensors\nto sense their surrounding environment. CAVs can improve their perception\ncapabilities if vehicles exchange information about what they sense using V2X\ncommunications. This is known as cooperative or collective perception (or\nsensing). A frequent transmission of collective perception messages could\nimprove the perception capabilities of CAVs. However, this improvement can be\ncompromised if vehicles generate too many messages and saturate the\ncommunications channel. An important aspect is then when vehicles should\ngenerate the perception messages. ETSI has proposed the first set of message\ngeneration rules for collective perception. These rules define when vehicles\nshould generate collective perception messages and what should be their\ncontent. We show that the current rules generate a high number of collective\nperception messages with information about a small number of detected objects.\nThis results in an inefficient use of the communication channel that reduces\nthe effectiveness of collective perception. We address this challenge and\npropose an improved algorithm that modifies the generation of collective\nperception messages. We demonstrate that the proposed solution improves the\nreliability of V2X communication and the perception of CAVs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 11:12:59 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 15:44:50 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Thandavarayan", "Gokulnath", ""], ["Sepulcre", "Miguel", ""], ["Gozalvez", "Javier", ""]]}, {"id": "1908.11225", "submitter": "Mattia Lecci", "authors": "Paolo Testolina and Mattia Lecci and Mattia Rebato and Alberto\n  Testolin and Jonathan Gambini and Roberto Flamini and Christian Mazzucco and\n  Michele Zorzi", "title": "Enabling Simulation-Based Optimization Through Machine Learning: A Case\n  Study on Antenna Design", "comments": "6 pages, 5 figures, 1 table. Please cite it as: P. Testolina, M.\n  Lecci, M. Rebato, A. Testolin, J. Gambini, C. Mazzucco and M. Zorzi,\n  \"Enabling Simulation-Based Optimization Through Machine Learning: A Case\n  Study on Antenna Design\", in IEEE Global Communication Conference: Wireless\n  Communication (GLOBECOM WC), Waikoloa, USA, Dec. 2019", "journal-ref": null, "doi": "10.1109/GLOBECOM38437.2019.9013240", "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex phenomena are generally modeled with sophisticated simulators that,\ndepending on their accuracy, can be very demanding in terms of computational\nresources and simulation time. Their time-consuming nature, together with a\ntypically vast parameter space to be explored, make simulation-based\noptimization often infeasible. In this work, we present a method that enables\nthe optimization of complex systems through Machine Learning (ML) techniques.\nWe show how well-known learning algorithms are able to reliably emulate a\ncomplex simulator with a modest dataset obtained from it. The trained emulator\nis then able to yield values close to the simulated ones in virtually no time.\nTherefore, it is possible to perform a global numerical optimization over the\nvast multi-dimensional parameter space, in a fraction of the time that would be\nrequired by a simple brute-force search. As a testbed for the proposed\nmethodology, we used a network simulator for next-generation mmWave cellular\nsystems. After simulating several antenna configurations and collecting the\nresulting network-level statistics, we feed it into our framework. Results show\nthat, even with few data points, extrapolating a continuous model makes it\npossible to estimate the global optimum configuration almost instantaneously.\nThe very same tool can then be used to achieve any further optimization goal on\nthe same input parameters in negligible time.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:43:11 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 12:30:13 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Testolina", "Paolo", ""], ["Lecci", "Mattia", ""], ["Rebato", "Mattia", ""], ["Testolin", "Alberto", ""], ["Gambini", "Jonathan", ""], ["Flamini", "Roberto", ""], ["Mazzucco", "Christian", ""], ["Zorzi", "Michele", ""]]}, {"id": "1908.11313", "submitter": "Rafail Ismayilov", "authors": "Rafail Ismayilov, Bernd Holfeld, Renato L. G. Cavalcante and Megumi\n  Kaneko", "title": "Power and Beam Optimization for Uplink Millimeter-Wave Hotspot\n  Communication Systems", "comments": null, "journal-ref": null, "doi": "10.1109/WCNC.2019.8885561", "report-no": null, "categories": "cs.NI cs.IT eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an effective interference management and beamforming mechanism for\nuplink communication systems that yields fair allocation of rates. In\nparticular, we consider a hotspot area of a millimeter-wave (mmWave) access\nnetwork consisting of multiple user equipment (UE) in the uplink and multiple\naccess points (APs) with directional antennas and adjustable beam widths and\ndirections (beam configurations). This network suffers tremendously from\nmulti-beam multi-user interference, and, to improve the uplink transmission\nperformance, we propose a centralized scheme that optimizes the power, the beam\nwidth, the beam direction of the APs, and the UE - AP assignments. This problem\ninvolves both continuous and discrete variables, and it has the following\nstructure. If we fix all discrete variables, except for those related to the\nUE-AP assignment, the resulting optimization problem can be solved optimally.\nThis property enables us to propose a heuristic based on simulated annealing\n(SA) to address the intractable joint optimization problem with all discrete\nvariables. In more detail, for a fixed configuration of beams, we formulate a\nweighted rate allocation problem where each user gets the same portion of its\nmaximum achievable rate that it would have under non-interfered conditions. We\nsolve this problem with an iterative fixed point algorithm that optimizes the\npower of UEs and the UE - AP assignment in the uplink. This fixed point\nalgorithm is combined with SA to improve the beam configurations. Theoretical\nand numerical results show that the proposed method improves both the UE rates\nin the lower percentiles and the overall fairness in the network.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:53:49 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 08:44:30 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 10:06:11 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ismayilov", "Rafail", ""], ["Holfeld", "Bernd", ""], ["Cavalcante", "Renato L. G.", ""], ["Kaneko", "Megumi", ""]]}, {"id": "1908.11538", "submitter": "Rourab Paul", "authors": "Rourab Paul, Nimisha Ghosh, Suman Sau, Amlan Chakrabarti, Prasant\n  Mahapatra", "title": "IoT based Smart Access Controlled Secure Smart City Architecture Using\n  Blockchain", "comments": "Manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Standard security protocols like SSL, TLS, IPSec etc. have high memory and\nprocessor consumption which makes all these security protocols unsuitable for\nresource constrained platforms such as Internet of Things (IoT). Blockchain\n(BC) finds its efficient application in IoT platform to preserve the five basic\ncryptographic primitives, such as confidentiality, authenticity, integrity,\navailability and non-repudiation. Conventional adoption of BC in IoT platform\ncauses high energy consumption, delay and computational overhead which are not\nappropriate for various resource constrained IoT devices. This work proposes a\nmachine learning (ML) based smart access control framework in a public and a\nprivate BC for a smart city application which makes it more efficient as\ncompared to the existing IoT applications. The proposed IoT based smart city\narchitecture adopts BC technology for preserving all the cryptographic security\nand privacy issues. Moreover, BC has very minimal overhead on IoT platform as\nwell. This work investigates the existing threat models and critical access\ncontrol issues which handle multiple permissions of various nodes and detects\nrelevant inconsistencies to notify the corresponding nodes. Comparison in terms\nof all security issues with existing literature shows that the proposed\narchitecture is competitively efficient in terms of security access control.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 05:37:05 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 07:03:29 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 08:55:21 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Paul", "Rourab", ""], ["Ghosh", "Nimisha", ""], ["Sau", "Suman", ""], ["Chakrabarti", "Amlan", ""], ["Mahapatra", "Prasant", ""]]}, {"id": "1908.11551", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo, Stefano Ferretti, Gary S. H. Tan", "title": "Internet-based Adaptive Distributed Simulation of Mobile Ad-hoc Networks", "comments": "Proceedings of the Proceedings of the 2019 Winter Simulation\n  Conference (WSC 2019)", "journal-ref": null, "doi": "10.1109/WSC40007.2019.9004796", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on Internet-based simulation, a form of distributed\nsimulation in which a set of execution units that are physically located around\nthe globe work together to run a simulation model. This setup is very\nchallenging because of the latency/variability of communications. Thus, clever\nmechanisms must be adopted in the distributed simulation, such as the adaptive\npartitioning of the simulated model and load balancing strategies among\nexecution units. We simulate a wireless model over a real Internet-based\ndistributed simulation setup, and evaluate the scalability of the simulator\nwith and without the use of adaptive strategies for both communication overhead\nreduction and load-balancing enhancement. The results confirm the viability of\nour approach to build Internet-based simulations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 06:22:35 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 06:26:13 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""], ["Tan", "Gary S. H.", ""]]}, {"id": "1908.11808", "submitter": "Gabriele D'Angelo", "authors": "Stefano Ferretti, Gabriele D'Angelo", "title": "On the Ethereum Blockchain Structure: a Complex Networks Theory\n  Perspective", "comments": null, "journal-ref": null, "doi": "10.1002/cpe.5493", "report-no": null, "categories": "cs.CR cs.DC cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the Ethereum blockchain using the complex networks\nmodeling framework. Accounts acting on the blockchain are represented as nodes,\nwhile the interactions among these accounts, recorded on the blockchain, are\ntreated as links in the network. Using this representation, it is possible to\nderive interesting mathematical characteristics that improve the understanding\nof the actual interactions happening in the blockchain. Not only, by looking at\nthe history of the blockchain, it is possible to verify if radical changes in\nthe blockchain evolution happened.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 07:55:19 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}]