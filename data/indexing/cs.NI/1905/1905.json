[{"id": "1905.00115", "submitter": "Christian Raffelsberger", "authors": "Christian Raffelsberger, Raheeb Muzaffar, Christian Bettstetter", "title": "A Performance Evaluation Tool for Drone Communications in 4G Cellular\n  Networks", "comments": "This is the authors' version of the paper. The final version appears\n  in the proceedings of the 15th International Symposium on Wireless\n  Communication Systems (ISWCS '19), Oulu, Finland, 27-30 August 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a measurement tool for the performance evaluation of wireless\ncommunications with drones over cellular networks. The Android software records\nvarious LTE parameters, evaluates the TCP and UDP throughput, and tracks the\nGPS position. Example measurement results are presented.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 21:46:35 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 11:22:05 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Raffelsberger", "Christian", ""], ["Muzaffar", "Raheeb", ""], ["Bettstetter", "Christian", ""]]}, {"id": "1905.00152", "submitter": "Qingqing Wu", "authors": "Qingqing Wu and Rui Zhang", "title": "Towards Smart and Reconfigurable Environment: Intelligent Reflecting\n  Surface Aided Wireless Network", "comments": "A short version of this work was accepted by IEEE Communications\n  Magazine. Several other technical works on Beamforming, discrete phase\n  shifts, wireless power transfer are available at\n  https://elewuqq.wixsite.com/mysite", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the fifth-generation (5G) technologies will significantly improve\nthe spectrum and energy efficiency of today's wireless communication networks,\ntheir high complexity and hardware cost as well as increasingly more energy\nconsumption are still crucial issues to be solved. Furthermore, despite that\nsuch technologies are generally capable of adapting to the space and time\nvarying wireless environment, the signal propagation over it is essentially\nrandom and largely uncontrollable. Recently, intelligent reflecting surface\n(IRS) has been proposed as a revolutionizing solution to address this open\nissue, by smartly reconfiguring the wireless propagation environment with the\nuse of massive low-cost, passive, reflective elements integrated on a planar\nsurface. Specifically, different elements of an IRS can independently reflect\nthe incident signal by controlling its amplitude and/or phase and thereby\ncollaboratively achieve fine-grained three-dimensional (3D) passive beamforming\nfor signal enhancement or cancellation. In this article, we provide an overview\nof the IRS technology, including its main applications in wireless\ncommunication, competitive advantages over existing technologies, hardware\narchitecture as well as the corresponding new signal model. We focus on the key\nchallenges in designing and implementing the new IRS-aided hybrid (with both\nactive and passive components) wireless network, as compared to the traditional\nnetwork comprising active components only. Furthermore, numerical results are\nprovided to show the potential for significant performance enhancement with the\nuse of IRS in typical wireless network scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 01:13:59 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 07:03:47 GMT"}, {"version": "v3", "created": "Wed, 12 Jun 2019 01:33:06 GMT"}, {"version": "v4", "created": "Wed, 24 Jul 2019 12:36:43 GMT"}, {"version": "v5", "created": "Fri, 30 Aug 2019 04:49:30 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Wu", "Qingqing", ""], ["Zhang", "Rui", ""]]}, {"id": "1905.00154", "submitter": "Saeed Valizadeh", "authors": "Saeed Valizadeh and Marten van Dijk", "title": "On the Convergence Rates of Learning-based Signature Generation Schemes\n  to Contain Self-propagating Malware", "comments": "This work was funded by NSF grant CNS-1413996 \"MACS: A Modular\n  Approach to Cloud Security.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the importance of a defense system's learning\nrates to fight against the self-propagating class of malware such as worms and\nbots. To this end, we introduce a new propagation model based on the\ninteractions between an adversary (and its agents) who wishes to construct a\nzombie army of a specific size, and a defender taking advantage of standard\nsecurity tools and technologies such as honeypots (HPs) and intrusion detection\nand prevention systems (IDPSes) in the network environment. As time goes on,\nthe defender can incrementally learn from the collected/observed attack samples\n(e.g., malware payloads), and therefore being able to generate attack\nsignatures. The generated signatures then are used for filtering next attack\ntraffic and thus containing the attacker's progress in its malware propagation\nmission. Using simulation and numerical analysis, we evaluate the efficacy of\nsignature generation algorithms and in general any learning-based scheme in\nbringing an adversary's maneuvering in the environment to a halt as an\nadversarial containment strategy.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 01:19:32 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Valizadeh", "Saeed", ""], ["van Dijk", "Marten", ""]]}, {"id": "1905.00243", "submitter": "Marco Giordani", "authors": "Davide Peron, Marco Giordani, Michele Zorzi", "title": "An Efficient Requirement-Aware Attachment Policy for Future Millimeter\n  Wave Vehicular Networks", "comments": "8 pages, 8 figures, 2 tables, accepted to the 30th IEEE Intelligent\n  Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automotive industry is rapidly evolving towards connected and autonomous\nvehicles, whose ever more stringent data traffic requirements might exceed the\ncapacity of traditional technologies for vehicular networks. In this scenario,\ndensely deploying millimeter wave (mmWave) base stations is a promising\napproach to provide very high transmission speeds to the vehicles. However,\nmmWave signals suffer from high path and penetration losses which might render\nthe communication unreliable and discontinuous. Coexistence between mmWave and\nLong Term Evolution (LTE) communication systems has therefore been considered\nto guarantee increased capacity and robustness through heterogeneous\nnetworking. Following this rationale, we face the challenge of designing fair\nand efficient attachment policies in heterogeneous vehicular networks.\nTraditional methods based on received signal quality criteria lack\nconsideration of the vehicle's individual requirements and traffic demands, and\nlead to suboptimal resource allocation across the network. In this paper we\npropose a Quality-of-Service (QoS) aware attachment scheme which biases the\ncell selection as a function of the vehicular service requirements, preventing\nthe overload of transmission links. Our simulations demonstrate that the\nproposed strategy significantly improves the percentage of vehicles satisfying\napplication requirements and delivers efficient and fair association compared\nto state-of-the-art schemes.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 10:12:40 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Peron", "Davide", ""], ["Giordani", "Marco", ""], ["Zorzi", "Michele", ""]]}, {"id": "1905.00247", "submitter": "Ahmad Khaliq", "authors": "Ahmad Khaliq, Sangeet Saha, Bina Bhatt, Dongbing Gu and Klaus\n  McDonald-Maier", "title": "Profi-Load: An FPGA-Based Solution for Generating Network Load in\n  Profinet Communication", "comments": "Accepted in IEEE SMC 2019 Industry 4.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial automation has received a considerable attention in the last few\nyears with the rise of Internet of Things (IoT). Specifically, industrial\ncommunication network technology such as Profinet has proved to be a major game\nchanger for such automation. However, industrial automation devices often have\nto exhibit robustness to dynamically changing network conditions and thus,\ndemand a rigorous testing environment to avoid any safety-critical failures.\nHence, in this paper, we have proposed an FPGA-based novel framework called\nProfi-Load to generate Profinet traffic with specific intensities for a\nspecified duration of time. The proposed Profi-Load intends to facilitate the\nperformance testing of the industrial automated devices under various network\nconditions. By using the advantage of inherent hardware parallelism and\nre-configurable features of FPGA, Profi-Load is able to generate Profinet\ntraffic efficiently. Moreover, it can be reconfigured on the fly as per the\nspecific requirements. We have developed our proposed Profi-Load framework by\nemploying the Xilinx-based NetJury device which belongs to Zynq-7000 FPGA\nfamily. A series of experiments have been conducted to evaluate the\neffectiveness of Profi-Load and it has been observed that Profi-Load is able to\ngenerate precise load at a constant rate for stringent timing requirements.\nFurthermore, a suitable Human Machine Interface (HMI) has also been developed\nfor quick access to our framework. The HMI at the client side can directly\ncommunicate with the NetJury device and parameters such as, required load\namount, number of packet(s) to be sent or desired time duration can be selected\nusing the HMI.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 10:23:59 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 19:05:41 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Khaliq", "Ahmad", ""], ["Saha", "Sangeet", ""], ["Bhatt", "Bina", ""], ["Gu", "Dongbing", ""], ["McDonald-Maier", "Klaus", ""]]}, {"id": "1905.00300", "submitter": "Ajay Bhardwaj", "authors": "Ajay Bhardwaj and Samar Agnihotri", "title": "D2D Multicast in Underlay Cellular Networks with Exclusion Zones", "comments": "25 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Underlay device-to-device (D2D) multicast communication has potential to\nimprove performance of cellular networks. However, co-channel interference\namong cellular users (CUs) and D2D multicast groups (MGs) limits the gains of\nsuch communication. Allowing the CUs to have exclusion zones around them where\nno receiver of any MG can exist, is a realistic and pragmatic approach to\nreduce the co-channel interference of cellular transmission on D2D multicast\nreception. We use a stochastic geometry based approach to model this scenario.\nSpecifically, we model the locations of CUs and D2D MG receivers with\nhomogeneous Poisson Point Process (PPP), and Poisson Hole Process (PHP),\nrespectively. We formulate the network sum throughput maximization problem in\nterms of a joint MG channel and power allocation problem with constraints on\ncellular and MG users maximum transmit and acceptable quality of service. We\nestablish that the MG channel allocation problem has computational complexity\nthat is exponential in both, the number of MGs and the number of available\ncellular channels. Then, we decompose this problem into two subproblems: subset\nselection problem and subset channel assignment problem. Based on observations\nand insights obtained from numerical analysis of the optimal solution of the\nsubset selection problem in wide variety of scenarios, we propose a\ncomputationally efficient scheme that achieves almost optimal performance for\nthe subset selection problem. We further provide a computationally efficient\nalgorithm that achieves almost optimal performance for the subset channel\nassignment problem. Finally, combining these two schemes, we provide a\ncomputationally efficient and almost optimal scheme to solve the channel\nallocation problem, and various results and insights on the variation of the\noptimal system performance with respect to different system parameters\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 13:07:59 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 04:03:12 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Bhardwaj", "Ajay", ""], ["Agnihotri", "Samar", ""]]}, {"id": "1905.00399", "submitter": "Ana\\\"is Finzi", "authors": "Anais Finzi and Ahlem Mifdaoui and Fabrice Frances and Emmanuel Lochin", "title": "Network Calculus-based Timing Analysis of AFDX networks incorporating\n  multiple TSN/BLS traffic classes", "comments": "Main work from PhD thesis: Specification and Analysis of an Extended\n  AFDX with TSN/BLS shapers for Mixed-Criticality Avionics Applications. DOI:\n  10.13140/RG.2.2.35379.48160/1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formal timing analysis of an extension of the AFDX standard,\nincorporating the TSN/BLS shaper, to homogenize the avionics communication\narchitecture, and enable the interconnection of different avionics domains with\nmixed-criticality levels, e.g., current AFDX traffic, Flight Control and\nIn-Flight Entertainment. Existing Network Calculus models are limited to three\nclasses, but applications with heterogeneous traffic require additional\nclasses. Hence, we propose to generalize an existing Network Calculus model to\ndo a worst-case timing analysis of an architecture with multiple BLS on\nmulti-hop networks, to infer real-time bounds. Then, we conduct the performance\nanalysis of such a proposal. First we evaluate the model on a simple 3-classes\nsingle-hop network to assess the sensitivity and tightness of the model, and\ncompare it to existing models (CPA and Network Calculus). Secondly, we study a\nrealistic AFDX configuration with six classes and two BLS. Finally, we compute\na real use-case to add A350 flight control traffic to the AFDX. Results show\nthe good properties of the generalized Network Calculus model compared to the\nCPA model and the efficiency of the extended AFDX to noticeably enhance the\nmedium priority level delay bounds, while respecting the higher priority level\nconstraints, in comparison with the current AFDX standard.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 17:34:15 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 19:34:47 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Finzi", "Anais", ""], ["Mifdaoui", "Ahlem", ""], ["Frances", "Fabrice", ""], ["Lochin", "Emmanuel", ""]]}, {"id": "1905.00479", "submitter": "Sofi\\`ene Affes", "authors": "Imene Trigui, Panagiotis D. Diamantoulakis, Sofiene Affes, George K.\n  Karagiannidis", "title": "Shadowed FSO/mmWave Systems with Interference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance of mixed free space optical\n(FSO)/millimeter-wave (mmWave) relay networks with interference at the\ndestination. The FSO/mmWave channels are assumed to follow\nMalaga-M/Generalized-K fading models with pointing errors in the FSO link. The\nH-transform theory, wherein integral transforms involve Fox's H-functions as\nkernels, is embodied to unifying the performance analysis framework that\nencompasses closed-form expressions for the outage probability, the average bit\nerror rate (BER) and the average capacity. By virtue of some H-transform\nasymptotic expansions, the high signal-to-interference-plus-noise ratio (SINR)\nanalysis reduces to easy-to-compute expressions for the outage probability and\nBER, which reveals inside information for the system design. We finally\ninvestigate the optimal power allocation strategy, which minimizes the outage\nprobability.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 20:25:49 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Trigui", "Imene", ""], ["Diamantoulakis", "Panagiotis D.", ""], ["Affes", "Sofiene", ""], ["Karagiannidis", "George K.", ""]]}, {"id": "1905.00504", "submitter": "Chiranjib Saha", "authors": "Chiranjib Saha and Harpreet S. Dhillon", "title": "Machine Learning meets Stochastic Geometry: Determinantal Subset\n  Selection for Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless networks, many problems can be formulated as subset selection\nproblems where the goal is to select a subset from the ground set with the\nobjective of maximizing some objective function. These problems are typically\nNP-hard and hence solved through carefully constructed heuristics, which are\nthemselves mostly NP-complete and thus not easily applicable to large networks.\nOn the other hand, subset selection problems occur in slightly different\ncontext in machine learning (ML) where the goal is to select a subset of high\nquality yet diverse items from a ground set. In this paper, we introduce a\nnovel DPP-based learning (DPPL) framework for efficiently solving subset\nselection problems in wireless networks. The DPPL is intended to replace the\ntraditional optimization algorithms for subset selection by learning the\nquality-diversity trade-off in the optimal subsets selected by an optimization\nroutine. As a case study, we apply DPPL to the wireless link scheduling\nproblem, where the goal is to determine the subset of simultaneously active\nlinks which maximizes the network-wide sum-rate. We demonstrate that the\nproposed DPPL approaches the optimal solution with significantly lower\ncomputational complexity than the popular optimization algorithms used for this\nproblem in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 21:20:21 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Saha", "Chiranjib", ""], ["Dhillon", "Harpreet S.", ""]]}, {"id": "1905.00554", "submitter": "Xintao Huan", "authors": "Xintao Huan and Kyeong Soo Kim", "title": "On the Practical Implementation of Propagation Delay and Clock Skew\n  Compensated High-Precision Time Synchronization Schemes with\n  Resource-Constrained Sensor Nodes in Multi-Hop Wireless Sensor Networks", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless sensor networks (WSNs), implementing a high-precision time\nsynchronization scheme on resource-constrained sensor nodes is a major\nchallenge. Our investigation of the practical implementation on a real testbed\nof the state-of-the-art WSN time synchronization scheme based on the\nasynchronous source clock frequency recovery and the reverse two-way message\nexchange, which can compensate for both propagation delay and clock skew for\nhigher precision, reveals that its performance on battery-powered,\nlow-complexity sensor nodes is not up to that predicted from simulation\nexperiments due to the limited precision floating-point arithmetic of sensor\nnodes. Noting the lower computational capability of typical sensor nodes and\nits impact on time synchronization, we propose an asymmetric high-precision\ntime synchronization scheme that can provide high-precision time\nsynchronization even with resource-constrained sensor nodes in multi-hop WSNs.\nIn the proposed scheme, all synchronization-related computations are done at\nthe head node equipped with abundant computing and power resources, while the\nsensor nodes are responsible for timestamping only. Experimental results with a\ntestbed based on TelosB motes running TinyOS demonstrate that the proposed time\nsynchronization scheme can avoid time synchronization errors resulting from the\nsingle-precision floating-point arithmetic of the resource-constrained sensor\nnodes and achieve microsecond-level time synchronization accuracy in multi-hop\nWSNs.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 02:37:42 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 02:33:38 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Huan", "Xintao", ""], ["Kim", "Kyeong Soo", ""]]}, {"id": "1905.00631", "submitter": "Jiska Classen", "authors": "Dennis Mantz, Jiska Classen, Matthias Schulz, Matthias Hollick", "title": "InternalBlue - Bluetooth Binary Patching and Experimentation Framework", "comments": null, "journal-ref": null, "doi": "10.1145/3307334.3326089", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bluetooth is one of the most established technologies for short range digital\nwireless data transmission. With the advent of wearables and the Internet of\nThings (IoT), Bluetooth has again gained importance, which makes security\nresearch and protocol optimizations imperative. Surprisingly, there is a lack\nof openly available tools and experimental platforms to scrutinize Bluetooth.\nIn particular, system aspects and close to hardware protocol layers are mostly\nuncovered.\n  We reverse engineer multiple Broadcom Bluetooth chipsets that are widespread\nin off-the-shelf devices. Thus, we offer deep insights into the internal\narchitecture of a popular commercial family of Bluetooth controllers used in\nsmartphones, wearables, and IoT platforms. Reverse engineered functions can\nthen be altered with our InternalBlue Python framework---outperforming\nevaluation kits, which are limited to documented and vendor-defined functions.\nThe modified Bluetooth stack remains fully functional and high-performance.\nHence, it provides a portable low-cost research platform.\n  InternalBlue is a versatile framework and we demonstrate its abilities by\nimplementing tests and demos for known Bluetooth vulnerabilities. Moreover, we\ndiscover a novel critical security issue affecting a large selection of\nBroadcom chipsets that allows executing code within the attacked Bluetooth\nfirmware. We further show how to use our framework to fix bugs in chipsets out\nof vendor support and how to add new security features to Bluetooth firmware.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 09:14:37 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Mantz", "Dennis", ""], ["Classen", "Jiska", ""], ["Schulz", "Matthias", ""], ["Hollick", "Matthias", ""]]}, {"id": "1905.00634", "submitter": "Jiska Classen", "authors": "Jiska Classen, Matthias Hollick", "title": "Inside Job: Diagnosing Bluetooth Lower Layers Using Off-the-Shelf\n  Devices", "comments": null, "journal-ref": null, "doi": "10.1145/3317549.3319727", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bluetooth is among the dominant standards for wireless short-range\ncommunication with multi-billion Bluetooth devices shipped each year. Basic\nBluetooth analysis inside consumer hardware such as smartphones can be\naccomplished observing the Host Controller Interface (HCI) between the\noperating system's driver and the Bluetooth chip. However, the HCI does not\nprovide insights to tasks running inside a Bluetooth chip or Link Layer (LL)\npackets exchanged over the air. As of today, consumer hardware internal\nbehavior can only be observed with external, and often expensive tools, that\nneed to be present during initial device pairing. In this paper, we leverage\nstandard smartphones for on-device Bluetooth analysis and reverse engineer a\ndiagnostic protocol that resides inside Broadcom chips. Diagnostic features\ninclude sniffing lower layers such as LL for Classic Bluetooth and Bluetooth\nLow Energy (BLE), transmission and reception statistics, test mode, and memory\npeek and poke.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 09:20:57 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Classen", "Jiska", ""], ["Hollick", "Matthias", ""]]}, {"id": "1905.00719", "submitter": "Rongpeng Li", "authors": "Rongpeng Li, Zhifeng Zhao, Xing Xu, Fei Ni, and Honggang Zhang", "title": "Internet of Intelligence: The Collective Advantage for Advancing\n  Communications and Intelligence", "comments": "6 figures; accepted by IEEE Wireless Commun with the title \"The\n  Collective Advantage for Advancing Communications and Intelligence\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The fifth-generation cellular networks (5G) has boosted the unprecedented\nconvergence between the information world and physical world. On the other\nhand, empowered with the enormous amount of data and information, artificial\nintelligence (AI) has been universally applied and pervasive AI is believed to\nbe an integral part of the six-generation cellular networks (6G). Consequently,\nbenefiting from the advancement in communication technology and AI, we boldly\nargue that the conditions for collective intelligence (CI) will be mature in\nthe 6G era and CI will emerge among the widely connected beings and things.\nAfterwards, we highlight the potential huge impact of CI on both communications\nand intelligence. In particular, we introduce a regular language (i.e., the\ninformation economy metalanguage) supporting the future collective\ncommunications to augment human intelligence and explain its potential\napplications in naming Internet information and pushing information centric\nnetworks forward. Meanwhile, we propose a stigmergy-based federated collective\nintelligence and demonstrate its achievement in a simulated scenario where the\nagents collectively work together to form a pattern through simple indirect\ncommunications. In a word, CI could advance both communications and\nintelligence.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 09:09:56 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 01:37:31 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 02:18:12 GMT"}, {"version": "v4", "created": "Sun, 12 May 2019 00:09:37 GMT"}, {"version": "v5", "created": "Thu, 10 Oct 2019 02:56:50 GMT"}, {"version": "v6", "created": "Thu, 16 Apr 2020 14:06:33 GMT"}, {"version": "v7", "created": "Sat, 18 Apr 2020 08:25:18 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Xu", "Xing", ""], ["Ni", "Fei", ""], ["Zhang", "Honggang", ""]]}, {"id": "1905.00785", "submitter": "Francisco Carpio", "authors": "Francisco Carpio, Admela Jukan, Roman Sosa, Ana Juan Ferrer", "title": "Engineering a QoS Provider Mechanism for Edge Computing with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1109/GLOBECOM38437.2019.9013946", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of new system solutions that integrate traditional cloud\ncomputing with the edge/fog computing paradigm, dynamic optimization of service\nexecution has become a challenge due to the edge computing resources being more\ndistributed and dynamic. How to optimize the execution to provide Quality of\nService (QoS) in edge computing depends on both the system architecture and the\nresource allocation algorithms in place. We design and develop a QoS provider\nmechanism, as an integral component of a fog-to-cloud system, to work in\ndynamic scenarios by using deep reinforcement learning. We choose reinforcement\nlearning since it is particularly well suited for solving problems in dynamic\nand adaptive environments where the decision process needs to be frequently\nupdated. We specifically use a Deep Q-learning algorithm that optimizes QoS by\nidentifying and blocking devices that potentially cause service disruption due\nto dynamicity. We compare the reinforcement learning based solution with\nstate-of-the-art heuristics that use telemetry data, and analyze pros and cons.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 14:47:29 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Carpio", "Francisco", ""], ["Jukan", "Admela", ""], ["Sosa", "Roman", ""], ["Ferrer", "Ana Juan", ""]]}, {"id": "1905.00964", "submitter": "Sailik Sengupta", "authors": "Sailik Sengupta, Ankur Chowdhary, Abdulhakim Sabur, Adel Alshamrani,\n  Dijiang Huang, Subbarao Kambhampati", "title": "A Survey of Moving Target Defenses for Network Security", "comments": "The first two authors contributed equally", "journal-ref": "IEEE Communications Surveys and Tutorials, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network defenses based on traditional tools, techniques, and procedures fail\nto account for the attacker's inherent advantage present due to the static\nnature of network services and configurations. To take away this asymmetric\nadvantage, Moving Target Defense (MTD) continuously shifts the configuration of\nthe underlying system, in turn reducing the success rate of cyberattacks. In\nthis survey, we analyze the recent advancements made in the development of MTDs\nand define categorizations that capture the key aspects of such defenses. We\nfirst categorize these defenses into different sub-classes depending on what\nthey move, when they move and how they move. In trying to answer the latter\nquestion, we showcase the use of domain knowledge and game-theoretic modeling\ncan help the defender come up with effective and efficient movement strategies.\nSecond, to understand the practicality of these defense methods, we discuss how\nvarious MTDs have been implemented and find that networking technologies such\nas Software Defined Networking and Network Function Virtualization act as key\nenablers for implementing these dynamic defenses. We then briefly highlight MTD\ntest-beds and case-studies to aid readers who want to examine or deploy\nexisting MTD techniques. Third, our survey categorizes proposed MTDs based on\nthe qualitative and quantitative metrics they utilize to evaluate their\neffectiveness in terms of security and performance. We use well-defined metrics\nsuch as risk analysis and performance costs for qualitative evaluation and\nmetrics based on Confidentiality, Integrity, Availability (CIA), attack\nrepresentation, QoS impact, and targeted threat models for quantitative\nevaluation. Finally, we show that our categorization of MTDs is effective in\nidentifying novel research areas and highlight directions for future research.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 21:06:44 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 00:49:22 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Sengupta", "Sailik", ""], ["Chowdhary", "Ankur", ""], ["Sabur", "Abdulhakim", ""], ["Alshamrani", "Adel", ""], ["Huang", "Dijiang", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1905.01008", "submitter": "Kemal Davaslioglu", "authors": "Yi Shi and Kemal Davaslioglu and Yalin E. Sagduyu", "title": "Generative Adversarial Network for Wireless Signal Spoofing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a novel approach of spoofing wireless signals by using a\ngeneral adversarial network (GAN) to generate and transmit synthetic signals\nthat cannot be reliably distinguished from intended signals. It is of paramount\nimportance to authenticate wireless signals at the PHY layer before they\nproceed through the receiver chain. For that purpose, various waveform,\nchannel, and radio hardware features that are inherent to original wireless\nsignals need to be captured. In the meantime, adversaries become sophisticated\nwith the cognitive radio capability to record, analyze, and manipulate signals\nbefore spoofing. Building upon deep learning techniques, this paper introduces\na spoofing attack by an adversary pair of a transmitter and a receiver that\nassume the generator and discriminator roles in the GAN and play a minimax game\nto generate the best spoofing signals that aim to fool the best trained defense\nmechanism. The output of this approach is two-fold. From the attacker point of\nview, a deep learning-based spoofing mechanism is trained to potentially fool a\ndefense mechanism such as RF fingerprinting. From the defender point of view, a\ndeep learning-based defense mechanism is trained against potential spoofing\nattacks when an adversary pair of a transmitter and a receiver cooperates. The\nprobability that the spoofing signal is misclassified as the intended signal is\nmeasured for random signal, replay, and GAN-based spoofing attacks. Results\nshow that the GAN-based spoofing attack provides a major increase in the\nsuccess probability of wireless signal spoofing even when a deep learning\nclassifier is used as the defense.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 02:27:55 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 18:06:06 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Shi", "Yi", ""], ["Davaslioglu", "Kemal", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1905.01011", "submitter": "Jakob Pfender", "authors": "Jakob Pfender, Alvin Valera, Winston K. G. Seah", "title": "Content Delivery Latency of Caching Strategies for Information-Centric\n  IoT", "comments": "10 pages, 9 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-network caching is a central aspect of Information-Centric Networking\n(ICN). It enables the rapid distribution of content across the network,\nalleviating strain on content producers and reducing content delivery\nlatencies. ICN has emerged as a promising candidate for use in the Internet of\nThings (IoT). However, IoT devices operate under severe constraints, most\nnotably limited memory. This means that nodes cannot indiscriminately cache all\ncontent; instead, there is a need for a caching strategy that decides what\ncontent to cache. Furthermore, many applications in the IoT space are\ntimesensitive; therefore, finding a caching strategy that minimises the latency\nbetween content request and delivery is desirable. In this paper, we evaluate a\nnumber of ICN caching strategies in regards to latency and hop count reduction\nusing IoT devices in a physical testbed. We find that the topology of the\nnetwork, and thus the routing algorithm used to generate forwarding\ninformation, has a significant impact on the performance of a given caching\nstrategy. To the best of our knowledge, this is the first study that focuses on\nlatency effects in ICN-IoT caching while using real IoT hardware, and the first\nto explicitly discuss the link between routing algorithm, network topology, and\ncaching effects.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 02:50:08 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Pfender", "Jakob", ""], ["Valera", "Alvin", ""], ["Seah", "Winston K. G.", ""]]}, {"id": "1905.01097", "submitter": "Jian Zhang", "authors": "Jian Zhang, Qimei Cui, Xuefei Zhang, Kwang-Cheng Chen, Ping Zhang", "title": "Event-triggered Online Proactive Network Association to Mobile Edge\n  Computing for IoT", "comments": "6 pages, 4 figures, the paper submitted to IEEE GLOBECOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-low latency communication for mobile machines emerges as a critical\ntechnology in Internet of Things (IoT). Proactive network association has been\nsuggested to support ultra-low latency communication with the assistance of\nmobile edge computing. To resolve system dynamics and uncertainty, in this\npaper, an online proactive network association is proposed to minimize average\ntask delay while considering time-average energy consumption constraints. Under\ndistributed computing and networking environments, we formulate an\nevent-triggered proactive network association model by semi-Markov task states\nand independent identically distributed (i.i.d.) random events. Then we\nfacilitate the mobility-aware anticipatory network association to predictively\nconsider handover effects caused by the mobility. Based on the Markov decision\nprocesses (MDP) and Lyapunov optimization, the two-stage online proactive\nnetwork association (TOPNA) decision algorithm is proposed without the\nknowledge nor distribution of random events. Simulation results exhibit the\neffectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 10:00:45 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 03:34:17 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Zhang", "Jian", ""], ["Cui", "Qimei", ""], ["Zhang", "Xuefei", ""], ["Chen", "Kwang-Cheng", ""], ["Zhang", "Ping", ""]]}, {"id": "1905.01136", "submitter": "Hashim A. Hashim", "authors": "Hashim A. Hashim, Mohammad A. Abido", "title": "Location Management in LTE Networks using Multi-Objective Particle Swarm\n  Optimization", "comments": "Computer Networks", "journal-ref": null, "doi": "10.1016/j.comnet.2019.04.009", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term evolution (LTE) and LTE-advance (LTE-A) are widely used efficient\nnetwork technologies serving billions of users, since they are featured with\nhigh spectrum efficiency, less latency, and higher bandwidth. Despite\nremarkable advantages offered by these technologies, signaling overhead remains\na major issue in accessing the network. In particular, the load of signaling is\nmainly attributed to location management. This paper proposes an efficient\napproach for minimizing the total signaling overhead of location management in\nLTE networks using multi-objective particle swarm optimization (MOPSO).\nTracking area update (TAU) and paging are considered to be the main elements of\nthe signaling overhead of optimal location management in LTE. In addition, the\ntotal inter-list handover contributes significantly to the total signaling\noverhead. However, the total signaling cost of TAU and paging is adversely\nrelated to the total inter-list handover. Two cost functions should be\nminimized, the first is the total signaling cost of TAU and paging and the\nsecond is the total signaling overhead. The trade-off between these two\nobjectives can be circumvented by MOPSO, which alleviates the total signaling\noverhead. A set of non-dominated solutions on the Pareto-optimal front is\ndefined and the best compromise solution. The proposed algorithm results\nfeasible compromise solution, minimizing the signaling overhead and the\nconsumption of the power battery of a user. The efficacy and the robustness of\nthe proposed algorithm have been proven using large scale environment problem\nillustrative example. The location management in LTE networks using MOPSO best\ncompromise solution has been compared to a mixed integer non-linear programming\n(MINLP) algorithm. Location management mobility management entity MME pooling\nclustering SON Distributed Centralized pooling scheme fuzzy implementation\nsetup LP-CPLEX\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 17:19:29 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 14:04:11 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Hashim", "Hashim A.", ""], ["Abido", "Mohammad A.", ""]]}, {"id": "1905.01137", "submitter": "Farnaz Yousefi", "authors": "Farnaz Yousefi, Ehsan Khamespanah, Mohammed Gharib, Marjan Sirjani,\n  Ali Movaghar", "title": "VeriVANca: An Actor-Based Framework for Formal Verification of Warning\n  Message Dissemination Schemes in VANETs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the applications of vehicular ad-hoc networks is warning message\ndissemination among vehicles in dangerous situations to prevent more damage.\nThe only communication mechanism for message dissemination is multi-hop\nbroadcast; in which, forwarding a received message have to be regulated using a\nscheme regarding the selection of forwarding nodes. When analyzing these\nschemes, simulation-based frameworks fail to provide guaranteed analysis\nresults due to the high level of concurrency in this application. Therefore,\nthere is a need to use model checking approaches for achieving reliable\nresults. In this paper, we have developed a framework called VeriVANca, to\nprovide model checking facilities for the analysis of warning message\ndissemination schemes in VANETs. To this end, an actor-based modeling language,\nRebeca, is used which is equipped with a variety of model checking engines. To\nillustrate the applicability of VeriVANca, modeling and analysis of two warning\nmessage dissemination schemes are presented. Some scenarios for these schemes\nare presented to show that concurrent behaviors of the system components may\ncause uncertainty in both behavior and performance which may not be detected by\nsimulation-based techniques. Furthermore, the scalability of VeriVANca is\nexamined by analyzing a middle-sized model.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 11:30:06 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Yousefi", "Farnaz", ""], ["Khamespanah", "Ehsan", ""], ["Gharib", "Mohammed", ""], ["Sirjani", "Marjan", ""], ["Movaghar", "Ali", ""]]}, {"id": "1905.01138", "submitter": "Sunny Sanyal", "authors": "Sunny Sanyal, Dapeng Wu and Boubakr Nour", "title": "A Federated Filtering Framework for Internet of Medical Things", "comments": "6 pages, 6 Figures, accepted for oral presentation in IEEE ICC 2019,\n  Internet of Things, Federated Learning and Perturbation theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the dominant paradigm, all the wearable IoT devices used in the\nhealthcare sector also known as the internet of medical things (IoMT) are\nresource constrained in power and computational capabilities. The IoMT devices\nare continuously pushing their readings to the remote cloud servers for\nreal-time data analytics, that causes faster drainage of the device battery.\nMoreover, other demerits of continuous centralizing of data include exposed\nprivacy and high latency. This paper presents a novel Federated Filtering\nFramework for IoMT devices which is based on the prediction of data at the\ncentral fog server using shared models provided by the local IoMT devices. The\nfog server performs model averaging to predict the aggregated data matrix and\nalso computes filter parameters for local IoMT devices. Two significant\ntheoretical contributions of this paper are the global tolerable perturbation\nerror (${To{l_F}}$) and the local filtering parameter ($\\delta$); where the\nformer controls the decision-making accuracy due to eigenvalue perturbation and\nthe later balances the tradeoff between the communication overhead and\nperturbation error of the aggregated data matrix (predicted matrix) at the fog\nserver. Experimental evaluation based on real healthcare data demonstrates that\nthe proposed scheme saves upto 95\\% of the communication cost while maintaining\nreasonable data privacy and low latency.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 02:14:44 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Sanyal", "Sunny", ""], ["Wu", "Dapeng", ""], ["Nour", "Boubakr", ""]]}, {"id": "1905.01139", "submitter": "Santu Sardar", "authors": "Santu Sardar, Amit K. Mishra and Mohammed Zafar Ali Khan", "title": "Performance Evaluation of LTE-CommSense System for Discrimination of\n  Presence of Multiple Objects in Outdoor Environment", "comments": "This paper is a postprint of a paper submitted to and accepted for\n  publication in IEEE Transactions on Instrumentation and Measurement and is\n  subject to IEEE Transactions on Instrumentation and Measurement Copyright", "journal-ref": "IEEE Transactions on Instrumentation and Measurement. year 2019,\n  Print ISSN: 0018-9456, Online ISSN: 1557-9662", "doi": "10.1109/TIM.2019.2904332", "report-no": "TIM2904332", "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LTE-CommSense is a novel instrumentation scheme which analyzes channel\naffected reference signals of LTE downlink signal to obtain knowledge about the\nenvironmental change. This work presents the characterization of LTE-CommSense\ninstrument to detect presence or absence of objects in outdoor environment.\nAdditionally, we analyze its capability of detecting and distinguishing when\nmultiple objects are present. For performance evaluation and characterization\nof this instrument, we derive object detection accuracy, FAR, FRR and\nresolution which we believe are the most important figures of merit in this\ncase. As the operation of LTE-CommSense is to detect events instead of objects,\nwe redefine the concept of resolution for LTE-CommSense. Two different\nproposals to represent the redefined resolution viz. Neyman Pearson principle\nbased and Cramer Rao principle based resolution are presented here. All the\nperformance metrics are derived using practical data captured using an SDR\nplatform modeled as a LTE-CommSense receiver. We observe that, LTE-CommSense\nprovides better performance in detecting presence or absence of objects at near\nrange.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 19:02:59 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Sardar", "Santu", ""], ["Mishra", "Amit K.", ""], ["Khan", "Mohammed Zafar Ali", ""]]}, {"id": "1905.01140", "submitter": "Muhammad Umar Javed", "authors": "Muhammad U. Javed, Zaid Bin Tariq, Usama Muneeb, Ijaz Haider Naqvi", "title": "Multi-level Dynamic Optimization of Intelligent LEACH with Cost\n  Effective Deep Belief Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy utilization is a key attribute for energy constrained wireless sensor\nnetworks (WSN) that directly impacts the life time of the network. LEACH (and\nits variants) are considered to be the most common energy efficient routing\nprotocols for WSN. In this paper, we propose an optimized modification of LEACH\nthat makes use of multi-hop communication, dynamic cluster boundaries and\nenergy conservation in routing to maximize lifetime of a network. We propose a\nmulti-level approach to maximize our gains with regards to energy conservation\ni.e., i) Dynamic programming based intra-cluster optimization technique has\nbeen proposed ii) Ant Colony Optimization is used for energy efficient cluster\nhead connection with sink node and iii) Voronoi Tessellation are employed for\nefficient coverage planning i.e., dynamic formation of cluster boundaries. In\norder to accommodate a more flexible adhoc network, hybrid (reactive and\nproactive) event monitoring based on Deep Belief Network has been integrated in\ndistributed nodes to improve the latency of the system. The results show that\nthe proposed scheme significantly outperforms the current state of the art with\nregards to network lifetime and throughput.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 20:50:33 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Javed", "Muhammad U.", ""], ["Tariq", "Zaid Bin", ""], ["Muneeb", "Usama", ""], ["Naqvi", "Ijaz Haider", ""]]}, {"id": "1905.01141", "submitter": "Fabrice Guillemin", "authors": "Veronica Quintuna Rodriguez and Fabrice Guillemin", "title": "Higher aggregation of gNodeBs in Cloud-RAN architectures via parallel\n  computing", "comments": "Appeared at ICIN'19, Paris, February 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the virtualization and the centralization of\nreal-time network functions, notably in the framework of Cloud RAN (C-RAN). We\nthoroughly analyze the required fronthaul capacity for the deployment of the\nproposed C-RAN architecture. We are specifically interested in the performance\nof the software based channel coding function. We develop a dynamic\nmulti-threading approach to achieve parallel computing on a multi-core\nplatform. Measurements from an OAI-based testbed show important gains in terms\nof latency; this enables the increase of the distance between the radio\nelements and the virtualized RAN functions and thus a higher aggregation of\ngNodeBs in edge data centers, referred to as Central Offices (COs).\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 13:08:01 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Rodriguez", "Veronica Quintuna", ""], ["Guillemin", "Fabrice", ""]]}, {"id": "1905.01142", "submitter": "Wael Jaafar", "authors": "Wael Jaafar, Amina Mseddi, Wessam Ajib, Halima Elbiaze", "title": "Joint Caching and Resource Allocation in D2D-Assisted Wireless HetNet", "comments": "24 pages, 5 figures, submitted to IEEE Transactions on Wireless\n  Communications (12-Feb-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G networks are required to provide very fast and reliable communications\nwhile dealing with the increase of users traffic. In Heterogeneous Networks\n(HetNets) assisted with Device-to-Device (D2D) communication, traffic can be\noffloaded to Small Base Stations or to users to improve the network's\nsuccessful data delivery rate. In this paper, we aim at maximizing the average\nnumber of files that are successfully delivered to users, by jointly optimizing\ncaching placement and channel allocation in cache-enabled D2D-assisted HetNets.\nAt first, an analytical upper-bound on the average content delivery delay is\nderived. Then, the joint optimization problem is formulated. The non-convexity\nof the problem is alleviated, and the optimal solution is determined. Due to\nthe high time complexity of the obtained solution, a low-complex sub-optimal\napproach is proposed. Numerical results illustrate the efficacy of the proposed\nsolutions and compare them to conventional approaches. Finally, by\ninvestigating the impact of key parameters, e.g. power, caching capacity, QoS\nrequirements, etc., guidelines to design these networks are obtained.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 12:54:21 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Jaafar", "Wael", ""], ["Mseddi", "Amina", ""], ["Ajib", "Wessam", ""], ["Elbiaze", "Halima", ""]]}, {"id": "1905.01143", "submitter": "Ajay Pratap Dr.", "authors": "Ajay Pratap, Ragini Gupta, Venkata Sriram Siddhardh Nadendla and Sajal\n  K. Das", "title": "On Maximizing Task Throughput in IoT-enabled 5G Networks under Latency\n  and Bandwidth Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog computing in 5G networks has played a significant role in increasing the\nnumber of users in a given network. However, Internet-of-Things (IoT) has\ndriven system designers towards designing heterogeneous networks to support\ndiverse demands (tasks with different priority values) with different latency\nand data rate constraints. In this paper, our goal is to maximize the total\nnumber of tasks served by a heterogeneous network, labeled task throughput, in\nthe presence of data rate and latency constraints and device preferences\nregarding computational needs. Since our original problem is intractable, we\npropose an efficient solution based on graph-coloring techniques. We\ndemonstrate the effectiveness of our proposed algorithm using numerical\nresults, real-world experiments on a laboratory testbed and comparing with the\nstate-of-the-art algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 21:23:26 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Pratap", "Ajay", ""], ["Gupta", "Ragini", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""], ["Das", "Sajal K.", ""]]}, {"id": "1905.01154", "submitter": "Mike Koivisto", "authors": "Jukka Talvitie, Toni Levanen, Mike Koivisto, Tero Ihalainen, Kari\n  Pajukoski, and Mikko Valkama", "title": "Positioning and Location-Aware Communications for Modern Railways with\n  5G New Radio", "comments": "This article has been submitted to IEEE Communications Magazine for a\n  publication. This is the first revised version of the original article and is\n  now under second review round", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing high-capacity radio connectivity for high-speed trains (HSTs) is\none of the most important use cases of emerging 5G New Radio (NR) networks. In\nthis article, we show that 5G NR technology can also facilitate high-accuracy\ncontinuous localization and tracking of HSTs. Furthermore, we describe and\ndemonstrate how the NR network can utilize the continuous location information\nfor efficient beam-management and beamforming, as well as for downlink Doppler\nprecompensation in the single-frequency network context. Additionally, with\nparticular focus on millimeter wave networks, novel concepts for low-latency\nintercarrier interference (ICI) estimation and compensation, due to residual\nDoppler and oscillator phase noise, are described and demonstrated. The\nprovided numerical results at 30 GHz operating band show that sub-meter\npositioning and sub-degree beam-direction accuracies can be obtained with very\nhigh probabilities in the order of 95-99%. The results also show that the\ndescribed Doppler precompensation and ICI estimation and cancellation methods\nsubstantially improve the throughput of the single-frequency HST network.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 12:21:36 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 07:12:58 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Talvitie", "Jukka", ""], ["Levanen", "Toni", ""], ["Koivisto", "Mike", ""], ["Ihalainen", "Tero", ""], ["Pajukoski", "Kari", ""], ["Valkama", "Mikko", ""]]}, {"id": "1905.01194", "submitter": "Mohsin Khalil", "authors": "Mohsin Khalil, Farid Ullah Khan", "title": "Exploration of TCP Parameters for Enhanced Performance in a Datacenter\n  Environment", "comments": "Accepted in IEEE 2018 4th International Conference on Electrical,\n  Electronics and System Engineering (ICEESE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TCP parameters in most of the operating systems are optimized for generic\nhome and office environments having low latencies in their internal networks.\nHowever, this arrangement invariably results in a compromized network\nperformance when same parameters are straight away slotted into a datacenter\nenvironment. We identify key TCP parameters that have a major impact on network\nperformance based on the study and comparative analysis of home and datacenter\nenvironments. We discuss certain criteria for the modification of TCP\nparameters and support our analysis with simulation results that validate the\nperformance improvement in case of datacenter environment.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 14:09:54 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 17:27:34 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 07:20:36 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Khalil", "Mohsin", ""], ["Khan", "Farid Ullah", ""]]}, {"id": "1905.01430", "submitter": "Zhengping Luo", "authors": "Zhengping Luo, Shangqing Zhao, Zhuo Lu, Jie Xu, and Yalin E. Sagduyu", "title": "When Attackers Meet AI: Learning-empowered Attacks in Cooperative\n  Spectrum Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defense strategies have been well studied to combat Byzantine attacks that\naim to disrupt cooperative spectrum sensing by sending falsified versions of\nspectrum sensing data to a fusion center. However, existing studies usually\nassume network or attackers as passive entities, e.g., assuming the prior\nknowledge of attacks is known or fixed. In practice, attackers can actively\nadopt arbitrary behaviors and avoid pre-assumed patterns or assumptions used by\ndefense strategies. In this paper, we revisit this security vulnerability as an\nadversarial machine learning problem and propose a novel learning-empowered\nattack framework named Learning-Evaluation-Beating (LEB) to mislead the fusion\ncenter. Based on the black-box nature of the fusion center in cooperative\nspectrum sensing, our new perspective is to make the adversarial use of machine\nlearning to construct a surrogate model of the fusion center's decision model.\nWe propose a generic algorithm to create malicious sensing data using this\nsurrogate model. Our real-world experiments show that the LEB attack is\neffective to beat a wide range of existing defense strategies with an up to 82%\nof success ratio. Given the gap between the proposed LEB attack and existing\ndefenses, we introduce a non-invasive method named as influence-limiting\ndefense, which can coexist with existing defenses to defend against LEB attack\nor other similar attacks. We show that this defense is highly effective and\nreduces the overall disruption ratio of LEB attack by up to 80%.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 04:58:00 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 21:36:06 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Luo", "Zhengping", ""], ["Zhao", "Shangqing", ""], ["Lu", "Zhuo", ""], ["Xu", "Jie", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1905.01443", "submitter": "Rupei Xu", "authors": "Rupei Xu, Andr\\'as Farag\\'o and Jason P. Jue", "title": "Job Edge-Fog Interconnection Network Creation Game in Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the first paper to address the topology structure of Job Edge-Fog\ninterconnection network in the perspective of network creation game. A two\nlevel network creation game model is given, in which the first level is similar\nto the traditional network creation game with total length objective to other\nnodes. The second level adopts two types of cost functions, one is created\nbased on the Jackson-Wolinsky type of distance based utility, another is\ncreated based on the Network-Only Cost in the IoT literature. We show the\nperformance of this two level game (Price of Anarchy). This work discloses how\nthe selfish strategies of each individual device can influence the global\ntopology structure of the job edge-fog interconnection network and provides\ntheoretical foundations of the IoT infrastructure construction. A significant\nadvantage of this framework is that it can avoid solving the traditional\nexpensive and impractical quadratic assignment problem, which was the typical\nframework to study this task. Furthermore, it can control the systematic\nperformance based only on one or two cost parameters of the job edge-fog\nnetworks, independently and in a distributed way.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 06:35:26 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 08:12:48 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Xu", "Rupei", ""], ["Farag\u00f3", "Andr\u00e1s", ""], ["Jue", "Jason P.", ""]]}, {"id": "1905.01530", "submitter": "George Iosifidis Dr", "authors": "Georgios S. Paschos, Apostolos Destounis, George Iosifidis", "title": "Learning to Cooperate in D2D Caching Networks", "comments": "to appear in IEEE SPAWC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a wireless device-to-device (D2D) cooperative network where\nmemory-endowed nodes store and exchange content. Each node generates random\nfile requests following an unknown and possibly arbitrary spatio-temporal\nprocess, and a base station (BS) delivers any file that is not found at its\nneighbors' cache, at the expense of higher cost. We design an online learning\nalgorithm which minimizes the aggregate delivery cost by assisting each node to\ndecide which files to cache and which files to fetch from the BS and other\ndevices. Our policy relies on the online gradient descent algorithm, is\namenable to distributed execution, and achieves asymptotically optimal\nperformance for any request pattern, without prior information.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 17:21:00 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Paschos", "Georgios S.", ""], ["Destounis", "Apostolos", ""], ["Iosifidis", "George", ""]]}, {"id": "1905.01607", "submitter": "Siham Khoussi", "authors": "Siham Khoussi, Ayoub Nouri, Junxiao Shi, James Filliben, Lotfi\n  Benmohamed, Abdella Battou, Saddek Bensalem", "title": "Performance Evaluation of the NDN Data Plane Using Statistical Model\n  Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.FL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Named Data Networking (NDN) is an emerging technology for a future internet\narchitecture that addresses weaknesses of the Internet Protocol (IP). Since\nInternet users and applications have demonstrated an ever-increasing need for\nhigh speed packet forwarding, research groups have investigated different\ndesigns and implementation for fast NDN data plane forwarders and claimed they\nwere capable of achieving high throughput rates. However, the correctness of\nthese statements is not supported by any verification technique or formal\nproof. In this paper, we propose using a formal model-based approach to\novercome this issue. We consider the NDN-DPDK prototype implementation of a\nforwarder realized at NIST, which leverages concurrency to enhance overall\nquality of service. We use our approach to improve its design and to formally\nshow that it can achieve high throughput rates.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 05:02:06 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 20:29:45 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Khoussi", "Siham", ""], ["Nouri", "Ayoub", ""], ["Shi", "Junxiao", ""], ["Filliben", "James", ""], ["Benmohamed", "Lotfi", ""], ["Battou", "Abdella", ""], ["Bensalem", "Saddek", ""]]}, {"id": "1905.01654", "submitter": "Chengxiao Liu", "authors": "Chengxiao Liu, Wei Feng, Yunfei Chen, Cheng-Xiang Wang and Ning Ge", "title": "Optimal Beamforming for Hybrid Satellite Terrestrial Networks with\n  Nonlinear PA and Imperfect CSIT", "comments": "5 pages, 5 figures, journal", "journal-ref": "IEEE Wireless Communications Letters, 2019", "doi": "10.1109/LWC.2019.2952124", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hybrid satellite-terrestrial networks (HSTNs), spectrum sharing is crucial\nto alleviate the \"spectrum scarcity\" problem. Therein, the transmit beams\nshould be carefully designed to mitigate the inter-satellite-terrestrial\ninterference. Different from previous studies, this work considers the impact\nof both nonlinear power amplifier (PA) and large-scale channel state\ninformation at the transmitter (CSIT) on beamforming. These phenomena are\nusually inevitable in a practical HSTN. Based on the Saleh model of PA\nnonlinearity and the large-scale multi-beam satellite channel parameters, we\nformulate a beamforming optimization problem to maximize the achievable rate of\nthe satellite system while ensuring that the inter-satellite-terrestrial\ninterference is below a given threshold. The optimal amplitude and phase of\ndesired beams are derived in a decoupled manner. Simulation results demonstrate\nthe superiority of the proposed beamforming scheme.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 11:19:37 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 01:48:01 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 02:38:35 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 12:55:33 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Liu", "Chengxiao", ""], ["Feng", "Wei", ""], ["Chen", "Yunfei", ""], ["Wang", "Cheng-Xiang", ""], ["Ge", "Ning", ""]]}, {"id": "1905.01663", "submitter": "Shuo Wan", "authors": "Shuo Wan, Jiaxun Lu, Pingyi Fan, and Khaled B. Letaief", "title": "Towards Big data processing in IoT: network management for online edge\n  data processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC cs.IT eess.IV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heavy data load and wide cover range have always been crucial problems for\ninternet of things (IoT). However, in mobile-edge computing (MEC) network, the\nhuge data can be partly processed at the edge. In this paper, a MEC-based big\ndata analysis network is discussed. The raw data generated by distributed\nnetwork terminals are collected and processed by edge servers. The edge servers\nsplit out a large sum of redundant data and transmit extracted information to\nthe center cloud for further analysis. However, for consideration of limited\nedge computation ability, part of the raw data in huge data sources may be\ndirectly transmitted to the cloud. To manage limited resources online, we\npropose an algorithm based on Lyapunov optimization to jointly optimize the\npolicy of edge processor frequency, transmission power and bandwidth\nallocation. The algorithm aims at stabilizing data processing delay and saving\nenergy without knowing probability distributions of data sources. The proposed\nnetwork management algorithm may contribute to big data processing in future\nIoT.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 11:42:38 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Wan", "Shuo", ""], ["Lu", "Jiaxun", ""], ["Fan", "Pingyi", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "1905.01665", "submitter": "Vasilios Siris", "authors": "Vasilios A. Siris, Dimitrios Dimopoulos, Nikos Fotiou, Spyros\n  Voulgaris, George C. Polyzos", "title": "OAuth 2.0 meets Blockchain for Authorization in Constrained IoT\n  Environments", "comments": "Accepted in IEEE 5th World Forum on Internet of Things (WF-IoT),\n  15-18 April 2019, Limerick, Ireland. arXiv admin note: text overlap with\n  arXiv:1905.01671", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present models for utilizing blockchain and smart contract technology with\nthe widely used OAuth 2.0 open authorization framework to provide delegated\nauthorization for constrained IoT devices. The models involve different\ntradeoffs in terms of privacy, delay, and cost, while exploiting key advantages\nof blockchains and smart contracts. These include linking payments to\nauthorization grants, immutably recording authorization information and\npolicies in smart contracts, and offering resilience through the execution of\nsmart contract code on all blockchain nodes.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 11:47:49 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Siris", "Vasilios A.", ""], ["Dimopoulos", "Dimitrios", ""], ["Fotiou", "Nikos", ""], ["Voulgaris", "Spyros", ""], ["Polyzos", "George C.", ""]]}, {"id": "1905.01671", "submitter": "Vasilios Siris", "authors": "Vasilios A. Siris, Dimitrios Dimopoulos, Nikos Fotiou, Spyros\n  Voulgaris, George C. Polyzos", "title": "Interledger Smart Contracts for Decentralized Authorization to\n  Constrained Things", "comments": "Accepted in 2nd Workshop on Cryptocurrencies and Blockchains for\n  Distributed Systems (CryBlock 2019), in conjunction with IEEE INFOCOM, April\n  29 - May 2, 2019, Paris, France. arXiv admin note: text overlap with\n  arXiv:1905.01665", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present models that utilize smart contracts and interledger mechanisms to\nprovide decentralized authorization for constrained IoT devices. The models\ninvolve different tradeoffs in terms of cost, delay, complexity, and privacy,\nwhile exploiting key advantages of smart contracts and multiple blockchains\nthat communicate with interledger mechanisms. These include immutably recording\nhashes of authorization information and policies in smart contracts, resilience\nthrough the execution of smart contract code on all blockchain nodes, and\ncryptographically linking transactions and IoT events recorded on different\nblockchains using hash and time-lock mechanisms. The proposed models are\nevaluated on the public Ethereum testnets Rinkeby and Ropsten, in terms of\nexecution cost (gas), delay, and reduction of data that needs to be sent to the\nconstrained IoT devices.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 12:32:55 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Siris", "Vasilios A.", ""], ["Dimopoulos", "Dimitrios", ""], ["Fotiou", "Nikos", ""], ["Voulgaris", "Spyros", ""], ["Polyzos", "George C.", ""]]}, {"id": "1905.01679", "submitter": "Chaojie Gu", "authors": "Chaojie Gu, Linshan Jiang, Rui Tan, Mo Li, Jun Huang", "title": "Attack-Aware Data Timestamping in Low-Power Synchronization-Free LoRaWAN", "comments": "40th IEEE International Conference on Distributed Computing Systems\n  (ICDCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-power wide-area network technologies such as LoRaWAN are promising for\ncollecting low-rate monitoring data from geographically distributed sensors, in\nwhich timestamping the sensor data is a critical system function. This paper\nconsiders a synchronization-free approach to timestamping LoRaWAN uplink data\nbased on signal arrival time at the gateway, which well matches LoRaWAN's\none-hop star topology and releases bandwidth from transmitting timestamps and\nsynchronizing end devices' clocks at all times. However, we show that this\napproach is susceptible to a {\\em frame delay attack} consisting of malicious\nframe collision and delayed replay. Real experiments show that the attack can\naffect the end devices in large areas up to about $50,000\\,\\text{m}^2$. In a\nbroader sense, the attack threatens any system functions requiring timely\ndeliveries of LoRaWAN frames. To address this threat, we propose a\n$\\mathsf{LoRaTS}$ gateway design that integrates a commodity LoRaWAN gateway\nand a low-power software-defined radio receiver to track the inherent frequency\nbiases of the end devices. Based on an analytic model of LoRa's chirp spread\nspectrum modulation, we develop signal processing algorithms to estimate the\nfrequency biases with high accuracy beyond that achieved by LoRa's default\ndemodulation. The accurate frequency bias tracking capability enables the\ndetection of the attack that introduces additional frequency biases. Extensive\nexperiments show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 13:14:45 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 12:43:47 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Gu", "Chaojie", ""], ["Jiang", "Linshan", ""], ["Tan", "Rui", ""], ["Li", "Mo", ""], ["Huang", "Jun", ""]]}, {"id": "1905.01749", "submitter": "Max Noormohammadpour", "authors": "Mohammad Noormohammadpour, Srikanth Kandula, Cauligi S. Raghavendra,\n  Sriram Rao", "title": "Efficient Inter-Datacenter Bulk Transfers with Mixed Completion Time\n  Objectives", "comments": "Accepted to Elsevier Computer Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bulk transfers from one to multiple datacenters can have many different\ncompletion time objectives ranging from quickly replicating some $k$ copies to\nminimizing the time by which the last destination receives a full replica. We\ndesign an SDN-style wide-area traffic scheduler that optimizes different\ncompletion time objectives for various requests. The scheduler builds, for each\nbulk transfer, one or more multicast forwarding trees which preferentially use\nlightly loaded network links. Multiple multicast trees are used per bulk\ntransfer to insulate destinations that have higher available bandwidth and can\nhence finish quickly from congested destinations. These decisions--how many\ntrees to construct and which receivers to serve using a given tree--result from\nan optimization problem that minimizes a weighted sum of transfers' completion\ntime objectives and their bandwidth consumption. Results from simulations and\nemulations on Mininet show that our scheduler, Iris, can improve different\ncompletion time objectives by about $2.5\\times$.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 21:22:44 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 06:02:51 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 16:14:54 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Noormohammadpour", "Mohammad", ""], ["Kandula", "Srikanth", ""], ["Raghavendra", "Cauligi S.", ""], ["Rao", "Sriram", ""]]}, {"id": "1905.01960", "submitter": "Tamara Radivilova A", "authors": "Tamara Radivilova and Lyudmyla Kirichenko and Dmytro Ageiev and\n  Vitalii Bulakh", "title": "The Methods to Improve Quality of Service by Accounting Secure\n  Parameters", "comments": "10 pages, 1 figure, 1 equation, 1 table. arXiv admin note: text\n  overlap with arXiv:1904.05202", "journal-ref": "In: Hu Z., Petoukhov S., Dychka I., He M. (eds) Advances in\n  Computer Science for Engineering and Education II. ICCSEEA 2019. Advances in\n  Intelligent Systems and Computing, vol 938, pp 346-355. 2020. Springer, Cham", "doi": "10.1007/978-3-030-16621-2_32", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A solution to the problem of ensuring quality of service, providing a greater\nnumber of services with higher efficiency taking into account network security\nis proposed. In this paper, experiments were conducted to analyze the effect of\nself-similarity and attacks on the quality of service parameters. Method of\nbuffering and control of channel capacity and calculating of routing cost\nmethod in the network, which take into account the parameters of traffic\nmultifractality and the probability of detecting attacks in telecommunications\nnetworks were proposed. The both proposed methods accounting the given\nrestrictions on the delay time and the number of lost packets for every type\nquality of service traffic. During simulation the parameters of transmitted\ntraffic (self-similarity, intensity) and the parameters of network (current\nchannel load, node buffer size) were changed and the maximum allowable load of\nnetwork was determined. The results of analysis show that occurrence of\noverload when transmitting traffic over a switched channel associated with\nmultifractal traffic characteristics and presence of attack. It was shown that\nproposed methods can reduce the lost data and improve the efficiency of network\nresources.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 11:49:37 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Radivilova", "Tamara", ""], ["Kirichenko", "Lyudmyla", ""], ["Ageiev", "Dmytro", ""], ["Bulakh", "Vitalii", ""]]}, {"id": "1905.02178", "submitter": "Baturalp Buyukates", "authors": "Baturalp Buyukates and Alkan Soysal and Sennur Ulukus", "title": "Age of Information Scaling in Large Networks with Hierarchical\n  Cooperation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $n$ randomly located source-destination (S-D) pairs on a fixed area\nnetwork that want to communicate with each other, we study the age of\ninformation with a particular focus on its scaling as the network size $n$\ngrows. We propose a three-phase transmission scheme that utilizes\n\\textit{hierarchical cooperation} between users along with \\textit{mega update\npackets} and show that an average age scaling of $O(n^{\\alpha(h)}\\log n)$\nper-user is achievable where $h$ denotes the number of hierarchy levels and\n$\\alpha(h) = \\frac{1}{3\\cdot2^h+1}$ which tends to $0$ as $h$ increases such\nthat asymptotically average age scaling of the proposed scheme is $O(\\log n)$.\nTo the best of our knowledge, this is the best average age scaling result in a\nstatus update system with multiple S-D pairs.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:52:03 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Buyukates", "Baturalp", ""], ["Soysal", "Alkan", ""], ["Ulukus", "Sennur", ""]]}, {"id": "1905.02248", "submitter": "Xiaoliang Chen", "authors": "Xiaoliang Chen, Baojia Li, Roberto Proietti, Hongbo Lu, Zuqing Zhu, S.\n  J. Ben Yoo", "title": "DeepRMSA: A Deep Reinforcement Learning Framework for Routing,\n  Modulation and Spectrum Assignment in Elastic Optical Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JLT.2019.2923615", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes DeepRMSA, a deep reinforcement learning framework for\nrouting, modulation and spectrum assignment (RMSA) in elastic optical networks\n(EONs). DeepRMSA learns the correct online RMSA policies by parameterizing the\npolicies with deep neural networks (DNNs) that can sense complex EON states.\nThe DNNs are trained with experiences of dynamic lightpath provisioning. We\nfirst modify the asynchronous advantage actor-critic algorithm and present an\nepisode-based training mechanism for DeepRMSA, namely, DeepRMSA-EP. DeepRMSA-EP\ndivides the dynamic provisioning process into multiple episodes (each\ncontaining the servicing of a fixed number of lightpath requests) and performs\ntraining by the end of each episode. The optimization target of DeepRMSA-EP at\neach step of servicing a request is to maximize the cumulative reward within\nthe rest of the episode. Thus, we obviate the need for estimating the rewards\nrelated to unknown future states. To overcome the instability issue in the\ntraining of DeepRMSA-EP due to the oscillations of cumulative rewards, we\nfurther propose a window-based flexible training mechanism, i.e., DeepRMSA-FLX.\nDeepRMSA-FLX attempts to smooth out the oscillations by defining the\noptimization scope at each step as a sliding window, and ensuring that the\ncumulative rewards always include rewards from a fixed number of requests.\nEvaluations with the two sample topologies show that DeepRMSA-FLX can\neffectively stabilize the training while achieving blocking probability\nreductions of more than 20.3% and 14.3%, when compared with the baselines.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 19:51:24 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 18:58:41 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Chen", "Xiaoliang", ""], ["Li", "Baojia", ""], ["Proietti", "Roberto", ""], ["Lu", "Hongbo", ""], ["Zhu", "Zuqing", ""], ["Yoo", "S. J. Ben", ""]]}, {"id": "1905.02250", "submitter": "Salvatore D'Oro", "authors": "Salvatore D'Oro, Francesco Restuccia and Tommaso Melodia", "title": "Hiding Data in Plain Sight: Undetectable Wireless Communications Through\n  Pseudo-Noise Asymmetric Shift Keying", "comments": null, "journal-ref": "IEEE International Conference on Computer Communications\n  (INFOCOM'19) 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undetectable wireless transmissions are fundamental to avoid eavesdroppers.\nTo address this issue, wireless steganography hides covert information inside\nprimary information by slightly modifying the transmitted waveform such that\nprimary information will still be decodable, while covert information will be\nseen as noise by agnostic receivers. Since the addition of covert information\ninevitably decreases the SNR of the primary transmission, key challenges in\nwireless steganography are: i) to assess the impact of the covert channel on\nthe primary channel as a function of different channel conditions; and ii) to\nmake sure that the covert channel is undetectable. Existing approaches are\nprotocol-specific, also we notice that existing wireless technologies rely on\nphase-keying modulations that in most cases do not use the channel up to its\nShannon capacity. Therefore, the residual capacity can be leveraged to\nimplement a wireless system based on a pseudo-noise asymmetric shift keying\n(PN-ASK) modulation, where covert symbols are mapped by shifting the amplitude\nof primary symbols. This way, covert information will be undetectable, since a\nreceiver expecting phase-modulated symbols will see their shift in amplitude as\nan effect of channel/path loss degradation. We first investigate the SER of\nPN-ASK as a function of the channel; then, we find the optimal PN-ASK\nparameters that optimize primary and covert throughput under different channel\ncondition. We evaluate the throughput performance and undetectability of PN-ASK\nthrough extensive simulations and on an experimental testbed based on USRP N210\nsoftware-defined radios. We show that PN-ASK improves the throughput by more\nthan 8x with respect to prior art. Finally, we demonstrate through experiments\nthat PN-ASK is able to transmit covert data on top of IEEE 802.11g frames,\nwhich are correctly decoded by an off-the-shelf laptop WiFi.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 20:00:56 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["D'Oro", "Salvatore", ""], ["Restuccia", "Francesco", ""], ["Melodia", "Tommaso", ""]]}, {"id": "1905.02334", "submitter": "Nick Feamster", "authors": "Nick Feamster, Jason Livingood", "title": "Internet Speed Measurement: Current Challenges and Future\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Government organizations, regulators, consumers, Internet service providers,\nand application providers alike all have an interest in measuring user Internet\n\"speed\". Access speeds have increased by an order of magnitude in past years,\nwith gigabit speeds available to tens of millions of homes. Approaches must\nevolve to accurately reflect the changing user experience and network speeds.\nThis paper offers historical and technical background on current speed testing\nmethods, highlights their limitations as access network speeds continue to\nincrease, and offers recommendations for the next generation of Internet\n\"speed\" measurement.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 02:43:56 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 15:25:08 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 20:22:49 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Feamster", "Nick", ""], ["Livingood", "Jason", ""]]}, {"id": "1905.02337", "submitter": "Ekram Hossain", "authors": "Konpal Shaukat Ali, Mohamed-Slim Alouini, Ekram Hossain, and Md.\n  Jahangir Hossain", "title": "On Clustering and Channel Disparity in Non-Orthogonal Multiple Access\n  (NOMA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-orthogonal multiple access (NOMA) allows multiple users to share a\ntime-frequency resource block by using different power levels. An important\nchallenge associated with NOMA is the selection of users that share a resource\nblock. This is referred to as clustering, which generally exploits the channel\ndisparity (i.e. distinctness) among the users. We discuss clustering and the\nrelated resource allocation challenges (e.g. power allocation) associated with\nNOMA and highlight open problems that require further investigation. We review\nthe related literature on exploiting channel disparity for clustering and\nresource allocation. There have been several misconceptions regarding NOMA\nclustering including: 1) clustering users with low channel disparity is\ndetrimental, 2) similar power allocation is disastrous for NOMA. We clarify\nsuch misunderstandings with numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 03:06:34 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Ali", "Konpal Shaukat", ""], ["Alouini", "Mohamed-Slim", ""], ["Hossain", "Ekram", ""], ["Hossain", "Md. Jahangir", ""]]}, {"id": "1905.02386", "submitter": "Guoyao Feng", "authors": "Guoyao Feng, Srinivasan Seshan, Peter Steenkiste", "title": "PARI: A Probabilistic Approach to AS Relationships Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last two decades, several algorithms have been proposed to infer the\ntype of relationship between Autonomous Systems (ASes). While the recent works\nhave achieved increasingly higher accuracy, there has not been a systematic\nstudy on the uncertainty of AS relationship inference. In this paper, we\nanalyze the factors contributing to this uncertainty and introduce a new\nparadigm to explicitly model the uncertainty and reflect it in the inference\nresult. We also present PARI, an exemplary algorithm implementing this\nparadigm, that leverages a novel technique to capture the interdependence of\nrelationship inference across AS links.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 07:16:48 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Feng", "Guoyao", ""], ["Seshan", "Srinivasan", ""], ["Steenkiste", "Peter", ""]]}, {"id": "1905.02395", "submitter": "Sanket Partani", "authors": "Sanket Partani, Andreas Weinand, Hans D. Schotten", "title": "A Controller for Network-Assisted CACC based Platooning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Platooning involves a set of vehicles moving in a cooperative fashion at\nequal inter-vehicular distances. Taking advantage of wireless communication\ntechnology, this paper aims to show the impact of network protocols on a\nplatoon using a controller, based on the Cooperative Adaptive Cruise Control\n(CACC) principles. The network protocols used in this work are DSRC (Dedicated\nShort Range Communication) and LTE-V2V sidelink (Mode 4). The main focus of\nthis work is to showcase the ability of the controller to maintain platoon\nstability despite having uncertainties in both, the platoon and the message\ndelivery rates over the network protocols. The controller interacts with all\nvehicles using messages transmitted over the network protocols. The controller\nis designed to be responsible for micro-managing every vehicle in the platoon\nand to ensure that the platoon does not break under any circumstances. SUMO\n(Simulation of Urban MObility) is used as the simulation platform. Results\nindicate, that the controller manages to achieve platoon stability in all\nscenarios, unless a set number of consecutive messages are not transmitted, in\nwhich case it leads to collisions. This work also presents certain bottlenecks\npertaining to wireless communication with vehicles.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 08:06:39 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Partani", "Sanket", ""], ["Weinand", "Andreas", ""], ["Schotten", "Hans D.", ""]]}, {"id": "1905.02472", "submitter": "Ingo Van Duijn", "authors": "Chen Avin, Ingo van Duijn, Stefan Schmid", "title": "Self-Adjusting Linear Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging networked systems become increasingly flexible and reconfigurable.\nThis introduces an opportunity to adjust networked systems in a demand-aware\nmanner, leveraging spatial and temporal locality in the workload for online\noptimizations. However, it also introduces a trade-off: while more frequent\nadjustments can improve performance, they also entail higher reconfiguration\ncosts.\n  This paper initiates the formal study of linear networks which self-adjust to\nthe demand in an online manner, striking a balance between the benefits and\ncosts of reconfigurations. We show that the underlying algorithmic problem can\nbe seen as a distributed generalization of the classic dynamic list update\nproblem known from self-adjusting datastructures: in a network, requests can\noccur between node pairs. This distributed version turns out to be\nsignificantly harder than the classical problem in generalizes. Our main\nresults are a $\\Omega(\\log{n})$ lower bound on the competitive ratio, and a\n(distributed) online algorithm that is $O(\\log{n})$-competitive if the\ncommunication requests are issued according to a linear order.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 11:09:10 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Avin", "Chen", ""], ["van Duijn", "Ingo", ""], ["Schmid", "Stefan", ""]]}, {"id": "1905.02495", "submitter": "Christos Liaskos K.", "authors": "Christos Liaskos, Ageliki Tsioliaridou, Shuai Nie, Andreas\n  Pitsillides, Sotiris Ioannidis, Ian Akyildiz", "title": "An Interpretable Neural Network for Configuring Programmable Wireless\n  Environments", "comments": "In proceedings of IEEE SPAWC 2019 - Special Session on Signal\n  Processing Advances for Emerging Transceiver Hardware. This work was funded\n  by the European Union via the Horizon 2020: Future Emerging Topics call\n  (FETOPEN), grant EU736876, project VISORSURF (http://www.visorsurf.eu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined metasurfaces (SDMs) comprise a dense topology of basic\nelements called meta-atoms, exerting the highest degree of control over surface\ncurrents among intelligent panel technologies. As such, they can transform\nimpinging electromagnetic (EM) waves in complex ways, modifying their\ndirection, power, frequency spectrum, polarity and phase. A well-defined\nsoftware interface allows for applying such functionalities to waves and\ninter-networking SDMs, while abstracting the underlying physics. A network of\nSDMs deployed over objects within an area, such as a floorplan walls, creates\nprogrammable wireless environments (PWEs) with fully customizable propagation\nof waves within them. This work studies the use of machine learning for\nconfiguring such environments to the benefit of users within. The methodology\nconsists of modeling wireless propagation as a custom, interpretable,\nback-propagating neural network, with SDM elements as nodes and their\ncross-interactions as links. Following a training period the network learns the\npropagation basics of SDMs and configures them to facilitate the communication\nof users within their vicinity.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:19:14 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Liaskos", "Christos", ""], ["Tsioliaridou", "Ageliki", ""], ["Nie", "Shuai", ""], ["Pitsillides", "Andreas", ""], ["Ioannidis", "Sotiris", ""], ["Akyildiz", "Ian", ""]]}, {"id": "1905.02609", "submitter": "Luz Angela Aristiz\\'abal Quintero L.A.Aristizabal", "authors": "Luz Angela Aristizabal Q and Nicol\\'as Toro G", "title": "Reduction of Monitoring Register on Software Defined Networks", "comments": "8 pages, 5 figures", "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 11, No 2, April 2019", "doi": "10.5121/ijcsit", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterization of data network monitoring registers allows for reductions\nin the number of data, which is essential when the information flow is high,\nand implementation of processes with short response times, such as interchange\nof control information between devices and anomaly detection is required. The\npresent investigation applied wavelet transforms, so as to characterize the\nstatistic monitoring register of a software-defined network. Its main\ncontribution lies in the obtention of a record that, although reduced, retains\ndetailed, essential information for the correct application of anomaly\ndetectors.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 14:31:48 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Q", "Luz Angela Aristizabal", ""], ["G", "Nicol\u00e1s Toro", ""]]}, {"id": "1905.02805", "submitter": "David Wajc", "authors": "Bernhard Haeupler, David Wajc and Goran Zuzic", "title": "Network Coding Gaps for Completion Times of Multiple Unicasts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study network coding gaps for the problem of makespan minimization of\nmultiple unicasts. In this problem distinct packets at different nodes in a\nnetwork need to be delivered to a destination specific to each packet, as fast\nas possible. The network coding gap specifies how much coding packets together\nin a network can help compared to the more natural approach of routing.\n  While makespan minimization using routing has been intensely studied for the\nmultiple unicasts problem, no bounds on network coding gaps for this problem\nare known. We develop new techniques which allow us to upper bound the network\ncoding gap for the makespan of $k$ unicasts, proving this gap is at most\npolylogarithmic in $k$. Complementing this result, we show there exist\ninstances of $k$ unicasts for which this coding gap is polylogarithmic in $k$.\nOur results also hold for average completion time, and more generally any\n$\\ell_p$ norm of completion times.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 20:58:29 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 20:41:10 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 00:49:00 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Haeupler", "Bernhard", ""], ["Wajc", "David", ""], ["Zuzic", "Goran", ""]]}, {"id": "1905.02870", "submitter": "Alejandro Cohen", "authors": "Alejandro Cohen and Derya Malak and Vered Bar Bracha and Muriel Medard", "title": "Adaptive Causal Network Coding with Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adaptive and causal random linear network coding (AC-RLNC)\nalgorithm with forward error correction (FEC) for a point-to-point\ncommunication channel with delayed feedback. AC-RLNC is adaptive to the channel\ncondition, that the algorithm estimates, and is causal, as coding depends on\nthe particular erasure realizations, as reflected in the feedback\nacknowledgments. Specifically, the proposed model can learn the erasure pattern\nof the channel via feedback acknowledgments, and adaptively adjust its\nretransmission rates using a priori and posteriori algorithms. By those\nadjustments, AC-RLNC achieves the desired delay and throughput, and enables\ntransmission with zero error probability. We upper bound the throughput and the\nmean and maximum in order delivery delay of AC-RLNC, and prove that for the\npoint to point communication channel in the non-asymptotic regime the proposed\ncode may achieve more than 90% of the channel capacity. To upper bound the\nthroughput we utilize the minimum Bhattacharyya distance for the AC-RLNC code.\nWe validate those results via simulations. We contrast the performance of\nAC-RLNC with the one of selective repeat (SR)-ARQ, which is causal but not\nadaptive, and is a posteriori. Via a study on experimentally obtained\ncommercial traces, we demonstrate that a protocol based on AC-RLNC can,\nvis-`a-vis SR-ARQ, double the throughput gains, and triple the gain in terms of\nmean in order delivery delay when the channel is bursty. Furthermore, the\ndifference between the maximum and mean in order delivery delay is much smaller\nthan that of SR-ARQ. Closing the delay gap along with boosting the throughput\nis very promising for enabling ultra-reliable low-latency communications\n(URLLC) applications.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 02:12:50 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 02:11:55 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Cohen", "Alejandro", ""], ["Malak", "Derya", ""], ["Bracha", "Vered Bar", ""], ["Medard", "Muriel", ""]]}, {"id": "1905.02993", "submitter": "Mohamed A. Abd-Elmagid", "authors": "Mohamed A. Abd-Elmagid, Aidin Ferdowsi, Harpreet S. Dhillon, Walid\n  Saad", "title": "Deep Reinforcement Learning for Minimizing Age-of-Information in\n  UAV-assisted Networks", "comments": "This paper will be presented in IEEE Globecom, Waikoloa, HI, Dec.\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are expected to be a key component of the\nnext-generation wireless systems. Due to their deployment flexibility, UAVs are\nbeing considered as an efficient solution for collecting information data from\nground nodes and transmitting it wirelessly to the network. In this paper, a\nUAV-assisted wireless network is studied, in which energy-constrained ground\nnodes are deployed to observe different physical processes. In this network, a\nUAV that has a time constraint for its operation due to its limited battery,\nmoves towards the ground nodes to receive status update packets about their\nobserved processes. The flight trajectory of the UAV and scheduling of status\nupdate packets are jointly optimized with the objective of achieving the\nminimum weighted sum for the age-of-information (AoI) values of different\nprocesses at the UAV, referred to as weighted sum-AoI. The problem is modeled\nas a finite-horizon Markov decision process (MDP) with finite state and action\nspaces. Since the state space is extremely large, a deep reinforcement learning\n(RL) algorithm is proposed to obtain the optimal policy that minimizes the\nweighted sum-AoI, referred to as the age-optimal policy. Several simulation\nscenarios are considered to showcase the convergence of the proposed deep RL\nalgorithm. Moreover, the results also demonstrate that the proposed deep RL\napproach can significantly improve the achievable sum-AoI per process compared\nto the baseline policies, such as the distance-based and random walk policies.\nThe impact of various system design parameters on the optimal achievable\nsum-AoI per process is also shown through extensive simulations.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 10:14:37 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 02:57:59 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Abd-Elmagid", "Mohamed A.", ""], ["Ferdowsi", "Aidin", ""], ["Dhillon", "Harpreet S.", ""], ["Saad", "Walid", ""]]}, {"id": "1905.03086", "submitter": "Shadrokh Samavi", "authors": "Shadrokh Samavi, Pejman Khadivi", "title": "Fault-Tolerant Routing in Hypercube Networks by Avoiding Faulty Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next to the high performance, the essential feature of the multiprocessor\nsystems is their fault-tolerant capability. In this regard, fault-tolerant\ninterconnection networks and especially fault-tolerant routing methods are\ncrucial parts of these systems. Hypercube is a popular interconnection network\nthat is used in many multiprocessors. There are several suggested practices for\nfault tolerant routing in these systems. In this paper, a neural routing method\nis introduced which is named as Fault Avoidance Routing (FAR). This method\nkeeps the message as far from the faulty nodes as possible. The proposed method\nemploys the Hopfield neural network. In comparison with other neural routing\nmethods, FAR requires a small number of neurons. The simulation results show\nthat FAR has excellent performance in larger interconnection networks and\nnetworks with a high density of faulty nodes.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 07:30:54 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Samavi", "Shadrokh", ""], ["Khadivi", "Pejman", ""]]}, {"id": "1905.03089", "submitter": "Mariem Hmila", "authors": "Mariem Hmila, Manuel Fern\\'andez-Veiga, Miguel Rodr\\'iguez-P\\'erez,\n  Sergio Herrer\\'ia-Alonso", "title": "Energy Efficient Power and Channel Allocation in Underlay Device to\n  Multi Device Communications", "comments": null, "journal-ref": "IEEE Transactions Communications, Vol. 67, No. 8, August 2019", "doi": "10.1109/TCOMM.2019.2915227", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we optimize the energy efficiency (bits/s/Hz/J) of\ndevice-to-multi-device (D2MD) wireless communications. While the\ndevice-to-device scenario has been extensively studied to improve the spectral\nefficiency in cellular networks, the use of multicast communications opens the\npossibility of reusing the spectrum resources also inside the groups. The\noptimization problem is formulated as a mixed integer non-linear joint\noptimization for the power control and allocation of resource blocks (RBs) to\neach group. Our model explicitly considers resource sharing by letting\nco-channel transmission over a RB (up to a maximum of r transmitters) and/or\ntransmission through s different channels in each group. We use an iterative\ndecomposition approach, using first matching theory to find a stable even if\nsub-optimal channel allocation, to then optimize the transmission power vectors\nin each group via fractional programming. Additionally, within this framework,\nboth the network energy efficiency and the max-min individual energy efficiency\nare investigated. We characterize numerically the energy-efficient capacity\nregion, and our results show that the normalized energy efficiency is nearly\noptimal (above 90 percent of the network capacity) for a wide range of\nminimum-rate constraints. This performance is better than that of other\nmatching-based techniques previously proposed.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 14:25:23 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Hmila", "Mariem", ""], ["Fern\u00e1ndez-Veiga", "Manuel", ""], ["Rodr\u00edguez-P\u00e9rez", "Miguel", ""], ["Herrer\u00eda-Alonso", "Sergio", ""]]}, {"id": "1905.03093", "submitter": "Mohammad Riyaz Belgaum", "authors": "Mohammad Riyaz Belgaum, Safeeullah Soomro, Zainab Alansari and\n  Muhammad Alam", "title": "Cloud Service ranking using Checkpoint based Load balancing in real time\n  scheduling of Cloud Computing", "comments": null, "journal-ref": null, "doi": "10.1007/978-981-10-6872-0_64", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has been gaining popularity in the recent years. Several\nstudies are being proceeded to build cloud applications with exquisite quality\nbased on users demands. In achieving the same, one of the applied criteria is\ncheckpoint based load balancing in real time scheduling through which suitable\ncloud service is chosen from a group of cloud services candidates. Valuable\ninformation can be collected to rank the services within this checkpoint based\nload balancing. In order to attain ranking, different services are needed to be\ninvoked in the cloud, which is time consuming and wastage of services\ninvocation. To avoid the same, this chapter proposes an algorithm for\npredicting the ranks of different cloud services by using the values from\npreviously offered services.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 09:18:53 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Belgaum", "Mohammad Riyaz", ""], ["Soomro", "Safeeullah", ""], ["Alansari", "Zainab", ""], ["Alam", "Muhammad", ""]]}, {"id": "1905.03094", "submitter": "Mohammad Riyaz Belgaum", "authors": "Mohammad Riyaz Belgaum, Safeeullah Soomro, Zainab Alansari,\n  Shahrulniza Musa, Muhammad Alam, Mazliham Mohd Su'ud", "title": "Load Balancing with preemptive and non-preemptive task scheduling in\n  Cloud Computing", "comments": null, "journal-ref": null, "doi": "10.1109/ICETSS.2017.8324145", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Cloud computing environment the resources are managed dynamically based on\nthe need and demand for resources for a particular task. With a lot of\nchallenges to be addressed our concern is Load balancing where load balancing\nis done for optimal usage of resources and reduces the cost associated with it\nas we use pay-as-you-go policy. The task scheduling is done by the cloud\nservice provider using preemption and non-preemption based on the requirements\nin a virtualized scenario which has been focused here. In this paper, various\ntask scheduling algorithms are studied to present the dynamic allocation of\nresources under each category and the ways each of this scheduling algorithm\nadapts to handle the load and have high-performance computing\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 08:48:46 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Belgaum", "Mohammad Riyaz", ""], ["Soomro", "Safeeullah", ""], ["Alansari", "Zainab", ""], ["Musa", "Shahrulniza", ""], ["Alam", "Muhammad", ""], ["Su'ud", "Mazliham Mohd", ""]]}, {"id": "1905.03095", "submitter": "Bob Briscoe", "authors": "Bob Briscoe", "title": "Managing a Queue to a Soft Delay Target", "comments": "bobbriscoe.net Technical Report", "journal-ref": null, "doi": null, "report-no": "TR-BB-2017-003", "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This memo proposes to transplant the core idea of Curvy RED, the softened\ndelay target, into AQMs that are better designed to deal with dynamics, such as\nPIE or PI2, but that suffer from the weakness of a fixed delay target.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 14:53:36 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Briscoe", "Bob", ""]]}, {"id": "1905.03096", "submitter": "Tamara Radivilova A", "authors": "Vitalii Bulakh and Lyudmyla Kirichenko and Tamara Radivilova", "title": "Time series classification based on fractal properties", "comments": "4 pages, 2 figures, 3 equations, 1 table", "journal-ref": "2018 IEEE Second International Conference on Data Stream Mining &\n  Processing (DSMP)", "doi": "10.1109/DSMP.2018.8478532", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article considers classification task of fractal time series by the meta\nalgorithms based on decision trees. Binomial multiplicative stochastic cascades\nare used as input time series. Comparative analysis of the classification\napproaches based on different features is carried out. The results indicate the\nadvantage of the machine learning methods over the traditional estimating the\ndegree of self-similarity.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 11:47:33 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Bulakh", "Vitalii", ""], ["Kirichenko", "Lyudmyla", ""], ["Radivilova", "Tamara", ""]]}, {"id": "1905.03113", "submitter": "Yongquan Fu", "authors": "Yongquan Fu, Dongsheng Li, Siqi Shen, Yiming Zhang, Kai Chen", "title": "Locality-Sensitive Sketching for Resilient Network Flow Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network monitoring is vital in modern clouds and data center networks for\ntraffic engineering, network diagnosis, network intrusion detection, which need\ndiverse traffic statistics ranging from flow size distributions to heavy\nhitters. To cope with increasing network rates and massive traffic volumes,\nsketch based approximate measurement has been extensively studied to trade the\naccuracy for memory and computation cost, which unfortunately, is sensitive to\nhash collisions. In addition, deploying the sketch involves fine-grained\nperformance control and instrumentation.\n  This paper presents a locality-sensitive sketch (LSS) to be resilient to hash\ncollisions. LSS proactively minimizes the estimation error due to hash\ncollisions with an autoencoder based optimization model, and reduces the\nestimation variance by keeping similar network flows to the same bucket array.\nTo illustrate the feasibility of the sketch, we develop a disaggregated\nmonitoring application that supports non-intrusive sketching deployment and\nnative network-wide analysis. Testbed shows that the framework adapts to line\nrates and provides accurate query results. Real-world trace-driven simulations\nshow that LSS remains stable performance under wide ranges of parameters and\ndramatically outperforms state-of-the-art sketching structures, with over\n$10^3$ to $10^5$ times reduction in relative errors for per-flow queries as the\nratio of the number of buckets to the number of network flows reduces from 10\\%\nto 0.1\\%.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 14:47:04 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Fu", "Yongquan", ""], ["Li", "Dongsheng", ""], ["Shen", "Siqi", ""], ["Zhang", "Yiming", ""], ["Chen", "Kai", ""]]}, {"id": "1905.03144", "submitter": "Jan R\\\"uth", "authors": "Jan R\\\"uth, Konrad Wolsing, Martin Serror, Klaus Wehrle, Oliver\n  Hohlfeld", "title": "Blitz-starting QUIC Connections", "comments": "Technical Report, RWTH Aachen University, Chair of Communication and\n  Distributed Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we revisit the idea to remove Slow Start from congestion\ncontrol. To do so, we build upon the newly gained freedom of transport protocol\nextendability offered by QUIC to hint bandwidth estimates from a typical web\nclient to a server. Using this bandwidth estimate, we bootstrap congestion\nwindows of new connections to quickly utilize available bandwidth. This custom\nflow initialization removes the common early exit of Slow Start and thus fuels\nshort flow fairness with long-running connections. Our results indicate that we\ncan drastically reduce flow completion time accepting some losses and thereby\nan inflated transmission volume. For example, for a typical DSL client, loading\na 2 MB YouTube video chunk is accelerated by nearly 2x. In the worst case, we\nfind an inflation of the transfer volume by 12% due to losses.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:17:59 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["R\u00fcth", "Jan", ""], ["Wolsing", "Konrad", ""], ["Serror", "Martin", ""], ["Wehrle", "Klaus", ""], ["Hohlfeld", "Oliver", ""]]}, {"id": "1905.03193", "submitter": "Reza Parizi", "authors": "Abbas Yazdinejad, Reza M. Parizi, Ali Dehghantanha, Kim-Kwang Raymond\n  Choo", "title": "Blockchain-enabled Authentication Handover with Efficient Privacy\n  Protection in SDN-based 5G Networks", "comments": "Submitted to IEEE Transactions on Network Science and Engineering", "journal-ref": "IEEE Transactions on Network Science and Engineering, 2019", "doi": "10.1109/TNSE.2019.2937481", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G mobile networks provide additional benefits in terms of lower latency,\nhigher data rates, and more coverage, in comparison to 4G networks, and they\nare also coming close to standardization. For example, 5G has a new level of\ndata transfer and processing speed that assures users are not disconnected when\nthey move from one cell to another; thus, supporting faster connection.\nHowever, it comes with its own technical challenges relating to resource\nmanagement, authentication handover and user privacy protection. In 5G, the\nfrequent displacement of the users among the cells as a result of repeated\nauthentication handovers often lead to a delay, contradicting the 5G\nobjectives. In this paper, we propose a new authentication approach that\nutilizes blockchain and software defined networking (SDN) techniques to remove\nthe re-authentication in repeated handover among heterogeneous cells. The\nproposed approach is designed to assure the low delay, appropriate for the 5G\nnetwork in which users can be replaced with the least delay among heterogeneous\ncells using their public and private keys provided by the devised blockchain\ncomponent while protecting their privacy. In our comparison between\nProof-of-Work (POW)-based and network-based models, the delay of our\nauthentication handover was shown to be less than 1ms. Also, our approach\ndemonstrated less signaling overhead and energy consumption compared to peer\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 16:22:37 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Yazdinejad", "Abbas", ""], ["Parizi", "Reza M.", ""], ["Dehghantanha", "Ali", ""], ["Choo", "Kim-Kwang Raymond", ""]]}, {"id": "1905.03238", "submitter": "Ahmed Arafa", "authors": "Ahmed Arafa and Karim Banawan and Karim G. Seddik and H. Vincent Poor", "title": "On Timely Channel Coding with Hybrid ARQ", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A status updating communication system is examined, in which a transmitter\ncommunicates with a receiver over a noisy channel. The goal is to realize\ntimely delivery of fresh data over time, which is assessed by an\nage-of-information (AoI) metric. Channel coding is used to combat the channel\nerrors, and feedback is sent to acknowledge updates' reception. In case\ndecoding is unsuccessful, a hybrid ARQ protocol is employed, in which\nincremental redundancy (IR) bits are transmitted to enhance the decoding\nability. This continues for some amount of time in case decoding remains\nunsuccessful, after which a new (fresh) status update is transmitted instead.\nIn case decoding is successful, the transmitter has the option to idly wait for\na certain amount of time before sending a new update. A general problem is\nformulated that optimizes the codeword and IR lengths for each update, and the\nwaiting times, such that the long term average AoI is minimized. Stationary\ndeterministic policies are investigated, in which the codeword and IR lengths\nare fixed for each update, and the waiting time is a deterministic function of\nthe AoI. The optimal waiting policy is then derived, and is shown to have a\nthreshold structure, in which the transmitter sends a new update only if the\nAoI grows above a certain threshold that is a function of the codeword and IR\nlengths. Choosing the codeword and IR lengths is discussed in the context of\nbinary symmetric channels.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 17:51:10 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Arafa", "Ahmed", ""], ["Banawan", "Karim", ""], ["Seddik", "Karim G.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1905.03429", "submitter": "Prateesh Goyal", "authors": "Prateesh Goyal, Anup Agarwal, Ravi Netravali, Mohammad Alizadeh, Hari\n  Balakrishnan", "title": "ABC: A Simple Explicit Congestion Controller for Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Accel-Brake Control (ABC), a simple and deployable explicit\ncongestion control protocol for network paths with time-varying wireless links.\nABC routers mark each packet with an \"accelerate\" or \"brake\", which causes\nsenders to slightly increase or decrease their congestion windows. Routers use\nthis feedback to quickly guide senders towards a desired target rate. ABC\nrequires no changes to header formats or user devices, but achieves better\nperformance than XCP. ABC is also incrementally deployable; it operates\ncorrectly when the bottleneck is a non-ABC router, and can coexist with non-ABC\ntraffic sharing the same bottleneck link. We evaluate ABC using a Wi-Fi\nimplementation and trace-driven emulation of cellular links. ABC achieves\n30-40% higher throughput than Cubic+Codel for similar delays, and 2.2X lower\ndelays than BBR on a Wi-Fi path. On cellular network paths, ABC achieves 50%\nhigher throughput than Cubic+Codel.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 03:36:25 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 19:46:17 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 21:43:51 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 00:19:43 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Goyal", "Prateesh", ""], ["Agarwal", "Anup", ""], ["Netravali", "Ravi", ""], ["Alizadeh", "Mohammad", ""], ["Balakrishnan", "Hari", ""]]}, {"id": "1905.03440", "submitter": "Yong Zeng", "authors": "Yong Zeng and Xiaoli Xu", "title": "Path Design for Cellular-Connected UAV with Reinforcement Learning", "comments": "submitted for conference publications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the path design problem for cellular-connected unmanned\naerial vehicle (UAV), which aims to minimize its mission completion time while\nmaintaining good connectivity with the cellular network. We first argue that\nthe conventional path design approach via formulating and solving optimization\nproblems faces several practical challenges, and then propose a new\nreinforcement learning-based UAV path design algorithm by applying\n\\emph{temporal-difference} method to directly learn the \\emph{state-value\nfunction} of the corresponding Markov Decision Process. The proposed algorithm\nis further extended by using linear function approximation with tile coding to\ndeal with large state space. The proposed algorithms only require the raw\nmeasured or simulation-generated signal strength as the input and are suitable\nfor both online and offline implementations. Numerical results show that the\nproposed path designs can successfully avoid the coverage holes of cellular\nnetworks even in the complex urban environment.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 04:48:11 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Zeng", "Yong", ""], ["Xu", "Xiaoli", ""]]}, {"id": "1905.03494", "submitter": "Yuedong Xu", "authors": "Xinyu You, Xuanjie Li, Yuedong Xu, Hui Feng, Jin Zhao, Huaicheng Yan", "title": "Toward Packet Routing with Fully-distributed Multi-agent Deep\n  Reinforcement Learning", "comments": "12 pages, 10 figures", "journal-ref": "RAWNET workshop collocated with WiOpt 2019 Conference", "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packet routing is one of the fundamental problems in computer networks in\nwhich a router determines the next-hop of each packet in the queue to get it as\nquickly as possible to its destination. Reinforcement learning (RL) has been\nintroduced to design autonomous packet routing policies with local information\nof stochastic packet arrival and service. However, the curse of dimensionality\nof RL prohibits the more comprehensive representation of dynamic network\nstates, thus limiting its potential benefit. In this paper, we propose a novel\npacket routing framework based on \\emph{multi-agent} deep reinforcement\nlearning (DRL) in which each router possess an \\emph{independent} LSTM\nrecurrent neural network for training and decision making in a \\emph{fully\ndistributed} environment. The LSTM recurrent neural network extracts routing\nfeatures from rich information regarding backlogged packets and past actions,\nand effectively approximates the value function of Q-learning. We further allow\neach route to communicate periodically with direct neighbors so that a broader\nview of network state can be incorporated. Experimental results manifest that\nour multi-agent DRL policy can strike the delicate balance between\ncongestion-aware and shortest routes, and significantly reduce the packet\ndelivery time in general network topologies compared with its counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 09:01:27 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 14:35:43 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["You", "Xinyu", ""], ["Li", "Xuanjie", ""], ["Xu", "Yuedong", ""], ["Feng", "Hui", ""], ["Zhao", "Jin", ""], ["Yan", "Huaicheng", ""]]}, {"id": "1905.03507", "submitter": "Salam Hamdan Mrs", "authors": "Salam Hamdan, Amjad Hudaib, Arafat Awajan", "title": "Detecting Sybil Attacks in Vehicular Ad Hoc Networks", "comments": null, "journal-ref": null, "doi": "10.1080/17445760.2019.1617865", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ad hoc networks is vulnerable to numerous number of attacks due to its\ninfrastructure-less nature, one of these attacks is the Sybil attack. Sybil\nattack is a severe attack on vehicular ad hoc networks (VANET) in which the\nintruder maliciously claims or steals multiple identities and use these\nidentities to disturb the functionality of the VANET network by disseminating\nfalse identities. Many solutions have been proposed in order to defense the\nVANET network against the Sybil attack. In this research a hybrid algorithm is\nproposed, by combining footprint and privacy-preserving detection of abuses of\npseudonyms (P2DAP) methods. The hybrid detection algorithm is implemented using\nthe ns2 simulator. The proposed algorithm is working as follows, P2DAP acting\nbetter than footprint when the number of vehicles increases. On the other hand,\nthe footprint algorithm acting better when the speed of vehicles increases. The\nhybrid algorithm depends on encryption, authentication and on the trajectory of\nthe vehicle. The scenarios will be generated using SUMO and MOVE tools.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 09:50:11 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hamdan", "Salam", ""], ["Hudaib", "Amjad", ""], ["Awajan", "Arafat", ""]]}, {"id": "1905.03519", "submitter": "Mbazingwa Elirehema Mkiramweni", "authors": "Liying Li, Chungang Yang, Mbazingwa E. Mkiramweni, and Lei Pang", "title": "Intelligent Scheduling and Power Control for Multimedia Transmission in\n  5G CoMP Systems: A Dynamic Bargaining Game", "comments": "11 pages, 14 figures, This paper is accepted for publication in the\n  IEEE Journal on Selected Areas in Communications (JSAC) Special Issue on\n  \"Multimedia Economics for Future Networks: Theory Methods , and Application\"\n  on 21 April 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent terminals support a large number of multimedia, such as picture,\naudio, video, and so on. The coexistence of various multimedia makes it\nnecessary to provide service for different requests. In this work, we consider\ninterference-aware coordinated multi-point (CoMP) to mitigate inter-cell\ninterference and improve total throughput in the fifth-generation (5G) mobile\nnetworks. To select the scheduled edge users, cluster the cooperative base\nstations (BSs), and determine the transmitting power, a novel dynamic\nbargaining approach is proposed. Based on affinity propagation, we first select\nthe users to be scheduled and the cooperative BSs serving them respectively.\nThen, based on the Nash bargaining solution (NBS), we develop a power control\nscheme considering the transmission delay, which guarantees a generalized\nproportional fairness among users. Simulation results demonstrate the\nsuperiority of the user-centric scheduling and power control methods in 5G CoMP\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 10:29:40 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Li", "Liying", ""], ["Yang", "Chungang", ""], ["Mkiramweni", "Mbazingwa E.", ""], ["Pang", "Lei", ""]]}, {"id": "1905.03585", "submitter": "Tamara Radivilova A", "authors": "Igor Ivanisenko and Lyudmyla Kirichenko and Tamara Radivilova", "title": "Investigation of Multifractal Properties of Additive Data Stream", "comments": "4 pages, 5 figures, 7 equations. arXiv admin note: text overlap with\n  arXiv:1904.05925", "journal-ref": "2016 IEEE First International Conference on Data Stream Mining &\n  Processing (DSMP), Lviv, 2016, pp. 305-308", "doi": "10.1109/DSMP.2016.7583564", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work presents results of a numerical study of fractal characteristics of\nmultifractal stream at addition of stream, which does not have multifractal\nproperties. They showed that the generalized Hurst exponent of total stream\ntends to one of original multifractal stream with increase in signal/noise\nratio.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 11:32:42 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Ivanisenko", "Igor", ""], ["Kirichenko", "Lyudmyla", ""], ["Radivilova", "Tamara", ""]]}, {"id": "1905.03587", "submitter": "Tamara Radivilova A", "authors": "Igor Ivanisenko and Tamara Radivilova", "title": "The multifractal load balancing method", "comments": "2 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:1904.09227", "journal-ref": "2015 Second International Scientific-Practical Conference Problems\n  of Infocommunications Science and Technology (PIC S&T)", "doi": "10.1109/INFOCOMMST.2015.7357289", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The load-balancing system, built on the basis of a subsystem load balancer\nand subsystem control and monitoring that closely interact with each other was\npropose in work. This system is presented as a queuing system with priority\nservice discipline. In the described queuing system parallel processing flow\napplications occur in the multiple serving devices and successive junction of\nthem into unified stream is done. The method of multifractal load balancing is\nsubmited on the basis of the developed system of load balancing.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 12:04:11 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Ivanisenko", "Igor", ""], ["Radivilova", "Tamara", ""]]}, {"id": "1905.03851", "submitter": "Francesco Fraternali", "authors": "Francesco Fraternali, Bharathan Balaji, Yuvraj Agarwal, Luca Benini,\n  Rajesh Gupta", "title": "Demo Abstract: Pible: Battery-Free Mote for Perpetual Indoor BLE\n  Applications", "comments": "arXiv admin note: text overlap with arXiv:1812.04717", "journal-ref": "BuildSys 2018 Proceedings of the 5th Conference on Systems for\n  Built Environments", "doi": "10.1145/3276774.3282823", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As of today, large-scale wireless sensor networks are adopted for smart\nbuilding applications as they are easy and flexible to deploy. Low-power\nwireless nodes can achieve multi-year lifetimes with an AA battery using\nBluetooth Low Energy (BLE) and Zig-Bee. However, replacing these batteries at\nscale is a non-trivial, labor-intensive task. Energy harvesting has emerged as\na potential solution to avoid battery replacement but requires compromises such\nas application specific sensor node design, simplified communication protocol\nor reduced quality of service. We show the design of a battery-free sensor node\nusing commercial off the shelf components, and present Pible: a Perpetual\nIndoor BLE sensor node that uses an ambient light energy harvesting system and\ncan support numerous smart building applications. We show trade-offs between\nnode-lifetime, quality of service and light availability and present a\npredictive algorithm that adapts to changing lighting conditions to maximize\nnode lifetime and application quality of service.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 20:50:45 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Fraternali", "Francesco", ""], ["Balaji", "Bharathan", ""], ["Agarwal", "Yuvraj", ""], ["Benini", "Luca", ""], ["Gupta", "Rajesh", ""]]}, {"id": "1905.03873", "submitter": "Danish Sattar", "authors": "Danish Sattar and Ashraf Matrawy", "title": "DSAF: Dynamic Slice Allocation Framework for 5G Core Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing is a key to supporting different quality-of-service\nrequirements for users and application in the 5G network. However, allocating\nnetwork slices efficiently while providing a minimum guaranteed level of\nservice in a mobile core is challenging. To address this question, in our\nprevious work we proposed an optimization model to allocate slices. It provided\na static and manual allocation of slices. In this paper, we extend our work to\ndynamically allocated slices. We propose a dynamic slice allocation framework\nfor the 5G core network. The proposed framework provides user-interaction to\nrequest slices and any required services that need to run on a slice(s). It can\naccept a single or multiple allocation requests, and it dynamically allocates\nthem. Additionally, the framework allocates slices in a balanced fashion across\navailable resources. We compare our framework with the First Come First Serve\nand First Available allocation scheme.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 22:05:43 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Sattar", "Danish", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "1905.03883", "submitter": "Juuso Haavisto", "authors": "Juuso Haavisto, Muhammad Arif, Lauri Lov\\'en, Teemu Lepp\\\"anen and\n  Jukka Riekki", "title": "Open-source RANs in practice: an over-the-air deployment for 5G MEC", "comments": null, "journal-ref": null, "doi": "10.1109/EuCNC.2019.8801973", "report-no": null, "categories": "cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing that leverages cloud resources to the proximity of user\ndevices is seen as the future infrastructure for distributed applications.\nHowever, developing and deploying edge applications, that rely on cellular\nnetworks, is burdensome. Such network infrastructures are often based on\nproprietary components, each with unique programming abstractions and\ninterfaces. To facilitate straightforward deployment of edge applications, we\nintroduce OSS based RAN on OTA commercial spectrum with DevOps capabilities.\nOSS allows software modifications and integrations of the system components,\ne.g., EPC and edge hosts running applications, required for new data pipelines\nand optimizations not addressed in standardization. Such an OSS infrastructure\nenables further research and prototyping of novel end-user applications in an\nenvironment familiar to software engineers without telecommunications\nbackground. We evaluated the presented infrastructure with E2E OTA testing,\nresulting in 7.5MB/s throughput and latency of 21ms, which shows that the\npresented infrastructure provides low latency for edge applications.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 22:54:38 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Haavisto", "Juuso", ""], ["Arif", "Muhammad", ""], ["Lov\u00e9n", "Lauri", ""], ["Lepp\u00e4nen", "Teemu", ""], ["Riekki", "Jukka", ""]]}, {"id": "1905.03929", "submitter": "Yuxiu Hua", "authors": "Yuxiu Hua, Rongpeng Li, Zhifeng Zhao, Xianfu Chen, Honggang Zhang", "title": "GAN-powered Deep Distributional Reinforcement Learning for Resource\n  Management in Network Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Network slicing is a key technology in 5G communications system. Its purpose\nis to dynamically and efficiently allocate resources for diversified services\nwith distinct requirements over a common underlying physical infrastructure.\nTherein, demand-aware resource allocation is of significant importance to\nnetwork slicing. In this paper, we consider a scenario that contains several\nslices in a radio access network with base stations that share the same\nphysical resources (e.g., bandwidth or slots). We leverage deep reinforcement\nlearning (DRL) to solve this problem by considering the varying service demands\nas the environment state and the allocated resources as the environment action.\nIn order to reduce the effects of the annoying randomness and noise embedded in\nthe received service level agreement (SLA) satisfaction ratio (SSR) and\nspectrum efficiency (SE), we primarily propose generative adversarial\nnetwork-powered deep distributional Q network (GAN-DDQN) to learn the\naction-value distribution driven by minimizing the discrepancy between the\nestimated action-value distribution and the target action-value distribution.\nWe put forward a reward-clipping mechanism to stabilize GAN-DDQN training\nagainst the effects of widely-spanning utility values. Moreover, we further\ndevelop Dueling GAN-DDQN, which uses a specially designed dueling generator, to\nlearn the action-value distribution by estimating the state-value distribution\nand the action advantage function. Finally, we verify the performance of the\nproposed GAN-DDQN and Dueling GAN-DDQN algorithms through extensive\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 04:10:43 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 01:58:34 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 14:51:31 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Hua", "Yuxiu", ""], ["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Chen", "Xianfu", ""], ["Zhang", "Honggang", ""]]}, {"id": "1905.03932", "submitter": "Arnav Dhamija", "authors": "Arnav Dhamija", "title": "Disruption Tolerant Networks for Underwater Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disruption Tolerant Networks (DTNs) are employed in applications where the\nnetwork is likely to be disrupted due to environmental conditions or where the\nnetwork topology makes it impossible to find a direct route from the sender to\nthe receiver. Underwater networks typically use acoustic waves for transmitting\ndata. However, these waves are susceptible to interference from sources of\nnoise such as the wake from ships, sounds from snapping shrimp, and collisions\nfrom acoustic waves generated by other nodes.\n  DTNs are good candidates for situations where successfully delivering the\nmessage is more important than low delivery times and high network throughput.\nThis is true for certain applications of underwater networks. DTNs can also\ncreate new options for network topologies, such as opening up the possibility\nof using data muling nodes if the network is resilient to delays.\n  The Acoustic Research Laboratory (ARL) at NUS has developed their own\nGroovy-based underwater network simulator called UnetStack, in which network\nprotocols can be designed and tested in a simulator. These protocols can later\nbe directly deployed on physical hardware, such as Subnero's underwater modems.\nHence, this project revolves around creating a new UnetStack protocol called\nDtnLink for enabling disruption tolerant networking in various use cases of the\nARL.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 04:39:47 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Dhamija", "Arnav", ""]]}, {"id": "1905.03945", "submitter": "Zehua Guo", "authors": "Zehua Guo, Wendi Feng, Sen Liu, Wenchao Jiang, Yang Xu, Zhi-Li Zhang", "title": "RetroFlow: Maintaining Control Resiliency and Flow Programmability for\n  Software-Defined WANs", "comments": "Accepted by IEEE/ACM International Symposium on Quality of Service\n  (IWQoS '19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing resilient network control is a critical concern for deploying\nSoftware-Defined Networking (SDN) into Wide-Area Networks (WANs). For\nperformance reasons, a Software-Defined WAN is divided into multiple domains\ncontrolled by multiple controllers with a logically centralized view. Under\ncontroller failures, we need to remap the control of offline switches from\nfailed controllers to other active controllers. Existing solutions could either\noverload active controllers to interrupt their normal operations or degrade\nnetwork performance because of increasing the controller-switch communication\noverhead. In this paper, we propose RetroFlow to achieve low communication\noverhead without interrupting the normal processing of active controllers\nduring controller failures. By intelligently configuring a set of selected\noffline switches working under the legacy routing mode, RetroFlow relieves the\nactive controllers from controlling the selected offline switches while\nmaintaining the flow programmability (e.g., the ability to change paths of\nflows) of SDN. RetroFlow also smartly transfers the control of offline switches\nwith the SDN routing mode to active controllers to minimize the communication\noverhead from these offline switches to the active controllers. Simulation\nresults show that compared with the baseline algorithm, RetroFlow can reduce\nthe communication overhead up to 52.6% during a moderate controller failure by\nrecovering 100% flows from offline switches and can reduce the communication\noverhead up to 61.2% during a serious controller failure by setting to recover\n90% of flows from offline switches.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 05:24:32 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Guo", "Zehua", ""], ["Feng", "Wendi", ""], ["Liu", "Sen", ""], ["Jiang", "Wenchao", ""], ["Xu", "Yang", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "1905.03949", "submitter": "Dong Ma", "authors": "Dong Ma, Guohao Lan, Mahbub Hassan, Wen Hu, and Sajal K. Das", "title": "Sensing, Computing, and Communication for Energy Harvesting IoTs: A\n  Survey", "comments": "Accpeted for publication in IEEE Communications Surveys & Tutorials\n  (2019)", "journal-ref": null, "doi": "10.1109/COMST.2019.2962526", "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing number of deployments of Internet of Things (IoT)\ninfrastructure for a wide variety of applications, the battery maintenance has\nbecome a major limitation for the sustainability of such infrastructure. To\novercome this problem, energy harvesting offers a viable alternative to\nautonomously power IoT devices, resulting in a number of battery-less energy\nharvesting IoTs (or EH-IoTs) appearing in the market in recent years. Standards\nactivities are also underway, which involve wireless protocol design suitable\nfor EH-IoTs as well as testing procedures for various energy harvesting\nmethods. Despite the early commercial and standards activities, IoT sensing,\ncomputing and communications under unpredictable power supply still face\nsignificant research challenges. This paper systematically surveys recent\nadvances in EH-IoTs from several perspectives. First, it reviews the recent\ncommercial developments for EH-IoT in terms of both products and services,\nfollowed by initial standards activities in this space. Then it surveys methods\nthat enable the use of energy harvesting hardware as a proxy for conventional\nsensors to detect contexts in energy efficient manner. Next it reviews the\nadvancements in efficient checkpointing and timekeeping for intermittently\npowered IoT devices. We also survey recent research in novel wireless\ncommunication techniques for EH-IoTs, such as the applications of reinforcement\nlearning to optimize power allocations on-the-fly under unpredictable energy\nproductions, and packet-less IoT communications and backscatter communication\ntechniques for energy impoverished environments. The paper is concluded with a\ndiscussion of future research directions.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 05:42:57 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 00:47:58 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Ma", "Dong", ""], ["Lan", "Guohao", ""], ["Hassan", "Mahbub", ""], ["Hu", "Wen", ""], ["Das", "Sajal K.", ""]]}, {"id": "1905.04064", "submitter": "Ermin Sakic", "authors": "Ermin Sakic, Nemanja Deric, Endri Goshi, Wolfgang Kellerer", "title": "P4BFT: Hardware-Accelerated Byzantine-Resilient Network Control Plane", "comments": "Accepted for publication at IEEE Globecom 2019 CQRM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine Fault Tolerance (BFT) enables correct operation of distributed,\ni.e., replicated applications in the face of malicious take-over and\nfaulty/buggy individual instances. Recently, BFT designs have gained traction\nin the context of Software Defined Networking (SDN). In SDN, controller\nreplicas are distributed and their state replicated for high availability\npurposes. Malicious controller replicas, however, may destabilize the control\nplane and manipulate the data plane, thus motivating the BFT requirement.\nNonetheless, deploying BFT in practice comes at a disadvantage of increased\ntraffic load stemming from replicated controllers, as well as a requirement for\nproprietary switch functionalities, thus putting strain on switches' control\nplane where particular BFT actions must be executed in software.\n  P4BFT leverages an optimal strategy to decrease the total amount of messages\ntransmitted to switches that are the configuration targets of SDN controllers.\nIt does so by means of message comparison and deduction of correct messages in\nthe determined optimal locations in the data plane. In terms of the incurred\ncontrol plane load, our P4-based data plane extensions outperform the existing\nsolutions by ~33.2% and ~40.2% on average, in random 128-switch and\nFat-Tree/Internet2 topologies, respectively. To validate the correctness and\nperformance gains of P4BFT, we deploy bmv2 and Netronome Agilio SmartNIC-based\ntopologies. The advantages of P4BFT can thus be reproduced both with software\nswitches and \"commodity\" P4-enabled hardware. A hardware-accelerated controller\npacket comparison procedure results in an average 96.4% decrease in processing\ndelay per request compared to existing software approaches.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 10:46:28 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 09:36:55 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Sakic", "Ermin", ""], ["Deric", "Nemanja", ""], ["Goshi", "Endri", ""], ["Kellerer", "Wolfgang", ""]]}, {"id": "1905.04150", "submitter": "Pavlos Sermpezis", "authors": "Pavlos Sermpezis, Vasileios Kotronis", "title": "Inferring Catchment in Internet Routing", "comments": "ACM Sigmetrics 2019", "journal-ref": "Proceedings of the ACM on the Measurement and Analysis of\n  Computing Systems (POMACS), Vol. 3, No. 2, Article 30. Publication date: June\n  2019", "doi": "10.1145/3326145", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BGP is the de-facto Internet routing protocol for exchanging prefix\nreachability information between Autonomous Systems (AS). It is a dynamic,\ndistributed, path-vector protocol that enables rich expressions of network\npolicies (typically treated as secrets). In this regime, where complexity is\ninterwoven with information hiding, answering questions such as \"what is the\nexpected catchment of the anycast sites of a content provider on the AS-level,\nif new sites are deployed?\", or \"how will load-balancing behave if an ISP\nchanges its routing policy for a prefix?\", is a hard challenge. In this work,\nwe present a formal model and methodology that takes into account policy-based\nrouting and topological properties of the Internet graph, to predict the\nrouting behavior of networks. We design algorithms that provide new\ncapabilities for informative route inference (e.g., isolating the effect of\nrandomness that is present in prior simulation-based approaches). We analyze\nthe properties of these inference algorithms, and evaluate them using publicly\navailable routing datasets and real-world experiments. The proposed framework\ncan be useful in a number of applications: measurements, traffic engineering,\nnetwork planning, Internet routing models, etc. As a use case, we study the\nproblem of selecting a set of measurement vantage points to maximize route\ninference. Our methodology is general and can capture standard valley-free\nrouting, as well as more complex topological and routing setups appearing in\npractice.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:05:31 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Sermpezis", "Pavlos", ""], ["Kotronis", "Vasileios", ""]]}, {"id": "1905.04152", "submitter": "Hamid Shiri", "authors": "Hamid Shiri, Jihong Park, Mehdi Bennis", "title": "Massive Autonomous UAV Path Planning: A Neural Network Based Mean-Field\n  Game Theoretic Approach", "comments": "6 pages, 5 figures, submitted to IEEE GLOBECOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the autonomous control of massive unmanned aerial\nvehicles (UAVs) for mission-critical applications (e.g., dispatching many UAVs\nfrom a source to a destination for firefighting). Achieving their fast travel\nand low motion energy without inter-UAV collision under wind perturbation is a\ndaunting control task, which incurs huge communication energy for exchanging\nUAV states in real time. We tackle this problem by exploiting a mean-field game\n(MFG) theoretic control method that requires the UAV state exchanges only once\nat the initial source. Afterwards, each UAV can control its acceleration by\nlocally solving two partial differential equations (PDEs), known as the\nHamilton-Jacobi-Bellman (HJB) and Fokker-Planck-Kolmogorov (FPK) equations.\nThis approach, however, brings about huge computation energy for solving the\nPDEs, particularly under multi-dimensional UAV states. We address this issue by\nutilizing a machine learning (ML) method where two separate ML models\napproximate the solutions of the HJB and FPK equations. These ML models are\ntrained and exploited using an online gradient descent method with low\ncomputational complexity. Numerical evaluations validate that the proposed ML\naided MFG theoretic algorithm, referred to as MFG learning control, is\neffective in collision avoidance with low communication energy and acceptable\ncomputation energy.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:07:00 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Shiri", "Hamid", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1905.04289", "submitter": "Idris Badmus Mr", "authors": "Idris Badmus, Marja Matinmikko-Blue, Jaspreet Singh Walia, Tarik Taleb", "title": "Network Slice Instantiation for 5G Micro-Operator Deployment Scenario", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of network slicing is considered as a key part in the development\nof 5G. Network slicing is the means to logically isolate network capabilities\nin order to make each slice responsible for specific network requirement. In\nthe same light, the micro-operator concept has emerged for local deployment of\n5G for vertical specific service delivery. Even though microoperator networks\nare expected to be deployed using 5G, most research on network slicing has been\ndirected towards the description on the traditional (MNO) networks with little\nemphasis on slicing in local 5G networks deployed by different stakeholders. In\norder to achieve slicing in a micro-operator network, it is of vital importance\nto understand the different deployment scenarios that can exist and how slicing\ncan be realized for each of these deployments. In this paper, the microoperator\nnetworks described include closed, open and mixed network, and for each of\nthese network, different deployment scenarios are established. The paper\nfurther proposes approaches for the configuration of Network Slice Instances\n(NSIs) using the Network Slice Subnet Instances (NSSIs) and other Network\nFunctions (NFs) in a micro-operator network while considering the different\ndeployments. The results highlight the possible deployment scenarios that can\nbe established in a micro-operator network and how network slicing can be\nefficiently realized for the various local deployments.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 11:10:44 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 15:05:28 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Badmus", "Idris", ""], ["Matinmikko-Blue", "Marja", ""], ["Walia", "Jaspreet Singh", ""], ["Taleb", "Tarik", ""]]}, {"id": "1905.04349", "submitter": "Mohammadjavad Salehi", "authors": "MohammadJavad Salehi, Antti T\\\"olli, Seyed Pooya Shariatpanahi, Jarkko\n  Kaleva", "title": "Subpacketization-Rate Trade-off in Multi-Antenna Coded Caching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coded caching can be applied in wireless multi-antenna communications by\nmulticast beamforming coded data chunks to carefully selected user groups and\nusing the existing file fragments in user caches to decode the desired files at\neach user. However, the number of packets a file should be split into, known as\nsubpacketization, grows exponentially with the network size. We provide a new\nscheme, which enables the level of subpacketization to be selected freely among\na set of predefined values depending on basic network parameters such as\nantenna and user count. A simple efficiency index is also proposed as a\nperformance indicator at various subpacketization levels. The numerical\nexamples demonstrate that larger subpacketization generally results in better\nefficiency index and higher symmetric rate, while smaller subpacketization\nincurs significant loss in the achievable rate. This enables more efficient\ncaching schemes, tailored to the available computational and power resources.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 19:16:26 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Salehi", "MohammadJavad", ""], ["T\u00f6lli", "Antti", ""], ["Shariatpanahi", "Seyed Pooya", ""], ["Kaleva", "Jarkko", ""]]}, {"id": "1905.04437", "submitter": "Yiwen Zhang", "authors": "Yiwen Zhang, Yue Tan, Brent Stephens, and Mosharaf Chowdhury", "title": "RDMA Performance Isolation With Justitia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its increasing popularity, most of RDMA's benefits such as ultra-low\nlatency can be achieved only when running an application in isolation. Using\nmicrobenchmarks and real open-source RDMA applications, we identify a series of\nperformance anomalies when multiple applications coexist and show that such\nanomalies are pervasive across InfiniBand, RoCEv2, and iWARP. They arise due to\na fundamental tradeoff between performance isolation and work conservation,\nwhich the state-of-the-art RDMA congestion control protocols such as DCQCN\ncannot resolve. We present Justitia to address these performance anomalies.\nJustitia is a software-only, host-based, and easy-to-deploy solution that\nmaximizes RNIC utilization while guaranteeing performance isolation via\nshaping, rate limiting, and pacing at senders. Our evaluation of Justitia on\nmultiple RDMA implementations show that Justitia effectively isolates different\ntypes of traffic and significantly improves latency (by up to 56.9x) and\nthroughput (by up to 9.7x) of real-world RDMA-based applications without\ncompromising low CPU usage or modifying the applications.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 03:38:37 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zhang", "Yiwen", ""], ["Tan", "Yue", ""], ["Stephens", "Brent", ""], ["Chowdhury", "Mosharaf", ""]]}, {"id": "1905.04581", "submitter": "Ireneusz Szcze\\'sniak", "authors": "Ireneusz Szcze\\'sniak, Ireneusz Olszewski, Bo\\.zena\n  Wo\\'zna-Szcze\\'sniak", "title": "An efficient and exact algorithm for dynamic dedicated path protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient and exact algorithm for dynamic routing with\ndedicated path protection. We present the algorithm in the setting of optical\nnetworks, but it should be applicable to other networks, where services have to\nbe protected, and where the network resources are finite and discrete, e.g.,\nwireless radio or networks capable of advance resource reservation. To the best\nof our knowledge, we are the first to solve efficiently and exactly this\nlong-standing fundamental problem, which others argued intractable. The\nalgorithm is efficient, because it can solve large problems, and it is exact,\nbecause its results are optimal. We argue the stated problem is tractable by\nproviding for the proposed algorithm a polynomial pessimistic complexity\nanalysis, and a proof of correctness. Network operations, management, and\ncontrol require efficient and exact algorithms, especially now, when greater\nemphasis is placed on network performance, reliability, softwarization,\nagility, and return on investment. The proposed algorithm uses our generic\nDijkstra algorithm on a search graph generated \"on-the-fly\" based on the input\ngraph. We corroborated the optimality of the results of the proposed algorithm\nwith brute-force enumeration. We present the simulation results of\ndedicated-path protection with signal modulation constraints for elastic\noptical networks of 25, 50 and 100 nodes, and with 160, 320, and 640 spectrum\nunits. We also compare the bandwidth blocking probability with the\ncommonly-used edge-exclusion algorithm. We had 48600 simulation runs with about\n41 million searches.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 19:52:47 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 20:37:27 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 09:12:25 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Szcze\u015bniak", "Ireneusz", ""], ["Olszewski", "Ireneusz", ""], ["Wo\u017ana-Szcze\u015bniak", "Bo\u017cena", ""]]}, {"id": "1905.04649", "submitter": "Abha Kumari", "authors": "Abha Kumari, Ashok Singh Sairam", "title": "A Survey of Controller Placement Problem in Software Defined Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Defined Network (SDN) is an emerging network paradigm which provides\na centralized view of the network by decoupling the network control plane from\nthe data plane. This strategy of maintaining a global view of the network\noptimizes resource management. However, the implementation of SDN using a\nsingle physical controller lead to issues of scalability and robustness. A\nphysically distributed but logically centralized SDN controller architecture\npromises to resolve both these issues. Distributed SDN along with its benefits\nbrings along the problem of the number of controllers required and their\nplacement in the network. This problem is referred to as the controller\nplacement problem (CPP) and this paper is mainly concerned with the CPP\nsolution techniques. The paper formally defines CPP, gives a comprehensive\nreview of the various performance metrics and characteristics of the available\nCPP solutions. Finally, we point out the existing literature gap and discuss\nthe future research direction in this domain.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 05:52:16 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Kumari", "Abha", ""], ["Sairam", "Ashok Singh", ""]]}, {"id": "1905.04651", "submitter": "Muzammil Abdul Rehman", "authors": "Muzammil Abdul Rehman (1), Sharon Goldberg (2), David Choffnes (1)\n  ((1) Northeastern University, (2) Boston University)", "title": "Passport: Enabling Accurate Country-Level Router Geolocation using\n  Inaccurate Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  When does Internet traffic cross international borders? This question has\nmajor geopolitical, legal and social implications and is surprisingly difficult\nto answer. A critical stumbling block is a dearth of tools that accurately map\nrouters traversed by Internet traffic to the countries in which they are\nlocated. This paper presents Passport: a new approach for efficient, accurate\ncountry-level router geolocation and a system that implements it. Passport\nprovides location predictions with limited active measurements, using machine\nlearning to combine information from IP geolocation databases, router\nhostnames, whois records, and ping measurements. We show that Passport\nsubstantially outperforms existing techniques, and identify cases where paths\ntraverse countries with implications for security, privacy, and performance.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 06:04:03 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 18:05:02 GMT"}, {"version": "v3", "created": "Tue, 23 Jul 2019 07:03:25 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Rehman", "Muzammil Abdul", "", "Northeastern University"], ["Goldberg", "Sharon", "", "Boston University"], ["Choffnes", "David", "", "Northeastern University"]]}, {"id": "1905.04736", "submitter": "Ireneusz Szcze\\'sniak", "authors": "Ireneusz Szcze\\'sniak, Piotr Cho{\\l}da, Andrzej R. Pach, Bo\\.zena\n  Wo\\'zna-Szcze\\'sniak", "title": "Interoperator fixed-mobile network sharing", "comments": "19th International Conference on Optical Network Design and Modeling\n  (ONDM), pp. 192-197, May 2015", "journal-ref": null, "doi": "10.1109/ONDM.2015.7127297", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the novel idea of interoperator fixed-mobile network sharing,\nwhich can be software-defined and readily-deployed. We study the benefits which\nthe sharing brings in terms of resiliency, and show that, with the appropriate\nplacement of a few active nodes, the mean service downtime can be reduced more\nthan threefold by providing interoperator communication to as little as one\noptical network unit in one hundred. The implementation of the proposed idea\ncan be carried out in stages when needed (the pay-as-you-grow deployment), and\nin those parts of the network where high service availability is needed most,\ne.g., in a business district. While the performance should expectedly increase,\nwe show the resiliency is brought almost out of thin air by using redundant\nresources of different operators. We evaluated the service availability for\n87400 networks with the relative standard error of the sample mean below 1%.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 15:44:52 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Szcze\u015bniak", "Ireneusz", ""], ["Cho\u0142da", "Piotr", ""], ["Pach", "Andrzej R.", ""], ["Wo\u017ana-Szcze\u015bniak", "Bo\u017cena", ""]]}, {"id": "1905.04788", "submitter": "Mohammad Yousefvand", "authors": "Mohammad Yousefvand, Kenza Hamidouche, Narayan B. Mandayam", "title": "Learning-based Resource Optimization in Ultra Reliable Low Latency\n  HetNets", "comments": "Submitted to IEEE Globecom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problems of user offloading and resource optimization are\njointly addressed to support ultra-reliable and low latency communications\n(URLLC) in HetNets. In particular, a multi-tier network with a single macro\nbase station (MBS) and multiple overlaid small cell base stations (SBSs) is\nconsidered that includes users with different latency and reliability\nconstraints. Modeling the latency and reliability constraints of users with\nprobabilistic guarantees, the joint problem of user offloading and resource\nallocation (JUR) in a URLLC setting is formulated as an optimization problem to\nminimize the cost of serving users for the MBS. In the considered scheme, SBSs\nbid to serve URLLC users under their coverage at a given price, and the MBS\ndecides whether to serve each user locally or to offload it to one of the\noverlaid SBSs. Since the JUR optimization is NP-hard, we propose a low\ncomplexity learning-based heuristic method (LHM) which includes a support\nvector machine-based user association model and a convex resource optimization\n(CRO) algorithm. To further reduce the delay, we propose an alternating\ndirection method of multipliers (ADMM)-based solution to the CRO problem.\nSimulation results show that using LHM, the MBS significantly decreases the\nspectrum access delay for users (by $\\sim$ 93\\%) as compared to JUR, while also\nreducing its bandwidth and power costs in serving users (by $\\sim$ 33\\%) as\ncompared to directly serving users without offloading.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 20:33:03 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Yousefvand", "Mohammad", ""], ["Hamidouche", "Kenza", ""], ["Mandayam", "Narayan B.", ""]]}, {"id": "1905.04796", "submitter": "Martin Barrere", "authors": "Mart\\'in Barr\\`ere, Chris Hankin, Nicolas Nicolau, Demetrios G.\n  Eliades, Thomas Parisini", "title": "Identifying Security-Critical Cyber-Physical Components in Industrial\n  Control Systems", "comments": "Keywords: Security metrics, industrial control systems,\n  cyber-physical systems, AND-OR graphs, MAX-SAT resolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Industrial Control Systems (ICS) have become an appealing\ntarget for cyber attacks, having massive destructive consequences. Security\nmetrics are therefore essential to assess their security posture. In this\npaper, we present a novel ICS security metric based on AND/OR graphs that\nrepresent cyber-physical dependencies among network components. Our metric is\nable to efficiently identify sets of critical cyber-physical components, with\nminimal cost for an attacker, such that if compromised, the system would enter\ninto a non-operational state. We address this problem by efficiently\ntransforming the input AND/OR graph-based model into a weighted logical formula\nthat is then used to build and solve a Weighted Partial MAX-SAT problem. Our\ntool, META4ICS, leverages state-of-the-art techniques from the field of logical\nsatisfiability optimisation in order to achieve efficient computation times.\nOur experimental results indicate that the proposed security metric can\nefficiently scale to networks with thousands of nodes and be computed in\nseconds. In addition, we present a case study where we have used our system to\nanalyse the security posture of a realistic water transport network. We discuss\nour findings on the plant as well as further security applications of our\nmetric.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 21:53:16 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Barr\u00e8re", "Mart\u00edn", ""], ["Hankin", "Chris", ""], ["Nicolau", "Nicolas", ""], ["Eliades", "Demetrios G.", ""], ["Parisini", "Thomas", ""]]}, {"id": "1905.04947", "submitter": "Theodoros Giannakas", "authors": "Theodoros Giannakas, Thrasyvoulos Spyropoulos and Pavlos Sermpezis", "title": "The Order of Things: Position-Aware Network-friendly Recommendations in\n  Long Viewing Sessions", "comments": null, "journal-ref": "IEEE/IFIP WiOpt 2019", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caching has recently attracted a lot of attention in the wireless\ncommunications community, as a means to cope with the increasing number of\nusers consuming web content from mobile devices. Caching offers an opportunity\nfor a win-win scenario: nearby content can improve the video streaming\nexperience for the user, and free up valuable network resources for the\noperator. At the same time, recent works have shown that recommendations of\npopular content apps are responsible for a significant percentage of users\nrequests. As a result, some very recent works have considered how to nudge\nrecommendations to facilitate the network (e.g., increase cache hit rates). In\nthis paper, we follow up on this line of work, and consider the problem of\ndesigning cache friendly recommendations for long viewing sessions;\nspecifically, we attempt to answer two open questions in this context: (i)\ngiven that recommendation position affects user click rates, what is the impact\non the performance of such network-friendly recommender solutions? (ii) can the\nresulting optimization problems be solved efficiently, when considering both\nsequences of dependent accesses (e.g., YouTube) and position preference? To\nthis end, we propose a stochastic model that incorporates position-aware\nrecommendations into a Markovian traversal model of the content catalog, and\nderive the average cost of a user session using absorbing Markov chain theory.\nWe then formulate the optimization problem, and after a careful sequence of\nequivalent transformations show that it has a linear program equivalent and\nthus can be solved efficiently. Finally, we use a range of real datasets we\ncollected to investigate the impact of position preference in recommendations\non the proposed optimal algorithm. Our results suggest more than 30\\%\nimprovement with respect to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 10:26:21 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Giannakas", "Theodoros", ""], ["Spyropoulos", "Thrasyvoulos", ""], ["Sermpezis", "Pavlos", ""]]}, {"id": "1905.04956", "submitter": "Ehsan Mohammadpour", "authors": "Ehsan Mohammadpour, Elena Stai, Jean-Yves Le Boudec", "title": "Improved Delay Bound for a Service Curve Element with Known Transmission\n  Rate", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": "10.1109/LNET.2019.2927143", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network calculus is often used to prove delay bounds in deterministic\nnetworks, using arrival and service curves. We consider a FIFO system that\noffers a rate-latency service curve and where packet transmission occurs at\nline rate without pre-emption. The existing network calculus delay bounds take\nadvantage of the service curve guarantee but not of the fact that transmission\noccurs at full line rate. In this letter, we provide a novel, improved delay\nbound which takes advantage of these two features. Contrary to existing bounds,\nours is per-packet and depends on the packet length. We prove that it is tight.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 10:54:12 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 08:05:51 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Mohammadpour", "Ehsan", ""], ["Stai", "Elena", ""], ["Boudec", "Jean-Yves Le", ""]]}, {"id": "1905.04962", "submitter": "Manuel Peuster", "authors": "Manuel Peuster and Stefan Schneider and Holger Karl", "title": "The Softwarised Network Data Zoo", "comments": "IEEE/IFIP 15th International Conference on Network and Service\n  Management (CNSM), Halifax, Canada. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more management and orchestration approaches for (software) networks\nare based on machine learning paradigms and solutions. These approaches depend\nnot only on their program code to operate properly, but also require enough\ninput data to train their internal models. However, such training data is\nbarely available for the software networking domain and most presented\nsolutions rely on their own, sometimes not even published, data sets. This\nmakes it hard, or even infeasible, to reproduce and compare many of the\nexisting solutions. As a result, it ultimately slows down the adoption of\nmachine learning approaches in softwarised networks. To this end, we introduce\nthe \"softwarised network data zoo\" (SNDZoo), an open collection of software\nnetworking data sets aiming to streamline and ease machine learning research in\nthe software networking domain. We present a general methodology to collect,\narchive, and publish those data sets for use by other researches and, as an\nexample, eight initial data sets, focusing on the performance of virtualised\nnetwork functions.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 10:56:16 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 10:04:58 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Peuster", "Manuel", ""], ["Schneider", "Stefan", ""], ["Karl", "Holger", ""]]}, {"id": "1905.05015", "submitter": "Federica Paganelli", "authors": "Giovanni Cuffaro, Federica Paganelli, Georgios Mylonas", "title": "A resource-based rule engine for energy savings recommendations in\n  educational buildings", "comments": null, "journal-ref": null, "doi": "10.1109/GIOTS.2017.8016275", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raising awareness among young people on the relevance of behaviour change for\nachieving energy savings is widely considered as a key approach towards\nlong-term and cost-effective energy efficiency policies. The GAIA Project aims\nto deliver a comprehensive solution for both increasing awareness on energy\nefficiency and achieving energy savings in school buildings. In this framework,\nwe present a novel rule engine that, leveraging a resource-based graph model\nencoding relevant application domain knowledge, accesses IoT data for producing\nenergy savings recommendations. The engine supports configurability,\nextensibility and ease-of-use requirements, to be easily applied and customized\nto different buildings. The paper introduces the main design and implementation\ndetails and presents a set of preliminary performance results.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 12:45:31 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Cuffaro", "Giovanni", ""], ["Paganelli", "Federica", ""], ["Mylonas", "Georgios", ""]]}, {"id": "1905.05046", "submitter": "Shuowen Zhang", "authors": "Shuowen Zhang and Rui Zhang", "title": "Radio Map Based Path Planning for Cellular-Connected UAV", "comments": "to appear in Proc. IEEE Global Communications Conference (Globecom),\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the path planning for a cellular-connected unmanned\naerial vehicle (UAV) to minimize its flying distance from given initial to\nfinal locations, while ensuring a target link quality in terms of the\nlarge-scale channel gain with each of its associated ground base stations\n(GBSs) during the flight. To this end, we propose the use of radio map that\nprovides the information on the large-scale channel gains between each GBS and\nuniformly sampled locations on a three-dimensional (3D) grid over the region of\ninterest, which are assumed to be time-invariant due to the generally static\nand large-size obstacles therein (e.g., buildings). Based on the given radio\nmaps of the GBSs, we first obtain the optimal UAV path by solving an equivalent\nshortest path problem (SPP) in graph theory. To reduce the computation\ncomplexity of the optimal solution, we further propose a grid quantization\nmethod whereby the grid points in each GBS's radio map are more coarsely\nsampled by exploiting the spatial channel correlation over neighboring grids.\nThen, we solve the approximate SPP over the reduced-size radio map (graph) more\nefficiently. Numerical results show that the proposed solutions can effectively\nminimize the flying distance of the UAV subject to its communication quality\nconstraint. Moreover, a flexible trade-off between performance and complexity\ncan be achieved by adjusting the quantization ratio for the radio map.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 14:05:00 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 12:23:18 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Zhang", "Shuowen", ""], ["Zhang", "Rui", ""]]}, {"id": "1905.05130", "submitter": "Venkat Arun", "authors": "Venkat Arun and Hari Balakrishnan", "title": "RFocus: Practical Beamforming for Small Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce transmit power, increase throughput, and improve communication\nrange, radio systems---such as IoT sensor networks, Wi-Fi and cellular\nnetworks---benefit from the ability to direct their signals, to ensure that\nmore of the transmitted power reaches the receiver. Many modern systems\nbeamform with antenna arrays for this purpose. However, a radio's ability to\ndirect its signal is fundamentally limited by its size. Unfortunately practical\nchallenges limit the size of modern radios, and consequently, their ability to\nbeamform. In many settings, radios on devices must be small and inexpensive;\ntoday, these settings are unable to benefit from high-precision beamforming.\n  To address this problem, we introduce RFocus, which moves beamforming\nfunctions from the radio endpoints to the environment. RFocus includes a\ntwo-dimensional surface with a rectangular array of simple elements, each of\nwhich functions as an RF switch. Each element either lets the signal through or\nreflects it. The surface does not emit any power of its own. The state of the\nelements is set by a software controller to maximize the signal strength at a\nreceiver, with a novel optimization algorithm that uses signal strength\nmeasurements from the receiver. The RFocus surface can be manufactured as an\ninexpensive thin wallpaper, requiring no wiring. This solution requires only a\nmethod to communicate received signal strengths periodically to the RFocus\ncontroller. Our prototype implementation improves the median signal strength by\n10.5x, and the median channel capacity by 2.1x.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:33:58 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Arun", "Venkat", ""], ["Balakrishnan", "Hari", ""]]}, {"id": "1905.05137", "submitter": "Olakunle Ibitoye", "authors": "Olakunle Ibitoye, Omair Shafiq and Ashraf Matrawy", "title": "Analyzing Adversarial Attacks Against Deep Learning for Intrusion\n  Detection in IoT Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks have been widely studied in the field of computer vision\nbut their impact on network security applications remains an area of open\nresearch. As IoT, 5G and AI continue to converge to realize the promise of the\nfourth industrial revolution (Industry 4.0), security incidents and events on\nIoT networks have increased. Deep learning techniques are being applied to\ndetect and mitigate many of such security threats against IoT networks.\nFeedforward Neural Networks (FNN) have been widely used for classifying\nintrusion attacks in IoT networks. In this paper, we consider a variant of the\nFNN known as the Self-normalizing Neural Network (SNN) and compare its\nperformance with the FNN for classifying intrusion attacks in an IoT network.\nOur analysis is performed using the BoT-IoT dataset from the Cyber Range Lab of\nthe center of UNSW Canberra Cyber. In our experimental results, the FNN\noutperforms the SNN for intrusion detection in IoT networks based on multiple\nperformance metrics such as accuracy, precision, and recall as well as\nmulti-classification metrics such as Cohen's Kappa score. However, when tested\nfor adversarial robustness, the SNN demonstrates better resilience against the\nadversarial samples from the IoT dataset, presenting a promising future in the\nquest for safer and more secure deep learning in IoT networks.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:43:14 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ibitoye", "Olakunle", ""], ["Shafiq", "Omair", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "1905.05220", "submitter": "Philipp H. Kindt", "authors": "Philipp H. Kindt, Samarjit Chakraborty", "title": "On Optimal Neighbor Discovery", "comments": "Conference of the ACM Special Interest Group on Data Communication\n  (ACM SIGCOMM), 2019", "journal-ref": null, "doi": "10.1145/3341302.3342067", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices apply neighbor discovery (ND) protocols to wirelessly initiate\na first contact within the shortest possible amount of time and with minimal\nenergy consumption. For this purpose, over the last decade, a vast number of ND\nprotocols have been proposed, which have progressively reduced the relation\nbetween the time within which discovery is guaranteed and the energy\nconsumption. In spite of the simplicity of the problem statement, even after\nmore than 10 years of research on this specific topic, new solutions are still\nproposed even today. Despite the large number of known ND protocols, given an\nenergy budget, what is the best achievable latency still remains unclear. This\npaper addresses this question and for the first time presents safe and tight,\nduty-cycle-dependent bounds on the worst-case discovery latency that no ND\nprotocol can beat. Surprisingly, several existing protocols are indeed optimal,\nwhich has not been known until now. We conclude that there is no further\npotential to improve the relation between latency and duty-cycle, but future ND\nprotocols can improve their robustness against beacon collisions.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 18:11:48 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 14:08:21 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kindt", "Philipp H.", ""], ["Chakraborty", "Samarjit", ""]]}, {"id": "1905.05258", "submitter": "Ashkan Aghdai", "authors": "Ashkan Aghdai, Yang Xu, Mark Huang, David H. Dai, H. Jonathan Chao", "title": "Enabling Mobility in LTE-Compatible Mobile-edge Computing with\n  Programmable Switches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network softwarization triggered a new wave of innovation in modern network\ndesign. The next generation of mobile networks embraces this trend. Mobile-edge\ncomputing (MEC) is a key part of emerging mobile networks that enables\nultra-low latency mission-critical application such as vehicle-to vehicle\ncommunication. MEC aims at bringing delay-sensitive applications closer to the\nradio access network to enable ultra-low latency for users and decrease the\nback-haul pressure on mobile service providers. However, there are no practical\nsolutions to enable mobility at MEC where connections are no longer anchored to\nthe core network and serving applications are supposed to move as their users\nmove. We propose the mobile-edge gateway (MEGW) to address this gap. MEGW\nenables mobility for MEC applications transparently and without requiring any\nmodifications to existing protocols and applications. MEGW supports mobility by\nreconstructing mobile users' location via listening to LTE control plane in\naddition to using two-stage location-dependent traffic steering for edge\nconnections. Networks can incrementally upgrade to support MEC by upgrading\nsome IP router to programmable switches that run MEGW. We have implemented MEGW\nusing P4 language and verified its compatibility with existing LTE networks in\na testbed running reference LTE protocol stack. Furthermore, using packet-level\nsimulations we show that the two-stage traffic steering algorithm reduces the\nnumber of application migrations and simplifies service provisioning.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:30:47 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Aghdai", "Ashkan", ""], ["Xu", "Yang", ""], ["Huang", "Mark", ""], ["Dai", "David H.", ""], ["Chao", "H. Jonathan", ""]]}, {"id": "1905.05316", "submitter": "Mohammed Elbamby", "authors": "Mohammed S. Elbamby, Cristina Perfecto, Chen-Feng Liu, Jihong Park,\n  Sumudu Samarakoon, Xianfu Chen, Mehdi Bennis", "title": "Wireless Edge Computing with Latency and Reliability Guarantees", "comments": "20 pages, 13 figures. Accepted for publication in Proceedings of the\n  IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing is an emerging concept based on distributing computing,\nstorage, and control services closer to end network nodes. Edge computing lies\nat the heart of the fifth generation (5G) wireless systems and beyond. While\ncurrent state-of-the-art networks communicate, compute, and process data in a\ncentralized manner (at the cloud), for latency and compute-centric\napplications, both radio access and computational resources must be brought\ncloser to the edge, harnessing the availability of computing and\nstorage-enabled small cell base stations in proximity to the end devices.\nFurthermore, the network infrastructure must enable a distributed edge\ndecision-making service that learns to adapt to the network dynamics with\nminimal latency and optimize network deployment and operation accordingly. This\narticle will provide a fresh look to the concept of edge computing by first\ndiscussing the applications that the network edge must provide, with a special\nemphasis on the ensuing challenges in enabling ultra-reliable and low-latency\nedge computing services for mission-critical applications such as virtual\nreality (VR), vehicle-to-everything (V2X), edge artificial intelligence (AI),\nand so forth. Furthermore, several case studies where the edge is key are\nexplored followed by insights and prospect for future work.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 23:25:10 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Elbamby", "Mohammed S.", ""], ["Perfecto", "Cristina", ""], ["Liu", "Chen-Feng", ""], ["Park", "Jihong", ""], ["Samarakoon", "Sumudu", ""], ["Chen", "Xianfu", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1905.05342", "submitter": "Esther Max-Onakpoya", "authors": "Esther Max-Onakpoya, Oluwashina Madamori, Faren Grant, Robin\n  Vanderpool, Ming-Yuan Chih, David K. Ahern, Eliah Aronoff-Spencer, Corey E.\n  Baker", "title": "Augmenting Cloud Connectivity with Opportunistic Networks for Rural\n  Remote Patient Monitoring", "comments": "7 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current remote patient monitoring (RPM) systems are fully reliant on the\nInternet. However, complete reliance on Internet connectivity is impractical in\nrural and remote environments where modern infrastructure is often lacking,\npower outages are frequent, and/or network connectivity is sparse (e.g. rural\ncommunities, mountainous regions of Appalachia, American Indian reservations,\ndeveloping countries, and natural disaster situations). This paper proposes\naugmenting intermittent Internet with opportunistic communication to leverage\nthe social behaviors of patients, caregivers, and community members to\nfacilitate out-of-range monitoring of patients via Bluetooth 5 during\nintermittent network connectivity in rural communities. The architecture is\nevaluated for Owingsville, KY using U.S. Census Bureau, the National Cancer\nInstitute's, and IPUMS-ATUS sample data, and is compared against a delay\ntolerant RPM case that is completely disconnected from the Internet. The\nfindings show that with only 0.30 rural adult population participation, the\narchitecture can deliver 0.95 of non-emergency medical information with an\naverage delivery latency of approximately 13 hours.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 01:56:37 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 18:25:19 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Max-Onakpoya", "Esther", ""], ["Madamori", "Oluwashina", ""], ["Grant", "Faren", ""], ["Vanderpool", "Robin", ""], ["Chih", "Ming-Yuan", ""], ["Ahern", "David K.", ""], ["Aronoff-Spencer", "Eliah", ""], ["Baker", "Corey E.", ""]]}, {"id": "1905.05411", "submitter": "Nicolas Holliman Professor", "authors": "Richard Cloete, Nick Holliman", "title": "Measuring and simulating latency in interactive remote rendering systems", "comments": "Minor update to typos and acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: The computationally intensive task of real-time rendering can be\noffloaded to remote cloud systems. However, due to network latency, interactive\nremote rendering (IRR) introduces the challenge of interaction latency (IL),\nwhich is the time between an action and response to that action. Objectives: to\nmodel sources of latency, measure it in a real-world network and to use this\nunderstanding to simulate latency so that we have a controlled platform for\nexperimental work in latency management. Method: we present a seven-parameter\nmodel of latency for a typical IRR system; we describe new, minimally intrusive\nsoftware methods for measuring latency in a 3D graphics environment and create\na novel latency simulator tool in software. Results: We demonstrate our latency\nsimulator is comparable to real-world behavior and confirm that real-world\nlatency exceeds the interactive limit of 70ms over long distance connections.\nWe also find that current approaches to measuring IL are not general enough for\nmost situations and therefore propose a novel general-purpose solution.\nConclusion: to ameliorate latency in IRR systems we need controllable\nsimulation tools for experimentation. In addition to a new measurement\ntechnique, we propose a new approach that will be of interest to IRR\nresearchers and developers when designing IL compensation techniques.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 06:38:36 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 19:58:34 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Cloete", "Richard", ""], ["Holliman", "Nick", ""]]}, {"id": "1905.05431", "submitter": "Shenglong Peng", "authors": "Shenglong Peng, Xuan He, Junyi Du, Yong Liang Guan, and Liang Zhou", "title": "A TDMA-like Access Scheme with Splitting Request and Transmission for\n  Vehicular Networks", "comments": "2019 IEEE Wireless Communications and Networking Conference (WCNC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider safety message transmission in a dense vehicular\nnetwork. With increasing vehicular network density, the collision rate\nincreases when multiple vehicles transmit safety messages simultaneously. To\naddress this issue, we propose a request-transmission split time division\nmultiple access (TDMA) scheme, referred to as RTS-TDMA. In our scheme, we\ndivide a frame into three phases, i.e., a contention access phase, a broadcast\nfeedback phase, and a contention-free transmission phase. Each vehicle selects\na repetition rate according to a given probability distribution and repeats the\ntransmission of its request packet to improve the reliability of the request.\nIn addition, a roadside unit acts as the coordinator and uses a successive\ninterference cancellation technique to resolve request collisions. RTS-TDMA\nalso reduces the request time percentage by containing only the vehicle\nidentity in each request packet. Both theoretical analysis and numerical\nresults verify that the RTS-TDMA scheme can provide higher throughput than the\ncoded slotted ALOHA scheme.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 07:45:03 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Peng", "Shenglong", ""], ["He", "Xuan", ""], ["Du", "Junyi", ""], ["Guan", "Yong Liang", ""], ["Zhou", "Liang", ""]]}, {"id": "1905.05434", "submitter": "Onel Luis Alcaraz L\\'opez", "authors": "Onel L. Alcaraz L\\'opez, Hirley Alves, Matti Latva-aho", "title": "Joint Power Control and Rate Allocation enabling Ultra-Reliability and\n  Energy Efficiency in SIMO Wireless Networks", "comments": "15 pages, 12 figures, accepted for publication in IEEE TCOM", "journal-ref": null, "doi": "10.1109/TCOMM.2019.2914682", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coming cellular systems are envisioned to open up to new services with\nstringent reliability and energy efficiency requirements. In this paper we\nfocus on the joint power control and rate allocation problem in Single-Input\nMultiple-Output (SIMO) wireless systems with Rayleigh fading and stringent\nreliability constraints. We propose an allocation scheme that maximizes the\nenergy efficiency of the system while making use only of average statistics of\nthe signal and interference, and the number of antennas $M$ that are available\nat the receiver side. We show the superiority of the Maximum Ratio Combining\n(MRC) scheme over Selection Combining (SC) in terms of energy efficiency, and\nprove that the gap between the optimum allocated resources converges to\n$(M!)^(1/(2M))$ as the reliability constraint becomes more stringent.\nMeanwhile, in most cases MRC was also shown to be more energy efficient than\nSwitch and Stay Combining (SSC) scheme, although this does not hold only when\noperating with extremely large $M$, extremely high/small average\nsignal/interference power and/or highly power consuming receiving circuitry.\nNumerical results show the feasibility of the ultra-reliable operation when $M$\nincreases, while greater the fixed power consumption and/or drain efficiency of\nthe transmit amplifier is, the greater the optimum transmit power and rate.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 07:52:57 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["L\u00f3pez", "Onel L. Alcaraz", ""], ["Alves", "Hirley", ""], ["Latva-aho", "Matti", ""]]}, {"id": "1905.05453", "submitter": "Francesco Malandrino", "authors": "Francesco Malandrino and Cristina Rottondi and Carla-Fabiana\n  Chiasserini and Andrea Bianco and Ioannis Stavrakakis", "title": "Multiservice UAVs for Emergency Tasks in Post-disaster Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UAVs are increasingly being employed to carry out surveillance, parcel\ndelivery, communication-support and other specific tasks. Their equipment and\nmission plan are carefully selected to minimize the carried load an overall\nresource consumption. Typically, several single task UAVs are dispatched to\nperform different missions. In certain cases, (part of) the geographical area\nof operation may be common to these single task missions (such as those\nsupporting post-disaster recovery) and it may be more efficient to have\nmultiple tasks carried out as part of a single UAV mission using common or even\nadditional specialized equipment.\n  In this paper, we propose and investigate a joint planning of multitask\nmissions leveraging a fleet of UAVs equipped with a standard set of accessories\nenabling heterogeneous tasks. To this end, an optimization problem is\nformulated yielding the optimal joint planning and deriving the resulting\nquality of the delivered tasks. In addition, a heuristic solution is developed\nfor large-scale environments to cope with the increased complexity of the\noptimization framework. The developed joint planning of multitask missions is\napplied to a specific post-disaster recovery scenario of a flooding in the San\nFrancisco area. The results show the effectiveness of the proposed solutions\nand the potential savings in the number of UAVs needed to carry out all the\ntasks with the required level of quality.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:38:47 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Malandrino", "Francesco", ""], ["Rottondi", "Cristina", ""], ["Chiasserini", "Carla-Fabiana", ""], ["Bianco", "Andrea", ""], ["Stavrakakis", "Ioannis", ""]]}, {"id": "1905.05633", "submitter": "Corey Baker", "authors": "Oluwashina Madamori, Esther Max-Onakpoya, Christan Grant, Corey E.\n  Baker", "title": "Using Delay Tolerant Networks as a Backbone for Low-cost Smart Cities", "comments": "3 pages, accepted to IEEE SmartComp 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid urbanization burdens city infrastructure and creates the need for local\ngovernments to maximize the usage of resources to serve its citizens. Smart\ncity projects aim to alleviate the urbanization problem by deploying a vast\namount of Internet-of-things (IoT) devices to monitor and manage environmental\nconditions and infrastructure. However, smart city projects can be extremely\nexpensive to deploy and manage. A significant portion of the expense is a\nresult of providing Internet connectivity via 5G or WiFi to IoT devices. This\npaper proposes the use of delay tolerant networks (DTNs) as a backbone for\nsmart city communication; enabling developing communities to become smart\ncities at a fraction of the cost. A model is introduced to aid policy makers in\ndesigning and evaluating the expected performance of such networks. Preliminary\nresults are presented based on a public transit network data-set from Chapel\nHill, North Carolina. Finally, innovative ways of improving network performance\nin a low-cost smart city is discussed.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:22:54 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Madamori", "Oluwashina", ""], ["Max-Onakpoya", "Esther", ""], ["Grant", "Christan", ""], ["Baker", "Corey E.", ""]]}, {"id": "1905.05729", "submitter": "Ramon Ferrus", "authors": "K. Koutlia, R. Ferrus, E. Coronado, R. Riggio, F. Casadevall, A.\n  Umbert and J. Perez-Romero", "title": "Design and Experimental Validation of a Software-Defined Radio Access\n  Network Testbed with Slicing Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing is a fundamental feature of 5G systems to partition a single\nnetwork into a number of segregated logical networks, each optimized for a\nparticular type of service, or dedicated to a particular customer or\napplication. The realization of network slicing is particularly challenging in\nthe Radio Access Network (RAN) part, where multiple slices can be multiplexed\nover the same radio channel and Radio Resource Management (RRM) functions shall\nbe used to split the cell radio resources and achieve the expected behaviour\nper slice. In this context, this paper describes the key design and\nimplementation aspects of a Software-Defined RAN (SD-RAN) experimental testbed\nwith slicing support. The testbed has been designed consistently with the\nslicing capabilities and related management framework established by 3GPP in\nRelease 15. The testbed is used to demonstrate the provisioning of RAN slices\n(e.g. preparation, commissioning and activation phases) and the operation of\nthe implemented RRM functionality for slice-aware admission control and\nscheduling.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:18:08 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Koutlia", "K.", ""], ["Ferrus", "R.", ""], ["Coronado", "E.", ""], ["Riggio", "R.", ""], ["Casadevall", "F.", ""], ["Umbert", "A.", ""], ["Perez-Romero", "J.", ""]]}, {"id": "1905.05835", "submitter": "Pablo Moriano", "authors": "Pablo Moriano, Raquel Hill, L. Jean Camp", "title": "Using Bursty Announcements for Detecting BGP Routing Anomalies", "comments": "16 pages, 13 figures, 4 table", "journal-ref": "Comput. Netw. vol. 188, pp. 107835, 2021", "doi": "10.1016/j.comnet.2021.107835", "report-no": null, "categories": "cs.NI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the robust structure of the Internet, it is still susceptible to\ndisruptive routing updates that prevent network traffic from reaching its\ndestination. Our research shows that BGP announcements that are associated with\ndisruptive updates tend to occur in groups of relatively high frequency,\nfollowed by periods of infrequent activity. We hypothesize that we may use\nthese bursty characteristics to detect anomalous routing incidents. In this\nwork, we use manually verified ground truth metadata and volume of\nannouncements as a baseline measure, and propose a burstiness measure that\ndetects prior anomalous incidents with high recall and better precision than\nthe volume baseline. We quantify the burstiness of inter-arrival times around\nthe date and times of four large-scale incidents: the Indosat hijacking event\nin April 2014, the Telecom Malaysia leak in June 2015, the Bharti Airtel Ltd.\nhijack in November 2015, and the MainOne leak in November 2018; and three\nsmaller scale incidents that led to traffic interception: the Belarusian\ntraffic direction in February 2013, the Icelandic traffic direction in July\n2013, and the Russian telecom that hijacked financial services in April 2017.\nOur method leverages the burstiness of disruptive update messages to detect\nthese incidents. We describe limitations, open challenges, and how this method\ncan be used for routing anomaly detection.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 20:44:11 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 22:30:59 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Moriano", "Pablo", ""], ["Hill", "Raquel", ""], ["Camp", "L. Jean", ""]]}, {"id": "1905.05926", "submitter": "Hongyu Yang", "authors": "Hongyu Yang, Jun Zhang, S.H. Song, and Khaled B. Lataief", "title": "Connectivity-Aware UAV Path Planning with Aerial Coverage Maps", "comments": "This paper has been accepted by IEEE WCNC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular networks are promising to support effective wireless communications\nfor unmanned aerial vehicles (UAVs), which will help to enable various\nlong-range UAV applications. However, these networks are optimized for\nterrestrial users, and thus do not guarantee seamless aerial coverage. In this\npaper, we propose to overcome this difficulty by exploiting controllable\nmobility of UAVs, and investigate connectivity-aware UAV path planning. To\nexplicitly impose communication requirements on UAV path planning, we introduce\ntwo new metrics to quantify the cellular connectivity quality of a UAV path.\nMoreover, aerial coverage maps are used to provide accurate locations of\nscattered coverage holes in the complicated propagation environment. We\nformulate the UAV path planning problem as finding the shortest path subject to\nconnectivity constraints. Based on graph search methods, a novel\nconnectivity-aware path planning algorithm with low complexity is proposed. The\neffectiveness and superiority of our proposed algorithm are demonstrated using\nthe aerial coverage map of an urban section in Virginia, which is built by ray\ntracing. Simulation results also illustrate a tradeoff between the path length\nand connectivity quality of UAVs.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:20:34 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 01:54:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Yang", "Hongyu", ""], ["Zhang", "Jun", ""], ["Song", "S. H.", ""], ["Lataief", "Khaled B.", ""]]}, {"id": "1905.05998", "submitter": "Tongyu Dai", "authors": "Tongyu Dai, Xinggong Zhang, Yihang Zhang, Zongming Guo", "title": "Statistical Learning Based Congestion Control for Real-time Video\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demands on interactive video applications, how to adapt\nvideo bit rate to avoid network congestion has become critical, since\ncongestion results in self-inflicted delay and packet loss which deteriorate\nthe quality of real-time video service. The existing congestion control is hard\nto simultaneously achieve low latency, high throughput, good adaptability and\nfair bandwidth allocation, mainly because of the hardwired control strategy and\negocentric convergence objective. To address these issues, we propose an\nend-to-end statistical learning based congestion control, named Iris. By\nexploring the underlying principles of self-inflicted delay, we reveal that\ncongestion delay is determined by sending rate, receiving rate and network\nstatus, which inspires us to control video bit rate using a\nstatistical-learning congestion control model. The key idea of Iris is to force\nall flows to converge to the same queue load, and adjust the bit rate by the\nmodel. All flows keep a small and fixed number of packets queuing in the\nnetwork, thus the fair bandwidth allocation and low latency are both achieved.\nBesides, the adjustment step size of sending rate is updated by online\nlearning, to better adapt to dynamically changing networks. We carried out\nextensive experiments to evaluate the performance of Iris, with the\nimplementations of transport layer (UDP) and application layer (QUIC)\nrespectively. The testing environment includes emulated network, real-world\nInternet and commercial LTE networks. Compared against TCP flavors and\nstate-of-the-art protocols, Iris is able to achieve high bandwidth utilization,\nlow latency and good fairness concurrently. Especially over QUIC, Iris is able\nto increase the video bitrate up to 25%, and PSNR up to 1dB.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:39:43 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 01:49:09 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Dai", "Tongyu", ""], ["Zhang", "Xinggong", ""], ["Zhang", "Yihang", ""], ["Guo", "Zongming", ""]]}, {"id": "1905.06020", "submitter": "Siddhartha Borkotoky", "authors": "Siddhartha Borkotoky, Udo Schilcher, Christian Bettstetter", "title": "Cooperative Relaying in LoRa Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a communication scheme with relays to improve the reliability of a\nLong Range (LoRa) sensor network with duty-cycle limitations. The relays\noverhear the sensors' transmissions and forward them to a gateway. Simulations\nshow that relaying is very beneficial, even though the nodes are not\ncoordinated and duty cycling limits the number of sensor measurements that can\nbe forwarded. In our setup, a single relay can halve the measurement loss rate\nand eight relays provide a gain of up to two orders of magnitude. Further\nimprovements are achieved by including a few past measurements in each frame.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 08:19:32 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 02:17:45 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Borkotoky", "Siddhartha", ""], ["Schilcher", "Udo", ""], ["Bettstetter", "Christian", ""]]}, {"id": "1905.06205", "submitter": "Alexandru-Sabin Bana", "authors": "Alexandru-Sabin Bana, Elisabeth de Carvalho, Beatriz Soret, Taufik\n  Abr\\~ao, Jos\\'e Carlos Marinello, Erik G. Larsson, and Petar Popovski", "title": "Massive MIMO for Internet of Things (IoT) Connectivity", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive MIMO is considered to be one of the key technologies in the emerging\n5G systems, but also a concept applicable to other wireless systems. Exploiting\nthe large number of degrees of freedom (DoFs) of massive MIMO essential for\nachieving high spectral efficiency, high data rates and extreme spatial\nmultiplexing of densely distributed users. On the one hand, the benefits of\napplying massive MIMO for broadband communication are well known and there has\nbeen a large body of research on designing communication schemes to support\nhigh rates. On the other hand, using massive MIMO for Internet-of-Things (IoT)\nis still a developing topic, as IoT connectivity has requirements and\nconstraints that are significantly different from the broadband connections. In\nthis paper we investigate the applicability of massive MIMO to IoT\nconnectivity. Specifically, we treat the two generic types of IoT connections\nenvisioned in 5G: massive machine-type communication (mMTC) and ultra-reliable\nlow-latency communication (URLLC). This paper fills this important gap by\nidentifying the opportunities and challenges in exploiting massive MIMO for IoT\nconnectivity. We provide insights into the trade-offs that emerge when massive\nMIMO is applied to mMTC or URLLC and present a number of suitable communication\nschemes. The discussion continues to the questions of network slicing of the\nwireless resources and the use of massive MIMO to simultaneously support IoT\nconnections with very heterogeneous requirements. The main conclusion is that\nmassive MIMO can bring benefits to the scenarios with IoT connectivity, but it\nrequires tight integration of the physical-layer techniques with the protocol\ndesign.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:23:13 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Bana", "Alexandru-Sabin", ""], ["de Carvalho", "Elisabeth", ""], ["Soret", "Beatriz", ""], ["Abr\u00e3o", "Taufik", ""], ["Marinello", "Jos\u00e9 Carlos", ""], ["Larsson", "Erik G.", ""], ["Popovski", "Petar", ""]]}, {"id": "1905.06641", "submitter": "Lumin Liu", "authors": "Lumin Liu, Jun Zhang, S. H. Song, Khaled B. Letaief", "title": "Client-Edge-Cloud Hierarchical Federated Learning", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a collaborative machine learning framework to train a\ndeep learning model without accessing clients' private data. Previous works\nassume one central parameter server either at the cloud or at the edge. The\ncloud server can access more data but with excessive communication overhead and\nlong latency, while the edge server enjoys more efficient communications with\nthe clients. To combine their advantages, we propose a client-edge-cloud\nhierarchical Federated Learning system, supported with a HierFAVG algorithm\nthat allows multiple edge servers to perform partial model aggregation. In this\nway, the model can be trained faster and better communication-computation\ntrade-offs can be achieved. Convergence analysis is provided for HierFAVG and\nthe effects of key parameters are also investigated, which lead to qualitative\ndesign guidelines. Empirical experiments verify the analysis and demonstrate\nthe benefits of this hierarchical architecture in different data distribution\nscenarios. Particularly, it is shown that by introducing the intermediate edge\nservers, the model training time and the energy consumption of the end devices\ncan be simultaneously reduced compared to cloud-based Federated Learning.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:23:36 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 14:45:01 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Liu", "Lumin", ""], ["Zhang", "Jun", ""], ["Song", "S. H.", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "1905.06650", "submitter": "Rui-Xiao Zhang", "authors": "Rui-Xiao Zhang, Tianchi Huang, Chenglei Wu, Lifeng Sun", "title": "Reactive Video Caching via long-short-term fusion approach", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video caching has been a basic network functionality in today's network\narchitectures. Although the abundance of caching replacement algorithms has\nbeen proposed recently, these methods all suffer from a key limitation: due to\ntheir immature rules, inaccurate feature engineering or unresponsive model\nupdate, they cannot strike a balance between the long-term history and\nshort-term sudden events. To address this concern, we propose LA-E2, a\nlong-short-term fusion caching replacement approach, which is based on a\nlearning-aided exploration-exploitation process. Specifically, by effectively\ncombining the deep neural network (DNN) based prediction with the online\nexploitation-exploration process through a \\emph{top-k} method, LA-E2 can both\nmake use of the historical information and adapt to the constantly changing\npopularity responsively. Through the extensive experiments in two real-world\ndatasets, we show that LA-E2 can achieve state-of-the-art performance and\ngeneralize well. Especially when the cache size is small, our approach can\noutperform the baselines by 17.5\\%-68.7\\% higher in total hit rate.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:45:06 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Zhang", "Rui-Xiao", ""], ["Huang", "Tianchi", ""], ["Wu", "Chenglei", ""], ["Sun", "Lifeng", ""]]}, {"id": "1905.06685", "submitter": "Steffen Haas", "authors": "Steffen Haas, Florian Wilkens, Mathias Fischer", "title": "Efficient Attack Correlation and Identification of Attack Scenarios\n  based on Network-Motifs", "comments": "S. Haas, F. Wilkens and M. Fischer, \"Efficient Attack Correlation and\n  Identification of Attack Scenarios based on Network-Motifs,\" 2019 IEEE 38th\n  International Performance Computing and Communications Conference (IPCCC),\n  London, United Kingdom, 2019, pp. 1-11. doi: 10.1109/IPCCC47392.2019.8958734", "journal-ref": "2019 IEEE 38th International Performance Computing and\n  Communications Conference (IPCCC), London, United Kingdom, 2019, pp. 1-11", "doi": "10.1109/IPCCC47392.2019.8958734", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Intrusion Detection System (IDS) to secure computer networks reports\nindicators for an attack as alerts. However, every attack can result in a\nmultitude of IDS alerts that need to be correlated to see the full picture of\nthe attack. In this paper, we present a correlation approach that transforms\nclusters of alerts into a graph structure on which we compute signatures of\nnetwork motifs to characterize these clusters. A motif representation of attack\ncharacteristics is magnitudes smaller than the original alert data, but still\nallows to efficiently compare and correlate attacks with each other and with\nreference signatures. This allows not only to identify known attack scenarios,\ne.g., DDoS, scan, and worm attacks, but also to derive new reference signatures\nfor unknown scenarios. Our results indicate a reliable identification of\nscenarios, even when attacks differ in size and at least slightly in their\ncharacteristics. Applied on real-world alert data, our approach can classify\nand assign attack scenarios of up to 96% of all attacks and can represent their\ncharacteristics using 1% of the size of the full alert data.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 12:23:51 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 08:47:54 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Haas", "Steffen", ""], ["Wilkens", "Florian", ""], ["Fischer", "Mathias", ""]]}, {"id": "1905.06809", "submitter": "Edoardo Longo Mr.", "authors": "Paolo Galluzzi, Edoardo Longo, Alessandro E. C. Redondi, Matteo Cesana", "title": "Occupancy Estimation Using Low-Cost Wi-Fi Sniffers", "comments": "Submitted to Balkancom 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time measurements on the occupancy status of indoor and outdoor spaces\ncan be exploited in many scenarios (HVAC and lighting system control, building\nenergy optimization, allocation and reservation of spaces, etc.). Traditional\nsystems for occupancy estimation rely on environmental sensors (CO2,\ntemperature, humidity) or video cameras. In this paper, we depart from such\ntraditional approaches and propose a novel occupancy estimation system which is\nbased on the capture of Wi-Fi management packets from users' devices. The\nsystem, implemented on a low-cost ESP8266 microcontroller, leverages a\nsupervised learning model to adapt to different spaces and transmits occupancy\ninformation through the MQTT protocol to a web-based dashboard. Experimental\nresults demonstrate the validity of the proposed solution in four different\nindoor university spaces.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 14:50:28 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Galluzzi", "Paolo", ""], ["Longo", "Edoardo", ""], ["Redondi", "Alessandro E. C.", ""], ["Cesana", "Matteo", ""]]}, {"id": "1905.07020", "submitter": "Igor Kadota", "authors": "Igor Kadota and Eytan Modiano", "title": "Minimizing the Age of Information in Wireless Networks with Stochastic\n  Arrivals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a wireless network with a base station serving multiple traffic\nstreams to different destinations. Packets from each stream arrive to the base\nstation according to a stochastic process and are enqueued in a separate (per\nstream) queue. The queueing discipline controls which packet within each queue\nis available for transmission. The base station decides, at every time t, which\nstream to serve to the corresponding destination. The goal of scheduling\ndecisions is to keep the information at the destinations fresh. Information\nfreshness is captured by the Age of Information (AoI) metric.\n  In this paper, we derive a lower bound on the AoI performance achievable by\nany given network operating under any queueing discipline. Then, we consider\nthree common queueing disciplines and develop both an Optimal Stationary\nRandomized policy and a Max-Weight policy under each discipline. Our approach\nallows us to evaluate the combined impact of the stochastic arrivals, queueing\ndiscipline and scheduling policy on AoI. We evaluate the AoI performance both\nanalytically and using simulations. Numerical results show that the performance\nof the Max-Weight policy is close to the analytical lower bound.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:15:36 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Kadota", "Igor", ""], ["Modiano", "Eytan", ""]]}, {"id": "1905.07125", "submitter": "Kaifeng Han", "authors": "Kaifeng Han, Seung-Woo Ko, Seungmin Lee, Woo-Suk Ko, and Kaibin Huang", "title": "Joint Frequency-and-Phase Modulation for Backscatter-Tag Assisted\n  Vehicular Positioning", "comments": "5 pages, to appear in Proc. of IEEE SPAWC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving (auto-driving) has been becoming a killer technology for\nnext generation vehicles, whereas some fatal accidents grow concerns about its\nsafety. A fundamental function for safer auto-driving is to recognize the\nvehicles' locations, termed vehicular positioning. The state-of-the-art\nvehicular positioning is to rely on anchors that are stationary objects whose\nlocations are known, i.e. satellites for GPS and base stations for cellular\npositioning. It is important for reliable positioning to install anchors\ndensely, helping find enough anchors nearby. For the deployment to be\ncost-effective, there are some trials to use backscatter tags as alternative\nanchors by deploying them on a road surface, but its gain is limited by several\nreasons such as short contact time and difficulties in maintenance. Instead, we\npropose a new backscatter-tag assisted vehicular positioning system where tags\nare deployed along a roadside, which enables the extension of contact duration\nand facilitates the maintenance. On the other hand, there is a location\nmismatch between the vehicle and the tag, calling for developing a new\nbackscatter transmission to estimate their relative position. To this end, we\ndesign a novel waveform called joint frequency-and-phase modulation (JFPM) for\nbackscatter-tag assisted vehicular positioning where a transmit frequency is\nmodulated for the distance estimation assuming that the relevant signal is\nclearly differentiable from the others while the phase modulation helps the\ndifferentiation. The JFPM waveform leads to exploiting the maximum\nDegree-of-Freedoms (DoFs) of backscatter channel in which multiple-access and\nbroadcasting channels coexist, leading to more accurate positioning verified by\nextensive simulations.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 06:19:16 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Han", "Kaifeng", ""], ["Ko", "Seung-Woo", ""], ["Lee", "Seungmin", ""], ["Ko", "Woo-Suk", ""], ["Huang", "Kaibin", ""]]}, {"id": "1905.07137", "submitter": "Mohamed Faten Zhani", "authors": "Mohamed Faten Zhani and Hesham ElBakoury", "title": "FlexNGIA: A Flexible Internet Architecture for the Next-Generation\n  Tactile Internet", "comments": "35 pages, 14 figures", "journal-ref": "Journal of Network and Systems Management (Spinger), 2020", "doi": "10.1007/s10922-020-09525-0", "report-no": null, "categories": "cs.NI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From virtual reality and telepresence, to augmented reality, holoportation,\nand remotely controlled robotics, these future network applications promise an\nunprecedented development for society, economics and culture by revolutionizing\nthe way we live, learn, work and play. In order to deploy such futuristic\napplications and to cater to their performance requirements, recent trends\nstressed the need for the Tactile Internet, an Internet that, according to the\nInternational Telecommunication Union, combines ultra low latency with\nextremely high availability, reliability and security. Unfortunately, today's\nInternet falls short when it comes to providing such stringent requirements due\nto several fundamental limitations in the design of the current network\narchitecture and communication protocols. This brings the need to rethink the\nnetwork architecture and protocols, and efficiently harness recent\ntechnological advances in terms of virtualization and network softwarization to\ndesign the Tactile Internet of the future.\n  In this paper, we start by analyzing the characteristics and requirements of\nfuture networking applications. We then highlight the limitations of the\ntraditional network architecture and protocols and their inability to cater to\nthese requirements. Afterward, we put forward a novel network architecture\nadapted to the Tactile Internet called FlexNGIA, a Flexible Next-Generation\nInternet Architecture. We then describe some use-cases where we discuss the\npotential mechanisms and control loops that could be offered by FlexNGIA in\norder to ensure the required performance and reliability guarantees for future\napplications. Finally, we identify the key research challenges to further\ndevelop FlexNGIA towards a full-fledged architecture for the future Tactile\nInternet.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:24:51 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 23:57:56 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Zhani", "Mohamed Faten", ""], ["ElBakoury", "Hesham", ""]]}, {"id": "1905.07144", "submitter": "Shotaro Kamiya", "authors": "Kota Nakashima, Shotaro Kamiya, Kazuki Ohtsu, Koji Yamamoto, Takayuki\n  Nishio, Masahiro Morikura", "title": "Deep Reinforcement Learning-Based Channel Allocation for Wireless LANs\n  with Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Last year, IEEE 802.11 Extremely High Throughput Study Group (EHT Study\nGroup) was established to initiate discussions on new IEEE 802.11 features.\nCoordinated control methods of the access points (APs) in the wireless local\narea networks (WLANs) are discussed in EHT Study Group. The present study\nproposes a deep reinforcement learning-based channel allocation scheme using\ngraph convolutional networks (GCNs). As a deep reinforcement learning method,\nwe use a well-known method double deep Q-network. In densely deployed WLANs,\nthe number of the available topologies of APs is extremely high, and thus we\nextract the features of the topological structures based on GCNs. We apply GCNs\nto a contention graph where APs within their carrier sensing ranges are\nconnected to extract the features of carrier sensing relationships.\nAdditionally, to improve the learning speed especially in an early stage of\nlearning, we employ a game theory-based method to collect the training data\nindependently of the neural network model. The simulation results indicate that\nthe proposed method can appropriately control the channels when compared to\nextant methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:36:21 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Nakashima", "Kota", ""], ["Kamiya", "Shotaro", ""], ["Ohtsu", "Kazuki", ""], ["Yamamoto", "Koji", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""]]}, {"id": "1905.07152", "submitter": "Jan R\\\"uth", "authors": "Jan R\\\"uth and Ike Kunze and Oliver Hohlfeld", "title": "An Empirical View on Content Provider Fairness", "comments": "Network Traffic Measurement and Analysis Conference (TMA), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Congestion control is an indispensable component of transport protocols to\nprevent congestion collapse. As such, it distributes the available bandwidth\namong all competing flows, ideally in a fair manner. However, there exists a\nconstantly evolving set of congestion control algorithms, each addressing\ndifferent performance needs and providing the potential for custom\nparametrizations. In particular, content providers such as CDNs are known to\ntune TCP stacks for performance gains. In this paper, we thus empirically\ninvestigate if current Internet traffic generated by content providers still\nadheres to the conventional understanding of fairness. Our study compares\nfairness properties of testbed hosts to actual traffic of six major content\nproviders subject to different bandwidths, RTTs, queue sizes, and queueing\ndisciplines in a home-user setting. We find that some employed congestion\ncontrol algorithms lead to significantly asymmetric bandwidth shares, however,\nAQMs such as FQ_CoDel are able to alleviate such unfairness.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:55:37 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["R\u00fcth", "Jan", ""], ["Kunze", "Ike", ""], ["Hohlfeld", "Oliver", ""]]}, {"id": "1905.07339", "submitter": "Hang Zou", "authors": "Hang Zou, Chao Zhang, Samson Lasaulce, Lucas Saludjian and Patrick\n  Panciatici", "title": "Decision-Oriented Communications: Application to Energy-Efficient\n  Resource Allocation", "comments": null, "journal-ref": "WINCOM2018", "doi": "10.1109/WINCOM.2018.8629632", "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we introduce the problem of decision-oriented communications,\nthat is, the goal of the source is to send the right amount of information in\norder for the intended destination to execute a task. More specifically, we\nrestrict our attention to how the source should quantize information so that\nthe destination can maximize a utility function which represents the task to be\nexecuted only knowing the quantized information. For example, for utility\nfunctions under the form $u\\left(\\boldsymbol{x};\\ \\boldsymbol{g}\\right)$,\n$\\boldsymbol{x}$ might represent a decision in terms of using some radio\nresources and $\\boldsymbol{g}$ the system state which is only observed through\nits quantized version $Q(\\boldsymbol{g})$. Both in the case where the utility\nfunction is known and the case where it is only observed through its\nrealizations, we provide solutions to determine such a quantizer. We show how\nthis approach applies to energy-efficient power allocation. In particular, it\nis seen that quantizing the state very roughly is perfectly suited to\nsum-rate-type function maximization, whereas energy-efficiency metrics are more\nsensitive to imperfections.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 15:55:07 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Zou", "Hang", ""], ["Zhang", "Chao", ""], ["Lasaulce", "Samson", ""], ["Saludjian", "Lucas", ""], ["Panciatici", "Patrick", ""]]}, {"id": "1905.07479", "submitter": "Zehui Xiong", "authors": "Jiawen Kang, Zehui Xiong, Dusit Niyato, Han Yu, Ying-Chang Liang, Dong\n  In Kim", "title": "Incentive Design for Efficient Federated Learning in Mobile Networks: A\n  Contract Theory Approach", "comments": "submitted to the conference for potential publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To strengthen data privacy and security, federated learning as an emerging\nmachine learning technique is proposed to enable large-scale nodes, e.g.,\nmobile devices, to distributedly train and globally share models without\nrevealing their local data. This technique can not only significantly improve\nprivacy protection for mobile devices, but also ensure good performance of the\ntrained results collectively. Currently, most the existing studies focus on\noptimizing federated learning algorithms to improve model training performance.\nHowever, incentive mechanisms to motivate the mobile devices to join model\ntraining have been largely overlooked. The mobile devices suffer from\nconsiderable overhead in terms of computation and communication during the\nfederated model training process. Without well-designed incentive,\nself-interested mobile devices will be unwilling to join federated learning\ntasks, which hinders the adoption of federated learning. To bridge this gap, in\nthis paper, we adopt the contract theory to design an effective incentive\nmechanism for simulating the mobile devices with high-quality (i.e.,\nhigh-accuracy) data to participate in federated learning. Numerical results\ndemonstrate that the proposed mechanism is efficient for federated learning\nwith improved learning accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:50:19 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 12:13:23 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Kang", "Jiawen", ""], ["Xiong", "Zehui", ""], ["Niyato", "Dusit", ""], ["Yu", "Han", ""], ["Liang", "Ying-Chang", ""], ["Kim", "Dong In", ""]]}, {"id": "1905.07486", "submitter": "Jiankang Zhang", "authors": "Jiankang Zhang, Taihai Chen, Shida Zhong, Jingjing Wang, Wenbo Zhang,\n  Xin Zuo, Robert G. Maunder, Lajos Hanzo", "title": "Aeronautical Ad Hoc Networking for the Internet-Above-The-Clouds", "comments": null, "journal-ref": "Proceedings of the IEEE ( Volume: 107 , Issue: 5 , May 2019 )", "doi": "10.1109/JPROC.2019.2909694", "report-no": null, "categories": "cs.NI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The engineering vision of relying on the ``smart sky\" for supporting air\ntraffic and the ``Internet above the clouds\" for in-flight entertainment has\nbecome imperative for the future aircraft industry. Aeronautical ad hoc\nNetworking (AANET) constitutes a compelling concept for providing broadband\ncommunications above clouds by extending the coverage of Air-to-Ground (A2G)\nnetworks to oceanic and remote airspace via autonomous and self-configured\nwireless networking amongst commercial passenger airplanes. The AANET concept\nmay be viewed as a new member of the family of Mobile ad hoc Networks (MANETs)\nin action above the clouds. However, AANETs have more dynamic topologies,\nlarger and more variable geographical network size, stricter security\nrequirements and more hostile transmission conditions. These specific\ncharacteristics lead to more grave challenges in aircraft mobility modeling,\naeronautical channel modeling and interference mitigation as well as in network\nscheduling and routing. This paper provides an overview of AANET solutions by\ncharacterizing the associated scenarios, requirements and challenges.\nExplicitly, the research addressing the key techniques of AANETs, such as their\nmobility models, network scheduling and routing, security and interference are\nreviewed. Furthermore, we also identify the remaining challenges associated\nwith developing AANETs and present their prospective solutions as well as open\nissues. The design framework of AANETs and the key technical issues are\ninvestigated along with some recent research results. Furthermore, a range of\nperformance metrics optimized in designing AANETs and a number of\nrepresentative multi-objective optimization algorithms are outlined.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 21:39:29 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhang", "Jiankang", ""], ["Chen", "Taihai", ""], ["Zhong", "Shida", ""], ["Wang", "Jingjing", ""], ["Zhang", "Wenbo", ""], ["Zuo", "Xin", ""], ["Maunder", "Robert G.", ""], ["Hanzo", "Lajos", ""]]}, {"id": "1905.07607", "submitter": "Ali Kashif Bashir", "authors": "Rajakumar Arul, Gunasekaran Raja, Ali Kashif Bashir, Junaid Chaudry,\n  and Amjad Ali", "title": "A Console GRID LA Console GRID Leveraged Authentication and Key\n  Agreement Mechanism for LTE/SAE", "comments": "12 pages, 11 figures,", "journal-ref": "IEEE Transactions on Industrial Informatics, 2017", "doi": "10.1109/TII.2018.2817028", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing popularity of multimedia applications, pervasive connectivity,\nhigher bandwidth, and euphoric technology penetration among the bulk of the\nhuman race that happens to be cellular technology users, has fueled the\nadaptation to Long Term Evolution (LTE)/ System Architecture Evolution (SAE).\nThe LTE fulfills the resource demands of the next generation applications for\nnow. We identify security issues in the authentication mechanism used in LTE\nthat without countermeasures might give superuser rights to unauthorized users.\nThe LTE uses static LTE Key (LTE-K) to derive the entire key hierarchy such as\nLTE follows Evolved Packet System-Authentication and Key Agreement (EPS-AKA)\nbased authentication which discloses user identity, location, and other\nPersonally Identifiable Information (PII). To counter this, we propose a public\nkey cryptosystem named International mobile subscriber identity Protected\nConsole Grid-based Authentication and Key Agreement (IPG-AKA) protocol to\naddress the vulnerabilities related to weak key management. From the data\nobtained from threat modeling and simulation results, we claim that the IPG-AKA\nscheme not only improves the security of authentication procedures, it also\nshows improvements in authentication loads and reduction in key generation\ntime. The empirical results and qualitative analysis presented in this paper\nproves that IPG-AKA improves security in authentication procedure and\nperformance in the LTE.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 15:58:25 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Arul", "Rajakumar", ""], ["Raja", "Gunasekaran", ""], ["Bashir", "Ali Kashif", ""], ["Chaudry", "Junaid", ""], ["Ali", "Amjad", ""]]}, {"id": "1905.07617", "submitter": "Thomas Byrd", "authors": "Thomas Byrd and Vuk Marojevic, Roger Piqueras Jover", "title": "CSAI: Open-Source Cellular Radio Access Network Security Analysis\n  Instrument", "comments": "6 pages, 6 figures, Submitted to IEEE GLOBECOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our methodology and toolbox that allows analyzing the\nradio access network security of laboratory and commercial 4G and future 5G\ncellular networks. We leverage a free open-source software suite that\nimplements the LTE UE and eNB enabling real-time signaling using software radio\nperipherals. We modify the UE software processing stack to act as an LTE packet\ncollection and examination tool. This is possible because of the openness of\nthe 3GPP specifications. Hence, we are able to receive and decode LTE downlink\nmessages for the purpose of analyzing potential security problems of the\nstandard. This paper shows how to rapidly prototype LTE tools and build a\nsoftware-defined radio access network (RAN) analysis instrument for research\nand education. Using CSAI, the Cellular RAN Security Analysis Instrument, a\nresearcher can analyze broadcast and paging messages of cellular networks. CSAI\nis also able to test networks to aid in the identification of vulnerabilities\nand verify functionality post-remediation. Additionally, we found that it can\ncrash an eNB which motivates equivalent analyses of commercial network\nequipment and its robustness against denial of service attacks.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 17:42:42 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Byrd", "Thomas", ""], ["Marojevic", "Vuk", ""], ["Jover", "Roger Piqueras", ""]]}, {"id": "1905.07641", "submitter": "George Kesidis", "authors": "George Kesidis, Nader Alfares, Xi Li, Bhuvan Urgaonkar, Mahmut\n  Kandemir, Takis Konstantopoulos", "title": "On a caching system with object sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a content-caching system thatis shared by a number of proxies.\nThe cache could belocated in an edge-cloud datacenter and the proxies couldeach\nserve a large population of mobile end-users. Eachproxy operates its own\nLRU-list of a certain capacity inthe shared cache. The length of objects\nsimultaneouslyappearing in plural LRU-lists is equally divided amongthem,i.e.,\nobject sharing among the LRUs. We provide a \"working-set\" approximation for\nthis system to quicklyestimate the cache-hit probabilities under such\nobjectsharing, which can be used to facilitate admission control.Also, a way to\nreduce ripple evictions,i.e.,setrequestoverhead, is suggested. We give\nnumerical results for ourMemCacheD with Object Sharing (MCD-OS) prototype.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 20:16:02 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 15:39:14 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Kesidis", "George", ""], ["Alfares", "Nader", ""], ["Li", "Xi", ""], ["Urgaonkar", "Bhuvan", ""], ["Kandemir", "Mahmut", ""], ["Konstantopoulos", "Takis", ""]]}, {"id": "1905.07673", "submitter": "Jared Smith", "authors": "Tyler McDaniel, Jared M. Smith, Max Schuchard", "title": "The Maestro Attack: Orchestrating Malicious Flows with BGP", "comments": "In-submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Maestro attack, a novel Link Flooding Attack (LFA) that\nleverages control-plane traffic engineering techniques to concentrate\nbotnet-sourced Distributed Denial of Service flows on transit links. Executed\nfrom a compromised or malicious Autonomous System (AS), Maestro advertises\nspecific-prefix routes poisoned for selected ASes to collapse inbound traffic\npaths onto a single target link. A greedy heuristic fed by publicly available\nAS relationship data iteratively builds the set of ASes to poison. Given a\ncompromised BGP speaker with advantageous positioning relative to the target\nlink in the Internet topology, an adversary can expect to enhance total flow\ndensity by more than 30%. For a large botnet (e.g., Mirai), that translates to\naugmenting a DDoS by more than a million additional infected hosts.\nInterestingly, the size of the adversary-controlled AS plays little role in\nthis amplification effect. Devastating attacks on core links can be executed by\nsmall, resource-limited ASes. To understand the scope of the attack, we\nevaluate widespread Internet link vulnerability across several metrics,\nincluding BGP betweenness and botnet flow density. We then assess where an\nadversary must be positioned to execute the attack most successfully. Finally,\nwe present effective mitigations for network operators seeking to insulate\nthemselves from this attack.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 02:17:13 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["McDaniel", "Tyler", ""], ["Smith", "Jared M.", ""], ["Schuchard", "Max", ""]]}, {"id": "1905.08089", "submitter": "Martine Sophie Lenders", "authors": "Martine S. Lenders, Thomas C. Schmidt, Matthias W\\\"ahlisch", "title": "A Lesson in Scaling 6LoWPAN -- Minimal Fragment Forwarding in Lossy\n  Networks", "comments": "If you cite this paper, please use the LCN reference: M. S. Lenders,\n  T. C. Schmidt, M. W\\\"ahlisch. \"A Lesson in Scaling 6LoWPAN - Minimal Fragment\n  Forwarding in Lossy Networks.\" in Proc. of IEEE LCN, 2019", "journal-ref": "Proceedings of IEEE LCN 2019", "doi": "10.1109/LCN44214.2019.8990812", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper evaluates two forwarding strategies for fragmented datagrams in\nthe IoT: hop-wise reassembly and a minimal approach to directly forward\nfragments. Minimal fragment forwarding is challenged by the lack of forwarding\ninformation at subsequent fragments in 6LoWPAN and thus requires additional\ndata at nodes. We compared the two approaches in extensive experiments\nevaluating reliability, end-to-end latency, and memory consumption. In contrast\nto previous work and due to our alternate setup, we obtained different results\nand conclusions. Our findings indicate that direct fragment forwarding should\nbe deployed only with care, since higher packet transmission rates on the\nlink-layer can significantly reduce its reliability, which in turn can even\nfurther reduce end-to-end latency because of highly increased link-layer\nretransmissions.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:18:05 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 10:35:11 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Lenders", "Martine S.", ""], ["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "1905.08130", "submitter": "Salvatore D'Oro", "authors": "Salvatore D'Oro, Francesco Restuccia, and Tommaso Melodia", "title": "Toward Operator-to-Waveform 5G Radio Access Network Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio access network (RAN) slicing realizes a vision where physical network\nresources that belong to a specific infrastructure provider can be shared among\nmultiple mobile network operators (MNOs). Existing work in this area has\naddressed RAN slicing at different levels of network abstractions, but has\noften neglected the multitude of tightly intertwined inter-level operations\ninvolved in real-world slicing systems. For this reason, this article discusses\na novel framework for operator-to-waveform 5G RAN slicing. In the proposed\nframework, slicing operations are treated holistically, including MNO's\nselection of base stations (BSs) and maximum number of users, down to the\nwaveform-level scheduling of resource blocks. Experimental results show that\nthe proposed framework provides up to 150% improvement in terms of number of\nresource blocks that can be used to enable 5G transmission technologies that\nrequire coordination and synchronization among BSs.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 14:12:24 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["D'Oro", "Salvatore", ""], ["Restuccia", "Francesco", ""], ["Melodia", "Tommaso", ""]]}, {"id": "1905.08237", "submitter": "Nikolaos Pappas", "authors": "Nikolaos Pappas and Marios Kountouris", "title": "Delay Violation Probability and Age of Information Interplay in the\n  Two-user Multiple Access Channel", "comments": "IEEE SPAWC 2019 Special Session on Ultra-Reliable Low-Latency\n  Communications. arXiv admin note: text overlap with arXiv:1903.05066", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the interplay between delay violation probability and\naverage Age of Information (AoI) in a two-user wireless multiple access channel\nwith multipacket reception (MPR) capability. We consider a system in which\nusers have heterogeneous traffic characteristics: one has stringent delay\nconstraints, while the other measures a source and transmits status updates in\norder to keep the AoI low. We show the effect of sensor sampling rate on the\ndelay violation probability and that of the service rate of the delay-sensitive\nuser on information freshness.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 17:16:10 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Pappas", "Nikolaos", ""], ["Kountouris", "Marios", ""]]}, {"id": "1905.08295", "submitter": "Yavuz Yaman", "authors": "Yavuz Yaman, Predrag Spasojevic", "title": "An Intra-Cluster Model with Diffuse Scattering for mmWave\n  Communications: RT-ICM", "comments": "12 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In millimeter-wave (mmWave) channels, to overcome the high path loss,\nbeamforming is required. Hence, the spatial representation of the channel is\nessential. Further, for accurate beam alignment and minimizing the outages,\ninter-beam interferences, etc., cluster-level spatial modeling is also\nnecessary. Since, statistical channel models fail to reproduce the\nintra-cluster parameters due to the site-specific nature of the mmWave channel,\nin this paper, we propose a ray tracing intra-cluster model (RT-ICM) for mmWave\nchannels. The model considers only the first-order reflection; thereby reducing\nthe computation load while capturing most of the energy in a large number of\nimportant cases. The model accounts for diffuse scattering as it contributes\nsignificantly to the received power. Finally, since the clusters are spatially\nwell-separated due to the sparsity of first-order reflectors, we generalize the\nintra-cluster model to the mmWave channel model via replication. Since narrow\nbeamwidth increases the number of single-order clusters, we show that the\nproposed model suits well to MIMO and massive MIMO applications. We illustrate\nthat the model gives matching results with published measurements made in a\nclassroom at 60 GHz. For this specific implementation, while the maximum\ncluster angle of arrival (AoA) error is 1 degree, mean angle spread error is 9\ndegrees. The RMS error for the cluster peak power is found to be 2.2 dB.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 18:56:17 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Yaman", "Yavuz", ""], ["Spasojevic", "Predrag", ""]]}, {"id": "1905.08339", "submitter": "Chen Avin", "authors": "Chen Avin and Manya Ghobadi and Chen Griner and Stefan Schmid", "title": "Measuring the Complexity of Packet Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the structure of several real-world traces (including\nFacebook, High-Performance Computing, Machine Learning, and simulation\ngenerated traces) and presents a systematic approach to quantify and compare\nthe structure of packet traces based on the entropy contained in the trace\nfile. Insights into the structure of packet traces can lead to improved network\nalgorithms that are optimized toward specific traffic patterns. We then present\na methodology to quantify the temporal and non-temporal components of entropy\ncontained in a packet trace, called the trace complexity, using randomization\nand compression. We show that trace complexity provides unique insights into\nthe characteristics of various applications and argue that there is a need for\ntraffic generation models that preserve the intrinsic structure of empirically\nmeasured application traces. We then propose a traffic generator model that is\nable to produce a synthetic trace that matches the complexity level of its\ncorresponding real-world trace.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 20:45:15 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Avin", "Chen", ""], ["Ghobadi", "Manya", ""], ["Griner", "Chen", ""], ["Schmid", "Stefan", ""]]}, {"id": "1905.08478", "submitter": "Martin Reisslein", "authors": "Ahmed Nasrallah and Venkatraman Balasubramanian and Akhilesh\n  Thyagaturu and Martin Reisslein and Hesham ElBakoury", "title": "TSN Algorithms for Large Scale Networks: A Survey and Conceptual\n  Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a comprehensive survey of queueing and scheduling\nmechanisms for supporting large scale deterministic networks (LDNs). The survey\nfinds that extensive mechanism design research and standards development for\nLDNs has been conducted over the past few years. However, these mechanism\ndesign studies have not been followed up with a comprehensive rigorous\nevaluation. The main outcome of this survey is a clear organization of the\nvarious research and standardization efforts towards queueing and scheduling\nmechanisms for LDNs as well as the identification of the main strands of\nmechanism development and their interdependencies. Based on this survey, it\nappears urgent to conduct a comprehensive rigorous simulation study of the main\nstrands of mechanisms.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:11:54 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 08:08:01 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Nasrallah", "Ahmed", ""], ["Balasubramanian", "Venkatraman", ""], ["Thyagaturu", "Akhilesh", ""], ["Reisslein", "Martin", ""], ["ElBakoury", "Hesham", ""]]}, {"id": "1905.08765", "submitter": "Tiejun Lv", "authors": "Xuewei Zhang, Tiejun Lv, Yuan Ren, Wei Ni, Norman C. Beaulieu, and Y.\n  Jay Guo", "title": "Economical Caching for Scalable Videos in Cache-enabled Heterogeneous\n  Networks", "comments": "IEEE Journal on Selected Areas in Communications, Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the optimal economical caching schemes in cache-enabled\nheterogeneous networks, while delivering multimedia video services with\npersonalized viewing qualities to mobile users. By applying scalable video\ncoding (SVC), each video file to be requested is divided into one base layer\n(BL) and several enhancement layers (ELs). In order to assign different\ntransmission tasks, the serving small-cell base stations (SBSs) are grouped\ninto K clusters. The SBSs are able to cache and cooperatively transmit BL and\nEL contents to the user. We analytically derive the expressions for successful\ntransmission probability and ergodic service rate, and then the closed form of\nEConomical Efficiency (ECE) is obtained. In order to enhance the ECE\nperformance, we formulate the ECE optimization problems for two cases. In the\nfirst case, with equal cache size equipped at each SBS, the layer caching\nindicator is determined. Since this problem is NP-hard, after the l0-norm\napproximation, the discrete optimization variables are relaxed to be\ncontinuous, and this relaxed problem is convex. Next, based on the optimal\nsolution derived from the relaxed problem, we devise a greedystrategy based\nheuristic algorithm to achieve the near-optimal layer caching indicators. In\nthe second case, the cache size for each SBS, the layer size and the layer\ncaching indicator are jointly optimized. This problem is a mixed integer\nprogramming problem, which is more challenging. To effectively solve this\nproblem, the original ECE maximization problem is divided into two subproblems.\nThese two subproblems are iteratively solved until the original optimization\nproblem is convergent. Numerical results verify the correctness of theoretical\nderivations. Additionally, compared to the most popular layer placement\nstrategy, the performance superiority of the proposed SVC-based caching schemes\nis testified.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 10:32:19 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Zhang", "Xuewei", ""], ["Lv", "Tiejun", ""], ["Ren", "Yuan", ""], ["Ni", "Wei", ""], ["Beaulieu", "Norman C.", ""], ["Guo", "Y. Jay", ""]]}, {"id": "1905.08767", "submitter": "Panagiotis Papadopoulos", "authors": "Jordan Jueckstock, Shaown Sarker, Peter Snyder, Panagiotis\n  Papadopoulos, Matteo Varvello, Benjamin Livshits, Alexandros Kapravelos", "title": "The Blind Men and the Internet: Multi-Vantage Point Web Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design and deploy a synchronized multi-vantage point web\nmeasurement study to explore the comparability of web measurements across\nvantage points (VPs). We describe in reproducible detail the system with which\nwe performed synchronized crawls on the Alexa top 5K domains from four distinct\nnetwork VPs: research university, cloud datacenter, residential network, and\nTor gateway proxy. Apart from the expected poor results from Tor, we observed\nno shocking disparities across VPs, but we did find significant impact from the\nresidential VP's reliability and performance disadvantages. We also found\nsubtle but distinct indicators that some third-party content consistently\navoided crawls from our cloud VP. In summary, we infer that cloud VPs do fail\nto observe some content of interest to security and privacy researchers, who\nshould consider augmenting cloud VPs with alternate VPs for cross-validation.\nOur results also imply that the added visibility provided by residential VPs\nover university VPs is marginal compared to the infrastructure complexity and\nnetwork fragility they introduce.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:37:55 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Jueckstock", "Jordan", ""], ["Sarker", "Shaown", ""], ["Snyder", "Peter", ""], ["Papadopoulos", "Panagiotis", ""], ["Varvello", "Matteo", ""], ["Livshits", "Benjamin", ""], ["Kapravelos", "Alexandros", ""]]}, {"id": "1905.08773", "submitter": "Issam Damaj", "authors": "Marwa Kandil (1), Reem AlBaghdadi (1), Fatemah AlAttar (1), Issam\n  Damaj (2) ((1) American University of Kuwait, (2) Rafik Hariri University)", "title": "AmIE: An Ambient Intelligent Environment for Assisted Living", "comments": "6 pages, 8 figures, 1 table", "journal-ref": "The 2nd Eng Innovations in Healthcare International Conference,\n  IEEE, Dubai, UAE, March 26-27, (2019) 1-6", "doi": "10.1109/ICASET.2019.8714499", "report-no": null, "categories": "cs.CY cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modern world of technology Internet-of-things (IoT) systems strives to\nprovide an extensive interconnected and automated solutions for almost every\nlife aspect. This paper proposes an IoT context-aware system to present an\nAmbient Intelligence (AmI) environment; such as an apartment, house, or a\nbuilding; to assist blind, visually-impaired, and elderly people. The proposed\nsystem aims at providing an easy-to-utilize voice-controlled system to locate,\nnavigate and assist users indoors. The main purpose of the system is to provide\nindoor positioning, assisted navigation, outside weather information, room\ntemperature, people availability, phone calls and emergency evacuation when\nneeded. The system enhances the user's awareness of the surrounding environment\nby feeding them with relevant information through a wearable device to assist\nthem. In addition, the system is voice-controlled in both English and Arabic\nlanguages and the information are displayed as audio messages in both\nlanguages. The system design, implementation, and evaluation consider the\nconstraints in common types of premises in Kuwait and in challenges, such as\nthe training needed by the users. This paper presents cost-effective\nimplementation options by the adoption of a Raspberry Pi microcomputer,\nBluetooth Low Energy devices and an Android smart watch.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 13:57:31 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Kandil", "Marwa", "", "American University of Kuwait"], ["AlBaghdadi", "Reem", "", "American University of Kuwait"], ["AlAttar", "Fatemah", "", "American University of Kuwait"], ["Damaj", "Issam", "", "Rafik Hariri University"]]}, {"id": "1905.08979", "submitter": "Inayat Ali", "authors": "Inayat Ali, Huhnkuk Lim", "title": "Anchor-Less Producer Mobility Management in Named Data Networking for\n  Real-Time Multimedia", "comments": "Mobile Information Systems, 2019", "journal-ref": null, "doi": "10.1155/2019/3531567", "report-no": null, "categories": "cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information-centric networking (ICN) is one of the promising solutions that\ncater to the challenges of IP-based networking. ICN shifts the IP-based access\nmodel to a data-centric model. Named Data Networking (NDN) is a flexible ICN\narchitecture, which is based on content distribution considering data as the\ncore entity rather than IP-based hosts. User-generated mobile contents for\nreal-time multimedia communication such as Internet telephony are very common\nthese days and are increasing both in quality and quantity. In NDN, producer\nmobility is one of the challenging problems to support uninterrupted real-time\nmultimedia communication and needs to be resolved for the adoption of NDN as\nfuture Internet architecture. We assert that mobile nodes' future location\nprediction can aid in designing efficient anchor-less mobility management\ntechniques. In this article, we show how location prediction techniques can be\nused to provide an anchor-less mobility management solution in order to ensure\nseamless handover of the producer during real-time multimedia communication.\nThe results indicate that with a low level of location prediction accuracy, our\nproposed methodology still profoundly reduces the total handover latency and\nround trip time without creating network overhead.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 06:42:14 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Ali", "Inayat", ""], ["Lim", "Huhnkuk", ""]]}, {"id": "1905.09015", "submitter": "Marco Giordani", "authors": "Marco Giordani, Takamasa Higuchi, Andrea Zanella, Onur Altintas,\n  Michele Zorzi", "title": "A Framework to Assess Value of Information in Future Vehicular Networks", "comments": "6 pages, 6 figures, 2 tables, accepted for publication to the 2019\n  1st ACM Workshop on Technologies, mOdels, and Protocols for Cooperative\n  Connected Cars (TOP-Cars)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicles are becoming increasingly intelligent and connected, incorporating\nmore and more sensors to support safer and more efficient driving. The large\nvolume of data generated by such sensors, however, will likely saturate the\ncapacity of vehicular communication technologies, making it challenging to\nguarantee the required quality of service. In this perspective, it is essential\nto assess the value of information (VoI) provided by each data source, to\nprioritize the transmissions that have the greatest importance for the target\napplications. In this paper, we propose and evaluate a framework that uses\nanalytic hierarchy multicriteria decision processes to predict VoI based on\nspace, time, and quality attributes. Our results shed light on the impact of\nthe propagation scenario, the sensor resolution, the type of observation, and\nthe communication distance on the value assessment performance. In particular,\nwe show that VoI evolves at different rates as a function of the target\napplication's characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 08:30:10 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Giordani", "Marco", ""], ["Higuchi", "Takamasa", ""], ["Zanella", "Andrea", ""], ["Altintas", "Onur", ""], ["Zorzi", "Michele", ""]]}, {"id": "1905.09267", "submitter": "Ghayoor Shah", "authors": "Ghayoor Shah, Rodolfo Valiente, Nitish Gupta, S M Osman Gani, Behrad\n  Toghi, Yaser P. Fallah, Somak Datta Gupta", "title": "Real-Time Hardware-In-the-Loop Emulation Framework for DSRC-based\n  Connected Vehicle Applications", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of connected and automated vehicle (CAV) solutions have made\na significant impact on the safety of intelligent transportation systems.\nHowever, similar to any other emerging technology, thorough testing and\nevaluation studies are of paramount importance for the effectiveness of these\nsolutions. Due to the safety-critical nature of this problem, large-scale\nreal-world field tests do not seem to be a feasible and practical option. Thus,\nemploying simulation and emulation approaches are preferred in the development\nphase of the safety-related applications in CAVs. Such methodologies not only\nmitigate the high cost of deploying large number of real vehicles, but also\nenable researchers to exhaustively perform repeatable tests in various\nscenarios. Software simulation of very large-scale vehicular scenarios is\nmostly a time consuming task and as a matter of fact, any simulation\nenvironment would include abstractions in order to model the real-world system.\nIn contrast to the simulation-based solutions, network emulators are able to\nproduce more realistic test environments. In this work, we propose a\nhigh-fidelity hardware-in-the-loop network emulator framework in order to\ncreate testing environments for vehicle-to-vehicle (V2V) communication. The\nproposed architecture is able to run in real-time fashion in contrast to other\nexisting systems, which can potentially boost the development and validation of\nV2V systems.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 17:55:04 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 02:14:52 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Shah", "Ghayoor", ""], ["Valiente", "Rodolfo", ""], ["Gupta", "Nitish", ""], ["Gani", "S M Osman", ""], ["Toghi", "Behrad", ""], ["Fallah", "Yaser P.", ""], ["Gupta", "Somak Datta", ""]]}, {"id": "1905.09349", "submitter": "Soheil Abbasloo", "authors": "Soheil Abbasloo, Yang Xu, H. Jonathon Chao, Hang Shi, Ulas C. Kozat,\n  Yinghua Ye", "title": "Toward Optimal Performance with Network Assisted TCP at Mobile Edge", "comments": "To appear in USENIX's HotEdge 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast to the classic fashion for designing distributed end-to-end (e2e)\nTCP schemes for cellular networks (CN), we explore another design space by\nhaving the CN assist the task of the transport control. We show that in the\nemerging cellular architectures such as mobile/multi-access edge computing\n(MEC), where the servers are located close to the radio access network (RAN),\nsignificant improvements can be achieved by leveraging the nature of the\nlogically centralized network measurements at the RAN and passing information\nsuch as its minimum e2e delay and access link capacity to each server.\nParticularly, a Network Assistance module (located at the mobile edge) will\npair up with wireless scheduler to provide feedback information to each server\nand facilitate the task of congestion control. To that end, we present two\nNetwork Assisted schemes called NATCP (a clean-slate design replacing TCP at\nend-hosts) and NACubic (a backward compatible design requiring no change for\nTCP at end-hosts). Our preliminary evaluations using real cellular traces show\nthat both schemes dramatically outperform existing schemes both in single-flow\nand multi-flow scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 20:03:24 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Abbasloo", "Soheil", ""], ["Xu", "Yang", ""], ["Chao", "H. Jonathon", ""], ["Shi", "Hang", ""], ["Kozat", "Ulas C.", ""], ["Ye", "Yinghua", ""]]}, {"id": "1905.09555", "submitter": "Vishal Sharma", "authors": "Vishal Sharma, Ilsun You, Nadra Guizani", "title": "Security of 5G-V2X: Technologies, Standardization and Research\n  Directions", "comments": "9 pages, 6 figures, Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular-Vehicle to Everything (C-V2X) aims at resolving issues pertaining to\nthe traditional usability of Vehicle to Infrastructure (V2I) and Vehicle to\nVehicle (V2V) networking. Specifically, C-V2X lowers the number of entities\ninvolved in vehicular communications and allows the inclusion of\ncellular-security solutions to be applied to V2X. For this, the evolvement of\nLTE-V2X is revolutionary, but it fails to handle the demands of high\nthroughput, ultra-high reliability, and ultra-low latency alongside its\nsecurity mechanisms. To counter this, 5G-V2X is considered as an integral\nsolution, which not only resolves the issues related to LTE-V2X but also\nprovides a function-based network setup. Several reports have been given for\nthe security of 5G, but none of them primarily focuses on the security of\n5G-V2X. This article provides a detailed overview of 5G-V2X with a\nsecurity-based comparison to LTE-V2X. A novel Security Reflex Function\n(SRF)-based architecture is proposed and several research challenges are\npresented related to the security of 5G-V2X. Furthermore, the article lays out\nrequirements of Ultra-Dense and Ultra-Secure (UD-US) transmissions necessary\nfor 5G-V2X.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:41:17 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 07:27:45 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 08:42:41 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Sharma", "Vishal", ""], ["You", "Ilsun", ""], ["Guizani", "Nadra", ""]]}, {"id": "1905.09578", "submitter": "Hamza Khan", "authors": "Hamza Khan, Petri Luoto, Sumudu Samarakoon, Mehdi Bennis and Matti\n  Latva-Aho", "title": "Network Slicing for Vehicular Communication", "comments": "9 Pages, 10 Figures, Transactions on Emerging Telecommunications\n  Technologies", "journal-ref": null, "doi": "10.1002/ETT.3652", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-reliable vehicle-to-everything (V2X) communication is essential for\nenabling the next generation of intelligent vehicles. V2X communication is a\ngrowing area of communication, that connects vehicles to neighboring vehicles\n(V2V), infrastructure (V2I) and pedestrians (V2P). Network slicing is one of\nthe promising technology for connectivity of the next generation devices,\ncreating several logical networks on a common and programmable physical\ninfrastructure. Network slicing offers an efficient way to satisfy the diverse\nuse case requirements by exploiting the benefits of shared physical\ninfrastructure. In this regard, we propose a network slicing based\ncommunication solution for vehicular networks. In this work, we model a highway\nscenario with vehicles having heterogeneous traffic demands. The autonomous\ndriving slice (safety messages) and the infotainment slice (video stream) are\nthe two logical slices created on a common infrastructure. We formulated a\nnetwork clustering and slicing algorithm to partition the vehicles into\ndifferent clusters and allocate slice leaders to each cluster. Slice leaders\nserve its clustered vehicles with high quality V2V links and forwards safety\ninformation with low latency. On the other hand, road side unit provides\ninfotainment service using high quality V2I links. An extensive Long Term\nEvolution Advanced (LTE-A) system level simulator with enhancement of cellular\nV2X (C-V2X) standard is used to evaluate the performance of the proposed\nmethod, in which it is shown that the proposed network slicing technique\nachieves low latency and high-reliability communication.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 10:42:40 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Khan", "Hamza", ""], ["Luoto", "Petri", ""], ["Samarakoon", "Sumudu", ""], ["Bennis", "Mehdi", ""], ["Latva-Aho", "Matti", ""]]}, {"id": "1905.09771", "submitter": "Chaoyun Zhang", "authors": "Chaoyun Zhang, Marco Fiore, Paul Patras", "title": "Multi-Service Mobile Traffic Forecasting via Convolutional Long\n  Short-Term Memories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing is increasingly used to partition network infrastructure\nbetween different mobile services. Precise service-wise mobile traffic\nforecasting becomes essential in this context, as mobile operators seek to\npre-allocate resources to each slice in advance, to meet the distinct\nrequirements of individual services. This paper attacks the problem of\nmulti-service mobile traffic forecasting using a sequence-to-sequence (S2S)\nlearning paradigm and convolutional long short-term memories (ConvLSTMs). The\nproposed architecture is designed so as to effectively extract complex\nspatiotemporal features of mobile network traffic and predict with high\naccuracy the future demands for individual services at city scale. We conduct\nexperiments on a mobile traffic dataset collected in a large European\nmetropolis, demonstrating that the proposed S2S-ConvLSTM can forecast the\nmobile traffic volume produced by tens of different services in advance of up\nto one hour, by just using measurements taken during the past hour. In\nparticular, our solution achieves mean absolute errors (MAE) at antenna level\nthat are below 13KBps, outperforming other deep learning approaches by up to\n31.2%.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:50:54 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zhang", "Chaoyun", ""], ["Fiore", "Marco", ""], ["Patras", "Paul", ""]]}, {"id": "1905.10083", "submitter": "Zhi Zhou", "authors": "Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, Junshan Zhang", "title": "Edge Intelligence: Paving the Last Mile of Artificial Intelligence with\n  Edge Computing", "comments": "Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, and Junshan Zhang,\n  \"Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge\n  Computing,\" Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the breakthroughs in deep learning, the recent years have witnessed a\nbooming of artificial intelligence (AI) applications and services, spanning\nfrom personal assistant to recommendation systems to video/audio surveillance.\nMore recently, with the proliferation of mobile computing and\nInternet-of-Things (IoT), billions of mobile and IoT devices are connected to\nthe Internet, generating zillions Bytes of data at the network edge. Driving by\nthis trend, there is an urgent need to push the AI frontiers to the network\nedge so as to fully unleash the potential of the edge big data. To meet this\ndemand, edge computing, an emerging paradigm that pushes computing tasks and\nservices from the network core to the network edge, has been widely recognized\nas a promising solution. The resulted new inter-discipline, edge AI or edge\nintelligence, is beginning to receive a tremendous amount of interest. However,\nresearch on edge intelligence is still in its infancy stage, and a dedicated\nvenue for exchanging the recent advances of edge intelligence is highly desired\nby both the computer system and artificial intelligence communities. To this\nend, we conduct a comprehensive survey of the recent research efforts on edge\nintelligence. Specifically, we first review the background and motivation for\nartificial intelligence running at the network edge. We then provide an\noverview of the overarching architectures, frameworks and emerging key\ntechnologies for deep learning model towards training/inference at the network\nedge. Finally, we discuss future research opportunities on edge intelligence.\nWe believe that this survey will elicit escalating attentions, stimulate\nfruitful discussions and inspire further research ideas on edge intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:19:05 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Zhou", "Zhi", ""], ["Chen", "Xu", ""], ["Li", "En", ""], ["Zeng", "Liekang", ""], ["Luo", "Ke", ""], ["Zhang", "Junshan", ""]]}, {"id": "1905.10314", "submitter": "Ahmed Raoof", "authors": "Ahmed Raoof, Ashraf Matrawy, Chung-Horng Lung", "title": "Secure Routing in IoT: Evaluation of RPL Secure Mode under Attacks", "comments": "6 pages, 9 figures, 2 tables. Accepted at Globecom 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the Routing Protocol for Low Power and Lossy Networks (RPL) became the\nstandard for routing in the Internet of Things (IoT) networks, many researchers\nhad investigated the security aspects of this protocol. However, no work (to\nthe best of our knowledge) has investigated the use of the security mechanisms\nincluded in the protocol standard, due to the fact that there was no\nimplementation for these features in any IoT operating system yet. A partial\nimplementation of RPL security mechanisms was presented recently for Contiki\noperating system (by Perazzo et al.), which provided us with the opportunity to\nexamine RPL security mechanisms. In this paper, we investigate the effects and\nchallenges of using RPL security mechanisms under common routing attacks.\nFirst, a comparison of RPL performance, with and without its security\nmechanisms, under three routing attacks (Blackhole, Selective- Forward, and\nNeighbor attacks) is conducted using several metrics (e.g., average data packet\ndelivery rate, average data packet delay, average power consumption... etc.)\nBased on the observations from this comparison, we came with few suggestions\nthat could reduce the effects of such attacks, without having added security\nmechanisms for RPL.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 16:15:02 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 14:54:19 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Raoof", "Ahmed", ""], ["Matrawy", "Ashraf", ""], ["Lung", "Chung-Horng", ""]]}, {"id": "1905.10940", "submitter": "Huacheng Zeng", "authors": "Pedram Kheirkhah Sangdeh, Hossein Pirayesh, Adnan Quadri, Huacheng\n  Zeng", "title": "A Practical Spectrum Sharing Scheme for Cognitive Radio Networks: Design\n  and Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectrum shortage is a fundamental problem in wireless networks and this\nproblem becomes increasingly acute with the rapid proliferation of wireless\ndevices. To address this problem, spectrum sharing in the context of cognitive\nradio networks (CRNs) has been considered a promising solution. In this paper,\nwe propose a practical spectrum sharing scheme for a small CRN that comprises a\npair of primary users and a pair of secondary users by leveraging the\nmultiple-input and multiple-output (MIMO) technology. In our scheme, we assume\nthat the secondary users take full responsibility for cross-network\ninterference cancellation (IC). We also assume that the secondary users have no\nknowledge about the primary network, including its signal waveform, frame\nstructure, and network protocol. The key components of our proposed scheme are\ntwo MIMO-based interference management techniques: blind beamforming (BBF) and\nblind interference cancellation (BIC). We have built a prototype of our scheme\non a wireless testbed and demonstrated that the prototyped secondary network\ncan coexist with commercial Wi-Fi devices (primary users). Experimental results\nfurther show that, for a secondary device with two or three antennas, BBF and\nBIC achieve an average of 25dB and 33dB IC capability in an office environment,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 02:35:58 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Sangdeh", "Pedram Kheirkhah", ""], ["Pirayesh", "Hossein", ""], ["Quadri", "Adnan", ""], ["Zeng", "Huacheng", ""]]}, {"id": "1905.11023", "submitter": "Xiaochi Li", "authors": "Xiangmo Zhao, Xiaochi Li, Zhigang Xu, and Ting Chen", "title": "An Optimal Game Approach for Heterogeneous Vehicular Network Selection\n  with Varying Network Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most conventional heterogeneous network selection strategies applied in\nheterogeneous vehicular network regard the performance of each network constant\nin various traffic scenarios. This assumption leads such strategies to be\nineffective in the real-world performance-changing scenarios. To solve this\nproblem, we propose an optimal game approach for heterogeneous vehicular\nnetwork selection under conditions in which the performance parameters of some\nnetworks are changing. Terminals attempting to switch to the network with\nhigher evaluation is formulated as a multi-play non-cooperative game.\nHeterogeneous vehicular network characteristics are thoroughly accounted for to\nadjust the game strategy and adapt to the vehicular environment for stability\nand rapid convergence. A multi-play non-cooperative game model is built to\nformulate network selection. A probabilistic strategy is used to gradually\ndrive players toward convergence to prevent instability. Furthermore, a system\nprototype was built at the Connected and Automated Vehicle Test bed of Chang'an\nUniversity (CAVTest). Its corresponding test results indicate that the proposed\napproach can effectively suppress the ping-pong effect caused by massive\nhandoffs due to varying network performance and thus well outperforms the\nsingle-play strategy.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:51:52 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhao", "Xiangmo", ""], ["Li", "Xiaochi", ""], ["Xu", "Zhigang", ""], ["Chen", "Ting", ""]]}, {"id": "1905.11060", "submitter": "Jose M. Barcelo-Ordinas", "authors": "Jose M. Barcelo-Ordinas, Messaud Doudou, Jorge Garcia-Vidal, Nadjib\n  Badache", "title": "Self-Calibration Methods for Uncontrolled Environments in Sensor\n  Networks: A Reference Survey", "comments": null, "journal-ref": "Ad Hoc Networks, Volume 88, 15 May 2019, Pages 142-159", "doi": "10.1016/j.adhoc.2019.01.008", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing progress in sensor technology has constantly expanded the number and\nrange of low-cost, small, and portable sensors on the market, increasing the\nnumber and type of physical phenomena that can be measured with wirelessly\nconnected sensors. Large-scale deployments of wireless sensor networks (WSN)\ninvolving hundreds or thousands of devices and limited budgets often constrain\nthe choice of sensing hardware, which generally has reduced accuracy,\nprecision, and reliability. Therefore, it is challenging to achieve good data\nquality and maintain error-free measurements during the whole system lifetime.\nSelf-calibration or recalibration in ad hoc sensor networks to preserve data\nquality is essential, yet challenging, for several reasons, such as the\nexistence of random noise and the absence of suitable general models.\nCalibration performed in the field, without accurate and controlled\ninstrumentation, is said to be in an uncontrolled environment. This paper\nprovides current and fundamental self-calibration approaches and models for\nwireless sensor networks in uncontrolled environments.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:10:00 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Barcelo-Ordinas", "Jose M.", ""], ["Doudou", "Messaud", ""], ["Garcia-Vidal", "Jorge", ""], ["Badache", "Nadjib", ""]]}, {"id": "1905.11089", "submitter": "Cao Vien Phung", "authors": "Cao Vien Phung, Jasenka Dizdarevic, and Admela Jukan", "title": "Enhancing Block-Wise Transfer with Network Coding in CoAP", "comments": "4 pages, 2 figures, submitted to Euro-Par 2019", "journal-ref": null, "doi": "10.1007/978-3-030-48340-1_59", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CoAP (Constrained Application Protocol) with block-wise transfer (BWT) option\nis a known protocol choice for large data transfer in general lossy IoT network\nenvironments. Lossy transmission environments on the other hand lead to CoAP\nresending multiple blocks, which creates overheads. To tackle this problem, we\ndesign a BWT with network coding (NC), with the goal to reducing the number of\nunnecessary retransmissions. The results show the reduction in the number of\nblock retransmissions for different values of blocksize, implying the reduced\ntransfer time. For the maximum blocksize of 1024 bytes and total probability\nloss of 0.5, CoAP with NC can resend up to 5 times less blocks.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:55:56 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Phung", "Cao Vien", ""], ["Dizdarevic", "Jasenka", ""], ["Jukan", "Admela", ""]]}, {"id": "1905.11102", "submitter": "Pere Tuset", "authors": "Pere Tuset-Peir\\'o, Francisco V\\'azquez-Gallego, Jonathan Mu\\~noz,\n  Thomas Watteyne, Jesus Alonso-Zarate, Xavier Vilajosana", "title": "Experimental Interference Robustness Evaluation of IEEE 802.15.4-2015\n  OQPSK-DSSS and SUN-OFDM Physical Layers", "comments": "11 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we experimentally evaluate and compare the robustness against\ninterference of the OQPSK-DSSS (Offset Quadrature Phase Shift Keying - Direct\nSequence Spread Spectrum) and the SUN-OFDM (Smart Utility Network - Orthogonal\nFrequency Division Multiplexing) physical layers, as defined in the IEEE\n802.15.4-2015 standard. The objective of this study is to provide a\ncomprehensive analysis of the impact different types of interference produce on\nthese modulations, in terms of the resulting PDR (Packet Delivery Ratio) and\ndepending on the length of the packet being transmitted. The results show that\nthe SUN-OFDM physical layer provides significant benefits compared to the\nubiquitous OQPSK-DSSS in terms of interference robustness, regardless of the\ninterference type and the packet length. Overall, this demonstrates the\nsuitability of choosing the SUN-OFDM physical layer when deploying low-power\nwireless networks in industrial scenarios, specially taking into consideration\nthe possibility of trading-off robustness and spectrum efficiency depending on\nthe application requirements.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:17:06 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Tuset-Peir\u00f3", "Pere", ""], ["V\u00e1zquez-Gallego", "Francisco", ""], ["Mu\u00f1oz", "Jonathan", ""], ["Watteyne", "Thomas", ""], ["Alonso-Zarate", "Jesus", ""], ["Vilajosana", "Xavier", ""]]}, {"id": "1905.11239", "submitter": "Francesco Malandrino", "authors": "Francesco Malandrino and Carla-Fabiana Chiasserini and Giada Landi", "title": "Service Shifting: a Paradigm for Service Resilience in 5G", "comments": "IEEE Communications Magazine. arXiv admin note: substantial text\n  overlap with arXiv:1902.06317", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world services can be provided through multiple virtual network\nfunction (VNF) graphs, corresponding, e.g., to high- and low-complexity\nvariants of the service itself. Based on this observation, we extend the\nconcept of service scaling in network orchestration to service shifting, i.e.,\nupgrading or downgrading the VNF graph to use among those implementing the same\nservice. Service shifting can serve multiple goals, from reducing operational\ncosts to reacting to infrastructure problems. Furthermore, it enhances the\nflexibility of service-level agreements between network operators and third\nparty content providers (\"verticals). In this paper, we introduce and describe\nthe service shifting concept, its benefits, and the associated challenges, with\nspecial reference to how service shifting can be integrated within real-world\n5G architectures and implementations. We conclude that existing network\norchestration frameworks can be easily extended to support service shifting,\nand its adoption has the potential to make 5G network slices easier for the\noperators to manage under high-load conditions, while still meeting the\nverticals' requirements.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 11:28:49 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Malandrino", "Francesco", ""], ["Chiasserini", "Carla-Fabiana", ""], ["Landi", "Giada", ""]]}, {"id": "1905.11549", "submitter": "Xin Zhang", "authors": "Xin Zhang, Jia Liu, Zhengyuan Zhu", "title": "Distributed Linear Model Clustering over Networks: A Tree-Based\n  Fused-Lasso ADMM Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider to improve the model estimation efficiency by\naggregating the neighbors' information as well as identify the subgroup\nmembership for each node in the network. A tree-based $l_1$ penalty is proposed\nto save the computation and communication cost. We design a decentralized\ngeneralized alternating direction method of multiplier algorithm for solving\nthe objective function in parallel. The theoretical properties are derived to\nguarantee both the model consistency and the algorithm convergence. Thorough\nnumerical experiments are also conducted to back up our theory, which also show\nthat our approach outperforms in the aspects of the estimation accuracy,\ncomputation speed and communication cost.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 00:40:01 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Zhang", "Xin", ""], ["Liu", "Jia", ""], ["Zhu", "Zhengyuan", ""]]}, {"id": "1905.11570", "submitter": "Xianxin Song", "authors": "Xianxin Song, Xiaoqi Qin, Yunzheng Tao, Baoling Liu and Ping Zhang", "title": "Age Based Task Scheduling and Computation Offloading in Mobile-Edge\n  Computing Systems", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To support emerging real-time monitoring and control applications, the\ntimeliness of computation results is of critical importance to mobile-edge\ncomputing (MEC) systems. We propose a performance metric called age of task\n(AoT) based on the concept of age of information (AoI), to evaluate the\ntemporal value of computation tasks. In this paper, we consider a system\nconsisting of a single MEC server and one mobile device running several\napplications. We study an age minimization problem by jointly considering task\nscheduling, computation offloading and energy consumption. To solve the problem\nefficiently, we propose a light-weight task scheduling and computation\noffloading algorithm. Through performance evaluation, we show that our proposed\nage-based solution is competitive when compared with traditional strategies.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 02:09:13 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Song", "Xianxin", ""], ["Qin", "Xiaoqi", ""], ["Tao", "Yunzheng", ""], ["Liu", "Baoling", ""], ["Zhang", "Ping", ""]]}, {"id": "1905.11627", "submitter": "Abu Sufian", "authors": "A. Sufian, F. Sultana, P. Dutta", "title": "Data Load Balancing In Mobile Ad Hoc Network Using Fuzzy Logic (DBMF)", "comments": "8 pages, 3 Figures, National Conference on Recent Advances in\n  Computer Science and IT (NCRACIT),BGSB University, Rajouri, J&K", "journal-ref": "Proceeding of National Conference on Recent Advances in Computer\n  Science and IT (NCRACIT), BGSB University, Rajouri, J&K, Published online:\n  http://ijsrcseit.com/CSEIT411813, 2018", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volume and movement of data rapidly increasing in every type of data\ncommunications and networking, and ad hoc networks are not spared from these\nchallenges. Traditional Multipath routing protocols in Mobile Ad-hoc Networks\n(MANETs) did not focus on data load distribution and balancing as much as\nrequired. In this scheme, we have proposed data load distribution and balancing\nthrough multiple paths simultaneously. We have considered three important\nparameters of ad hoc network those are: mobility of node, the energy of node\nand packet drop rate at a node. This scheme combines these three metrics using\nfuzzy logic to get the decisive parameter. We have shown improvement of this\nscheme over similar kind of protocols in NS-2 network simulator.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:25:02 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Sufian", "A.", ""], ["Sultana", "F.", ""], ["Dutta", "P.", ""]]}, {"id": "1905.11644", "submitter": "Abu Sufian", "authors": "A. Sufian, A. Banerjee, P. Dutta", "title": "Cheat-Proof Communication through Cluster Head (C3H) in Mobile Ad Hoc\n  Network", "comments": "14 pages, 8 figures, 1 table", "journal-ref": "Pertanika J. Sci. & Technol. 26 (3): 1513 - 1526 (2018)", "doi": null, "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mobile ad hoc network (MANET) is a wireless network based on a group of\nmobile nodes without any centralised infrastructure. In civilian data\ncommunication, all nodes cannot be homogeneous-type and not do a specific data\ncommunication. Therefore, node co-operation and cheat-proof are essential\ncharacteristics for successfully running MANETs in civilian data communication.\nDenial of service and malicious behaviour of the node are the main concerns in\nsecuring successful communication in MANETs. This scheme proposed a generic\nsolution to preventing malicious behaviour of the node by the cluster head\nthrough the single hop node clustering strategy.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 07:01:07 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Sufian", "A.", ""], ["Banerjee", "A.", ""], ["Dutta", "P.", ""]]}, {"id": "1905.11705", "submitter": "Theodoros Karagkioules Mr", "authors": "Theodoros Karagkioules, Georgios S. Paschos, Nikolaos Liakopoulos,\n  Attilio Fiandrotti, Dimitrios Tsilimantos and Marco Cagnazzo", "title": "Optimizing Adaptive Video Streaming in Mobile Networks via Online\n  Learning", "comments": "9 pages, 3 figures, submitted to IEEE Transactions on Multimedia\n  (under review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel algorithm for video rate adaptation in HTTP\nAdaptive Streaming (HAS), based on online learning. The proposed algorithm,\nnamed Learn2Adapt (L2A), is shown to provide a robust rate adaptation strategy\nwhich, unlike most of the state-of-the-art techniques, does not require\nparameter tuning, channel model assumptions or application-specific\nadjustments. These properties make it very suitable for mobile users, who\ntypically experience fast variations in channel characteristics. Simulations\nshow that L2A improves on the overall Quality of Experience (QoE) and in\nparticular the average streaming rate, a result obtained independently of the\nchannel and application scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:37:19 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 14:36:21 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Karagkioules", "Theodoros", ""], ["Paschos", "Georgios S.", ""], ["Liakopoulos", "Nikolaos", ""], ["Fiandrotti", "Attilio", ""], ["Tsilimantos", "Dimitrios", ""], ["Cagnazzo", "Marco", ""]]}, {"id": "1905.11751", "submitter": "Simon D. Duque Anton", "authors": "Simon Duque Anton, Daniel Fraunholz, Dennis Krummacker, Christoph\n  Fischer, Michael Karrenbauer, Hans Dieter Schotten", "title": "The Dos and Don'ts of Industrial Network Simulation: A Field Report", "comments": "This is a preprint of a work published in the Proceedings of the 2nd\n  International Symposium on Computer Science and Intelligent Control (ISCSIC\n  2018)", "journal-ref": null, "doi": "10.1145/3284557.3284716", "report-no": null, "categories": "cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in industrial control lead to increasing incorporation of\nintercommunication technologies and embedded devices into the production\nenvironment. In addition to that, the rising complexity of automation tasks\ncreates demand for extensive solutions. Standardised protocols and commercial\noff the shelf devices aid in providing these solutions. Still, setting up\nindustrial communication networks is a tedious and high effort task. This\njustifies the need for simulation environments in the industrial context, as\nthey provide cost-, resource- and time-efficient evaluation of solution\napproaches. In this work, industrial use cases are identified and the according\nrequirements are derived. Furthermore, available simulation and emulation tools\nare analysed. They are mapped onto the requirements of industrial applications,\nso that an expressive assignment of solutions to application domains is given.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 11:31:02 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Anton", "Simon Duque", ""], ["Fraunholz", "Daniel", ""], ["Krummacker", "Dennis", ""], ["Fischer", "Christoph", ""], ["Karrenbauer", "Michael", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.11788", "submitter": "Andreas Schmidt", "authors": "Stefan Reif and Andreas Schmidt and Timo H\\\"onig and Thorsten Herfet\n  and Wolfgang Schr\\\"oder-Preikschat", "title": "$\\Delta$elta: Differential Energy-Efficiency, Latency, and Timing\n  Analysis for Real-Time Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3314206.3314211", "report-no": null, "categories": "cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuously increasing degree of automation in many areas (e.g.\nmanufacturing engineering, public infrastructure) lead to the construction of\ncyber-physical systems and cyber-physical networks. To both, time and energy\nare the most critical operating resources. Considering for instance the Tactile\nInternet specification, end-to-end latencies in these systems must be below\n1ms, which means that both communication and system latencies are in the same\norder of magnitude and must be predictably low. As control loops are commonly\nhandled over different variants of network infrastructure (e.g. mobile and\nfibre links) particular attention must be payed to the design of reliable, yet\nfast and energy-efficient data-transmission channels that are robust towards\nunexpected transmission failures. As design goals are often conflicting (e.g.\nhigh performance vs. low energy), it is necessary to analyze and investigate\ntrade-offs with regards to design decisions during the construction of\ncyber-physical networks. In this paper, we present $\\Delta$elta, an approach\ntowards a tool-supported construction process for cyber-physical networks.\n$\\Delta$elta extends the previously presented X-Lap tool by new analysis\nfeatures, but keeps the original measurements facilities unchanged.\n$\\Delta$elta jointly analyzes and correlates the runtime behavior (i.e.\nperformance, latency) and energy demand of individual system components. It\nprovides an automated analysis with precise thread-local time interpolation,\ncontrol-flow extraction, and examination of latency criticality. We further\ndemonstrate the applicability of $\\Delta$elta with an evaluation of a\nprototypical implementation.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 13:09:06 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Reif", "Stefan", ""], ["Schmidt", "Andreas", ""], ["H\u00f6nig", "Timo", ""], ["Herfet", "Thorsten", ""], ["Schr\u00f6der-Preikschat", "Wolfgang", ""]]}, {"id": "1905.12219", "submitter": "Beakal Gizachew Assefa Mr", "authors": "Beakal Gizachew Assefa and \\\"Oznur \\\"Ozkasap", "title": "RESDN: A Novel Metric and Method for Energy Efficient Routing in\n  Software Defined Networks", "comments": "Double column 14 pages , 16 figures, and 6 tables", "journal-ref": "IEEE Transactions on Network and Service Management,2020", "doi": "10.1109/TNSM.2020.2973621", "report-no": null, "categories": "cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined networking (SDN) paradigm, with the flexible and logically\ncentralized control, enables dynamically minimizing the network energy\nconsumption by redirecting paths of packets. However, the links and switches\nare designed to accommodate maximum traffic volume and their power consumption\nis not traffic proportional. Moreover, there exists a trade-off between energy\nefficiency and network performance that need to be considered together.\nAddressing these issues, we propose an energy efficiency metric named Ratio for\nEnergy Saving in SDN (RESDN) that quantifies energy efficiency based on link\nutility intervals. We provide integer programming formulation and method for\nmaximizing the RESDN of the network. To the best of our knowledge, RESDN\napproach is novel as it measures how links are profitably utilized in terms of\nthe amount of energy they consume with respect to their utility. We analyze our\napproach considering various metrics of interest, and different types of SDN\nenabled switches. Experiments show that maximizing the RESDN value improves\nenergy efficiency while maintaining acceptable network performance. In\ncomparison to state-of-the-art utility-based heuristics, RESDN method achieves\nup to 30% better ratio for energy saving, 14.7 watts per switch power saving,\n38% link saving, 2 hops decrease in average path length, 5% improved traffic\nproportionality.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 05:18:22 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 13:47:17 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 03:33:25 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Assefa", "Beakal Gizachew", ""], ["\u00d6zkasap", "\u00d6znur", ""]]}, {"id": "1905.12857", "submitter": "AKM Bahalul Haque", "authors": "AKM Bahalul Haque, Rabeya Sultana, Mohammad Sajid Fahad, MD Nasif\n  Latif and Md. Amdadul Bari", "title": "XDoser, A Benchmarking Tool for System Load Measurement Using Denial of\n  Service Features", "comments": "12 pages, 11 Figures, 4 tables", "journal-ref": "International Journal of Network Security & Its Applications\n  (IJNSA) Vol. 11, No.3", "doi": "10.5121/ijnsa.2019.11303", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Technology has developed so fast that we feel both safe as well as unsafe in\nboth ways. Systems used today are always prone to attack by malicious users. In\nmost cases, services are hindered because these systems cannot handle the\namount of over loads the attacker provides. So, proper service load measurement\nis necessary. The tool that is being described in this paper for developments\nis based on the Denial of Service methodologies. This tool, XDoser will put a\nsynthetic load on the servers for testing purpose. The HTTP Flood method is\nused which includes an HTTP POST method as it forces the website to gather the\nmaximum resources possible in response to every single request. The tool\ndeveloped in this paper will focus on overloading the backend with multiple\nrequests. So, the tool can be implemented for servers new or old for synthetic\ntest endurance testing.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 05:22:13 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Haque", "AKM Bahalul", ""], ["Sultana", "Rabeya", ""], ["Fahad", "Mohammad Sajid", ""], ["Latif", "MD Nasif", ""], ["Bari", "Md. Amdadul", ""]]}, {"id": "1905.12951", "submitter": "Ehsan Toreini", "authors": "Ehsan Toreini, Maryam Mehrnezhad, Siamak F. Shahandashti, Feng Hao", "title": "DOMtegrity: Ensuring Web Page Integrity against Malicious Browser\n  Extensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address an unsolved problem in the real world: how to\nensure the integrity of the web content in a browser in the presence of\nmalicious browser extensions? The problem of exposing confidential user\ncredentials to malicious extensions has been widely understood, which has\nprompted major banks to deploy two-factor authentication. However, the\nimportance of the `integrity' of the web content has received little attention.\nWe implement two attacks on real-world online banking websites and show that\nignoring the `integrity' of the web content can fundamentally defeat two-factor\nsolutions. To address this problem, we propose a cryptographic protocol called\nDOMtegrity to ensure the end-to-end integrity of the DOM structure of a web\npage from delivering at a web server to the rendering of the page in the user's\nbrowser. DOMtegrity is the first solution that protects DOM integrity without\nmodifying the browser architecture or requiring extra hardware. It works by\nexploiting subtle yet important differences between browser extensions and\nin-line JavaScript code. We show how DOMtegrity prevents the earlier attacks\nand a whole range of man-in-the-browser (MITB) attacks. We conduct extensive\nexperiments on more than 14,000 real-world extensions to evaluate the\neffectiveness of DOMtegrity.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:39:28 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Toreini", "Ehsan", ""], ["Mehrnezhad", "Maryam", ""], ["Shahandashti", "Siamak F.", ""], ["Hao", "Feng", ""]]}, {"id": "1905.12959", "submitter": "Juuso Haavisto", "authors": "Jude Okwuibe, Juuso Haavisto, Erkki Harjula, Ijaz Ahmad and Mika\n  Ylianttila", "title": "Orchestrating Service Migration for Low Power MEC-Enabled IoT Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Access Edge Computing (MEC) is a key enabling technology for Fifth\nGeneration (5G) mobile networks. MEC facilitates distributed cloud computing\ncapabilities and information technology service environment for applications\nand services at the edges of mobile networks. This architectural modification\nserves to reduce congestion, latency, and improve the performance of such edge\ncolocated applications and devices. In this paper, we demonstrate how reactive\nservice migration can be orchestrated for low-power MEC-enabled Internet of\nThings (IoT) devices. Here, we use open-source Kubernetes as container\norchestration system. Our demo is based on traditional client-server system\nfrom user equipment (UE) over Long Term Evolution (LTE) to the MEC server. As\nthe use case scenario, we post-process live video received over web real-time\ncommunication (WebRTC). Next, we integrate orchestration by Kubernetes with S1\nhandovers, demonstrating MEC-based software defined network (SDN). Now, edge\napplications may reactively follow the UE within the radio access network\n(RAN), expediting low-latency. The collected data is used to analyze the\nbenefits of the low-power MEC-enabled IoT device scheme, in which end-to-end\n(E2E) latency and power requirements of the UE are improved. We further discuss\nthe challenges of implementing such schemes and future research directions\ntherein.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 11:00:25 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Okwuibe", "Jude", ""], ["Haavisto", "Juuso", ""], ["Harjula", "Erkki", ""], ["Ahmad", "Ijaz", ""], ["Ylianttila", "Mika", ""]]}, {"id": "1905.13014", "submitter": "Chengjian Sun", "authors": "Chengjian Sun and Chenyang Yang", "title": "Unsupervised Deep Learning for Ultra-reliable and Low-latency\n  Communications", "comments": "6 pages, 1 figure, submitted to IEEE for possible publication. arXiv\n  admin note: text overlap with arXiv:1905.11017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how to solve resource allocation problems in\nultra-reliable and low-latency communications by unsupervised deep learning,\nwhich often yield functional optimization problems with quality-of-service\n(QoS) constraints. We take a joint power and bandwidth allocation problem as an\nexample, which minimizes the total bandwidth required to guarantee the QoS of\neach user in terms of the delay bound and overall packet loss probability. The\nglobal optimal solution is found in a symmetric scenario. A neural network was\nintroduced to find an approximated optimal solution in general scenarios, where\nthe QoS is ensured by using the property that the optimal solution should\nsatisfy as the \"supervision signal\". Simulation results show that the\nlearning-based solution performs the same as the optimal solution in the\nsymmetric scenario, and can save around 40% bandwidth with respect to the\nstate-of-the-art policy.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 03:15:59 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 08:39:01 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Sun", "Chengjian", ""], ["Yang", "Chenyang", ""]]}, {"id": "1905.13118", "submitter": "Usman Raza", "authors": "Aftab Khan, Tim Farnham, Roget Kou, Usman Raza, Thajanee Premalal,\n  Aleksandar Stanoev, William Thompson", "title": "Standing on the Shoulders of Giants: AI-driven Calibration of\n  Localisation Technologies", "comments": "Pre-print version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High accuracy localisation technologies exist but are prohibitively expensive\nto deploy for large indoor spaces such as warehouses, factories, and\nsupermarkets to track assets and people. However, these technologies can be\nused to lend their highly accurate localisation capabilities to low-cost,\ncommodity, and less-accurate technologies. In this paper, we bridge this link\nby proposing a technology-agnostic calibration framework based on artificial\nintelligence to assist such low-cost technologies through highly accurate\nlocalisation systems. A single-layer neural network is used to calibrate less\naccurate technology using more accurate one such as BLE using UWB and UWB using\na professional motion tracking system. On a real indoor testbed, we demonstrate\nan increase in accuracy of approximately 70% for BLE and 50% for UWB. Not only\nthe proposed approach requires a very short measurement campaign, the low\ncomplexity of the single-layer neural network also makes it ideal for\ndeployment on constrained devices typically for localisation purposes.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 15:50:14 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Khan", "Aftab", ""], ["Farnham", "Tim", ""], ["Kou", "Roget", ""], ["Raza", "Usman", ""], ["Premalal", "Thajanee", ""], ["Stanoev", "Aleksandar", ""], ["Thompson", "William", ""]]}, {"id": "1905.13172", "submitter": "Phillip Smith", "authors": "Phillip Smith, Anh Luong, Shamik Sarkar, Harsimran Singh, Neal\n  Patwari, Sneha Kasera, Kurt Derr and Samuel Ramirez", "title": "Sitara: Spectrum Measurement Goes Mobile Through Crowd-sourcing", "comments": "13 pages, 13 figures, 3 tables; For additional documentation and\n  source code refer to https://github.com/SPAN-UofU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.HC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined radios (SDRs) are often used in the experimental evaluation\nof next-generation wireless technologies. While crowd-sourced spectrum\nmonitoring is an important component of future spectrum-agile technologies,\nthere is no clear way to test it in the real world, i.e., with hundreds of\nusers each with an SDR in their pocket participating in RF experiments\ncontrolled by, and data uploaded to, the cloud. Current fully functional SDRs\nare bulky, with components connected via wires, and last at most hours on a\nsingle battery charge. To address the needs of such experiments, we design and\ndevelop a compact, portable, untethered, and inexpensive SDR we call Sitara.\nOur SDR interfaces with a mobile device over Bluetooth 5 and can function\nstandalone or as a client to a central command and control server. The Sitara\noffers true portability: it operates up to one week on battery power, requires\nno external wired connections and occupies a footprint smaller than a credit\ncard. It transmits and receives common waveforms, uploads IQ samples or\nprocessed receiver data through a mobile device to a server for remote\nprocessing and performs spectrum sensing functions. Multiple Sitaras form a\ndistributed system capable of conducting experiments in wireless networking and\ncommunication in addition to RF monitoring and sensing activities. In this\npaper, we describe our design, evaluate our solution, present experimental\nresults from multi-sensor deployments and discuss the value of this system in\nfuture experimentation.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:56:29 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Smith", "Phillip", ""], ["Luong", "Anh", ""], ["Sarkar", "Shamik", ""], ["Singh", "Harsimran", ""], ["Patwari", "Neal", ""], ["Kasera", "Sneha", ""], ["Derr", "Kurt", ""], ["Ramirez", "Samuel", ""]]}, {"id": "1905.13254", "submitter": "Hui Lin", "authors": "Hui Lin", "title": "SDN-based In-network Honeypot: Preemptively Disrupt and Mislead Attacks\n  in IoT Networks", "comments": "Presented at the 1st International Workshop on Security and Privacy\n  for the Internet-of-Things (IoTSec)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting cyber attacks in the network environments used by\nInternet-of-things (IoT) and preventing them from causing physical\nperturbations play an important role in delivering dependable services. To\nachieve this goal, we propose in-network Honeypot based on Software-Defined\nNetworking (SDN) to disrupt and mislead adversaries into exposures while they\nare in an early stage of preparing an attack. Different from traditional\nHoneypot requiring dedicated hardware setup, the in-network Honeypot directly\nreroutes traffic from suspicious nodes and intelligently spoofs the network\ntraffic to them by adding misleading information into normal traffic.\nPreliminary evaluations on real networks demonstrate that the in-network\nHoneypot can have little impacts on the performance of IoT networks.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 18:17:23 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Lin", "Hui", ""]]}, {"id": "1905.13352", "submitter": "Hafiz Muhammad Mohsin Bashir", "authors": "Hafiz Mohsin Bashir, Abdullah Bin Faisal, Muhammad Asim Jamshed, Peter\n  Vondras, Ali Musa Iftikhar, Ihsan Ayyub Qazi, Fahad R. Dogar", "title": "Reducing Tail Latency via Safe and Simple Duplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Duplication can be a powerful strategy for overcoming stragglers in cloud\nservices, but is often used conservatively because of the risk of overloading\nthe system. We present duplicate-aware scheduling or DAS, which makes\nduplication safe and easy to use, by leveraging the two well-known primitives\nof prioritization and purging. To support DAS across diverse layers of a cloud\nsystem (e.g., network, storage, etc), we propose the D-Stage abstraction, which\ndecouples the duplication policy from the mechanism, and facilitates working\nwith legacy layers of a system. Using this abstraction, we evaluate the\nbenefits of DAS for two data parallel applications (HDFS, an in-memory workload\ngenerator) and a network function (snort-based IDS cluster). Our experiments on\nthe public cloud and Emulab show that DAS is safe to use, and the tail latency\nimprovement holds across a wide range of workloads\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 23:30:56 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Bashir", "Hafiz Mohsin", ""], ["Faisal", "Abdullah Bin", ""], ["Jamshed", "Muhammad Asim", ""], ["Vondras", "Peter", ""], ["Iftikhar", "Ali Musa", ""], ["Qazi", "Ihsan Ayyub", ""], ["Dogar", "Fahad R.", ""]]}, {"id": "1905.13423", "submitter": "Xingran Chen", "authors": "Xingran Chen, Mohammad Hassan Lotfi and Saswati Sarkar", "title": "The Interplay of Competition and Cooperation Among Service Providers\n  (Part I)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the incentives of mobile network operators (MNOs) for\nacquiring additional spectrum to offer mobile virtual network operators (MVNOs)\nand thereby inviting competition for a common pool of end users (EUs). We\nconsider a base case and two generalizations: (i) one MNO and one MVNO, (ii)\none MNO, one MVNO and an outside option, and (iii) two MNOs and one MVNO. In\neach of these cases, we model the interactions of the service providers (SPs)\nusing a sequential game, identify when the Subgame Perfect Nash Equilibrium\n(SPNE) exists, when it is unique and characterize the SPNE when it exists. The\ncharacterizations are easy to compute, and are in closed form or involve\noptimizations in only one decision variable. We identify metrics to quantify\nthe interplay between cooperation and competition, and evaluate those as also\nthe SPNEs to show that cooperation between MNO and MVNO can enhance the payoffs\nof both, while increased competition due to the presence of additional MNOs is\nbeneficial to EUs but reduces the payoffs of the SPs.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 05:38:55 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 16:00:50 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 23:52:06 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 03:53:33 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Chen", "Xingran", ""], ["Lotfi", "Mohammad Hassan", ""], ["Sarkar", "Saswati", ""]]}, {"id": "1905.13430", "submitter": "Yair Meidan", "authors": "Yair Meidan, Vinay Sachidananda, Yuval Elovici, and Asaf Shabtai", "title": "Privacy-Preserving Detection of IoT Devices Connected Behind a NAT in a\n  Smart Home Setup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, telecommunication service providers (telcos) are exposed to\ncyber-attacks executed by compromised IoT devices connected to their customers'\nnetworks. Such attacks might have severe effects not only on the target of\nattacks but also on the telcos themselves. To mitigate those risks we propose a\nmachine learning based method that can detect devices of specific vulnerable\nIoT models connected behind a domestic NAT, thereby identifying home networks\nthat pose a risk to the telco's infrastructure and availability of services. As\npart of the effort to preserve the domestic customers' privacy, our method\nrelies on NetFlow data solely, refraining from inspecting the payload. To\npromote future research in this domain we share our novel dataset, collected in\nour lab from numerous and various commercial IoT devices.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 06:09:16 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Meidan", "Yair", ""], ["Sachidananda", "Vinay", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1905.13563", "submitter": "Ahmad Al-Kabbany", "authors": "Maggie E. Gendy and Ahmad Al-Kabbany and Ehab F. Badran", "title": "Maximizing Clearance Rate by Penalizing Redundant Task Assignment in\n  Mobile Crowdsensing Auctions", "comments": "arXiv admin note: text overlap with arXiv:1810.05774", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research is concerned with the effectiveness of auctions-based task\nassignment and management in centralized, participatory Mobile Crowdsensing\n(MCS) systems. During auctions, sensing tasks are matched with participants\nbased on bids and incentives that are provided by the participants and the\nplatform respectively. Recent literature addressed several challenges in\nauctions including untruthful bidding and malicious participants. Our recent\nwork started addressing another challenge, namely, the maximization of\nclearance rate (CR) in sensing campaigns, i.e., the percentage of the\naccomplished sensing tasks. In this research, we propose a new objective\nfunction for matching tasks with participants, in order to achieve\nCR-maximized, reputation-aware auctions. Particularly, we penalize redundant\ntask assignment, where a task is assigned to multiple participants, which can\nconsume the budget unnecessarily. We observe that the less the bidders on a\ncertain task, the higher the priority it should be assigned, to get\naccomplished. Hence, we introduce a new factor, the task redundancy factor in\nmanaging auctions. Through extensive simulations under varying conditions of\nsensing campaigns, and given a fixed budget, we show that penalizing redundancy\n(giving higher priority to unpopular tasks) yields significant CR increases of\napproximately 50%, compared to the highest clearance rates in the recent\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 02:35:52 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Gendy", "Maggie E.", ""], ["Al-Kabbany", "Ahmad", ""], ["Badran", "Ehab F.", ""]]}, {"id": "1905.13743", "submitter": "Alkan Soysal", "authors": "Alkan Soysal and Sennur Ulukus", "title": "Age of Information in G/G/1/1 Systems: Age Expressions, Bounds, Special\n  Cases, and Optimization", "comments": "Submitted for publication, May 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the age of information in G/G/1/1 systems under two service\ndiscipline models. In the first model, if a new update arrives when the service\nis busy, it is blocked; in the second model, a new update preempts the current\nupdate in service. For the blocking model, we first derive an exact age\nexpression, then we propose two simple to calculate upper bounds for the\naverage age. The first upper bound assumes the interarrival times to have\nlog-concave distribution. The second upper bound assumes both the interarrivals\nand service times to have log-concave distribution. Both upper bounds are tight\nin the case of M/M/1/1 systems. We show that deterministic interarrivals and\nservice times are optimum for the blocking service model. In addition, using\nthe age expression for G/G/1/1 systems, we calculate average age expressions\nfor special cases, i.e., M/G/1/1 and G/M/1/1 systems. Next, for the preemption\nin service model, we first derive an exact average age expression for G/G/1/1\nsystems. Then, we propose a simple to calculate upper bound for the average\nage. In addition, similar to blocking discipline, using the age expression for\nG/G/1/1 systems, we calculate average age expressions for special cases, i.e.,\nM/G/1/1 and G/M/1/1 systems. Average age for G/M/1/1 can be written as a\nsummation of two terms, the first of which depends only on the first and second\nmoments of interarrival times and the second of which depends only on the\nservice rate. In other words, interarrival and service times are decoupled. We\nshow that deterministic interarrivals are optimum for G/M/1/1 systems. On the\nother hand, we observe for non-exponential service times that the optimal\ndistribution of interarrival times depends on the relative values of the mean\ninterarrival time and the mean service time.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:54:30 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Soysal", "Alkan", ""], ["Ulukus", "Sennur", ""]]}]