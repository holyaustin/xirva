[{"id": "1506.00021", "submitter": "Michael Kazhdan", "authors": "Michael Kazhdan, Gurprit Singh, Adrien Pilleboue, David Coeurjolly,\n  Victor Ostromoukhov", "title": "Variance Analysis for Monte Carlo Integration: A\n  Representation-Theoretic Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we revisit the work of Pilleboue et al. [2015], providing a\nrepresentation-theoretic derivation of the closed-form expression for the\nexpected value and variance in homogeneous Monte Carlo integration. We show\nthat the results obtained for the variance estimation of Monte Carlo\nintegration on the torus, the sphere, and Euclidean space can be formulated as\nspecific instances of a more general theory. We review the related\nrepresentation theory and show how it can be used to derive a closed-form\nsolution.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 20:27:11 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Kazhdan", "Michael", ""], ["Singh", "Gurprit", ""], ["Pilleboue", "Adrien", ""], ["Coeurjolly", "David", ""], ["Ostromoukhov", "Victor", ""]]}, {"id": "1506.00783", "submitter": "Alexander Schmeding", "authors": "Elena Celledoni, Markus Eslitzbichler, Alexander Schmeding", "title": "Shape Analysis on Lie Groups with Applications in Computer Animation", "comments": "37 pages, 7 figures, v4: Major revision, corrected typos, simplified\n  and clarified arguments, main results remain unchanged", "journal-ref": "Journal of Geometric Mechanics Vol. 8 No. 3 (2016), pp. 273-304", "doi": "10.3934/jgm.2016008", "report-no": null, "categories": "math.DG cs.GR math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape analysis methods have in the past few years become very popular, both\nfor theoretical exploration as well as from an application point of view.\nOriginally developed for planar curves, these methods have been expanded to\nhigher dimensional curves, surfaces, activities, character motions and many\nother objects. In this paper, we develop a framework for shape analysis of\ncurves in Lie groups for problems of computer animations. In particular, we\nwill use these methods to find cyclic approximations of non-cyclic character\nanimations and interpolate between existing animations to generate new ones.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 07:55:22 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2015 14:22:50 GMT"}, {"version": "v3", "created": "Tue, 29 Mar 2016 11:24:06 GMT"}, {"version": "v4", "created": "Thu, 19 May 2016 08:45:57 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Celledoni", "Elena", ""], ["Eslitzbichler", "Markus", ""], ["Schmeding", "Alexander", ""]]}, {"id": "1506.00967", "submitter": "Leonardo Fernandez-Jambrina", "authors": "A. Cant\\'on, L. Fern\\'andez-Jambrina, M.E. Rosado Mar\\'ia, M.J.\n  V\\'azquez-Gallo", "title": "Geometric elements and classification of quadrics in rational B\\'ezier\n  form", "comments": "14 pages, 12 figures. Minor changes from previous version. To appear\n  in Journal of Computational and Applied Mathematics", "journal-ref": "Journal of Computational and Applied Mathematics 300, 400-419\n  (2016)", "doi": "10.1016/j.cam.2016.01.006", "report-no": null, "categories": "cs.GR math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we classify and derive closed formulas for geometric elements\nof quadrics in rational B\\'ezier triangular form (such as the center, the conic\nat infinity, the vertex and the axis of paraboloids and the principal planes),\nusing just the control vertices and the weights for the quadric patch. The\nresults are extended also to quadric tensor product patches. Our results rely\non using techniques from projective algebraic geometry to find suitable\nbilinear forms for the quadric in a coordinate-free fashion, considering a\npencil of quadrics that are tangent to the given quadric along a conic. Most of\nthe information about the quadric is encoded in one coefficient, involving the\nweights of the patch, which allows us to tell apart oval from ruled quadrics.\nThis coefficient is also relevant to determine the affine type of the quadric.\nSpheres and quadrics of revolution are characterised within this framework.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 17:35:47 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 11:07:51 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Cant\u00f3n", "A.", ""], ["Fern\u00e1ndez-Jambrina", "L.", ""], ["Mar\u00eda", "M. E. Rosado", ""], ["V\u00e1zquez-Gallo", "M. J.", ""]]}, {"id": "1506.02079", "submitter": "Michael Kazhdan", "authors": "Michael Kazhdan, Kunal Lillaney, William Roncal, Davi Bock, Joshua\n  Vogelstein, and Randal Burns", "title": "Gradient-Domain Fusion for Color Correction in Large EM Image Stacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new gradient-domain technique for processing registered EM image\nstacks to remove inter-image discontinuities while preserving intra-image\ndetail. To this end, we process the image stack by first performing anisotropic\nsmoothing along the slice axis and then solving a Poisson equation within each\nslice to re-introduce the detail. The final image stack is continuous across\nthe slice axis and maintains sharp details within each slice. Adapting existing\nout-of-core techniques for solving the linear system, we describe a parallel\nalgorithm with time complexity that is linear in the size of the data and space\ncomplexity that is sub-linear, allowing us to process datasets as large as five\nteravoxels with a 600 MB memory footprint.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 22:35:31 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Kazhdan", "Michael", ""], ["Lillaney", "Kunal", ""], ["Roncal", "William", ""], ["Bock", "Davi", ""], ["Vogelstein", "Joshua", ""], ["Burns", "Randal", ""]]}, {"id": "1506.02400", "submitter": "Alan Brunton", "authors": "Alan Brunton, Can Ates Arikan and Philipp Urban", "title": "Pushing the Limits of 3D Color Printing: Error Diffusion with\n  Translucent Materials", "comments": "15 pages, 14 figures; includes supplemental figures", "journal-ref": "ACM Transactions on Graphics, 35(1), Article 4, December 2015", "doi": "10.1145/2832905", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate color reproduction is important in many applications of 3D printing,\nfrom design prototypes to 3D color copies or portraits. Although full color is\navailable via other technologies, multi-jet printers have greater potential for\ngraphical 3D printing, in terms of reproducing complex appearance properties.\nHowever, to date these printers cannot produce full color, and doing so poses\nsubstantial technical challenges, from the shear amount of data to the\ntranslucency of the available color materials. In this paper, we propose an\nerror diffusion halftoning approach to achieve full color with multi-jet\nprinters, which operates on multiple isosurfaces or layers within the object.\nWe propose a novel traversal algorithm for voxel surfaces, which allows the\ntransfer of existing error diffusion algorithms from 2D printing. The resulting\nprints faithfully reproduce colors, color gradients and fine-scale details.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 08:47:52 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2016 15:09:27 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Brunton", "Alan", ""], ["Arikan", "Can Ates", ""], ["Urban", "Philipp", ""]]}, {"id": "1506.02976", "submitter": "Jose Rodrigues Jr", "authors": "Jose F. Rodrigues Jr., Agma J. M. Traina, Maria Cristina F. de\n  Oliveira, Caetano Traina Jr", "title": "Reviewing Data Visualization: an Analytical Taxonomical Study", "comments": "Published in the Proceedings of the Information Visualization\n  Conference as Jose Rodrigues, Agma Traina, Maria Oliveira, Caetano Traina,\n  Reviewing Data Visualization: an Analytical Taxonomical Study In: 10th\n  International Conference on Information Visualization, 2006, 713-720 IEEE\n  Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an analytical taxonomy that can suitably describe, rather\nthan simply classify, techniques for data presentation. Unlike previous works,\nwe do not consider particular aspects of visualization techniques, but their\nmechanisms and foundational vision perception. Instead of just adjusting\nvisualization research to a classification system, our aim is to better\nunderstand its process. For doing so, we depart from elementary concepts to\nreach a model that can describe how visualization techniques work and how they\nconvey meaning.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 16:08:19 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Rodrigues", "Jose F.", "Jr."], ["Traina", "Agma J. M.", ""], ["de Oliveira", "Maria Cristina F.", ""], ["Traina", "Caetano", "Jr"]]}, {"id": "1506.04480", "submitter": "Mingbi Zhao", "authors": "Mingbi Zhao", "title": "A Clustering Based Approach for Realistic and Efficient Data-Driven\n  Crowd Simulation", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  equation 6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a data-driven approach to generate realistic\nsteering behaviors for virtual crowds in crowd simulation. We take advantage of\nboth rule-based models and data-driven models by applying the interaction\npatterns discovered from crowd videos. Unlike existing example-based models in\nwhich current states are matched to states extracted from crowd videos\ndirectly, our approach adopts a hierarchical mechanism to generate the steering\nbehaviors of agents. First, each agent is classified into one of the\ninteraction patterns that are automatically discovered from crowd video before\nsimulation. Then the most matched action is selected from the associated\ninteraction pattern to generate the steering behaviors of the agent. By doing\nso, agents can avoid performing a simple state matching as in the traditional\nexample-based approaches, and can perform a wider variety of steering behaviors\nas well as mimic the cognitive process of pedestrians. Simulation results on\nscenarios with different crowd densities and main motion directions demonstrate\nthat our approach performs better than two state-of-the-art simulation models,\nin terms of prediction accuracy. Besides, our approach is efficient enough to\nrun at interactive rates in real time simulation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 05:29:06 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2015 07:27:16 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Zhao", "Mingbi", ""]]}, {"id": "1506.04806", "submitter": "S Shankar", "authors": "Sukrit Shankar, Pier Luigi Dragotti", "title": "A Novel Semantics and Feature Preserving Perspective for Content Aware\n  Image Retargeting", "comments": "74 Pages, 46 Figures, Masters Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing requirement for efficient image retargeting techniques\nto adapt the content to various forms of digital media. With rapid growth of\nmobile communications and dynamic web page layouts, one often needs to resize\nthe media content to adapt to the desired display sizes. For various layouts of\nweb pages and typically small sizes of handheld portable devices, the\nimportance in the original image content gets obfuscated after resizing it with\nthe approach of uniform scaling. Thus, there occurs a need for resizing the\nimages in a content aware manner which can automatically discard irrelevant\ninformation from the image and present the salient features with more\nmagnitude. There have been proposed some image retargeting techniques keeping\nin mind the content awareness of the input image. However, these techniques\nfail to prove globally effective for various kinds of images and desired sizes.\nThe major problem is the inefficiency of these algorithms to process these\nimages with minimal visual distortion while also retaining the meaning conveyed\nfrom the image. In this dissertation, we present a novel perspective for\ncontent aware image retargeting, which is well implementable in real time. We\nintroduce a novel method of analysing semantic information within the input\nimage while also maintaining the important and visually significant features.\nWe present the various nuances of our algorithm mathematically and logically,\nand show that the results prove better than the state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 00:53:09 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2015 17:07:08 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2015 23:54:12 GMT"}], "update_date": "2015-08-14", "authors_parsed": [["Shankar", "Sukrit", ""], ["Dragotti", "Pier Luigi", ""]]}, {"id": "1506.06096", "submitter": "Dorina Thanou", "authors": "Dorina Thanou, Philip A. Chou, and Pascal Frossard", "title": "Graph-based compression of dynamic 3D point cloud sequences", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2016.2529506", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of compression of 3D point cloud sequences\nthat are characterized by moving 3D positions and color attributes. As\ntemporally successive point cloud frames are similar, motion estimation is key\nto effective compression of these sequences. It however remains a challenging\nproblem as the point cloud frames have varying numbers of points without\nexplicit correspondence information. We represent the time-varying geometry of\nthese sequences with a set of graphs, and consider 3D positions and color\nattributes of the points clouds as signals on the vertices of the graphs. We\nthen cast motion estimation as a feature matching problem between successive\ngraphs. The motion is estimated on a sparse set of representative vertices\nusing new spectral graph wavelet descriptors. A dense motion field is\neventually interpolated by solving a graph-based regularization problem. The\nestimated motion is finally used for removing the temporal redundancy in the\npredictive coding of the 3D positions and the color characteristics of the\npoint cloud sequences. Experimental results demonstrate that our method is able\nto accurately estimate the motion between consecutive frames. Moreover, motion\nestimation is shown to bring significant improvement in terms of the overall\ncompression performance of the sequence. To the best of our knowledge, this is\nthe first paper that exploits both the spatial correlation inside each frame\n(through the graph) and the temporal correlation between the frames (through\nthe motion estimation) to compress the color and the geometry of 3D point cloud\nsequences in an efficient way.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 17:31:34 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Thanou", "Dorina", ""], ["Chou", "Philip A.", ""], ["Frossard", "Pascal", ""]]}, {"id": "1506.06098", "submitter": "Jose Rodrigues Jr", "authors": "J. Rodrigues, M. Gazziro, N. Goncalves, O. Neto, Y. Fernandes, A.\n  Gimenes, C. Alegre, R. Assis", "title": "The 12 prophets dataset", "comments": "Full dataset online at http://aleijadinho3d.icmc.usp.br/data.html", "journal-ref": null, "doi": null, "report-no": "University of Sao Paulo, Technical Report ICMC-USP 400, 2014", "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"Ajeijadinho 3D\" project is an initiative supported by the University of\nS\\~ao Paulo (Museum of Science and Dean of Culture and Extension), which\ninvolves the 3D digitization of art works of Brazilian sculptor Antonio\nFrancisco Lisboa, better known as Aleijadinho. The project made use of advanced\nacquisition and processing of 3D meshes for preservation and dissemination of\nthe cultural heritage. The dissemination occurs through a Web portal, so that\nthe population has the opportunity to meet the art works in detail using 3D\nvisualization and interaction. The portal address is\nhttp://www.aleijadinho3d.icmc.usp.br. The 3D acquisitions were conducted over a\nweek at the end of July 2013 in the cities of Ouro Preto, MG, Brazil and\nCongonhas do Campo, MG, Brazil. The scanning was done with a special equipment\nsupplied by company Leica Geosystems, which allowed the work to take place at\ndistances between 10 and 30 meters, defining a non-invasive procedure,\nsimplified logistics, and without the need for preparation or isolation of the\nsites. In Ouro Preto, we digitized the churches of Francisco of Assis, Our Lady\nof Carmo, and Our Lady of Mercy; in Congonhas do Campo we scanned the entire\nSanctuary of Bom Jesus de Matosinhos and his 12 prophets. Once scanned, the art\nworks went through a long process of preparation, which required careful\nhandling of meshes done by experts from the University of S\\~ao Paulo in\npartnership with company Imprimate.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 17:57:38 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Rodrigues", "J.", ""], ["Gazziro", "M.", ""], ["Goncalves", "N.", ""], ["Neto", "O.", ""], ["Fernandes", "Y.", ""], ["Gimenes", "A.", ""], ["Alegre", "C.", ""], ["Assis", "R.", ""]]}, {"id": "1506.06426", "submitter": "P. Christopher Staecker", "authors": "P. Christopher Staecker", "title": "A Borsuk-Ulam theorem for digital images", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GN cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Borsuk-Ulam theorem states that a continuous function $f:S^n \\to \\R^n$\nhas a point $x\\in S^n$ with $f(x)=f(-x)$. We give an analogue of this theorem\nfor digital images, which are modeled as discrete spaces of adjacent pixels\nequipped with $\\Z^n$-valued functions.\n  In particular, for a concrete two-dimensional rectangular digital image whose\npixels all have an assigned \"brightness\" function, we prove that there must\nexist a pair of opposite boundary points whose brightnesses are approximately\nequal. This theorem applies generally to any integer-valued function on an\nabstract simple graph.\n  We also discuss generalizations to digital images of dimension 3 and higher.\nWe give some partial results for higher dimensional images, and show a counter\nexample which demonstrates that the full results obtained in lower dimensions\ncannot hold generally.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 00:04:04 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Staecker", "P. Christopher", ""]]}, {"id": "1506.06636", "submitter": "Bertrand Kerautret", "authors": "Bertrand Kerautret (LORIA), Adrien Kr\\\"ahenb\\\"uhl (LORIA), Isabelle\n  Debled-Rennesson (LORIA), Jacques-Olivier Lachaud", "title": "3D Geometric Analysis of Tubular Objects based on Surface Normal\n  Accumulation", "comments": "in 18th International Conference on Image Analysis and Processing,\n  Sep 2015, Genova, Italy. 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple and efficient method for the reconstruction and\nextraction of geometric parameters from 3D tubular objects. Our method\nconstructs an image that accumulates surface normal information, then peaks\nwithin this image are located by tracking. Finally, the positions of these are\noptimized to lie precisely on the tubular shape centerline. This method is very\nversatile, and is able to process various input data types like full or partial\nmesh acquired from 3D laser scans, 3D height map or discrete volumetric images.\nThe proposed algorithm is simple to implement, contains few parameters and can\nbe computed in linear time with respect to the number of surface faces. Since\nthe extracted tube centerline is accurate, we are able to decompose the tube\ninto rectilinear parts and torus-like parts. This is done with a new linear\ntime 3D torus detection algorithm, which follows the same principle of a\nprevious work on 2D arc circle recognition. Detailed experiments show the\nversatility, accuracy and robustness of our new method.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 14:46:58 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2015 12:11:32 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Kerautret", "Bertrand", "", "LORIA"], ["Kr\u00e4henb\u00fchl", "Adrien", "", "LORIA"], ["Debled-Rennesson", "Isabelle", "", "LORIA"], ["Lachaud", "Jacques-Olivier", ""]]}, {"id": "1506.06668", "submitter": "Yoichi Ochiai Prof.", "authors": "Yoichi Ochiai, Kota Kumagai, Takayuki Hoshi, Jun Rekimoto, Satoshi\n  Hasegawa, and Yoshio Hayasaki", "title": "Fairy Lights in Femtoseconds: Aerial and Volumetric Graphics Rendered by\n  Focused Femtosecond Laser Combined with Computational Holographic Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.HC physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method of rendering aerial and volumetric graphics using\nfemtosecond lasers. A high-intensity laser excites a physical matter to emit\nlight at an arbitrary 3D position. Popular applications can then be explored\nespecially since plasma induced by a femtosecond laser is safer than that\ngenerated by a nanosecond laser. There are two methods of rendering graphics\nwith a femtosecond laser in air: Producing holograms using spatial light\nmodulation technology, and scanning of a laser beam by a galvano mirror. The\nholograms and workspace of the system proposed here occupy a volume of up to 1\ncm^3; however, this size is scalable depending on the optical devices and their\nsetup. This paper provides details of the principles, system setup, and\nexperimental evaluation, and discussions on scalability, design space, and\napplications of this system. We tested two laser sources: an adjustable (30-100\nfs) laser which projects up to 1,000 pulses per second at energy up to 7 mJ per\npulse, and a 269-fs laser which projects up to 200,000 pulses per second at an\nenergy up to 50 uJ per pulse. We confirmed that the spatiotemporal resolution\nof volumetric displays, implemented with these laser sources, is 4,000 and\n200,000 dots per second. Although we focus on laser-induced plasma in air, the\ndiscussion presented here is also applicable to other rendering principles such\nas fluorescence and microbubble in solid/liquid materials.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 16:20:34 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Ochiai", "Yoichi", ""], ["Kumagai", "Kota", ""], ["Hoshi", "Takayuki", ""], ["Rekimoto", "Jun", ""], ["Hasegawa", "Satoshi", ""], ["Hayasaki", "Yoshio", ""]]}, {"id": "1506.06745", "submitter": "Lev Nachmanson", "authors": "Lev Nachmanson, Roman Prutkin, Bongshin Lee, Nathalie Henry Riche,\n  Alexander E. Holroyd, Xiaoji Chen", "title": "GraphMaps: Browsing Large Graphs as Interactive Maps", "comments": "submitted to GD 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.DM cs.MS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for laying out large graphs have seen significant progress in the\npast decade. However, browsing large graphs remains a challenge. Rendering\nthousands of graphical elements at once often results in a cluttered image, and\nnavigating these elements naively can cause disorientation. To address this\nchallenge we propose a method called GraphMaps, mimicking the browsing\nexperience of online geographic maps.\n  GraphMaps creates a sequence of layers, where each layer refines the previous\none. During graph browsing, GraphMaps chooses the layer corresponding to the\nzoom level, and renders only those entities of the layer that intersect the\ncurrent viewport. The result is that, regardless of the graph size, the number\nof entities rendered at each view does not exceed a predefined threshold, yet\nall graph elements can be explored by the standard zoom and pan operations.\n  GraphMaps preprocesses a graph in such a way that during browsing, the\ngeometry of the entities is stable, and the viewer is responsive. Our case\nstudies indicate that GraphMaps is useful in gaining an overview of a large\ngraph, and also in exploring a graph on a finer level of detail.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 17:17:34 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Nachmanson", "Lev", ""], ["Prutkin", "Roman", ""], ["Lee", "Bongshin", ""], ["Riche", "Nathalie Henry", ""], ["Holroyd", "Alexander E.", ""], ["Chen", "Xiaoji", ""]]}, {"id": "1506.06855", "submitter": "Ibraheem Alhashim", "authors": "Ibraheem Alhashim", "title": "Modeling and Correspondence of Topologically Complex 3D Shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": "SFU-CMPT TR 2015-55-2", "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D shape creation and modeling remains a challenging task especially for\nnovice users. Many methods in the field of computer graphics have been proposed\nto automate the often repetitive and precise operations needed during the\nmodeling of detailed shapes. This report surveys different approaches of shape\nmodeling and correspondence especially for shapes exhibiting topological\ncomplexity. We focus on methods designed to help generate or process shapes\nwith large number of interconnected components often found in man-made shapes.\nWe first discuss a variety of modeling techniques, that leverage existing\nshapes, in easy to use creative modeling systems. We then discuss possible\ncorrespondence strategies for topologically different shapes as it is a\nrequirement for such systems. Finally, we look at different shape\nrepresentations and tools that facilitate the modification of shape topology\nand we focus on those particularly useful in free-form 3D modeling.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 04:40:30 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Alhashim", "Ibraheem", ""]]}, {"id": "1506.06968", "submitter": "Jose Rodrigues Jr", "authors": "Jose Rodrigues, Andre Balan, Luciana Zaina, Agma Traina", "title": "A Survey on Distributed Visualization Techniques over Clusters of\n  Personal Computers", "comments": null, "journal-ref": "INFOCOMP Journal of Computer Science, 2009, ISSN: 1807-4545, vol\n  8: 4. 79-90", "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, Distributed Visualization over Personal Computer (PC)\nclusters has become important for research and industrial communities. They\nhave made large-scale visualizations practical and more accessible. In this\nwork we survey Distributed Visualization techniques aiming at compiling last\ndecade's literature on the use of PC clusters as suitable alternatives to\nhigh-end workstations. We review the topic by defining basic concepts,\nenumerating system requirements and implementation challenges, and presenting\nup-to-date methodologies. Our work fulfills the needs of newcomers and seasoned\nprofessionals as an introductory compilation at the same time that it can help\nexperienced personnel by organizing ideas.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 12:22:32 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Rodrigues", "Jose", ""], ["Balan", "Andre", ""], ["Zaina", "Luciana", ""], ["Traina", "Agma", ""]]}, {"id": "1506.07515", "submitter": "Dongsung Huh", "authors": "Dongsung Huh", "title": "The Vector Space of Convex Curves: How to Mix Shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.RO math.DG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel, log-radius profile representation for convex curves and\ndefine a new operation for combining the shape features of curves. Unlike the\nstandard, angle profile-based methods, this operation accurately combines the\nshape features in a visually intuitive manner. This method have implications in\nshape analysis as well as in investigating how the brain perceives and\ngenerates curved shapes and motions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 19:56:56 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Huh", "Dongsung", ""]]}, {"id": "1506.07577", "submitter": "Gilbert Bernstein", "authors": "Gilbert Louis Bernstein, Chinmayee Shah, Crystal Lemire, Zachary\n  DeVito, Matthew Fisher, Philip Levis, Pat Hanrahan", "title": "Ebb: A DSL for Physical Simulation on CPUs and GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing programming environments for physical simulation is challenging\nbecause simulations rely on diverse algorithms and geometric domains. These\nchallenges are compounded when we try to run efficiently on heterogeneous\nparallel architectures. We present Ebb, a domain-specific language (DSL) for\nsimulation, that runs efficiently on both CPUs and GPUs. Unlike previous DSLs,\nEbb uses a three-layer architecture to separate (1) simulation code, (2)\ndefinition of data structures for geometric domains, and (3) runtimes\nsupporting parallel architectures. Different geometric domains are implemented\nas libraries that use a common, unified, relational data model. By structuring\nthe simulation framework in this way, programmers implementing simulations can\nfocus on the physics and algorithms for each simulation without worrying about\ntheir implementation on parallel computers. Because the geometric domain\nlibraries are all implemented using a common runtime based on relations, new\ngeometric domains can be added as needed, without specifying the details of\nmemory management, mapping to different parallel architectures, or having to\nexpand the runtime's interface.\n  We evaluate Ebb by comparing it to several widely used simulations,\ndemonstrating comparable performance to hand-written GPU code where available,\nand surpassing existing CPU performance optimizations by up to 9$\\times$ when\nno GPU code exists.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 22:32:41 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2016 02:25:31 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2016 23:42:30 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Bernstein", "Gilbert Louis", ""], ["Shah", "Chinmayee", ""], ["Lemire", "Crystal", ""], ["DeVito", "Zachary", ""], ["Fisher", "Matthew", ""], ["Levis", "Philip", ""], ["Hanrahan", "Pat", ""]]}, {"id": "1506.07915", "submitter": "Jose Rodrigues Jr", "authors": "Jose Rodrigues, Luciana Romani, Agma Traina, Caetano Traina", "title": "Combining Visual Analytics and Content Based Data Retrieval Technology\n  for Efficient Data Analysis", "comments": "Published as Jose Rodrigues, Luciana A. S. Romani, Agma Juci Machado\n  Traina, Caetano Traina Jr (2010), Combining Visual Analytics and Content\n  Based Data Retrieval Technology for Efficient Data Analysis, 14th Int Conf on\n  Inf Visualisation, 61-67", "journal-ref": "14th Int Conf on Inf Visualisation, 61-67 IEEE Press (2010)", "doi": "10.1109/IV.2010.101", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most useful techniques to help visual data analysis systems is\ninteractive filtering (brushing). However, visualization techniques often\nsuffer from overlap of graphical items and multiple attributes complexity,\nmaking visual selection inefficient. In these situations, the benefits of data\nvisualization are not fully observable because the graphical items do not pop\nup as comprehensive patterns. In this work we propose the use of content-based\ndata retrieval technology combined with visual analytics. The idea is to use\nthe similarity query functionalities provided by metric space systems in order\nto select regions of the data domain according to user-guidance and interests.\nAfter that, the data found in such regions feed multiple visualization\nworkspaces so that the user can inspect the correspondent datasets. Our\nexperiments showed that the methodology can break the visual analysis process\ninto smaller problems (views) and that the views hold the expectations of the\nanalyst according to his/her similarity query selection, improving data\nperception and analytical possibilities. Our contribution introduces a\nprinciple that can be used in all sorts of visualization techniques and\nsystems, this principle can be extended with different kinds of integration\nvisualization-metric-space, and with different metrics, expanding the\npossibilities of visual data analysis in aspects such as semantics and\nscalability.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 22:47:28 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Rodrigues", "Jose", ""], ["Romani", "Luciana", ""], ["Traina", "Agma", ""], ["Traina", "Caetano", ""]]}, {"id": "1506.08459", "submitter": "Jianbo Ye", "authors": "Jianbo Ye, Zhixin Yan", "title": "On the Approximation Theory of Linear Variational Subspace Design", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving large-scale optimization on-the-fly is often a difficult task for\nreal-time computer graphics applications. To tackle this challenge, model\nreduction is a well-adopted technique. Despite its usefulness, model reduction\noften requires a handcrafted subspace that spans a domain that hypothetically\nembodies desirable solutions. For many applications, obtaining such subspaces\ncase-by-case either is impossible or requires extensive human labors, hence\ndoes not readily have a scalable solution for growing number of tasks. We\npropose linear variational subspace design for large-scale constrained\nquadratic programming, which can be computed automatically without any human\ninterventions. We provide meaningful approximation error bound that\nsubstantiates the quality of calculated subspace, and demonstrate its empirical\nsuccess in interactive deformable modeling for triangular and tetrahedral\nmeshes.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 22:08:10 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Ye", "Jianbo", ""], ["Yan", "Zhixin", ""]]}, {"id": "1506.08956", "submitter": "Libin Sun", "authors": "Libin Sun, Brian Guenter, Neel Joshi, Patrick Therien, James Hays", "title": "Lens Factory: Automatic Lens Generation Using Off-the-shelf Components", "comments": "12 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Custom optics is a necessity for many imaging applications. Unfortunately,\ncustom lens design is costly (thousands to tens of thousands of dollars), time\nconsuming (10-12 weeks typical lead time), and requires specialized optics\ndesign expertise. By using only inexpensive, off-the-shelf lens components the\nLens Factory automatic design system greatly reduces cost and time. Design,\nordering of parts, delivery, and assembly can be completed in a few days, at a\ncost in the low hundreds of dollars. Lens design constraints, such as focal\nlength and field of view, are specified in terms familiar to the graphics\ncommunity so no optics expertise is necessary. Unlike conventional lens design\nsystems, which only use continuous optimization methods, Lens Factory adds a\ndiscrete optimization stage. This stage searches the combinatorial space of\npossible combinations of lens elements to find novel designs, evolving simple\ncanonical lens designs into more complex, better designs. Intelligent pruning\nrules make the combinatorial search feasible. We have designed and built\nseveral high performance optical systems which demonstrate the practicality of\nthe system.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 06:39:19 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2015 23:30:45 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Sun", "Libin", ""], ["Guenter", "Brian", ""], ["Joshi", "Neel", ""], ["Therien", "Patrick", ""], ["Hays", "James", ""]]}, {"id": "1506.09166", "submitter": "Ali Avanaki", "authors": "Ali R. N. Avanaki, Kathryn S. Espig, Sameer Sawhney, Liron\n  Pantanowitz, Anil V. Parwani, Albert Xthona, Tom R. L. Kimpe", "title": "Aging display's effect on interpretation of digital pathology slides", "comments": null, "journal-ref": null, "doi": "10.1117/12.2082315", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is our conjecture that the variability of colors in a pathology image\neffects the interpretation of pathology cases, whether it is diagnostic\naccuracy, diagnostic confidence, or workflow efficiency. In this paper, digital\npathology images are analyzed to quantify the perceived difference in color\nthat occurs due to display aging, in particular a change in the maximum\nluminance, white point, and color gamut. The digital pathology images studied\ninclude diagnostically important features, such as the conspicuity of nuclei.\nThree different display aging models are applied to images: aging of luminance\n& chrominance, aging of chrominance only, and a stabilized luminance &\nchrominance (i.e., no aging). These display models and images are then used to\ncompare conspicuity of nuclei using CIE deltaE2000, a perceptual color\ndifference metric. The effect of display aging using these display models and\nimages is further analyzed through a human reader study designed to quantify\nthe effects from a clinical perspective. Results from our reader study indicate\nsignificant impact of aged displays on workflow as well as diagnosis as follow.\nAs compared to the originals (no-aging), slides with the effect of aging\nsimulated were significantly more difficult to read (p-value of 0.0005) and\ntook longer to score (p-value of 0.02). Moreover, luminance+chrominance aging\nsignificantly reduced inter-session percent agreement of diagnostic scores\n(p-value of 0.0418).\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 17:29:43 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Avanaki", "Ali R. N.", ""], ["Espig", "Kathryn S.", ""], ["Sawhney", "Sameer", ""], ["Pantanowitz", "Liron", ""], ["Parwani", "Anil V.", ""], ["Xthona", "Albert", ""], ["Kimpe", "Tom R. L.", ""]]}]