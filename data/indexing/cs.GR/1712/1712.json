[{"id": "1712.00238", "submitter": "Morad Behandish", "authors": "Morad Behandish and Horea T. Ilies", "title": "Shape Complementarity Analysis for Objects of Arbitrary Shape", "comments": "Technical Report, University of Connecticut, 2014", "journal-ref": null, "doi": null, "report-no": "CDL-TR-14-01", "categories": "cs.CG cs.CV cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The basic problem of shape complementarity analysis appears fundamental to\napplications as diverse as mechanical design, assembly automation, robot motion\nplanning, micro- and nano-fabrication, protein-ligand binding, and rational\ndrug design. However, the current challenge lies in the lack of a general\nmathematical formulation that applies to objects of arbitrary shape. We propose\nthat a measure of shape complementarity can be obtained from the extent of\napproximate overlap between shape skeletons. A space-continuous implicit\ngeneralization of the skeleton, called the skeletal density function (SDF) is\ndefined over the Euclidean space that contains the individual assembly\npartners. The SDF shape descriptors capture the essential features that are\nrelevant to proper contact alignment, and are considerably more robust than the\nconventional explicit skeletal representations. We express the shape\ncomplementarity score as a convolution of the individual SDFs. The problem then\nbreaks down to a global optimization of the score over the configuration space\nof spatial relations, which can be efficiently implemented using fast Fourier\ntransforms (FFTs) on nonequispaced samples. We demonstrate the effectiveness of\nthe scoring approach for several examples from 2D peg-in-hole alignment to more\ncomplex 3D examples in mechanical assembly and protein docking. We show that\nthe proposed method is reliable, inherently robust against small perturbations,\nand effective in steering gradient-based optimization.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 09:07:14 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Behandish", "Morad", ""], ["Ilies", "Horea T.", ""]]}, {"id": "1712.00750", "submitter": "Morad Behandish", "authors": "Morad Behandish and Horea T. Ilies", "title": "Haptic Assembly and Prototyping: An Expository Review", "comments": "Technical Report, University of Connecticut, 2016", "journal-ref": null, "doi": null, "report-no": "CDL-TR-16-04", "categories": "cs.HC cs.CG cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important application of haptic technology to digital product development\nis in virtual prototyping (VP), part of which deals with interactive planning,\nsimulation, and verification of assembly-related activities, collectively\ncalled virtual assembly (VA). In spite of numerous research and development\nefforts over the last two decades, the industrial adoption of haptic-assisted\nVP/VA has been slower than expected. Putting hardware limitations aside, the\nmain roadblocks faced in software development can be traced to the lack of\neffective and efficient computational models of haptic feedback. Such models\nmust 1) accommodate the inherent geometric complexities faced when assembling\nobjects of arbitrary shape; and 2) conform to the computation time limitation\nimposed by the notorious frame rate requirements---namely, 1 kHz for haptic\nfeedback compared to the more manageable 30-60 Hz for graphic rendering. The\nsimultaneous fulfillment of these competing objectives is far from trivial.\n  This survey presents some of the conceptual and computational challenges and\nopportunities as well as promising future directions in haptic-assisted VP/VA,\nwith a focus on haptic assembly from a geometric modeling and spatial reasoning\nperspective. The main focus is on revisiting definitions and classifications of\ndifferent methods used to handle the constrained multibody simulation in\nreal-time, ranging from physics-based and geometry-based to hybrid and unified\napproaches using a variety of auxiliary computational devices to specify,\nimpose, and solve assembly constraints. Particular attention is given to the\nnewly developed 'analytic methods' inherited from motion planning and protein\ndocking that have shown great promise as an alternative paradigm to the more\npopular combinatorial methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 10:57:05 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Behandish", "Morad", ""], ["Ilies", "Horea T.", ""]]}, {"id": "1712.01694", "submitter": "Wellington Pinheiro dos Santos", "authors": "Wellington Pinheiro dos Santos, Francisco Marcos de Assis, Ricardo\n  Emmanuel de Souza, Priscilla B. Mendes, Henrique S. S. Monteiro, Havana Diogo\n  Alves", "title": "Fuzzy-Based Dialectical Non-Supervised Image Classification and\n  Clustering", "comments": null, "journal-ref": "International Journal of Hybrid Intelligent Systems, v. 7, p.\n  115-124, 2010", "doi": "10.3233/HIS-2010-0108", "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The materialist dialectical method is a philosophical investigative method to\nanalyze aspects of reality. These aspects are viewed as complex processes\ncomposed by basic units named poles, which interact with each other. Dialectics\nhas experienced considerable progress in the 19th century, with Hegel's\ndialectics and, in the 20th century, with the works of Marx, Engels, and\nGramsci, in Philosophy and Economics. The movement of poles through their\ncontradictions is viewed as a dynamic process with intertwined phases of\nevolution and revolutionary crisis. In order to build a computational process\nbased on dialectics, the interaction between poles can be modeled using fuzzy\nmembership functions. Based on this assumption, we introduce the Objective\nDialectical Classifier (ODC), a non-supervised map for classification based on\nmaterialist dialectics and designed as an extension of fuzzy c-means\nclassifier. As a case study, we used ODC to classify 181 magnetic resonance\nsynthetic multispectral images composed by proton density, $T_1$- and\n$T_2$-weighted synthetic brain images. Comparing ODC to k-means, fuzzy c-means,\nand Kohonen's self-organized maps, concerning with image fidelity indexes as\nestimatives of quantization distortion, we proved that ODC can reach almost the\nsame quantization performance as optimal non-supervised classifiers like\nKohonen's self-organized maps.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 17:56:15 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Santos", "Wellington Pinheiro dos", ""], ["de Assis", "Francisco Marcos", ""], ["de Souza", "Ricardo Emmanuel", ""], ["Mendes", "Priscilla B.", ""], ["Monteiro", "Henrique S. S.", ""], ["Alves", "Havana Diogo", ""]]}, {"id": "1712.01697", "submitter": "Wellington Pinheiro dos Santos", "authors": "Wellington Pinheiro dos Santos, Francisco Marcos de Assis, Ricardo\n  Emmanuel de Souza, Pl\\'inio Batista dos Santos Filho, Fernando Buarque de\n  Lima Neto", "title": "Dialectical Multispectral Classification of Diffusion-Weighted Magnetic\n  Resonance Images as an Alternative to Apparent Diffusion Coefficients Maps to\n  Perform Anatomical Analysis", "comments": null, "journal-ref": "Computerized Medical Imaging and Graphics, v. 33, p. 442-460, 2009", "doi": "10.1016/j.compmedimag.2009.04.004", "report-no": null, "categories": "cs.CV cs.GR cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multispectral image analysis is a relatively promising field of research with\napplications in several areas, such as medical imaging and satellite\nmonitoring. A considerable number of current methods of analysis are based on\nparametric statistics. Alternatively, some methods in Computational\nIntelligence are inspired by biology and other sciences. Here we claim that\nPhilosophy can be also considered as a source of inspiration. This work\nproposes the Objective Dialectical Method (ODM): a method for classification\nbased on the Philosophy of Praxis. ODM is instrumental in assembling evolvable\nmathematical tools to analyze multispectral images. In the case study described\nin this paper, multispectral images are composed of diffusion-weighted (DW)\nmagnetic resonance (MR) images. The results are compared to ground-truth images\nproduced by polynomial networks using a morphological similarity index. The\nclassification results are used to improve the usual analysis of the apparent\ndiffusion coefficient map. Such results proved that gray and white matter can\nbe distinguished in DW-MR multispectral analysis and, consequently, DW-MR\nimages can also be used to furnish anatomical information.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 18:23:33 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Santos", "Wellington Pinheiro dos", ""], ["de Assis", "Francisco Marcos", ""], ["de Souza", "Ricardo Emmanuel", ""], ["Filho", "Pl\u00ednio Batista dos Santos", ""], ["Neto", "Fernando Buarque de Lima", ""]]}, {"id": "1712.02333", "submitter": "Jian Chen", "authors": "Henan Zhao and Jian Chen", "title": "Bivariate Separable-Dimension Glyphs can Improve Visual Analysis of\n  Holistic Features", "comments": "This version has not been accepted by a conference or journal. We\n  have run new studies thus this work is no longer valid", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the cause of the inefficiency of bivariate glyphs by defining\nthe corresponding error. To recommend efficient and perceptually accurate\nbivariate-glyph design, we present an empirical study of five bivariate glyphs\nbased on three psychophysics principles: integral-separable dimensions, visual\nhierarchy, and pre-attentive pop out, to choose one integral pair\n($length_y-length_x$), three separable pairs ($length-color$, $length-texture$,\n$length_y-length_y$), and one redundant pair ($length_y-color/length_x$).\nTwenty participants performed four tasks requiring: reading numerical values,\nestimating ratio, comparing two points, and looking for extreme values among a\nsubset of points belonging to the same sub-group. The most surprising result\nwas that $length-texture$ was among the most effective methods, suggesting that\nlocal spatial frequency features can lead to global pattern detection that\nfacilitate visual search in complex 3D structure. Our results also reveal the\nfollowing: $length-color$ bivariate glyphs led to the most accurate answers and\nthe least task execution time, while $length_y-length_x$ (integral) dimensions\nwere among the worst and is not recommended; it achieved high performance only\nwhen pop-up color was added.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 18:56:47 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 23:52:50 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Zhao", "Henan", ""], ["Chen", "Jian", ""]]}, {"id": "1712.02494", "submitter": "Jiajun Lu", "authors": "Jiajun Lu, Hussein Sibai, Evan Fabry", "title": "Adversarial Examples that Fool Detectors", "comments": "Follow up paper for adversarial stop signs. Submitted to CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial example is an example that has been adjusted to produce a\nwrong label when presented to a system at test time. To date, adversarial\nexample constructions have been demonstrated for classifiers, but not for\ndetectors. If adversarial examples that could fool a detector exist, they could\nbe used to (for example) maliciously create security hazards on roads populated\nwith smart vehicles. In this paper, we demonstrate a construction that\nsuccessfully fools two standard detectors, Faster RCNN and YOLO. The existence\nof such examples is surprising, as attacking a classifier is very different\nfrom attacking a detector, and that the structure of detectors - which must\nsearch for their own bounding box, and which cannot estimate that box very\naccurately - makes it quite likely that adversarial patterns are strongly\ndisrupted. We show that our construction produces adversarial examples that\ngeneralize well across sequences digitally, even though large perturbations are\nneeded. We also show that our construction yields physical objects that are\nadversarial.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 05:13:54 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Lu", "Jiajun", ""], ["Sibai", "Hussein", ""], ["Fabry", "Evan", ""]]}, {"id": "1712.03380", "submitter": "Siddhartha Chaudhuri", "authors": "Utkarsh Mall, G. Roshan Lal, Siddhartha Chaudhuri, Parag Chaudhuri", "title": "A Deep Recurrent Framework for Cleaning Motion Capture Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep, bidirectional, recurrent framework for cleaning noisy and\nincomplete motion capture data. It exploits temporal coherence and joint\ncorrelations to infer adaptive filters for each joint in each frame. A single\nmodel can be trained to denoise a heterogeneous mix of action types, under\nsubstantial amounts of noise. A signal that has both noise and gaps is\npreprocessed with a second bidirectional network that synthesizes missing\nframes from surrounding context. The approach handles a wide variety of noise\ntypes and long gaps, does not rely on knowledge of the noise distribution, and\noperates in a streaming setting. We validate our approach through extensive\nevaluations on noise both in joint angles and in joint positions, and show that\nit improves upon various alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 12:03:53 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Mall", "Utkarsh", ""], ["Lal", "G. Roshan", ""], ["Chaudhuri", "Siddhartha", ""], ["Chaudhuri", "Parag", ""]]}, {"id": "1712.03574", "submitter": "Bailin Deng", "authors": "Juyong Zhang, Bailin Deng, Yang Hong, Yue Peng, Wenjie Qin, Ligang Liu", "title": "Static/Dynamic Filtering for Mesh Geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint bilateral filter, which enables feature-preserving signal smoothing\naccording to the structural information from a guidance, has been applied for\nvarious tasks in geometry processing. Existing methods either rely on a static\nguidance that may be inconsistent with the input and lead to unsatisfactory\nresults, or a dynamic guidance that is automatically updated but sensitive to\nnoises and outliers. Inspired by recent advances in image filtering, we propose\na new geometry filtering technique called static/dynamic filter, which utilizes\nboth static and dynamic guidances to achieve state-of-the-art results. The\nproposed filter is based on a nonlinear optimization that enforces smoothness\nof the signal while preserving variations that correspond to features of\ncertain scales. We develop an efficient iterative solver for the problem, which\nunifies existing filters that are based on static or dynamic guidances. The\nfilter can be applied to mesh face normals followed by vertex position update,\nto achieve scale-aware and feature-preserving filtering of mesh geometry. It\nalso works well for other types of signals defined on mesh surfaces, such as\ntexture colors. Extensive experimental results demonstrate the effectiveness of\nthe proposed filter for various geometry processing applications such as mesh\ndenoising, geometry feature enhancement, and texture color filtering.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 19:30:00 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 15:35:52 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Zhang", "Juyong", ""], ["Deng", "Bailin", ""], ["Hong", "Yang", ""], ["Peng", "Yue", ""], ["Qin", "Wenjie", ""], ["Liu", "Ligang", ""]]}, {"id": "1712.03686", "submitter": "Maria Perez-Ortiz", "authors": "Maria Perez-Ortiz and Rafal K. Mantiuk", "title": "A practical guide and software for analysing pairwise comparison\n  experiments", "comments": "Code available at https://github.com/mantiuk/pwcmp", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most popular strategies to capture subjective judgments from humans involve\nthe construction of a unidimensional relative measurement scale, representing\norder preferences or judgments about a set of objects or conditions. This\ninformation is generally captured by means of direct scoring, either in the\nform of a Likert or cardinal scale, or by comparative judgments in pairs or\nsets. In this sense, the use of pairwise comparisons is becoming increasingly\npopular because of the simplicity of this experimental procedure. However, this\nstrategy requires non-trivial data analysis to aggregate the comparison ranks\ninto a quality scale and analyse the results, in order to take full advantage\nof the collected data. This paper explains the process of translating pairwise\ncomparison data into a measurement scale, discusses the benefits and\nlimitations of such scaling methods and introduces a publicly available\nsoftware in Matlab. We improve on existing scaling methods by introducing\noutlier analysis, providing methods for computing confidence intervals and\nstatistical testing and introducing a prior, which reduces estimation error\nwhen the number of observers is low. Most of our examples focus on image\nquality assessment.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 09:21:36 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 14:43:34 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Perez-Ortiz", "Maria", ""], ["Mantiuk", "Rafal K.", ""]]}, {"id": "1712.03931", "submitter": "Manolis Savva", "authors": "Manolis Savva, Angel X. Chang, Alexey Dosovitskiy, Thomas Funkhouser,\n  Vladlen Koltun", "title": "MINOS: Multimodal Indoor Simulator for Navigation in Complex\n  Environments", "comments": "MINOS is a simulator designed to support research on end-to-end\n  navigation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MINOS, a simulator designed to support the development of\nmultisensory models for goal-directed navigation in complex indoor\nenvironments. The simulator leverages large datasets of complex 3D environments\nand supports flexible configuration of multimodal sensor suites. We use MINOS\nto benchmark deep-learning-based navigation methods, to analyze the influence\nof environmental complexity on navigation performance, and to carry out a\ncontrolled study of multimodality in sensorimotor learning. The experiments\nshow that current deep reinforcement learning approaches fail in large\nrealistic environments. The experiments also indicate that multimodality is\nbeneficial in learning to navigate cluttered scenes. MINOS is released\nopen-source to the research community at http://minosworld.org . A video that\nshows MINOS can be found at https://youtu.be/c0mL9K64q84\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 18:24:58 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Savva", "Manolis", ""], ["Chang", "Angel X.", ""], ["Dosovitskiy", "Alexey", ""], ["Funkhouser", "Thomas", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1712.04523", "submitter": "Jun Wu", "authors": "Jun Wu", "title": "Continuous Optimization of Adaptive Quadtree Structures", "comments": "Solid and Physical Modeling - SPM 2018", "journal-ref": "Computer-Aided Design 102 (2018) 72-82", "doi": "10.1016/j.cad.2018.04.008", "report-no": null, "categories": "math.NA cs.CE cs.GR cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel continuous optimization method to the discrete problem of\nquadtree optimization. The optimization aims at achieving a quadtree structure\nwith the highest mechanical stiffness, where the edges in the quadtree are\ninterpreted as structural elements carrying mechanical loads. We formulate\nquadtree optimization as a continuous material distribution problem. The\ndiscrete design variables (i.e., to refine or not to refine) are replaced by\ncontinuous variables on multiple levels in the quadtree hierarchy. In discrete\nquadtree optimization, a cell is only eligible for refinement if its parent\ncell has been refined. We propose a continuous analogue to this dependency for\ncontinuous multi-level design variables, and integrate it in the iterative\noptimization process. Our results show that the continuously optimized quadtree\nstructures perform much stiffer than uniform patterns and the heuristically\noptimized counterparts. We demonstrate the use of adaptive structures as\nlightweight infill for 3D printed parts, where uniform geometric patterns have\nbeen typically used in practice.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 21:13:36 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 08:56:03 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Wu", "Jun", ""]]}, {"id": "1712.05548", "submitter": "Paul Rosen", "authors": "Ashley Suh, Mustafa Hajij, Bei Wang, Carlos Scheidegger, Paul Rosen", "title": "Persistent Homology Guided Force-Directed Graph Layouts", "comments": null, "journal-ref": "IEEE Transactions on Visualization and Computer Graphics, vol. 26,\n  no. 1, pp. 697-707, Jan. 2020", "doi": "10.1109/TVCG.2019.2934802", "report-no": null, "categories": "cs.GR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are commonly used to encode relationships among entities, yet their\nabstractness makes them difficult to analyze. Node-link diagrams are popular\nfor drawing graphs, and force-directed layouts provide a flexible method for\nnode arrangements that use local relationships in an attempt to reveal the\nglobal shape of the graph. However, clutter and overlap of unrelated structures\ncan lead to confusing graph visualizations. This paper leverages the persistent\nhomology features of an undirected graph as derived information for interactive\nmanipulation of force-directed layouts. We first discuss how to efficiently\nextract 0-dimensional persistent homology features from both weighted and\nunweighted undirected graphs. We then introduce the interactive persistence\nbarcode used to manipulate the force-directed graph layout. In particular, the\nuser adds and removes contracting and repulsing forces generated by the\npersistent homology features, eventually selecting the set of persistent\nhomology features that most improve the layout. Finally, we demonstrate the\nutility of our approach across a variety of synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 06:06:57 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 22:11:43 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 23:54:22 GMT"}, {"version": "v4", "created": "Fri, 4 Oct 2019 18:20:35 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Suh", "Ashley", ""], ["Hajij", "Mustafa", ""], ["Wang", "Bei", ""], ["Scheidegger", "Carlos", ""], ["Rosen", "Paul", ""]]}, {"id": "1712.05644", "submitter": "Paul Vickers", "authors": "Helen Gibson and Paul Vickers", "title": "graphTPP: A multivariate based method for interactive graph layout and\n  analysis", "comments": "23 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph layout is the process of creating a visual representation of a graph\nthrough a node-link diagram. Node-attribute graphs have additional data stored\non the nodes which describe certain properties of the nodes called attributes.\nTypical force-directed representations often produce hairball-like structures\nthat neither aid in understanding the graph's topology nor the relationship to\nits attributes. The aim of this research was to investigate the use of\nnode-attributes for graph layout in order to improve the analysis process and\nto give further insight into the graph over purely topological layouts. In this\narticle we present graphTPP, a graph based extension to targeted projection\npursuit (TPP) --- an interactive, linear, dimension reduction technique --- as\na method for graph layout and subsequent further analysis. TPP allows users to\ncontrol the projection and is optimised for clustering. Three case studies were\nconducted in the areas of influence graphs, network security, and citation\nnetworks. In each case graphTPP was shown to outperform standard force-directed\ntechniques and even other dimension reduction methods in terms of clarity of\nclustered structure in the layout, the association between the structure and\nthe attributes and the insights elicited in each domain area.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 12:44:27 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Gibson", "Helen", ""], ["Vickers", "Paul", ""]]}, {"id": "1712.06115", "submitter": "Alexander Keller", "authors": "Alexander Keller and Ken Dahm", "title": "Integral Equations and Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As both light transport simulation and reinforcement learning are ruled by\nthe same Fredholm integral equation of the second kind, reinforcement learning\ntechniques may be used for photorealistic image synthesis: Efficiency may be\ndramatically improved by guiding light transport paths by an approximate\nsolution of the integral equation that is learned during rendering. In the\nlight of the recent advances in reinforcement learning for playing games, we\ninvestigate the representation of an approximate solution of an integral\nequation by artificial neural networks and derive a loss function for that\npurpose. The resulting Monte Carlo and quasi-Monte Carlo methods train neural\nnetworks with standard information instead of linear information and naturally\nare able to generate an arbitrary number of training samples. The methods are\ndemonstrated for applications in light transport simulation.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 14:02:19 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 15:48:22 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 07:39:06 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Keller", "Alexander", ""], ["Dahm", "Ken", ""]]}, {"id": "1712.06654", "submitter": "Ignacio Garcia Dorado", "authors": "Ignacio Garcia-Dorado, Pascal Getreuer, Madison Le, Robin Debreuil,\n  Alex Kauffmann, Peyman Milanfar", "title": "Graphic Narrative with Interactive Stylization Design", "comments": "10 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system to convert any set of images (e.g., a video clip or a\nphoto album) into a storyboard. We aim to create multiple pleasing graphic\nrepresentations of the content at interactive rates, so the user can explore\nand find the storyboard (images, layout, and stylization) that best suits their\nneeds and taste. The main challenges of this work are: selecting the content\nimages, placing them into panels, and applying a stylization. For the latter,\nwe propose an interactive design tool to create new stylizations using a wide\nrange of filter blocks. This approach unleashes the creativity by allowing the\nuser to tune, modify, and intuitively design new sequences of filters. In\nparallel to this manual design, we propose a novel procedural approach that\nautomatically assembles sequences of filters for innovative results. We aim to\nkeep the algorithm complexity as low as possible such that it can run\ninteractively on a mobile device. Our results include examples of styles\ndesigned using both our interactive and procedural tools, as well as their\nfinal composition into interesting and appealing storyboards.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 19:58:06 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Garcia-Dorado", "Ignacio", ""], ["Getreuer", "Pascal", ""], ["Le", "Madison", ""], ["Debreuil", "Robin", ""], ["Kauffmann", "Alex", ""], ["Milanfar", "Peyman", ""]]}, {"id": "1712.07485", "submitter": "Ihor Sirenko", "authors": "O. Stelia, L. Potapenko, I. Sirenko", "title": "On the one method of a third-degree bezier type spline curve\n  construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method is proposed for constructing a spline curve of the Bezier type,\nwhich is continuous along with its first derivative by a piecewise polynomial\nfunction. Conditions for its existence and uniqueness are given. The\nconstructed curve lies inside the convex hull of the control points, and the\nsegments of the broken line connecting the control points are tangent to the\ncurve. To construct the curve, we use the approach proposed earlier for\nconstructing a parabolic spline. The idea is to use additional points with\nunknown values of some function. Additional points are used as spline nodes,\nand the function values are determined from the condition of the first\nderivative continuity of a piecewise polynomial curve. In multiple\ninterpolation nodes, the function takes the given values and the values of the\nfirst derivative, which are determined by the control points. Examples of\nconstructing a spline curve are given.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 13:59:27 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Stelia", "O.", ""], ["Potapenko", "L.", ""], ["Sirenko", "I.", ""]]}, {"id": "1712.07540", "submitter": "Sayan Nag", "authors": "Sayan Nag", "title": "Image Registration Techniques: A Survey", "comments": null, "journal-ref": null, "doi": "10.17605/OSF.IO/RV65C", "report-no": null, "categories": "cs.CV cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image Registration is the process of aligning two or more images of the same\nscene with reference to a particular image. The images are captured from\nvarious sensors at different times and at multiple view-points. Thus to get a\nbetter picture of any change of a scene or object over a considerable period of\ntime image registration is important. Image registration finds application in\nmedical sciences, remote sensing and in computer vision. This paper presents a\ndetailed review of several approaches which are classified accordingly along\nwith their contributions and drawbacks. The main steps of an image registration\nprocedure are also discussed. Different performance measures are presented that\ndetermine the registration quality and accuracy. The scope for the future\nresearch are presented as well.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 21:44:28 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Nag", "Sayan", ""]]}, {"id": "1712.09684", "submitter": "Nitin Agarwal", "authors": "Nitin Agarwal, Xiangmin Xu, Gopi Meenakshisundaram", "title": "Geometry Processing of Conventionally Produced Mouse Brain Slice Images", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Brain mapping research in most neuroanatomical laboratories relies on\nconventional processing techniques, which often introduce histological\nartifacts such as tissue tears and tissue loss. In this paper we present\ntechniques and algorithms for automatic registration and 3D reconstruction of\nconventionally produced mouse brain slices in a standardized atlas space. This\nis achieved first by constructing a virtual 3D mouse brain model from annotated\nslices of Allen Reference Atlas (ARA). Virtual re-slicing of the reconstructed\nmodel generates ARA-based slice images corresponding to the microscopic images\nof histological brain sections. These image pairs are aligned using a geometric\napproach through contour images. Histological artifacts in the microscopic\nimages are detected and removed using Constrained Delaunay Triangulation before\nperforming global alignment. Finally, non-linear registration is performed by\nsolving Laplace's equation with Dirichlet boundary conditions. Our methods\nprovide significant improvements over previously reported registration\ntechniques for the tested slices in 3D space, especially on slices with\nsignificant histological artifacts. Further, as an application we count the\nnumber of neurons in various anatomical regions using a dataset of 51\nmicroscopic slices from a single mouse brain. This work represents a\nsignificant contribution to this subfield of neuroscience as it provides tools\nto neuroanatomist for analyzing and processing histological data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 21:05:06 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Agarwal", "Nitin", ""], ["Xu", "Xiangmin", ""], ["Meenakshisundaram", "Gopi", ""]]}]