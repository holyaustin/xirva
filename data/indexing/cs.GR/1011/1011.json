[{"id": "1011.0093", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi", "title": "Fast Color Quantization Using Weighted Sort-Means Clustering", "comments": "30 pages, 2 figures, 4 tables", "journal-ref": "Journal of the Optical Society of America A 26 (2009) 2434-2443", "doi": "10.1364/JOSAA.26.002434", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Color quantization is an important operation with numerous applications in\ngraphics and image processing. Most quantization methods are essentially based\non data clustering algorithms. However, despite its popularity as a general\npurpose clustering algorithm, k-means has not received much respect in the\ncolor quantization literature because of its high computational requirements\nand sensitivity to initialization. In this paper, a fast color quantization\nmethod based on k-means is presented. The method involves several modifications\nto the conventional (batch) k-means algorithm including data reduction, sample\nweighting, and the use of triangle inequality to speed up the nearest neighbor\nsearch. Experiments on a diverse set of images demonstrate that, with the\nproposed modifications, k-means becomes very competitive with state-of-the-art\ncolor quantization methods in terms of both effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 30 Oct 2010 16:56:17 GMT"}], "update_date": "2010-11-02", "authors_parsed": [["Celebi", "M. Emre", ""]]}, {"id": "1011.1787", "submitter": "Bernd R. Schlei", "authors": "B. R. Schlei", "title": "Volume-Enclosing Surface Extraction", "comments": "24 pages, 33 figures, 4 tables, final version", "journal-ref": "Computers and Graphics, Volume 36, Issue 2, 2012, Pages 111 - 130", "doi": "10.1016/j.cag.2011.12.008", "report-no": null, "categories": "cs.CG cs.GR nucl-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new method, which allows for the construction of\ntriangular isosurfaces from three-dimensional data sets, such as 3D image data\nand/or numerical simulation data that are based on regularly shaped, cubic\nlattices. This novel volume-enclosing surface extraction technique, which has\nbeen named VESTA, can produce up to six different results due to the nature of\nthe discretized 3D space under consideration. VESTA is neither template-based\nnor it is necessarily required to operate on 2x2x2 voxel cell neighborhoods\nonly. The surface tiles are determined with a very fast and robust construction\ntechnique while potential ambiguities are detected and resolved. Here, we\nprovide an in-depth comparison between VESTA and various versions of the\nwell-known and very popular Marching Cubes algorithm for the very first time.\nIn an application section, we demonstrate the extraction of VESTA isosurfaces\nfor various data sets ranging from computer tomographic scan data to simulation\ndata of relativistic hydrodynamic fireball expansions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 08:53:59 GMT"}, {"version": "v2", "created": "Mon, 15 Nov 2010 16:52:38 GMT"}, {"version": "v3", "created": "Fri, 23 Sep 2011 08:46:13 GMT"}, {"version": "v4", "created": "Fri, 8 Jun 2012 14:14:44 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Schlei", "B. R.", ""]]}, {"id": "1011.3189", "submitter": "Chamberlain Fong", "authors": "Chamberlain Fong, Brian K. Vogel", "title": "Warping Peirce Quincuncial Panoramas", "comments": "updated source code with figures and explanation of the software\n  implementation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Peirce quincuncial projection is a mapping of the surface of a sphere to\nthe interior of a square. It is a conformal map except for four points on the\nequator. These points of non-conformality cause significant artifacts in\nphotographic applications. In this paper, we propose an algorithm and\nuser-interface to mitigate these artifacts. Moreover, in order to facilitate an\ninteractive user-interface, we present a fast algorithm for calculating the\nPeirce quincuncial projection of spherical imagery. We then promote the Peirce\nquincuncial projection as a viable alternative to the more popular\nstereographic projection in some scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 14 Nov 2010 07:53:26 GMT"}, {"version": "v2", "created": "Tue, 16 Nov 2010 17:28:34 GMT"}, {"version": "v3", "created": "Mon, 25 Jul 2011 03:51:45 GMT"}, {"version": "v4", "created": "Sun, 19 Feb 2012 19:55:47 GMT"}, {"version": "v5", "created": "Sat, 26 Sep 2015 21:26:34 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Fong", "Chamberlain", ""], ["Vogel", "Brian K.", ""]]}, {"id": "1011.3583", "submitter": "Dheevatsa Mudigere", "authors": "Michael Bader, Hans-Joachim Bungartz, Dheevatsa Mudigere, Srihari\n  Narasimhan, Babu Narayanan", "title": "Fast GPGPU Data Rearrangement Kernels using CUDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many high performance-computing algorithms are bandwidth limited, hence the\nneed for optimal data rearrangement kernels as well as their easy integration\ninto the rest of the application. In this work, we have built a CUDA library of\nfast kernels for a set of data rearrangement operations. In particular, we have\nbuilt generic kernels for rearranging m dimensional data into n dimensions,\nincluding Permute, Reorder, Interlace/De-interlace, etc. We have also built\nkernels for generic Stencil computations on a two-dimensional data using\ntemplates and functors that allow application developers to rapidly build\ncustomized high performance kernels. All the kernels built achieve or surpass\nbest-known performance in terms of bandwidth utilization.\n", "versions": [{"version": "v1", "created": "Tue, 16 Nov 2010 04:38:53 GMT"}], "update_date": "2010-11-17", "authors_parsed": [["Bader", "Michael", ""], ["Bungartz", "Hans-Joachim", ""], ["Mudigere", "Dheevatsa", ""], ["Narasimhan", "Srihari", ""], ["Narayanan", "Babu", ""]]}, {"id": "1011.6049", "submitter": "Thomas Houit", "authors": "Thomas Houit and Frank Nielsen", "title": "Video Stippling", "comments": "12 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider rendering color videos using a non-photo-realistic\nart form technique commonly called stippling. Stippling is the art of rendering\nimages using point sets, possibly with various attributes like sizes,\nelementary shapes, and colors. Producing nice stippling is attractive not only\nfor the sake of image depiction but also because it yields a compact vectorial\nformat for storing the semantic information of media. Moreover, stippling is by\nconstruction easily tunable to various device resolutions without suffering\nfrom bitmap sampling artifacts when resizing. The underlying core technique for\nstippling images is to compute a centroidal Voronoi tessellation on a\nwell-designed underlying density. This density relates to the image content,\nand is used to compute a weighted Voronoi diagram. By considering videos as\nimage sequences and initializing properly the stippling of one image by the\nresult of its predecessor, one avoids undesirable point flickering artifacts\nand can produce stippled videos that nevertheless still exhibit noticeable\nartifacts. To overcome this, our method improves over the naive scheme by\nconsidering dynamic point creation and deletion according to the current scene\nsemantic complexity, and show how to effectively vectorize video while\nadjusting for both color and contrast characteristics. Furthermore, we explain\nhow to produce high quality stippled ``videos'' (eg., fully dynamic\nspatio-temporal point sets) for media containing various fading effects, like\nquick motions of objects or progressive shot changes. We report on practical\nperformances of our implementation, and present several stippled video results\nrendered on-the-fly using our viewer that allows both spatio-temporal dynamic\nrescaling (eg., upscale vectorially frame rate).\n", "versions": [{"version": "v1", "created": "Sun, 28 Nov 2010 15:04:34 GMT"}], "update_date": "2010-11-30", "authors_parsed": [["Houit", "Thomas", ""], ["Nielsen", "Frank", ""]]}]