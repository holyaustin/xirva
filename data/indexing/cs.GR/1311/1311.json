[{"id": "1311.0119", "submitter": "Davide Eynard", "authors": "Davide Eynard, Artiom Kovnatsky, Michael M. Bronstein", "title": "Structure-preserving color transformations using Laplacian commutativity", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mappings between color spaces are ubiquitous in image processing problems\nsuch as gamut mapping, decolorization, and image optimization for color-blind\npeople. Simple color transformations often result in information loss and\nambiguities (for example, when mapping from RGB to grayscale), and one wishes\nto find an image-specific transformation that would preserve as much as\npossible the structure of the original image in the target color space. In this\npaper, we propose Laplacian colormaps, a generic framework for\nstructure-preserving color transformations between images. We use the image\nLaplacian to capture the structural information, and show that if the color\ntransformation between two images preserves the structure, the respective\nLaplacians have similar eigenvectors, or in other words, are approximately\njointly diagonalizable. Employing the relation between joint diagonalizability\nand commutativity of matrices, we use Laplacians commutativity as a criterion\nof color mapping quality and minimize it w.r.t. the parameters of a color\ntransformation to achieve optimal structure preservation. We show numerous\napplications of our approach, including color-to-gray conversion, gamut\nmapping, multispectral image fusion, and image optimization for color deficient\nviewers.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2013 08:48:36 GMT"}], "update_date": "2013-11-04", "authors_parsed": [["Eynard", "Davide", ""], ["Kovnatsky", "Artiom", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "1311.0955", "submitter": "Eugene d'Eon", "authors": "Eugene d'Eon", "title": "A Dual-Beam Method-of-Images 3D Searchlight BSSRDF", "comments": "added clarifying text and 1 figure to illustrate the method", "journal-ref": null, "doi": "10.1145/2614106.2614140", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel BSSRDF for rendering translucent materials. Angular\neffects lacking in previous BSSRDF models are incorporated by using a dual-beam\nformulation. We employ a Placzek's Lemma interpretation of the method of images\nand discard diffusion theory. Instead, we derive a plane-parallel\ntransformation of the BSSRDF to form the associated BRDF and optimize the image\nconfiurations such that the BRDF is close to the known analytic solutions for\nthe associated albedo problem. This ensures reciprocity, accurate colors, and\nprovides an automatic level-of-detail transition for translucent objects that\nappear at various distances in an image. Despite optimizing the subsurface\nfluence in a plane-parallel setting, we find that this also leads to fairly\naccurate fluence distributions throughout the volume in the original 3D\nsearchlight problem. Our method-of-images modifications can also improve the\naccuracy of previous BSSRDFs.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 03:25:38 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2013 04:17:37 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["d'Eon", "Eugene", ""]]}, {"id": "1311.4376", "submitter": "Paul Vickers", "authors": "Paul Vickers and Joe Faith and Nick Rossiter", "title": "Understanding Visualization: A Formal Approach using Category Theory and\n  Semiotics", "comments": "15 pages, 14 figures", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics, vol. 19,\n  pp. 1048-1061, 2013", "doi": "10.1109/TVCG.2012.294", "report-no": null, "categories": "cs.LO cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article combines the vocabulary of semiotics and category theory to\nprovide a formal analysis of visualization. It shows how familiar processes of\nvisualization fit the semiotic frameworks of both Saussure and Peirce, and\nextends these structures using the tools of category theory to provide a\ngeneral framework for understanding visualization in practice, including:\nrelationships between systems, data collected from those systems, renderings of\nthose data in the form of representations, the reading of those representations\nto create visualizations, and the use of those visualizations to create\nknowledge and understanding of the system under inspection. The resulting\nframework is validated by demonstrating how familiar information visualization\nconcepts (such as literalness, sensitivity, redundancy, ambiguity,\ngeneralizability, and chart junk) arise naturally from it and can be defined\nformally and precisely. This article generalizes previous work on the formal\ncharacterization of visualization by, inter alia, Ziemkiewicz and Kosara and\nallows us to formally distinguish properties of the visualization process that\nprevious work does not.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 13:51:27 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Vickers", "Paul", ""], ["Faith", "Joe", ""], ["Rossiter", "Nick", ""]]}, {"id": "1311.4665", "submitter": "Stefanie Wuhrer", "authors": "Pegah Kamousi, Sylvain Lazard, Anil Maheshwari, Stefanie Wuhrer", "title": "Analysis of Farthest Point Sampling for Approximating Geodesics in a\n  Graph", "comments": "13 pages, 4 figures", "journal-ref": "Computational Geometry, Elsevier, 2016, 57, pp.1-7", "doi": "10.1016/j.comgeo.2016.05.005", "report-no": null, "categories": "cs.CG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard way to approximate the distance between any two vertices $p$ and\n$q$ on a mesh is to compute, in the associated graph, a shortest path from $p$\nto $q$ that goes through one of $k$ sources, which are well-chosen vertices.\nPrecomputing the distance between each of the $k$ sources to all vertices of\nthe graph yields an efficient computation of approximate distances between any\ntwo vertices. One standard method for choosing $k$ sources, which has been used\nextensively and successfully for isometry-invariant surface processing, is the\nso-called Farthest Point Sampling (FPS), which starts with a random vertex as\nthe first source, and iteratively selects the farthest vertex from the already\nselected sources.\n  In this paper, we analyze the stretch factor $\\mathcal{F}_{FPS}$ of\napproximate geodesics computed using FPS, which is the maximum, over all pairs\nof distinct vertices, of their approximated distance over their geodesic\ndistance in the graph. We show that $\\mathcal{F}_{FPS}$ can be bounded in terms\nof the minimal value $\\mathcal{F}^*$ of the stretch factor obtained using an\noptimal placement of $k$ sources as $\\mathcal{F}_{FPS}\\leq 2 r_e^2\n\\mathcal{F}^*+ 2 r_e^2 + 8 r_e + 1$, where $r_e$ is the ratio of the lengths of\nthe longest and the shortest edges of the graph. This provides some evidence\nexplaining why farthest point sampling has been used successfully for\nisometry-invariant shape processing. Furthermore, we show that it is\nNP-complete to find $k$ sources that minimize the stretch factor.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 09:22:18 GMT"}], "update_date": "2016-08-29", "authors_parsed": [["Kamousi", "Pegah", ""], ["Lazard", "Sylvain", ""], ["Maheshwari", "Anil", ""], ["Wuhrer", "Stefanie", ""]]}, {"id": "1311.5018", "submitter": "Teodor Cioaca", "authors": "Teodor Cioaca and Horea Caramizaru", "title": "On the impact of explicit or semi-implicit integration methods over the\n  stability of real-time numerical simulations", "comments": "Submitted to the ROMAI Journal of Applied Mathematics. Presented at\n  the CAIM 2013 Conference on Applied and Industrial Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Physics-based animation of soft or rigid bodies for real-time applications\noften suffers from numerical instabilities. We analyse one of the most common\nsources of unwanted behaviour: the numerical integration strategy. To assess\nthe impact of popular integration methods, we consider a scenario where soft\nand hard constraints are added to a custom designed deformable linear object.\nSince the goal for this class of simulation methods is to attain interactive\nframe-rates, we present the drawbacks of using explicit integration methods\nover inherently stable, implicit integrators. To help numerical solver\ndesigners better understand the impact of an integrator on a certain simulated\nworld, we have conceived a method of benchmarking the efficiency of an\nintegrator with respect to its speed, stability and symplecticity.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2013 11:30:03 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Cioaca", "Teodor", ""], ["Caramizaru", "Horea", ""]]}, {"id": "1311.5595", "submitter": "Alon Shtern", "authors": "Alon Shtern and Ron Kimmel", "title": "On Nonrigid Shape Similarity and Correspondence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important operation in geometry processing is finding the correspondences\nbetween pairs of shapes. The Gromov-Hausdorff distance, a measure of\ndissimilarity between metric spaces, has been found to be highly useful for\nnonrigid shape comparison. Here, we explore the applicability of related shape\nsimilarity measures to the problem of shape correspondence, adopting spectral\ntype distances. We propose to evaluate the spectral kernel distance, the\nspectral embedding distance and the novel spectral quasi-conformal distance,\ncomparing the manifolds from different viewpoints. By matching the shapes in\nthe spectral domain, important attributes of surface structure are being\naligned. For the purpose of testing our ideas, we introduce a fully automatic\nframework for finding intrinsic correspondence between two shapes. The proposed\nmethod achieves state-of-the-art results on the Princeton isometric shape\nmatching protocol applied, as usual, to the TOSCA and SCAPE benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 22:08:02 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Shtern", "Alon", ""], ["Kimmel", "Ron", ""]]}, {"id": "1311.6811", "submitter": "Yatao Bian", "authors": "Jian Song, Yatao Bian, Junchi Yan, Xu Zhao, Yuncai Liu", "title": "Digitize Your Body and Action in 3-D at Over 10 FPS: Real Time Dense\n  Voxel Reconstruction and Marker-less Motion Tracking via GPU Acceleration", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an approach to reconstruct 3-D human motion from\nmulti-cameras and track human skeleton using the reconstructed human 3-D point\n(voxel) cloud. We use an improved and more robust algorithm, probabilistic\nshape from silhouette to reconstruct human voxel. In addition, the annealed\nparticle filter is applied for tracking, where the measurement is computed\nusing the reprojection of reconstructed voxel. We use two different ways to\naccelerate the approach. For the CPU only acceleration, we leverage Intel TBB\nto speed up the hot spot of the computational overhead and reached an\naccelerating ratio of 3.5 on a 4-core CPU. Moreover, we implement an\nintensively paralleled version via GPU acceleration without TBB. Taking account\nall data transfer and computing time, the GPU version is about 400 times faster\nthan the original CPU implementation, leading the approach to run at a\nreal-time speed.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 18:41:48 GMT"}], "update_date": "2013-11-28", "authors_parsed": [["Song", "Jian", ""], ["Bian", "Yatao", ""], ["Yan", "Junchi", ""], ["Zhao", "Xu", ""], ["Liu", "Yuncai", ""]]}, {"id": "1311.7194", "submitter": "Dmitry Trifonov", "authors": "Dmitry Trifonov", "title": "Real-time High Resolution Fusion of Depth Maps on GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A system for live high quality surface reconstruction using a single moving\ndepth camera on a commodity hardware is presented. High accuracy and real-time\nframe rate is achieved by utilizing graphics hardware computing capabilities\nvia OpenCL and by using sparse data structure for volumetric surface\nrepresentation. Depth sensor pose is estimated by combining serial texture\nregistration algorithm with iterative closest points algorithm (ICP) aligning\nobtained depth map to the estimated scene model. Aligned surface is then fused\ninto the scene. Kalman filter is used to improve fusion quality. Truncated\nsigned distance function (TSDF) stored as block-based sparse buffer is used to\nrepresent surface. Use of sparse data structure greatly increases accuracy of\nscanned surfaces and maximum scanning area. Traditional GPU implementation of\nvolumetric rendering and fusion algorithms were modified to exploit sparsity to\nachieve desired performance. Incorporation of texture registration for sensor\npose estimation and Kalman filter for measurement integration improved accuracy\nand robustness of scanning process.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 03:17:03 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Trifonov", "Dmitry", ""]]}, {"id": "1311.7430", "submitter": "Przemys{\\l}aw Spurek", "authors": "P. Spurek, A. Chaikouskaya, J. Tabor, E. Zaj\\k{a}c", "title": "A local Gaussian filter and adaptive morphology as tools for completing\n  partially discontinuous curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for extraction and analysis of curve--type\nstructures which consist of disconnected components. Such structures are found\nin electron--microscopy (EM) images of metal nanograins, which are widely used\nin the field of nanosensor technology.\n  The topography of metal nanograins in compound nanomaterials is crucial to\nnanosensor characteristics. The method of completing such templates consists of\nthree steps. In the first step, a local Gaussian filter is used with different\nweights for each neighborhood. In the second step, an adaptive morphology\noperation is applied to detect the endpoints of curve segments and connect\nthem. In the last step, pruning is employed to extract a curve which optimally\nfits the template.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 21:45:10 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Spurek", "P.", ""], ["Chaikouskaya", "A.", ""], ["Tabor", "J.", ""], ["Zaj\u0105c", "E.", ""]]}, {"id": "1311.7462", "submitter": "Yi-King Choi", "authors": "Yi-King Choi, Wenping Wang, Bernard Mourrain, Changhe Tu, Xiaohong\n  Jia, Feng Sun", "title": "Continuous Collision Detection for Composite Quadric Models", "comments": "23 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A composite quadric model (CQM) is an object modeled by piecewise linear or\nquadric patches. We study the continuous detection problem of a special type of\nCQM objects which are commonly used in CAD/CAM, that is, the boundary surfaces\nof such a CQM intersect only in straight line segments or conic curve segments.\nWe present a framework for continuous collision detection (CCD) of this special\ntype of CQM (which we also call CQM for brevity) in motion. We derive algebraic\nformulations and compute numerically the first contact time instants and the\ncontact points of two moving CQMs in $\\mathbb R^3$. Since it is difficult to\nprocess CCD of two CQMs in a direct manner because they are composed of\nsemi-algebraic varieties, we break down the problem into subproblems of solving\nCCD of pairs of boundary elements of the CQMs. We present procedures to solve\nCCD of different types of boundary element pairs in different dimensions. Some\nCCD problems are reduced to their equivalents in a lower dimensional setting,\nwhere they can be solved more efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2013 03:08:37 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Choi", "Yi-King", ""], ["Wang", "Wenping", ""], ["Mourrain", "Bernard", ""], ["Tu", "Changhe", ""], ["Jia", "Xiaohong", ""], ["Sun", "Feng", ""]]}, {"id": "1311.7535", "submitter": "Oliver Burghard", "authors": "Oliver Burghard, Alexander Berner, Michael Wand, Niloy Mitra,\n  Hans-Peter Seidel, Reinhard Klein", "title": "Compact Part-Based Shape Spaces for Dense Correspondences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of establishing dense correspondences within a set of\nrelated shapes of strongly varying geometry. For such input, traditional shape\nmatching approaches often produce unsatisfactory results. We propose an\nensemble optimization method that improves given coarse correspondences to\nobtain dense correspondences. Following ideas from minimum description length\napproaches, it maximizes the compactness of the induced shape space to obtain\nhigh-quality correspondences. We make a number of improvements that are\nimportant for computer graphics applications: Our approach handles meshes of\ngeneral topology and handles partial matching between input of varying\ntopology. To this end we introduce a novel part-based generative statistical\nshape model. We develop a novel analysis algorithm that learns such models from\ntraining shapes of varying topology. We also provide a novel synthesis method\nthat can generate new instances with varying part layouts and subject to\ngeneric variational constraints. In practical experiments, we obtain a\nsubstantial improvement in correspondence quality over state-of-the-art\nmethods. As example application, we demonstrate a system that learns shape\nfamilies as assemblies of deformable parts and permits real-time editing with\ncontinuous and discrete variability.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2013 12:03:00 GMT"}, {"version": "v2", "created": "Mon, 9 Oct 2017 11:33:12 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Burghard", "Oliver", ""], ["Berner", "Alexander", ""], ["Wand", "Michael", ""], ["Mitra", "Niloy", ""], ["Seidel", "Hans-Peter", ""], ["Klein", "Reinhard", ""]]}]