[{"id": "1509.01220", "submitter": "Moshe Ben-Ezra", "authors": "Moshe Ben-Ezra", "title": "Light Efficient Flutter Shutter", "comments": "This documnet and the code listing in it are submitted under the\n  permissive MIT License in hope it will be useful. In case anyone is\n  interesting in 2012 date confirmation - the documnet was notarized at MIT on\n  5 Dec 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flutter shutter is a technique in which the exposure is chopped into segments\nand light is only integrated part of the time. By carefully selecting the\nchopping sequence it is possible to better condition the data for\nreconstruction problems such as motion deblurring, focal sweeping, and\ncompressed sensing. The partial exposure trades better conditioning for less\nenergy. In problems such as motion deblurring the available energy is what\ncaused the problem in the first place (as strong illumination allows short\nexposure thus eliminates motion blur). It is still beneficial because the\nbenefit from the better conditioning outweighs the cost in energy.\n  This documents is focused on light efficient flutter shutter that provides\nbetter conditioning and better energy utilization than conventional flutter\nshutter.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2015 00:37:47 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Ben-Ezra", "Moshe", ""]]}, {"id": "1509.03335", "submitter": "Yotam Gingold", "authors": "Jianchao Tan and Jyh-Ming Lien and Yotam Gingold", "title": "Decomposing Digital Paintings into Layers via RGB-space Geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In digital painting software, layers organize paintings. However, layers are\nnot explicitly represented, transmitted, or published with the final digital\npainting. We propose a technique to decompose a digital painting into layers.\nIn our decomposition, each layer represents a coat of paint of a single paint\ncolor applied with varying opacity throughout the image. Our decomposition is\nbased on the painting's RGB-space geometry. In RGB-space, a geometric structure\nis revealed due to the linear nature of the standard Porter-Duff \"over\" pixel\ncompositing operation. The vertices of the convex hull of pixels in RGB-space\nsuggest paint colors. Users choose the degree of simplification to perform on\nthe convex hull, as well as a layer order for the colors. We solve a\nconstrained optimization problem to find maximally translucent, spatially\ncoherent opacity for each layer, such that the composition of the layers\nreproduces the original image. We demonstrate the utility of the resulting\ndecompositions for re-editing.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 20:58:36 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Tan", "Jianchao", ""], ["Lien", "Jyh-Ming", ""], ["Gingold", "Yotam", ""]]}, {"id": "1509.03700", "submitter": "Peter Kovesi", "authors": "Peter Kovesi", "title": "Good Colour Maps: How to Design Them", "comments": "42 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many colour maps provided by vendors have highly uneven perceptual contrast\nover their range. It is not uncommon for colour maps to have perceptual flat\nspots that can hide a feature as large as one tenth of the total data range.\nColour maps may also have perceptual discontinuities that induce the appearance\nof false features. Previous work in the design of perceptually uniform colour\nmaps has mostly failed to recognise that CIELAB space is only designed to be\nperceptually uniform at very low spatial frequencies. The most important factor\nin designing a colour map is to ensure that the magnitude of the incremental\nchange in perceptual lightness of the colours is uniform. The specific\nrequirements for linear, diverging, rainbow and cyclic colour maps are\ndeveloped in detail. To support this work two test images for evaluating colour\nmaps are presented. The use of colour maps in combination with relief shading\nis considered and the conditions under which colour can enhance or disrupt\nrelief shading are identified. Finally, a set of new basis colours for the\nconstruction of ternary images are presented. Unlike the RGB primaries these\nbasis colours produce images whereby the salience of structures are consistent\nirrespective of the assignment of basis colours to data channels.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2015 03:35:20 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Kovesi", "Peter", ""]]}, {"id": "1509.04115", "submitter": "Changsoo Je", "authors": "Changsoo Je, Sang Wook Lee, Rae-Hong Park", "title": "Color-Phase Analysis for Sinusoidal Structured Light in Rapid Range\n  Imaging", "comments": "6 pages, 12 figures. 6th Asian Conference on Computer Vision (ACCV\n  2004)", "journal-ref": "Proc. 6th Asian Conference on Computer Vision (ACCV 2004), vol. 1,\n  pp. 270-275, Jeju Island, Korea, January 27, 2004", "doi": null, "report-no": null, "categories": "cs.CV cs.GR physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active range sensing using structured-light is the most accurate and reliable\nmethod for obtaining 3D information. However, most of the work has been limited\nto range sensing of static objects, and range sensing of dynamic (moving or\ndeforming) objects has been investigated recently only by a few researchers.\nSinusoidal structured-light is one of the well-known optical methods for 3D\nmeasurement. In this paper, we present a novel method for rapid high-resolution\nrange imaging using color sinusoidal pattern. We consider the real-world\nproblem of nonlinearity and color-band crosstalk in the color light projector\nand color camera, and present methods for accurate recovery of color-phase. For\nhigh-resolution ranging, we use high-frequency patterns and describe new\nunwrapping algorithms for reliable range recovery. The experimental results\ndemonstrate the effectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 14:35:20 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Je", "Changsoo", ""], ["Lee", "Sang Wook", ""], ["Park", "Rae-Hong", ""]]}, {"id": "1509.05301", "submitter": "Victor Schetinger", "authors": "Victor Schetinger, Manuel M. Oliveira, Roberto da Silva, Tiago J.\n  Carvalho", "title": "Humans Are Easily Fooled by Digital Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital images are ubiquitous in our modern lives, with uses ranging from\nsocial media to news, and even scientific papers. For this reason, it is\ncrucial evaluate how accurate people are when performing the task of identify\ndoctored images. In this paper, we performed an extensive user study evaluating\nsubjects capacity to detect fake images. After observing an image, users have\nbeen asked if it had been altered or not. If the user answered the image has\nbeen altered, he had to provide evidence in the form of a click on the image.\nWe collected 17,208 individual answers from 383 users, using 177 images\nselected from public forensic databases. Different from other previously\nstudies, our method propose different ways to avoid lucky guess when evaluating\nusers answers. Our results indicate that people show inaccurate skills at\ndifferentiating between altered and non-altered images, with an accuracy of\n58%, and only identifying the modified images 46.5% of the time. We also track\nuser features such as age, answering time, confidence, providing deep analysis\nof how such variables influence on the users' performance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 15:47:25 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Schetinger", "Victor", ""], ["Oliveira", "Manuel M.", ""], ["da Silva", "Roberto", ""], ["Carvalho", "Tiago J.", ""]]}, {"id": "1509.05330", "submitter": "Harry Boyer", "authors": "Ali Hamada Fakra (PIMENT), Fr\\'ed\\'eric Miranville (PIMENT), Dimitri\n  Bigot (PIMENT), Harry Boyer (PIMENT)", "title": "Elements of Validation of Artificial Lighting through the Software\n  CODYRUN: Application to a Test Case of the International Commission on\n  Illumination (CIE)", "comments": "IASTED Power and Energy Systems 2010, Sep 2010, Gaborone, Botswana.\n  2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CODYRUN is a software for computational aeraulic and thermal simulation in\nbuildings developed by the Laboratory of Building Physics and Systems\n(L.P.B.S). Numerical simulation codes of artificial lighting have been\nintroduced to extend the tool capacity. These calculation codes are able to\npredict the amount of light received by any point of a given working plane and\nfrom one or more sources installed on the ceiling of the room. The model used\nfor these calculations is original and semi-detailed (simplified). The test\ncase references of the task-3 TC-33 International Commission on Illumination\n(CIE) were applied to the software to ensure reliability to properly handle\nthis photometric aspect. This allowed having a precise idea about the\nreliability of the results of numerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 09:32:17 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Fakra", "Ali Hamada", "", "PIMENT"], ["Miranville", "Fr\u00e9d\u00e9ric", "", "PIMENT"], ["Bigot", "Dimitri", "", "PIMENT"], ["Boyer", "Harry", "", "PIMENT"]]}, {"id": "1509.05592", "submitter": "Changsoo Je", "authors": "Kwang Hee Lee, Changsoo Je, Sang Wook Lee", "title": "Color-Stripe Structured Light Robust to Surface Color and Discontinuity", "comments": "10 pages, 9 figures, 8th Asian Conference on Computer Vision (ACCV),\n  Tokyo, Japan, November 2007, Proceedings, Part II", "journal-ref": "Computer Vision - ACCV 2007, LNCS 4844, pp. 507-516, Springer\n  Berlin Heidelberg, November 14, 2007", "doi": "10.1007/978-3-540-76390-1_50", "report-no": null, "categories": "cs.CV cs.GR physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple color stripes have been employed for structured light-based rapid\nrange imaging to increase the number of uniquely identifiable stripes. The use\nof multiple color stripes poses two problems: (1) object surface color may\ndisturb the stripe color and (2) the number of adjacent stripes required for\nidentifying a stripe may not be maintained near surface discontinuities such as\noccluding boundaries. In this paper, we present methods to alleviate those\nproblems. Log-gradient filters are employed to reduce the influence of object\ncolors, and color stripes in two and three directions are used to increase the\nchance of identifying correct stripes near surface discontinuities.\nExperimental results demonstrate the effectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 11:26:19 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Lee", "Kwang Hee", ""], ["Je", "Changsoo", ""], ["Lee", "Sang Wook", ""]]}, {"id": "1509.08037", "submitter": "Takahiro Kawabe", "authors": "Takahiro Kawabe, Taiki Fukiage, Masataka Sawayama, Shin'ya Nishida", "title": "Deformation Lamps: A Projection Technique to Make a Static Object\n  Dynamic", "comments": "21 pages, 8 figures", "journal-ref": "ACM Transactions on Applied Perception 13, 2, Article 10, 2016", "doi": "10.1145/2874358", "report-no": null, "categories": "cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Light projection is a powerful technique to edit appearances of objects in\nthe real world. Based on pixel-wise modification of light transport, previous\ntechniques have successfully modified static surface properties such as surface\ncolor, dynamic range, gloss and shading. Here, we propose an alternative light\nprojection technique that adds a variety of illusory, yet realistic distortions\nto a wide range of static 2D and 3D projection targets. The key idea of our\ntechnique, named Deformation Lamps, is to project only dynamic luminance\ninformation, which effectively activates the motion (and shape) processing in\nthe visual system, while preserving the color and texture of the original\nobject. Although the projected dynamic luminance information is spatially\ninconsistent with the color and texture of the target object, the observer's\nbrain automatically com- bines these sensory signals in such a way as to\ncorrect the inconsistency across visual attributes. We conducted a\npsychophysical experiment to investigate the characteristics of the\ninconsistency correction, and found that the correction was dependent\ncritically on the retinal magnitude of inconsistency. Another experiment showed\nthat perceived magnitude of image deformation by our techniques was\nunderestimated. The results ruled out the possibility that the effect by our\ntechnique stemmed simply from the physical change of object appearance by light\nprojection. Finally, we discuss how our techniques can make the observers\nperceive a vivid and natural movement, deformation, or oscillation of a variety\nof static objects, including drawn pictures, printed photographs, sculptures\nwith 3D shading, objects with natural textures including human bodies.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2015 00:07:07 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Kawabe", "Takahiro", ""], ["Fukiage", "Taiki", ""], ["Sawayama", "Masataka", ""], ["Nishida", "Shin'ya", ""]]}, {"id": "1509.08834", "submitter": "Cindy Grimm", "authors": "Ly Phan and Sandra Rugonyi and Cindy Grimm", "title": "Visualization techniques for the developing chicken heart", "comments": "Longer version of conference paper published in 11th International\n  Symposium on Visual Computing (December 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a geometric surface parameterization algorithm and several\nvisualization techniques adapted to the problem of understanding the 4D\nperistaltic-like motion of the outflow tract (OFT) in an embryonic chick heart.\nWe illustrated the techniques using data from hearts under normal conditions\n(four embryos), and hearts in which blood flow conditions are altered through\nOFT banding (four embryos). The overall goal is to create quantitative measures\nof the temporal heart-shape change both within a single subject and between\nmultiple subjects. These measures will help elucidate how altering hemodynamic\nconditions changes the shape and motion of the OFT walls, which in turn\ninfluence the stresses and strains on the developing heart, causing it to\ndevelop differently. We take advantage of the tubular shape and periodic motion\nof the OFT to produce successively lower dimensional visualizations of the\ncardiac motion (e.g. curvature, volume, and cross-section) over time, and\nquantifications of such visualizations.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 16:31:57 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Phan", "Ly", ""], ["Rugonyi", "Sandra", ""], ["Grimm", "Cindy", ""]]}]