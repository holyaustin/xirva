[{"id": "1310.0041", "submitter": "Michael Kazhdan", "authors": "Michael Kazhdan, Randal Burns, Bobby Kasthuri, Jeff Lichtman, Jacob\n  Vogelstein, Joshua Vogelstein", "title": "Gradient-Domain Processing for Large EM Image Stacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new gradient-domain technique for processing registered EM image\nstacks to remove the inter-image discontinuities while preserving intra-image\ndetail. To this end, we process the image stack by first performing anisotropic\ndiffusion to smooth the data along the slice axis and then solving a\nscreened-Poisson equation within each slice to re-introduce the detail. The\nfinal image stack is both continuous across the slice axis (facilitating the\ntracking of information between slices) and maintains sharp details within each\nslice (supporting automatic feature detection). To support this editing, we\ndescribe the implementation of the first multigrid solver designed for\nefficient gradient domain processing of large, out-of-core, voxel grids.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 20:31:10 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Kazhdan", "Michael", ""], ["Burns", "Randal", ""], ["Kasthuri", "Bobby", ""], ["Lichtman", "Jeff", ""], ["Vogelstein", "Jacob", ""], ["Vogelstein", "Joshua", ""]]}, {"id": "1310.1240", "submitter": "Micha{\\l} Romaszewski", "authors": "Micha{\\l} Romaszewski, Piotr Gawron, Sebastian Opozda", "title": "Compression of animated 3D models using HO-SVD", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an analysis of Higher Order Singular Value Decomposition\n(HO-SVD) applied to lossy compression of 3D mesh animations. We describe\nstrategies for choosing a number of preserved spatial and temporal components\nafter tensor decomposition. Compression error is measured using three metrics\n(MSE, Hausdorff, MSDM). Results are compared with a method based on Principal\nComponent Analysis (PCA) and presented on a set of animations with typical mesh\ndeformations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2013 12:27:46 GMT"}], "update_date": "2013-10-07", "authors_parsed": [["Romaszewski", "Micha\u0142", ""], ["Gawron", "Piotr", ""], ["Opozda", "Sebastian", ""]]}, {"id": "1310.1710", "submitter": "Ka Chun Lam", "authors": "Lam Ka Chun and Lok Ming Lui", "title": "Landmark and Intensity Based Registration with Large Deformations via\n  Quasi-conformal Maps", "comments": "27 pages, 21 figures. arXiv admin note: text overlap with\n  arXiv:1307.2679 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG cs.CG cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Registration, which aims to find an optimal one-to-one correspondence between\ndifferent data, is an important problem in various fields. This problem is\nespecially challenging when large deformations occur. In this paper, we present\na novel algorithm to obtain diffeomorphic image or surface registrations with\nlarge deformations via quasi-conformal maps. The basic idea is to minimize an\nenergy functional involving a Beltrami coefficient term, which measures the\ndistortion of the quasi-conformal map. The Beltrami coefficient effectively\ncontrols the bijectivity and smoothness of the registration, even with very\nlarge deformations. Using the proposed algorithm, landmark-based registration\nbetween images or surfaces can be effectively computed. The obtained\nregistration is guaranteed to be diffeomorphic (1-1 and onto), even with a\nlarge deformation or large number of landmark constraints. The proposed\nalgorithm can also be combined with matching intensity (such as image intensity\nor surface curvature) to improve the accuracy of the registration. Experiments\nhave been carried out on both synthetic and real data. Results demonstrate the\nefficacy of the proposed algorithm to obtain diffeomorphic registration between\nimages or surfaces.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 09:17:00 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Chun", "Lam Ka", ""], ["Lui", "Lok Ming", ""]]}, {"id": "1310.2923", "submitter": "Haipeng Cai", "authors": "Haipeng Cai, Jian Chen, Alexander P. Auchus, and David H. Laidlaw", "title": "Composing DTI Visualizations with End-user Programming", "comments": "11 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.HC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design and prototype implementation of a scientific\nvisualization language called Zifazah for composing 3D visualizations of\ndiffusion tensor magnetic resonance imaging (DT-MRI or DTI) data. Unlike\nexisting tools allowing flexible customization of data visualizations that are\nprogrammer-oriented, we focus on domain scientists as end users in order to\nenable them to freely compose visualizations of their scientific data set. We\nanalyzed end-user descriptions extracted from interviews with neurologists and\nphysicians conducting clinical practices using DTI about how they would build\nand use DTI visualizations to collect syntax and semantics for the language\ndesign, and have discovered the elements and structure of the proposed\nlanguage. Zifazah makes use of the initial set of lexical terms and semantics\nto provide a declarative language in the spirit of intuitive syntax and usage.\nThis work contributes three, among others, main design principles for\nscientific visualization language design as well as a practice of such language\nfor DTI visualization with Zifazah. First, Zifazah incorporated visual symbolic\nmapping based on color, size and shape, which is a sub-set of Bertin's taxonomy\nmigrated to scientific visualizations. Second, Zifazah is defined as a spatial\nlanguage whereby lexical representation of spatial relationship for 3D object\nvisualization and manipulations, which is characteristic of scientific data,\ncan be programmed. Third, built on top of Bertin's semiology, flexible data\nencoding specifically for scientific visualizations is integrated in our\nlanguage in order to allow end users to achieve optimal visual composition at\ntheir best. Along with sample scripts representative of our language design\nfeatures, some new DTI visualizations as the running results created by end\nusers using the novel visualization language have also been presented.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 19:16:17 GMT"}], "update_date": "2013-10-11", "authors_parsed": [["Cai", "Haipeng", ""], ["Chen", "Jian", ""], ["Auchus", "Alexander P.", ""], ["Laidlaw", "David H.", ""]]}, {"id": "1310.2994", "submitter": "Haipeng Cai", "authors": "Haipeng Cai, Jian Chen and Alexander P. Auchus", "title": "Depth-dependent Parallel Visualization with 3D Stylized Dense Tubes", "comments": "10 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel visualization algorithm for the illustrative rendering\nof depth-dependent stylized dense tube data at interactive frame rates. While\nthis computation could be efficiently performed on a GPU device, we target a\nparallel framework to enable it to be efficiently running on an ordinary\nmulti-core CPU platform which is much more available than GPUs for common\nusers. Our approach is to map the depth information in each tube onto each of\nthe visual dimensions of shape, color, texture, value, and size on the basis of\nBertin's semiology theory. The purpose is to enable more legible displays in\nthe dense tube environments. A major contribution of our work is an efficient\nand effective parallel depthordering algorithm that makes use of the message\npassing interface (MPI) with VTK. We evaluated our framework with\nvisualizations of depth-stylized tubes derived from 3D diffusion tensor MRI\ndata by comparing its efficiency with several other alternative parallelization\nplatforms running the same computations. As our results show, the\nparallelization framework we proposed can efficiently render highly dense 3D\ndata sets like the tube data and thus is useful as a complement to parallel\nvisualization environments that rely on GPUs.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2013 00:38:49 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2013 01:31:31 GMT"}], "update_date": "2013-10-16", "authors_parsed": [["Cai", "Haipeng", ""], ["Chen", "Jian", ""], ["Auchus", "Alexander P.", ""]]}, {"id": "1310.4389", "submitter": "Ming-Ming Cheng Dr", "authors": "Ming-Ming Cheng, Shuai Zheng, Wen-Yan Lin, Jonathan Warrell, Vibhav\n  Vineet, Paul Sturgess, Nigel Crook, Niloy Mitra, Philip Torr", "title": "ImageSpirit: Verbal Guided Image Parsing", "comments": "http://mmcheng.net/imagespirit/", "journal-ref": "ACM Transactions on Graphics, 2014", "doi": "10.1145/2682628", "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans describe images in terms of nouns and adjectives while algorithms\noperate on images represented as sets of pixels. Bridging this gap between how\nhumans would like to access images versus their typical representation is the\ngoal of image parsing, which involves assigning object and attribute labels to\npixel. In this paper we propose treating nouns as object labels and adjectives\nas visual attribute labels. This allows us to formulate the image parsing\nproblem as one of jointly estimating per-pixel object and attribute labels from\na set of training images. We propose an efficient (interactive time) solution.\nUsing the extracted labels as handles, our system empowers a user to verbally\nrefine the results. This enables hands-free parsing of an image into pixel-wise\nobject/attribute labels that correspond to human semantics. Verbally selecting\nobjects of interests enables a novel and natural interaction modality that can\npossibly be used to interact with new generation devices (e.g. smart phones,\nGoogle Glass, living room devices). We demonstrate our system on a large number\nof real-world images with varying complexity. To help understand the tradeoffs\ncompared to traditional mouse based interactions, results are reported for both\na large scale quantitative evaluation and a user study.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 14:16:31 GMT"}, {"version": "v2", "created": "Wed, 21 May 2014 16:56:03 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Cheng", "Ming-Ming", ""], ["Zheng", "Shuai", ""], ["Lin", "Wen-Yan", ""], ["Warrell", "Jonathan", ""], ["Vineet", "Vibhav", ""], ["Sturgess", "Paul", ""], ["Crook", "Nigel", ""], ["Mitra", "Niloy", ""], ["Torr", "Philip", ""]]}, {"id": "1310.4459", "submitter": "Alon Shtern", "authors": "Alon Shtern and Ron Kimmel", "title": "Matching LBO eigenspace of non-rigid shapes via high order statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental tool in shape analysis is the virtual embedding of the\nRiemannian manifold describing the geometry of a shape into Euclidean space.\nSeveral methods have been proposed to embed isometric shapes in flat domains\nwhile preserving distances measured on the manifold. Recently, attention has\nbeen given to embedding shapes into the eigenspace of the Lapalce-Beltrami\noperator. The Laplace-Beltrami eigenspace preserves the diffusion distance, and\nis invariant under isometric transformations. However, Laplace-Beltrami\neigenfunctions computed independently for different shapes are often\nincompatible with each other. Applications involving multiple shapes, such as\npointwise correspondence, would greatly benefit if their respective\neigenfunctions were somehow matched. Here, we introduce a statistical approach\nfor matching eigenfunctions. We consider the values of the eigenfunctions over\nthe manifold as sampling of random variables, and try to match their\nmultivariate distributions. Comparing distributions is done indirectly, using\nhigh order statistics. We show that the permutation and sign ambiguities of low\norder eigenfunctions, can be inferred by minimizing the difference of their\nthird order moments. The sign ambiguities of antisymmetric eigenfunctions can\nbe resolved by exploiting isometric invariant relations between the gradients\nof the eigenfunctions and the surface normal. We present experiments\ndemonstrating the success of the proposed method applied to feature point\ncorrespondence.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 17:39:34 GMT"}], "update_date": "2013-10-17", "authors_parsed": [["Shtern", "Alon", ""], ["Kimmel", "Ron", ""]]}]