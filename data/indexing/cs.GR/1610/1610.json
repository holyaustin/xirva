[{"id": "1610.00402", "submitter": "Philip Chou", "authors": "Philip A. Chou, Eduardo Pavez, Ricardo L. de Queiroz, and Antonio\n  Ortega", "title": "Dynamic Polygon Clouds: Representation and Compression for VR/AR", "comments": "Microsoft Research Technical Report", "journal-ref": null, "doi": null, "report-no": "MSR-TR-2016-59", "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the {\\em polygon cloud}, also known as a polygon set or {\\em\nsoup}, as a compressible representation of 3D geometry (including its\nattributes, such as color texture) intermediate between polygonal meshes and\npoint clouds. Dynamic or time-varying polygon clouds, like dynamic polygonal\nmeshes and dynamic point clouds, can take advantage of temporal redundancy for\ncompression, if certain challenges are addressed. In this paper, we propose\nmethods for compressing both static and dynamic polygon clouds, specifically\ntriangle clouds. We compare triangle clouds to both triangle meshes and point\nclouds in terms of compression, for live captured dynamic colored geometry. We\nfind that triangle clouds can be compressed nearly as well as triangle meshes,\nwhile being far more robust to noise and other structures typically found in\nlive captures, which violate the assumption of a smooth surface manifold, such\nas lines, points, and ragged boundaries. We also find that triangle clouds can\nbe used to compress point clouds with significantly better performance than\npreviously demonstrated point cloud compression methods. In particular, for\nintra-frame coding of geometry, our method improves upon octree-based\nintra-frame coding by a factor of 5-10 in bit rate. Inter-frame coding improves\nthis by another factor of 2-5. Overall, our dynamic triangle cloud compression\nimproves over the previous state-of-the-art in dynamic point cloud compression\nby 33\\% or more.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 04:25:18 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 06:25:45 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Chou", "Philip A.", ""], ["Pavez", "Eduardo", ""], ["de Queiroz", "Ricardo L.", ""], ["Ortega", "Antonio", ""]]}, {"id": "1610.01691", "submitter": "Niels Joubert", "authors": "Niels Joubert, Jane L. E, Dan B Goldman, Floraine Berthouzoz, Mike\n  Roberts, James A. Landay, Pat Hanrahan", "title": "Towards a Drone Cinematographer: Guiding Quadrotor Cameras using Visual\n  Composition Principles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system to capture video footage of human subjects in the real\nworld. Our system leverages a quadrotor camera to automatically capture\nwell-composed video of two subjects. Subjects are tracked in a large-scale\noutdoor environment using RTK GPS and IMU sensors. Then, given the tracked\nstate of our subjects, our system automatically computes static shots based on\nwell-established visual composition principles and canonical shots from\ncinematography literature. To transition between these static shots, we\ncalculate feasible, safe, and visually pleasing transitions using a novel\nreal-time trajectory planning algorithm. We evaluate the performance of our\ntracking system, and experimentally show that RTK GPS significantly outperforms\nconventional GPS in capturing a variety of canonical shots. Lastly, we\ndemonstrate our system guiding a consumer quadrotor camera autonomously\ncapturing footage of two subjects in a variety of use cases. This is the first\nend-to-end system that enables people to leverage the mobility of quadrotors,\nas well as the knowledge of expert filmmakers, to autonomously capture\nhigh-quality footage of people in the real world.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 23:49:21 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Joubert", "Niels", ""], ["E", "Jane L.", ""], ["Goldman", "Dan B", ""], ["Berthouzoz", "Floraine", ""], ["Roberts", "Mike", ""], ["Landay", "James A.", ""], ["Hanrahan", "Pat", ""]]}, {"id": "1610.02769", "submitter": "Shuang Zhao", "authors": "Shuang Zhao, Fredo Durand, Changxi Zheng", "title": "Inverse Diffusion Curves using Shape Optimization", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse diffusion curve problem focuses on automatic creation of\ndiffusion curve images that resemble user provided color fields. This problem\nis challenging since the 1D curves have a nonlinear and global impact on\nresulting color fields via a partial differential equation (PDE). We introduce\na new approach complementary to previous methods by optimizing curve geometry.\nIn particular, we propose a novel iterative algorithm based on the theory of\nshape derivatives. The resulting diffusion curves are clean and well-shaped,\nand the final image closely approximates the input. Our method provides a\nuser-controlled parameter to regularize curve complexity, and generalizes to\nhandle input color fields represented in a variety of formats.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 03:57:40 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Zhao", "Shuang", ""], ["Durand", "Fredo", ""], ["Zheng", "Changxi", ""]]}, {"id": "1610.03525", "submitter": "Yann Thorimbert", "authors": "Yann Thorimbert, Bastien Chopard", "title": "Polynomial methods for Procedural Terrain Generation", "comments": "27 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method is presented, allowing for the generation of 3D terrain and\ntexture from coherent noise. The method is significantly faster than prevailing\nfractal brownian motion approaches, while producing results of equivalent\nquality. The algorithm is derived through a systematic approach that\ngeneralizes to an arbitrary number of spatial dimensions and gradient\nsmoothness. The results are compared, in terms of performance and quality, to\nfundamental and efficient gradient noise methods widely used in the domain of\nfast terrain generation: Perlin noise and OpenSimplex noise. Finally, to\nobjectively quantify the degree of realism of the results, a fractal analysis\nof the generated landscapes is performed and compared to real terrain data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 20:51:48 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 13:47:38 GMT"}, {"version": "v3", "created": "Sun, 7 Oct 2018 22:39:53 GMT"}, {"version": "v4", "created": "Wed, 5 Dec 2018 16:32:14 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Thorimbert", "Yann", ""], ["Chopard", "Bastien", ""]]}, {"id": "1610.04141", "submitter": "Jesper Molin Jesper Molin", "authors": "Jesper Molin, Anna Bod\\'en, Darren Treanor, Morten Fjeld, and Claes\n  Lundstr\\\"om", "title": "Scale Stain: Multi-Resolution Feature Enhancement in Pathology\n  Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital whole-slide images of pathological tissue samples have recently\nbecome feasible for use within routine diagnostic practice. These gigapixel\nsized images enable pathologists to perform reviews using computer workstations\ninstead of microscopes. Existing workstations visualize scanned images by\nproviding a zoomable image space that reproduces the capabilities of the\nmicroscope. This paper presents a novel visualization approach that enables\nfiltering of the scale-space according to color preference. The visualization\nmethod reveals diagnostically important patterns that are otherwise not\nvisible. The paper demonstrates how this approach has been implemented into a\nfully functional prototype that lets the user navigate the visualization\nparameter space in real time. The prototype was evaluated for two common\nclinical tasks with eight pathologists in a within-subjects study. The data\nreveal that task efficiency increased by 15% using the prototype, with\nmaintained accuracy. By analyzing behavioral strategies, it was possible to\nconclude that efficiency gain was caused by a reduction of the panning needed\nto perform systematic search of the images. The prototype system was well\nreceived by the pathologists who did not detect any risks that would hinder use\nin clinical routine.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 15:51:58 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Molin", "Jesper", ""], ["Bod\u00e9n", "Anna", ""], ["Treanor", "Darren", ""], ["Fjeld", "Morten", ""], ["Lundstr\u00f6m", "Claes", ""]]}, {"id": "1610.04281", "submitter": "Paul Hockett Dr", "authors": "Paul Hockett, Tim Ingleby", "title": "Augmented Reality with Hololens: Experiential Architectures Embedded in\n  the Real World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early hands-on experiences with the Microsoft Hololens augmented/mixed\nreality device are reported and discussed, with a general aim of exploring\nbasic 3D visualization. A range of usage cases are tested, including data\nvisualization and immersive data spaces, in-situ visualization of 3D models and\nfull scale architectural form visualization. Ultimately, the Hololens is found\nto provide a remarkable tool for moving from traditional visualization of 3D\nobjects on a 2D screen, to fully experiential 3D visualizations embedded in the\nreal world.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 22:32:08 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Hockett", "Paul", ""], ["Ingleby", "Tim", ""]]}, {"id": "1610.04531", "submitter": "Hamid Laga", "authors": "Hamid Laga, Qian Xie, Ian H. Jermyn, and Anuj Srivastava", "title": "Numerical Inversion of SRNF Maps for Elastic Shape Analysis of\n  Genus-Zero Surfaces", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2017", "doi": "10.1109/TPAMI.2016.2647596", "report-no": "Volume: 39 , Issue: 12", "categories": "cs.GR cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in elastic shape analysis (ESA) are motivated by the fact\nthat it provides comprehensive frameworks for simultaneous registration,\ndeformation, and comparison of shapes. These methods achieve computational\nefficiency using certain square-root representations that transform invariant\nelastic metrics into Euclidean metrics, allowing for applications of standard\nalgorithms and statistical tools. For analyzing shapes of embeddings of\n$\\mathbb{S}^2$ in $\\mathbb{R}^3$, Jermyn et al. introduced square-root normal\nfields (SRNFs) that transformed an elastic metric, with desirable invariant\nproperties, into the $\\mathbb{L}^2$ metric. These SRNFs are essentially surface\nnormals scaled by square-roots of infinitesimal area elements. A critical need\nin shape analysis is to invert solutions (deformations, averages, modes of\nvariations, etc) computed in the SRNF space, back to the original surface space\nfor visualizations and inferences. Due to the lack of theory for understanding\nSRNFs maps and their inverses, we take a numerical approach and derive an\nefficient multiresolution algorithm, based on solving an optimization problem\nin the surface space, that estimates surfaces corresponding to given SRNFs.\nThis solution is found effective, even for complex shapes, e.g. human bodies\nand animals, that undergo significant deformations including bending and\nstretching. Specifically, we use this inversion for computing elastic shape\ndeformations, transferring deformations, summarizing shapes, and for finding\nmodes of variability in a given collection, while simultaneously registering\nthe surfaces. We demonstrate the proposed algorithms using a statistical\nanalysis of human body shapes, classification of generic surfaces and analysis\nof brain structures.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 16:56:49 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Laga", "Hamid", ""], ["Xie", "Qian", ""], ["Jermyn", "Ian H.", ""], ["Srivastava", "Anuj", ""]]}, {"id": "1610.04861", "submitter": "Asad Khan Mr.", "authors": "Asad Khan, Muhammad Ahmad, Yudong Guo, Ligang Liu", "title": "Digital Makeup from Internet Images", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach of color transfer between images by exploring\ntheir high-level semantic information. First, we set up a database which\nconsists of the collection of downloaded images from the internet, which are\nsegmented automatically by using matting techniques. We then, extract image\nforegrounds from both source and multiple target images. Then by using image\nmatting algorithms, the system extracts the semantic information such as faces,\nlips, teeth, eyes, eyebrows, etc., from the extracted foregrounds of the source\nimage. And, then the color is transferred between corresponding parts with the\nsame semantic information. Next we get the color transferred result by\nseamlessly compositing different parts together using alpha blending. In the\nfinal step, we present an efficient method of color consistency to optimize the\ncolor of a collection of images showing the common scene. The main advantage of\nour method over existing techniques is that it does not need face matching, as\none could use more than one target images. It is not restricted to head shot\nimages as we can also change the color style in the wild. Moreover, our\nalgorithm does not require to choose the same color style, same pose and image\nsize between source and target images. Our algorithm is not restricted to\none-to-one image color transfer and can make use of more than one target images\nto transfer the color in different parts in the source image. Comparing with\nother approaches, our algorithm is much better in color blending in the input\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 16 Oct 2016 13:47:18 GMT"}, {"version": "v2", "created": "Thu, 29 Dec 2016 12:59:37 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Khan", "Asad", ""], ["Ahmad", "Muhammad", ""], ["Guo", "Yudong", ""], ["Liu", "Ligang", ""]]}, {"id": "1610.04936", "submitter": "Zongliang Zhang", "authors": "Zongliang Zhang, Jonathan Li, Yulan Guo, Yangbin Lin, Ming Cheng,\n  Cheng Wang", "title": "Partial Procedural Geometric Model Fitting for Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric model fitting is a fundamental task in computer graphics and\ncomputer vision. However, most geometric model fitting methods are unable to\nfit an arbitrary geometric model (e.g. a surface with holes) to incomplete\ndata, due to that the similarity metrics used in these methods are unable to\nmeasure the rigid partial similarity between arbitrary models. This paper hence\nproposes a novel rigid geometric similarity metric, which is able to measure\nboth the full similarity and the partial similarity between arbitrary geometric\nmodels. The proposed metric enables us to perform partial procedural geometric\nmodel fitting (PPGMF). The task of PPGMF is to search a procedural geometric\nmodel space for the model rigidly similar to a query of non-complete point set.\nModels in the procedural model space are generated according to a set of\nparametric modeling rules. A typical query is a point cloud. PPGMF is very\nuseful as it can be used to fit arbitrary geometric models to non-complete\n(incomplete, over-complete or hybrid-complete) point cloud data. For example,\nmost laser scanning data is non-complete due to occlusion. Our PPGMF method\nuses Markov chain Monte Carlo technique to optimize the proposed similarity\nmetric over the model space. To accelerate the optimization process, the method\nalso employs a novel coarse-to-fine model dividing strategy to reject\ndissimilar models in advance. Our method has been demonstrated on a variety of\ngeometric models and non-complete data. Experimental results show that the\nPPGMF method based on the proposed metric is able to fit non-complete data,\nwhile the method based on other metrics is unable. It is also shown that our\nmethod can be accelerated by several times via early rejection.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 00:47:36 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Zhang", "Zongliang", ""], ["Li", "Jonathan", ""], ["Guo", "Yulan", ""], ["Lin", "Yangbin", ""], ["Cheng", "Ming", ""], ["Wang", "Cheng", ""]]}, {"id": "1610.05351", "submitter": "Jorg Peters", "authors": "Kestutis Karciauskas, Daniele Panozzo and J\\\"org Peters", "title": "Spline surfaces with T-junctions", "comments": "Example of Fig 2 explained Oct 11 2016 at USACM Isogeometric and\n  Meshfree Methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a new way to create smooth piecewise polynomial free-form\nspline surfaces from quad- meshes that include T-junctions, where surface\nstrips start or terminate. All mesh nodes can be interpreted as control points\nof geometrically-smooth, piecewise polynomials that we call GT-splines.\nGT-splines are B-spline-like and cover T-junctions by two or four patches of\ndegree bi-4. They complement multi-sided surface constructions in generating\nfree-form surfaces with adaptive layout. Since GT-splines do not require a\nglobal coordination of knot intervals, GT-constructions are easy to deploy and\ncan provide smooth surfaces with T-junctions where T-splines can not have a\nsmooth parameterization. GT-constructions display a uniform highlight line\ndistribution on input meshes where alternatives, such as Catmull-Clark\nsubdivision, exhibit oscillations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 20:46:12 GMT"}, {"version": "v2", "created": "Mon, 1 May 2017 20:39:55 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Karciauskas", "Kestutis", ""], ["Panozzo", "Daniele", ""], ["Peters", "J\u00f6rg", ""]]}, {"id": "1610.07368", "submitter": "Patrick Seemann", "authors": "Patrick Seemann, Simon Fuhrmann, Stefan Guthe, Fabian Langguth, and\n  Michael Goesele", "title": "Simplification of Multi-Scale Geometry using Adaptive Curvature Fields", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm to compute multi-scale curvature fields on\ntriangle meshes. Our algorithm is based on finding robust mean curvatures using\nthe ball neighborhood, where the radius of a ball corresponds to the scale of\nthe features. The essential problem is to find a good radius for each ball to\nobtain a reliable curvature estimation. We propose an algorithm that finds\nsuitable radii in an automatic way. In particular, our algorithm is applicable\nto meshes produced by image-based reconstruction systems. These meshes often\ncontain geometric features at various scales, for example if certain regions\nhave been captured in greater detail. We also show how such a multi-scale\ncurvature field can be converted to a density field and used to guide\napplications like mesh simplification.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 11:34:13 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 17:36:37 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Seemann", "Patrick", ""], ["Fuhrmann", "Simon", ""], ["Guthe", "Stefan", ""], ["Langguth", "Fabian", ""], ["Goesele", "Michael", ""]]}, {"id": "1610.09534", "submitter": "Lan Xu", "authors": "Lan Xu, Lu Fang, Wei Cheng, Kaiwen Guo, Guyue Zhou, Qionghai Dai, and\n  Yebin Liu", "title": "FlyCap: Markerless Motion Capture Using Multiple Autonomous Flying\n  Cameras", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming at automatic, convenient and non-instrusive motion capture, this paper\npresents a new generation markerless motion capture technique, the FlyCap\nsystem, to capture surface motions of moving characters using multiple\nautonomous flying cameras (autonomous unmanned aerial vehicles(UAV) each\nintegrated with an RGBD video camera). During data capture, three cooperative\nflying cameras automatically track and follow the moving target who performs\nlarge scale motions in a wide space. We propose a novel non-rigid surface\nregistration method to track and fuse the depth of the three flying cameras for\nsurface motion tracking of the moving target, and simultaneously calculate the\npose of each flying camera. We leverage the using of visual-odometry\ninformation provided by the UAV platform, and formulate the surface tracking\nproblem in a non-linear objective function that can be linearized and\neffectively minimized through a Gaussian-Newton method. Quantitative and\nqualitative experimental results demonstrate the competent and plausible\nsurface and motion reconstruction results\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 15:44:07 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 05:33:30 GMT"}, {"version": "v3", "created": "Tue, 29 Nov 2016 08:30:19 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Xu", "Lan", ""], ["Fang", "Lu", ""], ["Cheng", "Wei", ""], ["Guo", "Kaiwen", ""], ["Zhou", "Guyue", ""], ["Dai", "Qionghai", ""], ["Liu", "Yebin", ""]]}, {"id": "1610.09988", "submitter": "Petra Surynkova", "authors": "Petra Surynkova", "title": "Selecting the Best Quadrilateral Mesh for Given Planar Shape", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of mesh matching is addressed in this work. For a given n-sided\nplanar region bounded by one loop of n polylines we are selecting optimal\nquadrilateral mesh from existing catalogue of meshes. The formulation of\nmatching between planar shape and quadrilateral mesh from the catalogue is\nbased on the problem of finding longest common subsequence (LCS). Theoretical\nfoundation of mesh matching method is provided. Suggested method represents a\nviable technique for selecting best mesh for planar region and stepping stone\nfor further parametrization of the region.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 15:56:30 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Surynkova", "Petra", ""]]}, {"id": "1610.09992", "submitter": "Heidi Elisabeth Iuell Dahl", "authors": "Vibeke Skytt, Quillon Harpham, Tor Dokken and Heidi E.I. Dahl", "title": "Deconfliction and Surface Generation from Bathymetry Data Using LR\n  B-splines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set of bathymetry point clouds acquired by different measurement techniques\nat different times, having different accuracy and varying patterns of points,\nare approximated by an LR B-spline surface. The aim is to represent the sea\nbottom with good accuracy and at the same time reduce the data size\nconsiderably. In this process the point clouds must be cleaned by selecting the\n\"best\" points for surface generation. This cleaning process is called\ndeconfliction, and we use a rough approximation of the combined point clouds as\na reference surface to select a consistent set of points. The reference surface\nis updated with the selected points to create an accurate approximation. LR\nB-splines is the selected surface format due to its suitability for adaptive\nrefinement and approximation, and its ability to represent local detail without\na global increase in the data size of the surface\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 16:08:42 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Skytt", "Vibeke", ""], ["Harpham", "Quillon", ""], ["Dokken", "Tor", ""], ["Dahl", "Heidi E. I.", ""]]}]