[{"id": "1605.00423", "submitter": "Musabbir Majeed", "authors": "Musabbir Majeed, Fehmi Cirak", "title": "Isogeometric analysis using manifold-based smooth basis functions", "comments": "27 pages, 25 figures", "journal-ref": null, "doi": "10.1016/j.cma.2016.08.013", "report-no": null, "categories": "cs.NA cs.GR math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an isogeometric analysis technique that builds on manifold-based\nsmooth basis functions for geometric modelling and analysis. Manifold-based\nsurface construction techniques are well known in geometric modelling and a\nnumber of variants exist. Common to all is the concept of constructing a smooth\nsurface by blending together overlapping patches (or, charts), as in\ndifferential geometry description of manifolds. Each patch on the surface has a\ncorresponding planar patch with a smooth one-to-one mapping onto the surface.\nIn our implementation, manifold techniques are combined with conformal\nparametrisations and the partition-of-unity method for deriving smooth basis\nfunctions on unstructured quadrilateral meshes. Each vertex and its adjacent\nelements on the surface control mesh have a corresponding planar patch of\nelements. The star-shaped planar patch with congruent wedge-shaped elements is\nsmoothly parameterised with copies of a conformally mapped unit square. The\nconformal maps can be easily inverted in order to compute the transition\nfunctions between the different planar patches that have an overlap on the\nsurface. On the collection of star-shaped planar patches the partition of unity\nmethod is used for approximation. The smooth partition of unity, or blending\nfunctions, are assembled from tensor-product b-spline segments defined on a\nunit square. On each patch a polynomial with a prescribed degree is used as a\nlocal approximant. To obtain a mesh-based approximation scheme, the\ncoefficients of the local approximants are expressed in dependence of vertex\ncoefficients. This yields a basis function for each vertex of the mesh which is\nsmooth and non-zero over a vertex and its adjacent elements. Our numerical\nsimulations indicate the optimal convergence of the resulting approximation\nscheme for Poisson problems and near optimal convergence for thin-plate and\nthin-shell problems.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 10:35:23 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Majeed", "Musabbir", ""], ["Cirak", "Fehmi", ""]]}, {"id": "1605.01396", "submitter": "Henry Segerman", "authors": "Saul Schleimer and Henry Segerman", "title": "Squares that Look Round: Transforming Spherical Images", "comments": "10 pages, 9 figures with many subfigures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR math.HO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose M\\\"obius transformations as the natural rotation and scaling tools\nfor editing spherical images. As an application we produce spherical Droste\nimages. We obtain other self-similar visual effects using rational functions,\nelliptic functions, and Schwarz-Christoffel maps.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 19:45:32 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Schleimer", "Saul", ""], ["Segerman", "Henry", ""]]}, {"id": "1605.01760", "submitter": "Tyson Brochu", "authors": "Ryan Schmidt and Tyson Brochu", "title": "Adaptive Mesh Booleans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for performing Boolean operations on volumes\nrepresented as triangle meshes. In contrast to existing methods which treat\nmeshes as 3D polyhedra and try to partition the faces at their exact\nintersection curves, we treat meshes as adaptive surfaces which can be\narbitrarily refined. Rather than depending on computing precise face\nintersections, our approach refines the input meshes in the intersection\nregions, then discards intersecting triangles and fills the resulting holes\nwith high-quality triangles. The original intersection curves are approximated\nto a user-definable precision, and our method can identify and preserve creases\nand sharp features. Advantages of our approach include the ability to trade\nspeed for accuracy, support for open meshes, and the ability to incorporate\ntolerances to handle cases where large numbers of faces are slightly\ninter-penetrating or near-coincident.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 21:25:54 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Schmidt", "Ryan", ""], ["Brochu", "Tyson", ""]]}, {"id": "1605.01816", "submitter": "Zhuo Diao", "authors": "Xujin Chen, Zhuo Diao, Xiaodong Hu and Zhongzheng Tang", "title": "Sufficient Conditions for Tuza's Conjecture on Packing and Covering\n  Triangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a simple graph $G=(V,E)$, a subset of $E$ is called a triangle cover if\nit intersects each triangle of $G$. Let $\\nu_t(G)$ and $\\tau_t(G)$ denote the\nmaximum number of pairwise edge-disjoint triangles in $G$ and the minimum\ncardinality of a triangle cover of $G$, respectively. Tuza conjectured in 1981\nthat $\\tau_t(G)/\\nu_t(G)\\le2$ holds for every graph $G$. In this paper, using a\nhypergraph approach, we design polynomial-time combinatorial algorithms for\nfinding small triangle covers. These algorithms imply new sufficient conditions\nfor Tuza's conjecture on covering and packing triangles. More precisely,\nsuppose that the set $\\mathscr T_G$ of triangles covers all edges in $G$. We\nshow that a triangle cover of $G$ with cardinality at most $2\\nu_t(G)$ can be\nfound in polynomial time if one of the following conditions is satisfied: (i)\n$\\nu_t(G)/|\\mathscr T_G|\\ge\\frac13$, (ii) $\\nu_t(G)/|E|\\ge\\frac14$, (iii)\n$|E|/|\\mathscr T_G|\\ge2$.\n  Keywords: Triangle cover, Triangle packing, Linear 3-uniform hypergraphs,\nCombinatorial algorithms\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 04:17:12 GMT"}, {"version": "v2", "created": "Wed, 11 May 2016 08:12:30 GMT"}, {"version": "v3", "created": "Tue, 24 May 2016 05:44:40 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Chen", "Xujin", ""], ["Diao", "Zhuo", ""], ["Hu", "Xiaodong", ""], ["Tang", "Zhongzheng", ""]]}, {"id": "1605.02245", "submitter": "Claudio Paglia", "authors": "Claudio Paglia", "title": "Real-time collision detection method for deformable bodies", "comments": "Computer-Aided Design, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a real-time solution for collision detection between\nobjects based on the physics properties. Traditional approaches on collision\ndetection often rely on the geometric relationships that computing the\nintersections between polygons. Such technique is very computationally\nexpensive when applied for deformable objects. As an alternative, we\napproximate the 3D mesh in an spherical surface implicitly. This allows us to\nperform a coarse-level collision detection at extremely fast speed. Then a\ndynamic programming based procedure is applied to identify the collision in\nfine details. Our method demonstrates better prevention to collision tunnelling\nand works more efficiently than the state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 20:41:58 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Paglia", "Claudio", ""]]}, {"id": "1605.04731", "submitter": "Xianye Liang", "authors": "Xianye Liang, Bocheng Zhuo, Peijie Li, Liangju He", "title": "CNN based texture synthesize with Semantic segment", "comments": "7 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:1505.07376, arXiv:1604.04339, arXiv:1602.07188 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithm display powerful ability in Computer Vision area, in\nrecent year, the CNN has been applied to solve problems in the subarea of\nImage-generating, which has been widely applied in areas such as photo editing,\nimage design, computer animation, real-time rendering for large scale of scenes\nand for visual effects in movies. However in the texture synthesize procedure.\nThe state-of-art CNN can not capture the spatial location of texture in image,\nlead to significant distortion after texture synthesize, we propose a new way\nto generating-image by adding the semantic segment step with deep learning\nalgorithm as Pre-Processing and analyze the outcome.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 11:24:03 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Liang", "Xianye", ""], ["Zhuo", "Bocheng", ""], ["Li", "Peijie", ""], ["He", "Liangju", ""]]}, {"id": "1605.04797", "submitter": "Qingnan Zhou", "authors": "Qingnan Zhou, Alec Jacobson", "title": "Thingi10K: A Dataset of 10,000 3D-Printing Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirically validating new 3D-printing related algorithms and implementations\nrequires testing data representative of inputs encountered \\emph{in the wild}.\nAn ideal benchmarking dataset should not only draw from the same distribution\nof shapes people print in terms of class (e.g., toys, mechanisms, jewelry),\nrepresentation type (e.g., triangle soup meshes) and complexity (e.g., number\nof facets), but should also capture problems and artifacts endemic to 3D\nprinting models (e.g., self-intersections, non-manifoldness). We observe that\nthe contextual and geometric characteristics of 3D printing models differ\nsignificantly from those used for computer graphics applications, not to\nmention standard models (e.g., Stanford bunny, Armadillo, Fertility). We\npresent a new dataset of 10,000 models collected from an online 3D printing\nmodel-sharing database. Via analysis of both geometric (e.g., triangle aspect\nratios, manifoldness) and contextual (e.g., licenses, tags, classes)\ncharacteristics, we demonstrate that this dataset represents a more concise\nsummary of real-world models used for 3D printing compared to existing\ndatasets. To facilitate future research endeavors, we also present an online\nquery interface to select subsets of the dataset according to project-specific\ncharacteristics. The complete dataset and per-model statistical data are freely\navailable to the public.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 15:09:19 GMT"}, {"version": "v2", "created": "Sat, 2 Jul 2016 03:15:10 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Zhou", "Qingnan", ""], ["Jacobson", "Alec", ""]]}, {"id": "1605.06215", "submitter": "Gary Pui-Tung Choi", "authors": "Chun Pang Yung, Gary P. T. Choi, Ke Chen, Lok Ming Lui", "title": "Efficient Feature-based Image Registration by Mapping Sparsified\n  Surfaces", "comments": null, "journal-ref": "Journal of Visual Communication and Image Representation 55,\n  561-571 (2018)", "doi": "10.1016/j.jvcir.2018.07.005", "report-no": null, "categories": "cs.GR cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement in the digital camera technology, the use of high\nresolution images and videos has been widespread in the modern society. In\nparticular, image and video frame registration is frequently applied in\ncomputer graphics and film production. However, conventional registration\napproaches usually require long computational time for high resolution images\nand video frames. This hinders the application of the registration approaches\nin the modern industries. In this work, we first propose a new image\nrepresentation method to accelerate the registration process by triangulating\nthe images effectively. For each high resolution image or video frame, we\ncompute an optimal coarse triangulation which captures the important features\nof the image. Then, we apply a surface registration algorithm to obtain a\nregistration map which is used to compute the registration of the high\nresolution image. Experimental results suggest that our overall algorithm is\nefficient and capable to achieve a high compression rate while the accuracy of\nthe registration is well retained when compared with the conventional\ngrid-based approach. Also, the computational time of the registration is\nsignificantly reduced using our triangulation-based approach.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 05:42:12 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 03:32:25 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Yung", "Chun Pang", ""], ["Choi", "Gary P. T.", ""], ["Chen", "Ke", ""], ["Lui", "Lok Ming", ""]]}, {"id": "1605.06242", "submitter": "Eamonn Maguire", "authors": "Eamonn Maguire, Javier Martin Montull, Gilles Louppe", "title": "Visualization of Publication Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Measuring scholarly impact has been a topic of much interest in recent years.\nWhile many use the citation count as a primary indicator of a publications\nimpact, the quality and impact of those citations will vary. Additionally, it\nis often difficult to see where a paper sits among other papers in the same\nresearch area. Questions we wished to answer through this visualization were:\nis a publication cited less than publications in the field?; is a publication\ncited by high or low impact publications?; and can we visually compare the\nimpact of publications across a result set? In this work we address the above\nquestions through a new visualization of publication impact. Our technique has\nbeen applied to the visualization of citation information in INSPIREHEP\n(http://www.inspirehep.net), the largest high energy physics publication\nrepository.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 08:29:28 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Maguire", "Eamonn", ""], ["Montull", "Javier Martin", ""], ["Louppe", "Gilles", ""]]}, {"id": "1605.07829", "submitter": "Marco Attene", "authors": "Marco Attene", "title": "As-exact-as-possible repair of unprintable STL files", "comments": null, "journal-ref": "Rapid Prototyping Journal (2018)", "doi": "10.1108/RPJ-11-2016-0185", "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: The class of models that can be represented by STL files is larger\nthan the class of models that can be printed using additive manufacturing\ntechnologies. Stated differently, there exist well-formed STL files that cannot\nbe printed. In this paper such a gap is formalized and a fully automatic\nprocedure is described to turn any such file into a printable model.\n  Approach: Based on well-established concepts from combinatorial topology, we\nprovide an unambiguous description of all the mathematical entities involved in\nthe modeling-printing pipeline. Specifically, we formally define the conditions\nthat an STL file must satisfy to be printable and, based on these, we design an\nas-exact-as-possible repairing algorithm.\n  Findings: We have found that, in order to cope with all the possible triangle\nconfigurations, the algorithm must distinguish between triangles that bound\nsolid parts and triangles that constitute zero-thickness sheets. Only the\nformer set can be fixed without distortion.\n  Originality: Previous methods that are guaranteed to fix all the possible\nconfigurations provide only approximate solutions with an unnecessary\ndistortion. Conversely, our procedure is as exact as possible, meaning that no\nvisible distortion is introduced unless it is strictly imposed by limitations\nof the printing device. Thanks to such an unprecedented flexibility and\naccuracy, this algorithm is expected to significantly simplify the\nmodeling-printing process, in particular within the continuously emerging\nnon-professional \"maker\" communities.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 11:16:00 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 11:53:20 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 14:41:52 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Attene", "Marco", ""]]}, {"id": "1605.09451", "submitter": "Flora Ponjou Tasse", "authors": "Flora Ponjou Tasse and Ji\\v{r}\\'i Kosinka and Neil Anthony Dodgson", "title": "Quantitative Analysis of Saliency Models", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous saliency detection research required the reader to evaluate\nperformance qualitatively, based on renderings of saliency maps on a few\nshapes. This qualitative approach meant it was unclear which saliency models\nwere better, or how well they compared to human perception. This paper provides\na quantitative evaluation framework that addresses this issue. In the first\nquantitative analysis of 3D computational saliency models, we evaluate four\ncomputational saliency models and two baseline models against ground-truth\nsaliency collected in previous work.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 00:33:04 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Tasse", "Flora Ponjou", ""], ["Kosinka", "Ji\u0159\u00ed", ""], ["Dodgson", "Neil Anthony", ""]]}, {"id": "1605.09737", "submitter": "Vaibhav Vavilala", "authors": "Vaibhav Vavilala", "title": "3D Printed Stencils for Texturing Flat Surfaces", "comments": "4 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of texturing flat surfaces by spray-painting through\n3D printed stencils. We propose a system that (1) decomposes an image into\nalpha-blended layers; (2) computes a stippling given a transparency channel;\n(3) generates a 3D printed stencil given a stippling and (4) simulates the\neffects of spray-painting through the stencil.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 17:39:49 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Vavilala", "Vaibhav", ""]]}]