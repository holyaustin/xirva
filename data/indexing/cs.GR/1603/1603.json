[{"id": "1603.00546", "submitter": "Jan Egger", "authors": "Jan Egger, Philip Voglreiter, Mark Dokter, Michael Hofmann, Xiaojun\n  Chen, Wolfram G. Zoller, Dieter Schmalstieg, Alexander Hann", "title": "US-Cut: Interactive Algorithm for rapid Detection and Segmentation of\n  Liver Tumors in Ultrasound Acquisitions", "comments": "6 pages, 6 figures, 1 table, 32 references", "journal-ref": "SPIE Medical Imaging Conference 2016, Paper 9790-47", "doi": "10.1117/12.2216509", "report-no": null, "categories": "cs.CV cs.CE cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound (US) is the most commonly used liver imaging modality worldwide.\nIt plays an important role in follow-up of cancer patients with liver\nmetastases. We present an interactive segmentation approach for liver tumors in\nUS acquisitions. Due to the low image quality and the low contrast between the\ntumors and the surrounding tissue in US images, the segmentation is very\nchallenging. Thus, the clinical practice still relies on manual measurement and\noutlining of the tumors in the US images. We target this problem by applying an\ninteractive segmentation algorithm to the US data, allowing the user to get\nreal-time feedback of the segmentation results. The algorithm has been\ndeveloped and tested hand-in-hand by physicians and computer scientists to make\nsure a future practical usage in a clinical setting is feasible. To cover\ntypical acquisitions from the clinical routine, the approach has been evaluated\nwith dozens of datasets where the tumors are hyperechoic (brighter), hypoechoic\n(darker) or isoechoic (similar) in comparison to the surrounding liver tissue.\nDue to the interactive real-time behavior of the approach, it was possible even\nin difficult cases to find satisfying segmentations of the tumors within\nseconds and without parameter settings, and the average tumor deviation was\nonly 1.4mm compared with manual measurements. However, the long term goal is to\nease the volumetric acquisition of liver tumors in order to evaluate for\ntreatment response. Additional aim is the registration of intraoperative US\nimages via the interactive segmentations to the patient's pre-interventional CT\nacquisitions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 01:42:48 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Egger", "Jan", ""], ["Voglreiter", "Philip", ""], ["Dokter", "Mark", ""], ["Hofmann", "Michael", ""], ["Chen", "Xiaojun", ""], ["Zoller", "Wolfram G.", ""], ["Schmalstieg", "Dieter", ""], ["Hann", "Alexander", ""]]}, {"id": "1603.00713", "submitter": "Christian Santoni", "authors": "Christian Santoni, Gabriele Salvati, Valentina Tibaldo and Fabio\n  Pellacini", "title": "LevelMerge: Collaborative Game Level Editing by Merging Labeled Graphs", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game level editing is the process of constructing a full game level starting\nfrom 3D asset libraries, e.g. 3d models, textures, shaders, scripts. In level\nediting, designers define the look and behavior of the whole level by placing\nobjects, assigning materials and lighting parameters, setting animations and\nphysics properties and customizing the objects AI and behavior by editing\nscripts. The heterogeneity of the task usually translates to a workflow where a\nteam of people, experts on separate aspects, cooperate to edit the game level,\noften working on the same objects (e.g.: a programmer working on the AI of a\ncharacter, while an artist works on its 3D model or its materials). Today this\ncollaboration is established by using version control systems designed for text\ndocuments, such as Git, to manage different versions and share them amongst\nusers. The merge algorithms used in these systems though does not perform well\nin our case since it does not respect the relations between game objects\nnecessary to maintain the semantic of the game level behavior and look. This is\na known problem and commercial systems for game level merging exists, e.g.\nPlasticSCM, but these are only slightly more robust than text-based ones. This\ncauses designers to often merge scenes manually, essentially reapplying others\nedits in the game level editor.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 13:52:41 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Santoni", "Christian", ""], ["Salvati", "Gabriele", ""], ["Tibaldo", "Valentina", ""], ["Pellacini", "Fabio", ""]]}, {"id": "1603.00960", "submitter": "Jan Egger", "authors": "Jan Egger, Christopher Nimsky", "title": "Cellular Automata Segmentation of the Boundary between the Compacta of\n  Vertebral Bodies and Surrounding Structures", "comments": "6 pages, 5 figures, 1 table, 42 references", "journal-ref": "SPIE Medical Imaging Conference 2016, Paper 9787-52", "doi": "10.1117/12.2209039", "report-no": null, "categories": "cs.CV cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the aging population, spinal diseases get more and more common\nnowadays; e.g., lifetime risk of osteoporotic fracture is 40% for white women\nand 13% for white men in the United States. Thus the numbers of surgical spinal\nprocedures are also increasing with the aging population and precise diagnosis\nplays a vital role in reducing complication and recurrence of symptoms. Spinal\nimaging of vertebral column is a tedious process subjected to interpretation\nerrors. In this contribution, we aim to reduce time and error for vertebral\ninterpretation by applying and studying the GrowCut-algorithm for boundary\nsegmentation between vertebral body compacta and surrounding structures.\nGrowCut is a competitive region growing algorithm using cellular automata. For\nour study, vertebral T2-weighted Magnetic Resonance Imaging (MRI) scans were\nfirst manually outlined by neurosurgeons. Then, the vertebral bodies were\nsegmented in the medical images by a GrowCut-trained physician using the\nsemi-automated GrowCut-algorithm. Afterwards, results of both segmentation\nprocesses were compared using the Dice Similarity Coefficient (DSC) and the\nHausdorff Distance (HD) which yielded to a DSC of 82.99+/-5.03% and a HD of\n18.91+/-7.2 voxel, respectively. In addition, the times have been measured\nduring the manual and the GrowCut segmentations, showing that a\nGrowCut-segmentation - with an average time of less than six minutes\n(5.77+/-0.73) - is significantly shorter than a pure manual outlining.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2016 03:35:07 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Egger", "Jan", ""], ["Nimsky", "Christopher", ""]]}, {"id": "1603.00961", "submitter": "Jan Egger", "authors": "Tobias L\\\"uddemann, Jan Egger", "title": "Interactive and Scale Invariant Segmentation of the Rectum/Sigmoid via\n  User-Defined Templates", "comments": "6 pages, 4 figures, 1 table, 43 references", "journal-ref": "SPIE Medical Imaging Conference 2016, Paper 9784-113", "doi": "10.1117/12.2216226", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among all types of cancer, gynecological malignancies belong to the 4th most\nfrequent type of cancer among women. Besides chemotherapy and external beam\nradiation, brachytherapy is the standard procedure for the treatment of these\nmalignancies. In the progress of treatment planning, localization of the tumor\nas the target volume and adjacent organs of risks by segmentation is crucial to\naccomplish an optimal radiation distribution to the tumor while simultaneously\npreserving healthy tissue. Segmentation is performed manually and represents a\ntime-consuming task in clinical daily routine. This study focuses on the\nsegmentation of the rectum/sigmoid colon as an Organ-At-Risk in gynecological\nbrachytherapy. The proposed segmentation method uses an interactive,\ngraph-based segmentation scheme with a user-defined template. The scheme\ncreates a directed two dimensional graph, followed by the minimal cost closed\nset computation on the graph, resulting in an outlining of the rectum. The\ngraphs outline is dynamically adapted to the last calculated cut. Evaluation\nwas performed by comparing manual segmentations of the rectum/sigmoid colon to\nresults achieved with the proposed method. The comparison of the algorithmic to\nmanual results yielded to a Dice Similarity Coefficient value of 83.85+/-4.08%,\nin comparison to 83.97+/-8.08% for the comparison of two manual segmentations\nof the same physician. Utilizing the proposed methodology resulted in a median\ntime of 128 seconds per dataset, compared to 300 seconds needed for pure manual\nsegmentation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2016 03:39:59 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["L\u00fcddemann", "Tobias", ""], ["Egger", "Jan", ""]]}, {"id": "1603.03482", "submitter": "Nathan Egge", "authors": "Nathan E. Egge and Jean-Marc Valin", "title": "Predicting Chroma from Luma with Frequency Domain Intra Prediction", "comments": "10 pages, 7 figures", "journal-ref": "Proceedings of SPIE 9410, Visual Information Processing and\n  Communication VI, 941009 (March 4, 2015)", "doi": "10.1117/12.2080837", "report-no": null, "categories": "cs.MM cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a technique for performing intra prediction of the\nchroma planes based on the reconstructed luma plane in the frequency domain.\nThis prediction exploits the fact that while RGB to YUV color conversion has\nthe property that it decorrelates the color planes globally across an image,\nthere is still some correlation locally at the block level. Previous proposals\ncompute a linear model of the spatial relationship between the luma plane (Y)\nand the two chroma planes (U and V). In codecs that use lapped transforms this\nis not possible since transform support extends across the block boundaries and\nthus neighboring blocks are unavailable during intra-prediction. We design a\nfrequency domain intra predictor for chroma that exploits the same local\ncorrelation with lower complexity than the spatial predictor and which works\nwith lapped transforms. We then describe a low-complexity algorithm that\ndirectly uses luma coefficients as a chroma predictor based on gain-shape\nquantization and band partitioning. An experiment is performed that compares\nthese two techniques inside the experimental Daala video codec and shows the\nlower complexity algorithm to be a better chroma predictor.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 22:55:36 GMT"}], "update_date": "2016-03-14", "authors_parsed": [["Egge", "Nathan E.", ""], ["Valin", "Jean-Marc", ""]]}, {"id": "1603.04060", "submitter": "Zherong Pan", "authors": "Zherong Pan, Jin Huang, Hujun Bao", "title": "Modelling Developable Ribbons Using Ruling Bending Coordinates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new method for modelling the dynamic behaviour of\ndevelopable ribbons, two dimensional strips with much smaller width than\nlength. Instead of approximating such surface with a general triangle mesh, we\ncharacterize it by a set of creases and bending angles across them. This\nrepresentation allows the developability to be satisfied everywhere while still\nleaves enough degree of freedom to represent salient global deformation. We\nshow how the potential and kinetic energies can be properly discretized in this\nconfiguration space and time integrated in a fully implicit manner. The result\nis a dynamic simulator with several desirable features: We can model\nnon-trivial deformation using much fewer elements than conventional FEM method.\nIt is stable under extreme deformation, external force or large timestep size.\nAnd we can readily handle various user constraints in Euclidean space.\n", "versions": [{"version": "v1", "created": "Sun, 13 Mar 2016 18:38:15 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Pan", "Zherong", ""], ["Huang", "Jin", ""], ["Bao", "Hujun", ""]]}, {"id": "1603.04292", "submitter": "Shizuo Kaji", "authors": "Alexandre Derouet-Jourdan, Shizuo Kaji, Yoshihiro Mizoguchi", "title": "A linear algorithm for Brick Wang tiling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wang tiling is a classical problem in combinatorics. A major theoretical\nquestion is to find a (small) set of tiles which tiles the plane only\naperiodically. In this case, resulting tilings are rather restrictive. On the\nother hand, Wang tiles are used as a tool to generate textures and patterns in\ncomputer graphics. In these applications, a set of tiles is normally chosen so\nthat it tiles the plane or its sub-regions easily in many different ways. With\ncomputer graphics applications in mind, we introduce a class of such tileset,\nwhich we call sequentially permissive tilesets, and consider tiling problems\nwith constrained boundary. We apply our methodology to a special set of Wang\ntiles, called Brick Wang tiles, introduced by Derouet-Jourdan et al. in 2015 to\nmodel wall patterns. We generalise their result by providing a linear algorithm\nto decide and solve the tiling problem for arbitrary planar regions with holes.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 14:59:41 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 08:55:12 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Derouet-Jourdan", "Alexandre", ""], ["Kaji", "Shizuo", ""], ["Mizoguchi", "Yoshihiro", ""]]}, {"id": "1603.05433", "submitter": "Przemys{\\l}aw Gospodarczyk MSc.", "authors": "Przemys{\\l}aw Gospodarczyk, Stanis{\\l}aw Lewanowicz, Pawe{\\l} Wo\\'zny", "title": "Degree reduction of composite B\\'ezier curves", "comments": null, "journal-ref": "Applied Mathematics and Computation 293, p. 40-48 (2017)", "doi": "10.1016/j.amc.2016.08.004", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of multi-degree reduction of a composite\nB\\'ezier curve with the parametric continuity constraints at the endpoints of\nthe segments. We present a novel method which is based on the idea of using\nconstrained dual Bernstein polynomials to compute the control points of the\nreduced composite curve. In contrast to other methods, ours minimizes the\n$L_2$-error for the whole composite curve instead of minimizing the\n$L_2$-errors for each segment separately. As a result, an additional\noptimization is possible. Examples show that the new method gives much better\nresults than multiple application of the degree reduction of a single B\\'ezier\ncurve.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 11:30:01 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2016 09:34:34 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Gospodarczyk", "Przemys\u0142aw", ""], ["Lewanowicz", "Stanis\u0142aw", ""], ["Wo\u017any", "Pawe\u0142", ""]]}, {"id": "1603.06078", "submitter": "Oliver Nalbach", "authors": "Oliver Nalbach, Elena Arabadzhiyska, Dushyant Mehta, Hans-Peter\n  Seidel, Tobias Ritschel", "title": "Deep Shading: Convolutional Neural Networks for Screen-Space Shading", "comments": null, "journal-ref": null, "doi": "10.1111/cgf.13225", "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision, convolutional neural networks (CNNs) have recently\nachieved new levels of performance for several inverse problems where RGB pixel\nappearance is mapped to attributes such as positions, normals or reflectance.\nIn computer graphics, screen-space shading has recently increased the visual\nquality in interactive image synthesis, where per-pixel attributes such as\npositions, normals or reflectance of a virtual 3D scene are converted into RGB\npixel appearance, enabling effects like ambient occlusion, indirect light,\nscattering, depth-of-field, motion blur, or anti-aliasing. In this paper we\nconsider the diagonal problem: synthesizing appearance from given per-pixel\nattributes using a CNN. The resulting Deep Shading simulates various\nscreen-space effects at competitive quality and speed while not being\nprogrammed by human experts but learned from example images.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2016 10:29:57 GMT"}, {"version": "v2", "created": "Wed, 3 Aug 2016 11:11:55 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Nalbach", "Oliver", ""], ["Arabadzhiyska", "Elena", ""], ["Mehta", "Dushyant", ""], ["Seidel", "Hans-Peter", ""], ["Ritschel", "Tobias", ""]]}, {"id": "1603.06143", "submitter": "Daniel Ritchie", "authors": "Daniel Ritchie, Anna Thomas, Pat Hanrahan, Noah D. Goodman", "title": "Neurally-Guided Procedural Models: Amortized Inference for Procedural\n  Graphics Programs using Neural Networks", "comments": null, "journal-ref": "Neural Information Processing Systems (NIPS 2016)", "doi": null, "report-no": null, "categories": "cs.GR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic inference algorithms such as Sequential Monte Carlo (SMC)\nprovide powerful tools for constraining procedural models in computer graphics,\nbut they require many samples to produce desirable results. In this paper, we\nshow how to create procedural models which learn how to satisfy constraints. We\naugment procedural models with neural networks which control how the model\nmakes random choices based on the output it has generated thus far. We call\nsuch models neurally-guided procedural models. As a pre-computation, we train\nthese models to maximize the likelihood of example outputs generated via SMC.\nThey are then used as efficient SMC importance samplers, generating\nhigh-quality results with very few samples. We evaluate our method on\nL-system-like models with image-based constraints. Given a desired quality\nthreshold, neurally-guided models can generate satisfactory results up to 10x\nfaster than unguided models.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2016 20:58:47 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2016 20:10:09 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Ritchie", "Daniel", ""], ["Thomas", "Anna", ""], ["Hanrahan", "Pat", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1603.06821", "submitter": "Steven Gortler", "authors": "Hui Zhao and Steven J. Gortler", "title": "A Report on Shape Deformation with a Stretching and Bending Energy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we describe a mesh editing system that we implemented that\nuses a natural stretching and bending energy defined over smooth surfaces. As\nsuch, this energy behaves uniformly under various mesh resolutions. All of the\nelements of our approach already exist in the literature. We hope that our\ndiscussions of these energies helps to shed light on the behaviors of these\nmethods and provides a unified discussion of these methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 15:14:21 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Zhao", "Hui", ""], ["Gortler", "Steven J.", ""]]}, {"id": "1603.07011", "submitter": "Mohammadreza Ashouri", "authors": "Mohammadreza Ashouri, Ali Golshani, Dara Moazzmi, Mandana Ghasemi", "title": "Graphs Drawing through Fuzzy Clustering", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems can be presented in an abstract form through a wide range of\nbinary objects and relations which are defined over problem domain. In these\nproblems, graphical demonstration of defined binary objects and solutions is\nthe most suitable representation approach. In this regard, graph drawing\nproblem discusses the methods for transforming combinatorial graphs to\ngeometrical drawings in order to visualize them. This paper studies the\nforce-directed algorithms and multi-surface techniques for drawing general\nundirected graphs. Particularly, this research describes force-directed\napproach to model the drawing of a general graph as a numerical optimization\nproblem. So, it can use rich knowledge which is presented as an established\nsystem by the numerical optimization. Moreover, this research proposes the\nmulti-surface approach as an efficient tool for overcoming local minimums in\nstandard force-directed algorithms. Next, we introduce a new method for\nmulti-surface approach based on fuzzy clustering algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 22:14:01 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Ashouri", "Mohammadreza", ""], ["Golshani", "Ali", ""], ["Moazzmi", "Dara", ""], ["Ghasemi", "Mandana", ""]]}, {"id": "1603.08551", "submitter": "Hugo Martay Dr", "authors": "Hugo Martay", "title": "Genetic cellular neural networks for generating three-dimensional\n  geometry", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a number of ways to procedurally generate interesting\nthree-dimensional shapes, and a method where a cellular neural network is\ncombined with a mesh growth algorithm is presented here. The aim is to create a\nshape from a genetic code in such a way that a crude search can find\ninteresting shapes. Identical neural networks are placed at each vertex of a\nmesh which can communicate with neural networks on neighboring vertices. The\noutput of the neural networks determine how the mesh grows, allowing\ninteresting shapes to be produced emergently, mimicking some of the complexity\nof biological organism development. Since the neural networks' parameters can\nbe freely mutated, the approach is amenable for use in a genetic algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 20:28:09 GMT"}], "update_date": "2016-03-30", "authors_parsed": [["Martay", "Hugo", ""]]}, {"id": "1603.08753", "submitter": "Liangliang Nan", "authors": "Yuanhao Cao, Liangliang Nan, Peter Wonka", "title": "Curve Networks for Surface Reconstruction", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Man-made objects usually exhibit descriptive curved features (i.e., curve\nnetworks). The curve network of an object conveys its high-level geometric and\ntopological structure. We present a framework for extracting feature curve\nnetworks from unstructured point cloud data. Our framework first generates a\nset of initial curved segments fitting highly curved regions. We then optimize\nthese curved segments to respect both data fitting and structural regularities.\nFinally, the optimized curved segments are extended and connected into curve\nnetworks using a clustering method. To facilitate effectiveness in case of\nsevere missing data and to resolve ambiguities, we develop a user interface for\ncompleting the curve networks. Experiments on various imperfect point cloud\ndata validate the effectiveness of our curve network extraction framework. We\ndemonstrate the usefulness of the extracted curve networks for surface\nreconstruction from incomplete point clouds.\n", "versions": [{"version": "v1", "created": "Tue, 29 Mar 2016 13:02:50 GMT"}], "update_date": "2016-03-30", "authors_parsed": [["Cao", "Yuanhao", ""], ["Nan", "Liangliang", ""], ["Wonka", "Peter", ""]]}, {"id": "1603.08984", "submitter": "Aron Monszpart", "authors": "Aron Monszpart, Nils Thuerey, Niloy J. Mitra", "title": "SMASH: Physics-guided Reconstruction of Collisions from Videos", "comments": "SIGGRAPH Asia 2016", "journal-ref": "ACM Trans. Graph. 35, 6, Article 199 (November 2016), 14 pages\n  (2016)", "doi": "10.1145/2980179.2982421", "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collision sequences are commonly used in games and entertainment to add drama\nand excitement. Authoring even two body collisions in the real world can be\ndifficult, as one has to get timing and the object trajectories to be correctly\nsynchronized. After tedious trial-and-error iterations, when objects can\nactually be made to collide, then they are difficult to capture in 3D. In\ncontrast, synthetically generating plausible collisions is difficult as it\nrequires adjusting different collision parameters (e.g., object mass ratio,\ncoefficient of restitution, etc.) and appropriate initial parameters. We\npresent SMASH to directly read off appropriate collision parameters directly\nfrom raw input video recordings. Technically we enable this by utilizing laws\nof rigid body collision to regularize the problem of lifting 2D trajectories to\na physically valid 3D reconstruction of the collision. The reconstructed\nsequences can then be modified and combined to easily author novel and\nplausible collisions. We evaluate our system on a range of synthetic scenes and\ndemonstrate the effectiveness of our method by accurately reconstructing\nseveral complex real world collision events.\n", "versions": [{"version": "v1", "created": "Tue, 29 Mar 2016 22:18:29 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 11:09:34 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Monszpart", "Aron", ""], ["Thuerey", "Nils", ""], ["Mitra", "Niloy J.", ""]]}]