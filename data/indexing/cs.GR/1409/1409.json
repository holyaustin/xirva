[{"id": "1409.1714", "submitter": "Emiliano Cristiani", "authors": "Simone Cacace and Emiliano Cristiani and Leonardo Rocchi", "title": "A level set based method for fixing overhangs in 3D printing", "comments": null, "journal-ref": "Appl. Math. Model., 44 (2017), 446-455", "doi": "10.1016/j.apm.2017.02.004", "report-no": null, "categories": "math.NA cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D printers based on the Fused Decomposition Modeling create objects\nlayer-by-layer dropping fused material. As a consequence, strong overhangs\ncannot be printed because the new-come material does not find a suitable\nsupport over the last deposed layer. In these cases, one can add some support\nstructures (scaffolds) which make the object printable, to be removed at the\nend. In this paper we propose a level set method to create object-dependent\nsupport structures, specifically conceived to reduce both the amount of\nadditional material and the printing time. We also review some open problems\nabout 3D printing which can be of interests for the mathematical community.\n", "versions": [{"version": "v1", "created": "Fri, 5 Sep 2014 10:00:35 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2016 20:08:25 GMT"}, {"version": "v3", "created": "Mon, 3 Oct 2016 10:28:33 GMT"}, {"version": "v4", "created": "Wed, 7 Dec 2016 14:05:05 GMT"}, {"version": "v5", "created": "Fri, 24 Feb 2017 21:02:06 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Cacace", "Simone", ""], ["Cristiani", "Emiliano", ""], ["Rocchi", "Leonardo", ""]]}, {"id": "1409.2081", "submitter": "Juntao Ye", "authors": "Juntao Ye", "title": "History-free Collision Response for Deformable Surfaces", "comments": "originally 4 pages, submitted as Technical Brief to Siggraph Asia\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous collision detection (CCD) and response methods are widely adopted\nin dynamics simulation of deformable models. They are history-based, as their\nsuccess is strictly based on an assumption of a collision-free state at the\nstart of each time interval. On the other hand, in many applications surfaces\nhave normals defined to designate their orientation (i.e. front- and\nback-face), yet CCD methods are totally blind to such orientation\nidentification (thus are orientation-free). We notice that if such information\nis utilized, many penetrations can be untangled. In this paper we present a\nhistory-free method for separation of two penetrating meshes, where at least\none of them has clarified surface orientation. This method first computes all\nedge-face (E-F) intersections with discrete collision detection (DCD), and then\nbuilds a number of penetration stencils. On response, the stencil vertices are\nrelocated into a penetration-free state, via a global displacement minimizer.\nOur method is very effective for handling penetration between two meshes, being\nit an initial configuration or in the middle of physics simulation. The major\nlimitation is that it is not applicable to self-collision within one mesh at\nthe time being.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 04:34:11 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Ye", "Juntao", ""]]}, {"id": "1409.2235", "submitter": "Qi Mo", "authors": "Qi Mo, Hengchin Yeh, Dinesh Manocha", "title": "Tracing Analytic Ray Curves for Light and Sound Propagation in\n  Non-linear Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The physical world consists of spatially varying media, such as the\natmosphere and the ocean, in which light and sound propagates along non-linear\ntrajectories. This presents a challenge to existing ray-tracing based methods,\nwhich are widely adopted to simulate propagation due to their efficiency and\nflexibility, but assume linear rays. We present a novel algorithm that traces\nanalytic ray curves computed from local media gradients, and utilizes the\nclosed-form solutions of both the intersections of the ray curves with planar\nsurfaces, and the travel distance. By constructing an adaptive unstructured\nmesh, our algorithm is able to model general media profiles that vary in three\ndimensions with complex boundaries consisting of terrains and other scene\nobjects such as buildings. We trace the analytic ray curves using the adaptive\nunstructured mesh, which considerably improves the efficiency over prior\nmethods. We highlight the algorithm's application on simulation of sound and\nvisual propagation in outdoor scenes.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 08:19:21 GMT"}, {"version": "v2", "created": "Tue, 9 Sep 2014 01:25:09 GMT"}, {"version": "v3", "created": "Sat, 13 Sep 2014 23:59:10 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Mo", "Qi", ""], ["Yeh", "Hengchin", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1409.5024", "submitter": "Agrima Seth", "authors": "Agrima Seth, Deepak Mishra", "title": "Comparative Study of Geometric and Image Based Modelling and Rendering\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a comparative study of the traditional 3D computer graphics technique\nof geometric modelling and image-based rendering techniques that were surveyed\nand implemented.We have discussed the classifications and representative\nmethods of both the techniques. The study has shown that there is a strong\ncontinuum between both the techniques and a hybrid of the two is most suitable\nfor further implementations.This hybridisation study is underway to create\nmodels of real life situations and provide disaster management training.\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2014 00:46:26 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Seth", "Agrima", ""], ["Mishra", "Deepak", ""]]}, {"id": "1409.5758", "submitter": "Pierre De Loor", "authors": "Elisabetta Bevacqua (CERV, Lab-STICC), Sankovic Igor (CERV,\n  Lab-STICC), Maatalaoui Ayoub (Lab-STICC), A. N\\'ed\\'elec (Lab-STICC), Pierre\n  De Loor (CERV, Lab-STICC)", "title": "Effects of Coupling in Human-Virtual Agent Body Interaction", "comments": "appears in Intelligent Virtual Agents, 14th International Conference,\n  IVA 2014, Boston : \\'Etats-Unis (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study of the dynamic coupling between a user and a\nvirtual character during body interaction. Coupling is directly linked with\nother dimensions, such as co-presence, engagement, and believability, and was\nmeasured in an experiment that allowed users to describe their subjective\nfeelings about those dimensions of interest. The experiment was based on a\ntheatrical game involving the imitation of slow upper-body movements and the\nproposal of new movements by the user and virtual agent. The agent's behaviour\nvaried in autonomy: the agent could limit itself to imitating the user's\nmovements only, initiate new movements, or combine both behaviours. After the\ngame, each participant completed a questionnaire regarding their engagement in\nthe interaction, their subjective feeling about the co-presence of the agent,\netc. Based on four main dimensions of interest, we tested several hypotheses\nagainst our experimental results, which are discussed here.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 18:49:11 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Bevacqua", "Elisabetta", "", "CERV, Lab-STICC"], ["Igor", "Sankovic", "", "CERV,\n  Lab-STICC"], ["Ayoub", "Maatalaoui", "", "Lab-STICC"], ["N\u00e9d\u00e9lec", "A.", "", "Lab-STICC"], ["De Loor", "Pierre", "", "CERV, Lab-STICC"]]}, {"id": "1409.7256", "submitter": "Yihui Xie", "authors": "Yihui Xie, Heike Hofmann, Xiaoyue Cheng", "title": "Reactive Programming for Interactive Graphics", "comments": "Published in at http://dx.doi.org/10.1214/14-STS477 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2014, Vol. 29, No. 2, 201-213", "doi": "10.1214/14-STS477", "report-no": "IMS-STS-STS477", "categories": "cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the big challenges of developing interactive statistical applications\nis the management of the data pipeline, which controls transformations from\ndata to plot. The user's interactions needs to be propagated through these\nmodules and reflected in the output representation at a fast pace. Each\nindividual module may be easy to develop and manage, but the dependency\nstructure can be quite challenging. The MVC (Model/View/Controller) pattern is\nan attempt to solve the problem by separating the user's interaction from the\nrepresentation of the data. In this paper we discuss the paradigm of reactive\nprogramming in the framework of the MVC architecture and show its applicability\nto interactive graphics. Under this paradigm, developers benefit from the\nseparation of user interaction from the graphical representation, which makes\nit easier for users and developers to extend interactive applications. We show\nthe central role of reactive data objects in an interactive graphics system,\nimplemented as the R package cranvas, which is freely available on GitHub and\nthe main developers include the authors of this paper.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 10:39:46 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Xie", "Yihui", ""], ["Hofmann", "Heike", ""], ["Cheng", "Xiaoyue", ""]]}, {"id": "1409.7724", "submitter": "Vijay Gadepally", "authors": "Zachary Weber and Vijay Gadepally", "title": "Using 3D Printing to Visualize Social Media Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data volume continues to grow at unprecedented rates. One of the key\nfeatures that makes big data valuable is the promise to find unknown patterns\nor correlations that may be able to improve the quality of processes or\nsystems. Unfortunately, with the exponential growth in data, users often have\ndifficulty in visualizing the often-unstructured, non-homogeneous data coming\nfrom a variety of sources. The recent growth in popularity of 3D printing has\nushered in a revolutionary way to interact with big data. Using a 3D printed\nmockup up a physical or notional environment, one can display data on the\nmockup to show real-time data patterns. In this poster and demonstration, we\ndescribe the process of 3D printing and demonstrate an application of\ndisplaying Twitter data on a 3D mockup of the Massachusetts Institute of\nTechnology (MIT) campus, known as LuminoCity.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 19:17:11 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Weber", "Zachary", ""], ["Gadepally", "Vijay", ""]]}]