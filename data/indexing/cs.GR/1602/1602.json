[{"id": "1602.00328", "submitter": "Konstantinos Rematas", "authors": "Konstantinos Rematas, Chuong Nguyen, Tobias Ritschel, Mario Fritz and\n  Tinne Tuytelaars", "title": "Novel Views of Objects from a Single Image", "comments": "to appear in PAMI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking an image of an object is at its core a lossy process. The rich\ninformation about the three-dimensional structure of the world is flattened to\nan image plane and decisions such as viewpoint and camera parameters are final\nand not easily revertible. As a consequence, possibilities of changing\nviewpoint are limited. Given a single image depicting an object, novel-view\nsynthesis is the task of generating new images that render the object from a\ndifferent viewpoint than the one given. The main difficulty is to synthesize\nthe parts that are disoccluded; disocclusion occurs when parts of an object are\nhidden by the object itself under a specific viewpoint. In this work, we show\nhow to improve novel-view synthesis by making use of the correlations observed\nin 3D models and applying them to new image instances. We propose a technique\nto use the structural information extracted from a 3D model that matches the\nimage object in terms of viewpoint and shape. For the latter part, we propose\nan efficient 2D-to-3D alignment method that associates precisely the image\nappearance with the 3D model geometry with minimal user interaction. Our\ntechnique is able to simulate plausible viewpoint changes for a variety of\nobject classes within seconds. Additionally, we show that our synthesized\nimages can be used as additional training data that improves the performance of\nstandard object detectors.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 21:43:13 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2016 03:03:50 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Rematas", "Konstantinos", ""], ["Nguyen", "Chuong", ""], ["Ritschel", "Tobias", ""], ["Fritz", "Mario", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1602.01224", "submitter": "Jan Vr\\v{s}ek", "authors": "Miroslav L\\'avi\\v{c}ka, Zbyn\\v{e}k \\v{S}\\'ir, and Jan Vr\\v{s}ek", "title": "Smooth surface interpolation using patches with rational offsets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for the interpolation of given data points and\nassociated normals with surface parametric patches with rational normal fields.\nWe give some arguments why a dual approach is the most convenient for these\nsurfaces, which are traditionally called Pythagorean normal vector (PN)\nsurfaces. Our construction is based on the isotropic model of the dual space to\nwhich the original data are pushed. Then the bicubic Coons patches are\nconstructed in the isotropic space and then pulled back to the standard three\ndimensional space. As a result we obtain the patch construction which is\ncompletely local and produces surfaces with the global G1~continuity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 08:24:21 GMT"}, {"version": "v2", "created": "Fri, 16 Sep 2016 10:41:05 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["L\u00e1vi\u010dka", "Miroslav", ""], ["\u0160\u00edr", "Zbyn\u011bk", ""], ["Vr\u0161ek", "Jan", ""]]}, {"id": "1602.01644", "submitter": "Jan Egger", "authors": "Xiaojun Chen, Lu Xu, Yue Yang, Jan Egger", "title": "A semi-automatic computer-aided method for surgical template design", "comments": "18 pages, 16 figures, 2 tables, 36 references", "journal-ref": "Scientific Reports 6, Article number: 20280, 2016", "doi": "10.1038/srep20280", "report-no": null, "categories": "cs.GR cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a generalized integrated framework of semi-automatic\nsurgical template design. Several algorithms were implemented including the\nmesh segmentation, offset surface generation, collision detection, ruled\nsurface generation, etc., and a special software named TemDesigner was\ndeveloped. With a simple user interface, a customized template can be semi-\nautomatically designed according to the preoperative plan. Firstly, mesh\nsegmentation with signed scalar of vertex is utilized to partition the inner\nsurface from the input surface mesh based on the indicated point loop. Then,\nthe offset surface of the inner surface is obtained through contouring the\ndistance field of the inner surface, and segmented to generate the outer\nsurface. Ruled surface is employed to connect inner and outer surfaces.\nFinally, drilling tubes are generated according to the preoperative plan\nthrough collision detection and merging. It has been applied to the template\ndesign for various kinds of surgeries, including oral implantology, cervical\npedicle screw insertion, iliosacral screw insertion and osteotomy,\ndemonstrating the efficiency, functionality and generality of our method.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 11:33:22 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Chen", "Xiaojun", ""], ["Xu", "Lu", ""], ["Yang", "Yue", ""], ["Egger", "Jan", ""]]}, {"id": "1602.01913", "submitter": "Ming Yang", "authors": "Ming Yang, Hongyang Chao, Chi Zhang, Jun Guo, Lu Yuan, Jian Sun", "title": "Effective Clipart Image Vectorization Through Direct Optimization of\n  Bezigons", "comments": "18 pages, 16 figures", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics (TVCG),\n  Volume 22 Issue 2, February 2016, Pages 1063-1075", "doi": "10.1109/TVCG.2015.2440273", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bezigons, i.e., closed paths composed of B\\'ezier curves, have been widely\nemployed to describe shapes in image vectorization results. However, most\nexisting vectorization techniques infer the bezigons by simply approximating an\nintermediate vector representation (such as polygons). Consequently, the\nresultant bezigons are sometimes imperfect due to accumulated errors, fitting\nambiguities, and a lack of curve priors, especially for low-resolution images.\nIn this paper, we describe a novel method for vectorizing clipart images. In\ncontrast to previous methods, we directly optimize the bezigons rather than\nusing other intermediate representations; therefore, the resultant bezigons are\nnot only of higher fidelity compared with the original raster image but also\nmore reasonable because they were traced by a proficient expert. To enable such\noptimization, we have overcome several challenges and have devised a\ndifferentiable data energy as well as several curve-based prior terms. To\nimprove the efficiency of the optimization, we also take advantage of the local\ncontrol property of bezigons and adopt an overlapped piecewise optimization\nstrategy. The experimental results show that our method outperforms both the\ncurrent state-of-the-art method and commonly used commercial software in terms\nof bezigon quality.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 02:50:43 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Yang", "Ming", ""], ["Chao", "Hongyang", ""], ["Zhang", "Chi", ""], ["Guo", "Jun", ""], ["Yuan", "Lu", ""], ["Sun", "Jian", ""]]}, {"id": "1602.02022", "submitter": "Jan Egger", "authors": "Dzenan Zukic, Jan Egger, Miriam H. A. Bauer, Daniela Kuhnt, Barbara\n  Carl, Bernd Freisleben, Andreas Kolb, Christopher Nimsky", "title": "Preoperative Volume Determination for Pituitary Adenoma", "comments": "7 pages, 6 figures, 1 table, 16 references in Proc. SPIE 7963,\n  Medical Imaging 2011: Computer-Aided Diagnosis, 79632T (9 March 2011). arXiv\n  admin note: text overlap with arXiv:1103.1778", "journal-ref": null, "doi": "10.1117/12.877660", "report-no": null, "categories": "cs.CV cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most common sellar lesion is the pituitary adenoma, and sellar tumors are\napproximately 10-15% of all intracranial neoplasms. Manual slice-by-slice\nsegmentation takes quite some time that can be reduced by using the appropriate\nalgorithms. In this contribution, we present a segmentation method for\npituitary adenoma. The method is based on an algorithm that we have applied\nrecently to segmenting glioblastoma multiforme. A modification of this scheme\nis used for adenoma segmentation that is much harder to perform, due to lack of\ncontrast-enhanced boundaries. In our experimental evaluation, neurosurgeons\nperformed manual slice-by-slice segmentation of ten magnetic resonance imaging\n(MRI) cases. The segmentations were compared to the segmentation results of the\nproposed method using the Dice Similarity Coefficient (DSC). The average DSC\nfor all datasets was 75.92% +/- 7.24%. A manual segmentation took about four\nminutes and our algorithm required about one second.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 14:08:21 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Zukic", "Dzenan", ""], ["Egger", "Jan", ""], ["Bauer", "Miriam H. A.", ""], ["Kuhnt", "Daniela", ""], ["Carl", "Barbara", ""], ["Freisleben", "Bernd", ""], ["Kolb", "Andreas", ""], ["Nimsky", "Christopher", ""]]}, {"id": "1602.02023", "submitter": "Nadia Robertini", "authors": "Nadia Robertini, Edilson De Aguiar, Thomas Helten, Christian Theobalt", "title": "Efficient Multi-view Performance Capture of Fine-Scale Surface Detail", "comments": "3D Vision (3DV), 2014 2nd International Conference on", "journal-ref": null, "doi": "10.1109/3DV.2014.46", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new effective way for performance capture of deforming meshes\nwith fine-scale time-varying surface detail from multi-view video. Our method\nbuilds up on coarse 4D surface reconstructions, as obtained with commonly used\ntemplate-based methods. As they only capture models of coarse-to-medium scale\ndetail, fine scale deformation detail is often done in a second pass by using\nstereo constraints, features, or shading-based refinement. In this paper, we\npropose a new effective and stable solution to this second step. Our framework\ncreates an implicit representation of the deformable mesh using a dense\ncollection of 3D Gaussian functions on the surface, and a set of 2D Gaussians\nfor the images. The fine scale deformation of all mesh vertices that maximizes\nphoto-consistency can be efficiently found by densely optimizing a new\nmodel-to-image consistency energy on all vertex positions. A principal\nadvantage is that our problem formulation yields a smooth closed form energy\nwith implicit occlusion handling and analytic derivatives. Error-prone\ncorrespondence finding, or discrete sampling of surface displacement values are\nalso not needed. We show several reconstructions of human subjects wearing\nloose clothing, and we qualitatively and quantitatively show that we robustly\ncapture more detail than related methods.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 14:08:47 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Robertini", "Nadia", ""], ["De Aguiar", "Edilson", ""], ["Helten", "Thomas", ""], ["Theobalt", "Christian", ""]]}, {"id": "1602.02139", "submitter": "Pedro Chamorro-Posada", "authors": "P. Chamorro-Posada", "title": "A simple method for estimating the fractal dimension from digital\n  images: The compression dimension", "comments": null, "journal-ref": "Chaos Solitons Fract 91 (2016) 562-572", "doi": "10.1016/j.chaos.2016.08.002", "report-no": null, "categories": "cs.GR cs.CV physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fractal structure of real world objects is often analyzed using digital\nimages. In this context, the compression fractal dimension is put forward. It\nprovides a simple method for the direct estimation of the dimension of fractals\nstored as digital image files. The computational scheme can be implemented\nusing readily available free software. Its simplicity also makes it very\ninteresting for introductory elaborations of basic concepts of fractal\ngeometry, complexity, and information theory. A test of the computational\nscheme using limited-quality images of well-defined fractal sets obtained from\nthe Internet and free software has been performed. Also, a systematic\nevaluation of the proposed method using computer generated images of the\nWeierstrass cosine function shows an accuracy comparable to those of the\nmethods most commonly used to estimate the dimension of fractal data sequences\napplied to the same test problem.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 23:43:26 GMT"}, {"version": "v2", "created": "Fri, 5 Aug 2016 12:27:51 GMT"}], "update_date": "2016-08-15", "authors_parsed": [["Chamorro-Posada", "P.", ""]]}, {"id": "1602.02481", "submitter": "Sungjoon Choi", "authors": "Sungjoon Choi, Qian-Yi Zhou, Stephen Miller, and Vladlen Koltun", "title": "A Large Dataset of Object Scans", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have created a dataset of more than ten thousand 3D scans of real objects.\nTo create the dataset, we recruited 70 operators, equipped them with\nconsumer-grade mobile 3D scanning setups, and paid them to scan objects in\ntheir environments. The operators scanned objects of their choosing, outside\nthe laboratory and without direct supervision by computer vision professionals.\nThe result is a large and diverse collection of object scans: from shoes, mugs,\nand toys to grand pianos, construction vehicles, and large outdoor sculptures.\nWe worked with an attorney to ensure that data acquisition did not violate\nprivacy constraints. The acquired data was irrevocably placed in the public\ndomain and is available freely at http://redwood-data.org/3dscan .\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 07:20:52 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2016 17:21:24 GMT"}, {"version": "v3", "created": "Thu, 5 May 2016 05:35:48 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Choi", "Sungjoon", ""], ["Zhou", "Qian-Yi", ""], ["Miller", "Stephen", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1602.02490", "submitter": "Jan Egger", "authors": "Jan Egger, Stefan Gro{\\ss}kopf, Bernd Freisleben", "title": "Simulation of bifurcated stent grafts to treat abdominal aortic\n  aneurysms (AAA)", "comments": "6 pages, 5 figures, 5 equations, 9 references in Proc. SPIE 6509,\n  Medical Imaging 2007: Visualization and Image-Guided Procedures, 65091N (22\n  March 2007)", "journal-ref": null, "doi": "10.1117/12.709260", "report-no": null, "categories": "cs.GR cs.CE cs.CG physics.med-ph q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a method is introduced, to visualize bifurcated stent grafts in\nCT-Data. The aim is to improve therapy planning for minimal invasive treatment\nof abdominal aortic aneurysms (AAA). Due to precise measurement of the\nabdominal aortic aneurysm and exact simulation of the bifurcated stent graft,\nphysicians are supported in choosing a suitable stent prior to an intervention.\nThe presented method can be used to measure the dimensions of the abdominal\naortic aneurysm as well as simulate a bifurcated stent graft. Both of these\nprocedures are based on a preceding segmentation and skeletonization of the\naortic, right and left iliac. Using these centerlines (aortic, right and left\niliac) a bifurcated initial stent is constructed. Through the implementation of\nan ACM method the initial stent is fit iteratively to the vessel walls - due to\nthe influence of external forces (distance- as well as balloonforce). Following\nthe fitting process, the crucial values for choosing a bifurcated stent graft\nare measured, e.g. aortic diameter, right and left common iliac diameter,\nminimum diameter of distal neck. The selected stent is then simulated to the\nCT-Data - starting with the initial stent. It hereby becomes apparent if the\ndimensions of the bifurcated stent graft are exact, i.e. the fitting to the\narteries was done properly and no ostium was covered.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 08:09:06 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Egger", "Jan", ""], ["Gro\u00dfkopf", "Stefan", ""], ["Freisleben", "Bernd", ""]]}, {"id": "1602.02651", "submitter": "Pablo Garrido", "authors": "Pablo Garrido, Levi Valgaerts, Ole Rehmsen, Thorsten Thormaehlen,\n  Patrick Perez, Christian Theobalt", "title": "Automatic Face Reenactment", "comments": "Proceedings of the 2014 IEEE Conference on Computer Vision and\n  Pattern Recognition (8 pages)", "journal-ref": null, "doi": "10.1109/CVPR.2014.537", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an image-based, facial reenactment system that replaces the face\nof an actor in an existing target video with the face of a user from a source\nvideo, while preserving the original target performance. Our system is fully\nautomatic and does not require a database of source expressions. Instead, it is\nable to produce convincing reenactment results from a short source video\ncaptured with an off-the-shelf camera, such as a webcam, where the user\nperforms arbitrary facial gestures. Our reenactment pipeline is conceived as\npart image retrieval and part face transfer: The image retrieval is based on\ntemporal clustering of target frames and a novel image matching metric that\ncombines appearance and motion to select candidate frames from the source\nvideo, while the face transfer uses a 2D warping strategy that preserves the\nuser's identity. Our system excels in simplicity as it does not rely on a 3D\nface model, it is robust under head motion and does not require the source and\ntarget performance to be similar. We show convincing reenactment results for\nvideos that we recorded ourselves and for low-quality footage taken from the\nInternet.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 17:05:37 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Garrido", "Pablo", ""], ["Valgaerts", "Levi", ""], ["Rehmsen", "Ole", ""], ["Thormaehlen", "Thorsten", ""], ["Perez", "Patrick", ""], ["Theobalt", "Christian", ""]]}, {"id": "1602.02881", "submitter": "Jan Egger", "authors": "Jing Lu, Jan Egger, Andreas Wimmer, Stefan Gro{\\ss}kopf, Bernd\n  Freisleben", "title": "Detection and Visualization of Endoleaks in CT Data for Monitoring of\n  Thoracic and Abdominal Aortic Aneurysm Stents", "comments": "7 pages, 7 figures, 1 table, 12 references, Proc. SPIE 6918, Medical\n  Imaging 2008: Visualization, Image-Guided Procedures, and Modeling, 69181F\n  (17 March 2008)", "journal-ref": null, "doi": "10.1117/12.769414", "report-no": null, "categories": "cs.CV cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an efficient algorithm for the segmentation of the\ninner and outer boundary of thoratic and abdominal aortic aneurysms (TAA & AAA)\nin computed tomography angiography (CTA) acquisitions. The aneurysm\nsegmentation includes two steps: first, the inner boundary is segmented based\non a grey level model with two thresholds; then, an adapted active contour\nmodel approach is applied to the more complicated outer boundary segmentation,\nwith its initialization based on the available inner boundary segmentation. An\nopacity image, which aims at enhancing important features while reducing\nspurious structures, is calculated from the CTA images and employed to guide\nthe deformation of the model. In addition, the active contour model is extended\nby a constraint force that prevents intersections of the inner and outer\nboundary and keeps the outer boundary at a distance, given by the thrombus\nthickness, to the inner boundary. Based upon the segmentation results, we can\nmeasure the aneurysm size at each centerline point on the centerline orthogonal\nmultiplanar reformatting (MPR) plane. Furthermore, a 3D TAA or AAA model is\nreconstructed from the set of segmented contours, and the presence of endoleaks\nis detected and highlighted. The implemented method has been evaluated on nine\nclinical CTA data sets with variations in anatomy and location of the pathology\nand has shown promising results.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 07:42:05 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Lu", "Jing", ""], ["Egger", "Jan", ""], ["Wimmer", "Andreas", ""], ["Gro\u00dfkopf", "Stefan", ""], ["Freisleben", "Bernd", ""]]}, {"id": "1602.03206", "submitter": "Filip Sala", "authors": "Filip A. Sala", "title": "Design of false color palettes for grayscale reproduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of false color palette is quite easy but some effort has to be done to\nachieve good dynamic range, contrast and overall appearance of the palette.\nSuch palettes, for instance, are commonly used in scientific papers for\npresenting the data. However, to lower the cost of the paper most scientists\ndecide to let the data to be printed in grayscale. The same applies to e-book\nreaders based on e-ink where most of them are still grayscale. For majority of\nfalse color palettes reproducing them in grayscale results in ambiguous mapping\nof the colors and may be misleading for the reader. In this article design of\nfalse color palettes suitable for grayscale reproduction is described. Due to\nthe monotonic change of luminance of these palettes grayscale representation is\nvery similar to the data directly presented with a grayscale palette. Some\nsuggestions and examples how to design such palettes are provided.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 17:35:21 GMT"}, {"version": "v2", "created": "Thu, 31 Mar 2016 19:22:26 GMT"}], "update_date": "2016-04-01", "authors_parsed": [["Sala", "Filip A.", ""]]}, {"id": "1602.03308", "submitter": "David Barina", "authors": "David Barina", "title": "Gabor Wavelets in Image Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work shows the use of a two-dimensional Gabor wavelets in image\nprocessing. Convolution with such a two-dimensional wavelet can be separated\ninto two series of one-dimensional ones. The key idea of this work is to\nutilize a Gabor wavelet as a multiscale partial differential operator of a\ngiven order. Gabor wavelets are used here to detect edges, corners and blobs. A\nperformance of such an interest point detector is compared to detectors\nutilizing a Haar wavelet and a derivative of a Gaussian function. The proposed\napproach may be useful when a fast implementation of the Gabor transform is\navailable or when the transform is already precomputed.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 09:45:38 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Barina", "David", ""]]}, {"id": "1602.04906", "submitter": "Junyan Wang", "authors": "Junyan Wang, Sai-kit Yeung, Jue Wang and Kun Zhou", "title": "Segmentation Rectification for Video Cutout via One-Class Structured\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on interactive video object cutout mainly focus on designing\ndynamic foreground-background (FB) classifiers for segmentation propagation.\nHowever, the research on optimally removing errors from the FB classification\nis sparse, and the errors often accumulate rapidly, causing significant errors\nin the propagated frames. In this work, we take the initial steps to addressing\nthis problem, and we call this new task \\emph{segmentation rectification}. Our\nkey observation is that the possibly asymmetrically distributed false positive\nand false negative errors were handled equally in the conventional methods. We,\nalternatively, propose to optimally remove these two types of errors. To this\neffect, we propose a novel bilayer Markov Random Field (MRF) model for this new\ntask. We also adopt the well-established structured learning framework to learn\nthe optimal model from data. Additionally, we propose a novel one-class\nstructured SVM (OSSVM) which greatly speeds up the structured learning process.\nOur method naturally extends to RGB-D videos as well. Comprehensive experiments\non both RGB and RGB-D data demonstrate that our simple and effective method\nsignificantly outperforms the segmentation propagation methods adopted in the\nstate-of-the-art video cutout systems, and the results also suggest the\npotential usefulness of our method in image cutout system.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 04:31:20 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Wang", "Junyan", ""], ["Yeung", "Sai-kit", ""], ["Wang", "Jue", ""], ["Zhou", "Kun", ""]]}, {"id": "1602.05256", "submitter": "Wichai Shanklin", "authors": "Wichai Shanklin", "title": "2D SEM images turn into 3D object models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scanning electron microscopy (SEM) is probably one the most fascinating\nexamination approach that has been used since more than two decades to detailed\ninspection of micro scale objects. Most of the scanning electron microscopes\ncould only produce 2D images that could not assist operational analysis of\nmicroscopic surface properties. Computer vision algorithms combined with very\nadvanced geometry and mathematical approaches turn any SEM into a full 3D\nmeasurement device. This work focuses on a methodical literature review for\nautomatic 3D surface reconstruction of scanning electron microscope images.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 00:41:58 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Shanklin", "Wichai", ""]]}, {"id": "1602.05920", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Manal H. Alassaf", "title": "Weighted Unsupervised Learning for 3D Object Detection", "comments": "IJACSA", "journal-ref": null, "doi": "10.14569/IJACSA.2016.070180", "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.MM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel weighted unsupervised learning for object\ndetection using an RGB-D camera. This technique is feasible for detecting the\nmoving objects in the noisy environments that are captured by an RGB-D camera.\nThe main contribution of this paper is a real-time algorithm for detecting each\nobject using weighted clustering as a separate cluster. In a preprocessing\nstep, the algorithm calculates the pose 3D position X, Y, Z and RGB color of\neach data point and then it calculates each data point's normal vector using\nthe point's neighbor. After preprocessing, our algorithm calculates k-weights\nfor each data point; each weight indicates membership. Resulting in clustered\nobjects of the scene.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 19:40:26 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 23:51:27 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Kowsari", "Kamran", ""], ["Alassaf", "Manal H.", ""]]}, {"id": "1602.06239", "submitter": "Michelle Rudolph-Lilith", "authors": "Michelle Rudolph-Lilith", "title": "On a recursive construction of circular paths and the search for $\\pi$\n  on the integer lattice $\\mathbb{Z}^2$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital circles not only play an important role in various technological\nsettings, but also provide a lively playground for more fundamental\nnumber-theoretical questions. In this paper, we present a new recursive\nalgorithm for the construction of digital circles on the integer lattice\n$\\mathbb{Z}^2$, which makes sole use of the signum function. By briefly\nelaborating on the nature of discretization of circular paths, we then find\nthat this algorithm recovers, in a space endowed with $\\ell^1$-norm, the\ndefining constant $\\pi$ of a circle in $\\mathbb{R}^2$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 15:54:02 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Rudolph-Lilith", "Michelle", ""]]}, {"id": "1602.06645", "submitter": "Song Liu", "authors": "Song Liu, Wanqing Li, Philip Ogunbona and Yang-Wai Chow", "title": "Creating Simplified 3D Models with High Quality Textures", "comments": "2015 International Conference on Digital Image Computing: Techniques\n  and Applications (DICTA), Page 1 - 8", "journal-ref": null, "doi": "10.1109/DICTA.2015.7371249", "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an extension to the KinectFusion algorithm which allows\ncreating simplified 3D models with high quality RGB textures. This is achieved\nthrough (i) creating model textures using images from an HD RGB camera that is\ncalibrated with Kinect depth camera, (ii) using a modified scheme to update\nmodel textures in an asymmetrical colour volume that contains a higher number\nof voxels than that of the geometry volume, (iii) simplifying dense polygon\nmesh model using quadric-based mesh decimation algorithm, and (iv) creating and\nmapping 2D textures to every polygon in the output 3D model. The proposed\nmethod is implemented in real-time by means of GPU parallel processing.\nVisualization via ray casting of both geometry and colour volumes provides\nusers with a real-time feedback of the currently scanned 3D model. Experimental\nresults show that the proposed method is capable of keeping the model texture\nquality even for a heavily decimated model and that, when reconstructing small\nobjects, photorealistic RGB textures can still be reconstructed.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 04:45:43 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Liu", "Song", ""], ["Li", "Wanqing", ""], ["Ogunbona", "Philip", ""], ["Chow", "Yang-Wai", ""]]}, {"id": "1602.07038", "submitter": "Barak Sober", "authors": "Barak Sober, David Levin", "title": "Computer Aided Restoration of Handwritten Character Strokes", "comments": "11 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work suggests a new variational approach to the task of computer aided\nrestoration of incomplete characters, residing in a highly noisy document. We\nmodel character strokes as the movement of a pen with a varying radius.\nFollowing this model, a cubic spline representation is being utilized to\nperform gradient descent steps, while maintaining interpolation at some initial\n(manually sampled) points. The proposed algorithm was utilized in the process\nof restoring approximately 1000 ancient Hebrew characters (dating to ca.\n8th-7th century BCE), some of which are presented herein and show that the\nalgorithm yields plausible results when applied on deteriorated documents.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 04:47:28 GMT"}, {"version": "v2", "created": "Wed, 6 Jul 2016 23:24:19 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Sober", "Barak", ""], ["Levin", "David", ""]]}]