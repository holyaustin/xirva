[{"id": "1412.0488", "submitter": "Pavel Tomancak", "authors": "Tobias Pietzsch and Stephan Saalfeld and Stephan Preibisch and Pavel\n  Tomancak", "title": "BigDataViewer: Interactive Visualization and Image Processing for\n  Terabyte Data Sets", "comments": "38 pages, 1 main figure, 27 supplementary figures, under review at\n  Nature Methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasingly popular light sheet microscopy techniques generate very\nlarge 3D time-lapse recordings of living biological specimen. The necessity to\nmake large volumetric datasets available for interactive visualization and\nanalysis has been widely recognized. However, existing solutions build on\ndedicated servers to generate virtual slices that are transferred to the client\napplications, practically leading to insufficient frame rates (less than 10\nframes per second) for truly interactive experience. An easily accessible open\nsource solution for interactive arbitrary virtual re-slicing of very large\nvolumes and time series of volumes has yet been missing. We fill this gap with\nBigDataViewer, a Fiji plugin to interactively navigate and visualize large\nimage sequences from both local and remote data sources.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 14:24:44 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Pietzsch", "Tobias", ""], ["Saalfeld", "Stephan", ""], ["Preibisch", "Stephan", ""], ["Tomancak", "Pavel", ""]]}, {"id": "1412.1330", "submitter": "Valerie Gouranton", "authors": "Jean-Baptiste Barreau (CReAAH, INRIA - IRISA, INSA Rennes),\n  Th\\'eophane Nicolas (INRAP), G Bruniaux (CReAAH), E Petit (CReAAH), Q Petit,\n  Y Bernard (CReAAH, UR1), Ronan Gaugne (UR1), Val\\'erie Gouranton (INRIA -\n  IRISA, INSA Rennes)", "title": "Ceramics Fragments Digitization by Photogrammetry, Reconstructions and\n  Applications", "comments": "International Conference on Culturage Heritage, EuroMed, 2014, Nov\n  2014, Lemessos, Cyprus", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an application of photogrammetry on ceramic fragments\nfrom two excavation sites located north-west of France. The restitution by\nphotogrammetry of these different fragments allowed reconstructions of the\npotteries in their original state or at least to get to as close as possible.\nWe used the 3D reconstructions to compute some metrics and to generate a\npresentation support by using a 3D printer. This work is based on affordable\ntools and illustrates how 3D technologies can be quite easily integrated in\narchaeology process with limited financial resources. 1. INTRODUCTION Today,\nphotogrammetry and 3D modelling are an integral part of the methods used in\narcheology and heritage management. They provide answers to scientific needs in\nthe fields of conservation, preservation, restoration and mediation of\narchitectural, archaeological and cultural heritage [2] [6] [7] [9].\nPhotogrammetry on ceramic fragments was one of the first applications\ncontemporary of the development of this technique applied in the archaeological\ncommunity [3]. More recently and due to its democratization, it was applied\nmore generally to artifacts [5]. Finally joined today by the rise of 3D\nprinting [8] [10], it can restore fragmented artifacts [1] [12]. These examples\ntarget one or several particular objects and use different types of equipment\nthat can be expensive. These aspects can put off uninitiated archaeologists. So\nit would be appropriate to see if these techniques could be generalized to a\nwhole class of geometrically simple and common artifacts, such as ceramics.\nFrom these observations, associated to ceramics specialists with fragments of\nbroken ceramics, we aimed at arranging different tools and methods, including\nphotogrammetry, to explore opportunities for a cheap and attainable\nreconstruction methodology and its possible applications. Our first objective\nwas to establish a protocol for scanning fragments with photogrammetry, and for\nreconstruction of original ceramics. We used the digital reconstitutions of the\nceramics we got following our process to calculate some metrics and to design\nand 3D print a display for the remaining fragments of one pottery.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 14:04:48 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Barreau", "Jean-Baptiste", "", "CReAAH, INRIA - IRISA, INSA Rennes"], ["Nicolas", "Th\u00e9ophane", "", "INRAP"], ["Bruniaux", "G", "", "CReAAH"], ["Petit", "E", "", "CReAAH"], ["Petit", "Q", "", "CReAAH, UR1"], ["Bernard", "Y", "", "CReAAH, UR1"], ["Gaugne", "Ronan", "", "UR1"], ["Gouranton", "Val\u00e9rie", "", "INRIA -\n  IRISA, INSA Rennes"]]}, {"id": "1412.1401", "submitter": "Kyung-Taek Jun", "authors": "Kyung-Taek Jun", "title": "Throat Finding Algorithms based on Throat Types", "comments": "23 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The three-dimensional geometry and connectivity of pore space determines the\nflow of single-phase incompressible flow. Herein I report on new throat finding\nalgorithms that contribute to finding the exact flow-relevant geometrical\nproperties of the void space, including high porosity samples of X2B images,\nthree-dimensional synchrotron X-ray computed microtomographic images, and\namounting to over 20% porosity. These new algorithms use the modified medial\naxis that comes from the 3DMA-Rock software package. To find accurate throats,\nwe classify three major throat types: mostly planar and simply connected type,\nnon-planar and simply connected type, and non-planar and non-simply connected\ntype. For each type, we make at least one algorithm to find the throats. Here I\nintroduce an example that has a non-planar and simply connected throat, and my\nsolution indicated by one of my algorithms. My five algorithms each calculate\nthe throat for each path. It selects one of them, which has the smallest inner\narea. New algorithms find accurate throats at least 98% among 12 high porosity\nsamples (over 20%). Also, I introduce a new length calculation in the digitized\nimage. The new calculation uses three mathematical concepts: i)\ndifferentiability, ii) implicit function theorem, iii) line integral. The\nresult can convert the discrete boundary of the XMCT image to the real\nboundary. When the real boundary has an arc shape, the new calculation has less\nthan 1% relative error.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 06:19:50 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Jun", "Kyung-Taek", ""]]}, {"id": "1412.3841", "submitter": "Przemys{\\l}aw Gospodarczyk MSc.", "authors": "Przemys{\\l}aw Gospodarczyk, Pawe{\\l} Wo\\'zny", "title": "Merging of B\\'ezier curves with box constraints", "comments": null, "journal-ref": "Journal of Computational and Applied Mathematics 296, 265-274\n  (2016)", "doi": "10.1016/j.cam.2015.10.005", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach to the problem of merging of\nB\\'ezier curves with respect to the $L_2$-norm. We give illustrative examples\nto show that the solution of the conventional merging problem may not be\nsuitable for further modification and applications. As in the case of the\ndegree reduction problem, we apply the so-called restricted area approach --\nproposed recently in (P. Gospodarczyk, Computer-Aided Design 62 (2015),\n143--151) -- to avoid certain defects and make the resulting curve more useful.\nA method of solving the new problem is based on box-constrained quadratic\nprogramming approach.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 22:11:44 GMT"}, {"version": "v2", "created": "Tue, 16 Dec 2014 14:07:04 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2015 18:41:02 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2015 13:46:38 GMT"}, {"version": "v5", "created": "Tue, 1 Sep 2015 08:55:21 GMT"}, {"version": "v6", "created": "Sun, 18 Oct 2015 20:50:07 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Gospodarczyk", "Przemys\u0142aw", ""], ["Wo\u017any", "Pawe\u0142", ""]]}, {"id": "1412.4246", "submitter": "Thomas Baudel", "authors": "Thomas Baudel", "title": "A Canonical Representation of Data-Linear Visualization Algorithms", "comments": "10 pages, extended version of the original technical report", "journal-ref": null, "doi": null, "report-no": "ILOG Technical report 05-003. 04/12/2005", "categories": "cs.GR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce linear-state dataflows, a canonical model for a large set of\nvisualization algorithms that we call data-linear visualizations. Our model\ndefines a fixed dataflow architecture: partitioning and subpartitioning of\ninput data, ordering, graphic primitives, and graphic attributes generation.\nLocal variables and accumulators are specific concepts that extend the\nexpressiveness of the dataflow to support features of visualization algorithms\nthat require state handling. We first show the flexibility of our model: it\nenables the declarative construction of many common algorithms with just a few\nmappings. Furthermore, the model enables easy mixing of visual mappings, such\nas creating treemaps of histograms and 2D plots, plots of histograms...\nFinally, we introduce our model in a more formal way and present some of its\nimportant properties. We have implemented this model in a visualization\nframework built around the concept of linear-state dataflows.\n", "versions": [{"version": "v1", "created": "Sat, 13 Dec 2014 15:24:38 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Baudel", "Thomas", ""]]}, {"id": "1412.6649", "submitter": "Reinhard Moratz", "authors": "Christopher H. Dorr and Reinhard Moratz", "title": "Qualitative shape representation based on the qualitative relative\n  direction and distance calculus eOPRAm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document serves as a brief technical report, detailing the processes\nused to represent and reconstruct simplified polygons using qualitative spatial\ndescriptions, as defined by the eOPRAm qualitative spatial calculus.\n", "versions": [{"version": "v1", "created": "Sat, 20 Dec 2014 12:51:24 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Dorr", "Christopher H.", ""], ["Moratz", "Reinhard", ""]]}, {"id": "1412.6706", "submitter": "Dustin Arendt", "authors": "Dustin L. Arendt and Leslie M. Blaha", "title": "SVEN: Informative Visual Representation of Complex Dynamic Structure", "comments": "Python, JavaScript, & HTML source contained within ancillary folder\n  under MPL2.0 license", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.GR cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs change over time, and typically variations on the small multiples or\nanimation pattern is used to convey this dynamism visually. However, both of\nthese classical techniques have significant drawbacks, so a new approach,\nStoryline Visualization of Events on a Network (SVEN) is proposed. SVEN builds\non storyline techniques, conveying nodes as contiguous lines over time. SVEN\nencodes time in a natural manner, along the horizontal axis, and optimizes the\nvertical placement of storylines to decrease clutter (line crossings,\nstraightness, and bends) in the drawing. This paper demonstrates SVEN on\nseveral different flavors of real-world dynamic data, and outlines the\nremaining near-term future work.\n", "versions": [{"version": "v1", "created": "Sat, 20 Dec 2014 23:21:46 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Arendt", "Dustin L.", ""], ["Blaha", "Leslie M.", ""]]}, {"id": "1412.7725", "submitter": "Zhicheng Yan", "authors": "Zhicheng Yan and Hao Zhang and Baoyuan Wang and Sylvain Paris and\n  Yizhou Yu", "title": "Automatic Photo Adjustment Using Deep Neural Networks", "comments": "TOG minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photo retouching enables photographers to invoke dramatic visual impressions\nby artistically enhancing their photos through stylistic color and tone\nadjustments. However, it is also a time-consuming and challenging task that\nrequires advanced skills beyond the abilities of casual photographers. Using an\nautomated algorithm is an appealing alternative to manual work but such an\nalgorithm faces many hurdles. Many photographic styles rely on subtle\nadjustments that depend on the image content and even its semantics. Further,\nthese adjustments are often spatially varying. Because of these\ncharacteristics, existing automatic algorithms are still limited and cover only\na subset of these challenges. Recently, deep machine learning has shown unique\nabilities to address hard problems that resisted machine algorithms for long.\nThis motivated us to explore the use of deep learning in the context of photo\nediting. In this paper, we explain how to formulate the automatic photo\nadjustment problem in a way suitable for this approach. We also introduce an\nimage descriptor that accounts for the local semantics of an image. Our\nexperiments demonstrate that our deep learning formulation applied using these\ndescriptors successfully capture sophisticated photographic styles. In\nparticular and unlike previous techniques, it can model local adjustments that\ndepend on the image semantics. We show on several examples that this yields\nresults that are qualitatively and quantitatively better than previous work.\n", "versions": [{"version": "v1", "created": "Wed, 24 Dec 2014 17:51:17 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 03:49:35 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Yan", "Zhicheng", ""], ["Zhang", "Hao", ""], ["Wang", "Baoyuan", ""], ["Paris", "Sylvain", ""], ["Yu", "Yizhou", ""]]}, {"id": "1412.7780", "submitter": "Guihua Shan", "authors": "Guihua Shan, Maojin Xie, FengAn Li, Yang Gao, Xuebin Chi", "title": "Interactive Visual Exploration of Halos in Large Scale Cosmology\n  Simulation", "comments": "9pages, 14figures", "journal-ref": "J. Visualization 17(3):145-156(2014)", "doi": "10.1007/s12650-014-0206-5", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Halo is one of the most important basic elements in cosmology simulation,\nwhich merges from small clumps to ever larger objects. The processes of the\nbirth and merging of the halos play a fundamental role in studying the\nevolution of large scale cosmological structures. In this paper, a visual\nanalysis system is developed to interactively identify and explore the\nevolution histories of thousands of halos. In this system, an intelligent\nstructure-aware selection method in What You See Is What You Get manner is\ndesigned to efficiently define the interesting region in 3D space with 2D\nhand-drawn lasso input. Then the exact information of halos within this 3D\nregion is identified by data mining in the merger tree files. To avoid visual\nclutter, all the halos are projected in 2D space with a MDS method. Through the\nlinked view of 3D View and 2D graph, Users can interactively explore these\nhalos, including the tracing path and evolution history tree.\n", "versions": [{"version": "v1", "created": "Thu, 25 Dec 2014 03:20:34 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Shan", "Guihua", ""], ["Xie", "Maojin", ""], ["Li", "FengAn", ""], ["Gao", "Yang", ""], ["Chi", "Xuebin", ""]]}]