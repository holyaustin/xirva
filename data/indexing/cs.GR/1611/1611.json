[{"id": "1611.00939", "submitter": "Adrian Jarabo", "authors": "Adrian Jarabo, Belen Masia, Julio Marco, Diego Gutierrez", "title": "Recent Advances in Transient Imaging: A Computer Graphics and Vision\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transient imaging has recently made a huge impact in the computer graphics\nand computer vision fields. By capturing, reconstructing, or simulating light\ntransport at extreme temporal resolutions, researchers have proposed novel\ntechniques to show movies of light in motion, see around corners, detect\nobjects in highly-scattering media, or infer material properties from a\ndistance, to name a few. The key idea is to leverage the wealth of information\nin the temporal domain at the pico or nanosecond resolution, information\nusually lost during the capture-time temporal integration. This paper presents\nrecent advances in this field of transient imaging from a graphics and vision\nperspective, including capture techniques, analysis, applications and\nsimulation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 10:11:10 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Jarabo", "Adrian", ""], ["Masia", "Belen", ""], ["Marco", "Julio", ""], ["Gutierrez", "Diego", ""]]}, {"id": "1611.01055", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Michiel van de Panne", "title": "Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space\n  Matter?", "comments": null, "journal-ref": null, "doi": "10.1145/3099564.3099567", "report-no": null, "categories": "cs.LG cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep reinforcement learning allows for high-dimensional state\ndescriptors, but little is known about how the choice of action representation\nimpacts the learning difficulty and the resulting performance. We compare the\nimpact of four different action parameterizations (torques, muscle-activations,\ntarget joint angles, and target joint-angle velocities) in terms of learning\ntime, policy robustness, motion quality, and policy query rates. Our results\nare evaluated on a gait-cycle imitation task for multiple planar articulated\nfigures and multiple gaits. We demonstrate that the local feedback provided by\nhigher-level action parameterizations can significantly impact the learning,\nrobustness, and quality of the resulting policies.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 15:15:00 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Peng", "Xue Bin", ""], ["van de Panne", "Michiel", ""]]}, {"id": "1611.01765", "submitter": "Manuel Contero", "authors": "C. Gonz\\'alez-Lluch, P. Company, M. Contero, J. D. Camba, R. Plumed", "title": "A Survey on 3D CAD model quality assurance and testing tools", "comments": null, "journal-ref": null, "doi": "10.1016/j.cad.2016.10.003", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new taxonomy of issues related to CAD model quality is presented, which\ndistinguishes between explicit and procedural models. For each type of model,\nmorphologic, syntactic, and semantic errors are characterized. The taxonomy was\nvalidated successfully when used to classify quality testing tools, which are\naimed at detecting and repairing data errors that may affect the\nsimplification, interoperability, and reusability of CAD models. The study\nshows that low semantic level errors that hamper simplification are reasonably\ncovered in explicit representations, although many CAD quality testers are\nstill unaffordable for Small and Medium Enterprises, both in terms of cost and\ntraining time. Interoperability has been reasonably solved by standards like\nSTEP AP 203 and AP214, but model reusability is not feasible in explicit\nrepresentations. Procedural representations are promising, as interactive\nmodeling editors automatically prevent most morphologic errors derived from\nunsuitable modeling strategies. Interoperability problems between procedural\nrepresentations are expected to decrease dramatically with STEP AP242. Higher\nsemantic aspects of quality such as assurance of design intent, however, are\nhardly supported by current CAD quality testers.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 12:26:37 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Gonz\u00e1lez-Lluch", "C.", ""], ["Company", "P.", ""], ["Contero", "M.", ""], ["Camba", "J. D.", ""], ["Plumed", "R.", ""]]}, {"id": "1611.01990", "submitter": "Yoni Choukroun", "authors": "Yoni Choukroun, Alon Shtern, Alex Bronstein and Ron Kimmel", "title": "Hamiltonian operator for spectral shape analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many shape analysis methods treat the geometry of an object as a metric space\nthat can be captured by the Laplace-Beltrami operator. In this paper, we\npropose to adapt the classical Hamiltonian operator from quantum mechanics to\nthe field of shape analysis. To this end we study the addition of a potential\nfunction to the Laplacian as a generator for dual spaces in which shape\nprocessing is performed. We present a general optimization approach for solving\nvariational problems involving the basis defined by the Hamiltonian using\nperturbation theory for its eigenvectors. The suggested operator is shown to\nproduce better functional spaces to operate with, as demonstrated on different\nshape analysis tasks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 11:11:10 GMT"}, {"version": "v2", "created": "Sun, 25 Jun 2017 17:45:00 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Choukroun", "Yoni", ""], ["Shtern", "Alon", ""], ["Bronstein", "Alex", ""], ["Kimmel", "Ron", ""]]}, {"id": "1611.02147", "submitter": "Kaimo Hu", "authors": "Kaimo Hu, Dong-Ming Yan, David Bommes, Pierre Alliez and Bedrich Benes", "title": "Error-Bounded and Feature Preserving Surface Remeshing with Minimal\n  Angle Improvement", "comments": "14 pages, 20 figures. Submitted to IEEE Transactions on Visualization\n  and Computer Graphics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The typical goal of surface remeshing consists in finding a mesh that is (1)\ngeometrically faithful to the original geometry, (2) as coarse as possible to\nobtain a low-complexity representation and (3) free of bad elements that would\nhamper the desired application. In this paper, we design an algorithm to\naddress all three optimization goals simultaneously. The user specifies desired\nbounds on approximation error {\\delta}, minimal interior angle {\\theta} and\nmaximum mesh complexity N (number of vertices). Since such a desired mesh might\nnot even exist, our optimization framework treats only the approximation error\nbound {\\delta} as a hard constraint and the other two criteria as optimization\ngoals. More specifically, we iteratively perform carefully prioritized local\noperators, whenever they do not violate the approximation error bound and\nimprove the mesh otherwise. In this way our optimization framework greedily\nsearches for the coarsest mesh with minimal interior angle above {\\theta} and\napproximation error bounded by {\\delta}. Fast runtime is enabled by a local\napproximation error estimation, while implicit feature preservation is obtained\nby specifically designed vertex relocation operators. Experiments show that our\napproach delivers high-quality meshes with implicitly preserved features and\nbetter balances between geometric fidelity, mesh complexity and element quality\nthan the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 16:12:08 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Hu", "Kaimo", ""], ["Yan", "Dong-Ming", ""], ["Bommes", "David", ""], ["Alliez", "Pierre", ""], ["Benes", "Bedrich", ""]]}, {"id": "1611.03079", "submitter": "Bryant Wyatt", "authors": "Will.D. Mayfield, Justin.C. Eiland, Taylor.J. Hutyra, Matt.C. Paulsen,\n  Bryant.M. Wyatt", "title": "Fractal Art Generation using GPUs", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractal image generation algorithms exhibit extreme parallelizability. Using\ngeneral purpose graphics processing unit (GPU) programming to implement\nescape-time algorithms for Julia sets of functions,parallel methods generate\nvisually attractive fractal images much faster than traditional methods. Vastly\nimproved speeds are achieved using this method of computation, which allow\nreal-time generation and display of images. A comparison is made between\nsequential and parallel implementations of the algorithm. An application\ncreated by the authors demonstrates using the increased speed to create dynamic\nimaging of fractals where the user may explore paths of parameter values\ncorresponding to a given function's Mandelbrot set. Examples are given of\nartistic and mathematical insights gained by experiencing fractals\ninteractively and from the ability to sample the parameter space quickly and\ncomprehensively.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 23:22:59 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Mayfield", "Will. D.", ""], ["Eiland", "Justin. C.", ""], ["Hutyra", "Taylor. J.", ""], ["Paulsen", "Matt. C.", ""], ["Wyatt", "Bryant. M.", ""]]}, {"id": "1611.03666", "submitter": "Vania Estrela Dr.", "authors": "L. A. Rivera, Vania V. Estrela, P. C. P. Carvalho", "title": "Oriented bounding boxes using multiresolution contours for fast\n  interference detection of arbitrary geometry objects", "comments": "8 pages, 10 figures", "journal-ref": "The 12-th International Conference in Central Europe on Computer\n  Graphics, Visualization and Computer Vision'2004, WSCG 2004, University of\n  West Bohemia, Campus Bory, Plzen-Bory, Czech Republic, February 2-6, 2004", "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interference detection of arbitrary geometric objects is not a trivial task\ndue to the heavy computational load imposed by implementation issues. The\nhierarchically structured bounding boxes help us to quickly isolate the contour\nof segments in interference. In this paper, a new approach is introduced to\ntreat the interference detection problem involving the representation of\narbitrary shaped objects. Our proposed method relies upon searching for the\nbest possible way to represent contours by means of hierarchically structured\nrectangular oriented bounding boxes. This technique handles 2D objects\nboundaries defined by closed B-spline curves with roughness details. Each\noriented box is adapted and fitted to the segments of the contour using second\norder statistical indicators from some elements of the segments of the object\ncontour in a multiresolution framework. Our method is efficient and robust when\nit comes to 2D animations in real time. It can deal with smooth curves and\npolygonal approximations as well results are present to illustrate the\nperformance of the new method.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 11:50:59 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Rivera", "L. A.", ""], ["Estrela", "Vania V.", ""], ["Carvalho", "P. C. P.", ""]]}, {"id": "1611.03677", "submitter": "Marie-Lena Eckert", "authors": "Tiffany Inglis, Marie-Lena Eckert, James Gregson, Nils Thuerey", "title": "Primal-Dual Optimization for Fluids", "comments": "14 pages, 18 figures, supplemental video\n  https://www.youtube.com/watch?v=Pgbat5MXo8Q", "journal-ref": null, "doi": "10.1111/cgf.13084", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply a novel optimization scheme from the image processing and machine\nlearning areas, a fast Primal-Dual method, to achieve controllable and\nrealistic fluid simulations. While our method is generally applicable to many\nproblems in fluid simulations, we focus on the two topics of fluid guiding and\nseparating solid-wall boundary conditions. Each problem is posed as an\noptimization problem and solved using our method, which contains acceleration\nschemes tailored to each problem. In fluid guiding, we are interested in\npartially guiding fluid motion to exert control while preserving fluid\ncharacteristics. With our method, we achieve explicit control over both\nlarge-scale motions and small-scale details which is valuable for many\napplications, such as level-of-detail adjustment (after running the coarse\nsimulation), spatially varying guiding strength, domain modification, and\nresimulation with different fluid parameters. For the separating solid-wall\nboundary conditions problem, our method effectively eliminates unrealistic\nartifacts of fluid crawling up solid walls and sticking to ceilings, requiring\nfew changes to existing implementations. We demonstrate the fast convergence of\nour Primal-Dual method with a variety of test cases for both model problems.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 12:20:43 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 08:48:44 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Inglis", "Tiffany", ""], ["Eckert", "Marie-Lena", ""], ["Gregson", "James", ""], ["Thuerey", "Nils", ""]]}, {"id": "1611.07233", "submitter": "Lukas Cavigelli", "authors": "Lukas Cavigelli, Pascal Hager, Luca Benini", "title": "CAS-CNN: A Deep Convolutional Neural Network for Image Compression\n  Artifact Suppression", "comments": "8 pages", "journal-ref": null, "doi": "10.1109/IJCNN.2017.7965927", "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lossy image compression algorithms are pervasively used to reduce the size of\nimages transmitted over the web and recorded on data storage media. However, we\npay for their high compression rate with visual artifacts degrading the user\nexperience. Deep convolutional neural networks have become a widespread tool to\naddress high-level computer vision tasks very successfully. Recently, they have\nfound their way into the areas of low-level computer vision and image\nprocessing to solve regression problems mostly with relatively shallow\nnetworks.\n  We present a novel 12-layer deep convolutional network for image compression\nartifact suppression with hierarchical skip connections and a multi-scale loss\nfunction. We achieve a boost of up to 1.79 dB in PSNR over ordinary JPEG and an\nimprovement of up to 0.36 dB over the best previous ConvNet result. We show\nthat a network trained for a specific quality factor (QF) is resilient to the\nQF used to compress the input image - a single network trained for QF 60\nprovides a PSNR gain of more than 1.5 dB over the wide QF range from 40 to 76.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 10:11:58 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Cavigelli", "Lukas", ""], ["Hager", "Pascal", ""], ["Benini", "Luca", ""]]}, {"id": "1611.07369", "submitter": "Georgina Hall", "authors": "Amir Ali Ahmadi, Georgina Hall, Ameesh Makadia, Vikas Sindhwani", "title": "Geometry of 3D Environments and Sum of Squares Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in robotics and computer vision, we study problems\nrelated to spatial reasoning of a 3D environment using sublevel sets of\npolynomials. These include: tightly containing a cloud of points (e.g.,\nrepresenting an obstacle) with convex or nearly-convex basic semialgebraic\nsets, computation of Euclidean distances between two such sets, separation of\ntwo convex basic semalgebraic sets that overlap, and tight containment of the\nunion of several basic semialgebraic sets with a single convex one. We use\nalgebraic techniques from sum of squares optimization that reduce all these\ntasks to semidefinite programs of small size and present numerical experiments\nin realistic scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 15:40:14 GMT"}, {"version": "v2", "created": "Wed, 1 Feb 2017 05:13:55 GMT"}, {"version": "v3", "created": "Tue, 7 Mar 2017 22:46:15 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Hall", "Georgina", ""], ["Makadia", "Ameesh", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "1611.08841", "submitter": "Apratim Bhattacharyya", "authors": "Apratim Bhattacharyya, Mateusz Malinowski, Bernt Schiele, Mario Fritz", "title": "Long-Term Image Boundary Prediction", "comments": "Accepted in the AAAI Conference for Artificial Intelligence, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boundary estimation in images and videos has been a very active topic of\nresearch, and organizing visual information into boundaries and segments is\nbelieved to be a corner stone of visual perception. While prior work has\nfocused on estimating boundaries for observed frames, our work aims at\npredicting boundaries of future unobserved frames. This requires our model to\nlearn about the fate of boundaries and corresponding motion patterns --\nincluding a notion of \"intuitive physics\". We experiment on natural video\nsequences along with synthetic sequences with deterministic physics-based and\nagent-based motions. While not being our primary goal, we also show that fusion\nof RGB and boundary prediction leads to improved RGB predictions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 13:45:14 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 15:23:40 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Bhattacharyya", "Apratim", ""], ["Malinowski", "Mateusz", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1611.08947", "submitter": "Jacqueline Chu", "authors": "Jacqueline Chu, Leonardo Ferrer, Min Shih, Kwan-Liu Ma", "title": "Navigable videos for presenting scientific data on head-mounted displays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Immersive, stereoscopic viewing enables scientists to better analyze the\nspatial structures of visualized physical phenomena. However, their findings\ncannot be properly presented in traditional media, which lack these core\nattributes. Creating a presentation tool that captures this environment poses\nunique challenges, namely related to poor viewing accessibility. Immersive\nscientific renderings often require high-end equipment, which can be\nimpractical to obtain. We address these challenges with our authoring tool and\nnavigational interface, which is designed for affordable head-mounted displays.\nWith the authoring tool, scientists can show salient data features as connected\n360{\\deg} video paths, resulting in a \"choose-your-own-adventure\" experience.\nOur navigational interface features bidirectional video playback for added\nviewing control when users traverse the tailor-made content. We evaluate our\nsystem's benefits by authoring case studies on several data sets and conducting\na usability study on the navigational interface's design. In summary, our\napproach provides scientists an immersive medium to visually present their\nresearch to the intended audience--spanning from students to colleagues--on\naffordable virtual reality headsets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 01:03:57 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Chu", "Jacqueline", ""], ["Ferrer", "Leonardo", ""], ["Shih", "Min", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "1611.09472", "submitter": "EPTCS", "authors": "Victor Winter (University of Nebraska-Omaha), Betty Love (University\n  of Nebraska-Omaha), Cindy Corritore (Creighton University)", "title": "The Bricklayer Ecosystem - Art, Math, and Code", "comments": "In Proceedings TFPIE 2015/6, arXiv:1611.08651", "journal-ref": "EPTCS 230, 2016, pp. 47-61", "doi": "10.4204/EPTCS.230.4", "report-no": null, "categories": "cs.PL cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Bricklayer Ecosystem - a freely-available online\neducational ecosystem created for people of all ages and coding backgrounds.\nBricklayer is designed in accordance with a \"low-threshold infinite ceiling\"\nphilosophy and has been successfully used to teach coding to primary school\nstudents, middle school students, university freshmen, and in-service secondary\nmath teachers. Bricklayer programs are written in the functional programming\nlanguage SML and, when executed, create 2D and 3D artifacts. These artifacts\ncan be viewed using a variety of third-party tools such as LEGO Digital\nDesigner (LDD), LDraw, Minecraft clients, Brickr, as well as STereoLithography\nviewers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 03:39:56 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Winter", "Victor", "", "University of Nebraska-Omaha"], ["Love", "Betty", "", "University\n  of Nebraska-Omaha"], ["Corritore", "Cindy", "", "Creighton University"]]}]