[{"id": "1511.01862", "submitter": "Haoming Chen", "authors": "Haoming Chen, Ankur Saxena, Felix Fernandes", "title": "On Intra Prediction for Screen Content Video Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Screen content coding (SCC) is becoming increasingly important in various\napplications, such as desktop sharing, video conferencing, and remote\neducation. When compared to natural camera- captured content, screen content\nhas different characteristics, in particular sharper edges. In this paper, we\npropose a novel intra prediction scheme for screen content video. In the\nproposed scheme, bilinear interpolation in angular intra prediction in HEVC is\nselectively replaced by nearest-neighbor intra prediction to preserve the sharp\nedges in screen content video. We present three different variants of the\nproposed nearest neighbor prediction algorithm: two implicit methods where both\nthe encoder, and the decoder derive whether to perform nearest neighbor\nprediction or not based on either (a) the sum of the absolute difference, or\n(b) the difference between the boundary pixels from which prediction is\nperformed; and another variant where Rate-Distortion-Optimization (RDO) search\nis performed at the encoder to decide whether or not to use the nearest\nneighbor interpolation, and explicitly signaled to the decoder. We also discuss\nthe various underlying trade-offs in terms of the complexity of the three\nvariants. All the three proposed variants provide significant gains over HEVC,\nand simulation results show that average gains of 3.3% BD-bitrate in\nIntra-frame coding are achieved by the RDO variant for screen content video. To\nthe best of our knowledge, this is the first paper that 1) points out current\nHEVC intra prediction scheme with bilinear interpolation does not work\nefficiently for screen content video and 2) uses different filters adaptively\nin the HEVC intra prediction interpolation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 19:31:51 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2015 23:51:17 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Chen", "Haoming", ""], ["Saxena", "Ankur", ""], ["Fernandes", "Felix", ""]]}, {"id": "1511.04224", "submitter": "Albert Liu", "authors": "Albert J. Liu, Stephen R. Marschner, Victoria E. Dye", "title": "Procedural wood textures", "comments": "This version: Increased resolution of images and added YouTube link\n  to video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing bidirectional reflectance distribution function (BRDF) models are\ncapable of capturing the distinctive highlights produced by the fibrous nature\nof wood. However, capturing parameter textures for even a single specimen\nremains a laborious process requiring specialized equipment. In this paper we\ntake a procedural approach to generating parameters for the wood BSDF. We\ncharacterize the elements of trees that are important for the appearance of\nwood, discuss techniques appropriate for representing those features, and\npresent a complete procedural wood shader capable of reproducing the growth\npatterns responsible for the distinctive appearance of highly prized\n``figured'' wood. Our procedural wood shader is random-access, 3D, modular, and\nis fast enough to generate a preview for design.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 10:19:41 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 08:14:34 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Liu", "Albert J.", ""], ["Marschner", "Stephen R.", ""], ["Dye", "Victoria E.", ""]]}, {"id": "1511.04902", "submitter": "Yann Schoenenberger", "authors": "Yann Schoenenberger, Johan Paratte, Pierre Vandergheynst", "title": "Graph-based denoising for time-varying point clouds", "comments": "4 pages, 3 figures, 3DTV-Con 2015", "journal-ref": "3DTV-Conference: The True Vision - Capture, Transmission and\n  Display of 3D Video (3DTV-CON) (2015) 1-4", "doi": "10.1109/3DTV.2015.7169366", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Noisy 3D point clouds arise in many applications. They may be due to errors\nwhen constructing a 3D model from images or simply to imprecise depth sensors.\nPoint clouds can be given geometrical structure using graphs created from the\nsimilarity information between points. This paper introduces a technique that\nuses this graph structure and convex optimization methods to denoise 3D point\nclouds. A short discussion presents how those methods naturally generalize to\ntime-varying inputs such as 3D point cloud time series.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 10:34:25 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Schoenenberger", "Yann", ""], ["Paratte", "Johan", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1511.05904", "submitter": "Lingyu Wei", "authors": "Lingyu Wei, Qixing Huang, Duygu Ceylan, Etienne Vouga, Hao Li", "title": "Dense Human Body Correspondences Using Convolutional Networks", "comments": "CVPR 2016 oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep learning approach for finding dense correspondences between\n3D scans of people. Our method requires only partial geometric information in\nthe form of two depth maps or partial reconstructed surfaces, works for humans\nin arbitrary poses and wearing any clothing, does not require the two people to\nbe scanned from similar viewpoints, and runs in real time. We use a deep\nconvolutional neural network to train a feature descriptor on depth map pixels,\nbut crucially, rather than training the network to solve the shape\ncorrespondence problem directly, we train it to solve a body region\nclassification problem, modified to increase the smoothness of the learned\ndescriptors near region boundaries. This approach ensures that nearby points on\nthe human body are nearby in feature space, and vice versa, rendering the\nfeature descriptor suitable for computing dense correspondences between the\nscans. We validate our method on real and synthetic data for both clothed and\nunclothed humans, and show that our correspondences are more robust than is\npossible with state-of-the-art unsupervised methods, and more accurate than\nthose found using methods that require full watertight 3D geometry.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 18:36:54 GMT"}, {"version": "v2", "created": "Sun, 26 Jun 2016 01:06:43 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Wei", "Lingyu", ""], ["Huang", "Qixing", ""], ["Ceylan", "Duygu", ""], ["Vouga", "Etienne", ""], ["Li", "Hao", ""]]}, {"id": "1511.06594", "submitter": "Khalid Khan", "authors": "Khalid Khan, D. K. Lobiyal and Adem Kilicman", "title": "Bezier curves and surfaces based on modified Bernstein polynomials", "comments": "11 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:1507.04110", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use the blending functions of Bernstein polynomials with\nshifted knots for construction of Bezier curves and surfaces. We study the\nnature of degree elevation and degree reduction for Bezier Bernstein functions\nwith shifted knots.\n  Parametric curves are represented using these modified Bernstein basis and\nthe concept of total positivity is applied to investigate the shape properties\nof the curve. We get Bezier curve defined on [0, 1] when we set the parameter\n\\alpha=\\beta to the value 0. We also present a de Casteljau algorithm to\ncompute Bernstein Bezier curves and surfaces with shifted knots. The new curves\nhave some properties similar to Bezier curves. Furthermore, some fundamental\nproperties for Bernstein Bezier curves and surfaces are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 13:52:39 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Khan", "Khalid", ""], ["Lobiyal", "D. K.", ""], ["Kilicman", "Adem", ""]]}, {"id": "1511.06624", "submitter": "Pui Tung Choi", "authors": "Ting Wei Meng, Gary Pui-Tung Choi, Lok Ming Lui", "title": "TEMPO: Feature-Endowed Teichm\\\"uller Extremal Mappings of Point Clouds", "comments": null, "journal-ref": "SIAM Journal on Imaging Sciences 9, 1922-1962 (2016)", "doi": "10.1137/15M1049117", "report-no": null, "categories": "cs.CG cs.CV cs.GR math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent decades, the use of 3D point clouds has been widespread in computer\nindustry. The development of techniques in analyzing point clouds is\nincreasingly important. In particular, mapping of point clouds has been a\nchallenging problem. In this paper, we develop a discrete analogue of the\nTeichm\\\"{u}ller extremal mappings, which guarantee uniform conformality\ndistortions, on point cloud surfaces. Based on the discrete analogue, we\npropose a novel method called TEMPO for computing Teichm\\\"{u}ller extremal\nmappings between feature-endowed point clouds. Using our proposed method, the\nTeichm\\\"{u}ller metric is introduced for evaluating the dissimilarity of point\nclouds. Consequently, our algorithm enables accurate recognition and\nclassification of point clouds. Experimental results demonstrate the\neffectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 14:57:05 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 12:37:02 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Meng", "Ting Wei", ""], ["Choi", "Gary Pui-Tung", ""], ["Lui", "Lok Ming", ""]]}, {"id": "1511.07932", "submitter": "Qinghui Liu", "authors": "Weixing Ji, Qinghui Liu, Guizhen Wang, ZhuoJia Shen", "title": "Embedding of Hypercube into Cylinder", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task mapping in modern high performance parallel computers can be modeled as\na graph embedding problem, which simulates the mapping as embedding one graph\ninto another and try to find the minimum wirelength for the mapping. Though\nembedding problems have been considered for several regular graphs, such as\nhypercubes into grids, binary trees into grids, et al, it is still an open\nproblem for hypercubes into cylinders. In this paper, we consider the problem\nof embedding hypercubes into cylinders to minimize the wirelength. We obtain\nthe exact wirelength formula of embedding hypercube $Q^r$ into cylinder\n$C_{2^3}\\times P_{2^{r-3}}$ with $r\\ge3$.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 01:41:08 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Ji", "Weixing", ""], ["Liu", "Qinghui", ""], ["Wang", "Guizhen", ""], ["Shen", "ZhuoJia", ""]]}, {"id": "1511.08118", "submitter": "D\\v{z}enan Zuki\\'c", "authors": "D\\v{z}enan Zuki\\'c and Julien Finet and Emmanuel Wilson and Filip\n  Banovac and Giuseppe Esposito and Kevin Cleary and Andinet Enquobahrie", "title": "SlicerPET: A workflow based software module for PET/CT guided needle\n  biopsy", "comments": null, "journal-ref": null, "doi": "10.1007/s11548-015-1213-2", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biopsy is commonly used to confirm cancer diagnosis when radiologically\nindicated. Given the ability of PET to localize malignancies in heterogeneous\ntumors and tumors that do not have a CT correlate, PET/CT guided biopsy may\nimprove the diagnostic yield of biopsies. To facilitate PET/CT guided needle\nbiopsy, we developed a workflow that allows us to bring PET image guidance into\nthe interventional CT suite. In this abstract, we present SlicerPET, a\nuser-friendly workflow based module developed using open source software\nlibraries to guide needle biopsy in the interventional suite.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 17:02:20 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Zuki\u0107", "D\u017eenan", ""], ["Finet", "Julien", ""], ["Wilson", "Emmanuel", ""], ["Banovac", "Filip", ""], ["Esposito", "Giuseppe", ""], ["Cleary", "Kevin", ""], ["Enquobahrie", "Andinet", ""]]}]