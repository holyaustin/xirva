[{"id": "1206.1148", "submitter": "Charl Botha Charl Botha", "authors": "Charl P. Botha and Bernhard Preim and Arie Kaufman and Shigeo\n  Takahashi and Anders Ynnerman", "title": "From individual to population: Challenges in Medical Visualization", "comments": "Improvements based on comments by reviewers: Typos and layout issues\n  fixed. Added two more multi-modal volume rendering references to 2.1. Added\n  more detail on Virtual Colonoscopy to 2.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first give a high-level overview of medical visualization\ndevelopment over the past 30 years, focusing on key developments and the trends\nthat they represent. During this discussion, we will refer to a number of key\npapers that we have also arranged on the medical visualization research\ntimeline. Based on the overview and our observations of the field, we then\nidentify and discuss the medical visualization research challenges that we\nforesee for the coming decade.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 08:38:27 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2012 12:40:29 GMT"}], "update_date": "2012-08-08", "authors_parsed": [["Botha", "Charl P.", ""], ["Preim", "Bernhard", ""], ["Kaufman", "Arie", ""], ["Takahashi", "Shigeo", ""], ["Ynnerman", "Anders", ""]]}, {"id": "1206.1428", "submitter": "Charl Botha", "authors": "Hanspeter Pfister, Verena Kaynig, Charl P. Botha, Stefan Bruckner,\n  Vincent J. Dercksen, Hans-Christian Hege and Jos B. T. M. Roerdink", "title": "Visualization in Connectomics", "comments": "Improved definition of diffusion PDF. Integrated reviewer comments:\n  Added figures showing DTI tractography and glyphs, fMRI connectivity vis, EM\n  reconstruction of neuronal structures, Brainbow image. Typos and grammar\n  errors fixed. Description of connectivity matrix added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectomics is a field of neuroscience that analyzes neuronal connections. A\nconnectome is a complete map of a neuronal system, comprising all neuronal\nconnections between its structures. The term \"connectome\" is close to the word\n\"genome\" and implies completeness of all neuronal connections, in the same way\nas a genome is a complete listing of all nucleotide sequences. The goal of\nconnectomics is to create a complete representation of the brain's wiring. Such\na representation is believed to increase our understanding of how functional\nbrain states emerge from their underlying anatomical structure. Furthermore, it\ncan provide important information for the cure of neuronal dysfunctions like\nschizophrenia or autism. In this paper, we review the current state-of-the-art\nof visualization and image processing techniques in the field of connectomics\nand describe some remaining challenges.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 09:17:34 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2012 12:19:28 GMT"}], "update_date": "2012-08-08", "authors_parsed": [["Pfister", "Hanspeter", ""], ["Kaynig", "Verena", ""], ["Botha", "Charl P.", ""], ["Bruckner", "Stefan", ""], ["Dercksen", "Vincent J.", ""], ["Hege", "Hans-Christian", ""], ["Roerdink", "Jos B. T. M.", ""]]}, {"id": "1206.1968", "submitter": "Saurabh Sarkar", "authors": "Saurabh Sarkar", "title": "A novel 2.5D approach for interfacing with web applications", "comments": "An approach offering a new idea for Human Computer Interaction,\n  including 3 pages and 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web applications need better user interface to be interactive and attractive.\nA new approach/concept of dimensional enhancement - 2.5D \"a 2D display of a\nvirtual 3D environment\", which can be implemented in social networking sites\nand further in other system applications.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 20:04:38 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2012 16:27:31 GMT"}, {"version": "v3", "created": "Sat, 29 Sep 2012 14:02:07 GMT"}, {"version": "v4", "created": "Tue, 2 Oct 2012 07:54:53 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Sarkar", "Saurabh", ""]]}, {"id": "1206.3975", "submitter": "Ivan Viola", "authors": "{\\AA}smund Birkeland, Veronika Solteszova, Dieter H\\\"onigmann, Odd\n  Helge Gilja, Svein Brekke, Timo Ropinski and Ivan Viola", "title": "The Ultrasound Visualization Pipeline - A Survey", "comments": null, "journal-ref": null, "doi": "10.1007/978-1-4471-6497-5_24", "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound is one of the most frequently used imaging modality in medicine.\nThe high spatial resolution, its interactive nature and non-invasiveness makes\nit the first choice in many examinations. Image interpretation is one of\nultrasound's main challenges. Much training is required to obtain a confident\nskill level in ultrasound-based diagnostics. State-of-the-art graphics\ntechniques is needed to provide meaningful visualizations of ultrasound in\nreal-time. In this paper we present the process-pipeline for ultrasound\nvisualization, including an overview of the tasks performed in the specific\nsteps. To provide an insight into the trends of ultrasound visualization\nresearch, we have selected a set of significant publications and divided them\ninto a technique-based taxonomy covering the topics pre-processing,\nsegmentation, registration, rendering and augmented reality. For the different\ntechnique types we discuss the difference between ultrasound-based techniques\nand techniques for other modalities.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 16:05:47 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Birkeland", "\u00c5smund", ""], ["Solteszova", "Veronika", ""], ["H\u00f6nigmann", "Dieter", ""], ["Gilja", "Odd Helge", ""], ["Brekke", "Svein", ""], ["Ropinski", "Timo", ""], ["Viola", "Ivan", ""]]}, {"id": "1206.4634", "submitter": "Ning Xie", "authors": "Ning Xie (Tokyo Institute of Technology), Hirotaka Hachiya (Tokyo\n  Institute of Technology), Masashi Sugiyama (Tokyo Institute of Technology)", "title": "Artist Agent: A Reinforcement Learning Approach to Automatic Stroke\n  Generation in Oriental Ink Painting", "comments": "ICML2012", "journal-ref": null, "doi": "10.1587/transinf.E96.D.1134", "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oriental ink painting, called Sumi-e, is one of the most appealing painting\nstyles that has attracted artists around the world. Major challenges in\ncomputer-based Sumi-e simulation are to abstract complex scene information and\ndraw smooth and natural brush strokes. To automatically find such strokes, we\npropose to model the brush as a reinforcement learning agent, and learn desired\nbrush-trajectories by maximizing the sum of rewards in the policy search\nframework. We also provide elaborate design of actions, states, and rewards\ntailored for a Sumi-e agent. The effectiveness of our proposed approach is\ndemonstrated through simulated Sumi-e experiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:14:24 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Xie", "Ning", "", "Tokyo Institute of Technology"], ["Hachiya", "Hirotaka", "", "Tokyo\n  Institute of Technology"], ["Sugiyama", "Masashi", "", "Tokyo Institute of Technology"]]}, {"id": "1206.4880", "submitter": "Jayamohan  M", "authors": "K. Revathy and M. Jayamohan", "title": "Dynamic Domain Classification for Fractal Image Compression", "comments": "8 pages, 4 tables, 1 figure", "journal-ref": null, "doi": "10.5121/ijcsit.2012.4208", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractal image compression is attractive except for its high encoding time\nrequirements. The image is encoded as a set of contractive affine\ntransformations. The image is partitioned into non-overlapping range blocks,\nand a best matching domain block larger than the range block is identified.\nThere are many attempts on improving the encoding time by reducing the size of\nsearch pool for range-domain matching. But these methods are attempting to\nprepare a static domain pool that remains unchanged throughout the encoding\nprocess. This paper proposes dynamic preparation of separate domain pool for\neach range block. This will result in significant reduction in the encoding\ntime. The domain pool for a particular range block can be selected based upon a\nparametric value. Here we use classification based on local fractal dimension.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2012 17:22:49 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Revathy", "K.", ""], ["Jayamohan", "M.", ""]]}, {"id": "1206.6049", "submitter": "Keith S Cover", "authors": "Keith S. Cover", "title": "Improved visualisation of brain arteriovenous malformations using color\n  intensity projections with hue cycling", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Color intensity projections (CIP) have been shown to improve the\nvisualisation of greyscale angiography images by combining greyscale images\ninto a single color image. A key property of the combined CIP image is the\nencoding of the arrival time information from greyscale images into the hue of\nthe color in the CIP image. A few minor improvements to the calculation of the\nCIP image are introduced that substantially improve the quality of the\nvisualisation. One improvement is interpolating of the greyscale images in time\nbefore calculation of the CIP image. A second is the use of hue cycling - where\nthe hue of the color is cycled through more than once in an image. The hue\ncycling allows the variation of the hue to be concentrated in structures of\ninterest. If there is a zero time point hue cycling can be applied after zero\ntime and before zero time can be indicated by greyscale. If there is an end\ntime point hue cycling can be applied before the end time and pixels can be set\nto black after the end time. An angiogram of a brain is used to demonstrate the\nsubstantial improvements hue cycling brings to CIP images. A third improvement\nis the use of maximum intensity projection for 2D rendering of a 3D CIP image\nvolume. A fourth improvement allowing interpreters to interactively adjust the\nphase of the hue via standard contrast - brightness controls using lookup\ntables. Other potential applications of CIP are also mentioned.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 11:05:36 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2013 20:16:26 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2013 11:43:11 GMT"}, {"version": "v4", "created": "Sat, 28 Nov 2015 16:00:29 GMT"}, {"version": "v5", "created": "Wed, 1 Feb 2017 04:27:46 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Cover", "Keith S.", ""]]}, {"id": "1206.6850", "submitter": "Guobiao Mei", "authors": "Guobiao Mei, Christian R. Shelton", "title": "Visualization of Collaborative Data", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-341-348", "categories": "cs.GR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative data consist of ratings relating two distinct sets of objects:\nusers and items. Much of the work with such data focuses on filtering:\npredicting unknown ratings for pairs of users and items. In this paper we focus\non the problem of visualizing the information. Given all of the ratings, our\ntask is to embed all of the users and items as points in the same Euclidean\nspace. We would like to place users near items that they have rated (or would\nrate) high, and far away from those they would give a low rating. We pose this\nproblem as a real-valued non-linear Bayesian network and employ Markov chain\nMonte Carlo and expectation maximization to find an embedding. We present a\nmetric by which to judge the quality of a visualization and compare our results\nto local linear embedding and Eigentaste on three real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:24:29 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Mei", "Guobiao", ""], ["Shelton", "Christian R.", ""]]}]