[{"id": "1505.00073", "submitter": "Yotam Gingold", "authors": "Lisa Huynh and Yotam Gingold", "title": "Bijective Deformations in $\\mathbb{R}^n$ via Integral Curve Coordinates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Integral Curve Coordinates, which identify each point in a\nbounded domain with a parameter along an integral curve of the gradient of a\nfunction $f$ on that domain; suitable functions have exactly one critical\npoint, a maximum, in the domain, and the gradient of the function on the\nboundary points inward. Because every integral curve intersects the boundary\nexactly once, Integral Curve Coordinates provide a natural bijective mapping\nfrom one domain to another given a bijection of the boundary. Our approach can\nbe applied to shapes in any dimension, provided that the boundary of the shape\n(or cage) is topologically equivalent to an $n$-sphere. We present a simple\nalgorithm for generating a suitable function space for $f$ in any dimension. We\ndemonstrate our approach in 2D and describe a practical (simple and robust)\nalgorithm for tracing integral curves on a (piecewise-linear) triangulated\nregular grid.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2015 02:47:12 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Huynh", "Lisa", ""], ["Gingold", "Yotam", ""]]}, {"id": "1505.00880", "submitter": "Hang Su", "authors": "Hang Su, Subhransu Maji, Evangelos Kalogerakis, Erik Learned-Miller", "title": "Multi-view Convolutional Neural Networks for 3D Shape Recognition", "comments": "v1: Initial version. v2: An updated ModelNet40 training/test split is\n  used; results with low-rank Mahalanobis metric learning are added. v3 (ICCV\n  2015): A second camera setup without the upright orientation assumption is\n  added; some accuracy and mAP numbers are changed slightly because a small\n  issue in mesh rendering related to specularities is fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A longstanding question in computer vision concerns the representation of 3D\nshapes for recognition: should 3D shapes be represented with descriptors\noperating on their native 3D formats, such as voxel grid or polygon mesh, or\ncan they be effectively represented with view-based descriptors? We address\nthis question in the context of learning to recognize 3D shapes from a\ncollection of their rendered views on 2D images. We first present a standard\nCNN architecture trained to recognize the shapes' rendered views independently\nof each other, and show that a 3D shape can be recognized even from a single\nview at an accuracy far higher than using state-of-the-art 3D shape\ndescriptors. Recognition rates further increase when multiple views of the\nshapes are provided. In addition, we present a novel CNN architecture that\ncombines information from multiple views of a 3D shape into a single and\ncompact shape descriptor offering even better recognition performance. The same\narchitecture can be applied to accurately recognize human hand-drawn sketches\nof shapes. We conclude that a collection of 2D views can be highly informative\nfor 3D shape recognition and is amenable to emerging CNN architectures and\ntheir derivatives.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 04:51:19 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2015 18:16:01 GMT"}, {"version": "v3", "created": "Sun, 27 Sep 2015 20:42:16 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Su", "Hang", ""], ["Maji", "Subhransu", ""], ["Kalogerakis", "Evangelos", ""], ["Learned-Miller", "Erik", ""]]}, {"id": "1505.01214", "submitter": "Babak Saleh", "authors": "Babak Saleh and Mira Dontcheva and Aaron Hertzmann and Zhicheng Liu", "title": "Learning Style Similarity for Searching Infographics", "comments": "6 pages, to appear in the 41st annual conference on Graphics\n  Interface (GI) 2015,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.HC cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infographics are complex graphic designs integrating text, images, charts and\nsketches. Despite the increasing popularity of infographics and the rapid\ngrowth of online design portfolios, little research investigates how we can\ntake advantage of these design resources. In this paper we present a method for\nmeasuring the style similarity between infographics. Based on human perception\ndata collected from crowdsourced experiments, we use computer vision and\nmachine learning algorithms to learn a style similarity metric for infographic\ndesigns. We evaluate different visual features and learning algorithms and find\nthat a combination of color histograms and Histograms-of-Gradients (HoG)\nfeatures is most effective in characterizing the style of infographics. We\ndemonstrate our similarity metric on a preliminary image retrieval test.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 22:59:32 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Saleh", "Babak", ""], ["Dontcheva", "Mira", ""], ["Hertzmann", "Aaron", ""], ["Liu", "Zhicheng", ""]]}, {"id": "1505.01810", "submitter": "Khalid Khan", "authors": "Khalid Khan and D.K. Lobiyal", "title": "B$\\acute{e}$zier curves based on Lupa\\c{s} $(p,q)$-analogue of Bernstein\n  polynomials in CAGD", "comments": "24 pages, 9 figures, $(p,q)$-lupas operator and limit $(p,q)$-lupas\n  operators and their property introduced, typo corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use the blending functions of Lupa\\c{s} type (rational)\n$(p,q)$-Bernstein operators based on $(p,q)$-integers for construction of\nLupa\\c{s} $(p,q)$-B$\\acute{e}$zier curves (rational curves) and surfaces\n(rational surfaces) with shape parameters. We study the nature of degree\nelevation and degree reduction for Lupa\\c{s} $(p,q)$-B$\\acute{e}$zier Bernstein\nfunctions. Parametric curves are represented using Lupa\\c{s} $(p,q)$-Bernstein\nbasis. We introduce affine de Casteljau algorithm for Lupa\\c{s} type\n$(p,q)$-Bernstein B$\\acute{e}$zier curves. The new curves have some properties\nsimilar to $q$-B$\\acute{e}$zier curves. Moreover, we construct the\ncorresponding tensor product surfaces over the rectangular domain $(u, v) \\in\n[0, 1] \\times [0, 1] $ depending on four parameters. We also study the de\nCasteljau algorithm and degree evaluation properties of the surfaces for these\ngeneralization over the rectangular domain. We get $q$-B$\\acute{e}$zier\nsurfaces for $(u, v) \\in [0, 1] \\times [0, 1] $ when we set the parameter\n$p_1=p_2=1.$ In comparison to $q$-B$\\acute{e}$zier curves and surfaces based on\nLupa\\c{s} $q$-Bernstein polynomials, our generalization gives us more\nflexibility in controlling the shapes of curves and surfaces.\n  We also show that the $(p,q)$-analogue of Lupa\\c{s} Bernstein operator\nsequence $L^{n}_{p_n,q_n}(f,x)$ converges uniformly to $f(x)\\in C[0,1]$ if and\nonly if $0<q_n<p_n\\leq1$ such that $\\lim\\limits_{n\\to\\infty} q_n=1, $\n$\\lim\\limits_{n\\to\\infty} p_n=1$ and $\\lim\\limits_{n\\to\\infty}p_n^n=a,$\n$\\lim\\limits_{n\\to\\infty}q_n^n=b$ with $0<a,b\\leq1.$ On the other hand, for any\n$p>0$ fixed and $p \\neq 1,$ the sequence $L^{n}_{p,q}(f,x)$ converges uniformly\nto $f(x)~ \\in C[0,1]$ if and only if $f(x)=ax+b$ for some $a, b \\in\n\\mathbb{R}.$\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2015 18:36:37 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2015 12:07:50 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2015 20:14:26 GMT"}, {"version": "v4", "created": "Fri, 15 Apr 2016 20:46:06 GMT"}, {"version": "v5", "created": "Sat, 11 Jun 2016 11:47:23 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Khan", "Khalid", ""], ["Lobiyal", "D. K.", ""]]}, {"id": "1505.03111", "submitter": "\\'Agoston R\\'oth", "authors": "\\'Agoston R\\'oth", "title": "Control point based exact description of curves and surfaces in extended\n  Chebyshev spaces", "comments": "24 pages, 7 figures, 2 appendices, 2 listings (some new materials\n  have been added)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extended Chebyshev spaces that also comprise the constants represent large\nfamilies of functions that can be used in real-life modeling or engineering\napplications that also involve important (e.g. transcendental) integral or\nrational curves and surfaces. Concerning computer aided geometric design, the\nunique normalized B-bases of such vector spaces ensure optimal shape preserving\nproperties, important evaluation or subdivision algorithms and useful shape\nparameters. Therefore, we propose global explicit formulas for the entries of\nthose transformation matrices that map these normalized B-bases to the\ntraditional (or ordinary) bases of the underlying vector spaces. Then, we also\ndescribe general and ready to use control point configurations for the exact\nrepresentation of those traditional integral parametric curves and (hybrid)\nsurfaces that are specified by coordinate functions given as (products of\nseparable) linear combinations of ordinary basis functions. The obtained\nresults are also extended to the control point and weight based exact\ndescription of the rational counterpart of these integral parametric curves and\nsurfaces. The universal applicability of our methods is presented through\npolynomial, trigonometric, hyperbolic or mixed extended Chebyshev vector\nspaces.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2015 18:24:18 GMT"}, {"version": "v2", "created": "Thu, 14 May 2015 06:59:37 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2015 04:35:36 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["R\u00f3th", "\u00c1goston", ""]]}, {"id": "1505.03615", "submitter": "Ming Chuang", "authors": "Ming Chuang and Michael Kazhdan", "title": "A Connectivity-Aware Multi-level Finite-Element System for Solving\n  Laplace-Beltrami Equations", "comments": "This work was done when the first author was a PhD student at Johns\n  Hopkins University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on octree-based finite-element systems has developed a multigrid\nsolver for Poisson equations on meshes. While the idea of defining a regularly\nindexed function space has been successfully used in a number of applications,\nit has also been noted that the richness of the function space is limited\nbecause the function values can be coupled across locally disconnected regions.\nIn this work, we show how to enrich the function space by introducing functions\nthat resolve the coupling while still preserving the nesting hierarchy that\nsupports multigrid. A spectral analysis reveals the superior quality of the\nresulting Laplace-Beltrami operator and applications to surface flow\ndemonstrate that our new solver more efficiently converges to the correct\nsolution.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2015 04:08:53 GMT"}], "update_date": "2015-05-15", "authors_parsed": [["Chuang", "Ming", ""], ["Kazhdan", "Michael", ""]]}, {"id": "1505.03977", "submitter": "Jelloul Elmesbahi", "authors": "Jelloul Elmesbahi, Ahmed Errami, Mohammed Khaldoun and Omar Bouattane", "title": "A wide diversity of 3D surfaces Generator using a new implicit function", "comments": "This second submission replaces the first following submission at:\n  arXiv:1505.03977 It completes this later by adding a second model to complete\n  the first one. It corresponds to particular surfaces (Lego cubes) and the\n  other remained results (about 500 3D surfaces). This is to avoid huge file\n  size for our submission and to proof the effectiveness of our model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper a new family of implicit function for synthesizing a\nwide variety of 3D surfaces. The basis of this family consists of the usual\nfunctions that are: the function rectangular pulses, the function saw-tooth\npulses, the function of triangular pulses, the staircase function and the power\nfunction. By combining these common functions, named constituent functions, in\none implicit function and by varying some parameters of this function we can\nsynthesize a wide variety of 3D surfaces with the possibility to set their\ndeformations.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2015 07:38:46 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 16:50:48 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Elmesbahi", "Jelloul", ""], ["Errami", "Ahmed", ""], ["Khaldoun", "Mohammed", ""], ["Bouattane", "Omar", ""]]}, {"id": "1505.05590", "submitter": "Yong-Jin Liu", "authors": "Yong-Jin Liu and Chun-Xu Xu and Dian Fan and Ying He", "title": "Constructing Intrinsic Delaunay Triangulations from the Dual of Geodesic\n  Voronoi Diagrams", "comments": "32 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic Delaunay triangulation (IDT) is a fundamental data structure in\ncomputational geometry and computer graphics. However, except for some\ntheoretical results, such as existence and uniqueness, little progress has been\nmade towards computing IDT on simplicial surfaces. To date the only way for\nconstructing IDTs is the edge-flipping algorithm, which iteratively flips the\nnon-Delaunay edge to be locally Delaunay. Although the algorithm is\nconceptually simple and guarantees to stop in finite steps, it has no known\ntime complexity. Moreover, the edge-flipping algorithm may produce non-regular\ntriangulations, which contain self-loops and/or faces with only two edges. In\nthis paper, we propose a new method for constructing IDT on manifold triangle\nmeshes. Based on the duality of geodesic Voronoi diagrams, our method can\nguarantee the resultant IDTs are regular. Our method has a theoretical\nworst-case time complexity $O(n^2\\log n)$ for a mesh with $n$ vertices. We\nobserve that most real-world models are far from their Delaunay triangulations,\nthus, the edge-flipping algorithm takes many iterations to fix the non-Delaunay\nedges. In contrast, our method is non-iterative and insensitive to the number\nof non-Delaunay edges. Empirically, it runs in linear time $O(n)$ on real-world\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 02:45:41 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Liu", "Yong-Jin", ""], ["Xu", "Chun-Xu", ""], ["Fan", "Dian", ""], ["He", "Ying", ""]]}, {"id": "1505.06022", "submitter": "Toshiya Hachisuka", "authors": "Toshiya Hachisuka", "title": "Implementing a Photorealistic Rendering System using GLSL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ray tracing on GPUs is becoming quite common these days. There are many\npublicly available documents on how to implement basic ray tracing on GPUs for\nspheres and implicit surfaces. We even have some general frameworks for ray\ntracing on GPUs. We however hardly find details on how to implement more\ncomplex ray tracing algorithms themselves that are commonly used for\nphotorealistic rendering. This paper explains an implementation of a\nstand-alone rendering system on GPUs which supports the bounding volume\nhierarchy and stochastic progressive photon mapping. The key characteristic of\nthe system is that it uses only GLSL shaders without relying on any platform\ndependent feature. The system can thus run on many platforms that support\nOpenGL, making photorealistic rendering on GPUs widely accessible. This paper\nalso sketches practical ideas for stackless traversal and pseudorandom number\ngeneration which both fit well with the limited system configuration.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2015 10:41:45 GMT"}], "update_date": "2015-05-25", "authors_parsed": [["Hachisuka", "Toshiya", ""]]}, {"id": "1505.06289", "submitter": "Will Monroe", "authors": "Angel Chang, Will Monroe, Manolis Savva, Christopher Potts,\n  Christopher D. Manning", "title": "Text to 3D Scene Generation with Rich Lexical Grounding", "comments": "10 pages, 7 figures, 3 tables. To appear in ACL-IJCNLP 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to map descriptions of scenes to 3D geometric representations has\nmany applications in areas such as art, education, and robotics. However, prior\nwork on the text to 3D scene generation task has used manually specified object\ncategories and language that identifies them. We introduce a dataset of 3D\nscenes annotated with natural language descriptions and learn from this data\nhow to ground textual descriptions to physical objects. Our method successfully\ngrounds a variety of lexical terms to concrete referents, and we show\nquantitatively that our method improves 3D scene generation over previous work\nusing purely rule-based methods. We evaluate the fidelity and plausibility of\n3D scenes generated with our grounding approach through human judgments. To\nease evaluation on this task, we also introduce an automated metric that\nstrongly correlates with human judgments.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 08:32:11 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2015 01:13:17 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Chang", "Angel", ""], ["Monroe", "Will", ""], ["Savva", "Manolis", ""], ["Potts", "Christopher", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1505.07079", "submitter": "Jose Rodrigues Jr", "authors": "Jose Rodrigues-Jr, Luciana Zaina, Maria Oliveira, Bruno Brandoli, and\n  Agma Traina", "title": "A survey on Information Visualization in light of Vision and Cognitive\n  sciences", "comments": "29 pages, Elsevier Journal preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Visualization techniques are built on a context with many factors\nrelated to both vision and cognition, making it difficult to draw a clear\npicture of how data visually turns into comprehension. In the intent of\npromoting a better picture, here, we survey concepts on vision, cognition, and\nInformation Visualization organized in a theorization named Visual Expression\nProcess. Our theorization organizes the basis of visualization techniques with\na reduced level of complexity; still, it is complete enough to foster\ndiscussions related to design and analytical tasks. Our work introduces the\nfollowing contributions: (1) a Theoretical compilation of vision, cognition,\nand Information Visualization; (2) Discussions supported by vast literature;\nand (3) Reflections on visual-cognitive aspects concerning use and design. We\nexpect our contributions will provide further clarification about how users and\ndesigners think about InfoVis, leveraging the potential of systems and\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 19:03:54 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 12:25:30 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Rodrigues-Jr", "Jose", ""], ["Zaina", "Luciana", ""], ["Oliveira", "Maria", ""], ["Brandoli", "Bruno", ""], ["Traina", "Agma", ""]]}, {"id": "1505.07267", "submitter": "Gilles Falquet", "authors": "Claudine M\\'etral and Gilles Falquet", "title": "Prototyping Information Visualization in 3D City Models: a Model-based\n  Approach", "comments": "Proc. of 3DGeoInfo 2014 Conference, Dubai, November 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When creating 3D city models, selecting relevant visualization techniques is\na particularly difficult user interface design task. A first obstacle is that\ncurrent geodata-oriented tools, e.g. ArcGIS, have limited 3D capabilities and\nlimited sets of visualization techniques. Another important obstacle is the\nlack of unified description of information visualization techniques for 3D city\nmodels. If many techniques have been devised for different types of data or\ninformation (wind flows, air quality fields, historic or legal texts, etc.)\nthey are generally described in articles, and not really formalized. In this\npaper we address the problem of visualizing information in (rich) 3D city\nmodels by presenting a model-based approach for the rapid prototyping of\nvisualization techniques. We propose to represent visualization techniques as\nthe composition of graph transformations. We show that these transformations\ncan be specified with SPARQL construction operations over RDF graphs. These\nspecifications can then be used in a prototype generator to produce 3D scenes\nthat contain the 3D city model augmented with data represented using the\ndesired technique.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 11:25:46 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["M\u00e9tral", "Claudine", ""], ["Falquet", "Gilles", ""]]}, {"id": "1505.07804", "submitter": "Jose Rodrigues Jr", "authors": "Jose F. Rodrigues Jr, Agma J. M. Traina, Maria C. F. Oliveira and\n  Caetano Traina Jr", "title": "The Spatial-Perceptual Design Space: a new comprehension for Data\n  Visualization", "comments": null, "journal-ref": "Information Visualization 6: 4. 261-279 (2007)", "doi": "10.1057/palgrave.ivs.9500161", "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the design space of visualizations aiming at identifying and\nrelating its components. In this sense, we establish a model to examine the\nprocess through which visualizations become expressive for users. This model\nhas leaded us to a taxonomy oriented to the human visual perception, a\nconceptualization that provides natural criteria in order to delineate a novel\nunderstanding for the visualization design space. The new organization of\nconcepts that we introduce is our main contribution: a grammar for the\nvisualization design based on the review of former works and of classical and\nstate-of-the-art techniques. Like so, the paper is presented as a survey whose\nstructure introduces a new conceptualization for the space of techniques\nconcerning visual analysis.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 19:14:44 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Rodrigues", "Jose F.", "Jr"], ["Traina", "Agma J. M.", ""], ["Oliveira", "Maria C. F.", ""], ["Traina", "Caetano", "Jr"]]}, {"id": "1505.07940", "submitter": "Jeremy Frey", "authors": "Dennis Wobrock (INRIA Bordeaux - Sud-Ouest), J\\'er\\'emy Frey (UB,\n  LaBRI, INRIA Bordeaux - Sud-Ouest), Delphine Graeff, Jean-Baptiste De La\n  Rivi\\`ere, Julien Castet, Fabien Lotte (LaBRI, INRIA Bordeaux - Sud-Ouest)", "title": "Continuous Mental Effort Evaluation during 3D Object Manipulation Tasks\n  based on Brain and Physiological Signals", "comments": "Published in INTERACT, Sep 2015, Bamberg, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing 3D User Interfaces (UI) requires adequate evaluation tools to\nensure good usability and user experience. While many evaluation tools are\nalready available and widely used, existing approaches generally cannot provide\ncontinuous and objective measures of usa-bility qualities during interaction\nwithout interrupting the user. In this paper, we propose to use brain (with\nElectroEncephaloGraphy) and physiological (ElectroCardioGraphy, Galvanic Skin\nResponse) signals to continuously assess the mental effort made by the user to\nperform 3D object manipulation tasks. We first show how this mental effort\n(a.k.a., mental workload) can be estimated from such signals, and then measure\nit on 8 participants during an actual 3D object manipulation task with an input\ndevice known as the CubTile. Our results suggest that monitoring workload\nenables us to continuously assess the 3DUI and/or interaction technique\nease-of-use. Overall, this suggests that this new measure could become a useful\naddition to the repertoire of available evaluation tools, enabling a finer\ngrain assessment of the ergonomic qualities of a given 3D user interface.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 06:53:08 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Wobrock", "Dennis", "", "INRIA Bordeaux - Sud-Ouest"], ["Frey", "J\u00e9r\u00e9my", "", "UB,\n  LaBRI, INRIA Bordeaux - Sud-Ouest"], ["Graeff", "Delphine", "", "LaBRI, INRIA Bordeaux - Sud-Ouest"], ["De La Rivi\u00e8re", "Jean-Baptiste", "", "LaBRI, INRIA Bordeaux - Sud-Ouest"], ["Castet", "Julien", "", "LaBRI, INRIA Bordeaux - Sud-Ouest"], ["Lotte", "Fabien", "", "LaBRI, INRIA Bordeaux - Sud-Ouest"]]}]