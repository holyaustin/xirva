[{"id": "1503.00040", "submitter": "Oncel Tuzel", "authors": "Chinmay Hegde, Oncel Tuzel, Fatih Porikli", "title": "Efficient Upsampling of Natural Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method of efficient upsampling of a single natural image.\nCurrent methods for image upsampling tend to produce high-resolution images\nwith either blurry salient edges, or loss of fine textural detail, or spurious\nnoise artifacts.\n  In our method, we mitigate these effects by modeling the input image as a sum\nof edge and detail layers, operating upon these layers separately, and merging\nthe upscaled results in an automatic fashion. We formulate the upsampled output\nimage as the solution to a non-convex energy minimization problem, and propose\nan algorithm to obtain a tractable approximate solution. Our algorithm\ncomprises two main stages. 1) For the edge layer, we use a nonparametric\napproach by constructing a dictionary of patches from a given image, and\nsynthesize edge regions in a higher-resolution version of the image. 2) For the\ndetail layer, we use a global parametric texture enhancement approach to\nsynthesize detail regions across the image.\n  We demonstrate that our method is able to accurately reproduce sharp edges as\nwell as synthesize photorealistic textures, while avoiding common artifacts\nsuch as ringing and haloing. In addition, our method involves no training phase\nor estimation of model parameters, and is easily parallelizable. We demonstrate\nthe utility of our method on a number of challenging standard test photos.\n", "versions": [{"version": "v1", "created": "Sat, 28 Feb 2015 00:18:39 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Hegde", "Chinmay", ""], ["Tuzel", "Oncel", ""], ["Porikli", "Fatih", ""]]}, {"id": "1503.00088", "submitter": "Weiyao Lin", "authors": "Yihao Zhang, Weiyao Lin, Bing Zhou, Zhenzhong Chen, Bin Sheng, Jianxin\n  Wu, Wenjun Zhang", "title": "Facial Expression Cloning with Elastic and Muscle Models", "comments": "This manuscript is the accepted version for JVCI (Journal of Visual\n  Communication and Image Representation)", "journal-ref": "Journal of Visual Communication and Image Representation, vol. 25,\n  no. 5, pp. 916-927, 2014", "doi": null, "report-no": null, "categories": "cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expression cloning plays an important role in facial expression synthesis. In\nthis paper, a novel algorithm is proposed for facial expression cloning. The\nproposed algorithm first introduces a new elastic model to balance the global\nand local warping effects, such that the impacts from facial feature diversity\namong people can be minimized, and thus more effective geometric warping\nresults can be achieved. Furthermore, a muscle-distribution-based (MD) model is\nproposed, which utilizes the muscle distribution of the human face and results\nin more accurate facial illumination details. In addition, we also propose a\nnew distance-based metric to automatically select the optimal parameters such\nthat the global and local warping effects in the elastic model can be suitably\nbalanced. Experimental results show that our proposed algorithm outperforms the\nexisting methods.\n", "versions": [{"version": "v1", "created": "Sat, 28 Feb 2015 07:23:08 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Zhang", "Yihao", ""], ["Lin", "Weiyao", ""], ["Zhou", "Bing", ""], ["Chen", "Zhenzhong", ""], ["Sheng", "Bin", ""], ["Wu", "Jianxin", ""], ["Zhang", "Wenjun", ""]]}, {"id": "1503.00202", "submitter": "Keqian Li", "authors": "Keqian Li", "title": "On Integrating Information Visualization Techniques into Data Mining: A\n  Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploding growth of digital data in the information era and its\nimmeasurable potential value has called for different types of data-driven\ntechniques to exploit its value for further applications. Information\nvisualization and data mining are two research field with such goal. While the\ntwo communities advocates different approaches of problem solving, the vision\nof combining the sophisticated algorithmic techniques from data mining as well\nas the intuitivity and interactivity of information visualization is tempting.\nIn this paper, we attempt to survey recent researches and real world systems\nintegrating the wisdom in two fields towards more effective and efficient data\nanalytics. More specifically, we study the intersection from a data mining\npoint of view, explore how information visualization can be used to complement\nand improve different stages of data mining through established theories for\noptimized visual presentation as well as practical toolsets for rapid\ndevelopment. We organize the survey by identifying three main stages of typical\nprocess of data mining, the preliminary analysis of data, the model\nconstruction, as well as the model evaluation, and study how each stage can\nbenefit from information visualization.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2015 01:10:03 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Li", "Keqian", ""]]}, {"id": "1503.01804", "submitter": "Achuta Kadambi", "authors": "Achuta Kadambi, Vage Taamazyan, Suren Jayasuriya, Ramesh Raskar", "title": "Frequency Domain TOF: Encoding Object Depth in Modulation Frequency", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time of flight cameras may emerge as the 3-D sensor of choice. Today, time of\nflight sensors use phase-based sampling, where the phase delay between emitted\nand received, high-frequency signals encodes distance. In this paper, we\npresent a new time of flight architecture that relies only on frequency---we\nrefer to this technique as frequency-domain time of flight (FD-TOF). Inspired\nby optical coherence tomography (OCT), FD-TOF excels when frequency bandwidth\nis high. With the increasing frequency of TOF sensors, new challenges to time\nof flight sensing continue to emerge. At high frequencies, FD-TOF offers\nseveral potential benefits over phase-based time of flight methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2015 22:15:33 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Kadambi", "Achuta", ""], ["Taamazyan", "Vage", ""], ["Jayasuriya", "Suren", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1503.01903", "submitter": "Christine Guillemot Dr", "authors": "A. Mousnier, E. Vural, C. Guillemot", "title": "Partial light field tomographic reconstruction from a fixed-camera focal\n  stack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel approach to partially reconstruct\nhigh-resolution 4D light fields from a stack of differently focused photographs\ntaken with a fixed camera. First, a focus map is calculated from this stack\nusing a simple approach combining gradient detection and region expansion with\ngraph-cut. Then, this focus map is converted into a depth map thanks to the\ncalibration of the camera. We proceed after this with the tomographic\nreconstruction of the epipolar images by back-projecting the focused regions of\nthe scene only. We call it masked back-projection. The angles of\nback-projection are calculated from the depth map. Thanks to the high angular\nresolution we achieve by suitably exploiting the image content captured over a\nlarge interval of focus distances, we are able to render puzzling perspective\nshifts although the original photographs were taken from a single fixed camera\nat a fixed position.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2015 10:50:40 GMT"}], "update_date": "2015-03-09", "authors_parsed": [["Mousnier", "A.", ""], ["Vural", "E.", ""], ["Guillemot", "C.", ""]]}, {"id": "1503.03167", "submitter": "Tejas Kulkarni", "authors": "Tejas D. Kulkarni, Will Whitney, Pushmeet Kohli, Joshua B. Tenenbaum", "title": "Deep Convolutional Inverse Graphics Network", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Deep Convolution Inverse Graphics Network (DC-IGN), a\nmodel that learns an interpretable representation of images. This\nrepresentation is disentangled with respect to transformations such as\nout-of-plane rotations and lighting variations. The DC-IGN model is composed of\nmultiple layers of convolution and de-convolution operators and is trained\nusing the Stochastic Gradient Variational Bayes (SGVB) algorithm. We propose a\ntraining procedure to encourage neurons in the graphics code layer to represent\na specific transformation (e.g. pose or light). Given a single input image, our\nmodel can generate new images of the same object with variations in pose and\nlighting. We present qualitative and quantitative results of the model's\nefficacy at learning a 3D rendering engine.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2015 04:08:42 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2015 04:57:24 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2015 02:22:07 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2015 02:10:00 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Kulkarni", "Tejas D.", ""], ["Whitney", "Will", ""], ["Kohli", "Pushmeet", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1503.05787", "submitter": "Tobias Isenberg", "authors": "Maarten H. Everts, Henk Bekker, Jos B.T.M. Roerdink, and Tobias\n  Isenberg", "title": "Interactive Illustrative Line Styles and Line Style Transfer Functions\n  for Flow Visualization", "comments": "Extended version of a short paper at Pacific Graphics 2011\n  (http://dx.doi.org/10.2312/PE/PG/PG2011short/105-110)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a flexible illustrative line style model for the visualization of\nstreamline data. Our model partitions view-oriented line strips into parallel\nbands whose basic visual properties can be controlled independently. We thus\nextend previous line stylization techniques specifically for visualization\npurposes by allowing the parametrization of these bands based on the local line\ndata attributes. Moreover, our approach supports emphasis and abstraction by\nintroducing line style transfer functions that map local line attribute values\nto complete line styles. With a flexible GPU implementation of this line style\nmodel we enable the interactive exploration of visual representations of\nstreamlines. We demonstrate the effectiveness of our model by applying it to 3D\nflow field datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2015 14:53:55 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2015 14:01:50 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Everts", "Maarten H.", ""], ["Bekker", "Henk", ""], ["Roerdink", "Jos B. T. M.", ""], ["Isenberg", "Tobias", ""]]}, {"id": "1503.06958", "submitter": "Rushan Ziatdinov", "authors": "Sajid Musa, Rushan Ziatdinov, Omer Faruk Sozcu, Carol Griffiths", "title": "Developing Educational Computer Animation Based on Human Personality\n  Types", "comments": "19 pages, 19 figures, 18 tables", "journal-ref": "European Journal of Contemporary Education, 2015, Vol. 11, Issue\n  1, pp. 52-71", "doi": "10.13187/ejced.2015.11.52", "report-no": null, "categories": "cs.HC cs.CY cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer animation in the past decade has become one of the most noticeable\nfeatures of technology-based learning environments. With today's high\neducational demands as well as the lack of time provided for certain courses,\nclassical educational methods have shown deficiencies in keeping up with the\ndrastic changes observed in the digital era. Without taking into account\nvarious significant factors such as gender, age, level of interest and memory\nlevel, educational animation may turn out to be insufficient for learners or\nfail to meet their needs. However, we have noticed that the applications of\nanimation for education have been given only inadequate attention, and\nstudents' personality types have never been taken into account. We suggest\nthere is an interesting relationship here, and propose essential factors in\ncreating educational animations based on students' personality types.\nParticularly, we investigate how information in computer animation may be\npresented in a preferable way based on the fundamental elements of computer\nanimation. The present study believes that it is likely to have wide benefits\nin the field of education. Considering the personality types in designing\neducational computer animations with the aid of gathered empirical results\nmight be a promising avenue to enhance the learning process.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 09:27:14 GMT"}], "update_date": "2015-03-25", "authors_parsed": [["Musa", "Sajid", ""], ["Ziatdinov", "Rushan", ""], ["Sozcu", "Omer Faruk", ""], ["Griffiths", "Carol", ""]]}, {"id": "1503.06995", "submitter": "Leonardo Fernandez-Jambrina", "authors": "A. Cant\\'on, L. Fern\\'andez-Jambrina", "title": "Interpolation of a spline developable surface between a curve and two\n  rulings", "comments": null, "journal-ref": "Frontiers of Information Technology & Electronic Engineering 16,\n  173-190 (2015)", "doi": "10.1631/FITEE.14a0210", "report-no": null, "categories": "cs.GR math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of interpolating a spline developable\npatch bounded by a given spline curve and the first and the last rulings of the\ndevelopable surface. In order to complete the boundary of the patch a second\nspline curve is to be given. Up to now this interpolation problem could be\nsolved, but without the possibility of choosing both endpoints for the rulings.\nWe circumvent such difficulty here by resorting to degree elevation of the\ndevelopable surface. This is useful not only to solve this problem, but also\nother problems dealing with triangular developable patches.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 11:42:43 GMT"}], "update_date": "2015-03-25", "authors_parsed": [["Cant\u00f3n", "A.", ""], ["Fern\u00e1ndez-Jambrina", "L.", ""]]}]