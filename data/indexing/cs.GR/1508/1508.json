[{"id": "1508.00396", "submitter": "Gary Pui-Tung Choi", "authors": "Gary Pui-Tung Choi, Lok Ming Lui", "title": "A Linear Formulation for Disk Conformal Parameterization of\n  Simply-Connected Open Surfaces", "comments": null, "journal-ref": "Advances in Computational Mathematics 44, 87-114 (2018)", "doi": "10.1007/s10444-017-9536-x", "report-no": null, "categories": "cs.CG cs.GR math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface parameterization is widely used in computer graphics and geometry\nprocessing. It simplifies challenging tasks such as surface registrations,\nmorphing, remeshing and texture mapping. In this paper, we present an efficient\nalgorithm for computing the disk conformal parameterization of simply-connected\nopen surfaces. A double covering technique is used to turn a simply-connected\nopen surface into a genus-0 closed surface, and then a fast algorithm for\nparameterization of genus-0 closed surfaces can be applied. The symmetry of the\ndouble covered surface preserves the efficiency of the computation. A planar\nparameterization can then be obtained with the aid of a M\\\"obius transformation\nand the stereographic projection. After that, a normalization step is applied\nto guarantee the circular boundary. Finally, we achieve a bijective disk\nconformal parameterization by a composition of quasi-conformal mappings.\nExperimental results demonstrate a significant improvement in the computational\ntime by over 60%. At the same time, our proposed method retains comparable\naccuracy, bijectivity and robustness when compared with the state-of-the-art\napproaches. Applications to texture mapping are presented for illustrating the\neffectiveness of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2015 12:25:25 GMT"}, {"version": "v2", "created": "Tue, 2 Aug 2016 03:22:22 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Choi", "Gary Pui-Tung", ""], ["Lui", "Lok Ming", ""]]}, {"id": "1508.02826", "submitter": "Nicolas Ray", "authors": "Nicolas Ray, Dmitry Sokolov", "title": "Inappropriate use of L-BFGS, Illustrated on frame field design", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  L-BFGS is a hill climbing method that is guarantied to converge only for\nconvex problems. In computer graphics, it is often used as a black box solver\nfor a more general class of non linear problems, including problems having many\nlocal minima. Some works obtain very nice results by solving such difficult\nproblems with L-BFGS. Surprisingly, the method is able to escape local minima:\nour interpretation is that the approximation of the Hessian is smoother than\nthe real Hessian, making it possible to evade the local minima. We analyse the\nbehavior of L-BFGS on the design of 2D frame fields. It involves an energy\nfunction that is infinitly continuous, strongly non linear and having many\nlocal minima. Moreover, the local minima have a clear visual interpretation:\nthey corresponds to differents frame field topologies. We observe that the\nperformances of LBFGS are almost unpredictables: they are very competitive when\nthe field is sampled on the primal graph, but really poor when they are sampled\non the dual graph.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 07:02:19 GMT"}], "update_date": "2015-08-13", "authors_parsed": [["Ray", "Nicolas", ""], ["Sokolov", "Dmitry", ""]]}, {"id": "1508.03590", "submitter": "Lo\\\"is Mignard-Debise", "authors": "Lois Mignard-Debise, Ivo Ihrke", "title": "Light-field Microscopy with a Consumer Light-field Camera", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of inexpensive consumer light- field camera technology for\nthe purpose of light-field mi- croscopy. Our experiments are based on the Lytro\n(first gen- eration) camera. Unfortunately, the optical systems of the Lytro\nand those of microscopes are not compatible, lead- ing to a loss of light-field\ninformation due to angular and spatial vignetting when directly recording\nmicroscopic pic- tures. We therefore consider an adaptation of the Lytro op-\ntical system. We demonstrate that using the Lytro directly as an oc- ular\nreplacement, leads to unacceptable spatial vignetting. However, we also found a\nsetting that allows the use of the Lytro camera in a virtual imaging mode which\nprevents the information loss to a large extent. We analyze the new vir- tual\nimaging mode and use it in two different setups for im- plementing light-field\nmicroscopy using a Lytro camera. As a practical result, we show that the camera\ncan be used for low magnification work, as e.g. common in quality control,\nsurface characterization, etc. We achieve a maximum spa- tial resolution of\nabout 6.25{\\mu}m, albeit at a limited SNR for the side views.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2015 12:17:09 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2015 09:12:02 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Mignard-Debise", "Lois", ""], ["Ihrke", "Ivo", ""]]}, {"id": "1508.03649", "submitter": "Hokky Situngkir", "authors": "Hokky Situngkir", "title": "Borobudur was Built Algorithmically", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": "BFI Working Paper Series, WP082010", "categories": "cs.CY cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The self-similarity of Indonesian Borobudur Temple is observed through the\ndimensionality of stupa that is hypothetically closely related to whole\narchitectural body. Fractal dimension is calculated by using the cube counting\nmethod and found that the dimension is 2.325, which is laid between the\ntwo-dimensional plane and three dimensional space. The applied fractal geometry\nand self-similarity of the building is emerged as the building process\nimplement the metric rules, since there is no universal metric standard known\nin ancient traditional Javanese culture thus the architecture is not based on\nfinal master plan. The paper also proposes how the hypothetical algorithmic\narchitecture might be applied computationally in order to see some experimental\ngenerations of similar building. The paper ends with some conjectures for\nfurther challenge and insights related to fractal geometry in Javanese\ntraditional cultural heritages.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2015 04:08:27 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Situngkir", "Hokky", ""]]}, {"id": "1508.03840", "submitter": "Ibrahim Adeyanju", "authors": "Ibrahim Adeyanju and Comfort Babalola and Kareemat Salaudeen and Biola\n  Oyediran", "title": "3D-Computer Animation for a Yoruba Native Folktale", "comments": "9 pages", "journal-ref": "International Journal of Computer Graphics & Animation (IJCGA)\n  Vol.5, No.3, July 2015", "doi": "10.5121/ijcga.2015.5302", "report-no": null, "categories": "cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer graphics has wide range of applications which are implemented into\ncomputer animation, computer modeling among others. Since the invention of\ncomputer graphics researchers have not paid much of attentions toward the\npossibility of converting oral tales otherwise known as folktales into possible\ncartoon animated videos. This paper is based on how to develop cartoons of\nlocal folktales that will be of huge benefits to Nigerians. The activities were\ndivided into 5 stages; analysis, design, development, implementation and\nevaluation which involved various processes and use of various specialized\nsoftware and hardware. After the implementation of this project, the video\ncharacteristics were evaluated using likert scale. Analysis of 30 user\nresponses indicated that 17 users (56.7 percent) rated the image quality as\nexcellent, the video and image synchronization was rated as excellent by 9\nusers (30 percent), the Background noise was rated excellent by 18 users (60\npercent), the Character Impression was rated Excellent by 11 users (36.67\npercent), the general assessment of the storyline was rated excellent by 17\nusers (56.7 percent), the video Impression was rated excellent by 11 users\n(36.67 percent) and the voice quality was rated by 10 users (33.33 percent) as\nexcellent.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2015 15:58:11 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Adeyanju", "Ibrahim", ""], ["Babalola", "Comfort", ""], ["Salaudeen", "Kareemat", ""], ["Oyediran", "Biola", ""]]}, {"id": "1508.04981", "submitter": "Changsoo Je", "authors": "Changsoo Je, Sang Wook Lee, and Rae-Hong Park", "title": "High-Contrast Color-Stripe Pattern for Rapid Structured-Light Range\n  Imaging", "comments": "13 pages, 12 figures, 8th European Conference on Computer Vision\n  (ECCV), Prague, Czech Republic, May 2004, Proceedings, Part I", "journal-ref": "Computer Vision - ECCV 2004, LNCS 3021, pp. 95-107,\n  Springer-Verlag Berlin Heidelberg, May 10, 2004", "doi": "10.1007/978-3-540-24670-1_8", "report-no": null, "categories": "cs.CV cs.GR physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For structured-light range imaging, color stripes can be used for increasing\nthe number of distinguishable light patterns compared to binary BW stripes.\nTherefore, an appropriate use of color patterns can reduce the number of light\nprojections and range imaging is achievable in single video frame or in \"one\nshot\". On the other hand, the reliability and range resolution attainable from\ncolor stripes is generally lower than those from multiply projected binary BW\npatterns since color contrast is affected by object color reflectance and\nambient light. This paper presents new methods for selecting stripe colors and\ndesigning multiple-stripe patterns for \"one-shot\" and \"two-shot\" imaging. We\nshow that maximizing color contrast between the stripes in one-shot imaging\nreduces the ambiguities resulting from colored object surfaces and limitations\nin sensor/projector resolution. Two-shot imaging adds an extra video frame and\nmaximizes the color contrast between the first and second video frames to\ndiminish the ambiguities even further. Experimental results demonstrate the\neffectiveness of the presented one-shot and two-shot color-stripe imaging\nschemes.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 13:43:46 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Je", "Changsoo", ""], ["Lee", "Sang Wook", ""], ["Park", "Rae-Hong", ""]]}, {"id": "1508.06171", "submitter": "Changsoo Je", "authors": "Changsoo Je and Hyung-Min Park", "title": "BREN: Body Reflection Essence-Neuter Model for Separation of Reflection\n  Components", "comments": "4 pages, 4 figures", "journal-ref": "Optics Letters, Volume 40, Issue 9, pp. 1940-1943, May 1, 2015", "doi": "10.1364/OL.40.001940", "report-no": null, "categories": "cs.CV cs.GR physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reflection color model consisting of body essence and\n(mixed) neuter, and present an effective method for separating dichromatic\nreflection components using a single image. Body essence is an entity invariant\nto interface reflection, and has two degrees of freedom unlike hue and maximum\nchromaticity. As a result, the proposed method is insensitive to noise and\nproper for colors around CMY (cyan, magenta, and yellow) as well as RGB (red,\ngreen, and blue), contrary to the maximum chromaticity-based methods. Interface\nreflection is separated by using a Gaussian function, which removes a critical\nthresholding problem. Furthermore, the method does not require any region\nsegmentation. Experimental results show the efficacy of the proposed model and\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 14:47:18 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Je", "Changsoo", ""], ["Park", "Hyung-Min", ""]]}, {"id": "1508.06181", "submitter": "Changsoo Je", "authors": "Changsoo Je, Min Tang, Youngeun Lee, Minkyoung Lee, Young J. Kim", "title": "PolyDepth: Real-time Penetration Depth Computation using Iterative\n  Contact-Space Projection", "comments": "Presented in ACM SIGGRAPH 2012. 15 pages, 23 figures", "journal-ref": "ACM Transactions on Graphics (ToG 2012), Volume 31, Issue 1,\n  Article 5, pp. 1-14, January 1, 2012", "doi": "10.1145/2077341.2077346", "report-no": null, "categories": "cs.GR cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a real-time algorithm that finds the Penetration Depth (PD)\nbetween general polygonal models based on iterative and local optimization\ntechniques. Given an in-collision configuration of an object in configuration\nspace, we find an initial collision-free configuration using several methods\nsuch as centroid difference, maximally clear configuration, motion coherence,\nrandom configuration, and sampling-based search. We project this configuration\non to a local contact space using a variant of continuous collision detection\nalgorithm and construct a linear convex cone around the projected\nconfiguration. We then formulate a new projection of the in-collision\nconfiguration onto the convex cone as a Linear Complementarity Problem (LCP),\nwhich we solve using a type of Gauss-Seidel iterative algorithm. We repeat this\nprocedure until a locally optimal PD is obtained. Our algorithm can process\ncomplicated models consisting of tens of thousands triangles at interactive\nrates.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 15:01:47 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Je", "Changsoo", ""], ["Tang", "Min", ""], ["Lee", "Youngeun", ""], ["Lee", "Minkyoung", ""], ["Kim", "Young J.", ""]]}, {"id": "1508.07569", "submitter": "Pui Tung Choi", "authors": "Gary Pui-Tung Choi, Kin Tat Ho, Lok Ming Lui", "title": "Spherical Conformal Parameterization of Genus-0 Point Clouds for Meshing", "comments": null, "journal-ref": "SIAM Journal on Imaging Sciences 9, 1582-1618 (2016)", "doi": "10.1137/15M1037561", "report-no": null, "categories": "cs.CG cs.CV cs.GR math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point cloud is the most fundamental representation of 3D geometric objects.\nAnalyzing and processing point cloud surfaces is important in computer graphics\nand computer vision. However, most of the existing algorithms for surface\nanalysis require connectivity information. Therefore, it is desirable to\ndevelop a mesh structure on point clouds. This task can be simplified with the\naid of a parameterization. In particular, conformal parameterizations are\nadvantageous in preserving the geometric information of the point cloud data.\nIn this paper, we extend a state-of-the-art spherical conformal\nparameterization algorithm for genus-0 closed meshes to the case of point\nclouds, using an improved approximation of the Laplace-Beltrami operator on\ndata points. Then, we propose an iterative scheme called the North-South\nreiteration for achieving a spherical conformal parameterization. A balancing\nscheme is introduced to enhance the distribution of the spherical\nparameterization. High quality triangulations and quadrangulations can then be\nbuilt on the point clouds with the aid of the parameterizations. Also, the\nmeshes generated are guaranteed to be genus-0 closed meshes. Moreover, using\nour proposed spherical conformal parameterization, multilevel representations\nof point clouds can be easily constructed. Experimental results demonstrate the\neffectiveness of our proposed framework.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2015 13:42:43 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 06:05:49 GMT"}, {"version": "v3", "created": "Wed, 16 Mar 2016 08:47:28 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Choi", "Gary Pui-Tung", ""], ["Ho", "Kin Tat", ""], ["Lui", "Lok Ming", ""]]}, {"id": "1508.07593", "submitter": "Remi Ronfard", "authors": "Remi Ronfard and Vineet Gandhi and Laurent Boiron and Vaishnavi Ameya\n  Murukutla", "title": "The Prose Storyboard Language: A Tool for Annotating and Directing\n  Movies", "comments": "20 pages, extended version includes new figures and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prose storyboard language is a formal language for describing movies shot\nby shot, where each shot is described with a unique sentence. The language uses\na simple syntax and limited vocabulary borrowed from working practices in\ntraditional movie-making, and is intended to be readable both by machines and\nhumans. The language is designed to serve as a high-level user interface for\nintelligent cinematography and editing systems.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2015 16:12:59 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 07:56:06 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 22:48:24 GMT"}, {"version": "v4", "created": "Fri, 30 Oct 2020 11:55:13 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Ronfard", "Remi", ""], ["Gandhi", "Vineet", ""], ["Boiron", "Laurent", ""], ["Murukutla", "Vaishnavi Ameya", ""]]}, {"id": "1508.07859", "submitter": "Changsoo Je", "authors": "Changsoo Je, Kwang Hee Lee, Sang Wook Lee", "title": "Multi-Projector Color Structured-Light Vision", "comments": "25 pages, 13 figures", "journal-ref": "Signal Processing: Image Communication, Volume 28, Issue 9, pp.\n  1046-1058, October, 2013", "doi": "10.1016/j.image.2013.05.005", "report-no": null, "categories": "cs.CV cs.GR physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research interest in rapid structured-light imaging has grown increasingly\nfor the modeling of moving objects, and a number of methods have been suggested\nfor the range capture in a single video frame. The imaging area of a 3D object\nusing a single projector is restricted since the structured light is projected\nonly onto a limited area of the object surface. Employing additional projectors\nto broaden the imaging area is a challenging problem since simultaneous\nprojection of multiple patterns results in their superposition in the\nlight-intersected areas and the recognition of original patterns is by no means\ntrivial. This paper presents a novel method of multi-projector color\nstructured-light vision based on projector-camera triangulation. By analyzing\nthe behavior of superposed-light colors in a chromaticity domain, we show that\nthe original light colors cannot be properly extracted by the conventional\ndirect estimation. We disambiguate multiple projectors by multiplexing the\norientations of projector patterns so that the superposed patterns can be\nseparated by explicit derivative computations. Experimental studies are carried\nout to demonstrate the validity of the presented method. The proposed method\nincreases the efficiency of range acquisition compared to conventional active\nstereo using multiple projectors.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 14:55:59 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Je", "Changsoo", ""], ["Lee", "Kwang Hee", ""], ["Lee", "Sang Wook", ""]]}]