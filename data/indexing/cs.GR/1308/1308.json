[{"id": "1308.0375", "submitter": "Bo  Li", "authors": "Bo Li and Xin Zhao", "title": "A New 3D Geometric Approach to Focus and Context Lens Effect Simulation", "comments": "Poster for I3D", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel methodology based on geometric approach to simulate\nmagnification lens effects. Our aim is to promote new applications of powerful\ngeometric modeling techniques in visual computing. Conventional image\nprocessing/visualization methods are computed in two dimensional space (2D). We\nexamine this conventional 2D manipulation from a completely innovative\nperspective of 3D geometric processing. Compared with conventional optical lens\ndesign, 3D geometric method are much more capable of preserving shape features\nand minimizing distortion. We magnify an area of interest to better visualize\nthe interior details, while keeping the rest of area without perceivable\ndistortion. We flatten the mesh back into 2D space for viewing, and further\napplications in the screen space. In both steps, we devise an iterative\ndeformation scheme to minimize distortion around both focus and context region,\nwhile avoiding the noncontinuous transition region between the focus and\ncontext areas. Particularly, our method allows the user to flexibly modify the\nROI shapes to accommodate complex feature. The user can also easily specify a\nspectrum of metrics for different visual effects. Various experimental results\ndemonstrate the effectiveness, robustness, and efficiency of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 23:08:03 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Li", "Bo", ""], ["Zhao", "Xin", ""]]}, {"id": "1308.0376", "submitter": "Tomoyoshi Shimobaba Dr.", "authors": "Tomoyoshi Shimobaba, Takashi Kakue, Minoru Oikawa, Naoki Takada,\n  Naohisa Okada, Yutaka Endo, Ryuji Hirayama, Tomoyoshi Ito", "title": "Calculation reduction method for color computer-generated hologram using\n  color space conversion", "comments": null, "journal-ref": null, "doi": "10.1117/1.OE.53.2.024108", "report-no": null, "categories": "physics.optics cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a calculation reduction method for color computer-generated\nholograms (CGHs) using color space conversion. Color CGHs are generally\ncalculated on RGB space. In this paper, we calculate color CGHs in other color\nspaces: for example, YCbCr color space. In YCbCr color space, a RGB image is\nconverted to the luminance component (Y), blue-difference chroma (Cb) and\nred-difference chroma (Cr) components. In terms of the human eye, although the\nnegligible difference of the luminance component is well-recognized, the\ndifference of the other components is not. In this method, the luminance\ncomponent is normal sampled and the chroma components are down-sampled. The\ndown-sampling allows us to accelerate the calculation of the color CGHs. We\ncompute diffraction calculations from the components, and then we convert the\ndiffracted results in YCbCr color space to RGB color space.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 23:09:28 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Shimobaba", "Tomoyoshi", ""], ["Kakue", "Takashi", ""], ["Oikawa", "Minoru", ""], ["Takada", "Naoki", ""], ["Okada", "Naohisa", ""], ["Endo", "Yutaka", ""], ["Hirayama", "Ryuji", ""], ["Ito", "Tomoyoshi", ""]]}, {"id": "1308.0419", "submitter": "Dong-Ming Yan", "authors": "Fuzhang Wu, Dong-Ming Yan, Weiming Dong, Xiaopeng Zhang and Peter\n  Wonka", "title": "Inverse Procedural Modeling of Facade Layouts", "comments": "10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the following research problem: How can we generate\na meaningful split grammar that explains a given facade layout? To evaluate if\na grammar is meaningful, we propose a cost function based on the description\nlength and minimize this cost using an approximate dynamic programming\nframework. Our evaluation indicates that our framework extracts meaningful\nsplit grammars that are competitive with those of expert users, while some\nusers and all competing automatic solutions are less successful.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 07:10:47 GMT"}, {"version": "v2", "created": "Thu, 8 May 2014 18:34:09 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Wu", "Fuzhang", ""], ["Yan", "Dong-Ming", ""], ["Dong", "Weiming", ""], ["Zhang", "Xiaopeng", ""], ["Wonka", "Peter", ""]]}, {"id": "1308.0867", "submitter": "Bo  Li", "authors": "Bo Li", "title": "A Survey of Spline-based Volumetric Data Modeling Framework and Its\n  Applications", "comments": "Master Thesis, Computer Science Department, Stony Brook University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid advances in 3D scanning and acquisition techniques have given rise\nto the explosive increase of volumetric digital models in recent years. This\ndissertation systematically trailblazes a novel volumetric modeling framework\nto represent 3D solids. The need to explore more efficient and robust 3D\nmodeling framework has gained the prominence. Although the traditional surface\nrepresentation (e.g., triangle mesh) has many attractive properties, it is\nincapable of expressing the interior space and materials. Such a serious\ndrawback overshadows many potential modeling and analysis applications.\nConsequently volumetric modeling techniques become the well-known solution to\nthis problem. Nevertheless, many unsolved research issues remain when\ndeveloping an efficient modeling paradigm for existing 3D models: complex\ngeometry (fine details and extreme concaveness), arbitrary topology,\nheterogenous materials, large-scale data storage and processing, etc.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2013 01:27:36 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Li", "Bo", ""]]}, {"id": "1308.0869", "submitter": "Bo  Li", "authors": "Bo Li", "title": "A Spline-based Volumetric Data Modeling Framework and Its Applications", "comments": "Ph.D thesis, Computer Science Department, Stony Brook University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this dissertation, we concentrate on the challenging research issue of\ndeveloping a spline-based modeling framework, which converts the conventional\ndata (e.g., surface meshes) to tensor-product trivariate splines. This\nmethodology can represent both boundary/volumetric geometry and real volumetric\nphysical attributes in a compact and continuous fashion. The regular\ntensor-product structure enables our new developed methods to be embedded into\nthe industry standard seamlessly. These properties make our techniques highly\npreferable in many physically-based applications including mechanical analysis,\nshape deformation and editing, virtual surgery training, etc.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2013 01:56:59 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Li", "Bo", ""]]}, {"id": "1308.1279", "submitter": "Russell Brown", "authors": "Russell A. Brown", "title": "Barycentric Coordinates as Interpolants", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Barycentric coordinates are frequently used as interpolants to shade computer\ngraphics images. A simple equation transforms barycentric coordinates from\nscreen space into eye space in order to undo the perspective transformation and\npermit accurate interpolative shading of texture maps. This technique is\namenable to computation using a block-normalized integer representation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 14:15:42 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2013 13:39:44 GMT"}, {"version": "v3", "created": "Thu, 8 Aug 2013 14:09:09 GMT"}, {"version": "v4", "created": "Thu, 23 Oct 2014 09:46:57 GMT"}, {"version": "v5", "created": "Fri, 24 Oct 2014 03:08:21 GMT"}, {"version": "v6", "created": "Mon, 27 Oct 2014 04:34:08 GMT"}, {"version": "v7", "created": "Tue, 28 Oct 2014 00:42:03 GMT"}, {"version": "v8", "created": "Wed, 29 Oct 2014 02:34:55 GMT"}, {"version": "v9", "created": "Thu, 30 Oct 2014 05:07:47 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Brown", "Russell A.", ""]]}, {"id": "1308.3917", "submitter": "Yi-King Choi", "authors": "Feng Sun, Yi-King Choi, Yizhou Yu, Wenping Wang", "title": "Medial Meshes for Volume Approximation", "comments": "12 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volume approximation is an important problem found in many applications of\ncomputer graphics, vision, and image processing. The problem is about computing\nan accurate and compact approximate representation of 3D volumes using some\nsimple primitives. In this study, we propose a new volume representation,\ncalled medial meshes, and present an efficient method for its computation.\nSpecifically, we use the union of a novel type of simple volume primitives,\nwhich are spheres and the convex hulls of two or three spheres, to approximate\na given 3D shape. We compute such a volume approximation based on a new method\nfor medial axis simplification guided by Hausdorff errors. We further\ndemonstrate the superior efficiency and accuracy of our method over existing\nmethods for medial axis simplification.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 03:34:21 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Sun", "Feng", ""], ["Choi", "Yi-King", ""], ["Yu", "Yizhou", ""], ["Wang", "Wenping", ""]]}, {"id": "1308.4338", "submitter": "Leonardo Torres", "authors": "Leonardo Torres and Alejandro C. Frery", "title": "SAR Image Despeckling Algorithms using Stochastic Distances and Nonlocal\n  Means", "comments": "Accepted for publication in Workshop of Theses and Dissertations\n  (WTD) in Conference on Graphics, Patterns, and Images (SIBGRAPI 2013). This\n  paper received the first best work award in the Dissertation category at the\n  WTD-SIBGRAPI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two approaches for filter design based on stochastic\ndistances for intensity speckle reduction. A window is defined around each\npixel, overlapping samples are compared and only those which pass a\ngoodness-of-fit test are used to compute the filtered value. The tests stem\nfrom stochastic divergences within the Information Theory framework. The\ntechnique is applied to intensity Synthetic Aperture Radar (SAR) data with\nhomogeneous regions using the Gamma model. The first approach uses a\nNagao-Matsuyama-type procedure for setting the overlapping samples, and the\nsecond uses the nonlocal method. The proposals are compared with the Improved\nSigma filter and with anisotropic diffusion for speckled data (SRAD) using a\nprotocol based on Monte Carlo simulation. Among the criteria used to quantify\nthe quality of filters, we employ the equivalent number of looks, and line and\nedge preservation. Moreover, we also assessed the filters by the Universal\nImage Quality Index and by the Pearson correlation between edges. Applications\nto real images are also discussed. The proposed methods show good results.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 15:58:19 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Torres", "Leonardo", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1308.4908", "submitter": "Joel Kronander", "authors": "Joel Kronander, Stefan Gustavson, Gerhard Bonnet, Anders Ynnerman and\n  Jonas Unger", "title": "A Unified Framework for Multi-Sensor HDR Video Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most successful approaches to modern high quality HDR-video\ncapture is to use camera setups with multiple sensors imaging the scene through\na common optical system. However, such systems pose several challenges for HDR\nreconstruction algorithms. Previous reconstruction techniques have considered\ndebayering, denoising, resampling (align- ment) and exposure fusion as separate\nproblems. In contrast, in this paper we present a unifying approach, performing\nHDR assembly directly from raw sensor data. Our framework includes a camera\nnoise model adapted to HDR video and an algorithm for spatially adaptive HDR\nreconstruction based on fitting of local polynomial approximations to observed\nsensor data. The method is easy to implement and allows reconstruction to an\narbitrary resolution and output mapping. We present an implementation in CUDA\nand show real-time performance for an experimental 4 Mpixel multi-sensor HDR\nvideo system. We further show that our algorithm has clear advantages over\nexisting methods, both in terms of flexibility and reconstruction quality.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 15:58:01 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Kronander", "Joel", ""], ["Gustavson", "Stefan", ""], ["Bonnet", "Gerhard", ""], ["Ynnerman", "Anders", ""], ["Unger", "Jonas", ""]]}, {"id": "1308.5843", "submitter": "Dimo Chotrov", "authors": "Stoyan Maleshkov, Dimo Chotrov", "title": "Affordable Virtual Reality System Architecture for Representation of\n  Implicit Object Properties", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 4, No 2, July 2012", "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A flexible, scalable and affordable virtual reality software system\narchitecture is proposed. This solution can be easily implemented on different\nhardware configurations: on a single computer or on a computer cluster. The\narchitecture is aimed to be integrated in the workflow for solving engineering\ntasks and oriented towards presenting implicit object properties through\nmultiple sensorial channels (visual, audio and haptic). Implicit properties\nrepresent hidden object features (i.e. magnetization, radiation, humidity,\ntoxicity, etc.) which cannot be perceived by the observer through his or her\nsenses but require specialized equipment in order to expand the sensory ability\nof the observer. Our approach extends the underlying general scene graph\nstructure incorporating additional effects nodes for implicit properties\nrepresentation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 12:44:54 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Maleshkov", "Stoyan", ""], ["Chotrov", "Dimo", ""]]}, {"id": "1308.5847", "submitter": "Dimo Chotrov", "authors": "Stoyan Maleshkov, Dimo Chotrov", "title": "Post-processing of Engineering Analysis Results for Visualization in VR\n  Systems", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 10,\n  Issue 2, March 2013", "doi": null, "report-no": null, "categories": "cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The applicability of Virtual Reality for evaluating engineering analysis\nresults is beginning to receive increased appreciation in the last years. The\nproblem many engineers are still facing is how to import their model together\nwith the analysis results in a virtual reality environment for exploration and\nresults validation. In this paper we propose an algorithm for transforming\nmodel data and results from finite element analysis (FEA) solving application\nto a format easily interpretable by a virtual reality application. The\nalgorithm includes also steps for reducing the face-count of the resulting mesh\nby eliminating faces from the inner part of the model in the cases when only\nthe surfaces of the model is analyzed. We also describe a possibility for\nsimultaneously assessing multiple analysis results relying on multimodal\nresults presentation by stimulating different senses of the operator.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 12:47:34 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Maleshkov", "Stoyan", ""], ["Chotrov", "Dimo", ""]]}, {"id": "1308.6487", "submitter": "Leonardo Torres", "authors": "Leonardo Torres and Tamer Cavalcante and Alejandro C. Frery", "title": "A New Algorithm of Speckle Filtering using Stochastic Distances", "comments": "Accepted for publication on the proceedings of the IEEE Geoscience\n  and Remote Sensing Symposium (IGARSS 2012), to be published in IEEE Press.\n  Available: http://www.igarss2012.org/Papers/viewpapers.asp?papernum=4877", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for filter design based on stochastic\ndistances and tests between distributions. A window is defined around each\npixel, overlapping samples are compared and only those which pass a\ngoodness-of-fit test are used to compute the filtered value. The technique is\napplied to intensity SAR data with homogeneous regions using the Gamma model.\nThe proposal is compared with the Lee's filter using a protocol based on Monte\nCarlo. Among the criteria used to quantify the quality of filters, we employ\nthe equivalent number of looks, line and edge preservation. Moreover, we also\nassessed the filters by the Universal Image Quality Index and the Pearson's\ncorrelation on edges regions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 14:56:01 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Torres", "Leonardo", ""], ["Cavalcante", "Tamer", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1308.6804", "submitter": "Alan Brunton", "authors": "Alan Brunton, Michael Wand, Stefanie Wuhrer, Hans-Peter Seidel, Tino\n  Weinkauf", "title": "A Low-Dimensional Representation for Robust Partial Isometric\n  Correspondences Computation", "comments": "17 pages, 12 figures", "journal-ref": "Graphical Models, 76(2), pp. 70--85, March 2014", "doi": "10.1016/j.gmod.2013.11.003", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic isometric shape matching has become the standard approach for pose\ninvariant correspondence estimation among deformable shapes. Most existing\napproaches assume global consistency, i.e., the metric structure of the whole\nmanifold must not change significantly. While global isometric matching is well\nunderstood, only a few heuristic solutions are known for partial matching.\nPartial matching is particularly important for robustness to topological noise\n(incomplete data and contacts), which is a common problem in real-world 3D\nscanner data. In this paper, we introduce a new approach to partial, intrinsic\nisometric matching. Our method is based on the observation that isometries are\nfully determined by purely local information: a map of a single point and its\ntangent space fixes an isometry for both global and the partial maps. From this\nidea, we develop a new representation for partial isometric maps based on\nequivalence classes of correspondences between pairs of points and their\ntangent spaces. From this, we derive a local propagation algorithm that find\nsuch mappings efficiently. In contrast to previous heuristics based on RANSAC\nor expectation maximization, our method is based on a simple and sound\ntheoretical model and fully deterministic. We apply our approach to register\npartial point clouds and compare it to the state-of-the-art methods, where we\nobtain significant improvements over global methods for real-world data and\nstronger guarantees than previous heuristic partial matching algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 17:38:40 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2014 11:20:26 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Brunton", "Alan", ""], ["Wand", "Michael", ""], ["Wuhrer", "Stefanie", ""], ["Seidel", "Hans-Peter", ""], ["Weinkauf", "Tino", ""]]}]