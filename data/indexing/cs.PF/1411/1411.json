[{"id": "1411.0143", "submitter": "Federico Larroca", "authors": "Paola Bermolen, Matthieu Jonckheere, Federico Larroca, Pascal Moyal", "title": "Estimating the Spatial Reuse with Configuration Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new methodology to estimate the spatial reuse of CSMA-like\nscheduling. Instead of focusing on spatial configurations of users, we model\nthe interferences between users as a random graph. Using configuration models\nfor random graphs, we show how the properties of the medium access mechanism\nare captured by some deterministic differential equations, when the size of the\ngraph gets large. Performance indicators such as the probability of connection\nof a given node can then be efficiently computed from these equations. We also\nperform simulations to illustrate the results on different types of random\ngraphs. Even on spatial structures, these estimates get very accurate as soon\nas the variance of the interference is not negligible.\n", "versions": [{"version": "v1", "created": "Sat, 1 Nov 2014 17:55:45 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Bermolen", "Paola", ""], ["Jonckheere", "Matthieu", ""], ["Larroca", "Federico", ""], ["Moyal", "Pascal", ""]]}, {"id": "1411.0912", "submitter": "Blesson Varghese", "authors": "Blesson Varghese, Ozgur Akgun, Ian Miguel, Long Thai and Adam Barker", "title": "Cloud Benchmarking for Performance", "comments": "6 pages, 6th IEEE International Conference on Cloud Computing\n  Technology and Science (IEEE CloudCom) 2014, Singapore", "journal-ref": null, "doi": "10.1109/CloudCom.2014.28", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can applications be deployed on the cloud to achieve maximum performance?\nThis question has become significant and challenging with the availability of a\nwide variety of Virtual Machines (VMs) with different performance capabilities\nin the cloud. The above question is addressed by proposing a six step\nbenchmarking methodology in which a user provides a set of four weights that\nindicate how important each of the following groups: memory, processor,\ncomputation and storage are to the application that needs to be executed on the\ncloud. The weights along with cloud benchmarking data are used to generate a\nranking of VMs that can maximise performance of the application. The rankings\nare validated through an empirical analysis using two case study applications;\nthe first is a financial risk application and the second is a molecular\ndynamics simulation, which are both representative of workloads that can\nbenefit from execution on the cloud. Both case studies validate the feasibility\nof the methodology and highlight that maximum performance can be achieved on\nthe cloud by selecting the top ranked VMs produced by the methodology.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 13:57:24 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Varghese", "Blesson", ""], ["Akgun", "Ozgur", ""], ["Miguel", "Ian", ""], ["Thai", "Long", ""], ["Barker", "Adam", ""]]}, {"id": "1411.1460", "submitter": "Oded Green", "authors": "Oded Green and Marat Dukhan and Richard Vuduc", "title": "Branch-Avoiding Graph Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper quantifies the impact of branches and branch mispredictions on the\nsingle-core performance for two classes of graph problems. Specifically, we\nconsider classical algorithms for computing connected components and\nbreadth-first search (BFS). We show that branch mispredictions are costly and\ncan reduce performance by as much as 30%-50%. This insight suggests that one\nshould seek graph algorithms and implementations that avoid branches.\n  As a proof-of-concept, we devise such implementations for both the classic\ntop-down algorithm for BFS and the Shiloach-Vishkin algorithm for connected\ncomponents. We evaluate these implementations on current x86 and ARM-based\nprocessors to show the efficacy of the approach. Our results suggest how both\ncompiler writers and architects might exploit this insight to improve graph\nprocessing systems more broadly and create better systems for such problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 00:36:24 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Green", "Oded", ""], ["Dukhan", "Marat", ""], ["Vuduc", "Richard", ""]]}, {"id": "1411.1998", "submitter": "MM Aftab Hossain", "authors": "M. M. Aftab Hossain, Riku J\\\"antti, Cicek Cavdar", "title": "Dimensioning of PA for massive MIMO system with load adaptive number of\n  antennas", "comments": "7 pages, 8 figures, to be published in Globecom GBA workshop 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper takes into consideration the non-ideal efficiency characteristics\nof realistic power amplifiers (PAs) along with the daily traffic profile in\norder to investigate the impact of PA dimensioning on the energy efficiency\n(EE) of load adaptive massive MIMO system. A multicellular system has been\nconsidered where each base station (BS) is equipped with a large number of\nantennas to serve many single antenna users. For a given number of users in a\ncell, the optimum number of active antennas maximizing EE has been derived\nwhere total BS downlink power is assumed to be fixed. Under the same\nassumption, the PAs have been dimensioned in a way that maximizes network EE\nnot only for a single time snapshot but over twenty four hours of operation\nwhile considering dynamic efficiency characteristics of the PAs. In order to\nincorporate this daily load profile, each BS has been modeled as an M/G/m/m\nstate dependent queue under the assumption that the network is dimensioned to\nserve a maximum number of users at a time corresponding to 100% cell traffic\nload. This load adaptive system along with the optimized PA dimensioning\nachieves 30% higher energy efficiency compared to a base line system where the\nBSs always run with a fixed number of active antennas which are most energy\nefficient while serving 100% traffic load.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 21:00:25 GMT"}], "update_date": "2014-11-10", "authors_parsed": [["Hossain", "M. M. Aftab", ""], ["J\u00e4ntti", "Riku", ""], ["Cavdar", "Cicek", ""]]}, {"id": "1411.2047", "submitter": "James Cadek", "authors": "Stephen Romansky", "title": "Investigation of the relationship between code change set n-grams and\n  change in energy consumption", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of software running on mobile devices is constantly growing as\nconsumers and industry purchase more battery powered devices. On the other\nhand, tools that provide developers with feed- back on how their software\nchanges affect battery life are not widely available. This work employs Green\nMining, the study of the rela- tionship between energy consumption and software\nchangesets, and n-gram language models to evaluate if source code changeset\nperplex- ity correlates with change in energy consumption. A correlation be-\ntween perplexity and change in energy consumption would permit the development\nof a tool that predicts the impact a code changeset may have on a software\napplications energy consumption. The case study results show that there is weak\nto no correlation between cross en- tropy and change in energy consumption.\nTherefore, future areas of investigation are proposed.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 22:05:16 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Romansky", "Stephen", ""]]}, {"id": "1411.2222", "submitter": "Neha Karanjkar", "authors": "Neha V. Karanjkar, Madhav P. Desai", "title": "Optimization of Discrete-parameter Multiprocessor Systems using a Novel\n  Ergodic Interpolation Technique", "comments": "A short version of this paper will be published in the proceedings of\n  IEEE MASCOTS 2015 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern multi-core systems have a large number of design parameters, most of\nwhich are discrete-valued, and this number is likely to keep increasing as chip\ncomplexity rises. Further, the accurate evaluation of a potential design choice\nis computationally expensive because it requires detailed cycle-accurate system\nsimulation. If the discrete parameter space can be embedded into a larger\ncontinuous parameter space, then continuous space techniques can, in principle,\nbe applied to the system optimization problem. Such continuous space techniques\noften scale well with the number of parameters.\n  We propose a novel technique for embedding the discrete parameter space into\nan extended continuous space so that continuous space techniques can be applied\nto the embedded problem using cycle accurate simulation for evaluating the\nobjective function. This embedding is implemented using simulation-based\nergodic interpolation, which, unlike spatial interpolation, produces the\ninterpolated value within a single simulation run irrespective of the number of\nparameters. We have implemented this interpolation scheme in a cycle-based\nsystem simulator. In a characterization study, we observe that the interpolated\nperformance curves are continuous, piece-wise smooth, and have low statistical\nerror. We use the ergodic interpolation-based approach to solve a large\nmulti-core design optimization problem with 31 design parameters. Our results\nindicate that continuous space optimization using ergodic interpolation-based\nembedding can be a viable approach for large multi-core design optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 9 Nov 2014 12:21:23 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2015 07:24:53 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Karanjkar", "Neha V.", ""], ["Desai", "Madhav P.", ""]]}, {"id": "1411.2867", "submitter": "Ravi Mazumdar Dr", "authors": "Oczan Ozturk, Ravi R. Mazumdar, and Nikolay B. Likhanov", "title": "Buffer occupancy asymptotics in rate proportional sharing networks with\n  heterogeneous long-tailed inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a network of rate proportional processor sharing\nservers in which sessions with long-tailed duration arrive as Poisson\nprocesses. In particular, we assume that a session of type $n$ transmits at a\nrate $r_n$ bits per unit time and lasts for a random time $\\tau_n$ with a\ngeneralized Pareto distribution given by $P \\{\\tau_n > x\\} \\sim \\alpha_n\nx^{-(1+\\beta_n)}$ for large $x$, where $\\alpha_n, \\beta_n > 0$. The weights are\ntaken to be the rates of the flows. The network is assumed to be loop-free with\nrespect to source-destination routes. We characterize the order $O-$asymptotics\nof the complementary buffer occupancy distribution at each node in terms of the\ninput characteristics of the sessions. In particular, we show that the\ndistributions obey a power law whose exponent can be calculated via solving a\nfixed point and deterministic knapsack problem. The paper concludes with some\ncanonical examples.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 16:13:32 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Ozturk", "Oczan", ""], ["Mazumdar", "Ravi R.", ""], ["Likhanov", "Nikolay B.", ""]]}, {"id": "1411.2890", "submitter": "Mahmood Mohassel Feghhi", "authors": "Mahmood Mohassel Feghhi, Aliazam Abbasfar, Mahtab Mirmohseni", "title": "Performance Analysis for Energy Harvesting Communication Protocols with\n  Fixed Rate Transmission", "comments": "29 pages, 12 figures, Accepted for publication in IET Communications,\n  August 2014", "journal-ref": "IET Communications, Vol. 8, No. 18, Dec. 2014, Pages 3259-3270", "doi": "10.1049/iet-com.2014.0281", "report-no": null, "categories": "cs.IT cs.ET cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy Harvesting (EH) has emerged as a promising technique for Green\nCommunications and it is a novel technique to prolong the lifetime of the\nwireless networks with replenishable nodes. In this paper, we consider the\nenergy shortage analysis of fixed rate transmission in communication systems\nwith energy harvesting nodes. First, we study the finite-horizon transmission\nand provide the general formula for the energy shortage probability. We also\ngive some examples as benchmarks. Then, we continue to derive a closed-form\nexpression for infinite-horizon transmission, which is a lower bound for the\nenergy shortage probability of any finite-horizon transmission. These results\nare proposed for both Additive White Gaussian Noise (AWGN) and fading channels.\nMoreover, we show that even under \\emph{random energy arrival}, one can\ntransmit at a fixed rate equal to capacity in the AWGN channels with negligible\naggregate shortage time. We achieve this result using our practical\ntransmission schemes, proposed for finite-horizon. Also, comprehensive\nnumerical simulations are performed in AWGN and fading channels with no Channel\nState Information (CSI) available at the transmitter, which corroborate our\ntheoretical findings. Furthermore, we improve the performance of our\ntransmission schemes in the fading channel with no CSI at the transmitter by\noptimizing the transmission initiation threshold.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 17:14:24 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Feghhi", "Mahmood Mohassel", ""], ["Abbasfar", "Aliazam", ""], ["Mirmohseni", "Mahtab", ""]]}, {"id": "1411.3656", "submitter": "Karel Ad\\'amek", "authors": "Karel Ad\\'amek, Jan Novotn\\'y and Wes Armour", "title": "The Implementation of a Real-Time Polyphase Filter", "comments": "Proceedings of WDS 2014, Charles University in Prague, Faculty of\n  Mathematics and Physics Troja, Prague", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study the suitability of dierent computational\naccelerators for the task of real-time data processing. The algorithm used for\ncomparison is the polyphase filter, a standard tool in signal processing and a\nwell established algorithm. We measure performance in FLOPs and execution time,\nwhich is a critical factor for real-time systems. For our real-time studies we\nhave chosen a data rate of 6.5GB/s, which is the estimated data rate for a\nsingle channel on the SKAs Low Frequency Aperture Array. Our findings how that\nGPUs are the most likely candidate for real-time data processing. GPUs are\nbetter in both performance and power consumption.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 18:33:21 GMT"}], "update_date": "2014-11-14", "authors_parsed": [["Ad\u00e1mek", "Karel", ""], ["Novotn\u00fd", "Jan", ""], ["Armour", "Wes", ""]]}, {"id": "1411.4433", "submitter": "Vashti Galpin", "authors": "Luca Bortolussi and Vashti Galpin and Jane Hillston", "title": "Stochastic HYPE: Flow-based modelling of stochastic hybrid systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic HYPE is a novel process algebra that models stochastic,\ninstantaneous and continuous behaviour. It develops the flow-based approach of\nthe hybrid process algebra HYPE by replacing non-urgent events with events with\nexponentially-distributed durations and also introduces random resets. The\nrandom resets allow for general stochasticity, and in particular allow for the\nuse of event durations drawn from distributions other than the exponential\ndistribution. To account for stochasticity, the semantics of stochastic HYPE\ntarget piecewise deterministic Markov processes (PDMPs), via intermediate\ntransition-driven stochastic hybrid automata (TDSHA) in contrast to the hybrid\nautomata used as semantic target for HYPE. Stochastic HYPE models have a\nspecific structure where the controller of a system is separate from the\ncontinuous aspect of this system providing separation of concerns and\nsupporting reasoning. A novel equivalence is defined which captures when two\nmodels have the same stochastic behaviour (as in stochastic bisimulation),\ninstantaneous behaviour (as in classical bisimulation) and continuous\nbehaviour. These techniques are illustrated via an assembly line example.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 11:08:17 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Bortolussi", "Luca", ""], ["Galpin", "Vashti", ""], ["Hillston", "Jane", ""]]}, {"id": "1411.4733", "submitter": "Ameen Chilwan", "authors": "Kashif Mahmood, Ameen Chilwan, Olav N. {\\O}sterb{\\o}, Michael Jarschel", "title": "On The Modeling of OpenFlow-based SDNs: The Single Node Case", "comments": "Published in Proceedings of CS & IT for NeCOM 2014", "journal-ref": "Proceedings of Computer Science and Information Technology (CS &\n  IT), Vol.4, 2014, pp 207-214", "doi": "10.5121/csit.2014.41120", "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenFlow is one of the most commonly used protocols for communication between\nthe controller and the forwarding element in a software defined network (SDN).\nA model based on M/M/1 queues is proposed in [1] to capture the communication\nbetween the forwarding element and the controller. Albeit the model provides\nuseful insight, it is accurate only for the case when the probability of\nexpecting a new flow is small. Secondly, it is not straight forward to extend\nthe model in [1] to more than one forwarding element in the data plane. In this\nwork we propose a model which addresses both these challenges. The model is\nbased on Jackson assumption but with corrections tailored to the OpenFlow based\nSDN network. Performance analysis using the proposed model indicates that the\nmodel is accurate even for the case when the probability of new flow is quite\nlarge. Further we show by a toy example that the model can be extended to more\nthan one node in the data plane.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 04:40:20 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Mahmood", "Kashif", ""], ["Chilwan", "Ameen", ""], ["\u00d8sterb\u00f8", "Olav N.", ""], ["Jarschel", "Michael", ""]]}, {"id": "1411.4759", "submitter": "Emilio Leonardi", "authors": "Emilio Leonardi and Giovanni Luca Torrisi", "title": "Modeling LRU caches with Shot Noise request processes", "comments": "To appear in SIAP - A preliminary, incomplete version of this work\n  has appeared in Proceedings of IEEE Infocom 2015, HK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze Least Recently Used (LRU) caches operating under the\nShot Noise requests Model (SNM). The SNM was recently proposed to better\ncapture the main characteristics of today Video on Demand (VoD) traffic. We\ninvestigate the validity of Che's approximation through an asymptotic analysis\nof the cache eviction time. In particular, we provide a large deviation\nprinciple, a law of large numbers and a central limit theorem for the cache\neviction time, as the cache size grows large. Finally, we derive upper and\nlower bounds for the \"hit\" probability in tandem networks of caches under Che's\napproximation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 08:20:39 GMT"}, {"version": "v2", "created": "Wed, 19 Nov 2014 17:18:34 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2015 08:03:12 GMT"}, {"version": "v4", "created": "Thu, 15 Dec 2016 13:26:13 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Leonardi", "Emilio", ""], ["Torrisi", "Giovanni Luca", ""]]}, {"id": "1411.5547", "submitter": "Andrea Tassi", "authors": "Andrea Tassi, Ioannis Chatzigeorgiou, Dejan Vukobratovi\\'c", "title": "Resource Allocation Frameworks for Network-coded Layered Multimedia\n  Multicast Services", "comments": "IEEE Journal on Selected Areas in Communications - Special Issue on\n  Fundamental Approaches to Network Coding in Wireless Communication Systems.\n  To appear", "journal-ref": null, "doi": "10.1109/JSAC.2014.2384231", "report-no": null, "categories": "cs.IT cs.MM cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosive growth of content-on-the-move, such as video streaming to\nmobile devices, has propelled research on multimedia broadcast and multicast\nschemes. Multi-rate transmission strategies have been proposed as a means of\ndelivering layered services to users experiencing different downlink channel\nconditions. In this paper, we consider Point-to-Multipoint layered service\ndelivery across a generic cellular system and improve it by applying different\nrandom linear network coding approaches. We derive packet error probability\nexpressions and use them as performance metrics in the formulation of resource\nallocation frameworks. The aim of these frameworks is both the optimization of\nthe transmission scheme and the minimization of the number of broadcast packets\non each downlink channel, while offering service guarantees to a predetermined\nfraction of users. As a case of study, our proposed frameworks are then adapted\nto the LTE-A standard and the eMBMS technology. We focus on the delivery of a\nvideo service based on the H.264/SVC standard and demonstrate the advantages of\nlayered network coding over multi-rate transmission. Furthermore, we establish\nthat the choice of both the network coding technique and resource allocation\nmethod play a critical role on the network footprint, and the quality of each\nreceived video layer.\n", "versions": [{"version": "v1", "created": "Thu, 20 Nov 2014 13:39:59 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Tassi", "Andrea", ""], ["Chatzigeorgiou", "Ioannis", ""], ["Vukobratovi\u0107", "Dejan", ""]]}, {"id": "1411.6521", "submitter": "Tony Luo", "authors": "Tie Luo and Mehul Motani and Vikram Srinivasan", "title": "Energy-Efficient Strategies for Cooperative Multi-Channel MAC Protocols", "comments": "Energy efficiency, cost efficiency, distributed information sharing,\n  DISH, altruistic cooperation", "journal-ref": "IEEE Transactions on Mobile Computing (TMC), vol. 11, no. 4, pp.\n  553-566, April 2012", "doi": "10.1109/TMC.2011.60", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Information SHaring (DISH) is a new cooperative approach to\ndesigning multi-channel MAC protocols. It aids nodes in their decision making\nprocesses by compensating for their missing information via information sharing\nthrough other neighboring nodes. This approach was recently shown to\nsignificantly boost the throughput of multi-channel MAC protocols. However, a\ncritical issue for ad hoc communication devices, i.e., energy efficiency, has\nyet to be addressed. In this paper, we address this issue by developing simple\nsolutions which (1) reduce the energy consumption (2) without compromising the\nthroughput performance, and meanwhile (3) maximize cost efficiency. We propose\ntwo energy-efficient strategies: in-situ energy conscious DISH which uses\nexisting nodes only, and altruistic DISH which needs additional nodes called\naltruists. We compare five protocols with respect to the strategies and\nidentify altruistic DISH to be the right choice in general: it (1) conserves\n40-80% of energy, (2) maintains the throughput advantage gained from the DISH\napproach, and (3) more than doubles the cost efficiency compared to protocols\nwithout applying the strategy. On the other hand, our study shows that in-situ\nenergy conscious DISH is suitable only in certain limited scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 16:43:26 GMT"}, {"version": "v2", "created": "Tue, 25 Nov 2014 02:52:37 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Luo", "Tie", ""], ["Motani", "Mehul", ""], ["Srinivasan", "Vikram", ""]]}, {"id": "1411.6749", "submitter": "Tie (Tony) Luo", "authors": "Tie Luo and Mehul Motani and Vikram Srinivasan", "title": "Analyzing DISH for Multi-Channel MAC Protocols in Wireless Networks", "comments": "Multi-channel multi-hop networks, availability of cooperation,\n  cooperative protocol, distributed information sharing, ACM MobiHoc, May 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For long, node cooperation has been exploited as a data relaying mechanism.\nHowever, the wireless channel allows for much richer interaction between nodes.\nOne such scenario is in a multi-channel environment, where transmitter-receiver\npairs may make incorrect decisions (e.g., in selecting channels) but idle\nneighbors could help by sharing information to prevent undesirable consequences\n(e.g., data collisions). This represents a Distributed Information SHaring\n(DISH) mechanism for cooperation and suggests new ways of designing cooperative\nprotocols. However, what is lacking is a theoretical understanding of this new\nnotion of cooperation. In this paper, we view cooperation as a network resource\nand evaluate the availability of cooperation via a metric, $p_{co}$, the\nprobability of obtaining cooperation. First, we analytically evaluate $p_{co}$\nin the context of multi-channel multi-hop wireless networks. Second, we verify\nour analysis via simulations and the results show that our analysis accurately\ncharacterizes the behavior of $p_{co}$ as a function of underlying network\nparameters. This step also yields important insights into DISH with respect to\nnetwork dynamics. Third, we investigate the correlation between $p_{co}$ and\nnetwork performance in terms of collision rate, packet delay, and throughput.\nThe results indicate a near-linear relationship, which may significantly\nsimplify performance analysis for cooperative networks and suggests that\n$p_{co}$ be used as an appropriate performance indicator itself. Throughout\nthis work, we utilize, as appropriate, three different DISH contexts ---\nmodel-based DISH, ideal DISH, and real DISH --- to explore $p_{co}$.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 06:58:51 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Luo", "Tie", ""], ["Motani", "Mehul", ""], ["Srinivasan", "Vikram", ""]]}, {"id": "1411.6791", "submitter": "Tie (Tony) Luo", "authors": "Tie Luo and Vikram Srinivasan and Mehul Motani", "title": "A Metric for DISH Networks: Analysis, Implications, and Applications", "comments": "Cooperative protocol, availability of cooperation, multi-channel\n  multi-hop wireless network, multi-channel MAC protocols, distributed\n  information sharing (DISH), channel bandwidth allocation", "journal-ref": "IEEE Transactions on Mobile Computing, vol. 9, no. 3, pp.\n  376--389, March 2010", "doi": "10.1109/TMC.2009.138", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless networks, node cooperation has been exploited as a data relaying\nmechanism for decades. However, the wireless channel allows for much richer\ninteraction among nodes. In particular, Distributed Information SHaring (DISH)\nrepresents a new improvement to multi-channel MAC protocol design by using a\ncooperative element at the control plane. In this approach, nodes exchange\ncontrol information to make up for other nodes' insufficient knowledge about\nthe environment, and thereby aid in their decision making. To date, what is\nlacking is a theoretical understanding of DISH. In this paper, we view\ncooperation as a network resource and evaluate the availability of cooperation,\n$p_{co}$. We first analyze $p_{co}$ in the context of a multi-channel multi-hop\nwireless network, and then perform simulations which show that the analysis\naccurately characterizes $p_{co}$ as a function of underlying network\nparameters. Next, we investigate the correlation between $p_{co}$ and network\nmetrics such as collision rate, packet delay, and throughput. We find a\nnear-linear relationship between $p_{co}$ and the metrics, which suggests that\n$p_{co}$ can be used as an appropriate performance indicator itself. Finally,\nwe apply our analysis to solving a channel bandwidth allocation problem, where\nwe derive optimal schemes and provide general guidelines on bandwidth\nallocation for DISH networks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 10:22:06 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Luo", "Tie", ""], ["Srinivasan", "Vikram", ""], ["Motani", "Mehul", ""]]}, {"id": "1411.7224", "submitter": "Emilio Leonardi", "authors": "Michele Garetto, Emilio Leonardi, Stefano Traverso", "title": "Efficient analysis of caching strategies under dynamic content\n  popularity", "comments": "to appear at Infocom 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a novel technique to analyze both isolated and\ninterconnected caches operating under different caching strategies and\nrealistic traffic conditions. The main strength of our approach is the ability\nto consider dynamic contents which are constantly added into the system\ncatalogue, and whose popularity evolves over time according to desired\nprofiles. We do so while preserving the simplicity and computational efficiency\nof models developed under stationary popularity conditions, which are needed to\nanalyze several caching strategies. Our main achievement is to show that the\nimpact of content popularity dynamics on cache performance can be effectively\ncaptured into an analytical model based on a fixed content catalogue (i.e., a\ncatalogue whose size and objects' popularity do not change over time).\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 13:42:41 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Garetto", "Michele", ""], ["Leonardi", "Emilio", ""], ["Traverso", "Stefano", ""]]}, {"id": "1411.7910", "submitter": "Diego Didona Mr", "authors": "Pierangelo Di Sanzo, Francesco Quaglia, Bruno Ciciani, Alessandro\n  Pellegrini, Diego Didona, Paolo Romano, Roberto Palmieri, Sebastiano Peluso", "title": "A Flexible Framework for Accurate Simulation of Cloud In-Memory Data\n  Stores", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-memory (transactional) data stores are recognized as a first-class data\nmanagement technology for cloud platforms, thanks to their ability to match the\nelasticity requirements imposed by the pay-as-you-go cost model. On the other\nhand, defining the well-suited amount of cache servers to be deployed, and the\ndegree of in-memory replication of slices of data, in order to optimize\nreliability/availability and performance tradeoffs, is far from being a trivial\ntask. Yet, it is an essential aspect of the provisioning process of cloud\nplatforms, given that it has an impact on how well cloud resources are actually\nexploited. To cope with the issue of determining optimized configurations of\ncloud in-memory data stores, in this article we present a flexible simulation\nframework offering skeleton simulation models that can be easily specialized in\norder to capture the dynamics of diverse data grid systems, such as those\nrelated to the specific protocol used to provide data consistency and/or\ntransactional guarantees. Besides its flexibility, another peculiar aspect of\nthe framework lies in that it integrates simulation and machine-learning\n(black-box) techniques, the latter being essentially used to capture the\ndynamics of the data-exchange layer (e.g. the message passing layer) across the\ncache servers. This is a relevant aspect when considering that the actual\ndata-transport/networking infrastructure on top of which the data grid is\ndeployed might be unknown, hence being not feasible to be modeled via white-box\n(namely purely simulative) approaches. We also provide an extended experimental\nstudy aimed at validating instances of simulation models supported by our\nframework against execution dynamics of real data grid systems deployed on top\nof either private or public cloud infrastructures.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2014 15:38:23 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Di Sanzo", "Pierangelo", ""], ["Quaglia", "Francesco", ""], ["Ciciani", "Bruno", ""], ["Pellegrini", "Alessandro", ""], ["Didona", "Diego", ""], ["Romano", "Paolo", ""], ["Palmieri", "Roberto", ""], ["Peluso", "Sebastiano", ""]]}]