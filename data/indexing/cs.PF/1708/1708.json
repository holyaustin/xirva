[{"id": "1708.00544", "submitter": "Jeremy Kepner", "authors": "Michael Jones, Jeremy Kepner, William Arcand, David Bestor, Bill\n  Bergeron, Vijay Gadepally, Michael Houle, Matthew Hubbell, Peter Michaleas,\n  Andrew Prout, Albert Reuther, Siddharth Samsi, Paul Monticiollo", "title": "Performance Measurements of Supercomputing and Cloud Storage Solutions", "comments": "5 pages, 4 figures, to appear in IEEE HPEC 2017", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091073", "report-no": null, "categories": "cs.DC astro-ph.IM cs.NI cs.OS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing amounts of data from varied sources, particularly in the fields of\nmachine learning and graph analytics, are causing storage requirements to grow\nrapidly. A variety of technologies exist for storing and sharing these data,\nranging from parallel file systems used by supercomputers to distributed block\nstorage systems found in clouds. Relatively few comparative measurements exist\nto inform decisions about which storage systems are best suited for particular\ntasks. This work provides these measurements for two of the most popular\nstorage technologies: Lustre and Amazon S3. Lustre is an open-source, high\nperformance, parallel file system used by many of the largest supercomputers in\nthe world. Amazon's Simple Storage Service, or S3, is part of the Amazon Web\nServices offering, and offers a scalable, distributed option to store and\nretrieve data from anywhere on the Internet. Parallel processing is essential\nfor achieving high performance on modern storage systems. The performance tests\nused span the gamut of parallel I/O scenarios, ranging from single-client,\nsingle-node Amazon S3 and Lustre performance to a large-scale, multi-client\ntest designed to demonstrate the capabilities of a modern storage appliance\nunder heavy load. These results show that, when parallel I/O is used correctly\n(i.e., many simultaneous read or write processes), full network bandwidth\nperformance is achievable and ranged from 10 gigabits/s over a 10 GigE S3\nconnection to 0.35 terabits/s using Lustre on a 1200 port 10 GigE switch. These\nresults demonstrate that S3 is well-suited to sharing vast quantities of data\nover the Internet, while Lustre is well-suited to processing large quantities\nof data locally.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 22:48:06 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Jones", "Michael", ""], ["Kepner", "Jeremy", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Gadepally", "Vijay", ""], ["Houle", "Michael", ""], ["Hubbell", "Matthew", ""], ["Michaleas", "Peter", ""], ["Prout", "Andrew", ""], ["Reuther", "Albert", ""], ["Samsi", "Siddharth", ""], ["Monticiollo", "Paul", ""]]}, {"id": "1708.01412", "submitter": "Zheng Li", "authors": "Zheng Li and He Zhang and Liam O'Brien and Rainbow Cai and Shayne\n  Flint", "title": "On Evaluating Commercial Cloud Services: A Systematic Review", "comments": null, "journal-ref": "Journal of Systems and Software, vol. 86, no. 9, pp. 2371-2393\n  (2013)", "doi": "10.1016/j.jss.2013.04.021", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Cloud Computing is increasingly booming in industry with many\ncompeting providers and services. Accordingly, evaluation of commercial Cloud\nservices is necessary. However, the existing evaluation studies are relatively\nchaotic. There exists tremendous confusion and gap between practices and theory\nabout Cloud services evaluation. Aim: To facilitate relieving the\naforementioned chaos, this work aims to synthesize the existing evaluation\nimplementations to outline the state-of-the-practice and also identify research\nopportunities in Cloud services evaluation. Method: Based on a conceptual\nevaluation model comprising six steps, the Systematic Literature Review (SLR)\nmethod was employed to collect relevant evidence to investigate the Cloud\nservices evaluation step by step. Results: This SLR identified 82 relevant\nevaluation studies. The overall data collected from these studies essentially\nrepresent the current practical landscape of implementing Cloud services\nevaluation, and in turn can be reused to facilitate future evaluation work.\nConclusions: Evaluation of commercial Cloud services has become a world-wide\nresearch topic. Some of the findings of this SLR identify several research gaps\nin the area of Cloud services evaluation (e.g., the Elasticity and Security\nevaluation of commercial Cloud services could be a long-term challenge), while\nsome other findings suggest the trend of applying commercial Cloud services\n(e.g., compared with PaaS, IaaS seems more suitable for customers and is\nparticularly important in industry). This SLR study itself also confirms some\nprevious experiences and reveals new Evidence-Based Software Engineering (EBSE)\nlessons.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 08:12:59 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Li", "Zheng", ""], ["Zhang", "He", ""], ["O'Brien", "Liam", ""], ["Cai", "Rainbow", ""], ["Flint", "Shayne", ""]]}, {"id": "1708.01414", "submitter": "Zheng Li", "authors": "Zheng Li and Liam O'Brien and Rainbow Cai and He Zhang", "title": "Boosting Metrics for Cloud Services Evaluation -- The Last Mile of Using\n  Benchmark Suites", "comments": "Proceedings of the 27th IEEE International Conference on Advanced\n  Information Networking and Applications (AINA 2013), pp. 381-388, Barcelona,\n  Spain, March 25-28, 2013", "journal-ref": null, "doi": "10.1109/AINA.2013.99", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmark suites are significant for evaluating various aspects of Cloud\nservices from a holistic view. However, there is still a gap between using\nbenchmark suites and achieving holistic impression of the evaluated Cloud\nservices. Most Cloud service evaluation work intended to report individual\nbenchmarking results without delivering summary measures. As a result, it could\nbe still hard for customers with such evaluation reports to understand an\nevaluated Cloud service from a global perspective. Inspired by the boosting\napproaches to machine learning, we proposed the concept Boosting Metrics to\nrepresent all the potential approaches that are able to integrate a suite of\nbenchmarking results. This paper introduces two types of preliminary boosting\nmetrics, and demonstrates how the boosting metrics can be used to supplement\nprimary measures of individual Cloud service features. In particular, boosting\nmetrics can play a summary Response role in applying experimental design to\nCloud services evaluation. Although the concept Boosting Metrics was refined\nbased on our work in the Cloud Computing domain, we believe it can be easily\nadapted to the evaluation work of other computing paradigms.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 08:25:15 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Li", "Zheng", ""], ["O'Brien", "Liam", ""], ["Cai", "Rainbow", ""], ["Zhang", "He", ""]]}, {"id": "1708.01419", "submitter": "Zheng Li", "authors": "Zheng Li and Liam O'Brien and Maria Kihl", "title": "DoKnowMe: Towards a Domain Knowledge-driven Methodology for Performance\n  Evaluation", "comments": null, "journal-ref": "ACM SIGMETRICS Performance Evaluation Review, vol. 43, no. 4, pp.\n  23-32 (2016)", "doi": "10.1145/2897356.2897360", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software engineering considers performance evaluation to be one of the key\nportions of software quality assurance. Unfortunately, there seems to be a lack\nof standard methodologies for performance evaluation even in the scope of\nexperimental computer science. Inspired by the concept of \"instantiation\" in\nobject-oriented programming, we distinguish the generic performance evaluation\nlogic from the distributed and ad-hoc relevant studies, and develop an abstract\nevaluation methodology (by analogy of \"class\") we name Domain Knowledge-driven\nMethodology (DoKnowMe). By replacing five predefined domain-specific knowledge\nartefacts, DoKnowMe could be instantiated into specific methodologies (by\nanalogy of \"object\") to guide evaluators in performance evaluation of different\nsoftware and even computing systems. We also propose a generic validation\nframework with four indicators (i.e.~usefulness, feasibility, effectiveness and\nrepeatability), and use it to validate DoKnowMe in the Cloud services\nevaluation domain. Given the positive and promising validation result, we plan\nto integrate more common evaluation strategies to improve DoKnowMe and further\nfocus on the performance evaluation of Cloud autoscaler systems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 08:33:10 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Li", "Zheng", ""], ["O'Brien", "Liam", ""], ["Kihl", "Maria", ""]]}, {"id": "1708.01673", "submitter": "Guocong Quan", "authors": "Jian Tan, Guocong Quan, Kaiyi Ji, Ness Shroff", "title": "On Resource Pooling and Separation for LRU Caching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caching systems using the Least Recently Used (LRU) principle have now become\nubiquitous. A fundamental question for these systems is whether the cache space\nshould be pooled together or divided to serve multiple flows of data item\nrequests in order to minimize the miss probabilities. In this paper, we show\nthat there is no straight yes or no answer to this question, depending on\ncomplex combinations of critical factors, including, e.g., request rates,\noverlapped data items across different request flows, data item popularities\nand their sizes. Specifically, we characterize the asymptotic miss\nprobabilities for multiple competing request flows under resource pooling and\nseparation for LRU caching when the cache size is large.\n  Analytically, we show that it is asymptotically optimal to jointly serve\nmultiple flows if their data item sizes and popularity distributions are\nsimilar and their arrival rates do not differ significantly; the\nself-organizing property of LRU caching automatically optimizes the resource\nallocation among them asymptotically. Otherwise, separating these flows could\nbe better, e.g., when data sizes vary significantly. We also quantify critical\npoints beyond which resource pooling is better than separation for each of the\nflows when the overlapped data items exceed certain levels. Technically, we\ngeneralize existing results on the asymptotic miss probability of LRU caching\nfor a broad class of heavy-tailed distributions and extend them to multiple\ncompeting flows with varying data item sizes, which also validates the Che\napproximation under certain conditions. These results provide new insights on\nimproving the performance of caching systems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 22:16:15 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Tan", "Jian", ""], ["Quan", "Guocong", ""], ["Ji", "Kaiyi", ""], ["Shroff", "Ness", ""]]}, {"id": "1708.04567", "submitter": "Zhen Xu", "authors": "Zhen Xu, Xuhao Chen, Jie Shen, Yang Zhang, Cheng Chen, and Canqun Yang", "title": "GARDENIA: A Domain-specific Benchmark Suite for Next-generation\n  Accelerators", "comments": "12 pages, 5 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Graph Analytics Repository for Designing\nNext-generation Accelerators (GARDENIA), a benchmark suite for studying\nirregular algorithms on massively parallel accelerators. Existing generic\nbenchmarks for accelerators have mainly focused on high performance computing\n(HPC) applications with limited control and data irregularity, while available\ngraph analytics benchmarks do not apply state-of-the-art algorithms and/or\noptimization techniques. GARDENIA includes emerging irregular applications in\nbig-data and machine learning domains which mimic massively multithreaded\ncommercial programs running on modern large-scale datacenters. Our\ncharacterization shows that GARDENIA exhibits irregular microarchitectural\nbehavior which is quite different from structured workloads and\nstraightforward-implemented graph benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 15:54:19 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 19:31:55 GMT"}, {"version": "v3", "created": "Tue, 9 Jan 2018 20:32:55 GMT"}, {"version": "v4", "created": "Sat, 3 Feb 2018 12:26:15 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Xu", "Zhen", ""], ["Chen", "Xuhao", ""], ["Shen", "Jie", ""], ["Zhang", "Yang", ""], ["Chen", "Cheng", ""], ["Yang", "Canqun", ""]]}, {"id": "1708.04796", "submitter": "Alexandre Da Veith", "authors": "Alexandre Da Silva Veith (1), Julio C. S. dos Anjos (2), Edison\n  Pignaton de Freitas (2), Thomas Lampoltshammer, Claudio Geyer (3) ((1)\n  AVALON, (2) URFGS, (3) PPGC)", "title": "Strategies for Big Data Analytics through Lambda Architectures in\n  Volatile Environments", "comments": null, "journal-ref": "IFAC, Nov 2016, Porto Alegre, Brazil. pp.114-119", "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectations regarding the future growth of Internet of Things (IoT)-related\ntechnologies are high. These expectations require the realization of a\nsustainable general purpose application framework that is capable to handle\nthese kinds of environments with their complexity in terms of heterogeneity and\nvolatility. The paradigm of the Lambda architecture features key\ncharacteristics (such as robustness, fault tolerance, scalability,\ngeneralization, extensibility, ad-hoc queries, minimal maintenance, and\nlow-latency reads and updates) to cope with this complexity. The paper at hand\nsuggest a basic set of strategies to handle the arising challenges regarding\nthe volatility, heterogeneity, and desired low latency execution by reducing\nthe overall system timing (scheduling, execution, monitoring, and faults\nrecovery) as well as possible faults (churn, no answers to executions). The\nproposed strategies make use of services such as migration, replication,\nMapReduce simulation, and combined processing methods (batch- and\nstreaming-based). Via these services, a distribution of tasks for the best\nbalance of computational resources is achieved, while monitoring and management\ncan be performed asynchronously in the background. %An application of batch and\nstream-based methods are proposed to reduce the latency.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 07:46:53 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Veith", "Alexandre Da Silva", ""], ["Anjos", "Julio C. S. dos", ""], ["de Freitas", "Edison Pignaton", ""], ["Lampoltshammer", "Thomas", ""], ["Geyer", "Claudio", ""]]}, {"id": "1708.05256", "submitter": "Thorsten Kurth", "authors": "Thorsten Kurth, Jian Zhang, Nadathur Satish, Ioannis Mitliagkas, Evan\n  Racah, Mostofa Ali Patwary, Tareq Malas, Narayanan Sundaram, Wahid Bhimji,\n  Mikhail Smorkalov, Jack Deslippe, Mikhail Shiryaev, Srinivas Sridharan,\n  Prabhat, Pradeep Dubey", "title": "Deep Learning at 15PF: Supervised and Semi-Supervised Classification for\n  Scientific Data", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first, 15-PetaFLOP Deep Learning system for solving\nscientific pattern classification problems on contemporary HPC architectures.\nWe develop supervised convolutional architectures for discriminating signals in\nhigh-energy physics data as well as semi-supervised architectures for\nlocalizing and classifying extreme weather in climate data. Our\nIntelcaffe-based implementation obtains $\\sim$2TFLOP/s on a single Cori\nPhase-II Xeon-Phi node. We use a hybrid strategy employing synchronous\nnode-groups, while using asynchronous communication across groups. We use this\nstrategy to scale training of a single model to $\\sim$9600 Xeon-Phi nodes;\nobtaining peak performance of 11.73-15.07 PFLOP/s and sustained performance of\n11.41-13.27 PFLOP/s. At scale, our HEP architecture produces state-of-the-art\nclassification accuracy on a dataset with 10M images, exceeding that achieved\nby selections on high-level physics-motivated features. Our semi-supervised\narchitecture successfully extracts weather patterns in a 15TB climate dataset.\nOur results demonstrate that Deep Learning can be optimized and scaled\neffectively on many-core, HPC systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 13:21:36 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Kurth", "Thorsten", ""], ["Zhang", "Jian", ""], ["Satish", "Nadathur", ""], ["Mitliagkas", "Ioannis", ""], ["Racah", "Evan", ""], ["Patwary", "Mostofa Ali", ""], ["Malas", "Tareq", ""], ["Sundaram", "Narayanan", ""], ["Bhimji", "Wahid", ""], ["Smorkalov", "Mikhail", ""], ["Deslippe", "Jack", ""], ["Shiryaev", "Mikhail", ""], ["Sridharan", "Srinivas", ""], ["Prabhat", "", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1708.05847", "submitter": "Patricia Bouyer", "authors": "Patricia Bouyer, Serge Haddad, Vincent Jug\\'e", "title": "Unbounded product-form Petri nets", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing steady-state distributions in infinite-state stochastic systems is\nin general a very dificult task. Product-form Petri nets are those Petri nets\nfor which the steady-state distribution can be described as a natural product\ncorresponding, up to a normalising constant, to an exponentiation of the\nmarkings. However, even though some classes of nets are known to have a\nproduct-form distribution, computing the normalising constant can be hard. The\nclass of (closed) {\\Pi}3-nets has been proposed in an earlier work, for which\nit is shown that one can compute the steady-state distribution efficiently.\nHowever these nets are bounded. In this paper, we generalise queuing Markovian\nnetworks and closed {\\Pi}3-nets to obtain the class of open {\\Pi}3-nets, that\ngenerate infinite-state systems. We show interesting properties of these nets:\n(1) we prove that liveness can be decided in polynomial time, and that\nreachability in live {\\Pi}3-nets can be decided in polynomial time; (2) we show\nthat we can decide ergodicity of such nets in polynomial time as well; (3) we\nprovide a pseudo-polynomial time algorithm to compute the normalising constant.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 14:06:03 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Bouyer", "Patricia", ""], ["Haddad", "Serge", ""], ["Jug\u00e9", "Vincent", ""]]}, {"id": "1708.07036", "submitter": "Paul Weng", "authors": "Paul Weng, Zeqi Qiu, John Costanzo, Xiaoqi Yin and Bruno Sinopoli", "title": "Optimal Threshold Policies for Robust Data Center Control", "comments": "Long version of paper accepted at AETA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the simultaneous rise of energy costs and demand for cloud computing,\nefficient control of data centers becomes crucial. In the data center control\nproblem, one needs to plan at every time step how many servers to switch on or\noff in order to meet stochastic job arrivals while trying to minimize\nelectricity consumption. This problem becomes particularly challenging when\nservers can be of various types and jobs from different classes can only be\nserved by certain types of server, as it is often the case in real data\ncenters. We model this problem as a robust Markov Decision Process (i.e., the\ntransition function is not assumed to be known precisely). We give sufficient\nconditions (which seem to be reasonable and satisfied in practice) guaranteeing\nthat an optimal threshold policy exists. This property can then be exploited in\nthe design of an efficient solving method, which we provide. Finally, we\npresent some experimental results demonstrating the practicability of our\napproach and compare with a previous related approach based on model predictive\ncontrol.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 15:04:57 GMT"}, {"version": "v2", "created": "Sun, 15 Oct 2017 11:54:02 GMT"}, {"version": "v3", "created": "Tue, 23 Jan 2018 13:45:49 GMT"}, {"version": "v4", "created": "Wed, 24 Jan 2018 02:00:47 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Weng", "Paul", ""], ["Qiu", "Zeqi", ""], ["Costanzo", "John", ""], ["Yin", "Xiaoqi", ""], ["Sinopoli", "Bruno", ""]]}, {"id": "1708.07786", "submitter": "Daniel Karapetyan Dr", "authors": "Daniel Karapetyan and Alexei Vernitski", "title": "Efficient Adaptive Implementation of the Serial Schedule Generation\n  Scheme using Preprocessing and Bloom Filters", "comments": "To appear in proceedings of the 11th Learning and Intelligent\n  Optimization Conference (LION)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of scheduling metaheuristics use indirect representation of\nsolutions as a way to efficiently explore the search space. Thus, a crucial\npart of such metaheuristics is a \"schedule generation scheme\" -- procedure\ntranslating the indirect solution representation into a schedule. Schedule\ngeneration scheme is used every time a new candidate solution needs to be\nevaluated. Being relatively slow, it eats up most of the running time of the\nmetaheuristic and, thus, its speed plays significant role in performance of the\nmetaheuristic. Despite its importance, little attention has been paid in the\nliterature to efficient implementation of schedule generation schemes. We give\ndetailed description of serial schedule generation scheme, including new\nimprovements, and propose a new approach for speeding it up, by using Bloom\nfilters. The results are further strengthened by automated control of\nparameters. Finally, we employ online algorithm selection to dynamically choose\nwhich of the two implementations to use. This hybrid approach significantly\noutperforms conventional implementation on a wide range of instances.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 15:46:57 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Karapetyan", "Daniel", ""], ["Vernitski", "Alexei", ""]]}, {"id": "1708.07883", "submitter": "Edward Kao", "authors": "Edward Kao, Vijay Gadepally, Michael Hurley, Michael Jones, Jeremy\n  Kepner, Sanjeev Mohindra, Paul Monticciolo, Albert Reuther, Siddharth Samsi,\n  William Song, Diane Staheli, Steven Smith", "title": "Streaming Graph Challenge: Stochastic Block Partition", "comments": "To be published in 2017 IEEE High Performance Extreme Computing\n  Conference (HPEC)", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091040", "report-no": null, "categories": "cs.DC cs.DS cs.PF cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important objective for analyzing real-world graphs is to achieve scalable\nperformance on large, streaming graphs. A challenging and relevant example is\nthe graph partition problem. As a combinatorial problem, graph partition is\nNP-hard, but existing relaxation methods provide reasonable approximate\nsolutions that can be scaled for large graphs. Competitive benchmarks and\nchallenges have proven to be an effective means to advance state-of-the-art\nperformance and foster community collaboration. This paper describes a graph\npartition challenge with a baseline partition algorithm of sub-quadratic\ncomplexity. The algorithm employs rigorous Bayesian inferential methods based\non a statistical model that captures characteristics of the real-world graphs.\nThis strong foundation enables the algorithm to address limitations of\nwell-known graph partition approaches such as modularity maximization. This\npaper describes various aspects of the challenge including: (1) the data sets\nand streaming graph generator, (2) the baseline partition algorithm with\npseudocode, (3) an argument for the correctness of parallelizing the Bayesian\ninference, (4) different parallel computation strategies such as node-based\nparallelism and matrix-based parallelism, (5) evaluation metrics for partition\ncorrectness and computational requirements, (6) preliminary timing of a\nPython-based demonstration code and the open source C++ code, and (7)\nconsiderations for partitioning the graph in streaming fashion. Data sets and\nsource code for the algorithm as well as metrics, with detailed documentation\nare available at GraphChallenge.org.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 21:10:06 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kao", "Edward", ""], ["Gadepally", "Vijay", ""], ["Hurley", "Michael", ""], ["Jones", "Michael", ""], ["Kepner", "Jeremy", ""], ["Mohindra", "Sanjeev", ""], ["Monticciolo", "Paul", ""], ["Reuther", "Albert", ""], ["Samsi", "Siddharth", ""], ["Song", "William", ""], ["Staheli", "Diane", ""], ["Smith", "Steven", ""]]}, {"id": "1708.08670", "submitter": "Yuri G. Gordienko", "authors": "Yuriy Kochura, Sergii Stirenko, Oleg Alienin, Michail Novotarskiy, and\n  Yuri Gordienko", "title": "Performance Analysis of Open Source Machine Learning Frameworks for\n  Various Parameters in Single-Threaded and Multi-Threaded Modes", "comments": "15 pages, 11 figures, 4 tables; this paper summarizes the activities\n  which were started recently and described shortly in the previous conference\n  presentations arXiv:1706.02248 and arXiv:1707.04940; it is accepted for\n  Springer book series \"Advances in Intelligent Systems and Computing\"", "journal-ref": "Advances in Intelligent Systems and Computing II. CSIT 2017.\n  Advances in Intelligent Systems and Computing, vol 689, pp 243-256. Springer,\n  Cham", "doi": "10.1007/978-3-319-70581-1_17", "report-no": null, "categories": "cs.LG cs.CV cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The basic features of some of the most versatile and popular open source\nframeworks for machine learning (TensorFlow, Deep Learning4j, and H2O) are\nconsidered and compared. Their comparative analysis was performed and\nconclusions were made as to the advantages and disadvantages of these\nplatforms. The performance tests for the de facto standard MNIST data set were\ncarried out on H2O framework for deep learning algorithms designed for CPU and\nGPU platforms for single-threaded and multithreaded modes of operation Also, we\npresent the results of testing neural networks architectures on H2O platform\nfor various activation functions, stopping metrics, and other parameters of\nmachine learning algorithm. It was demonstrated for the use case of MNIST\ndatabase of handwritten digits in single-threaded mode that blind selection of\nthese parameters can hugely increase (by 2-3 orders) the runtime without the\nsignificant increase of precision. This result can have crucial influence for\noptimization of available and new machine learning methods, especially for\nimage recognition problems.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 09:54:28 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Kochura", "Yuriy", ""], ["Stirenko", "Sergii", ""], ["Alienin", "Oleg", ""], ["Novotarskiy", "Michail", ""], ["Gordienko", "Yuri", ""]]}, {"id": "1708.09328", "submitter": "Ravi Mazumdar Dr", "authors": "Thirupathaiah Vasantam, Arpan Mukhopadhyay, and Ravi R Mazumdar", "title": "Insensitivity of the mean-field Limit of Loss Systems Under Power-of-d\n  Routing", "comments": "Submitted to Advances in Applied Probability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study large multi-server loss models under power-of-$d$\nrouting scheme when service time distributions are general with finite mean.\nPrevious works have addressed the exponential service time case when the number\nof servers goes to infinity giving rise to a mean field model. The fixed point\nof limiting mean field equations (MFE) was shown to be insensitive to the\nservice time distribution through simulation. Showing insensitivity to general\nservice time distributions has remained an open problem. Obtaining the MFE in\nthis case poses a challenge due to the resulting Markov description of the\nsystem being in positive orthant as opposed to a finite chain in the\nexponential case. In this paper, we first obtain the MFE and then show that the\nMFE has a unique fixed point that coincides with the fixed point in the\nexponential case thus establishing insensitivity. The approach is via a\nmeasure-valued Markov process representation and the martingale problem to\nestablish the mean-field limit. The techniques can be applied to other queueing\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 15:46:58 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Vasantam", "Thirupathaiah", ""], ["Mukhopadhyay", "Arpan", ""], ["Mazumdar", "Ravi R", ""]]}, {"id": "1708.09689", "submitter": "Georg Hager", "authors": "Andreas Pieper, Georg Hager, Holger Fehske", "title": "A domain-specific language and matrix-free stencil code for\n  investigating electronic properties of Dirac and topological materials", "comments": "16 pages, 2 tables, 11 figures", "journal-ref": null, "doi": "10.1177/1094342020959423", "report-no": null, "categories": "physics.comp-ph cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PVSC-DTM (Parallel Vectorized Stencil Code for Dirac and\nTopological Materials), a library and code generator based on a domain-specific\nlanguage tailored to implement the specific stencil-like algorithms that can\ndescribe Dirac and topological materials such as graphene and topological\ninsulators in a matrix-free way. The generated hybrid-parallel (MPI+OpenMP)\ncode is fully vectorized using Single Instruction Multiple Data (SIMD)\nextensions. It is significantly faster than matrix-based approaches on the node\nlevel and performs in accordance with the roofline model. We demonstrate the\nchip-level performance and distributed-memory scalability of basic building\nblocks such as sparse matrix-(multiple-) vector multiplication on modern\nmulticore CPUs. As an application example, we use the PVSC-DTM scheme to (i)\nexplore the scattering of a Dirac wave on an array of gate-defined quantum\ndots, to (ii) calculate a bunch of interior eigenvalues for strong topological\ninsulators, and to (iii) discuss the photoemission spectra of a disordered Weyl\nsemimetal.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 12:57:31 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 15:25:18 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 06:26:58 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Pieper", "Andreas", ""], ["Hager", "Georg", ""], ["Fehske", "Holger", ""]]}]