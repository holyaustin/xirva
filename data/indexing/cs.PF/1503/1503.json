[{"id": "1503.01416", "submitter": "Bulent Abali", "authors": "Bulent Abali, Richard J. Eickemeyer, Hubertus Franke, Chung-Sheng Li,\n  Marc A. Taubenblatt", "title": "Disaggregated and optically interconnected memory: when will it be cost\n  effective?", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"Disaggregated Server\" concept has been proposed for datacenters where\nthe same type server resources are aggregated in their respective pools, for\nexample a compute pool, memory pool, network pool, and a storage pool. Each\nserver is constructed dynamically by allocating the right amount of resources\nfrom these pools according to the workload's requirements. Modularity, higher\npackaging and cooling efficiencies, and higher resource utilization are among\nthe suggested benefits. With the emergence of very large datacenters, \"clouds\"\ncontaining tens of thousands of servers, datacenter efficiency has become an\nimportant topic. Few computer chip and systems vendors are working on and\nmaking frequent announcements on silicon photonics and disaggregated memory\nsystems.\n  In this paper we study the trade-off between cost and performance of building\na disaggregated memory system where DRAM modules in the datacenter are pooled,\nfor example in memory-only chassis and racks. The compute pool and the memory\npool are interconnected by an optical interconnect to overcome the distance and\nbandwidth issues of electrical fabrics. We construct a simple cost model that\nincludes the cost of latency, cost of bandwidth and the savings expected from a\ndisaggregated memory system. We then identify the level at which a\ndisaggregated memory system becomes cost competitive with a traditional direct\nattached memory system.\n  Our analysis shows that a rack-scale disaggregated memory system will have a\nnon-trivial performance penalty, and at the datacenter scale the penalty is\nimpractically high, and the optical interconnect costs are at least a factor of\n10 more expensive than where they should be when compared to the traditional\ndirect attached memory systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 18:38:33 GMT"}], "update_date": "2015-03-09", "authors_parsed": [["Abali", "Bulent", ""], ["Eickemeyer", "Richard J.", ""], ["Franke", "Hubertus", ""], ["Li", "Chung-Sheng", ""], ["Taubenblatt", "Marc A.", ""]]}, {"id": "1503.02413", "submitter": "Galia Shabtai", "authors": "Galia Shabtai, Danny Raz, and Yuval Shavitt", "title": "Stochastic Service Placement", "comments": "27 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation for cloud services is a complex task due to the diversity\nof the services and the dynamic workloads. One way to address this is by\noverprovisioning which results in high cost due to the unutilized resources. A\nmuch more economical approach, relying on the stochastic nature of the demand,\nis to allocate just the right amount of resources and use additional more\nexpensive mechanisms in case of overflow situations where demand exceeds the\ncapacity. In this paper we study this approach and show both by comprehensive\nanalysis for independent normal distributed demands and simulation on synthetic\ndata that it is significantly better than currently deployed methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 09:59:58 GMT"}], "update_date": "2015-03-10", "authors_parsed": [["Shabtai", "Galia", ""], ["Raz", "Danny", ""], ["Shavitt", "Yuval", ""]]}, {"id": "1503.02603", "submitter": "Mark Shifrin", "authors": "Mark Shifrin", "title": "An asymptotically optimal policy and state-space collapse for the\n  multi-class shared queue", "comments": "arXiv admin note: text overlap with arXiv:1412.6775", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-class G/G/1 queue with a finite shared buffer. There is\ntask admission and server scheduling control which aims to minimize the cost\nwhich consists of holding and rejection components. We construct a policy that\nis asymptotically optimal in the heavy traffic limit. The policy stems from\nsolution to Harrison-Taksar (HT) free boundary problem and is expressed by a\nsingle free boundary point. We show that the HT problem solution translated\ninto the queuelength processes follows a specific {\\it triangular} form. This\nform implies the queuelength control policy which is different from the known\n$c\\mu$ priority rule and has a novel structure.\n  We exemplify that the probabilistic methods we exploit can be successfully\napplied to solving scheduling and admission problems in cloud computing.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 18:26:55 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2015 23:44:06 GMT"}], "update_date": "2015-08-31", "authors_parsed": [["Shifrin", "Mark", ""]]}, {"id": "1503.02974", "submitter": "Matthew Wade", "authors": "Matthew J. Wade and Thomas P. Curtis and Russell J. Davenport", "title": "Modelling Computational Resources for Next Generation Sequencing\n  Bioinformatics Analysis of 16S rRNA Samples", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the rapidly evolving domain of next generation sequencing and\nbioinformatics analysis, data generation is one aspect that is increasing at a\nconcomitant rate. The burden associated with processing large amounts of\nsequencing data has emphasised the need to allocate sufficient computing\nresources to complete analyses in the shortest possible time with manageable\nand predictable costs. A novel method for predicting time to completion for a\npopular bioinformatics software (QIIME), was developed using key variables\ncharacteristic of the input data assumed to impact processing time. Multiple\nLinear Regression models were developed to determine run time for two denoising\nalgorithms and a general bioinformatics pipeline. The models were able to\naccurately predict clock time for denoising sequences from a naturally\nassembled community dataset, but not an artificial community. Speedup and\nefficiency tests for AmpliconNoise also highlighted that caution was needed\nwhen allocating resources for parallel processing of data. Accurate modelling\nof computational processing time using easily measurable predictors can assist\nNGS analysts in determining resource requirements for bioinformatics software\nand pipelines. Whilst demonstrated on a specific group of scripts, the\nmethodology can be extended to encompass other packages running on multiple\narchitectures, either in parallel or sequentially.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2015 16:18:57 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Wade", "Matthew J.", ""], ["Curtis", "Thomas P.", ""], ["Davenport", "Russell J.", ""]]}, {"id": "1503.03465", "submitter": "Daniel Lemire", "authors": "Daniel Lemire and Owen Kaser", "title": "Faster 64-bit universal hashing using carry-less multiplications", "comments": null, "journal-ref": "Journal of Cryptographic Engineering, Volume 6, Issue 3, pp\n  171-185, 2016", "doi": "10.1007/s13389-015-0110-5", "report-no": null, "categories": "cs.DS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intel and AMD support the Carry-less Multiplication (CLMUL) instruction set\nin their x64 processors. We use CLMUL to implement an almost universal 64-bit\nhash family (CLHASH). We compare this new family with what might be the fastest\nalmost universal family on x64 processors (VHASH). We find that CLHASH is at\nleast 60% faster. We also compare CLHASH with a popular hash function designed\nfor speed (Google's CityHash). We find that CLHASH is 40% faster than CityHash\non inputs larger than 64 bytes and just as fast otherwise.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2015 19:47:09 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2015 15:32:20 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2015 20:26:26 GMT"}, {"version": "v4", "created": "Mon, 23 Mar 2015 18:31:47 GMT"}, {"version": "v5", "created": "Fri, 27 Mar 2015 20:45:29 GMT"}, {"version": "v6", "created": "Fri, 26 Jun 2015 01:45:13 GMT"}, {"version": "v7", "created": "Fri, 18 Sep 2015 00:10:17 GMT"}, {"version": "v8", "created": "Wed, 4 Nov 2015 16:34:39 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Lemire", "Daniel", ""], ["Kaser", "Owen", ""]]}, {"id": "1503.04645", "submitter": "Guillaume Latu", "authors": "G. Latu, M. Haefele, J. Bigot, V. Grandgirard, T. Cartier-Michaud, F.\n  Rozar", "title": "Evaluating kernels on Xeon Phi to accelerate Gysela application", "comments": "submitted to ESAIM proceedings for CEMRACS 2014 summer school version\n  reviewed", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes the challenges presented by porting parts ofthe Gysela\ncode to the Intel Xeon Phi coprocessor, as well as techniques used for\noptimization, vectorization and tuning that can be applied to other\napplications. We evaluate the performance of somegeneric micro-benchmark on Phi\nversus Intel Sandy Bridge. Several interpolation kernels useful for the Gysela\napplication are analyzed and the performance are shown. Some memory-bound and\ncompute-bound kernels are accelerated by a factor 2 on the Phi device compared\nto Sandy architecture. Nevertheless, it is hard, if not impossible, to reach a\nlarge fraction of the peek performance on the Phi device,especially for\nreal-life applications as Gysela. A collateral benefit of this optimization and\ntuning work is that the execution time of Gysela (using 4D advections) has\ndecreased on a standard architecture such as Intel Sandy Bridge.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2015 13:43:23 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2015 16:46:01 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Latu", "G.", ""], ["Haefele", "M.", ""], ["Bigot", "J.", ""], ["Grandgirard", "V.", ""], ["Cartier-Michaud", "T.", ""], ["Rozar", "F.", ""]]}, {"id": "1503.05696", "submitter": "Ioannis Chatzigeorgiou", "authors": "Amjad Saeed Khan and Ioannis Chatzigeorgiou", "title": "Performance Analysis of Random Linear Network Coding in Two-Source\n  Single-Relay Networks", "comments": "Proc. ICC 2015, Workshop on Cooperative and Cognitive Mobile Networks\n  (CoCoNet), to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the multiple-access relay channel in a setting where two\nsource nodes transmit packets to a destination node, both directly and via a\nrelay node, over packet erasure channels. Intra-session network coding is used\nat the source nodes and inter-session network coding is employed at the relay\nnode to combine the recovered source packets of both source nodes. In this\nwork, we investigate the performance of the network-coded system in terms of\nthe probability that the destination node will successfully recover the source\npackets of the two source nodes. We build our analysis on fundamental\nprobability expressions for random matrices over finite fields and we derive\nupper bounds on the system performance for the case of systematic and\nnon-systematic network coding. Simulation results show that the upper bounds\nare very tight and accurately predict the decoding probability at the\ndestination node. Our analysis also exposes the clear benefits of systematic\nnetwork coding at the source nodes compared to non-systematic transmission.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2015 10:26:57 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Khan", "Amjad Saeed", ""], ["Chatzigeorgiou", "Ioannis", ""]]}, {"id": "1503.05872", "submitter": "Siva Theja Maguluri", "authors": "Siva Theja Maguluri and R. Srikant", "title": "Queue Length Behavior in a Switch under the MaxWeight Algorithm", "comments": "30 pages An earlier version dealing with the special case of Uniform\n  Bernoulli traffic can be found here: http://arxiv.org/abs/1503.05872", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a switch operating under the MaxWeight scheduling algorithm,\nunder any traffic pattern such that all the ports are loaded. This system is\ninteresting to study since the queue lengths exhibit a multi-dimensional\nstate-space collapse in the heavy-traffic regime. We use a Lyapunov-type drift\ntechnique to characterize the heavy-traffic behavior of the expectation of the\nsum queue lengths in steady-state, under the assumption that all ports are\nsaturated and all queues receive non-zero traffic. Under these conditions, we\nshow that the heavy-traffic scaled queue length is given by\n$\\left(1-\\frac{1}{2n}\\right)||\\sigma||^2$, where $\\sigma$ is the vector of the\nstandard deviations of arrivals to each port in the heavy-traffic limit. In the\nspecial case of uniform Bernoulli arrivals, the corresponding formula is given\nby $\\left(n-\\frac{3}{2}+\\frac{1}{2n}\\right)$. The result shows that the\nheavy-traffic scaled queue length has optimal scaling with respect to $n,$ thus\nsettling one version of an open conjecture; in fact, it is shown that the\nheavy-traffic queue length is at most within a factor of two from the optimal.\nWe then consider certain asymptotic regimes where the load of the system scales\nsimultaneously with the number of ports. We show that the MaxWeight algorithm\nhas optimal queue length scaling behavior provided that the arrival rate\napproaches capacity sufficiently fast.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2015 18:34:13 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2015 21:15:46 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2015 18:17:27 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Maguluri", "Siva Theja", ""], ["Srikant", "R.", ""]]}, {"id": "1503.06301", "submitter": "Kamalakar Karlapalem", "authors": "Yash Gupta and Kamalakar Karlapalem", "title": "Effective Handling of Urgent Jobs - Speed Up Scheduling for Computing\n  Applications", "comments": "Paper covering main contributions from MS Thesis of Yash Gupta\n  http://web2py.iiit.ac.in/research_centres/publications/view_publication/mastersthesis/247\n  - presented in ACM format", "journal-ref": null, "doi": null, "report-no": "MS Thesis Number IIIT/TH/2014/7", "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A queue is required when a service provider is not able to handle jobs\narriving over the time. In a highly flexible and dynamic environment, some jobs\nmight demand for faster execution at run-time especially when the resources are\nlimited and the jobs are competing for acquiring resources. A user might demand\nfor speed up (reduced wait time) for some of the jobs present in the queue at\nrun time. In such cases, it is required to accelerate (directly sending the job\nto the server) urgent jobs (requesting for speed up) ahead of other jobs\npresent in the queue for an earlier completion of urgent jobs. Under the\nassumption of no additional resources, such acceleration of jobs would result\nin slowing down of other jobs present in the queue. In this paper, we formulate\nthe problem of Speed Up Scheduling without acquiring any additional resources\nfor the scheduling of on-line speed up requests posed by a user at run-time and\npresent algorithms for the same. We apply the idea of Speed Up Scheduling to\ntwo different domains -Web Scheduling and CPU Scheduling. We demonstrate our\nresults with a simulation based model using trace driven workload and synthetic\ndatasets to show the usefulness of Speed Up scheduling. Speed Up provides a new\nway of addressing urgent jobs, provides a different evaluation criteria for\ncomparing scheduling algorithms and has practical applications.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2015 13:51:48 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Gupta", "Yash", ""], ["Karlapalem", "Kamalakar", ""]]}, {"id": "1503.06382", "submitter": "Vineeth Bala Sukumaran", "authors": "Vineeth Bala Sukumaran", "title": "On the tradeoff of average delay, average service cost, and average\n  utility for single server queues with monotone policies", "comments": "Ph.D. thesis, Department of Electrical Communication Engineering,\n  Indian Institute of Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we study the optimal tradeoff of average delay, average\nservice cost, and average utility for single server queueing models, with and\nwithout admission control. The continuous time and discrete time queueing\nmodels that we consider are motivated by cross-layer models for noisy\npoint-to-point links, with random packet arrivals. We study the above tradeoff\nproblem for a class of admissible policies, which are monotone and stationary\nand obtain an asymptotic characterization of the minimum average delay as a\nfunction of the average service cost and average utility constraints.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2015 04:00:45 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Sukumaran", "Vineeth Bala", ""]]}, {"id": "1503.06532", "submitter": "Kamran Karimi", "authors": "Kamran Karimi", "title": "The Feasibility of Using OpenCL Instead of OpenMP for Parallel CPU\n  Programming", "comments": "8 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenCL, along with CUDA, is one of the main tools used to program GPGPUs.\nHowever, it allows running the same code on multi-core CPUs too, making it a\nrival for the long-established OpenMP. In this paper we compare OpenCL and\nOpenMP when developing and running compute-heavy code on a CPU. Both ease of\nprogramming and performance aspects are considered. Since, unlike a GPU, no\nmemory copy operation is involved, our comparisons measure the code generation\nquality, as well as thread management efficiency of OpenCL and OpenMP. We\nevaluate the performance of these development tools under two conditions: a\nlarge number of short-running compute-heavy parallel code executions, when more\nthread management is performed, and a small number of long-running parallel\ncode executions, when less thread management is required. The results show that\nOpenCL and OpenMP each win in one of the two conditions. We argue that while\nusing OpenMP requires less setup, OpenCL can be a viable substitute for OpenMP\nfrom a performance point of view, especially when a high number of thread\ninvocations is required. We also provide a number of potential pitfalls to\nwatch for when moving from OpenMP to OpenCL.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 05:15:00 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Karimi", "Kamran", ""]]}, {"id": "1503.07241", "submitter": "Narayanan Sundaram", "authors": "Narayanan Sundaram, Nadathur Rajagopalan Satish, Md Mostofa Ali\n  Patwary, Subramanya R Dulloor, Satya Gautam Vadlamudi, Dipankar Das and\n  Pradeep Dubey", "title": "GraphMat: High performance graph analytics made productive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the growing importance of large-scale graph analytics, there is a need\nto improve the performance of graph analysis frameworks without compromising on\nproductivity. GraphMat is our solution to bridge this gap between a\nuser-friendly graph analytics framework and native, hand-optimized code.\nGraphMat functions by taking vertex programs and mapping them to high\nperformance sparse matrix operations in the backend. We get the productivity\nbenefits of a vertex programming framework without sacrificing performance.\nGraphMat is in C++, and we have been able to write a diverse set of graph\nalgorithms in this framework with the same effort compared to other vertex\nprogramming frameworks. GraphMat performs 1.2-7X faster than high performance\nframeworks such as GraphLab, CombBLAS and Galois. It achieves better multicore\nscalability (13-15X on 24 cores) than other frameworks and is 1.2X off native,\nhand-optimized code on a variety of different graph algorithms. Since GraphMat\nperformance depends mainly on a few scalable and well-understood sparse matrix\noperations, GraphMatcan naturally benefit from the trend of increasing\nparallelism on future hardware.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2015 00:10:50 GMT"}], "update_date": "2015-03-26", "authors_parsed": [["Sundaram", "Narayanan", ""], ["Satish", "Nadathur Rajagopalan", ""], ["Patwary", "Md Mostofa Ali", ""], ["Dulloor", "Subramanya R", ""], ["Vadlamudi", "Satya Gautam", ""], ["Das", "Dipankar", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1503.07693", "submitter": "Mahmoud Talebi", "authors": "Mahmoud Talebi, Jan Friso Groote, Jean-Paul Linnartz", "title": "Communication Patterns in Mean Field Models for Wireless Sensor Networks", "comments": "22 pages, in LNCS format, Submitted to QEST'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless sensor networks are usually composed of a large number of nodes, and\nwith the increasing processing power and power consumption efficiency they are\nexpected to run more complex protocols in the future. These pose problems in\nthe field of verification and performance evaluation of wireless networks. In\nthis paper, we tailor the mean-field theory as a modeling technique to analyze\ntheir behavior. We apply this method to the slotted ALOHA protocol, and\nestablish results on the long term trends of the protocol within a very large\nnetwork, specially regarding the stability of ALOHA-type protocols.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2015 11:38:29 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2015 15:12:31 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Talebi", "Mahmoud", ""], ["Groote", "Jan Friso", ""], ["Linnartz", "Jean-Paul", ""]]}, {"id": "1503.07931", "submitter": "Prasenjit Karmakar", "authors": "Prasenjit Karmakar and K. Gopinath", "title": "Are Markov Models Effective for Storage Reliability Modelling?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous Time Markov Chains (CTMC) have been used extensively to model\nreliability of storage systems. While the exponentially distributed sojourn\ntime of Markov models is widely known to be unrealistic (and it is necessary to\nconsider Weibull-type models for components such as disks), recent work has\nalso highlighted some additional infirmities with the CTMC model, such as the\nability to handle repair times. Due to the memoryless property of these models,\nany failure or repair of one component resets the \"clock\" to zero with any\npartial repair or aging in some other subsystem forgotten. It has therefore\nbeen argued that simulation is the only accurate technique available for\nmodelling the reliability of a storage system with multiple components.\n  We show how both the above problematic aspects can be handled when we\nconsider a careful set of approximations in a detailed model of the system. A\ndetailed model has many states, and the transitions between them and the\ncurrent state captures the \"memory\" of the various components. We model a\nnon-exponential distribution using a sum of exponential distributions, along\nwith the use of a CTMC solver in a probabilistic model checking tool that has\nsupport for reducing large state spaces. Furthermore, it is possible to get\nresults close to what is obtained through simulation and at much lower cost.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2015 00:08:13 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Karmakar", "Prasenjit", ""], ["Gopinath", "K.", ""]]}, {"id": "1503.08548", "submitter": "Konstantin Avrachenkov", "authors": "Konstantin Avrachenkov (NEO), Alexey Piunovskiy, Yi Zhang (imagine)", "title": "Hitting Times in Markov Chains with Restart and their Application to\n  Network Centrality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in telecommunications, computer scienceand physics,\nwe consider a discrete-time Markov process withrestart. At each step the\nprocess eitherwith a positive probability restarts from a given distribution,\norwith the complementary probability continues according to a Markovtransition\nkernel. The main contribution of the present work is thatwe obtain an explicit\nexpression for the expectation of the hittingtime (to a given target set) of\nthe process with restart.The formula is convenient when considering the problem\nof optimizationof the expected hitting time with respect to the restart\nprobability.We illustrate our results with two examplesin uncountable and\ncountable state spaces andwith an application to network centrality.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 06:21:38 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 07:36:38 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Avrachenkov", "Konstantin", "", "NEO"], ["Piunovskiy", "Alexey", "", "imagine"], ["Zhang", "Yi", "", "imagine"]]}, {"id": "1503.08809", "submitter": "James Briggs Mr", "authors": "J. P. Briggs, S. J. Pennycook, J. R. Fergusson, J. J\\\"aykk\\\"a, E. P.\n  S. Shellard", "title": "Separable projection integrals for higher-order correlators of the\n  cosmic microwave sky: Acceleration by factors exceeding 100", "comments": "Accepted by Journal of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2016.01.019", "report-no": null, "categories": "cs.DC astro-ph.CO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a case study describing efforts to optimise and modernise \"Modal\",\nthe simulation and analysis pipeline used by the Planck satellite experiment\nfor constraining general non-Gaussian models of the early universe via the\nbispectrum (or three-point correlator) of the cosmic microwave background\nradiation. We focus on one particular element of the code: the projection of\nbispectra from the end of inflation to the spherical shell at decoupling, which\ndefines the CMB we observe today. This code involves a three-dimensional inner\nproduct between two functions, one of which requires an integral, on a\nnon-rectangular domain containing a sparse grid. We show that by employing\nseparable methods this calculation can be reduced to a one-dimensional\nsummation plus two integrations, reducing the overall dimensionality from four\nto three. The introduction of separable functions also solves the issue of the\nnon-rectangular sparse grid. This separable method can become unstable in\ncertain cases and so the slower non-separable integral must be calculated\ninstead. We present a discussion of the optimisation of both approaches. We\nshow significant speed-ups of ~100x, arising from a combination of algorithmic\nimprovements and architecture-aware optimisations targeted at improving thread\nand vectorisation behaviour. The resulting MPI/OpenMP hybrid code is capable of\nexecuting on clusters containing processors and/or coprocessors, with\nstrong-scaling efficiency of 98.6% on up to 16 nodes. We find that a single\ncoprocessor outperforms two processor sockets by a factor of 1.3x and that\nrunning the same code across a combination of both microarchitectures improves\nperformance-per-node by a factor of 3.38x. By making bispectrum calculations\ncompetitive with those for the power spectrum (or two-point correlator) we are\nnow able to consider joint analysis for cosmological science exploitation of\nnew data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 19:31:24 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2015 12:31:14 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2015 15:53:07 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2016 13:20:01 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Briggs", "J. P.", ""], ["Pennycook", "S. J.", ""], ["Fergusson", "J. R.", ""], ["J\u00e4ykk\u00e4", "J.", ""], ["Shellard", "E. P. S.", ""]]}, {"id": "1503.09062", "submitter": "Emilio Coppa", "authors": "Emilio Coppa, Irene Finocchi", "title": "On data skewness, stragglers, and MapReduce progress indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of predicting the performance of MapReduce\napplications, designing accurate progress indicators that keep programmers\ninformed on the percentage of completed computation time during the execution\nof a job. Through extensive experiments, we show that state-of-the-art progress\nindicators (including the one provided by Hadoop) can be seriously harmed by\ndata skewness, load unbalancing, and straggling tasks. This is mainly due to\ntheir implicit assumption that the running time depends linearly on the input\nsize. We thus design a novel profile-guided progress indicator, called\nNearestFit, that operates without the linear hypothesis assumption and exploits\na careful combination of nearest neighbor regression and statistical curve\nfitting techniques. Our theoretical progress model requires fine-grained\nprofile data, that can be very difficult to manage in practice. To overcome\nthis issue, we resort to computing accurate approximations for some of the\nquantities used in our model through space- and time-efficient data streaming\nalgorithms. We implemented NearestFit on top of Hadoop 2.6.0. An extensive\nempirical assessment over the Amazon EC2 platform on a variety of real-world\nbenchmarks shows that NearestFit is practical w.r.t. space and time overheads\nand that its accuracy is generally very good, even in scenarios where\ncompetitors incur non-negligible errors and wide prediction fluctuations.\nOverall, NearestFit significantly improves the current state-of-art on progress\nanalysis for MapReduce.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 14:29:13 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2015 15:55:15 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Coppa", "Emilio", ""], ["Finocchi", "Irene", ""]]}]