[{"id": "1908.01924", "submitter": "Tianshu Hao", "authors": "Tianshu Hao, Yunyou Huang, Xu Wen, Wanling Gao, Fan Zhang, Chen Zheng,\n  Lei Wang, Hainan Ye, Kai Hwang, Zujie Ren, and Jianfeng Zhan", "title": "Edge AIBench: Towards Comprehensive End-to-end Edge Computing\n  Benchmarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In edge computing scenarios, the distribution of data and collaboration of\nworkloads on different layers are serious concerns for performance, privacy,\nand security issues. So for edge computing benchmarking, we must take an\nend-to-end view, considering all three layers: client-side devices, edge\ncomputing layer, and cloud servers. Unfortunately, the previous work ignores\nthis most important point. This paper presents the BenchCouncil's coordinated e\nort on edge AI benchmarks, named Edge AIBench. In total, Edge AIBench models\nfour typical application scenarios: ICU Patient Monitor, Surveillance Camera,\nSmart Home, and Autonomous Vehicle with the focus on data distribution and\nworkload collaboration on three layers. Edge AIBench is a part of the\nopen-source AIBench project, publicly available from\nhttp://www.benchcouncil.org/AIBench/index.html. We also build an edge computing\ntestbed with a federated learning framework to resolve performance, privacy,\nand security issues.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 01:34:51 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Hao", "Tianshu", ""], ["Huang", "Yunyou", ""], ["Wen", "Xu", ""], ["Gao", "Wanling", ""], ["Zhang", "Fan", ""], ["Zheng", "Chen", ""], ["Wang", "Lei", ""], ["Ye", "Hainan", ""], ["Hwang", "Kai", ""], ["Ren", "Zujie", ""], ["Zhan", "Jianfeng", ""]]}, {"id": "1908.02408", "submitter": "Sumit Mandal", "authors": "Sumit K. Mandal, Raid Ayoub, Michael Kishinevsky, Umit Y. Ogras", "title": "Analytical Performance Models for NoCs with Multiple Priority Traffic\n  Classes", "comments": "This article will appear as part of the ESWEEK-TECS special issue and\n  will be presented in the International Conference on Compilers, Architecture,\n  and Synthesis for Embedded Systems (CASES) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks-on-chip (NoCs) have become the standard for interconnect solutions\nin industrial designs ranging from client CPUs to many-core\nchip-multiprocessors. Since NoCs play a vital role in system performance and\npower consumption, pre-silicon evaluation environments include cycle-accurate\nNoC simulators. Long simulations increase the execution time of evaluation\nframeworks, which are already notoriously slow, and prohibit design-space\nexploration. Existing analytical NoC models, which assume fair arbitration,\ncannot replace these simulations since industrial NoCs typically employ\npriority schedulers and multiple priority classes. To address this limitation,\nwe propose a systematic approach to construct priority-aware analytical\nperformance models using micro-architecture specifications and input traffic.\nOur approach consists of developing two novel transformations of queuing system\nand designing an algorithm which iteratively uses these two transformations to\nestimate end-to-end latency. Our approach decomposes the given NoC into\nindividual queues with modified service time to enable accurate and scalable\nlatency computations. Specifically, we introduce novel transformations along\nwith an algorithm that iteratively applies these transformations to decompose\nthe queuing system. Experimental evaluations using real architectures and\napplications show high accuracy of 97% and up to 2.5x speedup in full-system\nsimulation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 00:26:49 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 04:38:53 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Mandal", "Sumit K.", ""], ["Ayoub", "Raid", ""], ["Kishinevsky", "Michael", ""], ["Ogras", "Umit Y.", ""]]}, {"id": "1908.02415", "submitter": "Amir Behrouzi-Far", "authors": "Amir Behrouzi-Far, Emina Soljanin", "title": "Redundancy Scheduling in Systems with Bi-Modal Job Service Time\n  Distribution", "comments": "Presented at Allerton 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Queuing systems with redundant requests have drawn great attention because of\ntheir promise to reduce the job completion time and variability. Despite a\nlarge body of work on the topic, we are still far from fully understanding the\nbenefits of redundancy in practice. We here take one step towards practical\nsystems by studying queuing systems with bi-modal job service time\ndistribution. Such distributions have been observed in practice, as can be seen\nin, e.g., Google cluster traces. We develop an analogy to a classical urns and\nballs problem, and use it to study the queuing time performance of two\nnon-adaptive classical scheduling policies: random and round-robin. We\nintroduce new performance indicators in the analogous model, and argue that\nthey are good predictors of the queuing time in non-adaptive scheduling\npolicies. We then propose a non-adaptive scheduling policy that is based on\ncombinatorial designs, and show that it has better performance indicators.\nSimulations confirm that the proposed scheduling policy, as the performance\nindicators suggest, reduces the queuing times compared to random and\nround-robin scheduling.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 01:42:14 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 19:11:51 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Behrouzi-Far", "Amir", ""], ["Soljanin", "Emina", ""]]}, {"id": "1908.02547", "submitter": "Vahid Andalib", "authors": "Vahid Andalib and Jyotirmoy Sarkar", "title": "A Repairable System Supported by Two Spare Units and Serviced by Two\n  Types of Repairers", "comments": "13 pages, 4 figures, research paper submitted to journal of\n  Reliability Engineering and System Safety", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a one-unit repairable system, supported by two identical spare units\non cold standby, and serviced by two types of repairers. The model applies, for\ninstance, to ANSI (American National Standard Institute) centrifugal pumps in a\nchemical plant. The failed unit undergoes repair either by an in-house repairer\nwithin a random or deterministic patience time, or else by a visiting expert\nrepairer. The expert repairs one or all failed units before leaving, and does\nso faster but at a higher cost rate than the regular repairer. Four models\narise depending on the number of repairs done by the expert and the nature of\nthe patience time. We compare these models based on the limiting availability\n$A_{\\infty}$, and the limiting profit per unit time $\\omega$, using semi-Markov\nprocesses, when all distributions are exponential. As anticipated, to maximize\n$A_{\\infty}$, the expert should repair all failed units. To maximize $\\omega$,\na suitably chosen deterministic patience time is better than a random patience\ntime. Furthermore, given all cost parameters, we determine the optimum number\nof repairs the expert should complete, and the optimum patience time given to\nthe regular repairer in order to maximize $\\omega$.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 19:19:42 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Andalib", "Vahid", ""], ["Sarkar", "Jyotirmoy", ""]]}, {"id": "1908.02607", "submitter": "Zihan Jiang", "authors": "Zihan Jiang, Wanling Gao, Lei Wang, Xingwang Xiong, Yuchen Zhang, Xu\n  Wen, Chunjie Luo, Hainan Ye, Yunquan Zhang, Shengzhong Feng, Kenli Li, Weijia\n  Xu, Jianfeng Zhan", "title": "HPC AI500: A Benchmark Suite for HPC AI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the trend of applying deep learning (DL) in high\nperformance scientific computing, the unique characteristics of emerging DL\nworkloads in HPC raise great challenges in designing, implementing HPC AI\nsystems. The community needs a new yard stick for evaluating the future HPC\nsystems. In this paper, we propose HPC AI500 --- a benchmark suite for\nevaluating HPC systems that running scientific DL workloads. Covering the most\nrepresentative scientific fields, each workload from HPC AI500 is based on\nreal-world scientific DL applications. Currently, we choose 14 scientific DL\nbenchmarks from perspectives of application scenarios, data sets, and software\nstack. We propose a set of metrics for comprehensively evaluating the HPC AI\nsystems, considering both accuracy, performance as well as power and cost. We\nprovide a scalable reference implementation of HPC AI500. HPC AI500 is a part\nof the open-source AIBench project, the specification and source code are\npublicly available from \\url{http://www.benchcouncil.org/AIBench/index.html}.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 10:18:08 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 03:38:49 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 09:31:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Jiang", "Zihan", ""], ["Gao", "Wanling", ""], ["Wang", "Lei", ""], ["Xiong", "Xingwang", ""], ["Zhang", "Yuchen", ""], ["Wen", "Xu", ""], ["Luo", "Chunjie", ""], ["Ye", "Hainan", ""], ["Zhang", "Yunquan", ""], ["Feng", "Shengzhong", ""], ["Li", "Kenli", ""], ["Xu", "Weijia", ""], ["Zhan", "Jianfeng", ""]]}, {"id": "1908.02640", "submitter": "Ahsan Javed Awan Dr", "authors": "Gagandeep Singh, Lorenzo Chelini, Stefano Corda, Ahsan Javed Awan,\n  Sander Stuijk, Roel Jordans, Henk Corporaal and Albert-Jan Boonstra", "title": "Near-Memory Computing: Past, Present, and Future", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional approach of moving data to the CPU for computation has\nbecome a significant performance bottleneck for emerging scale-out\ndata-intensive applications due to their limited data reuse. At the same time,\nthe advancement in 3D integration technologies has made the decade-old concept\nof coupling compute units close to the memory --- called near-memory computing\n(NMC) --- more viable. Processing right at the \"home\" of data can significantly\ndiminish the data movement problem of data-intensive applications.\n  In this paper, we survey the prior art on NMC across various dimensions\n(architecture, applications, tools, etc.) and identify the key challenges and\nopen issues with future research directions. We also provide a glimpse of our\napproach to near-memory computing that includes i) NMC specific\nmicroarchitecture independent application characterization ii) a compiler\nframework to offload the NMC kernels on our target NMC platform and iii) an\nanalytical model to evaluate the potential of NMC.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 14:00:08 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Singh", "Gagandeep", ""], ["Chelini", "Lorenzo", ""], ["Corda", "Stefano", ""], ["Awan", "Ahsan Javed", ""], ["Stuijk", "Sander", ""], ["Jordans", "Roel", ""], ["Corporaal", "Henk", ""], ["Boonstra", "Albert-Jan", ""]]}, {"id": "1908.02702", "submitter": "Andreas Herten", "authors": "Andreas Herten, Thorsten Hater, Wouter Klijn, Dirk Pleiter", "title": "Performance Comparison for Neuroscience Application Benchmarks", "comments": "Presented at ISC19 Conference Workshop IWOPH (International Workshop\n  on OpenPOWER for HPC)", "journal-ref": null, "doi": "10.1007/978-3-030-34356-9_31", "report-no": null, "categories": "cs.PF q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers within the Human Brain Project and related projects have in the\nlast couple of years expanded their needs for high-performance computing\ninfrastructures. The needs arise from a diverse set of science challenges that\nrange from large-scale simulations of brain models to processing of\nextreme-scale experimental data sets. The ICEI project, which is in the process\nof creating a distributed infrastructure optimised for brain research, started\nto build-up a set of benchmarks that reflect the diversity of applications in\nthis field. In this paper we analyse the performance of some selected\nbenchmarks on an IBM POWER8 and Intel Skylake based systems with and without\nGPUs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 16:19:15 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Herten", "Andreas", ""], ["Hater", "Thorsten", ""], ["Klijn", "Wouter", ""], ["Pleiter", "Dirk", ""]]}, {"id": "1908.03583", "submitter": "Joseph Izraelevitz", "authors": "Jian Yang, Juno Kim, Morteza Hoseinzadeh, Joseph Izraelevitz, Steven\n  Swanson", "title": "An Empirical Guide to the Behavior and Use of Scalable Persistent Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  After nearly a decade of anticipation, scalable nonvolatile memory DIMMs are\nfinally commercially available with the release of Intel's 3D XPoint DIMM. This\nnew nonvolatile DIMM supports byte-granularity accesses with access times on\nthe order of DRAM, while also providing data storage that survives power\noutages. Researchers have not idly waited for real nonvolatile DIMMs (NVDIMMs)\nto arrive. Over the past decade, they have written a slew of papers proposing\nnew programming models, file systems, libraries, and applications built to\nexploit the performance and flexibility that NVDIMMs promised to deliver. Those\npapers drew conclusions and made design decisions without detailed knowledge of\nhow real NVDIMMs would behave or how industry would integrate them into\ncomputer architectures. Now that 3D XPoint NVDIMMs are actually here, we can\nprovide detailed performance numbers, concrete guidance for programmers on\nthese systems, reevaluate prior art for performance, and reoptimize persistent\nmemory software for the real 3D XPoint DIMM. In this paper, we explore the\nperformance properties and characteristics of Intel's new 3D XPoint DIMM at the\nmicro and macro level. First, we investigate the basic characteristics of the\ndevice, taking special note of the particular ways in which its performance is\npeculiar relative to traditional DRAM or other past methods used to emulate\nNVM. From these observations, we recommend a set of best practices to maximize\nthe performance of the device. With our improved understanding, we then explore\nthe performance of prior art in application-level software for persistent\nmemory, taking note of where their performance was influenced by our\nguidelines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 18:01:32 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Yang", "Jian", ""], ["Kim", "Juno", ""], ["Hoseinzadeh", "Morteza", ""], ["Izraelevitz", "Joseph", ""], ["Swanson", "Steven", ""]]}, {"id": "1908.03653", "submitter": "Hermes Senger", "authors": "Hermes Senger, Jaime F. de Souza, Edson S. Gomi, Fabio Luporini,\n  Gerard J. Gorman", "title": "Performance of Devito on HPC-Optimised ARM Processors", "comments": "2 pages, one figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the performance of Devito, a domain specific language (DSL) for\nfinite differences on Arm ThunderX2 processors. Experiments with two common\nseismic computational kernels demonstrate that Arm processors can deliver\ncompetitive performance compared to other Intel Xeon processors.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 23:06:31 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 12:05:35 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Senger", "Hermes", ""], ["de Souza", "Jaime F.", ""], ["Gomi", "Edson S.", ""], ["Luporini", "Fabio", ""], ["Gorman", "Gerard J.", ""]]}, {"id": "1908.04236", "submitter": "Suryanarayana Murthy Durbhakula", "authors": "Murthy Durbhakula", "title": "MLP Aware Scheduling Techniques in Multithreaded Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Major chip manufacturers have all introduced Multithreaded processors. These\nprocessors are used for running a variety of workloads. Efficient resource\nutilization is an important design aspect in such processors. Particularly, it\nis important to take advantage of available memory-level parallelism(MLP). In\nthis paper I propose a MLP aware operating system (OS) scheduling algorithm for\nMultithreaded Multi-core processors. By observing the MLP available in each\nthread and by balancing it with available MLP resources in the system the OS\nwill come up with a new schedule of threads for the next quantum that could\npotentially improve overall performance. We do a qualitative comparison of our\nsolution with other hardware and software techniques. This work can be extended\nby doing a quantitative evaluation and by further refining the scheduling\noptimization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 16:45:41 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Durbhakula", "Murthy", ""]]}, {"id": "1908.04491", "submitter": "Hamidreza Moradi", "authors": "Hamidreza Moradi, Wei Wang, Amanda Fernandez and Dakai Zhu", "title": "uPredict: A User-Level Profiler-Based Predictive Framework for Single VM\n  Applications in Multi-Tenant Clouds", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing studies on performance prediction for virtual machines (VMs) in\nmulti-tenant clouds are at system level and generally require access to\nperformance counters in Hypervisors. In this work, we propose uPredict, a\nuser-level profiler-based performance predictive framework for single-VM\napplications in multi-tenant clouds. Here, three micro-benchmarks are specially\ndevised to assess the contention of CPUs, memory and disks in a VM,\nrespectively. Based on measured performance of an application and\nmicro-benchmarks, the application and VM-specific predictive models can be\nderived by exploiting various regression and neural network based techniques.\nThese models can then be used to predict the application's performance using\nthe in-situ profiled resource contention with the micro-benchmarks. We\nevaluated uPredict extensively with representative benchmarks from PARSEC, NAS\nParallel Benchmarks and CloudSuite, on both a private cloud and two public\nclouds. The results show that the average prediction errors are between 9.8% to\n17% for various predictive models on the private cloud with high resource\ncontention, while the errors are within 4% on public clouds. A smart\nload-balancing scheme powered by uPredict is presented and can effectively\nreduce the execution and turnaround times of the considered application by 19%\nand 10%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 05:00:31 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Moradi", "Hamidreza", ""], ["Wang", "Wei", ""], ["Fernandez", "Amanda", ""], ["Zhu", "Dakai", ""]]}, {"id": "1908.04546", "submitter": "Bruce Collie", "authors": "Bruce Collie, Philip Ginsbach, Michael F.P. O'Boyle", "title": "Type-Directed Program Synthesis and Constraint Generation for Library\n  Portability", "comments": "Accepted to PACT 2019", "journal-ref": null, "doi": "10.1109/PACT.2019.00013", "report-no": null, "categories": "cs.PL cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast numerical libraries have been a cornerstone of scientific computing for\ndecades, but this comes at a price. Programs may be tied to vendor specific\nsoftware ecosystems resulting in polluted, non-portable code. As we enter an\nera of heterogeneous computing, there is an explosion in the number of\naccelerator libraries required to harness specialized hardware. We need a\nsystem that allows developers to exploit ever-changing accelerator libraries,\nwithout over-specializing their code.\n  As we cannot know the behavior of future libraries ahead of time, this paper\ndevelops a scheme that assists developers in matching their code to new\nlibraries, without requiring the source code for these libraries.\n  Furthermore, it can recover equivalent code from programs that use existing\nlibraries and automatically port them to new interfaces. It first uses program\nsynthesis to determine the meaning of a library, then maps the synthesized\ndescription into generalized constraints which are used to search the program\nfor replacement opportunities to present to the developer.\n  We applied this approach to existing large applications from the scientific\ncomputing and deep learning domains. Using our approach, we show speedups\nranging from 1.1$\\times$ to over 10$\\times$ on end to end performance when\nusing accelerator libraries.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 08:58:44 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 15:32:33 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 17:06:48 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Collie", "Bruce", ""], ["Ginsbach", "Philip", ""], ["O'Boyle", "Michael F. P.", ""]]}, {"id": "1908.04574", "submitter": "Erik Sy", "authors": "Erik Sy", "title": "Enhanced Performance and Privacy via Resolver-Less DNS", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain name resolution into IP addresses can significantly delay\nconnection establishments on the web. Moreover, the common use of recursive DNS\nresolvers presents a privacy risk as they can closely monitor the user's\nbrowsing activities. In this paper, we present a novel HTTP response header\nallowing web server to provide their clients with relevant DNS records. Our\nresults indicate, that this resolver-less DNS mechanism allows user agents to\nsave the DNS lookup time for subsequent connection establishments. We find,\nthat this proposal saves at least 80ms per DNS lookup for the one percent of\nusers having the longest round-trip times towards their recursive resolver.\nFurthermore, our proposal decreases the number of DNS lookups and thus improves\nthe privacy posture of the user towards the used recursive resolver. Comparing\nthe security guarantees of the traditional DNS to our proposal, we find that\nresolver-less DNS achieves at least the same security properties. In detail, it\neven improves the user's resilience against censorship through tampered DNS\nresolvers.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 11:00:09 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Sy", "Erik", ""]]}, {"id": "1908.04705", "submitter": "Yu Emma Wang", "authors": "Yu Emma Wang, Carole-Jean Wu, Xiaodong Wang, Kim Hazelwood, David\n  Brooks", "title": "Exploiting Parallelism Opportunities with Deep Learning Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  State-of-the-art machine learning frameworks support a wide variety of design\nfeatures to enable a flexible machine learning programming interface and to\nease the programmability burden on machine learning developers. Identifying and\nusing a performance-optimal setting in feature-rich frameworks, however,\ninvolves a non-trivial amount of performance profiling efforts and often relies\non domain-specific knowledge. This paper takes a deep dive into analyzing the\nperformance impact of key design features in a machine learning framework and\nquantifies the role of parallelism. The observations and insights distill into\na simple set of guidelines that one can use to achieve much higher training and\ninference speedup. Across a diverse set of real-world deep learning models, the\nevaluation results show that the proposed performance tuning guidelines\noutperform the Intel and TensorFlow recommended settings by 1.29x and 1.34x,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:41:14 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 23:37:48 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Wang", "Yu Emma", ""], ["Wu", "Carole-Jean", ""], ["Wang", "Xiaodong", ""], ["Hazelwood", "Kim", ""], ["Brooks", "David", ""]]}, {"id": "1908.04718", "submitter": "Utku Sirin", "authors": "Utku Sirin, Anastasia Ailamaki", "title": "Micro-architectural Analysis of OLAP: Limitations and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding micro-architectural behavior is profound in efficiently using\nhardware resources. Recent work has shown that, despite being aggressively\noptimized for modern hardware, in-memory online transaction processing (OLTP)\nsystems severely underutilize their core micro-architecture resources [25].\nOnline analytical processing (OLAP) workloads, on the other hand, exhibit a\ncompletely different computing pattern. OLAP workloads are read-only,\nbandwidth-intensive and include various data access patterns including both\nsequential and random data accesses. In addition, with the rise of\ncolumn-stores, they run on high performance engines that are tightly optimized\nfor the efficient use of modern hardware. Hence, the micro-architectural\nbehavior of modern OLAP systems remains unclear.\n  This work presents the micro-architectural analysis of a breadth of OLAP\nsystems. We examine CPU cycles and memory bandwidth utilization. The results\nshow that, unlike the traditional, commercial OLTP systems, traditional,\ncommercial OLAP systems do not suffer from instruction cache misses.\nNevertheless, they suffer from their large instruction footprint resulting in\nslow response times. High performance OLAP engines execute tight instruction\nstreams; however, they spend 25 to 82% of the CPU cycles on stalls regardless\nof the workload being sequential- or random-access-heavy. In addition, high\nperformance OLAP engines underutilize the multi-core CPU or memory bandwidth\nresources due to their disproportional compute and memory demands. Hence,\nanalytical processing engines should carefully assign their compute and memory\nresources for efficient multi-core micro-architectural utilization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:18:00 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Sirin", "Utku", ""], ["Ailamaki", "Anastasia", ""]]}, {"id": "1908.05125", "submitter": "Anton Pyrkin", "authors": "Romeo Ortega, Stanislav Aranovskiy, Anton A. Pyrkin, Alessandro\n  Astolfi, Alexey A. Bobtsov", "title": "New Results on Parameter Estimation via Dynamic Regressor Extension and\n  Mixing: Continuous and Discrete-time Cases", "comments": "8 pages, 7 figures, under review in IEEE TAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some new results on the dynamic regressor extension and mixing\nparameter estimators for linear regression models recently proposed in the\nliterature. This technique has proven instrumental in the solution of several\nopen problems in system identification and adaptive control. The new results\ninclude: (i) a unified treatment of the continuous and the discrete-time cases;\n(ii) the proposal of two new extended regressor matrices, one which guarantees\na quantifiable transient performance improvement, and the other exponential\nconvergence under conditions that are strictly weaker than regressor\npersistence of excitation; and (iii) an alternative estimator ensuring\nparameter estimation in finite-time that retains its alertness to track\ntime-varying parameters. Simulations that illustrate our results are also\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 13:45:46 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Ortega", "Romeo", ""], ["Aranovskiy", "Stanislav", ""], ["Pyrkin", "Anton A.", ""], ["Astolfi", "Alessandro", ""], ["Bobtsov", "Alexey A.", ""]]}, {"id": "1908.06519", "submitter": "Sahand Salamat", "authors": "Sahand Salamat, Behnam Khaleghi, Mohsen Imani, Tajana Rosing", "title": "Workload-Aware Opportunistic Energy Efficiency in Multi-FPGA Platforms", "comments": "The paper will be published in ICCAD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuous growth of big data applications with high computational and\nscalability demands has resulted in increasing popularity of cloud computing.\nOptimizing the performance and power consumption of cloud resources is\ntherefore crucial to relieve the costs of data centers. In recent years,\nmulti-FPGA platforms have gained traction in data centers as low-cost yet\nhigh-performance solutions particularly as acceleration engines, thanks to the\nhigh degree of parallelism they provide. Nonetheless, the size of data centers\nworkloads varies during service time, leading to significant underutilization\nof computing resources while consuming a large amount of power, which turns out\nas a key factor of data center inefficiency, regardless of the underlying\nhardware structure. In this paper, we propose an efficient framework to\nthrottle the power consumption of multi-FPGA platforms by dynamically scaling\nthe voltage and hereby frequency during runtime according to prediction of, and\nadjustment to the workload level, while maintaining the desired Quality of\nService (QoS). This is in contrast to, and more efficient than, conventional\napproaches that merely scale (i.e., power-gate) the computing nodes or\nfrequency. The proposed framework carefully exploits a pre-characterized\nlibrary of delay-voltage, and power-voltage information of FPGA resources,\nwhich we show is indispensable to obtain the efficient operating point due to\nthe different sensitivity of resources w.r.t. voltage scaling, particularly\nconsidering multiple power rails residing in these devices. Our evaluations by\nimplementing state-of-the-art deep neural network accelerators revealed that,\nproviding an average power reduction of 4.0X, the proposed framework surpasses\nthe previous works by 33.6% (up to 83%).\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 21:44:37 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 00:00:22 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Salamat", "Sahand", ""], ["Khaleghi", "Behnam", ""], ["Imani", "Mohsen", ""], ["Rosing", "Tajana", ""]]}, {"id": "1908.06869", "submitter": "Cheng Li", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wei Wei, Lingjie Xu, Wen-mei Hwu", "title": "XSP: Across-Stack Profiling and Analysis of Machine Learning Models on\n  GPUs", "comments": null, "journal-ref": null, "doi": "10.1109/IPDPS47924.2020.00042", "report-no": null, "categories": "cs.LG cs.AR cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a rapid proliferation of machine learning/deep learning (ML)\nmodels and wide adoption of them in many application domains. This has made\nprofiling and characterization of ML model performance an increasingly pressing\ntask for both hardware designers and system providers, as they would like to\noffer the best possible system to serve ML models with the target latency,\nthroughput, cost, and energy requirements while maximizing resource\nutilization. Such an endeavor is challenging as the characteristics of an ML\nmodel depend on the interplay between the model, framework, system libraries,\nand the hardware (or the HW/SW stack). Existing profiling tools are disjoint,\nhowever, and only focus on profiling within a particular level of the stack,\nwhich limits the thoroughness and usefulness of the profiling results.\n  This paper proposes XSP - an across-stack profiling design that gives a\nholistic and hierarchical view of ML model execution. XSP leverages distributed\ntracing to aggregate and correlates profile data from different sources. XSP\nintroduces a leveled and iterative measurement approach that accurately\ncaptures the latencies at all levels of the HW/SW stack in spite of the\nprofiling overhead. We couple the profiling design with an automated analysis\npipeline to systematically analyze 65 state-of-the-art ML models. We\ndemonstrate that XSP provides insights which would be difficult to discern\notherwise.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:05:29 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:42:42 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 01:31:35 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Wei", "Wei", ""], ["Xu", "Lingjie", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1908.06900", "submitter": "Mehrdad Saadatmand", "authors": "Mahshid Helali Moghadam, Mehrdad Saadatmand, Markus Borg, Markus\n  Bohlin, Bj\\\"orn Lisper", "title": "An Autonomous Performance Testing Framework using Self-Adaptive Fuzzy\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test automation brings the potential to reduce costs and human effort, but\nseveral aspects of software testing remain challenging to automate. One such\nexample is automated performance testing to find performance breaking points.\nCurrent approaches to tackle automated generation of performance test cases\nmainly involve using source code or system model analysis or use-case based\ntechniques. However, source code and system models might not always be\navailable at testing time. On the other hand, if the optimal performance\ntesting policy for the intended objective in a testing process instead could be\nlearned by the testing system, then test automation without advanced\nperformance models could be possible. Furthermore, the learned policy could\nlater be reused for similar software systems under test, thus leading to higher\ntest efficiency. We propose SaFReL, a self-adaptive fuzzy reinforcement\nlearning-based performance testing framework. SaFReL learns the optimal policy\nto generate performance test cases through an initial learning phase, then\nreuses it during a transfer learning phase, while keeping the learning running\nand updating the policy in the long term. Through multiple experiments on a\nsimulated environment, we demonstrate that our approach generates the target\nperformance test cases for different programs more efficiently than a typical\ntesting process, and performs adaptively without access to source code and\nperformance models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:00:35 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 22:29:44 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Moghadam", "Mahshid Helali", ""], ["Saadatmand", "Mehrdad", ""], ["Borg", "Markus", ""], ["Bohlin", "Markus", ""], ["Lisper", "Bj\u00f6rn", ""]]}, {"id": "1908.08123", "submitter": "James F. Brady", "authors": "James F Brady", "title": "Computing System Congestion Management Using Exponential Smoothing\n  Forecasting", "comments": "7 figures, 20 pages including computer program listing v2 - clarified\n  some notation v3 - added C program GitHub location V4 - minor wording cleanup", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An overloaded computer must finish what it starts and not start what will\nfail or hang. A congestion management algorithm the author developed, and\nSiemens Corporation patented for telecom products, effectively manages traffic\noverload with its unique formulation of Exponential Smoothing forecasting.\nSiemens filed for exclusive rights to this technique in 2003 and obtained US\npatent US7301903B2 in 2007 with this author, an employee at the time of the\nfiling, the sole inventor. A computer program, written in C language, which\nexercises the methodology is listed at the end of this document and available\non GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 21:35:03 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 22:08:07 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 21:39:55 GMT"}, {"version": "v4", "created": "Mon, 23 Mar 2020 20:39:38 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Brady", "James F", ""]]}, {"id": "1908.08332", "submitter": "Luis Cruz", "authors": "Luis Cruz, Rui Abreu, John Grundy, Li Li, Xin Xia", "title": "Do Energy-oriented Changes Hinder Maintainability?", "comments": "International Conference on Software Maintenance and Evolution -\n  ICSME 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy efficiency is a crucial quality requirement for mobile applications.\nHowever, improving energy efficiency is far from trivial as developers lack the\nknowledge and tools to aid in this activity. In this paper we study the impact\nof changes to improve energy efficiency on the maintainability of Android\napplications. Using a dataset containing 539 energy efficiency-oriented\ncommits, we measure maintainability -- as computed by the Software Improvement\nGroup's web-based source code analysis service Better Code Hub (BCH) -- before\nand after energy efficiency-related code changes. Results show that in general\nimproving energy efficiency comes with a significant decrease in\nmaintainability. This is particularly evident in code changes to accommodate\nthe Power Save Mode and Wakelock Addition energy patterns. In addition, we\nperform manual analysis to assess how real examples of energy-oriented changes\naffect maintainability. Our results help mobile app developers to 1) avoid\ncommon maintainability issues when improving the energy efficiency of their\napps; and 2) adopt development processes to build maintainable and\nenergy-efficient code. We also support researchers by identifying challenges in\nmobile app development that still need to be addressed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:21:08 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Cruz", "Luis", ""], ["Abreu", "Rui", ""], ["Grundy", "John", ""], ["Li", "Li", ""], ["Xia", "Xin", ""]]}, {"id": "1908.08998", "submitter": "Wanling Gao", "authors": "Wanling Gao, Fei Tang, Lei Wang, Jianfeng Zhan, Chunxin Lan, Chunjie\n  Luo, Yunyou Huang, Chen Zheng, Jiahui Dai, Zheng Cao, Daoyi Zheng, Haoning\n  Tang, Kunlin Zhan, Biao Wang, Defei Kong, Tong Wu, Minghe Yu, Chongkang Tan,\n  Huan Li, Xinhui Tian, Yatao Li, Junchao Shao, Zhenyu Wang, Xiaoyu Wang, and\n  Hainan Ye", "title": "AIBench: An Industry Standard Internet Service AI Benchmark Suite", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's Internet Services are undergoing fundamental changes and shifting to\nan intelligent computing era where AI is widely employed to augment services.\nIn this context, many innovative AI algorithms, systems, and architectures are\nproposed, and thus the importance of benchmarking and evaluating them rises.\nHowever, modern Internet services adopt a microservice-based architecture and\nconsist of various modules. The diversity of these modules and complexity of\nexecution paths, the massive scale and complex hierarchy of datacenter\ninfrastructure, the confidential issues of data sets and workloads pose great\nchallenges to benchmarking. In this paper, we present the first\nindustry-standard Internet service AI benchmark suite---AIBench with seventeen\nindustry partners, including several top Internet service providers. AIBench\nprovides a highly extensible, configurable, and flexible benchmark framework\nthat contains loosely coupled modules. We identify sixteen prominent AI problem\ndomains like learning to rank, each of which forms an AI component benchmark,\nfrom three most important Internet service domains: search engine, social\nnetwork, and e-commerce, which is by far the most comprehensive AI benchmarking\neffort. On the basis of the AIBench framework, abstracting the real-world data\nsets and workloads from one of the top e-commerce providers, we design and\nimplement the first end-to-end Internet service AI benchmark, which contains\nthe primary modules in the critical paths of an industry scale application and\nis scalable to deploy on different cluster scales. The specifications, source\ncode, and performance numbers are publicly available from the benchmark council\nweb site http://www.benchcouncil.org/AIBench/index.html.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 10:15:39 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 14:39:47 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Gao", "Wanling", ""], ["Tang", "Fei", ""], ["Wang", "Lei", ""], ["Zhan", "Jianfeng", ""], ["Lan", "Chunxin", ""], ["Luo", "Chunjie", ""], ["Huang", "Yunyou", ""], ["Zheng", "Chen", ""], ["Dai", "Jiahui", ""], ["Cao", "Zheng", ""], ["Zheng", "Daoyi", ""], ["Tang", "Haoning", ""], ["Zhan", "Kunlin", ""], ["Wang", "Biao", ""], ["Kong", "Defei", ""], ["Wu", "Tong", ""], ["Yu", "Minghe", ""], ["Tan", "Chongkang", ""], ["Li", "Huan", ""], ["Tian", "Xinhui", ""], ["Li", "Yatao", ""], ["Shao", "Junchao", ""], ["Wang", "Zhenyu", ""], ["Wang", "Xiaoyu", ""], ["Ye", "Hainan", ""]]}, {"id": "1908.09070", "submitter": "Max Noormohammadpour", "authors": "Max Noormohammadpour, Ajitesh Srivastava, Cauligi S. Raghavendra", "title": "Optimizing Inter-Datacenter Tail Flow Completion Times using Best\n  Worst-case Routing", "comments": "Accepted for publication in the 2019 57th Annual Allerton Conference\n  on Communication, Control, and Computing (Allerton)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow routing over inter-datacenter networks is a well-known problem where the\nnetwork assigns a path to a newly arriving flow potentially according to the\nnetwork conditions and the properties of the new flow. An essential system-wide\nperformance metric for a routing algorithm is the flow completion times, which\naffect the performance of applications running across multiple datacenters.\nCurrent static and dynamic routing approaches do not take advantage of flow\nsize information in routing, which is practical in a controlled environment\nsuch as inter-datacenter networks that are managed by the datacenter operators.\nIn this paper, we discuss Best Worst-case Routing (BWR), which aims at\noptimizing the tail completion times of long-running flows over\ninter-datacenter networks with non-uniform link capacities. Since finding the\npath with the best worst-case completion time for a new flow is NP-Hard, we\ninvestigate two heuristics, BWRH and BWRHF, which use two different upper\nbounds on the worst-case completion times for routing. We evaluate BWRH and\nBWRHF against several real WAN topologies and multiple traffic patterns.\nAlthough BWRH better models the BWR problem, BWRH and BWRHF show negligible\ndifference across various system-wide performance metrics, while BWRHF being\nsignificantly faster. Furthermore, we show that compared to other popular\nrouting heuristics, BWRHF can reduce the mean and tail flow completion times by\nover $1.5\\times$ and $2\\times$, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 02:04:37 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Noormohammadpour", "Max", ""], ["Srivastava", "Ajitesh", ""], ["Raghavendra", "Cauligi S.", ""]]}, {"id": "1908.09606", "submitter": "Grzegorz Kwasniewski", "authors": "Grzegorz Kwasniewski (1), Marko Kabi\\'c (2,3), Maciej Besta (1), Joost\n  VandeVondele (2,3), Raffaele Solc\\`a (2,3), Torsten Hoefler (1) ((1)\n  Department of Computer Science, ETH Zurich, (2) ETH Zurich, (3) Swiss\n  National Supercomputing Centre (CSCS))", "title": "Red-blue pebbling revisited: near optimal parallel matrix-matrix\n  multiplication", "comments": "18 pages, 29 figures, short version submitted to the SC'19 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose COSMA: a parallel matrix-matrix multiplication algorithm that is\nnear communication-optimal for all combinations of matrix dimensions, processor\ncounts, and memory sizes. The key idea behind COSMA is to derive an optimal (up\nto a factor of 0.03\\% for 10MB of fast memory) sequential schedule and then\nparallelize it, preserving I/O optimality. To achieve this, we use the red-blue\npebble game to precisely model MMM dependencies and derive a constructive and\ntight sequential and parallel I/O lower bound proofs. Compared to 2D or 3D\nalgorithms, which fix processor decomposition upfront and then map it to the\nmatrix dimensions, it reduces communication volume by up to $\\sqrt{3}$ times.\nCOSMA outperforms the established ScaLAPACK, CARMA, and CTF algorithms in all\nscenarios up to 12.8x (2.2x on average), achieving up to 88\\% of Piz Daint's\npeak performance. Our work does not require any hand tuning and is maintained\nas an open source implementation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 11:40:17 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 00:24:39 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 15:36:04 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Kwasniewski", "Grzegorz", ""], ["Kabi\u0107", "Marko", ""], ["Besta", "Maciej", ""], ["VandeVondele", "Joost", ""], ["Solc\u00e0", "Raffaele", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1908.10926", "submitter": "V\\'it \\v{S}efl", "authors": "V\\'it \\v{S}efl", "title": "Performance Analysis of Zippers", "comments": "Part of DECLARE 19 proceedings, 15 pages, 9 listings, 6 figures,\n  source files available at https://github.com/vituscze/performance-zippers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A zipper is a powerful technique of representing a purely functional data\nstructure in a way that allows fast access to a specific element. It is often\nused in cases where the imperative data structures would use a mutable pointer.\nHowever, the efficiency of zippers as a replacement for mutable pointers is not\nsufficiently explored. We attempt to address this issue by comparing the\nperformance of zippers and mutable pointers in two common scenarios and three\ndifferent languages: C++, C#, and Haskell.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 19:48:10 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["\u0160efl", "V\u00edt", ""]]}, {"id": "1908.11338", "submitter": "Siddharth Samsi", "authors": "Tao B. Schardl and Siddharth Samsi", "title": "TapirXLA: Embedding Fork-Join Parallelism into the XLA Compiler in\n  TensorFlow Using Tapir", "comments": "IEEE HPEC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces TapirXLA, a replacement for TensorFlow's XLA compiler\nthat embeds recursive fork-join parallelism into XLA's low-level representation\nof code. Machine-learning applications rely on efficient parallel processing to\nachieve performance, and they employ a variety of technologies to improve\nperformance, including compiler technology. But compilers in machine-learning\nframeworks lack a deep understanding of parallelism, causing them to lose\nperformance by missing optimizations on parallel computation. This work studies\nhow Tapir, a compiler intermediate representation (IR) that embeds parallelism\ninto a mainstream compiler IR, can be incorporated into a compiler for machine\nlearning to remedy this problem. TapirXLA modifies the XLA compiler in\nTensorFlow to employ the Tapir/LLVM compiler to optimize low-level parallel\ncomputation. TapirXLA encodes the parallelism within high-level TensorFlow\noperations using Tapir's representation of fork-join parallelism. TapirXLA also\nexposes to the compiler implementations of linear-algebra library routines\nwhose parallel operations are encoded using Tapir's representation. We compared\nthe performance of TensorFlow using TapirXLA against TensorFlow using an\nunmodified XLA compiler. On four neural-network benchmarks, TapirXLA speeds up\nthe parallel running time of the network by a geometric-mean multiplicative\nfactor of 30% to 100%, across four CPU architectures.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:42:52 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Schardl", "Tao B.", ""], ["Samsi", "Siddharth", ""]]}, {"id": "1908.11348", "submitter": "Albert Reuther PhD", "authors": "Albert Reuther, Peter Michaleas, Michael Jones, Vijay Gadepally,\n  Siddharth Samsi and Jeremy Kepner", "title": "Survey and Benchmarking of Machine Learning Accelerators", "comments": "9 pages, 3 figures, IEEE-HPEC conference, Waltham, MA, September\n  24-26, 2019", "journal-ref": null, "doi": "10.1109/HPEC.2019.8916327", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in multicore processors and accelerators have opened the flood gates\nto greater exploration and application of machine learning techniques to a\nvariety of applications. These advances, along with breakdowns of several\ntrends including Moore's Law, have prompted an explosion of processors and\naccelerators that promise even greater computational and machine learning\ncapabilities. These processors and accelerators are coming in many forms, from\nCPUs and GPUs to ASICs, FPGAs, and dataflow accelerators. This paper surveys\nthe current state of these processors and accelerators that have been publicly\nannounced with performance and power consumption numbers. The performance and\npower values are plotted on a scatter graph and a number of dimensions and\nobservations from the trends on this plot are discussed and analyzed. For\ninstance, there are interesting trends in the plot regarding power consumption,\nnumerical precision, and inference versus training. We then select and\nbenchmark two commercially-available low size, weight, and power (SWaP)\naccelerators as these processors are the most interesting for embedded and\nmobile machine learning inference applications that are most applicable to the\nDoD and other SWaP constrained users. We determine how they actually perform\nwith real-world images and neural network models, compare those results to the\nreported performance and power consumption values and evaluate them against an\nIntel CPU that is used in some embedded applications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:54:49 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Reuther", "Albert", ""], ["Michaleas", "Peter", ""], ["Jones", "Michael", ""], ["Gadepally", "Vijay", ""], ["Samsi", "Siddharth", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1908.11660", "submitter": "Shubhendra Singhal Mr.", "authors": "Shubhendra Pal Singhal, M.Sridevi", "title": "Comparative study of performance of parallel Alpha Beta Pruning for\n  different architectures", "comments": "5 pages, 6 figures, Accepted in 2019 IEEE 9th International Advance\n  Computing Conference(IEEE Xplore)", "journal-ref": "2019 IEEE 9th International Conference on Advanced Computing\n  (IACC), Tiruchirappalli, India, 2019, pp. 115-119", "doi": "10.1109/IACC48062.2019.8971591", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of searching the best possible action depending on various\nstates like state of environment, system goal etc. has been a major area of\nstudy in computer systems. In any search algorithm, searching best possible\nsolution from the pool of every possibility known can lead to the construction\nof the whole state search space popularly called as minimax algorithm. This may\nlead to a impractical time complexities which may not be suitable for real time\nsearching operations. One of the practical solution for the reduction in\ncomputational time is Alpha Beta pruning. Instead of searching for the whole\nstate space, we prune the unnecessary branches, which helps reduce the time by\nsignificant amount. This paper focuses on the various possible implementations\nof the Alpha Beta pruning algorithms and gives an insight of what algorithm can\nbe used for parallelism. Various studies have been conducted on how to make\nAlpha Beta pruning faster. Parallelizing Alpha Beta pruning for the GPUs\nspecific architectures like mesh(CUDA) etc. or shared memory model(OpenMP)\nhelps in the reduction of the computational time. This paper studies the\ncomparison between sequential and different parallel forms of Alpha Beta\npruning and their respective efficiency for the chess game as an application.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 11:36:38 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 11:05:56 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Singhal", "Shubhendra Pal", ""], ["Sridevi", "M.", ""]]}]