[{"id": "1604.00103", "submitter": "Jun Kawahara", "authors": "Shoji Kasahara and Jun Kawahara", "title": "Effect of Bitcoin fee on transaction-confirmation process", "comments": null, "journal-ref": null, "doi": "10.3934/jimo.2018047", "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bitcoin system, transactions are prioritized according to transaction\nfees. Transactions without fees are given low priority and likely to wait for\nconfirmation. Because the demand of micro payment in Bitcoin is expected to\nincrease due to low remittance cost, it is important to quantitatively\ninvestigate how transactions with small fees of Bitcoin affect the\ntransaction-confirmation time. In this paper, we analyze the\ntransaction-confirmation time by queueing theory. We model the\ntransaction-confirmation process of Bitcoin as a priority queueing system with\nbatch service, deriving the mean transaction-confirmation time. Numerical\nexamples show how the demand of transactions with low fees affects the\ntransaction-confirmation time. We also consider the effect of the maximum block\nsize on the transaction-confirmation time.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 02:15:02 GMT"}, {"version": "v2", "created": "Mon, 4 Apr 2016 05:41:58 GMT"}, {"version": "v3", "created": "Tue, 30 May 2017 05:09:19 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Kasahara", "Shoji", ""], ["Kawahara", "Jun", ""]]}, {"id": "1604.01303", "submitter": "Liang Wang", "authors": "Liang Wang, Mario Almeida, Jeremy Blackburn, Jon Crowcroft", "title": "C3PO: Computation Congestion Control (PrOactive) - an algorithm for\n  dynamic diffusion of ephemeral in-network services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an obvious trend that more and more data and computation are\nmigrating into networks nowadays. Combining mature virtualization technologies\nwith service-centric net- working, we are entering into an era where countless\nservices reside in an ISP network to provide low-latency access. Such services\nare often computation intensive and are dynamically created and destroyed on\ndemands everywhere in the network to perform various tasks. Consequently, these\nephemeral in-network services introduce a new type of congestion in the network\nwhich we refer to as \"computation congestion\". The service load need to be\neffectively distributed on different nodes in order to maintain the\nfuntionality and responsiveness of the network, which calls for a new design\nrather than reusing the centralised scheduler designed for cloud-based\nservices. In this paper, we study both passive and proactive control\nstrategies, based on the proactive control we further propose a fully\ndistributed solution which is low complexity, adaptive, and responsive to\nnetwork dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 15:38:51 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 09:07:04 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Wang", "Liang", ""], ["Almeida", "Mario", ""], ["Blackburn", "Jeremy", ""], ["Crowcroft", "Jon", ""]]}, {"id": "1604.01890", "submitter": "Georg Hager", "authors": "Johannes Hofmann, Dietmar Fey, Michael Riedmann, Jan Eitzinger, Georg\n  Hager, Gerhard Wellein", "title": "Performance analysis of the Kahan-enhanced scalar product on current\n  multi- and manycore processors", "comments": "15 pages, 10 figures", "journal-ref": "Concurrency Computat.: Pract. Exper., 29: e3921 (2016)", "doi": "10.1002/cpe.3921", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance characteristics of a numerically enhanced\nscalar product (dot) kernel loop that uses the Kahan algorithm to compensate\nfor numerical errors, and describe efficient SIMD-vectorized implementations on\nrecent multi- and manycore processors. Using low-level instruction analysis and\nthe execution-cache-memory (ECM) performance model we pinpoint the relevant\nperformance bottlenecks for single-core and thread-parallel execution, and\npredict performance and saturation behavior. We show that the Kahan-enhanced\nscalar product comes at almost no additional cost compared to the naive\n(non-Kahan) scalar product if appropriate low-level optimizations, notably SIMD\nvectorization and unrolling, are applied. The ECM model is extended\nappropriately to accommodate not only modern Intel multicore chips but also the\nIntel Xeon Phi \"Knights Corner\" coprocessor and an IBM POWER8 CPU. This allows\nus to discuss the impact of processor features on the performance across four\nmodern architectures that are relevant for high performance computing.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 07:04:19 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Hofmann", "Johannes", ""], ["Fey", "Dietmar", ""], ["Riedmann", "Michael", ""], ["Eitzinger", "Jan", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1604.02097", "submitter": "Bo Jiang", "authors": "Bo Jiang, Daniel R. Figueiredo, Bruno Ribeiro, Don Towsley", "title": "On the Duration and Intensity of Competitions in Nonlinear P\\'olya Urn\n  Processes with Fitness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cumulative advantage (CA) refers to the notion that accumulated resources\nfoster the accumulation of further resources in competitions, a phenomenon that\nhas been empirically observed in various contexts. The oldest and arguably\nsimplest mathematical model that embodies this general principle is the P\\'olya\nurn process, which finds applications in a myriad of problems. The original\nmodel captures the dynamics of competitions between two equally fit agents\nunder linear CA effects, which can be readily generalized to incorporate\ndifferent fitnesses and nonlinear CA effects. We study two statistics of\ncompetitions under the generalized model, namely duration (i.e., time of the\nlast tie) and intensity (i.e., number of ties). We give rigorous mathematical\ncharacterizations of the tail distributions of both duration and intensity\nunder the various regimes for fitness and nonlinearity, which reveal very\ninteresting behaviors. For example, fitness superiority induces much shorter\ncompetitions in the sublinear regime while much longer competitions in the\nsuperlinear regime. Our findings can shed light on the application of P\\'olya\nurn processes in more general contexts where fitness and nonlinearity may be\npresent.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 00:35:18 GMT"}, {"version": "v2", "created": "Wed, 13 Apr 2016 15:00:48 GMT"}, {"version": "v3", "created": "Fri, 7 Apr 2017 19:49:58 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Jiang", "Bo", ""], ["Figueiredo", "Daniel R.", ""], ["Ribeiro", "Bruno", ""], ["Towsley", "Don", ""]]}, {"id": "1604.02435", "submitter": "Jian Li", "authors": "Jian Li, Rajarshi Bhattacharyya, Suman Paul, Srinivas Shakkottai, and\n  Vijay Subramanian", "title": "Incentivizing Sharing in Realtime D2D Streaming Networks: A Mean Field\n  Game Perspective", "comments": "To appear in IEEE/ACM Transactions on Networking. A preliminary\n  version appeared in the proceedings of IEEE Infocom 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.PF cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of streaming live content to a cluster of co-located\nwireless devices that have both an expensive unicast base-station-to-device\n(B2D) interface, as well as an inexpensive broadcast device-to-device (D2D)\ninterface, which can be used simultaneously. Our setting is a streaming system\nthat uses a block-by-block random linear coding approach to achieve a target\npercentage of on-time deliveries with minimal B2D usage. Our goal is to design\nan incentive framework that would promote such cooperation across devices,\nwhile ensuring good quality of service. Based on ideas drawn from truth-telling\nauctions, we design a mechanism that achieves this goal via appropriate\ntransfers (monetary payments or rebates) in a setting with a large number of\ndevices, and with peer arrivals and departures. Here, we show that a Mean Field\nGame can be used to accurately approximate our system. Furthermore, the\ncomplexity of calculating the best responses under this regime is low. We\nimplement the proposed system on an Android testbed, and illustrate its\nefficient performance using real world experiments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 19:32:43 GMT"}, {"version": "v2", "created": "Sun, 1 May 2016 14:38:05 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Li", "Jian", ""], ["Bhattacharyya", "Rajarshi", ""], ["Paul", "Suman", ""], ["Shakkottai", "Srinivas", ""], ["Subramanian", "Vijay", ""]]}, {"id": "1604.02727", "submitter": "Yorai Wardi", "authors": "Xinwei Chen, Yorai Wardi, Sudhakar Yalamanchili", "title": "IPA in the Loop: Control Design for Throughput Regulation in Computer\n  Processors", "comments": "To appear in Proc. 13th International Workshop on Discrete Event\n  Systems (WODES 2016), Xi'an, China, May 30 - June 1, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new technique for performance regulation in event-driven systems, recently\nproposed by the authors, consists of an adaptive-gain integral control. The\ngain is adjusted in the control loop by a real-time estimation of the\nderivative of the plant-function with respect to the control input. This\nestimation is carried out by Infinitesimal Perturbation Analysis (IPA). The\nmain motivation comes from applications to throughput regulation in computer\nprocessors, where to-date, testing and assessment of the proposed control\ntechnique has been assessed by simulation. The purpose of this paper is to\nreport on its implementation on a machine, namely an Intel Haswell\nmicroprocessor, and compare its performance to that obtained from cycle-level,\nfull system simulation environment. The intrinsic contribution of the paper to\nthe Workshop on Discrete Event System is in describing the process of taking an\nIPA-based design and simulation to a concrete implementation, thereby providing\na bridge between theory and applications.\n", "versions": [{"version": "v1", "created": "Sun, 10 Apr 2016 19:48:59 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Chen", "Xinwei", ""], ["Wardi", "Yorai", ""], ["Yalamanchili", "Sudhakar", ""]]}, {"id": "1604.02907", "submitter": "Hossein Nourikhah", "authors": "Hossein Nourikhah, Mohammad Kazem Akbari, Mohammad Kalantari", "title": "Modeling and predicting measured response time of cloud-based web\n  services using long-memory time series", "comments": null, "journal-ref": "The Journal of Supercomputing, February 2015, Volume 71, Issue 2,\n  pp 673-696", "doi": "10.1007/s11227-014-1317-4", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting cloud performance from user's perspective is a complex task,\nbecause of several factors involved in providing the service to the consumer.\nIn this work, the response time of 10 real-world services is analyzed. We have\nobserved long memory in terms of the measured response time of the\nCPU-intensive services and statistically verified this observation using\nestimators of the Hurst exponent. Then, na\\\"ive, mean, autoregressive\nintegrated moving average (ARIMA) and autoregressive fractionally integrated\nmoving average (ARFIMA) methods are used to forecast the future values of\nquality of service (QoS) at runtime. Results of the cross-validation over the\n10 datasets show that the long-memory ARFIMA model provides the mean of 37.5 %\nand the maximum of 57.8 % reduction in the forecast error when compared to the\nshort-memory ARIMA model according to the standard error measure of mean\nabsolute percentage error. Our work implies that consideration of the\nlong-range dependence in QoS data can help to improve the selection of services\naccording to their possible future QoS values.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 12:07:20 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Nourikhah", "Hossein", ""], ["Akbari", "Mohammad Kazem", ""], ["Kalantari", "Mohammad", ""]]}, {"id": "1604.03470", "submitter": "Nikolas Herbst", "authors": "Nikolas Herbst, Rouven Krebs, Giorgos Oikonomou, George Kousiouris,\n  Athanasia Evangelinou, Alexandru Iosup, and Samuel Kounev", "title": "Ready for Rain? A View from SPEC Research on the Future of Cloud Metrics", "comments": "SPEC Research Group - Cloud Working Group, Standard Performance\n  Evaluation Corporation (SPEC)", "journal-ref": null, "doi": null, "report-no": "Technical Report SPEC-RG-2016-01", "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, cloud computing has emerged from a pursuit for a\nservice-driven information and communication technology (ICT), into a\nsignifcant fraction of the ICT market. Responding to the growth of the market,\nmany alternative cloud services and their underlying systems are currently\nvying for the attention of cloud users and providers. Thus, benchmarking them\nis needed, to enable cloud users to make an informed choice, and to enable\nsystem DevOps to tune, design, and evaluate their systems. This requires\nfocusing on old and new system properties, possibly leading to the re-design of\nclassic benchmarking metrics, such as expressing performance as throughput and\nlatency (response time), and the design of new, cloud-specififc metrics.\nAddressing this requirement, in this work we focus on four system properties:\n(i) elasticity of the cloud service, to accommodate large variations in the\namount of service requested, (ii) performance isolation between the tenants of\nshared cloud systems, (iii) availability of cloud services and systems, and the\n(iv) operational risk of running a production system in a cloud\nenvironment.Focusing on key metrics, for each of these properties we review the\nstate-of-the-art, then select or propose new metrics together with measurement\napproaches. We see the presented metrics as a foundation towards upcoming,\nindustry-standard, cloud benchmarks.\n  Keywords: Cloud Computing; Metrics; Measurement; Benchmarking; Elasticity;\nIsolation; Performance; Service Level Objective; Availability; Operational\nRisk.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 16:23:15 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Herbst", "Nikolas", ""], ["Krebs", "Rouven", ""], ["Oikonomou", "Giorgos", ""], ["Kousiouris", "George", ""], ["Evangelinou", "Athanasia", ""], ["Iosup", "Alexandru", ""], ["Kounev", "Samuel", ""]]}, {"id": "1604.03823", "submitter": "Guilherme Thompson", "authors": "Fabrice Guillemin and Guilherme Thompson", "title": "Analysis of a trunk reservation policy in the framework of fog computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze in this paper a system composed of two data centers with limited\ncapacity in terms of servers. When one request for a single server is blocked\nat the first data center, this request is forwarded to the second one. To\nprotect the single server requests originally assigned to the second data\ncenter, a trunk reservation policy is introduced (i.e., a redirected request is\naccepted only if there is a sufficient number of free servers at the second\ndata center). After rescaling the system by assuming that there are many\nservers in both data centers and high request arrival rates, we are led to\nanalyze a random walk in the quarter plane, which has the particularity of\nhaving non constant reflecting conditions on one boundary of the quarter plane.\nContrary to usual reflected random walks, to compute the stationary\ndistribution of the presented random walk, we have to determine three unknown\nfunctions, one polynomial and two infinite generating functions. We show that\nthe coefficients of the polynomial are solutions to a linear system. After\nsolving this linear system, we are able to compute the two other unknown\nfunctions and the blocking probabilities at both data centers. Numerical\nexperiments are eventually performed to estimate the gain achieved by the trunk\nreservation policy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 15:14:08 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Guillemin", "Fabrice", ""], ["Thompson", "Guilherme", ""]]}, {"id": "1604.04013", "submitter": "Sean Meyn", "authors": "Yue Chen and Ana Bu\\v{s}i\\'c and Sean Meyn", "title": "Ergodic Theory for Controlled Markov Chains with Stationary Inputs", "comments": null, "journal-ref": null, "doi": "10.1214/17-AAP1300", "report-no": null, "categories": "cs.PF cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a stochastic process $\\{X(t)\\}$ on a finite state space $ {\\sf\nX}=\\{1,\\dots, d\\}$. It is conditionally Markov, given a real-valued `input\nprocess' $\\{\\zeta(t)\\}$. This is assumed to be small, which is modeled through\nthe scaling, \\[ \\zeta_t = \\varepsilon \\zeta^1_t, \\qquad 0\\le \\varepsilon \\le\n1\\,, \\] where $\\{\\zeta^1(t)\\}$ is a bounded stationary process. The following\nconclusions are obtained, subject to smoothness assumptions on the controlled\ntransition matrix and a mixing condition on $\\{\\zeta(t)\\}$:\n  (i) A stationary version of the process is constructed, that is coupled with\na stationary version of the Markov chain $\\{X^\\bullet$(t)\\}obtained with\n$\\{\\zeta(t)\\}\\equiv 0$. The triple $(\\{X(t)\\}, \\{X^\\bullet(t)\\},\\{\\zeta(t)\\})$\nis a jointly stationary process satisfying \\[ {\\sf P}\\{X(t) \\neq X^\\bullet(t)\\}\n= O(\\varepsilon) \\] Moreover, a second-order Taylor-series approximation is\nobtained: \\[ {\\sf P}\\{X(t) =i \\} ={\\sf P}\\{X^\\bullet(t) =i \\} + \\varepsilon^2\n\\varrho(i) + o(\\varepsilon^2),\\quad 1\\le i\\le d, \\] with an explicit formula\nfor the vector $\\varrho\\in\\mathbb{R}^d$.\n  (ii) For any $m\\ge 1$ and any function $f\\colon \\{1,\\dots,d\\}\\times\n\\mathbb{R}\\to\\mathbb{R}^m$, the stationary stochastic process $Y(t) =\nf(X(t),\\zeta(t))$ has a power spectral density $\\text{S}_f$ that admits a\nsecond order Taylor series expansion: A function $\\text{S}^{(2)}_f\\colon\n[-\\pi,\\pi] \\to \\mathbb{C}^{ m\\times m}$ is constructed such that \\[\n\\text{S}_f(\\theta) = \\text{S}^\\bullet_f(\\theta) + \\varepsilon^2\n\\text{S}_f^{(2)}(\\theta) + o(\\varepsilon^2),\\quad \\theta\\in [-\\pi,\\pi] . \\] An\nexplicit formula for the function $\\text{S}_f^{(2)}$ is obtained, based in part\non the bounds in (i).\n  The results are illustrated using a version of the timing channel of\nAnantharam and Verdu.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 02:16:52 GMT"}, {"version": "v2", "created": "Sat, 18 Jun 2016 09:39:26 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Chen", "Yue", ""], ["Bu\u0161i\u0107", "Ana", ""], ["Meyn", "Sean", ""]]}, {"id": "1604.04951", "submitter": "Junchul Choi", "authors": "Junchul Choi, Hyunok Oh, Soonhoi Ha", "title": "A Hybrid Performance Analysis Technique for Distributed Real-Time\n  Embedded Systems", "comments": "29 pages (25 page paper, 4 page appendix), 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It remains a challenging problem to tightly estimate the worst case response\ntime of an application in a distributed embedded system, especially when there\nare dependencies between tasks. We discovered that the state-of-the art\ntechniques considering task dependencies either fail to obtain a conservative\nbound or produce a loose upper bound. We propose a novel conservative\nperformance analysis, called hybrid performance analysis, combining the\nresponse time analysis technique and the scheduling time bound analysis\ntechnique to compute a tighter bound fast. Through extensive experiments with\nrandomly generated graphs, superior performance of our proposed approach\ncompared with previous methods is confirmed.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 01:24:48 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Choi", "Junchul", ""], ["Oh", "Hyunok", ""], ["Ha", "Soonhoi", ""]]}, {"id": "1604.04997", "submitter": "James Stevens", "authors": "James Stevens and Andreas Kl\\\"ockner", "title": "A Unified, Hardware-Fitted, Cross-GPU Performance Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mechanism to symbolically gather performance-relevant operation\ncounts from numerically-oriented subprograms (`kernels') expressed in the Loopy\nprogramming system, and apply these counts in a simple, linear model of kernel\nrun time. We use a series of `performance-instructive' kernels to fit the\nparameters of a unified model to the performance characteristics of GPU\nhardware from multiple hardware generations and vendors. We evaluate the\npredictive power of the model on a broad array of computational kernels\nrelevant to scientific computing. In terms of the geometric mean, our simple,\nvendor- and GPU-type-independent model achieves relative accuracy comparable to\nthat of previously published work using hardware specific models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 05:49:56 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Stevens", "James", ""], ["Kl\u00f6ckner", "Andreas", ""]]}, {"id": "1604.05516", "submitter": "Debayani Ghosh", "authors": "Debayani Ghosh, Krishna Jagannathan and Gaurav Raina", "title": "Right buffer sizing matters: some dynamical and statistical studies on\n  Compound TCP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent concerns that queuing delays in the Internet are on the\nrise, we conduct a performance evaluation of Compound TCP (C-TCP) in two\ntopologies: a single bottleneck and a multi-bottleneck topology, under\ndifferent traffic scenarios. The first topology consists of a single bottleneck\nrouter, and the second consists of two distinct sets of TCP flows, regulated by\ntwo edge routers, feeding into a common core router. We focus on some dynamical\nand statistical properties of the underlying system. From a dynamical\nperspective, we develop fluid models in a regime wherein the number of flows is\nlarge, bandwidth-delay product is high, buffers are dimensioned small\n(independent of the bandwidth-delay product) and routers deploy a Drop-Tail\nqueue policy. A detailed local stability analysis for these models yields the\nfollowing key insight: smaller buffers favour stability. Additionally, we\nhighlight that larger buffers, in addition to increasing latency, are prone to\ninducing limit cycles in the system dynamics, via a Hopf bifurcation. These\nlimit cycles in turn cause synchronisation among the TCP flows, and also result\nin a loss of link utilisation. For the topologies considered, we also\nempirically analyse some statistical properties of the bottleneck queues. These\nstatistical analyses serve to validate an important modelling assumption: that\nin the regime considered, each bottleneck queue may be approximated as either\nan $M/M/1/B$ or an $M/D/1/B$ queue. This immediately makes the modelling\nperspective attractive and the analysis tractable. Finally, we show that\nsmaller buffers, in addition to ensuring stability and low latency, would also\nyield fairly good system performance, in terms of throughput and flow\ncompletion times.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 11:00:08 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2016 09:24:35 GMT"}, {"version": "v3", "created": "Sun, 28 May 2017 07:51:25 GMT"}, {"version": "v4", "created": "Wed, 24 Oct 2018 17:15:13 GMT"}, {"version": "v5", "created": "Mon, 24 Dec 2018 09:53:16 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Ghosh", "Debayani", ""], ["Jagannathan", "Krishna", ""], ["Raina", "Gaurav", ""]]}, {"id": "1604.06763", "submitter": "C\\'eline Comte", "authors": "Thomas Bonald and C\\'eline Comte", "title": "Balanced Fair Resource Sharing in Computer Clusters", "comments": null, "journal-ref": null, "doi": "10.1016/j.peva.2017.08.006", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We represent a computer cluster as a multi-server queue with some arbitrary\nbipartite graph of compatibilities between jobs and servers. Each server\nprocesses its jobs sequentially in FCFS order. The service rate of a job at any\ngiven time is the sum of the service rates of all servers processing this job.\nWe show that the corresponding queue is quasi-reversible and use this property\nto design a scheduling algorithm achieving balanced fair sharing of the service\ncapacity.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 18:10:10 GMT"}, {"version": "v2", "created": "Sat, 11 Mar 2017 10:43:51 GMT"}, {"version": "v3", "created": "Mon, 4 Sep 2017 08:06:33 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Bonald", "Thomas", ""], ["Comte", "C\u00e9line", ""]]}, {"id": "1604.07076", "submitter": "Gabriele D'Angelo", "authors": "Stefano Ferretti, Gabriele D'Angelo", "title": "Smart Shires: The Revenge of Countrysides (Extended Version)", "comments": "Proceedings of the IEEE Symposium on Computers and Communication\n  (ISCC 2016), Messina (Italy), 2016", "journal-ref": null, "doi": "10.1109/ISCC.2016.7543827", "report-no": null, "categories": "cs.CY cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the need to devise novel strategies to create smart\nservices specifically designed to non-metropolitan areas, i.e. countrysides.\nThese solutions must be viable, cheap an should take into consideration the\ndifferent nature of countrysides, that cannot afford the deployment of services\ndesigned for smart cities. These solutions would have an important social\nimpact for people leaving in these countrysides, and might slow down the\nconstant migration of citizens towards metropolis. In this work, we focus on\ncommunication technologies and practical technological/software distributed\narchitectures. An important aspect for the real deployment of these smart\nshires is their simulation. We show that priority-based broadcast schemes over\nad-hoc networks can represent an effective communication substrate to be used\nin a software middleware promoting the creation of applications for smart shire\nscenarios.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 19:36:56 GMT"}, {"version": "v2", "created": "Tue, 23 Aug 2016 19:34:02 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "1604.07371", "submitter": "Srikanth Kandula", "authors": "Robert Grandl, Srikanth Kandula, Sriram Rao, Aditya Akella and\n  Janardhan Kulkarni", "title": "Do the Hard Stuff First: Scheduling Dependent Computations in\n  Data-Analytics Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": "MSR-TR-2016-19", "categories": "cs.DC cs.DB cs.OS cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scheduler that improves cluster utilization and job completion\ntimes by packing tasks having multi-resource requirements and\ninter-dependencies. While the problem is algorithmically very hard, we achieve\nnear-optimality on the job DAGs that appear in production clusters at a large\nenterprise and in benchmarks such as TPC-DS. A key insight is that carefully\nhandling the long-running tasks and those with tough-to-pack resource needs\nwill produce good-enough schedules. However, which subset of tasks to treat\ncarefully is not clear (and intractable to discover). Hence, we offer a search\nprocedure that evaluates various possibilities and outputs a preferred schedule\norder over tasks. An online component enforces the schedule orders desired by\nthe various jobs running on the cluster. In addition, it packs tasks, overbooks\nthe fungible resources and guarantees bounded unfairness for a variety of\ndesirable fairness schemes. Relative to the state-of-the art schedulers, we\nspeed up 50% of the jobs by over 30% each.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 19:20:18 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Grandl", "Robert", ""], ["Kandula", "Srikanth", ""], ["Rao", "Sriram", ""], ["Akella", "Aditya", ""], ["Kulkarni", "Janardhan", ""]]}, {"id": "1604.08004", "submitter": "Luigi Palopoli", "authors": "Luigi Palopoli and Daniele Fontanelli and Luca Abeni and Bernardo\n  Villalba Fr\\'ias", "title": "An Analytical Solution for Probabilistic Guarantees of Reservation Based\n  Soft Real-Time Systems", "comments": "IEEE Transactions on Parallel and Distributed Systems, Volume:27,\n  Issue: 3, March 2016", "journal-ref": null, "doi": "10.1109/TPDS.2015.2416732", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a methodology for the computation of the probability of deadline miss\nfor a periodic real-time task scheduled by a resource reservation algorithm. We\npropose a modelling technique for the system that reduces the computation of\nsuch a probability to that of the steady state probability of an infinite state\nDiscrete Time Markov Chain with a periodic structure. This structure is\nexploited to develop an efficient numeric solution where different\naccuracy/computation time trade-offs can be obtained by operating on the\ngranularity of the model. More importantly we offer a closed form conservative\nbound for the probability of a deadline miss. Our experiments reveal that the\nbound remains reasonably close to the experimental probability in one real-time\napplication of practical interest. When this bound is used for the optimisation\nof the overall Quality of Service for a set of tasks sharing the CPU, it\nproduces a good sub-optimal solution in a small amount of time.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 10:08:53 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Palopoli", "Luigi", ""], ["Fontanelli", "Daniele", ""], ["Abeni", "Luca", ""], ["Fr\u00edas", "Bernardo Villalba", ""]]}, {"id": "1604.08484", "submitter": "Ahsan Javed Awan", "authors": "Ahsan Javed Awan, Mats Brorsson, Vladimir Vlassov and Eduard Ayguade", "title": "Architectural Impact on Performance of In-memory Data Analytics: Apache\n  Spark Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While cluster computing frameworks are continuously evolving to provide\nreal-time data analysis capabilities, Apache Spark has managed to be at the\nforefront of big data analytics for being a unified framework for both, batch\nand stream data processing. However, recent studies on micro-architectural\ncharacterization of in-memory data analytics are limited to only batch\nprocessing workloads. We compare micro-architectural performance of batch\nprocessing and stream processing workloads in Apache Spark using hardware\nperformance counters on a dual socket server. In our evaluation experiments, we\nhave found that batch processing are stream processing workloads have similar\nmicro-architectural characteristics and are bounded by the latency of frequent\ndata access to DRAM. For data accesses we have found that simultaneous\nmulti-threading is effective in hiding the data latencies. We have also\nobserved that (i) data locality on NUMA nodes can improve the performance by\n10% on average and(ii) disabling next-line L1-D prefetchers can reduce the\nexecution time by up-to 14\\% and (iii) multiple small executors can provide\nup-to 36\\% speedup over single large executor.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 16:00:38 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Awan", "Ahsan Javed", ""], ["Brorsson", "Mats", ""], ["Vlassov", "Vladimir", ""], ["Ayguade", "Eduard", ""]]}, {"id": "1604.08501", "submitter": "Andreas Kl\\\"ockner", "authors": "Andreas Kl\\\"ockner and Lucas C. Wilcox and T. Warburton", "title": "Array Program Transformation with Loo.py by Example: High-Order Finite\n  Elements", "comments": null, "journal-ref": "ARRAY 2016 Proceedings of the 3rd ACM SIGPLAN International\n  Workshop on Libraries, Languages, and Compilers for Array Programming Pages\n  9-16", "doi": "10.1145/2935323.2935325", "report-no": null, "categories": "cs.PL cs.PF math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To concisely and effectively demonstrate the capabilities of our program\ntransformation system Loo.py, we examine a transformation path from two\nreal-world Fortran subroutines as found in a weather model to a single\nhigh-performance computational kernel suitable for execution on modern GPU\nhardware. Along the transformation path, we encounter kernel fusion,\nvectorization, prefetch- ing, parallelization, and algorithmic changes achieved\nby mechanized conversion between imperative and functional/substitution- based\ncode, among a number more. We conclude with performance results that\ndemonstrate the effects and support the effectiveness of the applied\ntransformations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 20:56:15 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Kl\u00f6ckner", "Andreas", ""], ["Wilcox", "Lucas C.", ""], ["Warburton", "T.", ""]]}, {"id": "1604.08734", "submitter": "Petri Luoto", "authors": "Petri Luoto, Mehdi Bennis, Pekka Pirinen, Sumudu Samarakoon, Kari\n  Horneman, Matti Latva-aho", "title": "System Level Performance Evaluation of LTE-V2X Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicles are among the fastest growing type of connected devices. Therefore,\nthere is a need for Vehicle-to-Everything (V2X) communication i.e. passing of\ninformation from a Vehicle-to-Vehicle (V2V) or Vehicle-to-Infrastructure (V2I)\nand vice versa. In this paper, the main focus is on the communication between\nvehicles and road side units (RSUs) commonly referred to as V2I communication\nin a multi-lane freeway scenario. Moreover, we analyze network related\nbottlenecks such as the maximum number of vehicles that can be supported when\ncoverage is provided by the Long Term Evolution Advanced (LTE-A) network. The\nperformance evaluation is assessed through extensive system-level simulations.\nResults show that new resource allocation and interference mitigation\ntechniques are needed in order to achieve the required high reliability\nrequirements, especially when network load is high.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 08:37:43 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Luoto", "Petri", ""], ["Bennis", "Mehdi", ""], ["Pirinen", "Pekka", ""], ["Samarakoon", "Sumudu", ""], ["Horneman", "Kari", ""], ["Latva-aho", "Matti", ""]]}]