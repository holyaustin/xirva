[{"id": "0902.0558", "submitter": "Marc Portoles Comeras", "authors": "Marc Portoles-Comeras, Albert Cabellos-Aparicio, Josep\n  Mangues-Bafalluy, Jordi Domingo-Pascual", "title": "Analysis of bandwidth measurement methodologies over WLAN systems", "comments": "14 pages, 17 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WLAN devices have become a fundamental component of nowadays network\ndeployments. However, even though traditional networking applications run\nmostly unchanged over wireless links, the actual interaction between these\napplications and the dynamics of wireless transmissions is not yet fully\nunderstood. An important example of such applications are bandwidth estimation\ntools. This area has become a mature research topic with well-developed\nresults. Unfortunately recent studies have shown that the application of these\nresults to WLAN links is not straightforward. The main reasons for this is that\nthe assumptions taken to develop bandwidth measurements tools do not hold any\nlonger in the presence of wireless links (e.g. non-FIFO scheduling). This paper\nbuilds from these observations and its main goal is to analyze the interaction\nbetween probe packets and WLAN transmissions in bandwidth estimation processes.\nThe paper proposes an analytical model that better accounts for the\nparticularities of WLAN links. The model is validated through extensive\nexperimentation and simulation and reveals that (1) the distribution of the\ndelay to transmit probing packets is not the same for the whole probing\nsequence, this biases the measurements process and (2) existing tools and\ntechniques point at the achievable throughput rather than the available\nbandwidth or the capacity, as previously assumed.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2009 17:23:55 GMT"}], "update_date": "2009-02-04", "authors_parsed": [["Portoles-Comeras", "Marc", ""], ["Cabellos-Aparicio", "Albert", ""], ["Mangues-Bafalluy", "Josep", ""], ["Domingo-Pascual", "Jordi", ""]]}, {"id": "0902.0782", "submitter": "Katia  Jaffres-Runser", "authors": "Katia Jaffr\\`es-Runser, Cristina Comaniciu, Jean-Marie Gorce", "title": "A Multiobjective Optimization Framework for Routing in Wireless Ad Hoc\n  Networks", "comments": null, "journal-ref": "IEEE International Symposium on Conference Modeling and\n  Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt) 2010", "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless ad hoc networks are seldom characterized by one single performance\nmetric, yet the current literature lacks a flexible framework to assist in\ncharacterizing the design tradeoffs in such networks. In this work, we address\nthis problem by proposing a new modeling framework for routing in ad hoc\nnetworks, which used in conjunction with metaheuristic multiobjective search\nalgorithms, will result in a better understanding of network behavior and\nperformance when multiple criteria are relevant. Our approach is to take a\nholistic view of the network that captures the cross-interactions among\ninterference management techniques implemented at various layers of the\nprotocol stack. The resulting framework is a complex multiobjective\noptimization problem that can be efficiently solved through existing\nmultiobjective search techniques. In this contribution, we present the Pareto\noptimal sets for an example sensor network when delay, robustness and energy\nare considered. The aim of this paper is to present the framework and hence for\nconciseness purposes, the multiobjective optimization search is not developed\nherein.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2009 19:48:42 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2010 11:15:29 GMT"}], "update_date": "2010-08-17", "authors_parsed": [["Jaffr\u00e8s-Runser", "Katia", ""], ["Comaniciu", "Cristina", ""], ["Gorce", "Jean-Marie", ""]]}, {"id": "0902.1035", "submitter": "Sid Touati", "authors": "Sid Touati (PRISM)", "title": "Towards a Statistical Methodology to Evaluate Program Speedups and their\n  Optimisation Techniques", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The community of program optimisation and analysis, code performance\nevaluation, parallelisation and optimising compilation has published since many\ndecades hundreds of research and engineering articles in major conferences and\njournals. These articles study efficient algorithms, strategies and techniques\nto accelerate programs execution times, or optimise other performance metrics\n(MIPS, code size, energy/power, MFLOPS, etc.). Many speedups are published, but\nnobody is able to reproduce them exactly. The non-reproducibility of our\nresearch results is a dark point of the art, and we cannot be qualified as {\\it\ncomputer scientists} if we do not provide rigorous experimental methodology.\nThis article provides a first effort towards a correct statistical protocol for\nanalysing and measuring speedups. As we will see, some common mistakes are done\nby the community inside published articles, explaining part of the\nnon-reproducibility of the results. Our current article is not sufficient by\nits own to deliver a complete experimental methodology, further efforts must be\ndone by the community to decide about a common protocol for our future\nexperiences. Anyway, our community should take care about the aspect of\nreproducibility of the results in the future.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2009 09:30:53 GMT"}, {"version": "v2", "created": "Thu, 12 Feb 2009 15:50:41 GMT"}, {"version": "v3", "created": "Tue, 17 Feb 2009 08:23:45 GMT"}, {"version": "v4", "created": "Thu, 19 Feb 2009 13:34:55 GMT"}, {"version": "v5", "created": "Fri, 27 Feb 2009 10:08:32 GMT"}, {"version": "v6", "created": "Thu, 5 Mar 2009 05:36:54 GMT"}, {"version": "v7", "created": "Thu, 2 Apr 2009 09:50:06 GMT"}, {"version": "v8", "created": "Mon, 6 Jul 2009 11:46:38 GMT"}], "update_date": "2009-07-06", "authors_parsed": [["Touati", "Sid", "", "PRISM"]]}, {"id": "0902.1169", "submitter": "Gagan Raj Gupta", "authors": "Gagan Raj Gupta, Sujay Sanghavi and Ness B. Shroff", "title": "Node Weighted Scheduling", "comments": "To appear in Sigmetrics 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new class of online policies for scheduling in\ninput-buffered crossbar switches. Our policies are throughput optimal for a\nlarge class of arrival processes which satisfy strong-law of large numbers.\nGiven an initial configuration and no further arrivals, our policies drain all\npackets in the system in the minimal amount of time (providing an online\nalternative to the batch approach based on Birkhoff-VonNeumann decompositions).\nWe show that it is possible for policies in our class to be throughput optimal\neven if they are not constrained to be maximal in every time slot.\n  Most algorithms for switch scheduling take an edge based approach; in\ncontrast, we focus on scheduling (a large enough set of) the most congested\nports. This alternate approach allows for lower-complexity algorithms, and also\nrequires a non-standard technique to prove throughput-optimality. One algorithm\nin our class, Maximum Vertex-weighted Matching (MVM) has worst-case complexity\nsimilar to Max-size Matching, and in simulations shows slightly better delay\nperformance than Max-(edge)weighted-Matching (MWM).\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2009 20:34:09 GMT"}], "update_date": "2009-02-09", "authors_parsed": [["Gupta", "Gagan Raj", ""], ["Sanghavi", "Sujay", ""], ["Shroff", "Ness B.", ""]]}, {"id": "0902.1394", "submitter": "Francesca Lo Piccolo", "authors": "Giuseppe Bianchi, Nicola Blefari Melazzi, Lorenzo Bracciale, Francesca\n  Lo Piccolo, Stefano Salsano", "title": "Fundamental delay bounds in peer-to-peer chunk-based real-time streaming\n  systems", "comments": "8 pages, 5 figures", "journal-ref": "Proceedings of 21st International Teletraffic Congress (ITC 21),\n  2009", "doi": null, "report-no": null, "categories": "cs.PF cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper addresses the following foundational question: what is the maximum\ntheoretical delay performance achievable by an overlay peer-to-peer streaming\nsystem where the streamed content is subdivided into chunks? As shown in this\npaper, when posed for chunk-based systems, and as a consequence of the\nstore-and-forward way in which chunks are delivered across the network, this\nquestion has a fundamentally different answer with respect to the case of\nsystems where the streamed content is distributed through one or more flows\n(sub-streams). To circumvent the complexity emerging when directly dealing with\ndelay, we express performance in term of a convenient metric, called \"stream\ndiffusion metric\". We show that it is directly related to the end-to-end\nminimum delay achievable in a P2P streaming network. In a homogeneous scenario,\nwe derive a performance bound for such metric, and we show how this bound\nrelates to two fundamental parameters: the upload bandwidth available at each\nnode, and the number of neighbors a node may deliver chunks to. In this bound,\nk-step Fibonacci sequences do emerge, and appear to set the fundamental laws\nthat characterize the optimal operation of chunk-based systems.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2009 10:05:48 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2010 17:56:48 GMT"}], "update_date": "2010-02-01", "authors_parsed": [["Bianchi", "Giuseppe", ""], ["Melazzi", "Nicola Blefari", ""], ["Bracciale", "Lorenzo", ""], ["Piccolo", "Francesca Lo", ""], ["Salsano", "Stefano", ""]]}, {"id": "0902.1884", "submitter": "Georg Hager", "authors": "Markus Wittmann and Georg Hager", "title": "A Proof of Concept for Optimizing Task Parallelism by Locality Queues", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task parallelism as employed by the OpenMP task construct, although ideal for\ntackling irregular problems or typical producer/consumer schemes, bears some\npotential for performance bottlenecks if locality of data access is important,\nwhich is typically the case for memory-bound code on ccNUMA systems. We present\na programming technique which ameliorates adverse effects of dynamic task\ndistribution by sorting tasks into locality queues, each of which is preferably\nprocessed by threads that belong to the same locality domain. Dynamic\nscheduling is fully preserved inside each domain, and is preferred over\npossible load imbalance even if non-local access is required. The effectiveness\nof the approach is demonstrated using a blocked six-point stencil solver as a\ntoy model.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2009 13:51:27 GMT"}], "update_date": "2009-02-12", "authors_parsed": [["Wittmann", "Markus", ""], ["Hager", "Georg", ""]]}, {"id": "0902.2736", "submitter": "Publications Loria", "authors": "Florian Horn", "title": "Random Fruits on the Zielonka Tree", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science - STACS 2009 (2009) 541-552", "doi": null, "report-no": null, "categories": "cs.GT cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic games are a natural model for the synthesis of controllers\nconfronted to adversarial and/or random actions. In particular,\n$\\omega$-regular games of infinite length can represent reactive systems which\nare not expected to reach a correct state, but rather to handle a continuous\nstream of events. One critical resource in such applications is the memory used\nby the controller. In this paper, we study the amount of memory that can be\nsaved through the use of randomisation in strategies, and present matching\nupper and lower bounds for stochastic Muller games.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2009 14:26:36 GMT"}], "update_date": "2009-02-17", "authors_parsed": [["Horn", "Florian", ""]]}, {"id": "0902.3065", "submitter": "Giuliano Casale", "authors": "Giuliano Casale", "title": "The Multi-Branched Method of Moments for Queueing Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new exact solution algorithm for closed multiclass product-form\nqueueing networks that is several orders of magnitude faster and less memory\nconsuming than established methods for multiclass models, such as the Mean\nValue Analysis (MVA) algorithm. The technique is an important generalization of\nthe recently proposed Method of Moments (MoM) which, differently from MVA,\nrecursively computes higher-order moments of queue-lengths instead of mean\nvalues.\n  The main contribution of this paper is to prove that the information used in\nthe MoM recursion can be increased by considering multiple recursive branches\nthat evaluate models with different number of queues. This reformulation allows\nto formulate a simpler matrix difference equation which leads to large\ncomputational savings with respect to the original MoM recursion. Computational\nanalysis shows several cases where the proposed algorithm is between 1,000 and\n10,000 times faster and less memory consuming than the original MoM, thus\nextending the range of multiclass models where exact solutions are feasible.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2009 07:48:34 GMT"}], "update_date": "2009-02-19", "authors_parsed": [["Casale", "Giuliano", ""]]}, {"id": "0902.4481", "submitter": "Jian Tan", "authors": "Predrag R. Jelenkovic and Jian Tan", "title": "Stability of Finite Population ALOHA with Variable Packets", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "EE2009-02-20", "categories": "cs.PF cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ALOHA is one of the most basic Medium Access Control (MAC) protocols and\nrepresents a foundation for other more sophisticated distributed and\nasynchronous MAC protocols, e.g., CSMA. In this paper, unlike in the\ntraditional work that focused on mean value analysis, we study the\ndistributional properties of packet transmission delays over an ALOHA channel.\nWe discover a new phenomenon showing that a basic finite population ALOHA model\nwith variable size (exponential) packets is characterized by power law\ntransmission delays, possibly even resulting in zero throughput. These results\nare in contrast to the classical work that shows exponential delays and\npositive throughput for finite population ALOHA with fixed packets.\nFurthermore, we characterize a new stability condition that is entirely derived\nfrom the tail behavior of the packet and backoff distributions that may not be\ndetermined by mean values. The power law effects and the possible instability\nmight be diminished, or perhaps eliminated, by reducing the variability of\npackets. However, we show that even a slotted (synchronized) ALOHA with packets\nof constant size can exhibit power law delays when the number of active users\nis random. From an engineering perspective, our results imply that the\nvariability of packet sizes and number of active users need to be taken into\nconsideration when designing robust MAC protocols, especially for ad-hoc/sensor\nnetworks where other factors, such as link failures and mobility, might further\ncompound the problem.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2009 22:59:58 GMT"}, {"version": "v2", "created": "Thu, 26 Feb 2009 22:34:03 GMT"}], "update_date": "2009-02-27", "authors_parsed": [["Jelenkovic", "Predrag R.", ""], ["Tan", "Jian", ""]]}, {"id": "0902.4527", "submitter": "Nikolaos Livathinos", "authors": "Nikolaos S. Livathinos", "title": "EXtensible Animator for Mobile Simulations: EXAMS", "comments": "9 pages with 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most widely used simulation environments for mobile wireless\nnetworks is the Network Simulator 2 (NS-2). However NS-2 stores its outcome in\na text file, so there is a need for a visualization tool to animate the\nsimulation of the wireless network. The purpose of this tool is to help the\nresearcher examine in detail how the wireless protocol works both on a network\nand a node basis. It is clear that much of this information is protocol\ndependent and cannot be depicted properly by a general purpose animation\nprocess. Existing animation tools do not provide this level of information\nneither permit the specific protocol to control the animation at all. EXAMS is\nan NS-2 visualization tool for mobile simulations which makes possible the\nportrayal of NS-2 internal information like transmission properties and node\ndata structures. This is mainly possible due to EXAMS extensible architecture\nwhich separates the animation process into a general and a protocol specific\npart. The latter can be developed independently by the protocol designer and\nloaded on demand. These and other useful characteristics of the EXAMS tool can\nbe an invaluable help for a researcher in order to investigate and debug a\nmobile networking protocol.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2009 08:03:30 GMT"}], "update_date": "2009-02-27", "authors_parsed": [["Livathinos", "Nikolaos S.", ""]]}, {"id": "0902.4822", "submitter": "Xavier Grehant", "authors": "Xavier Grehant and Sverre Jarp", "title": "Lightweight Task Analysis for Cache-Aware Scheduling on Heterogeneous\n  Clusters", "comments": "The paper was originally published in: ISBN #: 1-60132-084-1 (a\n  two-volume set) Proceedings of the 2008 International Conference on Parallel\n  and Distributed Processing Techniques and Applications (PDPTA'08) Editors:\n  Hamid R. Arabnia and Youngsong Mun", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel characterization of how a program stresses cache. This\ncharacterization permits fast performance prediction in order to simulate and\nassist task scheduling on heterogeneous clusters. It is based on the estimation\nof stack distance probability distributions. The analysis requires the\nobservation of a very small subset of memory accesses, and yields a reasonable\nto very accurate prediction in constant time.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2009 12:47:22 GMT"}], "update_date": "2009-03-02", "authors_parsed": [["Grehant", "Xavier", ""], ["Jarp", "Sverre", ""]]}]