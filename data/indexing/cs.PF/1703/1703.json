[{"id": "1703.00849", "submitter": "Anastasios Giovanidis", "authors": "Luis David Alvarez Corrales, Anastasios Giovanidis, Philippe Martins,\n  Laurent Decreusefond", "title": "Wireless Node Cooperation with Resource Availability Constraints", "comments": "submitted, 12 pages, double-column, 7 figures, 8 sub-figures in total", "journal-ref": null, "doi": "10.23919/WIOPT.2017.7959946", "report-no": null, "categories": "cs.NI cs.IT cs.PF math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Base station cooperation is a promising scheme to improve network performance\nfor next generation cellular networks. Up to this point research has focused on\nstation grouping criteria based solely on geographic proximity. However, for\nthe cooperation to be meaningful, each station participating in a group should\nhave sufficient available resources to share with others. In this work we\nconsider an alternative grouping criterion based on a distance that considers\nboth geographic proximity and available resources of the stations. When the\nnetwork is modelled by a Poisson Point Process, we derive analytical formulas\non the proportion of cooperative pairs or single stations, and the expected sum\ninterference from each of the groups. The results illustrate that cooperation\ngains strongly depend on the distribution of available resources over the\nnetwork.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 16:29:46 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Corrales", "Luis David Alvarez", ""], ["Giovanidis", "Anastasios", ""], ["Martins", "Philippe", ""], ["Decreusefond", "Laurent", ""]]}, {"id": "1703.02788", "submitter": "Enrico Calore", "authors": "Enrico Calore, Alessandro Gabbana, Sebastiano Fabio Schifano, Raffaele\n  Tripiccione", "title": "Evaluation of DVFS techniques on modern HPC processors and accelerators\n  for energy-aware applications", "comments": null, "journal-ref": null, "doi": "10.1002/cpe.4143", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy efficiency is becoming increasingly important for computing systems,\nin particular for large scale HPC facilities. In this work we evaluate, from an\nuser perspective, the use of Dynamic Voltage and Frequency Scaling (DVFS)\ntechniques, assisted by the power and energy monitoring capabilities of modern\nprocessors in order to tune applications for energy efficiency. We run selected\nkernels and a full HPC application on two high-end processors widely used in\nthe HPC context, namely an NVIDIA K80 GPU and an Intel Haswell CPU. We evaluate\nthe available trade-offs between energy-to-solution and time-to-solution,\nattempting a function-by-function frequency tuning. We finally estimate the\nbenefits obtainable running the full code on a HPC multi-GPU node, with respect\nto default clock frequency governors. We instrument our code to accurately\nmonitor power consumption and execution time without the need of any additional\nhardware, and we enable it to change CPUs and GPUs clock frequencies while\nrunning. We analyze our results on the different architectures using a simple\nenergy-performance model, and derive a number of energy saving strategies which\ncan be easily adopted on recent high-end HPC systems for generic applications.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 11:13:24 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Calore", "Enrico", ""], ["Gabbana", "Alessandro", ""], ["Schifano", "Sebastiano Fabio", ""], ["Tripiccione", "Raffaele", ""]]}, {"id": "1703.02873", "submitter": "Pansy Arafa", "authors": "Pansy Arafa, Hany Kashif, and Sebastian Fischmeister", "title": "Redundancy Suppression In Time-Aware Dynamic Binary Instrumentation", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software tracing techniques are well-established and used by instrumentation\ntools to extract run-time information for program analysis and debugging.\nDynamic binary instrumentation as one tool instruments program binaries to\nextract information. Unfortunately, instrumentation causes perturbation that is\nunacceptable for time-sensitive applications. Consequently we developed DIME*,\na tool for dynamic binary instrumentation that considers timing constraints.\nDIME* uses Pin and a rate-based server approach to extract information only as\nlong as user-specified constraints are maintained. Due to the large amount of\nredundancies in program traces, DIME* reduces the instrumentation overhead by\none to three orders of magnitude compared to native Pin while extracting up to\n99% of the information. We instrument VLC and PostgreSQL to demonstrate the\nusability of DIME*.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 14:40:58 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Arafa", "Pansy", ""], ["Kashif", "Hany", ""], ["Fischmeister", "Sebastian", ""]]}, {"id": "1703.06042", "submitter": "Sascha Van Cauwelaert", "authors": "Sascha Van Cauwelaert, Michele Lombardi and Pierre Schaus", "title": "A Visual Web Tool to Perform What-If Analysis of Optimization Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Operation Research, practical evaluation is essential to validate the\nefficacy of optimization approaches. This paper promotes the usage of\nperformance profiles as a standard practice to visualize and analyze\nexperimental results. It introduces a Web tool to construct and export\nperformance profiles as SVG or HTML files. In addition, the application relies\non a methodology to estimate the benefit of hypothetical solver improvements.\nTherefore, the tool allows one to employ what-if analysis to screen possible\nresearch directions, and identify those having the best potential. The approach\nis showcased on two Operation Research technologies: Constraint Programming and\nMixed Integer Linear Programming.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 12:53:52 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Van Cauwelaert", "Sascha", ""], ["Lombardi", "Michele", ""], ["Schaus", "Pierre", ""]]}, {"id": "1703.06503", "submitter": "Cedric Nugteren", "authors": "Cedric Nugteren and Valeriu Codreanu", "title": "CLTune: A Generic Auto-Tuner for OpenCL Kernels", "comments": "8 pages, published in MCSoC '15, IEEE 9th International Symposium on\n  Embedded Multicore/Many-core Systems-on-Chip (MCSoC), 2015", "journal-ref": null, "doi": "10.1109/MCSoC.2015.10", "report-no": null, "categories": "cs.PF cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents CLTune, an auto-tuner for OpenCL kernels. It evaluates and\ntunes kernel performance of a generic, user-defined search space of possible\nparameter-value combinations. Example parameters include the OpenCL workgroup\nsize, vector data-types, tile sizes, and loop unrolling factors. CLTune can be\nused in the following scenarios: 1) when there are too many tunable parameters\nto explore manually, 2) when performance portability across OpenCL devices is\ndesired, or 3) when the optimal parameters change based on input argument\nvalues (e.g. matrix dimensions). The auto-tuner is generic, easy to use,\nopen-source, and supports multiple search strategies including simulated\nannealing and particle swarm optimisation. CLTune is evaluated on two GPU\ncase-studies inspired by the recent successes in deep learning: 2D convolution\nand matrix-multiplication (GEMM). For 2D convolution, we demonstrate the need\nfor auto-tuning by optimizing for different filter sizes, achieving performance\non-par or better than the state-of-the-art. For matrix-multiplication, we use\nCLTune to explore a parameter space of more than two-hundred thousand\nconfigurations, we show the need for device-specific tuning, and outperform the\nclBLAS library on NVIDIA, AMD and Intel GPUs.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 20:10:00 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Nugteren", "Cedric", ""], ["Codreanu", "Valeriu", ""]]}, {"id": "1703.08219", "submitter": "Tiark Rompf", "authors": "Gr\\'egory M. Essertel, Ruby Y. Tahboub, James M. Decker, Kevin J.\n  Brown, Kunle Olukotun, Tiark Rompf", "title": "Flare: Native Compilation for Heterogeneous Workloads in Apache Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for modern data analytics to combine relational, procedural, and\nmap-reduce-style functional processing is widely recognized. State-of-the-art\nsystems like Spark have added SQL front-ends and relational query optimization,\nwhich promise an increase in expressiveness and performance. But how good are\nthese extensions at extracting high performance from modern hardware platforms?\n  While Spark has made impressive progress, we show that for relational\nworkloads, there is still a significant gap compared with best-of-breed query\nengines. And when stepping outside of the relational world, query optimization\ntechniques are ineffective if large parts of a computation have to be treated\nas user-defined functions (UDFs).\n  We present Flare: a new back-end for Spark that brings performance closer to\nthe best SQL engines, without giving up the added expressiveness of Spark. We\ndemonstrate order of magnitude speedups both for relational workloads such as\nTPC-H, as well as for a range of machine learning kernels that combine\nrelational and iterative functional processing.\n  Flare achieves these results through (1) compilation to native code, (2)\nreplacing parts of the Spark runtime system, and (3) extending the scope of\noptimization and code generation to large classes of UDFs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 20:04:55 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Essertel", "Gr\u00e9gory M.", ""], ["Tahboub", "Ruby Y.", ""], ["Decker", "James M.", ""], ["Brown", "Kevin J.", ""], ["Olukotun", "Kunle", ""], ["Rompf", "Tiark", ""]]}, {"id": "1703.08228", "submitter": "Craig Blackmore", "authors": "Craig Blackmore, Oliver Ray, Kerstin Eder", "title": "Automatically Tuning the GCC Compiler to Optimize the Performance of\n  Applications Running on Embedded Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel method for automatically tuning the selection\nof compiler flags to optimize the performance of software intended to run on\nembedded hardware platforms. We begin by developing our approach on code\ncompiled by the GNU C Compiler (GCC) for the ARM Cortex-M3 (CM3) processor; and\nwe show how our method outperforms the industry standard -O3 optimization level\nacross a diverse embedded benchmark suite. First we quantify the potential\ngains by using existing iterative compilation approaches that time-intensively\nsearch for optimal configurations for each benchmark. Then we adapt iterative\ncompilation to output a single configuration that optimizes performance across\nthe entire benchmark suite. Although this is a time-consuming process, our\napproach constructs an optimized variation of -O3, which we call -Ocm3, that\nrealizes nearly two thirds of known available gains on the CM3 and\nsignificantly outperforms a more complex state-of-the-art predictive method in\ncross-validation experiments. Finally, we demonstrate our method on additional\nplatforms by constructing two more optimization levels that find even more\nsignificant speed-ups on the ARM Cortex-A8 and 8-bit AVR processors.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 17:36:08 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 15:17:59 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Blackmore", "Craig", ""], ["Ray", "Oliver", ""], ["Eder", "Kerstin", ""]]}, {"id": "1703.08373", "submitter": "Debankur Mukherjee", "authors": "Debankur Mukherjee, Souvik Dhara, Sem Borst, and Johan S. H. van\n  Leeuwaarden", "title": "Optimal Service Elasticity in Large-Scale Distributed Systems", "comments": "Accepted in ACM SIGMETRICS, Urbana-Champaign, Illinois, USA, 2017", "journal-ref": "Proc. ACM Meas. Anal. Comput. Syst. 1 1 (2017)", "doi": "10.1145/3084463", "report-no": null, "categories": "math.PR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in large-scale cloud networks and data centers is to\nachieve highly efficient server utilization and limit energy consumption, while\nproviding excellent user-perceived performance in the presence of uncertain and\ntime-varying demand patterns. Auto-scaling provides a popular paradigm for\nautomatically adjusting service capacity in response to demand while meeting\nperformance targets, and queue-driven auto-scaling techniques have been widely\ninvestigated in the literature. In typical data center architectures and cloud\nenvironments however, no centralized queue is maintained, and load balancing\nalgorithms immediately distribute incoming tasks among parallel queues. In\nthese distributed settings with vast numbers of servers, centralized\nqueue-driven auto-scaling techniques involve a substantial communication\noverhead and major implementation burden, or may not even be viable at all.\n  Motivated by the above issues, we propose a joint auto-scaling and load\nbalancing scheme which does not require any global queue length information or\nexplicit knowledge of system parameters, and yet provides provably near-optimal\nservice elasticity. We establish the fluid-level dynamics for the proposed\nscheme in a regime where the total traffic volume and nominal service capacity\ngrow large in proportion. The fluid-limit results show that the proposed scheme\nachieves asymptotic optimality in terms of user-perceived delay performance as\nwell as energy consumption. Specifically, we prove that both the waiting time\nof tasks and the relative energy portion consumed by idle servers vanish in the\nlimit. At the same time, the proposed scheme operates in a distributed fashion\nand involves only constant communication overhead per task, thus ensuring\nscalability in massive data center operations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 11:46:39 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Mukherjee", "Debankur", ""], ["Dhara", "Souvik", ""], ["Borst", "Sem", ""], ["van Leeuwaarden", "Johan S. H.", ""]]}, {"id": "1703.08823", "submitter": "Quan-Lin Li", "authors": "Na Li, Quan-Lin Li and Zhe George Zhang", "title": "Groups of Repairmen and Repair-based Load Balancing in Supermarket\n  Models with Repairable Servers", "comments": "48 pages; 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supermarket models are a class of interesting parallel queueing networks with\ndynamic randomized load balancing and real-time resource management. When the\nparallel servers are subject to breakdowns and repairs, analysis of such a\nsupermarket model becomes more difficult and challenging. In this paper, we\napply the mean-field theory to studying four interrelated supermarket models\nwith repairable servers, and numerically indicate impact of the different\nrepairman groups on performance of the systems. First, we set up the systems of\nmean-field equations for the supermarket models with repairable servers. Then\nwe prove the asymptotic independence of the supermarket models through the\noperator semi-group and the mean-field limit. Furthermore, we show that the\nfixed points of the supermarket models satisfy the systems of nonlinear\nequations. Finally, we use the fixed points to give numerical computation for\nperformer analysis, and provide valuable observations on model improvement.\nTherefore, this paper provides a new and effective method in the study of\ncomplex supermarket models.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 15:13:36 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Li", "Na", ""], ["Li", "Quan-Lin", ""], ["Zhang", "Zhe George", ""]]}]