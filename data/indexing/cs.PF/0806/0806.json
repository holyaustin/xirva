[{"id": "0806.1139", "submitter": "Miguel Andres", "authors": "Miguel E. Andres, Pedro D'Argenio, Peter van Rossum", "title": "Significant Diagnostic Counterexamples in Probabilistic Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel technique for counterexample generation in\nprobabilistic model checking of Markov Chains and Markov Decision Processes.\n(Finite) paths in counterexamples are grouped together in witnesses that are\nlikely to provide similar debugging information to the user. We list five\nproperties that witnesses should satisfy in order to be useful as debugging\naid: similarity, accuracy, originality, significance, and finiteness. Our\nwitnesses contain paths that behave similar outside strongly connected\ncomponents.\n  This papers shows how to compute these witnesses by reducing the problem of\ngenerating counterexamples for general properties over Markov Decision\nProcesses, in several steps, to the easy problem of generating counterexamples\nfor reachability properties over acyclic Markov Chains.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2008 13:09:49 GMT"}], "update_date": "2008-06-09", "authors_parsed": [["Andres", "Miguel E.", ""], ["D'Argenio", "Pedro", ""], ["van Rossum", "Peter", ""]]}, {"id": "0806.4627", "submitter": "Thomas Hornung", "authors": "Michael Schmidt, Thomas Hornung, Georg Lausen, Christoph Pinkel", "title": "SP2Bench: A SPARQL Performance Benchmark", "comments": "Conference paper to appear in Proc. ICDE'09", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the SPARQL query language for RDF has reached the W3C\nrecommendation status. In response to this emerging standard, the database\ncommunity is currently exploring efficient storage techniques for RDF data and\nevaluation strategies for SPARQL queries. A meaningful analysis and comparison\nof these approaches necessitates a comprehensive and universal benchmark\nplatform. To this end, we have developed SP^2Bench, a publicly available,\nlanguage-specific SPARQL performance benchmark. SP^2Bench is settled in the\nDBLP scenario and comprises both a data generator for creating arbitrarily\nlarge DBLP-like documents and a set of carefully designed benchmark queries.\nThe generated documents mirror key characteristics and social-world\ndistributions encountered in the original DBLP data set, while the queries\nimplement meaningful requests on top of this data, covering a variety of SPARQL\noperator constellations and RDF access patterns. As a proof of concept, we\napply SP^2Bench to existing engines and discuss their strengths and weaknesses\nthat follow immediately from the benchmark results.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2008 15:31:26 GMT"}, {"version": "v2", "created": "Tue, 21 Oct 2008 14:44:17 GMT"}], "update_date": "2008-10-21", "authors_parsed": [["Schmidt", "Michael", ""], ["Hornung", "Thomas", ""], ["Lausen", "Georg", ""], ["Pinkel", "Christoph", ""]]}]