[{"id": "1303.0038", "submitter": "Vijay Kamble", "authors": "Vijay Kamble and Jean Walrand", "title": "Approximately Optimal Scheduling of an M/G/1 Queue with Heavy Tails", "comments": null, "journal-ref": "Queueing Systems, Volume 80, Issue 3, pp 261-271, 2015", "doi": "10.1007/s11134-015-9435-0", "report-no": null, "categories": "math.PR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributions with a heavy tail are difficult to estimate. If the design of a\nscheduling policy is sensitive to the details of heavy tail distributions of\nthe service times, an approximately optimal solution is difficult to obtain.\nThis paper shows that the optimal scheduling of an M/G/1 queue with heavy\ntailed service times does not present this difficulty and that an approximately\noptimal strategy can be derived by truncating the distributions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 22:54:52 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2013 11:00:48 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2015 21:13:52 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Kamble", "Vijay", ""], ["Walrand", "Jean", ""]]}, {"id": "1303.1561", "submitter": "Yanpei Liu", "authors": "Yanpei Liu and Stark C. Draper and Nam Sung Kim", "title": "Queuing Theoretic Analysis of Power-performance Tradeoff in\n  Power-efficient Computing", "comments": "Paper published in CISS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the power-performance relationship of power-efficient\ncomputing from a queuing theoretic perspective. We investigate the interplay of\nseveral system operations including processing speed, system on/off decisions,\nand server farm size. We identify that there are oftentimes \"sweet spots\" in\npower-efficient operations: there exist optimal combinations of processing\nspeed and system settings that maximize power efficiency. For the single server\ncase, a widely deployed threshold mechanism is studied. We show that there\nexist optimal processing speed and threshold value pairs that minimize the\npower consumption. This holds for the threshold mechanism with job batching.\nFor the multi-server case, it is shown that there exist best processing speed\nand server farm size combinations.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2013 22:24:37 GMT"}], "update_date": "2013-03-08", "authors_parsed": [["Liu", "Yanpei", ""], ["Draper", "Stark C.", ""], ["Kim", "Nam Sung", ""]]}, {"id": "1303.1651", "submitter": "Georg Hager", "authors": "Tobias Scharpff, Klaus Iglberger, Georg Hager, Ulrich Ruede", "title": "Model-guided Performance Analysis of the Sparse Matrix-Matrix\n  Multiplication", "comments": "8 pages, 12 figures. Small corrections w.r.t. previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving high efficiency with numerical kernels for sparse matrices is of\nutmost importance, since they are part of many simulation codes and tend to use\nmost of the available compute time and resources. In addition, especially in\nlarge scale simulation frameworks the readability and ease of use of\nmathematical expressions are essential components for the continuous\nmaintenance, modification, and extension of software. In this context, the\nsparse matrix-matrix multiplication is of special interest. In this paper we\nthoroughly analyze the single-core performance of sparse matrix-matrix\nmultiplication kernels in the Blaze Smart Expression Template (SET) framework.\nWe develop simple models for estimating the achievable maximum performance, and\nuse them to assess the efficiency of our implementations. Additionally, we\ncompare these kernels with several commonly used SET-based C++ libraries,\nwhich, just as Blaze, aim at combining the requirements of high performance\nwith an elegant user interface. For the different sparse matrix structures\nconsidered here, we show that our implementations are competitive or faster\nthan those of the other SET libraries for most problem sizes on a current Intel\nmulticore processor.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 11:40:27 GMT"}, {"version": "v2", "created": "Mon, 6 May 2013 07:43:45 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Scharpff", "Tobias", ""], ["Iglberger", "Klaus", ""], ["Hager", "Georg", ""], ["Ruede", "Ulrich", ""]]}, {"id": "1303.3026", "submitter": "Yuming Jiang", "authors": "Yuming Jiang", "title": "Stochastic Service Curve and Delay Bound Analysis: A Single Node Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A packet-switched network node with constant capacity (in bps) is considered,\nwhere packets within each flow are served in the first in first out (FIFO)\nmanner. While this single node system is perhaps the simplest computer\ncommunication system, its stochastic service curve characterization and\nindependent case analysis in the context of stochastic network calculus\n(snetcal) are still basic and many crucial questions surprisingly remain open.\nSpecifically, when the input is a single flow, what stochastic service curve\nand delay bound does the node provide? When the considered flow shares the node\nwith another flow, what stochastic service curve and delay bound does the node\nprovide to the considered flow, and if the two flows are independent, can this\nindependence be made use of and how? The aim of this paper is to provide\nanswers to these fundamental questions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 20:59:46 GMT"}], "update_date": "2013-03-14", "authors_parsed": [["Jiang", "Yuming", ""]]}, {"id": "1303.3632", "submitter": "Nikzad Babaii-Rizvandi", "authors": "Nikzad Babaii Rizvandi, Javid Taheri, Reza Moraveji, Albert Y. Zomaya", "title": "Statistical Regression to Predict Total Cumulative CPU Usage of\n  MapReduce Jobs", "comments": "16 pages- previously published as \"On Modelling and Prediction of\n  Total CPU Usage for Applications in MapReduce Enviornments\" in IEEE 12th\n  International Conference on Algorithms and Architectures for Parallel\n  Processing (ICA3PP-12), Fukuoka, Japan, 4-7 September, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, businesses have started using MapReduce as a popular computation\nframework for processing large amount of data, such as spam detection, and\ndifferent data mining tasks, in both public and private clouds. Two of the\nchallenging questions in such environments are (1) choosing suitable values for\nMapReduce configuration parameters e.g., number of mappers, number of reducers,\nand DFS block size, and (2) predicting the amount of resources that a user\nshould lease from the service provider. Currently, the tasks of both choosing\nconfiguration parameters and estimating required resources are solely the users\nresponsibilities. In this paper, we present an approach to provision the total\nCPU usage in clock cycles of jobs in MapReduce environment. For a MapReduce\njob, a profile of total CPU usage in clock cycles is built from the job past\nexecutions with different values of two configuration parameters e.g., number\nof mappers, and number of reducers. Then, a polynomial regression is used to\nmodel the relation between these configuration parameters and total CPU usage\nin clock cycles of the job. We also briefly study the influence of input data\nscaling on measured total CPU usage in clock cycles. This derived model along\nwith the scaling result can then be used to provision the total CPU usage in\nclock cycles of the same jobs with different input data size. We validate the\naccuracy of our models using three realistic applications (WordCount, Exim\nMainLog parsing, and TeraSort). Results show that the predicted total CPU usage\nin clock cycles of generated resource provisioning options are less than 8% of\nthe measured total CPU usage in clock cycles in our 20-node virtual Hadoop\ncluster.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2013 22:40:32 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Rizvandi", "Nikzad Babaii", ""], ["Taheri", "Javid", ""], ["Moraveji", "Reza", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "1303.4114", "submitter": "Florin Ciucu", "authors": "Florin Ciucu, Felix Poloczek and Jens Schmitt", "title": "Sharp Bounds in Stochastic Network Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practicality of the stochastic network calculus (SNC) is often questioned\non grounds of potential looseness of its performance bounds. In this paper it\nis uncovered that for bursty arrival processes (specifically Markov-Modulated\nOn-Off (MMOO)), whose amenability to \\textit{per-flow} analysis is typically\nproclaimed as a highlight of SNC, the bounds can unfortunately indeed be very\nloose (e.g., by several orders of magnitude off). In response to this uncovered\nweakness of SNC, the (Standard) per-flow bounds are herein improved by deriving\na general sample-path bound, using martingale based techniques, which\naccommodates FIFO, SP, EDF, and GPS scheduling. The obtained (Martingale)\nbounds gain an exponential decay factor of ${\\mathcal{O}}(e^{-\\alpha n})$ in\nthe number of flows $n$. Moreover, numerical comparisons against simulations\nshow that the Martingale bounds are remarkably accurate for FIFO, SP, and EDF\nscheduling; for GPS scheduling, although the Martingale bounds substantially\nimprove the Standard bounds, they are numerically loose, demanding for\nimprovements in the core SNC analysis of GPS.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2013 22:14:36 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2013 13:43:49 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Ciucu", "Florin", ""], ["Poloczek", "Felix", ""], ["Schmitt", "Jens", ""]]}, {"id": "1303.4538", "submitter": "Georg Hager", "authors": "Christoph Scheit, Georg Hager, Jan Treibig, Stefan Becker, Gerhard\n  Wellein", "title": "Optimization of FASTEST-3D for Modern Multicore Systems", "comments": "10 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FASTEST-3D is an MPI-parallel finite-volume flow solver based on\nblock-structured meshes that has been developed at the University of\nErlangen-Nuremberg since the early 1990s. It can be used to solve the laminar\nor turbulent incompressible Navier-Stokes equations. Up to now its scalability\nwas strongly limited by a rather rigid communication infrastructure, which led\nto a dominance of MPI time already at small process counts.\n  This paper describes several optimizations to increase the performance,\nscalability, and flexibility of FASTEST-3D. First, a node-level performance\nanalysis is carried out in order to pinpoint the main bottlenecks and identify\nsweet spots for energy-efficient execution. In addition, a single-precision\nversion of the solver for the linear equation system arising from the\ndiscretization of the governing equations is devised, which significantly\nincreases the single-core performance. Then the communication mechanisms in\nFASTEST-3D are analyzed and a new communication strategy based on non-blocking\ncalls is implemented. Performance results with the revised version show\nsignificantly increased single-node performance and considerably improved\ncommunication patterns along with much better parallel scalability. In this\ncontext we discuss the concept of \"acceptable parallel efficiency\" and how it\ninfluences the real gain of the optimizations. Scaling measurements are carried\nout on a modern petascale system. The obtained improvements are of major\nimportance for the use of FASTEST-3D on current high-performance computer\nclusters and will help to perform simulations with much higher spatial and\ntemporal resolution to tackle turbulent flow in technical applications.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2013 10:18:40 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Scheit", "Christoph", ""], ["Hager", "Georg", ""], ["Treibig", "Jan", ""], ["Becker", "Stefan", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1303.4816", "submitter": "Yongkun Li", "authors": "Yongkun Li, Patrick P.C. Lee, John C.S. Lui", "title": "Stochastic Modeling of Large-Scale Solid-State Storage Systems:\n  Analysis, Design Tradeoffs and Optimization", "comments": "14 pages, Sigmetrics 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solid state drives (SSDs) have seen wide deployment in mobiles, desktops, and\ndata centers due to their high I/O performance and low energy consumption. As\nSSDs write data out-of-place, garbage collection (GC) is required to erase and\nreclaim space with invalid data. However, GC poses additional writes that\nhinder the I/O performance, while SSD blocks can only endure a finite number of\nerasures. Thus, there is a performance-durability tradeoff on the design space\nof GC. To characterize the optimal tradeoff, this paper formulates an\nanalytical model that explores the full optimal design space of any GC\nalgorithm. We first present a stochastic Markov chain model that captures the\nI/O dynamics of large-scale SSDs, and adapt the mean-field approach to derive\nthe asymptotic steady-state performance. We further prove the model convergence\nand generalize the model for all types of workload. Inspired by this model, we\npropose a randomized greedy algorithm (RGA) that can operate along the optimal\ntradeoff curve with a tunable parameter. Using trace-driven simulation on\nDiskSim with SSD add-ons, we demonstrate how RGA can be parameterized to\nrealize the performance-durability tradeoff.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 02:46:43 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2013 03:39:20 GMT"}], "update_date": "2013-03-22", "authors_parsed": [["Li", "Yongkun", ""], ["Lee", "Patrick P. C.", ""], ["Lui", "John C. S.", ""]]}, {"id": "1303.6485", "submitter": "James Pallister", "authors": "James Pallister, Simon Hollis, Jeremy Bennett", "title": "Identifying Compiler Options to Minimise Energy Consumption for Embedded\n  Platforms", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": "10.1093/comjnl/bxt129", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an analysis of the energy consumption of an extensive\nnumber of the optimisations a modern compiler can perform. Using GCC as a test\ncase, we evaluate a set of ten carefully selected benchmarks for five different\nembedded platforms.\n  A fractional factorial design is used to systematically explore the large\noptimisation space (2^82 possible combinations), whilst still accurately\ndetermining the effects of optimisations and optimisation combinations.\nHardware power measurements on each platform are taken to ensure all\narchitectural effects on the energy consumption are captured.\n  We show that fractional factorial design can find more optimal combinations\nthan relying on built in compiler settings. We explore the relationship between\nrun-time and energy consumption, and identify scenarios where they are and are\nnot correlated.\n  A further conclusion of this study is the structure of the benchmark has a\nlarger effect than the hardware architecture on whether the optimisation will\nbe effective, and that no single optimisation is universally beneficial for\nexecution time or energy consumption.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 13:31:34 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2013 15:14:26 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Pallister", "James", ""], ["Hollis", "Simon", ""], ["Bennett", "Jeremy", ""]]}]