[{"id": "2007.00279", "submitter": "Zihan Jiang", "authors": "Zihan Jiang, Lei Wang, Xingwang Xiong, Wanling Gao, Chunjie Luo, Fei\n  Tang, Chuanxin Lan, Hongxiao Li, and Jianfeng Zhan", "title": "HPC AI500: The Methodology, Tools, Roofline Performance Models, and\n  Metrics for Benchmarking HPC AI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent years witness a trend of applying large-scale distributed deep\nlearning in both business and scientific computing areas, whose goal is to\nspeed up the training time to achieve a state-of-the-art quality. The HPC\ncommunity feels a great interest in building the HPC AI systems that are\ndedicated to running those workloads. The HPC AI benchmarks accelerate the\nprocess. Unfortunately, benchmarking HPC AI systems at scale raises serious\nchallenges. None of previous HPC AI benchmarks achieve the goal of being\nequivalent, relevant, representative, affordable, and repeatable. This paper\npresents a comprehensive methodology, tools, Roofline performance models, and\ninnovative metrics for benchmarking, optimizing, and ranking HPC AI systems,\nwhich we call HPC AI500 V2.0. We abstract the HPC AI system into nine\nindependent layers, and present explicit benchmarking rules and procedures to\nassure equivalence of each layer, repeatability, and replicability. On the\nbasis of AIBench -- by far the most comprehensive AI benchmarks suite, we\npresent and build two HPC AI benchmarks from both business and scientific\ncomputing: Image Classification, and Extreme Weather Analytics, achieving both\nrepresentativeness and affordability. To rank the performance and\nenergy-efficiency of HPC AI systems, we propose Valid FLOPS, and Valid FLOPS\nper watt, which impose a penalty on failing to achieve the target quality. We\npropose using convolution and GEMM -- the two most intensively-used kernel\nfunctions to measure the upper bound performance of the HPC AI systems, and\npresent HPC AI roofline models for guiding performance optimizations. The\nevaluations show our methodology, benchmarks, performance models, and metrics\ncan measure, optimize, and rank the HPC AI systems in a scalable, simple, and\naffordable way. HPC AI500 V2.0 are publicly available from\nhttp://www.benchcouncil.org/benchhub/hpc-ai500-benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 07:10:53 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Jiang", "Zihan", ""], ["Wang", "Lei", ""], ["Xiong", "Xingwang", ""], ["Gao", "Wanling", ""], ["Luo", "Chunjie", ""], ["Tang", "Fei", ""], ["Lan", "Chuanxin", ""], ["Li", "Hongxiao", ""], ["Zhan", "Jianfeng", ""]]}, {"id": "2007.00541", "submitter": "Ramses Sala", "authors": "Ramses Sala and Ralf M\\\"uller", "title": "Benchmarking for Metaheuristic Black-Box Optimization: Perspectives and\n  Open Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.PF math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on new optimization algorithms is often funded based on the\nmotivation that such algorithms might improve the capabilities to deal with\nreal-world and industrially relevant optimization challenges. Besides a huge\nvariety of different evolutionary and metaheuristic optimization algorithms,\nalso a large number of test problems and benchmark suites have been developed\nand used for comparative assessments of algorithms, in the context of global,\ncontinuous, and black-box optimization. For many of the commonly used synthetic\nbenchmark problems or artificial fitness landscapes, there are however, no\nmethods available, to relate the resulting algorithm performance assessments to\ntechnologically relevant real-world optimization problems, or vice versa. Also,\nfrom a theoretical perspective, many of the commonly used benchmark problems\nand approaches have little to no generalization value. Based on a mini-review\nof publications with critical comments, advice, and new approaches, this\ncommunication aims to give a constructive perspective on several open\nchallenges and prospective research directions related to systematic and\ngeneralizable benchmarking for black-box optimization.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 15:09:40 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Sala", "Ramses", ""], ["M\u00fcller", "Ralf", ""]]}, {"id": "2007.01222", "submitter": "Alim Ul Gias", "authors": "Alim Ul Gias and Giuliano Casale", "title": "COCOA: Cold Start Aware Capacity Planning for Function-as-a-Service\n  Platforms", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function-as-a-Service (FaaS) is increasingly popular in the software industry\ndue to the implied cost-savings in event-driven workloads and its synergy with\nDevOps. To size an on-premise FaaS platform, it is important to estimate the\nrequired CPU and memory capacity to serve the expected loads. Given the\nservice-level agreements, it is however challenging to take the cold start\nissue into account during the sizing process. We have investigated the\nsimilarity of this problem with the hit rate improvement problem in TTL caches\nand concluded that solutions for TTL cache, although potentially applicable,\nlead to over-provisioning in FaaS. Thus, we propose a novel approach, COCOA, to\nsolve this issue. COCOA uses a queueing-based approach to assess the effect of\ncold starts on FaaS response times. It also considers different memory\nconsumption values depending on whether the function is idle or in execution.\nUsing an event-driven FaaS simulator, FaasSim, we have developed, we show that\nCOCOA can reduce over-provisioning by over 70% in some workloads, while\nsatisfying the service-level agreements.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 16:11:03 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Gias", "Alim Ul", ""], ["Casale", "Giuliano", ""]]}, {"id": "2007.01395", "submitter": "Suraj Padmanaban Kesavan", "authors": "Suraj P.Kesavan, Harsh Bhatia, Abhinav Bhatele, Todd Gamblin,\n  Peer-Timo Bremer and Kwan-Liu Ma", "title": "Scalable Comparative Visualization of Ensembles of Call Graphs", "comments": "12 pages, 6 figures, Submitted to IEEE VIS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimizing the performance of large-scale parallel codes is critical for\nefficient utilization of computing resources. Code developers often explore\nvarious execution parameters, such as hardware configurations, system software\nchoices, and application parameters, and are interested in detecting and\nunderstanding bottlenecks in different executions. They often collect\nhierarchical performance profiles represented as call graphs, which combine\nperformance metrics with their execution contexts. The crucial task of\nexploring multiple call graphs together is tedious and challenging because of\nthe many structural differences in the execution contexts and significant\nvariability in the collected performance metrics (e.g., execution runtime). In\nthis paper, we present an enhanced version of CallFlow to support the\nexploration of ensembles of call graphs using new types of visualizations,\nanalysis, graph operations, and features. We introduce ensemble-Sankey, a new\nvisual design that combines the strengths of resource-flow (Sankey) and\nbox-plot visualization techniques. Whereas the resource-flow visualization can\neasily and intuitively describe the graphical nature of the call graph, the box\nplots overlaid on the nodes of Sankey convey the performance variability within\nthe ensemble. Our interactive visual interface provides linked views to help\nexplore ensembles of call graphs, e.g., by facilitating the analysis of\nstructural differences, and identifying similar or distinct call graphs. We\ndemonstrate the effectiveness and usefulness of our design through case studies\non large-scale parallel codes.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 00:42:45 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Kesavan", "Suraj P.", ""], ["Bhatia", "Harsh", ""], ["Bhatele", "Abhinav", ""], ["Gamblin", "Todd", ""], ["Bremer", "Peer-Timo", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2007.01459", "submitter": "Quan-Lin Li", "authors": "Quan-Lin Li, Yan-Xia Chang, Xiaole Wu and Guoqing Zhang", "title": "A New Theoretical Framework of Pyramid Markov Processes for Blockchain\n  Selfish Mining", "comments": "76 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.PF math.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a new theoretical framework of pyramid Markov\nprocesses to solve some open and fundamental problems of blockchain selfish\nmining. To this end, we first describe a more general blockchain selfish mining\nwith both a two-block leading competitive criterion and a new economic\nincentive, and establish a pyramid Markov process to express the dynamic\nbehavior of the selfish mining from both consensus protocol and economic\nincentive. Then we show that the pyramid Markov process is stable and so is the\nblockchain, and its stationary probability vector is matrix-geometric with an\nexplicitly representable rate matrix. Furthermore, we use the stationary\nprobability vector to be able to analyze the waste of computational resource\ndue to generating a lot of orphan (or stale) blocks. Nextly, we set up a\npyramid Markov reward process to investigate the long-run average profits of\nthe honest and dishonest mining pools, respectively. Specifically, we show that\nthe long-run average profits are multivariate linear such that we can measure\nthe improvement of mining efficiency of the dishonest mining pool comparing to\nthe honest mining pool. As a by-product, we build three approximative Markov\nprocesses when the system states are described as the block-number difference\nof two forked block branches. Also, by using their special cases with non\nnetwork latency, we can further provide some useful interpretation for both the\nMarkov chain (Figure 1) and the revenue analysis ((1) to (3)) of the seminal\nwork by Eyal and Sirer (2014). Finally, we use some numerical examples to\nverify the correctness and computability of our theoretical results. We hope\nthat the methodology and results developed in this paper shed light on the\nblockchain selfish mining such that a series of promising research can be\nproduced potentially.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 02:02:35 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 16:58:57 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Li", "Quan-Lin", ""], ["Chang", "Yan-Xia", ""], ["Wu", "Xiaole", ""], ["Zhang", "Guoqing", ""]]}, {"id": "2007.01463", "submitter": "Yanting Chen", "authors": "Yanting Chen, Jingui Xie, Taozeng Zhu", "title": "Flexibility in an asymmetric system with prolonged service time at\n  non-dedicated servers", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prolonged service time at non-dedicated servers has been observed in [1].\nMotivated by such real problems, we propose a stylized model which\ncharacterizes the feature of the prolonged service time at non-dedicated\nservers in an asymmetric system. We study the independent system, the full\nflexibility system and the partial flexibility system when the occupation rate\nof the system, the degree of the prolonged service time and the degree of the\nasymmetry are allowed to change. We show that under certain circumstances, the\npartial flexibility scheme outperforms the full flexibility system and the\nindependent system in such a model. Our results also provide instructions on\nhow to introduce flexibility when the service time at non-dedicated servers is\nprolonged in an asymmetric system.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 02:31:09 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 06:49:22 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Chen", "Yanting", ""], ["Xie", "Jingui", ""], ["Zhu", "Taozeng", ""]]}, {"id": "2007.01820", "submitter": "Arash Fouman", "authors": "Arash Fouman Ajirlou, Inna Partin-Vaisband", "title": "A Machine Learning Pipeline Stage for Adaptive Frequency Adjustment", "comments": "12 pages, 8 figures, 5 tables, IEEE transaction on computers. arXiv\n  admin note: substantial text overlap with arXiv:2006.07450", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning (ML) design framework is proposed for adaptively adjusting\nclock frequency based on propagation delay of individual instructions. A random\nforest model is trained to classify propagation delays in real time, utilizing\ncurrent operation type, current operands, and computation history as ML\nfeatures. The trained model is implemented in Verilog as an additional pipeline\nstage within a baseline processor. The modified system is experimentally tested\nat the gate level in 45 nm CMOS technology, exhibiting a speedup of 70% and\nenergy reduction of 30% with coarse-grained ML classification. A speedup of 89%\nis demonstrated with finer granularities with 15.5% reduction in energy\nconsumption.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 07:55:08 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Ajirlou", "Arash Fouman", ""], ["Partin-Vaisband", "Inna", ""]]}, {"id": "2007.03410", "submitter": "Mahmoud Darwich", "authors": "Mahmoud Darwich, Yasser Ismail, Talal Darwich, Magdy Bayoumi", "title": "Cost-Efficient Storage for On-Demand Video Streaming on Cloud", "comments": "International IEEE World Forum for Internet of Things", "journal-ref": null, "doi": "10.1109/WF-IoT48130.2020.9221374", "report-no": null, "categories": "cs.MM cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video stream is converted to several formats to support the user's device,\nthis conversion process is called video transcoding, which imposes high storage\nand powerful resources. With emerging of cloud technology, video stream\ncompanies adopted to process video on the cloud. Generally, many formats of the\nsame video are made (pre-transcoded) and streamed to the adequate user's\ndevice. However, pre-transcoding demands huge storage space and incurs a\nhigh-cost to the video stream companies. More importantly, the pre-transcoding\nof video streams could be hierarchy carried out through different storage types\nin the cloud. To minimize the storage cost, in this paper, we propose a method\nto store video streams in the hierarchical storage of the cloud. Particularly,\nwe develop a method to decide which video stream should be pre-transcoded in\nits suitable cloud storage to minimize the overall cost. Experimental\nsimulation and results show the effectiveness of our approach, specifically,\nwhen the percentage of frequently accessed videos is high in repositories, the\nproposed approach minimizes the overall cost by up to 40 percent.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 13:26:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Darwich", "Mahmoud", ""], ["Ismail", "Yasser", ""], ["Darwich", "Talal", ""], ["Bayoumi", "Magdy", ""]]}, {"id": "2007.03451", "submitter": "Abhinav Bhatele", "authors": "Ian J. Costello, Abhinav Bhatele", "title": "Analytics of Longitudinal System Monitoring Data for Performance\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, several HPC facilities have started continuous monitoring of\ntheir systems and jobs to collect performance-related data for understanding\nperformance and operational efficiency. Such data can be used to optimize the\nperformance of individual jobs and the overall system by creating data-driven\nmodels that can predict the performance of pending jobs. In this paper, we\nmodel the performance of representative control jobs using longitudinal\nsystem-wide monitoring data to explore the causes of performance variability.\nUsing machine learning, we are able to predict the performance of unseen jobs\nbefore they are executed based on the current system state. We analyze these\nprediction models in great detail to identify the features that are dominant\npredictors of performance. We demonstrate that such models can be\napplication-agnostic and can be used for predicting performance of applications\nthat are not included in training.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 13:57:59 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Costello", "Ian J.", ""], ["Bhatele", "Abhinav", ""]]}, {"id": "2007.03488", "submitter": "Thomas Bartz-Beielstein", "authors": "Thomas Bartz-Beielstein, Carola Doerr, Daan van den Berg, Jakob\n  Bossek, Sowmya Chandrasekaran, Tome Eftimov, Andreas Fischbach, Pascal\n  Kerschke, William La Cava, Manuel Lopez-Ibanez, Katherine M. Malan, Jason H.\n  Moore, Boris Naujoks, Patryk Orzechowski, Vanessa Volz, Markus Wagner, Thomas\n  Weise", "title": "Benchmarking in Optimization: Best Practice and Open Issues", "comments": "Version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.PF math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey compiles ideas and recommendations from more than a dozen\nresearchers with different backgrounds and from different institutes around the\nworld. Promoting best practice in benchmarking is its main goal. The article\ndiscusses eight essential topics in benchmarking: clearly stated goals,\nwell-specified problems, suitable algorithms, adequate performance measures,\nthoughtful analysis, effective and efficient designs, comprehensible\npresentations, and guaranteed reproducibility. The final goal is to provide\nwell-accepted guidelines (rules) that might be useful for authors and\nreviewers. As benchmarking in optimization is an active and evolving field of\nresearch this manuscript is meant to co-evolve over time by means of periodic\nupdates.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 14:20:26 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 22:36:27 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bartz-Beielstein", "Thomas", ""], ["Doerr", "Carola", ""], ["Berg", "Daan van den", ""], ["Bossek", "Jakob", ""], ["Chandrasekaran", "Sowmya", ""], ["Eftimov", "Tome", ""], ["Fischbach", "Andreas", ""], ["Kerschke", "Pascal", ""], ["La Cava", "William", ""], ["Lopez-Ibanez", "Manuel", ""], ["Malan", "Katherine M.", ""], ["Moore", "Jason H.", ""], ["Naujoks", "Boris", ""], ["Orzechowski", "Patryk", ""], ["Volz", "Vanessa", ""], ["Wagner", "Markus", ""], ["Weise", "Thomas", ""]]}, {"id": "2007.03505", "submitter": "Gabriele D'Angelo", "authors": "Mirko Zichichi, Stefano Ferretti, Gabriele D'Angelo", "title": "On the Efficiency of Decentralized File Storage for Personal Information\n  Management Systems", "comments": "To appear in the Proceedings of the 25th IEEE Symposium on Computers\n  and Communications (ISCC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.IR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an architecture, based on Distributed Ledger Technologies\n(DLTs) and Decentralized File Storage (DFS) systems, to support the use of\nPersonal Information Management Systems (PIMS). DLT and DFS are used to manage\ndata sensed by mobile users equipped with devices with sensing capability. DLTs\nguarantee the immutability, traceability and verifiability of references to\npersonal data, that are stored in DFS. In fact, the inclusion of data digests\nin the DLT makes it possible to obtain an unalterable reference and a\ntamper-proof log, while remaining compliant with the regulations on personal\ndata, i.e. GDPR. We provide an experimental evaluation on the feasibility of\nthe use of DFS. Three different scenarios have been studied: i) a proprietary\nIPFS approach with a dedicated node interfacing with the data producers, ii) a\npublic IPFS service and iii) Sia Skynet. Results show that through proper\nconfiguration of the system infrastructure, it is viable to build a\ndecentralized Personal Data Storage (PDS).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 14:41:18 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Zichichi", "Mirko", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "2007.03776", "submitter": "Maciej Besta", "authors": "Maciej Besta, Jens Domke, Marcel Schneider, Marek Konieczny, Salvatore\n  Di Girolamo, Timo Schneider, Ankit Singla, Torsten Hoefler", "title": "High-Performance Routing with Multipathing and Path Diversity in\n  Ethernet and HPC Networks", "comments": null, "journal-ref": "IEEE Transactions on Parallel and Distributed Systems (TPDS), 2021", "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent line of research into topology design focuses on lowering network\ndiameter. Many low-diameter topologies such as Slim Fly or Jellyfish that\nsubstantially reduce cost, power consumption, and latency have been proposed. A\nkey challenge in realizing the benefits of these topologies is routing. On one\nhand, these networks provide shorter path lengths than established topologies\nsuch as Clos or torus, leading to performance improvements. On the other hand,\nthe number of shortest paths between each pair of endpoints is much smaller\nthan in Clos, but there is a large number of non-minimal paths between router\npairs. This hampers or even makes it impossible to use established multipath\nrouting schemes such as ECMP. In this work, to facilitate high-performance\nrouting in modern networks, we analyze existing routing protocols and\narchitectures, focusing on how well they exploit the diversity of minimal and\nnon-minimal paths. We first develop a taxonomy of different forms of support\nfor multipathing and overall path diversity. Then, we analyze how existing\nrouting schemes support this diversity. Among others, we consider multipathing\nwith both shortest and non-shortest paths, support for disjoint paths, or\nenabling adaptivity. To address the ongoing convergence of HPC and \"Big Data\"\ndomains, we consider routing protocols developed for both HPC systems and for\ndata centers as well as general clusters. Thus, we cover architectures and\nprotocols based on Ethernet, InfiniBand, and other HPC networks such as\nMyrinet. Our review will foster developing future high-performance multipathing\nrouting protocols in supercomputers and data centers.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 20:16:54 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 21:44:48 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 00:08:46 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Besta", "Maciej", ""], ["Domke", "Jens", ""], ["Schneider", "Marcel", ""], ["Konieczny", "Marek", ""], ["Di Girolamo", "Salvatore", ""], ["Schneider", "Timo", ""], ["Singla", "Ankit", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2007.04868", "submitter": "Filippo Mantovani", "authors": "Filippo Mantovani, Marta Garcia-Gasulla, Jos\\'e Gracia, Esteban\n  Stafford, Fabio Banchelli, Marc Josep-Fabrego, Joel Criado-Ledesma, Mathias\n  Nachtmann", "title": "Performance and energy consumption of HPC workloads on a cluster based\n  on Arm ThunderX2 CPU", "comments": null, "journal-ref": "Future Generation Computer Systems, 2020", "doi": "10.1016/j.future.2020.06.033", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the performance and energy consumption of an\nArm-based high-performance computing (HPC) system developed within the European\nproject Mont-Blanc 3. This system, called Dibona, has been integrated by\nATOS/Bull, and it is powered by the latest Marvell's CPU, ThunderX2. This CPU\nis the same one that powers the Astra supercomputer, the first Arm-based\nsupercomputer entering the Top500 in November 2018. We study from\nmicro-benchmarks up to large production codes. We include an interdisciplinary\nevaluation of three scientific applications (a finite-element fluid dynamics\ncode, a smoothed particle hydrodynamics code, and a lattice Boltzmann code) and\nthe Graph 500 benchmark, focusing on parallel and energy efficiency as well as\nstudying their scalability up to thousands of Armv8 cores. For comparison, we\nrun the same tests on state-of-the-art x86 nodes included in Dibona and the\nTier-0 supercomputer MareNostrum4. Our experiments show that the ThunderX2 has\na 25% lower performance on average, mainly due to its small vector unit yet\nsomewhat compensated by its 30% wider links between the CPU and the main\nmemory. We found that the software ecosystem of the Armv8 architecture is\ncomparable to the one available for Intel. Our results also show that ThunderX2\ndelivers similar or better energy-to-solution and scalability, proving that\nArm-based chips are legitimate contenders in the market of next-generation HPC\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 15:12:51 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 05:44:13 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Mantovani", "Filippo", ""], ["Garcia-Gasulla", "Marta", ""], ["Gracia", "Jos\u00e9", ""], ["Stafford", "Esteban", ""], ["Banchelli", "Fabio", ""], ["Josep-Fabrego", "Marc", ""], ["Criado-Ledesma", "Joel", ""], ["Nachtmann", "Mathias", ""]]}, {"id": "2007.05221", "submitter": "Fanxu Meng", "authors": "Liang Yang, Fanxu Meng, Qingqing Wu, Daniel Benevides da Costa, and\n  Mohamed-Slim Alouini", "title": "Accurate Closed-Form Approximations to Channel Distributions of\n  RIS-Aided Wireless Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes highly accurate closed-form approximations to channel\ndistributions of two different reconfigurable intelligent surface (RIS)-based\nwireless system setups, namely, dual-hop RIS-aided (RIS-DH) scheme and\nRIS-aided transmit (RIS-T) scheme. Differently from previous works, the\nproposed approximations reveal to be very tight for arbitrary number $N$ of\nreflecting metasurface's elements. Our findings are then applied to the\nperformance analysis of the considered systems, in which the outage\nprobability, bit error rate, and average channel capacity are derived. Results\nshow that the achievable diversity orders $G_d$ for RIS-DH and RIS-T schemes\nare $N-1<G_d<N$ and $N$, respectively. Furthermore, it is revealed that both\nschemes can not provide the multiplexing gain and only diversity gains are\nachieved. For the RIS-DH scheme, the channels are similar to the keyhole\nmultiple-input multiple-output (MIMO) channels with only one degree of freedom,\nwhile the RIS-T scheme is like the transmit diversity structure.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 07:52:12 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Yang", "Liang", ""], ["Meng", "Fanxu", ""], ["Wu", "Qingqing", ""], ["da Costa", "Daniel Benevides", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2007.05261", "submitter": "Evangelos Pournaras", "authors": "Jovan Nikolic, Nursultan Jubatyrov, Evangelos Pournaras", "title": "Self-healing Dilemmas in Distributed Systems: Fault Correction vs. Fault\n  Tolerance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale decentralized systems of autonomous agents interacting via\nasynchronous communication often experience the following self-healing dilemma:\nfault detection inherits network uncertainties making a remote faulty process\nindistinguishable from a slow process. In the case of a slow process without\nfault, fault correction is undesirable as it can trigger new faults that could\nbe prevented with fault tolerance that is a more proactive system maintenance.\nBut in the case of an actual faulty process, fault tolerance alone without\neventually correcting persistent faults can make systems underperforming.\nMeasuring, understanding and resolving such self-healing dilemmas is a timely\nchallenge and critical requirement given the rise of distributed ledgers, edge\ncomputing, the Internet of Things in several energy, transport and health\napplications. This paper contributes a novel and general-purpose modeling of\nfault scenarios during system runtime. They are used to accurately measure and\npredict inconsistencies generated by the undesirable outcomes of fault\ncorrection and fault tolerance as the means to improve self-healing of\nlarge-scale decentralized systems at the design phase. A rigorous experimental\nmethodology is designed that evaluates 696 experimental settings of different\nfault scales, fault profiles and fault detection thresholds in a prototyped\ndecentralized network of 3000 nodes. Almost 9 million measurements of\ninconsistencies were collected in a network, where each node monitors the\nhealth status of another node, while both can defect. The prediction\nperformance of the modeled fault scenarios is validated in a challenging\napplication scenario of decentralized and dynamic in-network data aggregation\nusing real-world data from a Smart Grid pilot project. Findings confirm the\norigin of inconsistencies at design phase.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 09:10:00 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 17:50:13 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 16:34:40 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Nikolic", "Jovan", ""], ["Jubatyrov", "Nursultan", ""], ["Pournaras", "Evangelos", ""]]}, {"id": "2007.07125", "submitter": "Mattia Lecci", "authors": "Mattia Lecci, Paolo Testolina, Michele Polese, Marco Giordani, Michele\n  Zorzi", "title": "Accuracy vs. Complexity for mmWave Ray-Tracing: A Full Stack Perspective", "comments": "31 pages, 14 figures, 1 table. This paper has been submitted to IEEE\n  for publication. Copyright IEEE 2020. Please cite it as: Mattia Lecci, Paolo\n  Testolina, Michele Polese, Marco Giordani, Michele Zorzi, \"Accuracy vs.\n  Complexity for mmWave Ray-Tracing: A Full Stack Perspective.''", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The millimeter wave (mmWave) band will provide multi-gigabits-per-second\nconnectivity in the radio access of future wireless systems. The high\npropagation loss in this portion of the spectrum calls for the deployment of\nlarge antenna arrays to compensate for the loss through high directional gain,\nthus introducing a spatial dimension in the channel model to accurately\nrepresent the performance of a mmWave network. In this perspective, ray-tracing\ncan characterize the channel in terms of Multi Path Components (MPCs) to\nprovide a highly accurate model, at the price of extreme computational\ncomplexity (e.g., for processing detailed environment information about the\npropagation), which limits the scalability of the simulations. In this paper,\nwe present possible simplifications to improve the trade-off between accuracy\nand complexity in ray-tracing simulations at mmWaves by reducing the total\nnumber of MPCs. The effect of such simplifications is evaluated from a\nfull-stack perspective through end-to-end simulations, testing different\nconfiguration parameters, propagation scenarios, and higher-layer protocol\nimplementations. We then provide guidelines on the optimal degree of\nsimplification, for which it is possible to reduce the complexity of\nsimulations with a minimal reduction in accuracy for different deployment\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 15:44:35 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Lecci", "Mattia", ""], ["Testolina", "Paolo", ""], ["Polese", "Michele", ""], ["Giordani", "Marco", ""], ["Zorzi", "Michele", ""]]}, {"id": "2007.07219", "submitter": "Martin Zubeldia", "authors": "David Gamarnik, John N. Tsitsiklis, Martin Zubeldia", "title": "Stability, memory, and messaging tradeoffs in heterogeneous service\n  systems", "comments": "arXiv admin note: text overlap with arXiv:1807.02882", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a heterogeneous distributed service system, consisting of $n$\nservers with unknown and possibly different processing rates. Jobs with unit\nmean and independent processing times arrive as a renewal process of rate\n$\\lambda n$, with $0<\\lambda<1$, to the system. Incoming jobs are immediately\ndispatched to one of several queues associated with the $n$ servers. We assume\nthat the dispatching decisions are made by a central dispatcher endowed with a\nfinite memory, and with the ability to exchange messages with the servers.\n  We study the fundamental resource requirements (memory bits and message\nexchange rate) in order for a dispatching policy to be {\\bf maximally stable},\ni.e., stable whenever the processing rates are such that the arrival rate is\nless than the total available processing rate. First, for the case of Poisson\narrivals and exponential service times, we present a policy that is maximally\nstable while using a positive (but arbitrarily small) message rate, and\n$\\log_2(n)$ bits of memory. Second, we show that within a certain broad class\nof policies, a dispatching policy that exchanges $o\\big(n^2\\big)$ messages per\nunit of time, and with $o(\\log(n))$ bits of memory, cannot be maximally stable.\nThus, as long as the message rate is not too excessive, a logarithmic memory is\nnecessary and sufficient for maximal stability.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 18:37:16 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Gamarnik", "David", ""], ["Tsitsiklis", "John N.", ""], ["Zubeldia", "Martin", ""]]}, {"id": "2007.07336", "submitter": "Andrew Kirby", "authors": "Andrew C. Kirby, Siddharth Samsi, Michael Jones, Albert Reuther,\n  Jeremy Kepner, Vijay Gadepally", "title": "Layer-Parallel Training with GPU Concurrency of Deep Residual Neural\n  Networks via Nonlinear Multigrid", "comments": "7 pages, 6 figures, 27 citations. Accepted to 2020 IEEE High\n  Performance Extreme Computing Conference - Outstanding Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Multigrid Full Approximation Storage algorithm for solving Deep Residual\nNetworks is developed to enable neural network parallelized layer-wise training\nand concurrent computational kernel execution on GPUs. This work demonstrates a\n10.2x speedup over traditional layer-wise model parallelism techniques using\nthe same number of compute units.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 20:15:36 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 18:34:56 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kirby", "Andrew C.", ""], ["Samsi", "Siddharth", ""], ["Jones", "Michael", ""], ["Reuther", "Albert", ""], ["Kepner", "Jeremy", ""], ["Gadepally", "Vijay", ""]]}, {"id": "2007.07539", "submitter": "Andreas Vogel", "authors": "Kyaw L. Oo, Andreas Vogel", "title": "Accelerating Geometric Multigrid Preconditioning with Half-Precision\n  Arithmetic on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the hardware support for half-precision arithmetic on NVIDIA V100 GPUs,\nhigh-performance computing applications can benefit from lower precision at\nappropriate spots to speed up the overall execution time. In this paper, we\ninvestigate a mixed-precision geometric multigrid method to solve large sparse\nsystems of equations stemming from discretization of elliptic PDEs. While the\nfinal solution is always computed with high-precision accuracy, an iterative\nrefinement approach with multigrid preconditioning in lower precision and\nresiduum scaling is employed. We compare the FP64 baseline for Poisson's\nequation to purely FP16 multigrid preconditioning and to the employment of\nFP16-FP32-FP64 combinations within a mesh hierarchy. While the iteration count\nis almost not affected by using lower accuracy, the solver runtime is\nconsiderably decreased due to the reduced memory transfer and a speedup of up\nto 2.5x is gained for the overall solver. We investigate the performance of\nselected kernels with the hierarchical Roofline model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 08:27:33 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Oo", "Kyaw L.", ""], ["Vogel", "Andreas", ""]]}, {"id": "2007.09733", "submitter": "Jo\\~ao Louren\\c{c}o", "authors": "Tiago M. Vale, Jo\\~ao Leit\\~ao, Nuno Pregui\\c{c}a, Rodrigo Rodrigues,\n  Ricardo J. Dias, Jo\\~ao M. Louren\\c{c}o", "title": "Lazy State Determination: More concurrency for contending linearizable\n  transactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concurrency control algorithms in transactional systems limits\nconcurrency to provide strong semantics, which leads to poor performance under\nhigh contention. As a consequence, many transactional systems eschew strong\nsemantics to achieve acceptable performance. We show that by leveraging\nsemantic information associated with the transactional programs to increase\nconcurrency, it is possible to significantly improve performance while\nmaintaining linearizability. To this end, we introduce the lazy state\ndetermination API to easily expose the semantics of application transactions to\nthe database, and propose new optimistic and pessimistic concurrency control\nalgorithms that leverage this information to safely increase concurrency in the\npresence of contention. Our evaluation shows that our approach can achieve up\nto 5x more throughput with 1.5c less latency than standard techniques in the\npopular TPC-C benchmark.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 18:02:05 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Vale", "Tiago M.", ""], ["Leit\u00e3o", "Jo\u00e3o", ""], ["Pregui\u00e7a", "Nuno", ""], ["Rodrigues", "Rodrigo", ""], ["Dias", "Ricardo J.", ""], ["Louren\u00e7o", "Jo\u00e3o M.", ""]]}, {"id": "2007.09829", "submitter": "Jiliang Zhang", "authors": "Jiliang Zhang, Andr\\'es Alay\\'on Glazunov and Jie Zhang", "title": "Wireless Performance Evaluation of Building Layouts: Closed-Form\n  Computation of Figures of Merit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a part of our ground-breaking work on evaluation of\nbuildings in terms of wireless friendliness in the building-design stage. The\nmain goal is to devise construction practices that provide for a good\nperformance of wireless networks deployed in buildings. In this paper, the\ninterference gain (IG) and power gain (PG) are defined as two figures of merit\n(FoM) of the wireless performance of buildings. The FoMs bridge the gap between\nbuilding design and wireless communications industries. An approach to derive\nexact closed-form equations for these FoMs is proposed for the first time. The\nderived analytic expressions facilitate straightforward and more\ncomputationally efficient numerical evaluation of the proposed FoMs as compared\nto Monte Carlo simulations for well-known indoor propagation models. It is\nshown that the derived closed-form expression can be readily employed to\nevaluate the impact of building properties, such as the sizes and the aspect\nratios (ARs) of rooms, on the wireless performance. The proposed approach sheds\nlight to architects on evaluation and design of wireless-friendly building\nlayouts.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 01:43:34 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Zhang", "Jiliang", ""], ["Glazunov", "Andr\u00e9s Alay\u00f3n", ""], ["Zhang", "Jie", ""]]}, {"id": "2007.10571", "submitter": "Daniel Richins", "authors": "Daniel Richins, Dharmisha Doshi, Matthew Blackmore, Aswathy\n  Thulaseedharan Nair, Neha Pathapati, Ankit Patel, Brainard Daguman, Daniel\n  Dobrijalowski, Ramesh Illikkal, Kevin Long, David Zimmerman, Vijay Janapa\n  Reddi", "title": "AI Tax: The Hidden Cost of AI Data Center Applications", "comments": "32 pages. 16 figures. Submitted to ACM \"Transactions on Computer\n  Systems.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence and machine learning are experiencing widespread\nadoption in industry and academia. This has been driven by rapid advances in\nthe applications and accuracy of AI through increasingly complex algorithms and\nmodels; this, in turn, has spurred research into specialized hardware AI\naccelerators. Given the rapid pace of advances, it is easy to forget that they\nare often developed and evaluated in a vacuum without considering the full\napplication environment. This paper emphasizes the need for a holistic,\nend-to-end analysis of AI workloads and reveals the \"AI tax.\" We deploy and\ncharacterize Face Recognition in an edge data center. The application is an\nAI-centric edge video analytics application built using popular open source\ninfrastructure and ML tools. Despite using state-of-the-art AI and ML\nalgorithms, the application relies heavily on pre-and post-processing code. As\nAI-centric applications benefit from the acceleration promised by accelerators,\nwe find they impose stresses on the hardware and software infrastructure:\nstorage and network bandwidth become major bottlenecks with increasing AI\nacceleration. By specializing for AI applications, we show that a purpose-built\nedge data center can be designed for the stresses of accelerated AI at 15%\nlower TCO than one derived from homogeneous servers and infrastructure.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 02:42:26 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Richins", "Daniel", ""], ["Doshi", "Dharmisha", ""], ["Blackmore", "Matthew", ""], ["Nair", "Aswathy Thulaseedharan", ""], ["Pathapati", "Neha", ""], ["Patel", "Ankit", ""], ["Daguman", "Brainard", ""], ["Dobrijalowski", "Daniel", ""], ["Illikkal", "Ramesh", ""], ["Long", "Kevin", ""], ["Zimmerman", "David", ""], ["Reddi", "Vijay Janapa", ""]]}, {"id": "2007.10794", "submitter": "Felipe Gohring De Magalhaes", "authors": "Felipe Gohring de Magalhaes, Alexy Torres Aurora Dugo, Jean-Baptiste\n  Lefoul, Gabriela Nicolescu", "title": "On the benchmarking of partitioned real-time systems", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Avionic software is the subject of critical real time, determinism and safety\nconstraints. Software designers face several challenges, one of them being the\nestimation of worst-case execution time (WCET) of applications, that dictates\nthe execution time of the system. A pessimistic WCET estimation can lead to low\nexecution performances of the system, while an over-optimistic estimation can\nlead to deadline misses, breaking one the basic constraints of critical\nreal-time systems (RTS). Partitioned systems are one special category of real\ntime systems, employed by the avionic community to deploy avionic software. The\nARINC-653 standard is one common avionic standard that employs the concept of\npartitions. This standard defines partitioned architectures where one partition\nshould never directly interfere with another one. Assessing WCET of general\npurpose RTSs is achievable by the usage of one of the many published benchmark\nor WCET estimation frameworks. Contrarily, partitioned RTSs are special cases,\nin which common benchmark tools may not capture all the metrics. In this\ndocument, we present SFPBench, a generic benchmark framework for the assessment\nof performance metrics on partitioned RTSs. The general organization of the\nframework and its applications are illustrated, as well as an use-case,\nemploying SFPBench on an industrial partitioned operating system (OS) executing\non a Commercial Off-The-shelf (COTS) processor.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 22:09:20 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["de Magalhaes", "Felipe Gohring", ""], ["Dugo", "Alexy Torres Aurora", ""], ["Lefoul", "Jean-Baptiste", ""], ["Nicolescu", "Gabriela", ""]]}, {"id": "2007.11650", "submitter": "Nail Akar Prof.", "authors": "Nail Akar and Ozancan Dogan", "title": "Discrete-time Queueing Model of Age of Information with Multiple\n  Information Sources", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information freshness in IoT-based status update systems has recently been\nstudied through the Age of Information (AoI) and Peak AoI (PAoI) performance\nmetrics. In this paper, we study a discrete-time server arising in multi-source\nIoT systems which accepts incoming information packets from multiple\ninformation sources so as to be forwarded to a remote monitor for status update\npurposes. Under the assumption of Bernoulli information packet arrivals and a\ncommon geometric service time distribution across all the sources, we\nnumerically obtain the exact per-source distributions of AoI and PAoI in\nmatrix-geometric form for three different queueing disciplines: i)\nNon-Preemptive Bufferless (NPB) ii) Preemptive Bufferless (PB) iii)\nNon-Preemptive Single Buffer with Replacement (NPSBR). The proposed numerical\nalgorithm employs the theory of Discrete-Time Markov Chains (DTMC) of\nQuasi-Birth-Death (QBD) type and is matrix analytical, i.e, the algorithm is\nbased on numerically stable and efficient vector-matrix operations.Numerical\nexamples are provided to validate the accuracy and effectiveness of the\nproposed queueing model. We also present a numerical example on the optimum\nchoice of the Bernoulli parameters in a practical IoT system with two sources\nwith diverse AoI requirements.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 20:05:01 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Akar", "Nail", ""], ["Dogan", "Ozancan", ""]]}, {"id": "2007.11656", "submitter": "Nail Akar Prof.", "authors": "Ozancan Dogan and Nail Akar", "title": "The Multi-Source Preemptive M/PH/1/1 Queue with Packet Errors: Exact\n  Distribution of the Age of Information and Its Peak", "comments": "16 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Age of Information (AoI) and Peak AoI (PAoI) and their analytical models have\nrecently drawn substantial amount of attention in information theory and\nwireless communications disciplines, in the context of qualitative assessment\nof information freshness in status update systems. We take a queueing-theoretic\napproach and study a probabilistically preemptive bufferless $M/PH/1/1$\nqueueing system with arrivals stemming from $N$ separate information sources,\nwith the aim of modeling a generic status update system. In this model, a new\ninformation packet arrival from source $m$ is allowed to preempt a packet from\nsource $n$ in service, with a probability depending on $n$ and $m$. To make the\nmodel even more general than the existing ones, for each of the information\nsources, we assume a distinct PH-type service time distribution and a distinct\npacket error probability. Subsequently, we obtain the exact distributions of\nthe AoI and PAoI for each of the information sources using matrix-analytical\nalgorithms and in particular the theory of Markov fluid queues and sample path\narguments. This is in contrast with existing methods that rely on Stochastic\nHybrid Systems (SHS) which obtain only the average values and in less general\nsettings. Numerical examples are provided to validate the proposed approach as\nwell as to give engineering insight on the impact of preemption probabilities\non certain AoI and PAoI performance figures.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 20:15:52 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Dogan", "Ozancan", ""], ["Akar", "Nail", ""]]}, {"id": "2007.12094", "submitter": "Golrokh Hamidi", "authors": "Golrokh Hamidi", "title": "Reinforcement Learning Assisted Load Test Generation for E-Commerce\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: End-user satisfaction is not only dependent on the correct\nfunctioning of the software systems but is also heavily dependent on how well\nthose functions are performed. Therefore, performance testing plays a critical\nrole in making sure that the system responsively performs the indented\nfunctionality. Load test generation is a crucial activity in performance\ntesting. Existing approaches for load test generation require expertise in\nperformance modeling, or they are dependent on the system model or the source\ncode.\n  Aim: This thesis aims to propose and evaluate a model-free learning-based\napproach for load test generation, which doesn't require access to the system\nmodels or source code.\n  Method: In this thesis, we treated the problem of optimal load test\ngeneration as a reinforcement learning (RL) problem. We proposed two RL-based\napproaches using q-learning and deep q-network for load test generation. In\naddition, we demonstrated the applicability of our tester agents on a\nreal-world software system. Finally, we conducted an experiment to compare the\nefficiency of our proposed approaches to a random load test generation approach\nand a baseline approach.\n  Results: Results from the experiment show that the RL-based approaches\nlearned to generate effective workloads with smaller sizes and in fewer steps.\nThe proposed approaches led to higher efficiency than the random and baseline\napproaches.\n  Conclusion: Based on our findings, we conclude that RL-based agents can be\nused for load test generation, and they act more efficiently than the random\nand baseline approaches.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 15:56:43 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Hamidi", "Golrokh", ""]]}, {"id": "2007.13452", "submitter": "Yuxin Lu", "authors": "Yuxin Lu and Wai Ho Mow", "title": "Detection and Performance Analysis for Non-Coherent DF Relay Networks\n  with Optimized Generalized Differential Modulation", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.PF eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the detection and performance analysis problems for a\nrelay network with $N$ parallel decode-and-forward (DF) relays. Due to the\ndistributed nature of this network, it is practically very challenging to\nfulfill the requirement of instantaneous channel state information for coherent\ndetection. To bypass this requirement, we consider the use of non-coherent DF\nrelaying based on a generalized differential modulation (GDM) scheme, in which\ntransmission power allocation over the $M$-ary phase shift keying symbols is\nexploited when performing differential encoding. In this paper, a novel\ndetector at the destination of such a non-coherent DF relay network is\nproposed. It is an accurate approximation of the state-of-the-art detector,\ncalled the almost maximum likelihood detector (AMLD), but the detection\ncomplexity is considerably reduced from $\\mathcal{O}(M^2N)$ to\n$\\mathcal{O}(MN)$. By characterizing the dominant error terms, we derive an\naccurate approximate symbol error rate (SER) expression. An optimized power\nallocation scheme for GDM is further designed based on this SER expression. Our\nsimulation demonstrates that the proposed non-coherent scheme can perform close\nto the coherent counterpart as the block length increases. Additionally, we\nprove that the diversity order of both the proposed detector and the AMLD is\nexactly $\\lceil N/2 \\rceil + 1$. Extensive simulation results further verify\nthe accuracy of our results in various scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 11:47:33 GMT"}, {"version": "v2", "created": "Sun, 23 Aug 2020 06:59:06 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Lu", "Yuxin", ""], ["Mow", "Wai Ho", ""]]}, {"id": "2007.13648", "submitter": "Perry Gibson", "authors": "Perry Gibson, Jos\\'e Cano", "title": "Orpheus: A New Deep Learning Framework for Easy Deployment and\n  Evaluation of Edge Inference", "comments": "To be published as a poster in 2020 IEEE International Symposium on\n  Performance Analysis of Systems and Software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.LG cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Optimising deep learning inference across edge devices and optimisation\ntargets such as inference time, memory footprint and power consumption is a key\nchallenge due to the ubiquity of neural networks. Today, production deep\nlearning frameworks provide useful abstractions to aid machine learning\nengineers and systems researchers. However, in exchange they can suffer from\ncompatibility challenges (especially on constrained platforms), inaccessible\ncode complexity, or design choices that otherwise limit research from a systems\nperspective. This paper presents Orpheus, a new deep learning framework for\neasy prototyping, deployment and evaluation of inference optimisations. Orpheus\nfeatures a small codebase, minimal dependencies, and a simple process for\nintegrating other third party systems. We present some preliminary evaluation\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 14:54:40 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 20:58:35 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Gibson", "Perry", ""], ["Cano", "Jos\u00e9", ""]]}, {"id": "2007.13951", "submitter": "Sumit Mandal", "authors": "Sumit K. Mandal, Raid Ayoub, Michael Kishinevsky, Mohammad M. Islam,\n  Umit Y. Ogras", "title": "Analytical Performance Modeling of NoCs under Priority Arbitration and\n  Bursty Traffic", "comments": "This paper will appear in a future issue of IEEE Embedded Systems\n  Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks-on-Chip (NoCs) used in commercial many-core processors typically\nincorporate priority arbitration. Moreover, they experience bursty traffic due\nto application workloads. However, most state-of-the-art NoC analytical\nperformance analysis techniques assume fair arbitration and simple traffic\nmodels. To address these limitations, we propose an analytical modeling\ntechnique for priority-aware NoCs under bursty traffic. Experimental\nevaluations with synthetic and bursty traffic show that the proposed approach\nhas less than 10% modeling error with respect to cycle-accurate NoC simulator.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 02:16:34 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Mandal", "Sumit K.", ""], ["Ayoub", "Raid", ""], ["Kishinevsky", "Michael", ""], ["Islam", "Mohammad M.", ""], ["Ogras", "Umit Y.", ""]]}, {"id": "2007.13988", "submitter": "Kyle Olszewski", "authors": "Ruilong Li, Yuliang Xiu, Shunsuke Saito, Zeng Huang, Kyle Olszewski,\n  Hao Li", "title": "Monocular Real-Time Volumetric Performance Capture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first approach to volumetric performance capture and\nnovel-view rendering at real-time speed from monocular video, eliminating the\nneed for expensive multi-view systems or cumbersome pre-acquisition of a\npersonalized template model. Our system reconstructs a fully textured 3D human\nfrom each frame by leveraging Pixel-Aligned Implicit Function (PIFu). While\nPIFu achieves high-resolution reconstruction in a memory-efficient manner, its\ncomputationally expensive inference prevents us from deploying such a system\nfor real-time applications. To this end, we propose a novel hierarchical\nsurface localization algorithm and a direct rendering method without explicitly\nextracting surface meshes. By culling unnecessary regions for evaluation in a\ncoarse-to-fine manner, we successfully accelerate the reconstruction by two\norders of magnitude from the baseline without compromising the quality.\nFurthermore, we introduce an Online Hard Example Mining (OHEM) technique that\neffectively suppresses failure modes due to the rare occurrence of challenging\nexamples. We adaptively update the sampling probability of the training data\nbased on the current reconstruction accuracy, which effectively alleviates\nreconstruction artifacts. Our experiments and evaluations demonstrate the\nrobustness of our system to various challenging angles, illuminations, poses,\nand clothing styles. We also show that our approach compares favorably with the\nstate-of-the-art monocular performance capture. Our proposed approach removes\nthe need for multi-view studio settings and enables a consumer-accessible\nsolution for volumetric capture.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 04:45:13 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Li", "Ruilong", ""], ["Xiu", "Yuliang", ""], ["Saito", "Shunsuke", ""], ["Huang", "Zeng", ""], ["Olszewski", "Kyle", ""], ["Li", "Hao", ""]]}, {"id": "2007.15260", "submitter": "Gabriele D'Angelo", "authors": "Luca Serena, Gabriele D'Angelo, Stefano Ferretti", "title": "Implications of Dissemination Strategies on the Security of Distributed\n  Ledgers", "comments": "Proceedings of the 3rd Workshop on Cryptocurrencies and Blockchains\n  for Distributed Systems (CryBlock 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a simulation study on security attacks over Distributed\nLedger Technologies (DLTs). We specifically focus on attacks at the underlying\npeer-to-peer layer of these systems, that is in charge of disseminating\nmessages containing data and transaction to be spread among all participants.\nIn particular, we consider the Sybil attack, according to which a malicious\nnode creates many Sybils that drop messages coming from a specific attacked\nnode, or even all messages from honest nodes. Our study shows that the\nselection of the specific dissemination protocol, as well as the amount of\nconnections each peer has, have an influence on the resistance to this attack.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 06:52:04 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Serena", "Luca", ""], ["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""]]}, {"id": "2007.15314", "submitter": "Xiaohu Wu", "authors": "Xiaohu Wu, Francesco De Pellegrini and Giuliano Casale", "title": "Delay and Price Differentiation in Cloud Computing: A Service Model,\n  Supporting Architectures, and Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cloud service providers (CSPs) provide on-demand service at a price with\na small delay. We propose a QoS-differentiated model where multiple SLAs\ndeliver both on-demand service for latency-critical users and delayed services\nfor delay-tolerant users at lower prices. Two architectures are considered to\nfulfill SLAs. The first is based on priority queues. The second simply\nseparates servers into multiple modules, each for one SLA. As an ecosystem, we\nshow that the proposed framework is dominant-strategy incentive compatible.\nAlthough the first architecture appears more prevalent in the literature, we\nprove the superiority of the second architecture, under which we further\nleverage queueing theory to determine the optimal SLA delays and prices.\nFinally, the viability of the proposed framework is validated through numerical\ncomparison with the on-demand service and it exhibits a revenue improvement in\nexcess of 200%. Our results can help CSPs design optimal delay-differentiated\nservices and choose appropriate serving architectures.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 08:51:33 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Wu", "Xiaohu", ""], ["De Pellegrini", "Francesco", ""], ["Casale", "Giuliano", ""]]}, {"id": "2007.15373", "submitter": "Luis Sequeira Dr", "authors": "Jose Saldana, Luis Sequeira, Julian Fernandez-Navajas, Jose Ruiz-Mas", "title": "Traffic Optimization for TCP-based Massive Multiplayer Online Games", "comments": null, "journal-ref": "Proc. International Symposium on Performance Evaluation of\n  Computer and Telecommunication Systems SPECTS 2012, July 8-11, 2012, Genoa,\n  Italy. ISBN: 978-1-4673-2235-5", "doi": null, "report-no": null, "categories": "cs.NI cs.MM cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the use of a traffic optimization technique named TCM\n(Tunneling, Compressing and Multiplexing) to reduce the bandwidth of MMORPGs\n(Massively Multiplayer Online Role-Playing Games), which employ TCP to provide\na soft real-time service. In order to optimize the traffic and to improve\nbandwidth efficiency, TCM can be applied when the packets of a number of\nplayers share the same link, which occurs in some scenarios, as e.g. the\ntraffic between proxies and servers of game-supporting infrastructures. First,\nTCP/IP headers are compressed using standard algorithms that avoid sending\nrepeated fields; next, a number of packets are blended into a bigger one and\nfinally, they are sent using a tunnel. The expected compressed header size has\nbeen obtained using traffic traces of a real game. Next, simulations using a\ntraffic model of a popular MMORPG have been performed in order to estimate the\nexpected bandwidth savings and the reduction in packets per second. The\nobtained bandwidth saving is about 60 percent. Packets per second are also\nsignificantly reduced. In addition, the added delays are shown to be small\nenough so as not to impair layers' experienced quality.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 10:50:23 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Saldana", "Jose", ""], ["Sequeira", "Luis", ""], ["Fernandez-Navajas", "Julian", ""], ["Ruiz-Mas", "Jose", ""]]}, {"id": "2007.16070", "submitter": "Luis Sequeira Dr", "authors": "Jose Saldana, Mirko Suznjevic, Luis Sequeira, Julian\n  Fernandez-Navajas, Maja Matijasevic, Jose Ruiz-Mas", "title": "The Effect of TCP Variants on the Coexistence of MMORPG and Best-Effort\n  Traffic", "comments": null, "journal-ref": "8th International Workshop on Networking Issues in Multimedia\n  Entertainment (NIME'12), Munich, Germany, July 30, 2012. ISBN:\n  978-1-4673-1543-2", "doi": "10.1109/ICCCN.2012.6289245", "report-no": null, "categories": "cs.NI cs.MM cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study TCP flows coexistence between Massive Multiplayer Online Role\nPlaying Games (MMORPGs) and other TCP applications, by taking World of Warcraft\n(WoW) and a file transfer application based on File Transfer Protocol (FTP) as\nan example. Our focus is on the effects of the sender buffer size and FTP\ncross-traffic on the queuing delay experienced by the (MMORPG) game traffic. A\nnetwork scenario corresponding to a real life situation in an ADSL access\nnetwork has been simulated by using NS2. Three TCP variants, namely TCP SACK,\nTCP New Reno, and TCP Vegas, have been considered for cross-traffic. The\nresults show that TCP Vegas is able to maintain a constant rate while competing\nwith the game traffic, since it prevents packet loss and high queuing delays by\nnot increasing the sender window size. TCP SACK and TCP New Reno, on the other\nhand, tend to continuously increase the sender window size, thus potentially\nallowing higher packet loss and causing undesired delays for the game traffic.\nIn terms of buffer size, we have established that smaller buffers are better\nfor MMORPG applications, while larger buffers contribute to a higher overall\ndelay.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 11:03:23 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Saldana", "Jose", ""], ["Suznjevic", "Mirko", ""], ["Sequeira", "Luis", ""], ["Fernandez-Navajas", "Julian", ""], ["Matijasevic", "Maja", ""], ["Ruiz-Mas", "Jose", ""]]}]