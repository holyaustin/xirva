[{"id": "1801.00094", "submitter": "Mohammad Mansour", "authors": "Elie M. Shaccour, Mohammad M. Mansour", "title": "A Loop-Based Methodology for Reducing Computational Redundancy in\n  Workload Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of general purpose processors relies heavily on a workload\ngathering step in which representative programs are collected from various\napplication domains. Processor performance, when running the workload set, is\nprofiled using simulators that model the targeted processor architecture.\nHowever, simulating the entire workload set is prohibitively time-consuming,\nwhich precludes considering a large number of programs. To reduce simulation\ntime, several techniques in the literature have exploited the internal program\nrepetitiveness to extract and execute only representative code segments.\nExisting so- lutions are based on reducing cross-program computational\nredundancy or on eliminating internal-program redundancy to decrease execution\ntime. In this work, we propose an orthogonal and complementary loop- centric\nmethodology that targets loop-dominant programs by exploiting internal-program\ncharacteristics to reduce cross-program computational redundancy. The approach\nemploys a newly developed framework that extracts and analyzes core loops\nwithin workloads. The collected characteristics model memory behavior,\ncomputational complexity, and data structures of a program, and are used to\nconstruct a signature vector for each program. From these vectors,\ncross-workload similarity metrics are extracted, which are processed by a novel\nheuristic to exclude similar programs and reduce redundancy within the set.\nFinally, a reverse engineering approach that synthesizes executable\nmicro-benchmarks having the same instruction mix as the loops in the original\nworkload is introduced. A tool that automates the flow steps of the proposed\nmethodology is developed. Simulation results demonstrate that applying the\nproposed methodology to a set of workloads reduces the set size by half, while\npreserving the main characterizations of the initial workloads.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 07:31:29 GMT"}], "update_date": "2018-01-05", "authors_parsed": [["Shaccour", "Elie M.", ""], ["Mansour", "Mohammad M.", ""]]}, {"id": "1801.00246", "submitter": "Ali Karakus", "authors": "Ali Karakus, Noel Chalmers, Kasia Swirydowicz, Timothy Warburton", "title": "A GPU Accelerated Discontinuous Galerkin Incompressible Flow Solver", "comments": "33 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.PF physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a GPU-accelerated version of a high-order discontinuous Galerkin\ndiscretization of the unsteady incompressible Navier-Stokes equations. The\nequations are discretized in time using a semi-implicit scheme with explicit\ntreatment of the nonlinear term and implicit treatment of the split Stokes\noperators. The pressure system is solved with a conjugate gradient method\ntogether with a fully GPU-accelerated multigrid preconditioner which is\ndesigned to minimize memory requirements and to increase overall performance. A\nsemi-Lagrangian subcycling advection algorithm is used to shift the\ncomputational load per timestep away from the pressure Poisson solve by\nallowing larger timestep sizes in exchange for an increased number of advection\nsteps. Numerical results confirm we achieve the design order accuracy in time\nand space. We optimize the performance of the most time-consuming kernels by\ntuning the fine-grain parallelism, memory utilization, and maximizing\nbandwidth. To assess overall performance we present an empirically calibrated\nroofline performance model for a target GPU to explain the achieved efficiency.\nWe demonstrate that, in the most cases, the kernels used in the solver are\nclose to their empirically predicted roofline performance.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 06:48:37 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 22:27:04 GMT"}, {"version": "v3", "created": "Mon, 7 May 2018 15:31:41 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Karakus", "Ali", ""], ["Chalmers", "Noel", ""], ["Swirydowicz", "Kasia", ""], ["Warburton", "Timothy", ""]]}, {"id": "1801.00837", "submitter": "Mohammad Noormohammadpour", "authors": "Mohammad Noormohammadpour, Cauligi S. Raghavendra, Srikanth Kandula,\n  Sriram Rao", "title": "QuickCast: Fast and Efficient Inter-Datacenter Transfers using\n  Forwarding Tree Cohorts", "comments": "[Extended Version] Accepted for presentation in IEEE INFOCOM 2018,\n  Honolulu, HI", "journal-ref": "INFOCOM (2018) 225-233", "doi": "10.1109/INFOCOM.2018.8486324", "report-no": null, "categories": "cs.NI cs.DC cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large inter-datacenter transfers are crucial for cloud service efficiency and\nare increasingly used by organizations that have dedicated wide area networks\nbetween datacenters. A recent work uses multicast forwarding trees to reduce\nthe bandwidth needs and improve completion times of point-to-multipoint\ntransfers. Using a single forwarding tree per transfer, however, leads to poor\nperformance because the slowest receiver dictates the completion time for all\nreceivers. Using multiple forwarding trees per transfer alleviates this\nconcern--the average receiver could finish early; however, if done naively,\nbandwidth usage would also increase and it is apriori unclear how best to\npartition receivers, how to construct the multiple trees and how to determine\nthe rate and schedule of flows on these trees. This paper presents QuickCast, a\nfirst solution to these problems. Using simulations on real-world network\ntopologies, we see that QuickCast can speed up the average receiver's\ncompletion time by as much as $10\\times$ while only using $1.04\\times$ more\nbandwidth; further, the completion time for all receivers also improves by as\nmuch as $1.6\\times$ faster at high loads.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 21:10:52 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Noormohammadpour", "Mohammad", ""], ["Raghavendra", "Cauligi S.", ""], ["Kandula", "Srikanth", ""], ["Rao", "Sriram", ""]]}, {"id": "1801.01134", "submitter": "B\\'erenger Bramas", "authors": "Berenger Bramas, Pavel Kus", "title": "Computing the sparse matrix vector product using block-based kernels\n  without zero padding on processors with AVX-512 instructions", "comments": "Published in Peer J CS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sparse matrix-vector product (SpMV) is a fundamental operation in many\nscientific applications from various fields. The High Performance Computing\n(HPC) community has therefore continuously invested a lot of effort to provide\nan efficient SpMV kernel on modern CPU architectures. Although it has been\nshown that block-based kernels help to achieve high performance, they are\ndifficult to use in practice because of the zero padding they require. In the\ncurrent paper, we propose new kernels using the AVX-512 instruction set, which\nmakes it possible to use a blocking scheme without any zero padding in the\nmatrix memory storage. We describe mask-based sparse matrix formats and their\ncorresponding SpMV kernels highly optimized in assembly language. Considering\nthat the optimal blocking size depends on the matrix, we also provide a method\nto predict the best kernel to be used utilizing a simple interpolation of\nresults from previous executions. We compare the performance of our approach to\nthat of the Intel MKL CSR kernel and the CSR5 open-source package on a set of\nstandard benchmark matrices. We show that we can achieve significant\nimprovements in many cases, both for sequential and for parallel executions.\nFinally, we provide the corresponding code in an open source library, called\nSPC5.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 19:00:06 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 10:05:38 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Bramas", "Berenger", ""], ["Kus", "Pavel", ""]]}, {"id": "1801.02099", "submitter": "Faheem Zafari", "authors": "Jian Li, Faheem Zafari, Don Towsley, Kin K. Leung, Ananthram Swami", "title": "Joint Data Compression and Caching: Approaching Optimality with\n  Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimally compressing and caching data across a\ncommunication network. Given the data generated at edge nodes and a routing\npath, our goal is to determine the optimal data compression ratios and caching\ndecisions across the network in order to minimize average latency, which can be\nshown to be equivalent to maximizing the compression and caching gain under an\nenergy consumption constraint. We show that this problem is NP-hard in general\nand the hardness is caused by the caching decision subproblem, while the\ncompression sub-problem is polynomial-time solvable. We then propose an\napproximation algorithm that achieves a $(1-1/e)$-approximation solution to the\noptimum in strongly polynomial time. We show that our proposed algorithm\nachieve the near-optimal performance in synthetic-based evaluations. In this\npaper, we consider a tree-structured network as an illustrative example, but\nour results easily extend to general network topology at the expense of more\ncomplicated notations.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 22:26:39 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 16:22:21 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Li", "Jian", ""], ["Zafari", "Faheem", ""], ["Towsley", "Don", ""], ["Leung", "Kin K.", ""], ["Swami", "Ananthram", ""]]}, {"id": "1801.02436", "submitter": "Kaiyi Ji", "authors": "Kaiyi Ji, Guocong Quan, Jian Tan", "title": "Asymptotic Miss Ratio of LRU Caching with Consistent Hashing", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To efficiently scale data caching infrastructure to support emerging big data\napplications, many caching systems rely on consistent hashing to group a large\nnumber of servers to form a cooperative cluster. These servers are organized\ntogether according to a random hash function. They jointly provide a unified\nbut distributed hash table to serve swift and voluminous data item requests.\nDifferent from the single least-recently-used (LRU) server that has already\nbeen extensively studied, theoretically characterizing a cluster that consists\nof multiple LRU servers remains yet to be explored. These servers are not\nsimply added together; the random hashing complicates the behavior. To this\nend, we derive the asymptotic miss ratio of data item requests on a LRU cluster\nwith consistent hashing. We show that these individual cache spaces on\ndifferent servers can be effectively viewed as if they could be pooled together\nto form a single virtual LRU cache space parametrized by an appropriate cache\nsize. This equivalence can be established rigorously under the condition that\nthe cache sizes of the individual servers are large. For typical data caching\nsystems this condition is common. Our theoretical framework provides a\nconvenient abstraction that can directly apply the results from the simpler\nsingle LRU cache to the more complex LRU cluster with consistent hashing.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 14:27:19 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 02:43:25 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Ji", "Kaiyi", ""], ["Quan", "Guocong", ""], ["Tan", "Jian", ""]]}, {"id": "1801.02889", "submitter": "Arpan Mukhopadhyay", "authors": "Arpan Mukhopadhyay, Nidhi Hegde, Marc Lelarge", "title": "Optimal Content Replication and Request Matching in Large Caching\n  Systems", "comments": "INFOCOM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider models of content delivery networks in which the servers are\nconstrained by two main resources: memory and bandwidth. In such systems, the\nthroughput crucially depends on how contents are replicated across servers and\nhow the requests of specific contents are matched to servers storing those\ncontents. In this paper, we first formulate the problem of computing the\noptimal replication policy which if combined with the optimal matching policy\nmaximizes the throughput of the caching system in the stationary regime. It is\nshown that computing the optimal replication policy for a given system is an\nNP-hard problem. A greedy replication scheme is proposed and it is shown that\nthe scheme provides a constant factor approximation guarantee. We then propose\na simple randomized matching scheme which avoids the problem of interruption in\nservice of the ongoing requests due to re-assignment or repacking of the\nexisting requests in the optimal matching policy. The dynamics of the caching\nsystem is analyzed under the combination of proposed replication and matching\nschemes. We study a limiting regime, where the number of servers and the\narrival rates of the contents are scaled proportionally, and show that the\nproposed policies achieve asymptotic optimality. Extensive simulation results\nare presented to evaluate the performance of different policies and study the\nbehavior of the caching system under different service time distributions of\nthe requests.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 11:21:27 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Mukhopadhyay", "Arpan", ""], ["Hegde", "Nidhi", ""], ["Lelarge", "Marc", ""]]}, {"id": "1801.02911", "submitter": "Harsh Thakkar", "authors": "Harsh Thakkar and Dharmen Punjani and Yashwant Keswani and Jens\n  Lehmann and S\\\"oren Auer", "title": "A Stitch in Time Saves Nine -- SPARQL querying of Property Graphs using\n  Gremlin Traversals", "comments": "Author's draft -- submitted to SWJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graphs have become popular over the past years and frequently rely\non the Resource Description Framework (RDF) or Property Graphs (PG) as\nunderlying data models. However, the query languages for these two data models\n-- SPARQL for RDF and Gremlin for property graph traversal -- are lacking\ninteroperability. We present Gremlinator, a novel SPARQL to Gremlin translator.\nGremlinator translates SPARQL queries to Gremlin traversals for executing graph\npattern matching queries over graph databases. This allows to access and query\na wide variety of Graph Data Management Systems (DMS) using the W3C\nstandardized SPARQL query language and avoid the learning curve of a new Graph\nQuery Language. Gremlin is a system-agnostic traversal language covering both\nOLTP graph database or OLAP graph processors, thus making it a desirable choice\nfor supporting interoperability wrt. querying Graph DMSs. We present a\ncomprehensive empirical evaluation of Gremlinator and demonstrate its validity\nand applicability by executing SPARQL queries on top of the leading graph\nstores Neo4J, Sparksee, and Apache TinkerGraph and compare the performance with\nthe RDF stores Virtuoso, 4Store and JenaTDB. Our evaluation demonstrates the\nsubstantial performance gain obtained by the Gremlin counterparts of the SPARQL\nqueries, especially for star-shaped and complex queries.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 12:25:19 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 14:53:00 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Thakkar", "Harsh", ""], ["Punjani", "Dharmen", ""], ["Keswani", "Yashwant", ""], ["Lehmann", "Jens", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "1801.03572", "submitter": "Hao Yu", "authors": "Hao Yu and Michael J. Neely", "title": "Learning Aided Optimization for Energy Harvesting Devices with Outdated\n  State Information", "comments": "This version extends v1 (our INFOCOM 2018 paper): (1) add a new\n  section (Section V) to study the case where utility functions are non-i.i.d.\n  arbitrarily varying (2) add more simulation experiments. The current version\n  is published in IEEE/ACM Transactions on Networking", "journal-ref": "IEEE/ACM Transactions on Networking, 2019", "doi": null, "report-no": null, "categories": "math.OC cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers utility optimal power control for energy harvesting\nwireless devices with a finite capacity battery. The distribution information\nof the underlying wireless environment and harvestable energy is unknown and\nonly outdated system state information is known at the device controller. This\nscenario shares similarity with Lyapunov opportunistic optimization and online\nlearning but is different from both. By a novel combination of Zinkevich's\nonline gradient learning technique and the drift-plus-penalty technique from\nLyapunov opportunistic optimization, this paper proposes a learning-aided\nalgorithm that achieves utility within $O(\\epsilon)$ of the optimal, for any\ndesired $\\epsilon>0$, by using a battery with an $O(1/\\epsilon)$ capacity. The\nproposed algorithm has low complexity and makes power investment decisions\nbased on system history, without requiring knowledge of the system state or its\nprobability distribution.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 22:23:27 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 00:00:19 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Yu", "Hao", ""], ["Neely", "Michael J.", ""]]}, {"id": "1801.03578", "submitter": "Afshin Zafari", "authors": "Afshin Zafari, Elisabeth Larsson, Martin Tillenius", "title": "DuctTeip: An efficient programming model for distributed task based\n  parallel computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current high-performance computer systems used for scientific computing\ntypically combine shared memory computational nodes in a distributed memory\nenvironment. Extracting high performance from these complex systems requires\ntailored approaches. Task based parallel programming has been successful both\nin simplifying the programming and in exploiting the available hardware\nparallelism for shared memory systems. In this paper we focus on how to extend\ntask parallel programming to distributed memory systems. We use a hierarchical\ndecomposition of tasks and data in order to accommodate the different levels of\nhardware. We test the proposed programming model on two different applications,\na Cholesky factorization, and a solver for the Shallow Water Equations. We also\ncompare the performance of our implementation with that of other frameworks for\ndistributed task parallel programming, and show that it is competitive.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 22:50:01 GMT"}], "update_date": "2018-01-14", "authors_parsed": [["Zafari", "Afshin", ""], ["Larsson", "Elisabeth", ""], ["Tillenius", "Martin", ""]]}, {"id": "1801.03589", "submitter": "Afshin Zafari", "authors": "Afshin Zafari, Elisabeth Larsson, Marco Righero, M. Alessandro\n  Francavilla, Giorgio Giordanengo, Francesca Vipiana, Giuseppe Vecchi", "title": "Task parallel implementation of a solver for electromagnetic scattering\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electromagnetic computations, where the wavelength is small in relation to\nthe geometry of interest, become computationally demanding. In order to manage\ncomputations for realistic problems like electromagnetic scattering from\naircraft, the use of parallel computing is essential. In this paper, we\ndescribe how a solver based on a hierarchical nested equivalent source\napproximation can be implemented in parallel using a task based programming\nmodel. We show that the effort for moving from the serial implementation to a\nparallel implementation is modest due to the task based programming paradigm,\nand that the performance achieved on a multicore system is excellent provided\nthat the task size, depending on the method parameters, is large enough.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 23:45:18 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Zafari", "Afshin", ""], ["Larsson", "Elisabeth", ""], ["Righero", "Marco", ""], ["Francavilla", "M. Alessandro", ""], ["Giordanengo", "Giorgio", ""], ["Vipiana", "Francesca", ""], ["Vecchi", "Giuseppe", ""]]}, {"id": "1801.04329", "submitter": "Nikolay A. Simakov", "authors": "Nikolay A. Simakov, Martins D. Innus, Matthew D. Jones, Joseph P.\n  White, Steven M. Gallo, Robert L. DeLeon and Thomas R. Furlani", "title": "Effect of Meltdown and Spectre Patches on the Performance of HPC\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we examine how the updates addressing Meltdown and Spectre\nvulnerabilities impact the performance of HPC applications. To study this we\nuse the application kernel module of XDMoD to test the performance before and\nafter the application of the vulnerability patches. We tested the performance\ndifference for multiple application and benchmarks including: NWChem, NAMD,\nHPCC, IOR, MDTest and IMB. The results show that although some specific\nfunctions can have performance decreased by as much as 74%, the majority of\nindividual metrics indicates little to no decrease in performance. The\nreal-world applications show a 2-3% decrease in performance for single node\njobs and a 5-11% decrease for parallel multi node jobs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 21:57:14 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 19:08:36 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Simakov", "Nikolay A.", ""], ["Innus", "Martins D.", ""], ["Jones", "Matthew D.", ""], ["White", "Joseph P.", ""], ["Gallo", "Steven M.", ""], ["DeLeon", "Robert L.", ""], ["Furlani", "Thomas R.", ""]]}, {"id": "1801.04582", "submitter": "Afshin Zafari", "authors": "Afshin Zafari, Elisabeth Larsson", "title": "Distributed dynamic load balancing for task parallel programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive and investigate approaches to dynamically load\nbalance a distributed task parallel application software. The load balancing\nstrategy is based on task migration. Busy processes export parts of their ready\ntask queue to idle processes. Idle--busy pairs of processes find each other\nthrough a random search process that succeeds within a few steps with high\nprobability. We evaluate the load balancing approach for a block Cholesky\nfactorization implementation and observe a reduction in execution time on the\norder of 5\\% in the selected test cases.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 16:47:52 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Zafari", "Afshin", ""], ["Larsson", "Elisabeth", ""]]}, {"id": "1801.06153", "submitter": "Kai Li", "authors": "Kai Li, Wei Ni, Eduardo Tovar, and Mohsen Guizani", "title": "LCD: Low Latency Command Dissemination for A Platoon of Vehicles", "comments": "8 pages, 5 figures, accepted in IEEE International Conference on\n  Communications (ICC), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a vehicular platoon, a lead vehicle that is responsible for managing the\nplatoon's moving directions and velocity periodically disseminates control\ncommands to following vehicles based on vehicle-to-vehicle communications.\nHowever, reducing command dissemination latency with multiple vehicles while\nensuring successful message delivery to the tail vehicle is challenging. We\npropose a new linear dynamic programming algorithm using backward induction and\ninterchange arguments to minimize the dissemination latency of the vehicles.\nFurthermore, a closed form of dissemination latency in vehicular platoon is\nobtained by utilizing Markov chain with M/M/1 queuing model. Simulation results\nconfirm that the proposed dynamic programming algorithm improves the\ndissemination rate by at least 50.9%, compared to similar algorithms in the\nliterature. Moreover, it also approximates the best performance with the\nmaximum gap of up to 0.2 second in terms of latency.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 18:06:09 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Li", "Kai", ""], ["Ni", "Wei", ""], ["Tovar", "Eduardo", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1801.08618", "submitter": "Amir Erfan Eshratifar", "authors": "Amir Erfan Eshratifar, Mohammad Saeed Abrishami, Massoud Pedram", "title": "JointDNN: An Efficient Training and Inference Engine for Intelligent\n  Mobile Cloud Computing Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are being deployed in many mobile intelligent\napplications. End-side services, such as intelligent personal assistants,\nautonomous cars, and smart home services often employ either simple local\nmodels on the mobile or complex remote models on the cloud. However, recent\nstudies have shown that partitioning the DNN computations between the mobile\nand cloud can increase the latency and energy efficiencies. In this paper, we\npropose an efficient, adaptive, and practical engine, JointDNN, for\ncollaborative computation between a mobile device and cloud for DNNs in both\ninference and training phase. JointDNN not only provides an energy and\nperformance efficient method of querying DNNs for the mobile side but also\nbenefits the cloud server by reducing the amount of its workload and\ncommunications compared to the cloud-only approach. Given the DNN architecture,\nwe investigate the efficiency of processing some layers on the mobile device\nand some layers on the cloud server. We provide optimization formulations at\nlayer granularity for forward- and backward-propagations in DNNs, which can\nadapt to mobile battery limitations and cloud server load constraints and\nquality of service. JointDNN achieves up to 18 and 32 times reductions on the\nlatency and mobile energy consumption of querying DNNs compared to the\nstatus-quo approaches, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 22:20:11 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 20:53:08 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Eshratifar", "Amir Erfan", ""], ["Abrishami", "Mohammad Saeed", ""], ["Pedram", "Massoud", ""]]}, {"id": "1801.08873", "submitter": "Alexander Thomasian", "authors": "Alexander Thomasian", "title": "Mirrored and Hybrid Disk Arrays: Organization, Scheduling, Reliability,\n  and Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Basic mirroring (BM) classified as RAID level 1 replicates data on two disks,\nthus doubling disk access bandwidth for read requests. RAID1/0 is an array of\nBM pairs with balanced loads due to striping. When a disk fails the read load\non its pair is doubled, which results in halving the maximum attainable\nbandwidth. We review RAID1 organizations which attain a balanced load upon disk\nfailure, but as shown by reliability analysis tend to be less reliable than\nRAID1/0. Hybrid disk arrays which store XORed instead of replicated data tend\nto have a higher reliability than mirrored disks, but incur a higher overhead\nin updating data. Read request response time can be improved by processing them\nat a higher priority than writes, since they have a direct effect on\napplication response time. Shortest seek distance and affinity based routing\nboth shorten seek time. Anticipatory arm placement places arms optimally to\nminimize the seek distance. The analysis of RAID1 in normal, degraded, and\nrebuild mode is provided to quantify RAID1/0 performance. We compare the\nreliability of mirrored disk organizations against each other and hybrid disks\nand erasure coded disk arrays.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 15:59:51 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Thomasian", "Alexander", ""]]}, {"id": "1801.09212", "submitter": "Lei Wang", "authors": "Lei Wang, Jianfeng Zhan, Wanling Gao, KaiYong Yang, ZiHan Jiang, Rui\n  Ren, Xiwen He, Chunjie Luo", "title": "BOPS, Not FLOPS! A New Metric and Roofline Performance Model For\n  Datacenter Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For emerging datacenter (in short, DC) workloads, such as online Internet\nservices or offline data analytics, how to evaluate the upper bound performance\nand provide apple-to-apple comparisons are fundamental problems. To this end, a\nunified computation-centric metric is an essential requirement. As the most\nimportant computation-centric performance metric, FLOPS has guided computing\nsystems evolutions for many years. However, our observations demonstrate that\nthe average FLOPS efficiency of the DC workloads is only 0.1%, which implies\nthat FLOPS is inappropriate for DC computing. To address the above issue, we\npropose BOPS (Basic Operations Per Second), which is the average number of BOPs\n(Basic OPerations) completed per second. We conduct the analysis on the\ncharacteristics of seventeen typical DC workloads and extract the minimum\nrepresentative computation operations set, which is composed of integer and\nfloating point computation operations of arithmetic, comparing and array\naddressing. Then, we propose the formalized BOPS definition and the BOPS based\nupper bound performance model. Finally, the BOPS measuring tool is also\nimplemented. We perform experiments with seventeen DC workloads on three\ntypical Intel processors platforms. First, BOPS can reflect the performance gap\nof different computing systems, the bias between the peak BOPS performance gap\nand the average DC workloads' wall clock time gap is no more than 10%. Second,\nthe Sort workload can achieve 32% BOPS efficiency on the experimental platform.\nAt last, we present two use cases of BOPS. One is the BOPS based system\nevaluation, we illustrate that BOPS can compare performance of workloads from\nmultiple domains. The other is BOPS based optimizations. We show that under the\nguiding of the BOPS based upper bound model, the Sort workload and the Redis\nworkload achieve 4.4X and 1.2X performance improvements respectively.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 11:36:24 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 07:45:16 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 02:04:39 GMT"}, {"version": "v4", "created": "Fri, 8 Nov 2019 10:03:51 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wang", "Lei", ""], ["Zhan", "Jianfeng", ""], ["Gao", "Wanling", ""], ["Yang", "KaiYong", ""], ["Jiang", "ZiHan", ""], ["Ren", "Rui", ""], ["He", "Xiwen", ""], ["Luo", "Chunjie", ""]]}, {"id": "1801.09444", "submitter": "Suejb Memeti", "authors": "Suejb Memeti, Sabri Pllana, Alecio Binotto, Joanna Kolodziej, and\n  Ivona Brandic", "title": "Using Meta-heuristics and Machine Learning for Software Optimization of\n  Parallel Computing Systems: A Systematic Literature Review", "comments": "Preprint", "journal-ref": null, "doi": "10.1007/s00607-018-0614-9", "report-no": null, "categories": "cs.DC cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern parallel computing systems offer high performance, utilizing\nthese powerful computing resources to the highest possible extent demands\nadvanced knowledge of various hardware architectures and parallel programming\nmodels. Furthermore, optimized software execution on parallel computing systems\ndemands consideration of many parameters at compile-time and run-time.\nDetermining the optimal set of parameters in a given execution context is a\ncomplex task, and therefore to address this issue researchers have proposed\ndifferent approaches that use heuristic search or machine learning. In this\npaper, we undertake a systematic literature review to aggregate, analyze and\nclassify the existing software optimization methods for parallel computing\nsystems. We review approaches that use machine learning or meta-heuristics for\nsoftware optimization at compile-time and run-time. Additionally, we discuss\nchallenges and future research directions. The results of this study may help\nto better understand the state-of-the-art techniques that use machine learning\nand meta-heuristics to deal with the complexity of software optimization for\nparallel computing systems. Furthermore, it may aid in understanding the\nlimitations of existing approaches and identification of areas for improvement.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 11:03:37 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 16:22:04 GMT"}, {"version": "v3", "created": "Wed, 2 May 2018 15:37:30 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Memeti", "Suejb", ""], ["Pllana", "Sabri", ""], ["Binotto", "Alecio", ""], ["Kolodziej", "Joanna", ""], ["Brandic", "Ivona", ""]]}]