[{"id": "0704.0730", "submitter": "Hamed Haddadi MSc MIEE", "authors": "Hamed Haddadi, Raul Landa, Miguel Rio, Saleem Bhatti", "title": "Revisiting the Issues On Netflow Sample and Export Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": null, "abstract": "  The high volume of packets and packet rates of traffic on some router links\nmakes it exceedingly difficult for routers to examine every packet in order to\nkeep detailed statistics about the traffic which is traversing the router.\nSampling is commonly applied on routers in order to limit the load incurred by\nthe collection of information that the router has to undertake when evaluating\nflow information for monitoring purposes. The sampling process in nearly all\ncases is a deterministic process of choosing 1 in every N packets on a\nper-interface basis, and then forming the flow statistics based on the\ncollected sampled statistics. Even though this sampling may not be significant\nfor some statistics, such as packet rate, others can be severely distorted.\nHowever, it is important to consider the sampling techniques and their relative\naccuracy when applied to different traffic patterns. The main disadvantage of\nsampling is the loss of accuracy in the collected trace when compared to the\noriginal traffic stream. To date there has not been a detailed analysis of the\nimpact of sampling at a router in various traffic profiles and flow criteria.\nIn this paper, we assess the performance of the sampling process as used in\nNetFlow in detail, and we discuss some techniques for the compensation of loss\nof monitoring detail.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2007 14:47:25 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Haddadi", "Hamed", ""], ["Landa", "Raul", ""], ["Rio", "Miguel", ""], ["Bhatti", "Saleem", ""]]}, {"id": "0704.0788", "submitter": "Kerry Soileau", "authors": "Kerry M. Soileau", "title": "Optimal Synthesis of Multiple Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.PF", "license": null, "abstract": "  In this paper we give a definition of \"algorithm,\" \"finite algorithm,\"\n\"equivalent algorithms,\" and what it means for a single algorithm to dominate a\nset of algorithms. We define a derived algorithm which may have a smaller mean\nexecution time than any of its component algorithms. We give an explicit\nexpression for the mean execution time (when it exists) of the derived\nalgorithm. We give several illustrative examples of derived algorithms with two\ncomponent algorithms. We include mean execution time solutions for\ntwo-algorithm processors whose joint density of execution times are of several\ngeneral forms. For the case in which the joint density for a two-algorithm\nprocessor is a step function, we give a maximum-likelihood estimation scheme\nwith which to analyze empirical processing time data.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2007 19:47:54 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Soileau", "Kerry M.", ""]]}, {"id": "0704.0860", "submitter": "Mohamed Kaaniche", "authors": "Cristina Simache (LAAS), Mohamed Kaaniche (LAAS)", "title": "Availability assessment of SunOS/Solaris Unix Systems based on Syslogd\n  and wtmpx logfiles : a case study", "comments": null, "journal-ref": "Proc. 2005 IEEE Pacific Rim International Symposium on Dependable\n  Computing (PRDC'2005), Changsha, Hunan (Chine), 12-14 D{\\'e}cembre 2005\n  (18/12/2005) 49-56", "doi": null, "report-no": null, "categories": "cs.PF", "license": null, "abstract": "  This paper presents a measurement-based availability assessment study using\nfield data collected during a 4-year period from 373 SunOS/Solaris Unix\nworkstations and servers interconnected through a local area network. We focus\non the estimation of machine uptimes, downtimes and availability based on the\nidentification of failures that caused total service loss. Data corresponds to\nsyslogd event logs that contain a large amount of information about the normal\nactivity of the studied systems as well as their behavior in the presence of\nfailures. It is widely recognized that the information contained in such event\nlogs might be incomplete or imperfect. The solution investigated in this paper\nto address this problem is based on the use of auxiliary sources of data\nobtained from wtmpx files maintained by the SunOS/Solaris Unix operating\nsystem. The results obtained suggest that the combined use of wtmpx and syslogd\nlog files provides more complete information on the state of the target systems\nthat is useful to provide availability estimations that better reflect reality.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2007 08:24:47 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Simache", "Cristina", "", "LAAS"], ["Kaaniche", "Mohamed", "", "LAAS"]]}, {"id": "0704.0861", "submitter": "Mohamed Kaaniche", "authors": "Mohamed Kaaniche (LAAS), Y. Deswarte (LAAS), Eric Alata (LAAS), Marc\n  Dacier (SC), Vincent Nicomette (LAAS)", "title": "Empirical analysis and statistical modeling of attack processes based on\n  honeypots", "comments": null, "journal-ref": "IEEE/IFIP International Conference on Dependable Systems and\n  Networks (DSN-2006) (25/06/2006) 119-124", "doi": null, "report-no": null, "categories": "cs.PF cs.CR", "license": null, "abstract": "  Honeypots are more and more used to collect data on malicious activities on\nthe Internet and to better understand the strategies and techniques used by\nattackers to compromise target systems. Analysis and modeling methodologies are\nneeded to support the characterization of attack processes based on the data\ncollected from the honeypots. This paper presents some empirical analyses based\non the data collected from the Leurr{\\'e}.com honeypot platforms deployed on\nthe Internet and presents some preliminary modeling studies aimed at fulfilling\nsuch objectives.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2007 08:50:34 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Kaaniche", "Mohamed", "", "LAAS"], ["Deswarte", "Y.", "", "LAAS"], ["Alata", "Eric", "", "LAAS"], ["Dacier", "Marc", "", "SC"], ["Nicomette", "Vincent", "", "LAAS"]]}, {"id": "0704.0865", "submitter": "Mohamed Kaaniche", "authors": "Ana-Elena Rugina (LAAS), Karama Kanoun (LAAS), Mohamed Kaaniche (LAAS)", "title": "An architecture-based dependability modeling framework using AADL", "comments": null, "journal-ref": "Proc. 10th IASTED International Conference on Software Engineering\n  and Applications (SEA'2006), Dallas (USA), 13-15 November2006 (13/11/2006)\n  222-227", "doi": null, "report-no": null, "categories": "cs.PF cs.SE", "license": null, "abstract": "  For efficiency reasons, the software system designers' will is to use an\nintegrated set of methods and tools to describe specifications and designs, and\nalso to perform analyses such as dependability, schedulability and performance.\nAADL (Architecture Analysis and Design Language) has proved to be efficient for\nsoftware architecture modeling. In addition, AADL was designed to accommodate\nseveral types of analyses. This paper presents an iterative dependency-driven\napproach for dependability modeling using AADL. It is illustrated on a small\nexample. This approach is part of a complete framework that allows the\ngeneration of dependability analysis and evaluation models from AADL models to\nsupport the analysis of software and system architectures, in critical\napplication domains.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2007 09:33:06 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Rugina", "Ana-Elena", "", "LAAS"], ["Kanoun", "Karama", "", "LAAS"], ["Kaaniche", "Mohamed", "", "LAAS"]]}, {"id": "0704.0879", "submitter": "Mohamed Kaaniche", "authors": "Mohamed Kaaniche (LAAS), Luigi Romano (UIUC), Zbigniew Kalbarczyk\n  (UIUC), Ravishankar Iyer (UIUC), Rick Karcich (STORAGETEK)", "title": "A Hierarchical Approach for Dependability Analysis of a Commercial\n  Cache-Based RAID Storage Architecture", "comments": null, "journal-ref": "Proc. 28th IEEE International Symposium on Fault-Tolerant\n  Computing (FTCS-28), Munich (Germany), IEEE Computer Society, June 1998,\n  pp.6-15 (1998) 6-15", "doi": null, "report-no": null, "categories": "cs.PF", "license": null, "abstract": "  We present a hierarchical simulation approach for the dependability analysis\nand evaluation of a highly available commercial cache-based RAID storage\nsystem. The archi-tecture is complex and includes several layers of\noverlap-ping error detection and recovery mechanisms. Three ab-straction levels\nhave been developed to model the cache architecture, cache operations, and\nerror detection and recovery mechanism. The impact of faults and errors\noc-curring in the cache and in the disks is analyzed at each level of the\nhierarchy. A simulation submodel is associated with each abstraction level. The\nmodels have been devel-oped using DEPEND, a simulation-based environment for\nsystem-level dependability analysis, which provides facili-ties to inject\nfaults into a functional behavior model, to simulate error detection and\nrecovery mechanisms, and to evaluate quantitative measures. Several fault\nmodels are defined for each submodel to simulate cache component failures, disk\nfailures, transmission errors, and data errors in the cache memory and in the\ndisks. Some of the parame-ters characterizing fault injection in a given\nsubmodel cor-respond to probabilities evaluated from the simulation of the\nlower-level submodel. Based on the proposed method-ology, we evaluate and\nanalyze 1) the system behavior un-der a real workload and high error rate\n(focusing on error bursts), 2) the coverage of the error detection mechanisms\nimplemented in the system and the error latency distribu-tions, and 3) the\naccumulation of errors in the cache and in the disks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2007 11:46:49 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Kaaniche", "Mohamed", "", "LAAS"], ["Romano", "Luigi", "", "UIUC"], ["Kalbarczyk", "Zbigniew", "", "UIUC"], ["Iyer", "Ravishankar", "", "UIUC"], ["Karcich", "Rick", "", "STORAGETEK"]]}, {"id": "0704.1070", "submitter": "Hua Fu", "authors": "Hua Fu and Pooi Yuen Kam", "title": "Differential Diversity Reception of MDPSK over Independent Rayleigh\n  Channels with Nonidentical Branch Statistics and Asymmetric Fading Spectrum", "comments": "5 pages, 3 figures, to present at ISIT2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": null, "abstract": "  This paper is concerned with optimum diversity receiver structure and its\nperformance analysis of differential phase shift keying (DPSK) with\ndifferential detection over nonselective, independent, nonidentically\ndistributed, Rayleigh fading channels. The fading process in each branch is\nassumed to have an arbitrary Doppler spectrum with arbitrary Doppler bandwidth,\nbut to have distinct, asymmetric fading power spectral density characteristic.\nUsing 8-DPSK as an example, the average bit error probability (BEP) of the\noptimum diversity receiver is obtained by calculating the BEP for each of the\nthree individual bits. The BEP results derived are given in exact, explicit,\nclosed-form expressions which show clearly the behavior of the performance as a\nfunction of various system parameters.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2007 07:16:39 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Fu", "Hua", ""], ["Kam", "Pooi Yuen", ""]]}]