[{"id": "1709.00086", "submitter": "Deborah Bard", "authors": "Brian Friesen, Md. Mostofa Ali Patwary, Brian Austin, Nadathur Satish,\n  Zachary Slepian, Narayanan Sundaram, Deborah Bard, Daniel J Eisenstein, Jack\n  Deslippe, Pradeep Dubey, Prabhat", "title": "Galactos: Computing the Anisotropic 3-Point Correlation Function for 2\n  Billion Galaxies", "comments": "11 pages, 7 figures, accepted to SuperComputing 2017", "journal-ref": null, "doi": "10.1145/3126908.3126927", "report-no": null, "categories": "astro-ph.CO cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nature of dark energy and the complete theory of gravity are two central\nquestions currently facing cosmology. A vital tool for addressing them is the\n3-point correlation function (3PCF), which probes deviations from a spatially\nrandom distribution of galaxies. However, the 3PCF's formidable computational\nexpense has prevented its application to astronomical surveys comprising\nmillions to billions of galaxies. We present Galactos, a high-performance\nimplementation of a novel, O(N^2) algorithm that uses a load-balanced k-d tree\nand spherical harmonic expansions to compute the anisotropic 3PCF. Our\nimplementation is optimized for the Intel Xeon Phi architecture, exploiting\nSIMD parallelism, instruction and thread concurrency, and significant L1 and L2\ncache reuse, reaching 39% of peak performance on a single node. Galactos scales\nto the full Cori system, achieving 9.8PF (peak) and 5.06PF (sustained) across\n9636 nodes, making the 3PCF easily computable for all galaxies in the\nobservable universe.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 21:14:32 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Friesen", "Brian", ""], ["Patwary", "Md. Mostofa Ali", ""], ["Austin", "Brian", ""], ["Satish", "Nadathur", ""], ["Slepian", "Zachary", ""], ["Sundaram", "Narayanan", ""], ["Bard", "Deborah", ""], ["Eisenstein", "Daniel J", ""], ["Deslippe", "Jack", ""], ["Dubey", "Pradeep", ""], ["Prabhat", "", ""]]}, {"id": "1709.00333", "submitter": "Kyumars Sheykh Esmaili", "authors": "Philippe Dobbelaere and Kyumars Sheykh Esmaili", "title": "Kafka versus RabbitMQ", "comments": "25 single-column pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Publish/subscribe is a distributed interaction paradigm well adapted to the\ndeployment of scalable and loosely coupled systems.\n  Apache Kafka and RabbitMQ are two popular open-source and\ncommercially-supported pub/sub systems that have been around for almost a\ndecade and have seen wide adoption. Given the popularity of these two systems\nand the fact that both are branded as pub/sub systems, two frequently asked\nquestions in the relevant online forums are: how do they compare against each\nother and which one to use?\n  In this paper, we frame the arguments in a holistic approach by establishing\na common comparison framework based on the core functionalities of pub/sub\nsystems. Using this framework, we then venture into a qualitative and\nquantitative (i.e. empirical) comparison of the common features of the two\nsystems. Additionally, we also highlight the distinct features that each of\nthese systems has. After enumerating a set of use cases that are best suited\nfor RabbitMQ or Kafka, we try to guide the reader through a determination table\nto choose the best architecture given his/her particular set of requirements.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 14:27:19 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Dobbelaere", "Philippe", ""], ["Esmaili", "Kyumars Sheykh", ""]]}, {"id": "1709.00722", "submitter": "Kjell Winblad", "authors": "Kjell Winblad", "title": "Faster Concurrent Range Queries with Contention Adapting Search Trees\n  Using Immutable Data", "comments": "12 pages, 21 figures, To be published in 2017 Imperial College\n  Computing Student Workshop (ICCSW 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The need for scalable concurrent ordered set data structures with\nlinearizable range query support is increasing due to the rise of multicore\ncomputers, data processing platforms and in-memory databases. This paper\npresents a new concurrent ordered set with linearizable range query support.\nThe new data structure is based on the contention adapting search tree and an\nimmutable data structure. Experimental results show that the new data structure\nis as much as three times faster compared to related data structures. The data\nstructure scales well due to its ability to adapt the sizes of its immutable\nparts to the contention level and the sizes of the range queries.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 14:25:24 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Winblad", "Kjell", ""]]}, {"id": "1709.01190", "submitter": "Yiqiu Wang", "authors": "Yiqiu Wang, Anshumali Shrivastava, Jonathan Wang, Junghee Ryu", "title": "FLASH: Randomized Algorithms Accelerated over CPU-GPU for Ultra-High\n  Dimensional Similarity Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.DC cs.IR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FLASH (\\textbf{F}ast \\textbf{L}SH \\textbf{A}lgorithm for\n\\textbf{S}imilarity search accelerated with \\textbf{H}PC), a similarity search\nsystem for ultra-high dimensional datasets on a single machine, that does not\nrequire similarity computations and is tailored for high-performance computing\nplatforms. By leveraging a LSH style randomized indexing procedure and\ncombining it with several principled techniques, such as reservoir sampling,\nrecent advances in one-pass minwise hashing, and count based estimations, we\nreduce the computational and parallelization costs of similarity search, while\nretaining sound theoretical guarantees.\n  We evaluate FLASH on several real, high-dimensional datasets from different\ndomains, including text, malicious URL, click-through prediction, social\nnetworks, etc. Our experiments shed new light on the difficulties associated\nwith datasets having several million dimensions. Current state-of-the-art\nimplementations either fail on the presented scale or are orders of magnitude\nslower than FLASH. FLASH is capable of computing an approximate k-NN graph,\nfrom scratch, over the full webspam dataset (1.3 billion nonzeros) in less than\n10 seconds. Computing a full k-NN graph in less than 10 seconds on the webspam\ndataset, using brute-force ($n^2D$), will require at least 20 teraflops. We\nprovide CPU and GPU implementations of FLASH for replicability of our results.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 23:09:19 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 07:09:23 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Wang", "Yiqiu", ""], ["Shrivastava", "Anshumali", ""], ["Wang", "Jonathan", ""], ["Ryu", "Junghee", ""]]}, {"id": "1709.01477", "submitter": "Rostislav Razumchik", "authors": "Mikhail Konovalov and Rostislav Razumchik", "title": "Queueing systems with renovation vs. queues with RED. Supplementary\n  Material", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we consider M/D/1/N queue with renovation and derive analytic\nexpressions for the following performance characteristics: stationary loss\nrate, moments of the number in the system. Moments of consecutive losses,\nwaiting/sojourn time are out of scope. The motivation for studying these\ncharacteristics is in the comparison of renovation with known active queue\nmechanisms like RED.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 16:22:47 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Konovalov", "Mikhail", ""], ["Razumchik", "Rostislav", ""]]}, {"id": "1709.02101", "submitter": "EPTCS", "authors": "John C. McCabe-Dansted, Mark Reynolds (The University of Western\n  Australia)", "title": "A Parallel Linear Temporal Logic Tableau", "comments": "In Proceedings GandALF 2017, arXiv:1709.01761", "journal-ref": "EPTCS 256, 2017, pp. 166-179", "doi": "10.4204/EPTCS.256.12", "report-no": null, "categories": "cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many applications, we are unable to take full advantage of the potential\nmassive parallelisation offered by supercomputers or cloud computing because it\nis too hard to work out how to divide up the computation task between\nprocessors in such a way to minimise the need for communication. However, a\nrecently developed branch-independent tableaux for the common LTL temporal\nlogic should intuitively be easy to parallelise as each branch can be developed\nindependently. Here we describe a simple technique for partitioning such a\ntableau such that each partition can be processed independently without need\nfor interprocess communication. We investigate the extent to which this\ntechnique improves the performance of the LTL tableau on standard benchmarks\nand random formulas.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 06:57:51 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["McCabe-Dansted", "John C.", "", "The University of Western\n  Australia"], ["Reynolds", "Mark", "", "The University of Western\n  Australia"]]}, {"id": "1709.02108", "submitter": "EPTCS", "authors": "Andrei Sandler (University of Hertfordshire), Olga Tveretina\n  (University of Hertfordshire)", "title": "ParaPlan: A Tool for Parallel Reachability Analysis of Planar Polygonal\n  Differential Inclusion Systems", "comments": "In Proceedings GandALF 2017, arXiv:1709.01761", "journal-ref": "EPTCS 256, 2017, pp. 283-296", "doi": "10.4204/EPTCS.256.20", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the ParaPlan tool which provides the reachability analysis of\nplanar hybrid systems defined by differential inclusions (SPDI). It uses the\nparallelized and optimized version of the algorithm underlying the SPeeDI tool.\nThe performance comparison demonstrates the speed-up of up to 83 times with\nrespect to the sequential implementation on various benchmarks. Some of the\nbenchmarks we used are randomly generated with the novel approach based on the\npartitioning of the plane with Voronoi diagrams.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 07:00:38 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Sandler", "Andrei", "", "University of Hertfordshire"], ["Tveretina", "Olga", "", "University of Hertfordshire"]]}, {"id": "1709.02225", "submitter": "Niv Gabso", "authors": "Assaf Yifrach, Niv Gabso", "title": "Enhancing KiWi - Scalable Concurrent Key-Value Map", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take a relatively fresh wait-free, concurrent sorted map called KiWi, fix\nand enhance it. First, we test its linearizability by fuzzing and applying\nWing&Gong [2] linearizability test. After fixing a few bugs in the algorithm\ndesign and its implementation, we enhance it. We design, implement and test two\nnew linearizable operations sizeLowerBound() and sizeUpperBound(). We further\ncompose these operations to create more useful operations. Last, we evaluate\nthe map performance because previous evaluations became obsolete due to our bug\ncorrections.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 13:23:27 GMT"}, {"version": "v2", "created": "Fri, 13 Oct 2017 06:02:36 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Yifrach", "Assaf", ""], ["Gabso", "Niv", ""]]}, {"id": "1709.02280", "submitter": "Pooyan Jamshidi", "authors": "Pooyan Jamshidi, Norbert Siegmund, Miguel Velez, Christian K\\\"astner,\n  Akshay Patel, Yuvraj Agarwal", "title": "Transfer Learning for Performance Modeling of Configurable Systems: An\n  Exploratory Analysis", "comments": "To appear in 32nd IEEE/ACM International Conference on Automated\n  Software Engineering (ASE 2017), 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern software systems provide many configuration options which\nsignificantly influence their non-functional properties. To understand and\npredict the effect of configuration options, several sampling and learning\nstrategies have been proposed, albeit often with significant cost to cover the\nhighly dimensional configuration space. Recently, transfer learning has been\napplied to reduce the effort of constructing performance models by transferring\nknowledge about performance behavior across environments. While this line of\nresearch is promising to learn more accurate models at a lower cost, it is\nunclear why and when transfer learning works for performance modeling. To shed\nlight on when it is beneficial to apply transfer learning, we conducted an\nempirical study on four popular software systems, varying software\nconfigurations and environmental conditions, such as hardware, workload, and\nsoftware versions, to identify the key knowledge pieces that can be exploited\nfor transfer learning. Our results show that in small environmental changes\n(e.g., homogeneous workload change), by applying a linear transformation to the\nperformance model, we can understand the performance behavior of the target\nenvironment, while for severe environmental changes (e.g., drastic workload\nchange) we can transfer only knowledge that makes sampling more efficient,\ne.g., by reducing the dimensionality of the configuration space.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 14:31:21 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Jamshidi", "Pooyan", ""], ["Siegmund", "Norbert", ""], ["Velez", "Miguel", ""], ["K\u00e4stner", "Christian", ""], ["Patel", "Akshay", ""], ["Agarwal", "Yuvraj", ""]]}, {"id": "1709.02500", "submitter": "Mark Amo-Boateng PhD.", "authors": "Mark Amo-Boateng", "title": "Super-speeds with Zero-RAM: Next Generation Large-Scale Optimization in\n  Your Laptop!", "comments": "7 pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS cs.PF math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the novel breakthrough general purpose algorithm for\nlarge scale optimization problems. The novel algorithm is capable of achieving\nbreakthrough speeds for very large-scale optimization on general purpose\nlaptops and embedded systems. Application of the algorithm to the Griewank\nfunction was possible in up to 1 billion decision variables in double precision\ntook only 64485 seconds (~18 hours) to solve, while consuming 7,630 MB (7.6 GB)\nor RAM on a single threaded laptop CPU. It shows that the algorithm is\ncomputationally and memory (space) linearly efficient, and can find the optimal\nor near-optimal solution in a fraction of the time and memory that many\nconventional algorithms require. It is envisaged that this will open up new\npossibilities of real-time large-scale problems on personal laptops and\nembedded systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 01:47:56 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 01:14:46 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Amo-Boateng", "Mark", ""]]}, {"id": "1709.02718", "submitter": "Mayank Mishra", "authors": "Mayank Mishra and Arun K. Somani", "title": "On-Disk Data Processing: Issues and Future Directions", "comments": "24 pages, 17 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a survey of \"on-disk\" data processing (ODDP). ODDP,\nwhich is a form of near-data processing, refers to the computing arrangement\nwhere the secondary storage drives have the data processing capability.\nProposed ODDP schemes vary widely in terms of the data processing capability,\ntarget applications, architecture and the kind of storage drive employed. Some\nODDP schemes provide only a specific but heavily used operation like sort\nwhereas some provide a full range of operations. Recently, with the advent of\nSolid State Drives, powerful and extensive ODDP solutions have been proposed.\nIn this paper, we present a thorough review of architectures developed for\ndifferent on-disk processing approaches along with current and future\nchallenges and also identify the future directions which ODDP can take.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 14:28:12 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Mishra", "Mayank", ""], ["Somani", "Arun K.", ""]]}, {"id": "1709.03264", "submitter": "Miguel Cardenas Montes", "authors": "Miguel C\\'ardenas-Montes, Iv\\'an M\\'endez-Jim\\'enez, Juan Jos\\'e\n  Rodr\\'iguez-V\\'azquez, and Jos\\'e Mar\\'ia Hern\\'andez Calama", "title": "Report: Performance comparison between C2075 and P100 GPU cards using\n  cosmological correlation functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, some cosmological correlation functions are used to evaluate\nthe differential performance between C2075 and P100 GPU cards. In the past, the\ncorrelation functions used in this work have been widely studied and exploited\non some previous GPU architectures. The analysis of the performance indicates\nthat a speedup in the range from 13 to 15 is achieved without any additional\noptimization process for the P100 card.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 07:03:23 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["C\u00e1rdenas-Montes", "Miguel", ""], ["M\u00e9ndez-Jim\u00e9nez", "Iv\u00e1n", ""], ["Rodr\u00edguez-V\u00e1zquez", "Juan Jos\u00e9", ""], ["Calama", "Jos\u00e9 Mar\u00eda Hern\u00e1ndez", ""]]}, {"id": "1709.03745", "submitter": "Michael Kirsche", "authors": "Anna F\\\"orster, Asanga Udugama, Andreas K\\\"onsgen, Antonio Virdis,\n  Michael Kirsche", "title": "Proceedings of the 4th OMNeT++ Community Summit, University of Bremen -\n  Germany, September 7-8, 2017", "comments": "Proceedings of the 4th OMNeT++ Community Summit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the Proceedings of the 4th OMNeT++ Community Summit, which was held\nat the University of Bremen - Germany - on September 7-8, 2017.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 08:59:09 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["F\u00f6rster", "Anna", ""], ["Udugama", "Asanga", ""], ["K\u00f6nsgen", "Andreas", ""], ["Virdis", "Antonio", ""], ["Kirsche", "Michael", ""]]}, {"id": "1709.04794", "submitter": "Joris Tavernier", "authors": "Joris Tavernier, Jaak Simm, Karl Meerbergen, Joerg Kurt Wegner, Hugo\n  Ceulemans and Yves Moreau", "title": "Fast semi-supervised discriminant analysis for binary classification of\n  large data-sets", "comments": null, "journal-ref": null, "doi": "10.1016/j.patcog.2019.02.015", "report-no": null, "categories": "cs.AI cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data requires scalable algorithms. We propose and analyze\nthree scalable and related algorithms for semi-supervised discriminant analysis\n(SDA). These methods are based on Krylov subspace methods which exploit the\ndata sparsity and the shift-invariance of Krylov subspaces. In addition, the\nproblem definition was improved by adding centralization to the semi-supervised\nsetting. The proposed methods are evaluated on a industry-scale data set from a\npharmaceutical company to predict compound activity on target proteins. The\nresults show that SDA achieves good predictive performance and our methods only\nrequire a few seconds, significantly improving computation time on previous\nstate of the art.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 13:53:49 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 14:00:31 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Tavernier", "Joris", ""], ["Simm", "Jaak", ""], ["Meerbergen", "Karl", ""], ["Wegner", "Joerg Kurt", ""], ["Ceulemans", "Hugo", ""], ["Moreau", "Yves", ""]]}, {"id": "1709.06395", "submitter": "Anna F\\\"orster", "authors": "Anna F\\\"orster, Anas Bin Muslim, Asanga Udugama", "title": "Reactive User Behavior and Mobility Models", "comments": "Published in: A. Foerster, A. Udugama, A. Koensgen, A. Virdis, M.\n  Kirsche (Eds.), Proc. of the 4th OMNeT++ Community Summit, University of\n  Bremen - Germany - September 7-8, 2017", "journal-ref": null, "doi": null, "report-no": "OMNET/2017/07", "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a set of simulation models to more realistically\nmimic the behaviour of users reading messages. We propose a User Behaviour\nModel, where a simulated user reacts to a message by a flexible set of possible\nreactions (e.g. ignore, read, like, save, etc.) and a mobility-based reaction\n(visit a place, run away from danger, etc.). We describe our models and their\nimplementation in OMNeT++. We strongly believe that these models will\nsignificantly contribute to the state of the art of simulating realistically\nopportunistic networks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 22:18:07 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["F\u00f6rster", "Anna", ""], ["Muslim", "Anas Bin", ""], ["Udugama", "Asanga", ""]]}, {"id": "1709.06416", "submitter": "Shoumik Palkar", "authors": "Shoumik Palkar, James Thomas, Deepak Narayanan, Anil Shanbhag, Rahul\n  Palamuttam, Holger Pirk, Malte Schwarzkopf, Saman Amarasinghe, Samuel Madden,\n  and Matei Zaharia", "title": "Weld: Rethinking the Interface Between Data-Intensive Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analytics applications combine multiple functions from different\nlibraries and frameworks. Even when each function is optimized in isolation,\nthe performance of the combined application can be an order of magnitude below\nhardware limits due to extensive data movement across these functions. To\naddress this problem, we propose Weld, a new interface between data-intensive\nlibraries that can optimize across disjoint libraries and functions. Weld\nexposes a lazily-evaluated API where diverse functions can submit their\ncomputations in a simple but general intermediate representation that captures\ntheir data-parallel structure. It then optimizes data movement across these\nfunctions and emits efficient code for diverse hardware. Weld can be integrated\ninto existing frameworks such as Spark, TensorFlow, Pandas and NumPy without\nchanging their user-facing APIs. We demonstrate that Weld can speed up\napplications using these frameworks by up to 29x.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 05:37:20 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 20:35:12 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Palkar", "Shoumik", ""], ["Thomas", "James", ""], ["Narayanan", "Deepak", ""], ["Shanbhag", "Anil", ""], ["Palamuttam", "Rahul", ""], ["Pirk", "Holger", ""], ["Schwarzkopf", "Malte", ""], ["Amarasinghe", "Saman", ""], ["Madden", "Samuel", ""], ["Zaharia", "Matei", ""]]}, {"id": "1709.07035", "submitter": "Behruz Khalilov", "authors": "Behruz Khalilov, Anna F\\\"orster, Asanga Udugama", "title": "Radio Irregularity Model in OMNeT++", "comments": "Published in: A. Foerster, A. Udugama, A. Koensgen, A. Virdis, M.\n  Kirsche (Eds.), Proc. of the 4th OMNeT++ Community Summit, University of\n  Bremen - Germany - September 7-8, 2017", "journal-ref": null, "doi": null, "report-no": "OMNET/2017/04", "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio irregularity is a non-negligible phenomenon that has an impact on\nprotocol performances. For instance, irregularity in radio range leads to\nasymmetric links that cause the loss of packets in different directions. In\norder to investigate its effect, the Radio Irregularity Model (RIM) is proposed\nthat takes into account the irregularity of a radio range and estimates path\nlosses in an anisotropic environment. The purpose of this paper is to provide\ndetails of the RIM model developed in the INET Framework of the OMNeT++\nsimulator that can be used to investigate the impact of radio irregularity on\nprotocol performance.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 12:41:17 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Khalilov", "Behruz", ""], ["F\u00f6rster", "Anna", ""], ["Udugama", "Asanga", ""]]}, {"id": "1709.07122", "submitter": "Kartik Lakhotia", "authors": "Kartik Lakhotia, Rajgopal Kannan, Viktor Prasanna", "title": "Accelerating PageRank using Partition-Centric Processing", "comments": "Added acknowledgments. In proceedings of USENIX ATC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PageRank is a fundamental link analysis algorithm that also functions as a\nkey representative of the performance of Sparse Matrix-Vector (SpMV)\nmultiplication. The traditional PageRank implementation generates fine\ngranularity random memory accesses resulting in large amount of wasteful DRAM\ntraffic and poor bandwidth utilization. In this paper, we present a novel\nPartition-Centric Processing Methodology (PCPM) to compute PageRank, that\ndrastically reduces the amount of DRAM communication while achieving high\nsustained memory bandwidth. PCPM uses a Partition-centric abstraction coupled\nwith the Gather-Apply-Scatter (GAS) programming model. By carefully examining\nhow a PCPM based implementation impacts communication characteristics of the\nalgorithm, we propose several system optimizations that improve the execution\ntime substantially. More specifically, we develop (1) a new data layout that\nsignificantly reduces communication and random DRAM accesses, and (2) branch\navoidance mechanisms to get rid of unpredictable data-dependent branches.\n  We perform detailed analytical and experimental evaluation of our approach\nusing 6 large graphs and demonstrate an average 2.7x speedup in execution time\nand 1.7x reduction in communication volume, compared to the state-of-the-art.\nWe also show that unlike other GAS based implementations, PCPM is able to\nfurther reduce main memory traffic by taking advantage of intelligent node\nlabeling that enhances locality. Although we use PageRank as the target\napplication in this paper, our approach can be applied to generic SpMV\ncomputation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 01:41:34 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 19:26:08 GMT"}, {"version": "v3", "created": "Wed, 7 Feb 2018 09:02:35 GMT"}, {"version": "v4", "created": "Mon, 6 Aug 2018 20:32:23 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Lakhotia", "Kartik", ""], ["Kannan", "Rajgopal", ""], ["Prasanna", "Viktor", ""]]}, {"id": "1709.07536", "submitter": "Mejbah Alam", "authors": "Mejbah Alam, Justin Gottschlich, Nesime Tatbul, Javier Turek, Timothy\n  Mattson, Abdullah Muzahid", "title": "A Zero-Positive Learning Approach for Diagnosing Software Performance\n  Regressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of machine programming (MP), the automation of the development of\nsoftware, is making notable research advances. This is, in part, due to the\nemergence of a wide range of novel techniques in machine learning. In this\npaper, we apply MP to the automation of software performance regression\ntesting. A performance regression is a software performance degradation caused\nby a code change. We present AutoPerf - a novel approach to automate regression\ntesting that utilizes three core techniques: (i) zero-positive learning, (ii)\nautoencoders, and (iii) hardware telemetry. We demonstrate AutoPerf's\ngenerality and efficacy against 3 types of performance regressions across 10\nreal performance bugs in 7 benchmark and open-source programs. On average,\nAutoPerf exhibits 4% profiling overhead and accurately diagnoses more\nperformance bugs than prior state-of-the-art approaches. Thus far, AutoPerf has\nproduced no false negatives.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 22:39:39 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 18:53:21 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 21:07:46 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 23:38:38 GMT"}, {"version": "v5", "created": "Fri, 1 Nov 2019 06:17:41 GMT"}, {"version": "v6", "created": "Wed, 1 Jan 2020 19:10:01 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Alam", "Mejbah", ""], ["Gottschlich", "Justin", ""], ["Tatbul", "Nesime", ""], ["Turek", "Javier", ""], ["Mattson", "Timothy", ""], ["Muzahid", "Abdullah", ""]]}, {"id": "1709.08115", "submitter": "Ali Yekkehkhany", "authors": "Ali Yekkehkhany, Avesta Hojjati, Mohammad H Hajiesmaili", "title": "GB-PANDAS: Throughput and heavy-traffic optimality analysis for affinity\n  scheduling", "comments": "IFIP WG 7.3 Performance 2017 - The 35th International Symposium on\n  Computer Performance, Modeling, Measurements and Evaluation 2017", "journal-ref": null, "doi": "10.1145/3199524.3199528", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic affinity scheduling has been an open problem for nearly three\ndecades. The problem is to dynamically schedule multi-type tasks to\nmulti-skilled servers such that the resulting queueing system is both stable in\nthe capacity region (throughput optimality) and the mean delay of tasks is\nminimized at high loads near the boundary of the capacity region (heavy-traffic\noptimality). As for applications, data-intensive analytics like MapReduce,\nHadoop, and Dryad fit into this setting, where the set of servers is\nheterogeneous for different task types, so the pair of task type and server\ndetermines the processing rate of the task. The load balancing algorithm used\nin such frameworks is an example of affinity scheduling which is desired to be\nboth robust and delay optimal at high loads when hot-spots occur. Fluid model\nplanning, the MaxWeight algorithm, and the generalized $c\\mu$-rule are among\nthe first algorithms proposed for affinity scheduling that have theoretical\nguarantees on being optimal in different senses, which will be discussed in the\nrelated work section. All these algorithms are not practical for use in data\ncenter applications because of their non-realistic assumptions. The\njoin-the-shortest-queue-MaxWeight (JSQ-MaxWeight), JSQ-Priority, and\nweighted-workload algorithms are examples of load balancing policies for\nsystems with two and three levels of data locality with a rack structure. In\nthis work, we propose the Generalized-Balanced-Pandas algorithm (GB-PANDAS) for\na system with multiple levels of data locality and prove its throughput\noptimality. We prove this result under an arbitrary distribution for service\ntimes, whereas most previous theoretical work assumes geometric distribution\nfor service times. The extensive simulation results show that the GB-PANDAS\nalgorithm alleviates the mean delay and has a better performance than the\nJSQ-MaxWeight algorithm by twofold\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 20:38:25 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Yekkehkhany", "Ali", ""], ["Hojjati", "Avesta", ""], ["Hajiesmaili", "Mohammad H", ""]]}, {"id": "1709.08951", "submitter": "Andre van Hoorn", "authors": "Andre van Hoorn, Pooyan Jamshidi, Philipp Leitner, Ingo Weber", "title": "Report from GI-Dagstuhl Seminar 16394: Software Performance Engineering\n  in the DevOps World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report documents the program and the outcomes of GI-Dagstuhl Seminar\n16394 \"Software Performance Engineering in the DevOps World\".\n  The seminar addressed the problem of performance-aware DevOps. Both, DevOps\nand performance engineering have been growing trends over the past one to two\nyears, in no small part due to the rise in importance of identifying\nperformance anomalies in the operations (Ops) of cloud and big data systems and\nfeeding these back to the development (Dev). However, so far, the research\ncommunity has treated software engineering, performance engineering, and cloud\ncomputing mostly as individual research areas. We aimed to identify\ncross-community collaboration, and to set the path for long-lasting\ncollaborations towards performance-aware DevOps.\n  The main goal of the seminar was to bring together young researchers (PhD\nstudents in a later stage of their PhD, as well as PostDocs or Junior\nProfessors) in the areas of (i) software engineering, (ii) performance\nengineering, and (iii) cloud computing and big data to present their current\nresearch projects, to exchange experience and expertise, to discuss research\nchallenges, and to develop ideas for future collaborations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 11:42:34 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["van Hoorn", "Andre", ""], ["Jamshidi", "Pooyan", ""], ["Leitner", "Philipp", ""], ["Weber", "Ingo", ""]]}, {"id": "1709.09108", "submitter": "Lenore Mullin", "authors": "John L. Gustafson and Lenore M. Mullin", "title": "Tensors Come of Age: Why the AI Revolution will help HPC", "comments": "To be published in this years 30th anniversary edition of HPCwire", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article discusses how the automation of tensor algorithms, based on A\nMathematics of Arrays and Psi Calculus, and a new way to represent numbers,\nUnum Arithmetic, enables mechanically provable, scalable, portable, and more\nnumerically accurate software.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 16:11:43 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Gustafson", "John L.", ""], ["Mullin", "Lenore M.", ""]]}, {"id": "1709.09369", "submitter": "Giuseppe Lipari", "authors": "Cl\\'ement Ballabriga, Julien Forget, Giuseppe Lipari", "title": "Symbolic Computation of the Worst-Case Execution Time of a Program", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric Worst-case execution time (WCET) analysis of a sequential program\nproduces a formula that represents the worst-case execution time of the\nprogram, where parameters of the formula are user-defined parameters of the\nprogram (as loop bounds, values of inputs or internal variables, etc).\n  In this paper we propose a novel methodology to compute the parametric WCET\nof a program. Unlike other algorithms in the literature, our method is not\nbased on Integer Linear Programming (ILP). Instead, we follow an approach based\non the notion of symbolic computation of WCET formulae. After explaining our\nmethodology and proving its correctness, we present a set of experiments to\ncompare our method against the state of the art. We show that our approach\ndominates other parametric analyses, and produces results that are very close\nto those produced by non-parametric ILP-based approaches, while keeping very\ngood computing time.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 07:40:57 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Ballabriga", "Cl\u00e9ment", ""], ["Forget", "Julien", ""], ["Lipari", "Giuseppe", ""]]}, {"id": "1709.09713", "submitter": "Satya Pramod Jammy", "authors": "Satya P. Jammy, Christian T. Jacobs, David J. Lusher, Neil D. Sandham", "title": "Energy efficiency of finite difference algorithms on multicore CPUs,\n  GPUs, and Intel Xeon Phi processors", "comments": "Submitted to Computers and Fluids", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PF physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to hardware wall-time restrictions commonly seen in\nhigh-performance computing systems, it is likely that future systems will also\nbe constrained by energy budgets. In the present work, finite difference\nalgorithms of varying computational and memory intensity are evaluated with\nrespect to both energy efficiency and runtime on an Intel Ivy Bridge CPU node,\nan Intel Xeon Phi Knights Landing processor, and an NVIDIA Tesla K40c GPU. The\nconventional way of storing the discretised derivatives to global arrays for\nsolution advancement is found to be inefficient in terms of energy consumption\nand runtime. In contrast, a class of algorithms in which the discretised\nderivatives are evaluated on-the-fly or stored as thread-/process-local\nvariables (yielding high compute intensity) is optimal both with respect to\nenergy consumption and runtime. On all three hardware architectures considered,\na speed-up of ~2 and an energy saving of ~2 are observed for the high compute\nintensive algorithms compared to the memory intensive algorithm. The energy\nconsumption is found to be proportional to runtime, irrespective of the power\nconsumed and the GPU has an energy saving of ~5 compared to the same algorithm\non a CPU node.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 19:52:03 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Jammy", "Satya P.", ""], ["Jacobs", "Christian T.", ""], ["Lusher", "David J.", ""], ["Sandham", "Neil D.", ""]]}, {"id": "1709.10140", "submitter": "Carlos Eduardo Arango Gutierrez", "authors": "Carlos Arango, R\\'emy Dernat, John Sanabria", "title": "Performance Evaluation of Container-based Virtualization for High\n  Performance Computing Environments", "comments": "Keywords: Container-based virtualization; Linux containers;\n  Singularity-Containers; Docker; High performance computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Virtualization technologies have evolved along with the development of\ncomputational environments since virtualization offered needed features at that\ntime such as isolation, accountability, resource allocation, resource fair\nsharing and so on. Novel processor technologies bring to commodity computers\nthe possibility to emulate diverse environments where a wide range of\ncomputational scenarios can be run. Along with processors evolution, system\ndevelopers have created different virtualization mechanisms where each new\ndevelopment enhanced the performance of previous virtualized environments.\nRecently, operating system-based virtualization technologies captured the\nattention of communities abroad (from industry to academy and research) because\ntheir important improvements on performance area.\n  In this paper, the features of three container-based operating systems\nvirtualization tools (LXC, Docker and Singularity) are presented. LXC, Docker,\nSingularity and bare metal are put under test through a customized single node\nHPL-Benchmark and a MPI-based application for the multi node testbed. Also the\ndisk I/O performance, Memory (RAM) performance, Network bandwidth and GPU\nperformance are tested for the COS technologies vs bare metal. Preliminary\nresults and conclusions around them are presented and discussed.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 19:30:05 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Arango", "Carlos", ""], ["Dernat", "R\u00e9my", ""], ["Sanabria", "John", ""]]}]