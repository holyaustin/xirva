[{"id": "1507.00898", "submitter": "Carsten Kutzner", "authors": "Carsten Kutzner, Szil\\'ard P\\'all, Martin Fechner, Ansgar Esztermann,\n  Bert L. de Groot, Helmut Grubm\\\"uller", "title": "Best bang for your buck: GPU nodes for GROMACS biomolecular simulations", "comments": null, "journal-ref": "Journal of Computational Chemistry, 2015, 36, 1990-2008", "doi": "10.1002/jcc.24030", "report-no": null, "categories": "cs.DC cs.PF physics.bio-ph physics.comp-ph q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The molecular dynamics simulation package GROMACS runs efficiently on a wide\nvariety of hardware from commodity workstations to high performance computing\nclusters. Hardware features are well exploited with a combination of SIMD,\nmulti-threading, and MPI-based SPMD/MPMD parallelism, while GPUs can be used as\naccelerators to compute interactions offloaded from the CPU. Here we evaluate\nwhich hardware produces trajectories with GROMACS 4.6 or 5.0 in the most\neconomical way. We have assembled and benchmarked compute nodes with various\nCPU/GPU combinations to identify optimal compositions in terms of raw\ntrajectory production rate, performance-to-price ratio, energy efficiency, and\nseveral other criteria. Though hardware prices are naturally subject to trends\nand fluctuations, general tendencies are clearly visible. Adding any type of\nGPU significantly boosts a node's simulation performance. For inexpensive\nconsumer-class GPUs this improvement equally reflects in the\nperformance-to-price ratio. Although memory issues in consumer-class GPUs could\npass unnoticed since these cards do not support ECC memory, unreliable GPUs can\nbe sorted out with memory checking tools. Apart from the obvious determinants\nfor cost-efficiency like hardware expenses and raw performance, the energy\nconsumption of a node is a major cost factor. Over the typical hardware\nlifetime until replacement of a few years, the costs for electrical power and\ncooling can become larger than the costs of the hardware itself. Taking that\ninto account, nodes with a well-balanced ratio of CPU and consumer-class GPU\nresources produce the maximum amount of GROMACS trajectory over their lifetime.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2015 13:04:54 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kutzner", "Carsten", ""], ["P\u00e1ll", "Szil\u00e1rd", ""], ["Fechner", "Martin", ""], ["Esztermann", "Ansgar", ""], ["de Groot", "Bert L.", ""], ["Grubm\u00fcller", "Helmut", ""]]}, {"id": "1507.03648", "submitter": "Cengis Hasan", "authors": "Cengis Hasan and Zygmunt J. Haas", "title": "Deadline-aware Power Management in Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the dynamic power optimization problem in data centers. We formulate\nand solve the following offline problem: in which slot which server has to be\nassigned to which job; and in which slot which server has to be switched ON or\nOFF so that the total power is optimal for some time horizon. We show that the\noffline problem is a new version of generalized assignment problem including\nnew constraints issuing from deadline characteristics of jobs and difference of\nactivation energy of servers. We propose an online algorithm that solves the\nproblem heuristically and compare it to randomized routing.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 22:54:20 GMT"}], "update_date": "2015-07-19", "authors_parsed": [["Hasan", "Cengis", ""], ["Haas", "Zygmunt J.", ""]]}, {"id": "1507.04631", "submitter": "Jorg Liebeherr", "authors": "Alireza Shekaramiz and Jorg Liebeherr and Almut Burchard", "title": "Window Flow Control Systems with Random Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension of the window flow control analysis by R. Agrawal\net.al. (Reference [1]), C.-S. Chang (Reference [6]), and C.-S. Chang et. al.\n(Reference [8]) to a system with random service time and fixed feedback delay.\nWe consider two network service models. In the first model, the network service\nprocess itself has no time correlations. The second model addresses a two-state\nMarkov-modulated service.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2015 16:06:18 GMT"}], "update_date": "2015-07-17", "authors_parsed": [["Shekaramiz", "Alireza", ""], ["Liebeherr", "Jorg", ""], ["Burchard", "Almut", ""]]}, {"id": "1507.06702", "submitter": "Jesun Sahariar Firoz", "authors": "Jesun Sahariar Firoz, Thejaka Amila Kanewala, Marcin Zalewski, Martina\n  Barnas, Andrew Lumsdaine", "title": "The Anatomy of Large-Scale Distributed Graph Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing complexity of the software/hardware stack of modern\nsupercomputers results in explosion of parameters. The performance analysis\nbecomes a truly experimental science, even more challenging in the presence of\nmassive irregularity and data dependency. We analyze how the existing body of\nresearch handles the experimental aspect in the context of distributed graph\nalgorithms (DGAs). We distinguish algorithm-level contributions, often\nprioritized by authors, from runtime-level concerns that are harder to place.\nWe show that the runtime is such an integral part of DGAs that experimental\nresults are difficult to interpret and extrapolate without understanding the\nproperties of the runtime used. We argue that in order to gain understanding\nabout the impact of runtimes, more information needs to be gathered. To begin\nthis process, we provide an initial set of recommendations for describing DGA\nresults based on our analysis of the current state of the field.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2015 23:42:34 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Firoz", "Jesun Sahariar", ""], ["Kanewala", "Thejaka Amila", ""], ["Zalewski", "Marcin", ""], ["Barnas", "Martina", ""], ["Lumsdaine", "Andrew", ""]]}, {"id": "1507.06881", "submitter": "Shweta Sagari", "authors": "Shweta Sagari, Samuel Baysting, Dola Saha, Ivan Seskar, Wade Trappe,\n  Dipankar Raychaudhuri", "title": "Coordinated Dynamic Spectrum Management of LTE-U and Wi-Fi Networks", "comments": "Accepted paper at IEEE DySPAN 2015", "journal-ref": null, "doi": "10.1109/DySPAN.2015.7343904", "report-no": null, "categories": "cs.IT cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the co-existence of Wi-Fi and LTE in emerging\nunlicensed frequency bands which are intended to accommodate multiple radio\naccess technologies. Wi-Fi and LTE are the two most prominent access\ntechnologies being deployed today, motivating further study of the inter-system\ninterference arising in such shared spectrum scenarios as well as possible\ntechniques for enabling improved co-existence. An analytical model for\nevaluating the baseline performance of co-existing Wi-Fi and LTE is developed\nand used to obtain baseline performance measures. The results show that both\nWi-Fi and LTE networks cause significant interference to each other and that\nthe degradation is dependent on a number of factors such as power levels and\nphysical topology. The model-based results are partially validated via\nexperimental evaluations using USRP based SDR platforms on the ORBIT testbed.\nFurther, inter-network coordination with logically centralized radio resource\nmanagement across Wi-Fi and LTE systems is proposed as a possible solution for\nimproved co-existence. Numerical results are presented showing significant\ngains in both Wi-Fi and LTE performance with the proposed inter-network\ncoordination approach.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 15:24:15 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Sagari", "Shweta", ""], ["Baysting", "Samuel", ""], ["Saha", "Dola", ""], ["Seskar", "Ivan", ""], ["Trappe", "Wade", ""], ["Raychaudhuri", "Dipankar", ""]]}, {"id": "1507.08187", "submitter": "Van Chan Ngo", "authors": "Van Chan Ngo (ESTASYS), Axel Legay (ESTASYS)", "title": "Dependability Analysis of Control Systems using SystemC and Statistical\n  Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Petri nets are commonly used for modeling distributed systems in\norder to study their performance and dependability. This paper proposes a\nrealization of stochastic Petri nets in SystemC for modeling large embedded\ncontrol systems. Then statistical model checking is used to analyze the\ndependability of the constructed model. Our verification framework allows users\nto express a wide range of useful properties to be verified which is\nillustrated through a case study.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 15:36:21 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2016 05:31:36 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Ngo", "Van Chan", "", "ESTASYS"], ["Legay", "Axel", "", "ESTASYS"]]}, {"id": "1507.08340", "submitter": "Ahsan Javed Awan", "authors": "Ahsan Javed Awan, Mats Brorsson, Vladimir Vlassov and Eduard Ayguade", "title": "How Data Volume Affects Spark Based Data Analytics on a Scale-up Server", "comments": "accepted to 6th International Workshop on Big Data Benchmarks,\n  Performance Optimization and Emerging Hardware (BpoE-6) held in conjunction\n  with VLDB 2015. arXiv admin note: text overlap with arXiv:1506.07742", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sheer increase in volume of data over the last decade has triggered research\nin cluster computing frameworks that enable web enterprises to extract big\ninsights from big data. While Apache Spark is gaining popularity for exhibiting\nsuperior scale-out performance on the commodity machines, the impact of data\nvolume on the performance of Spark based data analytics in scale-up\nconfiguration is not well understood. We present a deep-dive analysis of Spark\nbased applications on a large scale-up server machine. Our analysis reveals\nthat Spark based data analytics are DRAM bound and do not benefit by using more\nthan 12 cores for an executor. By enlarging input data size, application\nperformance degrades significantly due to substantial increase in wait time\nduring I/O operations and garbage collection, despite 10\\% better instruction\nretirement rate (due to lower L1 cache misses and higher core utilization). We\nmatch memory behaviour with the garbage collector to improve performance of\napplications between 1.6x to 3x.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 22:59:49 GMT"}], "update_date": "2015-08-03", "authors_parsed": [["Awan", "Ahsan Javed", ""], ["Brorsson", "Mats", ""], ["Vlassov", "Vladimir", ""], ["Ayguade", "Eduard", ""]]}, {"id": "1507.08499", "submitter": "Andres Garcia-Saavedra", "authors": "Andres Garcia-Saavedra, Mohammad Karzand, Douglas J. Leith", "title": "Low Delay Random Linear Coding and Scheduling Over Multiple Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multipath transport protocols like MPTCP transfer data across multiple routes\nin parallel and deliver it in order at the receiver. When the delay on one or\nmore of the paths is variable, as is commonly the case, out of order arrivals\nare frequent and head of line blocking leads to high latency. This is\nexacerbated when packet loss, which is also common with wireless links, is\ntackled using ARQ. This paper introduces Stochastic Earliest Delivery Path\nFirst (S-EDPF), a resilient low delay packet scheduler for multipath transport\nprotocols. S-EDPF takes explicit account of the stochastic nature of paths and\nuses this to minimise in-order delivery delay. S-EDPF also takes account of\nFEC, jointly scheduling transmission of information and coded packets and in\nthis way allows lossy links to reduce delay and improve resiliency, rather than\ndegrading performance as usually occurs with existing multipath systems. We\nimplement S-EDPF as a multi-platform application that does not require\nadministration privileges nor modifications to the operating system and has\nnegligible impact on energy consumption. We present a thorough experimental\nevaluation in both controlled environments and into the wild, revealing\ndramatic gains in delay performance compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2015 13:42:56 GMT"}], "update_date": "2015-07-31", "authors_parsed": [["Garcia-Saavedra", "Andres", ""], ["Karzand", "Mohammad", ""], ["Leith", "Douglas J.", ""]]}]