[{"id": "1711.00005", "submitter": "Yong-Xian Wang", "authors": "Min Xu, Yongxian Wang, Anthony Theodore Chronopoulos, Hao Yue", "title": "Performance Optimization and Parallelization of a Parabolic Equation\n  Solver in Computational Ocean Acoustics on Modern Many-core Computer", "comments": "9 pages, 8 figures, 3 tables. preprint for the International\n  Conference on Computer Science and Application Engineering (CSAE2017).\n  2017.10.21-23, Shanghai, China", "journal-ref": null, "doi": "10.12783/dtcse/csae2017/17546", "report-no": null, "categories": "cs.MS cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of open-source codes widely used in computational ocean acoustics,\nFOR3D can provide a very good estimate for underwater acoustic propagation. In\nthis paper, we propose a performance optimization and parallelization to speed\nup the running of FOR3D. We utilized a variety of methods to enhance the entire\nperformance, such as using a multi-threaded programming model to exploit the\npotential capability of the many-core node of high-performance computing (HPC)\nsystem, tuning compile options, using efficient tuned mathematical library and\nutilizing vectorization optimization instruction. In addition, we extended the\napplication from single-frequency calculation to multi-frequency calculation\nsuccessfully by using OpenMP+MPI hybrid programming techniques on the\nmainstream HPC platform. A detailed performance evaluation was performed and\nthe results showed that the proposed parallelization obtained good accelerated\neffect of 25.77X when testing a typical three-dimensional medium-sized case on\nTianhe-2 supercomputer. It also showed that the tuned parallel version has a\nweak-scalability. The speed of calculation of underwater sound field can be\ngreatly improved by the strategy mentioned in this paper. The method used in\nthis paper is not only applicable to other similar computing models in\ncomputational ocean acoustics but also a guideline of performance enhancement\nfor scientific and engineering application running on modern\nmany-core-computing platform.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 13:58:48 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 08:52:52 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Xu", "Min", ""], ["Wang", "Yongxian", ""], ["Chronopoulos", "Anthony Theodore", ""], ["Yue", "Hao", ""]]}, {"id": "1711.00618", "submitter": "Aurojit Panda", "authors": "Michael Alan Chang and Aurojit Panda and Yuan-Cheng Tsai and Hantao\n  Wang and Scott Shenker", "title": "ThrottleBot - Performance without Insight", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale applications are increasingly built by composing sets of\nmicroservices. In this model the functionality for a single application might\nbe split across 100s or 1000s of microservices. Resource provisioning for these\napplications is complex, requiring administrators to understand both the\nfunctioning of each microservice, and dependencies between microservices in an\napplication. In this paper we present ThrottleBot, a system that automates the\nprocess of determining what resource when allocated to which microservice is\nlikely to have the greatest impact on application performance. We demonstrate\nthe efficacy of our approach by applying ThrottleBot to both synthetic and real\nworld applications. We believe that ThrottleBot when combined with existing\nmicroservice orchestrators, e.g., Kubernetes, enables push-button deployment of\nweb scale applications.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 05:54:31 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Chang", "Michael Alan", ""], ["Panda", "Aurojit", ""], ["Tsai", "Yuan-Cheng", ""], ["Wang", "Hantao", ""], ["Shenker", "Scott", ""]]}, {"id": "1711.00903", "submitter": "Katarzyna Swirydowicz", "authors": "Kasia \\'Swirydowicz, Noel Chalmers, Ali Karakus and Timothy Warburton", "title": "Acceleration of tensor-product operations for high-order finite element\n  methods", "comments": "31 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA cs.PF math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to GPU kernel optimization and performance analysis of\nthree tensor-product operators arising in finite element methods. We provide a\nmathematical background to these operations and implementation details.\nAchieving close-to-the-peak performance for these operators requires extensive\noptimization because of the operators' properties: low arithmetic intensity,\ntiered structure, and the need to store intermediate results inside the kernel.\nWe give a guided overview of optimization strategies and we present a\nperformance model that allows us to compare the efficacy of these optimizations\nagainst an empirically calibrated roofline.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 19:45:33 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 15:18:19 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["\u015awirydowicz", "Kasia", ""], ["Chalmers", "Noel", ""], ["Karakus", "Ali", ""], ["Warburton", "Timothy", ""]]}, {"id": "1711.01407", "submitter": "Chen Zheng", "authors": "Luis Charre, Bruno Gravano, R\\'emi P\\^ossas, Chen Zheng", "title": "Timing Aware Dummy Metal Fill Methodology", "comments": "3 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyzed parasitic coupling capacitance coming from dummy\nmetal fill and its impact on timing. Based on the modeling, we proposed two\napproaches to minimize the timing impact from dummy metal fill. The first\napproach applies more spacing between critical nets and metal fill, while the\nsecond approach leverages the shielding effects of reference nets. Experimental\nresults show consistent improvement compared to traditional metal fill method.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 07:11:22 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 03:33:29 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Charre", "Luis", ""], ["Gravano", "Bruno", ""], ["P\u00f4ssas", "R\u00e9mi", ""], ["Zheng", "Chen", ""]]}, {"id": "1711.01845", "submitter": "Istv\\'an Z Reguly", "authors": "G. D. Balogh, I. Z. Reguly, G. R. Mudalige", "title": "Comparison of Parallelisation Approaches, Languages, and Compilers for\n  Unstructured Mesh Algorithms on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently exploiting GPUs is increasingly essential in scientific\ncomputing, as many current and upcoming supercomputers are built using them. To\nfacilitate this, there are a number of programming approaches, such as CUDA,\nOpenACC and OpenMP 4, supporting different programming languages (mainly C/C++\nand Fortran). There are also several compiler suites (clang, nvcc, PGI, XL)\neach supporting different combinations of languages. In this study, we take a\ndetailed look at some of the currently available options, and carry out a\ncomprehensive analysis and comparison using computational loops and\napplications from the domain of unstructured mesh computations. Beyond runtimes\nand performance metrics (GB/s), we explore factors that influence performance\nsuch as register counts, occupancy, usage of different memory types,\ninstruction counts, and algorithmic differences. Results of this work show how\nclang's CUDA compiler frequently outperform NVIDIA's nvcc, performance issues\nwith directive-based approaches on complex kernels, and OpenMP 4 support\nmaturing in clang and XL; currently around 10% slower than CUDA.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 11:43:47 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Balogh", "G. D.", ""], ["Reguly", "I. Z.", ""], ["Mudalige", "G. R.", ""]]}, {"id": "1711.02469", "submitter": "Elie Ngomseu Mambou", "authors": "Ebenezer Esenogho and Elie Ngomseu Mambou", "title": "Integrating Queuing Regime into Cognitive Radio Channel Aggregation\n  Policies: A Performance Evaluation", "comments": "5 pages, 7 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel aggregation (CA) is one of the newest concept which cognitive radio\nnetwork is bringing to bear for the smooth role out of fifth/next generation\nwireless networks. This is the combining of several unused primary user\nspectrum holes into a logic usable channel. However, several of these\nstrategies have been investigated considering the varying nature of wireless\nlink and adaptive modulation and coding (AMC). Examples are the instant\nblocking strategy (IBS) and readjustment based strategy (RBS). This paper\ndevelops and compares two CA policies with queue, which are the IBS with queue\n(IBS + Q), and the RBS with queue (RBS+Q). This is in furtherance of previous\nproposed work. The aim is to identifying the impact of a queuing regime on the\nperformance of the secondary network such that any secondary user (SU) that has\nnot completed its service, as an alternative to dropping or forcibly\nterminating the service, it is queued in order to get another opportunity to\naccess the primary user (PU) channels. The performance is evaluated through a\nsimulation framework. The results validate that with a welldesigned queuing\nregime, capacity, access and other metrics can be improved with significant\nreduction in blocking and forced termination probabilities respectively.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 14:07:18 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Esenogho", "Ebenezer", ""], ["Mambou", "Elie Ngomseu", ""]]}, {"id": "1711.03386", "submitter": "Pengfei Xu", "authors": "Pengfei Xu, Shaohuai Shi, Xiaowen Chu", "title": "Performance Evaluation of Deep Learning Tools in Docker Containers", "comments": "Conference: BIgCom2017, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of deep learning techniques in a broad range of application\ndomains, many deep learning software frameworks have been developed and are\nbeing updated frequently to adapt to new hardware features and software\nlibraries, which bring a big challenge for end users and system administrators.\nTo address this problem, container techniques are widely used to simplify the\ndeployment and management of deep learning software. However, it remains\nunknown whether container techniques bring any performance penalty to deep\nlearning applications. The purpose of this work is to systematically evaluate\nthe impact of docker container on the performance of deep learning\napplications. We first benchmark the performance of system components (IO, CPU\nand GPU) in a docker container and the host system and compare the results to\nsee if there's any difference. According to our results, we find that\ncomputational intensive jobs, either running on CPU or GPU, have small overhead\nindicating docker containers can be applied to deep learning programs. Then we\nevaluate the performance of some popular deep learning tools deployed in a\ndocker container and the host system. It turns out that the docker container\nwill not cause noticeable drawbacks while running those deep learning tools. So\nencapsulating deep learning tool in a container is a feasible solution.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 14:28:12 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Xu", "Pengfei", ""], ["Shi", "Shaohuai", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1711.03709", "submitter": "Daniel S. Berger", "authors": "Daniel S. Berger, Nathan Beckmann, Mor Harchol-Balter", "title": "Practical Bounds on Optimal Caching with Variable Object Sizes", "comments": null, "journal-ref": "Proceedings of the ACM on Measurement and Analysis of Computing\n  Systems, Article 32, Volume 2, Issue 2, June 2018", "doi": "10.1145/3224427", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent caching systems aim to improve miss ratios, but there is no good\nsense among practitioners of how much further miss ratios can be improved. In\nother words, should the systems community continue working on this problem?\nCurrently, there is no principled answer to this question. In practice, object\nsizes often vary by several orders of magnitude, where computing the optimal\nmiss ratio (OPT) is known to be NP-hard. The few known results on caching with\nvariable object sizes provide very weak bounds and are impractical to compute\non traces of realistic length.\n  We propose a new method to compute upper and lower bounds on OPT. Our key\ninsight is to represent caching as a min-cost flow problem, hence we call our\nmethod the flow-based offline optimal (FOO). We prove that, under simple\nindependence assumptions, FOO's bounds become tight as the number of objects\ngoes to infinity. Indeed, FOO's error over 10M requests of production CDN and\nstorage traces is negligible: at most 0.3%. FOO thus reveals, for the first\ntime, the limits of caching with variable object sizes. While FOO is very\naccurate, it is computationally impractical on traces with hundreds of millions\nof requests. We therefore extend FOO to obtain more efficient bounds on OPT,\nwhich we call practical flow-based offline optimal (PFOO). We evaluate PFOO on\nseveral full production traces and use it to compare OPT to prior online\npolicies. This analysis shows that current caching systems are in fact still\nfar from optimal, suffering 11-43% more cache misses than OPT, whereas the best\nprior offline bounds suggest that there is essentially no room for improvement.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 06:27:08 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 18:07:40 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 18:14:21 GMT"}, {"version": "v4", "created": "Thu, 5 Jul 2018 20:10:45 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Berger", "Daniel S.", ""], ["Beckmann", "Nathan", ""], ["Harchol-Balter", "Mor", ""]]}, {"id": "1711.03720", "submitter": "Baruch Mor", "authors": "Baruch Mor and Dana Shapira", "title": "Scheduling with regular performance measures and optional job rejection\n  on a single machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address single machine problems with optional jobs - rejection, studied\nrecently in Zhang et al. [21] and Cao et al. [2]. In these papers, the authors\nfocus on minimizing regular performance measures, i.e., functions that are\nnon-decreasing in the jobs completion time, subject to the constraint that the\ntotal rejection cost cannot exceed a predefined upper bound. They also prove\nthat the considered problems are ordinary NP-hard and provide\npseudo-polynomial-time Dynamic Programming (DP) solutions. In this paper, we\nfocus on three of these problems: makespan with release-dates; total completion\ntimes; and total weighted completion, and present enhanced DP solutions\ndemonstrating both theoretical and practical improvements. Moreover, we provide\nextensive numerical studies verifying their efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 07:50:12 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 10:35:31 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Mor", "Baruch", ""], ["Shapira", "Dana", ""]]}, {"id": "1711.03941", "submitter": "Nitish K Panigrahy", "authors": "Nitish K. Panigrahy, Jian Li, Faheem Zafari, Don Towsley, Paul Yu", "title": "A TTL-based Approach for Content Placement in Edge Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge networks are promising to provide better services to users by\nprovisioning computing and storage resources at the edge of networks. However,\ndue to the uncertainty and diversity of user interests, content popularity,\ndistributed network structure, cache sizes, it is challenging to decide where\nto place the content, and how long it should be cached. In this paper, we study\nthe utility optimization of content placement at edge networks through\ntimer-based (TTL) policies. We propose provably optimal distributed algorithms\nthat operate at each network cache to maximize the overall network utility. Our\nTTL-based optimization model provides theoretical answers to how long each\ncontent must be cached, and where it should be placed in the edge network.\nExtensive evaluations show that our algorithm significantly outperforms path\nreplication with conventional caching algorithms over some network topologies.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 17:58:08 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 02:23:58 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 21:27:39 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 14:02:12 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Panigrahy", "Nitish K.", ""], ["Li", "Jian", ""], ["Zafari", "Faheem", ""], ["Towsley", "Don", ""], ["Yu", "Paul", ""]]}, {"id": "1711.04076", "submitter": "Saeid Tizpaz-Niari", "authors": "Saeid Tizpaz-Niari, Pavol Cerny, Bor-Yuh Evan Chang, Ashutosh Trivedi", "title": "Differential Performance Debugging with Discriminant Regression Trees", "comments": "To Appear in AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential performance debugging is a technique to find performance\nproblems. It applies in situations where the performance of a program is\n(unexpectedly) different for different classes of inputs. The task is to\nexplain the differences in asymptotic performance among various input classes\nin terms of program internals. We propose a data-driven technique based on\ndiscriminant regression tree (DRT) learning problem where the goal is to\ndiscriminate among different classes of inputs. We propose a new algorithm for\nDRT learning that first clusters the data into functional clusters, capturing\ndifferent asymptotic performance classes, and then invokes off-the-shelf\ndecision tree learning algorithms to explain these clusters. We focus on linear\nfunctional clusters and adapt classical clustering algorithms (K-means and\nspectral) to produce them. For the K-means algorithm, we generalize the notion\nof the cluster centroid from a point to a linear function. We adapt spectral\nclustering by defining a novel kernel function to capture the notion of linear\nsimilarity between two data points. We evaluate our approach on benchmarks\nconsisting of Java programs where we are interested in debugging performance.\nWe show that our algorithm significantly outperforms other well-known\nregression tree learning algorithms in terms of running time and accuracy of\nclassification.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 04:50:53 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 05:19:48 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Tizpaz-Niari", "Saeid", ""], ["Cerny", "Pavol", ""], ["Chang", "Bor-Yuh Evan", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1711.04172", "submitter": "Chen Zheng", "authors": "Anthony Kim, Sung Hyun Chen, Chen Zheng", "title": "Depth First Always On Routing Trace Algorithm", "comments": "4 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discussed current limitation in the\nelectronic-design-automotation (EDA) tool on tracing the always on routing. We\ndeveloped an algorithm to efficiently track the secondary power routing and\naccurately estimate the routing quality using approximate voltage drop as the\ncriteria. The fast check can identify potential hotspot issues without going\nthrough sign-off checks. It helps designers to capture issues at early stages\nand fix the issues with less design effort. We also discussed some limitations\nto our algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 17:06:56 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Kim", "Anthony", ""], ["Chen", "Sung Hyun", ""], ["Zheng", "Chen", ""]]}, {"id": "1711.05487", "submitter": "Athena Elafrou", "authors": "Athena Elafrou, Georgios Goumas, Nektarios Koziris", "title": "Performance Analysis and Optimization of Sparse Matrix-Vector\n  Multiplication on Modern Multi- and Many-Core Processors", "comments": "10 pages, 7 figures, ICPP 2017", "journal-ref": null, "doi": "10.1109/ICPP.2017.38", "report-no": null, "categories": "cs.PF cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a low-overhead optimizer for the ubiquitous sparse\nmatrix-vector multiplication (SpMV) kernel. Architectural diversity among\ndifferent processors together with structural diversity among different sparse\nmatrices lead to bottleneck diversity. This justifies an SpMV optimizer that is\nboth matrix- and architecture-adaptive through runtime specialization. To this\ndirection, we present an approach that first identifies the performance\nbottlenecks of SpMV for a given sparse matrix on the target platform either\nthrough profiling or by matrix property inspection, and then selects suitable\noptimizations to tackle those bottlenecks. Our optimization pool is based on\nthe widely used Compressed Sparse Row (CSR) sparse matrix storage format and\nhas low preprocessing overheads, making our overall approach practical even in\ncases where fast decision making and optimization setup is required. We\nevaluate our optimizer on three x86-based computing platforms and demonstrate\nthat it is able to distinguish and appropriately optimize SpMV for the majority\nof matrices in a representative test suite, leading to significant speedups\nover the CSR and Inspector-Executor CSR SpMV kernels available in the latest\nrelease of the Intel MKL library.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 10:22:53 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Elafrou", "Athena", ""], ["Goumas", "Georgios", ""], ["Koziris", "Nektarios", ""]]}, {"id": "1711.05561", "submitter": "Angelos Aveklouris", "authors": "Angelos Aveklouris, Maria Vlasiou, Bert Zwart", "title": "A Stochastic Resource-Sharing Network for Electric Vehicle Charging", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.PF cs.SY math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distribution grid used to charge electric vehicles such that\nvoltage drops stay bounded. We model this as a class of resource-sharing\nnetworks, known as bandwidth-sharing networks in the communication network\nliterature. We focus on resource-sharing networks that are driven by a class of\ngreedy control rules that can be implemented in a decentralized fashion. For a\nlarge number of such control rules, we can characterize the performance of the\nsystem by a fluid approximation. This leads to a set of dynamic equations that\ntake into account the stochastic behavior of EVs. We show that the invariant\npoint of these equations is unique and can be computed by solving a specific\nACOPF problem, which admits an exact convex relaxation. We illustrate our\nfindings with a case study using the SCE 47-bus network and several special\ncases that allow for explicit computations.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 13:24:18 GMT"}, {"version": "v2", "created": "Sat, 13 Jan 2018 11:16:16 GMT"}, {"version": "v3", "created": "Wed, 16 Jan 2019 15:28:59 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Aveklouris", "Angelos", ""], ["Vlasiou", "Maria", ""], ["Zwart", "Bert", ""]]}, {"id": "1711.07440", "submitter": "Weijia Chen", "authors": "Weijia Chen, Yuedong Xu, Xiaofeng Wu", "title": "Deep Reinforcement Learning for Multi-Resource Multi-Machine Job\n  Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing job scheduling time is a fundamental issue in data center networks\nthat has been extensively studied in recent years. The incoming jobs require\ndifferent CPU and memory units, and span different number of time slots. The\ntraditional solution is to design efficient heuristic algorithms with\nperformance guarantee under certain assumptions. In this paper, we improve a\nrecently proposed job scheduling algorithm using deep reinforcement learning\nand extend it to multiple server clusters. Our study reveals that deep\nreinforcement learning method has the potential to outperform traditional\nresource allocation algorithms in a variety of complicated environments.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 17:50:54 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Chen", "Weijia", ""], ["Xu", "Yuedong", ""], ["Wu", "Xiaofeng", ""]]}, {"id": "1711.07601", "submitter": "Jure Leskovec", "authors": "Chantat Eksombatchai, Pranav Jindal, Jerry Zitao Liu, Yuchen Liu,\n  Rahul Sharma, Charles Sugnet, Mark Ulrich, Jure Leskovec", "title": "Pixie: A System for Recommending 3+ Billion Items to 200+ Million Users\n  in Real-Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.PF cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User experience in modern content discovery applications critically depends\non high-quality personalized recommendations. However, building systems that\nprovide such recommendations presents a major challenge due to a massive pool\nof items, a large number of users, and requirements for recommendations to be\nresponsive to user actions and generated on demand in real-time. Here we\npresent Pixie, a scalable graph-based real-time recommender system that we\ndeveloped and deployed at Pinterest. Given a set of user-specific pins as a\nquery, Pixie selects in real-time from billions of possible pins those that are\nmost related to the query. To generate recommendations, we develop Pixie Random\nWalk algorithm that utilizes the Pinterest object graph of 3 billion nodes and\n17 billion edges. Experiments show that recommendations provided by Pixie lead\nup to 50% higher user engagement when compared to the previous Hadoop-based\nproduction system. Furthermore, we develop a graph pruning strategy at that\nleads to an additional 58% improvement in recommendations. Last, we discuss\nsystem aspects of Pixie, where a single server executes 1,200 recommendation\nrequests per second with 60 millisecond latency. Today, systems backed by Pixie\ncontribute to more than 80% of all user engagement on Pinterest.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 01:51:35 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Eksombatchai", "Chantat", ""], ["Jindal", "Pranav", ""], ["Liu", "Jerry Zitao", ""], ["Liu", "Yuchen", ""], ["Sharma", "Rahul", ""], ["Sugnet", "Charles", ""], ["Ulrich", "Mark", ""], ["Leskovec", "Jure", ""]]}, {"id": "1711.09407", "submitter": "Philippe Toint", "authors": "Margherita Porcelli and Philippe L. Toint", "title": "A note on using performance and data profilesfor training algorithms", "comments": "8 pages, 4 tables, 4 figures", "journal-ref": "Transactions of the AMS on Mathematical Software, vol. 45(2), 2019", "doi": null, "report-no": null, "categories": "math.OC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown how to use the performance and data profile benchmarking tools to\nimprove algorithms' performance. An illustration for the BFO derivative-free\noptimizer suggests that the obtained gains are potentially significant.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 15:24:05 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Porcelli", "Margherita", ""], ["Toint", "Philippe L.", ""]]}, {"id": "1711.10435", "submitter": "Albert Milner", "authors": "Tapio Bohn, Paul Salmi, Albert Milner", "title": "LP-Based Power Grid Enhancement Methodology", "comments": "4 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explored the opportunity to enhance power grid robustness\nafter routing stage, and propose a linear programming based algorithm that\nmaximizes the improvement of power grid strengthening with given available\nrouting resource. We further discussed some techniques to leverage tradeoffs\nbetween runtime and optimality of the solutions. Experimental results show\nsubstantial power integrity improvement with \"zero cost\".\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 16:33:31 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Bohn", "Tapio", ""], ["Salmi", "Paul", ""], ["Milner", "Albert", ""]]}, {"id": "1711.11468", "submitter": "Markus Wittmann", "authors": "Markus Wittmann, Viktor Haag, Thomas Zeiser, Harald K\\\"ostler, Gerhard\n  Wellein", "title": "Lattice Boltzmann Benchmark Kernels as a Testbed for Performance\n  Analysis", "comments": "preprint, submitted to Computer & Fluids Special Issue DSFD2017", "journal-ref": "Computers & Fluids, 2018", "doi": "10.1016/j.compfluid.2018.03.030", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice Boltzmann methods (LBM) are an important part of current\ncomputational fluid dynamics (CFD). They allow easy implementations and\nboundary handling. However, competitive time to solution not only depends on\nthe choice of a reasonable method, but also on an efficient implementation on\nmodern hardware. Hence, performance optimization has a long history in the\nlattice Boltzmann community. A variety of options exists regarding the\nimplementation with direct impact on the solver performance. Experimenting and\nevaluating each option often is hard as the kernel itself is typically embedded\nin a larger code base. With our suite of lattice Boltzmann kernels we provide\nthe infrastructure for such endeavors. Already included are several kernels\nranging from simple to fully optimized implementations. Although these kernels\nare not fully functional CFD solvers, they are equipped with a solid\nverification method. The kernels may act as an reference for performance\ncomparisons and as a blue print for optimization strategies. In this paper we\ngive an overview of already available kernels, establish a performance model\nfor each kernel, and show a comparison of implementations and recent\narchitectures.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 15:45:56 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Wittmann", "Markus", ""], ["Haag", "Viktor", ""], ["Zeiser", "Thomas", ""], ["K\u00f6stler", "Harald", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1711.11521", "submitter": "Yun Ma", "authors": "Yun Ma, Shuailiang Dong", "title": "Understanding Quality of Experiences on Different Mobile Browsers:\n  Measurements, Analysis, and Implications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web browser is one of the major channels to access the Internet on mobile\ndevices. Based on the smartphone usage logs from millions of real-world Android\nusers, it is interesting to find that about 38% users have more than one\nbrowser on their devices. However, it is unclear whether the quality of\nbrowsing experiences are different when visiting the same webpage on different\nbrowsers. In this paper, we collect 3-week consecutive traces of 337 popular\nwebpages on three popular mobile browsers: Chrome, Firefox, and Opera. We first\nuse a list of metrics and conduct an empirical study to measure the differences\nof these metrics on different browsers. Then, we explore the variety of loading\ntime and cache performance of different browsers when visiting the same\nwebpage, which has a great impact on the browsing experience. Furthermore, we\ntry to find which metrics have significant effect on the differences,\ninvestigating the possible causes. Finally, according to our findings, we give\nsome recommendations to web developers, browser vendors, and end users.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 17:18:07 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Ma", "Yun", ""], ["Dong", "Shuailiang", ""]]}]