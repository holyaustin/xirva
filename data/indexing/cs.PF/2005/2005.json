[{"id": "2005.00044", "submitter": "David Lomet", "authors": "David Lomet (Microsoft Research, Redmond, WA) and Chen Luo (UC Irvine,\n  Irvine, CA)", "title": "Efficiently Reclaiming Space in a Log Structured Store", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A log structured store uses a single write I/O for a number of diverse and\nnon-contiguous pages within a large buffer instead of using a write I/O for\neach page separately. This requires that pages be relocated on every write,\nbecause pages are never updated in place. Instead, pages are dynamically\nremapped on every write. Log structuring was invented for and used initially in\nfile systems. Today, a form of log structuring is used in SSD controllers\nbecause an SSD requires the erasure of a large block of pages before flash\nstorage can be reused. No update-in-place requires that the storage for\nout-of-date pages be reclaimed (garbage collected or \"cleaned\"). We analyze\ncleaning performance and introduce a cleaning strategy that uses a new way to\nprioritize the order in which stale pages are garbage collected. Our cleaning\nstrategy approximates an \"optimal cleaning strategy\". Simulation studies\nconfirm the results of the analysis. This strategy is a significant improvement\nover previous cleaning strategies.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 18:29:42 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Lomet", "David", "", "Microsoft Research, Redmond, WA"], ["Luo", "Chen", "", "UC Irvine,\n  Irvine, CA"]]}, {"id": "2005.00749", "submitter": "Zheng Wang", "authors": "Jie Ren, Lu Yuan, Petteri Nurmi, Xiaoming Wang, Miao Ma, Ling Gao,\n  Zhanyong Tang, Jie Zheng, Zheng Wang", "title": "Smart, Adaptive Energy Optimization for Mobile Web Interactions", "comments": "Accepted to be published at INFOCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.HC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Web technology underpins many interactive mobile applications. However,\nenergy-efficient mobile web interactions is an outstanding challenge. Given the\nincreasing diversity and complexity of mobile hardware, any practical\noptimization scheme must work for a wide range of users, mobile platforms and\nweb workloads. This paper presents CAMEL , a novel energy optimization system\nfor mobile web interactions. CAMEL leverages machine learning techniques to\ndevelop a smart, adaptive scheme to judiciously trade performance for reduced\npower consumption. Unlike prior work, C AMEL directly models how a given web\ncontent affects the user expectation and uses this to guide energy\noptimization. It goes further by employing transfer learning and conformal\npredictions to tune a previously learned model in the end-user environment and\nimprove it over time. We apply CAMEL to Chromium and evaluate it on four\ndistinct mobile systems involving 1,000 testing webpages and 30 users. Compared\nto four state-of-the-art web-event optimizers, CAMEL delivers 22% more energy\nsavings, but with 49% fewer violations on the quality of user experience, and\nexhibits orders of magnitudes less overhead when targeting a new computing\nenvironment.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 08:51:07 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Ren", "Jie", ""], ["Yuan", "Lu", ""], ["Nurmi", "Petteri", ""], ["Wang", "Xiaoming", ""], ["Ma", "Miao", ""], ["Gao", "Ling", ""], ["Tang", "Zhanyong", ""], ["Zheng", "Jie", ""], ["Wang", "Zheng", ""]]}, {"id": "2005.01945", "submitter": "Md Momin Al Aziz", "authors": "Toufique Morshed, Md Momin Al Aziz and Noman Mohammed", "title": "CPU and GPU Accelerated Fully Homomorphic Encryption", "comments": "Accepted in IEEE HOST'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Homomorphic Encryption (FHE) is one of the most promising technologies\nfor privacy protection as it allows an arbitrary number of function\ncomputations over encrypted data. However, the computational cost of these FHE\nsystems limits their widespread applications. In this paper, our objective is\nto improve the performance of FHE schemes by designing efficient parallel\nframeworks. In particular, we choose Torus Fully Homomorphic Encryption (TFHE)\nas it offers exact results for an infinite number of boolean gate (e.g., AND,\nXOR) evaluations. We first extend the gate operations to algebraic circuits\nsuch as addition, multiplication, and their vector and matrix equivalents.\nSecondly, we consider the multi-core CPUs to improve the efficiency of both the\ngate and the arithmetic operations. Finally, we port the TFHE to the Graphics\nProcessing Units (GPU) and device novel optimizations for boolean and\narithmetic circuits employing the multitude of cores. We also experimentally\nanalyze both the CPU and GPU parallel frameworks for different numeric\nrepresentations (16 to 32-bit). Our GPU implementation outperforms the existing\ntechnique, and it achieves a speedup of 20x for any 32-bit boolean operation\nand 14.5x for multiplications.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 05:03:50 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Morshed", "Toufique", ""], ["Aziz", "Md Momin Al", ""], ["Mohammed", "Noman", ""]]}, {"id": "2005.02454", "submitter": "Bassam Al-Shargabi Dr", "authors": "Bassam Al-Shargabi and Mohammed Aleswid", "title": "Performance of RPL in Healthcare Wireless Sensor Network", "comments": "7 pages, 10 figures", "journal-ref": "International Journal of Emerging Trends in Engineering\n  Research,Volume (8),no (3) 2020", "doi": "10.30534/ijeter/2020/31832020", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The new advances of the Internet of Things (IoT) technology can be utilized\nto promote service delivery in several real-life applications such as\nhealthcare systems. The Routing Protocol for Low Power and Loss Network (RPL)\nis a routing protocol designed to serve as a proper routing protocol for\npackets in Wireless Sensor Networks (WSN). Among the most prominent issues\nexist in the RPL protocol are packet loss within the WSN and sensors power\nconsumption especially in healthcare WSNs. Multiple Objective Functions (OF) in\nRPL intended to find the routes from source nodes to a destination node. This\npaper presents an evaluation to discover which OF is more efficient for a WSN\nin a healthcare scenario where the Packet Delivery Ratio (PDR) of WSN and the\nsensors' power consumption are prominent concerns. Expected transmission Count\n(ETX) and Objective Function Zero (OF0) of RPL were examined in various network\ndensities and network topologies such as the grid and random topology. The\nsimulation outcomes revealed that the OF0 is more efficient regarding the PDR\nand power consumption compared to the ETX in random\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 15:57:27 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Al-Shargabi", "Bassam", ""], ["Aleswid", "Mohammed", ""]]}, {"id": "2005.02683", "submitter": "Ioannis Dimitriou", "authors": "Ioannis Dimitriou", "title": "Analysis of the Symmetric Join the Shortest Orbit Queue", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces the join the shortest queue policy in the retrial\nsetting. We consider a Markovian single server retrial system with two infinite\ncapacity orbits. An arriving job finding the server busy, it is forwarded to\nthe least loaded orbit. Otherwise, it is forwarded to an orbit randomly.\nOrbiting jobs of either type retry to access the server independently. We\ninvestigate the stability condition, the stationary tail decay rate, and obtain\nthe equilibrium distribution by using the compensation method.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 09:32:34 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 11:48:11 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Dimitriou", "Ioannis", ""]]}, {"id": "2005.02858", "submitter": "H\\'elio M. de Oliveira", "authors": "Ernande F. Melo and H. M. de Oliveira", "title": "An Overview of Self-Similar Traffic: Its Implications in the Network\n  Design", "comments": "9 pages, 16 figures", "journal-ref": "Revista de Tecnologia da Informa\\c{c}\\~ao e Comunica\\c{c}\\~ao, v.\n  9, n. 1, p. 38-46, May 2020", "doi": null, "report-no": "ISSN 2237-5104", "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knowledge about the true nature of the traffic in computer networking is\na key requirement in the design of such networks. The phenomenon of\nself-similarity is a characteristic of the traffic of current client/server\npacket networks in LAN/WAN environments dominated by network technologies such\nas Ethernet and the TCP/IP protocol stack. The development of networks traffic\nsimulators, which take into account this attribute, is necessary for a more\nrealistic description the traffic on these networks and their use in the design\nof resources (contention elements) and protocols of flow control and network\ncongestion. In this scenario it is recommended do not adopt standard traffic\nmodels of the Poisson type.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 14:38:27 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Melo", "Ernande F.", ""], ["de Oliveira", "H. M.", ""]]}, {"id": "2005.03096", "submitter": "Yuxin Lu", "authors": "Yuxin Lu and Wai Ho Mow", "title": "Near-optimal Detector for SWIPT-enabled Differential DF Relay Networks\n  with SER Analysis", "comments": "Accepted by IEEE International Conference on Communications (ICC)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the symbol error rate (SER) performance of the\nsimultaneous wireless information and power transfer (SWIPT) enabled three-node\ndifferential decode-and-forward (DDF) relay networks, which adopt the power\nsplitting (PS) protocol at the relay. The use of non-coherent differential\nmodulation eliminates the need for sending training symbols to estimate the\ninstantaneous channel state informations (CSIs) at all network nodes, and\ntherefore improves the power efficiency, as compared with the coherent\nmodulation. However, performance analysis results are not yet available for the\nstate-of-the-art detectors such as the approximate maximum-likelihood detector.\nExisting works rely on Monte-Carlo simulation to show that there exists an\noptimal PS ratio that minimizes the overall SER. In this work, we propose a\nnear-optimal detector with linear complexity with respect to the modulation\nsize. We derive an accurate approximate SER expression, based on which the\noptimal PS ratio can be accurately estimated without requiring any Monte-Carlo\nsimulation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:54:11 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Lu", "Yuxin", ""], ["Mow", "Wai Ho", ""]]}, {"id": "2005.03135", "submitter": "Sean Peisert", "authors": "Bogdan Copos and Sean Peisert", "title": "Catch Me If You Can: Using Power Analysis to Identify HPC Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring users on large computing platforms such as high performance\ncomputing (HPC) and cloud computing systems is non-trivial. Utilities such as\nprocess viewers provide limited insight into what users are running, due to\ngranularity limitation, and other sources of data, such as system call tracing,\ncan impose significant operational overhead. However, despite technical and\nprocedural measures, instances of users abusing valuable HPC resources for\npersonal gains have been documented in the past \\cite{hpcbitmine}, and systems\nthat are open to large numbers of loosely-verified users from around the world\nare at risk of abuse. In this paper, we show how electrical power consumption\ndata from an HPC platform can be used to identify what programs are executed.\nThe intuition is that during execution, programs exhibit various patterns of\nCPU and memory activity. These patterns are reflected in the power consumption\nof the system and can be used to identify programs running. We test our\napproach on an HPC rack at Lawrence Berkeley National Laboratory using a\nvariety of scientific benchmarks. Among other interesting observations, our\nresults show that by monitoring the power consumption of an HPC rack, it is\npossible to identify if particular programs are running with precision up to\nand recall of 95\\% even in noisy scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 20:57:41 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Copos", "Bogdan", ""], ["Peisert", "Sean", ""]]}, {"id": "2005.03156", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Andreas Kipf, Darren Engwirda, Navin Vembar, Michael\n  Jones, Lauren Milechin, Vijay Gadepally, Chris Hill, Tim Kraska, William\n  Arcand, David Bestor, William Bergeron, Chansup Byun, Matthew Hubbell,\n  Michael Houle, Andrew Kirby, Anna Klein, Julie Mullen, Andrew Prout, Albert\n  Reuther, Antonio Rosa, Sid Samsi, Charles Yee, Peter Michaleas", "title": "Fast Mapping onto Census Blocks", "comments": "8 pages, 7 figures, 55 references; accepted to IEEE HPEC 2020", "journal-ref": null, "doi": "10.1109/HPEC43674.2020.9286157", "report-no": null, "categories": "cs.DC cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pandemic measures such as social distancing and contact tracing can be\nenhanced by rapidly integrating dynamic location data and demographic data.\nProjecting billions of longitude and latitude locations onto hundreds of\nthousands of highly irregular demographic census block polygons is\ncomputationally challenging in both research and deployment contexts. This\npaper describes two approaches labeled \"simple\" and \"fast\". The simple approach\ncan be implemented in any scripting language (Matlab/Octave, Python, Julia, R)\nand is easily integrated and customized to a variety of research goals. This\nsimple approach uses a novel combination of hierarchy, sparse bounding boxes,\npolygon crossing-number, vectorization, and parallel processing to achieve\n100,000,000+ projections per second on 100 servers. The simple approach is\ncompact, does not increase data storage requirements, and is applicable to any\ncountry or region. The fast approach exploits the thread, vector, and memory\noptimizations that are possible using a low-level language (C++) and achieves\nsimilar performance on a single server. This paper details these approaches\nwith the goal of enabling the broader community to quickly integrate location\nand demographic data.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 22:07:05 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 17:19:44 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Kepner", "Jeremy", ""], ["Kipf", "Andreas", ""], ["Engwirda", "Darren", ""], ["Vembar", "Navin", ""], ["Jones", "Michael", ""], ["Milechin", "Lauren", ""], ["Gadepally", "Vijay", ""], ["Hill", "Chris", ""], ["Kraska", "Tim", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "William", ""], ["Byun", "Chansup", ""], ["Hubbell", "Matthew", ""], ["Houle", "Michael", ""], ["Kirby", "Andrew", ""], ["Klein", "Anna", ""], ["Mullen", "Julie", ""], ["Prout", "Andrew", ""], ["Reuther", "Albert", ""], ["Rosa", "Antonio", ""], ["Samsi", "Sid", ""], ["Yee", "Charles", ""], ["Michaleas", "Peter", ""]]}, {"id": "2005.03459", "submitter": "Wanling Gao", "authors": "Wanling Gao, Fei Tang, Jianfeng Zhan, Xu Wen, Lei Wang, Zheng Cao,\n  Chuanxin Lan, Chunjie Luo, Xiaoli Liu, Zihan Jiang", "title": "Scenario-distilling AI Benchmarking", "comments": "23 pages. arXiv admin note: text overlap with arXiv:2002.07162", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern real-world application scenarios like Internet services not only\nconsist of diversity of AI and non-AI modules with very long and complex\nexecution paths, but also have huge code size, which raises serious\nbenchmarking or evaluating challenges. Using AI components or micro benchmarks\nalone can lead to error-prone conclusions. This paper presents a\nscenario-distilling methodology to attack the above challenge. We formalize a\nreal-world application scenario as a Directed Acyclic Graph-based model, and\npropose the rules to distill it into the permutation of essential AI and non-AI\ntasks as a high-level scenario benchmark specification. Together with seventeen\nindustry partners, we extract nine typical application scenarios, and identify\nthe primary components. We design and implement a highly extensible,\nconfigurable, and flexible benchmark framework, on the basis of which, we\nimplement two Internet service AI scenario benchmarks as proxies to two\nreal-world application scenarios. We claim scenario, component and micro\nbenchmarks should be considered as three indispensable parts for evaluating.\nOur evaluation shows the advantage of our methodology against using component\nor micro AI benchmarks alone. The specifications, source code, testbed, and\nresults are publicly available from\n\\url{https://www.benchcouncil.org/aibench-scenario/index.html}.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 01:24:25 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 11:11:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Gao", "Wanling", ""], ["Tang", "Fei", ""], ["Zhan", "Jianfeng", ""], ["Wen", "Xu", ""], ["Wang", "Lei", ""], ["Cao", "Zheng", ""], ["Lan", "Chuanxin", ""], ["Luo", "Chunjie", ""], ["Liu", "Xiaoli", ""], ["Jiang", "Zihan", ""]]}, {"id": "2005.04092", "submitter": "Stefano Cereda", "authors": "Stefano Cereda, Gianluca Palermo, Paolo Cremonesi and Stefano Doni", "title": "A Collaborative Filtering Approach for the Automatic Tuning of Compiler\n  Optimisations", "comments": "To be published in the 21st ACM SIGPLAN/SIGBED International\n  Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES\n  2020) PolyBench dataset available at:\n  https://github.com/stefanocereda/polybench_data cBench dataset available at:\n  https://github.com/amirjamez/COBAYN", "journal-ref": null, "doi": "10.1145/3372799.3394361", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting the right compiler optimisations has a severe impact on programs'\nperformance. Still, the available optimisations keep increasing, and their\neffect depends on the specific program, making the task human intractable.\nResearchers proposed several techniques to search in the space of compiler\noptimisations. Some approaches focus on finding better search algorithms, while\nothers try to speed up the search by leveraging previously collected knowledge.\nThe possibility to effectively reuse previous compilation results inspired us\ntoward the investigation of techniques derived from the Recommender Systems\nfield. The proposed approach exploits previously collected knowledge and\nimproves its characterisation over time. Differently from current\nstate-of-the-art solutions, our approach is not based on performance counters\nbut relies on Reaction Matching, an algorithm able to characterise programs\nlooking at how they react to different optimisation sets. The proposed approach\nhas been validated using two widely used benchmark suites, cBench and\nPolyBench, including 54 different programs. Our solution, on average, extracted\n90% of the available performance improvement 10 iterations before current\nstate-of-the-art solutions, which corresponds to 40% fewer compilations and\nperformance tests to perform.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:07:48 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 07:53:01 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Cereda", "Stefano", ""], ["Palermo", "Gianluca", ""], ["Cremonesi", "Paolo", ""], ["Doni", "Stefano", ""]]}, {"id": "2005.04093", "submitter": "Aleks Ontman", "authors": "Joshua Porter, Aleks Ontman", "title": "Importing Relationships into a Running Graph Database Using Parallel\n  Processing", "comments": "5 pages, code provided on GitHub\n  https://github.com/Lnofeisone/graph-iterateRelationship", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importing relationships into a running graph database using multiple threads\nrunning concurrently is a difficult task, as multiple threads cannot write\ninformation to the same node at the same time. Here we present an algorithm in\nwhich relationships are sorted into bins, then imported such that no two\nthreads ever access the same node concurrently. When this algorithm was\nimplemented as a procedure to run on the Neo4j graph database, it reduced the\ntime to import relationships by up to 69% when 32 threads were used.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:31:29 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Porter", "Joshua", ""], ["Ontman", "Aleks", ""]]}, {"id": "2005.04680", "submitter": "Alexander Heinecke", "authors": "Dhiraj Kalamkar, Evangelos Georganas, Sudarshan Srinivasan, Jianping\n  Chen, Mikhail Shiryaev, Alexander Heinecke", "title": "Optimizing Deep Learning Recommender Systems' Training On CPU Cluster\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last two years, the goal of many researchers has been to squeeze\nthe last bit of performance out of HPC system for AI tasks. Often this\ndiscussion is held in the context of how fast ResNet50 can be trained.\nUnfortunately, ResNet50 is no longer a representative workload in 2020. Thus,\nwe focus on Recommender Systems which account for most of the AI cycles in\ncloud computing centers. More specifically, we focus on Facebook's DLRM\nbenchmark. By enabling it to run on latest CPU hardware and software tailored\nfor HPC, we are able to achieve more than two-orders of magnitude improvement\nin performance (110x) on a single socket compared to the reference CPU\nimplementation, and high scaling efficiency up to 64 sockets, while fitting\nultra-large datasets. This paper discusses the optimization techniques for the\nvarious operators in DLRM and which component of the systems are stressed by\nthese different operators. The presented techniques are applicable to a broader\nset of DL workloads that pose the same scaling challenges/characteristics as\nDLRM.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 14:40:16 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kalamkar", "Dhiraj", ""], ["Georganas", "Evangelos", ""], ["Srinivasan", "Sudarshan", ""], ["Chen", "Jianping", ""], ["Shiryaev", "Mikhail", ""], ["Heinecke", "Alexander", ""]]}, {"id": "2005.05085", "submitter": "Luo Chunjie", "authors": "Chunjie Luo, Xiwen He, Jianfeng Zhan, Lei Wang, Wanling Gao, Jiahui\n  Dai", "title": "Comparison and Benchmarking of AI Models and Frameworks on Mobile\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PF eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to increasing amounts of data and compute resources, deep learning\nachieves many successes in various domains. The application of deep learning on\nthe mobile and embedded devices is taken more and more attentions, benchmarking\nand ranking the AI abilities of mobile and embedded devices becomes an urgent\nproblem to be solved. Considering the model diversity and framework diversity,\nwe propose a benchmark suite, AIoTBench, which focuses on the evaluation of the\ninference abilities of mobile and embedded devices. AIoTBench covers three\ntypical heavy-weight networks: ResNet50, InceptionV3, DenseNet121, as well as\nthree light-weight networks: SqueezeNet, MobileNetV2, MnasNet. Each network is\nimplemented by three frameworks which are designed for mobile and embedded\ndevices: Tensorflow Lite, Caffe2, Pytorch Mobile. To compare and rank the AI\ncapabilities of the devices, we propose two unified metrics as the AI scores:\nValid Images Per Second (VIPS) and Valid FLOPs Per Second (VOPS). Currently, we\nhave compared and ranked 5 mobile devices using our benchmark. This list will\nbe extended and updated soon after.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:05:23 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Luo", "Chunjie", ""], ["He", "Xiwen", ""], ["Zhan", "Jianfeng", ""], ["Wang", "Lei", ""], ["Gao", "Wanling", ""], ["Dai", "Jiahui", ""]]}, {"id": "2005.05206", "submitter": "Thomas Stahlbuhk", "authors": "Thomas Stahlbuhk, Brooke Shrader and Eytan Modiano", "title": "Learning Algorithms for Minimizing Queue Length Regret", "comments": "28 Pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.IT cs.LG cs.SY eess.SY math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a system consisting of a single transmitter/receiver pair and $N$\nchannels over which they may communicate. Packets randomly arrive to the\ntransmitter's queue and wait to be successfully sent to the receiver. The\ntransmitter may attempt a frame transmission on one channel at a time, where\neach frame includes a packet if one is in the queue. For each channel, an\nattempted transmission is successful with an unknown probability. The\ntransmitter's objective is to quickly identify the best channel to minimize the\nnumber of packets in the queue over $T$ time slots. To analyze system\nperformance, we introduce queue length regret, which is the expected difference\nbetween the total queue length of a learning policy and a controller that knows\nthe rates, a priori. One approach to designing a transmission policy would be\nto apply algorithms from the literature that solve the closely-related\nstochastic multi-armed bandit problem. These policies would focus on maximizing\nthe number of successful frame transmissions over time. However, we show that\nthese methods have $\\Omega(\\log{T})$ queue length regret. On the other hand, we\nshow that there exists a set of queue-length based policies that can obtain\norder optimal $O(1)$ queue length regret. We use our theoretical analysis to\ndevise heuristic methods that are shown to perform well in simulation.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 15:50:56 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 13:26:02 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Stahlbuhk", "Thomas", ""], ["Shrader", "Brooke", ""], ["Modiano", "Eytan", ""]]}, {"id": "2005.05836", "submitter": "Igor Sfiligoi", "authors": "Igor Sfiligoi", "title": "Demonstrating 100 Gbps in and out of the public Clouds", "comments": "4 pages, 6 figures, 3 tables", "journal-ref": null, "doi": "10.1145/3311790.3399612", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is increased awareness and recognition that public Cloud providers do\nprovide capabilities not found elsewhere, with elasticity being a major driver.\nThe value of elastic scaling is however tightly coupled to the capabilities of\nthe networks that connect all involved resources, both in the public Clouds and\nat the various research institutions. This paper presents results of\nmeasurements involving file transfers inside public Cloud providers, fetching\ndata from on-prem resources into public Cloud instances and fetching data from\npublic Cloud storage into on-prem nodes. The networking of the three major\nCloud providers, namely Amazon Web Services, Microsoft Azure and the Google\nCloud Platform, has been benchmarked. The on-prem nodes were managed by either\nthe Pacific Research Platform or located at the University of Wisconsin -\nMadison. The observed sustained throughput was of the order of 100 Gbps in all\nthe tests moving data in and out of the public Clouds and throughput reaching\ninto the Tbps range for data movements inside the public Cloud providers\nthemselves. All the tests used HTTP as the transfer protocol.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:56:05 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Sfiligoi", "Igor", ""]]}, {"id": "2005.05872", "submitter": "Antonio J. Pe\\v{n}a", "authors": "Harald Servat and Jes\\'us Labarta and Hans-Christian Hoppe and Judit\n  Gim\\'enez and Antonio J. Pe\\~na", "title": "Understanding Memory Access Patterns Using the BSC Performance Tools", "comments": null, "journal-ref": "H. Servat, J. Labarta, H. C. Hoppe, J. Gim\\'enez, and A. J.\n  Pe\\~na, \"Understanding memory access patterns using the BSC performance\n  tools\", Parallel Computing, Elsevier, vol. 78, pp. 1-14, Oct. 2018", "doi": "10.1016/j.parco.2018.06.007", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing gap between processor and memory speeds results in complex memory\nhierarchies as processors evolve to mitigate such divergence by taking\nadvantage of the locality of reference. In this direction, the BSC performance\nanalysis tools have been recently extended to provide insight relative to the\napplication memory accesses depicting their temporal and spatial\ncharacteristics, correlating with the source-code and the achieved performance\nsimultaneously. These extensions rely on the Precise Event-Based Sampling\n(PEBS) mechanism available in recent Intel processors to capture information\nregarding the application memory accesses. The sampled information is later\ncombined with the Folding technique to represent a detailed temporal evolution\nof the memory accesses and in conjunction with the achieved performance and the\nsource-code counterpart. The results obtained from the combination of these\ntools help not only application developers but also processor architects to\nunderstand better how the application behaves and how the system performs. In\nthis paper, we describe a tighter integration of the sampling mechanism into\nthe monitoring package. We also demonstrate the value of the complete workflow\nby exploring already optimized state--of--the--art benchmarks, providing\ndetailed insight of their memory access behavior. We have taken advantage of\nthis insight to apply small modifications that improve the applications'\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:44:02 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 22:19:17 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Servat", "Harald", ""], ["Labarta", "Jes\u00fas", ""], ["Hoppe", "Hans-Christian", ""], ["Gim\u00e9nez", "Judit", ""], ["Pe\u00f1a", "Antonio J.", ""]]}, {"id": "2005.05873", "submitter": "Abhishek  Sinha", "authors": "Rajarshi Bhattacharjee, Abhishek Sinha", "title": "Competitive Algorithms for Minimizing the Maximum Age-of-Information", "comments": "Submitted to the workshop Mathematical performance Modeling and\n  Analysis (MAMA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short paper, we consider the problem of designing a near-optimal\ncompetitive scheduling policy for $N$ mobile users, to maximize the freshness\nof available information uniformly across all users. Prompted by the\nunreliability and non-stationarity of the emerging 5G-mmWave channels for\nhigh-speed users, we forego of any statistical assumptions of the wireless\nchannels and user-mobility. Instead, we allow the channel states and the\nmobility patterns to be dictated by an omniscient adversary. It is not\ndifficult to see that no competitive scheduling policy can exist for the\ncorresponding throughput-maximization problem in this adversarial model.\nSurprisingly, we show that there exists a simple online distributed scheduling\npolicy with a finite competitive ratio for maximizing the freshness of\ninformation in this adversarial model. Moreover, we also prove that the\nproposed policy is competitively optimal up to an $O(\\ln N)$ factor.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:44:46 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Bhattacharjee", "Rajarshi", ""], ["Sinha", "Abhishek", ""]]}, {"id": "2005.06410", "submitter": "Pablo San Juan Sebasti\\'an", "authors": "Pablo San Juan, Adri\\'an Castell\\'o, Manuel F. Dolz, Pedro\n  Alonso-Jord\\'a, Enrique S. Quintana-Ort\\'i", "title": "High Performance and Portable Convolution Operators for ARM-based\n  Multicore Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The considerable impact of Convolutional Neural Networks on many Artificial\nIntelligence tasks has led to the development of various high performance\nalgorithms for the convolution operator present in this type of networks. One\nof these approaches leverages the \\imcol transform followed by a general matrix\nmultiplication (GEMM) in order to take advantage of the highly optimized\nrealizations of the GEMM kernel in many linear algebra libraries. The main\nproblems of this approach are 1) the large memory workspace required to host\nthe intermediate matrices generated by the IM2COL transform; and 2) the time to\nperform the IM2COL transform, which is not negligible for complex neural\nnetworks. This paper presents a portable high performance convolution algorithm\nbased on the BLIS realization of the GEMM kernel that avoids the use of the\nintermediate memory by taking advantage of the BLIS structure. In addition, the\nproposed algorithm eliminates the cost of the explicit IM2COL transform, while\nmaintaining the portability and performance of the underlying realization of\nGEMM in BLIS.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:36:25 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Juan", "Pablo San", ""], ["Castell\u00f3", "Adri\u00e1n", ""], ["Dolz", "Manuel F.", ""], ["Alonso-Jord\u00e1", "Pedro", ""], ["Quintana-Ort\u00ed", "Enrique S.", ""]]}, {"id": "2005.07410", "submitter": "Hongguang Sun", "authors": "Hongguang Sun, Howard H. Yang, Xijun Wang, Chao Xu, Tony Q.S. Quek", "title": "Performance Analysis for Multi-Antenna Small Cell Networks with\n  Clustered Dynamic TDD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small cell networks with dynamic time-division duplex (D-TDD) have emerged as\na potential solution to address the asymmetric traffic demands in 5G wireless\nnetworks. By allowing the dynamic adjustment of cell-specific UL/DL\nconfiguration, D-TDD flexibly allocates percentage of subframes to UL and DL\ntransmissions to accommodate the traffic within each cell. However, the\nunaligned transmissions bring in extra interference which degrades the\npotential gain achieved by D-TDD. In this work, we propose an analytical\nframework to study the performance of multi-antenna small cell networks with\nclustered D-TDD, where cell clustering is employed to mitigate the interference\nfrom opposite transmission direction in neighboring cells. With tools from\nstochastic geometry, we derive explicit expressions and tractable tight upper\nbounds for success probability and network throughput. The proposed analytical\nframework allows to quantify the effect of key system parameters, such as UL/DL\nconfiguration, cluster size, antenna number, and SINR threshold. Our results\nshow the superiority of the clustered D-TDD over the traditional D-TDD, and\nreveal the fact that there exists an optimal cluster size for DL performance,\nwhile UL performance always benefits from a larger cluster.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 08:34:28 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Sun", "Hongguang", ""], ["Yang", "Howard H.", ""], ["Wang", "Xijun", ""], ["Xu", "Chao", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2005.08256", "submitter": "Luxi Zhao", "authors": "Luxi Zhao, Paul Pop, Zhong Zheng, Hugo Daigmorte, Marc Boyer", "title": "Latency Analysis of Multiple Classes of AVB Traffic in TSN with Standard\n  Credit Behavior using Network Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-Sensitive Networking (TSN) is a set of amendments that extend Ethernet\nto support distributed safety-critical and real-time applications in the\nindustrial automation, aerospace and automotive areas. TSN integrates multiple\ntraffic types and supports interactions in several combinations. In this paper\nwe consider the configuration supporting Scheduled Traffic (ST) traffic\nscheduled based on Gate-Control-Lists (GCLs), Audio-Video-Bridging (AVB)\ntraffic according to IEEE 802.1BA that has bounded latencies, and Best-Effort\n(BE) traffic, for which no guarantees are provided. The paper extends the\ntiming analysis method to multiple AVB classes and proofs the credit bounds for\nmultiple classes of AVB traffic, respectively under frozen and non-frozen\nbehaviors of credit during guard band (GB). They are prerequisites for\nnon-overflow credits of Credit-Based Shaper (CBS) and preventing starvation of\nAVB traffic. Moreover, this paper proposes an improved timing analysis method\nreducing the pessimism for the worst-case end-to-end delays of AVB traffic by\nconsidering the limitations from the physical link rate and the output of CBS.\nFinally, we evaluate the improved analysis method on both synthetic and\nreal-world test cases, showing the significant reduction of pessimism on\nlatency bounds compared to related work, and presenting the correctness\nvalidation compared with simulation results. We also compare the AVB latency\nbounds in the case of frozen and non-frozen credit during GB. Additionally, we\nevaluate the scalability of our method with variation of the load of ST flows\nand of the bandwidth reservation for AVB traffic.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 14:06:42 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 02:13:51 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Zhao", "Luxi", ""], ["Pop", "Paul", ""], ["Zheng", "Zhong", ""], ["Daigmorte", "Hugo", ""], ["Boyer", "Marc", ""]]}, {"id": "2005.09140", "submitter": "Mina Zaminkar", "authors": "Mina Zaminkar and Reza Fotohi", "title": "SoS-RPL: Securing Internet of Things Against Sinkhole Attack Using RPL\n  Protocol-Based Node Rating and Ranking Mechanism", "comments": "26 pages, 11 figures, 10 tables, Wireless Pers Commun (2020)", "journal-ref": null, "doi": "10.1007/s11277-020-07421-z", "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through the Internet of Things (IoT) the internet scope is established by the\nintegration of physical things to classify themselves into mutual things. A\nphysical thing can be created by this inventive perception to signify itself in\nthe digital world. Regarding the physical things that are related to the\ninternet, it is worth noting that considering numerous theories and upcoming\npredictions, they mostly require protected structures, moreover, they are at\nrisk of several attacks. IoTs are endowed with particular routing disobedience\ncalled sinkhole attack owing to their distributed features. In these attacks, a\nmalicious node broadcasts illusive information regarding the routings to impose\nitself as a route towards specific nodes for the neighboring nodes and thus,\nattract data traffic. RPL (IP-V6 routing protocol for efficient and low-energy\nnetworks) is a standard routing protocol which is mainly employed in sensor\nnetworks and IoT. This protocol is called SoS-RPL consisting of two key\nsections of the sinkhole detection. In the first section rating and ranking the\nnodes in the RPL is carried out based on distance measurements. The second\nsection is in charge of discovering the misbehavior sources within the IoT\nnetwork through, the Average Packet Transmission RREQ (APT-RREQ). Here, the\ntechnique is assessed through wide simulations performed within the NS-3\nenvironment. Based on the results of the simulation, it is indicated that the\nIoT network behavior metrics are enhanced based on the detection rate,\nfalse-negative rate, false-positive rate, packet delivery rate, maximum\nthroughput, and packet loss rate.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 09:26:09 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zaminkar", "Mina", ""], ["Fotohi", "Reza", ""]]}, {"id": "2005.09745", "submitter": "Benjamin Berg", "authors": "Benjamin Berg, Mor Harchol-Balter, Benjamin Moseley, Weina Wang, and\n  Justin Whitehouse", "title": "Optimal Resource Allocation for Elastic and Inelastic Jobs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data centers are tasked with processing heterogeneous workloads\nconsisting of various classes of jobs. These classes differ in their arrival\nrates, size distributions, and job parallelizability. With respect to\nparalellizability, some jobs are elastic, meaning they can parallelize linearly\nacross many servers. Other jobs are inelastic, meaning they can only run on a\nsingle server. Although job classes can differ drastically, they are typically\nforced to share a single cluster. When sharing a cluster among heterogeneous\njobs, one must decide how to allocate servers to each job at every moment in\ntime. In this paper, we design and analyze allocation policies which aim to\nminimize the mean response time across jobs, where a job's response time is the\ntime from when it arrives until it completes.\n  We model this problem in a stochastic setting where each job may be elastic\nor inelastic. Job sizes are drawn from exponential distributions, but are\nunknown to the system. We show that, in the common case where elastic jobs are\nlarger on average than inelastic jobs, the optimal allocation policy is\nInelastic-First, giving inelastic jobs preemptive priority over elastic jobs.\nWe obtain this result by introducing a novel sample path argument. We also show\nthat there exist cases where Elastic-First (giving priority to elastic jobs)\nperforms better than Inelastic-First. We then provide the first analysis of\nmean response time under both Elastic-First and Inelastic-First by leveraging\nrecent techniques for solving high-dimensional Markov chains.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 20:35:56 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Berg", "Benjamin", ""], ["Harchol-Balter", "Mor", ""], ["Moseley", "Benjamin", ""], ["Wang", "Weina", ""], ["Whitehouse", "Justin", ""]]}, {"id": "2005.10413", "submitter": "Jonas H. M\\\"uller Kornd\\\"orfer", "authors": "Jonas H. M\\\"uller Kornd\\\"orfer and Mario Bielert and La\\'ercio L.\n  Pilla and Florina M. Ciorba", "title": "Mapping Matters: Application Process Mapping on 3-D Processor Topologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications' performance is influenced by the mapping of processes to\ncomputing nodes, the frequency and volume of exchanges among processing\nelements, the network capacity, and the routing protocol. A poor mapping of\napplication processes degrades performance and wastes resources. Process\nmapping is frequently ignored as an explicit optimization step since the system\ntypically offers a default mapping, users may lack awareness of their\napplications' communication behavior, and the opportunities for improving\nperformance through mapping are often unclear. This work studies the impact of\napplication process mapping on several processor topologies. We propose a\nworkflow that renders mapping as an explicit optimization step for parallel\napplications. We apply the workflow to a set of four applications, twelve\nmapping algorithms, and three direct network topologies. We assess the\nmappings' quality in terms of volume, frequency, and distance of exchanges\nusing metrics such as dilation (measured in hop$\\cdot$Byte). With a parallel\ntrace-based simulator, we predict the applications' execution on the three\ntopologies using the twelve mappings. We evaluate the impact of process mapping\non the applications' simulated performance in terms of execution and\ncommunication times and identify the mappings that achieve the highest\nperformance in both cases. To ensure the correctness of the simulations, we\ncompare the pre- and post-simulation results. This work emphasizes the\nimportance of process mapping as an explicit optimization step and offers a\nsolution for parallel applications to exploit the full potential of the\nallocated resources on a given system.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:28:40 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 23:24:30 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 14:28:33 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Kornd\u00f6rfer", "Jonas H. M\u00fcller", ""], ["Bielert", "Mario", ""], ["Pilla", "La\u00e9rcio L.", ""], ["Ciorba", "Florina M.", ""]]}, {"id": "2005.11050", "submitter": "Mohsen Amini Salehi", "authors": "Ali Mokhtari, Chavit Denninnart, Mohsen Amini Salehi", "title": "Autonomous Task Dropping Mechanism to Achieve Robustness in\n  Heterogeneous Computing Systems", "comments": null, "journal-ref": "in 29th Heterogeneity in Computing Workshop (HCW 2019), in the\n  Proceedings of the IPDPS 2019 Workshops & PhD Forum (IPDPSW)", "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of a distributed computing system is defined as the ability to\nmaintain its performance in the presence of uncertain parameters. Uncertainty\nis a key problem in heterogeneous (and even homogeneous) distributed computing\nsystems that perturbs system robustness. Notably, the performance of these\nsystems is perturbed by uncertainty in both task execution time and arrival.\nAccordingly, our goal is to make the system robust against these uncertainties.\nConsidering task execution time as a random variable, we use probabilistic\nanalysis to develop an autonomous proactive task dropping mechanism to attain\nour robustness goal. Specifically, we provide a mathematical model that\nidentifies the optimality of a task dropping decision, so that the system\nrobustness is maximized. Then, we leverage the mathematical model to develop a\ntask dropping heuristic that achieves the system robustness within a feasible\ntime complexity. Although the proposed model is generic and can be applied to\nany distributed system, we concentrate on heterogeneous computing (HC) systems\nthat have a higher degree of exposure to uncertainty than homogeneous systems.\nExperimental results demonstrate that the autonomous proactive dropping\nmechanism can improve the system robustness by up to 20%.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 08:14:04 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Mokhtari", "Ali", ""], ["Denninnart", "Chavit", ""], ["Salehi", "Mohsen Amini", ""]]}, {"id": "2005.11491", "submitter": "Wes Lloyd", "authors": "Huazeng Deng, Ling-Hong Hung, Raymond Schooley, David Perez, Niharika\n  Arumilli, Ka Yee Yeung, Wes Lloyd", "title": "Profiling Resource Utilization of Bioinformatics Workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a software tool, the Container Profiler, that measures and records\nthe resource usage of any containerized task. Our tool profiles the CPU,\nmemory, disk, and network utilization of a containerized job by collecting\nLinux operating system metrics at the virtual machine, container, and process\nlevels. The Container Profiler can produce utilization snapshots at multiple\ntime points, allowing for continuous monitoring of the resources consumed by a\ncontainer workflow.\n  To investigate the utility of the Container Profiler we profiled the resource\nutilization requirements of a multi-stage bioinformatics analytical workflow\n(RNA sequencing using unique molecular identifiers). We examined the collected\nprofile metrics and confirmed that they were consistent with the expected CPU,\ndisk, network resource utilization patterns for the different stages of the\nworkflow. We also quantified the profiling overhead and found that this was\nnegligible.\n  The Container Profiler is a useful tool that can be used to continuously\nmonitor the resource consumption of long and complex containerized workflows\nthat run locally or on the cloud. This can identify bottlenecks where more\nresources are needed to improve performance.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 08:42:57 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Deng", "Huazeng", ""], ["Hung", "Ling-Hong", ""], ["Schooley", "Raymond", ""], ["Perez", "David", ""], ["Arumilli", "Niharika", ""], ["Yeung", "Ka Yee", ""], ["Lloyd", "Wes", ""]]}, {"id": "2005.11523", "submitter": "Antonio Ken Iannillo", "authors": "Domenico Cotroneo, Antonio Ken Iannillo, Roberto Natella, Roberto\n  Pietrantuono", "title": "A Comprehensive Study on Software Aging across Android Versions and\n  Vendors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the phenomenon of software aging - namely, the gradual\nperformance degradation and resource exhaustion in the long run - in the\nAndroid OS. The study intends to highlight if, and to what extent, devices from\ndifferent vendors, under various usage conditions and configurations, are\naffected by software aging and which parts of the system are the main\ncontributors. The results demonstrate that software aging systematically\ndetermines a gradual loss of responsiveness perceived by the user, and an\nunjustified depletion of physical memory. The analysis reveals differences in\nthe aging trends due to the workload factors and to the type of running\napplications, as well as differences due to vendors' customization. Moreover,\nwe analyze several system-level metrics to trace back the software aging\neffects to their main causes. We show that bloated Java containers are a\nsignificant contributor to software aging, and that it is feasible to mitigate\naging through a micro-rejuvenation solution at the container level.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 12:14:58 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cotroneo", "Domenico", ""], ["Iannillo", "Antonio Ken", ""], ["Natella", "Roberto", ""], ["Pietrantuono", "Roberto", ""]]}, {"id": "2005.11608", "submitter": "Sheriffo Ceesay", "authors": "Sheriffo Ceesay, Adam Barker, Yuhui Lin", "title": "Benchmarking and Performance Modelling of MapReduce Communication\n  Pattern", "comments": "8 pages, 10 figures", "journal-ref": "2019 IEEE International Conference on Cloud Computing Technology\n  and Science (CloudCom)", "doi": "10.1109/CloudCom.2019.00029", "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and predicting the performance of big data applications running\nin the cloud or on-premises could help minimise the overall cost of operations\nand provide opportunities in efforts to identify performance bottlenecks. The\ncomplexity of the low-level internals of big data frameworks and the ubiquity\nof application and workload configuration parameters makes it challenging and\nexpensive to come up with comprehensive performance modelling solutions.\n  In this paper, instead of focusing on a wide range of configurable\nparameters, we studied the low-level internals of the MapReduce communication\npattern and used a minimal set of performance drivers to develop a set of phase\nlevel parametric models for approximating the execution time of a given\napplication on a given cluster. Models can be used to infer the performance of\nunseen applications and approximate their performance when an arbitrary dataset\nis used as input. Our approach is validated by running empirical experiments in\ntwo setups. On average the error rate in both setups is plus or minus 10% from\nthe measured values.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 21:52:29 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ceesay", "Sheriffo", ""], ["Barker", "Adam", ""], ["Lin", "Yuhui", ""]]}, {"id": "2005.11931", "submitter": "Niyaz Tokmagambetov", "authors": "Arshyn Altybay, Michael Ruzhansky, Mohammed Elamine Sebih, and Niyaz\n  Tokmagambetov", "title": "Tsunami propagation for singular topographies", "comments": "27 pages, 31 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.NA cs.PF math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a tsunami wave equation with singular coefficients and prove that\nit has a very weak solution. Moreover, we show the uniqueness results and\nconsistency theorem of the very weak solution with the classical one in some\nappropriate sense. Numerical experiments are done for the families of\nregularised problems in one- and two-dimensional cases. In particular, the\nappearance of a substantial second wave is observed, travelling in the opposite\ndirection from the point/line of singularity. Its structure and strength are\nanalysed numerically. In addition, for the two-dimensional tsunami wave\nequation, we develop GPU computing algorithms to reduce the computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 05:44:35 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Altybay", "Arshyn", ""], ["Ruzhansky", "Michael", ""], ["Sebih", "Mohammed Elamine", ""], ["Tokmagambetov", "Niyaz", ""]]}, {"id": "2005.12091", "submitter": "Tobias Weinzierl", "authors": "Philipp Samfass, Tobias Weinzierl, Benjamin Hazelwood, Michael Bader", "title": "TeaMPI -- Replication-based Resilience without the (Performance) Pain", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-50743-5_23", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In an era where we can not afford to checkpoint frequently, replication is a\ngeneric way forward to construct numerical simulations that can continue to run\neven if hardware parts fail. Yet, replication often is not employed on larger\nscales, as na\\\"ively mirroring a computation once effectively halves the\nmachine size, and as keeping replicated simulations consistent with each other\nis not trivial. We demonstrate for the ExaHyPE engine -- a task-based solver\nfor hyperbolic equation systems -- that it is possible to realise resiliency\nwithout major code changes on the user side, while we introduce a novel\nalgorithmic idea where replication reduces the time-to-solution. The redundant\nCPU cycles are not burned \"for nothing\". Our work employs a weakly consistent\ndata model where replicas run independently yet inform each other through\nheartbeat messages whether they are still up and running. Our key performance\nidea is to let the tasks of the replicated simulations share some of their\noutcomes, while we shuffle the actual task execution order per replica. This\nway, replicated ranks can skip some local computations and automatically start\nto synchronise with each other. Our experiments with a production-level seismic\nwave-equation solver provide evidence that this novel concept has the potential\nto make replication affordable for large-scale simulations in high-performance\ncomputing.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 13:12:35 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 13:00:32 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Samfass", "Philipp", ""], ["Weinzierl", "Tobias", ""], ["Hazelwood", "Benjamin", ""], ["Bader", "Michael", ""]]}, {"id": "2005.12873", "submitter": "Miyuru Dayarathna", "authors": "Miyuru Dayarathna and Toyotaro Suzumura", "title": "Benchmarking Graph Data Management and Processing Systems: A Survey", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.PF cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of scalable, representative, and widely adopted benchmarks\nfor graph data systems have been a question for which answers has been sought\nfor decades. We conduct an in-depth study of the existing literature on\nbenchmarks for graph data management and processing, covering 20 different\nbenchmarks developed during the last 15 years. We categorize the benchmarks\ninto three areas focusing on benchmarks for graph processing systems, graph\ndatabase benchmarks, and bigdata benchmarks with graph processing workloads.\nThis systematic approach allows us to identify multiple issues existing in this\narea, including i) few benchmarks exist which can produce high workload\nscenarios, ii) no significant work done on benchmarking graph stream processing\nas well as graph based machine learning, iii) benchmarks tend to use\nconventional metrics despite new meaningful metrics have been around for years,\niv) increasing number of big data benchmarks appear with graph processing\nworkloads. Following these observations, we conclude the survey by describing\nkey challenges for future research on graph data systems benchmarking.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 17:07:29 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 17:35:16 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 17:17:53 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Dayarathna", "Miyuru", ""], ["Suzumura", "Toyotaro", ""]]}, {"id": "2005.13144", "submitter": "Y.C. Tay", "authors": "Y.C. Tay", "title": "A review of analytical performance modeling and its role in computer\n  engineering and science", "comments": "Some parts of this article appeared in \"Lessons from Teaching\n  Analytical Performance Modeling\", Proc. ICPE Workshop on Education and\n  Practice of Performance Engineering, Mumbai, India (April 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is a review of analytical performance modeling for computer\nsystems. It discusses the motivation for this area of research, examines key\nissues, introduces some ideas, illustrates how it is applied, and points out a\nrole that it can play in developing Computer Science.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 03:53:41 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Tay", "Y. C.", ""]]}, {"id": "2005.13353", "submitter": "Youri Raaijmakers", "authors": "Youri Raaijmakers and Sem Borst and Onno Boxma", "title": "Threshold-based rerouting and replication for resolving job-server\n  affinity relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a system with several job types and two parallel server pools.\nWithin the pools the servers are homogeneous, but across pools possibly not in\nthe sense that the service speed of a job may depend on its type as well as the\nserver pool. Immediately upon arrival, jobs are assigned to a server pool. This\ncould be based on (partial) knowledge of their type, but such knowledge might\nnot be available. Information about the job type can however be obtained while\nthe job is in service; as the service progresses, the likelihood that the\nservice speed of this job type is low increases, creating an incentive to\nexecute the job on different, possibly faster, server(s). Two policies are\nconsidered: reroute the job to the other server pool, or replicate it there.\n  We determine the effective load per server under both the rerouting and\nreplication policy for completely unknown as well as partly known job types. We\nalso examine the impact of these policies on the stability bound, and find that\nthe uncertainty in job types may significantly degrade the performance. For\n(highly) unbalanced service speeds full replication achieves the largest\nstability bound while for (nearly) balanced service speeds no replication\nmaximizes the stability bound. Finally, we discuss how the use of\nthreshold-based policies can help improve the expected latency for completely\nor partly unknown job types.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 13:34:24 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Raaijmakers", "Youri", ""], ["Borst", "Sem", ""], ["Boxma", "Onno", ""]]}, {"id": "2005.13374", "submitter": "Mahyar T. Moghaddam", "authors": "Mahyar Tourchi Moghaddam", "title": "IoT-based Emergency Evacuation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fires, earthquakes, floods, hurricanes, overcrowding, or and even pandemic\nviruses endanger human lives. Hence, designing infrastructures to handle\npossible emergencies has become an ever-increasing need. The safe evacuation of\noccupants from the building takes precedence when dealing with the necessary\nmitigation and disaster risk management. This thesis deals with designing an\nIoT system to provide safe and quick evacuation suggestions. The IoT-based\nevacuation system provides optimal evacuation paths that can be continuously\nupdated based on run-time sensory data, so evacuation guidelines can be\nadjusted according to visitors occupants that evolve over time. This thesis\nmakes the following main contributions: i) Addressing an up to date state of\nthe art class for IoT architectural styles and patterns; ii) Proposing a set of\nself-adaptive IoT patterns and assessing their specific quality attributes\n(fault-tolerance, energy consumption, and performance); iii) Designing an IoT\ninfrastructure and testing its performance in both real-time and design-time\napplications; iv) Developing a network flow algorithm that facilitates\nminimizing the time necessary to evacuate people from a scene of a disaster; v)\nModeling various social agents and their interactions during an emergency to\nimprove the IoT system accordingly; vi) Evaluating the system by using\nempirical and real case studies.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 14:08:56 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Moghaddam", "Mahyar Tourchi", ""]]}, {"id": "2005.13685", "submitter": "Ameer Haj-Ali", "authors": "Ameer Haj-Ali, Hasan Genc, Qijing Huang, William Moses, John\n  Wawrzynek, Krste Asanovi\\'c, Ion Stoica", "title": "ProTuner: Tuning Programs with Monte Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore applying the Monte Carlo Tree Search (MCTS) algorithm in a\nnotoriously difficult task: tuning programs for high-performance deep learning\nand image processing. We build our framework on top of Halide and show that\nMCTS can outperform the state-of-the-art beam-search algorithm. Unlike beam\nsearch, which is guided by greedy intermediate performance comparisons between\npartial and less meaningful schedules, MCTS compares complete schedules and\nlooks ahead before making any intermediate scheduling decision. We further\nexplore modifications to the standard MCTS algorithm as well as combining real\nexecution time measurements with the cost model. Our results show that MCTS can\noutperform beam search on a suite of 16 real benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 22:25:10 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Haj-Ali", "Ameer", ""], ["Genc", "Hasan", ""], ["Huang", "Qijing", ""], ["Moses", "William", ""], ["Wawrzynek", "John", ""], ["Asanovi\u0107", "Krste", ""], ["Stoica", "Ion", ""]]}, {"id": "2005.13788", "submitter": "Ioannis Koukoutsidis", "authors": "Ioannis Koukoutsidis", "title": "Age of Information in an Overtake-Free Network of Quasi-Reversible\n  Queues", "comments": "Corrigendum to the MASCOTS 2020 paper. The following changes have\n  been made: a) Re-calculation of the AoI for multiple classes to take full\n  account of the presence of other-class packets b) correction of erroneous\n  statement about the equality of the AoI right bound to the peak AoI.\n  Clarifications on the extensibility of the analysis to other quasi-reversible\n  queues are also provided", "journal-ref": "28th International Symposium on Modeling, Analysis, and Simulation\n  of Computer and Telecommunication Systems (MASCOTS 2020)", "doi": "10.1109/MASCOTS50786.2020.9285958", "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to calculate the Age of Information in an overtake-free network\nof quasi-reversible queues, with exponential exogenous interarrivals of\nmultiple classes of update packets and exponential service times at all nodes.\nResults are provided for any number of M/M/1 First-Come-First-Served (FCFS)\nqueues in tandem, and for a network with two classes of update packets,\nentering through different queues in the network and exiting through the same\nqueue. The main takeaway is that in a network with different classes of update\npackets, individual classes roughly preserve the ages they would achieve if\nthey were alone in the network, except when shared queues become saturated, in\nwhich case the ages increase considerably.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 05:54:30 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 06:17:13 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 06:50:45 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Koukoutsidis", "Ioannis", ""]]}]