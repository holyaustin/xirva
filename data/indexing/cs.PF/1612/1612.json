[{"id": "1612.00309", "submitter": "Edwin Cordeiro", "authors": "Edwin Cordeiro and Rodrigo Carnier and Wagner L Zucchi", "title": "Comparison Between IPv4 to IPv6 Transition Techniques", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The IPv4 addresses exhaustion demands a protocol transition from IPv4 to\nIPv6. The original transition technique, the dual stack, is not widely deployed\nyet and it demanded the creation of new transition techniques to extend the\ntransition period. This work makes an experimental comparison of techniques\nthat use dual stack with a limited IPv4 address. This limited address might be\na RFC 1918 address with a NAT at the Internet Service Provider (ISP) gateway,\nalso known as Carrier Grade NAT (CGN), or an Address Plus Port (A+P) shared\nIPv4 address. The chosen techniques also consider an IPv6 only ISP network. The\ntransport of the IPv4 packets through the IPv6 only networks may use IPv4\npackets encapsulated on IPv6 packets or a double translation, by making one\nIPv4 to IPv6 translation to enter the IPv6 only network and one IPv6 to IPv4\ntranslation to return to the IPv4 network. The chosen techniques were DS-Lite,\n464XLAT, MAP-E and MAP-T. The first part of the test is to check some of the\nmost common usages of the Internet by a home user and the impacts of the\ntransition techniques on the user experience. The second part is a measured\ncomparison considering bandwidth, jitter and latency introduced by the\ntechniques and processor usage on the network equipment.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 15:24:23 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Cordeiro", "Edwin", ""], ["Carnier", "Rodrigo", ""], ["Zucchi", "Wagner L", ""]]}, {"id": "1612.00456", "submitter": "Yan Grange", "authors": "Y.G. Grange, R. Lakhoo, M. Petschow, C. Wu, B. Veenboer, I. Emsley,\n  T.J. Dijkema, A. P. Mechev and G. Mariani", "title": "Characterising radio telescope software with the Workload\n  Characterisation Framework", "comments": "4 pages, 4 figures; to be published in ADASS XXVI (held October\n  16-20, 2016) proceedings. See\n  http://www.adass2016.inaf.it/images/posters/grange.pdf for the poster", "journal-ref": "2019, ADASS XXVI, ASP Conf. Ser., Vol 521, Eds. M. Molinaro, K.\n  Shortridge, & F. Pasian, 683", "doi": null, "report-no": null, "categories": "astro-ph.IM cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modular framework, the Workload Characterisation Framework\n(WCF), that is developed to reproducibly obtain, store and compare key\ncharacteristics of radio astronomy processing software. As a demonstration, we\ndiscuss the experiences using the framework to characterise a LOFAR calibration\nand imaging pipeline.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 21:00:05 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Grange", "Y. G.", ""], ["Lakhoo", "R.", ""], ["Petschow", "M.", ""], ["Wu", "C.", ""], ["Veenboer", "B.", ""], ["Emsley", "I.", ""], ["Dijkema", "T. J.", ""], ["Mechev", "A. P.", ""], ["Mariani", "G.", ""]]}, {"id": "1612.01458", "submitter": "Alessandro Maria Rizzi", "authors": "Alessandro Maria Rizzi", "title": "Support vector regression model for BigData systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays Big Data are becoming more and more important. Many sectors of our\neconomy are now guided by data-driven decision processes. Big Data and business\nintelligence applications are facilitated by the MapReduce programming model\nwhile, at infrastructural layer, cloud computing provides flexible and cost\neffective solutions for allocating on demand large clusters. In such systems,\ncapacity allocation, which is the ability to optimally size minimal resources\nfor achieve a certain level of performance, is a key challenge to enhance\nperformance for MapReduce jobs and minimize cloud resource costs. In order to\ndo so, one of the biggest challenge is to build an accurate performance model\nto estimate job execution time of MapReduce systems. Previous works applied\nsimulation based models for modeling such systems. Although this approach can\naccurately describe the behavior of Big Data clusters, it is too\ncomputationally expensive and does not scale to large system. We try to\novercome these issues by applying machine learning techniques. More precisely\nwe focus on Support Vector Regression (SVR) which is intrinsically more robust\nw.r.t other techniques, like, e.g., neural networks, and less sensitive to\noutliers in the training set. To better investigate these benefits, we compare\nSVR to linear regression.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 18:14:12 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Rizzi", "Alessandro Maria", ""]]}, {"id": "1612.01868", "submitter": "Wafa Badreddine", "authors": "Wafa Badreddine (LIP6, NPA), Claude Chaudet (Institut TELECOM /\n  T\\'el\\'ecom ParisTech), Federico Petruzzi (NPA), Maria Potop-Butucaru (LIP6,\n  NPA)", "title": "Broadcast Strategies and Performance Evaluation of IEEE 802.15.4 in\n  Wireless Body Area Networks WBAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid advances in sensors and ultra-low power wireless communication has\nenabled a new generation of wireless sensor networks: Wireless Body Area\nNetworks (WBAN). To the best of our knowledge the current paper is the first to\naddress broadcast in WBAN. We first analyze several broadcast strategies\ninspired from the area of Delay Tolerant Networks (DTN). The proposed\nstrategies are evaluated via the OMNET++ simulator that we enriched with\nrealistic human body mobility models and channel models issued from the recent\nresearch on biomedical and health informatics. Contrary to the common\nexpectation, our results show that existing research in DTN cannot be\ntransposed without significant modifications in WBANs area. That is, existing\nbroadcast strategies for DTNs do not perform well with human body mobility.\nHowever, our extensive simulations give valuable insights and directions for\ndesigning efficient broadcast in WBAN. Furthermore, we propose a novel\nbroadcast strategy that outperforms the existing ones in terms of end-to-end\ndelay, network coverage and energy consumption. Additionally, we performed\ninvestigations of independent interest related to the ability of all the\nstudied strategies to ensure the total order delivery property when stressed\nwith various packet rates. These investigations open new and challenging\nresearch directions.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 15:33:55 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Badreddine", "Wafa", "", "LIP6, NPA"], ["Chaudet", "Claude", "", "Institut TELECOM /\n  T\u00e9l\u00e9com ParisTech"], ["Petruzzi", "Federico", "", "NPA"], ["Potop-Butucaru", "Maria", "", "LIP6,\n  NPA"]]}, {"id": "1612.02557", "submitter": "Sebastian Deorowicz", "authors": "Marek Kokot, Sebastian Deorowicz, Agnieszka Debudaj-Grabysz", "title": "Sorting Data on Ultra-Large Scale with RADULS. New Incarnation of Radix\n  Sort", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces RADULS, a new parallel sorter based on radix sort\nalgorithm, intended to organize ultra-large data sets efficiently. For example\n4G 16-byte records can be sorted with 16 threads in less than 15 seconds on\nIntel Xeon-based workstation. The implementation of RADULS is not only highly\noptimized to gain such an excellent performance, but also parallelized in a\ncache friendly manner to make the most of modern multicore architectures.\nBesides, our parallel scheduler launches a few different procedures at runtime,\naccording to the current parameters of the execution, for proper workload\nmanagement. All experiments show RADULS to be superior to competing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 08:20:48 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Kokot", "Marek", ""], ["Deorowicz", "Sebastian", ""], ["Debudaj-Grabysz", "Agnieszka", ""]]}, {"id": "1612.03709", "submitter": "Giovanni Neglia", "authors": "Giovanni Neglia (MAESTRO), Matteo Sereno, Giuseppe Bianchi", "title": "Geographical Load Balancing across Green Datacenters", "comments": null, "journal-ref": "SIGMETRICS Performance Evaluation Review, Jun 2016, Juan les Pins,\n  France. 44 (2), pp.64 - 69, 2016", "doi": "10.1145/3003977.3003998", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Geographic Load Balancing\" is a strategy for reducing the energy cost of\ndata centers spreading across different terrestrial locations. In this paper,\nwe focus on load balancing among micro-datacenters powered by renewable energy\nsources. We model via a Markov Chain the problem of scheduling jobs by\nprioritizing datacenters where renewable energy is currently available. Not\nfinding a convenient closed form solution for the resulting chain, we use mean\nfield techniques to derive an asymptotic approximate model which instead is\nshown to have an extremely simple and intuitive steady state solution. After\nproving, using both theoretical and discrete event simulation results, that the\nsystem performance converges to the asymptotic model for an increasing number\nof datacenters, we exploit the simple closed form model's solution to\ninvestigate relationships and trade-offs among the various system parameters.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 14:37:34 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Neglia", "Giovanni", "", "MAESTRO"], ["Sereno", "Matteo", ""], ["Bianchi", "Giuseppe", ""]]}, {"id": "1612.04363", "submitter": "Anastasios Giovanidis", "authors": "Anastasios Giovanidis, Apostolos Avranas", "title": "Spatial multi-LRU: Distributed Caching for Wireless Networks with\n  Coverage Overlaps", "comments": "14 pages, double column, 5 figures, 15 sub-figures in total. arXiv\n  admin note: substantial text overlap with arXiv:1602.07623", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.MM cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a novel family of decentralised caching policies,\napplicable to wireless networks with finite storage at the edge-nodes\n(stations). These policies, that are based on the Least-Recently-Used\nreplacement principle, are here referred to as spatial multi-LRU. They update\ncache inventories in a way that provides content diversity to users who are\ncovered by, and thus have access to, more than one station. Two variations are\nproposed, the multi-LRU-One and -All, which differ in the number of replicas\ninserted in the involved caches. We analyse their performance under two types\nof traffic demand, the Independent Reference Model (IRM) and a model that\nexhibits temporal locality. For IRM, we propose a Che-like approximation to\npredict the hit probability, which gives very accurate results. Numerical\nevaluations show that the performance of multi-LRU increases the more the\nmulti-coverage areas increase, and it is close to the performance of\ncentralised policies, when multi-coverage is sufficient. For IRM traffic,\nmulti-LRU-One is preferable to multi-LRU-All, whereas when the traffic exhibits\ntemporal locality the -All variation can perform better. Both variations\noutperform the simple LRU. When popularity knowledge is not accurate, the new\npolicies can perform better than centralised ones.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 20:54:49 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Giovanidis", "Anastasios", ""], ["Avranas", "Apostolos", ""]]}, {"id": "1612.04470", "submitter": "Farhad Merchant", "authors": "Farhad Merchant, Tarun Vatwani, Anupam Chattopadhyay, Soumyendu Raha,\n  S K Nandy, and Ranjani Narayan", "title": "Efficient Realization of Householder Transform through\n  Algorithm-Architecture Co-design for Acceleration of QR Factorization", "comments": null, "journal-ref": null, "doi": "10.1109/TPDS.2018.2803820", "report-no": null, "categories": "cs.PF cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present efficient realization of Householder Transform (HT) based QR\nfactorization through algorithm-architecture co-design where we achieve\nperformance improvement of 3-90x in-terms of Gflops/watt over state-of-the-art\nmulticore, General Purpose Graphics Processing Units (GPGPUs), Field\nProgrammable Gate Arrays (FPGAs), and ClearSpeed CSX700. Theoretical and\nexperimental analysis of classical HT is performed for opportunities to exhibit\nhigher degree of parallelism where parallelism is quantified as a number of\nparallel operations per level in the Directed Acyclic Graph (DAG) of the\ntransform. Based on theoretical analysis of classical HT, an opportunity\nre-arrange computations in the classical HT is identified that results in\nModified HT (MHT) where it is shown that MHT exhibits 1.33x times higher\nparallelism than classical HT. Experiments in off-the-shelf multicore and\nGeneral Purpose Graphics Processing Units (GPGPUs) for HT and MHT suggest that\nMHT is capable of achieving slightly better or equal performance compared to\nclassical HT based QR factorization realizations in the optimized software\npackages for Dense Linear Algebra (DLA). We implement MHT on a customized\nplatform for Dense Linear Algebra (DLA) and show that MHT achieves 1.3x better\nperformance than native implementation of classical HT on the same accelerator.\nFor custom realization of HT and MHT based QR factorization, we also identify\nmacro operations in the DAGs of HT and MHT that are realized on a\nReconfigurable Data-path (RDP). We also observe that due to re-arrangement in\nthe computations in MHT, custom realization of MHT is capable of achieving 12%\nbetter performance improvement over multicore and GPGPUs than the performance\nimprovement reported by General Matrix Multiplication (GEMM) over highly tuned\nDLA software packages for multicore and GPGPUs which is counter-intuitive.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 03:22:44 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Merchant", "Farhad", ""], ["Vatwani", "Tarun", ""], ["Chattopadhyay", "Anupam", ""], ["Raha", "Soumyendu", ""], ["Nandy", "S K", ""], ["Narayan", "Ranjani", ""]]}, {"id": "1612.04721", "submitter": "Giovanni Neglia", "authors": "Alberto Benegiamo (MAESTRO), Patrick Loiseau, Giovanni Neglia\n  (MAESTRO)", "title": "Dissecting demand response mechanisms: the role of consumption forecasts\n  and personalized offers", "comments": null, "journal-ref": "Proceedings of the 2016 American Control Conference (ACC), Jul\n  2016, Boston, MA, United States. pp.3225 - 3230, 2016", "doi": "10.1109/ACC.2016.7525414", "report-no": null, "categories": "math.OC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand-Response (DR) programs, whereby users of an electricity network are\nencouraged by economic incentives to rearrange their consumption in order to\nreduce production costs, are envisioned to be a key feature of the smart grid\nparadigm. Several recent works proposed DR mechanisms and used analytical\nmodels to derive optimal incentives. Most of these works, however, rely on a\nmacroscopic description of the population that does not model individual\nchoices of users. In this paper, we conduct a detailed analysis of those models\nand we argue that the macroscopic descriptions hide important assumptions that\ncan jeopardize the mechanisms' implementation (such as the ability to make\npersonalized offers and to perfectly estimate the demand that is moved from a\ntimeslot to another). Then, we start from a microscopic description that\nexplicitly models each user's decision. We introduce four DR mechanisms with\nvarious assumptions on the provider's capabilities. Contrarily to previous\nstudies, we find that the optimization problems that result from our mechanisms\nare complex and can be solved numerically only through a heuristic. We present\nnumerical simulations that compare the different mechanisms and their\nsensitivity to forecast errors. At a high level, our results show that the\nperformance of DR mechanisms under reasonable assumptions on the provider's\ncapabilities are significantly lower than\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 14:51:03 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Benegiamo", "Alberto", "", "MAESTRO"], ["Loiseau", "Patrick", "", "MAESTRO"], ["Neglia", "Giovanni", "", "MAESTRO"]]}, {"id": "1612.05486", "submitter": "Wasiur R. KhudaBukhsh", "authors": "Wasiur R. KhudaBukhsh and Amr Rizk and Alexander Fr\\\"ommgen and Heinz\n  Koeppl", "title": "Optimizing Stochastic Scheduling in Fork-Join Queueing Models: Bounds\n  and Applications", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fork-Join (FJ) queueing models capture the dynamics of system parallelization\nunder synchronization constraints, for example, for applications such as\nMapReduce, multipath transmission and RAID systems. Arriving jobs are first\nsplit into tasks and mapped to servers for execution, such that a job can only\nleave the system when all of its tasks are executed.\n  In this paper, we provide computable stochastic bounds for the waiting and\nresponse time distributions for heterogeneous FJ systems under general\nparallelization benefit. Our main contribution is a generalized mathematical\nframework for probabilistic server scheduling strategies that are essentially\ncharacterized by a probability distribution over the number of utilized\nservers, and the optimization thereof. We highlight the trade-off between the\nscaling benefit due to parallelization and the FJ inherent synchronization\npenalty. Further, we provide optimal scheduling strategies for arbitrary\nscaling regimes that map to different levels of parallelization benefit. One\nnotable insight obtained from our results is that different applications with\nvarying parallelization benefits result in different optimal strategies.\nFinally, we complement our analytical results by applying them to various\napplications showing the optimality of the proposed scheduling strategies.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 14:37:19 GMT"}, {"version": "v2", "created": "Mon, 23 Jan 2017 17:44:56 GMT"}, {"version": "v3", "created": "Thu, 2 Feb 2017 11:07:22 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["KhudaBukhsh", "Wasiur R.", ""], ["Rizk", "Amr", ""], ["Fr\u00f6mmgen", "Alexander", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1612.05543", "submitter": "Wasiur R. KhudaBukhsh", "authors": "Wasiur R. KhudaBukhsh, Sounak Kar, Amr Rizk, and Heinz Koeppl", "title": "A Generalized Performance Evaluation Framework for Parallel Systems with\n  Output Synchronization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frameworks, such as MapReduce and Hadoop are abundant nowadays. They seek to\nreap benefits of parallelization, albeit subject to a synchronization\nconstraint at the output. Fork-Join (FJ) queuing models are used to analyze\nsuch systems. Arriving jobs are split into tasks each of which is mapped to\nexactly one server. A job leaves the system when all of its tasks are executed.\n  As a metric of performance, we consider waiting times for both\nwork-conserving and non-work conserving server systems under a mathematical\nset-up general enough to take into account possible phase-type behavior of the\nservers, and as suggested by recent evidences, bursty arrivals.\n  To this end, we present a Markov-additive process framework for an FJ system\nand provide computable bounds on tail probabilities of steady-state waiting\ntimes, for both types of servers separately. We apply our results to three\nscenarios, namely, non-renewal (Markov-modulated) arrivals, servers showing\nphase-type behavior, and Markov-modulated arrivals and services. We compare our\nbounds against estimates obtained through simulations and also provide a\ntheoretical conceptualization of provisions in FJ systems. Finally, we\ncalibrate our model with real data traces, and illustrate how our bounds can be\nused to devise provisions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 16:33:34 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["KhudaBukhsh", "Wasiur R.", ""], ["Kar", "Sounak", ""], ["Rizk", "Amr", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1612.08163", "submitter": "Mahdi Jelodari Mamaghani", "authors": "Ana Lava, Mahdi Jelodari Mamaghani, Siamak Mohammadi and Steve Furber", "title": "Application-aware Retiming of Accelerators: A High-level Data-driven\n  Approach", "comments": "7 pages, 6 figures, submitted to IEEE Design and Test Journal -\n  special issue on Accelerators in October 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flexibility at hardware level is the main driving force behind adaptive\nsystems whose aim is to realise microarhitecture deconfiguration 'online'. This\nfeature allows the software/hardware stack to tolerate drastic changes of the\nworkload in data centres. With emerge of FPGA reconfigurablity this technology\nis becoming a mainstream computing paradigm. Adaptivity is usually accompanied\nby the high-level tools to facilitate multi-dimensional space exploration. An\nessential aspect in this space is memory orchestration where on-chip and\noff-chip memory distribution significantly influences the architecture in\ncoping with the critical spatial and timing constraints, e.g. Place and Route.\nThis paper proposes a memory smart technique for a particular class of adaptive\nsystems: Elastic Circuits which enjoy slack elasticity at fine level of\ngranularity. We explore retiming of a set of popular benchmarks via\ninvestigating the memory distribution within and among accelerators. The area,\nperformance and power patterns are adopted by our high-level synthesis\nframework, with respect to the behaviour of the input descriptions, to improve\nthe quality of the synthesised elastic circuits.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 10:55:46 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Lava", "Ana", ""], ["Mamaghani", "Mahdi Jelodari", ""], ["Mohammadi", "Siamak", ""], ["Furber", "Steve", ""]]}, {"id": "1612.08825", "submitter": "Alexander Amini", "authors": "Alexander Amini, Berthold Horn, Alan Edelman", "title": "Accelerated Convolutions for Efficient Multi-Scale Time to Contact\n  Computation in Julia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutions have long been regarded as fundamental to applied mathematics,\nphysics and engineering. Their mathematical elegance allows for common tasks\nsuch as numerical differentiation to be computed efficiently on large data\nsets. Efficient computation of convolutions is critical to artificial\nintelligence in real-time applications, like machine vision, where convolutions\nmust be continuously and efficiently computed on tens to hundreds of kilobytes\nper second. In this paper, we explore how convolutions are used in fundamental\nmachine vision applications. We present an accelerated n-dimensional\nconvolution package in the high performance computing language, Julia, and\ndemonstrate its efficacy in solving the time to contact problem for machine\nvision. Results are measured against synthetically generated videos and\nquantitatively assessed according to their mean squared error from the ground\ntruth. We achieve over an order of magnitude decrease in compute time and\nallocated memory for comparable machine vision applications. All code is\npackaged and integrated into the official Julia Package Manager to be used in\nvarious other scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 08:46:21 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Amini", "Alexander", ""], ["Horn", "Berthold", ""], ["Edelman", "Alan", ""]]}, {"id": "1612.09532", "submitter": "Nadir Farhi", "authors": "Nacira Guerrouahane, Djamil Aissani, Louiza Bouallouche-Medjkoune,\n  Nadir Farhi", "title": "M/g/c/c state dependent queueing model for road traffic simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a stochastic queuing model for the road traffic,\nwhich captures the stationary density-flow relationships in both uncongested\nand congestion conditions. The proposed model is based on the $M/g/c/c$ state\ndependent queuing model of Jain and Smith, and is inspired from the\ndeterministic Godunov scheme for the road traffic simulation. We first propose\na reformulation of the $M/g/c/c$ state dependent model that works with\ndensity-flow fundamental diagrams rather than density-speed relationships. We\nthen extend this model in order to consider upstream traffic demand as well as\ndownstream traffic supply. Finally, we calculate the speed and travel time\ndistributions for the $M/g/c/c$ state dependent queuing model and for the\nproposed model, and derive stationary performance measures (expected number of\ncars, blocking probability, expected travel time, and throughput). A comparison\nwith results predicted by the $M/g/c/c$ state dependent queuing model shows\nthat the proposed model correctly represents the dynamics of traffic and gives\ngood performances measures. The results illustrate the good accuracy of the\nproposed model.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 00:03:23 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Guerrouahane", "Nacira", ""], ["Aissani", "Djamil", ""], ["Bouallouche-Medjkoune", "Louiza", ""], ["Farhi", "Nadir", ""]]}]