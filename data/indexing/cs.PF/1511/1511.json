[{"id": "1511.01088", "submitter": "Juan Juli\\'an Merelo-Guerv\\'os Pr.", "authors": "Juan-J. Merelo, Pablo Garc\\'ia-S\\'anchez, Mario Garc\\'ia-Valdez,\n  Israel Blancas", "title": "There is no fast lunch: an examination of the running speed of\n  evolutionary algorithms in several languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.PF", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  It is quite usual when an evolutionary algorithm tool or library uses a\nlanguage other than C, C++, Java or Matlab that a reviewer or the audience\nquestions its usefulness based on the speed of those other languages,\npurportedly slower than the aforementioned ones. Despite speed being not\neverything needed to design a useful evolutionary algorithm application, in\nthis paper we will measure the speed for several very basic evolutionary\nalgorithm operations in several languages which use different virtual machines\nand approaches, and prove that, in fact, there is no big difference in speed\nbetween interpreted and compiled languages, and that in some cases, interpreted\nlanguages such as JavaScript or Python can be faster than compiled languages\nsuch as Scala, making them worthy of use for evolutionary algorithm\nexperimentation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 20:34:24 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["Merelo", "Juan-J.", ""], ["Garc\u00eda-S\u00e1nchez", "Pablo", ""], ["Garc\u00eda-Valdez", "Mario", ""], ["Blancas", "Israel", ""]]}, {"id": "1511.01232", "submitter": "Roberto Morabito", "authors": "Roberto Morabito", "title": "Power Consumption of Virtualization Technologies: an Empirical\n  Investigation", "comments": "Accepted to the IEEE/ACM UCC 2015 (SD3C Workshop) - IEEE Copyright", "journal-ref": null, "doi": "10.1109/UCC.2015.93", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization is growing rapidly as a result of the increasing number of\nalternative solutions in this area, and of the wide range of application field.\nUntil now, hypervisor-based virtualization has been the de facto solution to\nperform server virtualization. Recently, container-based virtualization - an\nalternative to hypervisors - has gained more attention because of lightweight\ncharacteristics, attracting cloud providers that have already made use of it to\ndeliver their services. However, a gap in the existing research on containers\nexists in the area of power consumption. This paper presents the results of a\nperformance comparison in terms of power consumption of four different\nvirtualization technologies: KVM and Xen, which are based on hypervisor\nvirtualization, Docker and LXC which are based on container virtualization. The\naim of this empirical investigation, carried out by means of a testbed, is to\nunderstand how these technologies react to particular workloads. Our initial\nresults show how, despite of the number of virtual entities running, both kinds\nof virtualization alternatives behave similarly in idle state and in CPU/Memory\nstress test. Contrarily, the results on network performance show differences\nbetween the two technologies.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 07:49:47 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Morabito", "Roberto", ""]]}, {"id": "1511.01794", "submitter": "Mingfu Li", "authors": "Mingfu Li", "title": "Queueing Analysis of Unicast IPTV With User Mobility and Adaptive\n  Modulation and Coding in Wireless Cellular Networks", "comments": "12 pages, 16 figures", "journal-ref": null, "doi": "10.1109/TVT.2017.2702626", "report-no": null, "categories": "cs.NI cs.IT cs.MM cs.PF math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unicast IPTV services that can support live TV, video-on-demand (VoD), video\nconferencing, and online gaming applications over broadband wireless cellular\nnetworks have been becoming popular in recent years. However, video streaming\nservices significantly impact the performance of wireless cellular networks\nbecause they are bandwidth hogs. To maintain the system performance, effective\nadmission control and resource allocation mechanisms based on an accurate\nmathematical analysis are required. On the other hand, the quality of a\nwireless link usually changes with time due to the user mobility or\ntime-varying channel characteristics. To counteract such time-varying channels\nand improve the spectral efficiency, adaptive modulation and coding (AMC)\nscheme can be adopted in offering unicast IPTV services for mobile users. In\nthis paper, closed-form solutions for the bandwidth usage, blocking rate, and\ndropping rate of unicast IPTV services over wireless cellular networks were\nderived based on the novel queueing model that considers both user mobility and\nAMC. Simulations were also conducted to validate the accuracy of analytical\nresults. Numerical results demonstrate that the presented analytical results\nare accurate. Based on the accurate closed-form solutions, network providers\ncan implement precise admission control and resource allocation for their\nnetworks to enhance the system performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 15:59:35 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Li", "Mingfu", ""]]}, {"id": "1511.02494", "submitter": "Athena Elafrou", "authors": "Athena Elafrou, Georgios Goumas, Nectarios Koziris", "title": "A lightweight optimization selection method for Sparse Matrix-Vector\n  Multiplication", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an optimization selection methodology for the\nubiquitous sparse matrix-vector multiplication (SpMV) kernel. We propose two\nmodels that attempt to identify the major performance bottleneck of the kernel\nfor every instance of the problem and then select an appropriate optimization\nto tackle it. Our first model requires online profiling of the input matrix in\norder to detect its most prevailing performance issue, while our second model\nonly uses comprehensive structural features of the sparse matrix. Our method\ndelivers high performance stability for SpMV across different platforms and\nsparse matrices, due to its application and architecture awareness. Our\nexperimental results demonstrate that a) our approach is able to distinguish\nand appropriately optimize special matrices in multicore platforms that fall\nout of the standard class of memory bandwidth bound matrices, and b) lead to a\nsignificant performance gain of 29% in a manycore platform compared to an\narchitecture-centric optimization, as a result of the successful selection of\nthe appropriate optimization for the great majority of the matrices. With a\nruntime overhead equivalent to a couple dozen SpMV operations, our approach is\npractical for use in iterative numerical solvers of real-life applications.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 15:06:10 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2015 19:44:35 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2016 02:20:27 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Elafrou", "Athena", ""], ["Goumas", "Georgios", ""], ["Koziris", "Nectarios", ""]]}, {"id": "1511.03005", "submitter": "Zhiwei Xu", "authors": "Zhiwei Xu, Bo Chen, Ninghan Wang, Yujun Zhang, Zhongcheng Li", "title": "ELDA: Towards Efficient and Lightweight Detection of Cache Pollution\n  Attacks in NDN", "comments": "A regular paper published in LCN 2015,9 pages,which includes a novel\n  lightweight FM sketch for estimating the number of distinct items in data\n  streams", "journal-ref": null, "doi": "10.1109/LCN.2015.7366286", "report-no": null, "categories": "cs.CR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a promising architectural design for future Internet, named data\nnetworking (NDN) relies on in-network caching to efficiently deliver name-based\ncontent. However, the in-network caching is vulnerable to cache pollution\nattacks (CPA), which can reduce cache hits by violating cache locality and\nsignificantly degrade the overall performance of NDN. To defend against CPA\nattacks, the most effective way is to first detect the attacks and then\nthrottle them. Since the CPA attack itself has already imposed a huge burden on\nvictims, to avoid exhausting the remaining resources on the victims for\ndetection purpose, we expect a lightweight detection solution. We thus propose\nELDA, an Efficient and Lightweight Detection scheme against cache pollution\nAttacks, in which we design a Lightweight Flajolet-Martin (LFM) sketch to\nmonitor the interest traffic. Our analysis and simulations demonstrate that, by\nconsuming a few computation and memory resources, ELDA can effectively and\nefficiently detect CPA attacks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 07:15:53 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Xu", "Zhiwei", ""], ["Chen", "Bo", ""], ["Wang", "Ninghan", ""], ["Zhang", "Yujun", ""], ["Li", "Zhongcheng", ""]]}, {"id": "1511.03742", "submitter": "Anton Lokhmotov", "authors": "Anton Lokhmotov", "title": "GEMMbench: a framework for reproducible and collaborative benchmarking\n  of matrix multiplication", "comments": "ADAPT'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generic matrix-matrix multiplication (GEMM) is arguably the most popular\ncomputational kernel of the 20th century. Yet, surprisingly, no common\nmethodology for evaluating GEMM performance has been established over the many\ndecades of using GEMM for comparing architectures, compilers and ninja-class\nprogrammers.\n  We introduce GEMMbench, a framework and methodology for evaluating\nperformance of GEMM implementations. GEMMbench is implemented on top of\nCollective Knowledge (CK), a lightweight framework for reproducible and\ncollaborative R&D in computer systems. Using CK allows the R&D community to\ncrowdsource hand-written and compiler-generated GEMM implementations and to\nstudy their performance across multiple platforms, data sizes and data types.\n  Our initial implementation supports hand-written OpenCL kernels operating on\nmatrices consisting of single- and double-precision floating-point values, and\nproducing single or multiple output elements per work-item (via thread\ncoarsening and vectorization).\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 01:02:58 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 21:28:05 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Lokhmotov", "Anton", ""]]}, {"id": "1511.05585", "submitter": "Utz-Uwe Haus", "authors": "David Adjiashvili and Utz-Uwe Haus and Adrian Tate", "title": "Model-Driven Automatic Tiling with Cache Associativity Lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional compiler optimization theory distinguishes three separate classes\nof cache miss -- Cold, Conflict and Capacity. Tiling for cache is typically\nguided by capacity miss counts. Models of cache function have not been\neffectively used to guide cache tiling optimizations due to model error and\nexpense. Instead, heuristic or empirical approaches are used to select tilings.\nWe argue that conflict misses, traditionally neglected or seen as a small\nconstant effect, are the only fundamentally important cache miss category, that\nthey form a solid basis by which caches can become modellable, and that models\nleaning on cache associatvity analysis can be used to generate cache performant\ntilings. We develop a mathematical framework that expresses potential and\nactual cache misses in associative caches using Associativity Lattices. We show\nthese lattices to possess two theoretical advantages over rectangular tiles --\nvolume maximization and miss regularity. We also show that to generate such\nlattice tiles requires, unlike rectangular tiling, no explicit, expensive\nlattice point counting. We also describe an implementation of our lattice\ntiling approach, show that it can be used to give speedups of over 10x versus\nunoptimized code, and despite currently only tiling for one level of cache, can\nalready be competitive with the aggressive compiler optimizations used in\ngeneral purposes compares such as GCC and Intel's ICC. We also show that the\ntiling approach can lead to reasonable automatic parallelism when compared to\nexisting auto-threading compilers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 21:14:50 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Adjiashvili", "David", ""], ["Haus", "Utz-Uwe", ""], ["Tate", "Adrian", ""]]}, {"id": "1511.05771", "submitter": "Roberto Rigamonti", "authors": "Baptiste Delporte and Roberto Rigamonti and Alberto Dassatti", "title": "Toward Transparent Heterogeneous Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous parallel systems are widely spread nowadays. Despite their\navailability, their usage and adoption are still limited, and even more rarely\nthey are used to full power. Indeed, compelling new technologies are constantly\ndeveloped and keep changing the technological landscape, but each of them\ntargets a limited sub-set of supported devices, and nearly all of them require\nnew programming paradigms and specific toolsets. Software, however, can hardly\nkeep the pace with the growing number of computational capabilities, and\ndevelopers are less and less motivated in learning skills that could quickly\nbecome obsolete. In this paper we present our effort in the direction of a\ntransparent system optimization based on automatic code profiling and\nJust-In-Time compilation, that resulted in a fully-working embedded prototype\ncapable of dynamically detect computing-intensive code blocks and automatically\ndispatch them to different computation units. Experimental results show that\nour system allows gains up to 32x in performance --- after an initial warm-up\nphase --- without requiring any human intervention.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 13:37:18 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 14:15:41 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Delporte", "Baptiste", ""], ["Rigamonti", "Roberto", ""], ["Dassatti", "Alberto", ""]]}, {"id": "1511.05892", "submitter": "Andrea Tassi", "authors": "Andrea Tassi, Ioannis Chatzigeorgiou, Daniel E. Lucani", "title": "Analysis and Optimization of Sparse Random Linear Network Coding for\n  Reliable Multicast Services", "comments": "To appear on IEEE Transactions on Communications", "journal-ref": null, "doi": "10.1109/TCOMM.2015.2503398", "report-no": null, "categories": "cs.IT cs.MM cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point-to-multipoint communications are expected to play a pivotal role in\nnext-generation networks. This paper refers to a cellular system transmitting\nlayered multicast services to a multicast group of users. Reliability of\ncommunications is ensured via different Random Linear Network Coding (RLNC)\ntechniques. We deal with a fundamental problem: the computational complexity of\nthe RLNC decoder. The higher the number of decoding operations is, the more the\nuser's computational overhead grows and, consequently, the faster the battery\nof mobile devices drains. By referring to several sparse RLNC techniques, and\nwithout any assumption on the implementation of the RLNC decoder in use, we\nprovide an efficient way to characterize the performance of users targeted by\nultra-reliable layered multicast services. The proposed modeling allows to\nefficiently derive the average number of coded packet transmissions needed to\nrecover one or more service layers. We design a convex resource allocation\nframework that allows to minimize the complexity of the RLNC decoder by jointly\noptimizing the transmission parameters and the sparsity of the code. The\ndesigned optimization framework also ensures service guarantees to\npredetermined fractions of users. The performance of the proposed optimization\nframework is then investigated in a LTE-A eMBMS network multicasting H.264/SVC\nvideo services.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 17:41:26 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 00:31:19 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Tassi", "Andrea", ""], ["Chatzigeorgiou", "Ioannis", ""], ["Lucani", "Daniel E.", ""]]}, {"id": "1511.07392", "submitter": "Carl Graham", "authors": "Felipe Olmos (CMAP), Carl Graham (CMAP), Alain Simonian", "title": "Cache Miss Estimation for Non-Stationary Request Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the paper is to evaluate the miss probability of a Least Recently\nUsed (LRU) cache, when it is offered a non-stationary request process given by\na Poisson cluster point process. First, we construct a probability space using\nPalm theory, describing how to consider a tagged document with respect to the\nrest of the request process. This framework allows us to derive a general\nintegral formula for the expected number of misses of the tagged document.\nThen, we consider the limit when the cache size and the arrival rate go to\ninfinity proportionally, and use the integral formula to derive an asymptotic\nexpansion of the miss probability in powers of the inverse of the cache size.\nThis enables us to quantify and improve the accuracy of the so-called Che\napproximation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 20:13:18 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 13:37:17 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Olmos", "Felipe", "", "CMAP"], ["Graham", "Carl", "", "CMAP"], ["Simonian", "Alain", ""]]}, {"id": "1511.07423", "submitter": "Nguyen Quang-Hung", "authors": "Nguyen Quang-Hung, Nam Thoai", "title": "Minimizing Total Busy Time for Energy-Aware Virtual Machine Allocation\n  Problems", "comments": "8 pages, Proceedings of the Sixth International Symposium on\n  Information and Communication Technology. arXiv admin note: substantial text\n  overlap with arXiv:1511.06825", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper investigates the energy-aware virtual machine (VM) allocation\nproblems in clouds along characteristics: multiple resources, fixed interval\ntime and non-preemption of virtual machines. Many previous works have been\nproposed to use a minimum number of physical machines, however, this is not\nnecessarily a good solution to minimize total energy consumption in the VM\nplacement with multiple resources, fixed interval time and non-preemption. We\nobserved that minimizing the sum of total busy time of all physical machines\nimplies minimizing total energy consumption of physical machines. In addition\nto, if mapping of a VM onto physical machines have the same total busy time\nthen the best mapping has physical machine's remaining available resource\nminimizing. Based on these observations, we proposed heuristic-based EM\nalgorithm to solve the energy-aware VM allocation with fixed starting time and\nduration time. In addition, this work studies some heuristics for sorting the\nlist of virtual machines (e.g., sorting by the earliest starting time, or\nlatest finishing time, or the longest duration time first, etc.) to allocate\nVM. We evaluate the EM using CloudSim toolkit and jobs log-traces in the\nFeitelson's Parallel Workloads Archive. Simulation's results show that all of\nEM-ST, EM-LFT and EM-LDTF algorithms could reduce total energy consumption\ncompared to state-of-the-art of power-aware VM allocation algorithms. (e.g.\nPower-Aware Best-Fit Decreasing (PABFD) [7])).\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 04:53:42 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Quang-Hung", "Nguyen", ""], ["Thoai", "Nam", ""]]}, {"id": "1511.07658", "submitter": "Teng Li", "authors": "Teng Li, Vikram K. Narayana, Tarek El-Ghazawi", "title": "Efficient Resource Sharing Through GPU Virtualization on Accelerated\n  High Performance Computing Systems", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The High Performance Computing (HPC) field is witnessing a widespread\nadoption of Graphics Processing Units (GPUs) as co-processors for conventional\nhomogeneous clusters. The adoption of prevalent Single- Program Multiple-Data\n(SPMD) programming paradigm for GPU-based parallel processing brings in the\nchallenge of resource underutilization, with the asymmetrical\nprocessor/co-processor distribution. In other words, under SPMD, balanced\nCPU/GPU distribution is required to ensure full resource utilization. In this\npaper, we propose a GPU resource virtualization approach to allow underutilized\nmicroprocessors to effi- ciently share the GPUs. We propose an efficient GPU\nsharing scenario achieved through GPU virtualization and analyze the\nperformance potentials through execution models. We further present the\nimplementation details of the virtualization infrastructure, followed by the\nexperimental analyses. The results demonstrate considerable performance gains\nwith GPU virtualization. Furthermore, the proposed solution enables full\nutilization of asymmetrical resources, through efficient GPU sharing among\nmicroprocessors, while incurring low overhead due to the added virtualization\nlayer.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 11:33:53 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Li", "Teng", ""], ["Narayana", "Vikram K.", ""], ["El-Ghazawi", "Tarek", ""]]}, {"id": "1511.08167", "submitter": "I\\~naki Ucar", "authors": "I\\~naki Ucar and Arturo Azcorra", "title": "Deseeding Energy Consumption of Network Stacks", "comments": "10 pages, 12 figures", "journal-ref": "IEEE 1st International Forum on Research and Technologies for\n  Society and Industry Leveraging a better tomorrow (RTSI), Turin, 2015, pp.\n  7-16", "doi": "10.1109/RTSI.2015.7325085", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular works on energy efficiency strategies for wireless communications are\nbased on classical energy models that account for the wireless card only.\nNevertheless, there is a non-negligible energy toll called \"cross-factor\" that\nencompasses the energy drained while a frame crosses the network stack of an\nOS.\n  This paper addresses the challenge of deepen into the roots of the\ncross-factor, deseed its components and analyse its causes. Energy issues are\ncritical for IoT devices. Thus, this paper conceives and validates a new\ncomprehensive framework that enables us to measure a wide range of wireless\ndevices, as well as multiple devices synchronously. We also present a rigorous\nmethodology to perform whole-device energy measurements in laptops, a more\ngeneric and suitable device to perform energy debugging. Finally, and using\nthis framework, we provide a collection of measurements and insights that\ndeepens our understanding of the cross-factor.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 17:53:05 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Ucar", "I\u00f1aki", ""], ["Azcorra", "Arturo", ""]]}, {"id": "1511.08290", "submitter": "Taniya Shafique", "authors": "Taniya Shafique, Zia Muhammad and Huy-Dung Han", "title": "Cross-layer Chase Combining with Selective Retransmission, Analysis and\n  Throughput Optimization for OFDM Systems", "comments": "arXiv admin note: text overlap with arXiv:1503.05819", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present bandwidth efficient retransmission method employong\nselective retransmission approach at modulation layer under orthogonal\nfrequency division multiplexing (OFDM) signaling. Our proposed cross-layer\ndesign embeds a selective retransmission sublayer in physical layer (PHY) that\ntargets retransmission of information symbols transmitted over poor quality\nOFDM sub-carriers. Most of the times, few errors in decoded bit stream result\nin packet failure at medium access control (MAC) layer. The unnecessary\nretransmission of good quality information symbols of a failed packet has\ndetrimental effect on overall throughput of transceiver. We propose a\ncross-layer Chase combining with selective retransmission (CCSR) method by\nblending Chase combining at MAC layer and selective retransmission in PHY. The\nselective retransmission in PHY targets the poor quality information symbols\nprior to decoding, which results into lower hybrid automatic repeat reQuest\n(HARQ) retransmissions at MAC layer. We also present tight bit-error rate (BER)\nupper bound and tight throughput lower bound for CCSR method. In order to\nmaximize throughput of the proposed method, we formulate optimization problem\nwith respect to the amount of information to be retransmitted in selective\nretransmission. The simulation results demonstrate significant throughput gain\nof the proposed CCSR method as compared to conventional Chase combining method.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 04:58:45 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Shafique", "Taniya", ""], ["Muhammad", "Zia", ""], ["Han", "Huy-Dung", ""]]}, {"id": "1511.08635", "submitter": "Roberto Rigamonti", "authors": "Baptiste Delporte and Roberto Rigamonti and Alberto Dassatti", "title": "HPA: An Opportunistic Approach to Embedded Energy Efficiency", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing energy consumption is a challenge that is faced on a daily basis by\nteams from the High-Performance Computing as well as the Embedded domain. This\nissue is mostly attacked from an hardware perspective, by devising\narchitectures that put energy efficiency as a primary target, often at the cost\nof processing power. Lately, computing platforms have become more and more\nheterogeneous, but the exploitation of these additional capabilities is so\ncomplex from the application developer's perspective that they are left unused\nmost of the time, resulting therefore in a supplemental waste of energy rather\nthan in faster processing times.\n  In this paper we present a transparent, on-the-fly optimization scheme that\nallows a generic application to automatically exploit the available computing\nunits to partition its computational load. We have called our approach\nHeterogeneous Platform Accelerator (HPA). The idea is to use profiling to\nautomatically select a computing-intensive candidate for acceleration, and then\ndistribute the computations to the different units by off-loading blocks of\ncode to them.\n  Using an NVIDIA Jetson TK1 board, we demonstrate that not only HPA results in\nfaster processing speed, but also in a considerable reduction in the total\nenergy absorbed.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 11:59:41 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Delporte", "Baptiste", ""], ["Rigamonti", "Roberto", ""], ["Dassatti", "Alberto", ""]]}]