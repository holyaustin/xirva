[{"id": "1805.00680", "submitter": "Evangelos Psomakelis Mr", "authors": "Evangelos Psomakelis, Konstantinos Tserpes, Dimosthenis\n  Anagnostopoulos and Theodora Varvarigou", "title": "BUDAMAF: Data Management in Cloud Federations", "comments": "11 pages, 2 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data management has always been a multi-domain problem even in the simplest\ncases. It involves, quality of service, security, resource management, cost\nmanagement, incident identification, disaster avoidance and/or recovery, as\nwell as many other concerns. In our case, this situation gets ever more\ncomplicated because of the divergent nature of a cloud federation like BASMATI.\nIn this federation, the BASMATI Unified Data Management Framework (BUDaMaF),\ntries to create an automated uniform way of managing all the data transactions,\nas well as the data stores themselves, in a polyglot multi-cloud, consisting of\na plethora of different machines and data store systems.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 08:53:35 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Psomakelis", "Evangelos", ""], ["Tserpes", "Konstantinos", ""], ["Anagnostopoulos", "Dimosthenis", ""], ["Varvarigou", "Theodora", ""]]}, {"id": "1805.01559", "submitter": "Georgios Paschos", "authors": "Georgios Paschos, Nikolaos Liakopoulos, Merouane Debbah and Tong Wen", "title": "Computational Optimal Transport for 5G Massive C-RAN Device Association", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive scale of future wireless networks will create computational\nbottlenecks in performance optimization. In this paper, we study the problem of\nconnecting mobile traffic to Cloud RAN (C-RAN) stations. To balance station\nload, we steer the traffic by designing device association rules. The baseline\nassociation rule connects each device to the station with the strongest signal,\nwhich does not account for interference or traffic hot spots, and leads to load\nimbalances and performance deterioration. Instead, we can formulate an\noptimization problem to decide centrally the best association rule at each time\ninstance. However, in practice this optimization has such high dimensions, that\neven linear programming solvers fail to solve. To address the challenge of\nmassive connectivity, we propose an approach based on the theory of optimal\ntransport, which studies the economical transfer of probability between two\ndistributions. Our proposed methodology can further inspire scalable algorithms\nfor massive optimization problems in wireless networks.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 22:08:19 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Paschos", "Georgios", ""], ["Liakopoulos", "Nikolaos", ""], ["Debbah", "Merouane", ""], ["Wen", "Tong", ""]]}, {"id": "1805.01988", "submitter": "Zhengyu Yang", "authors": "Zhengyu Yang, Morteza Hoseinzadeh, Allen Andrews, Clay Mayers, David\n  Evans, Rory Bolt, Janki Bhimani, Ningfang Mi, Steven Swanson", "title": "AutoTiering: Automatic Data Placement Manager in Multi-Tier All-Flash\n  Datacenter", "comments": null, "journal-ref": null, "doi": "10.1109/PCCC.2017.8280433", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the year of 2017, the capital expenditure of Flash-based Solid State\nDrivers (SSDs) keeps declining and the storage capacity of SSDs keeps\nincreasing. As a result, the \"selling point\" of traditional spinning Hard Disk\nDrives (HDDs) as a backend storage - low cost and large capacity - is no longer\nunique, and eventually they will be replaced by low-end SSDs which have large\ncapacity but perform orders of magnitude better than HDDs. Thus, it is widely\nbelieved that all-flash multi-tier storage systems will be adopted in the\nenterprise datacenters in the near future. However, existing caching or tiering\nsolutions for SSD-HDD hybrid storage systems are not suitable for all-flash\nstorage systems. This is because that all-flash storage systems do not have a\nlarge speed difference (e.g., 10x) among each tier. Instead, different\nspecialties (such as high performance, high capacity, etc.) of each tier should\nbe taken into consideration. Motivated by this, we develop an automatic data\nplacement manager called \"AutoTiering\" to handle virtual machine disk files\n(VMDK) allocation and migration in an all-flash multi-tier datacenter to best\nutilize the storage resource, optimize the performance, and reduce the\nmigration overhead. AutoTiering is based on an optimization framework, whose\ncore technique is to predict VM's performance change on different tiers with\ndifferent specialties without conducting real migration. As far as we know,\nAutoTiering is the first optimization solution designed for all-flash\nmulti-tier datacenters. We implement AutoTiering on VMware ESXi, and\nexperimental results show that it can significantly improve the I/O performance\ncompared to existing solutions.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 03:11:54 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Yang", "Zhengyu", ""], ["Hoseinzadeh", "Morteza", ""], ["Andrews", "Allen", ""], ["Mayers", "Clay", ""], ["Evans", "David", ""], ["Bolt", "Rory", ""], ["Bhimani", "Janki", ""], ["Mi", "Ningfang", ""], ["Swanson", "Steven", ""]]}, {"id": "1805.02867", "submitter": "Maxim Milakov", "authors": "Maxim Milakov (NVIDIA), Natalia Gimelshein (NVIDIA)", "title": "Online normalizer calculation for softmax", "comments": "1) Added link to the benchmark code, 2) Benchmarked Safe Softmax +\n  Top-K fused and attributed part of 5x explicitly to fusion in sections 5.2\n  and 6, 3) Stylistic changes, 4) Minor clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Softmax function is ubiquitous in machine learning, multiple previous\nworks suggested faster alternatives for it. In this paper we propose a way to\ncompute classical Softmax with fewer memory accesses and hypothesize that this\nreduction in memory accesses should improve Softmax performance on actual\nhardware. The benchmarks confirm this hypothesis: Softmax accelerates by up to\n1.3x and Softmax+TopK combined and fused by up to 5x.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 07:34:17 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 06:51:27 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Milakov", "Maxim", "", "NVIDIA"], ["Gimelshein", "Natalia", "", "NVIDIA"]]}, {"id": "1805.03841", "submitter": "Beau Johnston", "authors": "Beau Johnston and Josh Milthorpe", "title": "Dwarfs on Accelerators: Enhancing OpenCL Benchmarking for Heterogeneous\n  Computing Architectures", "comments": "10 pages, 5 figures", "journal-ref": "ICPP 2018 Proceedings of the 47th International Conference on\n  Parallel Processing Companion", "doi": "10.1145/3229710.3229729", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For reasons of both performance and energy efficiency, high-performance\ncomputing (HPC) hardware is becoming increasingly heterogeneous. The OpenCL\nframework supports portable programming across a wide range of computing\ndevices and is gaining influence in programming next-generation accelerators.\nTo characterize the performance of these devices across a range of applications\nrequires a diverse, portable and configurable benchmark suite, and OpenCL is an\nattractive programming model for this purpose. We present an extended and\nenhanced version of the OpenDwarfs OpenCL benchmark suite, with a strong focus\nplaced on the robustness of applications, curation of additional benchmarks\nwith an increased emphasis on correctness of results and choice of problem\nsize. Preliminary results and analysis are reported for eight benchmark codes\non a diverse set of architectures -- three Intel CPUs, five Nvidia GPUs, six\nAMD GPUs and a Xeon Phi.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:31:13 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Johnston", "Beau", ""], ["Milthorpe", "Josh", ""]]}, {"id": "1805.03949", "submitter": "Guillaume Houzeaux", "authors": "Marta Garcia-Gasulla, Guillaume Houzeaux, Roger Ferrer, Antoni\n  Artigues, Victor L\\'opez, Jes\\'us Labarta and Mariano V\\'azquez", "title": "MPI+X: task-based parallelization and dynamic load balance of finite\n  element assembly", "comments": null, "journal-ref": null, "doi": "10.1080/10618562.2019.1617856", "report-no": null, "categories": "cs.MS cs.DC cs.PF cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The main computing tasks of a finite element code(FE) for solving partial\ndifferential equations (PDE's) are the algebraic system assembly and the\niterative solver. This work focuses on the first task, in the context of a\nhybrid MPI+X paradigm. Although we will describe algorithms in the FE context,\na similar strategy can be straightforwardly applied to other discretization\nmethods, like the finite volume method. The matrix assembly consists of a loop\nover the elements of the MPI partition to compute element matrices and\nright-hand sides and their assemblies in the local system to each MPI\npartition. In a MPI+X hybrid parallelism context, X has consisted traditionally\nof loop parallelism using OpenMP. Several strategies have been proposed in the\nliterature to implement this loop parallelism, like coloring or substructuring\ntechniques to circumvent the race condition that appears when assembling the\nelement system into the local system. The main drawback of the first technique\nis the decrease of the IPC due to bad spatial locality. The second technique\navoids this issue but requires extensive changes in the implementation, which\ncan be cumbersome when several element loops should be treated. We propose an\nalternative, based on the task parallelism of the element loop using some\nextensions to the OpenMP programming model. The taskification of the assembly\nsolves both aforementioned problems. In addition, dynamic load balance will be\napplied using the DLB library, especially efficient in the presence of hybrid\nmeshes, where the relative costs of the different elements is impossible to\nestimate a priori. This paper presents the proposed methodology, its\nimplementation and its validation through the solution of large computational\nmechanics problems up to 16k cores.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 16:01:01 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Garcia-Gasulla", "Marta", ""], ["Houzeaux", "Guillaume", ""], ["Ferrer", "Roger", ""], ["Artigues", "Antoni", ""], ["L\u00f3pez", "Victor", ""], ["Labarta", "Jes\u00fas", ""], ["V\u00e1zquez", "Mariano", ""]]}, {"id": "1805.04215", "submitter": "Behnam Dezfouli", "authors": "Chia-Chi Li and Behnam Dezfouli", "title": "ProCal: A Low-Cost and Programmable Calibration Tool for IoT Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR-SIOTLAB-APRIL2018-PROCAL", "categories": "cs.PF cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibration is an important step towards building reliable IoT systems. For\nexample, accurate sensor reading requires ADC calibration, and power monitoring\nchips must be calibrated before being used for measuring the energy consumption\nof IoT devices. In this paper, we present ProCal, a low-cost, accurate, and\nscalable power calibration tool. ProCal is a programmable platform which\nprovides dynamic voltage and current output for calibration. The basic idea is\nto use a digital potentiometer connected to a parallel resistor network\ncontrolled through digital switches. The resistance and output frequency of\nProCal is controlled by a software communicating with the board through the SPI\ninterface. Our design provides a simple synchronization mechanism which\nprevents the need for accurate time synchronization. We present mathematical\nmodeling and validation of the tool by incorporating the concept of Fibonacci\nsequence. Our extensive experimental studies show that this tool can\nsignificantly improve measurement accuracy. For example, for ATMega2560, the\nADC error reduces from 0.2% to 0.01%. ProCal not only costs less than 2\\% of\nthe current commercial solutions, it is also highly accurate by being able to\nprovide extensive range of current and voltage values.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 01:15:29 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Li", "Chia-Chi", ""], ["Dezfouli", "Behnam", ""]]}, {"id": "1805.04252", "submitter": "Zheng Wang", "authors": "Ben Taylor, Vicent Sanz Marco, Willy Wolff, Yehia Elkhatib, Zheng Wang", "title": "Adaptive Selection of Deep Learning Models on Embedded Systems", "comments": "Accepted to be published at LCTES 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent ground-breaking advances in deep learning networks ( DNNs ) make\nthem attractive for embedded systems. However, it can take a long time for DNNs\nto make an inference on resource-limited embedded devices. Offloading the\ncomputation into the cloud is often infeasible due to privacy concerns, high\nlatency, or the lack of connectivity. As such, there is a critical need to find\na way to effectively execute the DNN models locally on the devices. This paper\npresents an adaptive scheme to determine which DNN model to use for a given\ninput, by considering the desired accuracy and inference time. Our approach\nemploys machine learning to develop a predictive model to quickly select a\npre-trained DNN to use for a given input and the optimization constraint. We\nachieve this by first training off-line a predictive model, and then use the\nlearnt model to select a DNN model to use for new, unseen inputs. We apply our\napproach to the image classification task and evaluate it on a Jetson TX2\nembedded deep learning platform using the ImageNet ILSVRC 2012 validation\ndataset. We consider a range of influential DNN models. Experimental results\nshow that our approach achieves a 7.52% improvement in inference accuracy, and\na 1.8x reduction in inference time over the most-capable single DNN model.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 06:53:59 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Taylor", "Ben", ""], ["Marco", "Vicent Sanz", ""], ["Wolff", "Willy", ""], ["Elkhatib", "Yehia", ""], ["Wang", "Zheng", ""]]}, {"id": "1805.04271", "submitter": "Marco Giordani", "authors": "Marco Giordani, Andrea Zanella, Takamasa Higuchi, Onur Altintas,\n  Michele Zorzi", "title": "Performance Study of LTE and mmWave in Vehicle-to-Network Communications", "comments": "7 pages, 8 figures, 2 tables, accepted to the IEEE 17th Annual\n  Mediterranean Ad Hoc Networking Workshop (Med-Hoc-Net)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key enabler for the emerging autonomous and cooperative driving services is\nhigh-throughput and reliable Vehicle-to-Network (V2N) communication. In this\nrespect, the millimeter wave (mmWave) frequencies hold great promises because\nof the large available bandwidth which may provide the required link capacity.\nHowever, this potential is hindered by the challenging propagation\ncharacteristics of high-frequency channels and the dynamic topology of the\nvehicular scenarios, which affect the reliability of the connection. Moreover,\nmmWave transmissions typically leverage beamforming gain to compensate for the\nincreased path loss experienced at high frequencies. This, however, requires\nfine alignment of the transmitting and receiving beams, which may be difficult\nin vehicular scenarios. Those limitations may undermine the performance of V2N\ncommunications and pose new challenges for proper vehicular communication\ndesign. In this paper, we study by simulation the practical feasibility of some\nmmWave-aware strategies to support V2N, in comparison to the traditional LTE\nconnectivity below 6 GHz. The results show that the orchestration among\ndifferent radios represents a viable solution to enable both high-capacity and\nrobust V2N communications.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 08:22:21 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Giordani", "Marco", ""], ["Zanella", "Andrea", ""], ["Higuchi", "Takamasa", ""], ["Altintas", "Onur", ""], ["Zorzi", "Michele", ""]]}, {"id": "1805.04303", "submitter": "Marc Leinweber", "authors": "Marc Leinweber and Hannes Hartenstein and Philipp Andelfinger", "title": "Enabling Cross-Event Optimization in Discrete-Event Simulation Through\n  Compile-Time Event Batching", "comments": null, "journal-ref": null, "doi": "10.5445/IR/1000082690", "report-no": "Karlsruhe Reports in Informatics ; 2018,5", "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A discrete-event simulation (DES) involves the execution of a sequence of\nevent handlers dynamically scheduled at runtime. As a consequence, a priori\nknowledge of the control flow of the overall simulation program is limited. In\nparticular, powerful optimizations supported by modern compilers can only be\napplied on the scope of individual event handlers, which frequently involve\nonly a few lines of code. We propose a method that extends the scope for\ncompiler optimizations in discrete-event simulations by generating batches of\nmultiple events that are subjected to compiler optimizations as contiguous\nprocedures. A runtime mechanism executes suitable batches at negligible\noverhead. Our method does not require any compiler extensions and introduces\nonly minor additional effort during model development. The feasibility and\npotential performance gains of the approach are illustrated on the example of\nan idealized proof-ofconcept model. We believe that the applicability of the\napproach extends to general event-driven programs.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 10:03:36 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Leinweber", "Marc", ""], ["Hartenstein", "Hannes", ""], ["Andelfinger", "Philipp", ""]]}, {"id": "1805.04319", "submitter": "D\\'aniel Ber\\'enyi", "authors": "D\\'aniel Ber\\'enyi and Andr\\'as Leitereg and G\\'abor Lehel", "title": "Towards scalable pattern-based optimization for dense linear algebra", "comments": "23 pages, 6 figures, was presented on the Lambda Days 2018 Conference", "journal-ref": "Concurrency and Computation: Practice and Experience 30:e4696\n  (2018)", "doi": "10.1002/cpe.4696", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear algebraic expressions are the essence of many computationally\nintensive problems, including scientific simulations and machine learning\napplications. However, translating high-level formulations of these expressions\nto efficient machine-level representations is far from trivial: developers\nshould be assisted by automatic optimization tools so that they can focus their\nattention on high-level problems, rather than low-level details. The\ntractability of these optimizations is highly dependent on the choice of the\nprimitive constructs in terms of which the computations are to be expressed. In\nthis work we propose to describe operations on multi-dimensional arrays using a\nselection of higher-order functions, inspired by functional programming, and we\npresent rewrite rules for these such that they can be automatically optimized\nfor modern hierarchical and heterogeneous architectures. Using this formalism\nwe systematically construct and analyse different subdivisions and permutations\nof the dense matrix multiplication problem.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 10:54:41 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Ber\u00e9nyi", "D\u00e1niel", ""], ["Leitereg", "Andr\u00e1s", ""], ["Lehel", "G\u00e1bor", ""]]}, {"id": "1805.05571", "submitter": "Imran Shafique Ansari", "authors": "Imran Shafique Ansari, Mohamed-Slim Alouini, and Julian Cheng", "title": "Ergodic Capacity Analysis of Free-Space Optical Links With Nonzero\n  Boresight Pointing Errors", "comments": null, "journal-ref": null, "doi": "10.1109/TWC.2015.2418285", "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A unified capacity analysis of a free-space optical (FSO) link that accounts\nfor nonzero boresight pointing errors and both types of detection techniques\n(i.e. intensity modulation/direct detection as well as heterodyne detection) is\naddressed in this work. More specifically, an exact closed-form expression for\nthe moments of the end-to-end signal-to-noise ratio (SNR) of a single link FSO\ntransmission system is presented in terms of well-known elementary functions.\nCapitalizing on these new moments expressions, we present approximate and\nsimple closed-form results for the ergodic capacity at high and low SNR\nregimes. All the presented results are verified via computer-based Monte-Carlo\nsimulations.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 05:41:15 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Ansari", "Imran Shafique", ""], ["Alouini", "Mohamed-Slim", ""], ["Cheng", "Julian", ""]]}, {"id": "1805.05572", "submitter": "Imran Shafique Ansari", "authors": "Imran Shafique Ansari, Ferkan Yilmaz, and Mohamed-Slim Alouini", "title": "Performance Analysis of Free-Space Optical Links Over M\\'{a}laga\n  ($\\mathcal{M}$) Turbulence Channels with Pointing Errors", "comments": null, "journal-ref": null, "doi": "10.1109/TWC.2015.2467386", "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a unified performance analysis of a free-space\noptical (FSO) link that accounts for pointing errors and both types of\ndetection techniques (i.e. intensity modulation/direct detection (IM/DD) as\nwell as heterodyne detection). More specifically, we present unified exact\nclosed-form expressions for the cumulative distribution function, the\nprobability density function, the moment generating function, and the moments\nof the end-to-end signal-to-noise ratio (SNR) of a single link FSO transmission\nsystem, all in terms of the Meijer's G function except for the moments that is\nin terms of simple elementary functions. We then capitalize on these unified\nresults to offer unified exact closed-form expressions for various performance\nmetrics of FSO link transmission systems, such as, the outage probability, the\nscintillation index (SI), the average error rate for binary and $M$-ary\nmodulation schemes, and the ergodic capacity (except for IM/DD technique, where\nwe present closed-form lower bound results), all in terms of Meijer's G\nfunctions except for the SI that is in terms of simple elementary functions.\nAdditionally, we derive the asymptotic results for all the expressions derived\nearlier in terms of Meijer's G function in the high SNR regime in terms of\nsimple elementary functions via an asymptotic expansion of the Meijer's G\nfunction. We also derive new asymptotic expressions for the ergodic capacity in\nthe low as well as high SNR regimes in terms of simple elementary functions via\nutilizing moments. All the presented results are verified via computer-based\nMonte-Carlo simulations.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 05:43:36 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Ansari", "Imran Shafique", ""], ["Yilmaz", "Ferkan", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1805.05836", "submitter": "Vahid Maleki Raee", "authors": "Vahid Maleki Raee, Diala Naboulsi, Roch Glitho", "title": "Energy Efficient Task Assignment in Virtualized Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.DC cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Sensor Networks (WSNs) are being used extensively today in various\ndomains. However, they are traditionally deployed with applications embedded in\nthem which precludes their re-use for new applications. Nowadays,\nvirtualization enables several applications on a same WSN by abstracting the\nphysical resources (i.e. sensing capabilities) into logical ones. However, this\ncomes at a cost, including an energy cost. It is therefore critical to ensure\nthe efficient allocation of these resources. In this paper, we study the\nproblem of assigning application sensing tasks to sensor devices, in\nvirtualized WSNs. Our goal is to minimize the overall energy consumption\nresulting from the assignment. We focus on the static version of the problem\nand formulate it using Integer Linear Programming (ILP), while accounting for\nsensor nodes' available energy and virtualization overhead. We solve the\nproblem over different scenarios and compare the obtained solution to the case\nof a traditional WSN, i.e. one with no support for virtualization. Our results\nshow that significant energy can be saved when tasks are appropriately assigned\nin a WSN that supports virtualization.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 20:15:32 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Raee", "Vahid Maleki", ""], ["Naboulsi", "Diala", ""], ["Glitho", "Roch", ""]]}, {"id": "1805.06638", "submitter": "Laurent Decreusefond", "authors": "Jalal Rachad (LTCI), Ridha Nasri, Laurent Decreusefond (LTCI)", "title": "Interference Analysis in Dynamic TDD System Combined or not With Cell\n  Clustering Scheme", "comments": null, "journal-ref": "Vehicular Technology Conference, Jun 2018, Porto, Portugal", "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Time Division Duplex (TDD) has been introduced as a solution to deal\nwith the uplink and downlink traffic asymmetry, mainly observed for dense\nheterogeneous network deployments. However, the use of this feature requires\nnew interference mitigation schemes capable to handle two additional types of\ninterferences between cells in opposite transmission cycle: downlink to uplink\nand uplink to downlink interferences. Among them, Cell clustering has been\nproposed as an efficient solution to minimize inter-cell interferences in\nopposite transmission directions and somehow responds to the requirements of\nenhanced Interference Mitigation and Traffic Adaptation (eIMTA) problem. This\nwork is devoted to provide a new analytical approach to model inter-cell\ninterferences and quantify performances of Dynamic TDD system in terms of SINR\n(Signal to Interferences plus Noise Ratio) distribution. Analytical system\nperformance investigation concerns two scenarios: i) basic Dynamic TDD without\nany other feature and ii) Dynamic TDD with interference mitigation schemes.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 07:52:45 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Rachad", "Jalal", "", "LTCI"], ["Nasri", "Ridha", "", "LTCI"], ["Decreusefond", "Laurent", "", "LTCI"]]}, {"id": "1805.06693", "submitter": "Richard Combes", "authors": "Julien Floquet and Richard Combes and Zwi Altman", "title": "Hierarchical Beamforming: Resource Allocation, Fairness and Flow Level\n  Performance", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.PF cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider hierarchical beamforming in wireless networks. For a given\npopulation of flows, we propose computationally efficient algorithms for fair\nrate allocation including proportional fairness and max-min fairness. We next\npropose closed-form formulas for flow level performance, for both elastic (with\neither proportional fairness and max-min fairness) and streaming traffic. We\nfurther assess the performance of hierarchical beamforming using numerical\nexperiments. Since the proposed solutions have low complexity compared to\nconventional beamforming, our work suggests that hierarchical beamforming is a\npromising candidate for the implementation of beamforming in future cellular\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 10:49:50 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Floquet", "Julien", ""], ["Combes", "Richard", ""], ["Altman", "Zwi", ""]]}, {"id": "1805.06747", "submitter": "Reza Salkhordeh", "authors": "Reza Salkhordeh and Shahriar Ebrahimi and Hossein Asadi", "title": "ReCA: an Efficient Reconfigurable Cache Architecture for Storage Systems\n  with Online Workload Characterization", "comments": null, "journal-ref": "IEEE TPDS 2018", "doi": "10.1109/TPDS.2018.2796100", "report-no": null, "categories": "cs.PF cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, SSDs have gained tremendous attention in computing and\nstorage systems due to significant performance improvement over HDDs. The cost\nper capacity of SSDs, however, prevents them from entirely replacing HDDs in\nsuch systems. One approach to effectively take advantage of SSDs is to use them\nas a caching layer to store performance critical data blocks to reduce the\nnumber of accesses to disk subsystem. Due to characteristics of Flash-based\nSSDs such as limited write endurance and long latency on write operations,\nemploying caching algorithms at the Operating System (OS) level necessitates to\ntake such characteristics into consideration. Previous caching techniques are\noptimized towards only one type of application, which affects both generality\nand applicability. In addition, they are not adaptive when the workload pattern\nchanges over time. This paper presents an efficient Reconfigurable Cache\nArchitecture (ReCA) for storage systems using a comprehensive workload\ncharacterization to find an optimal cache configuration for I/O intensive\napplications. For this purpose, we first investigate various types of I/O\nworkloads and classify them into five major classes. Based on this\ncharacterization, an optimal cache configuration is presented for each class of\nworkloads. Then, using the main features of each class, we continuously monitor\nthe characteristics of an application during system runtime and the cache\norganization is reconfigured if the application changes from one class to\nanother class of workloads. The cache reconfiguration is done online and\nworkload classes can be extended to emerging I/O workloads in order to maintain\nits efficiency with the characteristics of I/O requests. Experimental results\nobtained by implementing ReCA in a server running Linux show that the proposed\narchitecture improves performance and lifetime up to 24\\% and 33\\%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 19:24:20 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Salkhordeh", "Reza", ""], ["Ebrahimi", "Shahriar", ""], ["Asadi", "Hossein", ""]]}, {"id": "1805.06865", "submitter": "Ziv Scully", "authors": "Ziv Scully, Mor Harchol-Balter, Alan Scheller-Wolf", "title": "Optimal Scheduling and Exact Response Time Analysis for Multistage Jobs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduling to minimize mean response time in an M/G/1 queue is a classic\nproblem. The problem is usually addressed in one of two scenarios. In the\nperfect-information scenario, the scheduler knows each job's exact size, or\nservice requirement. In the zero-information scenario, the scheduler knows only\neach job's size distribution. The well-known shortest remaining processing time\n(SRPT) policy is optimal in the perfect-information scenario, and the more\ncomplex Gittins policy is optimal in the zero-information scenario.\n  In real systems the scheduler often has partial but incomplete information\nabout each job's size. We introduce a new job model, that of multistage jobs,\nto capture this partial-information scenario. A multistage job consists of a\nsequence of stages, where both the sequence of stages and stage sizes are\nunknown, but the scheduler always knows which stage of a job is in progress. We\ngive an optimal algorithm for scheduling multistage jobs in an M/G/1 queue and\nan exact response time analysis of our algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 17:06:21 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 05:00:55 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Scully", "Ziv", ""], ["Harchol-Balter", "Mor", ""], ["Scheller-Wolf", "Alan", ""]]}, {"id": "1805.07686", "submitter": "Isaac Grosof", "authors": "Isaac Grosof, Ziv Scully and Mor Harchol-Balter", "title": "SRPT for Multiserver Systems", "comments": "15 pages. Submitted to IFIP Performance 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Shortest Remaining Processing Time (SRPT) scheduling policy and its\nvariants have been extensively studied in both theoretical and practical\nsettings. While beautiful results are known for single-server SRPT, much less\nis known for multiserver SRPT. In particular, stochastic analysis of the M/G/k\nunder multiserver SRPT is entirely open. Intuition suggests that multiserver\nSRPT should be optimal or near-optimal for minimizing mean response time.\nHowever, the only known analysis of multiserver SRPT is in the worst-case\nadversarial setting, where SRPT can be far from optimal. In this paper, we give\nthe first stochastic analysis bounding mean response time of the M/G/k under\nmultiserver SRPT. Using our response time bound, we show that multiserver SRPT\nhas asymptotically optimal mean response time in the heavy-traffic limit. The\nkey to our bounds is a strategic combination of stochastic and worst-case\ntechniques. Beyond SRPT, we prove similar response time bounds and optimality\nresults for several other multiserver scheduling policies.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 01:07:03 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Grosof", "Isaac", ""], ["Scully", "Ziv", ""], ["Harchol-Balter", "Mor", ""]]}, {"id": "1805.07998", "submitter": "Ali Mohammed", "authors": "Ali Mohammed, Ahmed Eleliemy, and Florina M. Ciorba", "title": "Performance Reproduction and Prediction of Selected Dynamic Loop\n  Scheduling Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific applications are complex, large, and often exhibit irregular and\nstochastic behavior. The use of efficient loop scheduling techniques in\ncomputationally-intensive applications is crucial for improving their\nperformance on high-performance computing (HPC) platforms. A number of dynamic\nloop scheduling (DLS) techniques have been proposed between the late 1980s and\nearly 2000s, and efficiently used in scientific applications. In most cases,\nthe computing systems on which they have been tested and validated are no\nlonger available. This work is concerned with the minimization of the sources\nof uncertainty in the implementation of DLS techniques to avoid unnecessary\ninfluences on the performance of scientific applications. Therefore, it is\nimportant to ensure that the DLS techniques employed in scientific applications\ntoday adhere to their original design goals and specifications. The goal of\nthis work is to attain and increase the trust in the implementation of DLS\ntechniques in present studies. To achieve this goal, the performance of a\nselection of scheduling experiments from the 1992 original work that introduced\nfactoring is reproduced and predicted via both, simulative and native\nexperimentation. The experiments show that the simulation reproduces the\nperformance achieved on the past computing platform and accurately predicts the\nperformance achieved on the present computing platform. The performance\nreproduction and prediction confirm that the present implementation of the DLS\ntechniques considered both, in simulation and natively, adheres to their\noriginal description. The results confirm the hypothesis that reproducing\nexperiments of identical scheduling scenarios on past and modern hardware leads\nto an entirely different behavior from expected.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 11:46:49 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 16:02:32 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Mohammed", "Ali", ""], ["Eleliemy", "Ahmed", ""], ["Ciorba", "Florina M.", ""]]}, {"id": "1805.08359", "submitter": "Ying Mao", "authors": "Ying Mao, Victoria Green, Jiayin Wang, Haoyi Xiong, Zhishan Guo", "title": "DRESS: Dynamic RESource-reservation Scheme for Congested Data-intensive\n  Computing Platforms", "comments": "IEEE International Conference on Cloud Computing (IEEE CLOUD 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, we have envisioned an increasing number of businesses\nstart driving by big data analytics, such as Amazon recommendations and Google\nAdvertisements. At the back-end side, the businesses are powered by big data\nprocessing platforms to quickly extract information and make decisions. Running\non top of a computing cluster, those platforms utilize scheduling algorithms to\nallocate resources. An efficient scheduler is crucial to the system performance\ndue to limited resources, e.g. CPU and Memory, and a large number of user\ndemands. However, besides requests from clients and current status of the\nsystem, it has limited knowledge about execution length of the running jobs,\nand incoming jobs' resource demands, which make assigning resources a\nchallenging task. If most of the resources are occupied by a long-running job,\nother jobs will have to keep waiting until it releases them. This paper\npresents a new scheduling strategy, named DRESS that particularly aims to\noptimize the allocation among jobs with various demands. Specifically, it\nclassifies the jobs into two categories based on their requests, reserves a\nportion of resources for each of category, and dynamically adjusts the reserved\nratio by monitoring the pending requests and estimating release patterns of\nrunning jobs. The results demonstrate DRESS significantly reduces the\ncompletion time for one category, up to 76.1% in our experiments, and in the\nmeanwhile, maintains a stable overall system performance.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 02:28:55 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Mao", "Ying", ""], ["Green", "Victoria", ""], ["Wang", "Jiayin", ""], ["Xiong", "Haoyi", ""], ["Guo", "Zhishan", ""]]}, {"id": "1805.09641", "submitter": "Koffi Enakoutsa Dr", "authors": "Khanik Kerobyan, Ruben Kerobyan, Koffi Enakoutsa", "title": "Infinite-server queueing model with MAPkGk Markov arrival streams,\n  random volume of customers in random environment subject to catastrophe", "comments": "11 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the infinite server queue model in semi-Markov random\nenvironment with k Markov arrival streams, random resources of customers, and\ncatastrophes is considered. After catastrophes occur, all customers in the\nmodel are flashed out and the system jumps into recovery station. After the\nrecovery time the model works from the empty state. The transient and\nstationary joint distributions of numbers of different types of customers in\nthe model at moment t, numbers of different types of served in some interval\ncustomers, volume of accumulated resources in the model at moment t, and total\nvolume of served resources in an interval for the model without catastrophes\nare found. The transient and stationary joint distributions of numbers of\ndifferent types of customers in the model at moment t, and volume of\naccumulated resources in the model at moment t and their moments for the model\nwith catastrophes are obtained. All results are obtained using Danzig\ncollective marks method and renewal theory methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 14:46:19 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Kerobyan", "Khanik", ""], ["Kerobyan", "Ruben", ""], ["Enakoutsa", "Koffi", ""]]}, {"id": "1805.09642", "submitter": "Koffi Enakoutsa Dr", "authors": "K. Kerobyan, R. Covington, R. Kerobyan, K. Enakoutsa", "title": "An infinite-server queueing model MMAPkGk in semi-Markov random\n  environment with marked MAP arrival and subject to catastrophes", "comments": "13 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper the infinite-server MMAPkGk queueing model with random\nresource vector of customers, marked MAP arrival and semi-Markov (SM) arrival\nof catastrophes is considered. The joint generating functions (PGF) of\ntransient and stationary distributions of number of busy servers and numbers of\ndifferent types served customers, as well as Laplace transformations (LT) of\njoint distributions of total accumulated resources in the model at moment and\ntotal accumulated resources of served customers during time interval are found.\nThe basic differential and renewal equations for transient and stationary PGF\nof queue sizes of customers are found.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 14:46:46 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Kerobyan", "K.", ""], ["Covington", "R.", ""], ["Kerobyan", "R.", ""], ["Enakoutsa", "K.", ""]]}, {"id": "1805.10434", "submitter": "Zili Meng", "authors": "Zili Meng, Jun Bi, Chen Sun, Shuhe Wang, Minhu Wang, Hongxin Hu", "title": "PAM: When Overloaded, Push Your Neighbor Aside!", "comments": "In Proceedings of ACM SIGCOMM 2018 Conference Posters and Demos", "journal-ref": null, "doi": "10.1145/3234200.3234215", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently SmartNICs are widely used to accelerate service chains in NFV.\nHowever, when the SmartNIC is overloaded, casually migrating vNFs away from\nSmartNIC to CPU may lead to additional packet transmissions between SmartNIC\nand CPU. To address this problem, we present PAM, push aside migration to\neffectively alleviate the hot spot on SmartNIC with no performance overhead.\nOur key novelty is to push vNFs on the border of SmartNIC and CPU aside to\nrelease resources for the bottleneck vNF. Evaluation shows that PAM could\nefficiently alleviate the hot spot on SmartNIC and generate a service chain\nwith much lower latency compared with the naive solution.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 06:18:53 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 07:30:16 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Meng", "Zili", ""], ["Bi", "Jun", ""], ["Sun", "Chen", ""], ["Wang", "Shuhe", ""], ["Wang", "Minhu", ""], ["Hu", "Hongxin", ""]]}, {"id": "1805.11681", "submitter": "Li-On Raviv", "authors": "Li-on Raviv and Amir Leshem", "title": "Maximizing Service Reward for Queues with Deadlines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a real time queuing system with rewards and\ndeadlines. We assume that packet processing time is known upon arrival, as is\nthe case in communication networks. This assumption allows us to demonstrate\nthat the well known Earliest-Deadline-First policy performance can be improved.\nWe then propose a scheduling policy that provides excellent results for packets\nwith rewards and deadlines. We prove that the policy is optimal under\ndeterministic service time and binomial reward distribution. In the more\ngeneral case we prove that the policy processes the maximal number of packets\nwhile collecting rewards higher than the expected reward. We present simulation\nresults that show its high performance in more generic cases compared to the\nmost commonly used scheduling policies.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 19:43:01 GMT"}, {"version": "v2", "created": "Sun, 19 Aug 2018 17:24:59 GMT"}, {"version": "v3", "created": "Thu, 23 Aug 2018 05:15:30 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Raviv", "Li-on", ""], ["Leshem", "Amir", ""]]}]