[{"id": "1603.00491", "submitter": "Marat Dukhan", "authors": "Marat Dukhan, Richard Vuduc, Jason Riedy", "title": "Wanted: Floating-Point Add Round-off Error instruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new instruction (FPADDRE) that computes the round-off error in\nfloating-point addition. We explain how this instruction benefits\nhigh-precision arithmetic operations in applications where double precision is\nnot sufficient. Performance estimates on Intel Haswell, Intel Skylake, and AMD\nSteamroller processors, as well as Intel Knights Corner co-processor,\ndemonstrate that such an instruction would improve the latency of double-double\naddition by up to 55% and increase double-double addition throughput by up to\n103%, with smaller, but non-negligible benefits for double-double\nmultiplication. The new instruction delivers up to 2x speedups on three\nbenchmarks that use high-precision floating-point arithmetic: double-double\nmatrix-matrix multiplication, compensated dot product, and polynomial\nevaluation via the compensated Horner scheme.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 21:12:09 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Dukhan", "Marat", ""], ["Vuduc", "Richard", ""], ["Riedy", "Jason", ""]]}, {"id": "1603.01022", "submitter": "Shanai Wu", "authors": "Shanai Wu, Yoan Shin, Jin Young Kim, and Dong In Kim", "title": "Analysis of the Packet Loss Probability in Energy Harvesting Cognitive\n  Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Markovian battery model is proposed to provide the variation of energy\nstates for energy harvesting (EH) secondary users (SUs) in the EH cognitive\nradio networks (CRN). Based on the proposed battery model, we derive the packet\nloss probability in the EH SUs due to sensing inaccuracy and energy outage.\nWith the proposed analysis, the packet loss probability can easily be predicted\nand utilized to optimize the transmission policy (i.e., opportunities for\nsuccessful transmission and EH) of EH SUs to improve their throughput.\nEspecially, the proposed method can be applied to upper layer (scheduling and\nrouting) optimization. To this end, we validate the proposed analysis through\nMonte-Carlo simulation and show an agreement between the analysis and\nsimulations results.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2016 08:43:58 GMT"}], "update_date": "2016-03-04", "authors_parsed": [["Wu", "Shanai", ""], ["Shin", "Yoan", ""], ["Kim", "Jin Young", ""], ["Kim", "Dong In", ""]]}, {"id": "1603.01313", "submitter": "Yanpei Liu", "authors": "Yanpei Liu and Guilherme Cox and Qingyuan Deng and Stark C. Draper and\n  Ricardo Bianchini", "title": "FastCap: An Efficient and Fair Algorithm for Power Capping in Many-Core\n  Systems", "comments": "Accepted by ISPASS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future servers will incorporate many active lowpower modes for different\nsystem components, such as cores and memory. Though these modes provide\nflexibility for power management via Dynamic Voltage and Frequency Scaling\n(DVFS), they must be operated in a coordinated manner. Such coordinated control\ncreates a combinatorial space of possible power mode configurations. Given the\nrapid growth of the number of cores, it is becoming increasingly challenging to\nquickly select the configuration that maximizes the performance under a given\npower budget. Prior power capping techniques do not scale well to large numbers\nof cores, and none of those works has considered memory DVFS. In this paper, we\npresent FastCap, our optimization approach for system-wide power capping, using\nboth CPU and memory DVFS. Based on a queuing model, FastCap formulates power\ncapping as a non-linear optimization problem where we seek to maximize the\nsystem performance under a power budget, while promoting fairness across\napplications. Our FastCap algorithm solves the optimization online and\nefficiently (low complexity on the number of cores), using a small set of\nperformance counters as input. To evaluate FastCap, we simulate it for a\nmany-core server running different types of workloads. Our results show that\nFastCap caps power draw accurately, while producing better application\nperformance and fairness than many existing CPU power capping methods (even\nafter they are extended to use of memory DVFS as well).\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2016 23:21:04 GMT"}], "update_date": "2016-03-07", "authors_parsed": [["Liu", "Yanpei", ""], ["Cox", "Guilherme", ""], ["Deng", "Qingyuan", ""], ["Draper", "Stark C.", ""], ["Bianchini", "Ricardo", ""]]}, {"id": "1603.01316", "submitter": "Helio M. de Oliveira", "authors": "R.C. de Oliveira, H.M. de Oliveira, R.A. Ramalho and L.P.S. Viana", "title": "Performance Assessment of WhatsApp and IMO on Android Operating System\n  (Lollipop and KitKat) during VoIP calls using 3G or WiFi", "comments": "8 pages, Number of floats/tables/figures: 5", "journal-ref": "Global Journal of Computer Science and Technology, Vol 16, No 1-A\n  (2016)", "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper assesses the performance of mobile messaging and VoIP connections.\nWe investigate the CPU usage of WhatsApp and IMO under different scenarios.\nThis analysis also enabled a comparison of the performance of these\napplications on two Android operating system (OS) versions: KitKat or Lollipop.\nTwo models of smartphones were considered, viz. Galaxy Note 4 and Galaxy S4.\nThe applications behavior was statistically investigated for both sending and\nreceiving VoIP calls. Connections have been examined over 3G and WiFi. The\nhandset model plays a decisive role in CPU usage of the application. t-tests\nshowed that IMO has a better performance that WhatsApp whatever be the Android\nat a significance level 1%, on Galaxy Note 4. In contrast, WhatsApp requires\nless CPU than IMO on Galaxy S4 whatever be the OS and access (3G/WiFi). Galaxy\nNote 4 using WiFi always outperformed S4 in terms of processing efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2016 00:05:18 GMT"}, {"version": "v2", "created": "Sat, 14 May 2016 11:37:22 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["de Oliveira", "R. C.", ""], ["de Oliveira", "H. M.", ""], ["Ramalho", "R. A.", ""], ["Viana", "L. P. S.", ""]]}, {"id": "1603.01404", "submitter": "Gideon Weiss", "authors": "Ivo Adan, Marko Boon, Gideon Weiss", "title": "Design Heuristic for Parallel Many Server Systems under FCFS-ALIS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a parallel queueing system with multiple types of servers and\ncustomers. A bipartite graph describes which pairs of customer-server types are\ncompatible. We consider the service policy that always assigns servers to the\nfirst, longest waiting compatible customer, and that always assigns customers\nto the longest idle compatible server if on arrival, multiple compatible\nservers are available. For a general renewal stream of arriving customers and\ngeneral service time distributions, the behavior of such systems is very\ncomplicated. In particular, the calculation of matching rates, the fraction of\nservices of customer-server type, is intractable. We suggest through a\nheuristic argument that if the number of servers becomes large, the matching\nrates are well approximated by matching rates calculated from the tractable\nbipartite infinite matching model. We present simulation evidence to support\nthis heuristic argument, and show how this can be used to design systems with\ndesired performance requirements.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2016 10:03:09 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 19:12:26 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Adan", "Ivo", ""], ["Boon", "Marko", ""], ["Weiss", "Gideon", ""]]}, {"id": "1603.01489", "submitter": "Brendan Cody-Kenny", "authors": "Brendan Cody-Kenny, Michael O'Neill, Stephen Barrett", "title": "Performance Localisation", "comments": "Major revision including extended analysis of previous results.\n  Submitted for publication, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance becomes an issue particularly when execution cost hinders the\nfunctionality of a program. Typically a profiler can be used to find program\ncode execution which represents a large portion of the overall execution cost\nof a program. Pinpointing where a performance issue exists provides a starting\npoint for tracing cause back through a program.\n  While profiling shows where a performance issue manifests, we use mutation\nanalysis to show where a performance improvement is likely to exist. We find\nthat mutation analysis can indicate locations within a program which are highly\nimpactful to the overall execution cost of a program yet are executed\nrelatively infrequently. By better locating potential performance improvements\nin programs we hope to make performance improvement more amenable to\nautomation.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2016 15:05:54 GMT"}, {"version": "v2", "created": "Mon, 5 Sep 2016 12:58:24 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Cody-Kenny", "Brendan", ""], ["O'Neill", "Michael", ""], ["Barrett", "Stephen", ""]]}, {"id": "1603.01876", "submitter": "Jeremy Kepner", "authors": "Patrick Dreher, Chansup Byun, Chris Hill, Vijay Gadepally, Bradley\n  Kuszmaul, Jeremy Kepner", "title": "PageRank Pipeline Benchmark: Proposal for a Holistic System Benchmark\n  for Big-Data Platforms", "comments": "9 pages, 7 figures, to appear in IPDPS 2016 Graph Algorithms Building\n  Blocks (GABB) workshop", "journal-ref": null, "doi": "10.1109/IPDPSW.2016.89", "report-no": null, "categories": "cs.PF astro-ph.IM cs.DC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of big data systems has created a need for benchmarks to measure and\ncompare the capabilities of these systems. Big data benchmarks present unique\nscalability challenges. The supercomputing community has wrestled with these\nchallenges for decades and developed methodologies for creating rigorous\nscalable benchmarks (e.g., HPC Challenge). The proposed PageRank pipeline\nbenchmark employs supercomputing benchmarking methodologies to create a\nscalable benchmark that is reflective of many real-world big data processing\nsystems. The PageRank pipeline benchmark builds on existing prior scalable\nbenchmarks (Graph500, Sort, and PageRank) to create a holistic benchmark with\nmultiple integrated kernels that can be run together or independently. Each\nkernel is well defined mathematically and can be implemented in any programming\nenvironment. The linear algebraic nature of PageRank makes it well suited to\nbeing implemented using the GraphBLAS standard. The computations are simple\nenough that performance predictions can be made based on simple computing\nhardware models. The surrounding kernels provide the context for each kernel\nthat allows rigorous definition of both the input and the output for each\nkernel. Furthermore, since the proposed PageRank pipeline benchmark is scalable\nin both problem size and hardware, it can be used to measure and quantitatively\ncompare a wide range of present day and future systems. Serial implementations\nin C++, Python, Python with Pandas, Matlab, Octave, and Julia have been\nimplemented and their single threaded performance has been measured.\n", "versions": [{"version": "v1", "created": "Sun, 6 Mar 2016 20:51:47 GMT"}, {"version": "v2", "created": "Sat, 4 Jun 2016 01:42:05 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Dreher", "Patrick", ""], ["Byun", "Chansup", ""], ["Hill", "Chris", ""], ["Gadepally", "Vijay", ""], ["Kuszmaul", "Bradley", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1603.02094", "submitter": "Steffen Bondorf", "authors": "Steffen Bondorf and Paul Nikolaus and Jens B. Schmitt", "title": "Quality and Cost of Deterministic Network Calculus - Design and\n  Evaluation of an Accurate and Fast Analysis", "comments": "Accepted at ACM SIGMETRICS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are integral parts of modern safety-critical systems and\ncertification demands the provision of guarantees for data transmissions.\nDeterministic Network Calculus (DNC) can compute a worst-case bound on a data\nflow's end-to-end delay. Accuracy of DNC results has been improved steadily,\nresulting in two DNC branches: the classical algebraic analysis and the more\nrecent optimization-based analysis. The optimization-based branch provides a\ntheoretical solution for tight bounds. Its computational cost grows, however,\n(possibly super-)exponentially with the network size. Consequently, a heuristic\noptimization formulation trading accuracy against computational costs was\nproposed. In this paper, we challenge optimization-based DNC with a new\nalgebraic DNC algorithm.\n  We show that: (i) no current optimization formulation scales well with the\nnetwork size and (ii) algebraic DNC can be considerably improved in both\naspects, accuracy and computational cost. To that end, we contribute a novel\nDNC algorithm that transfers the optimization's search for best attainable\ndelay bounds to algebraic DNC. It achieves a high degree of accuracy and our\nnovel efficiency improvements reduce the cost of the analysis dramatically. In\nextensive numerical experiments, we observe that our delay bounds deviate from\nthe optimization-based ones by only 1.142% on average while computation times\nsimultaneously decrease by several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 14:53:33 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 09:24:13 GMT"}, {"version": "v3", "created": "Tue, 16 May 2017 09:37:51 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Bondorf", "Steffen", ""], ["Nikolaus", "Paul", ""], ["Schmitt", "Jens B.", ""]]}, {"id": "1603.02293", "submitter": "Moritz Steiner", "authors": "Moritz Steiner and Ruomei Gao", "title": "What slows you down? Your network or your device?", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study takes a close look at mobile web performance. The two main\nparameters determining web page load time are the network speed and the\ncomputing power of the end-user device. Based on data from real users, this\npaper quantifies the relative importance of network and device. The findings\nsuggest that increased processing power of latest generation smart phones and\noptimized browsers have a significant impact on web performance; up to 56%\nreduction in median page load time from one generation to the following. The\ncellular networks, on the other hand, have become so mature that the median\npage load time on one fiber-to-the-home network (using wifi for the last meter)\nis only 18-28% faster than cellular and the median page load time on one DSL\nnetwork is 19% slower compared to a well-deployed cellular network.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 21:08:53 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Steiner", "Moritz", ""], ["Gao", "Ruomei", ""]]}, {"id": "1603.02297", "submitter": "Paul Springer", "authors": "Paul Springer and Jeff R. Hammond and Paolo Bientinesi", "title": "TTC: A high-performance Compiler for Tensor Transpositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TTC, an open-source parallel compiler for multidimensional tensor\ntranspositions. In order to generate high-performance C++ code, TTC explores a\nnumber of optimizations, including software prefetching, blocking,\nloop-reordering, and explicit vectorization. To evaluate the performance of\nmultidimensional transpositions across a range of possible use-cases, we also\nrelease a benchmark covering arbitrary transpositions of up to six dimensions.\nPerformance results show that the routines generated by TTC achieve close to\npeak memory bandwidth on both the Intel Haswell and the AMD Steamroller\narchitectures, and yield significant performance gains over modern compilers.\nBy implementing a set of pruning heuristics, TTC allows users to limit the\nnumber of potential solutions; this option is especially useful when dealing\nwith high-dimensional tensors, as the search space might become prohibitively\nlarge. Experiments indicate that when only 100 potential solutions are\nconsidered, the resulting performance is about 99% of that achieved with\nexhaustive search.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 21:13:00 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Springer", "Paul", ""], ["Hammond", "Jeff R.", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1603.02655", "submitter": "Varun Nagpal", "authors": "Varun Nagpal", "title": "Study and evaluation of an Irregular Graph Algorithm on Multicore and\n  GPU Processor Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": "1115-1213Nagpal", "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One area of Computing applications which poses significant challenge of\nperformance scalability on Chip Multiprocessors(CMP's) are Irregular\napplications. Such applications have very little computation and unpredictable\nmemory access patterns making them memory-bound in contrast to compute-bound\napplications. Since the gap between processor and memory performance continues\nto exist, difficulty to hide and decrease this gap is one of the important\nfactors which results in poor performance of these applications on CMP's.\n  The goal of this thesis is to overcome many such challenges posed during\nperformance acceleration of an irregular graph algorithm called Triad Census.\nWe accelerated the Triad Census algorithm on two significantly different Chip\nMultiprocessors: Dual-socket Intel Xeon Multicore (8 hardware threads per\nsocket) and 240-processor core NVIDIA Tesla C1060 GPGPU(128 hardware threads\nper core).\n  The experimental results obtained on Intel Multicore Xeon system shows\nperformance speedups (w.r.t baseline sequential) of maximum 56x , average 33x\nand minimum 8.3x for real world graph data sets. On NVIDIA Tesla C1060 GPGPU,\nwe were able to match almost equally the Multicore results - 58.4x maximum,\n32.8x average and 4.2x minimum speedups w.r.t baseline sequential. In terms of\nraw performance, for the graph data set called Patents network, our results on\nIntel Xeon Multicore(16 hw threads) were 1.27x times faster than previous\nresults on Cray XMT(16 hw threads) while results achieved on GPGPU were\ncomparatively slower(0.72x). To the best of our knowledge, this algorithm has\nonly been accelerated on supercomputer class computer named Cray XMT and no\nwork exists that demonstrates performance evaluation and comparison of this\nalgorithm on relatively lower-cost Multicore and GPGPU based platforms.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2016 20:07:31 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Nagpal", "Varun", ""]]}, {"id": "1603.02955", "submitter": "Roberto Morabito", "authors": "Roberto Morabito", "title": "A Performance Evaluation of Container Technologies on Internet of Things\n  Devices", "comments": null, "journal-ref": null, "doi": "10.1109/INFCOMW.2016.7562228", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of virtualization technologies in different contexts - such as Cloud\nEnvironments, Internet of Things (IoT), Software Defined Networking (SDN) - has\nrapidly increased during the last years. Among these technologies,\ncontainer-based solutions own characteristics for deploying distributed and\nlightweight applications. This paper presents a performance evaluation of\ncontainer technologies on constrained devices, in this case, on Raspberry Pi.\nThe study shows that, overall, the overhead added by containers is negligible.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 16:40:39 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Morabito", "Roberto", ""]]}, {"id": "1603.03252", "submitter": "\\v{L}ubo\\v{s} Koren\\v{c}iak", "authors": "\\v{L}ubo\\v{s} Koren\\v{c}iak, Vojt\\v{e}ch \\v{R}eh\\'ak, Adrian Farmadin", "title": "Extension of PRISM by Synthesis of Optimal Timeouts in Fixed-Delay CTMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a practically appealing extension of the probabilistic model\nchecker PRISM rendering it to handle fixed-delay continuous-time Markov chains\n(fdCTMCs) with rewards, the equivalent formalism to the deterministic and\nstochastic Petri nets (DSPNs). fdCTMCs allow transitions with fixed-delays (or\ntimeouts) on top of the traditional transitions with exponential rates. Our\nextension supports an evaluation of expected reward until reaching a given set\nof target states. The main contribution is that, considering the fixed-delays\nas parameters, we implemented a synthesis algorithm that computes the\nepsilon-optimal values of the fixed-delays minimizing the expected reward. We\nprovide a performance evaluation of the synthesis on practical examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 13:20:05 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["Koren\u010diak", "\u013dubo\u0161", ""], ["\u0158eh\u00e1k", "Vojt\u011bch", ""], ["Farmadin", "Adrian", ""]]}, {"id": "1603.03820", "submitter": "Wei Tan", "authors": "Wei Tan, Liangliang Cao, Liana Fong", "title": "Faster and Cheaper: Parallelizing Large-Scale Matrix Factorization on\n  GPUs", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization (MF) is employed by many popular algorithms, e.g.,\ncollaborative filtering. The emerging GPU technology, with massively multicore\nand high intra-chip memory bandwidth but limited memory capacity, presents an\nopportunity for accelerating MF much further when appropriately exploiting the\nGPU architectural characteristics.\n  This paper presents cuMF, a CUDA-based matrix factorization library that\nimplements memory-optimized alternate least square (ALS) method to solve very\nlarge-scale MF. CuMF uses a variety set of techniques to maximize the\nperformance on either single or multiple GPUs. These techniques include smart\naccess of sparse data leveraging GPU memory hierarchy, using data parallelism\nin conjunction with model parallelism, minimizing the communication overhead\nbetween computing units, and utilizing a novel topology-aware parallel\nreduction scheme.\n  With only a single machine with four Nvidia GPU cards, cuMF can be 6-10 times\nas fast, and 33-100 times as cost-efficient, compared with the state-of-art\ndistributed CPU solutions. Moreover, this cuMF can solve the largest matrix\nfactorization problem ever reported yet in current literature, while\nmaintaining impressively good performance.\n", "versions": [{"version": "v1", "created": "Fri, 11 Mar 2016 23:27:37 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Tan", "Wei", ""], ["Cao", "Liangliang", ""], ["Fong", "Liana", ""]]}, {"id": "1603.07322", "submitter": "Yin Sun", "authors": "Yin Sun, C. Emre Koksal, and Ness B. Shroff", "title": "On Delay-Optimal Scheduling in Queueing Systems with Replications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.IT cs.NI math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern computer systems, jobs are divided into short tasks and executed in\nparallel. Empirical observations in practical systems suggest that the task\nservice times are highly random and the job service time is bottlenecked by the\nslowest straggling task. One common solution for straggler mitigation is to\nreplicate a task on multiple servers and wait for one replica of the task to\nfinish early. The delay performance of replications depends heavily on the\nscheduling decisions of when to replicate, which servers to replicate on, and\nwhich job to serve first. So far, little is understood on how to optimize these\nscheduling decisions for minimizing the delay to complete the jobs. In this\npaper, we present a comprehensive study on delay-optimal scheduling of\nreplications in both centralized and distributed multi-server systems.\nLow-complexity scheduling policies are designed and are proven to be\ndelay-optimal or near delay-optimal in stochastic ordering among all causal and\nnon-preemptive policies. These theoretical results are established for general\nsystem settings and delay metrics that allow for arbitrary arrival processes,\narbitrary job sizes, arbitrary due times, and heterogeneous servers with data\nlocality constraints. Novel sample-path tools are developed to prove these\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 19:55:10 GMT"}, {"version": "v2", "created": "Thu, 24 Mar 2016 17:25:40 GMT"}, {"version": "v3", "created": "Mon, 28 Mar 2016 06:35:32 GMT"}, {"version": "v4", "created": "Thu, 12 May 2016 06:17:50 GMT"}, {"version": "v5", "created": "Thu, 26 Jan 2017 05:21:33 GMT"}, {"version": "v6", "created": "Sat, 28 Jan 2017 19:44:11 GMT"}, {"version": "v7", "created": "Thu, 2 Feb 2017 21:10:07 GMT"}, {"version": "v8", "created": "Mon, 6 Feb 2017 21:38:14 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Sun", "Yin", ""], ["Koksal", "C. Emre", ""], ["Shroff", "Ness B.", ""]]}, {"id": "1603.07899", "submitter": "Konrad Siek", "authors": "Jan Baranowski, Pawe{\\l} Kobyli\\'nski, Konrad Siek, Pawe{\\l} T.\n  Wojciechowski", "title": "Helenos: A Realistic Benchmark for Distributed Transactional Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactional Memory (TM) is an approach to concurrency control that aims to\nmake writing parallel programs both effective and simple. The approach is\nstarted in non-distributed multiprocessor systems, but is gaining popularity in\ndistributed systems to synchronize tasks at large scales. Efficiency and\nscalability are often the key issues in TM research, so performance benchmarks\nare an important part of it. However, while standard TM benchmarks like the\nSTAMP suite and STMBench7 are available and widely accepted, they do not\ntranslate well into distributed systems. Hence, the set of benchmarks usable\nwith distributed TM systems is very limited, and must be padded with\nmicrobenchmarks, whose simplicity and artificial nature often makes them\nuninformative or misleading. Therefore, this paper introduces Helenos, a\nrealistic, complex, and comprehensive distributed TM benchmark based on the\nproblem of the Facebook inbox, an application of the Cassandra distributed\nstore.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2016 13:14:23 GMT"}, {"version": "v2", "created": "Wed, 30 Mar 2016 12:00:49 GMT"}], "update_date": "2016-03-31", "authors_parsed": [["Baranowski", "Jan", ""], ["Kobyli\u0144ski", "Pawe\u0142", ""], ["Siek", "Konrad", ""], ["Wojciechowski", "Pawe\u0142 T.", ""]]}, {"id": "1603.09560", "submitter": "Quan-Lin Li", "authors": "Quan-Lin Li, Chang Chen, Rui-Na Fan, Liang Xu and Jing-Yu Ma", "title": "Queueing Analysis of a Large-Scale Bike Sharing System through\n  Mean-Field Theory", "comments": "51 pages; 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.PF math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bike sharing systems are fast increasing as a public transport mode in\nurban short trips, and have been developed in many major cities around the\nworld. A major challenge in the study of bike sharing systems is that\nlarge-scale and complex queueing networks have to be applied through\nmulti-dimensional Markov processes, while their discussion always suffers a\ncommon difficulty: State space explosion. For this reason, this paper provides\na mean-field computational method to study such a large-scale bike sharing\nsteps: Firstly, a multi-dimensional Markov process is set up for expressing the\nstates of the bike sharing system, and the empirical process of the\nmulti-dimensional Markov process is given to partly overcome the difficulty of\nstate space explosion. Based on this, the mean-field equations are derived by\nmeans of a virtual time-inhomogeneous M(t)/M(t)/1/K queue whose arrival and\nservice rates are determined by the mean-field computation. Secondly, the\nmartingale limit is employed to investigate the limiting behavior of the\nempirical process, the fixed point is proved to be unique so that it can be\ncomputed by means of a nonlinear birth-death process, the asymptotic\nindependence of this system is discussed simply, and specifically, these lead\nto numerical computation of the steady-state probability of the problematic\n(empty or full) stations. Finally, some numerical examples are given for\nvaluable observation on how the steady-state probability of the problematic\nstations depends on some crucial parameters of the bike sharing system.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 12:44:53 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 04:00:05 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Li", "Quan-Lin", ""], ["Chen", "Chang", ""], ["Fan", "Rui-Na", ""], ["Xu", "Liang", ""], ["Ma", "Jing-Yu", ""]]}]