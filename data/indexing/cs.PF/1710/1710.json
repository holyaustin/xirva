[{"id": "1710.00077", "submitter": "Manuel Krebber B.Sc.", "authors": "Manuel Krebber, Henrik Barthels, Paolo Bientinesi", "title": "Efficient Pattern Matching in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern matching is a powerful tool for symbolic computations. Applications\ninclude term rewriting systems, as well as the manipulation of symbolic\nexpressions, abstract syntax trees, and XML and JSON data. It also allows for\nan intuitive description of algorithms in the form of rewrite rules. We present\nthe open source Python module MatchPy, which offers functionality and\nexpressiveness similar to the pattern matching in Mathematica. In particular,\nit includes syntactic pattern matching, as well as matching for commutative\nand/or associative functions, sequence variables, and matching with\nconstraints. MatchPy uses new and improved algorithms to efficiently find\nmatches for large pattern sets by exploiting similarities between patterns. The\nperformance of MatchPy is investigated on several real-world problems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 20:14:47 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Krebber", "Manuel", ""], ["Barthels", "Henrik", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1710.00122", "submitter": "Osama Talaat Ibrahim Eng", "authors": "Osama Talaat Ibrahim and Ahmed El-Mahdy", "title": "An Efficient Load Balancing Method for Tree Algorithms", "comments": "IEEE International Conferences on Scalable Computing and\n  Communications (ScalCom) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, multiprocessing is mainstream with exponentially increasing number\nof processors. Load balancing is, therefore, a critical operation for the\nefficient execution of parallel algorithms. In this paper we consider the\nfundamental class of tree-based algorithms that are notoriously irregular, and\nhard to load-balance with existing static techniques. We propose a hybrid load\nbalancing method using the utility of statistical random sampling in estimating\nthe tree depth and node count distributions to uniformly partition an input\ntree. To conduct an initial performance study, we implemented the method on an\nIntel Xeon Phi accelerator system. We considered the tree traversal operation\non both regular and irregular unbalanced trees manifested by Fibonacci and\nunbalanced (biased) randomly generated trees, respectively. The results show\nscalable performance for up to the 60 physical processors of the accelerator,\nas well as an extrapolated 128 processors case.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 00:12:05 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Ibrahim", "Osama Talaat", ""], ["El-Mahdy", "Ahmed", ""]]}, {"id": "1710.00296", "submitter": "Weina Wang", "authors": "Weina Wang, Mor Harchol-Balter, Haotian Jiang, Alan Scheller-Wolf, R.\n  Srikant", "title": "Delay Asymptotics and Bounds for Multi-Task Parallel Jobs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study delay of jobs that consist of multiple parallel tasks, which is a\ncritical performance metric in a wide range of applications such as data file\nretrieval in coded storage systems and parallel computing. In this problem,\neach job is completed only when all of its tasks are completed, so the delay of\na job is the maximum of the delays of its tasks. Despite the wide attention\nthis problem has received, tight analysis is still largely unknown since\nanalyzing job delay requires characterizing the complicated correlation among\ntask delays, which is hard to do.\n  We first consider an asymptotic regime where the number of servers, $n$, goes\nto infinity, and the number of tasks in a job, $k^{(n)}$, is allowed to\nincrease with $n$. We establish the asymptotic independence of any $k^{(n)}$\nqueues under the condition $k^{(n)} = o(n^{1/4})$. This greatly generalizes the\nasymptotic-independence type of results in the literature where asymptotic\nindependence is shown only for a fixed constant number of queues. As a\nconsequence of our independence result, the job delay converges to the maximum\nof independent task delays.\n  We next consider the non-asymptotic regime. Here we prove that independence\nyields a stochastic upper bound on job delay for any $n$ and any $k^{(n)}$ with\n$k^{(n)}\\le n$. The key component of our proof is a new technique we develop,\ncalled \"Poisson oversampling\". Our approach converts the job delay problem into\na corresponding balls-and-bins problem. However, in contrast with typical\nballs-and-bins problems where there is a negative correlation among bins, we\nprove that our variant exhibits positive correlation.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 05:19:19 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 18:16:21 GMT"}, {"version": "v3", "created": "Sun, 16 Sep 2018 01:50:55 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wang", "Weina", ""], ["Harchol-Balter", "Mor", ""], ["Jiang", "Haotian", ""], ["Scheller-Wolf", "Alan", ""], ["Srikant", "R.", ""]]}, {"id": "1710.00414", "submitter": "Mehmet Aktas", "authors": "Mehmet Fatih Aktas, Pei Peng, Emina Soljanin", "title": "Straggler Mitigation by Delayed Relaunch of Tasks", "comments": "Accepted for IFIP WG 7.3 Performance 2017. Nov. 14-16, 2017, New\n  York, NY USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redundancy for straggler mitigation, originally in data download and more\nrecently in distributed computing context, has been shown to be effective both\nin theory and practice. Analysis of systems with redundancy has drawn\nsignificant attention and numerous papers have studied pain and gain of\nredundancy under various service models and assumptions on the straggler\ncharacteristics. We here present a cost (pain) vs. latency (gain) analysis of\nusing simple replication or erasure coding for straggler mitigation in\nexecuting jobs with many tasks. We quantify the effect of the tail of task\nexecution times and discuss tail heaviness as a decisive parameter for the cost\nand latency of using redundancy. Specifically, we find that coded redundancy\nachieves better cost vs. latency tradeoff than simple replication and can yield\nreduction in both cost and latency under less heavy tailed execution times. We\nshow that delaying redundancy is not effective in reducing cost and that\ndelayed relaunch of stragglers can yield significant reduction in cost and\nlatency. We validate these observations by comparing with the simulations that\nuse empirical distributions extracted from Google cluster data.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 21:09:29 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Aktas", "Mehmet Fatih", ""], ["Peng", "Pei", ""], ["Soljanin", "Emina", ""]]}, {"id": "1710.00748", "submitter": "Mehmet Aktas", "authors": "Mehmet Fatih Aktas, Pei Peng, Emina Soljanin", "title": "Effective Straggler Mitigation: Which Clones Should Attack and When?", "comments": "Published at MAMA Workshop in conjunction with ACM Sigmetrics, June\n  5, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redundancy for straggler mitigation, originally in data download and more\nrecently in distributed computing context, has been shown to be effective both\nin theory and practice. Analysis of systems with redundancy has drawn\nsignificant attention and numerous papers have studied pain and gain of\nredundancy under various service models and assumptions on the straggler\ncharacteristics. We here present a cost (pain) vs. latency (gain) analysis of\nusing simple replication or erasure coding for straggler mitigation in\nexecuting jobs with many tasks. We quantify the effect of the tail of task\nexecution times and discuss tail heaviness as a decisive parameter for the cost\nand latency of using redundancy. Specifically, we find that coded redundancy\nachieves better cost vs. latency and allows for greater achievable latency and\ncost tradeoff region compared to replication and can yield reduction in both\ncost and latency under less heavy tailed execution times. We show that delaying\nredundancy is not effective in reducing cost.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 16:04:27 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Aktas", "Mehmet Fatih", ""], ["Peng", "Pei", ""], ["Soljanin", "Emina", ""]]}, {"id": "1710.01079", "submitter": "Andrew Anderson", "authors": "Andrew Anderson and David Gregg", "title": "Optimal DNN Primitive Selection with Partitioned Boolean Quadratic\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) require very large amounts of computation both\nfor training and for inference when deployed in the field. Many different\nalgorithms have been proposed to implement the most computationally expensive\nlayers of DNNs. Further, each of these algorithms has a large number of\nvariants, which offer different trade-offs of parallelism, data locality,\nmemory footprint, and execution time. In addition, specific algorithms operate\nmuch more efficiently on specialized data layouts and formats.\n  We state the problem of optimal primitive selection in the presence of data\nformat transformations, and show that it is NP-hard by demonstrating an\nembedding in the Partitioned Boolean Quadratic Assignment problem (PBQP).\n  We propose an analytic solution via a PBQP solver, and evaluate our approach\nexperimentally by optimizing several popular DNNs using a library of more than\n70 DNN primitives, on an embedded platform and a general purpose platform. We\nshow experimentally that significant gains are possible versus the state of the\nart vendor libraries by using a principled analytic solution to the problem of\nlayout selection in the presence of data format transformations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 11:25:24 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 10:56:03 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Anderson", "Andrew", ""], ["Gregg", "David", ""]]}, {"id": "1710.01113", "submitter": "Chiara Boldrini", "authors": "Chiara Boldrini, Riccardo Incaini, Raffaele Bruno", "title": "Relocation in Car Sharing Systems with Shared Stackable Vehicles:\n  Modelling Challenges and Outlook", "comments": "IEEE ITSC 2017: 20th International Conference on Intelligent\n  Transportation Systems, Yokohama, Japan. October 16 - 19, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Car sharing is expected to reduce traffic congestion and pollution in cities\nwhile at the same time improving accessibility to public transport. However,\nthe most popular form of car sharing, one-way car sharing, still suffers from\nthe vehicle unbalance problem. Innovative solutions to this issue rely on\ncustom vehicles with stackable capabilities: customers or operators can drive a\ntrain of vehicles if necessary, thus efficiently bringing several cars from an\narea with few requests to an area with many requests. However, how to model a\ncar sharing system with stackable vehicles is an open problem in the related\nliterature. In this paper, we propose a queueing theoretical model to fill this\ngap, and we use this model to derive an upper-bound on user-based relocation\ncapabilities. We also validate, for the first time in the related literature,\nlegacy queueing theoretical models against a trace of real car sharing data.\nFinally, we present preliminary results about the impact, on car availability,\nof simple user-based relocation heuristics with stackable vehicles. Our results\nindicate that user-based relocation schemes that exploit vehicle stackability\ncan significantly improve car availability at stations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 12:49:43 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Boldrini", "Chiara", ""], ["Incaini", "Riccardo", ""], ["Bruno", "Raffaele", ""]]}, {"id": "1710.02282", "submitter": "Gabriele D'Angelo", "authors": "Stefano Ferretti, Gabriele D'Angelo, Vittorio Ghini, Moreno Marzolla", "title": "The Quest for Scalability and Accuracy in the Simulation of the Internet\n  of Things: an Approach based on Multi-Level Simulation", "comments": "Proceedings of the IEEE/ACM International Symposium on Distributed\n  Simulation and Real Time Applications (DS-RT 2017)", "journal-ref": null, "doi": "10.1109/DISTRA.2017.8167672", "report-no": null, "categories": "cs.PF cs.DC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology for simulating the Internet of Things (IoT)\nusing multi-level simulation models. With respect to conventional simulators,\nthis approach allows us to tune the level of detail of different parts of the\nmodel without compromising the scalability of the simulation. As a use case, we\nhave developed a two-level simulator to study the deployment of smart services\nover rural territories. The higher level is base on a coarse grained,\nagent-based adaptive parallel and distributed simulator. When needed, this\nsimulator spawns OMNeT++ model instances to evaluate in more detail the issues\nconcerned with wireless communications in restricted areas of the simulated\nworld. The performance evaluation confirms the viability of multi-level\nsimulations for IoT environments.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 06:05:58 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 07:12:41 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""], ["Ghini", "Vittorio", ""], ["Marzolla", "Moreno", ""]]}, {"id": "1710.02568", "submitter": "Andrea Tassi", "authors": "Andrea Tassi, Robert J. Piechocki, Andrew Nix", "title": "High-Speed Data Dissemination over Device-to-Device Millimeter-Wave\n  Networks for Highway Vehicular Communication", "comments": "To appear in IEEE VNC 2017, Torino, IT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gigabit-per-second connectivity among vehicles is expected to be a key\nenabling technology for sensor information sharing, in turn, resulting in safer\nIntelligent Transportation Systems (ITSs). Recently proposed millimeter-wave\n(mmWave) systems appear to be the only solution capable of meeting the data\nrate demand imposed by future ITS services. In this poster, we assess the\nperformance of a mmWave device-to-device (D2D) vehicular network by\ninvestigating the impact of system and communication parameters on end-users.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 19:56:24 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Tassi", "Andrea", ""], ["Piechocki", "Robert J.", ""], ["Nix", "Andrew", ""]]}, {"id": "1710.02575", "submitter": "Andrea Tassi", "authors": "Ioannis Mavromatis, Andrea Tassi, Robert J. Piechocki, Andrew Nix", "title": "Agile Calibration Process of Full-Stack Simulation Frameworks for V2X\n  Communications", "comments": "To appear in IEEE VNC 2017, Torino, IT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer simulations and real-world car trials are essential to investigate\nthe performance of Vehicle-to-Everything (V2X) networks. However, simulations\nare imperfect models of the physical reality and can be trusted only when they\nindicate agreement with the real-world. On the other hand, trials lack\nreproducibility and are subject to uncertainties and errors. In this paper, we\nwill illustrate a case study where the interrelationship between trials,\nsimulation, and the reality-of-interest is presented. Results are then compared\nin a holistic fashion. Our study will describe the procedure followed to\nmacroscopically calibrate a full-stack network simulator to conduct\nhigh-fidelity full-stack computer simulations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 20:25:59 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Mavromatis", "Ioannis", ""], ["Tassi", "Andrea", ""], ["Piechocki", "Robert J.", ""], ["Nix", "Andrew", ""]]}, {"id": "1710.03439", "submitter": "Yuqing Zhu", "authors": "Yuqing Zhu, Jianxun Liu, Mengying Guo, Yungang Bao, Wenlong Ma,\n  Zhuoyue Liu, Kunpeng Song, Yingchun Yang", "title": "BestConfig: Tapping the Performance Potential of Systems via Automatic\n  Configuration Tuning", "comments": null, "journal-ref": "ACM SoCC 2017", "doi": "10.1145/3127479.3128605", "report-no": null, "categories": "cs.PF cs.DB cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ever increasing number of configuration parameters are provided to system\nusers. But many users have used one configuration setting across different\nworkloads, leaving untapped the performance potential of systems. A good\nconfiguration setting can greatly improve the performance of a deployed system\nunder certain workloads. But with tens or hundreds of parameters, it becomes a\nhighly costly task to decide which configuration setting leads to the best\nperformance. While such task requires the strong expertise in both the system\nand the application, users commonly lack such expertise.\n  To help users tap the performance potential of systems, we present\nBestConfig, a system for automatically finding a best configuration setting\nwithin a resource limit for a deployed system under a given application\nworkload. BestConfig is designed with an extensible architecture to automate\nthe configuration tuning for general systems. To tune system configurations\nwithin a resource limit, we propose the divide-and-diverge sampling method and\nthe recursive bound-and-search algorithm. BestConfig can improve the throughput\nof Tomcat by 75%, that of Cassandra by 63%, that of MySQL by 430%, and reduce\nthe running time of Hive join job by about 50% and that of Spark join job by\nabout 80%, solely by configuration adjustment.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 08:10:06 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Zhu", "Yuqing", ""], ["Liu", "Jianxun", ""], ["Guo", "Mengying", ""], ["Bao", "Yungang", ""], ["Ma", "Wenlong", ""], ["Liu", "Zhuoyue", ""], ["Song", "Kunpeng", ""], ["Yang", "Yingchun", ""]]}, {"id": "1710.03561", "submitter": "Geraint Palmer", "authors": "Geraint I. Palmer, Vincent A. Knight, Paul R. Harper, Asyl L. Hawa", "title": "Ciw: An open source discrete event simulation library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Ciw, an open source library for conducting discrete\nevent simulations that has been developed in Python. The strengths of the\nlibrary are illustrated in terms of best practice and reproducibility for\ncomputational research. An analysis of Ciw's performance and comparison to\nseveral alternative discrete event simulation frameworks is presented.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 11:05:34 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Palmer", "Geraint I.", ""], ["Knight", "Vincent A.", ""], ["Harper", "Paul R.", ""], ["Hawa", "Asyl L.", ""]]}, {"id": "1710.04094", "submitter": "Thomas R\\\"ohl", "authors": "Thomas R\\\"ohl, Jan Eitzinger, Georg Hager and Gerhard Wellein", "title": "Validation of hardware events for successful performance pattern\n  identification in High Performance Computing", "comments": null, "journal-ref": "Tools for High Performance Computing 2015", "doi": "10.1007/978-3-319-39589-0_2", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware performance monitoring (HPM) is a crucial ingredient of performance\nanalysis tools. While there are interfaces like LIKWID, PAPI or the kernel\ninterface perf\\_event which provide HPM access with some additional features,\nmany higher level tools combine event counts with results retrieved from other\nsources like function call traces to derive (semi-)automatic performance\nadvice. However, although HPM is available for x86 systems since the early 90s,\nonly a small subset of the HPM features is used in practice. Performance\npatterns provide a more comprehensive approach, enabling the identification of\nvarious performance-limiting effects. Patterns address issues like bandwidth\nsaturation, load imbalance, non-local data access in ccNUMA systems, or false\nsharing of cache lines. This work defines HPM event sets that are best suited\nto identify a selection of performance patterns on the Intel Haswell processor.\nWe validate the chosen event sets for accuracy in order to arrive at a reliable\npattern detection mechanism and point out shortcomings that cannot be easily\ncircumvented due to bugs or limitations in the hardware.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 14:40:04 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["R\u00f6hl", "Thomas", ""], ["Eitzinger", "Jan", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1710.05420", "submitter": "Ermao Cai", "authors": "Ermao Cai, Da-Cheng Juan, Dimitrios Stamoulis, Diana Marculescu", "title": "NeuralPower: Predict and Deploy Energy-Efficient Convolutional Neural\n  Networks", "comments": "Accepted as a conference paper at ACML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"How much energy is consumed for an inference made by a convolutional neural\nnetwork (CNN)?\" With the increased popularity of CNNs deployed on the\nwide-spectrum of platforms (from mobile devices to workstations), the answer to\nthis question has drawn significant attention. From lengthening battery life of\nmobile devices to reducing the energy bill of a datacenter, it is important to\nunderstand the energy efficiency of CNNs during serving for making an\ninference, before actually training the model. In this work, we propose\nNeuralPower: a layer-wise predictive framework based on sparse polynomial\nregression, for predicting the serving energy consumption of a CNN deployed on\nany GPU platform. Given the architecture of a CNN, NeuralPower provides an\naccurate prediction and breakdown for power and runtime across all layers in\nthe whole network, helping machine learners quickly identify the power,\nruntime, or energy bottlenecks. We also propose the \"energy-precision ratio\"\n(EPR) metric to guide machine learners in selecting an energy-efficient CNN\narchitecture that better trades off the energy consumption and prediction\naccuracy. The experimental results show that the prediction accuracy of the\nproposed NeuralPower outperforms the best published model to date, yielding an\nimprovement in accuracy of up to 68.5%. We also assess the accuracy of\npredictions at the network level, by predicting the runtime, power, and energy\nof state-of-the-art CNN architectures, achieving an average accuracy of 88.24%\nin runtime, 88.34% in power, and 97.21% in energy. We comprehensively\ncorroborate the effectiveness of NeuralPower as a powerful framework for\nmachine learners by testing it on different GPU platforms and Deep Learning\nsoftware tools.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 23:39:29 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Cai", "Ermao", ""], ["Juan", "Da-Cheng", ""], ["Stamoulis", "Dimitrios", ""], ["Marculescu", "Diana", ""]]}, {"id": "1710.05615", "submitter": "Hyegyeong Park", "authors": "Hyegyeong Park, Dongwon Lee and Jaekyun Moon", "title": "LDPC Code Design for Distributed Storage: Balancing Repair Bandwidth,\n  Reliability and Storage Overhead", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed storage systems suffer from significant repair traffic generated\ndue to frequent storage node failures. This paper shows that properly designed\nlow-density parity-check (LDPC) codes can substantially reduce the amount of\nrequired block downloads for repair thanks to the sparse nature of their factor\ngraph representation. In particular, with a careful construction of the factor\ngraph, both low repair-bandwidth and high reliability can be achieved for a\ngiven code rate. First, a formula for the average repair bandwidth of LDPC\ncodes is developed. This formula is then used to establish that the minimum\nrepair bandwidth can be achieved by forcing a regular check node degree in the\nfactor graph. Moreover, it is shown that given a fixed code rate, the variable\nnode degree should also be regular to yield minimum repair bandwidth, under\nsome reasonable minimum variable node degree constraint. It is also shown that\nfor a given repair-bandwidth requirement, LDPC codes can yield substantially\nhigher reliability than currently utilized Reed-Solomon (RS) codes. Our\nreliability analysis is based on a formulation of the general equation for the\nmean-time-to-data-loss (MTTDL) associated with LDPC codes. The formulation\nreveals that the stopping number is closely related to the MTTDL. It is further\nshown that LDPC codes can be designed such that a small loss of\nrepair-bandwidth optimality may be traded for a large improvement in\nerasure-correction capability and thus the MTTDL.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 10:49:25 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Park", "Hyegyeong", ""], ["Lee", "Dongwon", ""], ["Moon", "Jaekyun", ""]]}, {"id": "1710.05720", "submitter": "EPTCS", "authors": "Simon Rehwald, Amjad Ibrahim, Kristian Beckers, Alexander Pretschner", "title": "ACCBench: A Framework for Comparing Causality Algorithms", "comments": "In Proceedings CREST 2017, arXiv:1710.02770", "journal-ref": "EPTCS 259, 2017, pp. 16-30", "doi": "10.4204/EPTCS.259.2", "report-no": null, "categories": "cs.AI cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern socio-technical systems are increasingly complex. A fundamental\nproblem is that the borders of such systems are often not well-defined\na-priori, which among other problems can lead to unwanted behavior during\nruntime. Ideally, unwanted behavior should be prevented. If this is not\npossible the system shall at least be able to help determine potential cause(s)\na-posterori, identify responsible parties and make them accountable for their\nbehavior. Recently, several algorithms addressing these concepts have been\nproposed. However, the applicability of the corresponding approaches,\nspecifically their effectiveness and performance, is mostly unknown. Therefore,\nin this paper, we propose ACCBench, a benchmark tool that allows to compare and\nevaluate causality algorithms under a consistent setting. Furthermore, we\ncontribute an implementation of the two causality algorithms by G\\\"o{\\ss}ler\nand Metayer and G\\\"o{\\ss}ler and Astefanoaei as well as of a policy compliance\napproach based on some concepts of Main et al. Lastly, we conduct a case study\nof an Intelligent Door Control System, which exposes concrete strengths and\nweaknesses of all algorithms under different aspects. In the course of this, we\nshow that the effectiveness of the algorithms in terms of cause detection as\nwell as their performance differ to some extent. In addition, our analysis\nreports on some qualitative aspects that should be considered when evaluating\neach algorithm. For example, the human effort needed to configure the algorithm\nand model the use case is analyzed.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 05:20:33 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Rehwald", "Simon", ""], ["Ibrahim", "Amjad", ""], ["Beckers", "Kristian", ""], ["Pretschner", "Alexander", ""]]}, {"id": "1710.06189", "submitter": "Huichao Hong", "authors": "Huichao Hong, Lixin Zheng, Shuwan Pan", "title": "Computation of gray-level co-occurrence matrix based on CUDA and its\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As in various fields like scientific research and industrial application, the\ncomputation time optimization is becoming a task that is of increasing\nimportance because of its highly parallel architecture. The graphics processing\nunit is regarded as a powerful engine for application programs that demand\nfairly high computation capabilities. Based on this, an algorithm was\nintroduced in this paper to optimize the method used to compute the gray-level\nco-occurrence matrix (GLCM) of an image, and strategies (e.g., \"copying\",\n\"image partitioning\", etc.) were proposed to optimize the parallel algorithm.\nResults indicate that without losing the computational accuracy, the speed-up\nratio of the GLCM computation of images with different resolutions by GPU by\nthe use of CUDA was 50 times faster than that of the GLCM computation by CPU,\nwhich manifested significantly improved performance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 10:00:08 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Hong", "Huichao", ""], ["Zheng", "Lixin", ""], ["Pan", "Shuwan", ""]]}, {"id": "1710.06384", "submitter": "David Holzm\\\"uller", "authors": "David Holzm\\\"uller", "title": "Efficient Neighbor-Finding on Space-Filling Curves", "comments": "This is a slightly modified version of my bachelor thesis in\n  mathematics. The corresponding code can be found at\n  https://github.com/dholzmueller/sfcpp . Changes in v2: Added e-mail address\n  and links to github project, fixed footnote hyperlinks. Changes in v3: Minor\n  changes, corrected statement of Corollary 4.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space-filling curves (SFC, also known as FASS-curves) are a useful tool in\nscientific computing and other areas of computer science to sequentialize\nmultidimensional grids in a cache-efficient and parallelization-friendly way\nfor storage in an array. Many algorithms, for example grid-based numerical PDE\nsolvers, have to access all neighbor cells of each grid cell during a grid\ntraversal. While the array indices of neighbors can be stored in a cell, they\nstill have to be computed for initialization or when the grid is adaptively\nrefined. A fast neighbor-finding algorithm can thus significantly improve the\nruntime of computations on multidimensional grids.\n  In this thesis, we show how neighbors on many regular grids ordered by\nspace-filling curves can be found in an average-case time complexity of $O(1)$.\nIn general, this assumes that the local orientation (i.e. a variable of a\ndescribing grammar) of the SFC inside the grid cell is known in advance, which\ncan be efficiently realized during traversals. Supported SFCs include Hilbert,\nPeano and Sierpinski curves in arbitrary dimensions. We assume that integer\narithmetic operations can be performed in $O(1)$, i.e. independent of the size\nof the integer. We do not deal with the case of adaptively refined grids here.\nHowever, it appears that a generalization of the algorithm to suitable adaptive\ngrids is possible. To formulate the neighbor-finding algorithm and prove its\ncorrectness and runtime properties, a modeling framework is introduced. This\nframework extends the idea of vertex-labeling to a description using grammars\nand matrices. With the sfcpp library, we provide a C++ implementation to render\nSFCs generated by such models and automatically compute all lookup tables\nneeded for the neighbor-finding algorithm. Furthermore, optimized\nneighbor-finding implementations for various SFCs are included for which we\nprovide runtime measurements.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 16:54:28 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 09:02:14 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 11:20:47 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Holzm\u00fcller", "David", ""]]}, {"id": "1710.06957", "submitter": "Shafinaz Islam", "authors": "Shafinaz Islam", "title": "Network Load Balancing Methods: Experimental Comparisons and Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Load balancing algorithms play critical roles in systems where the workload\nhas to be distributed across multiple resources, such as cores in\nmultiprocessor system, computers in distributed computing, and network links.\nIn this paper, we study and evaluate four load balancing methods: random, round\nrobin, shortest queue, and shortest queue with stale load information. We build\na simulation model and compare mean delay of the systems for the load balancing\nmethods. We also provide a method to improve shortest queue with stale load\ninformation load balancing. A performance analysis for the improvement is also\npresented in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 22:55:43 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Islam", "Shafinaz", ""]]}, {"id": "1710.07234", "submitter": "Long Gong", "authors": "Long Gong, Liang Liu, Sen Yang, Jun Xu, Yi Xie, Xinbing Wang", "title": "SERENADE: A Parallel Randomized Algorithm Suite for Crossbar Scheduling\n  in Input-Queued Switches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of today's high-speed switches and routers adopt an input-queued\ncrossbar switch architecture. Such a switch needs to compute a matching\n(crossbar schedule) between the input ports and output ports during each\nswitching cycle (time slot). A key research challenge in designing large (in\nnumber of input/output ports $N$) input-queued crossbar switches is to develop\ncrossbar scheduling algorithms that can compute \"high quality\" matchings --\ni.e., those that result in high switch throughput (ideally $100\\%$) and low\nqueueing delays for packets -- at line rates. SERENA is one such algorithm: it\noutputs excellent matching decisions that result in $100\\%$ switch throughput\nand reasonably good queueing delays. However, since SERENA is a centralized\nalgorithm with $O(N)$ computational complexity, it cannot support switches that\nboth are large and have a very high line rate per port. In this work, we\npropose SERENADE (SERENA, the Distributed Edition), a parallel iterative\nalgorithm that emulates SERENA in only $O(\\log N)$ iterations between input\nports and output ports, and hence has a time complexity of only $O(\\log N)$ per\nport. We prove that SERENADE can exactly emulate SERENA. We also propose an\nearly-stop version of SERENADE, called O-SERENADE, to only approximately\nemulate SERENA. Through extensive simulations, we show that O-SERENADE can\nachieve 100\\% throughput and that it has similar as or slightly better delay\nperformance than SERENA under various load conditions and traffic patterns.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 16:26:51 GMT"}, {"version": "v2", "created": "Tue, 26 Dec 2017 03:15:53 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 06:41:57 GMT"}, {"version": "v4", "created": "Mon, 18 Mar 2019 14:32:54 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Gong", "Long", ""], ["Liu", "Liang", ""], ["Yang", "Sen", ""], ["Xu", "Jun", ""], ["Xie", "Yi", ""], ["Wang", "Xinbing", ""]]}, {"id": "1710.08281", "submitter": "Ethel Ethel", "authors": "Obinna Ethelbert, Faraz Fatemi Moghaddam, Philipp Wieder, Ramin\n  Yahyapour", "title": "A JSON Token-Based Authentication and Access Management Schema for Cloud\n  SaaS Applications", "comments": "6 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.PF cs.SE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cloud computing is significantly reshaping the computing industry built\naround core concepts such as virtualization, processing power, connectivity and\nelasticity to store and share IT resources via a broad network. It has emerged\nas the key technology that unleashes the potency of Big Data, Internet of\nThings, Mobile and Web Applications, and other related technologies, but it\nalso comes with its challenges - such as governance, security, and privacy.\nThis paper is focused on the security and privacy challenges of cloud computing\nwith specific reference to user authentication and access management for cloud\nSaaS applications. The suggested model uses a framework that harnesses the\nstateless and secure nature of JWT for client authentication and session\nmanagement. Furthermore, authorized access to protected cloud SaaS resources\nhave been efficiently managed. Accordingly, a Policy Match Gate (PMG) component\nand a Policy Activity Monitor (PAM) component have been introduced. In\naddition, other subcomponents such as a Policy Validation Unit (PVU) and a\nPolicy Proxy DB (PPDB) have also been established for optimized service\ndelivery. A theoretical analysis of the proposed model portrays a system that\nis secure, lightweight and highly scalable for improved cloud resource security\nand management.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 14:01:29 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Ethelbert", "Obinna", ""], ["Moghaddam", "Faraz Fatemi", ""], ["Wieder", "Philipp", ""], ["Yahyapour", "Ramin", ""]]}, {"id": "1710.08315", "submitter": "Jinhua Tao", "authors": "Jinhua Tao, Zidong Du, Qi Guo, Huiying Lan, Lei Zhang, Shengyuan Zhou,\n  Lingjie Xu, Cong Liu, Haifeng Liu, Shan Tang, Allen Rush, Willian Chen,\n  Shaoli Liu, Yunji Chen, Tianshi Chen", "title": "BENCHIP: Benchmarking Intelligence Processors", "comments": "37pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing attention on deep learning has tremendously spurred the design\nof intelligence processing hardware. The variety of emerging intelligence\nprocessors requires standard benchmarks for fair comparison and system\noptimization (in both software and hardware). However, existing benchmarks are\nunsuitable for benchmarking intelligence processors due to their non-diversity\nand nonrepresentativeness. Also, the lack of a standard benchmarking\nmethodology further exacerbates this problem. In this paper, we propose\nBENCHIP, a benchmark suite and benchmarking methodology for intelligence\nprocessors. The benchmark suite in BENCHIP consists of two sets of benchmarks:\nmicrobenchmarks and macrobenchmarks. The microbenchmarks consist of\nsingle-layer networks. They are mainly designed for bottleneck analysis and\nsystem optimization. The macrobenchmarks contain state-of-the-art industrial\nnetworks, so as to offer a realistic comparison of different platforms. We also\npropose a standard benchmarking methodology built upon an industrial software\nstack and evaluation metrics that comprehensively reflect the various\ncharacteristics of the evaluated intelligence processors. BENCHIP is utilized\nfor evaluating various hardware platforms, including CPUs, GPUs, and\naccelerators. BENCHIP will be open-sourced soon.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 14:53:54 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 10:37:09 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Tao", "Jinhua", ""], ["Du", "Zidong", ""], ["Guo", "Qi", ""], ["Lan", "Huiying", ""], ["Zhang", "Lei", ""], ["Zhou", "Shengyuan", ""], ["Xu", "Lingjie", ""], ["Liu", "Cong", ""], ["Liu", "Haifeng", ""], ["Tang", "Shan", ""], ["Rush", "Allen", ""], ["Chen", "Willian", ""], ["Liu", "Shaoli", ""], ["Chen", "Yunji", ""], ["Chen", "Tianshi", ""]]}, {"id": "1710.08774", "submitter": "Jason Sewall", "authors": "Jason Sewall, Simon J. Pennycook", "title": "High-Performance Code Generation though Fusion and Vectorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique for automatically transforming kernel-based\ncomputations in disparate, nested loops into a fused, vectorized form that can\nreduce intermediate storage needs and lead to improved performance on\ncontemporary hardware.\n  We introduce representations for the abstract relationships and data\ndependencies of kernels in loop nests and algorithms for manipulating them into\nmore efficient form; we similarly introduce techniques for determining data\naccess patterns for stencil-like array accesses and show how this can be used\nto elide storage and improve vectorization.\n  We discuss our prototype implementation of these ideas---named HFAV---and its\nuse of a declarative, inference-based front-end to drive transformations, and\nwe present results for some prominent codes in HPC.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 13:51:36 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Sewall", "Jason", ""], ["Pennycook", "Simon J.", ""]]}, {"id": "1710.09001", "submitter": "Jingge Zhu", "authors": "Jingge Zhu, Ye Pu, Vipul Gupta, Claire Tomlin, Kannan Ramchandran", "title": "A Sequential Approximation Framework for Coded Distributed Optimization", "comments": "presented in 55th Annual Allerton Conference on Communication,\n  Control, and Computing, Oct. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the previous work of Lee et al. and Ferdinand et al. on coded\ncomputation, we propose a sequential approximation framework for solving\noptimization problems in a distributed manner. In a distributed computation\nsystem, latency caused by individual processors (\"stragglers\") usually causes a\nsignificant delay in the overall process. The proposed method is powered by a\nsequential computation scheme, which is designed specifically for systems with\nstragglers. This scheme has the desirable property that the user is guaranteed\nto receive useful (approximate) computation results whenever a processor\nfinishes its subtask, even in the presence of uncertain latency. In this paper,\nwe give a coding theorem for sequentially computing matrix-vector\nmultiplications, and the optimality of this coding scheme is also established.\nAs an application of the results, we demonstrate solving optimization problems\nusing a sequential approximation approach, which accelerates the algorithm in a\ndistributed system with stragglers.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 21:53:21 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Zhu", "Jingge", ""], ["Pu", "Ye", ""], ["Gupta", "Vipul", ""], ["Tomlin", "Claire", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1710.09506", "submitter": "Jorg Liebeherr", "authors": "Majid Raeis, Almut Burchard, Jorg Liebeherr", "title": "Analysis of the Leakage Queue: A Queueing Model for Energy Storage\n  Systems with Self-discharge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy storage is a crucial component of the smart grid, since it provides\nthe ability to buffer transient fluctuations of the energy supply from\nrenewable sources. Even without a load, energy storage systems experience a\nreduction of the stored energy through self-discharge. In some storage\ntechnologies, the rate of self-discharge can exceed 50% of the stored energy\nper day. In this paper, we investigate the self-discharge phenomenon in energy\nstorage using a queueing system model, which we refer to as leakage queue. When\nthe average net charge is positive, we discover that the leakage queue operates\nin one of two regimes: a leakage-dominated regime and a capacity-dominated\nregime. We find that in the leakage-dominated regime, the stored energy\nstabilizes at a point that is below the storage capacity. Under suitable\nindependence assumptions for energy supply and demand, the stored energy in\nthis regime closely follows a normal distribution. We present two methods for\ncomputing probabilities of underflow and overflow at a leakage queue. The\nmethods are validated in a numerical example where the energy supply resembles\na wind energy source.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 01:33:21 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Raeis", "Majid", ""], ["Burchard", "Almut", ""], ["Liebeherr", "Jorg", ""]]}, {"id": "1710.09797", "submitter": "Abishek Sankararaman", "authors": "Abishek Sankararaman, Fran\\c{c}ois Baccelli and Sergey Foss", "title": "Interference Queueing Networks on Grids", "comments": "Minor Spell Changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a countably infinite collection of interacting queues, with a queue\nlocated at each point of the $d$-dimensional integer grid, having independent\nPoisson arrivals, but dependent service rates. The service discipline is of the\nprocessor sharing type,with the service rate in each queue slowed down, when\nthe neighboring queues have a larger workload. The interactions are translation\ninvariant in space and is neither of the Jackson Networks type, nor of the\nmean-field type. Coupling and percolation techniques are first used to show\nthat this dynamics has well defined trajectories. Coupling from the past\ntechniques are then proposed to build its minimal stationary regime. The rate\nconservation principle of Palm calculus is then used to identify the stability\ncondition of this system, where the notion of stability is appropriately\ndefined for an infinite dimensional process. We show that the identified\ncondition is also necessary in certain special cases and conjecture it to be\ntrue in all cases. Remarkably, the rate conservation principle also provides a\nclosed form expression for the mean queue size. When the stability condition\nholds, this minimal solution is the unique translation invariant stationary\nregime. In addition, there exists a range of small initial conditions for which\nthe dynamics is attracted to the minimal regime. Nevertheless, there exists\nanother range of larger though finite initial conditions for which the dynamics\ndiverges, even though stability criterion holds.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 16:33:42 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 13:27:01 GMT"}, {"version": "v3", "created": "Sat, 23 Feb 2019 22:33:31 GMT"}, {"version": "v4", "created": "Sat, 9 Mar 2019 19:31:19 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Sankararaman", "Abishek", ""], ["Baccelli", "Fran\u00e7ois", ""], ["Foss", "Sergey", ""]]}, {"id": "1710.09995", "submitter": "Anthony Chronopoulos", "authors": "Yong-Xian Wang, Li-Lun Zhang, Wei Liu, Xing-Hua Cheng, Yu Zhuang,\n  Anthony T. Chronopoulos", "title": "Performance optimizations for scalable CFD applications on hybrid\n  CPU+MIC heterogeneous computing system with millions of cores", "comments": "12pages, 12 figures", "journal-ref": null, "doi": "10.1016/j.compfluid.2018.03.005", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For computational fluid dynamics (CFD) applications with a large number of\ngrid points/cells, parallel computing is a common efficient strategy to reduce\nthe computational time. How to achieve the best performance in the modern\nsupercomputer system, especially with heterogeneous computing resources such as\nhybrid CPU+GPU, or a CPU + Intel Xeon Phi (MIC) co-processors, is still a great\nchallenge.\n  An in-house parallel CFD code capable of simulating three dimensional\nstructured grid applications is developed and tested in this study. Several\nmethods of parallelization, performance optimization and code tuning both in\nthe CPU-only homogeneous system and in the heterogeneous system are proposed\nbased on identifying potential parallelism of applications, balancing the work\nload among all kinds of computing devices, tuning the multi-thread code toward\nbetter performance in intra-machine node with hundreds of CPU/MIC cores, and\noptimizing the communication among inter-nodes, inter-cores, and between CPUs\nand MICs.\n  Some benchmark cases from model and/or industrial CFD applications are tested\non the Tianhe-1A and Tianhe-2 supercomputer to evaluate the performance. Among\nthese CFD cases, the maximum number of grid cells reached 780 billion. The\ntuned solver successfully scales up to half of the entire Tianhe-2\nsupercomputer system with over 1.376 million of heterogeneous cores. The test\nresults and performance analysis are discussed in detail.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 06:06:47 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Wang", "Yong-Xian", ""], ["Zhang", "Li-Lun", ""], ["Liu", "Wei", ""], ["Cheng", "Xing-Hua", ""], ["Zhuang", "Yu", ""], ["Chronopoulos", "Anthony T.", ""]]}, {"id": "1710.10325", "submitter": "Kai Chen", "authors": "Kai Chen, Blesson Varghese, Peter Kilpatrick, Dimitrios S.\n  Nikolopoulos", "title": "Power Modelling for Heterogeneous Cloud-Edge Data Centers", "comments": "10 pages,10 figures,conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing power modelling research focuses not on the method used for\ndeveloping models but rather on the model itself. This paper aims to develop a\nmethod for deploying power models on emerging processors that will be used, for\nexample, in cloud-edge data centers. Our research first develops a hardware\ncounter selection method that appropriately selects counters most correlated to\npower on ARM and Intel processors. Then, we propose a two stage power model\nthat works across multiple architectures. The key results are: (i) the\nautomated hardware performance counter selection method achieves comparable\nselection to the manual selection methods reported in literature, and (ii) the\ntwo stage power model can predict dynamic power more accurately on both ARM and\nIntel processors when compared to classic power models.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 20:40:50 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Chen", "Kai", ""], ["Varghese", "Blesson", ""], ["Kilpatrick", "Peter", ""], ["Nikolopoulos", "Dimitrios S.", ""]]}, {"id": "1710.11471", "submitter": "Sarath Pattathil", "authors": "Sarath Pattathil, Vivek S. Borkar, Gaurav S. Kasbekar", "title": "Distributed Server Allocation for Content Delivery Networks", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dynamic formulation of file-sharing networks in terms of an\naverage cost Markov decision process with constraints. By analyzing a\nWhittle-like relaxation thereof, we propose an index policy in the spirit of\nWhittle and compare it by simulations with other natural heuristics.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 10:46:22 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 17:08:04 GMT"}, {"version": "v3", "created": "Wed, 22 Aug 2018 13:48:19 GMT"}, {"version": "v4", "created": "Sat, 9 Feb 2019 22:33:13 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Pattathil", "Sarath", ""], ["Borkar", "Vivek S.", ""], ["Kasbekar", "Gaurav S.", ""]]}]