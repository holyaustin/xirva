[{"id": "1804.00503", "submitter": "Nancy El Rachkidy", "authors": "Nancy El Rachkidy, Alexandre Guitton, Megumi Kaneko", "title": "Decoding Superposed LoRa Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-range low-power wireless communications, such as LoRa, are used in many\nIoT and environmental monitoring applications. They typically increase the\ncommunication range to several kilometers, at the cost of reducing the bitrate\nto a few bits per seconds. Collisions further reduce the performance of these\ncommunications. In this paper, we propose two algorithms to decode colliding\nsignals: one algorithm requires the transmitters to be slightly desynchronized,\nand the other requires the transmitters to be synchronized. To do so, we use\nthe timing information to match the correct symbols to the correct\ntransmitters. We show that our algorithms are able to significantly improve the\noverall throughput of LoRa.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 02:04:47 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Rachkidy", "Nancy El", ""], ["Guitton", "Alexandre", ""], ["Kaneko", "Megumi", ""]]}, {"id": "1804.01614", "submitter": "Jianbin Qin", "authors": "Jianbin Qin and Chuan Xiao", "title": "Pigeonring: A Principle for Faster Thresholded Similarity Search", "comments": "17 pages, 38 figures. Accepted and published in VLDB 2019. Please\n  cite the VLDB paper: @article{DBLP:journals/pvldb/QinX18, author = {Jianbin\n  Qin and Chuan Xiao}, title = {Pigeonring: {A} Principle for Faster\n  Thresholded Similarity Search}, journal = {{PVLDB}}, year = {2018}, }", "journal-ref": "Proceedings of the VLDB Endowment, vol12, 2018, 1, 28-42", "doi": "10.14778/3275536.3275539", "report-no": null, "categories": "cs.DB cs.DS cs.IR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pigeonhole principle states that if $n$ items are contained in $m$ boxes,\nthen at least one box has no more than $n / m$ items. It is utilized to solve\nmany data management problems, especially for thresholded similarity searches.\nDespite many pigeonhole principle-based solutions proposed in the last few\ndecades, the condition stated by the principle is weak. It only constrains the\nnumber of items in a single box. By organizing the boxes in a ring, we propose\na new principle, called the pigeonring principle, which constrains the number\nof items in multiple boxes and yields stronger conditions. To utilize the new\nprinciple, we focus on problems defined in the form of identifying data objects\nwhose similarities or distances to the query is constrained by a threshold.\nMany solutions to these problems utilize the pigeonhole principle to find\ncandidates that satisfy a filtering condition. By the new principle, stronger\nfiltering conditions can be established. We show that the pigeonhole principle\nis a special case of the new principle. This suggests that all the pigeonhole\nprinciple-based solutions are possible to be accelerated by the new principle.\nA universal filtering framework is introduced to encompass the solutions to\nthese problems based on the new principle. Besides, we discuss how to quickly\nfind candidates specified by the new principle. The implementation requires\nonly minor modifications on top of existing pigeonhole principle-based\nalgorithms. Experimental results on real datasets demonstrate the applicability\nof the new principle as well as the superior performance of the algorithms\nbased on the new principle.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 22:01:43 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 21:42:29 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 03:10:24 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Qin", "Jianbin", ""], ["Xiao", "Chuan", ""]]}, {"id": "1804.01783", "submitter": "C\\'eline Comte", "authors": "C\\'eline Comte", "title": "Dynamic Load Balancing with Tokens", "comments": null, "journal-ref": "2018 IFIP Networking Conference (IFIP Networking) and Workshops", "doi": "10.23919/IFIPNetworking.2018.8697018", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently exploiting the resources of data centers is a complex task that\nrequires efficient and reliable load balancing and resource allocation\nalgorithms. The former are in charge of assigning jobs to servers upon their\narrival in the system, while the latter are responsible for sharing server\nresources between their assigned jobs. These algorithms should take account of\nvarious constraints, such as data locality, that restrict the feasible job\nassignments. In this paper, we propose a token-based mechanism that efficiently\nbalances load between servers without requiring any knowledge on job arrival\nrates and server capacities. Assuming a balanced fair sharing of the server\nresources, we show that the resulting dynamic load balancing is insensitive to\nthe job size distribution. Its performance is compared to that obtained under\nthe best static load balancing and in an ideal system that would constantly\noptimize the resource utilization.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 11:16:56 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2018 18:08:16 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Comte", "C\u00e9line", ""]]}, {"id": "1804.01972", "submitter": "Daniel Byrne Jr", "authors": "Daniel Byrne", "title": "A Survey of Miss-Ratio Curve Construction Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Miss-ratio curve (MRC), or equivalently hit-ratio curve (HRC), construction\ntechniques have recently gathered the attention of many researchers. Recent\nadvancements have allowed for approximating these curves in constant time,\nallowing for online working-set-size (WSS) measurement. Techniques span the\nalgorithmic design paradigm from classic dynamic programming to artificial\nintelligence inspired techniques. Our survey produces broad classification of\nthe current techniques primarily based on \\emph{what} locality metric is being\nrecorded and \\emph{how} that metric is stored for processing.\n  Applications of theses curves span from dynamic cache partitioning in the\nprocessor, to improving block allocation at the operating system level. Our\nsurvey will give an overview of the historical, exact MRC construction methods,\nand compare them with the state-of-the-art methods present in today's\nliterature. In addition, we will show where there are still open areas of\nresearch and remain excited to see what this domain can produce with a strong\ntheoretical background.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 17:48:29 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Byrne", "Daniel", ""]]}, {"id": "1804.03179", "submitter": "Fatima Ezzahra Airod", "authors": "Fatima Ezzahra Airod, Houda Chafnaji, and Ahmed Tamtaoui", "title": "A Comparative Study of Full-Duplex Relaying Schemes for Low Latency\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various sectors are likely to carry a set of emerging applications while\ntargeting a reliable communication with low latency transmission. To address\nthis issue, upon a spectrally-efficient transmission, this paper investigates\nthe performance of a one full-dulpex (FD) relay system, and considers for that\npurpose, two basic relaying schemes, namely the symbol-by-symbol transmission,\ni.e., amplify-and-forward (AF) and the block-by-block transmission, i.e.,\nselective decode-and-forward (SDF). The conducted analysis presents an\nexhaustive comparison, covering both schemes, over two different transmission\nmodes, i.e., the non combining mode where the best link, direct or relay link\nis decoded and the signals combining mode, where direct and relay links are\ncombined at the receiver side. While targeting latency purpose as a necessity,\nsimulations show a refined results of performed comparisons, and reveal that AF\nrelaying scheme is more adapted to combining mode, whereas the SDF relaying\nscheme is more suitable for non combining mode.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 18:43:24 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Airod", "Fatima Ezzahra", ""], ["Chafnaji", "Houda", ""], ["Tamtaoui", "Ahmed", ""]]}, {"id": "1804.03256", "submitter": "Martin Wilhelm", "authors": "Martin Wilhelm", "title": "Restructuring expression dags for efficient parallelization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DC cs.DS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the field of robust geometric computation it is often necessary to make\nexact decisions based on inexact floating-point arithmetic. One common approach\nis to store the computation history in an arithmetic expression dag and to\nre-evaluate the expression with increasing precision until an exact decision\ncan be made. We show that exact-decisions number types based on expression dags\ncan be evaluated faster in practice through parallelization on multiple cores.\nWe compare the impact of several restructuring methods for the expression dag\non its running time in a parallel environment.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 22:08:13 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Wilhelm", "Martin", ""]]}, {"id": "1804.03512", "submitter": "Qin Tao", "authors": "Qin Tao, Caijun Zhong, Hai Lin, and Zhaoyang Zhang", "title": "Symbol Detection of Ambient Backscatter Systems with Manchester Coding", "comments": "accepted by IEEE transaction on wireless communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambient backscatter communication is a newly emerged paradigm, which utilizes\nthe ambient radio frequency (RF) signal as the carrier to reduce the system\nbattery requirement, and is regarded as a promising solution for enabling large\nscale deployment of future Internet of Things (IoT) networks. The key issue of\nambient backscatter communication systems is how to perform reliable detection.\nIn this paper, we propose novel encoding methods at the information tag, and\ndevise the corresponding symbol detection methods at the reader. In particular,\nManchester coding and differential Manchester coding are adopted at the\ninformation tag, and the corresponding semi-coherent Manchester (SeCoMC) and\nnon-coherent Manchester (NoCoMC) detectors are developed. In addition,\nanalytical bit error rate (BER) expressions are characterized for both\ndetectors assuming either complex Gaussian or unknown deterministic ambient\nsignal. Simulation results show that the BER performance of unknown\ndeterministic ambient signal is better, and the SeCoMC detector outperforms the\nNoCoMC detector. Finally, compared with the prior detectors for ambient\nbackscatter communications, the proposed detectors have the advantages of\nachieving superior BER performance with lower communication delay.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 09:53:01 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Tao", "Qin", ""], ["Zhong", "Caijun", ""], ["Lin", "Hai", ""], ["Zhang", "Zhaoyang", ""]]}, {"id": "1804.03548", "submitter": "Marcel von Maltitz", "authors": "Marcel von Maltitz and Georg Carle", "title": "A Performance and Resource Consumption Assessment of Secure Multiparty\n  Computation", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-00305-0_25", "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, secure multiparty computation (SMC) advanced from a\ntheoretical technique to a practically applicable technology. Several\nframeworks were proposed of which some are still actively developed.\n  We perform a first comprehensive study of performance characteristics of SMC\nprotocols using a promising implementation based on secret sharing, a common\nand state-of-the-art foundation. Therefor, we analyze its scalability with\nrespect to environmental parameters as the number of peers, network properties\n-- namely transmission rate, packet loss, network latency -- and\nparallelization of computations as parameters and execution time, CPU cycles,\nmemory consumption and amount of transmitted data as variables.\n  Our insights on the resource consumption show that such a solution is\npractically applicable in intranet environments and -- with limitations -- in\nInternet settings.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 14:08:00 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["von Maltitz", "Marcel", ""], ["Carle", "Georg", ""]]}, {"id": "1804.03562", "submitter": "Zhipeng Gui", "authors": "Fa Li, Zhipeng Gui, Huayi Wu, Jianya Gong, Yuan Wang, Siyu Tian,\n  Jiawen Zhang", "title": "Big enterprise registration data imputation: Supporting spatiotemporal\n  analysis of industries in China", "comments": "15 pages, 15 figures", "journal-ref": "https://www.sciencedirect.com/science/article/pii/S0198971517302971, 2018", "doi": "10.1016/j.compenvurbsys.2018.01.010", "report-no": null, "categories": "cs.CY cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Big, fine-grained enterprise registration data that includes time and\nlocation information enables us to quantitatively analyze, visualize, and\nunderstand the patterns of industries at multiple scales across time and space.\nHowever, data quality issues like incompleteness and ambiguity, hinder such\nanalysis and application. These issues become more challenging when the volume\nof data is immense and constantly growing. High Performance Computing (HPC)\nframeworks can tackle big data computational issues, but few studies have\nsystematically investigated imputation methods for enterprise registration data\nin this type of computing environment. In this paper, we propose a big data\nimputation workflow based on Apache Spark as well as a bare-metal computing\ncluster, to impute enterprise registration data. We integrated external data\nsources, employed Natural Language Processing (NLP), and compared several\nmachine-learning methods to address incompleteness and ambiguity problems found\nin enterprise registration data. Experimental results illustrate the\nfeasibility, efficiency, and scalability of the proposed HPC-based imputation\nframework, which also provides a reference for other big georeferenced text\ndata processing. Using these imputation results, we visualize and briefly\ndiscuss the spatiotemporal distribution of industries in China, demonstrating\nthe potential applications of such data when quality issues are resolved.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 06:36:25 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 00:48:15 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Li", "Fa", ""], ["Gui", "Zhipeng", ""], ["Wu", "Huayi", ""], ["Gong", "Jianya", ""], ["Wang", "Yuan", ""], ["Tian", "Siyu", ""], ["Zhang", "Jiawen", ""]]}, {"id": "1804.03564", "submitter": "Manu Kumar Gupta", "authors": "Manu K. Gupta, N. Hemachandra, J. Venkateswaran", "title": "Some parametrized dynamic priority policies for 2-class M/G/1 queues:\n  completeness and applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Completeness of a dynamic priority scheduling scheme is of fundamental\nimportance for the optimal control of queues in areas as diverse as computer\ncommunications, communication networks, supply chains and manufacturing\nsystems. Our first main contribution is to identify the mean waiting time\ncompleteness as a unifying aspect for four different dynamic priority\nscheduling schemes by proving their completeness and equivalence in 2-class\nM/G/1 queue. These dynamic priority schemes are earliest due date based, head\nof line priority jump, relative priority, and probabilistic priority.\n  In our second main contribution, we characterize the optimal scheduling\npolicies for the case studies in different domains by exploiting the\ncompleteness of above dynamic priority schemes. The major theme of second main\ncontribution is resource allocation/optimal control in revenue management\nproblems for contemporary systems such as cloud computing, high-performance\ncomputing, etc., where congestion is inherent. Using completeness and\ntheoretically tractable nature of relative priority policy, we study the impact\nof approximation in a fairly generic data network utility framework. We\nintroduce the notion of min-max fairness in multi-class queues and show that a\nsimple global FCFS policy is min-max fair. Next, we re-derive the celebrated\n$c/\\rho$ rule for 2-class M/G/1 queues by an elegant argument and also simplify\na complex joint pricing and scheduling problem for a wider class of scheduling\npolicies.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 14:37:26 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Gupta", "Manu K.", ""], ["Hemachandra", "N.", ""], ["Venkateswaran", "J.", ""]]}, {"id": "1804.03965", "submitter": "Fabrizio Maria Maggi", "authors": "Fredrik Milani and Fabrizio M. Maggi", "title": "A Comparative Evaluation of Log-Based Process Performance Analysis\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining has gained traction over the past decade and an impressive\nbody of research has resulted in the introduction of a variety of process\nmining approaches measuring process performance. Having this set of techniques\navailable, organizations might find it difficult to identify which approach is\nbest suited considering context, performance indicator, and data availability.\nIn light of this challenge, this paper aims at introducing a framework for\ncategorizing and selecting performance analysis approaches based on existing\nresearch. We start from a systematic literature review for identifying the\nexisting works discussing how to measure process performance based on\ninformation retrieved from event logs. Then, the proposed framework is built\nstarting from the information retrieved from these studies taking into\nconsideration different aspects of performance analysis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:04:02 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Milani", "Fredrik", ""], ["Maggi", "Fabrizio M.", ""]]}, {"id": "1804.04794", "submitter": "Behnam Dezfouli", "authors": "Behnam Dezfouli, Immanuel Amirtharaj, and Chia-Chi Li", "title": "EMPIOT: An Energy Measurement Platform for Wireless IoT Devices", "comments": null, "journal-ref": "Journal of Network and Computer Applications, Volume 121, 1\n  November 2018, Pages 135-148", "doi": null, "report-no": "TR-SIOTLAB-MARCH2018-EMPIOT", "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Profiling and minimizing the energy consumption of resource-constrained\ndevices is an essential step towards employing IoT in various application\ndomains. Due to the large size and high cost of commercial energy measurement\nplatforms, alternative solutions have been proposed by the research community.\nHowever, the three main shortcomings of existing tools are complexity, limited\nmeasurement range, and low accuracy. Specifically, these tools are not suitable\nfor the energy measurement of new IoT devices such as those supporting the\n802.11 technology. In this paper we propose EMPIOT, an accurate, low-cost, easy\nto build, and flexible power measurement platform. We present the hardware and\nsoftware components of this platform and study the effect of various design\nparameters on accuracy and overhead. In particular, we analyze the effects of\ndriver, bus speed, input voltage, and buffering mechanism on sampling rate,\nmeasurement accuracy and processing demand. These extensive experimental\nstudies enable us to configure the system in order to achieve its highest\nperformance. We also propose a novel calibration technique and report the\ncalibration parameters under various settings. Using five different IoT devices\nperforming four types of workloads, we evaluate the performance of EMPIOT\nagainst the ground truth obtained from a high-accuracy industrial-grade power\nmeasurement tool. Our results show that, for very low-power devices that\nutilize 802.15.4 wireless standard, the measurement error is less than 3.5%. In\naddition, for 802.11-based devices that generate short and high power spikes,\nthe error is less than 2.5%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 05:49:59 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2018 05:54:19 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Dezfouli", "Behnam", ""], ["Amirtharaj", "Immanuel", ""], ["Li", "Chia-Chi", ""]]}, {"id": "1804.05671", "submitter": "Christina Delimitrou", "authors": "Neeraj Kulkarni, Feng Qi, Christina Delimitrou", "title": "Pliant: Leveraging Approximation to Improve Datacenter Resource\n  Efficiency", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud multi-tenancy is typically constrained to a single interactive service\ncolocated with one or more batch, low-priority services, whose performance can\nbe sacrificed when deemed necessary. Approximate computing applications offer\nthe opportunity to enable tighter colocation among multiple applications whose\nperformance is important. We present Pliant, a lightweight cloud runtime that\nleverages the ability of approximate computing applications to tolerate some\nloss in their output quality to boost the utilization of shared servers. During\nperiods of high resource contention, Pliant employs incremental and\ninterference-aware approximation to reduce contention in shared resources, and\nprevent QoS violations for co-scheduled interactive, latency-critical services.\nWe evaluate Pliant across different interactive and approximate computing\napplications, and show that it preserves QoS for all co-scheduled workloads,\nwhile incurring a 2.1\\% loss in output quality, on average.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 17:54:46 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Kulkarni", "Neeraj", ""], ["Qi", "Feng", ""], ["Delimitrou", "Christina", ""]]}, {"id": "1804.06062", "submitter": "Alok Singh", "authors": "Alok Singh, Eric Stephan, Malachi Schram, Ilkay Altintas", "title": "Deep Learning on Operational Facility Data Related to Large-Scale\n  Distributed Area Scientific Workflows", "comments": null, "journal-ref": "2017 IEEE 13th International Conference on e-Science, 2017, pp.\n  586 to 591", "doi": "10.1109/eScience.2017.94", "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributed computing platforms provide a robust mechanism to perform\nlarge-scale computations by splitting the task and data among multiple\nlocations, possibly located thousands of miles apart geographically. Although\nsuch distribution of resources can lead to benefits, it also comes with its\nassociated problems such as rampant duplication of file transfers increasing\ncongestion, long job completion times, unexpected site crashing, suboptimal\ndata transfer rates, unpredictable reliability in a time range, and suboptimal\nusage of storage elements. In addition, each sub-system becomes a potential\nfailure node that can trigger system wide disruptions. In this vision paper, we\noutline our approach to leveraging Deep Learning algorithms to discover\nsolutions to unique problems that arise in a system with computational\ninfrastructure that is spread over a wide area. The presented vision, motivated\nby a real scientific use case from Belle II experiments, is to develop\nmultilayer neural networks to tackle forecasting, anomaly detection and\noptimization challenges in a complex and distributed data movement environment.\nThrough this vision based on Deep Learning principles, we aim to achieve\nreduced congestion events, faster file transfer rates, and enhanced site\nreliability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 06:29:56 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 19:43:16 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Singh", "Alok", ""], ["Stephan", "Eric", ""], ["Schram", "Malachi", ""], ["Altintas", "Ilkay", ""]]}, {"id": "1804.06139", "submitter": "Yoshiaki Inoue", "authors": "Yoshiaki Inoue, Hiroyuki Masuyama, Tetsuya Takine, and Toshiyuki\n  Tanaka", "title": "A General Formula for the Stationary Distribution of the Age of\n  Information and Its Application to Single-Server Queues", "comments": "Submitted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2019.2938171", "report-no": null, "categories": "cs.PF cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the stationary distribution of the age of information\n(AoI) in information update systems. We first derive a general formula for the\nstationary distribution of the AoI, which holds for a wide class of information\nupdate systems. The formula indicates that the stationary distribution of the\nAoI is given in terms of the stationary distributions of the system delay and\nthe peak AoI. To demonstrate its applicability and usefulness, we analyze the\nAoI in single-server queues with four different service disciplines: first-come\nfirst-served (FCFS), preemptive last-come first-served (LCFS), and two variants\nof non-preemptive LCFS service disciplines. For the FCFS and the preemptive\nLCFS service disciplines, the GI/GI/1, M/GI/1, and GI/M/1 queues are\nconsidered, and for the non-preemptive LCFS service disciplines, the M/GI/1 and\nGI/M/1 queues are considered. With these results, we further show comparison\nresults for the mean AoI's in the M/GI/1 and GI/M/1 queues under those service\ndisciplines.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 09:52:54 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 23:19:55 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Inoue", "Yoshiaki", ""], ["Masuyama", "Hiroyuki", ""], ["Takine", "Tetsuya", ""], ["Tanaka", "Toshiyuki", ""]]}, {"id": "1804.06489", "submitter": "Mehmet Aktas", "authors": "Mehmet Fatih Aktas, Elie Najm, Emina Soljanin", "title": "Simplex Queues for Hot-Data Download", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud storage systems, hot data is usually replicated over multiple nodes\nin order to accommodate simultaneous access by multiple users as well as\nincrease the fault tolerance of the system. Recent cloud storage research has\nproposed using availability codes, which is a special class of erasure codes,\nas a more storage efficient way to store hot data. These codes enable data\nrecovery from multiple, small disjoint groups of servers. The number of the\nrecovery groups is referred to as the availability and the size of each group\nas the locality of the code. Until now, we have very limited knowledge on how\ncode locality and availability affect data access time. Data download from\nthese systems involves multiple fork-join queues operating in-parallel, making\nthe analysis of access time a very challenging problem. In this paper, we\npresent an approximate analysis of data access time in storage systems that\nemploy simplex codes, which are an important and in certain sense optimal class\nof availability codes. We consider and compare three strategies in assigning\ndownload requests to servers; first one aggressively exploits the storage\navailability for faster download, second one implements only load balancing,\nand the last one employs storage availability only for hot data download\nwithout incurring any negative impact on the cold data download.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 22:26:48 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Aktas", "Mehmet Fatih", ""], ["Najm", "Elie", ""], ["Soljanin", "Emina", ""]]}, {"id": "1804.06564", "submitter": "Behnam Dezfouli", "authors": "Rami Akeela, and Behnam Dezfouli", "title": "Software-defined Radios: Architecture, State-of-the-art, and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR-SIOTLAB-MARCH2018-SDRSURV", "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined Radio (SDR) is a programmable transceiver with the\ncapability of operating various wireless communication protocols without the\nneed to change or update the hardware. Progress in the SDR field has led to the\nescalation of protocol development and a wide spectrum of applications, with\nmore emphasis on programmability, flexibility, portability, and energy\nefficiency, in cellular, WiFi, and M2M communication. Consequently, SDR has\nearned a lot of attention and is of great significance to both academia and\nindustry. SDR designers intend to simplify the realization of communication\nprotocols while enabling researchers to experiment with prototypes on deployed\nnetworks. This paper is a survey of the state-of-the-art SDR platforms in the\ncontext of wireless communication protocols. We offer an overview of SDR\narchitecture and its basic components, then discuss the significant design\ntrends and development tools. In addition, we highlight key contrasts between\nSDR architectures with regards to energy, computing power, and area, based on a\nset of metrics. We also review existing SDR platforms and present an analytical\ncomparison as a guide to developers. Finally, we recognize a few of the related\nresearch topics and summarize potential solutions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 05:55:05 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Akeela", "Rami", ""], ["Dezfouli", "Behnam", ""]]}, {"id": "1804.06826", "submitter": "Daniele Scarpazza", "authors": "Zhe Jia, Marco Maggioni, Benjamin Staiger, Daniele P. Scarpazza", "title": "Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking", "comments": "Technical report. First Edition. April 18th, 2018. 66 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every year, novel NVIDIA GPU designs are introduced. This rapid architectural\nand technological progression, coupled with a reluctance by manufacturers to\ndisclose low-level details, makes it difficult for even the most proficient GPU\nsoftware designers to remain up-to-date with the technological advances at a\nmicroarchitectural level. To address this dearth of public,\nmicroarchitectural-level information on the novel NVIDIA GPUs, independent\nresearchers have resorted to microbenchmarks-based dissection and discovery.\nThis has led to a prolific line of publications that shed light on instruction\nencoding, and memory hierarchy's geometry and features at each level. Namely,\nresearch that describes the performance and behavior of the Kepler, Maxwell and\nPascal architectures. In this technical report, we continue this line of\nresearch by presenting the microarchitectural details of the NVIDIA Volta\narchitecture, discovered through microbenchmarks and instruction set\ndisassembly. Additionally, we compare quantitatively our Volta findings against\nits predecessors, Kepler, Maxwell and Pascal.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 17:25:13 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Jia", "Zhe", ""], ["Maggioni", "Marco", ""], ["Staiger", "Benjamin", ""], ["Scarpazza", "Daniele P.", ""]]}, {"id": "1804.07571", "submitter": "Ludwig Dierks", "authors": "Ludwig Dierks, Ian A. Kash, Sven Seuken", "title": "On the cluster admission problem for cloud computing", "comments": "This paper is a significantly extended version of work that was\n  published as a 6-page extended abstract in the proceedings of the 14th\n  Workshop on the Economics of Networks, Systems and Computation (NetEcon'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing providers face the problem of matching heterogeneous customer\nworkloads to resources that will serve them. This is particularly challenging\nif customers, who are already running a job on a cluster, scale their resource\nusage up and down over time. The provider therefore has to continuously decide\nwhether she can add additional workloads to a given cluster or if doing so\nwould impact existing workloads' ability to scale. Currently, this is often\ndone using simple threshold policies to reserve large parts of each cluster,\nwhich leads to low efficiency (i.e., low average utilization of the cluster).\nWe propose more sophisticated policies for controlling admission to a cluster\nand demonstrate that they significantly increase cluster utilization. We first\nintroduce the cluster admission problem and formalize it as a constrained\nPartially Observable Markov Decision Process (POMDP). As it is infeasible to\nsolve the POMDP optimally, we then systematically design admission policies\nthat estimate moments of each workload's distribution of future resource usage.\nVia extensive simulations grounded in a trace from Microsoft Azure, we show\nthat our admission policies lead to a substantial improvement over the simple\nthreshold policy. We then show that substantial further gains are possible if\nhigh-quality information is available about arriving workloads. Based on this,\nwe propose an information elicitation approach to incentivize users to provide\nthis information and simulate its effects.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 12:11:26 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 17:50:59 GMT"}, {"version": "v3", "created": "Fri, 14 Sep 2018 10:05:07 GMT"}, {"version": "v4", "created": "Mon, 3 Dec 2018 12:24:59 GMT"}, {"version": "v5", "created": "Tue, 4 Dec 2018 14:29:08 GMT"}, {"version": "v6", "created": "Fri, 21 Jun 2019 09:34:47 GMT"}, {"version": "v7", "created": "Mon, 6 Apr 2020 16:04:41 GMT"}, {"version": "v8", "created": "Fri, 14 Aug 2020 16:04:35 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Dierks", "Ludwig", ""], ["Kash", "Ian A.", ""], ["Seuken", "Sven", ""]]}, {"id": "1804.08040", "submitter": "Jorg Liebeherr", "authors": "Jorg Liebeherr", "title": "A Fluid-Flow Interpretation of SCED Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a fluid-flow interpretation of Service Curve Earliest Deadline\nFirst (SCED) scheduling simplifies deadline derivations for this scheduler. By\nexploiting the recently reported isomorphism between min-plus and max-plus\nnetwork calculus, and expressing deadlines in a max-plus algebra, deadline\ncomputations no longer require pseudo-inverse computations. SCED deadlines are\nprovided for general convex or concave piecewise linear service curves.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 22:45:21 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 14:08:25 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Liebeherr", "Jorg", ""]]}, {"id": "1804.08121", "submitter": "Mahdi Azari", "authors": "Mohammad Mahdi Azari, Fernando Rosas, Sofie Pollin", "title": "Cellular Connectivity for UAVs: Network Modeling, Performance Analysis\n  and Design Guidelines", "comments": "Related Works: 1) arXiv:1710.11404 2) arXiv:1710.03103 3)\n  arXiv:1708.06598", "journal-ref": null, "doi": "10.1109/TWC.2019.2910112", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing use of aerial user equipments (UEs) in various applications\nrequires ubiquitous and reliable connectivity for safe control and data\nexchange between these devices and ground stations. Key questions that need to\nbe addressed when planning the deployment of aerial UEs are whether the\ncellular network is a suitable candidate for enabling such connectivity, and\nhow the inclusion of aerial UEs might impact the overall network efficiency.\nThis paper provides an in-depth analysis of user and network level performance\nof a cellular network that serves both unmanned aerial vehicles (UAVs) and\nground users in the downlink. Our results show that the favorable propagation\nconditions that UAVs enjoy due to their height often backfire on them, as the\nincreased co-channel interference received from neighboring ground BSs is not\ncompensated by the improved signal strength. When compared with a ground user\nin an urban area, our analysis shows that a UAV flying at 100 meters can\nexperience a throughput decrease of a factor 10 and a coverage drop from 76% to\n30%. Motivated by these findings, we develop UAV and network based solutions to\nenable an adequate integration of UAVs into cellular networks. In particular,\nwe show that an optimal tilting of the UAV antenna can increase their coverage\nand throughput from 23% to 89% and from 3.5 b/s/Hz to 5.8 b/s/Hz, respectively,\noutperforming ground UEs. Furthermore, our findings reveal that depending on\nUAV altitude, the aerial user performance can scale with respect to the network\ndensity better than that of a ground user. Finally, our results show that\nnetwork densification and the use of micro cells limit UAV performance. While\nUAV usage has the potential to increase area spectral efficiency (ASE) of\ncellular networks with moderate number of cells, they might hamper the\ndevelopment of future ultra dense networks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 15:16:06 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Azari", "Mohammad Mahdi", ""], ["Rosas", "Fernando", ""], ["Pollin", "Sofie", ""]]}, {"id": "1804.08378", "submitter": "Nicolas Weber", "authors": "Nicolas Weber, Florian Schmidt, Mathias Niepert, Felipe Huici", "title": "BrainSlug: Transparent Acceleration of Deep Learning Through Depth-First\n  Parallelism", "comments": "Technical Report, 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CV cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network frameworks such as PyTorch and TensorFlow are the workhorses\nof numerous machine learning applications ranging from object recognition to\nmachine translation. While these frameworks are versatile and straightforward\nto use, the training of and inference in deep neural networks is resource\n(energy, compute, and memory) intensive. In contrast to recent works focusing\non algorithmic enhancements, we introduce BrainSlug, a framework that\ntransparently accelerates neural network workloads by changing the default\nlayer-by-layer processing to a depth-first approach, reducing the amount of\ndata required by the computations and thus improving the performance of the\navailable hardware caches. BrainSlug achieves performance improvements of up to\n41.1% on CPUs and 35.7% on GPUs. These optimizations come at zero cost to the\nuser as they do not require hardware changes and only need tiny adjustments to\nthe software.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 12:49:04 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Weber", "Nicolas", ""], ["Schmidt", "Florian", ""], ["Niepert", "Mathias", ""], ["Huici", "Felipe", ""]]}, {"id": "1804.08407", "submitter": "EPTCS", "authors": "Khalid Halba (National Institute of Standards and Technology), Charif\n  Mahmoudi (National Institute of Standards and Technology), Edward Griffor\n  (National Institute of Standards and Technology)", "title": "Robust Safety for Autonomous Vehicles through Reconfigurable Networking", "comments": "In Proceedings SCAV 2018, arXiv:1804.03406", "journal-ref": "EPTCS 269, 2018, pp. 48-58", "doi": "10.4204/EPTCS.269.5", "report-no": null, "categories": "cs.NI cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles bring the promise of enhancing the consumer experience in\nterms of comfort and convenience and, in particular, the safety of the\nautonomous vehicle. Safety functions in autonomous vehicles such as Automatic\nEmergency Braking and Lane Centering Assist rely on computation, information\nsharing, and the timely actuation of the safety functions. One opportunity to\nachieve robust autonomous vehicle safety is by enhancing the robustness of\nin-vehicle networking architectures that support built-in resiliency\nmechanisms. Software Defined Networking (SDN) is an advanced networking\nparadigm that allows fine-grained manipulation of routing tables and routing\nengines and the implementation of complex features such as failover, which is a\nmechanism of protecting in-vehicle networks from failure, and in which a\nstandby link automatically takes over once the main link fails. In this paper,\nwe leverage SDN network programmability features to enable resiliency in the\nautonomous vehicle realm. We demonstrate that a Software Defined In-Vehicle\nNetworking (SDIVN) does not add overhead compared to Legacy In-Vehicle Networks\n(LIVNs) under non-failure conditions and we highlight its superiority in the\ncase of a link failure and its timely delivery of messages. We verify the\nproposed architectures benefits using a simulation environment that we have\ndeveloped and we validate our design choices through testing and simulations\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 06:53:49 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Halba", "Khalid", "", "National Institute of Standards and Technology"], ["Mahmoudi", "Charif", "", "National Institute of Standards and Technology"], ["Griffor", "Edward", "", "National Institute of Standards and Technology"]]}, {"id": "1804.08933", "submitter": "Pasquale Grippa", "authors": "Pasquale Grippa, Udo Schilcher and Christian Bettstetter", "title": "On Access Control in Cabin-Based Transport Systems", "comments": null, "journal-ref": null, "doi": "10.1109/TITS.2018.2864551", "report-no": null, "categories": "cs.SY cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a boarding solution for a transport system in which the number of\npassengers allowed to enter a transport cabin is automatically controlled.\nExpressions charac- terizing the stochastic properties of the passenger queue\nlength, waiting time, and cabin capacity are derived using queuing theory for a\ntransport line with deterministic arrivals of cabins and Poisson arrivals of\npassengers. Expected cabin capacity and stability threshold for each station\nare derived for a general passenger arrival distribution. Results show that a\nsignificant reduction of the waiting time at a given station is only possible\nat the cost of making the stability of one of the preceding stations worse than\nthat of the given station. Experimental studies with real passenger arrivals\nare needed to draw firm conclusions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 09:49:57 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Grippa", "Pasquale", ""], ["Schilcher", "Udo", ""], ["Bettstetter", "Christian", ""]]}, {"id": "1804.10563", "submitter": "Zhengyu Yang", "authors": "Zhengyu Yang, Danlin Jia, Stratis Ioannidis, Ningfang Mi, Bo Sheng", "title": "Intermediate Data Caching Optimization for Multi-Stage and Parallel Big\n  Data Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data and cloud computing, large amounts of data are\ngenerated from user applications and need to be processed in the datacenter.\nData-parallel computing frameworks, such as Apache Spark, are widely used to\nperform such data processing at scale. Specifically, Spark leverages\ndistributed memory to cache the intermediate results, represented as Resilient\nDistributed Datasets (RDDs). This gives Spark an advantage over other parallel\nframeworks for implementations of iterative machine learning and data mining\nalgorithms, by avoiding repeated computation or hard disk accesses to retrieve\nRDDs. By default, caching decisions are left at the programmer's discretion,\nand the LRU policy is used for evicting RDDs when the cache is full. However,\nwhen the objective is to minimize total work, LRU is woefully inadequate,\nleading to arbitrarily suboptimal caching decisions. In this paper, we design\nan algorithm for multi-stage big data processing platforms to adaptively\ndetermine and cache the most valuable intermediate datasets that can be reused\nin the future. Our solution automates the decision of which RDDs to cache: this\namounts to identifying nodes in a direct acyclic graph (DAG) representing\ncomputations whose outputs should persist in the memory. Our experiment results\nshow that our proposed cache optimization solution can improve the performance\nof machine learning applications on Spark decreasing the total work to\nrecompute RDDs by 12%.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 15:40:05 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 19:33:24 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Yang", "Zhengyu", ""], ["Jia", "Danlin", ""], ["Ioannidis", "Stratis", ""], ["Mi", "Ningfang", ""], ["Sheng", "Bo", ""]]}, {"id": "1804.10590", "submitter": "Mahadesh Panju", "authors": "Mahadesh Panju, Ramkumar Raghu, Vinod Sharma and Rajesh Ramachandran", "title": "Queuing Theoretic Models for Multicast and Coded-Caching in Downlink\n  Wireless Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a server connected to $L$ users over a shared finite capacity\nlink. Each user is equipped with a cache. File requests at the users are\ngenerated as independent Poisson processes according to a popularity profile\nfrom a library of $M$ files. The server has access to all the files in the\nlibrary. Users can store parts of the files or full files from the library in\ntheir local caches. The server should send missing parts of the files requested\nby the users. The server attempts to fulfill the pending requests with minimal\ntransmissions exploiting multicasting and coding opportunities among the\npending requests. We study the performance of this system in terms of queuing\ndelays for the naive multicasting and several coded multicasting schemes\nproposed in the literature. We also provide approximate expressions for the\nmean queuing delay for these models and establish their effectiveness with\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 16:59:02 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Panju", "Mahadesh", ""], ["Raghu", "Ramkumar", ""], ["Sharma", "Vinod", ""], ["Ramachandran", "Rajesh", ""]]}, {"id": "1804.10694", "submitter": "R. Baghdadi", "authors": "Riyadh Baghdadi, Jessica Ray, Malek Ben Romdhane, Emanuele Del Sozzo,\n  Abdurrahman Akkas, Yunming Zhang, Patricia Suriana, Shoaib Kamil, Saman\n  Amarasinghe", "title": "Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.00419", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.MS cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Tiramisu, a polyhedral framework designed to generate\nhigh performance code for multiple platforms including multicores, GPUs, and\ndistributed machines. Tiramisu introduces a scheduling language with novel\nextensions to explicitly manage the complexities that arise when targeting\nthese systems. The framework is designed for the areas of image processing,\nstencils, linear algebra and deep learning. Tiramisu has two main features: it\nrelies on a flexible representation based on the polyhedral model and it has a\nrich scheduling language allowing fine-grained control of optimizations.\nTiramisu uses a four-level intermediate representation that allows full\nseparation between the algorithms, loop transformations, data layouts, and\ncommunication. This separation simplifies targeting multiple hardware\narchitectures with the same algorithm. We evaluate Tiramisu by writing a set of\nimage processing, deep learning, and linear algebra benchmarks and compare them\nwith state-of-the-art compilers and hand-tuned libraries. We show that Tiramisu\nmatches or outperforms existing compilers and libraries on different hardware\narchitectures, including multicore CPUs, GPUs, and distributed machines.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 21:28:44 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 19:58:57 GMT"}, {"version": "v3", "created": "Wed, 26 Sep 2018 21:24:44 GMT"}, {"version": "v4", "created": "Tue, 18 Dec 2018 02:41:00 GMT"}, {"version": "v5", "created": "Thu, 20 Dec 2018 16:25:40 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Baghdadi", "Riyadh", ""], ["Ray", "Jessica", ""], ["Romdhane", "Malek Ben", ""], ["Del Sozzo", "Emanuele", ""], ["Akkas", "Abdurrahman", ""], ["Zhang", "Yunming", ""], ["Suriana", "Patricia", ""], ["Kamil", "Shoaib", ""], ["Amarasinghe", "Saman", ""]]}, {"id": "1804.10973", "submitter": "Yuming Jiang", "authors": "Yuming Jiang", "title": "A Basic Result on the Superposition of Arrival Processes in\n  Deterministic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-Sensitive Networking (TSN) and Deterministic Networking (DetNet) are\nemerging standards to enable deterministic, delay-critical communication in\nsuch networks. This naturally (re-)calls attention to the network calculus\ntheory (NC), since a rich set of results for delay guarantee analysis have\nalready been developed there. One could anticipate an immediate adoption of\nthose existing network calculus results to TSN and DetNet. However, the\nfundamental difference between the traffic specification adopted in TSN and\nDetNet and those traffic models in NC makes this difficult, let alone that\nthere is a long-standing open challenge in NC. To address them, this paper\nconsiders an arrival time function based max-plus NC traffic model. In\nparticular, for the former, the mapping between the TSN / DetNet and the NC\ntraffic model is proved. For the latter, the superposition property of the\narrival time function based NC traffic model is found and proved. Appealingly,\nthe proved superposition property shows a clear analogy with that of a\nwell-known counterpart traffic model in NC. These results help make an\nimportant step towards the development of a system theory for delay guarantee\nanalysis of TSN / DetNet networks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 18:22:13 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 14:37:35 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Jiang", "Yuming", ""]]}, {"id": "1804.11115", "submitter": "Ali Mohammed", "authors": "Ali Mohammed, Ahmed Eleliemy, Florina M. Ciorba, Franziska Kasielke,\n  Ioana Banicescu", "title": "Experimental Verification and Analysis of Dynamic Loop Scheduling in\n  Scientific Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific applications are often irregular and characterized by large\ncomputationally-intensive parallel loops. Dynamic loop scheduling (DLS)\ntechniques improve the performance of computationally-intensive scientific\napplications via load balancing of their execution on high-performance\ncomputing (HPC) systems. Identifying the most suitable choices of data\ndistribution strategies, system sizes, and DLS techniques which improve the\nperformance of a given application, requires intensive assessment and a large\nnumber of exploratory native experiments (using real applications on real\nsystems), which may not always be feasible or practical due to associated time\nand costs. In such cases, simulative experiments are more appropriate for\nstudying the performance of applications. This motivates the question of How\nrealistic are the simulations of executions of scientific applications using\nDLS on HPC platforms? In the present work, a methodology is devised to answer\nthis question. It involves the experimental verification and analysis of the\nperformance of DLS in scientific applications. The proposed methodology is\nemployed for a computer vision application executing using four DLS techniques\non two different HPC plat- forms, both via native and simulative experiments.\nThe evaluation and analysis of the native and simulative results indicate that\nthe accuracy of the simulative experiments is strongly influenced by the\napproach used to extract the computational effort of the application (FLOP- or\ntime-based), the choice of application model representation into simulation\n(data or task parallel), and the available HPC subsystem models in the\nsimulator (multi-core CPUs, memory hierarchy, and network topology). The\nminimum and the maximum percent errors achieved between the native and the\nsimulative experiments are 0.95% and 8.03%, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 10:53:10 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Mohammed", "Ali", ""], ["Eleliemy", "Ahmed", ""], ["Ciorba", "Florina M.", ""], ["Kasielke", "Franziska", ""], ["Banicescu", "Ioana", ""]]}]