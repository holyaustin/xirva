[{"id": "1112.0442", "submitter": "Tan Lu", "authors": "Tan Lu and Minghua Chen (Department of Information Engineering, The\n  Chinese University of Hong Kong)", "title": "Simple and Effective Dynamic Provisioning for Power-Proportional Data\n  Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy consumption represents a significant cost in data center operation. A\nlarge fraction of the energy, however, is used to power idle servers when the\nworkload is low. Dynamic provisioning techniques aim at saving this portion of\nthe energy, by turning off unnecessary servers. In this paper, we explore how\nmuch performance gain can knowing future workload information brings to dynamic\nprovisioning. In particular, we study the dynamic provisioning problem under\nthe cost model that a running server consumes a fixed amount energy per unit\ntime, and develop online solutions with and without future workload information\navailable. We first reveal an elegant structure of the off-line dynamic\nprovisioning problem, which allows us to characterize and achieve the optimal\nsolution in a {}\"divide-and-conquer\" manner. We then exploit this insight to\ndesign three online algorithms with competitive ratios $2-\\alpha$,\n$(e-\\alpha)/(e-1)\\approx1.58-\\alpha/(e-1)$ and $e/(e-1+\\alpha)$, respectively,\nwhere $0\\leq\\alpha\\leq1$ is the fraction of a critical window in which future\nworkload information is available. A fundamental observation is that\n\\emph{future workload information beyond the critical window will not}\n\\emph{improve dynamic provisioning performance}. Our algorithms are\ndecentralized and are simple to implement. We demonstrate their effectiveness\nin simulations using real-world traces. We also compare their performance with\nstate-of-the-art solutions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2011 12:17:22 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2012 09:15:13 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Lu", "Tan", "", "Department of Information Engineering, The\n  Chinese University of Hong Kong"], ["Chen", "Minghua", "", "Department of Information Engineering, The\n  Chinese University of Hong Kong"]]}, {"id": "1112.0850", "submitter": "Johannes Habich", "authors": "Johannes Habich and Christian Feichtinger and Harald K\\\"ostler and\n  Georg Hager and Gerhard Wellein", "title": "Performance engineering for the Lattice Boltzmann method on GPGPUs:\n  Architectural requirements and performance results", "comments": "10 pages, 7 figures, 4 tables, preprint submitted to Computers and\n  Fluids journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs offer several times the floating point performance and memory bandwidth\nof current standard two socket CPU servers, e.g. NVIDIA C2070 vs. Intel Xeon\nWestmere X5650. The lattice Boltzmann method has been established as a flow\nsolver in recent years and was one of the first flow solvers to be successfully\nported and that performs well on GPUs. We demonstrate advanced optimization\nstrategies for a D3Q19 lattice Boltzmann based incompressible flow solver for\nGPGPUs and CPUs based on NVIDIA CUDA and OpenCL. Since the implemented\nalgorithm is limited by memory bandwidth, we concentrate on improving memory\naccess. Basic data layout issues for optimal data access are explained and\ndiscussed. Furthermore, the algorithmic steps are rearranged to improve\nscattered access of the GPU memory. The importance of occupancy is discussed as\nwell as optimization strategies to improve overall concurrency. We arrive at a\nwell-optimized GPU kernel, which is integrated into a larger framework that can\nhandle single phase fluid flow simulations as well as particle-laden flows. Our\n3D LBM GPU implementation reaches up to 650 MLUPS in single precision and 290\nMLUPS in double precision on an NVIDIA Tesla C2070.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 07:06:49 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Habich", "Johannes", ""], ["Feichtinger", "Christian", ""], ["K\u00f6stler", "Harald", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1112.1041", "submitter": "Stefan Kiefer", "authors": "Tom\\'a\\v{s} Br\\'azdil and Stefan Kiefer", "title": "Stabilization of Branching Queueing Networks", "comments": "technical report for a STACS'12 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Queueing networks are gaining attraction for the performance analysis of\nparallel computer systems. A Jackson network is a set of interconnected\nservers, where the completion of a job at server i may result in the creation\nof a new job for server j. We propose to extend Jackson networks by \"branching\"\nand by \"control\" features. Both extensions are new and substantially expand the\nmodelling power of Jackson networks. On the other hand, the extensions raise\ncomputational questions, particularly concerning the stability of the networks,\ni.e, the ergodicity of the underlying Markov chain. We show for our extended\nmodel that it is decidable in polynomial time if there exists a controller that\nachieves stability. Moreover, if such a controller exists, one can efficiently\ncompute a static randomized controller which stabilizes the network in a very\nstrong sense; in particular, all moments of the queue sizes are finite.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 19:57:44 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Kiefer", "Stefan", ""]]}, {"id": "1112.2046", "submitter": "Purvang Dalal", "authors": "Purvang Dalal, Nikhil Kothari and K. S. Dasgupta", "title": "Improving TCP Performance over Wireless Network with Frequent\n  Disconnections", "comments": "16 Pages, 11 Figures; International Journal of Computer Networks &\n  Communications (IJCNC) Vol.3, No.6, November 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presented in this paper is the solution to the problem that arises when the\nTCP/IP protocol suite is used to provide Internet connectivity through mobile\nterminals over emerging 802.11 wireless links. Taking into consideration the\nstrong drive towards wireless Internet access through mobile terminals, the\nproblem of frequent disconnections causing serial timeouts is examined and\nanalyzed, with the help of extensive simulations. After a detailed review of\nwireless link loss recovery mechanism and identification of related problems, a\nnew scheme with modifications at link layer and transport layer is proposed.\nThe proposed modifications which depend on interaction between two layers (i)\nreduce the idle time before transmission at TCP by preventing timeout\noccurrences and (ii) decouple the congestion control from recovery of the\nlosses due to link failure. Results of simulation based experiments demonstrate\nconsiderable performance improvement with the proposed modifications over the\nconventional TCP, when a wireless sender is experiencing frequent link\nfailures.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 08:36:34 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Dalal", "Purvang", ""], ["Kothari", "Nikhil", ""], ["Dasgupta", "K. S.", ""]]}, {"id": "1112.2822", "submitter": "Jing Xie Miss", "authors": "Jing Xie, Yuming Jiang and Min Xie", "title": "A Temporal Approach to Stochastic Network Calculus", "comments": "45 pages. An early version of this paper has been presented at 17th\n  Annual Meeting of the IEEE/ACM International Symposium on Modelling, Analysis\n  and Simulation of Computer and Telecommunication Systems. This version has\n  been submitted to a journal and is waiting for being reviewed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic network calculus is a newly developed theory for stochastic\nservice guarantee analysis of computer networks. In the current stochastic\nnetwork calculus literature, its fundamental models are based on the cumulative\namount of traffic or cumulative amount of service. However, there are network\nscenarios where direct application of such models is difficult. This paper\npresents a temporal approach to stochastic network calculus. The key idea is to\ndevelop models and derive results from the time perspective. Particularly, we\ndefine traffic models and service models based on the cumulative packet\ninter-arrival time and the cumulative packet service time, respectively.\nRelations among these models as well as with the existing models in the\nliterature are established. In addition, we prove the basic properties of the\nproposed models, such as delay bound and backlog bound, output\ncharacterization, concatenation property and superposition property. These\nresults form a temporal stochastic network calculus and compliment the existing\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 08:50:47 GMT"}], "update_date": "2011-12-14", "authors_parsed": [["Xie", "Jing", ""], ["Jiang", "Yuming", ""], ["Xie", "Min", ""]]}, {"id": "1112.4539", "submitter": "Naohito Nakasato", "authors": "Naohito Nakasato", "title": "Implementation of a Parallel Tree Method on a GPU", "comments": "Journal of Computational Science, 2011; See our recent update at\n  http://galaxy.u-aizu.ac.jp/trac/note/wiki/Octree_On_GPU", "journal-ref": null, "doi": "10.1016/j.jocs.2011.01.006", "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kd-tree is a fundamental tool in computer science. Among other\napplications, the application of kd-tree search (by the tree method) to the\nfast evaluation of particle interactions and neighbor search is highly\nimportant, since the computational complexity of these problems is reduced from\nO(N^2) for a brute force method to O(N log N) for the tree method, where N is\nthe number of particles. In this paper, we present a parallel implementation of\nthe tree method running on a graphics processing unit (GPU). We present a\ndetailed description of how we have implemented the tree method on a Cypress\nGPU. An optimization that we found important is localized particle ordering to\neffectively utilize cache memory. We present a number of test results and\nperformance measurements. Our results show that the execution of the tree\ntraversal in a force calculation on a GPU is practical and efficient.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2011 00:59:41 GMT"}], "update_date": "2011-12-21", "authors_parsed": [["Nakasato", "Naohito", ""]]}, {"id": "1112.5505", "submitter": "Nikzad Babaii-Rizvandi", "authors": "Nikzad Babaii Rizvandi, Javid Taheri, Albert Y. Zomaya, Reza Moraveji", "title": "A Study on Using Uncertain Time Series Matching Algorithms in MapReduce\n  Applications", "comments": "12 pages a version has been accepted to journal of \"Concurrency and\n  Computation: Practice and Experience\", available online from the University\n  of Sydney at http://www.nicta.com.au/pub?doc=4744", "journal-ref": null, "doi": null, "report-no": "TR672- University of Sydney", "categories": "cs.DC cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study CPU utilization time patterns of several Map-Reduce\napplications. After extracting running patterns of several applications, the\npatterns with their statistical information are saved in a reference database\nto be later used to tweak system parameters to efficiently execute unknown\napplications in future. To achieve this goal, CPU utilization patterns of new\napplications along with its statistical information are compared with the\nalready known ones in the reference database to find/predict their most\nprobable execution patterns. Because of different patterns lengths, the Dynamic\nTime Warping (DTW) is utilized for such comparison; a statistical analysis is\nthen applied to DTWs' outcomes to select the most suitable candidates.\nMoreover, under a hypothesis, another algorithm is proposed to classify\napplications under similar CPU utilization patterns. Three widely used text\nprocessing applications (WordCount, Distributed Grep, and Terasort) and another\napplication (Exim Mainlog parsing) are used to evaluate our hypothesis in\ntweaking system parameters in executing similar applications. Results were very\npromising and showed effectiveness of our approach on 5-node Map-Reduce\nplatform\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 02:38:42 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2012 00:30:11 GMT"}, {"version": "v3", "created": "Fri, 20 Jan 2012 00:28:52 GMT"}, {"version": "v4", "created": "Wed, 13 Jun 2012 03:33:54 GMT"}, {"version": "v5", "created": "Fri, 18 Jan 2013 03:54:34 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Rizvandi", "Nikzad Babaii", ""], ["Taheri", "Javid", ""], ["Zomaya", "Albert Y.", ""], ["Moraveji", "Reza", ""]]}, {"id": "1112.5588", "submitter": "Georg Hager", "authors": "Moritz Kreutzer, Georg Hager, Gerhard Wellein, Holger Fehske, Achim\n  Basermann, Alan R. Bishop", "title": "Sparse matrix-vector multiplication on GPGPU clusters: A new storage\n  format and a scalable implementation", "comments": "10 pages, 5 figures. Added reference to other recent sparse matrix\n  formats", "journal-ref": null, "doi": "10.1109/IPDPSW.2012.211", "report-no": null, "categories": "cs.DC cs.MS cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix-vector multiplication (spMVM) is the dominant operation in many\nsparse solvers. We investigate performance properties of spMVM with matrices of\nvarious sparsity patterns on the nVidia \"Fermi\" class of GPGPUs. A new \"padded\njagged diagonals storage\" (pJDS) format is proposed which may substantially\nreduce the memory overhead intrinsic to the widespread ELLPACK-R scheme. In our\ntest scenarios the pJDS format cuts the overall spMVM memory footprint on the\nGPGPU by up to 70%, and achieves 95% to 130% of the ELLPACK-R performance.\nUsing a suitable performance model we identify performance bottlenecks on the\nnode level that invalidate some types of matrix structures for efficient\nmulti-GPGPU parallelization. For appropriate sparsity patterns we extend\nprevious work on distributed-memory parallel spMVM to demonstrate a scalable\nhybrid MPI-GPGPU code, achieving efficient overlap of communication and\ncomputation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 14:03:56 GMT"}, {"version": "v2", "created": "Wed, 29 Feb 2012 07:40:22 GMT"}], "update_date": "2013-03-08", "authors_parsed": [["Kreutzer", "Moritz", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""], ["Fehske", "Holger", ""], ["Basermann", "Achim", ""], ["Bishop", "Alan R.", ""]]}]