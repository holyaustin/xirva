[{"id": "1707.00516", "submitter": "Siddharth Samsi", "authors": "Siddharth Samsi, Brian Helfer, Jeremy Kepner, Albert Reuther and\n  Darrell O. Ricke", "title": "A Linear Algebra Approach to Fast DNA Mixture Analysis Using GPUs", "comments": "Accepted for publication at the 2017 IEEE High Performance Extreme\n  Computing conference", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091027", "report-no": null, "categories": "cs.PF cs.CE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of DNA samples is an important step in forensics, and the speed of\nanalysis can impact investigations. Comparison of DNA sequences is based on the\nanalysis of short tandem repeats (STRs), which are short DNA sequences of 2-5\nbase pairs. Current forensics approaches use 20 STR loci for analysis. The use\nof single nucleotide polymorphisms (SNPs) has utility for analysis of complex\nDNA mixtures. The use of tens of thousands of SNPs loci for analysis poses\nsignificant computational challenges because the forensic analysis scales by\nthe product of the loci count and number of DNA samples to be analyzed. In this\npaper, we discuss the implementation of a DNA sequence comparison algorithm by\nre-casting the algorithm in terms of linear algebra primitives. By developing\nan overloaded matrix multiplication approach to DNA comparisons, we can\nleverage advances in GPU hardware and algoithms for Dense Generalized\nMatrix-Multiply (DGEMM) to speed up DNA sample comparisons. We show that it is\npossible to compare 2048 unknown DNA samples with 20 million known samples in\nunder 6 seconds using a NVIDIA K80 GPU.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 12:57:54 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Samsi", "Siddharth", ""], ["Helfer", "Brian", ""], ["Kepner", "Jeremy", ""], ["Reuther", "Albert", ""], ["Ricke", "Darrell O.", ""]]}, {"id": "1707.00832", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo, Stefano Ferretti, Vittorio Ghini", "title": "Modeling the Internet of Things: a simulation perspective", "comments": "Proceedings of the IEEE 2017 International Conference on High\n  Performance Computing and Simulation (HPCS 2017)", "journal-ref": null, "doi": "10.1109/HPCS.2017.13", "report-no": null, "categories": "cs.DC cs.MA cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of properly simulating the Internet of\nThings (IoT). Simulating an IoT allows evaluating strategies that can be\nemployed to deploy smart services over different kinds of territories. However,\nthe heterogeneity of scenarios seriously complicates this task. This imposes\nthe use of sophisticated modeling and simulation techniques. We discuss novel\napproaches for the provision of scalable simulation scenarios, that enable the\nreal-time execution of massively populated IoT environments. Attention is given\nto novel hybrid and multi-level simulation techniques that, when combined with\nagent-based, adaptive Parallel and Distributed Simulation (PADS) approaches,\ncan provide means to perform highly detailed simulations on demand. To support\nthis claim, we detail a use case concerned with the simulation of vehicular\ntransportation systems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 07:16:02 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 13:06:53 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""], ["Ghini", "Vittorio", ""]]}, {"id": "1707.01859", "submitter": "Tobias Meggendorfer", "authors": "Jan K\\v{r}et\\'insk\\'y and Tobias Meggendorfer", "title": "Efficient Strategy Iteration for Mean Payoff in Markov Decision\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes (MDPs) are standard models for probabilistic\nsystems with non-deterministic behaviours. Mean payoff (or long-run average\nreward) provides a mathematically elegant formalism to express performance\nrelated properties. Strategy iteration is one of the solution techniques\napplicable in this context. While in many other contexts it is the technique of\nchoice due to advantages over e.g. value iteration, such as precision or\npossibility of domain-knowledge-aware initialization, it is rarely used for\nMDPs, since there it scales worse than value iteration. We provide several\ntechniques that speed up strategy iteration by orders of magnitude for many\nMDPs, eliminating the performance disadvantage while preserving all its\nadvantages.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 16:41:07 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 14:08:50 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Meggendorfer", "Tobias", ""]]}, {"id": "1707.02096", "submitter": "Mohammad Noormohammadpour", "authors": "Mohammad Noormohammadpour, Cauligi S. Raghavendra, Sriram Rao,\n  Srikanth Kandula", "title": "DCCast: Efficient Point to Multipoint Transfers Across Datacenters", "comments": "9th USENIX Workshop on Hot Topics in Cloud Computing,\n  https://www.usenix.org/conference/hotcloud17/program/presentation/noormohammadpour", "journal-ref": "HotCloud (2017) 1-8", "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using multiple datacenters allows for higher availability, load balancing and\nreduced latency to customers of cloud services. To distribute multiple copies\nof data, cloud providers depend on inter-datacenter WANs that ought to be used\nefficiently considering their limited capacity and the ever-increasing data\ndemands. In this paper, we focus on applications that transfer objects from one\ndatacenter to several datacenters over dedicated inter-datacenter networks. We\npresent DCCast, a centralized Point to Multi-Point (P2MP) algorithm that uses\nforwarding trees to efficiently deliver an object from a source datacenter to\nrequired destination datacenters. With low computational overhead, DCCast\nselects forwarding trees that minimize bandwidth usage and balance load across\nall links. With simulation experiments on Google's GScale network, we show that\nDCCast can reduce total bandwidth usage and tail Transfer Completion Times\n(TCT) by up to $50\\%$ compared to delivering the same objects via independent\npoint-to-point (P2P) transfers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 09:25:01 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Noormohammadpour", "Mohammad", ""], ["Raghavendra", "Cauligi S.", ""], ["Rao", "Sriram", ""], ["Kandula", "Srikanth", ""]]}, {"id": "1707.02789", "submitter": "Anna Engelmann", "authors": "Anna Engelmann, Wolfgang Bziuk, Admela Jukan and Muriel Medard", "title": "Exploiting Parallelism in Optical Network Systems: A Case Study of\n  Random Linear Network Coding (RLNC) in Ethernet-over-Optical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As parallelism becomes critically important in the semiconductor technology,\nhigh-performance computing, and cloud applications, parallel network systems\nwill increasingly follow suit. Today, parallelism is an essential architectural\nfeature of 40/100/400 Gigabit Ethernet standards, whereby high speed Ethernet\nsystems are equipped with multiple parallel network interfaces. This creates\nnew network topology abstractions and new technology requirements: instead of a\nsingle high capacity network link, multiple Ethernet end-points and interfaces\nneed to be considered together with multiple links in form of discrete parallel\npaths. This new paradigm is enabling implementations of various new features to\nimprove overall system performance. In this paper, we analyze the performance\nof parallel network systems with network coding. In particular, by using random\nLNC (RLNC), - a code without the need for decoding, we can make use of the fact\nthat we have codes that are both distributed (removing the need for\ncoordination or optimization of resources) and composable (without the need to\nexchange code information), leading to a fully stateless operation. We propose\na novel theoretical modeling framework, including derivation of the upper and\nlower bounds as well as an expected value of the differential delay of parallel\npaths, and the resulting queue size at the receiver. The results show a great\npromise of network system parallelism in combination with RLNC: with a proper\nset of design parameters, the differential delay and the buffer size at the\nEthernet receiver can be reduced significantly, while the cross-layer design\nand routing can be greatly simplified.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 10:33:07 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Engelmann", "Anna", ""], ["Bziuk", "Wolfgang", ""], ["Jukan", "Admela", ""], ["Medard", "Muriel", ""]]}, {"id": "1707.03223", "submitter": "\\v{L}ubo\\v{s} Koren\\v{c}iak", "authors": "Christel Baier, Clemens Dubslaff, \\v{L}ubo\\v{s} Koren\\v{c}iak,\n  Anton\\'in Ku\\v{c}era Vojt\\v{e}ch \\v{R}eh\\'ak", "title": "Synthesis of Optimal Resilient Control Strategies", "comments": "This article is a full version of a paper accepted to the Automated\n  Technology for Verification and Analysis (ATVA) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO cs.PF", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Repair mechanisms are important within resilient systems to maintain the\nsystem in an operational state after an error occurred. Usually, constraints on\nthe repair mechanisms are imposed, e.g., concerning the time or resources\nrequired (such as energy consumption or other kinds of costs). For systems\nmodeled by Markov decision processes (MDPs), we introduce the concept of\nresilient schedulers, which represent control strategies guaranteeing that\nthese constraints are always met within some given probability. Assigning\nrewards to the operational states of the system, we then aim towards resilient\nschedulers which maximize the long-run average reward, i.e., the expected mean\npayoff. We present a pseudo-polynomial algorithm that decides whether a\nresilient scheduler exists and if so, yields an optimal resilient scheduler. We\nshow also that already the decision problem asking whether there exists a\nresilient scheduler is PSPACE-hard.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 11:34:18 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Baier", "Christel", ""], ["Dubslaff", "Clemens", ""], ["Koren\u010diak", "\u013dubo\u0161", ""], ["\u0158eh\u00e1k", "Anton\u00edn Ku\u010dera Vojt\u011bch", ""]]}, {"id": "1707.03515", "submitter": "Jeremy Kepner", "authors": "Chansup Byun, Jeremy Kepner, William Arcand, David Bestor, Bill\n  Bergeron, Vijay Gadepally, Michael Houle, Matthew Hubbell, Michael Jones,\n  Anna Klein, Peter Michaleas, Lauren Milechin, Julie Mullen, Andrew Prout,\n  Antonio Rosa, Siddharth Samsi, Charles Yee, Albert Reuther", "title": "Benchmarking Data Analysis and Machine Learning Applications on the\n  Intel KNL Many-Core Processor", "comments": "6 pages; 9 figures; accepted to IEEE HPEC 2017", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091067", "report-no": null, "categories": "cs.PF astro-ph.IM cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knights Landing (KNL) is the code name for the second-generation Intel Xeon\nPhi product family. KNL has generated significant interest in the data analysis\nand machine learning communities because its new many-core architecture targets\nboth of these workloads. The KNL many-core vector processor design enables it\nto exploit much higher levels of parallelism. At the Lincoln Laboratory\nSupercomputing Center (LLSC), the majority of users are running data analysis\napplications such as MATLAB and Octave. More recently, machine learning\napplications, such as the UC Berkeley Caffe deep learning framework, have\nbecome increasingly important to LLSC users. Thus, the performance of these\napplications on KNL systems is of high interest to LLSC users and the broader\ndata analysis and machine learning communities. Our data analysis benchmarks of\nthese application on the Intel KNL processor indicate that single-core\ndouble-precision generalized matrix multiply (DGEMM) performance on KNL systems\nhas improved by ~3.5x compared to prior Intel Xeon technologies. Our data\nanalysis applications also achieved ~60% of the theoretical peak performance.\nAlso a performance comparison of a machine learning application, Caffe, between\nthe two different Intel CPUs, Xeon E5 v3 and Xeon Phi 7210, demonstrated a 2.7x\nimprovement on a KNL node.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 02:04:58 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Byun", "Chansup", ""], ["Kepner", "Jeremy", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Gadepally", "Vijay", ""], ["Houle", "Michael", ""], ["Hubbell", "Matthew", ""], ["Jones", "Michael", ""], ["Klein", "Anna", ""], ["Michaleas", "Peter", ""], ["Milechin", "Lauren", ""], ["Mullen", "Julie", ""], ["Prout", "Andrew", ""], ["Rosa", "Antonio", ""], ["Samsi", "Siddharth", ""], ["Yee", "Charles", ""], ["Reuther", "Albert", ""]]}, {"id": "1707.04011", "submitter": "Mohammad Noormohammadpour", "authors": "Mohammad Noormohammadpour, Cauligi S. Raghavendra, Sriram Rao", "title": "DCRoute: Speeding up Inter-Datacenter Traffic Allocation while\n  Guaranteeing Deadlines", "comments": "23rd IEEE International Conference on High Performance Computing\n  (HiPC)", "journal-ref": null, "doi": "10.1109/HiPC.2016.019", "report-no": null, "categories": "cs.NI cs.DC cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datacenters provide the infrastructure for cloud computing services used by\nmillions of users everyday. Many such services are distributed over multiple\ndatacenters at geographically distant locations possibly in different\ncontinents. These datacenters are then connected through high speed WAN links\nover private or public networks. To perform data backups or data\nsynchronization operations, many transfers take place over these networks that\nhave to be completed before a deadline in order to provide necessary service\nguarantees to end users. Upon arrival of a transfer request, we would like the\nsystem to be able to decide whether such a request can be guaranteed successful\ndelivery. If yes, it should provide us with transmission schedule in the\nshortest time possible. In addition, we would like to avoid packet reordering\nat the destination as it affects TCP performance. Previous work in this area\neither cannot guarantee that admitted transfers actually finish before the\nspecified deadlines or use techniques that can result in packet reordering. In\nthis paper, we propose DCRoute, a fast and efficient routing and traffic\nallocation technique that guarantees transfer completion before deadlines for\nadmitted requests. It assigns each transfer a single path to avoid packet\nreordering. Through simulations, we show that DCRoute is at least 200 times\nfaster than other traffic allocation techniques based on linear programming\n(LP) while admitting almost the same amount of traffic to the system.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 07:47:20 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Noormohammadpour", "Mohammad", ""], ["Raghavendra", "Cauligi S.", ""], ["Rao", "Sriram", ""]]}, {"id": "1707.04019", "submitter": "Mohammad Noormohammadpour", "authors": "Mohammad Noormohammadpour, Cauligi S. Raghavendra, Sriram Rao, Asad M.\n  Madni", "title": "RCD: Rapid Close to Deadline Scheduling for Datacenter Networks", "comments": "World Automation Congress (WAC), IEEE, 2016", "journal-ref": null, "doi": "10.1109/WAC.2016.7582951", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datacenter-based Cloud Computing services provide a flexible, scalable and\nyet economical infrastructure to host online services such as multimedia\nstreaming, email and bulk storage. Many such services perform geo-replication\nto provide necessary quality of service and reliability to users resulting in\nfrequent large inter- datacenter transfers. In order to meet tenant service\nlevel agreements (SLAs), these transfers have to be completed prior to a\ndeadline. In addition, WAN resources are quite scarce and costly, meaning they\nshould be fully utilized. Several recently proposed schemes, such as B4,\nTEMPUS, and SWAN have focused on improving the utilization of inter-datacenter\ntransfers through centralized scheduling, however, they fail to provide a\nmechanism to guarantee that admitted requests meet their deadlines. Also, in a\nrecent study, authors propose Amoeba, a system that allows tenants to define\ndeadlines and guarantees that the specified deadlines are met, however, to\nadmit new traffic, the proposed system has to modify the allocation of already\nadmitted transfers. In this paper, we propose Rapid Close to Deadline\nScheduling (RCD), a close to deadline traffic allocation technique that is fast\nand efficient. Through simulations, we show that RCD is up to 15 times faster\nthan Amoeba, provides high link utilization along with deadline guarantees, and\nis able to make quick decisions on whether a new request can be fully satisfied\nbefore its deadline.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 08:09:18 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Noormohammadpour", "Mohammad", ""], ["Raghavendra", "Cauligi S.", ""], ["Rao", "Sriram", ""], ["Madni", "Asad M.", ""]]}, {"id": "1707.04245", "submitter": "Chris Fawcett", "authors": "Chris Fawcett, Lars Kotthoff, Holger H. Hoos", "title": "Hot-Rodding the Browser Engine: Automatic Configuration of JavaScript\n  Compilers", "comments": "11 pages, long version of a poster presented at CGO 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern software systems in many application areas offer to the user a\nmultitude of parameters, switches and other customisation hooks. Humans tend to\nhave difficulties determining the best configurations for particular\napplications. Modern optimising compilers are an example of such software\nsystems; their many parameters need to be tuned for optimal performance, but\nare often left at the default values for convenience. In this work, we\nautomatically determine compiler parameter settings that result in optimised\nperformance for particular applications. Specifically, we apply a\nstate-of-the-art automated parameter configuration procedure based on\ncutting-edge machine learning and optimisation techniques to two prominent\nJavaScript compilers and demonstrate that significant performance improvements,\nmore than 35% in some cases, can be achieved over the default parameter\nsettings on a diverse set of benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 23:31:23 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Fawcett", "Chris", ""], ["Kotthoff", "Lars", ""], ["Hoos", "Holger H.", ""]]}, {"id": "1707.04254", "submitter": "EPTCS", "authors": "Andrea Vandin (IMT School for Advanced Studies Lucca)", "title": "Language-based Abstractions for Dynamical Systems", "comments": "In Proceedings QAPL 2017, arXiv:1707.03668", "journal-ref": "EPTCS 250, 2017, pp. 15-24", "doi": "10.4204/EPTCS.250.2", "report-no": null, "categories": "cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary differential equations (ODEs) are the primary means to modelling\ndynamical systems in many natural and engineering sciences. The number of\nequations required to describe a system with high heterogeneity limits our\ncapability of effectively performing analyses. This has motivated a large body\nof research, across many disciplines, into abstraction techniques that provide\nsmaller ODE systems while preserving the original dynamics in some appropriate\nsense. In this paper we give an overview of a recently proposed\ncomputer-science perspective to this problem, where ODE reduction is recast to\nfinding an appropriate equivalence relation over ODE variables, akin to\nclassical models of computation based on labelled transition systems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 13:51:26 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Vandin", "Andrea", "", "IMT School for Advanced Studies Lucca"]]}, {"id": "1707.04566", "submitter": "Damien Courouss\\'e", "authors": "Fernando Endo and Damien Courouss\\'e and Henri-Pierre Charles", "title": "Pushing the Limits of Online Auto-tuning: Machine Code Optimization in\n  Short-Running Kernels", "comments": "Extension of a Conference Paper published in the proceedings of\n  MCSoC-16: IEEE 10th International Symposium on Embedded Multicore/Many-core\n  Systems-on-Chip, Lyon, France, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online auto-tuning approach for computing kernels. Differently\nfrom existing online auto-tuners, which regenerate code with long compilation\nchains from the source to the binary code, our approach consists on deploying\nauto-tuning directly at the level of machine code generation. This allows\nauto-tuning to pay off in very short-running applications. As a proof of\nconcept, our approach is demonstrated in two benchmarks, which execute during\nhundreds of milliseconds to a few seconds only. In a CPU-bound kernel, the\naverage speedups achieved are 1.10 to 1.58 depending on the target\nmicro-architecture, up to 2.53 in the most favourable conditions (all run-time\noverheads included). In a memory-bound kernel, less favourable to our runtime\nauto-tuning optimizations, the average speedups are 1.04 to 1.10, up to 1.30 in\nthe best configuration. Despite the short execution times of our benchmarks,\nthe overhead of our runtime auto-tuning is between 0.2 and 4.2% only of the\ntotal application execution times. By simulating the CPU-bound application in\n11 different CPUs, we showed that, despite the clear hardware disadvantage of\nIn-Order (io) cores vs. Out-of-Order (ooo) equivalent cores, online auto-tuning\nin io CPUs obtained an average speedup of 1.03 and an energy efficiency\nimprovement of 39~\\% over the SIMD reference in ooo CPUs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 17:28:28 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Endo", "Fernando", ""], ["Courouss\u00e9", "Damien", ""], ["Charles", "Henri-Pierre", ""]]}, {"id": "1707.04610", "submitter": "Tian Guo", "authors": "Tian Guo", "title": "Cloud-based or On-device: An Empirical Study of Mobile Deep Inference", "comments": "Accepted at The IEEE International Conference on Cloud Engineering\n  (IC2E) conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern mobile applications are benefiting significantly from the advancement\nin deep learning, e.g., implementing real-time image recognition and\nconversational system. Given a trained deep learning model, applications\nusually need to perform a series of matrix operations based on the input data,\nin order to infer possible output values. Because of computational complexity\nand size constraints, these trained models are often hosted in the cloud. To\nutilize these cloud-based models, mobile apps will have to send input data over\nthe network. While cloud-based deep learning can provide reasonable response\ntime for mobile apps, it restricts the use case scenarios, e.g. mobile apps\nneed to have network access. With mobile specific deep learning optimizations,\nit is now possible to employ on-device inference. However, because mobile\nhardware, such as GPU and memory size, can be very limited when compared to its\ndesktop counterpart, it is important to understand the feasibility of this new\non-device deep learning inference architecture. In this paper, we empirically\nevaluate the inference performance of three Convolutional Neural Networks\n(CNNs) using a benchmark Android application we developed. Our measurement and\nanalysis suggest that on-device inference can cost up to two orders of\nmagnitude greater response time and energy when compared to cloud-based\ninference, and that loading model and computing probability are two performance\nbottlenecks for on-device deep inferences.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 19:05:50 GMT"}, {"version": "v2", "created": "Sun, 15 Apr 2018 17:48:20 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Guo", "Tian", ""]]}, {"id": "1707.04939", "submitter": "Yuri G. Gordienko", "authors": "Vladyslav Taran, Oleg Alienin, Sergii Stirenko, A.Rojbi, and Yuri\n  Gordienko", "title": "Performance Evaluation of Distributed Computing Environments with Hadoop\n  and Spark Frameworks", "comments": "5 pages, 1 table, 2017 IEEE International Young Scientists Forum on\n  Applied Physics and Engineering (YSF-2017) (Lviv, Ukraine)", "journal-ref": null, "doi": "10.1109/YSF.2017.8126655", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, due to rapid development of information and communication\ntechnologies, the data are created and consumed in the avalanche way.\nDistributed computing create preconditions for analyzing and processing such\nBig Data by distributing the computations among a number of compute nodes. In\nthis work, performance of distributed computing environments on the basis of\nHadoop and Spark frameworks is estimated for real and virtual versions of\nclusters. As a test task, we chose the classic use case of word counting in\ntexts of various sizes. It was found that the running times grow very fast with\nthe dataset size and faster than a power function even. As to the real and\nvirtual versions of cluster implementations, this tendency is the similar for\nboth Hadoop and Spark frameworks. Moreover, speedup values decrease\nsignificantly with the growth of dataset size, especially for virtual version\nof cluster configuration. The problem of growing data generated by IoT and\nmultimodal (visual, sound, tactile, neuro and brain-computing, muscle and eye\ntracking, etc.) interaction channels is presented. In the context of this\nproblem, the current observations as to the running times and speedup on Hadoop\nand Spark frameworks in real and virtual cluster configurations can be very\nuseful for the proper scaling-up and efficient job management, especially for\nmachine learning and Deep Learning applications, where Big Data are widely\npresent.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 19:47:17 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Taran", "Vladyslav", ""], ["Alienin", "Oleg", ""], ["Stirenko", "Sergii", ""], ["Rojbi", "A.", ""], ["Gordienko", "Yuri", ""]]}, {"id": "1707.04940", "submitter": "Yuri G. Gordienko", "authors": "Yuriy Kochura, Sergii Stirenko, Yuri Gordienko", "title": "Comparative Performance Analysis of Neural Networks Architectures on H2O\n  Platform for Various Activation Functions", "comments": "4 pages, 6 figures, 6 tables; 2017 IEEE International Young\n  Scientists Forum on Applied Physics and Engineering (YSF-2017) (Lviv,\n  Ukraine)", "journal-ref": null, "doi": "10.1109/YSF.2017.8126654", "report-no": null, "categories": "cs.LG cs.CV cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (deep structured learning, hierarchi- cal learning or deep\nmachine learning) is a branch of machine learning based on a set of algorithms\nthat attempt to model high- level abstractions in data by using multiple\nprocessing layers with complex structures or otherwise composed of multiple\nnon-linear transformations. In this paper, we present the results of testing\nneural networks architectures on H2O platform for various activation functions,\nstopping metrics, and other parameters of machine learning algorithm. It was\ndemonstrated for the use case of MNIST database of handwritten digits in\nsingle-threaded mode that blind selection of these parameters can hugely\nincrease (by 2-3 orders) the runtime without the significant increase of\nprecision. This result can have crucial influence for opitmization of available\nand new machine learning methods, especially for image recognition problems.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 19:57:28 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Kochura", "Yuriy", ""], ["Stirenko", "Sergii", ""], ["Gordienko", "Yuri", ""]]}, {"id": "1707.05260", "submitter": "Farzad Farshchi", "authors": "Farzad Farshchi, Prathap Kumar Valsan, Renato Mancuso, Heechul Yun", "title": "Deterministic Memory Abstraction and Supporting Multicore System\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.OS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poor time predictability of multicore processors has been a long-standing\nchallenge in the real-time systems community. In this paper, we make a case\nthat a fundamental problem that prevents efficient and predictable real-time\ncomputing on multicore is the lack of a proper memory abstraction to express\nmemory criticality, which cuts across various layers of the system: the\napplication, OS, and hardware. We, therefore, propose a new holistic resource\nmanagement approach driven by a new memory abstraction, which we call\nDeterministic Memory. The key characteristic of deterministic memory is that\nthe platform - the OS and hardware - guarantees small and tightly bounded\nworst-case memory access timing. In contrast, we call the conventional memory\nabstraction as best-effort memory in which only highly pessimistic worst-case\nbounds can be achieved. We propose to utilize both abstractions to achieve high\ntime predictability but without significantly sacrificing performance. We\npresent deterministic memory-aware OS and architecture designs, including\nOS-level page allocator, hardware-level cache, and DRAM controller designs. We\nimplement the proposed OS and architecture extensions on Linux and gem5\nsimulator. Our evaluation results, using a set of synthetic and real-world\nbenchmarks, demonstrate the feasibility and effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 16:12:15 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 20:40:13 GMT"}, {"version": "v3", "created": "Fri, 9 Feb 2018 22:36:45 GMT"}, {"version": "v4", "created": "Thu, 19 Apr 2018 00:06:48 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Farshchi", "Farzad", ""], ["Valsan", "Prathap Kumar", ""], ["Mancuso", "Renato", ""], ["Yun", "Heechul", ""]]}, {"id": "1707.05405", "submitter": "Ayman Noor", "authors": "Ayman Noor", "title": "Study and Analysis of MAC/IPAD Lab Configuration", "comments": "11 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about three virtualization modes: VMware, Parallels, and Boot\nCamping. The trade off of their testing is the hardware requirements. The main\nquestion is, among the three, which is the most suitable? The answer actually\nvaries from user to user. It depends on the user needs. Moreover, it is\nnecessary to consider its performance, graphics, efficiency and reliability,\nand interoperability, and that is our major scope. In order to take the final\ndecision in choosing one of the modes it is important to run some tests, which\ncosts a lot in terms of money, complexity, and time consumption. Therefore, in\norder to overcome this trade off, most of the research has been done through\nonline benchmarking and my own anticipation. The final solution was extracted\nafter comparing all previously mentioned above and after rigorous testing made\nwhich will be introduced later in this document.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 22:26:19 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Noor", "Ayman", ""]]}, {"id": "1707.05538", "submitter": "Ana\\\"is Finzi", "authors": "Ana\\\"is Finzi, Ahlem Mifdaoui, Fabrice Frances, Emmanuel Lochin", "title": "Incorporating TSN/BLS in AFDX for Mixed-Criticality Avionics\n  Applications: Specification and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an extension of the AFDX standard, incorporating a\nTSN/BLS shaper, to homogenize the avionics communication architecture, and\nenable the interconnection of different avionics domains with mixed-criticality\nlevels, e.g., legacy AFDX traffic, Flight Control and In-Flight Entertainment.\nFirst, we present the main specifications of such a proposed solution. Then, we\ndetail the corresponding worst-case timing analysis, using the Network Calculus\nframework, to infer real-time guarantees. Finally, we conduct the performance\nanalysis of such a proposal on a realistic AFDX configuration. Results show the\nefficiency of the Extended AFDX standard to noticeably enhance the medium\npriority level delay bounds, while respecting the higher priority level\nconstraints, in comparison with the legacy AFDX standard.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 09:31:15 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Finzi", "Ana\u00efs", ""], ["Mifdaoui", "Ahlem", ""], ["Frances", "Fabrice", ""], ["Lochin", "Emmanuel", ""]]}, {"id": "1707.05836", "submitter": "Moritz Steiner", "authors": "Utkarsh Goel, Moritz Steiner, Mike P. Wittie, Stephen Ludin, Martin\n  Flack", "title": "Domain-Sharding for Faster HTTP/2 in Lossy Cellular Networks", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HTTP/2 (h2) is a new standard for Web communications that already delivers a\nlarge share of Web traffic. Unlike HTTP/1, h2 uses only one underlying TCP\nconnection. In a cellular network with high loss and sudden spikes in latency,\nwhich the TCP stack might interpret as loss, using a single TCP connection can\nnegatively impact Web performance. In this paper, we perform an extensive\nanalysis of real world cellular network traffic and design a testbed to emulate\nloss characteristics in cellular networks. We use the emulated cellular network\nto measure h2 performance in comparison to HTTP/1.1, for webpages synthesized\nfrom HTTP Archive repository data.\n  Our results show that, in lossy conditions, h2 achieves faster page load\ntimes (PLTs) for webpages with small objects. For webpages with large objects,\nh2 degrades the PLT. We devise a new domain-sharding technique that isolates\nlarge and small object downloads on separate connections. Using sharding, we\nshow that under lossy cellular conditions, h2 over multiple connections\nimproves the PLT compared to h2 with one connection and HTTP/1.1 with six\nconnections. Finally, we recommend content providers and content delivery\nnetworks to apply h2-aware domain-sharding on webpages currently served over h2\nfor improved mobile Web performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 19:34:22 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Goel", "Utkarsh", ""], ["Steiner", "Moritz", ""], ["Wittie", "Mike P.", ""], ["Ludin", "Stephen", ""], ["Flack", "Martin", ""]]}, {"id": "1707.05866", "submitter": "Debankur Mukherjee", "authors": "Debankur Mukherjee, Sem C. Borst, and Johan S.H. van Leeuwaarden", "title": "Asymptotically Optimal Load Balancing Topologies", "comments": "A few relevant results from arXiv:1612.00723 are included for\n  convenience", "journal-ref": "Proc. ACM Meas. Anal. Comput. Syst. 2 1 (2018)", "doi": "10.1145/3179417", "report-no": null, "categories": "math.PR cs.DM cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a system of $N$ servers inter-connected by some underlying graph\ntopology $G_N$. Tasks arrive at the various servers as independent Poisson\nprocesses of rate $\\lambda$. Each incoming task is irrevocably assigned to\nwhichever server has the smallest number of tasks among the one where it\nappears and its neighbors in $G_N$. Tasks have unit-mean exponential service\ntimes and leave the system upon service completion.\n  The above model has been extensively investigated in the case $G_N$ is a\nclique. Since the servers are exchangeable in that case, the queue length\nprocess is quite tractable, and it has been proved that for any $\\lambda < 1$,\nthe fraction of servers with two or more tasks vanishes in the limit as $N \\to\n\\infty$. For an arbitrary graph $G_N$, the lack of exchangeability severely\ncomplicates the analysis, and the queue length process tends to be worse than\nfor a clique. Accordingly, a graph $G_N$ is said to be $N$-optimal or\n$\\sqrt{N}$-optimal when the occupancy process on $G_N$ is equivalent to that on\na clique on an $N$-scale or $\\sqrt{N}$-scale, respectively.\n  We prove that if $G_N$ is an Erd\\H{o}s-R\\'enyi random graph with average\ndegree $d(N)$, then it is with high probability $N$-optimal and\n$\\sqrt{N}$-optimal if $d(N) \\to \\infty$ and $d(N) / (\\sqrt{N} \\log(N)) \\to\n\\infty$ as $N \\to \\infty$, respectively. This demonstrates that optimality can\nbe maintained at $N$-scale and $\\sqrt{N}$-scale while reducing the number of\nconnections by nearly a factor $N$ and $\\sqrt{N} / \\log(N)$ compared to a\nclique, provided the topology is suitably random. It is further shown that if\n$G_N$ contains $\\Theta(N)$ bounded-degree nodes, then it cannot be $N$-optimal.\nIn addition, we establish that an arbitrary graph $G_N$ is $N$-optimal when its\nminimum degree is $N - o(N)$, and may not be $N$-optimal even when its minimum\ndegree is $c N + o(N)$ for any $0 < c < 1/2$.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 21:30:30 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 16:06:35 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Mukherjee", "Debankur", ""], ["Borst", "Sem C.", ""], ["van Leeuwaarden", "Johan S. H.", ""]]}, {"id": "1707.06204", "submitter": "Bo Jiang", "authors": "Bo Jiang, Philippe Nain, Don Towsley", "title": "On the Convergence of the TTL Approximation for an LRU Cache under\n  Independent Stationary Request Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modeling and analysis of an LRU cache is extremely challenging as exact\nresults for the main performance metrics (e.g. hit rate) are either lacking or\ncannot be used because of their high computational complexity for large caches.\nAs a result, various approximations have been proposed. The state-of-the-art\nmethod is the so-called TTL approximation, first proposed and shown to be\nasymptotically exact for IRM requests by Fagin. It has been applied to various\nother workload models and numerically demonstrated to be accurate but without\ntheoretical justification. In this paper we provide theoretical justification\nfor the approximation in the case where distinct contents are described by\nindependent stationary and ergodic processes. We show that this approximation\nis exact as the cache size and the number of contents go to infinity. This\nextends earlier results for the independent reference model. Moreover, we\nestablish results not only for the aggregate cache hit probability but also for\nevery individual content. Last, we obtain bounds on the rate of convergence.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 17:12:58 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 21:49:20 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 19:44:25 GMT"}, {"version": "v4", "created": "Mon, 9 Jul 2018 22:19:02 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Jiang", "Bo", ""], ["Nain", "Philippe", ""], ["Towsley", "Don", ""]]}, {"id": "1707.06817", "submitter": "Quan-Lin Li", "authors": "Quan-Lin Li, Zhi-Yong Qian and Rui-Na Fan", "title": "Fluid and Diffusion Limits for Bike Sharing Systems", "comments": "34 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bike sharing systems have rapidly developed around the world, and they are\nserved as a promising strategy to improve urban traffic congestion and to\ndecrease polluting gas emissions. So far performance analysis of bike sharing\nsystems always exists many difficulties and challenges under some more general\nfactors. In this paper, a more general large-scale bike sharing system is\ndiscussed by means of heavy traffic approximation of multiclass closed queueing\nnetworks with non-exponential factors. Based on this, the fluid scaled\nequations and the diffusion scaled equations are established by means of the\nnumbers of bikes both at the stations and on the roads, respectively.\nFurthermore, the scaling processes for the numbers of bikes both at the\nstations and on the roads are proved to converge in distribution to a\nsemimartingale reflecting Brownian motion (SRBM) in a $N^{2}$-dimensional box,\nand also the fluid and diffusion limit theorems are obtained. Furthermore,\nperformance analysis of the bike sharing system is provided. Thus the results\nand methodology of this paper provide new highlight in the study of more\ngeneral large-scale bike sharing systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 09:56:38 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Li", "Quan-Lin", ""], ["Qian", "Zhi-Yong", ""], ["Fan", "Rui-Na", ""]]}, {"id": "1707.07097", "submitter": "Benjamin Berg", "authors": "Benjamin Berg, Jan-Pieter Dorsman, Mor Harchol-Balter", "title": "Towards Optimality in Parallel Scheduling", "comments": null, "journal-ref": "Proc. ACM Meas. Anal. Comput. Syst. 1, 2, Article 40 (December\n  2017), 30 pages", "doi": "10. 1145/3154499", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To keep pace with Moore's law, chip designers have focused on increasing the\nnumber of cores per chip rather than single core performance. In turn, modern\njobs are often designed to run on any number of cores. However, to effectively\nleverage these multi-core chips, one must address the question of how many\ncores to assign to each job. Given that jobs receive sublinear speedups from\nadditional cores, there is an obvious tradeoff: allocating more cores to an\nindividual job reduces the job's runtime, but in turn decreases the efficiency\nof the overall system. We ask how the system should schedule jobs across cores\nso as to minimize the mean response time over a stream of incoming jobs.\n  To answer this question, we develop an analytical model of jobs running on a\nmulti-core machine. We prove that EQUI, a policy which continuously divides\ncores evenly across jobs, is optimal when all jobs follow a single speedup\ncurve and have exponentially distributed sizes. EQUI requires jobs to change\ntheir level of parallelization while they run. Since this is not possible for\nall workloads, we consider a class of \"fixed-width\" policies, which choose a\nsingle level of parallelization, k, to use for all jobs. We prove that,\nsurprisingly, it is possible to achieve EQUI's performance without requiring\njobs to change their levels of parallelization by using the optimal fixed level\nof parallelization, k*. We also show how to analytically derive the optimal k*\nas a function of the system load, the speedup curve, and the job size\ndistribution.\n  In the case where jobs may follow different speedup curves, finding a good\nscheduling policy is even more challenging. We find that policies like EQUI\nwhich performed well in the case of a single speedup function now perform\npoorly. We propose a very simple policy, GREEDY*, which performs near-optimally\nwhen compared to the numerically-derived optimal policy.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jul 2017 03:30:17 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 19:14:53 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Berg", "Benjamin", ""], ["Dorsman", "Jan-Pieter", ""], ["Harchol-Balter", "Mor", ""]]}, {"id": "1707.07175", "submitter": "Xiaoqi Tan", "authors": "Xiaoqi Tan, Bo Sun, Yuan Wu, Danny H.K. Tsang", "title": "Asymptotic Performance Evaluation of Battery Swapping and Charging\n  Station for Electric Vehicles", "comments": "35 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A battery swapping and charging station (BSCS) is an energy refueling\nstation, where i) electric vehicles (EVs) with depleted batteries (DBs) can\nswap their DBs for fully-charged ones, and ii) the swapped DBs are then charged\nuntil they are fully-charged. Successful deployment of a BSCS system\nnecessitates a careful planning of swapping- and charging-related\ninfrastructures, and thus a comprehensive performance evaluation of the BSCS is\nbecoming crucial. This paper studies such a performance evaluation problem with\na novel mixed queueing network (MQN) model and validates this model with\nextensive numerical simulation. We adopt the EVs' blocking probability as our\nquality-of-service measure and focus on studying the impact of the key\nparameters of the BSCS (e.g., the numbers of parking spaces, swapping islands,\nchargers, and batteries) on the blocking probability. We prove a necessary and\nsufficient condition for showing the ergodicity of the MQN when the number of\nbatteries approaches infinity, and further prove that the blocking probability\nhas two different types of asymptotic behaviors. Meanwhile, for each type of\nasymptotic behavior, we analytically derive the asymptotic lower bound of the\nblocking probability.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jul 2017 14:49:24 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 09:09:00 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Tan", "Xiaoqi", ""], ["Sun", "Bo", ""], ["Wu", "Yuan", ""], ["Tsang", "Danny H. K.", ""]]}, {"id": "1707.07551", "submitter": "Quan-Lin Li", "authors": "Quan-Lin Li, Rui-Na Fan and Zhi-Yong Qian", "title": "A Nonlinear Solution to Closed Queueing Networks for Bike Sharing\n  Systems with Markovian Arrival Processes and under an Irreducible Path Graph", "comments": "29 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:1606.04805", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a favorite urban public transport mode, the bike sharing system is a\nlarge-scale and complicated system, and there exists a key requirement that a\nuser and a bike should be matched sufficiently in time. Such matched behavior\nmakes analysis of the bike sharing systems more difficult and challenging. This\npaper considers a more general large-scale bike sharing system from two\nimportant views: (a) Bikes move in an irreducible path graph, which is related\nto geographical structure of the bike sharing system; and (b) Markovian arrival\nprocesses (MAPs) are applied to describe the non-Poisson and burst behavior of\nbike-user (abbreviated as user) arrivals, while the burstiness demonstrates\nthat the user arrivals are time-inhomogeneous and space-heterogeneous in\npractice. For such a complicated bike sharing system, this paper establishes a\nmulticlass closed queueing network by means of some virtual ideas, for example,\nbikes are abstracted as virtual customers; stations and roads are regarded as\nvirtual nodes. Thus user arrivals are related to service times at station\nnodes; and users riding bikes on roads are viewed as service times at road\nnodes. Further, to deal with this multiclass closed queueing network, we\nprovide a detailed observation practically on physical behavior of the bike\nsharing system in order to establish the routing matrix, which gives a\nnonlinear solution to compute the relative arrival rates in terms of the\nproduct-form solution to the steady-state probabilities of joint queue lengths\nat the virtual nodes. Based on this, we can compute the steady-state\nprobability of problematic stations, and also deal with other interesting\nperformance measures of the bike sharing system. We hope that the methodology\nand results of this paper can be applicable in the study of more general bike\nsharing systems through multiclass closed queueing networks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 10:11:10 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Li", "Quan-Lin", ""], ["Fan", "Rui-Na", ""], ["Qian", "Zhi-Yong", ""]]}, {"id": "1707.08860", "submitter": "Huajin Wang", "authors": "Huajin Wang, Jianhui Li, Zhihong Shen and Yuanchun Zhou", "title": "Approximations and Bounds for (n, k) Fork-Join Queues: A Linear\n  Transformation Approach", "comments": "10 pages", "journal-ref": "2018 18th IEEE/ACM International Symposium on Cluster, Cloud and\n  Grid Computing (CCGRID)", "doi": "10.1109/CCGRID.2018.00069", "report-no": null, "categories": "cs.PF cs.DC cs.NI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to basic fork-join queues, a job in (n, k) fork-join queues only\nneeds its k out of all n sub-tasks to be finished. Since (n, k) fork-join\nqueues are prevalent in popular distributed systems, erasure coding based cloud\nstorages, and modern network protocols like multipath routing, estimating the\nsojourn time of such queues is thus critical for the performance measurement\nand resource plan of computer clusters. However, the estimating keeps to be a\nwell-known open challenge for years, and only rough bounds for a limited range\nof load factors have been given. In this paper, we developed a closed-form\nlinear transformation technique for jointly-identical random variables: An\norder statistic can be represented by a linear combination of maxima. This\nbrand-new technique is then used to transform the sojourn time of non-purging\n(n, k) fork-join queues into a linear combination of the sojourn times of basic\n(k, k), (k+1, k+1), ..., (n, n) fork-join queues. Consequently, existing\napproximations for basic fork-join queues can be bridged to the approximations\nfor non-purging (n, k) fork-join queues. The uncovered approximations are then\nused to improve the upper bounds for purging (n, k) fork-join queues.\nSimulation experiments show that this linear transformation approach is\npracticed well for moderate n and relatively large k.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 13:35:13 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 09:02:36 GMT"}, {"version": "v3", "created": "Tue, 1 Aug 2017 03:02:27 GMT"}, {"version": "v4", "created": "Sat, 5 Aug 2017 05:44:25 GMT"}, {"version": "v5", "created": "Fri, 8 Sep 2017 04:40:18 GMT"}, {"version": "v6", "created": "Sun, 3 Dec 2017 10:57:40 GMT"}, {"version": "v7", "created": "Mon, 11 Dec 2017 00:59:00 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Wang", "Huajin", ""], ["Li", "Jianhui", ""], ["Shen", "Zhihong", ""], ["Zhou", "Yuanchun", ""]]}, {"id": "1707.09450", "submitter": "Yunsung Kim", "authors": "Yunsung Kim, Guilherme Cox, Martha A. Kim, Abhishek Bhattacharjee", "title": "Address Translation Design Tradeoffs for Heterogeneous Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a broad, pathfinding design space exploration of memory\nmanagement units (MMUs) for heterogeneous systems. We consider a variety of\ndesigns, ranging from accelerators tightly coupled with CPUs (and using their\nMMUs) to fully independent accelerators that have their own MMUs. We find that\nregardless of the CPU-accelerator communication, accelerators should not rely\non the CPU MMU for any aspect of address translation, and instead must have its\nown, local, fully-fledged MMU. That MMU, however, can and should be as\napplication-specific as the accelerator itself, as our data indicates that even\na 100% hit rate in a small, standard L1 Translation Lookaside Buffer (TLB)\npresents a substantial accelerator performance overhead. Furthermore, we\nisolate the benefits of individual MMU components (e.g., TLBs versus page table\nwalkers) and discover that their relative performance, area, and energy are\nworkload dependent, with their interplay resulting in different area-optimal\nand energy-optimal configurations.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 02:12:36 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Kim", "Yunsung", ""], ["Cox", "Guilherme", ""], ["Kim", "Martha A.", ""], ["Bhattacharjee", "Abhishek", ""]]}, {"id": "1707.09642", "submitter": "Stefano Conoci", "authors": "Stefano Conoci, Pierangelo Di Sanzo, Bruno Ciciani, Francesco Quaglia", "title": "Adaptive Performance Optimization under Power Constraint in Multi-thread\n  Applications with Diverse Scalability", "comments": "11 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern data centers, energy usage represents one of the major factors\naffecting operational costs. Power capping is a technique that limits the power\nconsumption of individual systems, which allows reducing the overall power\ndemand at both cluster and data center levels. However, literature power\ncapping approaches do not fit well the nature of important applications based\non first-class multi-thread technology. For these applications performance may\nnot grow linearly as a function of the thread-level parallelism because of the\nneed for thread synchronization while accessing shared resources, such as\nshared data. In this paper we consider the problem of maximizing the\napplication performance under a power cap by dynamically tuning the\nthread-level parallelism and the power state of the CPU-cores. Based on\nexperimental observations, we design an adaptive technique that selects in\nlinear time the optimal combination of thread-level parallelism and CPU-core\npower state for the specific workload profile of the multi-threaded\napplication. We evaluate our proposal by relying on different benchmarks,\nconfigured to use different thread synchronization methods, and compare its\neffectiveness to different state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jul 2017 17:19:26 GMT"}, {"version": "v2", "created": "Sun, 3 Sep 2017 16:53:21 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Conoci", "Stefano", ""], ["Di Sanzo", "Pierangelo", ""], ["Ciciani", "Bruno", ""], ["Quaglia", "Francesco", ""]]}]