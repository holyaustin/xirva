[{"id": "1901.00375", "submitter": "Laurent Decreusefond", "authors": "Ana\\\"is Vergne (LTCI), Laurent Decreusefond (LTCI), Philippe Martins\n  (LTCI)", "title": "Computing the $k$-coverage of a wireless network", "comments": "Valuetools 2019, Mar 2019, Palma de Mallorca, Spain. 2019. arXiv\n  admin note: text overlap with arXiv:1802.08442", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coverage is one of the main quality of service of a wirelessnetwork.\n$k$-coverage, that is to be covered simultaneously by $k$network nodes, is\nsynonym of reliability and numerous applicationssuch as multiple site MIMO\nfeatures, or handovers. We introduce here anew algorithm for computing the\n$k$-coverage of a wirelessnetwork. Our method is based on the observation that\n$k$-coverage canbe interpreted as $k$ layers of $1$-coverage, or simply\ncoverage. Weuse simplicial homology to compute the network's topology and\nareduction algorithm to indentify the layers of $1$-coverage. Weprovide figures\nand simulation results to illustrate our algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 17:52:53 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Vergne", "Ana\u00efs", "", "LTCI"], ["Decreusefond", "Laurent", "", "LTCI"], ["Martins", "Philippe", "", "LTCI"]]}, {"id": "1901.00416", "submitter": "Syed Waqar Nabi Dr", "authors": "Wim Vanderbauwhede and Syed Waqar Nabi", "title": "Towards Automatic Transformation of Legacy Scientific Code into OpenCL\n  for Optimal Performance on FPGAs", "comments": "Presented: HLPGPU at HiPEAC 2018 (Manchester, UK). arXiv admin note:\n  text overlap with arXiv:1711.04471", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a large body of legacy scientific code written in languages like\nFortran that is not optimised to get the best performance out of heterogeneous\nacceleration devices like GPUs and FPGAs, and manually porting such code into\nparallel languages frameworks like OpenCL requires considerable effort. We are\nworking towards developing a turn-key, self-optimising compiler for\naccelerating scientific applications, that can automatically transform legacy\ncode into a solution for heterogeneous targets. In this paper we focus on FPGAs\nas the acceleration devices, and carry out our discussion in the context of the\nOpenCL programming framework. We show a route to automatic creation of kernels\nwhich are optimised for execution in a \"streaming\" fashion, which gives optimal\nperformance on FPGAs. We use a 2D shallow-water model as an illustration;\nspecifically we show how the use of \\emph{channels} to communicate directly\nbetween peer kernels and the use of on-chip memory to create stencil buffers\ncan lead to significant performance improvements. Our results show better FPGA\nperformance against a baseline CPU implementation, and better energy-efficiency\nagainst both CPU and GPU implementations.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 12:52:52 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 13:30:29 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Vanderbauwhede", "Wim", ""], ["Nabi", "Syed Waqar", ""]]}, {"id": "1901.00826", "submitter": "Zhongdong Liu", "authors": "Zhongdong Liu, Bo Ji", "title": "Towards the Tradeoff Between Service Performance and Information\n  Freshness", "comments": "Submitted to 2019 IEEE International Conference on Communications\n  (ICC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed an unprecedented growth in the demand for\ndata-driven real-time services. These services are fueled by emerging\napplications that require rapidly injecting data streams and computing updated\nanalytics results in real-time. In many of such applications, the computing\nresources are often shared for processing both updates from information sources\nand queries from end users. This requires joint scheduling of updates and\nqueries because the service provider needs to make a critical decision upon\nreceiving a user query: either it responds immediately with currently available\nbut possibly stale information, or it first processes new updates and then\nresponds with fresher information. Hence, the tradeoff between service\nperformance and information freshness naturally arises in this context. To that\nend, we propose a simple single-server two-queue model that captures the\ncoupled scheduling of updates and queries and aim to design scheduling policies\nthat can properly address the important tradeoff between performance and\nfreshness. Specifically, we consider the response time as a performance metric\nand the Age of Information (AoI) as a freshness metric. After demonstrating the\nlimitations of the simplest FCFS policy, we propose two threshold-based\npolicies: the Query-k policy that prioritizes queries and the Update-k policy\nthat prioritizes updates. Then, we rigorously analyze both the response time\nand the Peak AoI (PAoI) of the threshold-based policies. Further, we propose\nthe Joint-(M,N) policy, which allows flexibly prioritizing updates or queries\nthrough choosing different values of two thresholds M and N. Finally, we\nconduct simulations to evaluate the response time and the PAoI of the proposed\npolicies. The results show that our proposed threshold-based policies can\neffectively control the balance between performance and freshness.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 17:28:51 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 21:42:00 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Liu", "Zhongdong", ""], ["Ji", "Bo", ""]]}, {"id": "1901.02414", "submitter": "Nitish K Panigrahy", "authors": "Nitish K. Panigrahy, Prithwish Basu, Philippe Nain, Don Towsley,\n  Ananthram Swami, Kevin S. Chan and Kin K. Leung", "title": "Resource Allocation in One-dimensional Distributed Service Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider assignment policies that allocate resources to users, where both\nresources and users are located on a one-dimensional line. First, we consider\nunidirectional assignment policies that allocate resources only to users\nlocated to their left. We propose the Move to Right (MTR) policy, which scans\nfrom left to right assigning nearest rightmost available resource to a user,\nand contrast it to the Unidirectional Gale-Shapley (UGS) matching policy. While\nboth these policies are optimal among all unidirectional policies, we show that\nthey are equivalent with respect to the expected distance traveled by a request\n(request distance), although MTR is fairer. Moreover, we show that when user\nand resource locations are modeled by statistical point processes, and\nresources are allowed to satisfy more than one user, the spatial system under\nunidirectional policies can be mapped into bulk service queuing systems, thus\nallowing the application of a plethora of queuing theory results that yield\nclosed form expressions. As we consider a case where different resources can\nsatisfy different numbers of users, we also generate new results for bulk\nservice queues. We also consider bidirectional policies where there are no\ndirectional restrictions on resource allocation and develop an algorithm for\ncomputing the optimal assignment which is more efficient than known algorithms\nin the literature when there are more resources than users. Finally, numerical\nevaluation of performance of unidirectional and bidirectional allocation\nschemes yields design guidelines beneficial for resource placement.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 17:23:17 GMT"}, {"version": "v2", "created": "Sat, 9 Mar 2019 17:04:19 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 00:29:05 GMT"}, {"version": "v4", "created": "Tue, 11 Feb 2020 23:04:08 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Panigrahy", "Nitish K.", ""], ["Basu", "Prithwish", ""], ["Nain", "Philippe", ""], ["Towsley", "Don", ""], ["Swami", "Ananthram", ""], ["Chan", "Kevin S.", ""], ["Leung", "Kin K.", ""]]}, {"id": "1901.02926", "submitter": "Mark Hill", "authors": "Mark D. Hill", "title": "Three Other Models of Computer System Performance", "comments": "4 pages + references; 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note argues for more use of simple models beyond Amdahl's Law:\nBottleneck Analysis, Little's Law, and a M/M/1 Queue.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 20:47:20 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Hill", "Mark D.", ""]]}, {"id": "1901.03371", "submitter": "Quan-Lin Li", "authors": "Jing-Yu Ma, Quan-Lin Li, Li Xia", "title": "Optimal Asynchronous Dynamic Policies in Energy-Efficient Data Centers", "comments": "63 pages, 6 figures. arXiv admin note: substantial text overlap with\n  arXiv:1808.07905", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use a Markov decision process to find optimal asynchronous\npolicy of an energy-efficient data center with two groups of heterogeneous\nservers, a finite buffer, and a fast setup process at sleep state. Servers in\nGroup 1 always work. Servers in Group 2 may either work or sleep, and a fast\nsetup process occurs when server's states are changed from sleep to work. In\nsuch a data center, an asynchronous dynamic policy is designed as two\nsub-policies: The setup policy and the sleep policy, which determine the switch\nrule between the work and sleep states for the servers in Group 2. To analyze\nthe optimal asynchronous dynamic policy, we apply the Markov decision process\nto establish a policy-based Poisson equation, which provides expression for the\nunique solution of the performance potential by means of the RG-factorization.\nBased on this, we can characterize the monotonicity and optimality of the\nlong-run average profit of the data center with respect to the asynchronous\ndynamic policy under different service prices. Furthermore, we prove that the\nbang-bang control is always optimal for this optimization problem, and supports\na threshold-type dynamic control in the energy-efficient data center. We hope\nthat the methodology and results derived in this paper can shed light to the\nstudy of more general energy-efficient data centers.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 11:56:18 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Ma", "Jing-Yu", ""], ["Li", "Quan-Lin", ""], ["Xia", "Li", ""]]}, {"id": "1901.03393", "submitter": "Steven Weber", "authors": "Jonathan Stokes and Steven Weber", "title": "Star sampling with and without replacement", "comments": "Superseded by arXiv:1910.00431", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Star sampling (SS) is a random sampling procedure on a graph wherein each\nsample consists of a randomly selected vertex (the star center) and its one-hop\nneighbors (the star endpoints). We consider the use of star sampling to find\nany member of an arbitrary target set of vertices in a graph, where the figure\nof merit (cost) is either the expected number of samples (unit cost) or the\nexpected number of star centers plus star endpoints (linear cost) until a\nvertex in the target set is encountered, either as a star center or as a star\npoint. We analyze this performance measure on three related star sampling\nparadigms: SS with replacement (SSR), SS without center replacement (SSC), and\nSS without star replacement (SSS). We derive exact and approximate expressions\nfor the expected unit and linear costs of SSR, SSC, and SSS on Erdos-Renyi (ER)\ngraphs. Our results show there is i) little difference in unit cost, but ii)\nsignificant difference in linear cost, across the three paradigms. Although our\nresults are derived for ER graphs, experiments on \"real-world\" graphs suggest\nour performance expressions are reasonably accurate for non-ER graphs.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 21:16:56 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 22:07:21 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 18:02:31 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Stokes", "Jonathan", ""], ["Weber", "Steven", ""]]}, {"id": "1901.03401", "submitter": "Justin Meza", "authors": "Justin Meza", "title": "Large Scale Studies of Memory, Storage, and Network Failures in a Modern\n  Data Center", "comments": "PhD thesis, CMU (Dec 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workloads running in the modern data centers of large scale Internet\nservice providers (such as Amazon, Baidu, Facebook, Google, and Microsoft)\nsupport billions of users and span globally distributed infrastructure. Yet,\nthe devices used in modern data centers fail due to a variety of causes, from\nfaulty components to bugs to misconfiguration. Faulty devices make operating\nlarge scale data centers challenging because the workloads running in modern\ndata centers consist of interdependent programs distributed across many\nservers, so failures that are isolated to a single device can still have a\nwidespread effect on a workload. In this dissertation, we measure and model the\ndevice failures in a large scale Internet service company, Facebook. We focus\non three device types that form the foundation of Internet service data center\ninfrastructure: DRAM for main memory, SSDs for persistent storage, and switches\nand backbone links for network connectivity. For each of these device types, we\nanalyze long term device failure data broken down by important device\nattributes and operating conditions, such as age, vendor, and workload. We also\nbuild and release statistical models to examine the failure trends for the\ndevices we analyze. Our key conclusion in this dissertation is that we can gain\na deep understanding of why devices fail---and how to predict their\nfailure---using measurement and modeling. We hope that the analysis,\ntechniques, and models we present in this dissertation will enable the\ncommunity to better measure, understand, and prepare for the hardware\nreliability challenges we face in the future.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 01:43:38 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Meza", "Justin", ""]]}, {"id": "1901.04047", "submitter": "Ali Yekkehkhany", "authors": "Ali Yekkehkhany and Rakesh Nagi", "title": "Blind GB-PANDAS: A Blind Throughput-Optimal Load Balancing Algorithm for\n  Affinity Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic affinity load balancing of multi-type tasks on multi-skilled servers,\nwhen the service rate of each task type on each of the servers is known and can\npossibly be different from each other, is an open problem for over three\ndecades. The goal is to do task assignment on servers in a real time manner so\nthat the system becomes stable, which means that the queue lengths do not\ndiverge to infinity in steady state (throughput optimality), and the mean task\ncompletion time is minimized (delay optimality). The fluid model planning,\nMax-Weight, and c-$\\mu$-rule algorithms have theoretical guarantees on\noptimality in some aspects for the affinity problem, but they consider a\ncomplicated queueing structure and either require the task arrival rates, the\nservice rates of tasks on servers, or both. In many cases that are discussed in\nthe introduction section, both task arrival rates and service rates of\ndifferent task types on different servers are unknown. In this work, the Blind\nGB-PANDAS algorithm is proposed which is completely blind to task arrival rates\nand service rates. Blind GB-PANDAS uses an exploration-exploitation approach\nfor load balancing. We prove that Blind GB-PANDAS is throughput optimal under\narbitrary and unknown distributions for service times of different task types\non different servers and unknown task arrival rates. Blind GB-PANDAS desires to\nroute an incoming task to the server with the minimum weighted-workload, but\nsince the service rates are unknown, such routing of incoming tasks is not\nguaranteed which makes the throughput optimality analysis more complicated than\nthe case where service rates are known. Our extensive experimental results\nreveal that Blind GB-PANDAS significantly outperforms existing methods in terms\nof mean task completion time at high loads.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 19:51:33 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 01:20:46 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Yekkehkhany", "Ali", ""], ["Nagi", "Rakesh", ""]]}, {"id": "1901.04891", "submitter": "Fengjiao Li", "authors": "Fengjiao Li, Jia Liu, Bo Ji", "title": "Combinatorial Sleeping Bandits with Fairness Constraints", "comments": "Fixed one minor mistake in the proofs, which impacts the constant\n  $\\beta_2$ in Theorem 2 only; Updated the reference by adding several highly\n  relevant papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit (MAB) model has been widely adopted for studying many\npractical optimization problems (network resource allocation, ad placement,\ncrowdsourcing, etc.) with unknown parameters. The goal of the player here is to\nmaximize the cumulative reward in the face of uncertainty. However, the basic\nMAB model neglects several important factors of the system in many real-world\napplications, where multiple arms can be simultaneously played and an arm could\nsometimes be \"sleeping\". Besides, ensuring fairness is also a key design\nconcern in practice. To that end, we propose a new Combinatorial Sleeping MAB\nmodel with Fairness constraints, called CSMAB-F, aiming to address the\naforementioned crucial modeling issues. The objective is now to maximize the\nreward while satisfying the fairness requirement of a minimum selection\nfraction for each individual arm. To tackle this new problem, we extend an\nonline learning algorithm, UCB, to deal with a critical tradeoff between\nexploitation and exploration and employ the virtual queue technique to properly\nhandle the fairness constraints. By carefully integrating these two techniques,\nwe develop a new algorithm, called Learning with Fairness Guarantee (LFG), for\nthe CSMAB-F problem. Further, we rigorously prove that not only LFG is\nfeasibility-optimal, but it also has a time-average regret upper bounded by\n$\\frac{N}{2\\eta}+\\frac{\\beta_1\\sqrt{mNT\\log{T}}+\\beta_2 N}{T}$, where N is the\ntotal number of arms, m is the maximum number of arms that can be\nsimultaneously played, T is the time horizon, $\\beta_1$ and $\\beta_2$ are\nconstants, and $\\eta$ is a design parameter that we can tune. Finally, we\nperform extensive simulations to corroborate the effectiveness of the proposed\nalgorithm. Interestingly, the simulation results reveal an important tradeoff\nbetween the regret and the speed of convergence to a point satisfying the\nfairness constraints.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 15:52:22 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 15:26:50 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 18:06:06 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Li", "Fengjiao", ""], ["Liu", "Jia", ""], ["Ji", "Bo", ""]]}, {"id": "1901.04982", "submitter": "Mathias Gottschlag", "authors": "Mathias Gottschlag, Frank Bellosa", "title": "Mechanism to Mitigate AVX-Induced Frequency Reduction", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Intel CPUs reduce their frequency when executing wide vector\noperations (AVX2 and AVX-512 instructions), as these instructions increase\npower consumption. The frequency is only increased again two milliseconds after\nthe last code section containing such instructions has been executed in order\nto prevent excessive numbers of frequency changes. Due to this delay,\nintermittent use of wide vector operations can slow down the rest of the system\nsignificantly. For example, previous work has shown the performance of web\nservers to be reduced by up to 10% if the SSL library uses AVX-512 vector\ninstructions. These performance variations are hard to predict during software\ndevelopment as the performance impact of vectorization depends on the specific\nworkload.\n  We describe a mechanism to reduce the slowdown caused by wide vector\ninstructions without requiring extensive changes to existing software. Our\ndesign allows the developer to mark problematic AVX code regions. The scheduler\nthen restricts execution of this code to a subset of the cores so that only\nthese cores' frequency is affected. Threads are automatically migrated to a\nsuitable core whenever necessary. We identify a suitable load balancing policy\nto ensure good utilization of all available cores. Our approach is able to\nreduce the performance variability caused by AVX2 and AVX-512 instructions by\nover 70%.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 11:57:48 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Gottschlag", "Mathias", ""], ["Bellosa", "Frank", ""]]}, {"id": "1901.05344", "submitter": "Georg Hager", "authors": "Francesco Cremonesi, Georg Hager, Gerhard Wellein, Felix Sch\\\"urmann", "title": "Analytic Performance Modeling and Analysis of Detailed Neuron\n  Simulations", "comments": "18 pages, 6 figures, 15 tables", "journal-ref": null, "doi": "10.1177/1094342020912528", "report-no": null, "categories": "cs.PF cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big science initiatives are trying to reconstruct and model the brain by\nattempting to simulate brain tissue at larger scales and with increasingly more\nbiological detail than previously thought possible. The exponential growth of\nparallel computer performance has been supporting these developments, and at\nthe same time maintainers of neuroscientific simulation code have strived to\noptimally and efficiently exploit new hardware features. Current state of the\nart software for the simulation of biological networks has so far been\ndeveloped using performance engineering practices, but a thorough analysis and\nmodeling of the computational and performance characteristics, especially in\nthe case of morphologically detailed neuron simulations, is lacking. Other\ncomputational sciences have successfully used analytic performance engineering\nand modeling methods to gain insight on the computational properties of\nsimulation kernels, aid developers in performance optimizations and eventually\ndrive co-design efforts, but to our knowledge a model-based performance\nanalysis of neuron simulations has not yet been conducted.\n  We present a detailed study of the shared-memory performance of\nmorphologically detailed neuron simulations based on the Execution-Cache-Memory\n(ECM) performance model. We demonstrate that this model can deliver accurate\npredictions of the runtime of almost all the kernels that constitute the neuron\nmodels under investigation. The gained insight is used to identify the main\ngoverning mechanisms underlying performance bottlenecks in the simulation. The\nimplications of this analysis on the optimization of neural simulation software\nand eventually co-design of future hardware architectures are discussed. In\nthis sense, our work represents a valuable conceptual and quantitative\ncontribution to understanding the performance properties of biological networks\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 15:28:06 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Cremonesi", "Francesco", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""], ["Sch\u00fcrmann", "Felix", ""]]}, {"id": "1901.05836", "submitter": "Luisa D'Amore", "authors": "Luisa D'Amore, Valeria Mele, Diego Romano and Giuliano Laccetti", "title": "A Multilevel Approach for the Performance Analysis of Parallel\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a multilevel approach for analysing performances of parallel\nalgorithms. The main outcome of such approach is that the algorithm is\ndescribed by using a set of operators which are related to each other according\nto the problem decomposition. Decomposition level determines the granularity of\nthe algorithm. A set of block matrices (decomposition and execution) highlights\nfundamental characteristics of the algorithm, such as inherent parallelism and\nsources of overheads.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 17:18:26 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["D'Amore", "Luisa", ""], ["Mele", "Valeria", ""], ["Romano", "Diego", ""], ["Laccetti", "Giuliano", ""]]}, {"id": "1901.06786", "submitter": "Gayane Vardoyan", "authors": "Gayane Vardoyan, Saikat Guha, Philippe Nain, Don Towsley", "title": "On the Capacity Region of Bipartite and Tripartite Entanglement\n  Switching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a quantum switch serving a set of users. The function of the switch\nis to create bi- or tripartite entangled state among users at the highest\npossible rates at a fixed ratio. We model a set of randomized switching\npolicies. Discovering that some are better than others, we present analytical\nresults for the case where the switch stores one qubit per user, and find that\nthe best policies outperform a time division multiplexing (TDM) policy for\nsharing the switch between bipartite and tripartite state generation. This\nperformance improvement decreases as the number of users grows. The model is\neasily augmented to study the capacity region in the presence of qubit\ndecoherence, obtaining similar results. Moreover, decoherence appears to have\nlittle effect on capacity. We also study a smaller class of policies when the\nswitch stores two qubits per user.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 04:06:43 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 02:19:08 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 16:10:35 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Vardoyan", "Gayane", ""], ["Guha", "Saikat", ""], ["Nain", "Philippe", ""], ["Towsley", "Don", ""]]}, {"id": "1901.08627", "submitter": "Gabor Horvath", "authors": "Gabor Horvath and Illes Horvath and Miklos Telek", "title": "High order concentrated non-negative matrix-exponential functions", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly concentrated functions play an important role in many research fields\nincluding control system analysis and physics, and they turned out to be the\nkey idea behind inverse Laplace transform methods as well.\n  This paper uses the matrix-exponential family of functions to create highly\nconcentrated functions, whose squared coefficient of variation (SCV) is very\nlow. In the field of stochastic modeling, matrix-exponential functions have\nbeen used for decades. They have many advantages: they are easy to manipulate,\nalways non-negative, and integrals involving matrix-exponential functions often\nhave closed-form solutions. For the time being there is no symbolic\nconstruction available to obtain the most concentrated matrix-exponential\nfunctions, and the numerical optimization-based approach has many pitfalls,\ntoo.\n  In this paper, we present a numerical optimization-based procedure to\nconstruct highly concentrated matrix-exponential functions. To make the\nobjective function explicit and easy to evaluate we introduce and use a new\nrepresentation called hyper-trigonometric representation. This representation\nmakes it possible to achieve very low SCV.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 14:49:52 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Horvath", "Gabor", ""], ["Horvath", "Illes", ""], ["Telek", "Miklos", ""]]}, {"id": "1901.09094", "submitter": "Dengwang Tang", "authors": "Dengwang Tang, Vijay G. Subramanian", "title": "Derandomized Load Balancing using Random Walks on Expander Graphs", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NI cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a computing center with a huge amount of machines, when a job arrives, a\ndispatcher need to decide which machine to route this job to based on limited\ninformation. A classical method, called the power-of-$d$ choices algorithm is\nto pick $d$ servers independently at random and dispatch the job to the least\nloaded server among the $d$ servers. In this paper, we analyze a low-randomness\nvariant of this dispatching scheme, where $d$ queues are sampled through $d$\nindependent non-backtracking random walks on a $k$-regular graph $G$. Under\ncertain assumptions of the graph $G$ we show that under this scheme, the\ndynamics of the queuing system converges to the same deterministic ordinary\ndifferential equation (ODE) for the power-of-$d$ choices scheme. We also show\nthat the system is stable under the proposed scheme, and the stationary\ndistribution of the system converges to the fixed point of the ODE.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 02:31:23 GMT"}, {"version": "v2", "created": "Sun, 21 Apr 2019 16:58:35 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Tang", "Dengwang", ""], ["Subramanian", "Vijay G.", ""]]}, {"id": "1901.09161", "submitter": "Minghua Chen", "authors": "Qiulin Lin and Hanling Yi and John Pang and Minghua Chen and Adam\n  Wierman and Michael Honig and Yuanzhang Xiao", "title": "Competitive Online Optimization under Inventory Constraints", "comments": "The first two authors contribute to the work equally. Manuscript\n  submitted October 22, 2018; accepted December 17, 2018; to appear in ACM\n  SIGMETRICS 2019", "journal-ref": "Proceedings of the ACM on Measurement and Analysis of Computing\n  Systems (for publishing papers of ACM SIGMETRICS), 2019", "doi": null, "report-no": null, "categories": "cs.PF cs.DS cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies online optimization under inventory (budget) constraints.\nWhile online optimization is a well-studied topic, versions with inventory\nconstraints have proven difficult. We consider a formulation of\ninventory-constrained optimization that is a generalization of the classic\none-way trading problem and has a wide range of applications. We present a new\nalgorithmic framework, \\textsf{CR-Pursuit}, and prove that it achieves the\nminimal competitive ratio among all deterministic algorithms (up to a\nproblem-dependent constant factor) for inventory-constrained online\noptimization. Our algorithm and its analysis not only simplify and unify the\nstate-of-the-art results for the standard one-way trading problem, but they\nalso establish novel bounds for generalizations including concave revenue\nfunctions. For example, for one-way trading with price elasticity, the\n\\textsf{CR-Pursuit} algorithm achieves a competitive ratio that is within a\nsmall additive constant (i.e., 1/3) to the lower bound of $\\ln \\theta+1$, where\n$\\theta$ is the ratio between the maximum and minimum base prices.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 04:45:01 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Lin", "Qiulin", ""], ["Yi", "Hanling", ""], ["Pang", "John", ""], ["Chen", "Minghua", ""], ["Wierman", "Adam", ""], ["Honig", "Michael", ""], ["Xiao", "Yuanzhang", ""]]}, {"id": "1901.09842", "submitter": "George Kesidis", "authors": "George Kesidis", "title": "Overbooking Microservices in the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of scheduling serverless-computing instances such as\nAmazon Lambda functions, or scheduling microservices within (privately held)\nvirtual machines (VMs). Instead of a quota per tenant/customer, we assume\ndemand for Lambda functions is modulated by token-bucket mechanisms per tenant.\nSuch quotas are due to, e.g., limited resources (as in a fog/edge-cloud\ncontext) or to prevent excessive unauthorized invocation of numerous instances\nby malware. Based on an upper bound on the stationary number of active \"Lambda\nservers\" considering the execution-time distribution of Lambda functions, we\ndescribe an approach that the cloud could use to overbook Lambda functions for\nimproved utilization of IT resources. An earlier bound for a single service\ntier is extended to multiple service tiers. For the context of scheduling\nmicroservices in a private setting, the framework could be used to determine\nthe required VM resources for a token-bucket constrained workload stream.\nFinally, we note that the looser Markov inequality may be useful in settings\nwhere the job service times are dependent.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:36:06 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 02:41:36 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Kesidis", "George", ""]]}, {"id": "1901.09942", "submitter": "Nadi Sarrar", "authors": "Nadi Sarrar", "title": "On transaction parallelizability in Ethereum", "comments": "2 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.PF", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Ethereum clients execute transactions in a sequential order prescribed by the\nconsensus protocol. This is a safe and conservative approach to blockchain\ntransaction processing which forgoes running transactions in parallel even when\ndoing so would be beneficial and safe, e.g., when there is no intersection in\nthe sets of accounts that the transactions read or modify. In this work we\nstudy the degree of transaction parallelizability and present results from\nthree different simulations using real Ethereum transaction data. Our\nsimulations demonstrate that notable gains are achievable with parallelization,\nand suggest that the potential for parallelizability improves as transaction\nrates increase.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:02:44 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 13:40:45 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Sarrar", "Nadi", ""]]}, {"id": "1901.10183", "submitter": "Tal Ben-Nun", "authors": "Tal Ben-Nun, Maciej Besta, Simon Huber, Alexandros Nikolaos Ziogas,\n  Daniel Peter, Torsten Hoefler", "title": "A Modular Benchmarking Infrastructure for High-Performance and\n  Reproducible Deep Learning", "comments": "Accepted to IPDPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Deep500: the first customizable benchmarking infrastructure that\nenables fair comparison of the plethora of deep learning frameworks,\nalgorithms, libraries, and techniques. The key idea behind Deep500 is its\nmodular design, where deep learning is factorized into four distinct levels:\noperators, network processing, training, and distributed training. Our\nevaluation illustrates that Deep500 is customizable (enables combining and\nbenchmarking different deep learning codes) and fair (uses carefully selected\nmetrics). Moreover, Deep500 is fast (incurs negligible overheads), verifiable\n(offers infrastructure to analyze correctness), and reproducible. Finally, as\nthe first distributed and reproducible benchmarking system for deep learning,\nDeep500 provides software infrastructure to utilize the most powerful\nsupercomputers for extreme-scale workloads.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 09:03:41 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 07:59:35 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ben-Nun", "Tal", ""], ["Besta", "Maciej", ""], ["Huber", "Simon", ""], ["Ziogas", "Alexandros Nikolaos", ""], ["Peter", "Daniel", ""], ["Hoefler", "Torsten", ""]]}]