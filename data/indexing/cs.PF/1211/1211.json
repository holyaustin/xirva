[{"id": "1211.0313", "submitter": "Paulo Urriza", "authors": "Paulo Urriza, Eric Rebeiz, Danijela Cabric", "title": "Multiple Antenna Cyclostationary Spectrum Sensing Based on the Cyclic\n  Correlation Significance Test", "comments": "26 pages, 8 figures, submitted to IEEE JSAC: Cognitive Radio Series.\n  arXiv admin note: substantial text overlap with arXiv:1210.8176", "journal-ref": null, "doi": "10.1109/JSAC.2013.131118", "report-no": null, "categories": "cs.PF stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and analyze a spectrum sensing method based on\ncyclostationarity specifically targeted for receivers with multiple antennas.\nThis detection method is used for determining the presence or absence of\nprimary users in cognitive radio networks based on the eigenvalues of the\ncyclic covariance matrix of received signals. In particular, the cyclic\ncorrelation significance test is used to detect a specific signal-of-interest\nby exploiting knowledge of its cyclic frequencies. Analytical expressions for\nthe probability of detection and probability of false-alarm under both\nspatially uncorrelated or spatially correlated noise are derived and verified\nby simulation. The detection performance in a Rayleigh flat-fading environment\nis found and verified through simulations. One of the advantages of the\nproposed method is that the detection threshold is shown to be independent of\nboth the number of samples and the noise covariance, effectively eliminating\nthe dependence on accurate noise estimation. The proposed method is also shown\nto provide higher detection probability and better robustness to noise\nuncertainty than existing multiple-antenna cyclostationary-based spectrum\nsensing algorithms under both AWGN as well as a quasi-static Rayleigh fading\nchannel.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 21:30:52 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Urriza", "Paulo", ""], ["Rebeiz", "Eric", ""], ["Cabric", "Danijela", ""]]}, {"id": "1211.0557", "submitter": "Eric Schkufza", "authors": "Eric Schkufza, Rahul Sharma, Alex Aiken", "title": "Stochastic Superoptimization", "comments": "To appear in ASPLOS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate the loop-free, binary superoptimization task as a stochastic\nsearch problem. The competing constraints of transformation correctness and\nperformance improvement are encoded as terms in a cost function, and a Markov\nChain Monte Carlo sampler is used to rapidly explore the space of all possible\nprograms to find one that is an optimization of a given target program.\nAlthough our method sacrifices com- pleteness, the scope of programs we are\nable to reason about, and the quality of the programs we produce, far exceed\nthose of existing superoptimizers. Beginning from binaries com- piled by llvm\n-O0 for 64-bit X86, our prototype implemen- tation, STOKE, is able to produce\nprograms which either match or outperform the code sequences produced by gcc\nwith full optimizations enabled, and, in some cases, expert handwritten\nassembly.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2012 20:23:23 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Schkufza", "Eric", ""], ["Sharma", "Rahul", ""], ["Aiken", "Alex", ""]]}, {"id": "1211.0618", "submitter": "Joel Spencer", "authors": "Joel Spencer, Madhu Sudan, Kuang Xu", "title": "Queuing with future information", "comments": "Published in at http://dx.doi.org/10.1214/13-AAP973 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 5, 2091-2142", "doi": "10.1214/13-AAP973", "report-no": "IMS-AAP-AAP973", "categories": "math.PR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an admissions control problem, where a queue with service rate $1-p$\nreceives incoming jobs at rate $\\lambda\\in(1-p,1)$, and the decision maker is\nallowed to redirect away jobs up to a rate of $p$, with the objective of\nminimizing the time-average queue length. We show that the amount of\ninformation about the future has a significant impact on system performance, in\nthe heavy-traffic regime. When the future is unknown, the optimal average queue\nlength diverges at rate $\\sim\\log_{1/(1-p)}\\frac{1}{1-\\lambda}$, as $\\lambda\\to\n1$. In sharp contrast, when all future arrival and service times are revealed\nbeforehand, the optimal average queue length converges to a finite constant,\n$(1-p)/p$, as $\\lambda\\to1$. We further show that the finite limit of $(1-p)/p$\ncan be achieved using only a finite lookahead window starting from the current\ntime frame, whose length scales as $\\mathcal{O}(\\log\\frac{1}{1-\\lambda})$, as\n$\\lambda\\to1$. This leads to the conjecture of an interesting duality between\nqueuing delay and the amount of information about the future.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2012 15:44:07 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2013 23:13:43 GMT"}, {"version": "v3", "created": "Wed, 2 Jul 2014 13:52:53 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Spencer", "Joel", ""], ["Sudan", "Madhu", ""], ["Xu", "Kuang", ""]]}, {"id": "1211.0820", "submitter": "Hwancheol Jeong", "authors": "Hwancheol Jeong, Sunghoon Kim, Weonjong Lee and Seok-Ho Myung", "title": "Performance of SSE and AVX Instruction Sets", "comments": "7 pages, 5 figures, 4 tables, Contribution to proceedings of the 30th\n  International Symposium on Lattice Field Theory (Lattice 2012), June 24-29,\n  2012", "journal-ref": "PoS (LATTICE 2012) 249", "doi": null, "report-no": null, "categories": "hep-lat cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SSE (streaming SIMD extensions) and AVX (advanced vector extensions) are SIMD\n(single instruction multiple data streams) instruction sets supported by recent\nCPUs manufactured in Intel and AMD. This SIMD programming allows parallel\nprocessing by multiple cores in a single CPU. Basic arithmetic and data\ntransfer operations such as sum, multiplication and square root can be\nprocessed simultaneously. Although popular compilers such as GNU compilers and\nIntel compilers provide automatic SIMD optimization options, one can obtain\nbetter performance by a manual SIMD programming with proper optimization: data\npacking, data reuse and asynchronous data transfer. In particular, linear\nalgebraic operations of vectors and matrices can be easily optimized by the\nSIMD programming. Typical calculations in lattice gauge theory are composed of\nlinear algebraic operations of gauge link matrices and fermion vectors, and so\ncan adopt the manual SIMD programming to improve the performance.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2012 10:39:40 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Jeong", "Hwancheol", ""], ["Kim", "Sunghoon", ""], ["Lee", "Weonjong", ""], ["Myung", "Seok-Ho", ""]]}, {"id": "1211.0906", "submitter": "Frank Hutter", "authors": "Frank Hutter, Lin Xu, Holger H. Hoos, Kevin Leyton-Brown", "title": "Algorithm Runtime Prediction: Methods & Evaluation", "comments": "51 pages, 13 figures, 8 tables. Added references, feature cost, and\n  experiments with subsets of features; reworded Sections 1&2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perhaps surprisingly, it is possible to predict how long an algorithm will\ntake to run on a previously unseen input, using machine learning techniques to\nbuild a model of the algorithm's runtime as a function of problem-specific\ninstance features. Such models have important applications to algorithm\nanalysis, portfolio-based algorithm selection, and the automatic configuration\nof parameterized algorithms. Over the past decade, a wide variety of techniques\nhave been studied for building such models. Here, we describe extensions and\nimprovements of existing models, new families of models, and -- perhaps most\nimportantly -- a much more thorough treatment of algorithm parameters as model\ninputs. We also comprehensively describe new and existing features for\npredicting algorithm runtime for propositional satisfiability (SAT), travelling\nsalesperson (TSP) and mixed integer programming (MIP) problems. We evaluate\nthese innovations through the largest empirical analysis of its kind, comparing\nto a wide range of runtime modelling techniques from the literature. Our\nexperiments consider 11 algorithms and 35 instance distributions; they also\nspan a very wide range of SAT, MIP, and TSP instances, with the least\nstructured having been generated uniformly at random and the most structured\nhaving emerged from real industrial applications. Overall, we demonstrate that\nour new models yield substantially better runtime predictions than previous\napproaches in terms of their generalization to new problem instances, to new\nalgorithms from a parameterized space, and to both simultaneously.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2012 16:15:16 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2013 09:00:50 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Hutter", "Frank", ""], ["Xu", "Lin", ""], ["Hoos", "Holger H.", ""], ["Leyton-Brown", "Kevin", ""]]}, {"id": "1211.1581", "submitter": "Volker Weinberg", "authors": "Volker Weinberg", "title": "Data-parallel programming with Intel Array Building Blocks (ArBB)", "comments": "13 pages, 7 figures, PRACE Whitepaper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intel Array Building Blocks is a high-level data-parallel programming\nenvironment designed to produce scalable and portable results on existing and\nupcoming multi- and many-core platforms.\n  We have chosen several mathematical kernels - a dense matrix-matrix\nmultiplication, a sparse matrix-vector multiplication, a 1-D complex FFT and a\nconjugate gradients solver - as synthetic benchmarks and representatives of\nscientific codes and ported them to ArBB. This whitepaper describes the ArBB\nports and presents performance and scaling measurements on the Westmere-EX\nbased system SuperMIG at LRZ in comparison with OpenMP and MKL.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 16:00:28 GMT"}], "update_date": "2012-11-08", "authors_parsed": [["Weinberg", "Volker", ""]]}, {"id": "1211.1643", "submitter": "Luca Bortolussi", "authors": "Luca Bortolussi", "title": "Hybrid Behaviour of Markov Population Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA cs.PF q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the behaviour of population models written in Stochastic\nConcurrent Constraint Programming (sCCP), a stochastic extension of Concurrent\nConstraint Programming. In particular, we focus on models from which we can\ndefine a semantics of sCCP both in terms of Continuous Time Markov Chains\n(CTMC) and in terms of Stochastic Hybrid Systems, in which some populations are\napproximated continuously, while others are kept discrete. We will prove the\ncorrectness of the hybrid semantics from the point of view of the limiting\nbehaviour of a sequence of models for increasing population size. More\nspecifically, we prove that, under suitable regularity conditions, the sequence\nof CTMC constructed from sCCP programs for increasing population size converges\nto the hybrid system constructed by means of the hybrid semantics. We\ninvestigate in particular what happens for sCCP models in which some\ntransitions are guarded by boolean predicates or in the presence of\ninstantaneous transitions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 19:30:47 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2013 09:33:54 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Bortolussi", "Luca", ""]]}, {"id": "1211.2292", "submitter": "Duy Truong", "authors": "Truong Vinh Truong Duy, Katsuhiro Yamazaki, Kosai Ikegami, and Shigeru\n  Oyanagi", "title": "Hybrid MPI-OpenMP Paradigm on SMP Clusters: MPEG-2 Encoder and N-Body\n  Simulation", "comments": "8 pages, 9 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clusters of SMP nodes provide support for a wide diversity of parallel\nprogramming paradigms. Combining both shared memory and message passing\nparallelizations within the same application, the hybrid MPI-OpenMP paradigm is\nan emerging trend for parallel programming to fully exploit distributed\nshared-memory architecture. In this paper, we improve the performance of MPEG-2\nencoder and n-body simulation by employing the hybrid MPI-OpenMP programming\nparadigm on SMP clusters. The hierarchical image data structure of the MPEG\nbit-stream is eminently suitable for the hybrid model to achieve multiple\nlevels of parallelism: MPI for parallelism at the group of pictures level\nacross SMP nodes and OpenMP for parallelism within pictures at the slice level\nwithin each SMP node. Similarly, the work load of the force calculation which\naccounts for upwards of 90% of the cycles in typical computations in the n-body\nsimulation is shared among OpenMP threads after ORB domain decomposition among\nMPI processes. Besides, loop scheduling of OpenMP threads is adopted with\nappropriate chunk size to provide better load balance of work, leading to\nenhanced performance. With the n-body simulation, experimental results\ndemonstrate that the hybrid MPI-OpenMP program outperforms the corresponding\npure MPI program by average factors of 1.52 on a 4-way cluster and 1.21 on a\n2-way cluster. Likewise, the hybrid model offers a performance improvement of\n18% compared to the MPI model for the MPEG-2 encoder.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2012 05:51:06 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Duy", "Truong Vinh Truong", ""], ["Yamazaki", "Katsuhiro", ""], ["Ikegami", "Kosai", ""], ["Oyanagi", "Shigeru", ""]]}, {"id": "1211.2293", "submitter": "Duy Truong", "authors": "Truong Vinh Truong Duy, Katsuhiro Yamazaki, and Shigeru Oyanagi", "title": "Performance Evaluation of Treecode Algorithm for N-Body Simulation Using\n  GridRPC System", "comments": "4 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is aimed at improving the performance of the treecode algorithm\nfor N-Body simulation by employing the NetSolve GridRPC programming model to\nexploit the use of multiple clusters. N-Body is a classical problem, and\nappears in many areas of science and engineering, including astrophysics,\nmolecular dynamics, and graphics. In the simulation of N-Body, the specific\nroutine for calculating the forces on the bodies which accounts for upwards of\n90% of the cycles in typical computations is eminently suitable for obtaining\nparallelism with GridRPC calls. It is divided among the compute nodes by\nsimultaneously calling multiple GridRPC requests to them. The performance of\nthe GridRPC implementation is then compared to that of the MPI version and\nhybrid MPI-OpenMP version for the treecode algorithm on individual clusters.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2012 06:08:36 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Duy", "Truong Vinh Truong", ""], ["Yamazaki", "Katsuhiro", ""], ["Oyanagi", "Shigeru", ""]]}, {"id": "1211.3250", "submitter": "Katia  Jaffres-Runser", "authors": "Qi Wang, Katia Jaffr\\`es-Runser, Claire Goursaud and Jean-Marie Gorce", "title": "Deriving Pareto-optimal performance bounds for 1 and 2-relay wireless\n  networks", "comments": "Shorter version submitted to ICC 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of deriving fundamental trade-off bounds for\na 1-relay and a 2-relay wireless network when multiple performance criteria are\nof interest. It proposes a simple MultiObjective (MO) performance evaluation\nframework composed of a broadcast and interference-limited network model;\ncapacity, delay and energy performance metrics and an associated MO\noptimization problem. Pareto optimal performance bounds between end-to-end\ndelay and energy for a capacity-achieving network are given for 1-relay and\n2-relay topologies and assessed through simulations. Moreover, we also show in\nthis paper that these bounds are tight since they can be reached by simple\npractical coding strategies performed by the source and the relays. Two\ndifferent types of network coding strategies are investigated. Practical\nperformance bounds for both strategies are compared to the theoretical upper\nbound. Results confirm that the proposed upper bound on delay and energy\nperformance is tight and can be reached with the proposed combined source and\nnetwork coding strategies.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2012 09:38:24 GMT"}], "update_date": "2012-11-15", "authors_parsed": [["Wang", "Qi", ""], ["Jaffr\u00e8s-Runser", "Katia", ""], ["Goursaud", "Claire", ""], ["Gorce", "Jean-Marie", ""]]}, {"id": "1211.4864", "submitter": "Salman Habib", "authors": "Salman Habib, Vitali Morozov, Hal Finkel, Adrian Pope, Katrin\n  Heitmann, Kalyan Kumaran, Tom Peterka, Joe Insley, David Daniel, Patricia\n  Fasel, Nicholas Frontiere, and Zarija Lukic", "title": "The Universe at Extreme Scale: Multi-Petaflop Sky Simulation on the BG/Q", "comments": "11 pages, 11 figures, final version of paper for talk presented at\n  SC12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.CO astro-ph.IM cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remarkable observational advances have established a compelling\ncross-validated model of the Universe. Yet, two key pillars of this model --\ndark matter and dark energy -- remain mysterious. Sky surveys that map billions\nof galaxies to explore the `Dark Universe', demand a corresponding\nextreme-scale simulation capability; the HACC (Hybrid/Hardware Accelerated\nCosmology Code) framework has been designed to deliver this level of\nperformance now, and into the future. With its novel algorithmic structure,\nHACC allows flexible tuning across diverse architectures, including accelerated\nand multi-core systems.\n  On the IBM BG/Q, HACC attains unprecedented scalable performance -- currently\n13.94 PFlops at 69.2% of peak and 90% parallel efficiency on 1,572,864 cores\nwith an equal number of MPI ranks, and a concurrency of 6.3 million. This level\nof performance was achieved at extreme problem sizes, including a benchmark run\nwith more than 3.6 trillion particles, significantly larger than any\ncosmological simulation yet performed.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 23:23:22 GMT"}], "update_date": "2012-11-28", "authors_parsed": [["Habib", "Salman", ""], ["Morozov", "Vitali", ""], ["Finkel", "Hal", ""], ["Pope", "Adrian", ""], ["Heitmann", "Katrin", ""], ["Kumaran", "Kalyan", ""], ["Peterka", "Tom", ""], ["Insley", "Joe", ""], ["Daniel", "David", ""], ["Fasel", "Patricia", ""], ["Frontiere", "Nicholas", ""], ["Lukic", "Zarija", ""]]}, {"id": "1211.5736", "submitter": "Mohamed Kaaniche", "authors": "Giovanna Dondossola, Geert Deconinck, Felicita Di Giandomenico (ISTI),\n  Susanna Donatelli, Mohamed Kaaniche (LAAS), Paulo Verissimo", "title": "Critical Utility Infrastructural Resilience", "comments": null, "journal-ref": "International Workshop on Complex Network and Infrastructure\n  Protection (CNIP-06), Rome : Italy (2006)", "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper refers to CRUTIAL, CRitical UTility InfrastructurAL Resilience, a\nEuropean project within the research area of Critical Information\nInfrastructure Protection, with a specific focus on the infrastructures\noperated by power utilities, widely recognized as fundamental to national and\ninternational economy, security and quality of life. Such infrastructures faced\nwith the recent market deregulations and the multiple interdependencies with\nother infrastructures are becoming more and more vulnerable to various threats,\nincluding accidental failures and deliberate sabotage and malicious attacks.\nThe subject of CRUTIAL research are small scale networked ICT systems used to\ncontrol and manage the electric power grid, in which artifacts controlling the\nphysical process of electricity transportation need to be connected with\ncorporate and societal applications performing management and maintenance\nfunctionality. The peculiarity of such ICT-supported systems is that they are\nrelated to the power system dynamics and its emergency conditions. Specific\neffort need to be devoted by the Electric Power community and by the\nInformation Technology community to influence the technological progress in\norder to allow commercial intelligent electronic devices to be effectively\ndeployed for the protection of citizens against cyber threats to electric power\nmanagement and control systems. A well-founded know-how needs to be built\ninside the industrial power sector to allow all the involved stakeholders to\nachieve their service objectives without compromising the resilience properties\nof the logical and physical assets that support the electric power provision.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2012 07:53:55 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Dondossola", "Giovanna", "", "ISTI"], ["Deconinck", "Geert", "", "ISTI"], ["Di Giandomenico", "Felicita", "", "ISTI"], ["Donatelli", "Susanna", "", "LAAS"], ["Kaaniche", "Mohamed", "", "LAAS"], ["Verissimo", "Paulo", ""]]}, {"id": "1211.5738", "submitter": "Mohamed Kaaniche", "authors": "Mohamed Kaaniche (LAAS), Paolo Lollini (University of Florence),\n  Andrea Bondavalli (University of Florence), Karama Kanoun (LAAS)", "title": "Modeling the resilience of large and evolving systems", "comments": null, "journal-ref": "International Journal of Performability Engineering 4, 2 (2008)\n  153-168", "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes the state of knowledge and ongoing research on methods\nand techniques for resilience evaluation, taking into account the\nresilience-scaling challenges and properties related to the ubiquitous\ncomputerized systems. We mainly focus on quantitative evaluation approaches\nand, in particular, on model-based evaluation techniques that are commonly used\nto evaluate and compare, from the dependability point of view, different\narchitecture alternatives at the design stage. We outline some of the main\nmodeling techniques aiming at mastering the largeness of analytical\ndependability models at the construction level. Actually, addressing the model\nlargeness problem is important with respect to the investigation of the\nscalability of current techniques to meet the complexity challenges of\nubiquitous systems. Finally we present two case studies in which some of the\npresented techniques are applied for modeling web services and General Packet\nRadio Service (GPRS) mobile telephone networks, as prominent examples of large\nand evolving systems.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2012 07:56:54 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Kaaniche", "Mohamed", "", "LAAS"], ["Lollini", "Paolo", "", "University of Florence"], ["Bondavalli", "Andrea", "", "University of Florence"], ["Kanoun", "Karama", "", "LAAS"]]}]