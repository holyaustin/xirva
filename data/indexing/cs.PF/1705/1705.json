[{"id": "1705.01070", "submitter": "Vitali Volovoi", "authors": "Vitali Volovoi", "title": "Correcting for Non-Markovian Asymptotic Effects using Markovian\n  Representation", "comments": "Added background, convergence discussion, additional examples. 9\n  pages (double column format), 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymptotic properties of Markov Processes, such as steady state probabilities\nor hazard rate for absorbing states can be efficiently calculated by means of\nlinear algebra even for large-scale problems. This paper discusses the methods\nfor adjusting parameters of the Markov models to account for non-constant\ntransition rates. In particular, transitions with fixed delays are considered\nalong with the transitions that follow Weibull and lognormal distributions.\nProcedures for both steady-state solutions in the absence of an absorbing\nstate, and for hazard rates to an absorbing state are provided and demonstrated\non several examples.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 16:52:31 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 15:32:58 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Volovoi", "Vitali", ""]]}, {"id": "1705.01176", "submitter": "Eddie Santos", "authors": "Eddie Antonio Santos, Carson McLean, Christopher Solinas, Abram Hindle", "title": "How does Docker affect energy consumption? Evaluating workloads in and\n  out of Docker containers", "comments": "12 pages (minus references), 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Context: Virtual machines provide isolation of services at the cost of\nhypervisors and more resource usage. This spurred the growth of systems like\nDocker that enable single hosts to isolate several applications, similar to\nVMs, within a low-overhead abstraction called containers.\n  Motivation: Although containers tout low overhead performance, do they still\nhave low energy consumption?\n  Methodology: This work statistically compares ($t$-test, Wilcoxon) the energy\nconsumption of three application workloads in Docker and on bare-metal Linux.\n  Results: In all cases, there was a statistically significant ($t$-test and\nWilcoxon $p < 0.05$) increase in energy consumption when running tests in\nDocker, mostly due to the performance of I/O system calls.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 21:29:28 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Santos", "Eddie Antonio", ""], ["McLean", "Carson", ""], ["Solinas", "Christopher", ""], ["Hindle", "Abram", ""]]}, {"id": "1705.03125", "submitter": "Mohammadamir Kavousi", "authors": "Mohammadamir Kavousi", "title": "Affinity Scheduling and the Applications on Data Center Scheduling with\n  Data Locality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce framework is the de facto standard in Hadoop. Considering the data\nlocality in data centers, the load balancing problem of map tasks is a special\ncase of affinity scheduling problem. There is a huge body of work on affinity\nscheduling, proposing heuristic algorithms which try to increase data locality\nin data centers like Delay Scheduling and Quincy. However, not enough attention\nhas been put on theoretical guarantees on throughput and delay optimality of\nsuch algorithms. In this work, we present and compare different algorithms and\ndiscuss their shortcoming and strengths. To the best of our knowledge, most\ndata centers are using static load balancing algorithms which are not efficient\nin any ways and results in wasting the resources and causing unnecessary delays\nfor users.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 00:00:38 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Kavousi", "Mohammadamir", ""]]}, {"id": "1705.06102", "submitter": "George Kesidis", "authors": "George Kesidis, Yuquan Shan, Yujia Wang, Bhuvan Urgaonkar, Jalal\n  Khamse-Ashari, Ioanns Lambadaris", "title": "Scheduling Distributed Resources in Heterogeneous Private Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first consider the static problem of allocating resources to ( i.e. ,\nscheduling) multiple distributed application framework s, possibly with\ndifferent priorities and server preferences , in a private cloud with\nheterogeneous servers. Several fai r scheduling mechanisms have been proposed\nfor this purpose. We extend pr ior results on max-min and proportional fair\nscheduling to t his constrained multiresource and multiserver case for generi c\nfair scheduling criteria. The task efficiencies (a metric r elated to\nproportional fairness) of max-min fair allocations found b y progressive\nfilling are compared by illustrative examples . They show that \"server\nspecific\" fairness criteria and those that are b ased on residual (unreserved)\nresources are more efficient.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 11:43:08 GMT"}, {"version": "v2", "created": "Mon, 29 May 2017 14:12:19 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 14:48:20 GMT"}, {"version": "v4", "created": "Sat, 22 Sep 2018 01:43:35 GMT"}, {"version": "v5", "created": "Sun, 30 Dec 2018 13:25:14 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Kesidis", "George", ""], ["Shan", "Yuquan", ""], ["Wang", "Yujia", ""], ["Urgaonkar", "Bhuvan", ""], ["Khamse-Ashari", "Jalal", ""], ["Lambadaris", "Ioanns", ""]]}, {"id": "1705.06661", "submitter": "Paul Springer", "authors": "Paul Springer, Devin Matthews, Paolo Bientinesi", "title": "Spin Summations: A High-Performance Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Besides tensor contractions, one of the most pronounced computational\nbottlenecks in the non-orthogonally spin-adapted forms of the quantum chemistry\nmethods CCSDT and CCSDTQ, and their approximate forms---including CCSD(T) and\nCCSDT(Q)---are spin summations. At a first sight, spin summations are\noperations similar to tensor transpositions; a closer look instead reveals\nadditional challenges to high-performance calculations, including temporal\nlocality as well as scattered memory accesses. This publication explores a\nsequence of algorithmic solutions for spin summations, each exploiting\nindividual properties of either the underlying hardware (e.g. caches,\nvectorization), or the problem itself (e.g. factorizability). The final\nalgorithm combines the advantages of all the solutions, while avoiding their\ndrawbacks; this algorithm, achieves high-performance through parallelization,\nvectorization, and by exploiting the temporal locality inherent to spin\nsummations. Combined, these optimizations result in speedups between 2.4x and\n5.5x over the NCC quantum chemistry software package. In addition to such a\nperformance boost, our algorithm can perform the spin summations in-place, thus\nreducing the memory footprint by 2x over an out-of-place variant.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 15:48:46 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Springer", "Paul", ""], ["Matthews", "Devin", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1705.07400", "submitter": "Juncheng Yang", "authors": "Juncheng Yang, Reza Karimi, Trausti S{\\ae}mundsson, Avani Wildani,\n  Ymir Vigfusson", "title": "MITHRIL: Mining Sporadic Associations for Cache Prefetching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing pressure on cloud application scalability has accentuated storage\nperformance as a critical bottle- neck. Although cache replacement algorithms\nhave been extensively studied, cache prefetching - reducing latency by\nretrieving items before they are actually requested remains an underexplored\narea. Existing approaches to history-based prefetching, in particular, provide\ntoo few benefits for real systems for the resources they cost. We propose\nMITHRIL, a prefetching layer that efficiently exploits historical patterns in\ncache request associations. MITHRIL is inspired by sporadic association rule\nmining and only relies on the timestamps of requests. Through evaluation of 135\nblock-storage traces, we show that MITHRIL is effective, giving an average of a\n55% hit ratio increase over LRU and PROBABILITY GRAPH, a 36% hit ratio gain\nover AMP at reasonable cost. We further show that MITHRIL can supplement any\ncache replacement algorithm and be readily integrated into existing systems.\nFurthermore, we demonstrate the improvement comes from MITHRIL being able to\ncapture mid-frequency blocks.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 05:51:21 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Yang", "Juncheng", ""], ["Karimi", "Reza", ""], ["S\u00e6mundsson", "Trausti", ""], ["Wildani", "Avani", ""], ["Vigfusson", "Ymir", ""]]}, {"id": "1705.07575", "submitter": "Kewen Meng", "authors": "Kewen Meng, Boyana Norris", "title": "Mira: A Framework for Static Performance Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance model of an application can pro- vide understanding about its\nruntime behavior on particular hardware. Such information can be analyzed by\ndevelopers for performance tuning. However, model building and analyzing is\nfrequently ignored during software development until perfor- mance problems\narise because they require significant expertise and can involve many\ntime-consuming application runs. In this paper, we propose a fast, accurate,\nflexible and user-friendly tool, Mira, for generating performance models by\napplying static program analysis, targeting scientific applications running on\nsupercomputers. We parse both the source code and binary to estimate\nperformance attributes with better accuracy than considering just source or\njust binary code. Because our analysis is static, the target program does not\nneed to be executed on the target architecture, which enables users to perform\nanalysis on available machines instead of conducting expensive exper- iments on\npotentially expensive resources. Moreover, statically generated models enable\nperformance prediction on non-existent or unavailable architectures. In\naddition to flexibility, because model generation time is significantly reduced\ncompared to dynamic analysis approaches, our method is suitable for rapid\napplication performance analysis and improvement. We present several scientific\napplication validation results to demonstrate the current capabilities of our\napproach on small benchmarks and a mini application.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 06:31:22 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Meng", "Kewen", ""], ["Norris", "Boyana", ""]]}, {"id": "1705.07730", "submitter": "Boris Ryabko", "authors": "Boris Ryabko, Anton Rakitskiy", "title": "Application of the Computer Capacity to the Analysis of Processors\n  Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of computer capacity was proposed in 2012, and this quantity has\nbeen estimated for computers of different kinds.\n  In this paper we show that, when designing new processors, the manufacturers\nchange the parameters that affect the computer capacity. This allows us to\npredict the values of parameters of future processors. As the main example we\nuse Intel processors, due to the accessibility of detailed description of all\ntheir technical characteristics.\n", "versions": [{"version": "v1", "created": "Sun, 14 May 2017 10:12:14 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Ryabko", "Boris", ""], ["Rakitskiy", "Anton", ""]]}, {"id": "1705.07779", "submitter": "Mehmet Donmez", "authors": "Mehmet A. Donmez and Maxim Raginsky and Andrew C. Singer and Lav R.\n  Varshney", "title": "Cost-Performance Tradeoffs in Fusing Unreliable Computational Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate fusing several unreliable computational units that perform the\nsame task. We model an unreliable computational outcome as an additive\nperturbation to its error-free result in terms of its fidelity and cost. We\nanalyze performance of repetition-based strategies that distribute cost across\nseveral unreliable units and fuse their outcomes. When the cost is a convex\nfunction of fidelity, the optimal repetition-based strategy in terms of\nincurred cost while achieving a target mean-square error (MSE) performance may\nfuse several computational units. For concave and linear costs, a single more\nreliable unit incurs lower cost compared to fusion of several lower cost and\nless reliable units while achieving the same MSE performance. We show how our\nresults give insight into problems from theoretical neuroscience, circuits, and\ncrowdsourcing.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 14:47:06 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Donmez", "Mehmet A.", ""], ["Raginsky", "Maxim", ""], ["Singer", "Andrew C.", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1705.07983", "submitter": "Michael Luby", "authors": "Michael G. Luby, Roberto Padovani, Thomas J. Richardson, Lorenz\n  Minder, Pooja Aggarwal", "title": "Liquid Cloud Storage", "comments": "44 pages, 21 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A liquid system provides durable object storage based on spreading\nredundantly generated data across a network of hundreds to thousands of\npotentially unreliable storage nodes. A liquid system uses a combination of a\nlarge code, lazy repair, and a flow storage organization. We show that a liquid\nsystem can be operated to enable flexible and essentially optimal combinations\nof storage durability, storage overhead, repair bandwidth usage, and access\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 20:21:09 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Luby", "Michael G.", ""], ["Padovani", "Roberto", ""], ["Richardson", "Thomas J.", ""], ["Minder", "Lorenz", ""], ["Aggarwal", "Pooja", ""]]}, {"id": "1705.08210", "submitter": "Wayne Joubert", "authors": "Wayne Joubert, James Nance, Deborah Weighill, Daniel Jacobson", "title": "Parallel Accelerated Vector Similarity Calculations for Genomics\n  Applications", "comments": null, "journal-ref": null, "doi": "10.1016/j.parco.2018.03.009", "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The surge in availability of genomic data holds promise for enabling\ndetermination of genetic causes of observed individual traits, with\napplications to problems such as discovery of the genetic roots of phenotypes,\nbe they molecular phenotypes such as gene expression or metabolite\nconcentrations, or complex phenotypes such as diseases. However, the growing\nsizes of these datasets and the quadratic, cubic or higher scaling\ncharacteristics of the relevant algorithms pose a serious computational\nchallenge necessitating use of leadership scale computing. In this paper we\ndescribe a new approach to performing vector similarity metrics calculations,\nsuitable for parallel systems equipped with graphics processing units (GPUs) or\nIntel Xeon Phi processors. Our primary focus is the Proportional Similarity\nmetric applied to Genome Wide Association Studies (GWAS) and Phenome Wide\nAssociation Studies (PheWAS). We describe the implementation of the algorithms\non accelerated processors, methods used for eliminating redundant calculations\ndue to symmetries, and techniques for efficient mapping of the calculations to\nmany-node parallel systems. Results are presented demonstrating high per-node\nperformance and parallel scalability with rates of more than five quadrillion\nelementwise comparisons achieved per second on the ORNL Titan system. In a\ncompanion paper we describe corresponding techniques applied to calculations of\nthe Custom Correlation Coefficient for comparative genomics applications.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 12:34:55 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 23:17:55 GMT"}, {"version": "v3", "created": "Fri, 20 Apr 2018 15:47:04 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Joubert", "Wayne", ""], ["Nance", "James", ""], ["Weighill", "Deborah", ""], ["Jacobson", "Daniel", ""]]}, {"id": "1705.08213", "submitter": "Wayne Joubert", "authors": "Wayne Joubert, James Nance, Sharlee Climer, Deborah Weighill, Daniel\n  Jacobson", "title": "Parallel Accelerated Custom Correlation Coefficient Calculations for\n  Genomics Applications", "comments": "arXiv admin note: text overlap with arXiv:1705.08210", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive quantities of genomic data being made available through gene\nsequencing techniques are enabling breakthroughs in genomic science in many\nareas such as medical advances in the diagnosis and treatment of diseases.\nAnalyzing this data, however, is a computational challenge insofar as the\ncomputational costs of the relevant algorithms can grow with quadratic, cubic\nor higher complexity-leading to the need for leadership scale computing. In\nthis paper we describe a new approach to calculations of the Custom Correlation\nCoefficient (CCC) between Single Nucleotide Polymorphisms (SNPs) across a\npopulation, suitable for parallel systems equipped with graphics processing\nunits (GPUs) or Intel Xeon Phi processors. We describe the mapping of the\nalgorithms to accelerated processors, techniques used for eliminating redundant\ncalculations due to symmetries, and strategies for efficient mapping of the\ncalculations to many-node parallel systems. Results are presented demonstrating\nhigh per-node performance and near-ideal parallel scalability with rates of\nmore than nine quadrillion elementwise comparisons achieved per second with the\nlatest optimized code on the ORNL Titan system, this being orders of magnitude\nfaster than rates achieved using other codes and platforms as reported in the\nliterature. Also it is estimated that as many as 90 quadrillion comparisons per\nsecond may be achievable on the upcoming ORNL Summit system, an additional 10X\nperformance increase. In a companion paper we describe corresponding techniques\napplied to calculations of the Proportional Similarity metric for comparative\ngenomics applications.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 12:39:05 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 23:14:28 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2018 20:51:41 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Joubert", "Wayne", ""], ["Nance", "James", ""], ["Climer", "Sharlee", ""], ["Weighill", "Deborah", ""], ["Jacobson", "Daniel", ""]]}, {"id": "1705.09433", "submitter": "Huanhuan Huang", "authors": "Huanhuan Huang, Tong Ye, Tony T. Lee, and Weisheng Hu", "title": "Optimum Transmission Window for EPONs with Gated-Limited Service", "comments": "14 pages, 10 figures, IEEE transaction on networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper studies the Ethernet Passive Optical Network (EPON) with\ngated-limited service. The transmission window (TW) is limited in this system\nto guaranteeing a bounded delay experienced by disciplined users, and to\nconstrain malicious users from monopolizing the transmission channel. Thus,\nselecting an appropriate TW size is critical to the performance of EPON with\ngated-limited service discipline. To investigate the impact of TW size on\npacket delay, we derive a generalized mean waiting time formula for M/G/1 queue\nwith vacation times and gated-limited service discipline. A distinguished\nfeature of this model is that there are two queues in the buffer of each\noptical network unit (ONU): one queue is inside the gate and the other one is\noutside the gate. Furthermore, based on the Chernoff bound of queue length, we\nprovide a simple rule to determine an optimum TW size for gated-limited service\nEPONs. Analytic results reported in this paper are all verified by simulations.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 05:16:55 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Huang", "Huanhuan", ""], ["Ye", "Tong", ""], ["Lee", "Tony T.", ""], ["Hu", "Weisheng", ""]]}, {"id": "1705.09473", "submitter": "Andrea Tassi", "authors": "Suzie Brown, Oliver Johnson, Andrea Tassi", "title": "Reliability of Broadcast Communications Under Sparse Random Linear\n  Network Coding", "comments": "Accepted for publication on IEEE Transactions on Vehicular Technology", "journal-ref": "IEEE Transactions on Vehicular Technology, vol 67/5, 2018, pages\n  4677-4682", "doi": "10.1109/TVT.2018.2790436", "report-no": null, "categories": "cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-reliable Point-to-Multipoint (PtM) communications are expected to\nbecome pivotal in networks offering future dependable services for smart\ncities. In this regard, sparse Random Linear Network Coding (RLNC) techniques\nhave been widely employed to provide an efficient way to improve the\nreliability of broadcast and multicast data streams. This paper addresses the\npressing concern of providing a tight approximation to the probability of a\nuser recovering a data stream protected by this kind of coding technique. In\nparticular, by exploiting the Stein--Chen method, we provide a novel and\ngeneral performance framework applicable to any combination of system and\nservice parameters, such as finite field sizes, lengths of the data stream and\nlevel of sparsity. The deviation of the proposed approximation from Monte Carlo\nsimulations is negligible, improving significantly on the state of the art\nperformance bounds.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 08:21:00 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 10:14:04 GMT"}, {"version": "v3", "created": "Thu, 4 Jan 2018 10:00:46 GMT"}, {"version": "v4", "created": "Thu, 18 Oct 2018 09:53:37 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Brown", "Suzie", ""], ["Johnson", "Oliver", ""], ["Tassi", "Andrea", ""]]}, {"id": "1705.09482", "submitter": "Guy Louchard", "authors": "Guy Louchard", "title": "A refined and asymptotic analysis of optimal stopping problems of Bruss\n  and Weber", "comments": "22 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical secretary problem has been generalized over the years into\nseveral directions. In this paper we confine our interest to those\ngeneralizations which have to do with the more general problem of stopping on a\nlast observation of a specific kind. We follow Dendievel, (where a bibliography\ncan be found) who studies several types of such problems, mainly initiated by\nBruss and Weber. Whether in discrete time or continuous time, whether all\nparameters are known or must be sequentially estimated, we shall call such\nproblems simply \"Bruss-Weber problems\". Our contribution in the present paper\nis a refined analysis of several problems in this class and a study of the\nasymptotic behaviour of solutions.\n  The problems we consider center around the following model. Let\n$X_1,X_2,\\ldots,X_n$ be a sequence of independent random variables which can\ntake three values: $\\{+1,-1,0\\}.$ Let $p:=\\P(X_i=1), p':=\\P(X_i=-1),\n\\qt:=\\P(X_i=0), p\\geq p'$, where $p+p'+\\qt=1$. The goal is to maximize the\nprobability of stopping on a value $+1$ or $-1$ appearing for the last time in\nthe sequence. Following a suggestion by Bruss, we have also analyzed an\nx-strategy with incomplete information: the cases $p$ known, $n$ unknown, then\n$n$ known, $p$ unknown and finally $n,p$ unknown are considered. We also\npresent simulations of the corresponding complete selection algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 08:58:29 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Louchard", "Guy", ""]]}, {"id": "1705.10738", "submitter": "Christian Berthet", "authors": "Christian Berthet", "title": "Approximation of LRU Caches Miss Rate: Application to Power-law\n  Popularities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the 1977 pioneering work of R. Fagin, we give a closed-form\nexpression for the approximated Miss Rate (MR) of LRU Caches assuming a\npower-law popularity. Asymptotic behavior of this expression is an already\nknown result when power-law parameter is above 1. It is extended to any value\nof the parameter. In addition, we bring a new analysis of the conditions (cache\nrelative size, popularity parameter) under which the ratio of LRU MR to Static\nMR is worst-case.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 14:46:14 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Berthet", "Christian", ""]]}, {"id": "1705.10756", "submitter": "Niyazi Sorkunlu", "authors": "Niyazi Sorkunlu, Varun Chandola, Abani Patra", "title": "Tracking System Behaviour from Resource Usage Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Resource usage data, collected using tools such as TACC Stats, capture the\nresource utilization by nodes within a high performance computing system. We\npresent methods to analyze the resource usage data to understand the system\nperformance and identify performance anomalies. The core idea is to model the\ndata as a three-way tensor corresponding to the compute nodes, usage metrics,\nand time. Using the reconstruction error between the original tensor and the\ntensor reconstructed from a low rank tensor decomposition, as a scalar\nperformance metric, enables us to monitor the performance of the system in an\nonline fashion. This error statistic is then used for anomaly detection that\nrelies on the assumption that the normal/routine behavior of the system can be\ncaptured using a low rank approx- imation of the original tensor. We evaluate\nthe performance of the algorithm using information gathered from system logs\nand show that the performance anomalies identified by the proposed method\ncorrelates with critical errors reported in the system logs. Results are shown\nfor data collected for 2013 from the Lonestar4 system at the Texas Advanced\nComputing Center (TACC)\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 17:09:34 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Sorkunlu", "Niyazi", ""], ["Chandola", "Varun", ""], ["Patra", "Abani", ""]]}]