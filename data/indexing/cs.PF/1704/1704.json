[{"id": "1704.00513", "submitter": "Julian Romera", "authors": "Julian Romera", "title": "Optimizing Communication by Compression for Multi-GPU Scalable\n  Breadth-First Searches", "comments": "Initial version, 105 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Breadth First Search (BFS) algorithm is the foundation and building block\nof many higher graph-based operations such as spanning trees, shortest paths\nand betweenness centrality. The importance of this algorithm increases each day\ndue to it is a key requirement for many data structures which are becoming\npopular nowadays. When the BFS algorithm is parallelized by distributing the\ngraph between several processors the interconnection network limits the\nperformance. Hence, improvements on this area may benefit the overall\nperformance of the algorithm.\n  This work presents an alternative compression scheme for communications in\ndistributed BFS processing. It focuses on BFS processors using General-Purpose\nGraphics Processing Units.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 10:22:32 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Romera", "Julian", ""]]}, {"id": "1704.00605", "submitter": "Daniel Lemire", "authors": "Wojciech Mu{\\l}a and Daniel Lemire", "title": "Faster Base64 Encoding and Decoding Using AVX2 Instructions", "comments": "software at https://github.com/lemire/fastbase64", "journal-ref": "ACM Transactions on the Web 12 (3), 2018", "doi": "10.1145/3132709", "report-no": null, "categories": "cs.MS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Web developers use base64 formats to include images, fonts, sounds and other\nresources directly inside HTML, JavaScript, JSON and XML files. We estimate\nthat billions of base64 messages are decoded every day. We are motivated to\nimprove the efficiency of base64 encoding and decoding. Compared to\nstate-of-the-art implementations, we multiply the speeds of both the encoding\n(~10x) and the decoding (~7x). We achieve these good results by using the\nsingle-instruction-multiple-data (SIMD) instructions available on recent Intel\nprocessors (AVX2). Our accelerated software abides by the specification and\nreports errors when encountering characters outside of the base64 set. It is\navailable online as free software under a liberal license.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 19:04:09 GMT"}, {"version": "v2", "created": "Mon, 24 Apr 2017 00:25:35 GMT"}, {"version": "v3", "created": "Sat, 12 Aug 2017 03:04:27 GMT"}, {"version": "v4", "created": "Wed, 17 Jan 2018 19:27:41 GMT"}, {"version": "v5", "created": "Thu, 14 Jun 2018 21:02:13 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Mu\u0142a", "Wojciech", ""], ["Lemire", "Daniel", ""]]}, {"id": "1704.00630", "submitter": "Joan Guisado-G\\'amez", "authors": "Arnau Prat-P\\'erez, Joan Guisado-G\\'amez, Xavier Fern\\'andez Salas,\n  Petr Koupy, Siegfried Depner, Davide Basilio Bartolini", "title": "Towards a property graph generator for benchmarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of synthetic graph generators is a common practice among\ngraph-oriented benchmark designers, as it allows obtaining graphs with the\nrequired scale and characteristics. However, finding a graph generator that\naccurately fits the needs of a given benchmark is very difficult, thus\npractitioners end up creating ad-hoc ones. Such a task is usually\ntime-consuming, and often leads to reinventing the wheel. In this paper, we\nintroduce the conceptual design of DataSynth, a framework for property graphs\ngeneration with customizable schemas and characteristics. The goal of DataSynth\nis to assist benchmark designers in generating graphs efficiently and at scale,\nsaving from implementing their own generators. Additionally, DataSynth\nintroduces novel features barely explored so far, such as modeling the\ncorrelation between properties and the structure of the graph. This is achieved\nby a novel property-to-node matching algorithm for which we present preliminary\npromising results.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 15:04:01 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Prat-P\u00e9rez", "Arnau", ""], ["Guisado-G\u00e1mez", "Joan", ""], ["Salas", "Xavier Fern\u00e1ndez", ""], ["Koupy", "Petr", ""], ["Depner", "Siegfried", ""], ["Bartolini", "Davide Basilio", ""]]}, {"id": "1704.00693", "submitter": "Istv\\'an Z Reguly", "authors": "Istvan Z Reguly, Gihan R Mudalige, Mike B Giles", "title": "Loop Tiling in Large-Scale Stencil Codes at Run-time with OPS", "comments": null, "journal-ref": null, "doi": "10.1109/TPDS.2017.2778161", "report-no": null, "categories": "cs.PF cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key common bottleneck in most stencil codes is data movement, and prior\nresearch has shown that improving data locality through optimisations that\nschedule across loops do particularly well. However, in many large PDE\napplications it is not possible to apply such optimisations through compilers\nbecause there are many options, execution paths and data per grid point, many\ndependent on run-time parameters, and the code is distributed across different\ncompilation units. In this paper, we adapt the data locality improving\noptimisation called iteration space slicing for use in large OPS applications\nboth in shared-memory and distributed-memory systems, relying on run-time\nanalysis and delayed execution. We evaluate our approach on a number of\napplications, observing speedups of 2$\\times$ on the Cloverleaf 2D/3D proxy\napplication, which contain 83/141 loops respectively, $3.5\\times$ on the linear\nsolver TeaLeaf, and $1.7\\times$ on the compressible Navier-Stokes solver\nOpenSBLI. We demonstrate strong and weak scalability up to 4608 cores of\nCINECA's Marconi supercomputer. We also evaluate our algorithms on Intel's\nKnights Landing, demonstrating maintained throughput as the problem size grows\nbeyond 16GB, and we do scaling studies up to 8704 cores. The approach is\ngenerally applicable to any stencil DSL that provides per loop data access\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 17:16:39 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 14:57:19 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Reguly", "Istvan Z", ""], ["Mudalige", "Gihan R", ""], ["Giles", "Mike B", ""]]}, {"id": "1704.01722", "submitter": "Tejas Bodas", "authors": "Konstantin Avrachenkov (NEO), Tejas Bodas (LAAS-SARA)", "title": "On the equivalence between multiclass processor sharing and random order\n  scheduling policies", "comments": null, "journal-ref": null, "doi": null, "report-no": "Rapport LAAS n{\\textdegree} 17108", "categories": "cs.PF math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a single server system serving a multiclass population. Some popular\nscheduling policies for such system are the discriminatory processor sharing\n(DPS), discriminatory random order service (DROS), generalized processor\nsharing (GPS) and weighted fair queueing (WFQ). In this paper, we propose two\nclasses of policies, namely MPS (multiclass processor sharing) and MROS\n(multiclass random order service), that generalize the four policies mentioned\nabove. For the special case when the multiclass population arrive according to\nPoisson processes and have independent and exponential service requirement with\nparameter $\\mu$, we show that the tail of the sojourn time distribution for a\nclass $i$ customer in a system with the MPS policy is a constant multiple of\nthe tail of the waiting time distribution of a class $i$ customer in a system\nwith the MROS policy. This result implies that for a class $i$ customer, the\ntail of the sojourn time distribution in a system with the DPS (GPS) scheduling\npolicy is a constant multiple of the tail of the waiting time distribution in a\nsystem with the DROS (respectively WFQ) policy.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 06:23:45 GMT"}, {"version": "v2", "created": "Mon, 24 Apr 2017 08:27:24 GMT"}, {"version": "v3", "created": "Wed, 11 Apr 2018 09:42:06 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Avrachenkov", "Konstantin", "", "NEO"], ["Bodas", "Tejas", "", "LAAS-SARA"]]}, {"id": "1704.02003", "submitter": "Samuel Pollard", "authors": "Samuel Pollard and Boyana Norris", "title": "A Comparison of Parallel Graph Processing Implementations", "comments": "10 pages, 10 figures, Submitted to EuroPar 2017 and rejected. Revised\n  and submitted to IEEE Cluster 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly growing number of large network analysis problems has led to the\nemergence of many parallel and distributed graph processing systems---one\nsurvey in 2014 identified over 80. Since then, the landscape has evolved; some\npackages have become inactive while more are being developed. Determining the\nbest approach for a given problem is infeasible for most developers. To enable\neasy, rigorous, and repeatable comparison of the capabilities of such systems,\nwe present an approach and associated software for analyzing the performance\nand scalability of parallel, open-source graph libraries. We demonstrate our\napproach on five graph processing packages: GraphMat, the Graph500, the Graph\nAlgorithm Platform Benchmark Suite, GraphBIG, and PowerGraph using synthetic\nand real-world datasets. We examine previously overlooked aspects of parallel\ngraph processing performance such as phases of execution and energy usage for\nthree algorithms: breadth first search, single source shortest paths, and\nPageRank and compare our results to Graphalytics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 19:48:37 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 01:44:23 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Pollard", "Samuel", ""], ["Norris", "Boyana", ""]]}, {"id": "1704.02790", "submitter": "Hussein Al-Zubaidy", "authors": "Hussein Al-Zubaidy, Viktoria Fodor, Gy\\\"orgy D\\'an, Markus Flierl", "title": "Performance Analysis of Reliable Video Streaming with Strict Playout\n  Deadline in Multi-Hop Wireless Networks", "comments": "33 single column pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by emerging vision-based intelligent services, we consider the\nproblem of rate adaptation for high quality and low delay visual information\ndelivery over wireless networks using scalable video coding. Rate adaptation in\nthis setting is inherently challenging due to the interplay between the\nvariability of the wireless channels, the queuing at the network nodes and the\nframe-based decoding and playback of the video content at the receiver at very\nshort time scales. To address the problem, we propose a low-complexity,\nmodel-based rate adaptation algorithm for scalable video streaming systems,\nbuilding on a novel performance model based on stochastic network calculus. We\nvalidate the model using extensive simulations. We show that it allows fast,\nnear optimal rate adaptation for fixed transmission paths, as well as\ncross-layer optimized routing and video rate adaptation in mesh networks, with\nless than $10$\\% quality degradation compared to the best achievable\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 10:32:18 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Al-Zubaidy", "Hussein", ""], ["Fodor", "Viktoria", ""], ["D\u00e1n", "Gy\u00f6rgy", ""], ["Flierl", "Markus", ""]]}, {"id": "1704.02855", "submitter": "Ioannis Giannakopoulos", "authors": "Ioannis Giannakopoulos, Dimitrios Tsoumakos and Nectarios Koziris", "title": "A Decision Tree Based Approach Towards Adaptive Profiling of Distributed\n  Applications", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of the distributed paradigm has allowed applications to increase\ntheir scalability, robustness and fault tolerance, but it has also complicated\ntheir structure, leading to an exponential growth of the applications'\nconfiguration space and increased difficulty in predicting their performance.\nIn this work, we describe a novel, automated profiling methodology that makes\nno assumptions on application structure. Our approach utilizes oblique Decision\nTrees in order to recursively partition an application's configuration space in\ndisjoint regions, choose a set of representative samples from each subregion\naccording to a defined policy and return a model for the entire space as a\ncomposition of linear models over each subregion. An extensive evaluation over\nreal-life applications and synthetic performance functions showcases that our\nscheme outperforms other state-of-the-art profiling methodologies. It\nparticularly excels at reflecting abnormalities and discontinuities of the\nperformance function, allowing the user to influence the sampling policy based\non the modeling accuracy and the space coverage.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 13:46:58 GMT"}, {"version": "v2", "created": "Sun, 21 May 2017 13:36:45 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Giannakopoulos", "Ioannis", ""], ["Tsoumakos", "Dimitrios", ""], ["Koziris", "Nectarios", ""]]}, {"id": "1704.02996", "submitter": "Rathijit Sen", "authors": "Rathijit Sen, Jianqiao Zhu, Jignesh M. Patel, and Somesh Jha", "title": "ROSA: R Optimizations with Static Analysis", "comments": "A talk on this work will be presented at RIOT 2017 (3rd Workshop on R\n  Implementation, Optimization and Tooling)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  R is a popular language and programming environment for data scientists. It\nis increasingly co-packaged with both relational and Hadoop-based data\nplatforms and can often be the most dominant computational component in data\nanalytics pipelines. Recent work has highlighted inefficiencies in executing R\nprograms, both in terms of execution time and memory requirements, which in\npractice limit the size of data that can be analyzed by R. This paper presents\nROSA, a static analysis framework to improve the performance and space\nefficiency of R programs. ROSA analyzes input programs to determine program\nproperties such as reaching definitions, live variables, aliased variables, and\ntypes of variables. These inferred properties enable program transformations\nsuch as C++ code translation, strength reduction, vectorization, code motion,\nin addition to interpretive optimizations such as avoiding redundant object\ncopies and performing in-place evaluations. An empirical evaluation shows\nsubstantial reductions by ROSA in execution time and memory consumption over\nboth CRAN R and Microsoft R Open.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 18:08:36 GMT"}, {"version": "v2", "created": "Mon, 3 Jul 2017 16:54:03 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Sen", "Rathijit", ""], ["Zhu", "Jianqiao", ""], ["Patel", "Jignesh M.", ""], ["Jha", "Somesh", ""]]}, {"id": "1704.03100", "submitter": "EPTCS", "authors": "Sanjiva Prasad (Indian Institute of Technology Delhi)", "title": "Best-by-Simulations: A Framework for Comparing Efficiency of\n  Reconfigurable Multicore Architectures on Workloads with Deadlines", "comments": "In Proceedings PLACES 2017, arXiv:1704.02418", "journal-ref": "EPTCS 246, 2017, pp. 61-71", "doi": "10.4204/EPTCS.246.10", "report-no": null, "categories": "cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy consumption is a major concern in multicore systems. Perhaps the\nsimplest strategy for reducing energy costs is to use only as many cores as\nnecessary while still being able to deliver a desired quality of service.\nMotivated by earlier work on a dynamic (heterogeneous) core allocation scheme\nfor H.264 video decoding that reduces energy costs while delivering desired\nframe rates, we formulate operationally the general problem of executing a\nsequence of actions on a reconfigurable machine while meeting a corresponding\nsequence of absolute deadlines, with the objective of reducing cost. Using a\ntransition system framework that associates costs (e.g., time, energy) with\nexecuting an action on a particular resource configuration, we use the notion\nof amortised cost to formulate in terms of simulation relations appropriate\nnotions for comparing deadline-conformant executions. We believe these notions\ncan provide the basis for an operational theory of optimal cost executions and\nperformance guarantees for approximate solutions, in particular relating the\nnotion of simulation from transition systems to that of competitive analysis\nused for, e.g., online algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 00:44:42 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Prasad", "Sanjiva", "", "Indian Institute of Technology Delhi"]]}, {"id": "1704.03911", "submitter": "You Zhou", "authors": "You Zhou, Yian Zhou, Min Chen, Shigang Chen", "title": "Persistent Spread Measurement for Big Network Data Based on Register\n  Intersection", "comments": "ACM SIGMETRICS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent spread measurement is to count the number of distinct elements\nthat persist in each network flow for predefined time periods. It has many\npractical applications, including detecting long-term stealthy network\nactivities in the background of normal-user activities, such as stealthy DDoS\nattack, stealthy network scan, or faked network trend, which cannot be detected\nby traditional flow cardinality measurement. With big network data, one\nchallenge is to measure the persistent spreads of a massive number of flows\nwithout incurring too much memory overhead as such measurement may be performed\nat the line speed by network processors with fast but small on-chip memory. We\npropose a highly compact Virtual Intersection HyperLogLog (VI-HLL) architecture\nfor this purpose. It achieves far better memory efficiency than the best prior\nwork of V-Bitmap, and in the meantime drastically extends the measurement\nrange. Theoretical analysis and extensive experiments demonstrate that VI-HLL\nprovides good measurement accuracy even in very tight memory space of less than\n1 bit per flow.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 19:42:23 GMT"}, {"version": "v2", "created": "Fri, 14 Apr 2017 19:31:35 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Zhou", "You", ""], ["Zhou", "Yian", ""], ["Chen", "Min", ""], ["Chen", "Shigang", ""]]}, {"id": "1704.03992", "submitter": "Ying Zhang", "authors": "Ying Zhang", "title": "Fully Distributed and Asynchronized Stochastic Gradient Descent for\n  Networked Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a general data-fitting problem over a networked system,\nin which many computing nodes are connected by an undirected graph. This kind\nof problem can find many real-world applications and has been studied\nextensively in the literature. However, existing solutions either need a\ncentral controller for information sharing or requires slot synchronization\namong different nodes, which increases the difficulty of practical\nimplementations, especially for a very large and heterogeneous system.\n  As a contrast, in this paper, we treat the data-fitting problem over the\nnetwork as a stochastic programming problem with many constraints. By adapting\nthe results in a recent paper, we design a fully distributed and asynchronized\nstochastic gradient descent (SGD) algorithm. We show that our algorithm can\nachieve global optimality and consensus asymptotically by only local\ncomputations and communications. Additionally, we provide a sharp lower bound\nfor the convergence speed in the regular graph case. This result fits the\nintuition and provides guidance to design a `good' network topology to speed up\nthe convergence. Also, the merit of our design is validated by experiments on\nboth synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 04:58:54 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Zhang", "Ying", ""]]}, {"id": "1704.04313", "submitter": "Lukas Cavigelli", "authors": "Lukas Cavigelli, Philippe Degen, Luca Benini", "title": "CBinfer: Change-Based Inference for Convolutional Neural Networks on\n  Video Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.PF eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting per-frame features using convolutional neural networks for\nreal-time processing of video data is currently mainly performed on powerful\nGPU-accelerated workstations and compute clusters. However, there are many\napplications such as smart surveillance cameras that require or would benefit\nfrom on-site processing. To this end, we propose and evaluate a novel algorithm\nfor change-based evaluation of CNNs for video data recorded with a static\ncamera setting, exploiting the spatio-temporal sparsity of pixel changes. We\nachieve an average speed-up of 8.6x over a cuDNN baseline on a realistic\nbenchmark with a negligible accuracy loss of less than 0.1% and no retraining\nof the network. The resulting energy efficiency is 10x higher than that of\nper-frame evaluation and reaches an equivalent of 328 GOp/s/W on the Tegra X1\nplatform.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 00:36:55 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 09:27:14 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Cavigelli", "Lukas", ""], ["Degen", "Philippe", ""], ["Benini", "Luca", ""]]}, {"id": "1704.04374", "submitter": "Paul Springer", "authors": "Paul Springer, Tong Su, Paolo Bientinesi", "title": "HPTT: A High-Performance Tensor Transposition C++ Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we presented TTC, a domain-specific compiler for tensor\ntranspositions. Despite the fact that the performance of the generated code is\nnearly optimal, due to its offline nature, TTC cannot be utilized in all the\napplication codes in which the tensor sizes and the necessary tensor\npermutations are determined at runtime. To overcome this limitation, we\nintroduce the open-source C++ library High-Performance Tensor Transposition\n(HPTT). Similar to TTC, HPTT incorporates optimizations such as blocking,\nmulti-threading, and explicit vectorization; furthermore it decomposes any\ntransposition into multiple loops around a so called micro-kernel. This modular\ndesign---inspired by BLIS---makes HPTT easy to port to different architectures,\nby only replacing the hand-vectorized micro-kernel (e.g., a 4x4 transpose).\nHPTT also offers an optional autotuning framework---guided by a performance\nmodel---that explores a vast search space of implementations at runtime\n(similar to FFTW). Across a wide range of different tensor transpositions and\narchitectures (e.g., Intel Ivy Bridge, Intel Knights Landing, ARMv7, IBM\nPower7), HPTT attains a bandwidth comparable to that of SAXPY, and yields\nremarkable speedups over Eigen's tensor transposition implementation. Most\nimportantly, the integration of HPTT into the Cyclops Tensor Framework (CTF)\nimproves the overall performance of tensor contractions by up to 3.1x.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 09:45:06 GMT"}, {"version": "v2", "created": "Wed, 10 May 2017 21:34:51 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Springer", "Paul", ""], ["Su", "Tong", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1704.04428", "submitter": "Aravind Vasudevan", "authors": "Aravind Vasudevan, Andrew Anderson and David Gregg", "title": "Parallel Multi Channel Convolution using General Matrix Multiplication", "comments": "Camera ready version to be published at ASAP 2017 - The 28th Annual\n  IEEE International Conference on Application-specific Systems, Architectures\n  and Processors. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have emerged as one of the most\nsuccessful machine learning technologies for image and video processing. The\nmost computationally intensive parts of CNNs are the convolutional layers,\nwhich convolve multi-channel images with multiple kernels. A common approach to\nimplementing convolutional layers is to expand the image into a column matrix\n(im2col) and perform Multiple Channel Multiple Kernel (MCMK) convolution using\nan existing parallel General Matrix Multiplication (GEMM) library. This im2col\nconversion greatly increases the memory footprint of the input matrix and\nreduces data locality.\n  In this paper we propose a new approach to MCMK convolution that is based on\nGeneral Matrix Multiplication (GEMM), but not on im2col. Our algorithm\neliminates the need for data replication on the input thereby enabling us to\napply the convolution kernels on the input images directly. We have implemented\nseveral variants of our algorithm on a CPU processor and an embedded ARM\nprocessor. On the CPU, our algorithm is faster than im2col in most cases.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 17:09:43 GMT"}, {"version": "v2", "created": "Mon, 3 Jul 2017 12:43:10 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Vasudevan", "Aravind", ""], ["Anderson", "Andrew", ""], ["Gregg", "David", ""]]}, {"id": "1704.04849", "submitter": "George Kesidis", "authors": "George Kesidis", "title": "Stationary Distribution of a Generalized LRU-MRU Content Cache", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many different caching mechanisms have been previously proposed, exploring\ndifferent insertion and eviction policies and their performance individually\nand as part of caching networks. We obtain a novel closed-form stationary\ninvariant distribution for a generalization of LRU and MRU caching nodes under\na reference Markov model. Numerical comparisons are made with an \"Incremental\nRank Progress\" (IRP a.k.a. CLIMB) and random eviction (a.k.a. random\nreplacement) methods under a steady-state Zipf popularity distribution. The\nrange of cache hit probabilities is smaller under MRU and larger under IRP\ncompared to LRU. We conclude with the invariant distribution for a special case\nof a random-eviction caching tree-network and associated discussion.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 02:18:59 GMT"}, {"version": "v2", "created": "Sun, 23 Apr 2017 19:25:29 GMT"}, {"version": "v3", "created": "Tue, 25 Apr 2017 00:54:31 GMT"}, {"version": "v4", "created": "Fri, 28 Apr 2017 22:02:42 GMT"}, {"version": "v5", "created": "Mon, 5 Jun 2017 14:45:40 GMT"}, {"version": "v6", "created": "Sun, 18 Jun 2017 22:32:24 GMT"}, {"version": "v7", "created": "Tue, 19 Dec 2017 19:28:22 GMT"}, {"version": "v8", "created": "Tue, 22 Oct 2019 17:22:52 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Kesidis", "George", ""]]}, {"id": "1704.04857", "submitter": "Han Deng", "authors": "Han Deng, I-Hong Hou", "title": "On the Capacity Requirement for Arbitrary End-to-End Deadline and\n  Reliability Guarantees in Multi-hop Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It has been shown that it is impossible to achieve both stringent end-to-end\ndeadline and reliability guarantees in a large network without having complete\ninformation of all future packet arrivals. In order to maintain desirable\nperformance in the presence of uncertainty of future packet arrivals, common\npractice is to add redundancy by increasing link capacities. This paper studies\nthe amount of capacity needed to provide stringent performance guarantees. We\npropose a low-complexity online algorithm and prove that it only requires a\nsmall amount of redundancy to guarantee both end-to-end deadline and\nreliability. Further, we show that in large networks with very high reliability\nrequirements, the redundancy needed by our policy is at most twice as large as\na theoretical lower bound. Also, for practical implementation, we propose a\nfully distributed protocol based on the previous centralized policy. Without\nadding redundancy, we further propose a low-complexity order-optimal online\npolicy for the network. Simulation results also show that our policy achieves\nmuch better performance than other state-of-the-art policies.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 03:20:13 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Deng", "Han", ""], ["Hou", "I-Hong", ""]]}, {"id": "1704.05316", "submitter": "Sabri Pllana", "authors": "Suejb Memeti and Lu Li and Sabri Pllana and Joanna Kolodziej and\n  Christoph Kessler", "title": "Benchmarking OpenCL, OpenACC, OpenMP, and CUDA: programming\n  productivity, performance, and energy consumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern parallel computing systems are heterogeneous at their node level.\nSuch nodes may comprise general purpose CPUs and accelerators (such as, GPU, or\nIntel Xeon Phi) that provide high performance with suitable energy-consumption\ncharacteristics. However, exploiting the available performance of heterogeneous\narchitectures may be challenging. There are various parallel programming\nframeworks (such as, OpenMP, OpenCL, OpenACC, CUDA) and selecting the one that\nis suitable for a target context is not straightforward.\n  In this paper, we study empirically the characteristics of OpenMP, OpenACC,\nOpenCL, and CUDA with respect to programming productivity, performance, and\nenergy. To evaluate the programming productivity we use our homegrown tool\nCodeStat, which enables us to determine the percentage of code lines that was\nrequired to parallelize the code using a specific framework. We use our tool\nx-MeterPU to evaluate the energy consumption and the performance. Experiments\nare conducted using the industry-standard SPEC benchmark suite and the Rodinia\nbenchmark suite for accelerated computing on heterogeneous systems that combine\nIntel Xeon E5 Processors with a GPU accelerator or an Intel Xeon Phi\nco-processor.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 13:08:35 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Memeti", "Suejb", ""], ["Li", "Lu", ""], ["Pllana", "Sabri", ""], ["Kolodziej", "Joanna", ""], ["Kessler", "Christoph", ""]]}, {"id": "1704.05592", "submitter": "Alexey Vasyukov", "authors": "Alexey Ermakov, Alexey Vasyukov", "title": "Testing Docker Performance for HPC Applications", "comments": "10 pages, 12 figures, 13 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal for this article is to compare performance penalties when using\nKVM virtualization and Docker containers for creating isolated environments for\nHPC applications. The article provides both data obtained using commonly\naccepted synthetic tests (High Performance Linpack) and real life applications\n(OpenFOAM). The article highlights the influence on resulting application\nperformance of major infrastructure configuration options: CPU type presented\nto VM, networking connection type used.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 02:48:49 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Ermakov", "Alexey", ""], ["Vasyukov", "Alexey", ""]]}, {"id": "1704.05867", "submitter": "Giuliano Casale", "authors": "Giuliano Casale", "title": "A note on integrating products of linear forms over the unit simplex", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating a product of linear forms over the unit simplex can be done in\npolynomial time if the number of variables n is fixed (V. Baldoni et al.,\n2011). In this note, we highlight that this problem is equivalent to obtaining\nthe normalizing constant of state probabilities for a popular class of Markov\nprocesses used in queueing network theory. In light of this equivalence, we\nsurvey existing computational algorithms developed in queueing theory that can\nbe used for exact integration. For example, under some regularity conditions,\nqueueing theory algorithms can exactly integrate a product of linear forms of\ntotal degree N by solving N systems of linear equations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 18:05:04 GMT"}, {"version": "v2", "created": "Sat, 6 May 2017 04:40:17 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Casale", "Giuliano", ""]]}, {"id": "1704.05954", "submitter": "Muhammad Junaid Farooq", "authors": "Muhammad Junaid Farooq and Quanyan Zhu", "title": "Optimizing Mission Critical Data Dissemination in Massive IoT Networks", "comments": "Accepted in Workshop on Spatial Stochastic Models for Wireless\n  Networks (SpaSWiN), Paris, France, May, 2017", "journal-ref": "15th International Symposium on Modeling and Optimization in\n  Mobile, Ad Hoc, and Wireless Networks (WiOpt 2017)", "doi": "10.23919/WIOPT.2017.7959930", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mission critical data dissemination in massive Internet of things (IoT)\nnetworks imposes constraints on the message transfer delay between devices. Due\nto low power and communication range of IoT devices, data is foreseen to be\nrelayed over multiple device-to-device (D2D) links before reaching the\ndestination. The coexistence of a massive number of IoT devices poses a\nchallenge in maximizing the successful transmission capacity of the overall\nnetwork alongside reducing the multi-hop transmission delay in order to support\nmission critical applications. There is a delicate interplay between the\ncarrier sensing threshold of the contention based medium access protocol and\nthe choice of packet forwarding strategy selected at each hop by the devices.\nThe fundamental problem in optimizing the performance of such networks is to\nbalance the tradeoff between conflicting performance objectives such as the\nspatial frequency reuse, transmission quality, and packet progress towards the\ndestination. In this paper, we use a stochastic geometry approach to quantify\nthe performance of multi-hop massive IoT networks in terms of the spatial\nfrequency reuse and the transmission quality under different packet forwarding\nschemes. We also develop a comprehensive performance metric that can be used to\noptimize the system to achieve the best performance. The results can be used to\nselect the best forwarding scheme and tune the carrier sensing threshold to\noptimize the performance of the network according to the delay constraints and\ntransmission quality requirements.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 23:03:40 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Farooq", "Muhammad Junaid", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1704.07355", "submitter": "Fabien Andr\\'e", "authors": "Fabien Andr\\'e (Technicolor) and Anne-Marie Kermarrec (Inria) and\n  Nicolas Le Scouarnec (Technicolor)", "title": "Accelerated Nearest Neighbor Search with Quick ADC", "comments": "8 pages, 5 figures, published in Proceedings of ICMR'17, Bucharest,\n  Romania, June 06-09, 2017", "journal-ref": null, "doi": "10.1145/3078971.3078992", "report-no": null, "categories": "cs.CV cs.DB cs.IR cs.MM cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Nearest Neighbor (NN) search in high-dimensional spaces is a\nfoundation of many multimedia retrieval systems. Because it offers low\nresponses times, Product Quantization (PQ) is a popular solution. PQ compresses\nhigh-dimensional vectors into short codes using several sub-quantizers, which\nenables in-RAM storage of large databases. This allows fast answers to NN\nqueries, without accessing the SSD or HDD. The key feature of PQ is that it can\ncompute distances between short codes and high-dimensional vectors using\ncache-resident lookup tables. The efficiency of this technique, named\nAsymmetric Distance Computation (ADC), remains limited because it performs many\ncache accesses.\n  In this paper, we introduce Quick ADC, a novel technique that achieves a 3 to\n6 times speedup over ADC by exploiting Single Instruction Multiple Data (SIMD)\nunits available in current CPUs. Efficiently exploiting SIMD requires\nalgorithmic changes to the ADC procedure. Namely, Quick ADC relies on two key\nmodifications of ADC: (i) the use 4-bit sub-quantizers instead of the standard\n8-bit sub-quantizers and (ii) the quantization of floating-point distances.\nThis allows Quick ADC to exceed the performance of state-of-the-art systems,\ne.g., it achieves a Recall@100 of 0.94 in 3.4 ms on 1 billion SIFT descriptors\n(128-bit codes).\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 17:49:37 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Andr\u00e9", "Fabien", "", "Technicolor"], ["Kermarrec", "Anne-Marie", "", "Inria"], ["Scouarnec", "Nicolas Le", "", "Technicolor"]]}, {"id": "1704.08657", "submitter": "David Barina", "authors": "David Barina and Michal Kula and Michal Matysek and Pavel Zemcik", "title": "Accelerating Discrete Wavelet Transforms on Parallel Architectures", "comments": "submitted on WSCG 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2-D discrete wavelet transform (DWT) can be found in the heart of many\nimage-processing algorithms. Until recently, several studies have compared the\nperformance of such transform on various shared-memory parallel architectures,\nespecially on graphics processing units (GPUs). All these studies, however,\nconsidered only separable calculation schemes. We show that corresponding\nseparable parts can be merged into non-separable units, which halves the number\nof steps. In addition, we introduce an optional optimization approach leading\nto a reduction in the number of arithmetic operations. The discussed schemes\nwere adapted on the OpenCL framework and pixel shaders, and then evaluated\nusing GPUs of two biggest vendors. We demonstrate the performance of the\nproposed non-separable methods by comparison with existing separable schemes.\nThe non-separable schemes outperform their separable counterparts on numerous\nsetups, especially considering the pixel shaders.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 17:01:07 GMT"}, {"version": "v2", "created": "Mon, 29 May 2017 17:39:27 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Barina", "David", ""], ["Kula", "Michal", ""], ["Matysek", "Michal", ""], ["Zemcik", "Pavel", ""]]}]