[{"id": "1702.00505", "submitter": "Luigi Nardi", "authors": "Luigi Nardi, Bruno Bodin, Sajad Saeedi, Emanuele Vespa, Andrew J.\n  Davison, Paul H. J. Kelly", "title": "Algorithmic Performance-Accuracy Trade-off in 3D Vision Applications\n  Using HyperMapper", "comments": "10 pages, Keywords: design space exploration, machine learning,\n  computer vision, SLAM, embedded systems, GPU, crowd-sourcing", "journal-ref": "31st IEEE International Parallel and Distributed Processing\n  Symposium May 29 - June 2, 2017 Orlando, Florida USA", "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate an emerging application, 3D scene understanding,\nlikely to be significant in the mobile space in the near future. The goal of\nthis exploration is to reduce execution time while meeting our quality of\nresult objectives. In previous work we showed for the first time that it is\npossible to map this application to power constrained embedded systems,\nhighlighting that decision choices made at the algorithmic design-level have\nthe most impact.\n  As the algorithmic design space is too large to be exhaustively evaluated, we\nuse a previously introduced multi-objective Random Forest Active Learning\nprediction framework dubbed HyperMapper, to find good algorithmic designs. We\nshow that HyperMapper generalizes on a recent cutting edge 3D scene\nunderstanding algorithm and on a modern GPU-based computer architecture.\nHyperMapper is able to beat an expert human hand-tuning the algorithmic\nparameters of the class of Computer Vision applications taken under\nconsideration in this paper automatically. In addition, we use crowd-sourcing\nusing a 3D scene understanding Android app to show that the Pareto front\nobtained on an embedded system can be used to accelerate the same application\non all the 83 smart-phones and tablets crowd-sourced with speedups ranging from\n2 to over 12.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 00:01:46 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 21:58:41 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Nardi", "Luigi", ""], ["Bodin", "Bruno", ""], ["Saeedi", "Sajad", ""], ["Vespa", "Emanuele", ""], ["Davison", "Andrew J.", ""], ["Kelly", "Paul H. J.", ""]]}, {"id": "1702.00629", "submitter": "Matthias Werner", "authors": "Peter Steinbach and Matthias Werner", "title": "gearshifft - The FFT Benchmark Suite for Heterogeneous Platforms", "comments": null, "journal-ref": "High Performance Computing, Theoretical Computer Science and\n  General Issues, Vol. 10266, Springer International Publishing. (ISC High\n  Performance 2017)", "doi": "10.1007/978-3-319-58667-0", "report-no": null, "categories": "cs.PF cs.MS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fast Fourier Transforms (FFTs) are exploited in a wide variety of fields\nranging from computer science to natural sciences and engineering. With the\nrising data production bandwidths of modern FFT applications, judging best\nwhich algorithmic tool to apply, can be vital to any scientific endeavor. As\ntailored FFT implementations exist for an ever increasing variety of high\nperformance computer hardware, choosing the best performing FFT implementation\nhas strong implications for future hardware purchase decisions, for resources\nFFTs consume and for possibly decisive financial and time savings ahead of the\ncompetition. This paper therefor presents gearshifft, which is an open-source\nand vendor agnostic benchmark suite to process a wide variety of problem sizes\nand types with state-of-the-art FFT implementations (fftw, clfft and cufft).\ngearshifft provides a reproducible, unbiased and fair comparison on a wide\nvariety of hardware to explore which FFT variant is best for a given problem\nsize.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 11:41:32 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 14:37:00 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Steinbach", "Peter", ""], ["Werner", "Matthias", ""]]}, {"id": "1702.02715", "submitter": "Yanjun  Qi Dr.", "authors": "Beilun Wang, Ji Gao, Yanjun Qi", "title": "A Fast and Scalable Joint Estimator for Learning Multiple Related Sparse\n  Gaussian Graphical Models", "comments": "8 pages, accepted by AISTAT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating multiple sparse Gaussian Graphical Models (sGGMs) jointly for many\nrelated tasks (large $K$) under a high-dimensional (large $p$) situation is an\nimportant task. Most previous studies for the joint estimation of multiple\nsGGMs rely on penalized log-likelihood estimators that involve expensive and\ndifficult non-smooth optimizations. We propose a novel approach, FASJEM for\n\\underline{fa}st and \\underline{s}calable \\underline{j}oint\nstructure-\\underline{e}stimation of \\underline{m}ultiple sGGMs at a large\nscale. As the first study of joint sGGM using the Elementary Estimator\nframework, our work has three major contributions: (1) We solve FASJEM through\nan entry-wise manner which is parallelizable. (2) We choose a proximal\nalgorithm to optimize FASJEM. This improves the computational efficiency from\n$O(Kp^3)$ to $O(Kp^2)$ and reduces the memory requirement from $O(Kp^2)$ to\n$O(K)$. (3) We theoretically prove that FASJEM achieves a consistent estimation\nwith a convergence rate of $O(\\log(Kp)/n_{tot})$. On several synthetic and four\nreal-world datasets, FASJEM shows significant improvements over baselines on\naccuracy, computational complexity, and memory costs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 06:09:48 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 06:49:21 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 10:44:16 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Wang", "Beilun", ""], ["Gao", "Ji", ""], ["Qi", "Yanjun", ""]]}, {"id": "1702.02968", "submitter": "Timur Bazhirov", "authors": "Mohammad Mohammadi, Timur Bazhirov", "title": "Comparative benchmarking of cloud computing vendors with High\n  Performance Linpack", "comments": null, "journal-ref": null, "doi": "10.1145/3195612.3195613", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comparative analysis of the maximum performance achieved by the\nLinpack benchmark on compute intensive hardware publicly available from\nmultiple cloud providers. We study both performance within a single compute\nnode, and speedup for distributed memory calculations with up to 32 nodes or at\nleast 512 computing cores. We distinguish between hyper-threaded and\nnon-hyper-threaded scenarios and estimate the performance per single computing\ncore. We also compare results with a traditional supercomputing system for\nreference. Our findings provide a way to rank the cloud providers and\ndemonstrate the viability of the cloud for high performance computing\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 20:11:26 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Mohammadi", "Mohammad", ""], ["Bazhirov", "Timur", ""]]}, {"id": "1702.03444", "submitter": "Abhijit Datta Banik Dr", "authors": "Abhijit Datta Banik, Mohan L. Chaudhry and Florin Avram", "title": "Steady-state analysis of single exponential vacation in a\n  $PH/MSP/1/\\infty$ queue using roots", "comments": "30 Pages, 2 figures, International Conference Zaragoza-Pau on\n  Mathematics and its Application", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an infinite-buffer single-server queue where inter-arrival times\nare phase-type ($PH$), the service is provided according to Markovian service\nprocess $(MSP)$, and the server may take single, exponentially distributed\nvacations when the queue is empty. The proposed analysis is based on roots of\nthe associated characteristic equation of the vector-generating function (VGF)\nof system-length distribution at a pre-arrival epoch. Also, we obtain the\nsteady-state system-length distribution at an arbitrary epoch along with some\nimportant performance measures such as the mean number of customers in the\nsystem and the mean system sojourn time of a customer. Later, we have\nestablished heavy- and light-traffic approximations as well as an approximation\nfor the tail probabilities at pre-arrival epoch based on one root of the\ncharacteristic equation. At the end, we present numerical results in the form\nof tables to show the effect of model parameters on the performance measures.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 17:37:57 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Banik", "Abhijit Datta", ""], ["Chaudhry", "Mohan L.", ""], ["Avram", "Florin", ""]]}, {"id": "1702.04250", "submitter": "William McDoniel", "authors": "William McDoniel (1), Markus H\\\"ohnerbach (1), Rodrigo Canales (1),\n  Ahmed E. Ismail (2), Paolo Bientinesi (2) ((1) RWTH Aachen University, (2)\n  West Virginia University)", "title": "LAMMPS' PPPM Long-Range Solver for the Second Generation Xeon Phi", "comments": "18 pages, 8 figures, submitted to ISC High Performance 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular Dynamics is an important tool for computational biologists,\nchemists, and materials scientists, consuming a sizable amount of\nsupercomputing resources. Many of the investigated systems contain charged\nparticles, which can only be simulated accurately using a long-range solver,\nsuch as PPPM. We extend the popular LAMMPS molecular dynamics code with an\nimplementation of PPPM particularly suitable for the second generation Intel\nXeon Phi. Our main target is the optimization of computational kernels by means\nof vectorization, and we observe speedups in these kernels of up to 12x. These\nimprovements carry over to LAMMPS users, with overall speedups ranging between\n2-3x, without requiring users to retune input parameters. Furthermore, our\noptimizations make it easier for users to determine optimal input parameters\nfor attaining top performance.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 15:03:05 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["McDoniel", "William", ""], ["H\u00f6hnerbach", "Markus", ""], ["Canales", "Rodrigo", ""], ["Ismail", "Ahmed E.", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1702.04653", "submitter": "Georg Hager", "authors": "Julian Hammer, Jan Eitzinger, Georg Hager, Gerhard Wellein", "title": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": "10.1007/978-3-319-56702-0_1", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving optimal program performance requires deep insight into the\ninteraction between hardware and software. For software developers without an\nin-depth background in computer architecture, understanding and fully utilizing\nmodern architectures is close to impossible. Analytic loop performance modeling\nis a useful way to understand the relevant bottlenecks of code execution based\non simple machine models. The Roofline Model and the Execution-Cache-Memory\n(ECM) model are proven approaches to performance modeling of loop nests. In\ncomparison to the Roofline model, the ECM model can also describes the\nsingle-core performance and saturation behavior on a multicore chip. We give an\nintroduction to the Roofline and ECM models, and to stencil performance\nmodeling using layer conditions (LC). We then present Kerncraft, a tool that\ncan automatically construct Roofline and ECM models for loop nests by\nperforming the required code, data transfer, and LC analysis. The layer\ncondition analysis allows to predict optimal spatial blocking factors for loop\nnests. Together with the models it enables an ab-initio estimate of the\npotential benefits of loop blocking optimizations and of useful block sizes. In\ncases where LC analysis is not easily possible, Kerncraft supports a cache\nsimulator as a fallback option. Using a 25-point long-range stencil we\ndemonstrate the usefulness and predictive power of the Kerncraft tool.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 21:20:06 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Hammer", "Julian", ""], ["Eitzinger", "Jan", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1702.04942", "submitter": "Nicola Caon", "authors": "Nicola Caon, Antonio Dorta, Juan Carlos Trelles Arjona", "title": "Benchmarking the computing resources at the Instituto de Astrof\\'isica\n  de Canarias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this study is the characterization of the computing resources used\nby researchers at the \"Instituto de Astrof\\'isica de Canarias\" (IAC). Since\nthere is a huge demand of computing time and we use tools such as HTCondor to\nimplement High Throughput Computing (HTC) across all available PCs, it is\nessential for us to assess in a quantitative way, using objective parameters,\nthe performances of our computing nodes. In order to achieve that, we have run\na set of benchmark tests on a number of different desktop and laptop PC models\namong those used in our institution. In particular, we run the \"Polyhedron\nFortran Benchmarks\" suite, using three different compilers: GNU Fortran\nCompiler, Intel Fortran Compiler and the PGI Fortran Compiler; execution times\nare then normalized to the reference values published by Polyhedron. The same\ntests were run multiple times on a same PCs, and on 3 to 5 PCs of the same\nmodel (whenever possible) to check for repeatability and consistency of the\nresults. We found that in general execution times, for a given PC model, are\nconsistent within an uncertainty of about 10%, and show a gain in CPU speed of\na factor of about 3 between the oldest PCs used at the IAC (7-8 years old) and\nthe newest ones.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 12:21:11 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Caon", "Nicola", ""], ["Dorta", "Antonio", ""], ["Arjona", "Juan Carlos Trelles", ""]]}, {"id": "1702.07195", "submitter": "Carlos Garcia", "authors": "Enzo Rucci, Carlos Garcia, Guillermo Botella, Armando De Giusti,\n  Marcelo Naiouf, Manuel Prieto-Matias", "title": "First Experiences Optimizing Smith-Waterman on Intel's Knights Landing\n  Processor", "comments": "Submitted to Euro-Par 2017 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known Smith-Waterman (SW) algorithm is the most commonly used method\nfor local sequence alignments. However, SW is very computationally demanding\nfor large protein databases. There exist several implementations that take\nadvantage of computing parallelization on many-cores, FPGAs or GPUs, in order\nto increase the alignment throughtput. In this paper, we have explored SW\nacceleration on Intel KNL processor. The novelty of this architecture requires\nthe revision of previous programming and optimization techniques on many-core\narchitectures. To the best of authors knowledge, this is the first KNL\narchitecture assessment for SW algorithm. Our evaluation, using the renowned\nEnvironmental NR database as benchmark, has shown that multi-threading and SIMD\nexploitation reports competitive performance (351 GCUPS) in comparison with\nother implementations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 12:37:54 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Rucci", "Enzo", ""], ["Garcia", "Carlos", ""], ["Botella", "Guillermo", ""], ["De Giusti", "Armando", ""], ["Naiouf", "Marcelo", ""], ["Prieto-Matias", "Manuel", ""]]}, {"id": "1702.07554", "submitter": "Johannes Hofmann", "authors": "Johannes Hofmann and Georg Hager and Gerhard Wellein and Dietmar Fey", "title": "An analysis of core- and chip-level architectural features in four\n  generations of Intel server processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a survey of architectural features among four generations\nof Intel server processors (Sandy Bridge, Ivy Bridge, Haswell, and Broad- well)\nwith a focus on performance with floating point workloads. Starting on the core\nlevel and going down the memory hierarchy we cover instruction throughput for\nfloating-point instructions, L1 cache, address generation capabilities, core\nclock speed and its limitations, L2 and L3 cache bandwidth and latency, the\nimpact of Cluster on Die (CoD) and cache snoop modes, and the Uncore clock\nspeed. Using microbenchmarks we study the influence of these factors on code\nperformance. This insight can then serve as input for analytic performance\nmodels. We show that the energy efficiency of the LINPACK and HPCG benchmarks\ncan be improved considerably by tuning the Uncore clock speed without\nsacrificing performance, and that the Graph500 benchmark performance may profit\nfrom a suitable choice of cache snoop mode settings.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 12:17:21 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Hofmann", "Johannes", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""], ["Fey", "Dietmar", ""]]}]