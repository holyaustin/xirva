[{"id": "2002.00331", "submitter": "Jun Zhao", "authors": "Yulan Gao, Chao Yong, Zehui Xiong, Jun Zhao, Yue Xiao, Dusit Niyato", "title": "Reflection Resource Management for Intelligent Reflecting Surface Aided\n  Wireless Networks", "comments": "Please feel free to contact us for questions or remarks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI cs.PF eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the adoption of an intelligent reflecting surface (IRS) for\nmultiple single-antenna source terminal (ST)-DT pairs in two-hop networks is\ninvestigated. Different from the previous studies on IRS that merely focused on\ntuning the reflection coefficient of all the reflection elements at IRS, in\nthis paper, we consider the true reflection resource management. Specifically,\nthe true reflection resource management can be realized via trigger module\nselection based on our proposed IRS architecture that all the reflection\nelements are partially controlled by multiple parallel switches of controller.\nAs the number of reflection elements increases, the true reflection resource\nmanagement will become urgently needed in this context, which is due to the\nnon-ignorable energy consumption. Moreover, the proposed modular architecture\nof IRS is designed to make the reflection elements part independent and\ncontrollable. As such, our goal is to maximize the minimum\nsignal-to-interference-plus-noise ratio (SINR) at DTs via a joint trigger\nmodule subset selection, transmit power allocation of STs, and the\ncorresponding passive beamforming of the trigger modules, subject to per ST\npower budgets and module size constraint. Whereas this problem is NP-hard due\nto the module size constraint, to deal with it, we transform the hard module\nsize constraint into the group sparse constraint by introducing the mixed row\nblock norm, which yields a suitable semidefinite relaxation. Additionally, the\nparallel alternating direction method of multipliers (PADMM) is proposed to\nidentify the trigger module subset, and then subsequently the transmit power\nallocation and passive beamforming can be obtained by solving the original\nminimum SINR maximization problem without the group sparse constraint via\npartial linearization for generalized fractional programs.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 05:15:14 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 17:28:31 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Gao", "Yulan", ""], ["Yong", "Chao", ""], ["Xiong", "Zehui", ""], ["Zhao", "Jun", ""], ["Xiao", "Yue", ""], ["Niyato", "Dusit", ""]]}, {"id": "2002.01614", "submitter": "Ji Liu", "authors": "Ji Liu, Abdullah-Al Kafi, Xipeng Shen, Huiyang Zhou", "title": "MKPipe: A Compiler Framework for Optimizing Multi-Kernel Workloads in\n  OpenCL for FPGA", "comments": "12 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenCL for FPGA enables developers to design FPGAs using a programming model\nsimilar for processors. Recent works have shown that code optimization at the\nOpenCL level is important to achieve high computational efficiency. However,\nexisting works either focus primarily on optimizing single kernels or solely\ndepend on channels to design multi-kernel pipelines. In this paper, we propose\na source-to-source compiler framework, MKPipe, for optimizing multi-kernel\nworkloads in OpenCL for FPGA. Besides channels, we propose new schemes to\nenable multi-kernel pipelines. Our optimizing compiler employs a systematic\napproach to explore the tradeoffs of these optimizations methods. To enable\nmore efficient overlapping between kernel execution, we also propose a novel\nworkitem/workgroup-id remapping technique. Furthermore, we propose new\nalgorithms for throughput balancing and resource balancing to tune the\noptimizations upon individual kernels in the multi-kernel workloads. Our\nresults show that our compiler-optimized multi-kernels achieve up to 3.6x (1.4x\non average) speedup over the baseline, in which the kernels have already been\noptimized individually.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 03:05:56 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Liu", "Ji", ""], ["Kafi", "Abdullah-Al", ""], ["Shen", "Xipeng", ""], ["Zhou", "Huiyang", ""]]}, {"id": "2002.01696", "submitter": "Josu Doncel", "authors": "Josu Doncel and Mohamad Assaad", "title": "Age of Information in a Decentralized Network of Parallel Queues with\n  Routing and Packets Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF math.OC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The paper deals with Age of Information (AoI) in a network of multiple\nsources and parallel queues with buffering capabilities, preemption in service\nand losses in served packets. The queues do not communicate between each other\nand the packets are dispatched through the queues according to a predefined\nprobabilistic routing. By making use of the Stochastic Hybrid System (SHS)\nmethod, we provide a derivation of the average AoI of a system of two parallel\nqueues (with and without buffer capabilities) and compare the results with\nthose of a single queue. We show that known results of packets delay in Queuing\nTheory do not hold for the AoI. Unfortunately, the complexity of computing the\naverage AoI using the SHS method increases highly with the number of queues. We\ntherefore provide an upper bound of the average AoI in a system of an arbitrary\nnumber of M/M/1/(N+1) queues and show its tightness in various regimes. This\nupper bound allows providing a tight approximation of the average AoI with a\nvery low complexity. We then provide a game framework that allows each source\nto determine its best probabilistic routing decision. By using Mean Field\nGames, we provide an analysis of the routing game framework, propose an\nefficient iterative method to find the routing decision of each source and\nprove its convergence to the desired equilibrium.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 09:43:34 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 21:08:18 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Doncel", "Josu", ""], ["Assaad", "Mohamad", ""]]}, {"id": "2002.01872", "submitter": "Daniela Briola", "authors": "Oscar Cornejo, Daniela Briola, Daniela Micucci, Leonardo Mariani", "title": "CBR: Controlled Burst Recording", "comments": "accepted at ICST2020 https://icst2020.info/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collecting traces from software running in the field is both useful and\nchallenging. Traces may indeed help revealing unexpected usage scenarios,\ndetecting and reproducing failures, and building behavioral models that reflect\nhow the software is actually used. On the other hand, recording traces is an\nintrusive activity that may annoy users, negatively affecting the usability of\nthe applications, if not properly designed. In this paper we address field\nmonitoring by introducing Controlled Burst Recording, a monitoring solution\nthat can collect comprehensive runtime data without compromising the quality of\nthe user experience. The technique encodes the knowledge extracted from the\nmonitored application as a finite state model that both represents the\nsequences of operations that can be executed by the users and the corresponding\ninternal computations that might be activated by each operation. Our initial\nassessment with information extracted from ArgoUML shows that Controlled Burst\nRecording can reconstruct behavioral information more effectively than\ncompeting sampling techniques, with a low impact on the system response time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:18:51 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 18:00:27 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Cornejo", "Oscar", ""], ["Briola", "Daniela", ""], ["Micucci", "Daniela", ""], ["Mariani", "Leonardo", ""]]}, {"id": "2002.01981", "submitter": "Arie Agranonik", "authors": "Arie Agranonik, Maya Herman, Mark Last", "title": "Parallel 3DPIFCM Algorithm for Noisy Brain MRI Images", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we implemented the algorithm we developed in [1] called 3DPIFCM\nin a parallel environment by using CUDA on a GPU. In our previous work we\nintroduced 3DPIFCM which performs segmentation of images in noisy conditions\nand uses particle swarm optimization for finding the optimal algorithm\nparameters to account for noise. This algorithm achieved state of the art\nsegmentation accuracy when compared to FCM (Fuzzy C-Means), IFCMPSO (Improved\nFuzzy C-Means with Particle Swarm Optimization), GAIFCM (Genetic Algorithm\nImproved Fuzzy C-Means) on noisy MRI images of an adult Brain.\n  When using a genetic algorithm or PSO (Particle Swarm Optimization) on a\nsingle machine for optimization we witnessed long execution times for practical\nclinical usage. Therefore, in the current paper our goal was to speed up the\nexecution of 3DPIFCM by taking out parts of the algorithm and executing them as\nkernels on a GPU. The algorithm was implemented using the CUDA [13] framework\nfrom NVIDIA and experiments where performed on a server containing 64GB RAM , 8\ncores and a TITAN X GPU with 3072 SP cores and 12GB of GPU memory.\n  Our results show that the parallel version of the algorithm performs up to\n27x faster than the original sequential version and 68x faster than GAIFCM\nalgorithm. We show that the speedup of the parallel version increases as we\nincrease the size of the image due to better utilization of cores in the GPU.\nAlso, we show a speedup of up to 5x in our Brainweb experiment compared to\nother generic variants such as IFCMPSO and GAIFCM.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 20:30:29 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Agranonik", "Arie", ""], ["Herman", "Maya", ""], ["Last", "Mark", ""]]}, {"id": "2002.02268", "submitter": "Bastian Hagedorn", "authors": "Bastian Hagedorn, Johannes Lenfers, Thomas Koehler, Sergei Gorlatch,\n  Michel Steuwer", "title": "A Language for Describing Optimization Strategies", "comments": "https://elevate-lang.org/ https://github.com/elevate-lang", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimizing programs to run efficiently on modern parallel hardware is hard\nbut crucial for many applications. The predominantly used imperative languages\n- like C or OpenCL - force the programmer to intertwine the code describing\nfunctionality and optimizations. This results in a nightmare for portability\nwhich is particularly problematic given the accelerating trend towards\nspecialized hardware devices to further increase efficiency.\n  Many emerging DSLs used in performance demanding domains such as deep\nlearning, automatic differentiation, or image processing attempt to simplify or\neven fully automate the optimization process. Using a high-level - often\nfunctional - language, programmers focus on describing functionality in a\ndeclarative way. In some systems such as Halide or TVM, a separate schedule\nspecifies how the program should be optimized. Unfortunately, these schedules\nare not written in well-defined programming languages. Instead, they are\nimplemented as a set of ad-hoc predefined APIs that the compiler writers have\nexposed.\n  In this paper, we present Elevate: a functional language for describing\noptimization strategies. Elevate follows a tradition of prior systems used in\ndifferent contexts that express optimization strategies as composition of\nrewrites. In contrast to systems with scheduling APIs, in Elevate programmers\nare not restricted to a set of built-in optimizations but define their own\noptimization strategies freely in a composable way. We show how user-defined\noptimization strategies in Elevate enable the effective optimization of\nprograms expressed in a functional data-parallel language demonstrating\ncompetitive performance with Halide and TVM.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 14:20:33 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Hagedorn", "Bastian", ""], ["Lenfers", "Johannes", ""], ["Koehler", "Thomas", ""], ["Gorlatch", "Sergei", ""], ["Steuwer", "Michel", ""]]}, {"id": "2002.02989", "submitter": "Georg Hager", "authors": "Ayesha Afzal and Georg Hager and Gerhard Wellein", "title": "Desynchronization and Wave Pattern Formation in MPI-Parallel and Hybrid\n  Memory-Bound Programs", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": "10.1007/978-3-030-50743-5_20", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analytic, first-principles performance modeling of distributed-memory\nparallel codes is notoriously imprecise. Even for applications with extremely\nregular and homogeneous compute-communicate phases, simply adding communication\ntime to computation time does often not yield a satisfactory prediction of\nparallel runtime due to deviations from the expected simple lockstep pattern\ncaused by system noise, variations in communication time, and inherent load\nimbalance. In this paper, we highlight the specific cases of provoked and\nspontaneous desynchronization of memory-bound, bulk-synchronous pure MPI and\nhybrid MPI+OpenMP programs. Using simple microbenchmarks we observe that\nalthough desynchronization can introduce increased waiting time per process, it\ndoes not necessarily cause lower resource utilization but can lead to an\nincrease in available bandwidth per core. In case of significant communication\noverhead, even natural noise can shove the system into a state of automatic\noverlap of communication and computation, improving the overall time to\nsolution. The saturation point, i.e., the number of processes per memory domain\nrequired to achieve full memory bandwidth, is pivotal in the dynamics of this\nprocess and the emerging stable wave pattern. We also demonstrate how hybrid\nMPI-OpenMP programming can prevent desirable desynchronization by eliminating\nthe bandwidth bottleneck among processes. A Chebyshev filter diagonalization\napplication is used to demonstrate some of the observed effects in a realistic\nsetting.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 19:25:17 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Afzal", "Ayesha", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "2002.03109", "submitter": "Pu Yuan", "authors": "Pu Yuan, Kan Zheng, Xiong Xiong, Kuan Zhang and Lei Lei", "title": "Performance Modeling and Analysis of a Hyperledger-based System Using\n  GSPN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a highly scalable permissioned blockchain platform, Hyperledger Fabric\nsupports a wide range of industry use cases ranging from governance to finance.\nIn this paper, we propose a model to analyze the performance of a\nHyperledgerbased system by using Generalised Stochastic Petri Nets (GSPN). This\nmodel decomposes a transaction flow into multiple phases and provides a\nsimulation-based approach to obtain the system latency and throughput with a\nspecific arrival rate. Based on this model, we analyze the impact of different\nconfigurations of ordering service on system performance to find out the\nbottleneck. Moreover, a mathematical configuration selection approach is\nproposed to determine the best configuration which can maximize the system\nthroughput. Finally, extensive experiments are performed on a running system to\nvalidate the proposed model and approaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 08:05:00 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yuan", "Pu", ""], ["Zheng", "Kan", ""], ["Xiong", "Xiong", ""], ["Zhang", "Kuan", ""], ["Lei", "Lei", ""]]}, {"id": "2002.03344", "submitter": "Georg Hager", "authors": "Christie L. Alappat and Johannes Hofmann and Georg Hager and Holger\n  Fehske and Alan R. Bishop and Gerhard Wellein", "title": "Understanding HPC Benchmark Performance on Intel Broadwell and Cascade\n  Lake Processors", "comments": "19 pages, 9 figures, 3 tables. Corrected affiliations and\n  acknowledgments", "journal-ref": null, "doi": "10.1007/978-3-030-50743-5_21", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware platforms in high performance computing are constantly getting more\ncomplex to handle even when considering multicore CPUs alone. Numerous features\nand configuration options in the hardware and the software environment that are\nrelevant for performance are not even known to most application users or\ndevelopers. Microbenchmarks, i.e., simple codes that fathom a particular aspect\nof the hardware, can help to shed light on such issues, but only if they are\nwell understood and if the results can be reconciled with known facts or\nperformance models. The insight gained from microbenchmarks may then be applied\nto real applications for performance analysis or optimization. In this paper we\ninvestigate two modern Intel x86 server CPU architectures in depth: Broadwell\nEP and Cascade Lake SP. We highlight relevant hardware configuration settings\nthat can have a decisive impact on code performance and show how to properly\nmeasure on-chip and off-chip data transfer bandwidths. The new victim L3 cache\nof Cascade Lake and its advanced replacement policy receive due attention.\nFinally we use DGEMM, sparse matrix-vector multiplication, and the HPCG\nbenchmark to make a connection to relevant application scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 11:25:21 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:53:06 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Alappat", "Christie L.", ""], ["Hofmann", "Johannes", ""], ["Hager", "Georg", ""], ["Fehske", "Holger", ""], ["Bishop", "Alan R.", ""], ["Wellein", "Gerhard", ""]]}, {"id": "2002.03493", "submitter": "Tianshu Hao", "authors": "Tianshu Hao, Jianfeng Zhan, Kai Hwang, Wanling Gao, Xu Wen", "title": "AI-oriented Medical Workload Allocation for Hierarchical\n  Cloud/Edge/Device Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a hierarchically-structured cloud/edge/device computing environment,\nworkload allocation can greatly affect the overall system performance. This\npaper deals with AI-oriented medical workload generated in emergency rooms (ER)\nor intensive care units (ICU) in metropolitan areas. The goal is to optimize\nAI-workload allocation to cloud clusters, edge servers, and end devices so that\nminimum response time can be achieved in life-saving emergency applications.\n  In particular, we developed a new workload allocation method for the AI\nworkload in distributed cloud/edge/device computing systems. An efficient\nscheduling and allocation strategy is developed in order to reduce the overall\nresponse time to satisfy multi-patient demands. We apply several ICU AI\nworkloads from a comprehensive edge computing benchmark Edge AIBench. The\nhealthcare AI applications involved are short-of-breath alerts, patient\nphenotype classification, and life-death threats. Our experimental results\ndemonstrate the high efficiency and effectiveness in real-life health-care and\nemergency applications.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 01:32:24 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Hao", "Tianshu", ""], ["Zhan", "Jianfeng", ""], ["Hwang", "Kai", ""], ["Gao", "Wanling", ""], ["Wen", "Xu", ""]]}, {"id": "2002.03744", "submitter": "Zijian Zhang", "authors": "Zijian Zhang and Linglong Dai", "title": "A Joint Precoding Framework for Wideband Reconfigurable Intelligent\n  Surface-Aided Cell-Free Network", "comments": "14 pages, 10 figures. This joint precoding framework considers the\n  general case of multiple BSs, multiple RISs, multiple users, multiple\n  antennas at both BSs and users, and multiple carriers, so it can be also used\n  for other special cases in which some of these parameters are single. The\n  simulation codes will be provided at:\n  http://oa.ee.tsinghua.edu.cn/dailinglong/publications/publications.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.PF cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the strong ability against the inter-cell interference, cell-free\nnetwork has been considered as a promising technique to improve the network\ncapacity of future wireless systems. However, for further capacity enhancement,\nit requires to deploy more base stations (BSs) with high cost and power\nconsumption. To address the issue, inspired by the recently proposed technique\ncalled reconfigurable intelligent surface (RIS), we propose the concept of\nRIS-aided cell-free network to improve the network capacity with low cost and\npower consumption. The key idea is to replace some of the required BSs by\nlow-cost and energy-efficient RISs, and deploy more RISs in the cell-free\nnetwork for capacity enhancement. Then, for the proposed RIS-aided cell-free\nnetwork in the typical wideband scenario, we formulate the joint precoding\ndesign problem at the BSs and RISs to maximize the network capacity. Due to the\nnon-convexity and high complexity of the formulated problem, we develop an\nalternating optimization algorithm to solve this challenging problem. In\nparticular, we decouple this problem via Lagrangian dual transform and\nfractional programming, and solve the subproblems alternatively. Note that most\nof the considered scenarios in existing works are special cases of the general\nscenario in this paper, and the proposed joint precoding framework can also\nserve as a general solution to maximize the capacity in most of existing\nRIS-aided scenarios. Finally, simulation results verify that, compared with the\nconventional cell-free network, the network capacity of the proposed scheme can\nbe improved significantly.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:43:59 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 02:25:50 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Zhang", "Zijian", ""], ["Dai", "Linglong", ""]]}, {"id": "2002.03792", "submitter": "Onel Luis Alcaraz L\\'opez", "authors": "Onel L. A. L\\'opez, Samuel Montejo-S\\'anchez, Richard D. Souza, Hirley\n  Alves, Constantinos B. Papadias", "title": "On CSI-free Multi-Antenna Schemes for Massive RF Wireless Energy\n  Transfer", "comments": "16 pags, 10 figs, 1 table, submitted to IEEE JSAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NI cs.PF stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Energy Transfer (WET) is emerging as a potential green enabler for\nmassive Internet of Things (IoT). Herein, we analyze Channel State Information\n(CSI)-free multi-antenna strategies for powering wirelessly a large set of\nsingle-antenna IoT devices. The CSI-free schemes are AA-SS (AA-IS), where all\nantennas transmit the same (independent) signal(s), and SA, where just one\nantenna transmits at a time such that all antennas are utilized during the\ncoherence block. We characterize the distribution of the provided energy under\ncorrelated Rician fading for each scheme and find out that while AA-IS and SA\ncannot take advantage of the multiple antennas to improve the average provided\nenergy, its dispersion can be significantly reduced. Meanwhile, AA-SS provides\nthe greatest average energy, but also the greatest energy dispersion, and the\ngains depend critically on the mean phase shifts between the antenna elements.\nWe find that consecutive antennas must be $\\pi$ phase-shifted for optimum\naverage energy performance under AA-SS. Our numerical results evidenced that\ncorrelation is beneficial under AA-SS, while a greater line of sight (LOS)\nand/or number of antennas is not always beneficial under such scheme.\nMeanwhile, both AA-IS and SA schemes benefit from small correlation, large LOS\nand/or large number of antennas.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 07:38:53 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 15:05:43 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["L\u00f3pez", "Onel L. A.", ""], ["Montejo-S\u00e1nchez", "Samuel", ""], ["Souza", "Richard D.", ""], ["Alves", "Hirley", ""], ["Papadias", "Constantinos B.", ""]]}, {"id": "2002.03794", "submitter": "Mingzhen Li", "authors": "Mingzhen Li, Yi Liu, Xiaoyan Liu, Qingxiao Sun, Xin You, Hailong Yang,\n  Zhongzhi Luan, Lin Gan, Guangwen Yang, Depei Qian", "title": "The Deep Learning Compiler: A Comprehensive Survey", "comments": null, "journal-ref": "IEEE Transactions on Parallel & Distributed Systems, vol. 32, no.\n  03, pp. 708-727, 2021", "doi": "10.1109/TPDS.2020.3030548", "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of deploying various deep learning (DL) models on diverse DL\nhardware has boosted the research and development of DL compilers in the\ncommunity. Several DL compilers have been proposed from both industry and\nacademia such as Tensorflow XLA and TVM. Similarly, the DL compilers take the\nDL models described in different DL frameworks as input, and then generate\noptimized codes for diverse DL hardware as output. However, none of the\nexisting survey has analyzed the unique design architecture of the DL compilers\ncomprehensively. In this paper, we perform a comprehensive survey of existing\nDL compilers by dissecting the commonly adopted design in details, with\nemphasis on the DL oriented multi-level IRs, and frontend/backend\noptimizations. Specifically, we provide a comprehensive comparison among\nexisting DL compilers from various aspects. In addition, we present detailed\nanalysis on the design of multi-level IRs and illustrate the commonly adopted\noptimization techniques. Finally, several insights are highlighted as the\npotential research directions of DL compiler. This is the first survey paper\nfocusing on the design architecture of DL compilers, which we hope can pave the\nroad for future research towards DL compiler.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 07:29:08 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 05:08:44 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 10:34:01 GMT"}, {"version": "v4", "created": "Fri, 28 Aug 2020 09:19:43 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Li", "Mingzhen", ""], ["Liu", "Yi", ""], ["Liu", "Xiaoyan", ""], ["Sun", "Qingxiao", ""], ["You", "Xin", ""], ["Yang", "Hailong", ""], ["Luan", "Zhongzhi", ""], ["Gan", "Lin", ""], ["Yang", "Guangwen", ""], ["Qian", "Depei", ""]]}, {"id": "2002.04269", "submitter": "Ludovic Thomas", "authors": "Ludovic Thomas (1) and Jean-Yves Le Boudec (1) ((1) \\'Ecole\n  Polytechnique F\\'ed\\'erale de Lausanne)", "title": "On Time Synchronization Issues in Time-Sensitive Networks with\n  Regulators and Nonideal Clocks", "comments": "ACM SIGMETRICS 2020 Boston, Massachusetts, USA June 8-12, 2020", "journal-ref": "In Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, 2, Article 27\n  (June 2020). ACM, New York, NY", "doi": "10.1145/3392145", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow reshaping is used in time-sensitive networks (as in the context of IEEE\nTSN and IETF Detnet) in order to reduce burstiness inside the network and to\nsupport the computation of guaranteed latency bounds. This is performed using\nper-flow regulators (such as the Token Bucket Filter) or interleaved regulators\n(as with IEEE TSN Asynchronous Traffic Shaping). Both types of regulators are\nbeneficial as they cancel the increase of burstiness due to multiplexing inside\nthe network. It was demonstrated, by using network calculus, that they do not\nincrease the worst-case latency. However, the properties of regulators were\nestablished assuming that time is perfect in all network nodes. In reality,\nnodes use local, imperfect clocks. Time-sensitive networks exist in two\nflavours: (1) in non-synchronized networks, local clocks run independently at\nevery node and their deviations are not controlled and (2) in synchronized\nnetworks, the deviations of local clocks are kept within very small bounds\nusing for example a synchronization protocol (such as PTP) or a satellite based\ngeo-positioning system (such as GPS). We revisit the properties of regulators\nin both cases. In non-synchronized networks, we show that ignoring the timing\ninaccuracies can lead to network instability due to unbounded delay in per-flow\nor interleaved regulators. We propose and analyze two methods (rate and burst\ncascade, and asynchronous dual arrival-curve method) for avoiding this problem.\nIn synchronized networks, we show that there is no instability with per-flow\nregulators but, surprisingly, interleaved regulators can lead to instability.\nTo establish these results, we develop a new framework that captures industrial\nrequirements on clocks in both non-synchronized and synchronized networks, and\nwe develop a toolbox that extends network calculus to account for clock\nimperfections.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:17:20 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:28:54 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 15:00:46 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Thomas", "Ludovic", ""], ["Boudec", "Jean-Yves Le", ""]]}, {"id": "2002.04416", "submitter": "Alessandro Pellegrini", "authors": "Alessandro Pellegrini", "title": "Reproducibility Report for the Paper: Modeling of Request Cloning in\n  Cloud Server Systems using Processor Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The authors have uploaded their artifact on Zenodo, which ensures a long-term\nretention of the artifact. The code is suitably documented, and some examples\nare given. A minimalistic overall description of the engine is provided. The\nartifact allows to setup the environment quite quickly, and the dependencies\nare well documented. The process to regenerate data for the figures in the\npaper completes, and all results are reproducible.\n  This paper can thus receive the Artifacts Available badge and the Artifacts\nEvaluated-Functional. Given the high quality of the artifact, also the\nArtifacts Evaluated-Reusable badge can be assigned.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 14:39:13 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Pellegrini", "Alessandro", ""]]}, {"id": "2002.04561", "submitter": "Roland Lei{\\ss}a", "authors": "Andr\\'e M\\\"uller (1), Bertil Schmidt (1), Andreas Hildebrandt (1),\n  Richard Membarth (2 and 3), Roland Lei{\\ss}a (3), Matthis Kruse (3),\n  Sebastian Hack (3) ((1) Johannes Gutenberg University, (2) DFKI, (3) Saarland\n  University)", "title": "AnySeq: A High Performance Sequence Alignment Library based on Partial\n  Evaluation", "comments": "To be published in IPDPS 2020. This work is supported by the Federal\n  Ministry of Education and Research (BMBF) as part of the MetaDL, Metacca, and\n  ProThOS projects as well as by the Intel Visual Computing Institute (IVCI)\n  and Cluster of Excellence on Multimodal Computing and Interaction (MMCI) at\n  Saarland University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence alignments are fundamental to bioinformatics which has resulted in a\nvariety of optimized implementations. Unfortunately, the vast majority of them\nare hand-tuned and specific to certain architectures and execution models. This\nnot only makes them challenging to understand and extend, but also difficult to\nport to other platforms. We present AnySeq - a novel library for computing\ndifferent types of pairwise alignments of DNA sequences. Our approach combines\nhigh performance with an intuitively understandable implementation, which is\nachieved through the concept of partial evaluation. Using the AnyDSL compiler\nframework, AnySeq enables the compilation of algorithmic variants that are\nhighly optimized for specific usage scenarios and hardware targets with a\nsingle, uniform codebase. The resulting domain-specific library thus allows the\nvariation of alignment parameters (such as alignment type, scoring scheme, and\ntraceback vs.~plain score) by simple function composition rather than\nmetaprogramming techniques which are often hard to understand. Our\nimplementation supports multithreading and SIMD vectorization on CPUs,\nCUDA-enabled GPUs, and FPGAs. AnySeq is at most 7% slower and in many cases\nfaster (up to 12%) than state-of-the art manually optimized alignment libraries\non CPUs (SeqAn) and on GPUs (NVBio).\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 17:34:12 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["M\u00fcller", "Andr\u00e9", "", "2 and 3"], ["Schmidt", "Bertil", "", "2 and 3"], ["Hildebrandt", "Andreas", "", "2 and 3"], ["Membarth", "Richard", "", "2 and 3"], ["Lei\u00dfa", "Roland", ""], ["Kruse", "Matthis", ""], ["Hack", "Sebastian", ""]]}, {"id": "2002.04834", "submitter": "Leila Rashidi", "authors": "Leila Rashidi, Don Towsley, Arman Mohseni-Kabir, and Ali Movaghar", "title": "On the Performance Analysis of Epidemic Routing in Non-Sparse Delay\n  Tolerant Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of epidemic routing in a delay tolerant network as a\nfunction of node density. Focusing on the probability of successful delivery to\na destination within a deadline (PS), we show that PS experiences a phase\ntransition as node density increases. Specifically, we prove that PS exhibits a\nphase transition when nodes are placed according to a Poisson process and\nallowed to move according to independent and identical processes with limited\nspeed. We then propose four fluid models to evaluate the performance of\nepidemic routing in non-sparse networks. A model is proposed for supercritical\nnetworks based on approximation of the infection rate as a function of time.\nOther models are based on the approximation of the pairwise infection rate. Two\nof them, one for subcritical networks and another for supercritical networks,\nuse the pairwise infection rate as a function of the number of infected nodes.\nThe other model uses pairwise infection rate as a function of time, and can be\napplied for both subcritical and supercritical networks achieving good\naccuracy. The model for subcritical networks is accurate when density is not\nclose to the percolation critical density. Moreover, the models that target\nonly supercritical regime are accurate.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:15:23 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Rashidi", "Leila", ""], ["Towsley", "Don", ""], ["Mohseni-Kabir", "Arman", ""], ["Movaghar", "Ali", ""]]}, {"id": "2002.04896", "submitter": "Vivek Gavane", "authors": "Vivek Gavane, Supriya Prabhugawankar, Shivam Garg, Archana Achalere,\n  and Rajendra Joshi", "title": "CROFT: A scalable three-dimensional parallel Fast Fourier Transform\n  (FFT) implementation for High Performance Clusters", "comments": "28 Pages, 15 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FFT of three-dimensional (3D) input data is an important computational\nkernel of numerical simulations and is widely used in High Performance\nComputing (HPC) codes running on a large number of processors. Performance of\nmany scientific applications such as Molecular Dynamic simulations depends on\nthe underlying 3D parallel FFT library being used.\n  In this paper, we present C-DACs three-dimensional Fast Fourier Transform\n(CROFT) library which implements three-dimensional parallel FFT using pencil\ndecomposition. To exploit the hyperthreading capabilities of processor cores\nwithout affecting performance, CROFT is designed to use multithreading along\nwith MPI. CROFT implementation has an innovative feature of overlapping compute\nand memory-I/O with MPI communication using multithreading. As opposed to other\n3D FFT implementations, CROFT uses only two threads where one thread is\ndedicated for communication so that it can be effectively overlapped with\ncomputations. Thus, depending on the number of processes used, CROFT achieves\nperformance improvement of about 51% to 42% as compared to FFTW3 library.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 10:12:15 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 12:57:33 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Gavane", "Vivek", ""], ["Prabhugawankar", "Supriya", ""], ["Garg", "Shivam", ""], ["Achalere", "Archana", ""], ["Joshi", "Rajendra", ""]]}, {"id": "2002.04989", "submitter": "Shrey Dabhi", "authors": "Shrey Dabhi and Manojkumar Parmar", "title": "Eigenvector Component Calculation Speedup over NumPy for\n  High-Performance Computing", "comments": "Accepted at 8th International Conference on Recent Trends in\n  Computing (ICRTC 2020), to be published in Springer Lecture Notes in Networks\n  and Systems (LNNS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications related to artificial intelligence, machine learning, and system\nidentification simulations essentially use eigenvectors. Calculating\neigenvectors for very large matrices using conventional methods is\ncompute-intensive and renders the applications slow. Recently,\nEigenvector-Eigenvalue Identity formula promising significant speedup was\nidentified. We study the algorithmic implementation of the formula against the\nexisting state-of-the-art algorithms and their implementations to evaluate the\nperformance gains. We provide a first of its kind systematic study of the\nimplementation of the formula. We demonstrate further improvements using\nhigh-performance computing concepts over native NumPy eigenvector\nimplementation which uses LAPACK and BLAS.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 13:44:41 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 16:40:42 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 20:27:06 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 07:21:06 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Dabhi", "Shrey", ""], ["Parmar", "Manojkumar", ""]]}, {"id": "2002.05091", "submitter": "James Pavur", "authors": "James Pavur, Martin Strohmeier, Vincent Lenders, Ivan Martinovic", "title": "QPEP: A QUIC-Based Approach to Encrypted Performance Enhancing Proxies\n  for High-Latency Satellite Broadband", "comments": "A reference implementation of QPEP and a dockerized version of the\n  testbed and scripts used for its evaluation can be found at\n  https://www.github.com/pavja2/qpep", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Satellite broadband services are critical infrastructures enabling advanced\ntechnologies to function in the most remote regions of the globe. However,\nstatus-quo services are often unencrypted by default and vulnerable to\neavesdropping attacks. In this paper, we challenge the historical perception\nthat over-the-air security must trade off with TCP performance in high-latency\nsatellite networks due to the deep-packet inspection requirements of\nPerformance Enhancing Proxies (PEPs).\n  After considering why prior work in this area has failed to find wide\nadoption, we present an open-source encrypted-by-default PEP - QPEP - which\nseeks to address these issues. QPEP is built around the open QUIC standard and\ndesigned so individual customers may adopt it without ISP involvement. QPEP's\nperformance is assessed through simulations in a replicable docker-based\ntestbed. Across many benchmarks and network conditions, QPEP is found to avoid\nthe perceived security-encryption trade-off in PEP design. Compared to\nunencrypted PEP implementations, QPEP reduces average page load times by more\nthan 30% while also offering over-the-air privacy. Compared to the traditional\nVPN encryption available to customers today, QPEP more than halves average page\nload times. Together, these experiments lead to the conclusion that QPEP\nrepresents a promising new approach to protecting modern satellite broadband\nconnections.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:54:00 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Pavur", "James", ""], ["Strohmeier", "Martin", ""], ["Lenders", "Vincent", ""], ["Martinovic", "Ivan", ""]]}, {"id": "2002.05666", "submitter": "Behnam Pourghassemi", "authors": "Behnam Pourghassemi, Jordan Bonecutter, Zhou Li, Aparna\n  Chandramowlishwaran", "title": "adPerf: Characterizing the Performance of Third-party Ads", "comments": "13 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monetizing websites and web apps through online advertising is widespread in\nthe web ecosystem. The online advertising ecosystem nowadays forces publishers\nto integrate ads from these third-party domains. On the one hand, this raises\nseveral privacy and security concerns that are actively studied in recent\nyears. On the other hand, given the ability of today's browsers to load dynamic\nweb pages with complex animations and Javascript, online advertising has also\ntransformed and can have a significant impact on webpage performance. The\nperformance cost of online ads is critical since it eventually impacts user\nsatisfaction as well as their Internet bill and device energy consumption.\n  In this paper, we apply an in-depth and first-of-a-kind performance\nevaluation of web ads. Unlike prior efforts that rely primarily on adblockers,\nwe perform a fine-grained analysis on the web browser's page loading process to\ndemystify the performance cost of web ads. We aim to characterize the cost by\nevery component of an ad, so the publisher, ad syndicate, and advertiser can\nimprove the ad's performance with detailed guidance. For this purpose, we\ndevelop an infrastructure, adPerf, for the Chrome browser that classifies page\nloading workloads into ad-related and main-content at the granularity of\nbrowser activities (such as Javascript and Layout). Our evaluations show that\nonline advertising entails more than 15% of browser page loading workload and\napproximately 88% of that is spent on JavaScript. We also track the sources and\ndelivery chain of web ads and analyze performance considering the origin of the\nad contents. We observe that 2 of the well-known third-party ad domains\ncontribute to 35% of the ads performance cost and surprisingly, top news\nwebsites implicitly include unknown third-party ads which in some cases build\nup to more than 37% of the ads performance cost.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:09:05 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Pourghassemi", "Behnam", ""], ["Bonecutter", "Jordan", ""], ["Li", "Zhou", ""], ["Chandramowlishwaran", "Aparna", ""]]}, {"id": "2002.05884", "submitter": "Leila Rashidi", "authors": "Leila Rashidi, Amir Dalili-Yazdi, Reza Entezari-Maleki, Leonel Sousa,\n  and Ali Movaghar", "title": "Performance Modeling of Epidemic Routing in Mobile Social Networks with\n  Emphasis on Scalability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the performance of epidemic routing in mobile social\nnetworks. It first analyzes the time taken for a node to meet the first node of\na set of nodes restricted to move in a specific subarea. Afterwards, a\nmonolithic Stochastic Reward Net (SRN) is proposed to evaluate the delivery\ndelay and the average number of transmissions under epidemic routing by\nconsidering skewed location visiting preferences. This model is not scalable\nenough, in terms of the number of nodes and frequently visited locations. In\norder to achieve higher scalability, the folding technique is applied to the\nmonolithic model, and an approximate folded SRN is proposed to evaluate\nperformance of epidemic routing. Discrete-event simulation is used to validate\nthe proposed models. Both SRN models show high accuracy in predicting the\nperformance of epidemic routing. We also propose an Ordinary Differential\nEquation (ODE) model for epidemic routing and compare it with the folded model.\nObtained results show that the folded model is more accurate than the ODE\nmodel. Moreover, it is proved that the number of transmissions by the time of\ndelivery follows uniform distribution, in a general class of networks, where\npositions of nodes are always independent and identically distributed.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 06:29:12 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Rashidi", "Leila", ""], ["Dalili-Yazdi", "Amir", ""], ["Entezari-Maleki", "Reza", ""], ["Sousa", "Leonel", ""], ["Movaghar", "Ali", ""]]}, {"id": "2002.06018", "submitter": "Takahiro Hirofuchi", "authors": "Takahiro Hirofuchi and Ryousei Takano", "title": "A Prompt Report on the Performance of Intel Optane DC Persistent Memory\n  Module", "comments": "To appear in IEICE Transactions on Information and Systems, 2020.\n  arXiv admin note: substantial text overlap with arXiv:1907.12014", "journal-ref": null, "doi": "10.1587/transinf.2019EDL8141", "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this prompt report, we present the basic performance evaluation of Intel\nOptane Data Center Persistent Memory Module (Optane DCPMM), which is the first\ncommercially-available, byte-addressable non-volatile memory modules released\nin April 2019. Since at the moment of writing only a few reports on its\nperformance were published, this letter is intended to complement other\nperformance studies. Through experiments using our own measurement tools, we\nobtained that the latency of random read-only access was approximately 374 ns.\nThat of random writeback-involving access was 391 ns. The bandwidths of\nread-only and writeback-involving access for interleaved memory modules were\napproximately 38 GB/s and 3 GB/s, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 08:00:56 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Hirofuchi", "Takahiro", ""], ["Takano", "Ryousei", ""]]}, {"id": "2002.06129", "submitter": "Gregory Kiar", "authors": "Pierre Rioux, Gregory Kiar, Alexandre Hutton, Alan C. Evans, Shawn T.\n  Brown", "title": "Deploying large fixed file datasets with SquashFS and Singularity", "comments": "5 pages, 2 figures, 2 tables. Submitted to PEARC 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared high-performance computing (HPC) platforms, such as those provided by\nXSEDE and Compute Canada, enable researchers to carry out large-scale\ncomputational experiments at a fraction of the cost of the cloud. Most systems\nrequire the use of distributed filesystems (e.g. Lustre) for providing a highly\nmulti-user, large capacity storage environment. These suffer performance\npenalties as the number of files increases due to network contention and\nmetadata performance. We demonstrate how a combination of two technologies,\nSingularity and SquashFS, can help developers, integrators, architects, and\nscientists deploy large datasets (O(10M) files) on these shared systems with\nminimal performance limitations. The proposed integration enables more\nefficient access and indexing than normal file-based dataset installations,\nwhile providing transparent file access to users and processes. Furthermore,\nthe approach does not require administrative privileges on the target system.\nWhile the examples studied here have been taken from the field of neuroimaging,\nthe technologies adopted are not specific to that field. Currently, this\nsolution is limited to read-only datasets. We propose the adoption of this\ntechnology for the consumption and dissemination of community datasets across\nshared computing resources.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:00:32 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Rioux", "Pierre", ""], ["Kiar", "Gregory", ""], ["Hutton", "Alexandre", ""], ["Evans", "Alan C.", ""], ["Brown", "Shawn T.", ""]]}, {"id": "2002.06603", "submitter": "Samuel S. Ogden", "authors": "Samuel S. Ogden and Tian Guo", "title": "MDInference: Balancing Inference Accuracy and Latency for Mobile\n  Applications", "comments": "To be published as an invited paper at IC2E'20. 10.5 pages (9.5 text\n  + 1 bibliography) 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are allowing mobile devices to incorporate a wide range\nof features into user applications. However, the computational complexity of\nthese models makes it difficult to run them effectively on resource-constrained\nmobile devices. Prior work approached the problem of supporting deep learning\nin mobile applications by either decreasing model complexity or utilizing\npowerful cloud servers. These approaches each only focus on a single aspect of\nmobile inference and thus they often sacrifice overall performance.\n  In this work we introduce a holistic approach to designing mobile deep\ninference frameworks. We first identify the key goals of accuracy and latency\nfor mobile deep inference and the conditions that must be met to achieve them.\nWe demonstrate our holistic approach through the design of a hypothetical\nframework called MDInference. This framework leverages two complementary\ntechniques; a model selection algorithm that chooses from a set of cloud-based\ndeep learning models to improve inference accuracy and an on-device request\nduplication mechanism to bound latency. Through empirically-driven simulations\nwe show that MDInference improves aggregate accuracy over static approaches by\nover 40% without incurring SLA violations. Additionally, we show that with a\ntarget latency of 250ms, MDInference increased the aggregate accuracy in 99.74%\ncases on faster university networks and 96.84% cases on residential networks.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 15:51:28 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 23:56:56 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 16:35:42 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Ogden", "Samuel S.", ""], ["Guo", "Tian", ""]]}, {"id": "2002.06906", "submitter": "Tim Hellemans", "authors": "Tim Hellemans and Benny Van Houdt", "title": "Performance Analysis of Load Balancing Policies with Memory", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joining the shortest or least loaded queue among $d$ randomly selected queues\nare two fundamental load balancing policies. Under both policies the dispatcher\ndoes not maintain any information on the queue length or load of the servers.\nIn this paper we analyze the performance of these policies when the dispatcher\nhas some memory available to store the ids of some of the idle servers. We\nconsider methods where the dispatcher discovers idle servers as well as methods\nwhere idle servers inform the dispatcher about their state.\n  We focus on large-scale systems and our analysis uses the cavity method. The\nmain insight provided is that the performance measures obtained via the cavity\nmethod for a load balancing policy {\\it with} memory reduce to the performance\nmeasures for the same policy {\\it without} memory provided that the arrival\nrate is properly scaled. Thus, we can study the performance of load balancers\nwith memory in the same manner as load balancers without memory. In particular\nthis entails closed form solutions for joining the shortest or least loaded\nqueue among $d$ randomly selected queues with memory in case of exponential job\nsizes. Moreover, we obtain a simple closed form expression for the (scaled)\nexpected waiting time as the system tends towards instability.\n  We present simulation results that support our belief that the approximation\nobtained by the cavity method becomes exact as the number of servers tends to\ninfinity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:08:52 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 15:30:09 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Hellemans", "Tim", ""], ["Van Houdt", "Benny", ""]]}, {"id": "2002.07062", "submitter": "Mohit Sinha", "authors": "Phani Kumar Nyshadham, Mohit Sinha, Biswajit Mishra, H S Vijay", "title": "An optimal scheduling architecture for accelerating batch algorithms on\n  Neural Network processor architectures", "comments": "9 pages, page 7 contains the proposed example", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural network topologies, algorithms are running on batches of data\ntensors. The batches of data are typically scheduled onto the computing cores\nwhich execute in parallel. For the algorithms running on batches of data, an\noptimal batch scheduling architecture is very much needed by suitably utilizing\nhardware resources - thereby resulting in significant reduction training and\ninference time. In this paper, we propose to accelerate the batch algorithms\nfor neural networks through a scheduling architecture enabling optimal compute\npower utilization. The proposed optimal scheduling architecture can be built\ninto HW or can be implemented in SW alone which can be leveraged for\naccelerating batch algorithms. The results demonstrate that the proposed\narchitecture speeds up the batch algorithms compared to the previous solutions.\nThe proposed idea applies to any HPC architecture meant for neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:13:13 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Nyshadham", "Phani Kumar", ""], ["Sinha", "Mohit", ""], ["Mishra", "Biswajit", ""], ["Vijay", "H S", ""]]}, {"id": "2002.07162", "submitter": "Wanling Gao", "authors": "Wanling Gao, Fei Tang, Jianfeng Zhan, Chuanxin Lan, Chunjie Luo, Lei\n  Wang, Jiahui Dai, Zheng Cao, Xiongwang Xiong, Zihan Jiang, Tianshu Hao, Fanda\n  Fan, Xu Wen, Fan Zhang, Yunyou Huang, Jianan Chen, Mengjia Du, Rui Ren, Chen\n  Zheng, Daoyi Zheng, Haoning Tang, Kunlin Zhan, Biao Wang, Defei Kong, Minghe\n  Yu, Chongkang Tan, Huan Li, Xinhui Tian, Yatao Li, Gang Lu, Junchao Shao,\n  Zhenyu Wang, Xiaoyu Wang, Hainan Ye", "title": "AIBench: An Agile Domain-specific Benchmarking Methodology and an AI\n  Benchmark Suite", "comments": "25 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:1908.08998", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific software and hardware co-design is encouraging as it is much\neasier to achieve efficiency for fewer tasks. Agile domain-specific\nbenchmarking speeds up the process as it provides not only relevant design\ninputs but also relevant metrics, and tools. Unfortunately, modern workloads\nlike Big data, AI, and Internet services dwarf the traditional one in terms of\ncode size, deployment scale, and execution path, and hence raise serious\nbenchmarking challenges.\n  This paper proposes an agile domain-specific benchmarking methodology.\nTogether with seventeen industry partners, we identify ten important end-to-end\napplication scenarios, among which sixteen representative AI tasks are\ndistilled as the AI component benchmarks. We propose the permutations of\nessential AI and non-AI component benchmarks as end-to-end benchmarks. An\nend-to-end benchmark is a distillation of the essential attributes of an\nindustry-scale application. We design and implement a highly extensible,\nconfigurable, and flexible benchmark framework, on the basis of which, we\npropose the guideline for building end-to-end benchmarks, and present the first\nend-to-end Internet service AI benchmark.\n  The preliminary evaluation shows the value of our benchmark suite---AIBench\nagainst MLPerf and TailBench for hardware and software designers,\nmicro-architectural researchers, and code developers. The specifications,\nsource code, testbed, and results are publicly available from the web site\n\\url{http://www.benchcouncil.org/AIBench/index.html}.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 07:29:05 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gao", "Wanling", ""], ["Tang", "Fei", ""], ["Zhan", "Jianfeng", ""], ["Lan", "Chuanxin", ""], ["Luo", "Chunjie", ""], ["Wang", "Lei", ""], ["Dai", "Jiahui", ""], ["Cao", "Zheng", ""], ["Xiong", "Xiongwang", ""], ["Jiang", "Zihan", ""], ["Hao", "Tianshu", ""], ["Fan", "Fanda", ""], ["Wen", "Xu", ""], ["Zhang", "Fan", ""], ["Huang", "Yunyou", ""], ["Chen", "Jianan", ""], ["Du", "Mengjia", ""], ["Ren", "Rui", ""], ["Zheng", "Chen", ""], ["Zheng", "Daoyi", ""], ["Tang", "Haoning", ""], ["Zhan", "Kunlin", ""], ["Wang", "Biao", ""], ["Kong", "Defei", ""], ["Yu", "Minghe", ""], ["Tan", "Chongkang", ""], ["Li", "Huan", ""], ["Tian", "Xinhui", ""], ["Li", "Yatao", ""], ["Lu", "Gang", ""], ["Shao", "Junchao", ""], ["Wang", "Zhenyu", ""], ["Wang", "Xiaoyu", ""], ["Ye", "Hainan", ""]]}, {"id": "2002.07641", "submitter": "Michael Norris", "authors": "Michael Norris, Berkay Celik, Patrick McDaniel, Gang Tan, Prasanna\n  Venkatesh, Shulin Zhao, and Anand Sivasubramaniam", "title": "IoTRepair: Systematically Addressing Device Faults in Commodity IoT\n  (Extended Paper)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT devices are decentralized and deployed in un-stable environments, which\ncauses them to be prone to various kinds of faults, such as device failure and\nnetwork disruption. Yet, current IoT platforms require programmers to handle\nfaults manually, a complex and error-prone task. In this paper, we present\nIoTRepair, a fault-handling system for IoT that (1)integrates a fault\nidentification module to track faulty devices,(2) provides a library of\nfault-handling functions for effectively handling different fault types, (3)\nprovides a fault handler on top of the library for autonomous IoT fault\nhandling, with user and developer configuration as input. Through an evaluation\nin a simulated lab environment and with various fault injectio\nnmethods,IoTRepair is compared with current fault-handling solutions. The fault\nhandler reduces the incorrect states on average 50.01%, which corresponds to\nless unsafe and insecure device states. Overall, through a systematic design of\nan IoT fault handler, we provide users flexibility and convenience in handling\ncomplex IoT fault handling, allowing safer IoT environments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:27:52 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Norris", "Michael", ""], ["Celik", "Berkay", ""], ["McDaniel", "Patrick", ""], ["Tan", "Gang", ""], ["Venkatesh", "Prasanna", ""], ["Zhao", "Shulin", ""], ["Sivasubramaniam", "Anand", ""]]}, {"id": "2002.07752", "submitter": "Prasanth Chatarasi", "authors": "Prasanth Chatarasi, Hyoukjun Kwon, Natesh Raina, Saurabh Malik,\n  Vaisakh Haridas, Angshuman Parashar, Michael Pellauer, Tushar Krishna, Vivek\n  Sarkar", "title": "Marvel: A Data-centric Compiler for DNN Operators on Spatial\n  Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of a spatial DNN accelerator depends heavily on the compiler\nand its cost model ability to generate optimized mappings for various operators\nof DNN models on to the accelerator's compute and memory resources. But,\nexisting cost models lack a formal boundary over the operators for precise and\ntractable analysis, which poses adaptability challenges for new DNN operators.\nTo address this challenge, we leverage the recently introduced Maestro\nData-Centric (MDC) notation. We develop a formal understanding of DNN operators\nwhose mappings can be described in the MDC notation, because any mapping\nadhering to the notation is always analyzable by the MDC's cost model.\nFurthermore, we introduce a transformation for translating mappings into the\nMDC notation for exploring the mapping space.\n  Searching for the optimal mappings is challenging because of the large space\nof mappings, and this challenge gets exacerbated with new operators and diverse\naccelerator configurations.To address this challenge, we propose a decoupled\noff-chip/on-chip approach that decomposes the mapping space into off-chip and\non-chip subspaces, and first optimizes the off-chip subspace followed by the\non-chip subspace. The motivation for this decomposition is to reduce the size\nof the search space dramatically and also to prioritize the optimization of\noff-chip data movement, which is 2-3 orders of magnitude more compared to the\non-chip data movement. We implemented our approach in a tool called {\\em\nMarvel}, and another major benefit of our approach is that it is applicable to\nany DNN operator conformable with the MDC notation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:39:21 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 19:08:00 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Chatarasi", "Prasanth", ""], ["Kwon", "Hyoukjun", ""], ["Raina", "Natesh", ""], ["Malik", "Saurabh", ""], ["Haridas", "Vaisakh", ""], ["Parashar", "Angshuman", ""], ["Pellauer", "Michael", ""], ["Krishna", "Tushar", ""], ["Sarkar", "Vivek", ""]]}, {"id": "2002.07795", "submitter": "Yehia Arafa", "authors": "Yehia Arafa, Ammar ElWazir, Abdelrahman ElKanishy, Youssef Aly,\n  Ayatelrahman Elsayed, Abdel-Hameed Badawy, Gopinath Chennupati, Stephan\n  Eidenbenz, and Nandakishore Santhi", "title": "Verified Instruction-Level Energy Consumption Measurement for NVIDIA\n  GPUs", "comments": null, "journal-ref": null, "doi": "10.1145/3387902.3392613", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs are prevalent in modern computing systems at all scales. They consume a\nsignificant fraction of the energy in these systems. However, vendors do not\npublish the actual cost of the power/energy overhead of their internal\nmicroarchitecture. In this paper, we accurately measure the energy consumption\nof various PTX instructions found in modern NVIDIA GPUs. We provide an\nexhaustive comparison of more than 40 instructions for four high-end NVIDIA\nGPUs from four different generations (Maxwell, Pascal, Volta, and Turing).\nFurthermore, we show the effect of the CUDA compiler optimizations on the\nenergy consumption of each instruction. We use three different software\ntechniques to read the GPU on-chip power sensors, which use NVIDIA's NVML API\nand provide an in-depth comparison between these techniques. Additionally, we\nverified the software measurement techniques against a custom-designed hardware\npower measurement. The results show that Volta GPUs have the best energy\nefficiency of all the other generations for the different categories of the\ninstructions. This work should aid in understanding NVIDIA GPUs'\nmicroarchitecture. It should also make energy measurements of any GPU kernel\nboth efficient and accurate.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:49:24 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 19:58:14 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Arafa", "Yehia", ""], ["ElWazir", "Ammar", ""], ["ElKanishy", "Abdelrahman", ""], ["Aly", "Youssef", ""], ["Elsayed", "Ayatelrahman", ""], ["Badawy", "Abdel-Hameed", ""], ["Chennupati", "Gopinath", ""], ["Eidenbenz", "Stephan", ""], ["Santhi", "Nandakishore", ""]]}, {"id": "2002.08084", "submitter": "Arliones Stevert Hoeller Junior", "authors": "Arliones Hoeller, Richard Demo Souza, Samuel Montejo-S\\'anchez, and\n  Hirley Alves", "title": "Performance Analysis of Single-Cell Adaptive Data Rate-Enabled LoRaWAN", "comments": "4 pages, 4 figures, accepted for publication in IEEE Wireless\n  Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LoRaWAN enables massive connectivity for Internet-of-Things applications.\nMany published works employ stochastic geometry to derive outage models of\nLoRaWAN over fading channels assuming fixed transmit power and distance-based\nspreading factor (SF) allocation. However, in practice, LoRaWAN employs the\nAdaptive Data Rate (ADR) mechanism, which dynamically adjusts SF and transmit\npower of nodes based on channel state. The community addressed the performance\nof ADR using simulations, but analytical models have not been introduced. In\nthis letter, we seek to close this gap. We build over an analytical LoRaWAN\nmodel to consider the performance of steady-state ADR-enabled LoRaWAN. We\nderive outage expressions and an optimization procedure to maximize the number\nof users under reliability constraints. Results show that power allocation\nreduces interference and improves network capacity while reducing average\npower.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 09:41:44 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Hoeller", "Arliones", ""], ["Souza", "Richard Demo", ""], ["Montejo-S\u00e1nchez", "Samuel", ""], ["Alves", "Hirley", ""]]}, {"id": "2002.08141", "submitter": "Avi Mohan", "authors": "Avinash Mohan, Aditya Gopalan and Anurag Kumar", "title": "Throughput Optimal Decentralized Scheduling with Single-bit State\n  Feedback for a Class of Queueing Systems", "comments": "53 pages, 18 figures, IEEE/ACM Transactions on Networking", "journal-ref": "IEEE/ACM Transactions on Networking, April 2020", "doi": "10.1109/TNET.2020.2976923", "report-no": null, "categories": "cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by medium access control for resource-challenged wireless Internet\nof Things (IoT), we consider the problem of queue scheduling with reduced queue\nstate information. In particular, we consider a time-slotted scheduling model\nwith $N$ sensor nodes, with pair-wise dependence, such that Nodes $i$ and $i +\n1,~0 < i < N$ cannot transmit together. We develop new throughput-optimal\nscheduling policies requiring only the empty-nonempty state of each queue that\nwe term Queue Nonemptiness-Based (QNB) policies. We propose a Policy Splicing\ntechnique to combine scheduling policies for small networks in order to\nconstruct throughput-optimal policies for larger networks, some of which also\naim for low delay. For $N = 3,$ there exists a sum-queue length optimal QNB\nscheduling policy. We show, however, that for $N > 4,$ there is no QNB policy\nthat is sum-queue length optimal over all arrival rate vectors in the capacity\nregion.\n  We then extend our results to a more general class of interference\nconstraints that we call cluster-of-cliques (CoC) conflict graphs. We consider\ntwo types of CoC networks, namely, Linear Arrays of Cliques (LAoC) and\nStar-of-Cliques (SoC) networks. We develop QNB policies for these classes of\nnetworks, study their stability and delay properties, and propose and analyze\ntechniques to reduce the amount of state information to be disseminated across\nthe network for scheduling. In the SoC setting, we propose a throughput-optimal\npolicy that only uses information that nodes in the network can glean by\nsensing activity (or lack thereof) on the channel. Our throughput-optimality\nresults rely on two new arguments: a Lyapunov drift lemma specially adapted to\npolicies that are queue length-agnostic, and a priority queueing analysis for\nshowing strong stability.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 12:48:20 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Mohan", "Avinash", ""], ["Gopalan", "Aditya", ""], ["Kumar", "Anurag", ""]]}, {"id": "2002.08161", "submitter": "Salvatore Cielo", "authors": "Salvatore Cielo, Luigi Iapichino, Fabio Baruffa, Matteo Bugli and\n  Christoph Federrath", "title": "Honing and proofing Astrophysical codes on the road to Exascale.\n  Experiences from code modernization on many-core systems", "comments": "16 pages, 10 figures, 4 tables. To be published in Future Generation\n  of Computer Systems (FGCS), Special Issue on \"On The Road to Exascale II:\n  Advances in High Performance Computing and Simulations\"", "journal-ref": "Future Generation of Computer Systems,Volume 112, November 2020,\n  Pages 93-107", "doi": "10.1016/j.future.2020.05.003", "report-no": null, "categories": "cs.DC astro-ph.IM cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of modern and upcoming computing architectures poses severe\nchallenges for code developers and application specialists, and forces them to\nexpose the highest possible degree of parallelism, in order to make the best\nuse of the available hardware. The Intel$^{(R)}$ Xeon Phi$^{(TM)}$ of second\ngeneration (code-named Knights Landing, henceforth KNL) is the latest many-core\nsystem, which implements several interesting hardware features like for example\na large number of cores per node (up to 72), the 512 bits-wide vector registers\nand the high-bandwidth memory. The unique features of KNL make this platform a\npowerful testbed for modern HPC applications. The performance of codes on KNL\nis therefore a useful proxy of their readiness for future architectures. In\nthis work we describe the lessons learnt during the optimisation of the widely\nused codes for computational astrophysics P-Gadget-3, Flash and Echo. Moreover,\nwe present results for the visualisation and analysis tools VisIt and yt. These\nexamples show that modern architectures benefit from code optimisation at\ndifferent levels, even more than traditional multi-core systems. However, the\nlevel of modernisation of typical community codes still needs improvements, for\nthem to fully utilise resources of novel architectures.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 13:18:01 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Cielo", "Salvatore", ""], ["Iapichino", "Luigi", ""], ["Baruffa", "Fabio", ""], ["Bugli", "Matteo", ""], ["Federrath", "Christoph", ""]]}, {"id": "2002.08181", "submitter": "Twan Basten", "authors": "Martijn Hendriks, Marc Geilen, Kees Goossens, Rob de Jong, Twan Basten", "title": "Interface Modeling for Quality and Resource Management", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (May 26,\n  2021) lmcs:7513", "doi": null, "report-no": null, "categories": "cs.LO cs.DM cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop an interface-modeling framework for quality and resource\nmanagement that captures configurable working points of hardware and software\ncomponents in terms of functionality, resource usage and provision, and quality\nindicators such as performance and energy consumption. We base these aspects on\npartially-ordered sets to capture quality levels, budget sizes, and functional\ncompatibility. This makes the framework widely applicable and domain\nindependent (although we aim for embedded and cyber-physical systems). The\nframework paves the way for dynamic (re-)configuration and multi-objective\noptimization of component-based systems for quality- and resource-management\npurposes.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 13:42:21 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 22:05:06 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 14:30:22 GMT"}, {"version": "v4", "created": "Tue, 25 May 2021 12:49:05 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Hendriks", "Martijn", ""], ["Geilen", "Marc", ""], ["Goossens", "Kees", ""], ["de Jong", "Rob", ""], ["Basten", "Twan", ""]]}, {"id": "2002.08256", "submitter": "Arliones Stevert Hoeller Junior", "authors": "Arliones Hoeller, Jean Sant'Ana, Juho Markkula, Konstantin Mikhaylov,\n  Richard Souza, Hirley Alves", "title": "Beyond 5G Low-Power Wide-Area Networks: A LoRaWAN Suitability Study", "comments": "5 pages, 4 figures, accepted for presentation at 6G Wireless Summit\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PF eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deliver a discussion regarding the role of Low-Power\nWide-Area Networks (LPWAN) in the cellular Internet-of-Things (IoT)\ninfrastructure to support massive Machine-Type Communications (mMTC) in\nnext-generation wireless systems beyond 5G. We commence by presenting a\nperformance analysis of current LPWAN systems, specifically LoRaWAN, in terms\nof coverage and throughput. The results obtained using analytic methods and\nnetwork simulations are combined in the paper for getting a more comprehensive\nvision. Next, we identify possible performance bottlenecks, speculate on the\ncharacteristics of coming IoT applications, and seek to identify potential\nenhancements to the current technologies that may overcome the identified\nshortcomings.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:03:28 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Hoeller", "Arliones", ""], ["Sant'Ana", "Jean", ""], ["Markkula", "Juho", ""], ["Mikhaylov", "Konstantin", ""], ["Souza", "Richard", ""], ["Alves", "Hirley", ""]]}, {"id": "2002.08316", "submitter": "J\\'anos V\\'egh", "authors": "J\\'anos V\\'egh", "title": "Re-evaluating scaling methods for distributed parallel systems", "comments": "12 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2001.01266", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper explains why Amdahl's Law shall be interpreted specifically for\ndistributed parallel systems and why it generated so many debates, discussions,\nand abuses. We set up a general model and list many of the terms affecting\nparallel processing. We scrutinize the validity of neglecting certain terms in\ndifferent approximations, with special emphasis on the famous scaling laws of\nparallel processing. We clarify that when using the right interpretation of\nterms, Amdahl's Law is the governing law of all kinds of parallel processing.\nAmdahl's Law describes among others the history of supercomputing, the inherent\nperformance limitation of the different kinds of parallel processing and it is\nthe basic Law of the 'modern computing' paradigm, that the computing systems\nworking under extreme computing conditions are desperately needed.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 20:49:12 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 16:36:08 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["V\u00e9gh", "J\u00e1nos", ""]]}, {"id": "2002.08908", "submitter": "Xingyu Zhou", "authors": "Xingyu Zhou, Ness Shroff and Adam Wierman", "title": "Asymptotically Optimal Load Balancing in Large-scale Heterogeneous\n  Systems with Multiple Dispatchers", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the load balancing problem in large-scale heterogeneous systems\nwith multiple dispatchers. We introduce a general framework called\nLocal-Estimation-Driven (LED). Under this framework, each dispatcher keeps\nlocal (possibly outdated) estimates of queue lengths for all the servers, and\nthe dispatching decision is made purely based on these local estimates. The\nlocal estimates are updated via infrequent communications between dispatchers\nand servers. We derive sufficient conditions for LED policies to achieve\nthroughput optimality and delay optimality in heavy-traffic, respectively.\nThese conditions directly imply delay optimality for many previous local-memory\nbased policies in heavy traffic. Moreover, the results enable us to design new\ndelay optimal policies for heterogeneous systems with multiple dispatchers.\nFinally, the heavy-traffic delay optimality of the LED framework directly\nresolves a recent open problem on how to design optimal load balancing schemes\nusing delayed information.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:52:53 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Zhou", "Xingyu", ""], ["Shroff", "Ness", ""], ["Wierman", "Adam", ""]]}, {"id": "2002.08987", "submitter": "Muhammad Shahbaz", "authors": "Tushar Swamy, Alexander Rucker, Muhammad Shahbaz, and Kunle Olukotun", "title": "Taurus: An Intelligent Data Plane", "comments": "12 pages, 13 figures, and 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging applications -- cloud computing, the internet of things, and\naugmented/virtual reality -- need responsive, available, secure, ubiquitous,\nand scalable datacenter networks. Network management currently uses simple,\nper-packet, data-plane heuristics (e.g., ECMP and sketches) under an\nintelligent, millisecond-latency control plane that runs data-driven\nperformance and security policies. However, to meet users' quality-of-service\nexpectations in a modern data center, networks must operate intelligently at\nline rate. In this paper, we present Taurus, an intelligent data plane capable\nof machine-learning inference at line rate. Taurus adds custom hardware based\non a map-reduce abstraction to programmable network devices, such as switches\nand NICs; this new hardware uses pipelined and SIMD parallelism for fast\ninference. Our evaluation of a Taurus-enabled switch ASIC -- supporting several\nreal-world benchmarks -- shows that Taurus operates three orders of magnitude\nfaster than a server-based control plane, while increasing area by 24% and\nlatency, on average, by 178 ns. On the long road to self-driving networks,\nTaurus is the equivalent of adaptive cruise control: deterministic rules steer\nflows, while machine learning tunes performance and heightens security.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:18:36 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Swamy", "Tushar", ""], ["Rucker", "Alexander", ""], ["Shahbaz", "Muhammad", ""], ["Olukotun", "Kunle", ""]]}, {"id": "2002.09179", "submitter": "Mattia Lecci", "authors": "Mattia Lecci and Paolo Testolina and Marco Giordani and Michele Polese\n  and Tanguy Ropitault and Camillo Gentile and Neeraj Varshney and Anuraag Bodi\n  and Michele Zorzi", "title": "Simplified Ray Tracing for the Millimeter Wave Channel: A Performance\n  Evaluation", "comments": "6 pages, 6 figures, 1 table. This paper has been accepted for\n  presentation at ITA 2020. (c) 2020 IEEE. Please cite it as: M. Lecci, P.\n  Testolina, M. Giordani, M. Polese, T. Ropitault, C. Gentile, N. Varshney, A.\n  Bodi, M. Zorzi, \"Simplified Ray Tracing for the Millimeter Wave Channel: A\n  Performance Evaluation,\" Information Theory and Applications Workshop (ITA),\n  San Diego, US, 2020", "journal-ref": null, "doi": "10.1109/ITA50056.2020.9244950", "report-no": null, "categories": "eess.SP cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter-wave (mmWave) communication is one of the cornerstone innovations\nof fifth-generation (5G) wireless networks, thanks to the massive bandwidth\navailable in these frequency bands. To correctly assess the performance of such\nsystems, however, it is essential to have reliable channel models, based on a\ndeep understanding of the propagation characteristics of the mmWave signal. In\nthis respect, ray tracers can provide high accuracy, at the expense of a\nsignificant computational complexity, which limits the scalability of\nsimulations. To address this issue, in this paper we present possible\nsimplifications that can reduce the complexity of ray tracing in the mmWave\nenvironment, without significantly affecting the accuracy of the model. We\nevaluate the effect of such simplifications on link-level metrics, testing\ndifferent configuration parameters and propagation scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 08:32:07 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Lecci", "Mattia", ""], ["Testolina", "Paolo", ""], ["Giordani", "Marco", ""], ["Polese", "Michele", ""], ["Ropitault", "Tanguy", ""], ["Gentile", "Camillo", ""], ["Varshney", "Neeraj", ""], ["Bodi", "Anuraag", ""], ["Zorzi", "Michele", ""]]}, {"id": "2002.09477", "submitter": "Chen Yuan", "authors": "Yi Lu, Chen Yuan, Xiang Zhang, Hua Huang, Guangyi Liu, Renchang Dai,\n  Zhiwei Wang", "title": "Graph Computing based Distributed State Estimation with PMUs", "comments": "5 pages, 3 figures, 3 tables, 2020 IEEE Power and Energy Society\n  General Meeting. arXiv admin note: substantial text overlap with\n  arXiv:1902.06893", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA cs.PF eess.SP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power system state estimation plays a fundamental and critical role in the\nenergy management system (EMS). To achieve a high performance and accurate\nsystem states estimation, a graph computing based distributed state estimation\napproach is proposed in this paper. Firstly, a power system network is divided\ninto multiple areas. Reference buses are selected with PMUs being installed at\nthese buses for each area. Then, the system network is converted into multiple\nindependent areas. In this way, the power system state estimation could be\nconducted in parallel for each area and the estimated system states are\nobtained without compromise of accuracy. IEEE 118-bus system and MP 10790-bus\nsystem are employed to verify the results accuracy and present the promising\ncomputation performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 21:58:32 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lu", "Yi", ""], ["Yuan", "Chen", ""], ["Zhang", "Xiang", ""], ["Huang", "Hua", ""], ["Liu", "Guangyi", ""], ["Dai", "Renchang", ""], ["Wang", "Zhiwei", ""]]}, {"id": "2002.10333", "submitter": "Yaser Ebazadeh", "authors": "Reza Fotohi, Yaser Ebazadeh, Mohammad Seyyar Geshlag", "title": "A New Approach for Improvement Security against DoS Attacks in Vehicular\n  Ad-hoc Network", "comments": "7 pages, 12 figures, 2 tables, 4 equation, journal", "journal-ref": "Int J Adv Comput Sci Appl, 7(7), 10-16 (2016)", "doi": "10.14569/IJACSA.2016.070702", "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular Ad-Hoc Networks (VANET) are a proper subset of mobile wireless\nnetworks, where nodes are revulsive, the vehicles are armed with special\nelectronic devices on the motherboard OBU (On Board Unit) which enables them to\ntrasmit and receive messages from other vehicles in the VANET. Furthermore the\ncommunication between the vehicles, the VANET interface is donated by the\ncontact points with road infrastructure. VANET is a subgroup of MANETs. Unlike\nthe MANETs nodes, VANET nodes are moving very fast. Impound a permanent route\nfor the dissemination of emergency messages and alerts from a danger zone is a\nvery challenging task. Therefore, routing plays a significant duty in VANETs.\ndecreasing network overhead, avoiding network congestion, increasing traffic\ncongestion and packet delivery ratio are the most important issues associated\nwith routing in VANETs. In addition, VANET network is subject to various\nsecurity attacks. In base VANET systems, an algorithm is used to dicover\nattacks at the time of confirmation in which overhead delay occurs. This paper\nproposes (P-Secure) approach which is used for the detection of DoS attacks\nbefore the confirmation time. This reduces the overhead delays for processing\nand increasing the security in VANETs. Simulation results show that the\nP-Secure approach, is more efficient than OBUmodelVaNET approach in terms of\nPDR, e2e_delay, throughput and drop packet rate.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:01:36 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Fotohi", "Reza", ""], ["Ebazadeh", "Yaser", ""], ["Geshlag", "Mohammad Seyyar", ""]]}, {"id": "2002.10788", "submitter": "Emilio Incerto", "authors": "Giulio Garbi and Emilio Incerto and Mirco Tribastone", "title": "Learning Queuing Networks by Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3358960.3379134", "report-no": null, "categories": "cs.PF cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that building analytical performance models in practice is\ndifficult because it requires a considerable degree of proficiency in the\nunderlying mathematics. In this paper, we propose a machine-learning approach\nto derive performance models from data. We focus on queuing networks, and\ncrucially exploit a deterministic approximation of their average dynamics in\nterms of a compact system of ordinary differential equations. We encode these\nequations into a recurrent neural network whose weights can be directly related\nto model parameters. This allows for an interpretable structure of the neural\nnetwork, which can be trained from system measurements to yield a white-box\nparameterized model that can be used for prediction purposes such as what-if\nanalyses and capacity planning. Using synthetic models as well as a real case\nstudy of a load-balancing system, we show the effectiveness of our technique in\nyielding models with high predictive power.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:56:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Garbi", "Giulio", ""], ["Incerto", "Emilio", ""], ["Tribastone", "Mirco", ""]]}, {"id": "2002.12556", "submitter": "EPTCS", "authors": "Nuno Baeta (University of Coimbra), Pedro Quaresma (University of\n  Coimbra), Zolt\\'an Kov\\'acs (The Private University College of Education of\n  the Diocese of Linz)", "title": "Towards a Geometry Automated Provers Competition", "comments": "In Proceedings ThEdu'19, arXiv:2002.11895", "journal-ref": "EPTCS 313, 2020, pp. 93-100", "doi": "10.4204/EPTCS.313.6", "report-no": null, "categories": "cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometry automated theorem proving area distinguishes itself by a large\nnumber of specific methods and implementations, different approaches\n(synthetic, algebraic, semi-synthetic) and different goals and applications\n(from research in the area of artificial intelligence to applications in\neducation).\n  Apart from the usual measures of efficiency (e.g. CPU time), the possibility\nof visual and/or readable proofs is also an expected output against which the\ngeometry automated theorem provers (GATP) should be measured.\n  The implementation of a competition between GATP would allow to create a test\nbench for GATP developers to improve the existing ones and to propose new ones.\nIt would also allow to establish a ranking for GATP that could be used by\n\"clients\" (e.g. developers of educational e-learning systems) to choose the\nbest implementation for a given intended use.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:24:29 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Baeta", "Nuno", "", "University of Coimbra"], ["Quaresma", "Pedro", "", "University of\n  Coimbra"], ["Kov\u00e1cs", "Zolt\u00e1n", "", "The Private University College of Education of\n  the Diocese of Linz"]]}, {"id": "2002.12798", "submitter": "Yida Wang", "authors": "Hongbin Zheng, Sejong Oh, Huiqing Wang, Preston Briggs, Jiading Gai,\n  Animesh Jain, Yizhi Liu, Rich Heaton, Randy Huang, Yida Wang", "title": "Optimizing Memory-Access Patterns for Deep Learning Accelerators", "comments": "Extended abstract for a poster presented at C4ML workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) workloads are moving towards accelerators for faster\nprocessing and lower cost. Modern DL accelerators are good at handling the\nlarge-scale multiply-accumulate operations that dominate DL workloads; however,\nit is challenging to make full use of the compute power of an accelerator since\nthe data must be properly staged in a software-managed scratchpad memory.\nFailing to do so can result in significant performance loss. This paper\nproposes a systematic approach which leverages the polyhedral model to analyze\nall operators of a DL model together to minimize the number of memory accesses.\nExperiments show that our approach can substantially reduce the impact of\nmemory accesses required by common neural-network models on a homegrown AWS\nmachine-learning inference chip named Inferentia, which is available through\nAmazon EC2 Inf1 instances.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 05:06:19 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zheng", "Hongbin", ""], ["Oh", "Sejong", ""], ["Wang", "Huiqing", ""], ["Briggs", "Preston", ""], ["Gai", "Jiading", ""], ["Jain", "Animesh", ""], ["Liu", "Yizhi", ""], ["Heaton", "Rich", ""], ["Huang", "Randy", ""], ["Wang", "Yida", ""]]}]