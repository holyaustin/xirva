[{"id": "1705.00140", "submitter": "S Raja", "authors": "V. Arvind, Rajit Datta, Partha Mukhopadhyay, S. Raja", "title": "Efficient Identity Testing and Polynomial Factorization over\n  Non-associative Free Rings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study arithmetic computations in the nonassociative, and\nnoncommutative free polynomial ring $\\mathbb{F}\\{x_1,x_2,\\ldots,x_n\\}$. Prior\nto this work, nonassociative arithmetic computation was considered by Hrubes,\nWigderson, and Yehudayoff [HWY10], and they showed lower bounds and proved\ncompleteness results. We consider Polynomial Identity Testing (PIT) and\npolynomial factorization over $\\mathbb{F}\\{x_1,x_2,\\ldots,x_n\\}$ and show the\nfollowing results. (1) Given an arithmetic circuit $C$ of size $s$ computing a\npolynomial $f\\in \\mathbb{F} \\{x_1,x_2,\\ldots,x_n\\}$ of degree $d$, we give a\ndeterministic $poly(n,s,d)$ algorithm to decide if $f$ is identically zero\npolynomial or not. Our result is obtained by a suitable adaptation of the PIT\nalgorithm of Raz-Shpilka [RS05] for noncommutative ABPs. (2) Given an\narithmetic circuit $C$ of size $s$ computing a polynomial $f\\in \\mathbb{F}\n\\{x_1,x_2,\\ldots,x_n\\}$ of degree $d$, we give an efficient deterministic\nalgorithm to compute circuits for the irreducible factors of $f$ in time\n$poly(n,s,d)$ when $\\mathbb{F}=\\mathbb{Q}$. Over finite fields of\ncharacteristic $p$, our algorithm runs in time $poly(n,s,d,p)$.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 07:04:07 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 06:12:46 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Arvind", "V.", ""], ["Datta", "Rajit", ""], ["Mukhopadhyay", "Partha", ""], ["Raja", "S.", ""]]}, {"id": "1705.00942", "submitter": "Heng Guo", "authors": "Jin-Yi Cai, Heng Guo, Tyson Williams", "title": "Clifford Gates in the Holant Framework", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Clifford gates and stabilizer circuits in the quantum\ncomputing literature, which admit efficient classical simulation, are\nequivalent to affine signatures under a unitary condition. The latter is a\nknown class of tractable functions under the Holant framework.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 12:40:37 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Guo", "Heng", ""], ["Williams", "Tyson", ""]]}, {"id": "1705.01194", "submitter": "Jess Banks", "authors": "Jess Banks, Robert Kleinberg, Cristopher Moore", "title": "The Lov\\'asz Theta Function for Random Regular Graphs and Community\n  Detection in the Hard Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.SI math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive upper and lower bounds on the degree $d$ for which the Lov\\'asz\n$\\vartheta$ function, or equivalently sum-of-squares proofs with degree two,\ncan refute the existence of a $k$-coloring in random regular graphs $G_{n,d}$.\nWe show that this type of refutation fails well above the $k$-colorability\ntransition, and in particular everywhere below the Kesten-Stigum threshold.\nThis is consistent with the conjecture that refuting $k$-colorability, or\ndistinguishing $G_{n,d}$ from the planted coloring model, is hard in this\nregion. Our results also apply to the disassortative case of the stochastic\nblock model, adding evidence to the conjecture that there is a regime where\ncommunity detection is computationally hard even though it is\ninformation-theoretically possible. Using orthogonal polynomials, we also\nprovide explicit upper bounds on $\\vartheta(\\overline{G})$ for regular graphs\nof a given girth, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 22:56:43 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 17:54:57 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Banks", "Jess", ""], ["Kleinberg", "Robert", ""], ["Moore", "Cristopher", ""]]}, {"id": "1705.01465", "submitter": "S\\'andor Kisfaludi-Bak", "authors": "Mark de Berg, Hans L. Bodlaender, S\\'andor Kisfaludi-Bak", "title": "The Homogeneous Broadcast Problem in Narrow and Wide Strips", "comments": "50 pages, WADS 2017 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of nodes in a wireless network, where each node is modeled\nas a point in the plane, and let $s\\in P$ be a given source node. Each node $p$\ncan transmit information to all other nodes within unit distance, provided $p$\nis activated. The (homogeneous) broadcast problem is to activate a minimum\nnumber of nodes such that in the resulting directed communication graph, the\nsource $s$ can reach any other node. We study the complexity of the regular and\nthe hop-bounded version of the problem (in the latter, $s$ must be able to\nreach every node within a specified number of hops), with the restriction that\nall points lie inside a strip of width $w$. We almost completely characterize\nthe complexity of both the regular and the hop-bounded versions as a function\nof the strip width $w$.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 14:48:56 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["de Berg", "Mark", ""], ["Bodlaender", "Hans L.", ""], ["Kisfaludi-Bak", "S\u00e1ndor", ""]]}, {"id": "1705.01497", "submitter": "John Augustine", "authors": "John Augustine, Krishna Palem, and Parishkrati", "title": "Sustaining Moore's Law Through Inexactness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inexact computing aims to compute good solutions that require considerably\nless resource -- typically energy -- compared to computing exact solutions.\nWhile inexactness is motivated by concerns derived from technology scaling and\nMoore's law, there is no formal or foundational framework for reasoning about\nthis novel approach to designing algorithms. In this work, we present a\nfundamental relationship between the quality of computing the value of a\nboolean function and the energy needed to compute it in a mathematically\nrigorous and general setting. On this basis, one can study the tradeoff between\nthe quality of the solution to a problem and the amount of energy that is\nconsumed. We accomplish this by introducing a computational model to classify\nproblems based on notions of symmetry inspired by physics. We show that some\nproblems are symmetric in that every input bit is, in a sense, equally\nimportant, while other problems display a great deal of asymmetry in the\nimportance of input bits. We believe that our model is novel and provides a\nfoundation for inexact Computing. Building on this, we show that asymmetric\nproblems allow us to invest resources favoring the important bits -- a feature\nthat can be leveraged to design efficient inexact algorithms. On the negative\nside and in contrast, we can prove that the best inexact algorithms for\nsymmetric problems are no better than simply reducing the resource investment\nuniformly across all bits. Akin to classical theories concerned with space and\ntime complexity, we believe the ability to classify problems as shown in our\npaper will serve as a basis for formally reasoning about the effectiveness of\ninexactness in the context of a range of computational problems with energy\nbeing the primary resource.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 16:24:13 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 13:26:34 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Augustine", "John", ""], ["Palem", "Krishna", ""], ["Parishkrati", "", ""]]}, {"id": "1705.01595", "submitter": "Holger Dell", "authors": "Radu Curticapean and Holger Dell and D\\'aniel Marx", "title": "Homomorphisms Are a Good Basis for Counting Small Subgraphs", "comments": "An extended abstract of this paper appears at STOC 2017", "journal-ref": null, "doi": "10.1145/3055399.3055502", "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce graph motif parameters, a class of graph parameters that depend\nonly on the frequencies of constant-size induced subgraphs. Classical works by\nLov\\'asz show that many interesting quantities have this form, including, for\nfixed graphs $H$, the number of $H$-copies (induced or not) in an input graph\n$G$, and the number of homomorphisms from $H$ to $G$.\n  Using the framework of graph motif parameters, we obtain faster algorithms\nfor counting subgraph copies of fixed graphs $H$ in host graphs $G$: For graphs\n$H$ on $k$ edges, we show how to count subgraph copies of $H$ in time\n$k^{O(k)}\\cdot n^{0.174k + o(k)}$ by a surprisingly simple algorithm. This\nimproves upon previously known running times, such as $O(n^{0.91k + c})$ time\nfor $k$-edge matchings or $O(n^{0.46k + c})$ time for $k$-cycles.\n  Furthermore, we prove a general complexity dichotomy for evaluating graph\nmotif parameters: Given a class $\\mathcal C$ of such parameters, we consider\nthe problem of evaluating $f\\in \\mathcal C$ on input graphs $G$, parameterized\nby the number of induced subgraphs that $f$ depends upon. For every recursively\nenumerable class $\\mathcal C$, we prove the above problem to be either FPT or\n#W[1]-hard, with an explicit dichotomy criterion. This allows us to recover\nknown dichotomies for counting subgraphs, induced subgraphs, and homomorphisms\nin a uniform and simplified way, together with improved lower bounds.\n  Finally, we extend graph motif parameters to colored subgraphs and prove a\ncomplexity trichotomy: For vertex-colored graphs $H$ and $G$, where $H$ is from\na fixed class $\\mathcal H$, we want to count color-preserving $H$-copies in\n$G$. We show that this problem is either polynomial-time solvable or FPT or\n#W[1]-hard, and that the FPT cases indeed need FPT time under reasonable\nassumptions.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 19:47:33 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Curticapean", "Radu", ""], ["Dell", "Holger", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "1705.01720", "submitter": "Shay Moran", "authors": "Daniel M. Kane and Shachar Lovett and Shay Moran", "title": "Near-optimal linear decision trees for k-SUM and related problems", "comments": "18 paged, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct near optimal linear decision trees for a variety of decision\nproblems in combinatorics and discrete geometry. For example, for any constant\n$k$, we construct linear decision trees that solve the $k$-SUM problem on $n$\nelements using $O(n \\log^2 n)$ linear queries. Moreover, the queries we use are\ncomparison queries, which compare the sums of two $k$-subsets; when viewed as\nlinear queries, comparison queries are $2k$-sparse and have only $\\{-1,0,1\\}$\ncoefficients. We give similar constructions for sorting sumsets $A+B$ and for\nsolving the SUBSET-SUM problem, both with optimal number of queries, up to\npoly-logarithmic terms.\n  Our constructions are based on the notion of \"inference dimension\", recently\nintroduced by the authors in the context of active classification with\ncomparison queries. This can be viewed as another contribution to the fruitful\nlink between machine learning and discrete geometry, which goes back to the\ndiscovery of the VC dimension.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 07:11:47 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Kane", "Daniel M.", ""], ["Lovett", "Shachar", ""], ["Moran", "Shay", ""]]}, {"id": "1705.01773", "submitter": "Maksims Dimitrijevs", "authors": "Maksims Dimitrijevs, Abuzer Yakary{\\i}lmaz", "title": "Uncountable realtime probabilistic classes", "comments": "12 pages. Accepted to DCFS2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the minimum cases for realtime probabilistic machines that can\ndefine uncountably many languages with bounded error. We show that logarithmic\nspace is enough for realtime PTMs on unary languages. On binary case, we follow\nthe same result for double logarithmic space, which is tight. When replacing\nthe worktape with some limited memories, we can follow uncountable results on\nunary languages for two counters.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 10:08:06 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Dimitrijevs", "Maksims", ""], ["Yakary\u0131lmaz", "Abuzer", ""]]}, {"id": "1705.01826", "submitter": "Stefan Rass", "authors": "Stefan Rass", "title": "Towards a Physical Oracle for the Partition Problem using Analogue\n  Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable achievements in its practical tractability, the notorious\nclass of NP-complete problems has been escaping all attempts to find a\nworst-case polynomial time-bound solution algorithms for any of them. The vast\nmajority of work relies on Turing machines or equivalent models, all of which\nrelate to digital computing. This raises the question of whether a computer\nthat is (partly) non-digital could offer a new door towards an efficient\nsolution. And indeed, the partition problem, which is another NP-complete\nsibling of the famous Boolean satisfiability problem SAT, might be open to\nefficient solutions using analogue computing. We investigate this hypothesis\nhere, providing experimental evidence that Partition, and in turn also SAT, may\nbecome tractable on a combined digital and analogue computing machine. This\nwork provides mostly theoretical and based on simulations, and as such does not\nexhibit a polynomial time algorithm to solve NP-complete problems. Instead, it\nis intended as a pointer to new directions of research on special-purpose\ncomputing architectures that may help handling the class NP efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 13:11:47 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Rass", "Stefan", ""]]}, {"id": "1705.01843", "submitter": "Ronald de Wolf", "authors": "Joran van Apeldoorn, Andr\\'as Gily\\'en, Sander Gribling, Ronald de\n  Wolf", "title": "Quantum SDP-Solvers: Better upper and lower bounds", "comments": "v4: 69 pages, small corrections and clarifications. This version will\n  appear in Quantum", "journal-ref": "Quantum 4, 230 (2020)", "doi": "10.22331/q-2020-02-14-230", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brand\\~ao and Svore very recently gave quantum algorithms for approximately\nsolving semidefinite programs, which in some regimes are faster than the\nbest-possible classical algorithms in terms of the dimension $n$ of the problem\nand the number $m$ of constraints, but worse in terms of various other\nparameters. In this paper we improve their algorithms in several ways, getting\nbetter dependence on those other parameters. To this end we develop new\ntechniques for quantum algorithms, for instance a general way to efficiently\nimplement smooth functions of sparse Hamiltonians, and a generalized\nminimum-finding procedure.\n  We also show limits on this approach to quantum SDP-solvers, for instance for\ncombinatorial optimizations problems that have a lot of symmetry. Finally, we\nprove some general lower bounds showing that in the worst case, the complexity\nof every quantum LP-solver (and hence also SDP-solver) has to scale linearly\nwith $mn$ when $m\\approx n$, which is the same as classical.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 13:59:43 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 10:19:03 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 10:57:55 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2020 19:18:46 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["van Apeldoorn", "Joran", ""], ["Gily\u00e9n", "Andr\u00e1s", ""], ["Gribling", "Sander", ""], ["de Wolf", "Ronald", ""]]}, {"id": "1705.02397", "submitter": "Nikhil Mande", "authors": "Arkadev Chattopadhyay and Nikhil S. Mande", "title": "Weights at the Bottom Matter When the Top is Heavy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proving super-polynomial lower bounds against depth-2 threshold circuits of\nthe form THR of THR is a well-known open problem that represents a frontier of\nour understanding in boolean circuit complexity. By contrast, exponential lower\nbounds on the size of THR of MAJ circuits were shown by Razborov and Sherstov\n(SIAM J.Comput., 2010) even for computing functions in depth-3 AC^0. Yet, no\nseparation among the two depth-2 threshold circuit classes were known. In fact,\nit is not clear a priori that they ought to be different. In particular,\nGoldmann, Hastad and Razborov (Computational Complexity, 1992) showed that the\nclass MAJ of MAJ is identical to the class MAJ of THR.\n  In this work, we provide an exponential separation between THR of MAJ and THR\nof THR. We achieve this by showing a function f that is computed by linear size\nTHR of THR circuits and yet has exponentially large sign rank. This, by a\nwell-known result, implies that f requires exponentially large THR of MAJ\ncircuits to be computed. Our result suggests that the sign rank method alone is\nunlikely to prove strong lower bounds against THR of THR circuits.\n  The main technical ingredient of our work is to prove a strong sign rank\nlower bound for an XOR function. This requires novel use of approximation\ntheoretic tools.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 21:08:31 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Chattopadhyay", "Arkadev", ""], ["Mande", "Nikhil S.", ""]]}, {"id": "1705.02417", "submitter": "Tommaso Gagliardoni", "authors": "Tommaso Gagliardoni", "title": "Quantum Security of Cryptographic Primitives", "comments": "PhD Thesis. This document is an electronic version with minor\n  modifications of the original, published through the E-Publishing-Service of\n  the TU Darmstadt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We call quantum security the area of IT security dealing with scenarios where\none or more parties have access to quantum hardware. This encompasses both the\nfields of post-quantum cryptography (that is, traditional cryptography\nengineered to be resistant against quantum adversaries), and quantum\ncryptography (that is, security protocols designed to be natively run on a\nquantum infrastructure, such as quantum key distribution).\n  In this work, we propose the first systematic classification of quantum\nsecurity scenarios, and for each of them we recall the main tools and results,\nas well as presenting new ones. We achieve this goal by identifying four\ndistinct quantum security classes, or domains, each of them encompassing the\nsecurity notions and constructions related to a particular scenario. We start\nwith the class QS0, which is `classical cryptography' (meaning that no quantum\nscenario is considered). Regarding post-quantum cryptography, we introduce the\nclass QS1, where we discuss in detail the problems arising when designing a\nclassical cryptographic object meant to be resistant against adversaries with\nlocal quantum computing power, and we provide a classification of the possible\nquantum security reductions in this scenario when considering provable\nsecurity. In respect to hybrid classical-quantum models, in the security class\nQS2 we discuss in detail the possible scenarios where these scenarios arise,\nand what a correct formalization should be in terms of quantum oracle access.\nFinally, in the class QS3 we consider all those cryptographic constructions\ndesigned to run natively on quantum hardware.\n  We believe that the framework we introduce in this work will be a valuable\ntool for the scientific community in addressing the challenges arising when\nformalizing sound constructions and notions of security in the quantum world.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 23:21:31 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Gagliardoni", "Tommaso", ""]]}, {"id": "1705.02944", "submitter": "Rasmus J Kyng", "authors": "Rasmus Kyng, Peng Zhang", "title": "Hardness Results for Structured Linear Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if the nearly-linear time solvers for Laplacian matrices and\ntheir generalizations can be extended to solve just slightly larger families of\nlinear systems, then they can be used to quickly solve all systems of linear\nequations over the reals. This result can be viewed either positively or\nnegatively: either we will develop nearly-linear time algorithms for solving\nall systems of linear equations over the reals, or progress on the families we\ncan solve in nearly-linear time will soon halt.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 16:11:26 GMT"}, {"version": "v2", "created": "Sun, 24 Sep 2017 18:28:43 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Kyng", "Rasmus", ""], ["Zhang", "Peng", ""]]}, {"id": "1705.03188", "submitter": "Ramya C", "authors": "C.Ramya, B.V.Raghavendra Rao", "title": "Linear Projections of the Vandermonde Polynomial", "comments": "Submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An n-variate Vandermonde polynomial is the determinant of the n x n matrix\nwhere the ith column is the vector (1, x_i, x_i^2, ...., x_i^{n-1})^T.\nVandermonde polynomials play a crucial role in the theory of alternating\npolynomials and occur in Lagrangian polynomial interpolation as well as in the\ntheory of error correcting codes. In this work we study structural and\ncomputational aspects of linear projections of Vandermonde polynomials.\nFirstly, we consider the problem of testing if a given polynomial is linearly\nequivalent to the Vandermonde polynomial. We obtain a deterministic polynomial\ntime algorithm to test if the polynomial f is linearly equivalent to the\nVandermonde polynomial when f is given as product of linear factors. In the\ncase when the polynomial f is given as a black-box our algorithm runs in\nrandomized polynomial time. Exploring the structure of projections of\nVandermonde polynomials further, we describe the group of symmetries of a\nVandermonde polynomial and show that the associated Lie algebra is simple.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 05:52:18 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Ramya", "C.", ""], ["Rao", "B. V. Raghavendra", ""]]}, {"id": "1705.03263", "submitter": "Gustav Nordh", "authors": "Gustav Nordh", "title": "A Note on the Power of Non-Deterministic Circuits with Gate Restrictions", "comments": "Corrected some glitches in the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the power of non-deterministic circuits over restricted sets\nof base gates. We note that the power of non-deterministic circuits exhibit a\ndichotomy, in the following sense: For weak enough bases, non-deterministic\ncircuits are no more powerful than deterministic circuits, and for the\nremaining bases, non-deterministic circuits are super polynomial more efficient\nthan deterministic circuits (under the assumption that $P/poly \\neq NP/poly$).\nMoreover, we give a precise characterization of the borderline between the two\nsituations.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 10:24:57 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 11:00:32 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Nordh", "Gustav", ""]]}, {"id": "1705.03283", "submitter": "Daniel Neuen", "authors": "Daniel Neuen and Pascal Schweitzer", "title": "An exponential lower bound for Individualization-Refinement algorithms\n  for Graph Isomorphism", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The individualization-refinement paradigm provides a strong toolbox for\ntesting isomorphism of two graphs and indeed, the currently fastest\nimplementations of isomorphism solvers all follow this approach. While these\nsolvers are fast in practice, from a theoretical point of view, no general\nlower bounds concerning the worst case complexity of these tools are known. In\nfact, it is an open question whether individualization-refinement algorithms\ncan achieve upper bounds on the running time similar to the more theoretical\ntechniques based on a group theoretic approach.\n  In this work we give a negative answer to this question and construct a\nfamily of graphs on which algorithms based on the individualization-refinement\nparadigm require exponential time. Contrary to a previous construction of\nMiyazaki, that only applies to a specific implementation within the\nindividualization-refinement framework, our construction is immune to changing\nthe cell selector, or adding various heuristic invariants to the algorithm.\nFurthermore, our graphs also provide exponential lower bounds in the case when\nthe $k$-dimensional Weisfeiler-Leman algorithm is used to replace the standard\ncolor refinement operator and the arguments even work when the entire\nautomorphism group of the inputs is initially provided to the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 11:41:16 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Neuen", "Daniel", ""], ["Schweitzer", "Pascal", ""]]}, {"id": "1705.03284", "submitter": "Janne H. Korhonen", "authors": "Janne H. Korhonen, Jukka Suomela", "title": "Towards a complexity theory for the congested clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The congested clique model of distributed computing has been receiving\nattention as a model for densely connected distributed systems. While there has\nbeen significant progress on the side of upper bounds, we have very little in\nterms of lower bounds for the congested clique; indeed, it is now know that\nproving explicit congested clique lower bounds is as difficult as proving\ncircuit lower bounds.\n  In this work, we use various more traditional complexity-theoretic tools to\nbuild a clearer picture of the complexity landscape of the congested clique:\n  -- Nondeterminism and beyond: We introduce the nondeterministic congested\nclique model (analogous to NP) and show that there is a natural canonical\nproblem family that captures all problems solvable in constant time with\nnondeterministic algorithms. We further generalise these notions by introducing\nthe constant-round decision hierarchy (analogous to the polynomial hierarchy).\n  -- Non-constructive lower bounds: We lift the prior non-uniform counting\narguments to a general technique for proving non-constructive uniform lower\nbounds for the congested clique. In particular, we prove a time hierarchy\ntheorem for the congested clique, showing that there are decision problems of\nessentially all complexities, both in the deterministic and nondeterministic\nsettings.\n  -- Fine-grained complexity: We map out relationships between various natural\nproblems in the congested clique model, arguing that a reduction-based\ncomplexity theory currently gives us a fairly good picture of the complexity\nlandscape of the congested clique.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 11:43:38 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 12:29:35 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2018 14:48:45 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Korhonen", "Janne H.", ""], ["Suomela", "Jukka", ""]]}, {"id": "1705.03581", "submitter": "Pasin Manurangsi", "authors": "Pasin Manurangsi", "title": "Inapproximability of Maximum Biclique Problems, Minimum $k$-Cut and\n  Densest At-Least-$k$-Subgraph from the Small Set Expansion Hypothesis", "comments": "A preliminary version of this work will appear at ICALP 2017 under a\n  different title \"Inapproximability of Maximum Edge Biclique, Maximum Balanced\n  Biclique and Minimum k-Cut from the Small Set Expansion Hypothesis\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Small Set Expansion Hypothesis (SSEH) is a conjecture which roughly\nstates that it is NP-hard to distinguish between a graph with a small subset of\nvertices whose edge expansion is almost zero and one in which all small subsets\nof vertices have expansion almost one. In this work, we prove inapproximability\nresults for the following graph problems based on this hypothesis:\n  - Maximum Edge Biclique (MEB): given a bipartite graph $G$, find a complete\nbipartite subgraph of $G$ with maximum number of edges.\n  - Maximum Balanced Biclique (MBB): given a bipartite graph $G$, find a\nbalanced complete bipartite subgraph of $G$ with maximum number of vertices.\n  - Minimum $k$-Cut: given a weighted graph $G$, find a set of edges with\nminimum total weight whose removal partitions $G$ into $k$ connected\ncomponents.\n  - Densest At-Least-$k$-Subgraph (DAL$k$S): given a weighted graph $G$, find a\nset $S$ of at least $k$ vertices such that the induced subgraph on $S$ has\nmaximum density (the ratio between the total weight of edges and the number of\nvertices).\n  We show that, assuming SSEH and NP $\\nsubseteq$ BPP, no polynomial time\nalgorithm gives $n^{1 - \\varepsilon}$-approximation for MEB or MBB for every\nconstant $\\varepsilon > 0$. Moreover, assuming SSEH, we show that it is NP-hard\nto approximate Minimum $k$-Cut and DAL$k$S to within $(2 - \\varepsilon)$ factor\nof the optimum for every constant $\\varepsilon > 0$.\n  The ratios in our results are essentially tight since trivial algorithms give\n$n$-approximation to both MEB and MBB and efficient $2$-approximation\nalgorithms are known for Minimum $k$-Cut [SV95] and DAL$k$S [And07, KS09].\n  Our first result is proved by combining a technique developed by Raghavendra\net al. [RST12] to avoid locality of gadget reductions with a generalization of\nBansal and Khot's long code test [BK09] whereas our second result is shown via\nelementary reductions.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 02:03:01 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Manurangsi", "Pasin", ""]]}, {"id": "1705.03588", "submitter": "Shuichi Hirahara", "authors": "Shuichi Hirahara", "title": "A Duality Between Depth-Three Formulas and Approximation by Depth-Two", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish an explicit link between depth-3 formulas and one-sided\napproximation by depth-2 formulas, which were previously studied independently.\nSpecifically, we show that the minimum size of depth-3 formulas is (up to a\nfactor of n) equal to the inverse of the maximum, over all depth-2 formulas, of\none-sided-error correlation bound divided by the size of the depth-2 formula,\non a certain hard distribution. We apply this duality to obtain several\nconsequences:\n  1. Any function f can be approximated by a CNF formula of size $O(\\epsilon\n2^n / n)$ with one-sided error and advantage $\\epsilon$ for some $\\epsilon$,\nwhich is tight up to a constant factor.\n  2. There exists a monotone function f such that f can be approximated by some\npolynomial-size CNF formula, whereas any monotone CNF formula approximating f\nrequires exponential size.\n  3. Any depth-3 formula computing the parity function requires $\\Omega(2^{2\n\\sqrt{n}})$ gates, which is tight up to a factor of $\\sqrt n$. This establishes\na quadratic separation between depth-3 circuit size and depth-3 formula size.\n  4. We give a characterization of the depth-3 monotone circuit complexity of\nthe majority function, in terms of a natural extremal problem on hypergraphs.\nIn particular, we show that a known extension of Turan's theorem gives a tight\n(up to a polynomial factor) circuit size for computing the majority function by\na monotone depth-3 circuit with bottom fan-in 2.\n  5. AC0[p] has exponentially small one-sided correlation with the parity\nfunction for odd prime p.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 02:28:52 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Hirahara", "Shuichi", ""]]}, {"id": "1705.03673", "submitter": "Till Fluschnik", "authors": "Till Fluschnik, Marco Morik, and Manuel Sorge", "title": "The Complexity of Routing with Few Collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of routing multiple objects through a\nnetwork in such a way that only few collisions occur: Given a graph $G$ with\ntwo distinct terminal vertices and two positive integers $p$ and $k$, the\nquestion is whether one can connect the terminals by at least $p$ routes (e.g.\npaths) such that at most $k$ edges are time-wise shared among them. We study\nthree types of routes: traverse each vertex at most once (paths), each edge at\nmost once (trails), or no such restrictions (walks). We prove that for paths\nand trails the problem is NP-complete on undirected and directed graphs even if\n$k$ is constant or the maximum vertex degree in the input graph is constant.\nFor walks, however, it is solvable in polynomial time on undirected graphs for\narbitrary $k$ and on directed graphs if $k$ is constant. We additionally study\nfor all route types a variant of the problem where the maximum length of a\nroute is restricted by some given upper bound. We prove that this\nlength-restricted variant has the same complexity classification with respect\nto paths and trails, but for walks it becomes NP-complete on undirected graphs.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 09:38:03 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Fluschnik", "Till", ""], ["Morik", "Marco", ""], ["Sorge", "Manuel", ""]]}, {"id": "1705.03842", "submitter": "Ignacio Garc\\'ia-Marco", "authors": "Ignacio Garc\\'ia-Marco, Pascal Koiran, Timoth\\'ee Pecatte", "title": "On the linear independence of shifted powers", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We call shifted power a polynomial of the form $(x-a)^e$. The main goal of\nthis paper is to obtain broadly applicable criteria ensuring that the elements\nof a finite family $F$ of shifted powers are linearly independent or, failing\nthat, to give a lower bound on the dimension of the space of polynomials\nspanned by $F$. In particular, we give simple criteria ensuring that the\ndimension of the span of $F$ is at least $c.|F|$ for some absolute constant\n$c<1$. We also propose conjectures implying the linear independence of the\nelements of $F$. These conjectures are known to be true for the field of real\nnumbers, but not for the field of complex numbers.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 16:16:05 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 17:42:34 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Garc\u00eda-Marco", "Ignacio", ""], ["Koiran", "Pascal", ""], ["Pecatte", "Timoth\u00e9e", ""]]}, {"id": "1705.03866", "submitter": "Fulvio Gesmundo", "authors": "Fulvio Gesmundo and Joseph M. Landsberg", "title": "Explicit polynomial sequences with maximal spaces of partial derivatives\n  and a question of K. Mulmuley", "comments": "18 pages - final version to appear in Theory of Computing", "journal-ref": "Vol. 15 Art. 3 pp. 1-24, 2019", "doi": "10.4086/toc.2019.v015a003", "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We answer a question of K. Mulmuley: In [Efremenko-Landsberg-Schenck-Weyman]\nit was shown that the method of shifted partial derivatives cannot be used to\nseparate the padded permanent from the determinant. Mulmuley asked if this\n\"no-go\" result could be extended to a model without padding. We prove this is\nindeed the case using the iterated matrix multiplication polynomial. We also\nprovide several examples of polynomials with maximal space of partial\nderivatives, including the complete symmetric polynomials. We apply Koszul\nflattenings to these polynomials to have the first explicit sequence of\npolynomials with symmetric border rank lower bounds higher than the bounds\nattainable via partial derivatives.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 17:33:26 GMT"}, {"version": "v2", "created": "Sat, 29 Dec 2018 15:00:18 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Gesmundo", "Fulvio", ""], ["Landsberg", "Joseph M.", ""]]}, {"id": "1705.03876", "submitter": "Tuomo Lempi\\\"ainen", "authors": "Tuomo Lempi\\\"ainen and Jukka Suomela", "title": "Constant Space and Non-Constant Time in Distributed Computing", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the relationship of time and space is an established topic in\ntraditional centralised complexity theory, this is not the case in distributed\ncomputing. We aim to remedy this by studying the time and space complexity of\nalgorithms in a weak message-passing model of distributed computing. While a\nconstant number of communication rounds implies a constant number of states\nvisited during the execution, the other direction is not clear at all. We\nconsider several graph families and show that indeed, there exist non-trivial\ngraph problems that are solvable by constant-space algorithms but that require\na non-constant running time. This provides us with a new complexity class for\ndistributed computing and raises interesting questions about the existence of\nfurther combinations of time and space complexity.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 17:58:28 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Lempi\u00e4inen", "Tuomo", ""], ["Suomela", "Jukka", ""]]}, {"id": "1705.04205", "submitter": "Akash Kumar", "authors": "Elena Grigorescu, Akash Kumar and Karl Wimmer", "title": "Flipping out with many flips: hardness of testing k-monotonicity", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A function f : {0, 1}^n -> {0, 1} is said to be k-monotone if it flips\nbetween 0 and 1 at most k times on every ascending chain. Such functions\nrepresent a natural generalization of (1-)monotone functions, and have been\nrecently studied in circuit complexity, PAC learning, and cryptography. Our\nwork is part of a renewed focus in understanding testability of properties\ncharacterized by freeness of arbitrary order patterns as a generalization of\nmonotonicity. Recently, Canonne et al. (ITCS 2017) initiate the study of\nk-monotone functions in the area of property testing, and Newman et al. (SODA\n2017) study testability of families characterized by freeness from order\npatterns on real-valued functions over the line [n] domain. We study k-monotone\nfunctions in the more relaxed parametrized property testing model, introduced\nby Parnas et al. (JCSS, 72(6), 2006). In this process we resolve a problem left\nopen in previous work. Specifically, our results include the following.\n  1. Testing 2-monotonicity on the hypercube non-adaptively with one-sided\nerror requires an exponential in \\sqrt n number of queries. This behavior shows\na stark contrast with testing (1-)monotonicity, which only needs O(\\sqrt n)\nqueries (Khot et al. (FOCS 2015)). Furthermore, even the apparently easier task\nof distinguishing 2-monotone functions from functions that are far from being\nn^.01 -monotone also requires an exponential number of queries.\n  2. On the hypercube [n]^d domain, there exists a testing algorithm that makes\na constant number of queries and distinguishes functions that are k-monotone\nfrom functions that are far from being O(kd^2)-monotone. Such a dependency is\nlikely necessary, given the lower bound above for the hypercube.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 14:29:09 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 17:46:56 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Grigorescu", "Elena", ""], ["Kumar", "Akash", ""], ["Wimmer", "Karl", ""]]}, {"id": "1705.04587", "submitter": "Malin Rau", "authors": "S\\\"oren Henning, Klaus Jansen, Malin Rau, Lars Schmarje", "title": "Complexity and Inapproximability Results for Parallel Task Scheduling\n  and Strip Packing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Parallel Task Scheduling problem $Pm|size_j|C_{\\max}$ with a\nconstant number of machines. This problem is known to be strongly NP-complete\nfor each $m \\geq 5$, while it is solvable in pseudo-polynomial time for each $m\n\\leq 3$. We give a positive answer to the long-standing open question whether\nthis problem is strongly $NP$-complete for $m=4$. As a second result, we\nimprove the lower bound of $\\frac{12}{11}$ for approximating pseudo-polynomial\nStrip Packing to $\\frac{5}{4}$. Since the best known approximation algorithm\nfor this problem has a ratio of $\\frac{4}{3} + \\varepsilon$, this result\nnarrows the gap between approximation ratio and inapproximability result by a\nsignificant step. Both results are proven by a reduction from the strongly\n$NP$-complete problem 3-Partition.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 14:22:53 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Henning", "S\u00f6ren", ""], ["Jansen", "Klaus", ""], ["Rau", "Malin", ""], ["Schmarje", "Lars", ""]]}, {"id": "1705.04770", "submitter": "M. Amin Rahimian", "authors": "Jan H\\k{a}z{\\l}a, Ali Jadbabaie, Elchanan Mossel, M. Amin Rahimian", "title": "Bayesian Decision Making in Groups is Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG cs.MA cs.SI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computations that Bayesian agents undertake when exchanging\nopinions over a network. The agents act repeatedly on their private information\nand take myopic actions that maximize their expected utility according to a\nfully rational posterior belief. We show that such computations are NP-hard for\ntwo natural utility functions: one with binary actions, and another where\nagents reveal their posterior beliefs. In fact, we show that distinguishing\nbetween posteriors that are concentrated on different states of the world is\nNP-hard. Therefore, even approximating the Bayesian posterior beliefs is hard.\nWe also describe a natural search algorithm to compute agents' actions, which\nwe call elimination of impossible signals, and show that if the network is\ntransitive, the algorithm can be modified to run in polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 23:38:35 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 20:16:31 GMT"}, {"version": "v3", "created": "Sat, 14 Jul 2018 05:35:09 GMT"}, {"version": "v4", "created": "Sat, 27 Jul 2019 17:27:23 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["H\u0105z\u0142a", "Jan", ""], ["Jadbabaie", "Ali", ""], ["Mossel", "Elchanan", ""], ["Rahimian", "M. Amin", ""]]}, {"id": "1705.04895", "submitter": "Coralia Cartis", "authors": "Coralia Cartis, Nick Gould and Philippe L Toint", "title": "Evaluation complexity bounds for smooth constrained nonlinear\n  optimisation using scaled KKT conditions, high-order models and the\n  criticality measure $\\chi$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation complexity for convexly constrained optimization is considered and\nit is shown first that the complexity bound of $O(\\epsilon^{-3/2})$ proved by\nCartis, Gould and Toint (IMAJNA 32(4) 2012, pp.1662-1695) for computing an\n$\\epsilon$-approximate first-order critical point can be obtained under\nsignificantly weaker assumptions. Moreover, the result is generalized to the\ncase where high-order derivatives are used, resulting in a bound of\n$O(\\epsilon^{-(p+1)/p})$ evaluations whenever derivatives of order $p$ are\navailable. It is also shown that the bound of\n$O(\\epsilon_P^{-1/2}\\epsilon_D^{-3/2})$ evaluations ($\\epsilon_P$ and\n$\\epsilon_D$ being primal and dual accuracy thresholds) suggested by Cartis,\nGould and Toint (SINUM, 2015) for the general nonconvex case involving both\nequality and inequality constraints can be generalized to a bound of\n$O(\\epsilon_P^{-1/p}\\epsilon_D^{-(p+1)/p})$ evaluations under similarly\nweakened assumptions. This paper is variant of a companion report (NTR-11-2015,\nUniversity of Namur, Belgium) which uses a different first-order criticality\nmeasure to obtain the same complexity bounds.\n", "versions": [{"version": "v1", "created": "Sat, 13 May 2017 23:05:32 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Cartis", "Coralia", ""], ["Gould", "Nick", ""], ["Toint", "Philippe L", ""]]}, {"id": "1705.05393", "submitter": "Brad Woods", "authors": "Brad Woods and Abraham Punnen", "title": "A class of exponential neighbourhoods for the quadratic travelling\n  salesman problem", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quadratic Travelling Salesman Problem (QTSP) is to find a least-cost\nHamiltonian cycle in an edge-weighted graph, where costs are defined on all\npairs of edges such that each edge in the pair is contained in the Hamiltonian\ncycle. This is a more general version than the one that appears in the\nliterature as the QTSP, denoted here as the \\emph{adjacent quadratic} TSP,\nwhich only considers costs for pairs of adjacent edges. Major directions of\nresearch work on the linear TSP include exact algorithms, heuristics,\napproximation algorithms, polynomially solvable special cases and exponential\nneighbourhoods among others. In this paper we explore the complexity of\nsearching exponential neighbourhoods for QTSP, the fixed-rank QTSP, and the\nadjacent quadratic TSP. The fixed-rank QTSP is introduced as a restricted\nversion of the QTSP where the cost matrix has fixed rank $p$. It is shown that\nfixed-rank QTSP is solvable in pseudopolynomial time and admits an FPTAS for\neach of the special cases studied, except for the case of matching edge\nejection tours. The adjacent quadratic TSP is shown to be polynomially-solvable\nin many of the cases for which the linear TSP is polynomially-solvable.\nInterestingly, optimizing over the matching edge ejection tour neighbourhood is\nshown to be pseudopolynomial for the rank 1 case without a linear term in the\nobjective function, but NP-hard for the adjacent quadratic TSP case.\n  We also show that the quadratic shortest path problem on an acyclic digraph\ncan be solved in pseudopolynomial time and by an FPTAS when the rank of the\nassociated cost matrix is fixed.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 18:01:52 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 16:49:12 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Woods", "Brad", ""], ["Punnen", "Abraham", ""]]}, {"id": "1705.05452", "submitter": "Bernd Schuh", "authors": "Bernd R. Schuh", "title": "Polynomial time estimates for #SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limits on the number of satisfying assignments for CNS instances with n\nvariables and m clauses are derived from various inequalities. Some bounds can\nbe calculated in polynomial time, sharper bounds demand information about the\ndistribution of the number of unsatisfied clauses. Quite generally, the number\nof satisfying assignments involve variance and mean of this distribution. For\nlarge formulae, m>>1, bounds vary with 2**n/n, so they may be of use only for\ninstances with a large number of satisfying assignments.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 08:25:30 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Schuh", "Bernd R.", ""]]}, {"id": "1705.05599", "submitter": "Fabian Senger", "authors": "Oliver Schaudt, Fabian Senger", "title": "The Parameterized Complexity of the Equidomination Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph $G=(V,E)$ is called equidominating if there exists a value $t \\in\n\\mathbb{N}$ and a weight function $\\omega : V \\rightarrow \\mathbb{N}$ such that\nthe total weight of a subset $D\\subseteq V$ is equal to $t$ if and only if $D$\nis a minimal dominating set. To decide whether or not a given graph is\nequidominating is referred to as the Equidomination problem.\n  In this paper we show that two parameterized versions of the Equidomination\nproblem are fixed-parameter tractable: the first parameterization considers the\ntarget value $t$ leading to the Target-$t$ Equidomination problem. The second\nparameterization allows only weights up to a value $k$, which yields the\n$k$-Equidomination problem.\n  In addition, we characterize the graphs whose every induced subgraph is\nequidominating. We give a finite forbidden induced subgraph characterization\nand derive a fast recognition algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 08:58:32 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 13:47:41 GMT"}, {"version": "v3", "created": "Wed, 13 Dec 2017 10:59:17 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Schaudt", "Oliver", ""], ["Senger", "Fabian", ""]]}, {"id": "1705.05946", "submitter": "Hai-Jun Zhou", "authors": "Yi-Zhi Xu and Hai-Jun Zhou", "title": "Optimal segmentation of directed graph and the minimum number of\n  feedback arcs", "comments": "14 pages", "journal-ref": null, "doi": "10.1007/s10955-017-1860-5", "report-no": null, "categories": "cond-mat.dis-nn cs.CC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum feedback arc set problem asks to delete a minimum number of arcs\n(directed edges) from a digraph (directed graph) to make it free of any\ndirected cycles. In this work we approach this fundamental cycle-constrained\noptimization problem by considering a generalized task of dividing the digraph\ninto D layers of equal size. We solve the D-segmentation problem by the\nreplica-symmetric mean field theory and belief-propagation heuristic\nalgorithms. The minimum feedback arc density of a given random digraph ensemble\nis then obtained by extrapolating the theoretical results to the limit of large\nD. A divide-and-conquer algorithm (nested-BPR) is devised to solve the minimum\nfeedback arc set problem with very good performance and high efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 22:54:58 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Xu", "Yi-Zhi", ""], ["Zhou", "Hai-Jun", ""]]}, {"id": "1705.06070", "submitter": "Andrej Dudenhefner", "authors": "Andrej Dudenhefner, Jakob Rehof", "title": "Rank 3 Inhabitation of Intersection Types Revisited (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the undecidability result of rank 3 intersection type inhabitation\n(Urzyczyn 2009) in pursuit of two goals. First, we strengthen the previous\nresult by showing that intersection type inhabitation is undecidable for types\nof rank 3 and order 3, i.e. it is not necessary to introduce new functional\ndependencies (new instructions) during proof search. Second, we pinpoint the\nprinciples necessary to simulate Turing machine computation directly, whereas\nprevious constructions used a highly parallel and non-deterministic computation\nmodel. Since our construction is more concise than existing approaches taking\nno detours, we believe that it is valuable for a better understanding of the\nexpressiveness of intersection type inhabitation.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 09:49:35 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 07:37:53 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Dudenhefner", "Andrej", ""], ["Rehof", "Jakob", ""]]}, {"id": "1705.06303", "submitter": "Daniele De Martino", "authors": "S. Colabrese, D. De Martino, L. Leuzzi and E. Marinari", "title": "Phase transitions in integer linear problems", "comments": "15 pages, 6 figures, comments are welcome", "journal-ref": null, "doi": "10.1088/1742-5468/aa85c3", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The resolution of linear system with positive integer variables is a basic\nyet difficult computational problem with many applications. We consider sparse\nuncorrelated random systems parametrised by the density $c$ and the ratio\n$\\alpha=N/M$ between number of variables $N$ and number of constraints $M$. By\nmeans of ensemble calculations we show that the space of feasible solutions\nendows a Van-Der-Waals phase diagram in the plane ($c$, $\\alpha$). We give\nnumerical evidence that the associated computational problems become more\ndifficult across the critical point and in particular in the coexistence\nregion.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 18:29:28 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Colabrese", "S.", ""], ["De Martino", "D.", ""], ["Leuzzi", "L.", ""], ["Marinari", "E.", ""]]}, {"id": "1705.06643", "submitter": "Steven Heilman", "authors": "Steven Heilman", "title": "Symmetric Convex Sets with Minimal Gaussian Surface Area", "comments": "52 pages, typos corrected, new section added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\Omega\\subset\\mathbb{R}^{n+1}$ have minimal Gaussian surface area among\nall sets satisfying $\\Omega=-\\Omega$ with fixed Gaussian volume. Let $A=A_{x}$\nbe the second fundamental form of $\\partial\\Omega$ at $x$, i.e. $A$ is the\nmatrix of first order partial derivatives of the unit normal vector at\n$x\\in\\partial\\Omega$. For any $x=(x_{1},\\ldots,x_{n+1})\\in\\mathbb{R}^{n+1}$,\nlet $\\gamma_{n}(x)=(2\\pi)^{-n/2}e^{-(x_{1}^{2}+\\cdots+x_{n+1}^{2})/2}$. Let\n$\\|A\\|^{2}$ be the sum of the squares of the entries of $A$, and let\n$\\|A\\|_{2\\to 2}$ denote the $\\ell_{2}$ operator norm of $A$.\n  It is shown that if $\\Omega$ or $\\Omega^{c}$ is convex, and if either\n$$\\int_{\\partial\\Omega}(\\|A_{x}\\|^{2}-1)\\gamma_{n}(x)dx>0\\qquad\\mbox{or}\\qquad\n\\int_{\\partial\\Omega}\\Big(\\|A_{x}\\|^{2}-1+2\\sup_{y\\in\\partial\\Omega}\\|A_{y}\\|_{2\\to\n2}^{2}\\Big)\\gamma_{n}(x)dx<0,$$ then $\\partial\\Omega$ must be a round cylinder.\nThat is, except for the case that the average value of $\\|A\\|^{2}$ is slightly\nless than $1$, we resolve the convex case of a question of Barthe from 2001.\n  The main tool is the Colding-Minicozzi theory for Gaussian minimal surfaces,\nwhich studies eigenfunctions of the Ornstein-Uhlenbeck type operator $L=\n\\Delta-\\langle x,\\nabla \\rangle+\\|A\\|^{2}+1$ associated to the surface\n$\\partial\\Omega$. A key new ingredient is the use of a randomly chosen degree 2\npolynomial in the second variation formula for the Gaussian surface area. Our\nactual results are a bit more general than the above statement. Also, some of\nour results hold without the assumption of convexity.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 15:15:39 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 23:01:24 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 18:01:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Heilman", "Steven", ""]]}, {"id": "1705.06796", "submitter": "Michael O'Brien", "authors": "Irene Muzi and Michael P. O'Brien and Felix Reidl and Blair D.\n  Sullivan", "title": "Being even slightly shallow makes life hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of identifying dense substructures,\nnamely $r/2$-shallow topological minors and $r$-subdivisions. Of particular\ninterest is the case when $r=1$, when these substructures correspond to very\nlocalized relaxations of subgraphs. Since Densest Subgraph can be solved in\npolynomial time, we ask whether these slight relaxations also admit efficient\nalgorithms.\n  In the following, we provide a negative answer: Dense $r/2$-Shallow\nTopological Minor and Dense $r$-Subdivsion are already NP-hard for $r = 1$ in\nvery sparse graphs. Further, they do not admit algorithms with running time\n$2^{o(\\mathbf{tw}^2)} n^{O(1)}$ when parameterized by the treewidth of the\ninput graph for $r \\geq 2$ unless ETH fails.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 20:46:31 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Muzi", "Irene", ""], ["O'Brien", "Michael P.", ""], ["Reidl", "Felix", ""], ["Sullivan", "Blair D.", ""]]}, {"id": "1705.06996", "submitter": "Hamza Fawzi", "authors": "Hamza Fawzi and Mohab Safey El Din", "title": "A lower bound on the positive semidefinite rank of convex bodies", "comments": "v2: 14 pages - minor changes following comments by referees; v1: 13\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The positive semidefinite rank of a convex body $C$ is the size of its\nsmallest positive semidefinite formulation. We show that the positive\nsemidefinite rank of any convex body $C$ is at least $\\sqrt{\\log d}$ where $d$\nis the smallest degree of a polynomial that vanishes on the boundary of the\npolar of $C$. This improves on the existing bound which relies on results from\nquantifier elimination. The proof relies on the B\\'ezout bound applied to the\nKarush-Kuhn-Tucker conditions of optimality. We discuss the connection with the\nalgebraic degree of semidefinite programming and show that the bound is tight\n(up to constant factor) for random spectrahedra of suitable dimension.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 13:54:57 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 16:49:46 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Fawzi", "Hamza", ""], ["Din", "Mohab Safey El", ""]]}, {"id": "1705.07211", "submitter": "Dmitry Gavinsky", "authors": "Dmitry Gavinsky", "title": "Quantum versus classical simultaneity in communication complexity", "comments": "Reflecting a number of reviewers' comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses two problems in the context of two-party communication\ncomplexity of functions. First, it concludes the line of research, which can be\nviewed as demonstrating qualitative advantage of quantum communication in the\nthree most common communication \"layouts\": two-way interactive communication;\none-way communication; simultaneous message passing (SMP). We demonstrate a\nfunctional problem, whose communication complexity is $O((\\log n)^2)$ in the\nquantum version of SMP and $\\tilde\\Omega(\\sqrt n)$ in the classical\n(randomised) version of SMP.\n  Second, this work contributes to understanding the power of the weakest\ncommonly studied regime of quantum communication $-$ SMP with quantum messages\nand without shared randomness (the latter restriction can be viewed as a\nsomewhat artificial way of making the quantum model \"as weak as possible\"). Our\nfunction has an efficient solution in this regime as well, which means that\neven lacking shared randomness, quantum SMP can be exponentially stronger than\nits classical counterpart with shared randomness.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 22:23:39 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 02:01:16 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 20:46:19 GMT"}, {"version": "v4", "created": "Sat, 4 May 2019 16:37:26 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Gavinsky", "Dmitry", ""]]}, {"id": "1705.07285", "submitter": "Philippe Toint", "authors": "C. Cartis, N. I. M. Gould and Ph. L. Toint", "title": "Optimality of orders one to three and beyond: characterization and\n  evaluation complexity in constrained nonconvex optimization", "comments": "32 pages, 3 figures", "journal-ref": "Journal of Complexity, vol. 53, pp. 68-94, 2019", "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Necessary conditions for high-order optimality in smooth nonlinear\nconstrained optimization are explored and their inherent intricacy discussed. A\ntwo-phase minimization algorithm is proposed which can achieve approximate\nfirst-, second- and third-order criticality and its evaluation complexity is\nanalyzed as a function of the choice (among existing methods) of an inner\nalgorithm for solving subproblems in each of the two phases. The relation\nbetween high-order criticality and penalization techniques is finally\nconsidered, showing that standard algorithmic approaches will fail if\napproximate constrained high-order critical points are sought.\n", "versions": [{"version": "v1", "created": "Sat, 20 May 2017 09:48:20 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 10:39:30 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Cartis", "C.", ""], ["Gould", "N. I. M.", ""], ["Toint", "Ph. L.", ""]]}, {"id": "1705.07312", "submitter": "Yichen Chen", "authors": "Yichen Chen and Mengdi Wang", "title": "Lower Bound On the Computational Complexity of Discounted Markov\n  Decision Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of the infinite-horizon\ndiscounted-reward Markov Decision Problem (MDP) with a finite state space\n$|\\mathcal{S}|$ and a finite action space $|\\mathcal{A}|$. We show that any\nrandomized algorithm needs a running time at least\n$\\Omega(|\\mathcal{S}|^2|\\mathcal{A}|)$ to compute an $\\epsilon$-optimal policy\nwith high probability. We consider two variants of the MDP where the input is\ngiven in specific data structures, including arrays of cumulative probabilities\nand binary trees of transition probabilities. For these cases, we show that the\ncomplexity lower bound reduces to $\\Omega\\left( \\frac{|\\mathcal{S}|\n|\\mathcal{A}|}{\\epsilon} \\right)$. These results reveal a surprising\nobservation that the computational complexity of the MDP depends on the data\nstructure of input.\n", "versions": [{"version": "v1", "created": "Sat, 20 May 2017 14:21:30 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Chen", "Yichen", ""], ["Wang", "Mengdi", ""]]}, {"id": "1705.07728", "submitter": "Svyatoslav Covanov", "authors": "Svyatoslav Covanov (CARAMBA)", "title": "Improved method for finding optimal formulae for bilinear maps in a\n  finite field", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2012, Barbulescu, Detrey, Estibals and Zimmermann proposed a new framework\nto exhaustively search for optimal formulae for evaluating bilinear maps, such\nas Strassen or Karatsuba formulae. The main contribution of this work is a new\ncriterion to aggressively prune useless branches in the exhaustive search, thus\nleading to the computation of new optimal formulae, in particular for the short\nproduct modulo X 5 and the circulant product modulo (X 5 -- 1). Moreover , we\nare able to prove that there is essentially only one optimal decomposition of\nthe product of 3 x 2 by 2 x 3 matrices up to the action of some group of\nautomorphisms.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 06:20:33 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 13:39:12 GMT"}, {"version": "v3", "created": "Fri, 7 Dec 2018 16:10:46 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Covanov", "Svyatoslav", "", "CARAMBA"]]}, {"id": "1705.08282", "submitter": "Anjeneya Swami Kare Mr.", "authors": "N. R. Aravind, Subrahmanyam Kalyanasundaram, Anjeneya Swami Kare and\n  Juho Lauri", "title": "Algorithms and hardness results for happy coloring problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a vertex-colored graph, an edge is happy if its endpoints have the same\ncolor. Similarly, a vertex is happy if all its incident edges are happy.\nMotivated by the computation of homophily in social networks, we consider the\nalgorithmic aspects of the following Maximum Happy Edges (k-MHE) problem: given\na partially k-colored graph G, find an extended full k-coloring of G maximizing\nthe number of happy edges. When we want to maximize the number of happy\nvertices, the problem is known as Maximum Happy Vertices (k-MHV). We further\nstudy the complexity of the problems and their weighted variants. For instance,\nwe prove that for every k >= 3, both problems are NP-complete for bipartite\ngraphs and k-MHV remains hard for split graphs. In terms of exact algorithms,\nwe show both problems can be solved in time O*(2^n), and give an even faster\nO*(1.89^n)-time algorithm when k = 3. From a parameterized perspective, we give\na linear vertex kernel for Weighted k-MHE, where edges are weighted and the\ngoal is to obtain happy edges of at least a specified total weight. Finally, we\nprove both problems are solvable in polynomial-time when the graph has bounded\ntreewidth or bounded neighborhood diversity.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 14:04:40 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Aravind", "N. R.", ""], ["Kalyanasundaram", "Subrahmanyam", ""], ["Kare", "Anjeneya Swami", ""], ["Lauri", "Juho", ""]]}, {"id": "1705.09014", "submitter": "Renato Portugal", "authors": "A. Abreu, L. Cunha, T. Fernandes, C. de Figueiredo, L. Kowada, F.\n  Marquezino, D. Posner, R. Portugal", "title": "The tessellation problem of quantum walks", "comments": "10 pages, 7 figs", "journal-ref": "Theoretical Computer Science 801, 175-191, 2020", "doi": "10.1016/j.tcs.2019.09.013", "report-no": null, "categories": "cs.DM cs.CC math.CO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum walks have received a great deal of attention recently because they\ncan be used to develop new quantum algorithms and to simulate interesting\nquantum systems. In this work, we focus on a model called staggered quantum\nwalk, which employs advanced ideas of graph theory and has the advantage of\nincluding the most important instances of other discrete-time models. The\nevolution operator of the staggered model is obtained from a tessellation\ncover, which is defined in terms of a set of partitions of the graph into\ncliques. It is important to establish the minimum number of tessellations\nrequired in a tessellation cover, and what classes of graphs admit a small\nnumber of tessellations. We describe two main results: (1) infinite classes of\ngraphs where we relate the chromatic number of the clique graph to the minimum\nnumber of tessellations required in a tessellation cover, and (2) the problem\nof deciding whether a graph is $k$-tessellable for $k\\ge 3$ is NP-complete.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 01:26:40 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Abreu", "A.", ""], ["Cunha", "L.", ""], ["Fernandes", "T.", ""], ["de Figueiredo", "C.", ""], ["Kowada", "L.", ""], ["Marquezino", "F.", ""], ["Posner", "D.", ""], ["Portugal", "R.", ""]]}, {"id": "1705.09177", "submitter": "Ignasi Sau", "authors": "Sancrey R. Alves, Konrad K. Dabrowski, Luerbio Faria, Sulamita Klein,\n  Ignasi Sau, U\\'everton S. Souza", "title": "On the (parameterized) complexity of recognizing well-covered\n  (r,l)-graphs", "comments": "24 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An $(r, \\ell)$-partition of a graph $G$ is a partition of its vertex set into\n$r$ independent sets and $\\ell$ cliques. A graph is $(r, \\ell)$ if it admits an\n$(r, \\ell)$-partition. A graph is well-covered if every maximal independent set\nis also maximum. A graph is $(r,\\ell)$-well-covered if it is both $(r,\\ell)$\nand well-covered. In this paper we consider two different decision problems. In\nthe $(r,\\ell)$-Well-Covered Graph problem ($(r,\\ell)$WCG for short), we are\ngiven a graph $G$, and the question is whether $G$ is an\n$(r,\\ell)$-well-covered graph. In the Well-Covered $(r,\\ell)$-Graph problem\n(WC$(r,\\ell)$G for short), we are given an $(r,\\ell)$-graph $G$ together with\nan $(r,\\ell)$-partition of $V(G)$ into $r$ independent sets and $\\ell$ cliques,\nand the question is whether $G$ is well-covered. We classify most of these\nproblems into P, coNP-complete, NP-complete, NP-hard, or coNP-hard. Only the\ncases WC$(r,0)$G for $r\\geq 3$ remain open. In addition, we consider the\nparameterized complexity of these problems for several choices of parameters,\nsuch as the size $\\alpha$ of a maximum independent set of the input graph, its\nneighborhood diversity, its clique-width, or the number $\\ell$ of cliques in an\n$(r, \\ell)$-partition. In particular, we show that the parameterized problem of\ndeciding whether a general graph is well-covered parameterized by $\\alpha$ can\nbe reduced to the WC$(0,\\ell)$G problem parameterized by $\\ell$. In addition,\nwe prove that both problems are coW[2]-hard but can be solved in XP-time.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 13:47:33 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 16:22:13 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Alves", "Sancrey R.", ""], ["Dabrowski", "Konrad K.", ""], ["Faria", "Luerbio", ""], ["Klein", "Sulamita", ""], ["Sau", "Ignasi", ""], ["Souza", "U\u00e9verton S.", ""]]}, {"id": "1705.09379", "submitter": "Jeroen Zuiddam", "authors": "Matthias Christandl, Asger Kj{\\ae}rulff Jensen, Jeroen Zuiddam", "title": "Tensor rank is not multiplicative under the tensor product", "comments": null, "journal-ref": "Linear Algebra Appl. 543 (2018) 125-139", "doi": "10.1016/j.laa.2017.12.020", "report-no": null, "categories": "math.AC cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tensor rank of a tensor t is the smallest number r such that t can be\ndecomposed as a sum of r simple tensors. Let s be a k-tensor and let t be an\nl-tensor. The tensor product of s and t is a (k + l)-tensor. Tensor rank is\nsub-multiplicative under the tensor product. We revisit the connection between\nrestrictions and degenerations. A result of our study is that tensor rank is\nnot in general multiplicative under the tensor product. This answers a question\nof Draisma and Saptharishi. Specifically, if a tensor t has border rank\nstrictly smaller than its rank, then the tensor rank of t is not multiplicative\nunder taking a sufficiently hight tensor product power. The \"tensor Kronecker\nproduct\" from algebraic complexity theory is related to our tensor product but\ndifferent, namely it multiplies two k-tensors to get a k-tensor.\nNonmultiplicativity of the tensor Kronecker product has been known since the\nwork of Strassen.\n  It remains an open question whether border rank and asymptotic rank are\nmultiplicative under the tensor product. Interestingly, lower bounds on border\nrank obtained from generalised flattenings (including Young flattenings)\nmultiply under the tensor product.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 21:55:17 GMT"}, {"version": "v2", "created": "Tue, 29 Aug 2017 20:12:25 GMT"}, {"version": "v3", "created": "Fri, 26 Jan 2018 10:17:09 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Christandl", "Matthias", ""], ["Jensen", "Asger Kj\u00e6rulff", ""], ["Zuiddam", "Jeroen", ""]]}, {"id": "1705.09517", "submitter": "Pasin Manurangsi", "authors": "Pasin Manurangsi and Aviad Rubinstein", "title": "Inapproximability of VC Dimension and Littlestone's Dimension", "comments": "To appear in Conference On Learning Theory (COLT) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of computing the VC Dimension and Littlestone's\nDimension. Given an explicit description of a finite universe and a concept\nclass (a binary matrix whose $(x,C)$-th entry is $1$ iff element $x$ belongs to\nconcept $C$), both can be computed exactly in quasi-polynomial time ($n^{O(\\log\nn)}$). Assuming the randomized Exponential Time Hypothesis (ETH), we prove\nnearly matching lower bounds on the running time, that hold even for\napproximation algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 10:38:01 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Manurangsi", "Pasin", ""], ["Rubinstein", "Aviad", ""]]}, {"id": "1705.09652", "submitter": "Jeroen Zuiddam", "authors": "Markus Bl\\\"aser, Matthias Christandl, Jeroen Zuiddam", "title": "The border support rank of two-by-two matrix multiplication is seven", "comments": null, "journal-ref": "Chicago Journal of Theoretical Computer Science 2018, article 05,\n  pages 1-16", "doi": "10.4086/cjtcs.2018.005", "report-no": null, "categories": "cs.CC math.RT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the border support rank of the tensor corresponding to\ntwo-by-two matrix multiplication is seven over the complex numbers. We do this\nby constructing two polynomials that vanish on all complex tensors with format\nfour-by-four-by-four and border rank at most six, but that do not vanish\nsimultaneously on any tensor with the same support as the two-by-two matrix\nmultiplication tensor. This extends the work of Hauenstein, Ikenmeyer, and\nLandsberg. We also give two proofs that the support rank of the two-by-two\nmatrix multiplication tensor is seven over any field: one proof using a result\nof De Groote saying that the decomposition of this tensor is unique up to\nsandwiching, and another proof via the substitution method. These results\nanswer a question asked by Cohn and Umans. Studying the border support rank of\nthe matrix multiplication tensor is relevant for the design of matrix\nmultiplication algorithms, because upper bounds on the border support rank of\nthe matrix multiplication tensor lead to upper bounds on the computational\ncomplexity of matrix multiplication, via a construction of Cohn and Umans.\nMoreover, support rank has applications in quantum communication complexity.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 17:22:03 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Bl\u00e4ser", "Markus", ""], ["Christandl", "Matthias", ""], ["Zuiddam", "Jeroen", ""]]}, {"id": "1705.09710", "submitter": "Marcos Villagra", "authors": "Marcos Villagra", "title": "A Block-Sensitivity Lower Bound for Quantum Testing Hamming Distance", "comments": "Short note, 3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gap-Hamming distance problem is the promise problem of deciding if the\nHamming distance $h$ between two strings of length $n$ is greater than $a$ or\nless than $b$, where the gap $g=|a-b|\\geq 1$ and $a$ and $b$ could depend on\n$n$. In this short note, we give a lower bound of $\\Omega( \\sqrt{n/g})$ on the\nquantum query complexity of computing the Gap-Hamming distance between two\ngiven strings of lenght $n$. The proof is a combinatorial argument based on\nblock sensitivity and a reduction from a threshold function.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 20:41:40 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Villagra", "Marcos", ""]]}, {"id": "1705.10081", "submitter": "Aleksandr Maksimenko", "authors": "Aleksandr Maksimenko", "title": "Affine maps between quadratic assignment polytopes and subgraph\n  isomorphism polytopes", "comments": "6 pages, translated to English", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two polytopes. The quadratic assignment polytope $QAP(n)$ is the\nconvex hull of the set of tensors $x\\otimes x$, $x \\in P_n$, where $P_n$ is the\nset of $n\\times n$ permutation matrices. The second polytope is defined as\nfollows. For every permutation of vertices of the complete graph $K_n$ we\nconsider appropriate $\\binom{n}{2} \\times \\binom{n}{2}$ permutation matrix of\nthe edges of $K_n$. The Young polytope $P((n-2,2))$ is the convex hull of all\nsuch matrices.\n  In 2009, S. Onn showed that the subgraph isomorphism problem can be reduced\nto optimization both over $QAP(n)$ and over $P((n-2,2))$. He also posed the\nquestion whether $QAP(n)$ and $P((n-2,2))$, having $n!$ vertices each, are\nisomorphic. We show that $QAP(n)$ and $P((n-2,2))$ are not isomorphic. Also, we\nshow that $QAP(n)$ is a face of $P((2n-2,2))$, but $P((n-2,2))$ is a projection\nof $QAP(n)$.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 09:03:47 GMT"}, {"version": "v2", "created": "Sat, 3 Jun 2017 07:21:03 GMT"}, {"version": "v3", "created": "Sat, 17 Jun 2017 08:40:02 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Maksimenko", "Aleksandr", ""]]}, {"id": "1705.11060", "submitter": "Ronald De Haan", "authors": "Britta Dorn, Ronald de Haan, Ildik\\'o Schlotter", "title": "Obtaining a Proportional Allocation by Deleting Items", "comments": "This is the authors' self-archived copy of a paper that appeared in\n  the proceedings of the 5th International Conference on Algorithmic Decision\n  Theory (ADT 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following control problem on fair allocation of indivisible\ngoods. Given a set $I$ of items and a set of agents, each having strict linear\npreference over the items, we ask for a minimum subset of the items whose\ndeletion guarantees the existence of a proportional allocation in the remaining\ninstance; we call this problem Proportionality by Item Deletion (PID). Our main\nresult is a polynomial-time algorithm that solves PID for three agents. By\ncontrast, we prove that PID is computationally intractable when the number of\nagents is unbounded, even if the number $k$ of item deletions allowed is small,\nsince the problem turns out to be W[3]-hard with respect to the parameter $k$.\nAdditionally, we provide some tight lower and upper bounds on the complexity of\nPID when regarded as a function of $|I|$ and $k$.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 12:29:26 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Dorn", "Britta", ""], ["de Haan", "Ronald", ""], ["Schlotter", "Ildik\u00f3", ""]]}]