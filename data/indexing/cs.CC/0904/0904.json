[{"id": "0904.0471", "submitter": "Jason Morton", "authors": "J.M. Landsberg, Jason Morton, and Serguei Norine", "title": "Holographic algorithms without matchgates", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of holographic algorithms, which are polynomial time algorithms\nfor certain combinatorial counting problems, yields insight into the hierarchy\nof complexity classes. In particular, the theory produces algebraic tests for a\nproblem to be in the class P. In this article we streamline the implementation\nof holographic algorithms by eliminating one of the steps in the construction\nprocedure, and generalize their applicability to new signatures. Instead of\nmatchgates, which are weighted graph fragments that replace vertices of a\nnatural bipartite graph G associated to a problem P, our approach uses only\nonly a natural number-of-edges by number-of-edges matrix associated to G. An\neasy-to-compute multiple of its Pfaffian is the number of solutions to the\ncounting problem. This simplification improves our understanding of the\napplicability of holographic algorithms, indicates a more geometric approach to\ncomplexity classes, and facilitates practical implementations. The generalized\napplicability arises because our approach allows for new algebraic tests that\nare different from the \"Grassmann-Plucker identities\" used up until now.\nNatural problems treatable by these new methods have been previously considered\nin a different context, and we present one such example.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2009 21:19:56 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Landsberg", "J. M.", ""], ["Morton", "Jason", ""], ["Norine", "Serguei", ""]]}, {"id": "0904.0570", "submitter": "Andreas Schnabl", "authors": "Georg Moser (University of Innsbruck), Andreas Schnabl (University of\n  Innsbruck)", "title": "The Derivational Complexity Induced by the Dependency Pair Method", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (July 13,\n  2011) lmcs:805", "doi": "10.2168/LMCS-7(3:1)2011", "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the derivational complexity induced by the dependency pair method,\nenhanced with standard refinements. We obtain upper bounds on the derivational\ncomplexity induced by the dependency pair method in terms of the derivational\ncomplexity of the base techniques employed. In particular we show that the\nderivational complexity induced by the dependency pair method based on some\ndirect technique, possibly refined by argument filtering, the usable rules\ncriterion, or dependency graphs, is primitive recursive in the derivational\ncomplexity induced by the direct method. This implies that the derivational\ncomplexity induced by a standard application of the dependency pair method\nbased on traditional termination orders like KBO, LPO, and MPO is exactly the\nsame as if those orders were applied as the only termination technique.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 15:10:50 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2009 11:33:52 GMT"}, {"version": "v3", "created": "Tue, 21 Sep 2010 08:52:40 GMT"}, {"version": "v4", "created": "Wed, 1 Jun 2011 17:22:27 GMT"}, {"version": "v5", "created": "Mon, 11 Jul 2011 21:10:44 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Moser", "Georg", "", "University of Innsbruck"], ["Schnabl", "Andreas", "", "University of\n  Innsbruck"]]}, {"id": "0904.0644", "submitter": "Xi Chen", "authors": "Xi Chen, Decheng Dai, Ye Du and Shang-Hua Teng", "title": "Settling the Complexity of Arrow-Debreu Equilibria in Markets with\n  Additively Separable Utilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the problem of computing an Arrow-Debreu market equilibrium is\nPPAD-complete even when all traders use additively separable, piecewise-linear\nand concave utility functions. In fact, our proof shows that this\nmarket-equilibrium problem does not have a fully polynomial-time approximation\nscheme unless every problem in PPAD is solvable in polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 20:22:40 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Chen", "Xi", ""], ["Dai", "Decheng", ""], ["Du", "Ye", ""], ["Teng", "Shang-Hua", ""]]}, {"id": "0904.0648", "submitter": "Nisheeth Srivastava", "authors": "Nisheeth Srivastava", "title": "Evolvability need not imply learnability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We show that Boolean functions expressible as monotone disjunctive normal\nforms are PAC-evolvable under a uniform distribution on the Boolean cube if the\nhypothesis size is allowed to remain fixed. We further show that this result is\ninsufficient to prove the PAC-learnability of monotone Boolean functions,\nthereby demonstrating a counter-example to a recent claim to the contrary. We\nfurther discuss scenarios wherein evolvability and learnability will coincide\nas well as scenarios under which they differ. The implications of the latter\ncase on the prospects of learning in complex hypothesis spaces is briefly\nexamined.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 20:30:24 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Srivastava", "Nisheeth", ""]]}, {"id": "0904.0698", "submitter": "Marcel R\\'emon", "authors": "M. R\\'emon", "title": "About the impossibility to prove P=NP and the pseudo-randomness in NP", "comments": "21 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": "2008/18, Dept Math, Namur University", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationship between the complexity classes P and NP is an unsolved\nquestion in the field of theoretical computer science. In this paper, we look\nat the link between the P - NP question and the \"Deterministic\" versus \"Non\nDeterministic\" nature of a problem, and more specifically at the temporal\nnature of the complexity within the NP class of problems. Let us remind that\nthe NP class is called the class of \"Non Deterministic Polynomial\" languages.\nUsing the meta argument that results in Mathematics should be \"time\nindependent\" as they are reproducible, the paper shows that the P!=NP assertion\nis impossible to prove in the a-temporal framework of Mathematics. In a\nprevious version of the report, we use a similar argument based on randomness\nto show that the P = NP assertion was also impossible to prove, but this part\nof the paper was shown to be incorrect. So, this version deletes it. In fact,\nthis paper highlights the time dependence of the complexity for any NP problem,\nlinked to some pseudo-randomness in its heart.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2009 09:16:04 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2010 11:43:39 GMT"}, {"version": "v3", "created": "Thu, 24 Mar 2016 23:30:56 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["R\u00e9mon", "M.", ""]]}, {"id": "0904.0721", "submitter": "Linh Anh Nguyen D.Sc.", "authors": "Linh Anh Nguyen and Andrzej Sza{\\l}as", "title": "Optimal Tableau Decision Procedures for PDL", "comments": null, "journal-ref": "Fund. Inform. 104(4), pp. 349-384, 2010", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reformulate Pratt's tableau decision procedure of checking satisfiability\nof a set of formulas in PDL. Our formulation is simpler and more direct for\nimplementation. Extending the method we give the first EXPTIME (optimal)\ntableau decision procedure not based on transformation for checking consistency\nof an ABox w.r.t. a TBox in PDL (here, PDL is treated as a description logic).\nWe also prove the new result that the data complexity of the instance checking\nproblem in PDL is coNP-complete.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2009 15:20:07 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2009 09:39:45 GMT"}], "update_date": "2011-04-12", "authors_parsed": [["Nguyen", "Linh Anh", ""], ["Sza\u0142as", "Andrzej", ""]]}, {"id": "0904.0973", "submitter": "Kohtaro Tadaki", "authors": "Kohtaro Tadaki", "title": "A statistical mechanical interpretation of algorithmic information\n  theory III: Composite systems and fixed points", "comments": "5 pages, no figures, final manuscript to appear in the Proceedings of\n  the 2009 IEEE Information Theory Workshop, Taormina, Sicily, Italy, October\n  11 - 16, 2009", "journal-ref": "Mathematical Structures in Computer Science 22 (2012) 752-770", "doi": "10.1017/S096012951100051X", "report-no": null, "categories": "cs.IT cs.CC math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical mechanical interpretation of algorithmic information theory\n(AIT, for short) was introduced and developed by our former works [K. Tadaki,\nLocal Proceedings of CiE 2008, pp.425-434, 2008] and [K. Tadaki, Proceedings of\nLFCS'09, Springer's LNCS, vol.5407, pp.422-440, 2009], where we introduced the\nnotion of thermodynamic quantities, such as partition function Z(T), free\nenergy F(T), energy E(T), and statistical mechanical entropy S(T), into AIT. We\nthen discovered that, in the interpretation, the temperature T equals to the\npartial randomness of the values of all these thermodynamic quantities, where\nthe notion of partial randomness is a stronger representation of the\ncompression rate by means of program-size complexity. Furthermore, we showed\nthat this situation holds for the temperature itself as a thermodynamic\nquantity, namely, for each of all the thermodynamic quantities above, the\ncomputability of its value at temperature T gives a sufficient condition for T\nin (0,1) to be a fixed point on partial randomness. In this paper, we develop\nthe statistical mechanical interpretation of AIT further and pursue its formal\ncorrespondence to normal statistical mechanics. The thermodynamic quantities in\nAIT are defined based on the halting set of an optimal computer, which is a\nuniversal decoding algorithm used to define the notion of program-size\ncomplexity. We show that there are infinitely many optimal computers which give\ncompletely different sufficient conditions in each of the thermodynamic\nquantities in AIT. We do this by introducing the notion of composition of\ncomputers into AIT, which corresponds to the notion of composition of systems\nin normal statistical mechanics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2009 17:11:50 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2009 20:59:39 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tadaki", "Kohtaro", ""]]}, {"id": "0904.0981", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Georg Moser", "title": "Dependency Pairs and Polynomial Path Orders", "comments": "23 pages, conference version accepted at RTA 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.SC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We show how polynomial path orders can be employed efficiently in conjunction\nwith weak innermost dependency pairs to automatically certify polynomial\nruntime complexity of term rewrite systems and the polytime computability of\nthe functions computed. The established techniques have been implemented and we\nprovide ample experimental data to assess the new method.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2009 18:10:53 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2009 14:44:02 GMT"}, {"version": "v3", "created": "Wed, 8 Jun 2011 07:03:03 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["Avanzini", "Martin", ""], ["Moser", "Georg", ""]]}, {"id": "0904.1113", "submitter": "Bodo Manthey", "authors": "David Arthur and Bodo Manthey and Heiko R\\\"oglin", "title": "k-Means has Polynomial Smoothed Complexity", "comments": "Full version of FOCS 2009 paper. The argument has been improved and\n  the restriction to at least three dimensions could be dropped", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-means method is one of the most widely used clustering algorithms,\ndrawing its popularity from its speed in practice. Recently, however, it was\nshown to have exponential worst-case running time. In order to close the gap\nbetween practical performance and theoretical analysis, the k-means method has\nbeen studied in the model of smoothed analysis. But even the smoothed analyses\nso far are unsatisfactory as the bounds are still super-polynomial in the\nnumber n of data points.\n  In this paper, we settle the smoothed running time of the k-means method. We\nshow that the smoothed number of iterations is bounded by a polynomial in n and\n1/\\sigma, where \\sigma is the standard deviation of the Gaussian perturbations.\nThis means that if an arbitrary input data set is randomly perturbed, then the\nk-means method will run in expected polynomial time on that input set.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2009 11:21:23 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2009 08:53:03 GMT"}], "update_date": "2009-08-07", "authors_parsed": [["Arthur", "David", ""], ["Manthey", "Bodo", ""], ["R\u00f6glin", "Heiko", ""]]}, {"id": "0904.1149", "submitter": "Kohtaro Tadaki", "authors": "Kohtaro Tadaki", "title": "Chaitin \\Omega numbers and halting problems", "comments": "17 pages, LaTeX2e, no figures. This is an earlier full version of the\n  paper that will appear in the Proceedings of Computability in Europe 2009,\n  Heidelberg, Germany, July 19 - 24, 2009", "journal-ref": "In: Ambos-Spies K., L\\\"owe B., Merkle W. (eds) Mathematical Theory\n  and Computational Practice. CiE 2009. LNCS, vol 5635 (2009) Springer", "doi": "10.1007/978-3-642-03073-4_46", "report-no": null, "categories": "math.LO cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chaitin [G. J. Chaitin, J. Assoc. Comput. Mach., vol.22, pp.329-340, 1975]\nintroduced \\Omega number as a concrete example of random real. The real \\Omega\nis defined as the probability that an optimal computer halts, where the optimal\ncomputer is a universal decoding algorithm used to define the notion of\nprogram-size complexity. Chaitin showed \\Omega to be random by discovering the\nproperty that the first n bits of the base-two expansion of \\Omega solve the\nhalting problem of the optimal computer for all binary inputs of length at most\nn. In the present paper we investigate this property from various aspects. We\nconsider the relative computational power between the base-two expansion of\n\\Omega and the halting problem by imposing the restriction to finite size on\nboth the problems. It is known that the base-two expansion of \\Omega and the\nhalting problem are Turing equivalent. We thus consider an elaboration of the\nTuring equivalence in a certain manner.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2009 17:32:55 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tadaki", "Kohtaro", ""]]}, {"id": "0904.1302", "submitter": "Stephan Kreutzer", "authors": "Stephan Kreutzer", "title": "On the Parameterised Intractability of Monadic Second-Order Logic", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of Courcelle's celebrated results states that if C is a class of graphs\nof bounded tree-width, then model-checking for monadic second order logic is\nfixed-parameter tractable on C by linear time parameterised algorithms. An\nimmediate question is whether this is best possible or whether the result can\nbe extended to classes of unbounded tree-width.\n  In this paper we show that in terms of tree-width, the theorem can not be\nextended much further. More specifically, we show that if C is a class of\ngraphs which is closed under colourings and satisfies certain constructibility\nconditions such that the tree-width of C is not bounded by log^{16}(n) then\nMSO_2-model checking is not fixed-parameter tractable unless the satisfiability\nproblem SAT for propositional logic can be solved in sub-exponential time. If\nthe tree-width of C is not poly-logarithmically bounded, then MSO_2-model\nchecking is not fixed-parameter tractable unless all problems in the\npolynomial-time hierarchy, and hence in particular all problems in NP, can be\nsolved in sub-exponential time.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2009 10:36:24 GMT"}], "update_date": "2009-04-09", "authors_parsed": [["Kreutzer", "Stephan", ""]]}, {"id": "0904.1435", "submitter": "Shiva Kintali", "authors": "Shiva Kintali, Laura J. Poplawski, Rajmohan Rajaraman, Ravi Sundaram,\n  Shang-Hua Teng", "title": "Reducibility Among Fractional Stability Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we resolve the computational complexity of a number of\noutstanding open problems with practical applications. Here is the list of\nproblems we show to be PPAD-complete, along with the domains of practical\nsignificance: Fractional Stable Paths Problem (FSPP) [21] - Internet routing;\nCore of Balanced Games [41] - Economics and Game theory; Scarf's Lemma [41] -\nCombinatorics; Hypergraph Matching [1]- Social Choice and Preference Systems;\nFractional Bounded Budget Connection Games (FBBC) [30] - Social networks; and\nStrong Fractional Kernel [2]- Graph Theory. In fact, we show that no fully\npolynomial-time approximation schemes exist (unless PPAD is in FP).\n  This paper is entirely a series of reductions that build in nontrivial ways\non the framework established in previous work. In the course of deriving these\nreductions, we created two new concepts - preference games and personalized\nequilibria. The entire set of new reductions can be presented as a lattice with\nthe above problems sandwiched between preference games (at the \"easy\" end) and\npersonalized equilibria (at the \"hard\" end). Our completeness results extend to\nnatural approximate versions of most of these problems. On a technical note, we\nwish to highlight our novel \"continuous-to-discrete\" reduction from exact\npersonalized equilibria to approximate personalized equilibria using a linear\nprogram augmented with an exponential number of \"min\" constraints of a specific\nform. In addition to enhancing our repertoire of PPAD-complete problems, we\nexpect the concepts and techniques in this paper to find future use in\nalgorithmic game theory.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2009 22:03:54 GMT"}], "update_date": "2009-04-10", "authors_parsed": [["Kintali", "Shiva", ""], ["Poplawski", "Laura J.", ""], ["Rajaraman", "Rajmohan", ""], ["Sundaram", "Ravi", ""], ["Teng", "Shang-Hua", ""]]}, {"id": "0904.1630", "submitter": "Aaron Sterling", "authors": "Aaron Sterling", "title": "Self-Assembly of a Statistically Self-Similar Fractal", "comments": "I am withdrawing all work I would like to polish before resubmitting,\n  including this paper. Several typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate existence of a tile assembly system that self-assembles the\nstatistically self-similar Sierpinski Triangle in the Winfree-Rothemund Tile\nAssembly Model. This appears to be the first paper that considers self-assembly\nof a random fractal, instead of a deterministic fractal or a finite, bounded\nshape. Our technical contributions include a way to remember, and use,\nunboundedly-long prefixes of an infinite coding sequence at each stage of\nfractal construction; a tile assembly mechanism for nested recursion; and a\ndefinition of \"almost-everywhere local determinism,\" to describe a tileset\nwhose assembly is locally determined, conditional upon a zeta-dimension zero\nset of (infinitely many) \"input\" tiles. This last is similar to the definition\nof randomized computation for Turing machines, in which an algorithm is\ndeterministic relative to an oracle sequence of coin flips that provides advice\nbut does not itself compute. Keywords: tile self-assembly, statistically\nself-similar Sierpinski Triangle.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2009 03:19:04 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2009 15:58:20 GMT"}, {"version": "v3", "created": "Wed, 20 Jul 2011 14:00:06 GMT"}], "update_date": "2011-07-21", "authors_parsed": [["Sterling", "Aaron", ""]]}, {"id": "0904.2058", "submitter": "Chandan Saha", "authors": "Chandan Saha, Ramprasad Saptharishi, Nitin Saxena", "title": "The Power of Depth 2 Circuits over Algebras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of polynomial identity testing (PIT) for depth 2\narithmetic circuits over matrix algebra. We show that identity testing of depth\n3 (Sigma-Pi-Sigma) arithmetic circuits over a field F is polynomial time\nequivalent to identity testing of depth 2 (Pi-Sigma) arithmetic circuits over\nU_2(F), the algebra of upper-triangular 2 x 2 matrices with entries from F.\nSuch a connection is a bit surprising since we also show that, as computational\nmodels, Pi-Sigma circuits over U_2(F) are strictly `weaker' than Sigma-Pi-Sigma\ncircuits over F.\n  The equivalence further shows that PIT of depth 3 arithmetic circuits reduces\nto PIT of width-2 planar commutative Algebraic Branching Programs (ABP). Thus,\nidentity testing for commutative ABPs is interesting even in the case of\nwidth-2.\n  Further, we give a deterministic polynomial time identity testing algorithm\nfor a Pi-Sigma circuit over any constant dimensional commutative algebra over\nF. While over commutative algebras of polynomial dimension, identity testing is\nat least as hard as that of Sigma-Pi-Sigma circuits over F.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2009 06:36:37 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Saha", "Chandan", ""], ["Saptharishi", "Ramprasad", ""], ["Saxena", "Nitin", ""]]}, {"id": "0904.2310", "submitter": "Marek Karpinski", "authors": "Piotr Berman, Marek Karpinski, Andrzej Lingas", "title": "Exact and Approximation Algorithms for Geometric and Capacitated Set\n  Cover Problems with Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First, we study geometric variants of the standard set cover motivated by\nassignment of directional antenna and shipping with deadlines, providing the\nfirst known polynomial-time exact solutions. Next, we consider the following\ngeneral capacitated set cover problem. There is given a set of elements with\nreal weights and a family S of sets of elements. One can use a set if it is a\nsubset of one of the sets on our lists and the sum of weights is at most one.\nThe goal is to cover all the elements with the allowed sets.<br>We show that\nany polynomial-time algorithm that approximates the un-capacitated version of\nthe set cover problem with ratio r can be converted to an approximation\nalgorithm for the capacitated version with ratio r + 1.357.In particular, the\ncomposition of these two results yields a polynomial-time approximation\nalgorithm for the problem of covering a set of customers represented by a\nweighted n-point set with a minimum number of antennas of variable angular\nrange and fixed capacity with ratio 2.357. Finally, we provide a PTAS for the\ndual problem where the number of sets (e.g., antennas) to use is fixed and the\ntask is to minimize the maximum set load, in case the sets correspond to line\nintervals or arcs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2009 13:11:33 GMT"}], "update_date": "2009-09-30", "authors_parsed": [["Berman", "Piotr", ""], ["Karpinski", "Marek", ""], ["Lingas", "Andrzej", ""]]}, {"id": "0904.2759", "submitter": "Ben Reichardt", "authors": "Ben W. Reichardt", "title": "Span programs and quantum query complexity: The general adversary bound\n  is nearly tight for every boolean function", "comments": "70 pages, 2 figures", "journal-ref": "Extended abstract in Proc. 50th IEEE Symp. on Foundations of\n  Computer Science (FOCS), 2009, pages 544-551", "doi": "10.1109/FOCS.2009.55", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general adversary bound is a semi-definite program (SDP) that\nlower-bounds the quantum query complexity of a function. We turn this lower\nbound into an upper bound, by giving a quantum walk algorithm based on the dual\nSDP that has query complexity at most the general adversary bound, up to a\nlogarithmic factor.\n  In more detail, the proof has two steps, each based on \"span programs,\" a\ncertain linear-algebraic model of computation. First, we give an SDP that\noutputs for any boolean function a span program computing it that has optimal\n\"witness size.\" The optimal witness size is shown to coincide with the general\nadversary lower bound. Second, we give a quantum algorithm for evaluating span\nprograms with only a logarithmic query overhead on the witness size.\n  The first result is motivated by a quantum algorithm for evaluating composed\nspan programs. The algorithm is known to be optimal for evaluating a large\nclass of formulas. The allowed gates include all constant-size functions for\nwhich there is an optimal span program. So far, good span programs have been\nfound in an ad hoc manner, and the SDP automates this procedure. Surprisingly,\nthe SDP's value equals the general adversary bound. A corollary is an optimal\nquantum algorithm for evaluating \"balanced\" formulas over any finite boolean\ngate set. The second result extends span programs' applicability beyond the\nformula evaluation problem.\n  A strong universality result for span programs follows. A good quantum query\nalgorithm for a problem implies a good span program, and vice versa. Although\nnearly tight, this equivalence is nontrivial. Span programs are a promising\nmodel for developing more quantum algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2009 18:41:43 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Reichardt", "Ben W.", ""]]}, {"id": "0904.3116", "submitter": "Daniil Musatov", "authors": "Daniil Musatov, Andrei Romashchenko, Alexander Shen", "title": "Variations on Muchnik's Conditional Complexity Theorem", "comments": "24 pages, 1 figure, presented at CSR2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Muchnik's theorem about simple conditional descriptions states that for all\nstrings $a$ and $b$ there exists a short program $p$ transforming $a$ to $b$\nthat has the least possible length and is simple conditional on $b$. In this\npaper we present two new proofs of this theorem. The first one is based on the\non-line matching algorithm for bipartite graphs. The second one, based on\nextractors, can be generalized to prove a version of Muchnik's theorem for\nspace-bounded Kolmogorov complexity.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2009 21:05:09 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2009 17:58:42 GMT"}, {"version": "v3", "created": "Mon, 2 Aug 2010 14:13:23 GMT"}, {"version": "v4", "created": "Fri, 18 Mar 2011 12:33:43 GMT"}], "update_date": "2011-03-21", "authors_parsed": [["Musatov", "Daniil", ""], ["Romashchenko", "Andrei", ""], ["Shen", "Alexander", ""]]}, {"id": "0904.3169", "submitter": "Christoph Durr", "authors": "Christoph Durr and Flavio Guinez and Martin Matamala", "title": "Reconstructing 3-colored grids from horizontal and vertical projections\n  is NP-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of coloring a grid using k colors with the\nrestriction that in each row and each column has an specific number of cells of\neach color. In an already classical result, Ryser obtained a necessary and\nsufficient condition for the existence of such a coloring when two colors are\nconsidered. This characterization yields a linear time algorithm for\nconstructing such a coloring when it exists. Gardner et al. showed that for\nk>=7 the problem is NP-hard. Afterward Chrobak and Durr improved this result,\nby proving that it remains NP-hard for k>=4. We solve the gap by showing that\nfor 3 colors the problem is already NP-hard. Besides we also give some results\non tiling tomography problems.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 08:55:44 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Durr", "Christoph", ""], ["Guinez", "Flavio", ""], ["Matamala", "Martin", ""]]}, {"id": "0904.3183", "submitter": "Fredrik Kuivinen", "authors": "Fredrik Kuivinen", "title": "On the Complexity of Submodular Function Minimisation on Diamonds", "comments": "31 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(L; \\sqcap, \\sqcup)$ be a finite lattice and let $n$ be a positive\ninteger. A function $f : L^n \\to \\mathbb{R}$ is said to be submodular if\n$f(\\tup{a} \\sqcap \\tup{b}) + f(\\tup{a} \\sqcup \\tup{b}) \\leq f(\\tup{a}) +\nf(\\tup{b})$ for all $\\tup{a}, \\tup{b} \\in L^n$. In this paper we study\nsubmodular functions when $L$ is a diamond. Given oracle access to $f$ we are\ninterested in finding $\\tup{x} \\in L^n$ such that $f(\\tup{x}) = \\min_{\\tup{y}\n\\in L^n} f(\\tup{y})$ as efficiently as possible.\n  We establish a min--max theorem, which states that the minimum of the\nsubmodular function is equal to the maximum of a certain function defined over\na certain polyhedron; and a good characterisation of the minimisation problem,\ni.e., we show that given an oracle for computing a submodular $f : L^n \\to\n\\mathbb{Z}$ and an integer $m$ such that $\\min_{\\tup{x} \\in L^n} f(\\tup{x}) =\nm$, there is a proof of this fact which can be verified in time polynomial in\n$n$ and $\\max_{\\tup{t} \\in L^n} \\log |f(\\tup{t})|$; and a pseudo-polynomial\ntime algorithm for the minimisation problem, i.e., given an oracle for\ncomputing a submodular $f : L^n \\to \\mathbb{Z}$ one can find $\\min_{\\tup{t} \\in\nL^n} f(\\tup{t})$ in time bounded by a polynomial in $n$ and $\\max_{\\tup{t} \\in\nL^n} |f(\\tup{t})|$.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 12:41:07 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Kuivinen", "Fredrik", ""]]}, {"id": "0904.3273", "submitter": "John Hamel Dr.", "authors": "John S. Hamel", "title": "A Thermodynamic Turing Machine: Artificial Molecular Computing Using\n  Classical Reversible Logic Switching Networks", "comments": "Version 2 eliminates two erroneous figures (4 and 5 in version 1) and\n  adds a new section containing circuit examples of how to implement Hadamard\n  transforms in one step for Deutsch, Bernstein Vazirani and Simon problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses how to implement certain classes of quantum computer\nalgorithms using classical discrete switching networks that are amenable to\nimplementation in main stream CMOS transistor IC technology. The methods differ\nfrom other classical approaches in that asynchronous feedback is exploited in\nclassical transistor reversible logic circuits to implement the Hadamard\ntransform in one simultaneous step over all qubits as in a true quantum\ncomputer. The Simon problem is used as an example. The method is used to\nprovide an order n execution speed method for the Gaussian elimination step in\nthe Simon problem. The approach is referred to as a Thermodynamic Turing\nMachine in that it behaves like an artificial molecule where solutions to a\nproblem are found by evolving the classical circuits from one thermodynamic\nequilibrium state to another.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 15:39:45 GMT"}, {"version": "v2", "created": "Thu, 14 May 2009 17:56:45 GMT"}], "update_date": "2009-05-14", "authors_parsed": [["Hamel", "John S.", ""]]}, {"id": "0904.3607", "submitter": "Ali Akbar Safilian", "authors": "Ali Akbar Safilian and Farzad Didehvar", "title": "Relation between the Usual Order and the Enumeration Orders of Elements\n  of r.e. Sets", "comments": "15 pages; submitted to Mathematical Logic Quarterly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have compared r.e. sets based on their enumeration orders\nwith Turing machines. Accordingly, we have defined novel concept uniformity for\nTuring machines and r.e. sets and have studied some relationships between\nuniformity and both one-reducibility and Turing reducibility. Furthermore, we\nhave defined type-2 uniformity concept and studied r.e. sets and Turing\nmachines based on this concept. In the end, we have introduced a new structure\ncalled Turing Output Binary Search Tree that helps us lighten some ideas.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2009 07:07:35 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Safilian", "Ali Akbar", ""], ["Didehvar", "Farzad", ""]]}, {"id": "0904.3912", "submitter": "Frank Ferraro", "authors": "Frank Ferraro, Garrett Hall, Andrew Wood", "title": "Refutation of Aslam's Proof that NP = P", "comments": "13 pages, 2 figures, a response to Aslam's paper (arXiv:0812.1385v11)\n  and the underlying arguments (arXiv:0812.1385v9). Very minor content changes\n  and typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aslam presents an algorithm he claims will count the number of perfect\nmatchings in any incomplete bipartite graph with an algorithm in the\nfunction-computing version of NC, which is itself a subset of FP. Counting\nperfect matchings is known to be #P-complete; therefore if Aslam's algorithm is\ncorrect, then NP=P. However, we show that Aslam's algorithm does not correctly\ncount the number of perfect matchings and offer an incomplete bipartite graph\nas a concrete counter-example.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2009 18:01:54 GMT"}, {"version": "v2", "created": "Thu, 14 May 2009 22:52:47 GMT"}], "update_date": "2009-05-15", "authors_parsed": [["Ferraro", "Frank", ""], ["Hall", "Garrett", ""], ["Wood", "Andrew", ""]]}, {"id": "0904.3927", "submitter": "Cole Brown", "authors": "Andrew Keenan Richardson, Cole Arthur Brown", "title": "A Critique of \"Solving the P/NP Problem Under Intrinsic Uncertainty\",\n  arXiv:0811.0463", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Although whether P equals NP is an important, open problem in computer\nscience, and although Jaeger's 2008 paper, \"Solving the P/NP Problem Under\nIntrinsic Uncertainty\" (arXiv:0811.0463) presents an attempt at tackling the\nproblem by discussing the possibility that all computation is uncertain to some\ndegree, there are a number of logical oversights present in that paper which\npreclude it from serious consideration toward having resolved P-versus-NP.\nThere are several differences between the model of computation presented in\nJaeger's paper and the standard model, as well as several bold assumptions that\nare not well supported in Jaeger's paper or in the literature. In addition, we\nfind several omissions of rigorous proof that ultimately weaken this paper to a\npoint where it cannot be considered a candidate solution to the P-versus-NP\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2009 19:32:10 GMT"}], "update_date": "2009-04-27", "authors_parsed": [["Richardson", "Andrew Keenan", ""], ["Brown", "Cole Arthur", ""]]}, {"id": "0904.3941", "submitter": "Sagarmoy Dutta", "authors": "Sagarmoy Dutta and Piyush P Kurur", "title": "Representating groups on graphs", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": "10.1007/978-3-642-03816-7_26", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we formulate and study the problem of representing groups on\ngraphs. We show that with respect to polynomial time turing reducibility, both\nabelian and solvable group representability are all equivalent to graph\nisomorphism, even when the group is presented as a permutation group via\ngenerators. On the other hand, the representability problem for general groups\non trees is equivalent to checking, given a group $G$ and $n$, whether a\nnontrivial homomorphism from $G$ to $S_n$ exists. There does not seem to be a\npolynomial time algorithm for this problem, in spite of the fact that tree\nisomorphism has polynomial time algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2009 20:39:59 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Dutta", "Sagarmoy", ""], ["Kurur", "Piyush P", ""]]}, {"id": "0904.4331", "submitter": "Prabhu Manyem", "authors": "Prabhu Manyem", "title": "Lower Bounds on Syntactic Logic Expressions for Optimization Problems\n  and Duality using Lagrangian Dual to characterize optimality conditions", "comments": "An expansion of the previous version to include: a single call to a\n  decision Turing machine to solve optimization problems obeying strong duality\n  in polynomial time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that simple syntactic expressions such as existential second order\n(ESO) universal Horn formulae can express NP-hard optimisation problems. There\nis a significant difference between the expressibilities of decision problems\nand optimisation problems. This is similar to the difference in computation\ntimes for the two classes of problems; for example, a 2SAT Horn formula can be\nsatisfied in polynomial time, whereas the optimisation version in NP-hard. It\nis known that all polynomially solvable decision problems can be expressed as\nESO universal ($\\Pi_1$) Horn sentences in the presence of a successor relation.\nWe show here that, on the other hand, if $P \\neq NP$, optimisation problems\ndefy such a characterisation, by demonstrating that even a $\\Pi_0$ (quantifier\nfree) Horn formula is unable to guarantee polynomial time solvability. Finally,\nby connecting concepts in optimisation duality with those in descriptive\ncomplexity, we will show a method by which optimisation problems can be solved\nby a single call to a \"decision\" Turing machine, as opposed to multiple calls\nusing a classical binary search setting.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2009 08:28:11 GMT"}, {"version": "v2", "created": "Wed, 6 May 2009 04:08:41 GMT"}, {"version": "v3", "created": "Sun, 24 Jul 2011 09:15:16 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Manyem", "Prabhu", ""]]}, {"id": "0904.4360", "submitter": "Arnab Bhattacharyya", "authors": "Arnab Bhattacharyya and Bernhard Haeupler", "title": "Robust Regulatory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.CC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the characteristic features of genetic networks is their inherent\nrobustness, that is, their ability to retain functionality in spite of the\nintroduction of random errors. In this paper, we seek to better understand how\nrobustness is achieved and what functionalities can be maintained robustly. Our\ngoal is to formalize some of the language used in biological discussions in a\nreasonable mathematical framework, where questions can be answered in a\nrigorous fashion. These results provide basic conceptual understanding of\nrobust regulatory networks that should be valuable independent of the details\nof the formalism.\n  We model the gene regulatory network as a boolean network, a general and\nwell-established model introduced by Stuart Kauffman. A boolean network is said\nto be in a viable configuration if the node states of the network at its\nfixpoint satisfy some given constraint. We specify how mutations affect the\nbehavior of the boolean network. A network is then said to be robust if most\nrandom mutations to the network reach a viable configuration. The main question\ninvestigated in our study is: given a constraint on the fixpoint configuration,\ndoes there exist a network that is robust with respect to it and, if so, what\nis its structure? We demonstrate both explicit constructions of robust networks\nas well as negative results disproving their existence.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2009 10:46:26 GMT"}], "update_date": "2009-04-29", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Haeupler", "Bernhard", ""]]}, {"id": "0904.4512", "submitter": "Andr\\'as Salamon", "authors": "Andr\\'as Z. Salamon and Vashti Galpin", "title": "Bounds on series-parallel slowdown", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use activity networks (task graphs) to model parallel programs and\nconsider series-parallel extensions of these networks. Our motivation is\ntwo-fold: the benefits of series-parallel activity networks and the modelling\nof programming constructs, such as those imposed by current parallel computing\nenvironments. Series-parallelisation adds precedence constraints to an activity\nnetwork, usually increasing its makespan (execution time). The slowdown ratio\ndescribes how additional constraints affect the makespan. We disprove an\nexisting conjecture positing a bound of two on the slowdown when workload is\nnot considered. Where workload is known, we conjecture that 4/3 slowdown is\nalways achievable, and prove our conjecture for small networks using max-plus\nalgebra. We analyse a polynomial-time algorithm showing that achieving 4/3\nslowdown is in exp-APX. Finally, we discuss the implications of our results.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2009 01:39:57 GMT"}], "update_date": "2009-04-30", "authors_parsed": [["Salamon", "Andr\u00e1s Z.", ""], ["Galpin", "Vashti", ""]]}, {"id": "0904.4911", "submitter": "Michael Goodrich", "authors": "Michael T. Goodrich", "title": "On the Algorithmic Complexity of the Mastermind Game with Black-Peg\n  Results", "comments": "Expanded version with a figure showing the Mastermind game", "journal-ref": "Information Processing Letters, Volume 109, 675-678, 2009", "doi": "10.1016/j.ipl.2009.02.021", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the algorithmic complexity of the Mastermind game,\nwhere results are single-color black pegs. This differs from the usual\ndual-color version of the game, but better corresponds to applications in\ngenetics. We show that it is NP-complete to determine if a sequence of\nsingle-color Mastermind results have a satisfying vector. We also show how to\ndevise efficient algorithms for discovering a hidden vector through\nsingle-color queries. Indeed, our algorithm improves a previous method of\nChvatal by almost a factor of 2.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2009 18:31:15 GMT"}], "update_date": "2009-05-13", "authors_parsed": [["Goodrich", "Michael T.", ""]]}]