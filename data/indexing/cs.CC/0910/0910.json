[{"id": "0910.0110", "submitter": "Patrick Briest", "authors": "Patrick Briest and Sanjeev Khanna", "title": "Improved Hardness of Approximation for Stackelberg Shortest-Path Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Stackelberg shortest-path pricing problem, which is defined\nas follows. Given a graph G with fixed-cost and pricable edges and two distinct\nvertices s and t, we may assign prices to the pricable edges. Based on the\npredefined fixed costs and our prices, a customer purchases a cheapest s-t-path\nin G and we receive payment equal to the sum of prices of pricable edges\nbelonging to the path. Our goal is to find prices maximizing the payment\nreceived from the customer. While Stackelberg shortest-path pricing was known\nto be APX-hard before, we provide the first explicit approximation threshold\nand prove hardness of approximation within 2-o(1).\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2009 09:15:06 GMT"}], "update_date": "2009-10-02", "authors_parsed": [["Briest", "Patrick", ""], ["Khanna", "Sanjeev", ""]]}, {"id": "0910.0287", "submitter": "Luigi Cimmino", "authors": "Luigi Cimmino", "title": "Shor's Algorithm from the Mindset of Quantum Oracles", "comments": "8 pages, report on deterministic quantum measuremet theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to show a brand-new way of making deterministic\nQuantum Computing (short QC), in the sense of Theory of Calculability, by\nmeaning of unitary evolution. We start from the original Shor's Algorithm to\nexplain how the newest one works, at least compared to theory. We will give a\nnew conceptual foundation of QC, resulting from a set of conventional and well\nknown results of Calculability and Quantum Mechanics. In the practice, if that\ncan be used in its general sense, we will show an inaccessible relativized\nprocess which let us able to obtain same results with the same outlay in the\ntime resource as the Shor's one for factorizing a given number n. Then the\nQO-system will be a prototype way giving to the relativized calculus the\npossibility to put in to practice an oracle, kind of object having till now\nabstract nature. The basic physical tool of our theorization, we call Quantum\nState Selection, consists in the twin-combined measurement process through\npositive valued measure operator (POVM), needed to provide the quantum oracle's\nanswer.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2009 22:55:59 GMT"}, {"version": "v2", "created": "Sun, 3 Apr 2011 14:34:21 GMT"}], "update_date": "2011-04-05", "authors_parsed": [["Cimmino", "Luigi", ""]]}, {"id": "0910.0443", "submitter": "Danupon Nanongkai", "authors": "Parinya Chalermsook, Bundit Laekhanukit, Danupon Nanongkai", "title": "Stackelberg Pricing is Hard to Approximate within $2-\\epsilon$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stackelberg Pricing Games is a two-level combinatorial pricing problem\nstudied in the Economics, Operation Research, and Computer Science communities.\nIn this paper, we consider the decade-old shortest path version of this problem\nwhich is the first and most studied problem in this family.\n  The game is played on a graph (representing a network) consisting of {\\em\nfixed cost} edges and {\\em pricable} or {\\em variable cost} edges. The fixed\ncost edges already have some fixed price (representing the competitor's\nprices). Our task is to choose prices for the variable cost edges. After that,\na client will buy the cheapest path from a node $s$ to a node $t$, using any\ncombination of fixed cost and variable cost edges. The goal is to maximize the\nrevenue on variable cost edges.\n  In this paper, we show that the problem is hard to approximate within\n$2-\\epsilon$, improving the previous \\APX-hardness result by Joret [to appear\nin {\\em Networks}]. Our technique combines the existing ideas with a new\ninsight into the price structure and its relation to the hardness of the\ninstances.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2009 19:54:54 GMT"}], "update_date": "2009-10-05", "authors_parsed": [["Chalermsook", "Parinya", ""], ["Laekhanukit", "Bundit", ""], ["Nanongkai", "Danupon", ""]]}, {"id": "0910.0582", "submitter": "Michael Lampis", "authors": "Michael Lampis", "title": "Algorithmic Meta-Theorems for Graphs of Bounded Vertex Cover", "comments": "In this version, the algorithmic results have been extended to a new\n  graph width, called neighborhood diversity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Possibly the most famous algorithmic meta-theorem is Courcelle's theorem,\nwhich states that all MSO-expressible graph properties are decidable in linear\ntime for graphs of bounded treewidth. Unfortunately, the running time's\ndependence on the MSO formula describing the problem is in general a tower of\nexponentials of unbounded height, and there exist lower bounds proving that\nthis cannot be improved even if we restrict ourselves to deciding FO logic on\ntrees.\n  In this paper we attempt to circumvent these lower bounds by focusing on a\nsubclass of bounded treewidth graphs, the graphs of bounded vertex cover. By\nusing a technique different from the standard decomposition and dynamic\nprogramming technique of treewidth we prove that in this case the running time\nimplied by Courcelle's theorem can be improved dramatically, from\nnon-elementary to doubly and singly exponential for MSO and FO logic\nrespectively. Our technique relies on a new graph width measure we introduce,\nfor which we show some additional results that may indicate that it is of\nindependent interest. We also prove lower bound results which show that our\nupper bounds cannot be improved significantly, under widely believed complexity\nassumptions. Our work answers an open problem posed by Michael Fellows.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2009 02:58:25 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2009 21:22:08 GMT"}], "update_date": "2009-11-05", "authors_parsed": [["Lampis", "Michael", ""]]}, {"id": "0910.0641", "submitter": "Arnab Bhattacharyya", "authors": "Arnab Bhattacharyya, Swastik Kopparty, Grant Schoenebeck, Madhu Sudan,\n  David Zuckerman", "title": "Optimal Testing of Reed-Muller Codes", "comments": "22 pages; introduction reformulated and some minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of testing if a given function f : F_2^n -> F_2 is\nclose to any degree d polynomial in n variables, also known as the Reed-Muller\ntesting problem. The Gowers norm is based on a natural 2^{d+1}-query test for\nthis property. Alon et al. [AKKLR05] rediscovered this test and showed that it\naccepts every degree d polynomial with probability 1, while it rejects\nfunctions that are Omega(1)-far with probability Omega(1/(d 2^{d})). We give an\nasymptotically optimal analysis of this test, and show that it rejects\nfunctions that are (even only) Omega(2^{-d})-far with Omega(1)-probability (so\nthe rejection probability is a universal constant independent of d and n). This\nimplies a tight relationship between the (d+1)st Gowers norm of a function and\nits maximal correlation with degree d polynomials, when the correlation is\nclose to 1. Our proof works by induction on n and yields a new analysis of even\nthe classical Blum-Luby-Rubinfeld [BLR93] linearity test, for the setting of\nfunctions mapping F_2^n to F_2. The optimality follows from a tighter analysis\nof counterexamples to the \"inverse conjecture for the Gowers norm\" constructed\nby [GT09,LMS08]. Our result has several implications. First, it shows that the\nGowers norm test is tolerant, in that it also accepts close codewords. Second,\nit improves the parameters of an XOR lemma for polynomials given by Viola and\nWigderson [VW07]. Third, it implies a \"query hierarchy\" result for property\ntesting of affine-invariant properties. That is, for every function q(n), it\ngives an affine-invariant property that is testable with O(q(n))-queries, but\nnot with o(q(n))-queries, complementing an analogous result of [GKNR09] for\ngraph properties.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2009 21:17:45 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2010 05:06:05 GMT"}], "update_date": "2010-04-12", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Kopparty", "Swastik", ""], ["Schoenebeck", "Grant", ""], ["Sudan", "Madhu", ""], ["Zuckerman", "David", ""]]}, {"id": "0910.1268", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM)", "title": "The Complexity of Infinite Computations In Models of Set Theory", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 4 (December\n  21, 2009) lmcs:1205", "doi": "10.2168/LMCS-5(4:4)2009", "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the following surprising result: there exist a 1-counter B\\\"uchi\nautomaton and a 2-tape B\\\"uchi automaton such that the \\omega-language of the\nfirst and the infinitary rational relation of the second in one model of ZFC\nare \\pi_2^0-sets, while in a different model of ZFC both are analytic but non\nBorel sets.\n  This shows that the topological complexity of an \\omega-language accepted by\na 1-counter B\\\"uchi automaton or of an infinitary rational relation accepted by\na 2-tape B\\\"uchi automaton is not determined by the axiomatic system ZFC.\n  We show that a similar result holds for the class of languages of infinite\npictures which are recognized by B\\\"uchi tiling systems.\n  We infer from the proof of the above results an improvement of the lower\nbound of some decision problems recently studied by the author.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 14:03:53 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2009 18:58:05 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2009 18:39:54 GMT"}, {"version": "v4", "created": "Mon, 21 Dec 2009 14:08:27 GMT"}, {"version": "v5", "created": "Wed, 23 Dec 2009 20:10:04 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Finkel", "Olivier", "", "ELM"]]}, {"id": "0910.1427", "submitter": "Maurice  Jansen", "authors": "Maurice Jansen and Jayalal Sarma M.N", "title": "Balancing Bounded Treewidth Circuits", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-13182-0_21", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic tools for graphs of small treewidth are used to address questions\nin complexity theory. For both arithmetic and Boolean circuits, it is shown\nthat any circuit of size $n^{O(1)}$ and treewidth $O(\\log^i n)$ can be\nsimulated by a circuit of width $O(\\log^{i+1} n)$ and size $n^c$, where $c =\nO(1)$, if $i=0$, and $c=O(\\log \\log n)$ otherwise. For our main construction,\nwe prove that multiplicatively disjoint arithmetic circuits of size $n^{O(1)}$\nand treewidth $k$ can be simulated by bounded fan-in arithmetic formulas of\ndepth $O(k^2\\log n)$. From this we derive the analogous statement for\nsyntactically multilinear arithmetic circuits, which strengthens a theorem of\nMahajan and Rao. As another application, we derive that constant width\narithmetic circuits of size $n^{O(1)}$ can be balanced to depth $O(\\log n)$,\nprovided certain restrictions are made on the use of iterated multiplication.\nAlso from our main construction, we derive that Boolean bounded fan-in circuits\nof size $n^{O(1)}$ and treewidth $k$ can be simulated by bounded fan-in\nformulas of depth $O(k^2\\log n)$. This strengthens in the non-uniform setting\nthe known inclusion that $SC^0 \\subseteq NC^1$. Finally, we apply our\nconstruction to show that {\\sc reachability} for directed graphs of bounded\ntreewidth is in $LogDCFL$.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2009 06:56:50 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Jansen", "Maurice", ""], ["N", "Jayalal Sarma M.", ""]]}, {"id": "0910.1443", "submitter": "Maurice  Jansen", "authors": "Maurice Jansen", "title": "Weakening Assumptions for Deterministic Subexponential Time Non-Singular\n  Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In (Kabanets, Impagliazzo, 2004) it is shown how to decide the circuit\npolynomial identity testing problem (CPIT) in deterministic subexponential\ntime, assuming hardness of some explicit multilinear polynomial family for\narithmetical circuits. In this paper, a special case of CPIT is considered,\nnamely low-degree non-singular matrix completion (NSMC). For this subclass of\nproblems it is shown how to obtain the same deterministic time bound, using a\nweaker assumption in terms of determinantal complexity.\n  Hardness-randomness tradeoffs will also be shown in the converse direction,\nin an effort to make progress on Valiant's VP versus VNP problem. To separate\nVP and VNP, it is known to be sufficient to prove that the determinantal\ncomplexity of the m-by-m permanent is $m^{\\omega(\\log m)}$. In this paper it is\nshown, for an appropriate notion of explicitness, that the existence of an\nexplicit multilinear polynomial family with determinantal complexity\nm^{\\omega(\\log m)}$ is equivalent to the existence of an efficiently computable\ngenerator $G_n$ for multilinear NSMC with seed length $O(n^{1/\\sqrt{\\log n}})$.\nThe latter is a combinatorial object that provides an efficient deterministic\nblack-box algorithm for NSMC. ``Multilinear NSMC'' indicates that $G_n$ only\nhas to work for matrices $M(x)$ of $poly(n)$ size in $n$ variables, for which\n$det(M(x))$ is a multilinear polynomial.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2009 08:44:29 GMT"}], "update_date": "2009-10-09", "authors_parsed": [["Jansen", "Maurice", ""]]}, {"id": "0910.1862", "submitter": "Alexander A. Sherstov", "authors": "Alexander A. Sherstov", "title": "The intersection of two halfspaces has high threshold degree", "comments": "Full version of the FOCS'09 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threshold degree of a Boolean function f:{0,1}^n->{-1,+1} is the least\ndegree of a real polynomial p such that f(x)=sgn p(x). We construct two\nhalfspaces on {0,1}^n whose intersection has threshold degree Theta(sqrt n), an\nexponential improvement on previous lower bounds. This solves an open problem\ndue to Klivans (2002) and rules out the use of perceptron-based techniques for\nPAC learning the intersection of two halfspaces, a central unresolved challenge\nin computational learning. We also prove that the intersection of two majority\nfunctions has threshold degree Omega(log n), which is tight and settles a\nconjecture of O'Donnell and Servedio (2003).\n  Our proof consists of two parts. First, we show that for any nonconstant\nBoolean functions f and g, the intersection f(x)^g(y) has threshold degree O(d)\nif and only if ||f-F||_infty + ||g-G||_infty < 1 for some rational functions F,\nG of degree O(d). Second, we settle the least degree required for approximating\na halfspace and a majority function to any given accuracy by rational\nfunctions.\n  Our technique further allows us to make progress on Aaronson's challenge\n(2008) and contribute strong direct product theorems for polynomial\nrepresentations of composed Boolean functions of the form F(f_1,...,f_n). In\nparticular, we give an improved lower bound on the approximate degree of the\nAND-OR tree.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2009 16:14:48 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Sherstov", "Alexander A.", ""]]}, {"id": "0910.2058", "submitter": "Christopher Laumann", "authors": "C.R. Laumann, A.M. L\\\"auchli, R. Moessner, A. Scardicchio and S.L.\n  Sondhi", "title": "On product, generic and random generic quantum satisfiability", "comments": "9 pages, 5 figures, 1 table. Updated to more closely match published\n  version. New proof in appendix", "journal-ref": "Phys. Rev. A 81, 062345 (2010)", "doi": "10.1103/PhysRevA.81.062345", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a cluster of results on k-QSAT, the problem of quantum\nsatisfiability for k-qubit projectors which generalizes classical\nsatisfiability with k-bit clauses to the quantum setting. First we define the\nNP-complete problem of product satisfiability and give a geometrical criterion\nfor deciding when a QSAT interaction graph is product satisfiable with positive\nprobability. We show that the same criterion suffices to establish quantum\nsatisfiability for all projectors. Second, we apply these results to the random\ngraph ensemble with generic projectors and obtain improved lower bounds on the\nlocation of the SAT--unSAT transition. Third, we present numerical results on\nrandom, generic satisfiability which provide estimates for the location of the\ntransition for k=3 and k=4 and mild evidence for the existence of a phase which\nis satisfiable by entangled states alone.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2009 15:12:52 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2010 16:20:32 GMT"}], "update_date": "2010-07-02", "authors_parsed": [["Laumann", "C. R.", ""], ["L\u00e4uchli", "A. M.", ""], ["Moessner", "R.", ""], ["Scardicchio", "A.", ""], ["Sondhi", "S. L.", ""]]}, {"id": "0910.2271", "submitter": "Ali Sinop", "authors": "Venkatesan Guruswami, Ali Kemal Sinop", "title": "Improved Inapproximability Results for Maximum k-Colorable Subgraph", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": "10.1007/978-3-642-03685-9_13", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the maximization version of the fundamental graph coloring problem.\nHere the goal is to color the vertices of a k-colorable graph with k colors so\nthat a maximum fraction of edges are properly colored (i.e. their endpoints\nreceive different colors). A random k-coloring properly colors an expected\nfraction 1-1/k of edges. We prove that given a graph promised to be\nk-colorable, it is NP-hard to find a k-coloring that properly colors more than\na fraction ~1-O(1/k} of edges. Previously, only a hardness factor of 1-O(1/k^2)\nwas known. Our result pins down the correct asymptotic dependence of the\napproximation factor on k. Along the way, we prove that approximating the\nMaximum 3-colorable subgraph problem within a factor greater than 32/33 is\nNP-hard. Using semidefinite programming, it is known that one can do better\nthan a random coloring and properly color a fraction 1-1/k +2 ln k/k^2 of edges\nin polynomial time. We show that, assuming the 2-to-1 conjecture, it is hard to\nproperly color (using k colors) more than a fraction 1-1/k + O(ln k/ k^2) of\nedges of a k-colorable graph.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2009 23:49:08 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2009 21:22:15 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2009 22:34:46 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Sinop", "Ali Kemal", ""]]}, {"id": "0910.2370", "submitter": "Srikanth Srinivasan", "authors": "V. Arvind, Srikanth Srinivasan", "title": "On the hardness of the noncommutative determinant", "comments": "11 pages, v2: 18 pages, some typos removed, new section added on\n  Clifford algebras, and some reorganization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the computational complexity of computing the\nnoncommutative determinant. We first consider the arithmetic circuit complexity\nof computing the noncommutative determinant polynomial. Then, more generally,\nwe also examine the complexity of computing the determinant (as a function)\nover noncommutative domains. Our hardness results are summarized below:\n  1. We show that if the noncommutative determinant polynomial has small\nnoncommutative arithmetic circuits then so does the noncommutative permanent.\nConsequently, the commutative permanent polynomial has small commutative\narithmetic circuits. 2. For any field F we show that computing the n X n\npermanent over F is polynomial-time reducible to computing the 2n X 2n\n(noncommutative) determinant whose entries are O(n^2) X O(n^2) matrices over\nthe field F. 3. We also derive as a consequence that computing the n X n\npermanent over nonnegative rationals is polynomial-time reducible to computing\nthe noncommutative determinant over Clifford algebras of n^{O(1)} dimension.\n  Our techniques are elementary and use primarily the notion of the Hadamard\nProduct of noncommutative polynomials.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 11:58:22 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2009 09:25:42 GMT"}], "update_date": "2009-10-26", "authors_parsed": [["Arvind", "V.", ""], ["Srinivasan", "Srikanth", ""]]}, {"id": "0910.2415", "submitter": "Andrei Romashchenko", "authors": "Bruno Durand (LIF), Andrei Romashchenko (LIF), Alexander Shen (LIF)", "title": "Fixed-point tile sets and their applications", "comments": "v7: updated reference to S.G.Simpson's paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.DS math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An aperiodic tile set was first constructed by R. Berger while proving the\nundecidability of the domino problem. It turned out that aperiodic tile sets\nappear in many topics ranging from logic (the Entscheidungsproblem) to physics\n(quasicrystals). We present a new construction of an aperiodic tile set that is\nbased on Kleene's fixed-point construction instead of geometric arguments. This\nconstruction is similar to J. von Neumann self-reproducing automata; similar\nideas were also used by P. Gacs in the context of error-correcting\ncomputations. This construction it rather flexible, so it can be used in many\nways: we show how it can be used to implement substitution rules, to construct\nstrongly aperiodic tile sets (any tiling is far from any periodic tiling), to\ngive a new proof for the undecidability of the domino problem and related\nresults, characterize effectively closed 1D subshift it terms of 2D shifts of\nfinite type (improvement of a result by M. Hochman), to construct a tile set\nwhich has only complex tilings, and to construct a \"robust\" aperiodic tile set\nthat does not have periodic (or close to periodic) tilings even if we allow\nsome (sparse enough) tiling errors. For the latter we develop a hierarchical\nclassification of points in random sets into islands of different ranks.\nFinally, we combine and modify our tools to prove our main result: there exists\na tile set such that all tilings have high Kolmogorov complexity even if\n(sparse enough) tiling errors are allowed.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 18:55:52 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2009 06:38:41 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2010 14:42:41 GMT"}, {"version": "v4", "created": "Fri, 17 Sep 2010 14:22:01 GMT"}, {"version": "v5", "created": "Fri, 12 Nov 2010 15:39:26 GMT"}, {"version": "v6", "created": "Mon, 3 Oct 2011 19:31:37 GMT"}, {"version": "v7", "created": "Thu, 4 Dec 2014 10:19:41 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Durand", "Bruno", "", "LIF"], ["Romashchenko", "Andrei", "", "LIF"], ["Shen", "Alexander", "", "LIF"]]}, {"id": "0910.2443", "submitter": "J. M. Landsberg", "authors": "J.M. Landsberg", "title": "P versus NP and geometry", "comments": "20 pages, to appear in special issue of J. Symbolic. Comp. dedicated\n  to MEGA 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I describe three geometric approaches to resolving variants of P v. NP,\npresent several results that illustrate the role of group actions in complexity\ntheory, and make a first step towards completely geometric definitions of\ncomplexity classes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 17:47:36 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2010 18:10:18 GMT"}], "update_date": "2010-04-15", "authors_parsed": [["Landsberg", "J. M.", ""]]}, {"id": "0910.2649", "submitter": "Chinmay Karande", "authors": "Chinmay Karande", "title": "Polynomially Correlated Knapsack is NP-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  0-1 Knapsack is a fundamental NP-complete problem. In this article we prove\nthat it remains NP-complete even when the weights of the objects in the packing\nconstraints and their values in the objective function satisfy specific\nstringent conditions: the values are integral powers of the weights of the\nobjects.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2009 15:43:40 GMT"}], "update_date": "2009-10-15", "authors_parsed": [["Karande", "Chinmay", ""]]}, {"id": "0910.3127", "submitter": "Jakob Nordstr\\\"om", "authors": "Jakob Nordstr\\\"om, Alexander Razborov", "title": "On Minimal Unsatisfiability and Time-Space Trade-offs for k-DNF\n  Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of proving lower bounds on proof space in k-DNF resolution,\n[Ben-Sasson and Nordstrom 2009] introduced the concept of minimally\nunsatisfiable sets of k-DNF formulas and proved that a minimally unsatisfiable\nk-DNF set with m formulas can have at most O((mk)^(k+1)) variables. They also\ngave an example of such sets with Omega(mk^2) variables.\n  In this paper we significantly improve the lower bound to Omega(m)^k, which\nalmost matches the upper bound above. Furthermore, we show that this implies\nthat the analysis of their technique for proving time-space separations and\ntrade-offs for k-DNF resolution is almost tight. This means that although it is\npossible, or even plausible, that stronger results than in [Ben-Sasson and\nNordstrom 2009] should hold, a fundamentally different approach would be needed\nto obtain such results.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2009 14:33:58 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2009 21:10:31 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Nordstr\u00f6m", "Jakob", ""], ["Razborov", "Alexander", ""]]}, {"id": "0910.3282", "submitter": "Yunlei Zhao", "authors": "Andrew C. Yao, Moti Yung, Yunlei Zhao", "title": "Adaptive Concurrent Non-Malleability with Bare Public-Keys", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent non-malleability (CNM) is central for cryptographic protocols\nrunning concurrently in environments such as the Internet. In this work, we\nformulate CNM in the bare public-key (BPK) model, and show that round-efficient\nconcurrent non-malleable cryptography with full adaptive input selection can be\nestablished, in general, with bare public-keys (where, in particular, no\ntrusted assumption is made). Along the way, we clarify the various subtleties\nof adaptive concurrent non-malleability in the bare public-key model.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2009 07:28:50 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Yao", "Andrew C.", ""], ["Yung", "Moti", ""], ["Zhao", "Yunlei", ""]]}, {"id": "0910.3376", "submitter": "Andrew Drucker", "authors": "Andrew Drucker (MIT), Ronald de Wolf (CWI Amsterdam)", "title": "Quantum Proofs for Classical Theorems", "comments": "50 pages LaTeX. Updated based on journal version; the journal version\n  is open-access and has nicer typesetting\n  (http://theoryofcomputing.org/articles/gs002/)", "journal-ref": "Theory of Computing, Graduate surveys 2, 2011", "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alongside the development of quantum algorithms and quantum complexity theory\nin recent years, quantum techniques have also proved instrumental in obtaining\nresults in classical (non-quantum) areas. In this paper we survey these results\nand the quantum toolbox they use.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2009 14:19:34 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2011 00:33:32 GMT"}], "update_date": "2011-03-15", "authors_parsed": [["Drucker", "Andrew", "", "MIT"], ["de Wolf", "Ronald", "", "CWI Amsterdam"]]}, {"id": "0910.3719", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Rocco A. Servedio", "title": "Improved Approximation of Linear Threshold Functions", "comments": "full version of CCC'09 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove two main results on how arbitrary linear threshold functions $f(x) =\n\\sign(w\\cdot x - \\theta)$ over the $n$-dimensional Boolean hypercube can be\napproximated by simple threshold functions.\n  Our first result shows that every $n$-variable threshold function $f$ is\n$\\eps$-close to a threshold function depending only on $\\Inf(f)^2 \\cdot\n\\poly(1/\\eps)$ many variables, where $\\Inf(f)$ denotes the total influence or\naverage sensitivity of $f.$ This is an exponential sharpening of Friedgut's\nwell-known theorem \\cite{Friedgut:98}, which states that every Boolean function\n$f$ is $\\eps$-close to a function depending only on $2^{O(\\Inf(f)/\\eps)}$ many\nvariables, for the case of threshold functions. We complement this upper bound\nby showing that $\\Omega(\\Inf(f)^2 + 1/\\epsilon^2)$ many variables are required\nfor $\\epsilon$-approximating threshold functions.\n  Our second result is a proof that every $n$-variable threshold function is\n$\\eps$-close to a threshold function with integer weights at most $\\poly(n)\n\\cdot 2^{\\tilde{O}(1/\\eps^{2/3})}.$ This is a significant improvement, in the\ndependence on the error parameter $\\eps$, on an earlier result of\n\\cite{Servedio:07cc} which gave a $\\poly(n) \\cdot 2^{\\tilde{O}(1/\\eps^{2})}$\nbound. Our improvement is obtained via a new proof technique that uses strong\nanti-concentration bounds from probability theory. The new technique also gives\na simple and modular proof of the original \\cite{Servedio:07cc} result, and\nextends to give low-weight approximators for threshold functions under a range\nof probability distributions beyond just the uniform distribution.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2009 23:11:46 GMT"}], "update_date": "2009-10-21", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "0910.4042", "submitter": "Hector Zenil", "authors": "Hector Zenil", "title": "Compression-based investigation of the dynamical properties of cellular\n  automata and other systems", "comments": "28 pages. This version includes the conjecture relating the\n  transition coefficient to computational universality. Camera ready version", "journal-ref": "Journal of Complex Systems, 19(1), 2010", "doi": null, "report-no": null, "categories": "cs.CC nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for studying the qualitative dynamical properties of abstract\ncomputing machines based on the approximation of their program-size complexity\nusing a general lossless compression algorithm is presented. It is shown that\nthe compression-based approach classifies cellular automata (CA) into clusters\naccording to their heuristic behavior, with these clusters showing a\ncorrespondence with Wolfram's main classes of CA behavior. A compression based\nmethod to estimate a characteristic exponent to detect phase transitions and\nmeasure the resiliency or sensitivity of a system to its initial conditions is\nalso proposed. A conjecture regarding the capability of a system to reach\ncomputational universality related to the values of this phase transition\ncoefficient is formulated. These ideas constitute a compression-based framework\nfor investigating the dynamical properties of cellular automata and other\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2009 10:33:50 GMT"}, {"version": "v2", "created": "Sat, 14 Aug 2010 04:54:31 GMT"}, {"version": "v3", "created": "Wed, 29 Sep 2010 18:46:45 GMT"}, {"version": "v4", "created": "Fri, 21 Jan 2011 18:17:18 GMT"}], "update_date": "2011-01-24", "authors_parsed": [["Zenil", "Hector", ""]]}, {"id": "0910.4122", "submitter": "Raghu Meka", "authors": "Raghu Meka, David Zuckerman", "title": "Pseudorandom Generators for Polynomial Threshold Functions", "comments": "Revision 5: Updated to the journal version to appear in SICOMP.\n  Revision 4: Improves seed-length for halfspaces to O(log n + log^2(1/eps))\n  (the change in analysis is minor: use INW PRG instead of Nisan's PRG).\n  Revision 3: Fixed some more minor errors (mainly in proof of Theorem 4.3).\n  Revision 2: Corrected the non-explicit bound to O(d log n + log(1/eps)) and\n  some minor typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the natural question of constructing pseudorandom generators (PRGs)\nfor low-degree polynomial threshold functions (PTFs). We give a PRG with\nseed-length log n/eps^{O(d)} fooling degree d PTFs with error at most eps.\nPreviously, no nontrivial constructions were known even for quadratic threshold\nfunctions and constant error eps. For the class of degree 1 threshold functions\nor halfspaces, we construct PRGs with much better dependence on the error\nparameter eps and obtain a PRG with seed-length O(log n + log^2(1/eps)).\nPreviously, only PRGs with seed length O(log n log^2(1/eps)/eps^2) were known\nfor halfspaces. We also obtain PRGs with similar seed lengths for fooling\nhalfspaces over the n-dimensional unit sphere.\n  The main theme of our constructions and analysis is the use of invariance\nprinciples to construct pseudorandom generators. We also introduce the notion\nof monotone read-once branching programs, which is key to improving the\ndependence on the error rate eps for halfspaces. These techniques may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2009 15:48:00 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2009 21:50:20 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2009 17:16:04 GMT"}, {"version": "v4", "created": "Thu, 11 Nov 2010 18:25:40 GMT"}, {"version": "v5", "created": "Tue, 15 Nov 2011 14:41:26 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Meka", "Raghu", ""], ["Zuckerman", "David", ""]]}, {"id": "0910.4224", "submitter": "Alexander A. Sherstov", "authors": "Alexander A. Sherstov", "title": "Optimal bounds for sign-representing the intersection of two halfspaces\n  by polynomials", "comments": "A few minor simplifications added", "journal-ref": "In Proceedings of the 42nd ACM Symposium on Theory of Computing\n  (STOC 2010)", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threshold degree of a function f:{0,1}^n->{-1,+1} is the least degree of\na real polynomial p with f(x)=sgn p(x). We prove that the intersection of two\nhalfspaces on {0,1}^n has threshold degree Omega(n), which matches the trivial\nupper bound and completely answers a question due to Klivans (2002). The best\nprevious lower bound was Omega(sqrt n). Our result shows that the intersection\nof two halfspaces on {0,1}^n only admits a trivial 2^{Theta(n)}-time learning\nalgorithm based on sign-representation by polynomials, unlike the advances\nachieved in PAC learning DNF formulas and read-once Boolean formulas. The proof\nintroduces a new technique of independent interest, based on Fourier analysis\nand matrix theory.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2009 04:05:31 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2010 22:27:37 GMT"}], "update_date": "2010-02-25", "authors_parsed": [["Sherstov", "Alexander A.", ""]]}, {"id": "0910.4266", "submitter": "Hartmut Klauck", "authors": "Rahul Jain, Hartmut Klauck", "title": "The Partition Bound for Classical Communication Complexity and Query\n  Complexity", "comments": "28 pages, ver. 2, added content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe new lower bounds for randomized communication complexity and\nquery complexity which we call the partition bounds. They are expressed as the\noptimum value of linear programs. For communication complexity we show that the\npartition bound is stronger than both the rectangle/corruption bound and the\n\\gamma_2/generalized discrepancy bounds. In the model of query complexity we\nshow that the partition bound is stronger than the approximate polynomial\ndegree and classical adversary bounds. We also exhibit an example where the\npartition bound is quadratically larger than polynomial degree and classical\nadversary bounds.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2009 09:40:58 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2009 03:53:09 GMT"}], "update_date": "2009-11-19", "authors_parsed": [["Jain", "Rahul", ""], ["Klauck", "Hartmut", ""]]}, {"id": "0910.4353", "submitter": "Paul Vitanyi", "authors": "Sebastiaan A. Terwijn (University of Amsterdam), Leen Torenvliet\n  (University of Amsterdam), and Paul M.B. Vitanyi (CWI and University of\n  Amsterdam)", "title": "Nonapproximablity of the Normalized Information Distance", "comments": "LaTeX 8 pages, Submitted. 2nd version corrected some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalized information distance (NID) uses the theoretical notion of\nKolmogorov complexity, which for practical purposes is approximated by the\nlength of the compressed version of the file involved, using a real-world\ncompression program. This practical application is called `normalized\ncompression distance' and it is trivially computable. It is a parameter-free\nsimilarity measure based on compression, and is used in pattern recognition,\ndata mining, phylogeny, clustering, and classification. The complexity\nproperties of its theoretical precursor, the NID, have been open. We show that\nthe NID is neither upper semicomputable nor lower semicomputable up to any\nreasonable precision.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2009 16:06:34 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2009 16:26:40 GMT"}], "update_date": "2009-10-23", "authors_parsed": [["Terwijn", "Sebastiaan A.", "", "University of Amsterdam"], ["Torenvliet", "Leen", "", "University of Amsterdam"], ["Vitanyi", "Paul M. B.", "", "CWI and University of\n  Amsterdam"]]}, {"id": "0910.4518", "submitter": "Stefan Kratsch", "authors": "Stefan Kratsch and Magnus Wahlstrom", "title": "Preprocessing of Min Ones Problems: A Dichotomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parameterized problem consists of a classical problem and an additional\ncomponent, the so-called parameter. This point of view allows a formal\ndefinition of preprocessing: Given a parameterized instance (I,k), a polynomial\nkernelization computes an equivalent instance (I',k') of size and parameter\nbounded by a polynomial in k. We give a complete classification of Min Ones\nConstraint Satisfaction problems, i.e., Min Ones SAT(\\Gamma), with respect to\nadmitting or not admitting a polynomial kernelization (unless NP \\subseteq\ncoNP/poly). For this we introduce the notion of mergeability. If all relations\nof the constraint language \\Gamma are mergeable, then a new variant of\nsunflower kernelization applies, based on non-zero-closed cores. We obtain a\nkernel with O(k^{d+1}) variables and polynomial total size, where d is the\nmaximum arity of a constraint in \\Gamma, comparing nicely with the bound of\nO(k^{d-1}) vertices for the less general and arguably simpler d-Hitting Set\nproblem. Otherwise, any relation in \\Gamma that is not mergeable permits us to\nconstruct a log-cost selection formula, i.e., an n-ary selection formula with\nO(log n) true local variables. From this we can construct our lower bound using\nrecent results by Bodlaender et al. as well as Fortnow and Santhanam, proving\nthat there is no polynomial kernelization, unless NP \\subseteq coNP/poly and\nthe polynomial hierarchy collapses to the third level.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2009 14:14:37 GMT"}], "update_date": "2009-10-26", "authors_parsed": [["Kratsch", "Stefan", ""], ["Wahlstrom", "Magnus", ""]]}, {"id": "0910.4698", "submitter": "Scott Aaronson", "authors": "Scott Aaronson", "title": "BQP and the Polynomial Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationship between BQP and PH has been an open problem since the\nearliest days of quantum computing. We present evidence that quantum computers\ncan solve problems outside the entire polynomial hierarchy, by relating this\nquestion to topics in circuit complexity, pseudorandomness, and Fourier\nanalysis.\n  First, we show that there exists an oracle relation problem (i.e., a problem\nwith many valid outputs) that is solvable in BQP, but not in PH. This also\nyields a non-oracle relation problem that is solvable in quantum logarithmic\ntime, but not in AC0.\n  Second, we show that an oracle decision problem separating BQP from PH would\nfollow from the Generalized Linial-Nisan Conjecture, which we formulate here\nand which is likely of independent interest. The original Linial-Nisan\nConjecture (about pseudorandomness against constant-depth circuits) was\nrecently proved by Braverman, after being open for twenty years.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2009 17:23:15 GMT"}], "update_date": "2009-10-27", "authors_parsed": [["Aaronson", "Scott", ""]]}, {"id": "0910.5107", "submitter": "Arno Pauly", "authors": "Arno Pauly", "title": "The Complexity of Iterated Strategy Elimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the computational complexity of the question whether a certain\nstrategy can be removed from a game by means of iterated elimination of\ndominated strategies. In particular, we study the influence of different\ndefinitions of domination and of the number of different payoff values. In\naddition, the consequence of restriction to constant-sum games is shown.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2009 12:40:17 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2010 12:12:28 GMT"}], "update_date": "2010-01-20", "authors_parsed": [["Pauly", "Arno", ""]]}, {"id": "0910.5301", "submitter": "Abhinav Kumar", "authors": "Abhinav Kumar, Satyanarayana V. Lokam, Vijay M. Patankar, Jayalal\n  Sarma M. N", "title": "Using Elimination Theory to construct Rigid Matrices", "comments": "25 Pages, minor typos corrected", "journal-ref": "Computational Complexity 23 (2014), 531-563", "doi": "10.1007/s00037-013-0061-0", "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rigidity of a matrix A for target rank r is the minimum number of entries\nof A that must be changed to ensure that the rank of the altered matrix is at\nmost r. Since its introduction by Valiant (1977), rigidity and similar\nrank-robustness functions of matrices have found numerous applications in\ncircuit complexity, communication complexity, and learning complexity. Almost\nall nxn matrices over an infinite field have a rigidity of (n-r)^2. It is a\nlong-standing open question to construct infinite families of explicit matrices\neven with superlinear rigidity when r = Omega(n).\n  In this paper, we construct an infinite family of complex matrices with the\nlargest possible, i.e., (n-r)^2, rigidity. The entries of an n x n matrix in\nthis family are distinct primitive roots of unity of orders roughly exp(n^2 log\nn). To the best of our knowledge, this is the first family of concrete (but not\nentirely explicit) matrices having maximal rigidity and a succinct algebraic\ndescription.\n  Our construction is based on elimination theory of polynomial ideals. In\nparticular, we use results on the existence of polynomials in elimination\nideals with effective degree upper bounds (effective Nullstellensatz). Using\nelementary algebraic geometry, we prove that the dimension of the affine\nvariety of matrices of rigidity at most k is exactly n^2-(n-r)^2+k. Finally, we\nuse elimination theory to examine whether the rigidity function is\nsemi-continuous.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2009 07:56:23 GMT"}, {"version": "v2", "created": "Sun, 23 Sep 2012 18:03:25 GMT"}, {"version": "v3", "created": "Wed, 16 Apr 2014 04:17:57 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Kumar", "Abhinav", ""], ["Lokam", "Satyanarayana V.", ""], ["Patankar", "Vijay M.", ""], ["N", "Jayalal Sarma M.", ""]]}, {"id": "0910.5819", "submitter": "S{\\l}awomir Lasota", "authors": "Slawomir Lasota, Marcin Poturalski", "title": "Undecidability of performance equivalence of Petri nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate bisimulation equivalence on Petri nets under durational\nsemantics. Our motivation was to verify the conjecture that in durational\nsetting, the bisimulation equivalence checking problem becomes more tractable\nthan in ordinary setting (which is the case, e.g., over communication-free\nnets). We disprove this conjecture in three of four proposed variants of\ndurational semantics. The fourth variant remains an intriguing open problem.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2009 09:25:43 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2015 20:38:29 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Lasota", "Slawomir", ""], ["Poturalski", "Marcin", ""]]}]