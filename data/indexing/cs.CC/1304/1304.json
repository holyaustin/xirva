[{"id": "1304.0053", "submitter": "Niall Murphy", "authors": "Turlough Neary, Damien Woods, Niall Murphy, Rainer Glaschick", "title": "Wang's B machines are efficiently universal, as is Hasenjaeger's small\n  universal electromechanical toy", "comments": "18 pages, 1 figure, 1 table, Conference: Turing in context II -\n  History and Philosophy of Computing, 2012", "journal-ref": "Journal of Complexity, Volume 30, Issue 5, October 2014, pages\n  634-646", "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the 1960's Gisbert Hasenjaeger built Turing Machines from\nelectromechanical relays and uniselectors. Recently, Glaschick reverse\nengineered the program of one of these machines and found that it is a\nuniversal Turing machine. In fact, its program uses only four states and two\nsymbols, making it a very small universal Turing machine. (The machine has\nthree tapes and a number of other features that are important to keep in mind\nwhen comparing it to other small universal machines.) Hasenjaeger's machine\nsimulates Hao Wang's B machines, which were proved universal by Wang.\nUnfortunately, Wang's original simulation algorithm suffers from an exponential\nslowdown when simulating Turing machines. Hence, via this simulation,\nHasenjaeger's machine also has an exponential slowdown when simulating Turing\nmachines. In this work, we give a new efficient simulation algorithm for Wang's\nB machines by showing that they simulate Turing machines with only a polynomial\nslowdown. As a second result, we find that Hasenjaeger's machine also\nefficiently simulates Turing machines in polynomial time. Thus, Hasenjaeger's\nmachine is both small and fast. In another application of our result, we show\nthat Hooper's small universal Turing machine simulates Turing machines in\npolynomial time, an exponential improvement.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2013 00:34:31 GMT"}, {"version": "v2", "created": "Tue, 5 Aug 2014 18:34:14 GMT"}], "update_date": "2014-08-06", "authors_parsed": [["Neary", "Turlough", ""], ["Woods", "Damien", ""], ["Murphy", "Niall", ""], ["Glaschick", "Rainer", ""]]}, {"id": "1304.0188", "submitter": "Igor Shparlinski", "authors": "Igor Shparlinski", "title": "Evasive Properties of Sparse Graphs and Some Linear Equations in Primes", "comments": "This version corrects a mistake made in the previous version, which\n  was pointed out to the author by Laszlo Babai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an unconditional version of a conditional, on the Extended Riemann\nHypothesis, result of L. Babai, A. Banerjee, R. Kulkarni and V. Naik (2010) on\nthe evasiveness of sparse graphs.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2013 11:16:11 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2013 21:03:00 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2013 00:24:43 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Shparlinski", "Igor", ""]]}, {"id": "1304.0371", "submitter": "Ben lee Volk", "authors": "Amir Shpilka, Avishay Tal, Ben lee Volk", "title": "On the Structure of Boolean Functions with Small Spectral Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CA math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove results regarding Boolean functions with small\nspectral norm (the spectral norm of f is\n$\\|\\hat{f}\\|_1=\\sum_{\\alpha}|\\hat{f}(\\alpha)|$). Specifically, we prove the\nfollowing results for functions $f:\\{0,1\\}^n \\to \\{0,1\\}$ with\n$\\|\\hat{f}\\|_1=A$.\n  1. There is a subspace $V$ of co-dimension at most $A^2$ such that $f|_V$ is\nconstant.\n  2. f can be computed by a parity decision tree of size $2^{A^2}n^{2A}$. (a\nparity decision tree is a decision tree whose nodes are labeled with arbitrary\nlinear functions.)\n  3. If in addition f has at most s nonzero Fourier coefficients, then f can be\ncomputed by a parity decision tree of depth $A^2 \\log s$.\n  4. For every $0<\\epsilon$ there is a parity decision tree of depth $O(A^2 +\n\\log(1/\\epsilon))$ and size $2^{O(A^2)} \\cdot\n\\min\\{1/\\epsilon^2,O(\\log(1/\\epsilon))^{2A}\\}$ that \\epsilon-approximates f.\nFurthermore, this tree can be learned, with probability $1-\\delta$, using\n$\\poly(n,\\exp(A^2),1/\\epsilon,\\log(1/\\delta))$ membership queries.\n  All the results above also hold (with a slight change in parameters) to\nfunctions $f:Z_p^n\\to \\{0,1\\}$.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2013 15:01:17 GMT"}, {"version": "v2", "created": "Wed, 22 May 2013 11:15:55 GMT"}], "update_date": "2013-05-23", "authors_parsed": [["Shpilka", "Amir", ""], ["Tal", "Avishay", ""], ["Volk", "Ben lee", ""]]}, {"id": "1304.0513", "submitter": "Mika G\\\"o\\\"os", "authors": "Magnus Find, Mika G\\\"o\\\"os, Matti J\\\"arvisalo, Petteri Kaski, Mikko\n  Koivisto, Janne H. Korhonen", "title": "Separating OR, SUM, and XOR Circuits", "comments": "1 + 16 pages, 2 figures. In this version we have improved the\n  presentation following comments made by Stasys Jukna and Igor Sergeev", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a boolean n by n matrix A we consider arithmetic circuits for computing\nthe transformation x->Ax over different semirings. Namely, we study three\ncircuit models: monotone OR-circuits, monotone SUM-circuits (addition of\nnon-negative integers), and non-monotone XOR-circuits (addition modulo 2). Our\nfocus is on \\emph{separating} these models in terms of their circuit\ncomplexities. We give three results towards this goal:\n  (1) We prove a direct sum type theorem on the monotone complexity of tensor\nproduct matrices. As a corollary, we obtain matrices that admit OR-circuits of\nsize O(n), but require SUM-circuits of size \\Omega(n^{3/2}/\\log^2n).\n  (2) We construct so-called \\emph{k-uniform} matrices that admit XOR-circuits\nof size O(n), but require OR-circuits of size \\Omega(n^2/\\log^2n).\n  (3) We consider the task of \\emph{rewriting} a given OR-circuit as a\nXOR-circuit and prove that any subquadratic-time algorithm for this task\nviolates the strong exponential time hypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 01:25:48 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2013 02:03:17 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Find", "Magnus", ""], ["G\u00f6\u00f6s", "Mika", ""], ["J\u00e4rvisalo", "Matti", ""], ["Kaski", "Petteri", ""], ["Koivisto", "Mikko", ""], ["Korhonen", "Janne H.", ""]]}, {"id": "1304.0713", "submitter": "Yuan Li", "authors": "Chris Beck and Yuan Li", "title": "Represent MOD function by low degree polynomial with unbounded one-sided\n  error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove tight lower bounds on the smallest degree of a\nnonzero polynomial in the ideal generated by $MOD_q$ or $\\neg MOD_q$ in the\npolynomial ring $F_p[x_1, \\ldots, x_n]/(x_1^2 = x_1, \\ldots, x_n^2 = x_n)$,\n$p,q$ are coprime, which is called \\emph{immunity} over $F_p$. The immunity of\n$MOD_q$ is lower bounded by $\\lfloor (n+1)/2 \\rfloor$, which is achievable when\n$n$ is a multiple of $2q$; the immunity of $\\neg MOD_q$ is exactly $\\lfloor\n(n+q-1)/q \\rfloor$ for every $q$ and $n$. Our result improves the previous\nbound $\\lfloor \\frac{n}{2(q-1)} \\rfloor$ by Green.\n  We observe how immunity over $F_p$ is related to $\\acc$ circuit lower bound.\nFor example, if the immunity of $f$ over $F_p$ is lower bounded by $n/2 -\no(\\sqrt{n})$, and $|1_f| = \\Omega(2^n)$, then $f$ requires $\\acc$ circuit of\nexponential size to compute.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 17:50:54 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Beck", "Chris", ""], ["Li", "Yuan", ""]]}, {"id": "1304.0730", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Pravesh Kothari and Jan Vondrak", "title": "Representation, Approximation and Learning of Submodular Functions Using\n  Low-rank Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of approximate representation and learning of\nsubmodular functions over the uniform distribution on the Boolean hypercube\n$\\{0,1\\}^n$. Our main result is the following structural theorem: any\nsubmodular function is $\\epsilon$-close in $\\ell_2$ to a real-valued decision\ntree (DT) of depth $O(1/\\epsilon^2)$. This immediately implies that any\nsubmodular function is $\\epsilon$-close to a function of at most\n$2^{O(1/\\epsilon^2)}$ variables and has a spectral $\\ell_1$ norm of\n$2^{O(1/\\epsilon^2)}$. It also implies the closest previous result that states\nthat submodular functions can be approximated by polynomials of degree\n$O(1/\\epsilon^2)$ (Cheraghchi et al., 2012). Our result is proved by\nconstructing an approximation of a submodular function by a DT of rank\n$4/\\epsilon^2$ and a proof that any rank-$r$ DT can be $\\epsilon$-approximated\nby a DT of depth $\\frac{5}{2}(r+\\log(1/\\epsilon))$.\n  We show that these structural results can be exploited to give an\nattribute-efficient PAC learning algorithm for submodular functions running in\ntime $\\tilde{O}(n^2) \\cdot 2^{O(1/\\epsilon^{4})}$. The best previous algorithm\nfor the problem requires $n^{O(1/\\epsilon^{2})}$ time and examples (Cheraghchi\net al., 2012) but works also in the agnostic setting. In addition, we give\nimproved learning algorithms for a number of related settings.\n  We also prove that our PAC and agnostic learning algorithms are essentially\noptimal via two lower bounds: (1) an information-theoretic lower bound of\n$2^{\\Omega(1/\\epsilon^{2/3})}$ on the complexity of learning monotone\nsubmodular functions in any reasonable model; (2) computational lower bound of\n$n^{\\Omega(1/\\epsilon^{2/3})}$ based on a reduction to learning of sparse\nparities with noise, widely-believed to be intractable. These are the first\nlower bounds for learning of submodular functions over the uniform\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2013 18:37:35 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Feldman", "Vitaly", ""], ["Kothari", "Pravesh", ""], ["Vondrak", "Jan", ""]]}, {"id": "1304.0828", "submitter": "Philippe Rigollet", "authors": "Quentin Berthet and Philippe Rigollet", "title": "Computational Lower Bounds for Sparse PCA", "comments": "Alternate title: \"Complexity Theoretic Lower Bounds for Sparse\n  Principal Component Detection\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of sparse principal component detection, we bring evidence\ntowards the existence of a statistical price to pay for computational\nefficiency. We measure the performance of a test by the smallest signal\nstrength that it can detect and we propose a computationally efficient method\nbased on semidefinite programming. We also prove that the statistical\nperformance of this test cannot be strictly improved by any computationally\nefficient method. Our results can be viewed as complexity theoretic lower\nbounds conditionally on the assumptions that some instances of the planted\nclique problem cannot be solved in randomized polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 03:11:07 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2013 16:00:10 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Berthet", "Quentin", ""], ["Rigollet", "Philippe", ""]]}, {"id": "1304.0829", "submitter": "Tony Tan", "authors": "Eryk Kopczynski and Tony Tan", "title": "Regular graphs and the spectra of two-variable logic with counting", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The {\\em spectrum} of a first-order logic sentence is the set of natural\nnumbers that are cardinalities of its finite models. In this paper we show that\nwhen restricted to using only two variables, but allowing counting quantifiers,\nthe spectra of first-order logic sentences are semilinear and hence, closed\nunder complement. At the heart of our proof are semilinear characterisations\nfor the existence of regular and biregular graphs, the class of graphs in which\nthere are a priori bounds on the degrees of the vertices.\n  Our proof also provides a simple characterisation of models of two-variable\nlogic with counting -- that is, up to renaming and extending the relation\nnames, they are simply a collection of regular and biregular graphs.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 03:15:45 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2013 19:06:16 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2013 23:04:12 GMT"}, {"version": "v4", "created": "Wed, 11 Jun 2014 16:18:28 GMT"}], "update_date": "2014-06-12", "authors_parsed": [["Kopczynski", "Eryk", ""], ["Tan", "Tony", ""]]}, {"id": "1304.0845", "submitter": "Robert Spalek", "authors": "Robert Spalek (Google)", "title": "Adversary Lower Bound for the Orthogonal Array Problem", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a quantum query lower bound \\Omega(n^{(d+1)/(d+2)}) for the problem\nof deciding whether an input string of size n contains a k-tuple which belongs\nto a fixed orthogonal array on k factors of strength d<=k-1 and index 1,\nprovided that the alphabet size is sufficiently large. Our lower bound is tight\nwhen d=k-1.\n  The orthogonal array problem includes the following problems as special\ncases: k-sum problem with d=k-1, k-distinctness problem with d=1, k-pattern\nproblem with d=0, (d-1)-degree problem with 1<=d<=k-1, unordered search with\nd=0 and k=1, and graph collision with d=0 and k=2.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 05:36:55 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Spalek", "Robert", "", "Google"]]}, {"id": "1304.0872", "submitter": "David Doty", "authors": "David Doty", "title": "Timing in chemical reaction networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC cs.DS q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical reaction networks (CRNs) formally model chemistry in a well-mixed\nsolution. CRNs are widely used to describe information processing occurring in\nnatural cellular regulatory networks, and with upcoming advances in synthetic\nbiology, CRNs are a promising programming language for the design of artificial\nmolecular control circuitry. Due to a formal equivalence between CRNs and a\nmodel of distributed computing known as population protocols, results transfer\nreadily between the two models.\n  We show that if a CRN respects finite density (at most O(n) additional\nmolecules can be produced from n initial molecules), then starting from any\ndense initial configuration (all molecular species initially present have\ninitial count Omega(n), where n is the initial molecular count and volume),\nthen every producible species is produced in constant time with high\nprobability.\n  This implies that no CRN obeying the stated constraints can function as a\ntimer, able to produce a molecule, but doing so only after a time that is an\nunbounded function of the input size. This has consequences regarding an open\nquestion of Angluin, Aspnes, and Eisenstat concerning the ability of population\nprotocols to perform fast, reliable leader election and to simulate arbitrary\nalgorithms from a uniform initial state.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 08:50:30 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Doty", "David", ""]]}, {"id": "1304.1005", "submitter": "Marius Zimand", "authors": "N.V. Vinodchandran and Marius Zimand", "title": "On optimal language compression for sets in PSPACE/poly", "comments": "submitted to Theory of Computing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if DTIME[2^O(n)] is not included in DSPACE[2^o(n)], then, for\nevery set B in PSPACE/poly, all strings x in B of length n can be represented\nby a string compressed(x) of length at most log(|B^{=n}|)+O(log n), such that a\npolynomial-time algorithm, given compressed(x), can distinguish x from all the\nother strings in B^{=n}. Modulo the O(log n) additive term, this achieves the\ninformation-theoretic optimum for string compression. We also observe that\noptimal compression is not possible for sets more complex than PSPACE/poly\nbecause for any time-constructible superpolynomial function t, there is a set A\ncomputable in space t(n) such that at least one string x of length n requires\ncompressed(x) to be of length 2 log(|A^=n|).\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 16:37:02 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Vinodchandran", "N. V.", ""], ["Zimand", "Marius", ""]]}, {"id": "1304.1007", "submitter": "Jukka Suomela", "authors": "Mika G\\\"o\\\"os, Juho Hirvonen, Jukka Suomela", "title": "Linear-in-$\\Delta$ Lower Bounds in the LOCAL Model", "comments": "1 + 21 pages, 10 figures", "journal-ref": null, "doi": "10.1007/s00446-015-0245-8", "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By prior work, there is a distributed algorithm that finds a maximal\nfractional matching (maximal edge packing) in $O(\\Delta)$ rounds, where\n$\\Delta$ is the maximum degree of the graph. We show that this is optimal:\nthere is no distributed algorithm that finds a maximal fractional matching in\n$o(\\Delta)$ rounds.\n  Our work gives the first linear-in-$\\Delta$ lower bound for a natural graph\nproblem in the standard model of distributed computing---prior lower bounds for\na wide range of graph problems have been at best logarithmic in $\\Delta$.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 16:46:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["G\u00f6\u00f6s", "Mika", ""], ["Hirvonen", "Juho", ""], ["Suomela", "Jukka", ""]]}, {"id": "1304.1206", "submitter": "Anand Kumar Narayanan", "authors": "Ming-Deh Huang and Anand Kumar Narayanan", "title": "Finding Primitive Elements in Finite Fields of Small Characteristic", "comments": "Modifications made to the polynomial selection and testing phases", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a deterministic algorithm for finding a generating element of the\nmultiplicative group of the finite field $\\mathbb{F}_{p^n}$ where $p$ is a\nprime. In time polynomial in $p$ and $n$, the algorithm either outputs an\nelement that is provably a generator or declares that it has failed in finding\none. The algorithm relies on a relation generation technique in Joux's\nheuristically $L(1/4)$-method for discrete logarithm computation. Based on a\nheuristic assumption, the algorithm does succeed in finding a generator. For\nthe special case when the order of $p$ in $(\\mathbb{Z}/n\\mathbb{Z})^\\times$ is\nsmall (that is $(\\log_p(n))^{\\mathcal{O}(1)}$), we present a modification with\ngreater guarantee of success while making weaker heuristic assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 23:08:51 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2013 01:09:58 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2013 07:30:43 GMT"}, {"version": "v4", "created": "Mon, 4 Nov 2013 01:41:10 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Huang", "Ming-Deh", ""], ["Narayanan", "Anand Kumar", ""]]}, {"id": "1304.1217", "submitter": "Mert Sa\\u{g}lam", "authors": "Mert Saglam and Gabor Tardos", "title": "On the communication complexity of sparse set disjointness and\n  exists-equal problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the two player randomized communication complexity of\nthe sparse set disjointness and the exists-equal problems and give matching\nlower and upper bounds (up to constant factors) for any number of rounds for\nboth of these problems. In the sparse set disjointness problem, each player\nreceives a k-subset of [m] and the goal is to determine whether the sets\nintersect. For this problem, we give a protocol that communicates a total of\nO(k\\log^{(r)}k) bits over r rounds and errs with very small probability. Here\nwe can take r=\\log^{*}k to obtain a O(k) total communication \\log^{*}k-round\nprotocol with exponentially small error probability, improving on the O(k)-bits\nO(\\log k)-round constant error probability protocol of Hastad and Wigderson\nfrom 1997.\n  In the exist-equal problem, the players receive vectors x,y\\in [t]^n and the\ngoal is to determine whether there exists a coordinate i such that x_i=y_i.\nNamely, the exists-equal problem is the OR of n equality problems. Observe that\nexists-equal is an instance of sparse set disjointness with k=n, hence the\nprotocol above applies here as well, giving an O(n\\log^{(r)}n) upper bound. Our\nmain technical contribution in this paper is a matching lower bound: we show\nthat when t=\\Omega(n), any r-round randomized protocol for the exists-equal\nproblem with error probability at most 1/3 should have a message of size\n\\Omega(n\\log^{(r)}n). Our lower bound holds even for super-constant r <=\n\\log^*n, showing that any O(n) bits exists-equal protocol should have \\log^*n -\nO(1) rounds.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 00:20:31 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Saglam", "Mert", ""], ["Tardos", "Gabor", ""]]}, {"id": "1304.1245", "submitter": "Shengyu Zhang", "authors": "Hing Yin Tsang, Chung Hoi Wong, Ning Xie, Shengyu Zhang", "title": "Fourier sparsity, spectral norm, and the Log-rank conjecture", "comments": "v2: Corollary 31 of v1 removed because of a bug in the proof. (Other\n  results not affected.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Boolean functions with sparse Fourier coefficients or small spectral\nnorm, and show their applications to the Log-rank Conjecture for XOR functions\nf(x\\oplus y) --- a fairly large class of functions including well studied ones\nsuch as Equality and Hamming Distance. The rank of the communication matrix M_f\nfor such functions is exactly the Fourier sparsity of f. Let d be the F2-degree\nof f and D^CC(f) stand for the deterministic communication complexity for\nf(x\\oplus y). We show that 1. D^CC(f) = O(2^{d^2/2} log^{d-2} ||\\hat f||_1). In\nparticular, the Log-rank conjecture holds for XOR functions with constant\nF2-degree. 2. D^CC(f) = O(d ||\\hat f||_1) = O(\\sqrt{rank(M_f)}\\logrank(M_f)).\nWe obtain our results through a degree-reduction protocol based on a variant of\npolynomial rank, and actually conjecture that its communication cost is already\n\\log^{O(1)}rank(M_f). The above bounds also hold for the parity decision tree\ncomplexity of f, a measure that is no less than the communication complexity\n(up to a factor of 2).\n  Along the way we also show several structural results about Boolean functions\nwith small F2-degree or small spectral norm, which could be of independent\ninterest. For functions f with constant F2-degree: 1) f can be written as the\nsummation of quasi-polynomially many indicator functions of subspaces with\n\\pm-signs, improving the previous doubly exponential upper bound by Green and\nSanders; 2) being sparse in Fourier domain is polynomially equivalent to having\na small parity decision tree complexity; 3) f depends only on polylog||\\hat\nf||_1 linear functions of input variables. For functions f with small spectral\nnorm: 1) there is an affine subspace with co-dimension O(||\\hat f||_1) on which\nf is a constant; 2) there is a parity decision tree with depth O(||\\hat f||_1\nlog ||\\hat f||_0).\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 04:59:41 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2013 00:50:42 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Tsang", "Hing Yin", ""], ["Wong", "Chung Hoi", ""], ["Xie", "Ning", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1304.1307", "submitter": "Anatoly Plotnikov D.", "authors": "Anatoly D. Plotnikov", "title": "On the structure of the class NP", "comments": "7 pages, 7 references", "journal-ref": "On the structure of the class NP. Computer Communication &\n  Collaboration (2013) 1: 19-23", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class UF of problems is introduced, strictly included in the class NP,\nwhich arises in the analysis of the time verifying the intermediate results of\ncomputations. The implications of the introduction of this class are\nconsidered. First of all, we prove that $P\\not= NP$ and establish that it needs\nto consider the problem \"P vs UF\" instead the problem \"P vs NP\". Also, we\ndetermine the set-theoretical of properties of a one-way functions that used in\ncryptology.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 10:26:49 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Plotnikov", "Anatoly D.", ""]]}, {"id": "1304.1347", "submitter": "Li-Yang Tan", "authors": "Ryan O'Donnell, Li-Yang Tan", "title": "A composition theorem for the Fourier Entropy-Influence conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fourier Entropy-Influence (FEI) conjecture of Friedgut and Kalai [FK96]\nseeks to relate two fundamental measures of Boolean function complexity: it\nstates that $H[f] \\leq C Inf[f]$ holds for every Boolean function $f$, where\n$H[f]$ denotes the spectral entropy of $f$, $Inf[f]$ is its total influence,\nand $C > 0$ is a universal constant. Despite significant interest in the\nconjecture it has only been shown to hold for a few classes of Boolean\nfunctions.\n  Our main result is a composition theorem for the FEI conjecture. We show that\nif $g_1,...,g_k$ are functions over disjoint sets of variables satisfying the\nconjecture, and if the Fourier transform of $F$ taken with respect to the\nproduct distribution with biases $E[g_1],...,E[g_k]$ satisfies the conjecture,\nthen their composition $F(g_1(x^1),...,g_k(x^k))$ satisfies the conjecture. As\nan application we show that the FEI conjecture holds for read-once formulas\nover arbitrary gates of bounded arity, extending a recent result [OWZ11] which\nproved it for read-once decision trees. Our techniques also yield an explicit\nfunction with the largest known ratio of $C \\geq 6.278$ between $H[f]$ and\n$Inf[f]$, improving on the previous lower bound of 4.615.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 12:28:49 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["O'Donnell", "Ryan", ""], ["Tan", "Li-Yang", ""]]}, {"id": "1304.1679", "submitter": "Damien Woods", "authors": "Pierre-\\'Etienne Meunier, Matthew J. Patitz, Scott M. Summers,\n  Guillaume Theyssier, Andrew Winslow, Damien Woods", "title": "Intrinsic universality in tile self-assembly requires cooperation", "comments": "Added references. Improved presentation of definitions and proofs.\n  This article uses definitions from arXiv:1212.4756. arXiv admin note: text\n  overlap with arXiv:1006.2897 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a negative result on the power of a model of algorithmic\nself-assembly for which it has been notoriously difficult to find general\ntechniques and results. Specifically, we prove that Winfree's abstract Tile\nAssembly Model, when restricted to use noncooperative tile binding, is not\nintrinsically universal. This stands in stark contrast to the recent result\nthat, via cooperative binding, the abstract Tile Assembly Model is indeed\nintrinsically universal. Noncooperative self-assembly, also known as\n\"temperature 1\", is where tiles bind to each other if they match on one or more\nsides, whereas cooperative binding requires binding on multiple sides. Our\nresult shows that the change from single- to multi-sided binding qualitatively\nimproves the kinds of dynamics and behavior that these models of nanoscale\nself-assembly are capable of. Our lower bound on simulation power holds in both\ntwo and three dimensions; the latter being quite surprising given that\nthree-dimensional noncooperative tile assembly systems simulate Turing\nmachines. On the positive side, we exhibit a three-dimensional noncooperative\nself-assembly tile set capable of simulating any two-dimensional noncooperative\nself-assembly system.\n  Our negative result can be interpreted to mean that Turing universal\nalgorithmic behavior in self-assembly does not imply the ability to simulate\narbitrary algorithmic self-assembly processes.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 11:11:26 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2013 19:26:46 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Meunier", "Pierre-\u00c9tienne", ""], ["Patitz", "Matthew J.", ""], ["Summers", "Scott M.", ""], ["Theyssier", "Guillaume", ""], ["Winslow", "Andrew", ""], ["Woods", "Damien", ""]]}, {"id": "1304.1796", "submitter": "David Woodruff", "authors": "David P. Woodruff and Grigory Yaroslavtsev", "title": "The Round Complexity of Small Set Intersection", "comments": "There is an error in the statement and proof of Lemma A.1, so we have\n  decided to withdraw the current manuscript. For the round / communication\n  tradeoff for small set disjointness, we refer the reader to the independent\n  work: http://arxiv.org/pdf/1304.1217.pdf The other results concerning\n  OR-Index and Augmented-OR-Index are not affected and will appear in a later\n  manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The set disjointness problem is one of the most fundamental and well-studied\nproblems in communication complexity. In this problem Alice and Bob hold sets\n$S, T \\subseteq [n]$, respectively, and the goal is to decide if $S \\cap T =\n\\emptyset$. Reductions from set disjointness are a canonical way of proving\nlower bounds in data stream algorithms, data structures, and distributed\ncomputation. In these applications, often the set sizes $|S|$ and $|T|$ are\nbounded by a value $k$ which is much smaller than $n$. This is referred to as\nsmall set disjointness. A major restriction in the above applications is the\nnumber of rounds that the protocol can make, which, e.g., translates to the\nnumber of passes in streaming applications. A fundamental question is thus in\nunderstanding the round complexity of the small set disjointness problem. For\nan essentially equivalent problem, called OR-Equality, Brody et. al showed that\nwith $r$ rounds of communication, the randomized communication complexity is\n$\\Omega(k \\ilog^r k)$, where$\\ilog^r k$ denotes the $r$-th iterated logarithm\nfunction. Unfortunately their result requires the error probability of the\nprotocol to be $1/k^{\\Theta(1)}$. Since na\\\"ive amplification of the success\nprobability of a protocol from constant to $1-1/k^{\\Theta(1)}$ blows up the\ncommunication by a $\\Theta(\\log k)$ factor, this destroys their improvements\nover the well-known lower bound of $\\Omega(k)$ which holds for any number of\nrounds. They pose it as an open question to achieve the same $\\Omega(k \\ilog^r\nk)$ lower bound for protocols with constant error probability. We answer this\nopen question by showing that the $r$-round randomized communication complexity\nof ${\\sf OREQ}_{n,k}$, and thus also of small set disjointness, with {\\it\nconstant error probability} is $\\Omega(k \\ilog^r k)$, asymptotically matching\nknown upper bounds for ${\\sf OREQ}_{n,k}$ and small set disjointness.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 19:53:52 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2013 19:59:27 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Woodruff", "David P.", ""], ["Yaroslavtsev", "Grigory", ""]]}, {"id": "1304.1831", "submitter": "David Gamarnik", "authors": "David Gamarnik and Madhu Sudan", "title": "Limits of local algorithms over sparse random graphs", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local algorithms on graphs are algorithms that run in parallel on the nodes\nof a graph to compute some global structural feature of the graph. Such\nalgorithms use only local information available at nodes to determine local\naspects of the global structure, while also potentially using some randomness.\nRecent research has shown that such algorithms show significant promise in\ncomputing structures like large independent sets in graphs locally. Indeed the\npromise led to a conjecture by Hatami, \\Lovasz and Szegedy\n\\cite{HatamiLovaszSzegedy} that local algorithms may be able to compute maximum\nindependent sets in (sparse) random $d$-regular graphs. In this paper we refute\nthis conjecture and show that every independent set produced by local\nalgorithms is multiplicative factor $1/2+1/(2\\sqrt{2})$ smaller than the\nlargest, asymptotically as $d\\rightarrow\\infty$.\n  Our result is based on an important clustering phenomena predicted first in\nthe literature on spin glasses, and recently proved rigorously for a variety of\nconstraint satisfaction problems on random graphs. Such properties suggest that\nthe geometry of the solution space can be quite intricate. The specific\nclustering property, that we prove and apply in this paper shows that typically\nevery two large independent sets in a random graph either have a significant\nintersection, or have a nearly empty intersection. As a result, large\nindependent sets are clustered according to the proximity to each other. While\nthe clustering property was postulated earlier as an obstruction for the\nsuccess of local algorithms, such as for example, the Belief Propagation\nalgorithm, our result is the first one where the clustering property is used to\nformally prove limits on local algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 22:36:46 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Gamarnik", "David", ""], ["Sudan", "Madhu", ""]]}, {"id": "1304.1996", "submitter": "Iyad Kanj", "authors": "Iyad Kanj and Stefan Szeider", "title": "On the Subexponential Time Complexity of CSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A CSP with n variables ranging over a domain of d values can be solved by\nbrute-force in d^n steps (omitting a polynomial factor). With a more careful\napproach, this trivial upper bound can be improved for certain natural\nrestrictions of the CSP. In this paper we establish theoretical limits to such\nimprovements, and draw a detailed landscape of the subexponential-time\ncomplexity of CSP.\n  We first establish relations between the subexponential-time complexity of\nCSP and that of other problems, including CNF-Sat. We exploit this connection\nto provide tight characterizations of the subexponential-time complexity of CSP\nunder common assumptions in complexity theory. For several natural CSP\nparameters, we obtain threshold functions that precisely dictate the\nsubexponential-time complexity of CSP with respect to the parameters under\nconsideration.\n  Our analysis provides fundamental results indicating whether and when one can\nsignificantly improve on the brute-force search approach for solving CSP.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2013 13:19:18 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Kanj", "Iyad", ""], ["Szeider", "Stefan", ""]]}, {"id": "1304.2026", "submitter": "Koji Kobayashi", "authors": "Koji Kobayashi", "title": "Resolution structure in HornSAT and CNFSAT", "comments": "6 pages, English and Japanese (see Other formats - Source)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes about the difference of resolution structure and size\nbetween HornSAT and CNFSAT. We can compute HornSAT by using clauses causality.\nTherefore we can compute proof diagram by using Log space reduction. But we\nmust compute CNFSAT by using clauses correlation. Therefore we cannot compute\nproof diagram by using Log space reduction, and reduction of CNFSAT is not\nP-Complete.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2013 17:06:29 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Kobayashi", "Koji", ""]]}, {"id": "1304.2079", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Pravesh Kothari", "title": "Learning Coverage Functions and Private Release of Marginals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximating and learning coverage functions. A\nfunction $c: 2^{[n]} \\rightarrow \\mathbf{R}^{+}$ is a coverage function, if\nthere exists a universe $U$ with non-negative weights $w(u)$ for each $u \\in U$\nand subsets $A_1, A_2, \\ldots, A_n$ of $U$ such that $c(S) = \\sum_{u \\in\n\\cup_{i \\in S} A_i} w(u)$. Alternatively, coverage functions can be described\nas non-negative linear combinations of monotone disjunctions. They are a\nnatural subclass of submodular functions and arise in a number of applications.\n  We give an algorithm that for any $\\gamma,\\delta>0$, given random and uniform\nexamples of an unknown coverage function $c$, finds a function $h$ that\napproximates $c$ within factor $1+\\gamma$ on all but $\\delta$-fraction of the\npoints in time $poly(n,1/\\gamma,1/\\delta)$. This is the first fully-polynomial\nalgorithm for learning an interesting class of functions in the demanding PMAC\nmodel of Balcan and Harvey (2011). Our algorithms are based on several new\nstructural properties of coverage functions. Using the results in (Feldman and\nKothari, 2014), we also show that coverage functions are learnable agnostically\nwith excess $\\ell_1$-error $\\epsilon$ over all product and symmetric\ndistributions in time $n^{\\log(1/\\epsilon)}$. In contrast, we show that,\nwithout assumptions on the distribution, learning coverage functions is at\nleast as hard as learning polynomial-size disjoint DNF formulas, a class of\nfunctions for which the best known algorithm runs in time\n$2^{\\tilde{O}(n^{1/3})}$ (Klivans and Servedio, 2004).\n  As an application of our learning results, we give simple\ndifferentially-private algorithms for releasing monotone conjunction counting\nqueries with low average error. In particular, for any $k \\leq n$, we obtain\nprivate release of $k$-way marginals with average error $\\bar{\\alpha}$ in time\n$n^{O(\\log(1/\\bar{\\alpha}))}$.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2013 00:06:26 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2013 23:42:11 GMT"}, {"version": "v3", "created": "Wed, 28 May 2014 00:38:46 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Feldman", "Vitaly", ""], ["Kothari", "Pravesh", ""]]}, {"id": "1304.2557", "submitter": "Krzysztof R. Apt", "authors": "Bart de Keijzer and Krzysztof R. Apt", "title": "The H-index can be easily manipulated", "comments": "7 pages", "journal-ref": "Bulletin of EATCS No 110, pp. 79-85, 2013", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove two complexity results about the H-index concerned with the Google\nscholar merge operation on one's scientific articles. The results show that,\nalthough it is hard to merge one's articles in an optimal way, it is easy to\nmerge them in such a way that one's H-index increases. This suggests the need\nfor an alternative scientific performance measure that is resistant to this\ntype of manipulation.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2013 12:39:20 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2013 14:08:54 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2013 12:52:08 GMT"}], "update_date": "2013-09-13", "authors_parsed": [["de Keijzer", "Bart", ""], ["Apt", "Krzysztof R.", ""]]}, {"id": "1304.2816", "submitter": "Hector Zenil", "authors": "Hector Zenil", "title": "Asymptotic Behaviour and Ratios of Complexity in Cellular Automata", "comments": "22 pages, 13 figures. As appeared in the International Journal of\n  Bifurcation and Chaos with corrections to the definition of Wolfram class", "journal-ref": "International Journal of Bifurcation and Chaos, vol. 13, no. 9,\n  2013", "doi": "10.1142/S0218127413501599", "report-no": null, "categories": "nlin.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic behaviour of symbolic computing systems, notably\none-dimensional cellular automata (CA), in order to ascertain whether and at\nwhat rate the number of complex versus simple rules dominate the rule space for\nincreasing neighbourhood range and number of symbols (or colours), and how\ndifferent behaviour is distributed in the spaces of different cellular automata\nformalisms. Using two different measures, Shannon's block entropy and\nKolmogorov complexity, the latter approximated by two different methods\n(lossless compressibility and block decomposition), we arrive at the same trend\nof larger complex behavioural fractions. We also advance a notion of asymptotic\nand limit behaviour for individual rules, both over initial conditions and\nruntimes, and we provide a formalisation of Wolfram's classification as a limit\nfunction in terms of Kolmogorov complexity.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2013 00:19:49 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 11:47:38 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2015 00:01:35 GMT"}, {"version": "v4", "created": "Thu, 5 Apr 2018 15:19:58 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Zenil", "Hector", ""]]}, {"id": "1304.3139", "submitter": "Anand Louis", "authors": "Anand Louis, Prasad Raghavendra, Santosh Vempala", "title": "The Complexity of Approximating Vertex Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We study the complexity of approximating the vertex expansion of graphs $G =\n(V,E)$, defined as \\[ \\Phi^V := \\min_{S \\subset V} n \\cdot \\frac{|N(S)|}{|S| |V\n\\backslash S|}. \\]\n  We give a simple polynomial-time algorithm for finding a subset with vertex\nexpansion $O(\\sqrt{OPT \\log d})$ where $d$ is the maximum degree of the graph.\nOur main result is an asymptotically matching lower bound: under the Small Set\nExpansion (SSE) hypothesis, it is hard to find a subset with expansion less\nthan $C\\sqrt{OPT \\log d}$ for an absolute constant $C$. In particular, this\nimplies for all constant $\\epsilon > 0$, it is SSE-hard to distinguish whether\nthe vertex expansion $< \\epsilon$ or at least an absolute constant. The\nanalogous threshold for edge expansion is $\\sqrt{OPT}$ with no dependence on\nthe degree; thus our results suggest that vertex expansion is harder to\napproximate than edge expansion. In particular, while Cheeger's algorithm can\ncertify constant edge expansion, it is SSE-hard to certify constant vertex\nexpansion in graphs.\n  Our proof is via a reduction from the {\\it Unique Games} instance obtained\nfrom the \\SSE hypothesis to the vertex expansion problem. It involves the\ndefinition of a smoother intermediate problem we call {\\sf Analytic Vertex\nExpansion} which is representative of both the vertex expansion and the\nconductance of the graph. Both reductions (from the UGC instance to this\nproblem and from this problem to vertex expansion) use novel proof ideas.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2013 20:31:28 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2013 20:29:57 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2013 19:56:28 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Louis", "Anand", ""], ["Raghavendra", "Prasad", ""], ["Vempala", "Santosh", ""]]}, {"id": "1304.3169", "submitter": "Markus Brill", "authors": "Haris Aziz and Felix Brandt and Markus Brill", "title": "The Computational Complexity of Random Serial Dictatorship", "comments": "11 pages", "journal-ref": "Economics Letters 121(3), 2013", "doi": "10.1016/j.econlet.2013.09.006", "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In social choice settings with linear preferences, random dictatorship is\nknown to be the only social decision scheme satisfying strategyproofness and ex\npost efficiency. When also allowing indifferences, random serial dictatorship\n(RSD) is a well-known generalization of random dictatorship that retains both\nproperties. RSD has been particularly successful in the special domain of\nrandom assignment where indifferences are unavoidable. While executing RSD is\nobviously feasible, we show that computing the resulting probabilities is\n#P-complete and thus intractable, both in the context of voting and assignment.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2013 00:17:22 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2013 13:34:38 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Aziz", "Haris", ""], ["Brandt", "Felix", ""], ["Brill", "Markus", ""]]}, {"id": "1304.3249", "submitter": "Paolo Parisen Toldin", "authors": "Jean-Yves Moyen, Paolo Parisen Toldin", "title": "A polytime complexity analyser for Probabilistic Polynomial Time over\n  imperative stack programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present iSAPP (Imperative Static Analyser for Probabilistic Polynomial\nTime), a complexity verifier tool that is sound and extensionally complete for\nthe Probabilistic Polynomial Time (PP) complexity class. iSAPP works on an\nimperative programming language for stack machines. The certificate of\npolynomiality can be built in polytime, with respect to the number of stacks\nused.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2013 10:20:24 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Moyen", "Jean-Yves", ""], ["Toldin", "Paolo Parisen", ""]]}, {"id": "1304.3365", "submitter": "Ali Sinop", "authors": "Sanjeev Arora and Rong Ge and Ali Kemal Sinop", "title": "Towards a better approximation for sparsest cut?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new $(1+\\epsilon)$-approximation for sparsest cut problem on graphs\nwhere small sets expand significantly more than the sparsest cut (sets of size\n$n/r$ expand by a factor $\\sqrt{\\log n\\log r}$ bigger, for some small $r$; this\ncondition holds for many natural graph families). We give two different\nalgorithms. One involves Guruswami-Sinop rounding on the level-$r$ Lasserre\nrelaxation. The other is combinatorial and involves a new notion called {\\em\nSmall Set Expander Flows} (inspired by the {\\em expander flows} of ARV) which\nwe show exists in the input graph. Both algorithms run in time $2^{O(r)}\n\\mathrm{poly}(n)$. We also show similar approximation algorithms in graphs with\ngenus $g$ with an analogous local expansion condition. This is the first\nalgorithm we know of that achieves $(1+\\epsilon)$-approximation on such general\nfamily of graphs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2013 16:51:07 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Sinop", "Ali Kemal", ""]]}, {"id": "1304.3541", "submitter": "Ramin Maazallahi", "authors": "Ramin Maazallahi and Aliakbar Niknafs", "title": "A modified dna computing approach to tackle the exponential solution\n  space of the graph coloring problem", "comments": "7 pages, 3 figures, 1 table, International Journal in Foundations of\n  Computer Science & Technology (IJFCST), Vol. 3, No.2, March 2013", "journal-ref": "International Journal in Foundations of Computer Science &\n  Technology (IJFCST), Vol. 3, No.2, March 2013", "doi": "10.5121/ijfcst.2013.3201", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although it has been evidenced that DNA computing is able to solve the graph\ncoloring problem in a polynomial time complexity, but the exponential solution\nspace is still a restrictive factor in applying this technique for solving\nreally large problems. In this paper a modified DNA computing approach based on\nAdleman-Lipton model is proposed which tackles the mentioned restriction by\ncoloring the vertices one by one. In each step, it expands the DNA strands\nencoding promising solutions and discards those which encode infeasible ones. A\nsample graph is colored by simulating the proposed approach and shows a notable\nreduction in the number of DNA strands used.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2013 05:34:44 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Maazallahi", "Ramin", ""], ["Niknafs", "Aliakbar", ""]]}, {"id": "1304.3812", "submitter": "Justin Thaler", "authors": "Justin Thaler", "title": "Time-Optimal Interactive Proofs for Circuit Evaluation", "comments": "This version corrects a confusing typographical error in Section 7.\n  We are grateful to Michael Walfish for identifying the error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers have been working toward the development of practical\ngeneral-purpose protocols for verifiable computation. These protocols enable a\ncomputationally weak verifier to offload computations to a powerful but\nuntrusted prover, while providing the verifier with a guarantee that the prover\nperformed the computations correctly. Despite substantial progress, existing\nimplementations are not yet practical. The main bottleneck is typically the\nextra effort required by the prover to return an answer with a guarantee of\ncorrectness, compared to returning an answer with no guarantee.\n  We describe a refinement of a powerful interactive proof protocol originally\ndue to Goldwasser, Kalai, and Rothblum. Cormode, Mitzenmacher, and Thaler show\nhow to implement the prover in this protocol in time O(S log S), where S is the\nsize of an arithmetic circuit computing the function of interest. Our\nrefinements apply to circuits whose wiring pattern is sufficiently \"regular\";\nfor these circuits, we bring the runtime of the prover down to O(S). That is,\nour prover can evaluate the circuit with a guarantee of correctness, with only\na constant-factor blowup in work compared to evaluating the circuit with no\nguarantee.\n  We argue that our refinements capture a large class of circuits, and prove\nsome theorems formalizing this. Experimentally, our refinements yield a 200x\nspeedup for the prover over the implementation of Cormode et al., and our\nprover is less than 10x slower than a C++ program that simply evaluates the\ncircuit. Along the way, we describe a special-purpose protocol for matrix\nmultiplication that is of interest in its own right.\n  Our final contribution is a protocol targeted at general data parallel\ncomputation. Compared to prior work, this protocol can more efficiently verify\ncomplicated computations as long as that computation is applied independently\nto many pieces of data.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 14:47:09 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2013 20:30:31 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2013 18:23:12 GMT"}, {"version": "v4", "created": "Wed, 8 Feb 2017 18:57:37 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Thaler", "Justin", ""]]}, {"id": "1304.3816", "submitter": "Justin Thaler", "authors": "Amit Chakrabarti and Graham Cormode and Navin Goyal and Justin Thaler", "title": "Annotations for Sparse Data Streams", "comments": "29 pages, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by cloud computing, a number of recent works have studied annotated\ndata streams and variants thereof. In this setting, a computationally weak\nverifier (cloud user), lacking the resources to store and manipulate his\nmassive input locally, accesses a powerful but untrusted prover (cloud\nservice). The verifier must work within the restrictive data streaming\nparadigm. The prover, who can annotate the data stream as it is read, must not\njust supply the answer but also convince the verifier of its correctness.\nIdeally, both the amount of annotation and the space used by the verifier\nshould be sublinear in the relevant input size parameters.\n  A rich theory of such algorithms -- which we call schemes -- has emerged.\nPrior work has shown how to leverage the prover's power to efficiently solve\nproblems that have no non-trivial standard data stream algorithms. However,\nwhile optimal schemes are now known for several basic problems, such optimality\nholds only for streams whose length is commensurate with the size of the data\nuniverse. In contrast, many real-world datasets are relatively sparse,\nincluding graphs that contain only O(n^2) edges, and IP traffic streams that\ncontain much fewer than the total number of possible IP addresses, 2^128 in\nIPv6.\n  We design the first schemes that allow both the annotation and the space\nusage to be sublinear in the total number of stream updates rather than the\nsize of the data universe. We solve significant problems, including variations\nof INDEX, SET-DISJOINTNESS, and FREQUENCY-MOMENTS, plus several natural\nproblems on graphs. On the other hand, we give a new lower bound that, for the\nfirst time, rules out smooth tradeoffs between annotation and space usage for a\nspecific problem. Our technique brings out new nuances in Merlin-Arthur\ncommunication complexity models, and provides a separation between online\nversions of the MA and AMA models.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2013 15:17:28 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Chakrabarti", "Amit", ""], ["Cormode", "Graham", ""], ["Goyal", "Navin", ""], ["Thaler", "Justin", ""]]}, {"id": "1304.3872", "submitter": "Samuel Epstein", "authors": "Samuel Epstein", "title": "All Sampling Methods Produce Outliers", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a computable probability measure P over natural numbers or infinite\nbinary sequences, there is no computable, randomized method that can produce an\narbitrarily large sample such that none of its members are outliers of P.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2013 02:16:32 GMT"}, {"version": "v2", "created": "Fri, 10 May 2013 04:43:45 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 02:20:09 GMT"}, {"version": "v4", "created": "Tue, 11 Jun 2019 09:54:03 GMT"}, {"version": "v5", "created": "Tue, 6 Aug 2019 23:51:13 GMT"}, {"version": "v6", "created": "Sat, 6 Feb 2021 23:23:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Epstein", "Samuel", ""]]}, {"id": "1304.3876", "submitter": "Daowen Qiu", "authors": "Shenggen Zheng, Daowen Qiu, Jozef Gruska", "title": "Power of the interactive proof systems with verifiers modeled by\n  semi-quantum two-way finite automata", "comments": "26 pages, 5 figures, some references have been added, and comments\n  are welcome", "journal-ref": "Information and Computation 241(2015) 197-214", "doi": "10.1016/j.ic.2015.02.003", "report-no": null, "categories": "cs.CC cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the power of AM for the case that verifiers are {\\em\ntwo-way finite automata with quantum and classical states} (2QCFA)--introduced\nby Ambainis and Watrous in 2002--and the communications are classical. It is of\ninterest to consider AM with such \"semi-quantum\" verifiers because they use\nonly limited quantum resources. Our main result is that such Quantum\nArthur-Merlin proof systems (QAM(2QCFA)) with polynomial expected running time\nare more powerful than in the case verifiers are two-way probabilistic finite\nautomata (AM(2PFA)) with polynomial expected running time. Moreover, we prove\nthat there is a language which can be recognized by an exponential expected\nrunning time QAM(2QCFA), but can not be recognized by any AM(2PFA), and that\nthe NP-complete language $L_{knapsack}$ can also be recognized by a QAM(2QCFA)\nworking only on quantum pure states using unitary operators.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2013 04:59:44 GMT"}, {"version": "v2", "created": "Tue, 7 May 2013 07:30:26 GMT"}, {"version": "v3", "created": "Sat, 2 May 2015 15:55:26 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Zheng", "Shenggen", ""], ["Qiu", "Daowen", ""], ["Gruska", "Jozef", ""]]}, {"id": "1304.3935", "submitter": "David J. Rosenbaum", "authors": "David J. Rosenbaum", "title": "Bidirectional Collision Detection and Faster Deterministic Isomorphism\n  Testing", "comments": "18 pages. v1 shows the results. v2 makes minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce bidirectional collision detection --- a new\nalgorithmic tool that applies to the collision problems that arise in many\nisomorphism problems. For the group isomorphism problem, we show that\nbidirectional collision detection yields a deterministic n^((1 / 2) log n +\nO(1)) time algorithm whereas previously the n^(log n + O(1))\ngenerator-enumeration algorithm was the best result for several decades. For\nthe hard special case of solvable groups, we combine bidirectional collision\ndetection with methods from the author's previous work to obtain a\ndeterministic square-root speedup over the best previous algorithm. We also\nshow a deterministic square-root speedup over the best previous algorithm for\ntesting isomorphism of rings. We can even apply bidirectional collision\ndetection to the graph isomorphism problem to obtain a deterministic T^(1 /\nsqrt(2)) speedup over the best previous deterministic algorithm. Although the\nspace requirements for our algorithms are greater than those for previous\ndeterministic isomorphism tests, we show time-space tradeoffs that interpolate\nbetween the resource requirements of our algorithms and previous work.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2013 19:21:14 GMT"}, {"version": "v2", "created": "Thu, 16 May 2013 04:37:28 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Rosenbaum", "David J.", ""]]}, {"id": "1304.4519", "submitter": "David Doty", "authors": "David Doty and Monir Hajiaghayi", "title": "Leaderless deterministic chemical reaction networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1204.4176", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC cs.DS q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper answers an open question of Chen, Doty, and Soloveichik [1], who\nshowed that a function f:N^k --> N^l is deterministically computable by a\nstochastic chemical reaction network (CRN) if and only if the graph of f is a\nsemilinear subset of N^{k+l}. That construction crucially used \"leaders\": the\nability to start in an initial configuration with constant but non-zero counts\nof species other than the k species X_1,...,X_k representing the input to the\nfunction f. The authors asked whether deterministic CRNs without a leader\nretain the same power.\n  We answer this question affirmatively, showing that every semilinear function\nis deterministically computable by a CRN whose initial configuration contains\nonly the input species X_1,...,X_k, and zero counts of every other species. We\nshow that this CRN completes in expected time O(n), where n is the total number\nof input molecules. This time bound is slower than the O(log^5 n) achieved in\n[1], but faster than the O(n log n) achieved by the direct construction of [1]\n(Theorem 4.1 in the latest online version of [1]), since the fast construction\nof that paper (Theorem 4.4) relied heavily on the use of a fast, error-prone\nCRN that computes arbitrary computable functions, and which crucially uses a\nleader.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 17:04:10 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Doty", "David", ""], ["Hajiaghayi", "Monir", ""]]}, {"id": "1304.4642", "submitter": "Maris Ozols", "authors": "Andrew M. Childs, Robin Kothari, Maris Ozols, Martin Roetteler", "title": "Easy and hard functions for the Boolean hidden shift problem", "comments": "29 pages, 2 figures", "journal-ref": "Proceedings of TQC 2013, LIPIcs, vol. 22, pp. 50-79, ISBN\n  978-3-939897-55-2 (2013)", "doi": "10.4230/LIPIcs.TQC.2013.50", "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the quantum query complexity of the Boolean hidden shift problem.\nGiven oracle access to f(x+s) for a known Boolean function f, the task is to\ndetermine the n-bit string s. The quantum query complexity of this problem\ndepends strongly on f. We demonstrate that the easiest instances of this\nproblem correspond to bent functions, in the sense that an exact one-query\nalgorithm exists if and only if the function is bent. We partially characterize\nthe hardest instances, which include delta functions. Moreover, we show that\nthe problem is easy for random functions, since two queries suffice. Our\nalgorithm for random functions is based on performing the pretty good\nmeasurement on several copies of a certain state; its analysis relies on the\nFourier transform. We also use this approach to improve the quantum rejection\nsampling approach to the Boolean hidden shift problem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 23:24:38 GMT"}], "update_date": "2013-11-28", "authors_parsed": [["Childs", "Andrew M.", ""], ["Kothari", "Robin", ""], ["Ozols", "Maris", ""], ["Roetteler", "Martin", ""]]}, {"id": "1304.4819", "submitter": "Guangda Hu", "authors": "Zeev Dvir and Guangda Hu", "title": "Matching-Vector Families and LDCs Over Large Modulo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove new upper bounds on the size of families of vectors in $\\Z_m^n$ with\nrestricted modular inner products, when $m$ is a large integer. More formally,\nif $\\vec{u}_1,\\ldots,\\vec{u}_t \\in \\Z_m^n$ and $\\vec{v}_1,\\ldots,\\vec{v}_t \\in\n\\Z_m^n$ satisfy $\\langle\\vec{u}_i,\\vec{v}_i\\rangle\\equiv0\\pmod m$ and\n$\\langle\\vec{u}_i,\\vec{v}_j\\rangle\\not\\equiv0\\pmod m$ for all $i\\neq j\\in[t]$,\nwe prove that $t \\leq O(m^{n/2+8.47})$. This improves a recent bound of $t \\leq\nm^{n/2 + O(\\log(m))}$ by \\cite{BDL13} and is the best possible up to the\nconstant 8.47 when $m$ is sufficiently larger than $n$.\n  The maximal size of such families, called `Matching-Vector families', shows\nup in recent constructions of locally decodable error correcting codes (LDCs)\nand determines the rate of the code. Using our result we are able to show that\nthese codes, called Matching-Vector codes, must have encoding length at least\n$K^{19/18}$ for $K$-bit messages, regardless of their query complexity. This\nimproves a known super linear bound of $ K2^{\\Omega({\\sqrt{\\log K}})}$ proved\nin \\cite{DGY11}.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 13:30:23 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 00:36:49 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Dvir", "Zeev", ""], ["Hu", "Guangda", ""]]}, {"id": "1304.4986", "submitter": "Marcel Jackson G", "authors": "Marcel Jackson, Tomasz Kowalski and Todd Niven", "title": "Complexity and polymorphisms for digraph constraint problems under some\n  basic constructions", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of polymorphisms in determining the complexity of constraint\nsatisfaction problems is well established.\n  In this context we study the stability of CSP complexity and polymorphism\nproperties under some basic graph theoretic constructions. As applications we\nobserve a collapse in the applicability of algorithms for CSPs over directed\ngraphs with both a total source and a total sink: the corresponding CSP is\nsolvable by the \"few subpowers algorithm\" if and only if it is solvable by a\nlocal consistency check algorithm. Moreover, we find that the property of\n\"strict width\" and solvability by few subpowers are unstable under first order\nreductions. The analysis also yields a complete characterisation of the main\npolymorphism properties for digraphs whose symmetric closure is a complete\ngraph.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 23:07:08 GMT"}, {"version": "v2", "created": "Sat, 22 Nov 2014 21:01:09 GMT"}, {"version": "v3", "created": "Thu, 21 Jul 2016 11:18:29 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Jackson", "Marcel", ""], ["Kowalski", "Tomasz", ""], ["Niven", "Todd", ""]]}, {"id": "1304.5010", "submitter": "Cristopher Moore", "authors": "Sixia Chen, Cristopher Moore, and Alexander Russell", "title": "Small-Bias Sets for Nonabelian Groups: Derandomizing the Alon-Roichman\n  Theorem", "comments": "Our results on solvable groups have been significantly improved,\n  giving eps-biased sets of polynomial (as opposed to quasipolynomial) size", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.GR math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In analogy with epsilon-biased sets over Z_2^n, we construct explicit\nepsilon-biased sets over nonabelian finite groups G. That is, we find sets S\nsubset G such that | Exp_{x in S} rho(x)| <= epsilon for any nontrivial\nirreducible representation rho. Equivalently, such sets make G's Cayley graph\nan expander with eigenvalue |lambda| <= epsilon. The Alon-Roichman theorem\nshows that random sets of size O(log |G| / epsilon^2) suffice. For groups of\nthe form G = G_1 x ... x G_n, our construction has size poly(max_i |G_i|, n,\nepsilon^{-1}), and we show that a set S \\subset G^n considered by Meka and\nZuckerman that fools read-once branching programs over G is also epsilon-biased\nin this sense. For solvable groups whose abelian quotients have constant\nexponent, we obtain epsilon-biased sets of size (log |G|)^{1+o(1)}\npoly(epsilon^{-1}). Our techniques include derandomized squaring (in both the\nmatrix product and tensor product senses) and a Chernoff-like bound on the\nexpected norm of the product of independently random operators that may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2013 03:17:23 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2013 16:09:12 GMT"}, {"version": "v3", "created": "Wed, 24 Apr 2013 16:07:40 GMT"}, {"version": "v4", "created": "Tue, 30 Apr 2013 17:59:34 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Chen", "Sixia", ""], ["Moore", "Cristopher", ""], ["Russell", "Alexander", ""]]}, {"id": "1304.5164", "submitter": "Robin Kothari", "authors": "Alessandro Cosentino, Robin Kothari, Adam Paetznick", "title": "Dequantizing read-once quantum formulas", "comments": "14 pages, 8 figures, to appear in proceedings of TQC 2013", "journal-ref": "8th Conference on the Theory of Quantum Computation, Communication\n  and Cryptography (TQC 2013), Leibniz International Proceedings in Informatics\n  (LIPIcs) 22, pp. 80-92 (2013)", "doi": "10.4230/LIPIcs.TQC.2013.80", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum formulas, defined by Yao [FOCS '93], are the quantum analogs of\nclassical formulas, i.e., classical circuits in which all gates have fanout\none. We show that any read-once quantum formula over a gate set that contains\nall single-qubit gates is equivalent to a read-once classical formula of the\nsame size and depth over an analogous classical gate set. For example, any\nread-once quantum formula over Toffoli and single-qubit gates is equivalent to\na read-once classical formula over Toffoli and NOT gates. We then show that the\nequivalence does not hold if the read-once restriction is removed. To show the\npower of quantum formulas without the read-once restriction, we define a new\nmodel of computation called the one-qubit model and show that it can compute\nall boolean functions. This model may also be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2013 15:38:07 GMT"}], "update_date": "2014-04-24", "authors_parsed": [["Cosentino", "Alessandro", ""], ["Kothari", "Robin", ""], ["Paetznick", "Adam", ""]]}, {"id": "1304.5247", "submitter": "Herv\\'e Zwirn", "authors": "Herve Zwirn", "title": "Computational Irreducibility and Computational Analogy", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous paper, we provided a formal definition for the concept of\ncomputational irreducibility (CIR), i.e. the fact for a function f from N to N\nthat it is impossible to compute f(n) without following approximately the same\npath than computing successively all the values f(i) from i=1 to n. Our\ndefinition is based on the concept of E Turing machines (for Enumerating Turing\nMachines) and on the concept of approximation of E Turing machines for which we\nalso gave a formal definition. We precise here these definitions through some\nmodifications intended to improve the robustness of the concept. We introduce\nthen a new concept: the Computational Analogy and prove some properties of\ncomputationally analog functions. Computational Analogy is an equivalence\nrelation which allows partitioning the set of computable functions in classes\nwhose members have the same properties regarding to their computational\nirreducibility and their computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2013 20:27:26 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2013 19:43:22 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2013 16:19:05 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Zwirn", "Herve", ""]]}, {"id": "1304.5388", "submitter": "Johannes Schmidt", "authors": "Nadia Creignou, Uwe Egly and Johannes Schmidt", "title": "Complexity Classifications for logic-based Argumentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider logic-based argumentation in which an argument is a pair (Fi,al),\nwhere the support Fi is a minimal consistent set of formulae taken from a given\nknowledge base (usually denoted by De) that entails the claim al (a formula).\nWe study the complexity of three central problems in argumentation: the\nexistence of a support Fi ss De, the validity of a support and the relevance\nproblem (given psi is there a support Fi such that psi ss Fi?). When arguments\nare given in the full language of propositional logic these problems are\ncomputationally costly tasks, the validity problem is DP-complete, the others\nare SigP2-complete. We study these problems in Schaefer's famous framework\nwhere the considered propositional formulae are in generalized conjunctive\nnormal form. This means that formulae are conjunctions of constraints build\nupon a fixed finite set of Boolean relations Ga (the constraint language). We\nshow that according to the properties of this language Ga, deciding whether\nthere exists a support for a claim in a given knowledge base is either\npolynomial, NP-complete, coNP-complete or SigP2-complete. We present a\ndichotomous classification, P or DP-complete, for the verification problem and\na trichotomous classification for the relevance problem into either polynomial,\nNP-complete, or SigP2-complete. These last two classifications are obtained by\nmeans of algebraic tools.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 12:10:51 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2014 09:53:27 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Creignou", "Nadia", ""], ["Egly", "Uwe", ""], ["Schmidt", "Johannes", ""]]}, {"id": "1304.5429", "submitter": "Kousha Etessami", "authors": "Kousha Etessami, Alistair Stewart, Mihalis Yannakakis", "title": "A note on the complexity of comparing succinctly represented integers,\n  with an application to maximum probability parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following two decision problems capture the complexity of comparing\nintegers or rationals that are succinctly represented in\nproduct-of-exponentials notation, or equivalently, via arithmetic circuits\nusing only multiplication and division gates, and integer inputs:\n  Input instance: four lists of positive integers: a_1, ...., a_n ; b_1,....,\nb_n ; c_1,....,c_m ; d_1, ...., d_m ; where each of the integers is represented\nin binary.\n  Problem 1 (equality testing): Decide whether a_1^{b_1} a_2^{b_2} ....\na_n^{b_n} = c_1^{d_1} c_2^{d_2} .... c_m^{d_m} .\n  Problem 2 (inequality testing): Decide whether a_1^{b_1} a_2^{b_2} ...\na_n^{b_n} >= c_1^{d_1} c_2^{d_2} .... c_m^{d_m} .\n  Problem 1 is easily decidable in polynomial time using a simple iterative\nalgorithm. Problem 2 is much harder. We observe that the complexity of Problem\n2 is intimately connected to deep conjectures and results in number theory. In\nparticular, if a refined form of the ABC conjecture formulated by Baker in 1998\nholds, or if the older Lang-Waldschmidt conjecture (formulated in 1978) on\nlinear forms in logarithms holds, then Problem 2 is decidable in P-time (in the\nstandard Turing model of computation). Moreover, it follows from the best\navailable quantitative bounds on linear forms in logarithms, e.g., by Baker and\nW\\\"{u}stholz (1993) or Matveev (2000), that if m and n are fixed universal\nconstants then Problem 2 is decidable in P-time (without relying on any\nconjectures). This latter fact was observed earlier by Shub (1993).\n  We describe one application: P-time maximum probability parsing for arbitrary\nstochastic context-free grammars (where \\epsilon-rules are allowed).\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 14:34:47 GMT"}, {"version": "v2", "created": "Wed, 1 May 2013 16:12:46 GMT"}, {"version": "v3", "created": "Mon, 7 Apr 2014 16:33:35 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Etessami", "Kousha", ""], ["Stewart", "Alistair", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "1304.5479", "submitter": "Ronald de Haan", "authors": "Ronald de Haan, Iyad Kanj, Stefan Szeider", "title": "Local Backbones", "comments": "A previous version appeared in the proceedings of the 16th\n  International Conference on Theory and Applications of Satisfiability Testing\n  (SAT 2013)", "journal-ref": "Proceedings of SAT 2013, LNCS 7962, pp. 377-393, 2013", "doi": "10.1007/978-3-642-39071-5_28", "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A backbone of a propositional CNF formula is a variable whose truth value is\nthe same in every truth assignment that satisfies the formula. The notion of\nbackbones for CNF formulas has been studied in various contexts. In this paper,\nwe introduce local variants of backbones, and study the computational\ncomplexity of detecting them. In particular, we consider k-backbones, which are\nbackbones for sub-formulas consisting of at most k clauses, and iterative\nk-backbones, which are backbones that result after repeated instantiations of\nk-backbones. We determine the parameterized complexity of deciding whether a\nvariable is a k-backbone or an iterative k-backbone for various restricted\nformula classes, including Horn, definite Horn, and Krom. We also present some\nfirst empirical results regarding backbones for CNF-Satisfiability (SAT). The\nempirical results we obtain show that a large fraction of the backbones of\nstructured SAT instances are local, in contrast to random instances, which\nappear to have few local backbones.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 16:59:11 GMT"}, {"version": "v2", "created": "Thu, 23 May 2013 14:23:29 GMT"}, {"version": "v3", "created": "Fri, 18 Jul 2014 14:54:29 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["de Haan", "Ronald", ""], ["Kanj", "Iyad", ""], ["Szeider", "Stefan", ""]]}, {"id": "1304.5604", "submitter": "Ivan Lavallee", "authors": "Marc Bui (LAISC), Michel Lamure (EDISS), Ivan Lavallee (LAISC)", "title": "La machine \\alpha: mod\\`ele g\\'en\\'erique pour les algorithmes naturels", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  So far, following the works of A.M. Turing, the algorithms were considered as\nthe mathematical abstraction from which we could write programs for computers\nwhose principle was based on the theoretical concept of Turing machine. We\nstart here from the observation that natural algorithms or rather algorithms of\nthe nature which are massively parallel, autoadaptative and reproductible, and\nfor which we do not know how they really work, nor why, are not easily\nspecified by the current theoretical model of Universal Turing machine, or\nUniversal Computer. In particular the aspects of communications, evolutionary\nrules (rulers), random (unpredictable) events, just like the genetic code, are\ntaken into account only by subtleties which oblige to break the theory. We\nshall propose one \\textit{universal model} of algorithm called machine-alpha\nwhich contains and generalizes the existing models. --- Jusqu'ici, suite aux\ntravaux de A.M.Turing [Turing, 1936], les algorithmes ont \\'et\\'e vus comme\nl'abstraction \\`a partir de laquelle on pouvait \\'ecrire des programmes pour\ndes ordinateurs dont le principe \\'etait lui-m\\^eme issu du concept th\\'eorique\nde machine de Turing. Nous partons ici du constat que les algorithmes naturels\nou plut\\^ot les algorithmes de la nature, massivement parall\\`eles,\nautoadaptatifs et auto reproductibles, dont on ne sait pas comment ils\nfonctionnent r\\'eellement, ni pourquoi, ne sont pas ais\\'ement sp\\'ecifi\\'es\npar le mod\\`ele th\\'eorique actuel de Machine de Turing Universelle, ou de\nCalculateur Universel ; en particulier les aspects de communications, de\nr\\`egles \\'evolutives, d' \\'ev\\'enements al\\'eatoires, \\`a l'image du code\ng\\'en\\'etique, ne sont pris en compte que par ajout d'artifices \\`a la\nth\\'eorie. Nous nous proposons ici de montrer comment aborder ces probl\\`emes\nen repensant le mod\\`ele th\\'eorique. Nous proposerons un mod\\`ele\nd'algorithme, appel\\'e ici machine-\\alpha qui contient et g\\'en\\'eralise les\nmod\\`eles existants.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2013 08:39:03 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Bui", "Marc", "", "LAISC"], ["Lamure", "Michel", "", "EDISS"], ["Lavallee", "Ivan", "", "LAISC"]]}, {"id": "1304.5617", "submitter": "Nabarun Mondal Mr", "authors": "Nabarun Mondal, Partha P. Ghosh", "title": "Another Asymptotic Notation : \"Almost\"", "comments": "Was sent as mail to Robert Sidgewick, now submitted to SOP\n  Transactions on Applied Mathematics(AM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymptotic notations are heavily used while analysing runtimes of algorithms.\nPresent paper argues that some of these usages are non trivial, therefore\nincurring errors in communication of ideas. After careful reconsidera- tion of\nthe various existing notations a new notation is proposed. This notation has\nsimilarities with the other heavily used notations like Big-Oh, Big Theta,\nwhile being more accurate when describing the order relationship. It has been\nargued that this notation is more suitable for describing algorithm runtime\nthan Big-Oh.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2013 09:26:59 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2015 06:48:26 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Mondal", "Nabarun", ""], ["Ghosh", "Partha P.", ""]]}, {"id": "1304.5719", "submitter": "Jukka Suomela", "authors": "Danny Dolev, Keijo Heljanko, Matti J\\\"arvisalo, Janne H. Korhonen,\n  Christoph Lenzen, Joel Rybicki, Jukka Suomela, Siert Wieringa", "title": "Synchronous Counting and Computational Algorithm Design", "comments": "35 pages, extended and revised version", "journal-ref": null, "doi": "10.1016/j.jcss.2015.09.002", "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a complete communication network on $n$ nodes, each of which is a\nstate machine. In synchronous 2-counting, the nodes receive a common clock\npulse and they have to agree on which pulses are \"odd\" and which are \"even\". We\nrequire that the solution is self-stabilising (reaching the correct operation\nfrom any initial state) and it tolerates $f$ Byzantine failures (nodes that\nsend arbitrary misinformation). Prior algorithms are expensive to implement in\nhardware: they require a source of random bits or a large number of states.\n  This work consists of two parts. In the first part, we use computational\ntechniques (often known as synthesis) to construct very compact deterministic\nalgorithms for the first non-trivial case of $f = 1$. While no algorithm exists\nfor $n < 4$, we show that as few as 3 states per node are sufficient for all\nvalues $n \\ge 4$. Moreover, the problem cannot be solved with only 2 states per\nnode for $n = 4$, but there is a 2-state solution for all values $n \\ge 6$.\n  In the second part, we develop and compare two different approaches for\nsynthesising synchronous counting algorithms. Both approaches are based on\ncasting the synthesis problem as a propositional satisfiability (SAT) problem\nand employing modern SAT-solvers. The difference lies in how to solve the SAT\nproblem: either in a direct fashion, or incrementally within a counter-example\nguided abstraction refinement loop. Empirical results suggest that the former\ntechnique is more efficient if we want to synthesise time-optimal algorithms,\nwhile the latter technique discovers non-optimal algorithms more quickly.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 10:58:03 GMT"}, {"version": "v2", "created": "Mon, 5 Jan 2015 10:40:27 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dolev", "Danny", ""], ["Heljanko", "Keijo", ""], ["J\u00e4rvisalo", "Matti", ""], ["Korhonen", "Janne H.", ""], ["Lenzen", "Christoph", ""], ["Rybicki", "Joel", ""], ["Suomela", "Jukka", ""], ["Wieringa", "Siert", ""]]}, {"id": "1304.5777", "submitter": "S\\'ebastien Tavenas", "authors": "S\\'ebastien Tavenas", "title": "Improved bounds for reduction to depth 4 and depth 3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Koiran showed that if a $n$-variate polynomial of degree $d$ (with\n$d=n^{O(1)}$) is computed by a circuit of size $s$, then it is also computed by\na homogeneous circuit of depth four and of size\n$2^{O(\\sqrt{d}\\log(d)\\log(s))}$. Using this result, Gupta, Kamath, Kayal and\nSaptharishi gave a $\\exp(O(\\sqrt{d\\log(d)\\log(n)\\log(s)}))$ upper bound for the\nsize of the smallest depth three circuit computing a $n$-variate polynomial of\ndegree $d=n^{O(1)}$ given by a circuit of size $s$.\n  We improve here Koiran's bound. Indeed, we show that if we reduce an\narithmetic circuit to depth four, then the size becomes\n$\\exp(O(\\sqrt{d\\log(ds)\\log(n)}))$. Mimicking Gupta, Kamath, Kayal and\nSaptharishi's proof, it also implies the same upper bound for depth three\ncircuits.\n  This new bound is not far from optimal in the sense that Gupta, Kamath, Kayal\nand Saptharishi also showed a $2^{\\Omega(\\sqrt{d})}$ lower bound for the size\nof homogeneous depth four circuits such that gates at the bottom have fan-in at\nmost $\\sqrt{d}$. Finally, we show that this last lower bound also holds if the\nfan-in is at least $\\sqrt{d}$.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 18:53:23 GMT"}, {"version": "v2", "created": "Fri, 16 May 2014 14:30:40 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Tavenas", "S\u00e9bastien", ""]]}, {"id": "1304.5808", "submitter": "Shenwei Huang", "authors": "Shenwei Huang", "title": "Improved Complexity Results on $k$-Coloring $P_t$-Free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is $H$-free if it does not contain an induced subgraph isomorphic to\n$H$. We denote by $P_k$ and $C_k$ the path and the cycle on $k$ vertices,\nrespectively. In this paper, we prove that 4-COLORING is NP-complete for\n$P_7$-free graphs, and that 5-COLORING is NP-complete for $P_6$-free graphs.\nThese two results improve all previous results on $k$-coloring $P_t$-free\ngraphs, and almost complete the classification of complexity of $k$-COLORING\n$P_t$-free graphs for $k\\ge 4$ and $t\\ge 1$, leaving as the only missing case\n4-COLORING $P_6$-free graphs. We expect that 4-COLORING is polynomial time\nsolvable for $P_6$-free graphs; in support of this, we describe a polynomial\ntime algorithm for 4-COLORING $P_6$-free graphs which are also $P$-free, where\n$P$ is the graph obtained from $C_4$ by adding a new vertex and making it\nadjacent to exactly one vertex on the $C_4$.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2013 22:35:16 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2013 06:00:17 GMT"}], "update_date": "2013-10-07", "authors_parsed": [["Huang", "Shenwei", ""]]}, {"id": "1304.5910", "submitter": "Herv\\'e Fournier", "authors": "Herv\\'e Fournier, Sylvain Perifel, R\\'emi de Verclos", "title": "On fixed-polynomial size circuit lower bounds for uniform polynomials in\n  the sense of Valiant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assuming the Generalised Riemann Hypothesis (GRH), we show that for all k,\nthere exist polynomials with coefficients in $\\MA$ having no arithmetic\ncircuits of size O(n^k) over the complex field (allowing any complex constant).\nWe also build a family of polynomials that can be evaluated in AM having no\narithmetic circuits of size O(n^k). Then we investigate the link between\nfixed-polynomial size circuit bounds in the Boolean and arithmetic settings. In\ncharacteristic zero, it is proved that $\\NP \\not\\subset \\size(n^k)$, or $\\MA\n\\subset \\size(n^k)$, or NP=MA imply lower bounds on the circuit size of uniform\npolynomials in n variables from the class VNP over the complex field, assuming\nGRH. In positive characteristic p, uniform polynomials in VNP have circuits of\nfixed-polynomial size if and only if both VP=VNP over F_p and Mod_pP has\ncircuits of fixed-polynomial size.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 10:42:03 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Fournier", "Herv\u00e9", ""], ["Perifel", "Sylvain", ""], ["de Verclos", "R\u00e9mi", ""]]}, {"id": "1304.5934", "submitter": "Bugra Caskurlu", "authors": "Bugra Caskurlu, K. Subramani", "title": "On Partial Vertex Cover on Bipartite Graphs and Trees", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the Vertex Cover problem is in P on bipartite graphs,\nhowever; the computational complexity of the Partial Vertex Cover problem on\nbipartite graphs is open. In this paper, we first show that the Partial Vertex\nCover problem is NP-hard on bipartite graphs. We then identify an interesting\nspecial case of bipartite graphs, for which the Partial Vertex Cover problem\ncan be solved in polynomial-time. We also show that the set of acyclic\nbipartite graphs, i.e., forests, and the set of bipartite graph where the\ndegree of each vertex is at most 3 fall into that special case. Therefore, we\nprove that the Partial Vertex Cover problem is in P on trees, and it is also in\nP on the set of bipartite graphs where the degree of each vertex is at most 3.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 12:59:20 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Caskurlu", "Bugra", ""], ["Subramani", "K.", ""]]}, {"id": "1304.5961", "submitter": "Andreas Pfandler", "authors": "Andreas Pfandler, Stefan R\\\"ummele, Stefan Szeider", "title": "Backdoors to Abduction", "comments": "12 pages, a short version will appear in the proceedings of the 23rd\n  International Joint Conference on Artificial Intelligence (IJCAI 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abductive reasoning (or Abduction, for short) is among the most fundamental\nAI reasoning methods, with a broad range of applications, including fault\ndiagnosis, belief revision, and automated planning. Unfortunately, Abduction is\nof high computational complexity; even propositional Abduction is\n\\Sigma_2^P-complete and thus harder than NP and coNP. This complexity barrier\nrules out the existence of a polynomial transformation to propositional\nsatisfiability (SAT). In this work we use structural properties of the\nAbduction instance to break this complexity barrier. We utilize the problem\nstructure in terms of small backdoor sets. We present fixed-parameter tractable\ntransformations from Abduction to SAT, which make the power of today's SAT\nsolvers available to Abduction.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 14:23:11 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Pfandler", "Andreas", ""], ["R\u00fcmmele", "Stefan", ""], ["Szeider", "Stefan", ""]]}, {"id": "1304.6333", "submitter": "Joshua Grochow", "authors": "Joshua A. Grochow", "title": "Unifying and generalizing known lower bounds via geometric complexity\n  theory", "comments": null, "journal-ref": "Computational Complexity 24(2):393-475, 2015 (open access)", "doi": "10.1007/s00037-015-0103-x", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that most arithmetic circuit lower bounds and relations between lower\nbounds naturally fit into the representation-theoretic framework suggested by\ngeometric complexity theory (GCT), including: the partial derivatives technique\n(Nisan-Wigderson), the results of Razborov and Smolensky on $AC^0[p]$,\nmultilinear formula and circuit size lower bounds (Raz et al.), the degree\nbound (Strassen, Baur-Strassen), the connected components technique (Ben-Or),\ndepth 3 arithmetic circuit lower bounds over finite fields\n(Grigoriev-Karpinski), lower bounds on permanent versus determinant\n(Mignon-Ressayre, Landsberg-Manivel-Ressayre), lower bounds on matrix\nmultiplication (B\\\"{u}rgisser-Ikenmeyer) (these last two were already known to\nfit into GCT), the chasms at depth 3 and 4 (Gupta-Kayal-Kamath-Saptharishi;\nAgrawal-Vinay; Koiran), matrix rigidity (Valiant) and others. That is, the\noriginal proofs, with what is often just a little extra work, already provide\nrepresentation-theoretic obstructions in the sense of GCT for their respective\nlower bounds. This enables us to expose a new viewpoint on GCT, whereby it is a\nnatural unification and broad generalization of known results. It also shows\nthat the framework of GCT is at least as powerful as known methods, and gives\nmany new proofs-of-concept that GCT can indeed provide significant asymptotic\nlower bounds. This new viewpoint also opens up the possibility of fruitful\ntwo-way interactions between previous results and the new methods of GCT; we\nprovide several concrete suggestions of such interactions. For example, the\nrepresentation-theoretic viewpoint of GCT naturally provides new properties to\nconsider in the search for new lower bounds.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2013 15:44:45 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Grochow", "Joshua A.", ""]]}, {"id": "1304.6363", "submitter": "Stuart Barry Cooper", "authors": "S. Barry Cooper", "title": "Incomputability after Alan Turing", "comments": null, "journal-ref": "Notices of the American Mathematical Society, Volume 59, Number 6,\n  2012, pp. 776-784", "doi": null, "report-no": null, "categories": "math.HO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incomputability as a mathematical notion arose from work of Alan Turing and\nAlonzo Church in the 1930s. Like Turing himself, it attracted less attention\nthan it deserved beyond the confines of mathematics. Today our experiences in\ncomputer science, physics, biology, artificial intelligence, economics and the\nhumanities point to the importance of the notion for understanding the world\naround us. This article takes a Turing centenary look at how the interface\nbetween the computable world and the incomputable formed a central theme in\nTuring's work - from the early establishment of the standard model of the\nstored program computer, to the late work on emergence of form in nature, and\nthe first approaches to understanding and simulating human intelligence.\nTuring's thinking was remarkably prescient, and his legacy still impacts on\nmuch of our work. The incomputable may turn out to be a specially important\npart of the legacy, with consequences that Alan Turing himself could not have\nenvisaged.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 19:02:47 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Cooper", "S. Barry", ""]]}, {"id": "1304.6551", "submitter": "Vaclav Lin", "authors": "V\\'aclav L\\'in", "title": "Decision-Theoretic Troubleshooting: Hardness of Approximation", "comments": "The paper has been withdrawn since it has been published in IJAR\n  (http://dx.doi.org/10.1016/j.ijar.2013.07.003)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-theoretic troubleshooting is one of the areas to which Bayesian\nnetworks can be applied. Given a probabilistic model of a malfunctioning\nman-made device, the task is to construct a repair strategy with minimal\nexpected cost. The problem has received considerable attention over the past\ntwo decades. Efficient solution algorithms have been found for simple cases,\nwhereas other variants have been proven NP-complete. We study several variants\nof the problem found in literature, and prove that computing approximate\ntroubleshooting strategies is NP-hard. In the proofs, we exploit a close\nconnection to set-covering problems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 11:31:09 GMT"}, {"version": "v2", "created": "Wed, 29 May 2013 09:40:01 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2013 10:32:42 GMT"}, {"version": "v4", "created": "Thu, 1 Aug 2013 10:31:25 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["L\u00edn", "V\u00e1clav", ""]]}, {"id": "1304.6685", "submitter": "Joshua Brody", "authors": "Joshua Brody and Pooya Hatami", "title": "Distance-Sensitive Property Testing Lower Bounds", "comments": "14 pages. arXiv admin note: text overlap with arXiv:1202.3479", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider several property testing problems and ask how the\nquery complexity depends on the distance parameter $\\eps$. We achieve new lower\nbounds in this setting for the problems of testing whether a function is\nmonotone and testing whether the function has low Fourier degree. For\nmonotonicity testing, our lower bound matches the recent upper bound of\nChakrabarty and Seshadhri.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 18:07:07 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2013 21:32:33 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Brody", "Joshua", ""], ["Hatami", "Pooya", ""]]}, {"id": "1304.6800", "submitter": "Richard Schmied", "authors": "Marek Karpinski and Richard Schmied", "title": "Approximation Hardness of Graphic TSP on Cubic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove explicit approximation hardness results for the Graphic TSP on cubic\nand subcubic graphs as well as the new inapproximability bounds for the\ncorresponding instances of the (1,2)-TSP. The proof technique uses new modular\nconstructions of simulating gadgets for the restricted cubic and subcubic\ninstances. The modular constructions used in the paper could be also of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 05:07:16 GMT"}, {"version": "v2", "created": "Tue, 14 May 2013 17:20:50 GMT"}], "update_date": "2013-05-15", "authors_parsed": [["Karpinski", "Marek", ""], ["Schmied", "Richard", ""]]}, {"id": "1304.6870", "submitter": "Anuj Dawar", "authors": "Matthew Anderson, Anuj Dawar, Bjarki Holm", "title": "Maximum Matching and Linear Programming in Fixed-Point Logic with\n  Counting", "comments": "Full version of paper to appear in LICS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish the expressibility in fixed-point logic with counting (FPC) of a\nnumber of natural polynomial-time problems. In particular, we show that the\nsize of a maximum matching in a graph is definable in FPC. This settles an open\nproblem first posed by Blass, Gurevich and Shelah, who asked whether the\nexistence of perfect matchings in general graphs could be determined in the\nmore powerful formalism of choiceless polynomial time with counting. Our result\nis established by showing that the ellipsoid method for solving linear programs\ncan be implemented in FPC. This allows us to prove that linear programs can be\noptimised in FPC if the corresponding separation oracle problem can be defined\nin FPC. On the way to defining a suitable separation oracle for the maximum\nmatching problem, we provide FPC formulas defining maximum flows and canonical\nminimum cuts in capacitated graphs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 10:51:32 GMT"}], "update_date": "2013-04-26", "authors_parsed": [["Anderson", "Matthew", ""], ["Dawar", "Anuj", ""], ["Holm", "Bjarki", ""]]}, {"id": "1304.7038", "submitter": "Andrew Winslow", "authors": "Andrew Winslow", "title": "Staged Self-Assembly and Polyomino Context-Free Grammars", "comments": "34 pages, 23 figures. An abstract version has been accepted to DNA 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work by Demaine et al. (2012) developed a strong connection between\nsmallest context-free grammars and staged self-assembly systems for\none-dimensional strings and assemblies. We extend this work to two-dimensional\npolyominoes and assemblies, comparing staged self-assembly systems to a natural\ngeneralization of context-free grammars we call polyomino context-free grammars\n(PCFGs). We achieve nearly optimal bounds on the largest ratios of the smallest\nPCFG and staged self-assembly system for a given polyomino with n cells. For\nthe ratio of PCFGs over assembly systems, we show the smallest PCFG can be an\nOmega(n/(log(n))^3)-factor larger than the smallest staged assembly system,\neven when restricted to square polyominoes. For the ratio of assembly systems\nover PCFGs, we show that the smallest staged assembly system is never more than\na O(log(n))-factor larger than the smallest PCFG and is sometimes an\nOmega(log(n)/loglog(n))-factor larger.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 22:29:58 GMT"}, {"version": "v2", "created": "Wed, 1 May 2013 16:58:18 GMT"}, {"version": "v3", "created": "Sat, 29 Jun 2013 16:54:56 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Winslow", "Andrew", ""]]}, {"id": "1304.7558", "submitter": "Amir Abboud", "authors": "Amir Abboud and Kevin Lewi", "title": "Exact Weight Subgraphs and the k-Sum Conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Exact-Weight-H problem of finding a (not necessarily induced)\nsubgraph H of weight 0 in an edge-weighted graph G. We show that for every H,\nthe complexity of this problem is strongly related to that of the infamous\nk-Sum problem. In particular, we show that under the k-Sum Conjecture, we can\nachieve tight upper and lower bounds for the Exact-Weight-H problem for various\nsubgraphs H such as matching, star, path, and cycle. One interesting\nconsequence is that improving on the O(n^3) upper bound for Exact-Weight-4-Path\nor Exact-Weight-5-Path will imply improved algorithms for 3-Sum, 5-Sum,\nAll-Pairs Shortest Paths and other fundamental problems. This is in sharp\ncontrast to the minimum-weight and (unweighted) detection versions, which can\nbe solved easily in time O(n^2). We also show that a faster algorithm for any\nof the following three problems would yield faster algorithms for the others:\n3-Sum, Exact-Weight-3-Matching, and Exact-Weight-3-Star.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 03:38:47 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Abboud", "Amir", ""], ["Lewi", "Kevin", ""]]}, {"id": "1304.7705", "submitter": "Ji\\v{r}\\'i Matou\\v{s}ek", "authors": "Jiri Matousek", "title": "Computing higher homotopy groups is W[1]-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it was shown that, for every fixed k>1, given a finite simply\nconnected simplicial complex X, the kth homotopy group \\pi_k(X) can be computed\nin time polynomial in the number n of simplices of X. We prove that this\nproblem is W[1]-hard w.r.t. the parameter k even for X of dimension 4, and thus\nvery unlikely to admit an algorithm with running time bound f(k)n^C for an\nabsolute constant C. We also simplify, by about 20 pages, a 1989 proof by Anick\nthat, with k part of input, the computation of the rank of \\pi_k(X) is #P-hard.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 16:37:12 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Matousek", "Jiri", ""]]}, {"id": "1304.7804", "submitter": "David Doty", "authors": "David Doty", "title": "Producibility in hierarchical self-assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three results are shown on producibility in the hierarchical model of tile\nself-assembly. It is shown that a simple greedy polynomial-time strategy\ndecides whether an assembly A is producible. The algorithm can be optimized to\nuse O(|A| log^2 |A|) time. Cannon, Demaine, Demaine, Eisenstat, Patitz,\nSchweller, Summers, and Winslow showed that the problem of deciding if an\nassembly A is the unique producible terminal assembly of a tile system T can be\nsolved in O(|A|^2 |T| + |A| |T|^2) time for the special case of noncooperative\n\"temperature 1\" systems. It is shown that this can be improved to O(|A| |T| log\n|T|) time. Finally, it is shown that if two assemblies are producible, and if\nthey can be overlapped consistently -- i.e., if the positions that they share\nhave the same tile type in each assembly -- then their union is also\nproducible.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 21:02:51 GMT"}, {"version": "v2", "created": "Wed, 1 May 2013 07:56:03 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Doty", "David", ""]]}, {"id": "1304.8046", "submitter": "Bruno Bauwens", "authors": "Lu\\'is Antunes, Bruno Bauwens, Andre Souto, Andreia Teixeira", "title": "Sophistication vs Logical Depth", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sophistication and logical depth are two measures that express how\ncomplicated the structure in a string is. Sophistication is defined as the\nminimal complexity of a computable function that defines a two-part description\nfor the string that is shortest within some precision; the second can be\ndefined as the minimal computation time of a program that is shortest within\nsome precision. We show that the Busy Beaver function of the sophistication of\na string exceeds its logical depth with logarithmically bigger precision, and\nthat logical depth exceeds the Busy Beaver function of sophistication with\nlogarithmically bigger precision. We also show that this is not true if the\nprecision is only increased by a constant (when the notions are defined with\nplain Kolmogorov complexity). Finally we show that sophistication is unstable\nin its precision: constant variations can change its value by a linear term in\nthe length of the string.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 16:06:39 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2013 15:09:30 GMT"}, {"version": "v3", "created": "Fri, 27 Jan 2017 09:36:17 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Antunes", "Lu\u00eds", ""], ["Bauwens", "Bruno", ""], ["Souto", "Andre", ""], ["Teixeira", "Andreia", ""]]}, {"id": "1304.8108", "submitter": "Mohit Singh", "authors": "Mohit Singh, Nisheeth K. Vishnoi", "title": "Entropy, Optimization and Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of computing max-entropy distributions\nover a discrete set of objects subject to observed marginals. Interest in such\ndistributions arises due to their applicability in areas such as statistical\nphysics, economics, biology, information theory, machine learning,\ncombinatorics and, more recently, approximation algorithms. A key difficulty in\ncomputing max-entropy distributions has been to show that they have\npolynomially-sized descriptions. We show that such descriptions exist under\ngeneral conditions. Subsequently, we show how algorithms for (approximately)\ncounting the underlying discrete set can be translated into efficient\nalgorithms to (approximately) compute max-entropy distributions. In the reverse\ndirection, we show how access to algorithms that compute max-entropy\ndistributions can be used to count, which establishes an equivalence between\ncounting and computing max-entropy distributions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 18:39:26 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Singh", "Mohit", ""], ["Vishnoi", "Nisheeth K.", ""]]}]