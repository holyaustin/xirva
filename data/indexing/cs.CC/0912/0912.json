[{"id": "0912.0027", "submitter": "Yunhui Fu", "authors": "Matthew Cook and Yunhui Fu and Robert T. Schweller", "title": "Temperature 1 Self-Assembly: Deterministic Assembly in 3D and\n  Probabilistic Assembly in 2D", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the power of the Wang tile self-assembly model at temperature\n1, a threshold value that permits attachment between any two tiles that share\neven a single bond. When restricted to deterministic assembly in the plane, no\ntemperature 1 assembly system has been shown to build a shape with a tile\ncomplexity smaller than the diameter of the shape. In contrast, we show that\ntemperature 1 self-assembly in 3 dimensions, even when growth is restricted to\nat most 1 step into the third dimension, is capable of simulating a large class\nof temperature 2 systems, in turn permitting the simulation of arbitrary Turing\nmachines and the assembly of $n\\times n$ squares in near optimal $O(\\log n)$\ntile complexity. Further, we consider temperature 1 probabilistic assembly in\n2D, and show that with a logarithmic scale up of tile complexity and shape\nscale, the same general class of temperature $\\tau=2$ systems can be simulated\nwith high probability, yielding Turing machine simulation and $O(\\log^2 n)$\nassembly of $n\\times n$ squares with high probability. Our results show a sharp\ncontrast in achievable tile complexity at temperature 1 if either growth into\nthe third dimension or a small probability of error are permitted. Motivated by\napplications in nanotechnology and molecular computing, and the plausibility of\nimplementing 3 dimensional self-assembly systems, our techniques may provide\nthe needed power of temperature 2 systems, while at the same time avoiding the\nexperimental challenges faced by those systems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2009 21:45:29 GMT"}, {"version": "v2", "created": "Thu, 13 May 2010 00:12:03 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Cook", "Matthew", ""], ["Fu", "Yunhui", ""], ["Schweller", "Robert T.", ""]]}, {"id": "0912.0226", "submitter": "Paul Bonsma", "authors": "Paul Bonsma", "title": "Max-Leaves Spanning Tree is APX-hard for Cubic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding a spanning tree with maximum number of\nleaves (MaxLeaf). A 2-approximation algorithm is known for this problem, and a\n3/2-approximation algorithm when restricted to graphs where every vertex has\ndegree 3 (cubic graphs). MaxLeaf is known to be APX-hard in general, and\nNP-hard for cubic graphs. We show that the problem is also APX-hard for cubic\ngraphs. The APX-hardness of the related problem Minimum Connected Dominating\nSet for cubic graphs follows.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 18:26:53 GMT"}], "update_date": "2009-12-02", "authors_parsed": [["Bonsma", "Paul", ""]]}, {"id": "0912.0309", "submitter": "Murray Patterson", "authors": "Cedric Chauve, Jan Manuch and Murray Patterson", "title": "Hardness Results for the Gapped Consecutive-Ones Property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by problems of comparative genomics and paleogenomics, in [Chauve\net al., 2009], the authors introduced the Gapped Consecutive-Ones Property\nProblem (k,delta)-C1P: given a binary matrix M and two integers k and delta,\ncan the columns of M be permuted such that each row contains at most k blocks\nof ones and no two consecutive blocks of ones are separated by a gap of more\nthan delta zeros. The classical C1P problem, which is known to be polynomial is\nequivalent to the (1,0)-C1P problem. They showed that the (2,delta)-C1P Problem\nis NP-complete for all delta >= 2 and that the (3,1)-C1P problem is\nNP-complete. They also conjectured that the (k,delta)-C1P Problem is\nNP-complete for k >= 2, delta >= 1 and (k,delta) =/= (2,1). Here, we prove that\nthis conjecture is true. The only remaining case is the (2,1)-C1P Problem,\nwhich could be polynomial-time solvable.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2009 00:26:17 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2009 03:20:22 GMT"}], "update_date": "2009-12-05", "authors_parsed": [["Chauve", "Cedric", ""], ["Manuch", "Jan", ""], ["Patterson", "Murray", ""]]}, {"id": "0912.0453", "submitter": "Matthieu Finiasz", "authors": "Matthieu Finiasz", "title": "NP-completeness of Certain Sub-classes of the Syndrome Decoding Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Syndrome Decoding was proven to be NP-complete in 1978 and,\nsince then, quite a few cryptographic applications have had their security rely\non the (provable) difficulty of solving some instances of it. However, in most\ncases, the instances to be solved follow some specific constraint: the target\nweight is a function of the dimension and length of the code. In these cases,\nis the Syndrome Decoding problem still NP-complete? This is the question that\nthis article intends to answer.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2009 16:07:32 GMT"}], "update_date": "2009-12-03", "authors_parsed": [["Finiasz", "Matthieu", ""]]}, {"id": "0912.0568", "submitter": "Paul Beame", "authors": "Paul Beame, Trinh Huynh, Toniann Pitassi", "title": "Hardness Amplification in Proof Complexity", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general method for converting any family of unsatisfiable CNF\nformulas that is hard for one of the simplest proof systems, tree resolution,\ninto formulas that require large rank in any proof system that manipulates\npolynomials or polynomial threshold functions of degree at most k (known as\nTh(k) proofs). Such systems include Lovasz-Schrijver and Cutting Planes proof\nsystems as well as their high degree analogues.\n  These are based on analyzing two new proof systems, denoted by T^cc(k) and\nR^cc(k). The proof lines of T^cc(k) are arbitrary Boolean functions, each of\nwhich can be evaluated by an efficient k-party randomized communication\nprotocol. They include Th{k-1} proofs as a special case. R^cc(k) proofs are\nstronger and only require that each inference be locally checkable by an\nefficient k-party randomized communication protocol.\n  Our main results are the following:\n  (1) When k is O(loglogn), for any unsatisfiable CNF formula F requiring\nresolution rank r, there is a related CNF formula G=Lift_k(F) requiring\nrefutation rank r^Omega(1/k) log^O(1) n in all R^cc(k) systems.\n  (2) There are strict hierarchies for T^cc(k) and R^cc(k) systems with respect\nto k when k is O(loglogn in that there are unsatisfiable CNF formulas requiring\nlarge rank R^cc(k) refutations but having log^O(1) n rank Th(k) refutations.\n  (3) When k is O(loglogn) there are 2^(n^Omega(1/k)) lower bounds on the size\nof tree-like T^cc(k) refutations for large classes of lifted CNF formulas.\n  (4) A general method for producing integrality gaps for low rank R^cc(2)\ninference (and hence Cutting Planes and Th(1) inference) based on related gaps\nfor low rank resolution. These gaps are optimal for MAX-2t-SAT.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2009 02:09:22 GMT"}], "update_date": "2009-12-04", "authors_parsed": [["Beame", "Paul", ""], ["Huynh", "Trinh", ""], ["Pitassi", "Toniann", ""]]}, {"id": "0912.0583", "submitter": "David Meyer", "authors": "David A. Meyer, James Pommersheim", "title": "Single query learning from abelian and non-abelian Hamming distance\n  oracles", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying an n-bit string using a single quantum\nquery to an oracle that computes the Hamming distance between the query and\nhidden strings. The standard action of the oracle on a response register of\ndimension r is by powers of the cycle (1...r), all of which, of course,\ncommute. We introduce a new model for the action of an oracle--by general\npermutations in S_r--and explore how the success probability depends on r and\non the map from Hamming distances to permutations. In particular, we prove that\nwhen r = 2, for even n the success probability is 1 with the right choice of\nthe map, while for odd n the success probability cannot be 1 for any choice.\nFurthermore, for small odd n and r = 3, we demonstrate numerically that the\nimage of the optimal map generates a non-abelian group of permutations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2009 06:02:06 GMT"}], "update_date": "2009-12-04", "authors_parsed": [["Meyer", "David A.", ""], ["Pommersheim", "James", ""]]}, {"id": "0912.0741", "submitter": "Turlough Neary", "authors": "Turlough Neary", "title": "A boundary between universality and non-universality in spiking neural P\n  systems", "comments": "Version 1 (arXiv:0912.0741v1) of this paper contained some technical\n  errors that were mainly due to the restriction of counter machines used.\n  Definition 3 given in this version differs from the definition given in\n  version 1. This new definition necessitated some minor adjustments in proofs\n  of Theorems 1, 2 and 3.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we offer a significant improvement on the previous smallest\nspiking neural P systems and solve the problem of finding the smallest possible\nextended spiking neural P system. Paun and Paun gave a universal spiking neural\nP system with 84 neurons and another that has extended rules with 49 neurons.\nSubsequently, Zhang et al. reduced the number of neurons used to give\nuniversality to 67 for spiking neural P systems and to 41 for the extended\nmodel. Here we give a small universal spiking neural P system that has only 17\nneurons and another that has extended rules with 5 neurons. All of the above\nmentioned spiking neural P systems suffer from an exponential slow down when\nsimulating Turing machines. Using a more relaxed encoding technique we get a\nuniversal spiking neural P system that has extended rules with only 4 neurons.\nThis latter spiking neural P system simulates 2-counter machines in linear time\nand thus suffer from a double exponential time overhead when simulating Turing\nmachines. We show that extended spiking neural P systems with 3 neurons are\nsimulated by log-space bounded Turing machines, and so there exists no such\nuniversal system with 3 neurons. It immediately follows that our 4-neuron\nsystem is the smallest possible extended spiking neural P system that is\nuniversal. Finally, we show that if we generalise the output technique we can\ngive a universal spiking neural P system with extended rules that has only 3\nneurons. This system is also the smallest of its kind as a universal spiking\nneural P system with extended rules and generalised output is not possible with\n2 neurons.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2009 20:36:55 GMT"}, {"version": "v2", "created": "Sun, 16 May 2010 14:33:32 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Neary", "Turlough", ""]]}, {"id": "0912.0746", "submitter": "J\\'er\\'emie Roland", "authors": "Boris Altshuler, Hari Krovi and Jeremie Roland", "title": "Anderson localization casts clouds over adiabatic quantum optimization", "comments": "14 pages, 4 figures", "journal-ref": "Proceedings of the National Academy of Sciences of the United\n  States of America, 107(28):12446-12450, 2010", "doi": "10.1073/pnas.1002116107", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding NP-complete problems is a central topic in computer science.\nThis is why adiabatic quantum optimization has attracted so much attention, as\nit provided a new approach to tackle NP-complete problems using a quantum\ncomputer. The efficiency of this approach is limited by small spectral gaps\nbetween the ground and excited states of the quantum computer's Hamiltonian. We\nshow that the statistics of the gaps can be analyzed in a novel way, borrowed\nfrom the study of quantum disordered systems in statistical mechanics. It turns\nout that due to a phenomenon similar to Anderson localization, exponentially\nsmall gaps appear close to the end of the adiabatic algorithm for large random\ninstances of NP-complete problems. This implies that unfortunately, adiabatic\nquantum optimization fails: the system gets trapped in one of the numerous\nlocal minima.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2009 22:31:36 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Altshuler", "Boris", ""], ["Krovi", "Hari", ""], ["Roland", "Jeremie", ""]]}, {"id": "0912.0928", "submitter": "Turlough Neary", "authors": "Turlough Neary", "title": "On the computational complexity of spiking neural P systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that there is no standard spiking neural P system that simulates\nTuring machines with less than exponential time and space overheads. The\nspiking neural P systems considered here have a constant number of neurons that\nis independent of the input length. Following this we construct a universal\nspiking neural P system with exhaustive use of rules that simulates Turing\nmachines in linear time and has only 10 neurons.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2009 20:15:28 GMT"}], "update_date": "2009-12-07", "authors_parsed": [["Neary", "Turlough", ""]]}, {"id": "0912.0965", "submitter": "Adam Smith", "authors": "Venkatesan Guruswami and Adam Smith", "title": "Explicit Capacity-achieving Codes for Worst-Case Additive Errors", "comments": "This preprint has been withdrawn since it is superseded by\n  arXiv:1004.4017 [cs.IT] (same authors), which contains significantly more\n  general results. This preprint will no longer be updated by the authors.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For every p in (0,1/2), we give an explicit construction of binary codes of\nrate approaching \"capacity\" 1-H(p) that enable reliable communication in the\npresence of worst-case additive errors}, caused by a channel oblivious to the\ncodeword (but not necessarily the message). Formally, we give an efficient\n\"stochastic\" encoding E(\\cdot,\\cdot) of messages combined with a small number\nof auxiliary random bits, such that for every message m and every error vector\ne (that could depend on m) that contains at most a fraction p of ones, w.h.p\nover the random bits r chosen by the encoder, m can be efficiently recovered\nfrom the corrupted codeword E(m,r) + e by a decoder without knowledge of the\nencoder's randomness r.\n  Our construction for additive errors also yields explicit deterministic codes\nof rate approaching 1-H(p) for the \"average error\" criterion: for every error\nvector e of at most p fraction 1's, most messages m can be efficiently\n(uniquely) decoded from the corrupted codeword C(m)+e. Note that such codes\ncannot be linear, as the bad error patterns for all messages are the same in a\nlinear code. We also give a new proof of the existence of such codes based on\nlist decoding and certain algebraic manipulation detection codes. Our proof is\nsimpler than the previous proofs from the literature on arbitrarily varying\nchannels.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2009 00:31:48 GMT"}, {"version": "v2", "created": "Sat, 1 May 2010 03:04:23 GMT"}], "update_date": "2010-05-04", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Smith", "Adam", ""]]}, {"id": "0912.1050", "submitter": "Panos Giannopoulos", "authors": "M. Fellows, P. Giannopoulos, C. Knauer, C. Paul, F. Rosamond, S.\n  Whitesides, N. Yu", "title": "Abstract Milling with Turn Costs", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Abstract Milling problem is a natural and quite general graph-theoretic\nmodel for geometric milling problems. Given a graph, one asks for a walk that\ncovers all its vertices with a minimum number of turns, as specified in the\ngraph model by a 0/1 turncost function fx at each vertex x giving, for each\nordered pair of edges (e,f) incident at x, the turn cost at x of a walk that\nenters the vertex on edge e and departs on edge f. We describe an initial study\nof the parameterized complexity of the problem. Our main positive result shows\nthat Abstract Milling, parameterized by: number of turns, treewidth and maximum\ndegree, is fixed-parameter tractable, We also show that Abstract Milling\nparameterized by (only) the number of turns and the pathwidth, is hard for W[1]\n-- one of the few parameterized intractability results for bounded pathwidth.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2009 20:15:21 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Fellows", "M.", ""], ["Giannopoulos", "P.", ""], ["Knauer", "C.", ""], ["Paul", "C.", ""], ["Rosamond", "F.", ""], ["Whitesides", "S.", ""], ["Yu", "N.", ""]]}, {"id": "0912.1329", "submitter": "Jian Li", "authors": "Samir Kuller, Jian Li, Barna Saha", "title": "Energy Efficient Scheduling via Partial Shutdown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by issues of saving energy in data centers we define a collection\nof new problems referred to as \"machine activation\" problems. The central\nframework we introduce considers a collection of $m$ machines (unrelated or\nrelated) with each machine $i$ having an {\\em activation cost} of $a_i$. There\nis also a collection of $n$ jobs that need to be performed, and $p_{i,j}$ is\nthe processing time of job $j$ on machine $i$. We assume that there is an\nactivation cost budget of $A$ -- we would like to {\\em select} a subset $S$ of\nthe machines to activate with total cost $a(S) \\le A$ and {\\em find} a schedule\nfor the $n$ jobs on the machines in $S$ minimizing the makespan (or any other\nmetric).\n  For the general unrelated machine activation problem, our main results are\nthat if there is a schedule with makespan $T$ and activation cost $A$ then we\ncan obtain a schedule with makespan $\\makespanconstant T$ and activation cost\n$\\costconstant A$, for any $\\epsilon >0$. We also consider assignment costs for\njobs as in the generalized assignment problem, and using our framework, provide\nalgorithms that minimize the machine activation and the assignment cost\nsimultaneously. In addition, we present a greedy algorithm which only works for\nthe basic version and yields a makespan of $2T$ and an activation cost $A\n(1+\\ln n)$.\n  For the uniformly related parallel machine scheduling problem, we develop a\npolynomial time approximation scheme that outputs a schedule with the property\nthat the activation cost of the subset of machines is at most $A$ and the\nmakespan is at most $(1+\\epsilon) T$ for any $\\epsilon >0$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2009 20:24:24 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Kuller", "Samir", ""], ["Li", "Jian", ""], ["Saha", "Barna", ""]]}, {"id": "0912.1403", "submitter": "Madhur Tulsiani", "authors": "Amit Deshpande, Kasturi Varadarajan, Madhur Tulsiani, Nisheeth K.\n  Vishnoi", "title": "Algorithms and Hardness for Subspace Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subspace approximation problem Subspace($k$,$p$) asks for a\n$k$-dimensional linear subspace that fits a given set of points optimally,\nwhere the error for fitting is a generalization of the least squares fit and\nuses the $\\ell_{p}$ norm instead. Most of the previous work on subspace\napproximation has focused on small or constant $k$ and $p$, using coresets and\nsampling techniques from computational geometry.\n  In this paper, extending another line of work based on convex relaxation and\nrounding, we give a polynomial time algorithm, \\emph{for any $k$ and any $p\n\\geq 2$}, with the approximation guarantee roughly $\\gamma_{p} \\sqrt{2 -\n\\frac{1}{n-k}}$, where $\\gamma_{p}$ is the $p$-th moment of a standard normal\nrandom variable N(0,1). We show that the convex relaxation we use has an\nintegrality gap (or \"rank gap\") of $\\gamma_{p} (1 - \\epsilon)$, for any\nconstant $\\epsilon > 0$. Finally, we show that assuming the Unique Games\nConjecture, the subspace approximation problem is hard to approximate within a\nfactor better than $\\gamma_{p} (1 - \\epsilon)$, for any constant $\\epsilon >\n0$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2009 04:54:17 GMT"}, {"version": "v2", "created": "Thu, 30 Dec 2010 12:34:41 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Deshpande", "Amit", ""], ["Varadarajan", "Kasturi", ""], ["Tulsiani", "Madhur", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "0912.1523", "submitter": "Franklin Marquezino", "authors": "G. Abal, R. Donangelo, F.L. Marquezino, A.C. Oliveira, R. Portugal", "title": "Decoherence in Search Algorithms", "comments": "14 pages, presented at 36th Seminar on Software and Hardware\n  (SEMISH), XXIX Brazilian Computer Society Congress, Bento Concalves, Brazil", "journal-ref": "Proceedings of the XXIX Brazilian Computer Society Congress\n  (SEMISH), 2009, pages 293-306", "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently several quantum search algorithms based on quantum walks were\nproposed. Those algorithms differ from Grover's algorithm in many aspects. The\ngoal is to find a marked vertex in a graph faster than classical algorithms.\nSince the implementation of those new algorithms in quantum computers or in\nother quantum devices is error-prone, it is important to analyze their\nrobustness under decoherence. In this work we analyze the impact of decoherence\non quantum search algorithms implemented on two-dimensional grids and on\nhypercubes.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2009 15:32:26 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Abal", "G.", ""], ["Donangelo", "R.", ""], ["Marquezino", "F. L.", ""], ["Oliveira", "A. C.", ""], ["Portugal", "R.", ""]]}, {"id": "0912.1776", "submitter": "Rajsekar Manokaran", "authors": "Amit Kumar, Rajsekar Manokaran, Madhur Tulsiani, Nisheeth K. Vishnoi", "title": "On the Optimality of a Class of LP-based Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we will be concerned with a class of packing and covering\nproblems which includes Vertex Cover and Independent Set. Typically, one can\nwrite an LP relaxation and then round the solution. In this paper, we explain\nwhy the simple LP-based rounding algorithm for the \\\\VC problem is optimal\nassuming the UGC. Complementing Raghavendra's result, our result generalizes to\na class of strict, covering/packing type CSPs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2009 15:49:04 GMT"}], "update_date": "2009-12-10", "authors_parsed": [["Kumar", "Amit", ""], ["Manokaran", "Rajsekar", ""], ["Tulsiani", "Madhur", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "0912.2565", "submitter": "Maurice  Jansen", "authors": "Maurice Jansen and Youming Qiao and Jayalal Sarma", "title": "Deterministic Identity Testing of Read-Once Algebraic Branching Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study polynomial identity testing of sums of $k$ read-once\nalgebraic branching programs ($\\Sigma_k$-RO-ABPs), generalizing the work in\n(Shpilka and Volkovich 2008,2009), who considered sums of $k$ read-once\nformulas ($\\Sigma_k$-RO-formulas). We show that $\\Sigma_k$-RO-ABPs are strictly\nmore powerful than $\\Sigma_k$-RO-formulas, for any $k \\leq \\lfloor n/2\\rfloor$,\nwhere $n$ is the number of variables. We obtain the following results:\n  1) Given free access to the RO-ABPs in the sum, we get a deterministic\nalgorithm that runs in time $O(k^2n^7s) + n^{O(k)}$, where $s$ bounds the size\nof any largest RO-ABP given on the input. This implies we have a deterministic\npolynomial time algorithm for testing whether the sum of a constant number of\nRO-ABPs computes the zero polynomial.\n  2) Given black-box access to the RO-ABPs computing the individual polynomials\nin the sum, we get a deterministic algorithm that runs in time $k^2n^{O(\\log\nn)} + n^{O(k)}$.\n  3) Finally, given only black-box access to the polynomial computed by the sum\nof the $k$ RO-ABPs, we obtain an $n^{O(k + \\log n)}$ time deterministic\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2009 02:10:50 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Jansen", "Maurice", ""], ["Qiao", "Youming", ""], ["Sarma", "Jayalal", ""]]}, {"id": "0912.2607", "submitter": "Bruno Grenet", "authors": "Bruno Grenet (LIP), Pascal Koiran (LIP), Natacha Portier (LIP)", "title": "The Multivariate Resultant is NP-hard in any Characteristic", "comments": "13 pages", "journal-ref": "Dans Mathematical Foundations of Computer Science 2010 -\n  Mathematical Foundations of Computer Science 2010, Brno : Czech Republic\n  (2010)", "doi": "10.1007/978-3-642-15155-2_42", "report-no": "RRLIP2009-34", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multivariate resultant is a fundamental tool of computational algebraic\ngeometry. It can in particular be used to decide whether a system of n\nhomogeneous equations in n variables is satisfiable (the resultant is a\npolynomial in the system's coefficients which vanishes if and only if the\nsystem is satisfiable). In this paper we present several NP-hardness results\nfor testing whether a multivariate resultant vanishes, or equivalently for\ndeciding whether a square system of homogeneous equations is satisfiable. Our\nmain result is that testing the resultant for zero is NP-hard under\ndeterministic reductions in any characteristic, for systems of low-degree\npolynomials with coefficients in the ground field (rather than in an\nextension). We also observe that in characteristic zero, this problem is in the\nArthur-Merlin class AM if the generalized Riemann hypothesis holds true. In\npositive characteristic, the best upper bound remains PSPACE.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2009 10:30:25 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2010 08:34:14 GMT"}, {"version": "v3", "created": "Thu, 4 Oct 2012 19:15:16 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Grenet", "Bruno", "", "LIP"], ["Koiran", "Pascal", "", "LIP"], ["Portier", "Natacha", "", "LIP"]]}, {"id": "0912.2652", "submitter": "Saugata Basu", "authors": "Saugata Basu", "title": "A complex analogue of Toda's Theorem", "comments": "31 pages. Final version to appear in Foundations of Computational\n  Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC math.AT math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toda \\cite{Toda} proved in 1989 that the (discrete) polynomial time\nhierarchy, $\\mathbf{PH}$, is contained in the class $\\mathbf{P}^{#\\mathbf{P}}$,\nnamely the class of languages that can be decided by a Turing machine in\npolynomial time given access to an oracle with the power to compute a function\nin the counting complexity class $#\\mathbf{P}$. This result, which illustrates\nthe power of counting is considered to be a seminal result in computational\ncomplexity theory. An analogous result (with a compactness hypothesis) in the\ncomplexity theory over the reals (in the sense of Blum-Shub-Smale real machines\n\\cite{BSS89}) was proved in \\cite{BZ09}. Unlike Toda's proof in the discrete\ncase, which relied on sophisticated combinatorial arguments, the proof in\n\\cite{BZ09} is topological in nature in which the properties of the topological\njoin is used in a fundamental way. However, the constructions used in\n\\cite{BZ09} were semi-algebraic -- they used real inequalities in an essential\nway and as such do not extend to the complex case. In this paper, we extend the\ntechniques developed in \\cite{BZ09} to the complex projective case. A key role\nis played by the complex join of quasi-projective complex varieties. As a\nconsequence we obtain a complex analogue of Toda's theorem. The results\ncontained in this paper, taken together with those contained in \\cite{BZ09},\nillustrate the central role of the Poincar\\'e polynomial in algorithmic\nalgebraic geometry, as well as, in computational complexity theory over the\ncomplex and real numbers -- namely, the ability to compute it efficiently\nenables one to decide in polynomial time all languages in the (compact)\npolynomial hierarchy over the appropriate field.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2009 14:50:38 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2009 14:31:03 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2009 21:43:13 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2009 22:08:56 GMT"}, {"version": "v5", "created": "Sun, 3 Jan 2010 16:46:48 GMT"}, {"version": "v6", "created": "Mon, 1 Mar 2010 18:49:53 GMT"}, {"version": "v7", "created": "Fri, 14 Oct 2011 10:06:57 GMT"}], "update_date": "2011-10-17", "authors_parsed": [["Basu", "Saugata", ""]]}, {"id": "0912.2709", "submitter": "Daniel Kane", "authors": "Daniel M. Kane", "title": "The Gaussian Surface Area and Noise Sensitivity of Degree-$d$\n  Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide asymptotically sharp bounds for the Gaussian surface area and the\nGaussian noise sensitivity of polynomial threshold functions. In particular we\nshow that if $f$ is a degree-$d$ polynomial threshold function, then its\nGaussian sensitivity at noise rate $\\epsilon$ is less than some quantity\nasymptotic to $\\frac{d\\sqrt{2\\epsilon}}{\\pi}$ and the Gaussian surface area is\nat most $\\frac{d}{\\sqrt{2\\pi}}$. Furthermore these bounds are asymptotically\ntight as $\\epsilon\\to 0$ and $f$ the threshold function of a product of $d$\ndistinct homogeneous linear functions.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2009 19:14:03 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Kane", "Daniel M.", ""]]}, {"id": "0912.3004", "submitter": "Panagiotis Cheilaris", "authors": "Panagiotis Cheilaris and Geza Toth", "title": "Graph unique-maximum and conflict-free colorings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the relationship between two kinds of vertex colorings of\ngraphs: unique-maximum colorings and conflict-free colorings. In a\nunique-maximum coloring, the colors are ordered, and in every path of the graph\nthe maximum color appears only once. In a conflict-free coloring, in every path\nof the graph there is a color that appears only once. We also study\ncomputational complexity aspects of conflict-free colorings and prove a\ncompleteness result. Finally, we improve lower bounds for those chromatic\nnumbers of the grid graph.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2009 21:01:42 GMT"}], "update_date": "2009-12-17", "authors_parsed": [["Cheilaris", "Panagiotis", ""], ["Toth", "Geza", ""]]}, {"id": "0912.3134", "submitter": "Michael Thomas", "authors": "Nadia Creignou, Johannes Schmidt, Michael Thomas", "title": "Complexity of Propositional Abduction for Restricted Sets of Boolean\n  Functions", "comments": "Proceedings version, the journal version is available at\n  http://arxiv.org/abs/1006.4923", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abduction is a fundamental and important form of non-monotonic reasoning.\nGiven a knowledge base explaining how the world behaves it aims at finding an\nexplanation for some observed manifestation. In this paper we focus on\npropositional abduction, where the knowledge base and the manifestation are\nrepresented by propositional formulae. The problem of deciding whether there\nexists an explanation has been shown to be SigmaP2-complete in general. We\nconsider variants obtained by restricting the allowed connectives in the\nformulae to certain sets of Boolean functions. We give a complete\nclassification of the complexity for all considerable sets of Boolean\nfunctions. In this way, we identify easier cases, namely NP-complete and\npolynomial cases; and we highlight sources of intractability. Further, we\naddress the problem of counting the explanations and draw a complete picture\nfor the counting complexity.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2009 13:28:23 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2010 20:58:09 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2010 14:24:20 GMT"}, {"version": "v4", "created": "Mon, 28 Jun 2010 13:32:20 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Creignou", "Nadia", ""], ["Schmidt", "Johannes", ""], ["Thomas", "Michael", ""]]}, {"id": "0912.3162", "submitter": "Lance Fortnow", "authors": "Harry Buhrman and Lance Fortnow and Michal Kouck\\'y and Bruno Loff", "title": "Derandomizing from Random Strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper we show that BPP is truth-table reducible to the set of\nKolmogorov random strings R_K. It was previously known that PSPACE, and hence\nBPP is Turing-reducible to R_K. The earlier proof relied on the adaptivity of\nthe Turing-reduction to find a Kolmogorov-random string of polynomial length\nusing the set R_K as oracle. Our new non-adaptive result relies on a new\nfundamental fact about the set R_K, namely each initial segment of the\ncharacteristic sequence of R_K is not compressible by recursive means. As a\npartial converse to our claim we show that strings of high\nKolmogorov-complexity when used as advice are not much more useful than\nrandomly chosen strings.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2009 15:15:20 GMT"}], "update_date": "2009-12-17", "authors_parsed": [["Buhrman", "Harry", ""], ["Fortnow", "Lance", ""], ["Kouck\u00fd", "Michal", ""], ["Loff", "Bruno", ""]]}, {"id": "0912.3310", "submitter": "David Kempe", "authors": "David Kempe, Mahyar Salek, Cristopher Moore", "title": "Frugal and Truthful Auctions for Vertex Covers, Flows, and Cuts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study truthful mechanisms for hiring a team of agents in three classes of\nset systems: Vertex Cover auctions, k-flow auctions, and cut auctions. For\nVertex Cover auctions, the vertices are owned by selfish and rational agents,\nand the auctioneer wants to purchase a vertex cover from them. For k-flow\nauctions, the edges are owned by the agents, and the auctioneer wants to\npurchase k edge-disjoint s-t paths, for given s and t. In the same setting, for\ncut auctions, the auctioneer wants to purchase an s-t cut. Only the agents know\ntheir costs, and the auctioneer needs to select a feasible set and payments\nbased on bids made by the agents.\n  We present constant-competitive truthful mechanisms for all three set\nsystems. That is, the maximum overpayment of the mechanism is within a constant\nfactor of the maximum overpayment of any truthful mechanism, for every set\nsystem in the class. The mechanism for Vertex Cover is based on scaling each\nbid by a multiplier derived from the dominant eigenvector of a certain matrix.\nThe mechanism for k-flows prunes the graph to be minimally (k+1)-connected, and\nthen applies the Vertex Cover mechanism. Similarly, the mechanism for cuts\ncontracts the graph until all s-t paths have length exactly 2, and then applies\nthe Vertex Cover mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2009 02:40:36 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2011 07:23:15 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Kempe", "David", ""], ["Salek", "Mahyar", ""], ["Moore", "Cristopher", ""]]}, {"id": "0912.3627", "submitter": "Andrey Voronenko A.", "authors": "Andrey A. Voronenko", "title": "New Learning and Testing Problems for Read-Once Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we consider several types of queries for classical and new\nproblems of learning and testing read-once functions. In several cases, the\nborder between polynomial and exponential complexities is obtained.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2009 09:58:55 GMT"}], "update_date": "2009-12-21", "authors_parsed": [["Voronenko", "Andrey A.", ""]]}, {"id": "0912.3730", "submitter": "Jean-Camille Birget", "authors": "Jean-Camille Birget", "title": "On the circuit-size of inverses", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reprove a result of Boppana and Lagarias: If Pi_2^P is different from\nSigma_2^P then there exists a partial function f that is computable by a\npolynomial-size family of circuits, but no inverse of f is computable by a\npolynomial-size family of circuits. We strengthen this result by showing that\nthere exist length-preserving total functions that are one-way by circuit size\nand that are computable in uniform polynomial time. We also prove, if Pi_2^P is\ndifferent from Sigma_2^P, that there exist polynomially balanced total\nsurjective functions that are one-way by circuit size; here non-uniformity is\nused.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2009 16:34:15 GMT"}, {"version": "v2", "created": "Thu, 24 Feb 2011 19:13:53 GMT"}], "update_date": "2011-02-25", "authors_parsed": [["Birget", "Jean-Camille", ""]]}, {"id": "0912.3802", "submitter": "Laszlo Egri Mr.", "authors": "Laszlo Egri, Andrei Krokhin, Benoit Larose, Pascal Tesson", "title": "The complexity of the list homomorphism problem for graphs", "comments": "12 pages, STACS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We completely classify the computational complexity of the list H-colouring\nproblem for graphs (with possible loops) in combinatorial and algebraic terms:\nfor every graph H the problem is either NP-complete, NL-complete, L-complete or\nis first-order definable; descriptive complexity equivalents are given as well\nvia Datalog and its fragments. Our algebraic characterisations match important\nconjectures in the study of constraint satisfaction problems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2009 21:14:52 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2010 21:20:05 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2010 08:59:14 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Egri", "Laszlo", ""], ["Krokhin", "Andrei", ""], ["Larose", "Benoit", ""], ["Tesson", "Pascal", ""]]}, {"id": "0912.4084", "submitter": "Charles Sauerbier", "authors": "Charles Sauerbier", "title": "Computing an Integer Prime Factoring in O(n^2.5)", "comments": "This paper has been withdrawn by the author. Paper is withdrawn. On\n  review the paper contributes nothing of significance. The runtime analysis of\n  the algorithms presented, while correct in terms of number of operations,\n  does not represent the complexity of the algorithms in terms of \"bits input\".\n  A naive mistake in reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paper is withdrawn. On review the paper contributes little of significance.\nThe runtime analysis of the algorithms presented, while correct in terms of\nnumber of operations, does not represent the complexity of the algorithms in\nterms of \"bits input\". A naive mistake in reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2009 06:10:33 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2010 22:42:51 GMT"}, {"version": "v3", "created": "Thu, 28 Jul 2011 14:07:24 GMT"}], "update_date": "2011-07-29", "authors_parsed": [["Sauerbier", "Charles", ""]]}, {"id": "0912.4117", "submitter": "Stefan G\\\"oller", "authors": "Stefan G\\\"oller, Markus Lohrey", "title": "Branching-time model checking of one-counter processes", "comments": null, "journal-ref": null, "doi": null, "report-no": "STACS 2010", "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  One-counter processes (OCPs) are pushdown processes which operate only on a\nunary stack alphabet. We study the computational complexity of model checking\ncomputation tree logic (CTL) over OCPs. A PSPACE upper bound is inherited from\nthe modal mu-calculus for this problem. First, we analyze the periodic\nbehaviour of CTL over OCPs and derive a model checking algorithm whose running\ntime is exponential only in the number of control locations and a syntactic\nnotion of the formula that we call leftward until depth. Thus, model checking\nfixed OCPs against CTL formulas with a fixed leftward until depth is in P. This\ngeneralizes a result of the first author, Mayr, and To for the expression\ncomplexity of CTL's fragment EF. Second, we prove that already over some fixed\nOCP, CTL model checking is PSPACE-hard. Third, we show that there already\nexists a fixed CTL formula for which model checking of OCPs is PSPACE-hard. For\nthe latter, we employ two results from complexity theory: (i) Converting a\nnatural number in Chinese remainder presentation into binary presentation is in\nlogspace-uniform NC^1 and (ii) PSPACE is AC^0-serializable. We demonstrate that\nour approach can be used to answer further open questions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2009 09:45:23 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 11:38:53 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["G\u00f6ller", "Stefan", ""], ["Lohrey", "Markus", ""]]}, {"id": "0912.4602", "submitter": "Prajakta Nimbhorkar", "authors": "Bireswar Das, Samir Datta, Prajakta Nimbhorkar", "title": "Log-space Algorithms for Paths and Matchings in k-trees", "comments": "Accepted in STACS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Reachability and shortest path problems are NL-complete for general graphs.\nThey are known to be in L for graphs of tree-width 2 [JT07]. However, for\ngraphs of tree-width larger than 2, no bound better than NL is known. In this\npaper, we improve these bounds for k-trees, where k is a constant. In\nparticular, the main results of our paper are log-space algorithms for\nreachability in directed k-trees, and for computation of shortest and longest\npaths in directed acyclic k-trees.\n  Besides the path problems mentioned above, we also consider the problem of\ndeciding whether a k-tree has a perfect macthing (decision version), and if so,\nfinding a perfect match- ing (search version), and prove that these two\nproblems are L-complete. These problems are known to be in P and in RNC for\ngeneral graphs, and in SPL for planar bipartite graphs [DKR08].\n  Our results settle the complexity of these problems for the class of k-trees.\nThe results are also applicable for bounded tree-width graphs, when a\ntree-decomposition is given as input. The technique central to our algorithms\nis a careful implementation of divide-and-conquer approach in log-space, along\nwith some ideas from [JT07] and [LMR07].\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2009 10:58:08 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 14:21:12 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Das", "Bireswar", ""], ["Datta", "Samir", ""], ["Nimbhorkar", "Prajakta", ""]]}, {"id": "0912.4807", "submitter": "Arthur Schmidt", "authors": "Arthur Schmidt", "title": "Quantum Algorithms for many-to-one Functions to Solve the Regulator and\n  the Principal Ideal Problem", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new quantum algorithms to solve the regulator and the principal\nideal problem in a real-quadratic number field. We improve the algorithms\nproposed by Hallgren by using two different techniques. The first improvement\nis the usage of a period function which is not one-to-one on its period. We\nshow that even in this case Shor's algorithm computes the period with constant\nprobability. The second improvement is the usage of reduced forms (a, b, c) of\ndiscriminant D with a>0 instead of reduced ideals of the same discriminant.\nThese improvements reduce the number of required qubits by at least 2 log D.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2009 08:44:40 GMT"}], "update_date": "2009-12-25", "authors_parsed": [["Schmidt", "Arthur", ""]]}, {"id": "0912.4865", "submitter": "Florent Krzakala", "authors": "T. Jorg, F. Krzakala, J. Kurchan, A. C. Maggs and J. Pujos", "title": "Energy gaps in quantum first-order mean-field-like transitions: The\n  problems that quantum annealing cannot solve", "comments": "6 pages, 3 figures", "journal-ref": "EPL, 89 (2010) 40004", "doi": "10.1209/0295-5075/89/40004", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study first-order quantum phase transitions in models where the mean-field\ntraitment is exact, and the exponentially fast closure of the energy gap with\nthe system size at the transition. We consider exactly solvable ferromagnetic\nmodels, and show that they reduce to the Grover problem in a particular limit.\nWe compute the coefficient in the exponential closure of the gap using an\ninstantonic approach, and discuss the (dire) consequences for quantum\nannealing.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2009 14:08:15 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2010 20:53:48 GMT"}], "update_date": "2010-03-12", "authors_parsed": [["Jorg", "T.", ""], ["Krzakala", "F.", ""], ["Kurchan", "J.", ""], ["Maggs", "A. C.", ""], ["Pujos", "J.", ""]]}, {"id": "0912.4884", "submitter": "Raghu Meka", "authors": "Prahladh Harsha, Adam Klivans and Raghu Meka", "title": "An Invariance Principle for Polytopes", "comments": "Added a lowerbound and minor corrections", "journal-ref": "JACM, 59(6):29, 2012", "doi": "10.1145/2395116.2395118", "report-no": null, "categories": "cs.CC cs.CG cs.DM cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let X be randomly chosen from {-1,1}^n, and let Y be randomly chosen from the\nstandard spherical Gaussian on R^n. For any (possibly unbounded) polytope P\nformed by the intersection of k halfspaces, we prove that\n  |Pr [X belongs to P] - Pr [Y belongs to P]| < log^{8/5}k * Delta, where Delta\nis a parameter that is small for polytopes formed by the intersection of\n\"regular\" halfspaces (i.e., halfspaces with low influence). The novelty of our\ninvariance principle is the polylogarithmic dependence on k. Previously, only\nbounds that were at least linear in k were known. We give two important\napplications of our main result: (1) A polylogarithmic in k bound on the\nBoolean noise sensitivity of intersections of k \"regular\" halfspaces (previous\nwork gave bounds linear in k). (2) A pseudorandom generator (PRG) with seed\nlength O((log n)*poly(log k,1/delta)) that delta-fools all polytopes with k\nfaces with respect to the Gaussian distribution. We also obtain PRGs with\nsimilar parameters that fool polytopes formed by intersection of regular\nhalfspaces over the hypercube. Using our PRG constructions, we obtain the first\ndeterministic quasi-polynomial time algorithms for approximately counting the\nnumber of solutions to a broad class of integer programs, including dense\ncovering problems and contingency tables.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2009 15:35:56 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2012 23:33:10 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Harsha", "Prahladh", ""], ["Klivans", "Adam", ""], ["Meka", "Raghu", ""]]}, {"id": "0912.4935", "submitter": "Minghui Jiang", "authors": "Minghui Jiang", "title": "Inapproximability of maximal strip recovery", "comments": "A preliminary version of this paper appeared in two parts in the\n  Proceedings of the 20th International Symposium on Algorithms and Computation\n  (ISAAC 2009) and the Proceedings of the 4th International Frontiers of\n  Algorithmics Workshop (FAW 2010)", "journal-ref": null, "doi": "10.1007/978-3-642-14553-7_8", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In comparative genomic, the first step of sequence analysis is usually to\ndecompose two or more genomes into syntenic blocks that are segments of\nhomologous chromosomes. For the reliable recovery of syntenic blocks, noise and\nambiguities in the genomic maps need to be removed first. Maximal Strip\nRecovery (MSR) is an optimization problem proposed by Zheng, Zhu, and Sankoff\nfor reliably recovering syntenic blocks from genomic maps in the midst of noise\nand ambiguities. Given $d$ genomic maps as sequences of gene markers, the\nobjective of \\msr{d} is to find $d$ subsequences, one subsequence of each\ngenomic map, such that the total length of syntenic blocks in these\nsubsequences is maximized. For any constant $d \\ge 2$, a polynomial-time\n2d-approximation for \\msr{d} was previously known. In this paper, we show that\nfor any $d \\ge 2$, \\msr{d} is APX-hard, even for the most basic version of the\nproblem in which all gene markers are distinct and appear in positive\norientation in each genomic map. Moreover, we provide the first explicit lower\nbounds on approximating \\msr{d} for all $d \\ge 2$. In particular, we show that\n\\msr{d} is NP-hard to approximate within $\\Omega(d/\\log d)$. From the other\ndirection, we show that the previous 2d-approximation for \\msr{d} can be\noptimized into a polynomial-time algorithm even if $d$ is not a constant but is\npart of the input. We then extend our inapproximability results to several\nrelated problems including \\cmsr{d}, \\gapmsr{\\delta}{d}, and\n\\gapcmsr{\\delta}{d}.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2009 03:25:15 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2010 16:18:33 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2010 17:23:39 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2010 17:16:01 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Jiang", "Minghui", ""]]}, {"id": "0912.5276", "submitter": "Thomas Vidick", "authors": "Joshua Brody, Amit Chakrabarti, Oded Regev, Thomas Vidick and Ronald\n  de Wolf", "title": "Better Gap-Hamming Lower Bounds via Better Round Elimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gap Hamming Distance is a well-studied problem in communication complexity,\nin which Alice and Bob have to decide whether the Hamming distance between\ntheir respective n-bit inputs is less than n/2-sqrt(n) or greater than\nn/2+sqrt(n). We show that every k-round bounded-error communication protocol\nfor this problem sends a message of at least Omega(n/(k^2\\log k)) bits. This\nlower bound has an exponentially better dependence on the number of rounds than\nthe previous best bound, due to Brody and Chakrabarti. Our communication lower\nbound implies strong space lower bounds on algorithms for a number of data\nstream computations, such as approximating the number of distinct elements in a\nstream.\n  Subsequent to this result, the bound has been improved by some of us to the\noptimal Omega(n), independent of k, by using different techniques.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 14:12:32 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Brody", "Joshua", ""], ["Chakrabarti", "Amit", ""], ["Regev", "Oded", ""], ["Vidick", "Thomas", ""], ["de Wolf", "Ronald", ""]]}, {"id": "0912.5342", "submitter": "Marco Pedicini", "authors": "Marco Pedicini, Mario Piazza", "title": "Elementary Complexity and von Neumann Algebras", "comments": "22 pages, 2 figures, journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how a construction of an implicit complexity model can\nbe implemented using concepts coming from the core of von Neumann algebras.\nNamely, our aim is to gain an understanding of classical computation in terms\nof the hyperfinite $\\mathrm{II}_1$ factor, starting from the class of Kalmar\nrecursive functions. More methodologically, we address the problem of finding\nthe right perspective from which to view the new relation between computation\nand combinatorial aspects in operator algebras. The rich structure of discrete\ninvariants may provide a mathematical setting able to shed light on some basic\ncombinatorial phenomena that are at the basis of our understanding of\ncomplexity.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2009 17:35:53 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Pedicini", "Marco", ""], ["Piazza", "Mario", ""]]}, {"id": "0912.5514", "submitter": "Christopher Portmann", "authors": "Anindya De, Christopher Portmann, Thomas Vidick, Renato Renner", "title": "Trevisan's extractor in the presence of quantum side information", "comments": "20+10 pages; v2: extract more min-entropy, use weakly random seed;\n  v3: extended introduction, matches published version with sections somewhat\n  reordered", "journal-ref": "SIAM Journal on Computing, 41(4):915-940, 2012", "doi": "10.1137/100813683", "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomness extraction involves the processing of purely classical information\nand is therefore usually studied in the framework of classical probability\ntheory. However, such a classical treatment is generally too restrictive for\napplications, where side information about the values taken by classical random\nvariables may be represented by the state of a quantum system. This is\nparticularly relevant in the context of cryptography, where an adversary may\nmake use of quantum devices. Here, we show that the well known construction\nparadigm for extractors proposed by Trevisan is sound in the presence of\nquantum side information.\n  We exploit the modularity of this paradigm to give several concrete extractor\nconstructions, which, e.g, extract all the conditional (smooth) min-entropy of\nthe source using a seed of length poly-logarithmic in the input, or only\nrequire the seed to be weakly random.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 20:56:19 GMT"}, {"version": "v2", "created": "Thu, 4 Nov 2010 09:14:42 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2012 18:05:19 GMT"}], "update_date": "2012-08-24", "authors_parsed": [["De", "Anindya", ""], ["Portmann", "Christopher", ""], ["Vidick", "Thomas", ""], ["Renner", "Renato", ""]]}]