[{"id": "2003.00314", "submitter": "J. Maurice Rojas", "authors": "J. Maurice Rojas and Yuyu Zhu", "title": "A complexity chasm for solving univariate sparse polynomial equations\n  over $p$-adic fields", "comments": "19 pages, 3 figures. This version contains an Appendix missing from\n  the ISSAC 2021 conference version, as well as some corrections and\n  improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We reveal a complexity chasm, separating the trinomial and tetranomial cases,\nfor solving univariate sparse polynomial equations over certain local fields.\nFirst, for any fixed field\n$K\\in\\{\\mathbb{Q}_2,\\mathbb{Q}_3,\\mathbb{Q}_5,\\ldots\\}$, we prove that any\npolynomial $f\\in\\mathbb{Z}[x]$ with exactly $3$ monomial terms, degree $d$, and\nall coefficients having absolute value at most $H$, can be solved over $K$ in\ndeterministic time $O(\\log^{O(1)}(dH))$ in the classical Turing model. (The\nbest previous algorithms were of complexity exponential in $\\log d$, even for\njust counting roots in $\\mathbb{Q}_p$.) In particular, our algorithm generates\napproximations in $\\mathbb{Q}$ with bit-length $O(\\log^{O(1)}(dH))$ to all the\nroots of $f$ in $K$, and these approximations converge quadratically under\nNewton iteration. On the other hand, we give a unified family of tetranomials\nrequiring $\\Omega(d\\log H)$ digits to distinguish the base-$p$ expansions of\ntheir roots in $K$.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 17:30:26 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 17:31:30 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 19:41:55 GMT"}, {"version": "v4", "created": "Sun, 6 Jun 2021 18:43:56 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Rojas", "J. Maurice", ""], ["Zhu", "Yuyu", ""]]}, {"id": "2003.00336", "submitter": "Shrinu Kushagra", "authors": "Shrinu Kushagra", "title": "Three-dimensional matching is NP-Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The standard proof of NP-Hardness of 3DM provides a power-$4$ reduction of\n3SAT to 3DM. In this note, we provide a linear-time reduction. Under the\nexponential time hypothesis, this reduction improves the runtime lower bound\nfrom $2^{o(\\sqrt[4]{m})}$ (under the standard reduction) to $2^{o(m)}$.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 19:51:55 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Kushagra", "Shrinu", ""]]}, {"id": "2003.00644", "submitter": "Jonni Virtema", "authors": "Miika Hannula, Juha Kontinen, Jan Van den Bussche and Jonni Virtema", "title": "Descriptive complexity of real computation and probabilistic\n  independence logic", "comments": null, "journal-ref": "Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in\n  Computer Science (LICS), 2020. Association for Computing Machinery, New York,\n  NY, USA, 550-563", "doi": "10.1145/3373718.3394773", "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel variant of BSS machines called Separate Branching BSS\nmachines (S-BSS in short) and develop a Fagin-type logical characterisation for\nlanguages decidable in non-deterministic polynomial time by S-BSS machines. We\nshow that NP on S-BSS machines is strictly included in NP on BSS machines and\nthat every NP language on S-BSS machines is a countable union of closed sets in\nthe usual topology of R^n. Moreover, we establish that on Boolean inputs NP on\nS-BSS machines without real constants characterises a natural fragment of the\ncomplexity class existsR (a class of problems polynomial time reducible to the\ntrue existential theory of the reals) and hence lies between NP and PSPACE.\nFinally we apply our results to determine the data complexity of probabilistic\nindependence logic.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 03:56:38 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 03:56:36 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Hannula", "Miika", ""], ["Kontinen", "Juha", ""], ["Bussche", "Jan Van den", ""], ["Virtema", "Jonni", ""]]}, {"id": "2003.00669", "submitter": "Bin Fu", "authors": "Bin Fu", "title": "Hardness of Sparse Sets and Minimal Circuit Size Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a polynomial method on finite fields to amplify the hardness of\nspare sets in nondeterministic time complexity classes on a randomized\nstreaming model. One of our results shows that if there exists a\n$2^{n^{o(1)}}$-sparse set in $NTIME(2^{n^{o(1)}})$ that does not have any\nrandomized streaming algorithm with $n^{o(1)}$ updating time, and $n^{o(1)}$\nspace, then $NEXP\\not=BPP$, where a $f(n)$-sparse set is a language that has at\nmost $f(n)$ strings of length $n$. We also show that if MCSP is $ZPP$-hard\nunder polynomial time truth-table reductions, then $EXP\\not=ZPP$.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 05:20:27 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 00:24:05 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Fu", "Bin", ""]]}, {"id": "2003.00963", "submitter": "Caterina Viola", "authors": "Manuel Bodirsky and Marcello Mamino and Caterina Viola", "title": "Piecewise Linear Valued Constraint Satisfaction Problems with Fixed\n  Number of Variables", "comments": "10 pages. Accepted for presentation at CTW2020 and publication in\n  AIRO Springer Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many combinatorial optimisation problems can be modelled as valued constraint\nsatisfaction problems. In this paper, we present a polynomial-time algorithm\nsolving the valued constraint satisfaction problem for a fixed number of\nvariables and for piecewise linear cost functions. Our algorithm finds the\ninfimum of a piecewise linear function and decides whether it is a proper\nminimum.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 15:20:12 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Mamino", "Marcello", ""], ["Viola", "Caterina", ""]]}, {"id": "2003.01591", "submitter": "Luca Calderoni", "authors": "Luca Calderoni, Luciano Margara, Moreno Marzolla", "title": "Direct Product Primality Testing of Graphs is GI-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the computational complexity of the graph primality testing\nproblem with respect to the direct product (also known as Kronecker, cardinal\nor tensor product). In [1] Imrich proves that both primality testing and a\nunique prime factorization can be determined in polynomial time for (finite)\nconnected and nonbipartite graphs. The author states as an open problem how\nresults on the direct product of nonbipartite, connected graphs extend to\nbipartite connected graphs and to disconnected ones. In this paper we partially\nanswer this question by proving that the graph isomorphism problem is\npolynomial-time many-one reducible to the graph compositeness testing problem\n(the complement of the graph primality testing problem). As a consequence of\nthis result, we prove that the graph isomorphism problem is polynomial-time\nTuring reducible to the primality testing problem. Our results show that\nconnectedness plays a crucial role in determining the computational complexity\nof the graph primality testing problem.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:25:46 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Calderoni", "Luca", ""], ["Margara", "Luciano", ""], ["Marzolla", "Moreno", ""]]}, {"id": "2003.02323", "submitter": "Chunxiao Li", "authors": "Chunxiao Li, Noah Fleming, Marc Vinyals, Toniann Pitassi, Vijay Ganesh", "title": "Towards a Complexity-theoretic Understanding of Restarts in SAT solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restarts are a widely-used class of techniques integral to the efficiency of\nConflict-Driven Clause Learning (CDCL) Boolean SAT solvers. While the utility\nof such policies has been well-established empirically, a theoretical\nexplanation of whether restarts are indeed crucial to the power of CDCL solvers\nis lacking. In this paper, we prove a series of theoretical results that\ncharacterize the power of restarts for various models of SAT solvers. More\nprecisely, we make the following contributions. First, we prove an exponential\nseparation between a {\\it drunk} randomized CDCL solver model with restarts and\nthe same model without restarts using a family of satisfiable instances.\nSecond, we show that the configuration of CDCL solver with VSIDS branching and\nrestarts (with activities erased after restarts) is exponentially more powerful\nthan the same configuration without restarts for a family of unsatisfiable\ninstances. To the best of our knowledge, these are the first separation results\ninvolving restarts in the context of SAT solvers. Third, we show that restarts\ndo not add any proof complexity-theoretic power vis-a-vis a number of models of\nCDCL and DPLL solvers with non-deterministic static variable and value\nselection.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 20:30:04 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 17:33:20 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Li", "Chunxiao", ""], ["Fleming", "Noah", ""], ["Vinyals", "Marc", ""], ["Pitassi", "Toniann", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2003.02524", "submitter": "Aggeliki Chalki", "authors": "Eleni Bakali and Aggeliki Chalki and Aris Pagourtzis", "title": "Characterizations and approximability of hard counting classes below #P", "comments": "18 pages, 5 figures, to be published in the proceedings of TAMC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important objective of research in counting complexity is to understand\nwhich counting problems are approximable. In this quest, the complexity class\nTotP, a hard subclass of #P, is of key importance, as it contains\nself-reducible counting problems with easy decision version, thus eligible to\nbe approximable. Indeed, most problems known so far to admit an fpras fall into\nthis class.\n  An open question raised recently by the community of descriptive complexity\nis to find a logical characterization of TotP and of robust subclasses of TotP.\nIn this work we define two subclasses of TotP, in terms of descriptive\ncomplexity, both of which are robust in the sense that they have natural\ncomplete problems, which are defined in terms of satisfiability of Boolean\nformulae.\n  We then explore the relationship between the class of approximable counting\nproblems and TotP.\n  We prove that TotP $\\nsubseteq$ FPRAS if and only if NP $\\neq$ RP and FPRAS\n$\\nsubseteq$ TotP unless RP = P. To this end we introduce two ancillary classes\nthat can both be seen as counting versions of RP. We further show that\n  FPRAS lies between one of these classes and a counting version of BPP.\n  Finally, we provide a complete picture of inclusions among all the classes\ndefined or discussed in this paper with respect to different conjectures about\nthe NP vs. RP vs. P questions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 10:34:34 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 13:29:50 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Bakali", "Eleni", ""], ["Chalki", "Aggeliki", ""], ["Pagourtzis", "Aris", ""]]}, {"id": "2003.02583", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet, Nicolas Grelier, Tillmann Miltzow", "title": "Maximum Clique in Disk-Like Intersection Graphs", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of Maximum Clique in intersection graphs of convex\nobjects in the plane. On the algorithmic side, we extend the polynomial-time\nalgorithm for unit disks [Clark '90, Raghavan and Spinrad '03] to translates of\nany fixed convex set. We also generalize the efficient polynomial-time\napproximation scheme (EPTAS) and subexponential algorithm for disks [Bonnet et\nal. '18, Bonamy et al. '18] to homothets of a fixed centrally symmetric convex\nset. The main open question on that topic is the complexity of Maximum Clique\nin disk graphs. It is not known whether this problem is NP-hard. We observe\nthat, so far, all the hardness proofs for Maximum Clique in intersection graph\nclasses $\\mathcal I$ follow the same road. They show that, for every graph $G$\nof a large-enough class $\\mathcal C$, the complement of an even subdivision of\n$G$ belongs to the intersection class $\\mathcal I$. Then they conclude invoking\nthe hardness of Maximum Independent Set on the class $\\mathcal C$, and the fact\nthat the even subdivision preserves that hardness. However there is a strong\nevidence that this approach cannot work for disk graphs [Bonnet et al. '18]. We\nsuggest a new approach, based on a problem that we dub Max Interval Permutation\nAvoidance, which we prove unlikely to have a subexponential-time approximation\nscheme. We transfer that hardness to Maximum Clique in intersection graphs of\nobjects which can be either half-planes (or unit disks) or axis-parallel\nrectangles. That problem is not amenable to the previous approach. We hope that\na scaled down (merely NP-hard) variant of Max Interval Permutation Avoidance\ncould help making progress on the disk case, for instance by showing the\nNP-hardness for (convex) pseudo-disks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 12:56:26 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Grelier", "Nicolas", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "2003.02866", "submitter": "Jianer Chen", "authors": "Jianer Chen and Ying Guo and Qin Huang", "title": "Linear-Time Parameterized Algorithms with Limited Local Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new (theoretical) computational model for the study of massive\ndata processing with limited computational resources. Our model measures the\ncomplexity of reading the very large data sets in terms of the data size N and\nanalyzes the computational cost in terms of a parameter k that characterizes\nthe computational power provided by limited local computing resources. We\ndevelop new algorithmic techniques that implement algorithms for solving\nwell-known computational problems on the proposed model. In particular, we\npresent an algorithm that finds a k-matching in a general unweighted graph in\ntime O(N + k^{2.5}) and an algorithm that constructs a maximum weighted\nk-matching in a general weighted graph in time O(N + k^3 log k). Both\nalgorithms have their space complexity bounded by O(k^2).\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 19:04:57 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Chen", "Jianer", ""], ["Guo", "Ying", ""], ["Huang", "Qin", ""]]}, {"id": "2003.02962", "submitter": "Daniel Kline", "authors": "Calin Chindris, Daniel Kline", "title": "Simultaneous robust subspace recovery and semi-stability of quiver\n  representations", "comments": "Minor typos/inaccuracies fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of simultaneously finding lower-dimensional subspace\nstructures in a given $m$-tuple of possibly corrupted, high-dimensional data\nsets all of the same size. We refer to this problem as simultaneous robust\nsubspace recovery (SRSR) and provide a quiver invariant theoretic approach to\nit. We show that SRSR is a particular case of the more general problem of\neffectively deciding whether a quiver representation is semi-stable (in the\nsense of Geometric Invariant Theory) and, in case it is not, finding a\nsubrepresentation certifying in an optimal way that the representation is not\nsemi-stable. In this paper, we show that SRSR and the more general quiver\nsemi-stability problem can be solved effectively.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 23:27:18 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 20:57:27 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 20:59:25 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Chindris", "Calin", ""], ["Kline", "Daniel", ""]]}, {"id": "2003.03019", "submitter": "Jeroen Zuiddam", "authors": "Matthias Christandl, Fran\\c{c}ois Le Gall, Vladimir Lysikov, Jeroen\n  Zuiddam", "title": "Barriers for rectangular matrix multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the algorithmic problem of multiplying large matrices that are\nrectangular. We prove that the method that has been used to construct the\nfastest algorithms for rectangular matrix multiplication cannot give optimal\nalgorithms. In fact, we prove a precise numerical barrier for this method. Our\nbarrier improves the previously known barriers, both in the numerical sense, as\nwell as in its generality. We prove our result using the asymptotic spectrum of\ntensors. More precisely, we crucially make use of two families of real tensor\nparameters with special algebraic properties: the quantum functionals and the\nsupport functionals. In particular, we prove that any lower bound on the dual\nexponent of matrix multiplication $\\alpha$ via the big Coppersmith-Winograd\ntensors cannot exceed 0.625.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 03:28:04 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Christandl", "Matthias", ""], ["Gall", "Fran\u00e7ois Le", ""], ["Lysikov", "Vladimir", ""], ["Zuiddam", "Jeroen", ""]]}, {"id": "2003.03595", "submitter": "Petteri Kaski", "authors": "Andreas Bj\\\"orklund, Petteri Kaski", "title": "The Fine-Grained Complexity of Computing the Tutte Polynomial of a\n  Linear Matroid", "comments": "This version adds Theorem 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that computing the Tutte polynomial of a linear matroid of dimension\n$k$ on $k^{O(1)}$ points over a field of $k^{O(1)}$ elements requires\n$k^{\\Omega(k)}$ time unless the \\#ETH---a counting extension of the Exponential\nTime Hypothesis of Impagliazzo and Paturi [CCC 1999] due to Dell {\\em et al.}\n[ACM TALG 2014]---is false. This holds also for linear matroids that admit a\nrepresentation where every point is associated to a vector with at most two\nnonzero coordinates. We also show that the same is true for computing the Tutte\npolynomial of a binary matroid of dimension $k$ on $k^{O(1)}$ points with at\nmost three nonzero coordinates in each point's vector. This is in sharp\ncontrast to computing the Tutte polynomial of a $k$-vertex graph (that is, the\nTutte polynomial of a {\\em graphic} matroid of dimension $k$---which is\nrepresentable in dimension $k$ over the binary field so that every vector has\ntwo nonzero coordinates), which is known to be computable in $2^k k^{O(1)}$\ntime [Bj\\\"orklund {\\em et al.}, FOCS 2008]. Our lower-bound proofs proceed via\n(i) a connection due to Crapo and Rota [1970] between the number of tuples of\ncodewords of full support and the Tutte polynomial of the matroid associated\nwith the code; (ii) an earlier-established \\#ETH-hardness of counting the\nsolutions to a bipartite $(d,2)$-CSP on $n$ vertices in $d^{o(n)}$ time; and\n(iii) new embeddings of such CSP instances as questions about codewords of full\nsupport in a linear code. We complement these lower bounds with two algorithm\ndesigns. The first design computes the Tutte polynomial of a linear matroid of\ndimension~$k$ on $k^{O(1)}$ points in $k^{O(k)}$ operations. The second design\ngeneralizes the Bj\\\"orklund~{\\em et al.} algorithm and runs in\n$q^{k+1}k^{O(1)}$ time for linear matroids of dimension $k$ defined over the\n$q$-element field by $k^{O(1)}$ points with at most two nonzero coordinates\neach.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 16:04:21 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 09:35:56 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Bj\u00f6rklund", "Andreas", ""], ["Kaski", "Petteri", ""]]}, {"id": "2003.04438", "submitter": "Rafael Melo", "authors": "J. O. Cunha, H. H. Kramer, R. A. Melo", "title": "On the computational complexity of uncapacitated multi-plant lot-sizing\n  problems", "comments": null, "journal-ref": null, "doi": "10.1007/s11590-020-01615-x", "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Production and inventory planning have become crucial and challenging in\nnowadays competitive industrial and commercial sectors, especially when\nmultiple plants or warehouses are involved. In this context, this paper\naddresses the complexity of uncapacitated multi-plant lot-sizing problems. We\nconsider a multi-item uncapacitated multi-plant lot-sizing problem with fixed\ntransfer costs and show that two of its very restricted special cases are\nalready NP-hard. Namely, we show that the single-item uncapacitated multi-plant\nlot-sizing problem with a single period and the multi-item uncapacitated\ntwo-plant lot-sizing problem with fixed transfer costs are NP-hard.\nFurthermore, as a direct implication of the proven results, we also show that a\ntwo-echelon multi-item lot-sizing with joint setup costs on transportation is\nNP-hard.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 22:26:17 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Cunha", "J. O.", ""], ["Kramer", "H. H.", ""], ["Melo", "R. A.", ""]]}, {"id": "2003.04834", "submitter": "Nitin Saurabh", "authors": "Markus Bl\\\"aser, Christian Ikenmeyer, Meena Mahajan, Anurag Pandey,\n  Nitin Saurabh", "title": "Algebraic Branching Programs, Border Complexity, and Tangent Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nisan showed in 1991 that the width of a smallest noncommutative\nsingle-(source,sink) algebraic branching program (ABP) to compute a\nnoncommutative polynomial is given by the ranks of specific matrices. This\nmeans that the set of noncommutative polynomials with ABP width complexity at\nmost $k$ is Zariski-closed, an important property in geometric complexity\ntheory. It follows that approximations cannot help to reduce the required ABP\nwidth.\n  It was mentioned by Forbes that this result would probably break when going\nfrom single-(source,sink) ABPs to trace ABPs. We prove that this is correct.\nMoreover, we study the commutative monotone setting and prove a result similar\nto Nisan, but concerning the analytic closure. We observe the same behavior\nhere: The set of polynomials with ABP width complexity at most $k$ is closed\nfor single-(source,sink) ABPs and not closed for trace ABPs. The proofs reveal\nan intriguing connection between tangent spaces and the vector space of flows\non the ABP. We close with additional observations on VQP and the closure of VNP\nwhich allows us to establish a separation between the two classes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 16:31:22 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Bl\u00e4ser", "Markus", ""], ["Ikenmeyer", "Christian", ""], ["Mahajan", "Meena", ""], ["Pandey", "Anurag", ""], ["Saurabh", "Nitin", ""]]}, {"id": "2003.05023", "submitter": "Amitabh Basu", "authors": "Amitabh Basu, Michele Conforti, Marco Di Summa, Hongyi Jiang", "title": "Complexity of branch-and-bound and cutting planes in mixed-integer\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the theoretical complexity of branch-and-bound (BB) and\ncutting plane (CP) algorithms for mixed-integer optimization. In particular, we\nstudy the relative efficiency of BB and CP, when both are based on the same\nfamily of disjunctions. We extend a result of Dash to the nonlinear setting\nwhich shows that for convex 0/1 problems, CP does at least as well as BB, with\nvariable disjunctions. We sharpen this by giving instances of the stable set\nproblem where we can provably establish that CP does exponentially better than\nBB. We further show that if one moves away from 0/1 sets, this advantage of CP\nover BB disappears; there are examples where BB finishes in O(1) time, but CP\ntakes infinitely long to prove optimality, and exponentially long to get to\narbitrarily close to the optimal value (for variable disjunctions). We next\nshow that if the dimension is considered a fixed constant, then the situation\nreverses and BB does at least as well as CP (up to a polynomial blow up), no\nmatter which family of disjunctions is used. This is also complemented by\nexamples where this gap is exponential (in the size of the input data).\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 22:29:48 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 15:55:30 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Basu", "Amitabh", ""], ["Conforti", "Michele", ""], ["Di Summa", "Marco", ""], ["Jiang", "Hongyi", ""]]}, {"id": "2003.05119", "submitter": "Stella Biderman", "authors": "Stella Biderman", "title": "Magic: the Gathering is as Hard as Arithmetic", "comments": "pre-print, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magic: the Gathering is a popular and famously complicated card game about\nmagical combat. Recently, several authors including Chatterjee and Ibsen-Jensen\n(2016) and Churchill, Biderman, and Herrick (2019) have investigated the\ncomputational complexity of playing Magic optimally. In this paper we show that\nthe ``mate-in-$n$'' problem for Magic is $\\Delta^0_n$-hard and that optimal\nplay in two-player Magic is non-arithmetic in general. These results apply to\nhow real Magic is played, can be achieved using standard-size tournament legal\ndecks, and do not rely on stochasticity or hidden information. Our paper builds\nupon the construction that Churchill, Biderman, and Herrick (2019) used to show\nthat this problem was at least as hard as the halting problem.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 05:42:28 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Biderman", "Stella", ""]]}, {"id": "2003.05152", "submitter": "Shir Peleg", "authors": "Shir Peleg and Amir Shpilka", "title": "A generalized Sylvester-Gallai type theorem for quadratic polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we prove a version of the Sylvester-Gallai theorem for quadratic\npolynomials that takes us one step closer to obtaining a deterministic\npolynomial time algorithm for testing zeroness of\n$\\Sigma^{[3]}\\Pi\\Sigma\\Pi^{[2]}$ circuits. Specifically, we prove that if a\nfinite set of irreducible quadratic polynomials $\\mathcal{Q}$ satisfy that for\nevery two polynomials $Q_1,Q_2\\in \\mathcal{Q}$ there is a subset\n$\\mathcal{K}\\subset \\mathcal{Q}$, such that $Q_1,Q_2 \\notin \\mathcal{K}$ and\nwhenever $Q_1$ and $Q_2$ vanish then also $\\prod_{i\\in \\mathcal{K}} Q_i$\nvanishes, then the linear span of the polynomials in $\\mathcal{Q}$ has\ndimension $O(1)$. This extends the earlier result [Shpilka19] that showed a\nsimilar conclusion when $|\\mathcal{K}| = 1$.\n  An important technical step in our proof is a theorem classifying all the\npossible cases in which a product of quadratic polynomials can vanish when two\nother quadratic polynomials vanish. I.e., when the product is in the radical of\nthe ideal generates by the two quadratics. This step extends a result from\n[Shpilka19]that studied the case when one quadratic polynomial is in the\nradical of two other quadratics.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 08:06:52 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Peleg", "Shir", ""], ["Shpilka", "Amir", ""]]}, {"id": "2003.05269", "submitter": "Rade Vuckovac", "authors": "Rade Vuckovac", "title": "On Function Description", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main result is that: function descriptions are not made equal, and they\ncan be categorised in at least two categories using various computational\nmethods for function evaluation. The result affects Kolmogorov complexity and\nRandom Oracle Model notions. More precisely, the idea that the size of an\nobject and the size of the smallest computer program defining that object is a\nratio that represents the object complexity needs additional definitions to\nhold its original assertions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 02:44:20 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Vuckovac", "Rade", ""]]}, {"id": "2003.05575", "submitter": "Sai Vikneshwar Mani Jayaraman", "authors": "Michael Langberg, Shi Li, Sai Vikneshwar Mani Jayaraman, and Atri\n  Rudra", "title": "Topology Dependent Bounds For FAQs", "comments": "A conference version was presented at PODS 2019", "journal-ref": null, "doi": "10.1145/3294052.3319686", "report-no": null, "categories": "cs.DC cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove topology dependent bounds on the number of rounds\nneeded to compute Functional Aggregate Queries (FAQs) studied by Abo Khamis et\nal. [PODS 2016] in a synchronous distributed network under the model considered\nby Chattopadhyay et al. [FOCS 2014, SODA 2017]. Unlike the recent work on\ncomputing database queries in the Massively Parallel Computation model, in the\nmodel of Chattopadhyay et al., nodes can communicate only via private\npoint-to-point channels and we are interested in bounds that work over an {\\em\narbitrary} communication topology. This is the first work to consider more\npractically motivated problems in this distributed model. For the sake of\nexposition, we focus on two special problems in this paper: Boolean Conjunctive\nQuery (BCQ) and computing variable/factor marginals in Probabilistic Graphical\nModels (PGMs). We obtain tight bounds on the number of rounds needed to compute\nsuch queries as long as the underlying hypergraph of the query is\n$O(1)$-degenerate and has $O(1)$-arity. In particular, the $O(1)$-degeneracy\ncondition covers most well-studied queries that are efficiently computable in\nthe centralized computation model like queries with constant treewidth. These\ntight bounds depend on a new notion of `width' (namely internal-node-width) for\nGeneralized Hypertree Decompositions (GHDs) of acyclic hypergraphs, which\nminimizes the number of internal nodes in a sub-class of GHDs. To the best of\nour knowledge, this width has not been studied explicitly in the theoretical\ndatabase literature. Finally, we consider the problem of computing the product\nof a vector with a chain of matrices and prove tight bounds on its round\ncomplexity (over the finite field of two elements) using a novel min-entropy\nbased argument.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 02:23:26 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Langberg", "Michael", ""], ["Li", "Shi", ""], ["Jayaraman", "Sai Vikneshwar Mani", ""], ["Rudra", "Atri", ""]]}, {"id": "2003.05582", "submitter": "Majid Farhadi", "authors": "Majid Farhadi, Anand Louis, Prasad Tetali", "title": "On the Complexity of $\\lambda_\\infty\\,,$ Vertex Expansion, and Spread\n  Constant of Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bobkov, Houdr\\'e, and the last author introduced a Poincar\\'e-type functional\nparameter, $\\lambda_\\infty$, of a graph $G$. They related $\\lambda_\\infty$ to\nthe {\\em vertex expansion} of the graph via a Cheeger-type inequality,\nanalogous to the inequality relating the spectral gap of the graph,\n$\\lambda_2$, to its {\\em edge expansion}. While $\\lambda_2$ can be computed\nefficiently, the computational complexity of $\\lambda_\\infty$ has remained an\nopen question. Following the work of the second author with Raghavendra and\nVempala, wherein the complexity of $\\lambda_\\infty$ was related to the\nso-called small-set expansion (SSE) problem, it has been believed that\ncomputing $\\lambda_\\infty$ is a hard problem. We confirm this conjecture by\nproving that computing $\\lambda_\\infty$ is indeed NP-hard, even for weighted\ntrees.\n  Our gadget further proves NP-hardness of computing \\emph{spread constant} of\na weighted tree; i.e., a geometric measure of the graph, introduced by Alon,\nBoppana, and Spencer, in the context of deriving an asymptotic isoperimetric\ninequality of Cartesian products of graphs. We conclude this case by providing\na fully polynomial time approximation scheme.\n  We further study a generalization of spread constant in machine learning\nliterature, namely the {\\em maximum variance embedding} problem. For trees, we\nprovide fast combinatorial algorithms that avoid solving a semidefinite\nrelaxation of the problem. On the other hand, for general graphs, we propose a\nrandomized projection method that can outperform the optimal orthogonal\nprojection, i.e., PCA, classically used for rounding of the optimum lifted\nsolution (to SDP relaxation) of the problem.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 02:40:21 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 01:29:01 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Farhadi", "Majid", ""], ["Louis", "Anand", ""], ["Tetali", "Prasad", ""]]}, {"id": "2003.05706", "submitter": "Ville Salo", "authors": "Ville Salo", "title": "Four heads are better than three", "comments": "14 pages; this v2 corrects, improves, and proves Theorem 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.CC cs.FL math.GR math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct recursively-presented finitely-generated torsion groups which\nhave bounded torsion and whose word problem is conjunctive equivalent (in\nparticular positive and Turing equivalent) to a given recursively enumerable\nset. These groups can be interpreted as groups of finite state machines or as\nsubgroups of topological full groups, on effective subshifts over other torsion\ngroups. We define a recursion-theoretic property of a set of natural numbers,\ncalled impredictability, which roughly states that a Turing machine can\nenumerate numbers such that every Turing machine occasionally \"correctly\nguesses\" whether they are in the language (by halting on them or not), even if\ntrying not to, and given an oracle for shorter identities. We prove that\nimpredictable recursively enumerable sets exist. Combining these constructions\nand slightly adapting a result of [Salo and T\\\"orm\\\"a, 2017], we obtain that\nfour-headed group-walking finite-state automata can define strictly more\nsubshifts than three-headed automata on a group containing a copy of the\nintegers, confirming a conjecture of [Salo and T\\\"orm\\\"a, 2017]. These are the\nfirst examples of groups where four heads are better than one, and they show\nthe maximal height of a finite head hierarchy is indeed four.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 11:08:22 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 11:05:03 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Salo", "Ville", ""]]}, {"id": "2003.05874", "submitter": "Suryajith Chillara", "authors": "Suryajith Chillara", "title": "New Exponential Size Lower Bounds against Depth Four Circuits of Bounded\n  Individual Degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Kayal, Saha and Tavenas [Theory of Computing, 2018] showed that for all large\nenough integers $n$ and $d$ such that $d\\geq \\omega(\\log{n})$, any syntactic\ndepth four circuit of bounded individual degree $\\delta = o(d)$ that computes\nthe Iterated Matrix Multiplication polynomial ($IMM_{n,d}$) must have size\n$n^{\\Omega\\left(\\sqrt{d/\\delta}\\right)}$. Unfortunately, this bound\ndeteriorates as the value of $\\delta$ increases. Further, the bound is\nsuperpolynomial only when $\\delta$ is $o(d)$. It is natural to ask if the\ndependence on $\\delta$ in the bound could be weakened. Towards this, in an\nearlier result [STACS, 2020], we showed that for all large enough integers $n$\nand $d$ such that $d = \\Theta(\\log^2{n})$, any syntactic depth four circuit of\nbounded individual degree $\\delta\\leq n^{0.2}$ that computes $IMM_{n,d}$ must\nhave size $n^{\\Omega(\\log{n})}$.\n  In this paper, we make further progress by proving that for all large enough\nintegers $n$ and $d$, and absolute constants $a$ and $b$ such that\n$\\omega(\\log^2n)\\leq d\\leq n^{a}$, any syntactic depth four circuit of bounded\nindividual degree $\\delta\\leq n^{b}$ that computes $IMM_{n,d}$ must have size\n$n^{\\Omega(\\sqrt{d})}$. Our bound is obtained by carefully adapting the proof\nof Kumar and Saraf [SIAM J. Computing, 2017] to the complexity measure\nintroduced in our earlier work [STACS, 2020].\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 16:09:42 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 20:25:36 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chillara", "Suryajith", ""]]}, {"id": "2003.05913", "submitter": "Yannai A. Gonczarowski", "authors": "Moshe Babaioff, Michal Feldman, Yannai A. Gonczarowski, Brendan\n  Lucier, Inbal Talgam-Cohen", "title": "Escaping Cannibalization? Correlation-Robust Pricing for a Unit-Demand\n  Buyer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a robust version of the revenue maximization problem, where a\nsingle seller wishes to sell $n$ items to a single unit-demand buyer. In this\nrobust version, the seller knows the buyer's marginal value distribution for\neach item separately, but not the joint distribution, and prices the items to\nmaximize revenue in the worst case over all compatible correlation structures.\nWe devise a computationally efficient (polynomial in the support size of the\nmarginals) algorithm that computes the worst-case joint distribution for any\nchoice of item prices. And yet, in sharp contrast to the additive buyer case\n(Carroll, 2017), we show that it is NP-hard to approximate the optimal choice\nof prices to within any factor better than $n^{1/2-\\epsilon}$. For the special\ncase of marginal distributions that satisfy the monotone hazard rate property,\nwe show how to guarantee a constant fraction of the optimal worst-case revenue\nusing item pricing; this pricing equates revenue across all possible\ncorrelations and can be computed efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 17:24:56 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 20:29:09 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Babaioff", "Moshe", ""], ["Feldman", "Michal", ""], ["Gonczarowski", "Yannai A.", ""], ["Lucier", "Brendan", ""], ["Talgam-Cohen", "Inbal", ""]]}, {"id": "2003.06879", "submitter": "Zack Fitzsimmons", "authors": "Zack Fitzsimmons and Omer Lev", "title": "Selecting Voting Locations for Fun and Profit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While manipulative attacks on elections have been well-studied, only recently\nhas attention turned to attacks that account for geographic information, which\nare extremely common in the real world. The most well known in the media is\ngerrymandering, in which district border-lines are changed to increase a\nparty's chance to win, but a different geographical manipulation involves\ninfluencing the election by selecting the location of polling places, as many\npeople are not willing to go to any distance to vote. In this paper we initiate\nthe study of this manipulation. We find that while it is easy to manipulate the\nselection of polling places on the line, it becomes difficult already on the\nplane or in the case of more than two candidates. Moreover, we show that for\nmore than two candidates the problem is inapproximable. However, we find a few\nrestricted cases on the plane where some algorithms perform well. Finally, we\ndiscuss how existing results for standard control actions hold in the\ngeographic setting, consider additional control actions in the geographic\nsetting, and suggest directions for future study.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 17:49:50 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Fitzsimmons", "Zack", ""], ["Lev", "Omer", ""]]}, {"id": "2003.06993", "submitter": "Xuangui Huang", "authors": "Xuangui Huang", "title": "Space Hardness of Solving Structured Linear Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that if the probabilistic logarithmic-space solver or the\ndeterministic nearly logarithmic-space solver for undirected Laplacian matrices\ncan be extended to solve slightly larger subclasses of linear systems, then\nthey can be use to solve all linear systems with similar space complexity.\nPreviously Kyng and Zhang proved similar results in the time complexity setting\nusing reductions between approximate solvers. We prove that their reductions\ncan be implemented using constant-depth, polynomial-size threshold circuits.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 03:26:41 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Huang", "Xuangui", ""]]}, {"id": "2003.07190", "submitter": "Joergen Bang-Jensen", "authors": "Jonas Bamse Andersen and J{\\o}rgen Bang-Jensen and Anders Yeo", "title": "On the parameterized complexity of 2-partitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an FPT algorithm for deciding whether the vertex set a digraph $D$\ncan be partitioned into two disjoint sets $V_1,V_2$ such that the digraph\n$D[V_1]$ induced by $V_1$ has a vertex that can reach all other vertices by\ndirected paths, the digraph $D[V_2]$ has no vertex of in-degree zero and\n$|V_i|\\geq k_i$, where $k_1,k_2$ are part of the input. This settles an open\nproblem from[1,4].\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 13:31:07 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Andersen", "Jonas Bamse", ""], ["Bang-Jensen", "J\u00f8rgen", ""], ["Yeo", "Anders", ""]]}, {"id": "2003.07345", "submitter": "Lek-Heng Lim", "authors": "Shmuel Friedland and Lek-Heng Lim", "title": "Symmetric Grothendieck inequality", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish an analogue of the Grothendieck inequality where the rectangular\nmatrix is replaced by a symmetric/Hermitian matrix and the bilinear form by a\nquadratic form. We call this the symmetric Grothendieck inequality; despite its\nname, it is a generalization -- the original Grothendieck inequality is a\nspecial case. While there are other proposals for such an inequality, ours\ndiffers in two important ways: (i) we have no additional requirement like\npositive semidefiniteness; (ii) our symmetric Grothendieck constant is\nuniversal, i.e., independent of the matrix and its dimensions. A consequence of\nour symmetric Grothendieck inequality is a \"conic Grothendieck inequality\" for\nany family of cones of symmetric matrices: The original Grothendieck inequality\nis a special case; as is the Nesterov $\\pi/2$-Theorem, which corresponds to the\ncones of positive semidefinite matrices; as well as the Goemans-Williamson\ninequality, which corresponds to the cones of Laplacians. For yet other cones,\ne.g., of diagonally dominant matrices, we get new Grothendieck-like\ninequalities. A slight extension leads to a unified framework that treats any\nGrothendieck-like inequality as an inequality between two norms within a family\nof \"Grothendieck norms\" restricted to a family of cones. This allows us to\nplace on equal footing the Goemans-Williamson inequality, Nesterov\n$\\pi/2$-Theorem, Ben-Tal-Nemirovski-Roos $4/\\pi$-Theorem, generalized\nGrothendieck inequality, order-$p$ Grothendieck inequality, rank-constrained\npositive semidefinite Grothendieck inequality; and in turn allows us to\nsimplify proofs, extend results from real to complex, obtain new bounds or\nestablish sharpness of existing ones. The symmetric Grothendieck inequality may\nalso be applied to obtain polynomial-time approximation bounds for NP-hard\ncombinatorial, integer, and nonconvex optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 17:42:16 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Friedland", "Shmuel", ""], ["Lim", "Lek-Heng", ""]]}, {"id": "2003.07487", "submitter": "Peter Mayr", "authors": "Guofeng Deng, Ezzeddine El Sai, Trevor Manders, Peter Mayr, Poramate\n  Nakkirt, Athena Sparks", "title": "Sandwiches for Promise Constraint Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promise Constraint Satisfaction Problems (PCSP) were proposed recently by\nBrakensiek and Guruswami arXiv:1704.01937 as a framework to study\napproximations for Constraint Satisfaction Problems (CSP). Informally a PCSP\nasks to distinguish between whether a given instance of a CSP has a solution or\nnot even a specified relaxation can be satisfied. All currently known tractable\nPCSPs can be reduced in a natural way to tractable CSPs. Barto arXiv:1909.04878\npresented an example of a PCSP over Boolean structures for which this reduction\nrequires solving a CSP over an infinite structure. We give a first example of a\nPCSP over Boolean structures which reduces to a tractable CSP over a structure\nof size $3$ but not smaller. Further we investigate properties of PCSPs that\nreduce to systems of linear equations or to CSPs over structures with\nsemilattice or majority polymorphism.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 01:13:25 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Deng", "Guofeng", ""], ["Sai", "Ezzeddine El", ""], ["Manders", "Trevor", ""], ["Mayr", "Peter", ""], ["Nakkirt", "Poramate", ""], ["Sparks", "Athena", ""]]}, {"id": "2003.07903", "submitter": "Huck Bennett", "authors": "Huck Bennett, Chris Peikert", "title": "Hardness of Bounded Distance Decoding on Lattices in $\\ell_p$ Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $ \\newcommand{\\Z}{\\mathbb{Z}} \\newcommand{\\eps}{\\varepsilon}\n\\newcommand{\\cc}[1]{\\mathsf{#1}} \\newcommand{\\NP}{\\cc{NP}}\n\\newcommand{\\problem}[1]{\\mathrm{#1}} \\newcommand{\\BDD}{\\problem{BDD}}\n  $Bounded Distance Decoding $\\BDD_{p,\\alpha}$ is the problem of decoding a\nlattice when the target point is promised to be within an $\\alpha$ factor of\nthe minimum distance of the lattice, in the $\\ell_{p}$ norm. We prove that\n$\\BDD_{p, \\alpha}$ is $\\NP$-hard under randomized reductions where $\\alpha \\to\n1/2$ as $p \\to \\infty$ (and for $\\alpha=1/2$ when $p=\\infty$), thereby showing\nthe hardness of decoding for distances approaching the unique-decoding radius\nfor large $p$. We also show fine-grained hardness for $\\BDD_{p,\\alpha}$. For\nexample, we prove that for all $p \\in [1,\\infty) \\setminus 2\\Z$ and constants\n$C > 1, \\eps > 0$, there is no $2^{(1-\\eps)n/C}$-time algorithm for\n$\\BDD_{p,\\alpha}$ for some constant $\\alpha$ (which approaches $1/2$ as $p \\to\n\\infty$), assuming the randomized Strong Exponential Time Hypothesis (SETH).\nMoreover, essentially all of our results also hold (under analogous non-uniform\nassumptions) for $\\BDD$ with preprocessing, in which unbounded precomputation\ncan be applied to the lattice before the target is available.\n  Compared to prior work on the hardness of $\\BDD_{p,\\alpha}$ by Liu,\nLyubashevsky, and Micciancio (APPROX-RANDOM 2008), our results improve the\nvalues of $\\alpha$ for which the problem is known to be $\\NP$-hard for all $p >\np_1 \\approx 4.2773$, and give the very first fine-grained hardness for $\\BDD$\n(in any norm). Our reductions rely on a special family of \"locally dense\"\nlattices in $\\ell_{p}$ norms, which we construct by modifying the\ninteger-lattice sparsification technique of Aggarwal and Stephens-Davidowitz\n(STOC 2018).\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 19:23:49 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Bennett", "Huck", ""], ["Peikert", "Chris", ""]]}, {"id": "2003.08329", "submitter": "Kai Jin", "authors": "Siu-Wing Cheng and Man-Kwun Chiu and Kai Jin and Man Ting Wong", "title": "A Generalization of Self-Improving Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ailon et al. [SICOMP'11] proposed self-improving algorithms for sorting and\nDelaunay triangulation (DT) when the input instances $x_1,\\cdots,x_n$ follow\nsome unknown \\emph{product distribution}. That is, $x_i$ comes from a fixed\nunknown distribution $\\mathsf{D}_i$, and the $x_i$'s are drawn independently.\nAfter spending $O(n^{1+\\varepsilon})$ time in a learning phase, the subsequent\nexpected running time is $O((n+ H)/\\varepsilon)$, where $H \\in\n\\{H_\\mathrm{S},H_\\mathrm{DT}\\}$, and $H_\\mathrm{S}$ and $H_\\mathrm{DT}$ are the\nentropies of the distributions of the sorting and DT output, respectively. In\nthis paper, we allow dependence among the $x_i$'s under the \\emph{group product\ndistribution}. There is a hidden partition of $[1,n]$ into groups; the $x_i$'s\nin the $k$-th group are fixed unknown functions of the same hidden variable\n$u_k$; and the $u_k$'s are drawn from an unknown product distribution. We\ndescribe self-improving algorithms for sorting and DT under this model when the\nfunctions that map $u_k$ to $x_i$'s are well-behaved. After an\n$O(\\mathrm{poly}(n))$-time training phase, we achieve $O(n + H_\\mathrm{S})$ and\n$O(n\\alpha(n) + H_\\mathrm{DT})$ expected running times for sorting and DT,\nrespectively, where $\\alpha(\\cdot)$ is the inverse Ackermann function.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 16:47:31 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 14:22:19 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Cheng", "Siu-Wing", ""], ["Chiu", "Man-Kwun", ""], ["Jin", "Kai", ""], ["Wong", "Man Ting", ""]]}, {"id": "2003.08331", "submitter": "Jeffrey Bosboom", "authors": "Aviv Adler, Jeffrey Bosboom, Erik D. Demaine, Martin L. Demaine,\n  Quanquan C. Liu, Jayson Lynch", "title": "Tatamibari is NP-complete", "comments": "26 pages, 21 figures. New discussion of safe placement of wires in\n  Sections 3.2 and 3.5. To appear at the 10th International Conference on Fun\n  with Algorithms (FUN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Nikoli pencil-and-paper game Tatamibari, a puzzle consists of an $m\n\\times n$ grid of cells, where each cell possibly contains a clue among +, -,\n|. The goal is to partition the grid into disjoint rectangles, where every\nrectangle contains exactly one clue, rectangles containing + are square,\nrectangles containing - are strictly longer horizontally than vertically,\nrectangles containing | are strictly longer vertically than horizontally, and\nno four rectangles share a corner. We prove this puzzle NP-complete,\nestablishing a Nikoli gap of 16 years. Along the way, we introduce a gadget\nframework for proving hardness of similar puzzles involving area coverage, and\nshow that it applies to an existing NP-hardness proof for Spiral Galaxies. We\nalso present a mathematical puzzle font for Tatamibari.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 16:54:28 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 18:49:14 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Adler", "Aviv", ""], ["Bosboom", "Jeffrey", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Liu", "Quanquan C.", ""], ["Lynch", "Jayson", ""]]}, {"id": "2003.09266", "submitter": "Aruni Choudhary", "authors": "Man-Kwun Chiu and Aruni Choudhary and Wolfgang Mulzer", "title": "Computational Complexity of the $\\alpha$-Ham-Sandwich Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic Ham-Sandwich theorem states that for any $d$ measurable sets in\n$\\mathbb{R}^d$, there is a hyperplane that bisects them simultaneously. An\nextension by B\\'ar\\'any, Hubard, and Jer\\'onimo [DCG 2008] states that if the\nsets are convex and \\emph{well-separated}, then for any given $\\alpha_1, \\dots,\n\\alpha_d \\in [0, 1]$, there is a unique oriented hyperplane that cuts off a\nrespective fraction $\\alpha_1, \\dots, \\alpha_d$ from each set. Steiger and Zhao\n[DCG 2010] proved a discrete analogue of this theorem, which we call the\n\\emph{$\\alpha$-Ham-Sandwich theorem}. They gave an algorithm to find the\nhyperplane in time $O(n (\\log n)^{d-3})$, where $n$ is the total number of\ninput points. The computational complexity of this search problem in high\ndimensions is open, quite unlike the complexity of the Ham-Sandwich problem,\nwhich is now known to be PPA-complete (Filos-Ratsikas and Goldberg [STOC\n2019]).\n  Recently, Fearley, Gordon, Mehta, and Savani [ICALP 2019] introduced a new\nsub-class of CLS (Continuous Local Search) called \\emph{Unique End-of-Potential\nLine} (UEOPL). This class captures problems in CLS that have unique solutions.\nWe show that for the $\\alpha$-Ham-Sandwich theorem, the search problem of\nfinding the dividing hyperplane lies in UEOPL. This gives the first non-trivial\ncontainment of the problem in a complexity class and places it in the company\nof classic search problems such as finding the fixed point of a contraction\nmap, the unique sink orientation problem and the $P$-matrix linear\ncomplementarity problem.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 13:29:28 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Chiu", "Man-Kwun", ""], ["Choudhary", "Aruni", ""], ["Mulzer", "Wolfgang", ""]]}, {"id": "2003.09532", "submitter": "Mahsa Eftekhari Hesari", "authors": "Talley Amir, James Aspnes, David Doty, Mahsa Eftekhari, Eric Severson", "title": "Message complexity of population protocols", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.DISC.2020.5", "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard population protocol model assumes that when two agents interact,\neach observes the entire state of the other agent. We initiate the study of\n$\\textit{message complexity}$ for population protocols, where the state of an\nagent is divided into an externally-visible $\\textit{message}$ and an internal\ncomponent, where only the message can be observed by the other agent in an\ninteraction.\n  We consider the case of $O(1)$ message complexity. When time is unrestricted,\nwe obtain an exact characterization of the stably computable predicates based\non the number of internal states $s(n)$: If $s(n) = o(n)$ then the protocol\ncomputes semilinear predicates (unlike the original model, which can compute\nnon-semilinear predicates with $s(n) = O(\\log n)$), and otherwise it computes a\npredicate decidable by a nondeterministic $O(n \\log s(n))$-space-bounded Turing\nmachine. We then introduce novel $O(\\mathrm{polylog}(n))$ expected time\nprotocols for junta/leader election and general purpose broadcast correct with\nhigh probability, and approximate and exact population size counting correct\nwith probability 1. Finally, we show that the main constraint on the power of\nbounded-message-size protocols is the size of the internal states: with\nunbounded internal states, any computable function can be computed with\nprobability 1 in the limit by a protocol that uses only $\\textit{1-bit}$\nmessages.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 23:53:43 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 20:31:47 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 17:53:58 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Amir", "Talley", ""], ["Aspnes", "James", ""], ["Doty", "David", ""], ["Eftekhari", "Mahsa", ""], ["Severson", "Eric", ""]]}, {"id": "2003.09791", "submitter": "Tianrong Lin", "authors": "Tianrong Lin", "title": "$P\\neq NP$", "comments": "withdraw, due to the construct of language AL is not correct", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The whole discussion is divided into two parts: one is for $|\\Sigma|\\geq 2$\n(general case), and another is for $|\\Sigma|=1$ (special case). The main\ncontribution of the paper is that a series of results are obtained.\nSpecifically, we prove in general case that : (1) There exists a language\n$AL\\in NP-P$, for any language $L\\in P$, the lower bound on reducibility from\n$AL$ to $L$ is $\\Omega(m^n)$ where $m\\geq 2$ is a constant, $n=|\\omega|$ and\n$\\omega\\in\\Sigma^*$ the input; (2) There exists no polynomial-time algorithm\nfor {\\it SAT}; (3) An immediate corollary of (1) and (2) is that $P\\neq NP$,\nwhich also can be deduced from (6); (4) There exists a language $coAL\\in\ncoNP-coP$, for any language $L\\in coP$, the lower bound on reducibility from\n$coAL$ to $L$ is $\\Omega(m^n)$ where $m\\geq 2$ is a constant, $n=|\\omega|$ and\n$\\omega\\in\\Sigma^*$ the input; (5) There exists no polynomial-time algorithm\nfor {\\it TAUT}; (6) An immediate corollary of (4) and (5) is that $coP\\neq\ncoNP$;\n  We next study the problem in special case. It is shown that: (1) there exists\n$k\\in\\mathbb{N}$ and a reducibility $\\varphi$ from an arbitrary language\n$L_1\\in NP-P$ (resp.~$L_1\\in coNP-coP$) to an another arbitrary language\n$L_2\\in P$ (resp.~$L_2\\in coP$) such that $T_{\\varphi}(n)\\leq n^k+k$ where\n$n=|\\omega|$ and $\\omega\\in\\Sigma^n$ is the input; (2) an immediate corollary\nis that $P=NP$ and $coP=coNP$ in the special case.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 03:19:00 GMT"}, {"version": "v10", "created": "Tue, 30 Jun 2020 07:53:38 GMT"}, {"version": "v11", "created": "Mon, 6 Jul 2020 13:54:45 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 12:10:29 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 14:07:16 GMT"}, {"version": "v4", "created": "Mon, 20 Apr 2020 03:52:25 GMT"}, {"version": "v5", "created": "Wed, 22 Apr 2020 09:50:12 GMT"}, {"version": "v6", "created": "Mon, 27 Apr 2020 10:39:37 GMT"}, {"version": "v7", "created": "Thu, 30 Apr 2020 07:06:24 GMT"}, {"version": "v8", "created": "Mon, 18 May 2020 15:27:59 GMT"}, {"version": "v9", "created": "Fri, 29 May 2020 10:40:24 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Lin", "Tianrong", ""]]}, {"id": "2003.09877", "submitter": "Zachary Remscrim", "authors": "Zachary Remscrim (University of Chicago)", "title": "Lower Bounds on the Running Time of Two-Way Quantum Finite Automata and\n  Sublogarithmic-Space Quantum Turing Machines", "comments": "In ITCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two-way finite automaton with quantum and classical states (2QCFA),\ndefined by Ambainis and Watrous, is a model of quantum computation whose\nquantum part is extremely limited; however, as they showed, 2QCFA are\nsurprisingly powerful: a 2QCFA with only a single-qubit can recognize the\nlanguage $L_{pal}=\\{w \\in \\{a,b\\}^*:w \\text{ is a palindrome}\\}$ with bounded\nerror in expected time $2^{O(n)}$, on inputs of length $n$.\n  We prove that their result essentially cannot be improved upon: a 2QCFA (of\nany size) cannot recognize $L_{pal}$ with bounded error in expected time\n$2^{o(n)}$. To our knowledge, this is the first example of a language that can\nbe recognized with bounded error by a 2QCFA in exponential time but not in\nsubexponential time. Moreover, we prove that a quantum Turing machine (QTM)\nrunning in space $o(\\log n)$ and expected time $2^{n^{1-\\Omega(1)}}$ cannot\nrecognize $L_{pal}$ with bounded error; again, this is the first lower bound of\nits kind.\n  Far more generally, we establish a lower bound on the running time of any\n2QCFA or $o(\\log n)$-space QTM that recognizes any language $L$ in terms of a\nnatural \"hardness measure\" of $L$. This allows us to exhibit a large family of\nlanguages for which we have asymptotically matching lower and upper bounds on\nthe running time of any such 2QCFA or QTM recognizer.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 12:40:15 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 18:40:17 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Remscrim", "Zachary", "", "University of Chicago"]]}, {"id": "2003.09879", "submitter": "Zachary Remscrim", "authors": "Zachary Remscrim (MIT)", "title": "The Power of a Single Qubit: Two-way Quantum Finite Automata and the\n  Word Problem", "comments": "To appear in ICALP 2020", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2020.139", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two-way finite automaton with quantum and classical states (2QCFA),\ndefined by Ambainis and Watrous, is a model of quantum computation whose\nquantum part is extremely limited; however, as they showed, 2QCFA are\nsurprisingly powerful: a 2QCFA, with a single qubit, can recognize, with\nbounded error, the language $L_{eq}=\\{a^m b^m :m \\in \\mathbb{N}\\}$ in expected\npolynomial time and the language $L_{pal}=\\{w \\in \\{a,b\\}^*:w \\text{ is a\npalindrome}\\}$ in expected exponential time.\n  We further demonstrate the power of 2QCFA by showing that they can recognize\nthe word problems of many groups. In particular 2QCFA, with a single qubit and\nalgebraic number transition amplitudes, can recognize, with bounded error, the\nword problem of any finitely generated virtually abelian group in expected\npolynomial time, as well as the word problems of a large class of linear groups\nin expected exponential time. This latter class (properly) includes all groups\nwith context-free word problem. We also exhibit results for 2QCFA with any\nconstant number of qubits.\n  As a corollary, we obtain a direct improvement on the original Ambainis and\nWatrous result by showing that $L_{eq}$ can be recognized by a 2QCFA with\nbetter parameters. As a further corollary, we show that 2QCFA can recognize\ncertain non-context-free languages in expected polynomial time.\n  In a companion paper, we prove matching lower bounds, thereby showing that\nthe class of languages recognizable with bounded error by a 2QCFA in expected\n$\\mathit{subexponential}$ time is properly contained in the class of languages\nrecognizable with bounded error by a 2QCFA in expected $\\mathit{exponential}$\ntime.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 12:46:37 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 17:18:59 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Remscrim", "Zachary", "", "MIT"]]}, {"id": "2003.09914", "submitter": "Erik Demaine", "authors": "Josh Brunner, Lily Chung, Erik D. Demaine, Dylan Hendrickson, Adam\n  Hesterberg, Adam Suhl, Avi Zeff", "title": "1 x 1 Rush Hour with Fixed Blocks is PSPACE-complete", "comments": "15 pages, 11 figures. Improved figures and writing. To appear at FUN\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider $n^2-1$ unit-square blocks in an $n \\times n$ square board, where\neach block is labeled as movable horizontally (only), movable vertically\n(only), or immovable -- a variation of Rush Hour with only $1 \\times 1$ cars\nand fixed blocks. We prove that it is PSPACE-complete to decide whether a given\nblock can reach the left edge of the board, by reduction from Nondeterministic\nConstraint Logic via 2-color oriented Subway Shuffle. By contrast,\npolynomial-time algorithms are known for deciding whether a given block can be\nmoved by one space, or when each block either is immovable or can move both\nhorizontally and vertically. Our result answers a 15-year-old open problem by\nTromp and Cilibrasi, and strengthens previous PSPACE-completeness results for\nRush Hour with vertical $1 \\times 2$ and horizontal $2 \\times 1$ movable blocks\nand 4-color Subway Shuffle.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 14:55:11 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 19:22:15 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Brunner", "Josh", ""], ["Chung", "Lily", ""], ["Demaine", "Erik D.", ""], ["Hendrickson", "Dylan", ""], ["Hesterberg", "Adam", ""], ["Suhl", "Adam", ""], ["Zeff", "Avi", ""]]}, {"id": "2003.10000", "submitter": "Bernardo Anibal Subercaseaux Roa", "authors": "J\\'er\\'emy Barbay, Bernardo Subercaseaux", "title": "The Computational Complexity of Evil Hangman", "comments": "13 pages, 4 figures, Accepted at FUN2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of Hangman is a classical asymmetric two player game in which one\nplayer, the setter, chooses a secret word from a language, that the other\nplayer, the guesser, tries to discover through single letter matching queries,\nanswered by all occurrences of this letter if any. In the Evil Hangman variant,\nthe setter can change the secret word during the game, as long as the new\nchoice is consistent with the information already given to the guesser. We show\nthat a greedy strategy for Evil Hangman can perform arbitrarily far from\noptimal, and most importantly, that playing optimally as an Evil Hangman setter\nis computationally difficult. The latter result holds even assuming perfect\nknowledge of the language, for several classes of languages, ranging from\nFinite to Turing Computable. The proofs are based on reductions to Dominating\nSet on 3-regular graphs and to the Membership problem, combinatorial problems\nalready known to be computationally hard.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 21:35:49 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 03:07:00 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 21:08:05 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Barbay", "J\u00e9r\u00e9my", ""], ["Subercaseaux", "Bernardo", ""]]}, {"id": "2003.10230", "submitter": "Michal Garl\\'ik", "authors": "Michal Garl\\'ik", "title": "Failure of Feasible Disjunction Property for $k$-DNF Resolution and\n  NP-hardness of Automating It", "comments": "arXiv admin note: text overlap with arXiv:1905.12372", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for every integer $k \\geq 2$, the Res($k$) propositional proof\nsystem does not have the weak feasible disjunction property. Next, we\ngeneralize a recent result of Atserias and M\\\"uller [FOCS, 2019] to Res($k$).\nWe show that if NP is not included in P (resp. QP, SUBEXP) then for every\ninteger $k \\geq 1$, Res($k$) is not automatable in polynomial (resp.\nquasi-polynomial, subexponential) time.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 03:02:26 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Garl\u00edk", "Michal", ""]]}, {"id": "2003.10570", "submitter": "Florent Foucaud", "authors": "Florent Foucaud, Benjamin Gras, Anthony Perez, Florian Sikora", "title": "On the complexity of Broadcast Domination and Multipacking in digraphs", "comments": "Extended abstract to appear in proceedings of IWOCA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of the two dual covering and packing distance-based\nproblems Broadcast Domination and Multipacking in digraphs. A dominating\nbroadcast of a digraph $D$ is a function $f:V(D)\\to\\mathbb{N}$ such that for\neach vertex $v$ of $D$, there exists a vertex $t$ with $f(t)>0$ having a\ndirected path to $v$ of length at most $f(t)$. The cost of $f$ is the sum of\n$f(v)$ over all vertices $v$. A multipacking is a set $S$ of vertices of $D$\nsuch that for each vertex $v$ of $D$ and for every integer $d$, there are at\nmost $d$ vertices from $S$ within directed distance at most $d$ from $v$. The\nmaximum size of a multipacking of $D$ is a lower bound to the minimum cost of a\ndominating broadcast of $D$. Let Broadcast Domination denote the problem of\ndeciding whether a given digraph $D$ has a dominating broadcast of cost at most\n$k$, and Multipacking the problem of deciding whether $D$ has a multipacking of\nsize at least $k$. It is known that Broadcast Domination is polynomial-time\nsolvable for the class of all undirected graphs (that is, symmetric digraphs),\nwhile polynomial-time algorithms for Multipacking are known only for a few\nclasses of undirected graphs. We prove that Broadcast Domination and\nMultipacking are both NP-complete for digraphs, even for planar layered acyclic\ndigraphs of small maximum degree. Moreover, when parameterized by the solution\ncost/solution size, we show that the problems are W-hard. We also show that\nBroadcast Domination is FPT on acyclic digraphs, and that it does not admit a\npolynomial kernel for such inputs, unless the polynomial hierarchy collapses to\nits third level. In addition, we show that both problems are FPT when\nparameterized by the solution cost/solution size together with the maximum\nout-degree, and as well, by the vertex cover number. Finally, we give for both\nproblems polynomial-time algorithms for some subclasses of acyclic digraphs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 22:31:41 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 14:59:21 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Foucaud", "Florent", ""], ["Gras", "Benjamin", ""], ["Perez", "Anthony", ""], ["Sikora", "Florian", ""]]}, {"id": "2003.10712", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae", "title": "Information-theoretically-sound non-interactive classical verification\n  of quantum computing with trusted center", "comments": "14 pages, no figure", "journal-ref": null, "doi": null, "report-no": "YITP-20-29", "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The posthoc verification protocol [J. F. Fitzsimons, M. Hajdu{\\v s}ek, and T.\nMorimae, Physical Review Letters {\\bf120}, 040501 (2018)] enables an\ninformation-theoretically-sound non-interactive verification of quantum\ncomputing, but the message from the prover to the verifier is quantum and the\nverifier has to do single-qubit measurements. The Mahadev protocol removes\nthese quantum parts, but the soundness becomes the computational one. In this\npaper, we construct an information-theoretically-sound non-interactive\nclassical verification protocol for quantum computing with a trusted center.\nThe trusted center sends random BB84 states to the prover, and the classical\ndescriptions of these BB84 states to the verifier. The messages from the center\nto the prover and the verifier are independent of the instance. By slightly\nmodifying our protocol, we also construct a non-interactive statistical\nzero-knowledge proof system for QMA with the trusted center.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 08:18:16 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Morimae", "Tomoyuki", ""]]}, {"id": "2003.11313", "submitter": "Martin Milani\\v{c}", "authors": "Nina Chiarelli, Matja\\v{z} Krnc, Martin Milani\\v{c}, Ulrich Pferschy,\n  Nevena Piva\\v{c}, Joachim Schauer", "title": "Fair allocation of indivisible goods under conflict constraints", "comments": "A preliminary version containing some of the results presented here\n  appeared in the proceedings of IWOCA 2020. Version 3 contains an appendix\n  with a remark about biconvex bipartite graphs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fair allocation of indivisible items to several agents and\nadd a graph theoretical perspective to this classical problem. Thereby we\nintroduce an incompatibility relation between pairs of items described in terms\nof a conflict graph. Every subset of items assigned to one agent has to form an\nindependent set in this graph. Thus, the allocation of items to the agents\ncorresponds to a partial coloring of the conflict graph. Every agent has its\nown profit valuation for every item. Aiming at a fair allocation, our goal is\nthe maximization of the lowest total profit of items allocated to any one of\nthe agents. The resulting optimization problem contains, as special cases, both\n{\\sc Partition} and {\\sc Independent Set}. In our contribution we derive\ncomplexity and algorithmic results depending on the properties of the given\ngraph. We can show that the problem is strongly NP-hard for bipartite graphs\nand their line graphs, and solvable in pseudo-polynomial time for the classes\nof chordal graphs, cocomparability graphs, biconvex bipartite graphs, and\ngraphs of bounded treewidth. Each of the pseudo-polynomial algorithms can also\nbe turned into a fully polynomial approximation scheme (FPTAS).\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 10:45:21 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 17:39:21 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 16:38:14 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Chiarelli", "Nina", ""], ["Krnc", "Matja\u017e", ""], ["Milani\u010d", "Martin", ""], ["Pferschy", "Ulrich", ""], ["Piva\u010d", "Nevena", ""], ["Schauer", "Joachim", ""]]}, {"id": "2003.11351", "submitter": "Jakub Opr\\v{s}al", "authors": "Andrei Krokhin, Jakub Opr\\v{s}al, Marcin Wrochna, Stanislav\n  \\v{Z}ivn\\'y", "title": "Topology and adjunction in promise constraint satisfaction", "comments": "This merges and subsumes arXiv:1904.03214 and arXiv:1907.00872.\n  Corrected a mistakes in the proof of Theorem 1.9 and reformulated Lemma 3.26", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximate graph colouring problem concerns colouring a $k$-colourable\ngraph with $c$ colours, where $c\\geq k$. This problem naturally generalises to\npromise graph homomorphism and further to promise constraint satisfaction\nproblems. Complexity analysis of all these problems is notoriously difficult.\nIn this paper, we introduce two new techniques to analyse the complexity of\npromise CSPs: one is based on topology and the other on adjunction. We apply\nthese techniques, together with the previously introduced algebraic approach,\nto obtain new NP-hardness results for a significant class of approximate graph\ncolouring and promise graph homomorphism problems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 12:06:58 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 12:23:12 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Krokhin", "Andrei", ""], ["Opr\u0161al", "Jakub", ""], ["Wrochna", "Marcin", ""], ["\u017divn\u00fd", "Stanislav", ""]]}, {"id": "2003.11764", "submitter": "Dmitriy Zhuk", "authors": "Dmitriy Zhuk", "title": "No-Rainbow Problem and the Surjective Constraint Satisfaction Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Surjective Constraint Satisfaction Problem (SCSP) is the problem of\ndeciding whether there exists a surjective assignment to a set of variables\nsubject to some specified constraints, where a surjective assignment is an\nassignment containing all elements of the domain. In this paper we show that\nthe most famous SCSP, called No-Rainbow Problem, is NP-Hard. Additionally, we\ndisprove the conjecture saying that the SCSP over a constraint language\n$\\Gamma$ and the CSP over the same language with constants have the same\ncomputational complexity up to poly-time reductions. Our counter-example also\nshows that the complexity of the SCSP cannot be described in terms of\npolymorphisms of the constraint language.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 06:55:46 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 19:39:35 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 10:19:32 GMT"}, {"version": "v4", "created": "Thu, 29 Apr 2021 16:04:02 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhuk", "Dmitriy", ""]]}, {"id": "2003.11951", "submitter": "Lintao Ye", "authors": "Lintao Ye, Nathaniel Woodford, Sandip Roy, Shreyas Sundaram", "title": "On the Complexity and Approximability of Optimal Sensor Selection and\n  Attack for Kalman Filtering", "comments": "arXiv admin note: text overlap with arXiv:1711.01920", "journal-ref": null, "doi": "10.1109/TAC.2020.3007383", "report-no": null, "categories": "math.OC cs.CC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a linear dynamical system affected by stochastic noise, we consider the\nproblem of selecting an optimal set of sensors (at design-time) to minimize the\ntrace of the steady state a priori or a posteriori error covariance of the\nKalman filter, subject to certain selection budget constraints. We show the\nfundamental result that there is no polynomial-time constant-factor\napproximation algorithm for this problem. This contrasts with other classes of\nsensor selection problems studied in the literature, which typically pursue\nconstant-factor approximations by leveraging greedy algorithms and\nsubmodularity (or supermodularity) of the cost function. Here, we provide a\nspecific example showing that greedy algorithms can perform arbitrarily poorly\nfor the problem of design-time sensor selection for Kalman filtering. We then\nstudy the problem of attacking (i.e., removing) a set of installed sensors,\nunder predefined attack budget constraints, to maximize the trace of the steady\nstate a priori or a posteriori error covariance of the Kalman filter. Again, we\nshow that there is no polynomial-time constant-factor approximation algorithm\nfor this problem, and show specifically that greedy algorithms can perform\narbitrarily poorly.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 19:13:36 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 01:44:57 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Ye", "Lintao", ""], ["Woodford", "Nathaniel", ""], ["Roy", "Sandip", ""], ["Sundaram", "Shreyas", ""]]}, {"id": "2003.11974", "submitter": "Alexandros Hollender", "authors": "Aris Filos-Ratsikas, Alexandros Hollender, Katerina Sotiraki, Manolis\n  Zampetakis", "title": "A Topological Characterization of Modulo-$p$ Arguments and Implications\n  for Necklace Splitting", "comments": "v2: improved presentation based on reviewer comments and suggestions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classes PPA-$p$ have attracted attention lately, because they are the\nmain candidates for capturing the complexity of Necklace Splitting with $p$\nthieves, for prime $p$. However, these classes were not known to have complete\nproblems of a topological nature, which impedes any progress towards settling\nthe complexity of the Necklace Splitting problem. On the contrary, topological\nproblems have been pivotal in obtaining completeness results for PPAD and PPA,\nsuch as the PPAD-completeness of finding a Nash equilibrium [Daskalakis et al.,\n2009, Chen et al., 2009b] and the PPA-completeness of Necklace Splitting with 2\nthieves [Filos-Ratsikas and Goldberg, 2019].\n  In this paper, we provide the first topological characterization of the\nclasses PPA-$p$. First, we show that the computational problem associated with\na simple generalization of Tucker's Lemma, termed $p$-polygon-Tucker, as well\nas the associated Borsuk-Ulam-type theorem, $p$-polygon-Borsuk-Ulam, are\nPPA-$p$-complete. Then, we show that the computational version of the\nwell-known BSS Theorem [Barany et al., 1981], as well as the associated\nBSS-Tucker problem are PPA-$p$-complete. Finally, using a different\ngeneralization of Tucker's Lemma (termed $\\mathbb{Z}_p$-star-Tucker), which we\nprove to be PPA-$p$-complete, we prove that $p$-thief Necklace Splitting is in\nPPA-$p$. This latter result gives a new combinatorial proof for the Necklace\nSplitting theorem, the only proof of this nature other than that of Meunier\n[2014].\n  All of our containment results are obtained through a new combinatorial proof\nfor $\\mathbb{Z}_p$-versions of Tucker's lemma that is a natural generalization\nof the standard combinatorial proof of Tucker's lemma by Freund and Todd\n[1981]. We believe that this new proof technique is of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:15:07 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 19:40:24 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Filos-Ratsikas", "Aris", ""], ["Hollender", "Alexandros", ""], ["Sotiraki", "Katerina", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "2003.12938", "submitter": "Ben Lee Volk", "authors": "Mrinal Kumar, Ben Lee Volk", "title": "A Polynomial Degree Bound on Equations of Non-rigid Matrices and Small\n  Linear Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there is a defining equation of degree at most\n$\\mathsf{poly}(n)$ for the (Zariski closure of the) set of the non-rigid\nmatrices: that is, we show that for every large enough field $\\mathbb{F}$,\nthere is a non-zero $n^2$-variate polynomial $P \\in \\mathbb{F}[x_{1, 1},\n\\ldots, x_{n, n}]$ of degree at most $\\mathsf{poly}(n)$ such that every matrix\n$M$ which can be written as a sum of a matrix of rank at most $n/100$ and a\nmatrix of sparsity at most $n^2/100$ satisfies $P(M) = 0$. This confirms a\nconjecture of Gesmundo, Hauenstein, Ikenmeyer and Landsberg [GHIL16] and\nimproves the best upper bound known for this problem down from $\\exp(n^2)$\n[KLPS14, GHIL16] to $\\mathsf{poly}(n)$.\n  We also show a similar polynomial degree bound for the (Zariski closure of\nthe) set of all matrices $M$ such that the linear transformation represented by\n$M$ can be computed by an algebraic circuit with at most $n^2/200$ edges\n(without any restriction on the depth). As far as we are aware, no such bound\nwas known prior to this work when the depth of the circuits is unbounded.\n  Our methods are elementary and short and rely on a polynomial map of Shpilka\nand Volkovich [SV15] to construct low degree \"universal\" maps for non-rigid\nmatrices and small linear circuits. Combining this construction with a simple\ndimension counting argument to show that any such polynomial map has a low\ndegree annihilating polynomial completes the proof.\n  As a corollary, we show that any derandomization of the polynomial identity\ntesting problem will imply new circuit lower bounds. A similar (but\nincomparable) theorem was proved by Kabanets and Impagliazzo [KI04].\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 03:35:51 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 18:17:19 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Kumar", "Mrinal", ""], ["Volk", "Ben Lee", ""]]}, {"id": "2003.13065", "submitter": "Alex B. Grilo", "authors": "Dorit Aharonov and Alex B. Grilo", "title": "Two combinatorial MA-complete problems", "comments": "Minor changes; Published in the proceedings of ITCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the interest in the complexity class MA, the randomized analog of NP,\njust a few natural MA-complete problems are known. The first problem was found\nby (Bravyi and Terhal, SIAM Journal of Computing 2009); it was then followed by\n(Crosson, Bacon and Brown, PRE 2010) and (Bravyi, Quantum Information and\nComputation 2015). Surprisingly, two of these problems are defined using\nterminology from quantum computation, while the third is inspired by quantum\ncomputation and keeps a physical terminology. This prevents classical\ncomplexity theorists from studying these problems, delaying potential progress,\ne.g., on the NP vs. MA question.\n  Here, we define two new combinatorial problems and prove their\nMA-completeness. The first problem, ACAC, gets as input a succinctly described\ngraph, with some marked vertices. The problem is to decide whether there is a\nconnected component with only unmarked vertices, or the graph is far from\nhaving this property. The second problem, SetCSP, generalizes standard\nconstraint satisfaction problem (CSP) into constraints involving sets of\nstrings.\n  Technically, our proof that SetCSP is MA-complete is based on an observation\nby (Aharonov and Grilo, FOCS 2019), in which it was noted that a restricted\ncase of Bravyi and Terhal's problem (namely, the uniform case) is already\nMA-complete; a simple trick allows to state this restricted case using\ncombinatorial language. The fact that the first, more natural, problem of ACAC\nis MA-hard follows quite naturally from this proof, while the containment of\nACAC in MA is based on the theory of random walks.\n  We notice that the main result of Aharonov and Grilo carries over to the\nSetCSP problem in a straightforward way, implying that finding a\ngap-amplification procedure for SetCSP (as in Dinur's PCP proof) is equivalent\nto MA=NP. This provides an alternative new path towards the major problem of\nderandomizing MA.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 16:21:19 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 14:37:30 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 11:31:22 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Aharonov", "Dorit", ""], ["Grilo", "Alex B.", ""]]}, {"id": "2003.13558", "submitter": "Thomas Worsch", "authors": "Thomas Worsch (Karlsruhe Institute of Technology)", "title": "A faster algorithm for the FSSP in one-dimensional CA with multiple\n  speeds", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cellular automata with multiple speeds for each cell $i$ there is a\npositive integer $p_i$ such that this cell updates its state still periodically\nbut only at times which are a multiple of $p_i$. Additionally there is a finite\nupper bound on all $p_i$. Manzoni and Umeo have described an algorithm for\nthese (one-dimensional) cellular automata which solves the Firing Squad\nSynchronization Problem. This algorithm needs linear time (in the number of\ncells to be synchronized) but for many problem instances it is slower than the\noptimum time by some positive constant factor. In the present paper we derive\nlower bounds on possible synchronization times and describe an algorithm which\nis never slower and in some cases faster than the one by Manzoni and Umeo and\nwhich is close to a lower bound (up to a constant summand) in more cases.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 15:34:09 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Worsch", "Thomas", "", "Karlsruhe Institute of Technology"]]}]