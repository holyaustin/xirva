[{"id": "1104.0185", "submitter": "Marc Thurley", "authors": "Martin Grohe and Marc Thurley", "title": "Counting Homomorphisms and Partition Functions", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphisms between relational structures are not only fundamental\nmathematical objects, but are also of great importance in an applied\ncomputational context. Indeed, constraint satisfaction problems (CSPs), a wide\nclass of algorithmic problems that occur in many different areas of computer\nscience such as artificial intelligence or database theory, may be viewed as\nasking for homomorphisms between two relational structures [FedVar98]. In a\nlogical setting, homomorphisms may be viewed as witnesses for positive\nprimitive formulas in a relational language. As we shall see, homomorphisms, or\nmore precisely the numbers of homomorphisms between two structures, are also\nrelated to a fundamental computational problem of statistical physics.\n  In this article, we are concerned with the complexity of counting\nhomomorphisms from a given structure A to a fixed structure B. Actually, we are\nmainly interested in a generalization of this problem to weighted homomorphisms\n(or partition functions). We almost exclusively focus on graphs. The first part\nof the article is a short survey of what is known about the problem. In the\nsecond part, we give a proof of a theorem due to Bulatov and the first author\nof this paper [BulGro05], which classifies the complexity of partition\nfunctions described by matrices with non-negative entries. The proof we give\nhere is essentially the same as the original one, with a few shortcuts due to\n[Thu09], but it is phrased in a different, more graph theoretical language that\nmay make it more accessible to most readers.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2011 14:35:01 GMT"}, {"version": "v2", "created": "Mon, 16 May 2011 14:41:41 GMT"}, {"version": "v3", "created": "Fri, 20 May 2011 14:12:46 GMT"}], "update_date": "2011-05-23", "authors_parsed": [["Grohe", "Martin", ""], ["Thurley", "Marc", ""]]}, {"id": "1104.0510", "submitter": "Jose Antonio Martin H.", "authors": "Jos\\'e Antonio Mart\\'in H", "title": "Minimal non-extensible precolorings and implicit-relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I study a variant of the general vertex coloring problem called\nprecoloring. Specifically, I study graph precolorings, by developing new\ntheory, for characterizing the minimal non-extensible precolorings. It is\ninteresting per se that, for graphs of arbitrarily large chromatic number, the\nminimal number of colored vertices, in a non-extensible precoloring, remains\nconstant; only two vertices $u,v$ suffice. Here, the relation between such\n$u,v$ is called an implicit-relation, distinguishing two cases: (i)\nimplicit-edges where $u,v$ are precolored with the same color and (ii)\nimplicit-identities where $u,v$ are precolored distinct.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2011 09:54:15 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["H", "Jos\u00e9 Antonio Mart\u00edn", ""]]}, {"id": "1104.0607", "submitter": "Peter Lohmann", "authors": "Peter Lohmann, Heribert Vollmer", "title": "Complexity Results for Modal Dependence Logic", "comments": "22 pages, full version of CSL 2010 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modal dependence logic was introduced recently by V\\\"a\\\"an\\\"anen. It enhances\nthe basic modal language by an operator =(). For propositional variables\np_1,...,p_n, =(p_1,...,p_(n-1);p_n) intuitively states that the value of p_n is\ndetermined by those of p_1,...,p_(n-1). Sevenster (J. Logic and Computation,\n2009) showed that satisfiability for modal dependence logic is complete for\nnondeterministic exponential time. In this paper we consider fragments of modal\ndependence logic obtained by restricting the set of allowed propositional\nconnectives. We show that satisfibility for poor man's dependence logic, the\nlanguage consisting of formulas built from literals and dependence atoms using\nconjunction, necessity and possibility (i.e., disallowing disjunction), remains\nNEXPTIME-complete. If we only allow monotone formulas (without negation, but\nwith disjunction), the complexity drops to PSPACE-completeness. We also extend\nV\\\"a\\\"an\\\"anen's language by allowing classical disjunction besides dependence\ndisjunction and show that the satisfiability problem remains NEXPTIME-complete.\nIf we then disallow both negation and dependence disjunction, satistiability is\ncomplete for the second level of the polynomial hierarchy. In this way we\ncompletely classify the computational complexity of the satisfiability problem\nfor all restrictions of propositional and dependence operators considered by\nV\\\"a\\\"an\\\"anen and Sevenster.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2011 16:19:59 GMT"}], "update_date": "2011-04-05", "authors_parsed": [["Lohmann", "Peter", ""], ["Vollmer", "Heribert", ""]]}, {"id": "1104.0872", "submitter": "Marius Zimand", "authors": "Marius Zimand", "title": "Possibilities and impossibilities in Kolmogorov complexity extraction", "comments": "Revised form of survey paper published in SIGACT News, Dec. 2010. A\n  few corrections and references have been added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomness extraction is the process of constructing a source of randomness\nof high quality from one or several sources of randomness of lower quality. The\nproblem can be modeled using probability distributions and min-entropy to\nmeasure their quality and also by using individual strings and Kolmogorov\ncomplexity to measure their quality. Complexity theorists are more familiar\nwith the first approach. In this paper we survey the second approach. We\npresent the connection between extractors and Kolmogorov extractors and the\nbasic positive and negative results concerning Kolmogorov complexity\nextraction.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2011 15:45:08 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2012 03:40:09 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Zimand", "Marius", ""]]}, {"id": "1104.1034", "submitter": "Peter Lohmann", "authors": "Johannes Ebbing, Peter Lohmann", "title": "Complexity of Model Checking for Modal Dependence Logic", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Modal dependence logic (MDL) was introduced recently by V\\\"a\\\"an\\\"anen. It\nenhances the basic modal language by an operator =(). For propositional\nvariables p_1,...,p_n the atomic formula =(p_1,...,p_(n-1),p_n) intuitively\nstates that the value of p_n is determined solely by those of p_1,...,p_(n-1).\nWe show that model checking for MDL formulae over Kripke structures is\nNP-complete and further consider fragments of MDL obtained by restricting the\nset of allowed propositional and modal connectives. It turns out that several\nfragments, e.g., the one without modalities or the one without propositional\nconnectives, remain NP-complete. We also consider the restriction of MDL where\nthe length of each single dependence atom is bounded by a number that is fixed\nfor the whole logic. We show that the model checking problem for this bounded\nMDL is still NP-complete. We additionally extend MDL by allowing classical\ndisjunction - introduced by Sevenster - besides dependence disjunction and show\nthat classical disjunction is always at least as computationally bad as bounded\narity dependence atoms and in some cases even worse, e.g., the fragment with\nnothing but the two disjunctions is NP-complete. Furthermore we almost\ncompletely classifiy the computational complexity of the model checking problem\nfor all restrictions of propositional and modal operators for both unbounded as\nwell as bounded MDL.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2011 08:43:43 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2012 18:03:06 GMT"}], "update_date": "2012-01-30", "authors_parsed": [["Ebbing", "Johannes", ""], ["Lohmann", "Peter", ""]]}, {"id": "1104.1045", "submitter": "Martin Hils", "authors": "Manuel Bodirsky, Martin Hils and Alex Krimkevich", "title": "Tractable Set Constraints", "comments": "An extended abstract of this paper appears in Proceedings of\n  IJCAI-11. The third author left the author team for the preparation of the\n  journal version. Several mistakes in the proofs have been removed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many fundamental problems in artificial intelligence, knowledge\nrepresentation, and verification involve reasoning about sets and relations\nbetween sets and can be modeled as set constraint satisfaction problems (set\nCSPs). Such problems are frequently intractable, but there are several\nimportant set CSPs that are known to be polynomial-time tractable. We introduce\na large class of set CSPs that can be solved in quadratic time. Our class,\nwhich we call EI, contains all previously known tractable set CSPs, but also\nsome new ones that are of crucial importance for example in description logics.\nThe class of EI set constraints has an elegant universal-algebraic\ncharacterization, which we use to show that every set constraint language that\nproperly contains all EI set constraints already has a finite sublanguage with\nan NP-hard constraint satisfaction problem.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2011 09:35:13 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2012 12:03:20 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Hils", "Martin", ""], ["Krimkevich", "Alex", ""]]}, {"id": "1104.1135", "submitter": "Gregory Gutin", "authors": "R. Crowston, M. Fellows, G. Gutin, M. Jones, F. Rosamond, S. Thomasse\n  and A. Yeo", "title": "Simultaneously Satisfying Linear Equations Over $\\mathbb{F}_2$: MaxLin2\n  and Max-$r$-Lin2 Parameterized Above Average", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the parameterized problem \\textsc{MaxLin2-AA}[$k$], we are given a system\nwith variables $x_1,...,x_n$ consisting of equations of the form $\\prod_{i \\in\nI}x_i = b$, where $x_i,b \\in \\{-1, 1\\}$ and $I\\subseteq [n],$ each equation has\na positive integral weight, and we are to decide whether it is possible to\nsimultaneously satisfy equations of total weight at least $W/2+k$, where $W$ is\nthe total weight of all equations and $k$ is the parameter (if $k=0$, the\npossibility is assured). We show that \\textsc{MaxLin2-AA}[$k$] has a kernel\nwith at most $O(k^2\\log k)$ variables and can be solved in time $2^{O(k\\log\nk)}(nm)^{O(1)}$. This solves an open problem of Mahajan et al. (2006).\n  The problem \\textsc{Max-$r$-Lin2-AA}[$k,r$] is the same as\n\\textsc{MaxLin2-AA}[$k$] with two differences: each equation has at most $r$\nvariables and $r$ is the second parameter. We prove a theorem on\n\\textsc{Max-$r$-Lin2-AA}[$k,r$] which implies that\n\\textsc{Max-$r$-Lin2-AA}[$k,r$] has a kernel with at most $(2k-1)r$ variables\nimproving a number of results including one by Kim and Williams (2010). The\ntheorem also implies a lower bound on the maximum of a function $f:\\ \\{-1,1\\}^n\n\\rightarrow \\mathbb{R}$ of degree $r$. We show applicability of the lower bound\nby giving a new proof of the Edwards-Erd{\\H o}s bound (each connected graph on\n$n$ vertices and $m$ edges has a bipartite subgraph with at least $m/2 +\n(n-1)/4$ edges) and obtaining a generalization.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2011 16:11:03 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2011 14:53:43 GMT"}, {"version": "v3", "created": "Sun, 15 May 2011 17:11:47 GMT"}], "update_date": "2011-05-17", "authors_parsed": [["Crowston", "R.", ""], ["Fellows", "M.", ""], ["Gutin", "G.", ""], ["Jones", "M.", ""], ["Rosamond", "F.", ""], ["Thomasse", "S.", ""], ["Yeo", "A.", ""]]}, {"id": "1104.1209", "submitter": "Daniel Kane", "authors": "Daniel M. Kane", "title": "A Small PRG for Polynomial Threshold Functions of Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a pseudo-random generator to fool degree-$d$ polynomial threshold\nfunctions with respect to the Gaussian distribution. For $c>0$ any constant, we\nconstruct a pseudo-random generator that fools such functions to within\n$\\epsilon$ and has seed length $\\log(n) 2^{O(d)} \\epsilon^{-4-c}$.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2011 22:43:07 GMT"}], "update_date": "2011-04-08", "authors_parsed": [["Kane", "Daniel M.", ""]]}, {"id": "1104.1410", "submitter": "Martin Schwarz", "authors": "Martin Schwarz, Kristan Temme, Frank Verstraete", "title": "Preparing projected entangled pair states on a quantum computer", "comments": "5 pages, 1 figure. To be published in Physical Review Letters.\n  Removed heuristics, refined run-time bound", "journal-ref": "Phys. Rev. Lett. 108, 110502 (2012)", "doi": "10.1103/PhysRevLett.108.110502", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a quantum algorithm to prepare injective PEPS on a quantum\ncomputer, a class of open tensor networks representing quantum states. The\nrun-time of our algorithm scales polynomially with the inverse of the minimum\ncondition number of the PEPS projectors and, essentially, with the inverse of\nthe spectral gap of the PEPS' parent Hamiltonian.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2011 19:22:07 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2012 20:03:58 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Schwarz", "Martin", ""], ["Temme", "Kristan", ""], ["Verstraete", "Frank", ""]]}, {"id": "1104.2074", "submitter": "Prabhanjan Ananth", "authors": "Prabhanjan Ananth and Meghana Nasre", "title": "New Hardness Results in Rainbow Connectivity", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A path in an edge colored graph is said to be a rainbow path if no two edges\non the path have the same color. An edge colored graph is (strongly) rainbow\nconnected if there exists a (geodesic) rainbow path between every pair of\nvertices. The (strong) rainbow connectivity of a graph $G$, denoted by\n($src(G)$, respectively) $rc(G)$ is the smallest number of colors required to\nedge color the graph such that the graph is (strong) rainbow connected. It is\nknown that for \\emph{even} $k$ to decide whether the rainbow connectivity of a\ngraph is at most $k$ or not is NP-hard. It was conjectured that for all $k$, to\ndecide whether $rc(G) \\leq k$ is NP-hard. In this paper we prove this\nconjecture. We also show that it is NP-hard to decide whether $src(G) \\leq k$\nor not even when $G$ is a bipartite graph.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2011 21:55:17 GMT"}], "update_date": "2011-04-13", "authors_parsed": [["Ananth", "Prabhanjan", ""], ["Nasre", "Meghana", ""]]}, {"id": "1104.2312", "submitter": "Henning Schnoor", "authors": "Edith Hemaspaandra and Henning Schnoor", "title": "Minimization for Generalized Boolean Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimization problem for propositional formulas is an important\noptimization problem in the second level of the polynomial hierarchy. In\ngeneral, the problem is Sigma-2-complete under Turing reductions, but\nrestricted versions are tractable. We study the complexity of minimization for\nformulas in two established frameworks for restricted propositional logic: The\nPost framework allowing arbitrarily nested formulas over a set of Boolean\nconnectors, and the constraint setting, allowing generalizations of CNF\nformulas. In the Post case, we obtain a dichotomy result: Minimization is\nsolvable in polynomial time or coNP-hard. This result also applies to Boolean\ncircuits. For CNF formulas, we obtain new minimization algorithms for a large\nclass of formulas, and give strong evidence that we have covered all\npolynomial-time cases.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2011 19:38:32 GMT"}], "update_date": "2011-04-13", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Schnoor", "Henning", ""]]}, {"id": "1104.2502", "submitter": "Rahul Jain", "authors": "Rahul Jain and Penghui Yao", "title": "A Parallel Approximation Algorithm for Positive Semidefinite Programming", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive semidefinite programs are an important subclass of semidefinite\nprograms in which all matrices involved in the specification of the problem are\npositive semidefinite and all scalars involved are non-negative. We present a\nparallel algorithm, which given an instance of a positive semidefinite program\nof size N and an approximation factor eps > 0, runs in (parallel) time\npoly(1/eps) \\cdot polylog(N), using poly(N) processors, and outputs a value\nwhich is within multiplicative factor of (1 + eps) to the optimal. Our result\ngeneralizes analogous result of Luby and Nisan [1993] for positive linear\nprograms and our algorithm is inspired by their algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2011 14:13:02 GMT"}], "update_date": "2011-04-14", "authors_parsed": [["Jain", "Rahul", ""], ["Yao", "Penghui", ""]]}, {"id": "1104.2524", "submitter": "Steven Chaplick", "authors": "Steven Chaplick and Juraj Stacho", "title": "The vertex leafage of chordal graphs", "comments": null, "journal-ref": "Journal of Discrete Applied Mathematics: Fifth Workshop on Graph\n  Classes, Optimization, and Width Parameters (GROW 2011). 168: 14-25. 2014", "doi": "10.1016/j.dam.2012.12.006.", "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every chordal graph $G$ can be represented as the intersection graph of a\ncollection of subtrees of a host tree, a so-called {\\em tree model} of $G$. The\nleafage $\\ell(G)$ of a connected chordal graph $G$ is the minimum number of\nleaves of the host tree of a tree model of $G$. The vertex leafage $\\vl(G)$ is\nthe smallest number $k$ such that there exists a tree model of $G$ in which\nevery subtree has at most $k$ leaves. The leafage is a polynomially computable\nparameter by the result of \\cite{esa}. In this contribution, we study the\nvertex leafage.\n  We prove for every fixed $k\\geq 3$ that deciding whether the vertex leafage\nof a given chordal graph is at most $k$ is NP-complete by proving a stronger\nresult, namely that the problem is NP-complete on split graphs with vertex\nleafage of at most $k+1$. On the other hand, for chordal graphs of leafage at\nmost $\\ell$, we show that the vertex leafage can be calculated in time\n$n^{O(\\ell)}$. Finally, we prove that there exists a tree model that realizes\nboth the leafage and the vertex leafage of $G$. Notably, for every path graph\n$G$, there exists a path model with $\\ell(G)$ leaves in the host tree and it\ncan be computed in $O(n^3)$ time.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2011 15:04:52 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2012 22:56:56 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Chaplick", "Steven", ""], ["Stacho", "Juraj", ""]]}, {"id": "1104.2538", "submitter": "Stefan Jaeger", "authors": "Stefan Jaeger", "title": "Computational Complexity on Signed Numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new representation of natural numbers and discusses its\nconsequences for computability and computational complexity. The paper argues\nthat the introduction of the first Peano axiom in the traditional definition of\nnatural numbers is not essential. It claims that natural numbers remain usable\nin traditional ways without assuming the existence of at least one natural\nnumber. However, the uncertainty about the existence of natural numbers\ntranslates into every computation and introduces intrinsic uncertainty that\ncannot be avoided. The uncertainty in the output of a computation can be\nreduced, though, at the expense of a longer runtime and thus higher complexity.\nFor the new representation of natural numbers, the paper claims that, with the\nfirst Peano axiom, P is equal to NP, and that without the first Peano axiom, P\nbecomes a proper subset of NP.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2011 16:09:49 GMT"}], "update_date": "2011-04-14", "authors_parsed": [["Jaeger", "Stefan", ""]]}, {"id": "1104.2788", "submitter": "Johannes Klaus Fichte", "authors": "Johannes Klaus Fichte and Stefan Szeider", "title": "Backdoors to Tractable Answer-Set Programming", "comments": "This paper extends and updates papers that appeared in the\n  proceedings of IJCAI'11 (arXiv:1104.2788) and ESSLLI'11 (arXiv:1205.3663). We\n  provide a higher detail level, full proofs and more examples; present new\n  results on preprocessing, a general method to lift parameters from normal\n  programs to disjunctive programs, and a theoretical comparison of\n  ASP-parameters; and provide some empirical data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is an increasingly popular framework for\ndeclarative programming that admits the description of problems by means of\nrules and constraints that form a disjunctive logic program. In particular,\nmany AI problems such as reasoning in a nonmonotonic setting can be directly\nformulated in ASP. Although the main problems of ASP are of high computational\ncomplexity, located at the second level of the Polynomial Hierarchy, several\nrestrictions of ASP have been identified in the literature, under which ASP\nproblems become tractable.\n  In this paper we use the concept of backdoors to identify new restrictions\nthat make ASP problems tractable. Small backdoors are sets of atoms that\nrepresent \"clever reasoning shortcuts\" through the search space and represent a\nhidden structure in the problem input. The concept of backdoors is widely used\nin the areas of propositional satisfiability and constraint satisfaction. We\nshow that it can be fruitfully adapted to ASP. We demonstrate how backdoors can\nserve as a unifying framework that accommodates several tractable restrictions\nof ASP known from the literature. Furthermore, we show how backdoors allow us\nto deploy recent algorithmic results from parameterized complexity theory to\nthe domain of answer set programming.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2011 14:59:45 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2012 19:55:55 GMT"}, {"version": "v3", "created": "Thu, 3 May 2012 17:23:05 GMT"}, {"version": "v4", "created": "Thu, 6 Mar 2014 17:39:40 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Fichte", "Johannes Klaus", ""], ["Szeider", "Stefan", ""]]}, {"id": "1104.2809", "submitter": "Matthew Patitz", "authors": "Bin Fu and Matthew J. Patitz and Robert T. Schweller and Bobby Sheline", "title": "Self-Assembly with Geometric Tiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a generalization of Winfree's abstract Tile Assembly\nModel (aTAM) in which tile types are assigned rigid shapes, or geometries,\nalong each tile face. We examine the number of distinct tile types needed to\nassemble shapes within this model, the temperature required for efficient\nassembly, and the problem of designing compact geometric faces to meet given\ncompatibility specifications. Our results show a dramatic decrease in the\nnumber of tile types needed to assemble $n \\times n$ squares to\n$\\Theta(\\sqrt{\\log n})$ at temperature 1 for the most simple model which meets\na lower bound from Kolmogorov complexity, and $O(\\log\\log n)$ in a model in\nwhich tile aggregates must move together through obstacle free paths within the\nplane. This stands in contrast to the $\\Theta(\\log n / \\log\\log n)$ tile types\nat temperature 2 needed in the basic aTAM. We also provide a general method for\nsimulating a large and computationally universal class of temperature 2 aTAM\nsystems with geometric tiles at temperature 1. Finally, we consider the problem\nof computing a set of compact geometric faces for a tile system to implement a\ngiven set of compatibility specifications. We show a number of bounds on the\ncomplexity of geometry size needed for various classes of compatibility\nspecifications, many of which we directly apply to our tile assembly results to\nachieve non-trivial reductions in geometry size.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2011 15:46:11 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Fu", "Bin", ""], ["Patitz", "Matthew J.", ""], ["Schweller", "Robert T.", ""], ["Sheline", "Bobby", ""]]}, {"id": "1104.2816", "submitter": "Marius Zimand", "authors": "Marius Zimand", "title": "On the optimal compression of sets in PSPACE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if DTIME[2^{O(n)}] is not included in DSPACE[2^{o(n)}], then,\nfor every set B in PSPACE, all strings x in B of length n can be represented by\na string compressed(x) of length at most log (|B^{=n}|) + O(log n), such that a\npolynomial-time algorithm, given compressed(x), can distinguish x from all the\nother strings in B^{=n}. Modulo the O(log n) additive trem, this achieves the\ninformation-theoretical optimum for string compression.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2011 16:11:38 GMT"}], "update_date": "2011-04-15", "authors_parsed": [["Zimand", "Marius", ""]]}, {"id": "1104.2818", "submitter": "Gregory Gutin", "authors": "Gregory Gutin, Mark Jones, Dominik Scheder, Anders Yeo", "title": "A New Bound for 3-Satisfiable MaxSat and its Algorithmic Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let F be a CNF formula with n variables and m clauses. F is 3-satisfiable if\nfor any 3 clauses in F, there is a truth assignment which satisfies all of\nthem. Lieberherr and Specker (1982) and, later, Yannakakis (1994) proved that\nin each 3-satisfiable CNF formula at least 2/3 of its clauses can be satisfied\nby a truth assignment. We improve this result by showing that every\n3-satisfiable CNF formula F contains a subset of variables U, such that some\ntruth assignment $\\tau$ will satisfy at least $2m/3+ m_U/3+\\rho n'$ clauses,\nwhere m is the number of clauses of F, m_U is the number of clauses of F\ncontaining a variable from U, n' is the total number of variables in clauses\nnot containing a variable in U, and \\rho is a positive absolute constant. Both\nU and $\\tau$ can be found in polynomial time. We use our result to show that\nthe following parameterized problem is fixed-parameter tractable and, moreover,\nhas a kernel with a linear number of variables. In 3-S-MAXSAT-AE, we are given\na 3-satisfiable CNF formula F with m clauses and asked to determine whether\nthere is an assignment which satisfies at least 2m/3 + k clauses, where k is\nthe parameter.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2011 16:13:43 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2011 13:50:22 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2012 08:46:17 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Gutin", "Gregory", ""], ["Jones", "Mark", ""], ["Scheder", "Dominik", ""], ["Yeo", "Anders", ""]]}, {"id": "1104.2842", "submitter": "Sebastian Ordyniak", "authors": "Sebastian Ordyniak and Stefan Szeider", "title": "Augmenting Tractable Fragments of Abstract Argumentation", "comments": "accepted for ijcai 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new and compelling approach to the efficient solution of\nimportant computational problems that arise in the context of abstract\nargumentation. Our approach makes known algorithms defined for restricted\nfragments generally applicable, at a computational cost that scales with the\ndistance from the fragment. Thus, in a certain sense, we gradually augment\ntractable fragments. Surprisingly, it turns out that some tractable fragments\nadmit such an augmentation and that others do not.\n  More specifically, we show that the problems of credulous and skeptical\nacceptance are fixed-parameter tractable when parameterized by the distance\nfrom the fragment of acyclic argumentation frameworks. Other tractable\nfragments such as the fragments of symmetrical and bipartite frameworks seem to\nprohibit an augmentation: the acceptance problems are already intractable for\nframeworks at distance 1 from the fragments.\n  For our study we use a broad setting and consider several different\nsemantics. For the algorithmic results we utilize recent advances in\nfixed-parameter tractability.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2011 17:31:07 GMT"}, {"version": "v2", "created": "Fri, 15 Apr 2011 12:19:54 GMT"}], "update_date": "2011-04-18", "authors_parsed": [["Ordyniak", "Sebastian", ""], ["Szeider", "Stefan", ""]]}, {"id": "1104.2970", "submitter": "David  Gao", "authors": "David Y. Gao and Changzhi Wu", "title": "On the Triality Theory in Global Optimization", "comments": "In this revised version, a new section 6 is added to response one of\n  reviewers' comment on the difference between the canonical duality theory and\n  the classical Lagrangian duality theory. An application to quartic\n  polynomials was given in arXiv:1110.0293v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triality theory is proved for a general unconstrained global optimization\nproblem. The method adopted is simple but mathematically rigorous. Results show\nthat if the primal problem and its canonical dual have the same dimension, the\ntriality theory holds strongly in the tri-duality form as it was originally\nproposed. Otherwise, both the canonical min-max duality and the double-max\nduality still hold strongly, but the double-min duality holds weakly in a\nsuper-symmetrical form as it was expected. Additionally, a complementary weak\nsaddle min-max duality theorem is discovered. Therefore, an open problem on\nthis statement left in 2003 is solved completely. This theory can be used to\nidentify not only the global minimum, but also the largest local minimum,\nmaximum, and saddle points. Application is illustrated. Some fundamental\nconcepts in optimization and remaining challenging problems in canonical\nduality theory are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2011 07:04:19 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2012 01:04:59 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Gao", "David Y.", ""], ["Wu", "Changzhi", ""]]}, {"id": "1104.3025", "submitter": "Steve Uurtamo", "authors": "Mohammad Iftekhar Husain, Steve Ko, Atri Rudra, Steve Uurtamo", "title": "Storage Enforcement with Kolmogorov Complexity and List Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following problem that arises in outsourced storage: a user\nstores her data $x$ on a remote server but wants to audit the server at some\nlater point to make sure it actually did store $x$. The goal is to design a\n(randomized) verification protocol that has the property that if the server\npasses the verification with some reasonably high probability then the user can\nrest assured that the server is storing $x$.\n  In this work we present an optimal solution (in terms of the user's storage\nand communication) while at the same time ensuring that a server that passes\nthe verification protocol with any reasonable probability will store, to within\na small \\textit{additive} factor, $C(x)$ bits of information, where $C(x)$ is\nthe plain Kolmogorov complexity of $x$. (Since we cannot prevent the server\nfrom compressing $x$, $C(x)$ is a natural upper bound.) The proof of security\nof our protocol combines Kolmogorov complexity with list decoding and unlike\nprevious work that relies upon cryptographic assumptions, we allow the server\nto have unlimited computational power. To the best of our knowledge, this is\nthe first work that combines Kolmogorov complexity and list decoding.\n  Our framework is general enough to capture extensions where the user splits\nup $x$ and stores the fragment across multiple servers and our verification\nprotocol can handle non-responsive servers and colluding servers. As a\nby-product, we also get a proof of retrievability. Finally, our results also\nhave an application in `storage enforcement' schemes, which in turn have an\napplication in trying to update a remote server that is potentially infected\nwith a virus.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2011 11:54:41 GMT"}], "update_date": "2011-04-18", "authors_parsed": [["Husain", "Mohammad Iftekhar", ""], ["Ko", "Steve", ""], ["Rudra", "Atri", ""], ["Uurtamo", "Steve", ""]]}, {"id": "1104.3056", "submitter": "Ross King", "authors": "Ross D. King", "title": "Numbers as Data Structures: The Prime Successor Function as Primitive", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The symbolic representation of a number should be considered as a data\nstructure, and the choice of data structure depends on the arithmetic\noperations that are to be performed. Numbers are almost universally represented\nusing position based notations based on exponential powers of a base number -\nusually 10. This representations is computationally efficient for the standard\narithmetic operations, but it is not efficient for factorisation. This has led\nto a common confusion that factorisation is inherently computationally hard. We\npropose a new representation of the natural numbers based on bags and using the\nprime successor function as a primitive - prime bags (PBs). This data structure\nis more efficient for most arithmetic operations, and enables numbers can be\nefficiently factored. However, it also has the interesting feature that\naddition appears to be computationally hard. PBs have an interesting\nalternative interpretation as partitions of numbers represented in the standard\nway, and this reveals a novel relationship between prime numbers and the\npartition function. The PB representation can be extended to rational and\nirrational numbers, and this provides the most direct proof of the\nirrationality of the square root of 2. I argue that what needs to be ultimately\nunderstood is not the peculiar computation complexity properties of the decimal\nsystem (e.g. factorisation), but rather what arithmetical operator trade-offs\nare generally possible.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2011 13:46:47 GMT"}], "update_date": "2011-04-18", "authors_parsed": [["King", "Ross D.", ""]]}, {"id": "1104.3148", "submitter": "Peter Lohmann", "authors": "Juha Kontinen, Antti Kuusisto, Peter Lohmann, Jonni Virtema", "title": "Complexity of two-variable Dependence Logic and IF-Logic", "comments": "27 pages, extended version of LICS 2011 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the two-variable fragments D^2 and IF^2 of dependence logic and\nindependence-friendly logic. We consider the satisfiability and finite\nsatisfiability problems of these logics and show that for D^2, both problems\nare NEXPTIME-complete, whereas for IF^2, the problems are undecidable. We also\nshow that D^2 is strictly less expressive than IF^2 and that already in D^2,\nequicardinality of two unary predicates and infinity can be expressed (the\nlatter in the presence of a constant symbol). This is an extended version of a\npublication in the proceedings of the 26th Annual IEEE Symposium on Logic in\nComputer Science (LICS 2011).\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2011 20:13:14 GMT"}], "update_date": "2011-04-19", "authors_parsed": [["Kontinen", "Juha", ""], ["Kuusisto", "Antti", ""], ["Lohmann", "Peter", ""], ["Virtema", "Jonni", ""]]}, {"id": "1104.3335", "submitter": "Shachar Lovett", "authors": "Hamed Hatami, Shachar Lovett", "title": "Correlation Testing for Affine Invariant Properties on $\\mathbb{F}_p^n$\n  in the High Error Regime", "comments": "43 pages. A preliminary version of this work appeared in STOC' 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been much interest in Gowers uniformity norms from the\nperspective of theoretical computer science. This is mainly due to the fact\nthat these norms provide a method for testing whether the maximum correlation\nof a function $f:\\mathbb{F}_p^n \\rightarrow \\mathbb{F}_p$ with polynomials of\ndegree at most $d \\le p$ is non-negligible, while making only a constant number\nof queries to the function. This is an instance of {\\em correlation testing}.\nIn this framework, a fixed test is applied to a function, and the acceptance\nprobability of the test is dependent on the correlation of the function from\nthe property. This is an analog of {\\em proximity oblivious testing}, a notion\ncoined by Goldreich and Ron, in the high error regime. In this work, we study\ngeneral properties which are affine invariant and which are correlation\ntestable using a constant number of queries. We show that any such property (as\nlong as the field size is not too small) can in fact be tested by Gowers\nuniformity tests, and hence having correlation with the property is equivalent\nto having correlation with degree $d$ polynomials for some fixed $d$. We stress\nthat our result holds also for non-linear properties which are affine\ninvariant. This completely classifies affine invariant properties which are\ncorrelation testable. The proof is based on higher-order Fourier analysis.\nAnother ingredient is a nontrivial extension of a graph theoretical theorem of\nErd\\\"os, Lov\\'asz and Spencer to the context of additive number theory.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2011 18:56:55 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2013 21:35:23 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Hatami", "Hamed", ""], ["Lovett", "Shachar", ""]]}, {"id": "1104.3421", "submitter": "Hector Zenil", "authors": "Hector Zenil, Fernando Soler-Toscano and Joost J. Joosten", "title": "Empirical Encounters with Computational Irreducibility and\n  Unpredictability", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several forms of irreducibility in computing systems, ranging from\nundecidability to intractability to nonlinearity. This paper is an exploration\nof the conceptual issues that have arisen in the course of investigating\nspeed-up and slowdown phenomena in small Turing machines. We present the\nresults of a test that may spur experimental approaches to the notion of\ncomputational irreducibility. The test involves a systematic attempt to outrun\nthe computation of a large number of small Turing machines (all 3 and 4 state,\n2 symbol) by means of integer sequence prediction using a specialized function\nfinder program. This massive experiment prompts an investigation into rates of\nconvergence of decision procedures and the decidability of sets in addition to\na discussion of the (un)predictability of deterministic computing systems in\npractice. We think this investigation constitutes a novel approach to the\ndiscussion of an epistemological question in the context of a computer\nsimulation, and thus represents an interesting exploration at the boundary\nbetween philosophical concerns and computational experiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2011 10:00:45 GMT"}, {"version": "v2", "created": "Sat, 14 May 2011 19:51:08 GMT"}, {"version": "v3", "created": "Thu, 23 Jun 2011 06:07:45 GMT"}], "update_date": "2011-06-24", "authors_parsed": [["Zenil", "Hector", ""], ["Soler-Toscano", "Fernando", ""], ["Joosten", "Joost J.", ""]]}, {"id": "1104.3463", "submitter": "Vijayakumar S", "authors": "M. A. Shalu and S. Vijayakumar", "title": "The Two Bicliques Problem is in NP intersection coNP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the problem of deciding whether the vertex set of a graph can be\ncovered with at most two bicliques is in NP$\\cap$coNP. We thus almost determine\nthe computational complexity of a problem whose status has remained open for\nquite some time. Our result implies that a polynomial time algorithm for the\nproblem is more likely than it being NP-complete unless P = NP.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2011 12:43:24 GMT"}, {"version": "v2", "created": "Tue, 19 Apr 2011 13:36:36 GMT"}, {"version": "v3", "created": "Wed, 20 Apr 2011 11:55:32 GMT"}, {"version": "v4", "created": "Mon, 25 Apr 2011 17:48:40 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Shalu", "M. A.", ""], ["Vijayakumar", "S.", ""]]}, {"id": "1104.3631", "submitter": "Haijun Zhou", "authors": "Jing-Qing Xiao and Haijun Zhou", "title": "Partition function loop series for a general graphical model: free\n  energy corrections and message-passing equations", "comments": "12 pages with 1 figure included. Extensive revision on structure of\n  the paper (no change in results). Accepted by Journal of Physica A", "journal-ref": "J. Phys. A: Math. Theor. 44 (2011) 425001", "doi": "10.1088/1751-8113/44/42/425001", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A loop series expansion for the partition function of a general statistical\nmodel on a graph is carried out. If the auxiliary probability distributions of\nthe expansion are chosen to be a fixed point of the belief-propagation\nequation, the first term of the loop series gives the Bethe-Peierls free energy\nfunctional at the replica-symmetric level of the mean-field spin glass theory,\nand corrections are contributed only by subgraphs that are free of dangling\nedges. This result generalize the early work of Chertkov and Chernyak on binary\nstatistical models. If the belief-propagation equation has multiple fixed\npoints, a loop series expansion is performed for the grand partition function.\nThe first term of this series gives the Bethe-Peierls free energy functional at\nthe first-step replica-symmetry-breaking (RSB) level of the mean-field\nspin-glass theory, and corrections again come only from subgraphs that are free\nof dangling edges, provided that the auxiliary probability distributions of the\nexpansion are chosen to be a fixed point of the survey-propagation equation.\nThe same loop series expansion can be performed for higher-level partition\nfunctions, obtaining the higher-level RSB Bethe-Peierls free energy functionals\n(and the correction terms) and message-passing equations without using the\nBethe-Peierls approximation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2011 03:50:45 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2011 03:13:25 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Xiao", "Jing-Qing", ""], ["Zhou", "Haijun", ""]]}, {"id": "1104.3720", "submitter": "Stefanie Naewe", "authors": "Johannes Bl\\\"omer and Stefanie Naewe", "title": "Solving the Closest Vector Problem with respect to l_p Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a deterministic algorithm for the closest vector\nproblem for all l_p-norms, 1 < p < \\infty, and all polyhedral norms, especially\nfor the l_1-norm and the l_{\\infty}-norm. We achieve our results by introducing\na new lattice problem, the lattice membership problem. We describe a\ndeterministic algorithm for the lattice membership problem, which is a\ngeneralization of Lenstra's algorithm for integer programming. We also describe\na polynomial time reduction from the closest vector problem to the lattice\nmembership problem. This approach leads to a deterministic algorithm that\nsolves the closest vector problem for all l_p-norms, 1 < p < \\infty, in time p\nlog_2 (r)^{O (1)} n^{(5/2+o(1))n} and for all polyhedral norms in time (s log_2\n(r))^{O (1)} n^{(2+o(1))n}, where s is the number of constraints defining the\npolytope and r is an upper bound on the coefficients used to describe the\nconvex body.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2011 12:03:46 GMT"}, {"version": "v2", "created": "Mon, 16 May 2011 12:57:28 GMT"}, {"version": "v3", "created": "Tue, 12 Jul 2011 17:25:13 GMT"}, {"version": "v4", "created": "Mon, 26 Sep 2011 11:35:15 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Bl\u00f6mer", "Johannes", ""], ["Naewe", "Stefanie", ""]]}, {"id": "1104.3760", "submitter": "Per Austrin", "authors": "Per Austrin and Mark Braverman and Eden Chlamtac", "title": "Inapproximability of NP-Complete Variants of Nash Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent work of Hazan and Krauthgamer (SICOMP 2011), it was shown that\nfinding an $\\eps$-approximate Nash equilibrium with near-optimal value in a\ntwo-player game is as hard as finding a hidden clique of size $O(\\log n)$ in\nthe random graph $G(n,1/2)$. This raises the question of whether a similar\nintractability holds for approximate Nash equilibrium without such constraints.\nWe give evidence that the constraint of near-optimal value makes the problem\ndistinctly harder: a simple algorithm finds an optimal 1/2-approximate\nequilibrium, while finding strictly better than 1/2-approximate equilibria is\nas hard as the Hidden Clique problem. This is in contrast to the unconstrained\nproblem where more sophisticated algorithms, achieving better approximations,\nare known.\n  Unlike general Nash equilibrium, which is in PPAD, optimal (maximum value)\nNash equilibrium is NP-hard. We proceed to show that optimal Nash equilibrium\nis just one of several known NP-hard problems related to Nash equilibrium, all\nof which have approximate variants which are as hard as finding a planted\nclique. In particular, we show this for approximate variants of the following\nproblems: finding a Nash equilibrium with value greater than $\\eta$ (for any\n$\\eta>0$, even when the best Nash equilibrium has value $1-\\eta$), finding a\nsecond Nash equilibrium, and finding a Nash equilibrium with small support.\n  Finally, we consider the complexity of approximate pure Bayes Nash equilibria\nin two-player games. Here we show that for general Bayesian games the problem\nis NP-hard. For the special case where the distribution over types is uniform,\nwe give a quasi-polynomial time algorithm matched by a hardness result based on\nthe Hidden Clique problem.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2011 14:26:03 GMT"}], "update_date": "2011-04-20", "authors_parsed": [["Austrin", "Per", ""], ["Braverman", "Mark", ""], ["Chlamtac", "Eden", ""]]}, {"id": "1104.3806", "submitter": "Konstantin Makarychev", "authors": "Alexandra Kolla, Konstantin Makarychev, Yury Makarychev", "title": "How to Play Unique Games against a Semi-Random Adversary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the average case complexity of the Unique Games\nproblem. We propose a natural semi-random model, in which a unique game\ninstance is generated in several steps. First an adversary selects a completely\nsatisfiable instance of Unique Games, then she chooses an epsilon-fraction of\nall edges, and finally replaces (\"corrupts\") the constraints corresponding to\nthese edges with new constraints. If all steps are adversarial, the adversary\ncan obtain any (1-epsilon) satisfiable instance, so then the problem is as hard\nas in the worst case. In our semi-random model, one of the steps is random, and\nall other steps are adversarial. We show that known algorithms for unique games\n(in particular, all algorithms that use the standard SDP relaxation) fail to\nsolve semi-random instances of Unique Games.\n  We present an algorithm that with high probability finds a solution\nsatisfying a (1-delta) fraction of all constraints in semi-random instances (we\nrequire that the average degree of the graph is Omega(log k). To this end, we\nconsider a new non-standard SDP program for Unique Games, which is not a\nrelaxation for the problem, and show how to analyze it. We present a new\nrounding scheme that simultaneously uses SDP and LP solutions, which we believe\nis of independent interest.\n  Our result holds only for epsilon less than some absolute constant. We prove\nthat if epsilon > 1/2, then the problem is hard in one of the models, the\nresult assumes the 2-to-2 conjecture.\n  Finally, we study semi-random instances of Unique Games that are at most\n(1-epsilon) satisfiable. We present an algorithm that with high probability,\ndistinguishes between the case when the instance is a semi-random instance and\nthe case when the instance is an (arbitrary) (1-delta) satisfiable instance if\nepsilon > c delta.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2011 17:16:59 GMT"}], "update_date": "2011-04-20", "authors_parsed": [["Kolla", "Alexandra", ""], ["Makarychev", "Konstantin", ""], ["Makarychev", "Yury", ""]]}, {"id": "1104.3913", "submitter": "Moritz Hardt", "authors": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, Rich\n  Zemel", "title": "Fairness Through Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fairness in classification, where individuals are classified, e.g.,\nadmitted to a university, and the goal is to prevent discrimination against\nindividuals based on their membership in some group, while maintaining utility\nfor the classifier (the university). The main conceptual contribution of this\npaper is a framework for fair classification comprising (1) a (hypothetical)\ntask-specific metric for determining the degree to which individuals are\nsimilar with respect to the classification task at hand; (2) an algorithm for\nmaximizing utility subject to the fairness constraint, that similar individuals\nare treated similarly. We also present an adaptation of our approach to achieve\nthe complementary goal of \"fair affirmative action,\" which guarantees\nstatistical parity (i.e., the demographics of the set of individuals receiving\nany classification are the same as the demographics of the underlying\npopulation), while treating similar individuals as similarly as possible.\nFinally, we discuss the relationship of fairness to privacy: when fairness\nimplies privacy, and how tools developed in the context of differential privacy\nmay be applied to fairness.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2011 01:45:07 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2011 04:55:13 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Dwork", "Cynthia", ""], ["Hardt", "Moritz", ""], ["Pitassi", "Toniann", ""], ["Reingold", "Omer", ""], ["Zemel", "Rich", ""]]}, {"id": "1104.4217", "submitter": "Bart M. P. Jansen", "authors": "Hans L. Bodlaender and Bart M. P. Jansen and Stefan Kratsch", "title": "Preprocessing for Treewidth: A Combinatorial Analysis through\n  Kernelization", "comments": "An extended abstract of this paper appeared in the proceedings of\n  ICALP 2011. This is the full version containing all proofs, along with some\n  improvements to the results of the extended abstract. This paper will appear\n  in the SIAM Journal on Discrete Mathematics. The SIAM version will contain\n  slight improvements to this arXiv version; for example, revised figures and\n  typesetting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of treewidth plays an important role in theoretical and practical\nstudies of graph problems. It has been recognized that, especially in practical\nenvironments, when computing the treewidth of a graph it is invaluable to first\napply an array of preprocessing rules that simplify and shrink it. This work\nseeks to prove rigorous performance guarantees for such preprocessing rules,\nboth known and new ones, by studying them in the framework of kernelization\nfrom parameterized complexity.\n  It is known that the NP-complete problem of determining whether a given graph\nG has treewidth at most k admits no polynomial-time preprocessing algorithm\nthat reduces any input instance to size polynomial in k, unless NP is in\ncoNP/poly and the polynomial hierarchy collapses to its third level. In this\npaper we therefore consider structural graph measures larger than treewidth,\nand determine whether efficient preprocessing can shrink the instance size to a\npolynomial in such a parameter value.\n  We prove that given an instance (G,k) of treewidth we can efficiently reduce\nits size to O(fvs(G)^4) vertices, where fvs(G) is the size of a minimum\nfeedback vertex set in G. We can also prove a size reduction to O(vc(G)^3)\nvertices, where vc(G) is the size of a minimum vertex cover. Phrased in the\nlanguage of parameterized complexity, we show that Treewidth has a polynomial\nkernel when parameterized by the size of a given feedback vertex set, and also\nby the size of a vertex cover. In contrast we show that Treewidth parameterized\nby the vertex-deletion distance to a single clique, and Weighted Treewidth\nparameterized by the size of a vertex cover, do not admit polynomial\nkernelizations unless NP is in coNP/poly.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2011 09:52:16 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2013 12:06:22 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Jansen", "Bart M. P.", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1104.4229", "submitter": "Bart M. P. Jansen", "authors": "Bart M. P. Jansen and Stefan Kratsch", "title": "Data Reduction for Graph Coloring Problems", "comments": "Author-accepted manuscript of the article that will appear in the FCT\n  2011 special issue of Information & Computation", "journal-ref": null, "doi": "10.1016/j.ic.2013.08.005", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the kernelization complexity of graph coloring problems\nwith respect to certain structural parameterizations of the input instances. We\nare interested in how well polynomial-time data reduction can provably shrink\ninstances of coloring problems, in terms of the chosen parameter. It is well\nknown that deciding 3-colorability is already NP-complete, hence parameterizing\nby the requested number of colors is not fruitful. Instead, we pick up on a\nresearch thread initiated by Cai (DAM, 2003) who studied coloring problems\nparameterized by the modification distance of the input graph to a graph class\non which coloring is polynomial-time solvable; for example parameterizing by\nthe number k of vertex-deletions needed to make the graph chordal. We obtain\nvarious upper and lower bounds for kernels of such parameterizations of\nq-Coloring, complementing Cai's study of the time complexity with respect to\nthese parameters.\n  Our results show that the existence of polynomial kernels for q-Coloring\nparameterized by the vertex-deletion distance to a graph class F is strongly\nrelated to the existence of a function f(q) which bounds the number of vertices\nwhich are needed to preserve the NO-answer to an instance of q-List-Coloring on\nF.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2011 10:55:45 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2013 10:46:50 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Jansen", "Bart M. P.", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1104.4423", "submitter": "Ioannis Caragiannis", "authors": "John Augustine, Ioannis Caragiannis, Angelo Fanelli, Christos\n  Kalaitzis", "title": "Enforcing efficient equilibria in network design games via subsidies", "comments": "30 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient design of networks has been an important engineering task that\ninvolves challenging combinatorial optimization problems. Typically, a network\ndesigner has to select among several alternatives which links to establish so\nthat the resulting network satisfies a given set of connectivity requirements\nand the cost of establishing the network links is as low as possible. The\nMinimum Spanning Tree problem, which is well-understood, is a nice example.\n  In this paper, we consider the natural scenario in which the connectivity\nrequirements are posed by selfish users who have agreed to share the cost of\nthe network to be established according to a well-defined rule. The design\nproposed by the network designer should now be consistent not only with the\nconnectivity requirements but also with the selfishness of the users.\nEssentially, the users are players in a so-called network design game and the\nnetwork designer has to propose a design that is an equilibrium for this game.\nAs it is usually the case when selfishness comes into play, such equilibria may\nbe suboptimal. In this paper, we consider the following question: can the\nnetwork designer enforce particular designs as equilibria or guarantee that\nefficient designs are consistent with users' selfishness by appropriately\nsubsidizing some of the network links? In an attempt to understand this\nquestion, we formulate corresponding optimization problems and present positive\nand negative results.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2011 12:00:10 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2011 16:56:48 GMT"}], "update_date": "2011-07-12", "authors_parsed": [["Augustine", "John", ""], ["Caragiannis", "Ioannis", ""], ["Fanelli", "Angelo", ""], ["Kalaitzis", "Christos", ""]]}, {"id": "1104.4433", "submitter": "Zolt\\'an K\\'asa", "authors": "Vladimir Yu. Popov", "title": "Arc-preserving subsequences of arc-annotated sequences", "comments": null, "journal-ref": "Acta Univ. Sapientiae, Informatica 3, 1 (2011) 35--47", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arc-annotated sequences are useful in representing the structural information\nof RNA and protein sequences. The longest arc-preserving common subsequence\nproblem has been introduced as a framework for studying the similarity of\narc-annotated sequences. In this paper, we consider arc-annotated sequences\nwith various arc structures. We consider the longest arc preserving common\nsubsequence problem. In particular, we show that the decision version of the\n1-{\\sc fragment LAPCS(crossing,chain)} and the decision version of the 0-{\\sc\ndiagonal LAPCS(crossing,chain)} are {\\bf NP}-complete for some fixed alphabet\n$\\Sigma$ such that $|\\Sigma| = 2$. Also we show that if $|\\Sigma| = 1$, then\nthe decision version of the 1-{\\sc fragment LAPCS(unlimited, plain)} and the\ndecision version of the 0-{\\sc diagonal LAPCS(unlimited, plain)} are {\\bf\nNP}-complete.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2011 13:13:19 GMT"}], "update_date": "2011-04-25", "authors_parsed": [["Popov", "Vladimir Yu.", ""]]}, {"id": "1104.4468", "submitter": "J\\'er\\'emie Roland", "authors": "Troy Lee and J\\'er\\'emie Roland", "title": "A strong direct product theorem for quantum query complexity", "comments": "V2: 19 pages (various additions and improvements, in particular:\n  improved parameters in the main theorems due to a finer analysis of the\n  output condition, and addition of an XOR lemma and a threshold direct product\n  theorem in the boolean case). V3: 19 pages (added grant information)", "journal-ref": "27th IEEE Conference on Computational Complexity (CCC'12), pages\n  236-246, 2012", "doi": "10.1109/CCC.2012.17", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that quantum query complexity satisfies a strong direct product\ntheorem. This means that computing $k$ copies of a function with less than $k$\ntimes the quantum queries needed to compute one copy of the function implies\nthat the overall success probability will be exponentially small in $k$. For a\nboolean function $f$ we also show an XOR lemma---computing the parity of $k$\ncopies of $f$ with less than $k$ times the queries needed for one copy implies\nthat the advantage over random guessing will be exponentially small.\n  We do this by showing that the multiplicative adversary method, which\ninherently satisfies a strong direct product theorem, is always at least as\nlarge as the additive adversary method, which is known to characterize quantum\nquery complexity.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2011 15:38:45 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2011 15:29:32 GMT"}, {"version": "v3", "created": "Fri, 8 Jul 2011 18:04:16 GMT"}], "update_date": "2012-07-23", "authors_parsed": [["Lee", "Troy", ""], ["Roland", "J\u00e9r\u00e9mie", ""]]}, {"id": "1104.4490", "submitter": "Amar Mukherjee", "authors": "Amar Mukherjee", "title": "The 3-satisfiability problem", "comments": "This paper is withdrawn by the author because a revision has been\n  developed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deterministic polynomial-time algorithm that solves the\n3-satisfiability problem.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2011 19:29:22 GMT"}, {"version": "v2", "created": "Thu, 5 Jan 2012 21:27:48 GMT"}], "update_date": "2012-01-09", "authors_parsed": [["Mukherjee", "Amar", ""]]}, {"id": "1104.4680", "submitter": "Prasad Raghavendra", "authors": "Boaz Barak, Prasad Raghavendra, David Steurer", "title": "Rounding Semidefinite Programming Hierarchies via Global Correlation", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a new way to round vector solutions of semidefinite programming (SDP)\nhierarchies into integral solutions, based on a connection between these\nhierarchies and the spectrum of the input graph. We demonstrate the utility of\nour method by providing a new SDP-hierarchy based algorithm for constraint\nsatisfaction problems with 2-variable constraints (2-CSP's).\n  More concretely, we show for every 2-CSP instance I a rounding algorithm for\nr rounds of the Lasserre SDP hierarchy for I that obtains an integral solution\nthat is at most \\eps worse than the relaxation's value (normalized to lie in\n[0,1]), as long as r > k\\cdot\\rank_{\\geq \\theta}(\\Ins)/\\poly(\\e) \\;, where k is\nthe alphabet size of I, $\\theta=\\poly(\\e/k)$, and $\\rank_{\\geq \\theta}(\\Ins)$\ndenotes the number of eigenvalues larger than $\\theta$ in the normalized\nadjacency matrix of the constraint graph of $\\Ins$.\n  In the case that $\\Ins$ is a \\uniquegames instance, the threshold $\\theta$ is\nonly a polynomial in $\\e$, and is independent of the alphabet size. Also in\nthis case, we can give a non-trivial bound on the number of rounds for\n\\emph{every} instance. In particular our result yields an SDP-hierarchy based\nalgorithm that matches the performance of the recent subexponential algorithm\nof Arora, Barak and Steurer (FOCS 2010) in the worst case, but runs faster on a\nnatural family of instances, thus further restricting the set of possible hard\ninstances for Khot's Unique Games Conjecture.\n  Our algorithm actually requires less than the $n^{O(r)}$ constraints\nspecified by the $r^{th}$ level of the Lasserre hierarchy, and in some cases\n$r$ rounds of our program can be evaluated in time $2^{O(r)}\\poly(n)$.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2011 04:58:50 GMT"}], "update_date": "2011-04-26", "authors_parsed": [["Barak", "Boaz", ""], ["Raghavendra", "Prasad", ""], ["Steurer", "David", ""]]}, {"id": "1104.4746", "submitter": "Ali Sinop", "authors": "Venkatesan Guruswami and Ali Kemal Sinop", "title": "Lasserre Hierarchy, Higher Eigenvalues, and Approximation Schemes for\n  Quadratic Integer Programming with PSD Objectives", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approximation scheme for optimizing certain Quadratic Integer\nProgramming problems with positive semidefinite objective functions and global\nlinear constraints. This framework includes well known graph problems such as\nMinimum graph bisection, Edge expansion, Uniform sparsest cut, and Small Set\nexpansion, as well as the Unique Games problem. These problems are notorious\nfor the existence of huge gaps between the known algorithmic results and\nNP-hardness results. Our algorithm is based on rounding semidefinite programs\nfrom the Lasserre hierarchy, and the analysis uses bounds for low-rank\napproximations of a matrix in Frobenius norm using columns of the matrix.\n  For all the above graph problems, we give an algorithm running in time\n$n^{O(r/\\epsilon^2)}$ with approximation ratio\n$\\frac{1+\\epsilon}{\\min\\{1,\\lambda_r\\}}$, where $\\lambda_r$ is the $r$'th\nsmallest eigenvalue of the normalized graph Laplacian $\\mathcal{L}$. In the\ncase of graph bisection and small set expansion, the number of vertices in the\ncut is within lower-order terms of the stipulated bound. Our results imply\n$(1+O(\\epsilon))$ factor approximation in time $n^{O(r^\\ast/\\epsilon^2)}$ where\n$r^\\ast$ is the number of eigenvalues of $\\mathcal{L}$ smaller than\n$1-\\epsilon$.\n  For Unique Games, we give a factor $(1+\\frac{2+\\epsilon}{\\lambda_r})$\napproximation for minimizing the number of unsatisfied constraints in\n$n^{O(r/\\epsilon)}$ time. This improves an earlier bound for solving Unique\nGames on expanders, and also shows that Lasserre SDPs are powerful enough to\nsolve well-known integrality gap instances for the basic SDP.\n  We also give an algorithm for independent sets in graphs that performs well\nwhen the Laplacian does not have too many eigenvalues bigger than $1+o(1)$.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2011 16:32:51 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2011 17:18:28 GMT"}, {"version": "v3", "created": "Wed, 18 May 2011 01:08:50 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Sinop", "Ali Kemal", ""]]}, {"id": "1104.4779", "submitter": "Barnaby Martin", "authors": "Barnaby Martin and Daniel Paulusma", "title": "The Computational Complexity of Disconnected Cut and 2K2-Partition", "comments": "Conference version appeared at CP 2011. To appear JCTB (DOI:\n  10.1016/j.jctb.2014.09.002)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a connected graph G=(V,E), a subset U of V is called a disconnected cut\nif U disconnects the graph and the subgraph induced by U is disconnected as\nwell. We show that the problem to test whether a graph has a disconnected cut\nis NP-complete. This problem is polynomially equivalent to the following\nproblems: testing if a graph has a 2K2-partition, testing if a graph allows a\nvertex-surjective homomorphism to the reflexive 4-cycle and testing if a graph\nhas a spanning subgraph that consists of at most two bicliques. Hence, as an\nimmediate consequence, these three decision problems are NP-complete as well.\nThis settles an open problem frequently posed in each of the four settings.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2011 19:49:40 GMT"}, {"version": "v2", "created": "Fri, 9 Sep 2011 14:55:03 GMT"}, {"version": "v3", "created": "Wed, 29 Oct 2014 14:05:37 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Martin", "Barnaby", ""], ["Paulusma", "Daniel", ""]]}, {"id": "1104.4993", "submitter": "Berit Gru{\\ss}ien", "authors": "Hubie Chen, Victor Dalmau, Berit Gru{\\ss}ien", "title": "Arc Consistency and Friends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural and established way to restrict the constraint satisfaction problem\nis to fix the relations that can be used to pose constraints; such a family of\nrelations is called a constraint language. In this article, we study arc\nconsistency, a heavily investigated inference method, and three extensions\nthereof from the perspective of constraint languages. We conduct a comparison\nof the studied methods on the basis of which constraint languages they solve,\nand we present new polynomial-time tractability results for singleton arc\nconsistency, the most powerful method studied.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2011 18:52:57 GMT"}], "update_date": "2011-04-27", "authors_parsed": [["Chen", "Hubie", ""], ["Dalmau", "Victor", ""], ["Gru\u00dfien", "Berit", ""]]}, {"id": "1104.5226", "submitter": "David Doty", "authors": "Ho-Lin Chen and David Doty", "title": "Parallelism and Time in Hierarchical Self-Assembly", "comments": "accepted to appear in SIAM Journal on Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the role that parallelism plays in time complexity of Winfree's\nabstract Tile Assembly Model (aTAM), a model of molecular algorithmic\nself-assembly. In the \"hierarchical\" aTAM, two assemblies, both consisting of\nmultiple tiles, are allowed to aggregate together, whereas in the \"seeded\"\naTAM, tiles attach one at a time to a growing assembly. Adleman, Cheng, Goel,\nand Huang (\"Running Time and Program Size for Self-Assembled Squares\", STOC\n2001) showed how to assemble an n x n square in O(n) time in the seeded aTAM\nusing O(log n / log log n) unique tile types, where both of these parameters\nare optimal. They asked whether the hierarchical aTAM could allow a tile system\nto use the ability to form large assemblies in parallel before they attach to\nbreak the Omega(n) lower bound for assembly time. We show that there is a tile\nsystem with the optimal O(log n / log log n) tile types that assembles an n x n\nsquare using O(log^2 n) parallel \"stages\", which is close to the optimal\nOmega(log n) stages, forming the final n x n square from four n/2 x n/2\nsquares, which are themselves recursively formed from n/4 x n/4 squares, etc.\nHowever, despite this nearly maximal parallelism, the system requires\nsuperlinear time to assemble the square. We extend the definition of *partial\norder tile systems* studied by Adleman et al. in a natural way to hierarchical\nassembly and show that no hierarchical partial order tile system can build any\nshape with diameter N in less than time Omega(N), demonstrating that in this\ncase the hierarchical model affords no speedup whatsoever over the seeded\nmodel. We strengthen the Omega(N) time lower bound for deterministic seeded\nsystems of Adleman et al. to nondeterministic seeded systems. Finally, we show\nthat for infinitely many n, a tile system can assemble an n x n' rectangle,\nwith n > n', in time O(n^{4/5} log n), breaking the linear-time lower bound.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2011 19:56:01 GMT"}, {"version": "v2", "created": "Sun, 12 Feb 2017 18:35:40 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Chen", "Ho-Lin", ""], ["Doty", "David", ""]]}, {"id": "1104.5257", "submitter": "Barnaby Martin", "authors": "Manuel Bodirsky, Jan Kara, Barnaby Martin", "title": "The Complexity of Surjective Homomorphism Problems -- a Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey known results about the complexity of surjective homomorphism\nproblems, studied in the context of related problems in the literature such as\nlist homomorphism, retraction and compaction. In comparison with these\nproblems, surjective homomorphism problems seem to be harder to classify and we\nexamine especially three concrete problems that have arisen from the\nliterature, two of which remain of open complexity.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2011 21:42:53 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2011 21:12:10 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Kara", "Jan", ""], ["Martin", "Barnaby", ""]]}, {"id": "1104.5566", "submitter": "Stefan Szeider", "authors": "Stefan Szeider", "title": "Limits of Preprocessing", "comments": "This is a slightly longer version of a paper that appeared in the\n  proceedings of AAAI 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a first theoretical analysis of the power of polynomial-time\npreprocessing for important combinatorial problems from various areas in AI. We\nconsider problems from Constraint Satisfaction, Global Constraints,\nSatisfiability, Nonmonotonic and Bayesian Reasoning. We show that, subject to a\ncomplexity theoretic assumption, none of the considered problems can be reduced\nby polynomial-time preprocessing to a problem kernel whose size is polynomial\nin a structural problem parameter of the input, such as induced width or\nbackdoor size. Our results provide a firm theoretical boundary for the\nperformance of polynomial-time preprocessing algorithms for the considered\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2011 08:31:41 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2011 15:53:23 GMT"}], "update_date": "2011-08-12", "authors_parsed": [["Szeider", "Stefan", ""]]}, {"id": "1104.5642", "submitter": "Luca Moscardelli", "authors": "Angelo Fanelli, Luca Moscardelli and Alexander Skopalik", "title": "On the Impact of Fair Best Response Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we completely characterize how the frequency with which each\nplayer participates in the game dynamics affects the possibility of reaching\nefficient states, i.e., states with an approximation ratio within a constant\nfactor from the price of anarchy, within a polynomially bounded number of best\nresponses. We focus on the well known class of congestion games and we show\nthat, if each player is allowed to play at least once and at most $\\beta$ times\nany $T$ best responses, states with approximation ratio $O(\\beta)$ times the\nprice of anarchy are reached after $T \\lceil \\log \\log n \\rceil$ best\nresponses, and that such a bound is essentially tight also after exponentially\nmany ones. One important consequence of our result is that the fairness among\nplayers is a necessary and sufficient condition for guaranteeing a fast\nconvergence to efficient states. This answers the important question of the\nmaximum order of $\\beta$ needed to fast obtain efficient states, left open by\n[9,10] and [3], in which fast convergence for constant $\\beta$ and very slow\nconvergence for $\\beta=O(n)$ have been shown, respectively. Finally, we show\nthat the structure of the game implicitly affects its performances. In\nparticular, we show that in the symmetric setting, in which all players share\nthe same set of strategies, the game always converges to an efficient state\nafter a polynomial number of best responses, regardless of the frequency each\nplayer moves with.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2011 14:59:17 GMT"}], "update_date": "2011-05-02", "authors_parsed": [["Fanelli", "Angelo", ""], ["Moscardelli", "Luca", ""], ["Skopalik", "Alexander", ""]]}]