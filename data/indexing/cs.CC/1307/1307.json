[{"id": "1307.0189", "submitter": "Philippe Dumas", "authors": "Philippe Dumas", "title": "Rational series and asymptotic expansion for linear homogeneous\n  divide-and-conquer recurrences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among all sequences that satisfy a divide-and-conquer recurrence, the\nsequences that are rational with respect to a numeration system are certainly\nthe most immediate and most essential. Nevertheless, until recently they have\nnot been studied from the asymptotic standpoint. We show how a mechanical\nprocess permits to compute their asymptotic expansion. It is based on linear\nalgebra, with Jordan normal form, joint spectral radius, and dilation\nequations. The method is compared with the analytic number theory approach,\nbased on Dirichlet series and residues, and new ways to compute the Fourier\nseries of the periodic functions involved in the expansion are developed. The\narticle comes with an extended bibliography.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2013 09:44:27 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Dumas", "Philippe", ""]]}, {"id": "1307.0556", "submitter": "Leslie Ann Goldberg", "authors": "Andreas G\\\"obel and Leslie Ann Goldberg and David Richerby", "title": "The Complexity of Counting Homomorphisms to Cactus Graphs Modulo 2", "comments": "minor changes", "journal-ref": null, "doi": "10.1145/2635825", "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A homomorphism from a graph G to a graph H is a function from V(G) to V(H)\nthat preserves edges. Many combinatorial structures that arise in mathematics\nand computer science can be represented naturally as graph homomorphisms and as\nweighted sums of graph homomorphisms. In this paper, we study the complexity of\ncounting homomorphisms modulo 2. The complexity of modular counting was\nintroduced by Papadimitriou and Zachos and it has been pioneered by Valiant who\nfamously introduced a problem for which counting modulo 7 is easy but counting\nmodulo 2 is intractable. Modular counting provides a rich setting in which to\nstudy the structure of homomorphism problems. In this case, the structure of\nthe graph H has a big influence on the complexity of the problem. Thus, our\napproach is graph-theoretic. We give a complete solution for the class of\ncactus graphs, which are connected graphs in which every edge belongs to at\nmost one cycle. Cactus graphs arise in many applications such as the modelling\nof wireless sensor networks and the comparison of genomes. We show that, for\nsome cactus graphs H, counting homomorphisms to H modulo 2 can be done in\npolynomial time. For every other fixed cactus graph H, the problem is complete\nfor the complexity class parity-P which is a wide complexity class to which\nevery problem in the polynomial hierarchy can be reduced (using randomised\nreductions). Determining which H lead to tractable problems can be done in\npolynomial time. Our result builds upon the work of Faben and Jerrum, who gave\na dichotomy for the case in which H is a tree.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2013 23:02:31 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2013 13:10:20 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2014 14:12:48 GMT"}, {"version": "v4", "created": "Fri, 25 Apr 2014 13:56:39 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["G\u00f6bel", "Andreas", ""], ["Goldberg", "Leslie Ann", ""], ["Richerby", "David", ""]]}, {"id": "1307.0836", "submitter": "Stephen Jordan", "authors": "Stephen P. Jordan", "title": "Strong equivalence of reversible circuits is coNP-complete", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": "Quantum Information and Computation 14(15/16):1302-1307, 2014", "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that deciding equivalence of logic circuits is a\ncoNP-complete problem. As a corollary, the problem of deciding weak equivalence\nof reversible circuits, i.e. ignoring the ancilla bits, is also coNP-complete.\nThe complexity of deciding strong equivalence, including the ancilla bits, is\nless obvious and may depend on gate set. Here we use Barrington's theorem to\nshow that deciding strong equivalence of reversible circuits built from the\nFredkin gate is coNP-complete. This implies coNP-completeness of deciding\nstrong equivalence for other commonly used universal reversible gate sets,\nincluding any gate set that includes the Toffoli or Fredkin gate.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2013 20:27:35 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Jordan", "Stephen P.", ""]]}, {"id": "1307.1157", "submitter": "Yi Ming Zou", "authors": "Yi Ming Zou", "title": "Representing Boolean Functions Using Polynomials: More Can Offer Less", "comments": "A shorter version of this article appeared in LNCS 6677, 2011", "journal-ref": "LNCS 6677, 2011, pp. 290-296", "doi": null, "report-no": null, "categories": "cs.CC math.CO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polynomial threshold gates are basic processing units of an artificial neural\nnetwork. When the input vectors are binary vectors, these gates correspond to\nBoolean functions and can be analyzed via their polynomial representations. In\npractical applications, it is desirable to find a polynomial representation\nwith the smallest number of terms possible, in order to use the least possible\nnumber of input lines to the unit under consideration. For this purpose,\ninstead of an exact polynomial representation, usually the sign representation\nof a Boolean function is considered. The non-uniqueness of the sign\nrepresentation allows the possibility for using a smaller number of monomials\nby solving a minimization problem. This minimization problem is combinatorial\nin nature, and so far the best known deterministic algorithm claims the use of\nat most $0.75\\times 2^n$ of the $2^n$ total possible monomials. In this paper,\nthe basic methods of representing a Boolean function by polynomials are\nexamined, and an alternative approach to this problem is proposed. It is shown\nthat it is possible to use at most $0.5\\times 2^n = 2^{n-1}$ monomials based on\nthe $\\{0, 1\\}$ binary inputs by introducing extra variables, and at the same\ntime keeping the degree upper bound at $n$. An algorithm for further reduction\nof the number of terms that used in a polynomial representation is provided.\nExamples show that in certain applications, the improvement achieved by the\nproposed method over the existing methods is significant.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2013 19:05:51 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Zou", "Yi Ming", ""]]}, {"id": "1307.1353", "submitter": "Moritz M\\\"uller", "authors": "Hubie Chen and Moritz M\\\"uller", "title": "One Hierarchy Spawns Another: Graph Deconstructions and the Complexity\n  Classification of Conjunctive Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of conjunctive query evaluation relative to a class of\nqueries; this problem is formulated here as the relational homomorphism problem\nrelative to a class of structures A, wherein each instance must be a pair of\nstructures such that the first structure is an element of A. We present a\ncomprehensive complexity classification of these problems, which strongly links\ngraph-theoretic properties of A to the complexity of the corresponding\nhomomorphism problem. In particular, we define a binary relation on graph\nclasses, which is a preorder, and completely describe the resulting hierarchy\ngiven by this relation. This relation is defined in terms of a notion which we\ncall graph deconstruction and which is a variant of the well-known notion of\ntree decomposition. We then use this hierarchy of graph classes to infer a\ncomplexity hierarchy of homomorphism problems which is comprehensive up to a\ncomputationally very weak notion of reduction, namely, a parameterized version\nof quantifier-free first-order reduction. In doing so, we obtain a\nsignificantly refined complexity classification of homomorphism problems, as\nwell as a unifying, modular, and conceptually clean treatment of existing\ncomplexity classifications. We then present and develop the theory of\nEhrenfeucht-Fraisse-style pebble games which solve the homomorphism problems\nwhere the cores of the structures in A have bounded tree depth. Finally, we use\nour framework to classify the complexity of model checking existential\nsentences having bounded quantifier rank.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 14:35:18 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2016 16:22:58 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Chen", "Hubie", ""], ["M\u00fcller", "Moritz", ""]]}, {"id": "1307.1915", "submitter": "Frank Gurski", "authors": "Frank Gurski, Jochen Rethmann, Egon Wanke", "title": "Complexity of the FIFO Stack-Up Problem", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the combinatorial FIFO stack-up problem. In delivery industry, bins\nhave to be stacked-up from conveyor belts onto pallets with respect to customer\norders. Given k sequences q_1, ..., q_k of labeled bins and a positive integer\np, the aim is to stack-up the bins by iteratively removing the first bin of one\nof the k sequences and put it onto an initially empty pallet of unbounded\ncapacity located at one of p stack-up places. Bins with different pallet labels\nhave to be placed on different pallets, bins with the same pallet label have to\nbe placed on the same pallet. After all bins for a pallet have been removed\nfrom the given sequences, the corresponding stack-up place will be cleared and\nbecomes available for a further pallet. The FIFO stack-up problem is to find a\nstack-up sequence such that all pallets can be build-up with the available p\nstack-up places. In this paper, we introduce two digraph models for the FIFO\nstack-up problem, namely the processing graph and the sequence graph. We show\nthat there is a processing of some list of sequences with at most p stack-up\nplaces if and only if the sequence graph of this list has directed pathwidth at\nmost p-1. This connection implies that the FIFO stack-up problem is NP-complete\nin general, even if there are at most 6 bins for every pallet and that the\nproblem can be solved in polynomial time, if the number p of stack-up places is\nassumed to be fixed. Further the processing graph allows us to show that the\nproblem can be solved in polynomial time, if the number k of sequences is\nassumed to be fixed.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2013 21:02:11 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2013 13:28:19 GMT"}, {"version": "v3", "created": "Sat, 7 Jun 2014 11:10:25 GMT"}, {"version": "v4", "created": "Mon, 20 Apr 2015 08:38:13 GMT"}, {"version": "v5", "created": "Fri, 2 Oct 2015 13:16:56 GMT"}, {"version": "v6", "created": "Thu, 15 Oct 2015 09:24:04 GMT"}], "update_date": "2015-10-16", "authors_parsed": [["Gurski", "Frank", ""], ["Rethmann", "Jochen", ""], ["Wanke", "Egon", ""]]}, {"id": "1307.2187", "submitter": "Micha{\\l} Pilipczuk", "authors": "D\\'aniel Marx, Micha{\\l} Pilipczuk", "title": "Everything you always wanted to know about the parameterized complexity\n  of Subgraph Isomorphism (but were afraid to ask)", "comments": "85 pages, 16 figures; program and input data file can be found as\n  ancillary files. Version [v2]: revised conclusions, ancillary files added\n  properly. Version [v3]: added a remark about fixed-parameter tractability of\n  the Conjoining Matching problem following from Lemma 3.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two graphs $H$ and $G$, the Subgraph Isomorphism problem asks if $H$ is\nisomorphic to a subgraph of $G$. While NP-hard in general, algorithms exist for\nvarious parameterized versions of the problem: for example, the problem can be\nsolved (1) in time $2^{O(|V(H)|)}\\cdot n^{O(\\tw(H))}$ using the color-coding\ntechnique of Alon, Yuster, and Zwick; (2) in time $f(|V(H)|,\\tw(G))\\cdot n$\nusing Courcelle's Theorem; (3) in time $f(|V(H)|,\\genus(G))\\cdot n$ using a\nresult on first-order model checking by Frick and Grohe; or (4) in time\n$f(\\maxdeg(H))\\cdot n^{O(\\tw(G)})$ for connected $H$ using the algorithm of\nMatou\\v{s}ek and Thomas. Already this small sample of results shows that the\nway an algorithm can depend on the parameters is highly nontrivial and subtle.\n  We develop a framework involving 10 relevant parameters for each of $H$ and\n$G$ (such as treewidth, pathwidth, genus, maximum degree, number of vertices,\nnumber of components, etc.), and ask if an algorithm with running time \\[\nf_1(p_1,p_2,..., p_\\ell)\\cdot n^{f_2(p_{\\ell+1},..., p_k)} \\] exist, where each\nof $p_1,..., p_k$ is one of the 10 parameters depending only on $H$ or $G$. We\nshow that {\\em all} the questions arising in this framework are answered by a\nset of 11 maximal positive results (algorithms) and a set of 17 maximal\nnegative results (hardness proofs); some of these results already appear in the\nliterature, while others are new in this paper.\n  On the algorithmic side, our study reveals for example that an unexpected\ncombination of bounded degree, genus, and feedback vertex set number of $G$\ngives rise to a highly nontrivial algorithm for Subgraph Isomorphism. On the\nhardness side, we present W[1]-hardness proofs under extremely restricted\nconditions, such as when $H$ is a bounded-degree tree of constant pathwidth and\n$G$ is a planar graph of bounded pathwidth.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 17:47:45 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2013 15:51:26 GMT"}, {"version": "v3", "created": "Sun, 25 Aug 2013 10:33:09 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Marx", "D\u00e1niel", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1307.3184", "submitter": "Samuel Epstein", "authors": "Samuel Epstein", "title": "Randomness Conservation over Algorithms", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Current discrete randomness and information conservation inequalities are\nover total recursive functions, i.e. restricted to deterministic processing.\nThis restriction implies that an algorithm can break algorithmic randomness\nconservation inequalities. We address this issue by proving tight bounds of\nrandomness and information conservation with respect to recursively enumerable\ntransformations, i.e. processing by algorithms. We also show conservation of\nrandomness of finite strings with respect to enumerable distributions, i.e.\nsemicomputable semi-measures.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2013 16:58:37 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2013 02:11:41 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2013 02:31:38 GMT"}, {"version": "v4", "created": "Mon, 14 Oct 2013 13:05:34 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Epstein", "Samuel", ""]]}, {"id": "1307.3301", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Jan Vondrak", "title": "Optimal Bounds on Approximation of Submodular and XOS Functions by\n  Juntas", "comments": "Extended abstract appears in proceedings of FOCS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the approximability of several classes of real-valued\nfunctions by functions of a small number of variables ({\\em juntas}). Our main\nresults are tight bounds on the number of variables required to approximate a\nfunction $f:\\{0,1\\}^n \\rightarrow [0,1]$ within $\\ell_2$-error $\\epsilon$ over\nthe uniform distribution: 1. If $f$ is submodular, then it is $\\epsilon$-close\nto a function of $O(\\frac{1}{\\epsilon^2} \\log \\frac{1}{\\epsilon})$ variables.\nThis is an exponential improvement over previously known results. We note that\n$\\Omega(\\frac{1}{\\epsilon^2})$ variables are necessary even for linear\nfunctions. 2. If $f$ is fractionally subadditive (XOS) it is $\\epsilon$-close\nto a function of $2^{O(1/\\epsilon^2)}$ variables. This result holds for all\nfunctions with low total $\\ell_1$-influence and is a real-valued analogue of\nFriedgut's theorem for boolean functions. We show that $2^{\\Omega(1/\\epsilon)}$\nvariables are necessary even for XOS functions.\n  As applications of these results, we provide learning algorithms over the\nuniform distribution. For XOS functions, we give a PAC learning algorithm that\nruns in time $2^{poly(1/\\epsilon)} poly(n)$. For submodular functions we give\nan algorithm in the more demanding PMAC learning model (Balcan and Harvey,\n2011) which requires a multiplicative $1+\\gamma$ factor approximation with\nprobability at least $1-\\epsilon$ over the target distribution. Our uniform\ndistribution algorithm runs in time $2^{poly(1/(\\gamma\\epsilon))} poly(n)$.\nThis is the first algorithm in the PMAC model that over the uniform\ndistribution can achieve a constant approximation factor arbitrarily close to 1\nfor all submodular functions. As follows from the lower bounds in (Feldman et\nal., 2013) both of these algorithms are close to optimal. We also give\napplications for proper learning, testing and agnostic learning with value\nqueries of these classes.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2013 00:41:01 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2013 19:06:49 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2015 07:13:28 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Feldman", "Vitaly", ""], ["Vondrak", "Jan", ""]]}, {"id": "1307.3648", "submitter": "David Gajser", "authors": "David Gajser", "title": "Verifying Time Complexity of Deterministic Turing Machines", "comments": "18 pages, 1 figure", "journal-ref": "Theoretical Computer Science, Volume 600, p. 86-97, 2015", "doi": "10.1016/j.tcs.2015.07.028", "report-no": null, "categories": "cs.LO cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, for all reasonable functions $T(n)=o(n\\log n)$, we can\nalgorithmically verify whether a given one-tape Turing machine runs in time at\nmost $T(n)$. This is a tight bound on the order of growth for the function $T$\nbecause we prove that, for $T(n)\\geq(n+1)$ and $T(n)=\\Omega(n\\log n)$, there\nexists no algorithm that would verify whether a given one-tape Turing machine\nruns in time at most $T(n)$.\n  We give results also for the case of multi-tape Turing machines. We show that\nwe can verify whether a given multi-tape Turing machine runs in time at most\n$T(n)$ iff $T(n_0)< (n_0+1)$ for some $n_0\\in\\mathbb{N}$.\n  We prove a very general undecidability result stating that, for any class of\nfunctions $\\mathcal{F}$ that contains arbitrary large constants, we cannot\nverify whether a given Turing machine runs in time $T(n)$ for some\n$T\\in\\mathcal{F}$. In particular, we cannot verify whether a Turing machine\nruns in constant, polynomial or exponential time.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2013 14:21:35 GMT"}, {"version": "v2", "created": "Mon, 19 May 2014 07:55:01 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Gajser", "David", ""]]}, {"id": "1307.3681", "submitter": "J. Maurice Rojas", "authors": "Martin Avendano, Roman Kogan, Mounir Nisse, and J. Maurice Rojas", "title": "Metric Estimates and Membership Complexity for Archimedean Amoebae and\n  Tropical Hypersurfaces", "comments": "21 pages, 5 figures. This version adds a new family of examples\n  showing the optimality of another one of our univariate bounds, and contains\n  a brief comparison with work of Akian, Gaubert, and Sharify on the matrix\n  polynomial problem. Various typos corrected as well", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given any complex Laurent polynomial $f$, $\\mathrm{Amoeba}(f)$ is the image\nof its complex zero set under the coordinate-wise log absolute value map. We\ngive an efficiently constructible polyhedral approximation,\n$\\mathrm{ArchtTrop}(f)$, of $\\mathrm{Amoeba}(f)$, and derive explicit upper and\nlower bounds, solely as a function of the number of monomial terms of $f$, for\nthe Hausdorff distance between these two sets. We also show that deciding\nwhether a given point lies in $\\mathrm{ArchTrop}(f)$ is doable in\npolynomial-time, for any fixed dimension, unlike the corresponding problem for\n$\\mathrm{Amoeba}(f)$, which is $\\mathbf{NP}$-hard already in one variable.\n$\\mathrm{ArchTrop}(f)$ can thus serve as a canonical low order approximation to\nstart any higher order iterative polynomial system solving algorithm, such as\nhomotopy continuation. $\\mathrm{ArchTrop}(f)$ also provides an Archimedean\nanalogue of Kapranov's Non-Archimedean Amoeba Theorem and a higher-dimensional\nextension of earlier estimates of Mikhalkin and Ostrowski.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2013 21:53:50 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2013 19:55:56 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2016 16:29:36 GMT"}, {"version": "v4", "created": "Thu, 16 Mar 2017 19:25:16 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Avendano", "Martin", ""], ["Kogan", "Roman", ""], ["Nisse", "Mounir", ""], ["Rojas", "J. Maurice", ""]]}, {"id": "1307.3682", "submitter": "Maiia Bakhova", "authors": "Maiia Bakhova", "title": "A reduction of 3-SAT problem to Buchberger algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a number of known NP class problems, and majority of them have been\nshown to be equivalent to others. In particular now it is clear that\nconstruction of a Gr\\\"{o}bner basis (or Buchberger algorithm) must be one of\nequivalent problems, but there was no example. In the following paper the\nreduction is constructed.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2013 21:56:52 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Bakhova", "Maiia", ""]]}, {"id": "1307.3824", "submitter": "Keki Burjorjee", "authors": "Keki M. Burjorjee", "title": "The Fundamental Learning Problem that Genetic Algorithms with Uniform\n  Crossover Solve Efficiently and Repeatedly As Evolution Proceeds", "comments": "For an easy introduction to implicit concurrency (with animations),\n  visit\n  http://blog.hackingevolution.net/2013/03/24/implicit-concurrency-in-genetic-algorithms/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CC cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes theoretical bonafides for implicit concurrent\nmultivariate effect evaluation--implicit concurrency for short---a broad and\nversatile computational learning efficiency thought to underlie\ngeneral-purpose, non-local, noise-tolerant optimization in genetic algorithms\nwith uniform crossover (UGAs). We demonstrate that implicit concurrency is\nindeed a form of efficient learning by showing that it can be used to obtain\nclose-to-optimal bounds on the time and queries required to approximately\ncorrectly solve a constrained version (k=7, \\eta=1/5) of a recognizable\ncomputational learning problem: learning parities with noisy membership\nqueries. We argue that a UGA that treats the noisy membership query oracle as a\nfitness function can be straightforwardly used to approximately correctly learn\nthe essential attributes in O(log^1.585 n) queries and O(n log^1.585 n) time,\nwhere n is the total number of attributes. Our proof relies on an accessible\nsymmetry argument and the use of statistical hypothesis testing to reject a\nglobal null hypothesis at the 10^-100 level of significance. It is, to the best\nof our knowledge, the first relatively rigorous identification of efficient\ncomputational learning in an evolutionary algorithm on a non-trivial learning\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2013 06:32:52 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Burjorjee", "Keki M.", ""]]}, {"id": "1307.3863", "submitter": "Meena Mahajan", "authors": "Meena Mahajan", "title": "Algebraic Complexity Classes", "comments": "Corrected some typos, added some references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey describes, at an introductory level, the algebraic complexity\nframework originally proposed by Leslie Valiant in 1979, and some of the\ninsights that have been obtained more recently.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2013 09:31:15 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2013 05:43:23 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Mahajan", "Meena", ""]]}, {"id": "1307.3913", "submitter": "Jakob Nordstrom", "authors": "Jakob Nordstrom (MIT)", "title": "Pebble Games, Proof Complexity, and Time-Space Trade-offs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 3 (September\n  13, 2013) lmcs:1111", "doi": "10.2168/LMCS-9(3:15)2013", "report-no": null, "categories": "cs.CC cs.DM cs.LO math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pebble games were extensively studied in the 1970s and 1980s in a number of\ndifferent contexts. The last decade has seen a revival of interest in pebble\ngames coming from the field of proof complexity. Pebbling has proven to be a\nuseful tool for studying resolution-based proof systems when comparing the\nstrength of different subsystems, showing bounds on proof space, and\nestablishing size-space trade-offs. This is a survey of research in proof\ncomplexity drawing on results and tools from pebbling, with a focus on proof\nspace lower bounds and trade-offs between proof size and proof space.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2013 12:44:08 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2013 19:52:11 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2013 18:42:01 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Nordstrom", "Jakob", "", "MIT"]]}, {"id": "1307.3975", "submitter": "Madhu Sudan", "authors": "Katalin Friedl and Madhu Sudan", "title": "Some Improvements to Total Degree Tests", "comments": "A version of this paper appeared in Proceedings of the 3rd Israel\n  Symposium on Theory of Computing and Systems, Tel Aviv, Israel, Jan 4-7,\n  1995. This version corrects some typographical errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A low-degree test is a collection of simple, local rules for checking the\nproximity of an arbitrary function to a low-degree polynomial. Each rule\ndepends on the function's values at a small number of places. If a function\nsatisfies many rules then it is close to a low-degree polynomial. Low-degree\ntests play an important role in the development of probabilistically checkable\nproofs.\n  In this paper we present two improvements to the efficiency of low-degree\ntests. Our first improvement concerns the smallest field size over which a\nlow-degree test can work. We show how to test that a function is a degree $d$\npolynomial over prime fields of size only $d+2$.\n  Our second improvement shows a better efficiency of the low-degree test of\nRubinfeld and Sudan (Proc. SODA 1992) than previously known. We show concrete\napplications of this improvement via the notion of \"locally checkable codes\".\nThis improvement translates into better tradeoffs on the size versus probe\ncomplexity of probabilistically checkable proofs than previously known.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2013 14:50:59 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Friedl", "Katalin", ""], ["Sudan", "Madhu", ""]]}, {"id": "1307.4308", "submitter": "Junichiro Fukuyama", "authors": "Junichiro Fukuyama", "title": "An Alternative Proof of the Exponential Monotone Complexity of the\n  Clique Function", "comments": "arXiv admin note: substantial text overlap with arXiv:1305.3218", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1985, Razborov discovered a proof that the monotone circuit complexity of\nthe clique problem is super-polynomial. Alon and Boppana improved the result\ninto exponential lower bound exp(\\Omega(n / \\log n)^{1/3})) of a monotone\ncircuit C to compute cliques of size (1/4) (n / log n)^{2/3}, where n is the\nnumber of vertices in a graph. Both proofs are based on the method of\napproximations and Erdos and Rado's sunflower lemma. There has been an interest\nin further generalization of the proof scheme.\n  In this paper, we present a new approach to show the exponential monotone\ncomplexity. Unlike the standard method, it dynamically constructs a counter\nexample: Assuming a monotone circuit C of sub-exponential size to compute\nk-cliques c, an algorithm finds an edge set t containing no c in the\ndisjunctive normal form constructed at the root of C. We call such t a shift.\nThe proof shows that t is disjoint from an edge set z whose removal leaves no\nk-cliques.\n  We explore the set theoretical nature of computation by Boolean circuits. We\ndevelop a theory by finding topological properties of the Hamming space 2^{[n]}\nwhere [n]={1, 2, ..., n}. A structural theorem is presented, which is closely\nrelated to the sunflower lemma and claims a stronger statement in most cases.\nThe theory lays the foundation of the above shift method. It also shows the\nexistence of a sunflower with small core in a family of sets, which is not an\nobvious consequence of the sunflower lemma.\n  Lastly, we point out that the new methodology has potential to apply to a\ngeneral circuit computing cliques due to the dynamic selection of t and z, and\nto improve the Alon-Boppana bound exp(\\Omega(n / \\log n)^{1/3})).\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2013 15:29:16 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2013 07:36:13 GMT"}], "update_date": "2013-09-10", "authors_parsed": [["Fukuyama", "Junichiro", ""]]}, {"id": "1307.4420", "submitter": "Lily Briggs", "authors": "Lily Briggs", "title": "On the Complexity of a Matching Problem with Asymmetric Weights", "comments": "9 pages; v2 fixed typos, made minor clarifications, and added author\n  affiliation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present complexity results regarding a matching-type problem related to\nstructural controllability of dynamical systems modelled on graphs.\nControllability of a dynamical system is the ability to choose certain inputs\nin order to drive the system from any given state to any desired state; a graph\nis said to be structurally controllable if it represents the structure of a\ncontrollable system. We define the Orientation Control Matching problem (OCM)\nto be the problem of orienting an undirected graph in a manner that maximizes\nits structural controllability. A generalized version, the Asymmetric\nOrientation Control Matching problem (AOCM), allows for asymmetric weights on\nthe possible directions of each edge. These problems are closely related to\n2-matchings, disjoint path covers, and disjoint cycle covers. We prove using\nreductions that OCM is polynomially solvable, while AOCM is much harder; we\nshow that it is NP-complete as well as APX-hard.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2013 20:32:45 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2013 14:44:48 GMT"}], "update_date": "2013-07-22", "authors_parsed": [["Briggs", "Lily", ""]]}, {"id": "1307.4440", "submitter": "Ronald de Haan", "authors": "Ronald de Haan, Anna Roub\\'i\\v{c}kov\\'a, Stefan Szeider", "title": "Parameterized Complexity Results for Plan Reuse", "comments": "Proceedings of AAAI 2013, pp. 224-231, AAAI Press, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is a notoriously difficult computational problem of high worst-case\ncomplexity. Researchers have been investing significant efforts to develop\nheuristics or restrictions to make planning practically feasible. Case-based\nplanning is a heuristic approach where one tries to reuse previous experience\nwhen solving similar problems in order to avoid some of the planning effort.\nPlan reuse may offer an interesting alternative to plan generation in some\nsettings.\n  We provide theoretical results that identify situations in which plan reuse\nis provably tractable. We perform our analysis in the framework of\nparameterized complexity, which supports a rigorous worst-case complexity\nanalysis that takes structural properties of the input into account in terms of\nparameters. A central notion of parameterized complexity is fixed-parameter\ntractability which extends the classical notion of polynomial-time tractability\nby utilizing the effect of structural properties of the problem input.\n  We draw a detailed map of the parameterized complexity landscape of several\nvariants of problems that arise in the context of case-based planning. In\nparticular, we consider the problem of reusing an existing plan, imposing\nvarious restrictions in terms of parameters, such as the number of steps that\ncan be added to the existing plan to turn it into a solution of the planning\ninstance at hand.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2013 22:35:15 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["de Haan", "Ronald", ""], ["Roub\u00ed\u010dkov\u00e1", "Anna", ""], ["Szeider", "Stefan", ""]]}, {"id": "1307.4466", "submitter": "EPTCS", "authors": "Michael Huth (Imperial College London), Jim Huan-Pu Kuo (Imperial\n  College London), Nir Piterman (University of Leicester)", "title": "The Rabin index of parity games", "comments": "In Proceedings GandALF 2013, arXiv:1307.4162", "journal-ref": "EPTCS 119, 2013, pp. 35-49", "doi": "10.4204/EPTCS.119.6", "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the descriptive complexity of parity games by taking into account\nthe coloring of their game graphs whilst ignoring their ownership structure.\nColored game graphs are identified if they determine the same winning regions\nand strategies, for all ownership structures of nodes. The Rabin index of a\nparity game is the minimum of the maximal color taken over all equivalent\ncoloring functions. We show that deciding whether the Rabin index is at least k\nis in PTIME for k=1 but NP-hard for all fixed k > 1. We present an EXPTIME\nalgorithm that computes the Rabin index by simplifying its input coloring\nfunction. When replacing simple cycle with cycle detection in that algorithm,\nits output over-approximates the Rabin index in polynomial time. Experimental\nresults show that this approximation yields good values in practice.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2013 01:41:27 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Huth", "Michael", "", "Imperial College London"], ["Kuo", "Jim Huan-Pu", "", "Imperial\n  College London"], ["Piterman", "Nir", "", "University of Leicester"]]}, {"id": "1307.4479", "submitter": "EPTCS", "authors": "Dario Della Monica, Margherita Napoli, Mimmo Parente", "title": "Model checking coalitional games in shortage resource scenarios", "comments": "In Proceedings GandALF 2013, arXiv:1307.4162", "journal-ref": "EPTCS 119, 2013, pp. 240-255", "doi": "10.4204/EPTCS.119.20", "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of multi-agents systems (MAS) has been recently studied taking\ninto account the need of expressing resource bounds. Several logics for\nspecifying properties of MAS have been presented in quite a variety of\nscenarios with bounded resources. In this paper, we study a different\nformalism, called Priced Resource-Bounded Alternating-time Temporal Logic\n(PRBATL), whose main novelty consists in moving the notion of resources from a\nsyntactic level (part of the formula) to a semantic one (part of the model).\nThis allows us to track the evolution of the resource availability along the\ncomputations and provides us with a formalisms capable to model a number of\nreal-world scenarios. Two relevant aspects are the notion of global\navailability of the resources on the market, that are shared by the agents, and\nthe notion of price of resources, depending on their availability. In a\nprevious work of ours, an initial step towards this new formalism was\nintroduced, along with an EXPTIME algorithm for the model checking problem. In\nthis paper we better analyze the features of the proposed formalism, also in\ncomparison with previous approaches. The main technical contribution is the\nproof of the EXPTIME-hardness of the the model checking problem for PRBATL,\nbased on a reduction from the acceptance problem for Linearly-Bounded\nAlternating Turing Machines. In particular, since the problem has multiple\nparameters, we show two fixed-parameter reductions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2013 01:43:23 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Della Monica", "Dario", ""], ["Napoli", "Margherita", ""], ["Parente", "Mimmo", ""]]}, {"id": "1307.4897", "submitter": "Karteek Sreenivasaiah", "authors": "Andreas Krebs, Nutan Limaye, Meena Mahajan, Karteek Sreenivasaiah", "title": "Small Depth Proof Systems", "comments": "19 pages, 1 figure. To appear in MFCS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A proof system for a language L is a function f such that Range(f) is exactly\nL. In this paper, we look at proofsystems from a circuit complexity point of\nview and study proof systems that are computationally very restricted. The\nrestriction we study is: they can be computed by bounded fanin circuits of\nconstant depth (NC^0), or of O(log log n) depth but with O(1) alternations\n(polylog AC^0). Each output bit depends on very few input bits; thus such proof\nsystems correspond to a kind of local error-correction on a theorem-proof pair.\n  We identify exactly how much power we need for proof systems to capture all\nregular languages. We show that all regular language have polylog AC^0 proof\nsystems, and from a previous result (Beyersdorff et al, MFCS 2011, where NC^0\nproof systems were first introduced), this is tight. Our technique also shows\nthat MAJ has polylog AC^0 proof system. We explore the question of whether TAUT\nhas NC^0 proof systems. Addressing this question about 2TAUT, and since 2TAUT\nis closely related to reachability in graphs, we ask the same question about\nReachability. We show that both Undirected Reachability and Directed\nUnReachability have NC^0 proof systems, but Directed Reachability is still\nopen.\n  In the context of how much power is needed for proof systems for languages in\nNP, we observe that proof systems for a good fraction of languages in NP do not\nneed the full power of AC^0; they have SAC^0 or coSAC^0 proof systems.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2013 10:31:44 GMT"}], "update_date": "2013-07-19", "authors_parsed": [["Krebs", "Andreas", ""], ["Limaye", "Nutan", ""], ["Mahajan", "Meena", ""], ["Sreenivasaiah", "Karteek", ""]]}, {"id": "1307.4910", "submitter": "Ville Salo", "authors": "Ville Salo", "title": "Hard Asymptotic Sets for One-Dimensional Cellular Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the (language of the) asymptotic set (and the nonwandering set)\nof a one-dimensional cellular automaton can be $\\SIGMA^1_1$-hard. We do not go\ninto much detail, since the constructions are relatively standard.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2013 11:36:52 GMT"}], "update_date": "2013-07-19", "authors_parsed": [["Salo", "Ville", ""]]}, {"id": "1307.5001", "submitter": "Crist\\'obal Guzm\\'an", "authors": "Cristobal Guzman, Arkadi Nemirovski", "title": "On Lower Complexity Bounds for Large-Scale Smooth Convex Optimization", "comments": "Submitted version (minor changes)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive lower bounds on the black-box oracle complexity of large-scale\nsmooth convex minimization problems, with emphasis on minimizing smooth (with\nHolder continuous, with a given exponent and constant, gradient) convex\nfunctions over high-dimensional ||.||_p-balls, 1<=p<=\\infty. Our bounds turn\nout to be tight (up to logarithmic in the design dimension factors), and can be\nviewed as a substantial extension of the existing lower complexity bounds for\nlarge-scale convex minimization covering the nonsmooth case and the 'Euclidean'\nsmooth case (minimization of convex functions with Lipschitz continuous\ngradients over Euclidean balls). As a byproduct of our results, we demonstrate\nthat the classical Conditional Gradient algorithm is near-optimal, in the sense\nof Information-Based Complexity Theory, when minimizing smooth convex functions\nover high-dimensional ||.||_\\infty-balls and their matrix analogies -- spectral\nnorm balls in the spaces of square matrices.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2013 16:29:21 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2013 13:45:54 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2014 20:03:21 GMT"}, {"version": "v4", "created": "Wed, 28 Nov 2018 03:09:25 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Guzman", "Cristobal", ""], ["Nemirovski", "Arkadi", ""]]}, {"id": "1307.5090", "submitter": "Rajsekar Manokaran", "authors": "Per Austrin and Rajsekar Manokaran and Cenny Wenner", "title": "On the NP-Hardness of Approximating Ordering Constraint Satisfaction\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show improved NP-hardness of approximating Ordering Constraint\nSatisfaction Problems (OCSPs). For the two most well-studied OCSPs, Maximum\nAcyclic Subgraph and Maximum Betweenness, we prove inapproximability of\n$14/15+\\epsilon$ and $1/2+\\epsilon$.\n  An OCSP is said to be approximation resistant if it is hard to approximate\nbetter than taking a uniformly random ordering. We prove that the Maximum\nNon-Betweenness Problem is approximation resistant and that there are width-$m$\napproximation-resistant OCSPs accepting only a fraction $1 / (m/2)!$ of\nassignments. These results provide the first examples of\napproximation-resistant OCSPs subject only to P $\\neq$ \\NP.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2013 21:54:04 GMT"}], "update_date": "2013-07-22", "authors_parsed": [["Austrin", "Per", ""], ["Manokaran", "Rajsekar", ""], ["Wenner", "Cenny", ""]]}, {"id": "1307.5321", "submitter": "Radu Iosif", "authors": "Marius Bozga and Radu Iosif and Filip Konecny", "title": "The Complexity of Reachability Problems for Flat Counter Machines with\n  Periodic Loops", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proves the NP-completeness of the reachability problem for the\nclass of flat counter machines with difference bounds and, more generally,\noctagonal relations, labeling the transitions on the loops. The proof is based\non the fact that the sequence of powers $\\{R^i\\}_{i=1}^\\infty$ of such\nrelations can be encoded as a periodic sequence of matrices, and that both the\nprefix and the period of this sequence are $2^{\\mathcal{O}(\\bin{R})}$ in the\nsize of the binary encoding $\\bin{R}$ of a relation $R$. This result allows to\ncharacterize the complexity of the reachability problem for one of the most\nstudied class of counter machines \\cite{cav10,comon-jurski98}, and has a\npotential impact for other problems in program verification.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2013 09:55:15 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2013 18:48:52 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2013 10:58:13 GMT"}, {"version": "v4", "created": "Sat, 1 Aug 2015 10:09:14 GMT"}, {"version": "v5", "created": "Sun, 14 Feb 2016 15:50:37 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Bozga", "Marius", ""], ["Iosif", "Radu", ""], ["Konecny", "Filip", ""]]}, {"id": "1307.5776", "submitter": "Edouard Bonnet", "authors": "\\'Edouard Bonnet, Vangelis Th. Paschos", "title": "An exact algorithm for 1-in-3 SAT", "comments": "this paper has been withdrawn since there are better results already\n  known. (Note that 1-in-3 SAT is also known as X3SAT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  1-in-3 SAT is an NP-complete variant of 3-SAT\\ where a \"clause\" is satisfied\niff exactly one of its three literal is satisfied. We present here an exact\nalgorithm solving \\oit\\ in time $O^*(1.260^n)$.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2013 17:02:36 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2013 14:56:40 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Paschos", "Vangelis Th.", ""]]}, {"id": "1307.6357", "submitter": "Takakazu Mori", "authors": "Takakazu Mori (Kyoto Sangyo University), Yoshiki Tsujii (Kyoto Sangyo\n  University), Mariko Yasugi (Kyoto Sangyo University)", "title": "Computability of Probability Distributions and Characteristic Functions", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 3 (September\n  3, 2013) lmcs:888", "doi": "10.2168/LMCS-9(3:9)2013", "report-no": null, "categories": "cs.CC cs.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a part of our works on effective properties of probability distributions,\nwe deal with the corresponding characteristic functions. A sequence of\nprobability distributions is computable if and only if the corresponding\nsequence of characteristic functions is computable. As for the onvergence\nproblem, the effectivized Glivenko's theorem holds. Effectivizations of\nBochner's theorem and de Moivre-Laplace central limit theorem are also proved.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 09:44:56 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2013 22:12:57 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2013 18:57:24 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Mori", "Takakazu", "", "Kyoto Sangyo University"], ["Tsujii", "Yoshiki", "", "Kyoto Sangyo\n  University"], ["Yasugi", "Mariko", "", "Kyoto Sangyo University"]]}, {"id": "1307.6414", "submitter": "Stefan K\\\"onig", "authors": "Christian Knauer, Stefan K\\\"onig, Daniel Werner", "title": "Fixed Parameter Complexity and Approximability of Norm Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG math.MG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of maximizing the $p$-th power of a $p$-norm over a\nhalfspace-presented polytope in $\\R^d$ is a convex maximization problem which\nplays a fundamental role in computational convexity. It has been shown in 1986\nthat this problem is $\\NP$-hard for all values $p \\in \\mathbb{N}$, if the\ndimension $d$ of the ambient space is part of the input. In this paper, we use\nthe theory of parametrized complexity to analyze how heavily the hardness of\nnorm maximization relies on the parameter $d$.\n  More precisely, we show that for $p=1$ the problem is fixed parameter\ntractable but that for all $p \\in \\mathbb{N} \\setminus \\{1\\}$ norm maximization\nis W[1]-hard.\n  Concerning approximation algorithms for norm maximization, we show that for\nfixed accuracy, there is a straightforward approximation algorithm for norm\nmaximization in FPT running time, but there is no FPT approximation algorithm,\nthe running time of which depends polynomially on the accuracy.\n  As with the $\\NP$-hardness of norm maximization, the W[1]-hardness\nimmediately carries over to various radius computation tasks in Computational\nConvexity.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 13:36:15 GMT"}], "update_date": "2013-07-25", "authors_parsed": [["Knauer", "Christian", ""], ["K\u00f6nig", "Stefan", ""], ["Werner", "Daniel", ""]]}, {"id": "1307.6429", "submitter": "Youming Qiao", "authors": "G\\'abor Ivanyos, Marek Karpinski, Youming Qiao, Miklos Santha", "title": "Generalized Wong sequences and their applications to Edmonds' problems", "comments": "25 pages; improved presentation; fix some gaps", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design two deterministic polynomial time algorithms for variants of a\nproblem introduced by Edmonds in 1967: determine the rank of a matrix M whose\nentries are homogeneous linear polynomials over the integers. Given a linear\nsubspace B of the n by n matrices over some field F, we consider the following\nproblems: symbolic matrix rank (SMR) is the problem to determine the maximum\nrank among matrices in B, symbolic determinant identity testing (SDIT) is the\nquestion to decide whether there exists a nonsingular matrix in B. The\nconstructive versions of these problems are asking to find a matrix of maximum\nrank, respectively a nonsingular matrix, if there exists one.\n  Our first algorithm solves the constructive SMR when B is spanned by unknown\nrank one matrices, answering an open question of Gurvits. Our second algorithm\nsolves the constructive SDIT when B is spanned by triangularizable matrices,\nbut the triangularization is not given explicitly. Both algorithms work over\nfinite fields of size at least n+1 and over the rational numbers, and the first\nalgorithm actually solves (the non-constructive) SMR independently from the\nfield size. Our main tool to obtain these results is to generalize Wong\nsequences, a classical method to deal with pairs of matrices, to the case of\npairs of matrix spaces.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 14:13:44 GMT"}, {"version": "v2", "created": "Thu, 26 Jun 2014 06:20:33 GMT"}], "update_date": "2014-06-27", "authors_parsed": [["Ivanyos", "G\u00e1bor", ""], ["Karpinski", "Marek", ""], ["Qiao", "Youming", ""], ["Santha", "Miklos", ""]]}, {"id": "1307.6738", "submitter": "Shengyu Zhang", "authors": "Shengyu Zhang", "title": "Efficient quantum protocols for XOR functions", "comments": "11 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for any Boolean function f on {0,1}^n, the bounded-error quantum\ncommunication complexity of XOR functions $f\\circ \\oplus$ satisfies that\n$Q_\\epsilon(f\\circ \\oplus) = O(2^d (\\log\\|\\hat f\\|_{1,\\epsilon} + \\log\n\\frac{n}{\\epsilon}) \\log(1/\\epsilon))$, where d is the F2-degree of f, and\n$\\|\\hat f\\|_{1,\\epsilon} = \\min_{g:\\|f-g\\|_\\infty \\leq \\epsilon} \\|\\hat f\\|_1$.\nThis implies that the previous lower bound $Q_\\epsilon(f\\circ \\oplus) =\n\\Omega(\\log\\|\\hat f\\|_{1,\\epsilon})$ by Lee and Shraibman \\cite{LS09} is tight\nfor f with low F2-degree. The result also confirms the quantum version of the\nLog-rank Conjecture for low-degree XOR functions. In addition, we show that the\nexact quantum communication complexity satisfies $Q_E(f) = O(2^d \\log \\|\\hat\nf\\|_0)$, where $\\|\\hat f\\|_0$ is the number of nonzero Fourier coefficients of\nf. This matches the previous lower bound $Q_E(f(x,y)) = \\Omega(\\log rank(M_f))$\nby Buhrman and de Wolf \\cite{BdW01} for low-degree XOR functions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2013 13:37:44 GMT"}], "update_date": "2013-07-26", "authors_parsed": [["Zhang", "Shengyu", ""]]}, {"id": "1307.6948", "submitter": "Hai-Jun Zhou", "authors": "Hai-Jun Zhou", "title": "Spin glass approach to the feedback vertex set problem", "comments": "9 pages, including 4 figures. Title slightly changed. Under\n  consideration in EPJB", "journal-ref": "European Physical Journal B 86: 455 (2013)", "doi": "10.1140/epjb/e2013-40690-1", "report-no": null, "categories": "cs.CC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A feedback vertex set (FVS) of an undirected graph is a set of vertices that\ncontains at least one vertex of each cycle of the graph. The feedback vertex\nset problem consists of constructing a FVS of size less than a certain given\nvalue. This combinatorial optimization problem has many practical applications,\nbut it is in the nondeterministic polynomial-complete class of worst-case\ncomputational complexity. In this paper we define a spin glass model for the\nFVS problem and then study this model on the ensemble of finite-connectivity\nrandom graphs. In our model the global cycle constraints are represented\nthrough the local constraints on all the edges of the graph, and they are then\ntreated by distributed message-passing procedures such as belief propagation.\nOur belief propagation-guided decimation algorithm can construct nearly optimal\nfeedback vertex sets for single random graph instances and regular lattices. We\nalso design a spin glass model for the FVS problem on a directed graph. Our\nwork will be very useful for identifying the set of vertices that contribute\nmost significantly to the dynamical complexity of a large networked system.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2013 08:04:11 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2013 03:26:28 GMT"}], "update_date": "2014-04-22", "authors_parsed": [["Zhou", "Hai-Jun", ""]]}, {"id": "1307.7066", "submitter": "Antti Valmari", "authors": "Antti Valmari", "title": "Asymptotic Proportion of Hard Instances of the Halting Problem", "comments": "18 pages. The differences between this version and arXiv:1307.7066v1\n  are significant. They have been listed in the last paragraph of Section 1.\n  Excluding layout, this arXiv version is essentially identical to the Acta\n  Cybernetica version", "journal-ref": "Acta Cybernetica 21 (2014) 307--330", "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the halting problem is undecidable, imperfect testers that fail on\nsome instances are possible. Such instances are called hard for the tester. One\nvariant of imperfect testers replies \"I don't know\" on hard instances, another\nvariant fails to halt, and yet another replies incorrectly \"yes\" or \"no\". Also\nthe halting problem has three variants: does a given program halt on the empty\ninput, does a given program halt when given itself as its input, or does a\ngiven program halt on a given input. The failure rate of a tester for some size\nis the proportion of hard instances among all instances of that size. This\npublication investigates the behaviour of the failure rate as the size grows\nwithout limit. Earlier results are surveyed and new results are proven. Some of\nthem use C++ on Linux as the computational model. It turns out that the\nbehaviour is sensitive to the details of the programming language or\ncomputational model, but in many cases it is possible to prove that the\nproportion of hard instances does not vanish.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2013 15:16:36 GMT"}, {"version": "v2", "created": "Thu, 27 Nov 2014 13:41:56 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Valmari", "Antti", ""]]}, {"id": "1307.7176", "submitter": "Dustin Mixon", "authors": "Matthew Fickus, Dustin G. Mixon, Aaron A. Nelson, Yang Wang", "title": "Phase retrieval from very few measurements", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.CC cs.IT math.IT", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In many applications, signals are measured according to a linear process, but\nthe phases of these measurements are often unreliable or not available. To\nreconstruct the signal, one must perform a process known as phase retrieval.\nThis paper focuses on completely determining signals with as few intensity\nmeasurements as possible, and on efficient phase retrieval algorithms from such\nmeasurements. For the case of complex M-dimensional signals, we construct a\nmeasurement ensemble of size 4M-4 which yields injective intensity\nmeasurements; this is conjectured to be the smallest such ensemble. For the\ncase of real signals, we devise a theory of \"almost\" injective intensity\nmeasurements, and we characterize such ensembles. Later, we show that phase\nretrieval from M+1 almost injective intensity measurements is NP-hard,\nindicating that computationally efficient phase retrieval must come at the\nprice of measurement redundancy.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2013 21:42:15 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Fickus", "Matthew", ""], ["Mixon", "Dustin G.", ""], ["Nelson", "Aaron A.", ""], ["Wang", "Yang", ""]]}, {"id": "1307.7220", "submitter": "Anmer Daskin", "authors": "Anmer Daskin, Ananth Grama, Sabre Kais", "title": "Multiple Network Alignment on Quantum Computers", "comments": null, "journal-ref": null, "doi": "10.1007/s11128-014-0818-7", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparative analyses of graph structured datasets underly diverse problems.\nExamples of these problems include identification of conserved functional\ncomponents (biochemical interactions) across species, structural similarity of\nlarge biomolecules, and recurring patterns of interactions in social networks.\nA large class of such analyses methods quantify the topological similarity of\nnodes across networks. The resulting correspondence of nodes across networks,\nalso called node alignment, can be used to identify invariant subgraphs across\nthe input graphs.\n  Given $k$ graphs as input, alignment algorithms use topological information\nto assign a similarity score to each $k$-tuple of nodes, with elements (nodes)\ndrawn from each of the input graphs. Nodes are considered similar if their\nneighbors are also similar. An alternate, equivalent view of these network\nalignment algorithms is to consider the Kronecker product of the input graphs,\nand to identify high-ranked nodes in the Kronecker product graph. Conventional\nmethods such as PageRank and HITS (Hypertext Induced Topic Selection) can be\nused for this purpose. These methods typically require computation of the\nprincipal eigenvector of a suitably modified Kronecker product matrix of the\ninput graphs. We adopt this alternate view of the problem to address the\nproblem of multiple network alignment. Using the phase estimation algorithm, we\nshow that the multiple network alignment problem can be efficiently solved on\nquantum computers. We characterize the accuracy and performance of our method,\nand show that it can deliver exponential speedups over conventional\n(non-quantum) methods.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2013 06:37:49 GMT"}, {"version": "v2", "created": "Tue, 26 Aug 2014 14:00:59 GMT"}], "update_date": "2014-09-25", "authors_parsed": [["Daskin", "Anmer", ""], ["Grama", "Ananth", ""], ["Kais", "Sabre", ""]]}, {"id": "1307.7364", "submitter": "Amit Weinstein", "authors": "Noga Alon, Rani Hod, Amit Weinstein", "title": "On active and passive testing", "comments": "16 pages", "journal-ref": "Combinator. Probab. Comp. 25 (2016) 1-20", "doi": "10.1017/S0963548315000292", "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a property of Boolean functions, what is the minimum number of queries\nrequired to determine with high probability if an input function satisfies this\nproperty or is \"far\" from satisfying it? This is a fundamental question in\nProperty Testing, where traditionally the testing algorithm is allowed to pick\nits queries among the entire set of inputs. Balcan, Blais, Blum and Yang have\nrecently suggested to restrict the tester to take its queries from a smaller\nrandom subset of polynomial size of the inputs. This model is called active\ntesting, and in the extreme case when the size of the set we can query from is\nexactly the number of queries performed it is known as passive testing.\n  We prove that passive or active testing of k-linear functions (that is, sums\nof k variables among n over Z_2) requires Theta(k*log n) queries, assuming k is\nnot too large. This extends the case k=1, (that is, dictator functions),\nanalyzed by Balcan et. al.\n  We also consider other classes of functions including low degree polynomials,\njuntas, and partially symmetric functions. Our methods combine algebraic,\ncombinatorial, and probabilistic techniques, including the Talagrand\nconcentration inequality and the Erdos--Rado theorem on Delta-systems.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2013 14:02:44 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2015 21:40:04 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Alon", "Noga", ""], ["Hod", "Rani", ""], ["Weinstein", "Amit", ""]]}, {"id": "1307.7430", "submitter": "Heng Guo", "authors": "Jin-Yi Cai, Heng Guo and Tyson Williams", "title": "Holographic Algorithms Beyond Matchgates", "comments": "Inf. Comput., to appear. Author accepted manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Holographic algorithms introduced by Valiant are composed of two ingredients:\nmatchgates, which are gadgets realizing local constraint functions by weighted\nplanar perfect matchings, and holographic reductions, which show equivalences\namong problems with different descriptions via certain basis transformations.\nIn this paper, we replace matchgates in the paradigm above by the affine type\nand the product type constraint functions, which are known to be tractable in\ngeneral (not necessarily planar) graphs. More specifically, we present\npolynomial-time algorithms to decide if a given counting problem has a\nholographic reduction to another problem defined by the affine or product-type\nfunctions. Our algorithms also find a holographic transformation when one\nexists. We further present polynomial-time algorithms of the same decision and\nsearch problems for symmetric functions, where the complexity is measured in\nterms of the (exponentially more) succinct representations. The algorithm for\nthe symmetric case also shows that the recent dichotomy theorem for Holant\nproblems with symmetric constraints is efficiently decidable. Our proof\ntechniques are mainly algebraic, e.g., using stabilizers and orbits of group\nactions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 01:19:18 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 13:55:06 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Guo", "Heng", ""], ["Williams", "Tyson", ""]]}, {"id": "1307.7615", "submitter": "Raghu Meka", "authors": "Raghu Meka, Avi Wigderson", "title": "Association schemes, non-commutative polynomial concentration, and\n  sum-of-squares lower bounds for planted clique", "comments": "This paper has been withdrawn due to an error; \"Theorem 1.6\" from the\n  original manuscript which is used crucially in the proof of the main result\n  is not correct. We thank Gilles Pisier for pointing this out", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding cliques in random graphs and the closely related \"planted\" clique\nvariant, where a clique of size t is planted in a random G(n,1/2) graph, have\nbeen the focus of substantial study in algorithm design. Despite much effort,\nthe best known polynomial-time algorithms only solve the problem for t =\nTheta(sqrt(n)). Here we show that beating sqrt(n) would require substantially\nnew algorithmic ideas, by proving a lower bound for the problem in the\nsum-of-squares (or Lasserre) hierarchy, the most powerful class of\nsemi-definite programming algorithms we know of: r rounds of the sum-of-squares\nhierarchy can only solve the planted clique for t > sqrt(n)/(C log n)^(r^2).\nPreviously, no nontrivial lower bounds were known. Our proof is formulated as a\ndegree lower bound in the Positivstellensatz algebraic proof system, which is\nequivalent to the sum-of-squares hierarchy. The heart of our (average-case)\nlower bound is a proof that a certain random matrix derived from the input\ngraph is (with high probability) positive semidefinite. Two ingredients play an\nimportant role in this proof. The first is the classical theory of association\nschemes, applied to the average and variance of that random matrix. The second\nis a new large deviation inequality for matrix-valued polynomials. Our new tail\nestimate seems to be of independent interest and may find other applications,\nas it generalizes both the estimates on real-valued polynomials and on sums of\nindependent random matrices.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 15:25:24 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2013 16:38:45 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2013 01:23:35 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Meka", "Raghu", ""], ["Wigderson", "Avi", ""]]}, {"id": "1307.8371", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi, Maria Florina Balcan, Philip M. Long", "title": "The Power of Localization for Efficiently Learning Linear Separators\n  with Noise", "comments": "Contains improved label complexity analysis communicated to us by\n  Steve Hanneke", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach for designing computationally efficient learning\nalgorithms that are tolerant to noise, and demonstrate its effectiveness by\ndesigning algorithms with improved noise tolerance guarantees for learning\nlinear separators.\n  We consider both the malicious noise model and the adversarial label noise\nmodel. For malicious noise, where the adversary can corrupt both the label and\nthe features, we provide a polynomial-time algorithm for learning linear\nseparators in $\\Re^d$ under isotropic log-concave distributions that can\ntolerate a nearly information-theoretically optimal noise rate of $\\eta =\n\\Omega(\\epsilon)$. For the adversarial label noise model, where the\ndistribution over the feature vectors is unchanged, and the overall probability\nof a noisy label is constrained to be at most $\\eta$, we also give a\npolynomial-time algorithm for learning linear separators in $\\Re^d$ under\nisotropic log-concave distributions that can handle a noise rate of $\\eta =\n\\Omega\\left(\\epsilon\\right)$.\n  We show that, in the active learning model, our algorithms achieve a label\ncomplexity whose dependence on the error parameter $\\epsilon$ is\npolylogarithmic. This provides the first polynomial-time active learning\nalgorithm for learning linear separators in the presence of malicious noise or\nadversarial label noise.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2013 16:11:26 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2013 18:51:51 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2013 21:49:27 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2013 19:18:31 GMT"}, {"version": "v5", "created": "Mon, 16 Dec 2013 17:20:36 GMT"}, {"version": "v6", "created": "Fri, 3 Jan 2014 17:20:00 GMT"}, {"version": "v7", "created": "Fri, 7 Mar 2014 17:15:52 GMT"}, {"version": "v8", "created": "Wed, 12 Oct 2016 17:42:40 GMT"}, {"version": "v9", "created": "Sun, 3 Jun 2018 18:22:37 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Balcan", "Maria Florina", ""], ["Long", "Philip M.", ""]]}, {"id": "1307.8425", "submitter": "Sergey Fomin", "authors": "Sergey Fomin, Dima Grigoriev, Gleb Koshevoy", "title": "Subtraction-free complexity, cluster transformations, and spanning trees", "comments": "30 pages. Version 4: Section 8 edited. Version 3: Section 8 is new.\n  Version 2: title changed; Section 7 is new; comparison with the Jerrum-Snir\n  lower bound added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subtraction-free computational complexity is the version of arithmetic\ncircuit complexity that allows only three operations: addition, multiplication,\nand division.\n  We use cluster transformations to design efficient subtraction-free\nalgorithms for computing Schur functions and their skew, double, and\nsupersymmetric analogues, thereby generalizing earlier results by P. Koev.\n  We develop such algorithms for computing generating functions of spanning\ntrees, both directed and undirected. A comparison to the lower bound due to M.\nJerrum and M. Snir shows that in subtraction-free computations, \"division can\nbe exponentially powerful.\"\n  Finally, we give a simple example where the gap between ordinary and\nsubtraction-free complexity is exponential.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2013 18:59:00 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2013 21:32:42 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2013 19:45:46 GMT"}, {"version": "v4", "created": "Sun, 28 Sep 2014 22:15:58 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Fomin", "Sergey", ""], ["Grigoriev", "Dima", ""], ["Koshevoy", "Gleb", ""]]}]