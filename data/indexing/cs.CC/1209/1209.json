[{"id": "1209.0263", "submitter": "Rahul Jain", "authors": "Rahul Jain, Penghui Yao", "title": "A strong direct product theorem in terms of the smooth rectangle bound", "comments": "12 pages, version 3, improved parameters in the main result", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A strong direct product theorem states that, in order to solve k instances of\na problem, if we provide less than k times the resource required to compute one\ninstance, then the probability of overall success is exponentially small in k.\nIn this paper, we consider the model of two-way public-coin communication\ncomplexity and show a strong direct product theorem for all relations in terms\nof the smooth rectangle bound, introduced by Jain and Klauck as a generic lower\nbound method in this model. Our result therefore uniformly implies a strong\ndirect product theorem for all relations for which an (asymptotically) optimal\nlower bound can be provided using the smooth rectangle bound, for example Inner\nProduct, Greater-Than, Set-Disjointness, Gap-Hamming Distance etc. Our result\nalso implies near optimal direct product results for several important\nfunctions and relations used to show exponential separations between classical\nand quantum communication complexity, for which near optimal lower bounds are\nprovided using the rectangle bound, for example by Raz [1999], Gavinsky [2008]\nand Klartag and Regev [2011]. In fact we are not aware of any relation for\nwhich it is known that the smooth rectangle bound does not provide an optimal\nlower bound. This lower bound subsumes many of the other lower bound methods,\nfor example the rectangle bound (a.k.a the corruption bound), the smooth\ndiscrepancy bound (a.k.a the \\gamma_2 bound) which in turn subsumes the\ndiscrepancy bound, the subdistribution bound and the conditional min-entropy\nbound.\n  We show our result using information theoretic arguments. A key tool we use\nis a sampling protocol due to Braverman [2012], in fact a modification of it\nused by Kerenidis, Laplante, Lerays, Roland and Xiao [2012].\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2012 08:02:29 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2012 05:48:28 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2013 08:24:25 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Jain", "Rahul", ""], ["Yao", "Penghui", ""]]}, {"id": "1209.0663", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago, Tobias Heindel, Damiano Mazza, Daniele Varacca", "title": "Computational Complexity of Interactive Behaviors", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of computational complexity focuses on functions and, hence,\nstudies programs whose interactive behavior is reduced to a simple\nquestion/answer pattern. We propose a broader theory whose ultimate goal is\nexpressing and analyzing the intrinsic difficulty of fully general interactive\nbehaviors. To this extent, we use standard tools from concurrency theory,\nincluding labelled transition systems (formalizing behaviors) and their\nasynchronous extension (providing causality information). Behaviors are\nimplemented by means of a multiprocessor machine executing CCS-like processes.\nThe resulting theory is shown to be consistent with the classical definitions:\nwhen we restrict to functional behaviors (i.e., question/answer patterns), we\nrecover several standard computational complexity classes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2012 14:59:08 GMT"}], "update_date": "2012-09-05", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Heindel", "Tobias", ""], ["Mazza", "Damiano", ""], ["Varacca", "Daniele", ""]]}, {"id": "1209.0802", "submitter": "Nerio Borges", "authors": "Nerio Borges", "title": "A sufficient condition for first order non-definability of arrowing\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We here present a sufficient condition for general arrowing problems to be\nnon definable in first order logic, based in well known tools of finite model\ntheory e.g. Hanf's Theorem and known concepts in finite combinatorics, like\nsenders and determiners.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2012 21:22:08 GMT"}], "update_date": "2012-09-06", "authors_parsed": [["Borges", "Nerio", ""]]}, {"id": "1209.1055", "submitter": "Sevag Gharibian", "authors": "Sevag Gharibian, Julia Kempe", "title": "Hardness of approximation for quantum problems", "comments": "21 pages, 1 figure, extended abstract appeared in Proceedings of the\n  39th International Colloquium on Automata, Languages and Programming (ICALP),\n  pages 387-398, Springer, 2012", "journal-ref": "Quantum Information & Computation 14 (5 & 6): 517-540, 2014. Also\n  in Proceedings of ICALP 2012", "doi": "10.1007/978-3-642-31594-7_33", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polynomial hierarchy plays a central role in classical complexity theory.\nHere, we define a quantum generalization of the polynomial hierarchy, and\ninitiate its study. We show that not only are there natural complete problems\nfor the second level of this quantum hierarchy, but that these problems are in\nfact hard to approximate. Using these techniques, we also obtain hardness of\napproximation for the class QCMA. Our approach is based on the use of\ndispersers, and is inspired by the classical results of Umans regarding\nhardness of approximation for the second level of the classical polynomial\nhierarchy [Umans, FOCS 1999]. The problems for which we prove hardness of\napproximation for include, among others, a quantum version of the Succinct Set\nCover problem, and a variant of the local Hamiltonian problem with hybrid\nclassical-quantum ground states.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 17:40:27 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Gharibian", "Sevag", ""], ["Kempe", "Julia", ""]]}, {"id": "1209.1060", "submitter": "Philon Nguyen", "authors": "Philon Nguyen", "title": "Combinatorial Spaces And Order Topologies", "comments": "24 pages, 6 figures, submitted for acceptance in journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An archetypal problem discussed in computer science is the problem of\nsearching for a given number in a given set of numbers. Other than sequential\nsearch, the classic solution is to sort the list of numbers and then apply\nbinary search. The binary search problem has a complexity of O(logN) for a list\nof N numbers while the sorting problem cannot be better than O(N) on any\nsequential computer following the usual assumptions. Whenever the problem of\ndeciding partial order can be done in O(1), a variation of the problem on some\nbounded list of numbers is to apply binary search without resorting to sort.\nThe overall complexity of the problem is then O(log R) for some radius R. A\nlogarithmic upper-bound for finite encodings is shown. Also, the topology of\norderings can provide efficient algorithms for search problems in combinatorial\nspaces. The main characteristic of those spaces is that they have typical\nexponential space complexities. The factorial case describes an order topology\nthat can be illustrated using the combinatorial polytope . When a known order\ntopology can be combined to a given formulation of a search problem, the\nresulting search problem has a polylogarithmic complexity. This logarithmic\ncomplexity can then become useful in combinatorial search by providing a\nlogarithmic break-down. These algorithms can be termed as the class of search\nalgorithms that do not require read and are equivalent to the class of\nlogarithmically recursive functions. Also, the notion of order invariance is\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 17:50:52 GMT"}, {"version": "v10", "created": "Thu, 11 Apr 2013 03:11:24 GMT"}, {"version": "v11", "created": "Sun, 3 Aug 2014 13:51:49 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2012 16:35:37 GMT"}, {"version": "v3", "created": "Thu, 27 Sep 2012 01:29:12 GMT"}, {"version": "v4", "created": "Sat, 29 Sep 2012 16:16:24 GMT"}, {"version": "v5", "created": "Mon, 8 Oct 2012 01:49:44 GMT"}, {"version": "v6", "created": "Tue, 9 Oct 2012 23:34:07 GMT"}, {"version": "v7", "created": "Sat, 15 Dec 2012 17:44:21 GMT"}, {"version": "v8", "created": "Wed, 2 Jan 2013 01:36:35 GMT"}, {"version": "v9", "created": "Sun, 10 Mar 2013 05:03:03 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Nguyen", "Philon", ""]]}, {"id": "1209.1128", "submitter": "Amir Shpilka", "authors": "Amir Shpilka", "title": "Capacity achieving multiwrite WOM codes", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give an explicit construction of a capacity achieving family\nof binary t-write WOM codes for any number of writes t, that have a polynomial\ntime encoding and decoding algorithms. The block length of our construction is\nN=(t/\\epsilon)^{O(t/(\\delta\\epsilon))} when \\epsilon is the gap to capacity and\nencoding and decoding run in time N^{1+\\delta}. This is the first deterministic\nconstruction achieving these parameters. Our techniques also apply to larger\nalphabets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 21:48:33 GMT"}], "update_date": "2012-09-07", "authors_parsed": [["Shpilka", "Amir", ""]]}, {"id": "1209.1664", "submitter": "J. M. Landsberg", "authors": "J.M. Landsberg", "title": "Explicit tensors of border rank at least 2n-1", "comments": "8 pages, version 2 contains a study of Griesser's equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For odd n, I write down tensors in C^n\\otimes C^n\\otimes C^n of border rank\n2n-1, showing the non-triviality of the Young-flattening equations of\nLandsberg-Ottaviani. I also study the border rank of the tensors of Alexeev et.\nal., showing the tensors their tensors T_{2^k}, despite having rank equal to\n2^{k+1}-1, have border rank equal to 2^k, the minimum of any concise tensor. I\nalso study the equations of Griesser.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2012 22:24:47 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2013 17:07:55 GMT"}], "update_date": "2013-08-08", "authors_parsed": [["Landsberg", "J. M.", ""]]}, {"id": "1209.1750", "submitter": "Daniel Grier", "authors": "Daniel Grier", "title": "Deciding the Winner of an Arbitrary Finite Poset Game is PSPACE-Complete", "comments": null, "journal-ref": "ICALP 2013, Part I, LNCS 7965, 2013, pp 497-503", "doi": "10.1007/978-3-642-39206-1_42", "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A poset game is a two-player game played over a partially ordered set (poset)\nin which the players alternate choosing an element of the poset, removing it\nand all elements greater than it. The first player unable to select an element\nof the poset loses. Polynomial time algorithms exist for certain restricted\nclasses of poset games, such as the game of Nim. However, until recently the\ncomplexity of arbitrary finite poset games was only known to exist somewhere\nbetween NC^1 and PSPACE. We resolve this discrepancy by showing that deciding\nthe winner of an arbitrary finite poset game is PSPACE-complete. To this end,\nwe give an explicit reduction from Node Kayles, a PSPACE-complete game in which\nplayers vie to chose an independent set in a graph.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2012 20:19:26 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2013 00:17:47 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Grier", "Daniel", ""]]}, {"id": "1209.1808", "submitter": "Michael Gnewuch", "authors": "Michael Gnewuch", "title": "Lower Error Bounds for Randomized Multilevel and Changing Dimension\n  Algorithms", "comments": "16 pages, 0 figures", "journal-ref": "Monte Carlo and Quasi-Monte Carlo Methods 2012, J. Dick, F. Y.\n  Kuo, G. W. Peters, I. H. Sloan (Eds.), 399-415, Springer, 2013", "doi": null, "report-no": null, "categories": "math.NA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide lower error bounds for randomized algorithms that approximate\nintegrals of functions depending on an unrestricted or even infinite number of\nvariables. More precisely, we consider the infinite-dimensional integration\nproblem on weighted Hilbert spaces with an underlying anchored decomposition\nand arbitrary weights. We focus on randomized algorithms and the randomized\nworst case error. We study two cost models for function evaluation which depend\non the number of active variables of the chosen sample points. Multilevel\nalgorithms behave very well with respect to the first cost model, while\nchanging dimension algorithms and also dimension-wise quadrature methods, which\nare based on a similar idea, can take advantage of the more generous second\ncost model. We prove the first non-trivial lower error bounds for randomized\nalgorithms in these cost models and demonstrate their quality in the case of\nproduct weights. In particular, we show that the randomized changing dimension\nalgorithms provided in [L. Plaskota, G. W. Wasilkowski, J. Complexity 27\n(2011), 505--518] achieve convergence rates arbitrarily close to the optimal\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2012 15:56:32 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Gnewuch", "Michael", ""]]}, {"id": "1209.2184", "submitter": "Benjamin Lipshitz", "authors": "Grey Ballard, James Demmel, Olga Holtz, Benjamin Lipshitz, Oded\n  Schwartz", "title": "Graph Expansion Analysis for Communication Costs of Fast Rectangular\n  Matrix Multiplication", "comments": null, "journal-ref": "Design and Analysis of Algorithms Volume 7659, 2012, pp 13-36", "doi": "10.1007/978-3-642-34862-4_2", "report-no": null, "categories": "cs.DS cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph expansion analysis of computational DAGs is useful for obtaining\ncommunication cost lower bounds where previous methods, such as geometric\nembedding, are not applicable. This has recently been demonstrated for\nStrassen's and Strassen-like fast square matrix multiplication algorithms. Here\nwe extend the expansion analysis approach to fast algorithms for rectangular\nmatrix multiplication, obtaining a new class of communication cost lower\nbounds. These apply, for example to the algorithms of Bini et al. (1979) and\nthe algorithms of Hopcroft and Kerr (1971). Some of our bounds are proved to be\noptimal.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 00:26:21 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Ballard", "Grey", ""], ["Demmel", "James", ""], ["Holtz", "Olga", ""], ["Lipshitz", "Benjamin", ""], ["Schwartz", "Oded", ""]]}, {"id": "1209.2333", "submitter": "Chandan Saha", "authors": "Manindra Agrawal, Chandan Saha and Nitin Saxena", "title": "Quasi-polynomial Hitting-set for Set-depth-Delta Formulas", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We call a depth-4 formula C set-depth-4 if there exists a (unknown) partition\n(X_1,...,X_d) of the variable indices [n] that the top product layer respects,\ni.e. C(x) = \\sum_{i=1}^k \\prod_{j=1}^{d} f_{i,j}(x_{X_j}), where f_{i,j} is a\nsparse polynomial in F[x_{X_j}]. Extending this definition to any depth - we\ncall a depth-Delta formula C (consisting of alternating layers of Sigma and Pi\ngates, with a Sigma-gate on top) a set-depth-Delta formula if every Pi-layer in\nC respects a (unknown) partition on the variables; if Delta is even then the\nproduct gates of the bottom-most Pi-layer are allowed to compute arbitrary\nmonomials.\n  In this work, we give a hitting-set generator for set-depth-Delta formulas\n(over any field) with running time polynomial in exp(({Delta}^2 log s)^{Delta -\n1}), where s is the size bound on the input set-depth-Delta formula. In other\nwords, we give a quasi-polynomial time blackbox polynomial identity test for\nsuch constant-depth formulas. Previously, the very special case of Delta=3\n(also known as set-multilinear depth-3 circuits) had no known sub-exponential\ntime hitting-set generator. This was declared as an open problem by Shpilka &\nYehudayoff (FnT-TCS 2010); the model being first studied by Nisan & Wigderson\n(FOCS 1995). Our work settles this question, not only for depth-3 but, up to\ndepth epsilon.log s / loglog s, for a fixed constant epsilon < 1.\n  The technique is to investigate depth-Delta formulas via depth-(Delta-1)\nformulas over a Hadamard algebra, after applying a `shift' on the variables. We\npropose a new algebraic conjecture about the low-support rank-concentration in\nthe latter formulas, and manage to prove it in the case of set-depth-Delta\nformulas.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 14:39:37 GMT"}], "update_date": "2012-09-12", "authors_parsed": [["Agrawal", "Manindra", ""], ["Saha", "Chandan", ""], ["Saxena", "Nitin", ""]]}, {"id": "1209.2408", "submitter": "Michael Forbes", "authors": "Michael A. Forbes and Amir Shpilka", "title": "Quasipolynomial-time Identity Testing of Non-Commutative and Read-Once\n  Oblivious Algebraic Branching Programs", "comments": "35 pages; v2 updated with improvements for the bounded-width case,\n  results for polynomials of low evaluation dimension, and applications to\n  Noether Normalization", "journal-ref": "54rd Annual IEEE Symposium on Foundations of Computer Science,\n  FOCS 2013,", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of obtaining deterministic black-box polynomial identity\ntesting algorithms (PIT) for algebraic branching programs (ABPs) that are\nread-once and oblivious. This class has an deterministic white-box polynomial\nidentity testing algorithm (due to Raz and Shpilka), but prior to this work\nthere was no known such black-box algorithm.\n  The main result of this work gives the first quasi-polynomial sized hitting\nsets for size S circuits from this class, when the order of the variables is\nknown. As our hitting set is of size exp(lg^2 S), this is analogous (in the\nterminology of boolean pseudorandomness) to a seed-length of lg^2 S, which is\nthe seed length of the pseudorandom generators of Nisan and\nImpagliazzo-Nisan-Wigderson for read-once oblivious boolean branching programs.\n  Our results are stronger for branching programs of bounded width, where we\ngive a hitting set of size exp(lg^2 S/lglg S), corresponding to a seed length\nof lg^2 S/lglg S. This is in stark contrast to the known results for read-once\noblivious boolean branching programs of bounded width, where no pseudorandom\ngenerator (or hitting set) with seed length o(lg^2 S) is known.\n  In follow up work, we strengthened a result of Mulmuley, and showed that\nderandomizing a particular case of the Noether Normalization Lemma is reducible\nto black-box PIT of read-once oblivious ABPs. Using the results of the present\nwork, this gives a derandomization of Noether Normalization in that case, which\nMulmuley conjectured would difficult due to its relations to problems in\nalgebraic geometry.\n  We also show that several other circuit classes can be black-box reduced to\nread-once oblivious ABPs, including set-multilinear ABPs (a generalization of\ndepth-3 set-multilinear formulas), non-commutative ABPs (generalizing\nnon-commutative formulas), and (semi-)diagonal depth-4 circuits (as introduced\nby Saxena).\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 19:52:41 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2013 22:02:53 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Forbes", "Michael A.", ""], ["Shpilka", "Amir", ""]]}, {"id": "1209.2713", "submitter": "Lo\\\"ick Magnin", "authors": "Lo\\\"ick Magnin and J\\'er\\'emie Roland", "title": "Explicit relation between all lower bound techniques for quantum query\n  complexity", "comments": "20 pages. v2: typos corrected", "journal-ref": "Proceedings of the 30th International Symposium on Theoretical\n  Aspects of Computer Science (STACS 2013) p. 434--445", "doi": "10.4230/LIPIcs.STACS.2013.434", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polynomial method and the adversary method are the two main techniques to\nprove lower bounds on quantum query complexity, and they have so far been\nconsidered as unrelated approaches. Here, we show an explicit reduction from\nthe polynomial method to the multiplicative adversary method. The proof goes by\nextending the polynomial method from Boolean functions to quantum state\ngeneration problems. In the process, the bound is even strengthened. We then\nshow that this extended polynomial method is a special case of the\nmultiplicative adversary method with an adversary matrix that is independent of\nthe function. This new result therefore provides insight on the reason why in\nsome cases the adversary method is stronger than the polynomial method. It also\nreveals a clear picture of the relation between the different lower bound\ntechniques, as it implies that all known techniques reduce to the\nmultiplicative adversary method.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2012 20:00:49 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2013 08:44:13 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Magnin", "Lo\u00efck", ""], ["Roland", "J\u00e9r\u00e9mie", ""]]}, {"id": "1209.2875", "submitter": "Daniel Osherson", "authors": "Daniel Osherson and Scott Weinstein", "title": "Notes on random reals", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of random real numbers is exceedingly well-developed, and\nfascinating from many points of view. It is also quite challenging\nmathematically. The present notes are intended as no more than a gateway to the\nlarger theory. They review just the most elementary part of the theory (bearing\non Kolmogorov- and ML-randomness). We hope that the simple arguments presented\nhere will encourage the enterprising student to examine richer treatments of\nthe subject available elsewhere, notably, in Downey and Hirschfeldt (2010).\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2012 12:46:58 GMT"}], "update_date": "2012-09-14", "authors_parsed": [["Osherson", "Daniel", ""], ["Weinstein", "Scott", ""]]}, {"id": "1209.3422", "submitter": "Thomas Seiller", "authors": "Cl\\'ement Aubert and Thomas Seiller", "title": "Characterizing co-NL by a group action", "comments": "To appear in Mathematical Structures in Computer Science", "journal-ref": null, "doi": "10.1017/S0960129514000267", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In a recent paper, Girard proposes to use his recent construction of a\ngeometry of interaction in the hyperfinite factor in an innovative way to\ncharacterize complexity classes. We begin by giving a detailed explanation of\nboth the choices and the motivations of Girard's definitions. We then provide a\ncomplete proof that the complexity class co-NL can be characterized using this\nnew approach. We introduce as a technical tool the non-deterministic pointer\nmachine, a concrete model to computes algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2012 17:47:31 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2012 08:39:34 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2013 15:00:44 GMT"}, {"version": "v4", "created": "Thu, 22 Jan 2015 18:05:39 GMT"}], "update_date": "2015-01-23", "authors_parsed": [["Aubert", "Cl\u00e9ment", ""], ["Seiller", "Thomas", ""]]}, {"id": "1209.3793", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Georg Moser", "title": "Polynomial Path Orders: A Maximal Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper is concerned with the automated complexity analysis of term\nrewrite systems (TRSs for short) and the ramification of these in implicit\ncomputational complexity theory (ICC for short). We introduce a novel path\norder with multiset status, the polynomial path order POP*. Essentially relying\non the principle of predicative recursion as proposed by Bellantoni and Cook,\nits distinct feature is the tight control of resources on compatible TRSs: The\n(innermost) runtime complexity of compatible TRSs is polynomially bounded. We\nhave implemented the technique, as underpinned by our experimental evidence our\napproach to the automated runtime complexity analysis is not only feasible, but\ncompared to existing methods incredibly fast. As an application in the context\nof ICC we provide an order-theoretic characterisation of the polytime\ncomputable functions. To be precise, the polytime computable functions are\nexactly the functions computable by an orthogonal constructor TRS compatible\nwith POP*.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2012 20:38:54 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Avanzini", "Martin", ""], ["Moser", "Georg", ""]]}, {"id": "1209.3849", "submitter": "Arie Matsliah", "authors": "Harry Buhrman, David Garcia-Soriano, Arie Matsliah, and Ronald de Wolf", "title": "The non-adaptive query complexity of testing k-parities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove tight bounds of Theta(k log k) queries for non-adaptively testing\nwhether a function f:{0,1}^n -> {0,1} is a k-parity or far from any k-parity.\nThe lower bound combines a recent method of Blais, Brody and Matulef [BBM11] to\nget lower bounds for testing from communication complexity with an Omega(k \\log\nk) lower bound for the one-way communication complexity of k-disjointness.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2012 05:45:57 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2013 16:56:17 GMT"}], "update_date": "2013-07-04", "authors_parsed": [["Buhrman", "Harry", ""], ["Garcia-Soriano", "David", ""], ["Matsliah", "Arie", ""], ["de Wolf", "Ronald", ""]]}, {"id": "1209.3865", "submitter": "Tanja Hartmann", "authors": "Tanja Hartmann, Jonathan Rollin, Ignaz Rutter", "title": "Cubic Augmentation of Planar Graphs", "comments": "accepted at ISAAC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of augmenting a planar graph such that it\nbecomes 3-regular and remains planar. We show that it is NP-hard to decide\nwhether such an augmentation exists. On the other hand, we give an efficient\nalgorithm for the variant of the problem where the input graph has a fixed\nplanar (topological) embedding that has to be preserved by the augmentation. We\nfurther generalize this algorithm to test efficiently whether a 3-regular\nplanar augmentation exists that additionally makes the input graph connected or\nbiconnected. If the input graph should become even triconnected, we show that\nthe existence of a 3-regular planar augmentation is again NP-hard to decide.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2012 08:01:35 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Hartmann", "Tanja", ""], ["Rollin", "Jonathan", ""], ["Rutter", "Ignaz", ""]]}, {"id": "1209.4865", "submitter": "Florent Capelli", "authors": "Florent Capelli, Arnaud Durand, Stefan Mengel", "title": "The arithmetic complexity of tensor contractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the algebraic complexity of tensor calulus. We consider a\ngeneralization of iterated matrix product to tensors and show that the\nresulting formulas exactly capture VP, the class of polynomial families\nefficiently computable by arithmetic circuits. This gives a natural and robust\ncharacterization of this complexity class that despite its naturalness is not\nvery well understood so far.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2012 17:19:03 GMT"}], "update_date": "2012-09-24", "authors_parsed": [["Capelli", "Florent", ""], ["Durand", "Arnaud", ""], ["Mengel", "Stefan", ""]]}, {"id": "1209.4971", "submitter": "Frederic Magniez", "authors": "Nathana\\\"el Fran\\c{c}ois and Frederic Magniez", "title": "Streaming Complexity of Checking Priority Queues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is in the line of designing efficient checkers for testing the\nreliability of some massive data structures. Given a sequential access to the\ninsert/extract operations on such a structure, one would like to decide, a\nposteriori only, if it corresponds to the evolution of a reliable structure. In\na context of massive data, one would like to minimize both the amount of\nreliable memory of the checker and the number of passes on the sequence of\noperations. Chu, Kannan and McGregor initiated the study of checking priority\nqueues in this setting. They showed that use of timestamps allows to check a\npriority queue with a single pass and memory space O(N^(1/2)), up to a\npolylogarithmic factor. Later, Chakrabarti, Cormode, Kondapally and McGregor\nremoved the use of timestamps, and proved that more passes do not help. We show\nthat, even in the presence of timestamps, more passes do not help, solving a\npreviously open problem. On the other hand, we show that a second pass, but in\nreverse direction, shrinks the memory space to O((log N)^2), extending a\nphenomenon the first time observed by Magniez, Mathieu and Nayak for checking\nwell-parenthesized expressions.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2012 08:37:17 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Fran\u00e7ois", "Nathana\u00ebl", ""], ["Magniez", "Frederic", ""]]}, {"id": "1209.5192", "submitter": "H. G\\\"okalp Demirci", "authors": "H. G\\\"okalp Demirci, A. C. Cem Say and Abuzer Yakary{\\i}lmaz", "title": "Probabilistic verifiers for asymmetric debates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the power of silent constant-space probabilistic verifiers that\nwatch asymmetric debates (where one side is unable to see some of the messages\nof the other) between two deterministic provers, and try to determine who is\nright. We prove that probabilistic verifiers outperform their deterministic\ncounterparts as asymmetric debate checkers. It is shown that the membership\nproblem for every language in NSPACE(s(n)) has a 2^{s(n)}-time debate where one\nprover is completely blind to the other one, for polynomially bounded space\nconstructible s(n). When partial information is allowed to be seen by the\nhandicapped prover, the class of languages debatable in 2^{s(n)} time contains\nTIME(2^{s(n)}), so a probabilistic finite automaton can solve any decision\nproblem in P with small error in polynomial time with the aid of such a debate.\nWe also compare our systems with those with a single prover, and with\ncompeting-prover interactive proof systems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 08:44:46 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Demirci", "H. G\u00f6kalp", ""], ["Say", "A. C. Cem", ""], ["Yakary\u0131lmaz", "Abuzer", ""]]}, {"id": "1209.5267", "submitter": "Simon Perdrix", "authors": "David Cattan\\'eo and Simon Perdrix", "title": "The Parameterized Complexity of Domination-type Problems and Application\n  to Linear Codes", "comments": "19 pages, 2 figures", "journal-ref": "TAMC'14, LNCS vol. 8402, pp.86-103, 2014", "doi": "10.1007/978-3-319-06089-7_7", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of domination-type problems.\n(sigma,rho)-domination is a general and unifying framework introduced by Telle:\na set D of vertices of a graph G is (sigma,rho)-dominating if for any v in D,\n|N(v)\\cap D| in sigma and for any $v\\notin D, |N(v)\\cap D| in rho. We mainly\nshow that for any sigma and rho the problem of (sigma,rho)-domination is W[2]\nwhen parameterized by the size of the dominating set. This general statement is\noptimal in the sense that several particular instances of\n(sigma,rho)-domination are W[2]-complete (e.g. Dominating Set). We also prove\nthat (sigma,rho)-domination is W[2] for the dual parameterization, i.e. when\nparameterized by the size of the dominated set. We extend this result to a\nclass of domination-type problems which do not fall into the\n(sigma,rho)-domination framework, including Connected Dominating Set. We also\nconsider problems of coding theory which are related to domination-type\nproblems with parity constraints. In particular, we prove that the problem of\nthe minimal distance of a linear code over Fq is W[2] for both standard and\ndual parameterizations, and W[1]-hard for the dual parameterization.\n  To prove W[2]-membership of the domination-type problems we extend the\nTuring-way to parameterized complexity by introducing a new kind of non\ndeterministic Turing machine with the ability to perform `blind' transitions,\ni.e. transitions which do not depend on the content of the tapes. We prove that\nthe corresponding problem Short Blind Multi-Tape Non-Deterministic Turing\nMachine is W[2]-complete. We believe that this new machine can be used to prove\nW[2]-membership of other problems, not necessarily related to domination\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 13:41:25 GMT"}, {"version": "v2", "created": "Wed, 14 Jan 2015 09:35:51 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Cattan\u00e9o", "David", ""], ["Perdrix", "Simon", ""]]}, {"id": "1209.5313", "submitter": "Will Perkins", "authors": "Will Perkins", "title": "Random k-SAT and the Power of Two Choices", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an Achlioptas-process version of the random k-SAT process: a bounded\nnumber of k-clauses are drawn uniformly at random at each step, and exactly one\nadded to the growing formula according to a particular rule. We prove the\nexistence of a rule that shifts the satisfiability threshold. This extends a\nwell-studied area of probabilistic combinatorics (Achlioptas processes) to\nrandom CSP's. In particular, while a rule to delay the 2-SAT threshold was\nknown previously, this is the first proof of a rule to shift the threshold of\nk-SAT for k >= 3.\n  We then propose a gap decision problem based upon this semi-random model. The\naim of the problem is to investigate the hardness of the random k-SAT decision\nproblem, as opposed to the problem of finding an assignment or certificate of\nunsatisfiability. Finally, we discuss connections to the study of Achlioptas\nrandom graph processes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 15:59:51 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2013 16:29:37 GMT"}], "update_date": "2013-10-16", "authors_parsed": [["Perkins", "Will", ""]]}, {"id": "1209.5669", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (Institut de Math\\'ematiques de Jussieu, CNRS et\n  Universit\\'e Paris)", "title": "Ambiguity of {\\omega}-Languages of Turing Machines", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 3 (August\n  28, 2014) lmcs:765", "doi": "10.2168/LMCS-10(3:12)2014", "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An {\\omega}-language is a set of infinite words over a finite alphabet X. We\nconsider the class of recursive {\\omega}-languages, i.e. the class of\n{\\omega}-languages accepted by Turing machines with a B\\\"uchi acceptance\ncondition, which is also the class {\\Sigma}11 of (effective) analytic subsets\nof X{\\omega} for some finite alphabet X. We investigate here the notion of\nambiguity for recursive {\\omega}-languages with regard to acceptance by B\\\"uchi\nTuring machines. We first present in detail essentials on the literature on\n{\\omega}-languages accepted by Turing Machines. Then we give a complete and\nbroad view on the notion of ambiguity and unambiguity of B\\\"uchi Turing\nmachines and of the {\\omega}-languages they accept. To obtain our new results,\nwe make use of results and methods of effective descriptive set theory.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 16:21:32 GMT"}, {"version": "v2", "created": "Wed, 18 Jun 2014 16:52:06 GMT"}, {"version": "v3", "created": "Tue, 26 Aug 2014 21:26:19 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Finkel", "Olivier", "", "Institut de Math\u00e9matiques de Jussieu, CNRS et\n  Universit\u00e9 Paris"]]}, {"id": "1209.5932", "submitter": "Subhamoy Maitra", "authors": "Kaushik Chakraborty, Byung-Soo Choi, Arpita Maitra and Subhamoy Maitra", "title": "Efficient quantum algorithm to construct arbitrary Dicke states", "comments": "After posting this draft to the arxiv (September 26, 2012), we\n  received an email from Prof. Andrew M. Childs on October 3, 2012, referring\n  [2] that also considered the same problem. However, our work is independent\n  and uses a different approach. We were not aware of [2] while posting this\n  draft for the first time. We have now included additional material and a\n  detailed comparison with [2]", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study efficient algorithms towards the construction of any\narbitrary Dicke state. Our contribution is to use proper symmetric Boolean\nfunctions that involve manipulations with Krawtchouk polynomials. Deutsch-Jozsa\nalgorithm, Grover algorithm and the parity measurement technique are stitched\ntogether to devise the complete algorithm. Further, motivated by the work of\nChilds et al (2002), we explore how one can plug the biased Hadamard\ntransformation in our strategy. Our work compares fairly with the results of\nChilds et al (2002).\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2012 13:22:24 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2012 13:25:06 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2012 15:41:31 GMT"}, {"version": "v4", "created": "Wed, 7 Nov 2012 03:05:49 GMT"}, {"version": "v5", "created": "Mon, 17 Jun 2013 08:31:12 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Chakraborty", "Kaushik", ""], ["Choi", "Byung-Soo", ""], ["Maitra", "Arpita", ""], ["Maitra", "Subhamoy", ""]]}, {"id": "1209.5993", "submitter": "Ketan Mulmuley D", "authors": "Ketan D. Mulmuley", "title": "Geometric Complexity Theory V: Efficient algorithms for Noether\n  Normalization", "comments": "This is the final version of the article to appear in the Journal of\n  the AMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a basic algorithmic problem in algebraic geometry, which we call\nNNL, of constructing a normalizing map as per Noether's Normalization Lemma.\nFor general explicit varieties, as formally defined in this paper, we give a\nrandomized polynomial-time Monte Carlo algorithm for this problem. For some\ninteresting cases of explicit varieties, we give deterministic quasi-polynomial\ntime algorithms. These may be contrasted with the standard EXPSPACE-algorithms\nfor these problems in computational algebraic geometry.\n  In particular, we show that:\n  (1) The categorical quotient for any finite dimensional representation $V$ of\n$SL_m$, with constant $m$, is explicit in characteristic zero.\n  (2) NNL for this categorical quotient can be solved deterministically in time\nquasi-polynomial in the dimension of $V$.\n  (3) The categorical quotient of the space of $r$-tuples of $m \\times m$\nmatrices by the simultaneous conjugation action of $SL_m$ is explicit in any\ncharacteristic.\n  (4) NNL for this categorical quotient can be solved deterministically in time\nquasi-polynomial in $m$ and $r$ in any characteristic $p$ not in $[2,\\ m/2]$.\n  (5) NNL for every explicit variety in zero or large enough characteristic can\nbe solved deterministically in quasi-polynomial time, assuming the hardness\nhypothesis for the permanent in geometric complexity theory.\n  The last result leads to a geometric complexity theory approach to put NNL\nfor every explicit variety in P.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2012 16:33:26 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2012 23:00:49 GMT"}, {"version": "v3", "created": "Wed, 19 Dec 2012 17:51:32 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2013 11:48:39 GMT"}, {"version": "v5", "created": "Thu, 26 May 2016 17:40:01 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Mulmuley", "Ketan D.", ""]]}]