[{"id": "1502.00067", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae, Harumichi Nishimura", "title": "Quantum interpretations of AWPP and APP", "comments": "22 pages, 1 figure", "journal-ref": "Quantum Information and Computation 16, pp.0498-0514 (2016)", "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AWPP is a complexity class introduced by Fenner, Fortnow, Kurtz, and Li,\nwhich is defined using GapP functions. Although it is an important class as the\nbest upperbound of BQP, its definition seems to be somehow artificial, and\ntherefore it would be better if we have some \"physical interpretation\" of AWPP.\nHere we provide a quantum physical interpretation of AWPP: we show that AWPP is\nequal to the class of problems efficiently solved by a quantum computer with\nthe ability of postselecting an event whose probability is close to an FP\nfunction. This result is applied to also obtain a quantum physical\ninterpretation of APP. In addition, we consider \"classical physical analogue\"\nof these results, and show that a restricted version of ${\\rm BPP}_{\\rm path}$\ncontains ${\\rm UP}\\cap{\\rm coUP}$ and is contained in WAPP.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2015 04:34:44 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2015 07:25:50 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2016 00:04:34 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Morimae", "Tomoyuki", ""], ["Nishimura", "Harumichi", ""]]}, {"id": "1502.00145", "submitter": "Clement Aubert", "authors": "Cl\\'ement Aubert (LACL)", "title": "An in-between \"implicit\" and \"explicit\" complexity: Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit Computational Complexity makes two aspects implicit, by manipulating\nprogramming languages rather than models of com-putation, and by internalizing\nthe bounds rather than using external measure. We survey how automata theory\ncontributed to complexity with a machine-dependant with implicit bounds model.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2015 18:44:47 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 07:33:03 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "LACL"]]}, {"id": "1502.00207", "submitter": "Zhaohui Wei", "authors": "Zhaohui Wei and Shengyu Zhang", "title": "Quantum game players can have advantage without discord", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last two decades have witnessed a rapid development of quantum\ninformation processing, a new paradigm which studies the power and limit of\n\"quantum advantages\" in various information processing tasks. Problems such as\nwhen quantum advantage exists, and if existing, how much it could be, are at a\ncentral position of these studies. In a broad class of scenarios, there are,\nimplicitly or explicitly, at least two parties involved, who share a state, and\nthe correlation in this shared state is the key factor to the efficiency under\nconcern. In these scenarios, the shared \\emph{entanglement} or \\emph{discord}\nis usually what accounts for quantum advantage. In this paper, we examine a\nfundamental problem of this nature from the perspective of game theory, a\nbranch of applied mathematics studying selfish behaviors of two or more\nplayers. We exhibit a natural zero-sum game, in which the chance for any player\nto win the game depends only on the ending correlation. We show that in a\ncertain classical equilibrium, a situation in which no player can further\nincrease her payoff by any local classical operation, whoever first uses a\nquantum computer has a big advantage over its classical opponent. The\nequilibrium is fair to both players and, as a shared correlation, it does not\ncontain any discord, yet a quantum advantage still exists. This indicates that\nat least in game theory, the previous notion of discord as a measure of\nnon-classical correlation needs to be reexamined, when there are two players\nwith different objectives.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 07:04:49 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Wei", "Zhaohui", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1502.00357", "submitter": "Ming-Chuan Yang", "authors": "Chia-Jung Lee, Satya V. Lokam, Shi-Chun Tsai, Ming-Chuan Yang", "title": "On Restricting No-Junta Boolean Function and Degree Lower Bounds by\n  Polynomial Method", "comments": "5 pages, ISIT 2015. Simplified proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Let $\\mathcal{F}_{n}^*$ be the set of Boolean functions depending on all $n$\nvariables. We prove that for any $f\\in \\mathcal{F}_{n}^*$, $f|_{x_i=0}$ or\n$f|_{x_i=1}$ depends on the remaining $n-1$ variables, for some variable $x_i$.\nThis existent result suggests a possible way to deal with general Boolean\nfunctions via its subfunctions of some restrictions.\n  As an application, we consider the degree lower bound of representing\npolynomials over finite rings. Let $f\\in \\mathcal{F}_{n}^*$ and denote the\nexact representing degree over the ring $\\mathbb{Z}_m$ (with the integer $m>2$)\nas $d_m(f)$. Let $m=\\Pi_{i=1}^{r}p_i^{e_i}$, where $p_i$'s are distinct primes,\nand $r$ and $e_i$'s are positive integers. If $f$ is symmetric, then $m\\cdot\nd_{p_1^{e_1}}(f)... d_{p_r^{e_r}}(f) > n$. If $f$ is non-symmetric, by the\nsecond moment method we prove almost always $m\\cdot d_{p_1^{e_1}}(f)...\nd_{p_r^{e_r}}(f) > \\lg{n}-1$. In particular, as $m=pq$ where $p$ and $q$ are\narbitrary distinct primes, we have $d_p(f)d_q(f)=\\Omega(n)$ for symmetric $f$\nand $d_p(f)d_q(f)=\\Omega(\\lg{n}-1)$ almost always for non-symmetric $f$. Hence\nany $n$-variate symmetric Boolean function can have exact representing degree\n$o(\\sqrt{n})$ in at most one finite field, and for non-symmetric functions,\nwith $o(\\sqrt{\\lg{n}})$-degree in at most one finite field.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 04:45:21 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 05:01:07 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Lee", "Chia-Jung", ""], ["Lokam", "Satya V.", ""], ["Tsai", "Shi-Chun", ""], ["Yang", "Ming-Chuan", ""]]}, {"id": "1502.01063", "submitter": "Marvin K\\\"unnemann", "authors": "Karl Bringmann and Marvin K\\\"unnemann", "title": "Quadratic Conditional Lower Bounds for String Problems and Dynamic Time\n  Warping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic similarity measures of strings are longest common subsequence and\nLevenshtein distance (i.e., the classic edit distance). A classic similarity\nmeasure of curves is dynamic time warping. These measures can be computed by\nsimple $O(n^2)$ dynamic programming algorithms, and despite much effort no\nalgorithms with significantly better running time are known.\n  We prove that, even restricted to binary strings or one-dimensional curves,\nrespectively, these measures do not have strongly subquadratic time algorithms,\ni.e., no algorithms with running time $O(n^{2-\\varepsilon})$ for any\n$\\varepsilon > 0$, unless the Strong Exponential Time Hypothesis fails. We\ngeneralize the result to edit distance for arbitrary fixed costs of the four\noperations (deletion in one of the two strings, matching, substitution), by\nidentifying trivial cases that can be solved in constant time, and proving\nquadratic-time hardness on binary strings for all other cost choices. This\nimproves and generalizes the known hardness result for Levenshtein distance\n[Backurs, Indyk STOC'15] by the restriction to binary strings and the\ngeneralization to arbitrary costs, and adds important problems to a recent line\nof research showing conditional lower bounds for a growing number of quadratic\ntime problems.\n  As our main technical contribution, we introduce a framework for proving\nquadratic-time hardness of similarity measures. To apply the framework it\nsuffices to construct a single gadget, which encapsulates all the expressive\npower necessary to emulate a reduction from satisfiability.\n  Finally, we prove quadratic-time hardness for longest palindromic subsequence\nand longest tandem subsequence via reductions from longest common subsequence,\nshowing that conditional lower bounds based on the Strong Exponential Time\nHypothesis also apply to string problems that are not necessarily similarity\nmeasures.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 23:27:26 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2015 21:30:10 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Bringmann", "Karl", ""], ["K\u00fcnnemann", "Marvin", ""]]}, {"id": "1502.01255", "submitter": "Johannes Koebler", "authors": "V. Arvind, Johannes K\\\"obler, Gaurav Rattan, and Oleg Verbitsky", "title": "Graph Isomorphism, Color Refinement, and Compactness", "comments": "30 pages; Lemma 10 is now corrected (see Theorem 9 in the new\n  version); P-hardness proofs for the classes Discrete, Amenable, Compact,\n  Tinhofer, and Refinable are included; a graph separating the classes Tinhofer\n  and Refinable is now included, we had left this open in the previous versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Color refinement is a classical technique used to show that two given graphs\nG and H are non-isomorphic; it is very efficient, although it does not succeed\non all graphs. We call a graph G amenable to color refinement if it succeeds in\ndistinguishing G from any non-isomorphic graph H. Tinhofer (1991) explored a\nlinear programming approach to Graph Isomorphism and defined compact graphs: A\ngraph is compact if its fractional automorphisms polytope is integral. Tinhofer\nnoted that isomorphism testing for compact graphs can be done quite efficiently\nby linear programming. However, the problem of characterizing and recognizing\ncompact graphs in polynomial time remains an open question.\n  Our results are summarized below:\n  - We show that amenable graphs are recognizable in time O((n + m)logn), where\nn and m denote the number of vertices and the number of edges in the input\ngraph.\n  - We show that all amenable graphs are compact.\n  - We study related combinatorial and algebraic graph properties introduced by\nTinhofer and Godsil. The corresponding classes of graphs form a hierarchy and\nwe prove that recognizing each of these graph classes is P-hard. In particular,\nthis gives a first complexity lower bound for recognizing compact graphs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 16:57:33 GMT"}, {"version": "v2", "created": "Mon, 23 Feb 2015 19:13:46 GMT"}, {"version": "v3", "created": "Mon, 4 May 2015 07:38:36 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Arvind", "V.", ""], ["K\u00f6bler", "Johannes", ""], ["Rattan", "Gaurav", ""], ["Verbitsky", "Oleg", ""]]}, {"id": "1502.01257", "submitter": "Thomas Seiller", "authors": "Thomas Seiller", "title": "Towards a Complexity-through-Realisability Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO math.OA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explain how recent developments in the fields of realisability models for\nlinear logic -- or geometry of interaction -- and implicit computational\ncomplexity can lead to a new approach of implicit computational complexity.\nThis semantic-based approach should apply uniformly to various computational\nparadigms, and enable the use of new mathematical methods and tools to attack\nproblem in computational complexity. This paper provides the background,\nmotivations and perspectives of this complexity-through-realisability theory to\nbe developed, and illustrates it with recent results.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 17:15:16 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2015 05:25:49 GMT"}], "update_date": "2015-07-03", "authors_parsed": [["Seiller", "Thomas", ""]]}, {"id": "1502.01335", "submitter": "Andreas Galanis", "authors": "Andreas Galanis, Leslie Ann Goldberg, Mark Jerrum", "title": "Approximately Counting H-Colourings is #BIS-Hard", "comments": null, "journal-ref": null, "doi": "10.1137/15M1020551", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of counting H-colourings from an input graph G to a\ntarget graph H. We show that if H is any fixed graph without trivial\ncomponents, then the problem is as hard as the well-known problem #BIS, which\nis the problem of (approximately) counting independent sets in a bipartite\ngraph. #BIS is a complete problem in an important complexity class for\napproximate counting, and is believed not to have an FPRAS. If this is so, then\nour result shows that for every graph H without trivial components, the\nH-colouring counting problem has no FPRAS. This problem was studied a decade\nago by Goldberg, Kelk and Paterson. They were able to show that approximately\nsampling H-colourings is #BIS-hard, but it was not known how to get the result\nfor approximate counting. Our solution builds on non-constructive ideas using\nthe work of Lovasz.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 20:57:56 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2015 16:40:40 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Galanis", "Andreas", ""], ["Goldberg", "Leslie Ann", ""], ["Jerrum", "Mark", ""]]}, {"id": "1502.01403", "submitter": "Yuchen Zhang", "authors": "Yuchen Zhang, Martin J. Wainwright, Michael I. Jordan", "title": "Distributed Estimation of Generalized Matrix Rank: Efficient Algorithms\n  and Lower Bounds", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following generalized matrix rank estimation problem: given an\n$n \\times n$ matrix and a constant $c \\geq 0$, estimate the number of\neigenvalues that are greater than $c$. In the distributed setting, the matrix\nof interest is the sum of $m$ matrices held by separate machines. We show that\nany deterministic algorithm solving this problem must communicate $\\Omega(n^2)$\nbits, which is order-equivalent to transmitting the whole matrix. In contrast,\nwe propose a randomized algorithm that communicates only $\\widetilde O(n)$\nbits. The upper bound is matched by an $\\Omega(n)$ lower bound on the\nrandomized communication complexity. We demonstrate the practical effectiveness\nof the proposed algorithm with some numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 00:53:01 GMT"}, {"version": "v2", "created": "Fri, 6 Feb 2015 18:51:23 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Zhang", "Yuchen", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1502.01462", "submitter": "Abuzer Yakaryilmaz", "authors": "Aida Gainutdinova and Abuzer Yakaryilmaz", "title": "Unary probabilistic and quantum automata on promise problems", "comments": "Minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue the systematic investigation of probabilistic and quantum finite\nautomata (PFAs and QFAs) on promise problems by focusing on unary languages. We\nshow that bounded-error QFAs are more powerful than PFAs. But, in contrary to\nthe binary problems, the computational powers of Las-Vegas QFAs and\nbounded-error PFAs are equivalent to deterministic finite automata (DFAs).\nLastly, we present a new family of unary promise problems with two parameters\nsuch that when fixing one parameter QFAs can be exponentially more succinct\nthan PFAs and when fixing the other parameter PFAs can be exponentially more\nsuccinct than DFAs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 08:53:07 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2015 12:57:38 GMT"}], "update_date": "2015-03-12", "authors_parsed": [["Gainutdinova", "Aida", ""], ["Yakaryilmaz", "Abuzer", ""]]}, {"id": "1502.01865", "submitter": "Stasys Jukna", "authors": "Stasys Jukna", "title": "Lower Bounds for Monotone Counting Circuits", "comments": "20 pages", "journal-ref": "Discrete Applied Mathematics 213 (2016) 139-152", "doi": "10.1016/j.dam.2016.04.024", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A {+,x}-circuit counts a given multivariate polynomial f, if its values on\n0-1 inputs are the same as those of f; on other inputs the circuit may output\narbitrary values. Such a circuit counts the number of monomials of f evaluated\nto 1 by a given 0-1 input vector (with multiplicities given by their\ncoefficients). A circuit decides $f$ if it has the same 0-1 roots as f. We\nfirst show that some multilinear polynomials can be exponentially easier to\ncount than to compute them, and can be exponentially easier to decide than to\ncount them. Then we give general lower bounds on the size of counting circuits.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 11:55:33 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Jukna", "Stasys", ""]]}, {"id": "1502.02135", "submitter": "Diptarka Chakraborty", "authors": "Diptarka Chakraborty and Raghunath Tewari", "title": "Simultaneous Time-Space Upper Bounds for Certain Problems in Planar\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that given a weighted, directed planar graph $G$, and\nany $\\epsilon >0$, there exists a polynomial time and\n$O(n^{\\frac{1}{2}+\\epsilon})$ space algorithm that computes the shortest path\nbetween two fixed vertices in $G$.\n  We also consider the {\\RB} problem, which states that given a graph $G$ whose\nedges are colored either red or blue and two fixed vertices $s$ and $t$ in $G$,\nis there a path from $s$ to $t$ in $G$ that alternates between red and blue\nedges. The {\\RB} problem in planar DAGs is {\\NL}-complete. We exhibit a\npolynomial time and $O(n^{\\frac{1}{2}+\\epsilon})$ space algorithm (for any\n$\\epsilon >0$) for the {\\RB} problem in planar DAG.\n  In the last part of this paper, we consider the problem of deciding and\nconstructing the perfect matching present in a planar bipartite graph and also\na similar problem which is to find a Hall-obstacle in a planar bipartite graph.\nWe show the time-space bound of these two problems are same as the bound of\nshortest path problem in a directed planar graph.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2015 12:54:48 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Chakraborty", "Diptarka", ""], ["Tewari", "Raghunath", ""]]}, {"id": "1502.02155", "submitter": "Rad Niazadeh", "authors": "Thomas Kesselheim, Robert Kleinberg, Rad Niazadeh", "title": "Secretary Problems with Non-Uniform Arrival Order", "comments": "To appear in Proceedings of the 47th Annual ACM Symposium on Theory\n  of Computing (STOC 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many online problems, it is known that the uniform arrival order enables\nthe design of algorithms with much better performance guarantees than under\nworst-case. The quintessential example is the secretary problem. If the\nsequence of elements is presented in uniformly random order there is an\nalgorithm that picks the maximum value with probability 1/e, whereas no\nnon-trivial performance guarantee is possible if the elements arrive in\nworst-case order. This work initiates an investigation into relaxations of the\nrandom-ordering hypothesis in online algorithms, by focusing on the secretary\nproblems. We present two sets of properties of distributions over permutations\nas sufficient conditions, called the block-independence property and\nuniform-induced-ordering property. We show these two are asymptotically\nequivalent by borrowing some techniques from the approximation theory.\nMoreover, we show they both imply the existence of secretary algorithms with\nconstant probability of correct selection, approaching the optimal constant 1/e\nin the limit. We substantiate our idea by providing several constructions of\ndistributions that satisfy block-independence. We also show that {\\Theta}(log\nlog n) is the minimum entropy of any permutation distribution that permits\nconstant probability of correct selection in the secretary problem with n\nelements. While our block-independence condition is sufficient for constant\nprobability of correct selection, it is not necessary; however, we present\ncomplexity-theoretic evidence that no simple necessary and sufficient criterion\nexists. Finally, we explore the extent to which the performance guarantees of\nother algorithms are preserved when one relaxes the uniform random ordering\nassumption, obtaining a positive result for Kleinberg's multiple-choice\nsecretary algorithm and a negative result for the weighted bipartite matching\nalgorithm of Korula and Pal.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2015 16:04:14 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Kesselheim", "Thomas", ""], ["Kleinberg", "Robert", ""], ["Niazadeh", "Rad", ""]]}, {"id": "1502.02174", "submitter": "Shelby Kimmel", "authors": "Shelby Kimmel, Cedric Yen-Yu Lin, Han-Hsuan Lin", "title": "Oracles with Costs", "comments": "In this version: typos fixed and motivating examples added", "journal-ref": null, "doi": "10.4230/LIPIcs.TQC.2015.1", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While powerful tools have been developed to analyze quantum query complexity,\nthere are still many natural problems that do not fit neatly into the black box\nmodel of oracles. We create a new model that allows multiple oracles with\ndiffering costs. This model captures more of the difficulty of certain natural\nproblems. We test this model on a simple problem, Search with Two Oracles, for\nwhich we create a quantum algorithm that we prove is asymptotically optimal. We\nfurther give some evidence, using a geometric picture of Grover's algorithm,\nthat our algorithm is exactly optimal.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2015 19:18:08 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2015 20:56:36 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Kimmel", "Shelby", ""], ["Lin", "Cedric Yen-Yu", ""], ["Lin", "Han-Hsuan", ""]]}, {"id": "1502.02290", "submitter": "Chinmoy Dutta", "authors": "Chinmoy Dutta and Yashodhan Kanoria and D. Manjunath and Jaikumar\n  Radhakrishnan", "title": "How Hard is Computing Parity with Noisy Communications?", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a tight lower bound of $\\Omega(N \\log\\log N)$ on the number of\ntransmissions required to compute the parity of $N$ input bits with constant\nerror in a noisy communication network of $N$ randomly placed sensors, each\nhaving one input bit and communicating with others using local transmissions\nwith power near the connectivity threshold. This result settles the lower bound\nquestion left open by Ying, Srikant and Dullerud (WiOpt 06), who showed how the\nsum of all the $N$ bits can be computed using $O(N \\log\\log N)$ transmissions.\nThe same lower bound has been shown to hold for a host of other functions\nincluding majority by Dutta and Radhakrishnan (FOCS 2008).\n  Most works on lower bounds for communication networks considered mostly the\nfull broadcast model without using the fact that the communication in real\nnetworks is local, determined by the power of the transmitters. In fact, in\nfull broadcast networks computing parity needs $\\theta(N)$ transmissions. To\nobtain our lower bound we employ techniques developed by Goyal, Kindler and\nSaks (FOCS 05), who showed lower bounds in the full broadcast model by reducing\nthe problem to a model of noisy decision trees. However, in order to capture\nthe limited range of transmissions in real sensor networks, we adapt their\ndefinition of noisy decision trees and allow each node of the tree access to\nonly a limited part of the input. Our lower bound is obtained by exploiting\nspecial properties of parity computations in such noisy decision trees.\n", "versions": [{"version": "v1", "created": "Sun, 8 Feb 2015 19:32:58 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Dutta", "Chinmoy", ""], ["Kanoria", "Yashodhan", ""], ["Manjunath", "D.", ""], ["Radhakrishnan", "Jaikumar", ""]]}, {"id": "1502.02563", "submitter": "Joseph Fitzsimons", "authors": "Michal Hajdu\\v{s}ek and Carlos A. P\\'erez-Delgado and Joseph F.\n  Fitzsimons", "title": "Device-Independent Verifiable Blind Quantum Computation", "comments": "Shortly before submission of this preprint, the authors became aware\n  of parallel and independent research by Gheorghiu, Kashefi and Wallden, which\n  also addresses device-independent verifiable blind quantum computation, and\n  appears simultaneously", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As progress on experimental quantum processors continues to advance, the\nproblem of verifying the correct operation of such devices is becoming a\npressing concern. The recent discovery of protocols for verifying computation\nperformed by entangled but non-communicating quantum processors holds the\npromise of certifying the correctness of arbitrary quantum computations in a\nfully device-independent manner. Unfortunately, all known schemes have\nprohibitive overhead, with resources scaling as extremely high degree\npolynomials in the number of gates constituting the computation. Here we\npresent a novel approach based on a combination of verified blind quantum\ncomputation and Bell state self-testing. This approach has dramatically reduced\noverhead, with resources scaling as only $O(m^4\\ln m)$ in the number of gates.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 16:57:45 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 15:25:19 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Hajdu\u0161ek", "Michal", ""], ["P\u00e9rez-Delgado", "Carlos A.", ""], ["Fitzsimons", "Joseph F.", ""]]}, {"id": "1502.02642", "submitter": "Slimane Oulad-Naoui", "authors": "Slimane Oulad-Naoui, Hadda Cherroun and Djelloul Ziadi", "title": "Mining Frequent Itemsets: a Formal Unification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally well agreed that developing a unifying theory is one of the\nmost important issues in Data Mining research. In the last two decades, a great\ndeal of work has been devoted to the algorithmic aspects of the Frequent\nItemset (FI) Mining problem. We are motivated by the need for formal modeling\nin the field. Thus, we introduce and analyze, in this theoretical study, a new\nmodel for the FI mining task. Indeed, we encode the itemsets as words over an\nordered alphabet, and state this problem by a formal series over the counting\nsemiring $(\\mathbb{N},+,\\times,0,1)$, whose range constitutes the itemsets and\nthe coefficients are their supports. This formalism offers many advantages in\nboth fundamental and practical aspects: the introduction of a clear and unified\ntheoretical framework through which we can express the main FI-approaches, the\npossibility of their generalization to mine other more complex objects, and\ntheir incrementalisation or parallelisation; in practice, we explain how this\nproblem can be seen as that of word recognition by an automaton, allowing an\nefficient implementation in $O(|Q|)$ space and $O(|\\mathcal{F}_L||Q|])$ time,\nwhere $Q$ is the set of states of the automaton used for representing the data,\nand $\\mathcal{F}_L$ the set of prefixial longest FI.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 20:28:46 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2015 19:13:44 GMT"}, {"version": "v3", "created": "Sun, 15 Dec 2019 21:10:41 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 23:46:00 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Oulad-Naoui", "Slimane", ""], ["Cherroun", "Hadda", ""], ["Ziadi", "Djelloul", ""]]}, {"id": "1502.02800", "submitter": "Svyatoslav Covanov", "authors": "Svyatoslav Covanov (CARAMBA), Emmanuel Thom\\'e (CARAMBA)", "title": "Fast integer multiplication using generalized Fermat primes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For almost 35 years, Sch{\\\"o}nhage-Strassen's algorithm has been the fastest\nalgorithm known for multiplying integers, with a time complexity O(n $\\times$\nlog n $\\times$ log log n) for multiplying n-bit inputs. In 2007, F{\\\"u}rer\nproved that there exists K > 1 and an algorithm performing this operation in\nO(n $\\times$ log n $\\times$ K log n). Recent work by Harvey, van der Hoeven,\nand Lecerf showed that this complexity estimate can be improved in order to get\nK = 8, and conjecturally K = 4. Using an alternative algorithm, which relies on\narithmetic modulo generalized Fermat primes, we obtain conjecturally the same\nresult K = 4 via a careful complexity analysis in the deterministic multitape\nTuring model.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 07:15:16 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2016 15:12:17 GMT"}, {"version": "v3", "created": "Tue, 29 Aug 2017 08:59:14 GMT"}, {"version": "v4", "created": "Tue, 17 Apr 2018 11:13:59 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Covanov", "Svyatoslav", "", "CARAMBA"], ["Thom\u00e9", "Emmanuel", "", "CARAMBA"]]}, {"id": "1502.03316", "submitter": "Ali Sinop", "authors": "Pranjal Awasthi, Moses Charikar, Ravishankar Krishnaswamy, Ali Kemal\n  Sinop", "title": "The Hardness of Approximation of Euclidean k-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euclidean $k$-means problem is a classical problem that has been\nextensively studied in the theoretical computer science, machine learning and\nthe computational geometry communities. In this problem, we are given a set of\n$n$ points in Euclidean space $R^d$, and the goal is to choose $k$ centers in\n$R^d$ so that the sum of squared distances of each point to its nearest center\nis minimized. The best approximation algorithms for this problem include a\npolynomial time constant factor approximation for general $k$ and a\n$(1+\\epsilon)$-approximation which runs in time $poly(n) 2^{O(k/\\epsilon)}$. At\nthe other extreme, the only known computational complexity result for this\nproblem is NP-hardness [ADHP'09]. The main difficulty in obtaining hardness\nresults stems from the Euclidean nature of the problem, and the fact that any\npoint in $R^d$ can be a potential center. This gap in understanding left open\nthe intriguing possibility that the problem might admit a PTAS for all $k,d$.\n  In this paper we provide the first hardness of approximation for the\nEuclidean $k$-means problem. Concretely, we show that there exists a constant\n$\\epsilon > 0$ such that it is NP-hard to approximate the $k$-means objective\nto within a factor of $(1+\\epsilon)$. We show this via an efficient reduction\nfrom the vertex cover problem on triangle-free graphs: given a triangle-free\ngraph, the goal is to choose the fewest number of vertices which are incident\non all the edges. Additionally, we give a proof that the current best hardness\nresults for vertex cover can be carried over to triangle-free graphs. To show\nthis we transform $G$, a known hard vertex cover instance, by taking a graph\nproduct with a suitably chosen graph $H$, and showing that the size of the\n(normalized) maximum independent set is almost exactly preserved in the product\ngraph using a spectral analysis, which might be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 14:38:45 GMT"}], "update_date": "2015-02-12", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Charikar", "Moses", ""], ["Krishnaswamy", "Ravishankar", ""], ["Sinop", "Ali Kemal", ""]]}, {"id": "1502.03482", "submitter": "Stanislav Zivny", "authors": "Johan Thapper, Stanislav Zivny", "title": "Necessary conditions for tractability of valued CSPs", "comments": "To appear in SIAM Journal on Discrete Mathematics (SIDMA)", "journal-ref": "SIAM Journal on Discrete Mathematics 29(4) (2015) 2361-2384", "doi": "10.1137/140990346", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connection between constraint languages and clone theory has been a\nfruitful line of research on the complexity of constraint satisfaction\nproblems. In a recent result, Cohen et al. [SICOMP'13] have characterised a\nGalois connection between valued constraint languages and so-called weighted\nclones. In this paper, we study the structure of weighted clones. We extend the\nresults of Creed and Zivny from [CP'11/SICOMP'13] on types of weightings\nnecessarily contained in every nontrivial weighted clone. This result has\nimmediate computational complexity consequences as it provides necessary\nconditions for tractability of weighted clones and thus valued constraint\nlanguages. We demonstrate that some of the necessary conditions are also\nsufficient for tractability, while others are provably not.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 23:11:42 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2015 21:48:25 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Thapper", "Johan", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1502.03540", "submitter": "Markus Lohrey", "authors": "Daniel K\\\"onig and Markus Lohrey", "title": "Evaluating Matrix Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The circuit evaluation problem (also known as the compressed word problem)\nfor finitely generated linear groups is studied. The best upper bound for this\nproblem is $\\mathsf{coRP}$, which is shown by a reduction to polynomial\nidentity testing. Conversely, the compressed word problem for the linear group\n$\\mathsf{SL}_3(\\mathbb{Z})$ is equivalent to polynomial identity testing. In\nthe paper, it is shown that the compressed word problem for every finitely\ngenerated nilpotent group is in $\\mathsf{DET} \\subseteq \\mathsf{NC}^2$. Within\nthe larger class of polycyclic groups we find examples where the compressed\nword problem is at least as hard as polynomial identity testing for skew\narithmetic circuits.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 04:50:55 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["K\u00f6nig", "Daniel", ""], ["Lohrey", "Markus", ""]]}, {"id": "1502.03796", "submitter": "Stanislav Zivny", "authors": "David A. Cohen, Martin C. Cooper, Guillaume Escamocher, Stanislav\n  Zivny", "title": "Variable and value elimination in binary constraint satisfaction via\n  forbidden patterns", "comments": "A full version of an IJCAI'13 paper to appear in Journal of Computer\n  and System Sciences (JCSS)", "journal-ref": "Journal of Computer and System Sciences 81(7) 1127-1143 (2015)", "doi": "10.1016/j.jcss.2015.02.001", "report-no": null, "categories": "cs.CC cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable or value elimination in a constraint satisfaction problem (CSP) can\nbe used in preprocessing or during search to reduce search space size. A\nvariable elimination rule (value elimination rule) allows the polynomial-time\nidentification of certain variables (domain elements) whose elimination,\nwithout the introduction of extra compensatory constraints, does not affect the\nsatisfiability of an instance. We show that there are essentially just four\nvariable elimination rules and three value elimination rules defined by\nforbidding generic sub-instances, known as irreducible existential patterns, in\narc-consistent CSP instances. One of the variable elimination rules is the\nalready-known Broken Triangle Property, whereas the other three are novel. The\nthree value elimination rules can all be seen as strict generalisations of\nneighbourhood substitution.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 20:22:44 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Cohen", "David A.", ""], ["Cooper", "Martin C.", ""], ["Escamocher", "Guillaume", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1502.03847", "submitter": "Santanu Bhowmick", "authors": "Sayan Bandyapadhyay, Santanu Bhowmick and Kasturi Varadarajan", "title": "A Constant Factor Approximation for Orthogonal Order Preserving Layout\n  Adjustment", "comments": "Edited Section 5, re-arranged content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an initial placement of a set of rectangles in the plane, we consider\nthe problem of finding a disjoint placement of the rectangles that minimizes\nthe area of the bounding box and preserves the orthogonal order i.e.\\ maintains\nthe sorted ordering of the rectangle centers along both $x$-axis and $y$-axis\nwith respect to the initial placement. This problem is known as Layout\nAdjustment for Disjoint Rectangles(LADR). It was known that LADR is\n$\\mathbb{NP}$-hard, but only heuristics were known for it. We show that a\ncertain decision version of LADR is $\\mathbb{APX}$-hard, and give a constant\nfactor approximation for LADR.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 22:15:37 GMT"}, {"version": "v2", "created": "Mon, 23 Feb 2015 16:45:40 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Bandyapadhyay", "Sayan", ""], ["Bhowmick", "Santanu", ""], ["Varadarajan", "Kasturi", ""]]}, {"id": "1502.03945", "submitter": "Alexandros A. Voudouris", "authors": "Ioannis Caragiannis, Xenophon Chatzigeorgiou, Panagiotis\n  Kanellopoulos, George A. Krimpas, Nikos Protopapas, Alexandros A. Voudouris", "title": "Efficiency and complexity of price competition among single-product\n  vendors", "comments": "23 pages, 6 tables, 2 figures, accepted to Artificial Intelligence\n  Journal, a preliminary version appeared in Proceedings of the 24th\n  International Joint Conference on Artificial Intelligence (IJCAI), pp. 25-31,\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent progress on pricing in the AI literature, we study\nmarketplaces that contain multiple vendors offering identical or similar\nproducts and unit-demand buyers with different valuations on these vendors. The\nobjective of each vendor is to set the price of its product to a fixed value so\nthat its profit is maximized. The profit depends on the vendor's price itself\nand the total volume of buyers that find the particular price more attractive\nthan the price of the vendor's competitors. We model the behaviour of buyers\nand vendors as a two-stage full-information game and study a series of\nquestions related to the existence, efficiency (price of anarchy) and\ncomputational complexity of equilibria in this game. To overcome situations\nwhere equilibria do not exist or exist but are highly inefficient, we consider\nthe scenario where some of the vendors are subsidized in order to keep prices\nlow and buyers highly satisfied.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 11:18:00 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 09:13:31 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Caragiannis", "Ioannis", ""], ["Chatzigeorgiou", "Xenophon", ""], ["Kanellopoulos", "Panagiotis", ""], ["Krimpas", "George A.", ""], ["Protopapas", "Nikos", ""], ["Voudouris", "Alexandros A.", ""]]}, {"id": "1502.03965", "submitter": "Bart M. P. Jansen", "authors": "Archontia C. Giannopoulou and Bart M. P. Jansen and Daniel Lokshtanov\n  and Saket Saurabh", "title": "Uniform Kernelization Complexity of Hitting Forbidden Minors", "comments": "34 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The F-Minor-Free Deletion problem asks, for a fixed set F and an input\nconsisting of a graph G and integer k, whether k vertices can be removed from G\nsuch that the resulting graph does not contain any member of F as a minor. This\npaper analyzes to what extent provably effective and efficient preprocessing is\npossible for F-Minor-Free Deletion. Fomin et al. (FOCS 2012) showed that the\nspecial case Planar F-Deletion (when F contains at least one planar graph) has\na kernel of size f(F) * k^{g(F)} for some functions f and g. The degree g of\nthe polynomial grows very quickly; it is not even known to be computable. Fomin\net al. left open whether Planar F-Deletion has kernels whose size is uniformly\npolynomial, i.e., of the form f(F) * k^c for some universal constant c that\ndoes not depend on F. Our results in this paper are twofold. (1) We prove that\nsome Planar F-Deletion problems do not have uniformly polynomial kernels\n(unless NP is in coNP/poly). In particular, we prove that Treewidth-Eta\nDeletion does not have a kernel with O(k^{eta/4} - eps) vertices for any eps >\n0, unless NP is in coNP/poly. In fact, we even prove the kernelization lower\nbound for the larger parameter vertex cover number. This resolves an open\nproblem of Cygan et al. (IPEC 2011). It is a natural question whether further\nrestrictions on F lead to uniformly polynomial kernels. However, we prove that\neven when F contains a path, the degree of the polynomial must, in general,\ndepend on the set F. (2) A canonical F-Minor-Free Deletion problem when F\ncontains a path is Treedepth-eta Deletion: can k vertices be removed to obtain\na graph of treedepth at most eta? We prove that Treedepth-eta Deletion admits\nuniformly polynomial kernels with O(k^6) vertices for every fixed eta. In order\nto develop the kernelization we prove several new results about the structure\nof optimal treedepth-decompositions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 12:48:31 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Giannopoulou", "Archontia C.", ""], ["Jansen", "Bart M. P.", ""], ["Lokshtanov", "Daniel", ""], ["Saurabh", "Saket", ""]]}, {"id": "1502.03974", "submitter": "Albert Atserias", "authors": "Albert Atserias", "title": "A Note on Semi-Algebraic Proofs and Gaussian Elimination over Prime\n  Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we show that unsatisfiable systems of linear equations with a\nconstant number of variables per equation over prime finite fields have\npolynomial-size constant-degree semi-algebraic proofs of unsatisfiability.\nThese are proofs that manipulate polynomial inequalities over the reals with\nvariables ranging in $\\{0,1\\}$. This upper bound is to be put in contrast with\nthe known fact that, for certain explicit systems of linear equations over the\ntwo-element field, such refutations require linear degree and exponential size\nif they are restricted to so-called static semi-algebraic proofs, and even\ntree-like semi-algebraic and sums-of-squares proofs. Our upper bound is a more\nor less direct translation of an argument due to Grigoriev, Hirsch and\nPasechnik (Moscow Mathematical Journal, 2002) who did it for a family of linear\nsystems of interest in propositional proof complexity. We point out that their\nmethod is more general and can be thought of as simulating Gaussian\nelimination.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 13:03:53 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Atserias", "Albert", ""]]}, {"id": "1502.04226", "submitter": "Kamil Khadiev", "authors": "Kamil Khadiev", "title": "Width Hierarchy for k-OBDD of Small Width", "comments": "8 pages", "journal-ref": "Lobachevskii Journal of Mathematics, V. 36, I. 2, pp 178-183 ,\n  2015", "doi": "10.1134/S1995080215020092", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper was explored well known model k-OBDD. There are proven width\nbased hierarchy of classes of boolean functions which computed by k-OBDD. The\nproof of hierarchy is based on sufficient condition of Boolean function's non\nrepresentation as k-OBDD and complexity properties of Boolean function SAF.\nThis function is modification of known Pointer Jumping (PJ) and Indirect\nStorage Access (ISA) functions.\n", "versions": [{"version": "v1", "created": "Sat, 14 Feb 2015 17:20:06 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2015 18:59:38 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Khadiev", "Kamil", ""]]}, {"id": "1502.04246", "submitter": "David Doty", "authors": "David Doty, David Soloveichik", "title": "Stable Leader Election in Population Protocols Requires Linear Time", "comments": "accepted to Distributed Computing special issue of invited papers\n  from DISC 2015; significantly revised proof structure and intuitive\n  explanations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A population protocol *stably elects a leader* if, for all $n$, starting from\nan initial configuration with $n$ agents each in an identical state, with\nprobability 1 it reaches a configuration $\\mathbf{y}$ that is correct (exactly\none agent is in a special leader state $\\ell$) and stable (every configuration\nreachable from $\\mathbf{y}$ also has a single agent in state $\\ell$). We show\nthat any population protocol that stably elects a leader requires $\\Omega(n)$\nexpected \"parallel time\" --- $\\Omega(n^2)$ expected total pairwise interactions\n--- to reach such a stable configuration. Our result also informs the\nunderstanding of the time complexity of chemical self-organization by showing\nan essential difficulty in generating exact quantities of molecular species\nquickly.\n", "versions": [{"version": "v1", "created": "Sat, 14 Feb 2015 21:17:03 GMT"}, {"version": "v2", "created": "Sun, 22 Feb 2015 03:36:53 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2015 18:55:40 GMT"}, {"version": "v4", "created": "Sat, 20 Aug 2016 16:43:30 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Doty", "David", ""], ["Soloveichik", "David", ""]]}, {"id": "1502.04341", "submitter": "Nicolai Vorobjov", "authors": "Nicolai Vorobjov and Andrei Gabrielov", "title": "On topological lower bounds for algebraic computation trees", "comments": "10 pages, minor editorial corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the height of any algebraic computation tree for deciding\nmembership in a semialgebraic set is bounded from below (up to a multiplicative\nconstant) by the logarithm of m-th Betti number (with respect to singular\nhomology) of the set, divided by m+1. This result complements the well known\nlower bound by Yao for locally closed semialgebraic sets in terms of the total\nBorel-Moore Betti number. We also prove that the height is bounded from below\nby the logarithm of m-th Betti number of a projection of the set onto a\ncoordinate subspace, divided by (m+1)^2. We illustrate these general results by\nexamples of lower complexity bounds for some specific computational problems.\n", "versions": [{"version": "v1", "created": "Sun, 15 Feb 2015 18:03:11 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2015 16:35:06 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Vorobjov", "Nicolai", ""], ["Gabrielov", "Andrei", ""]]}, {"id": "1502.04545", "submitter": "Markus Lohrey", "authors": "Daniel K\\\"onig and Markus Lohrey", "title": "Parallel Identity Testing for Skew Circuits with Big Powers and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powerful skew arithmetic circuits are introduced. These are skew arithmetic\ncircuits with variables, where input gates can be labelled with powers $x^n$\nfor binary encoded numbers $n$. It is shown that polynomial identity testing\nfor powerful skew arithmetic circuits belongs to $\\mathsf{coRNC}^2$, which\ngeneralizes a corresponding result for (standard) skew circuits. Two\napplications of this result are presented: (i) Equivalence of\nhigher-dimensional straight-line programs can be tested in $\\mathsf{coRNC}^2$;\nthis result is even new in the one-dimensional case, where the straight-line\nprograms produce strings. (ii) The compressed word problem (or circuit\nevaluation problem) for certain wreath products of finitely generated abelian\ngroups belongs to $\\mathsf{coRNC}^2$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 14:24:01 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["K\u00f6nig", "Daniel", ""], ["Lohrey", "Markus", ""]]}, {"id": "1502.04650", "submitter": "Weimin Chen", "authors": "Weimin Chen", "title": "Lower Bound for General Circuits Computing Clique Function", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  Section 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an exponential lower bound for general circuits computing the clique\nfunction and hereby confirm that NP != P.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 17:58:08 GMT"}, {"version": "v2", "created": "Fri, 20 Feb 2015 01:52:51 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Chen", "Weimin", ""]]}, {"id": "1502.04700", "submitter": "Ionut-Dragos Potirniche", "authors": "Ionut-Dragos Potirniche, C. R. Laumann, S. L. Sondhi", "title": "Classical-Quantum Mixing in the Random 2-Satisfiability Problem", "comments": "Updated references", "journal-ref": "Phys. Rev. A 92, 040301 (2015)", "doi": "10.1103/PhysRevA.92.040301", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical satisfiability (SAT) and quantum satisfiability (QSAT) are complete\nproblems for the complexity classes NP and QMA which are believed to be\nintractable for classical and quantum computers, respectively. Statistical\nensembles of instances of these problems have been studied previously in an\nattempt to elucidate their typical, as opposed to worst case, behavior. In this\npaper we introduce a new statistical ensemble that interpolates between\nclassical and quantum. For the simplest 2-SAT/2-QSAT ensemble we find the exact\nboundary that separates SAT and UNSAT instances. We do so by establishing\ncoincident lower and upper bounds, in the limit of large instances, on the\nextent of the UNSAT and SAT regions, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 21:00:06 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2015 02:17:41 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Potirniche", "Ionut-Dragos", ""], ["Laumann", "C. R.", ""], ["Sondhi", "S. L.", ""]]}, {"id": "1502.04803", "submitter": "Amer Mouawad", "authors": "Daniel Lokshtanov, Amer E. Mouawad, Fahad Panolan, M.S. Ramanujan,\n  Saket Saurabh", "title": "Reconfiguration on sparse graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vertex-subset graph problem Q defines which subsets of the vertices of an\ninput graph are feasible solutions. A reconfiguration variant of a\nvertex-subset problem asks, given two feasible solutions S and T of size k,\nwhether it is possible to transform S into T by a sequence of vertex additions\nand deletions such that each intermediate set is also a feasible solution of\nsize bounded by k. We study reconfiguration variants of two classical\nvertex-subset problems, namely Independent Set and Dominating Set. We denote\nthe former by ISR and the latter by DSR. Both ISR and DSR are PSPACE-complete\non graphs of bounded bandwidth and W[1]-hard parameterized by k on general\ngraphs. We show that ISR is fixed-parameter tractable parameterized by k when\nthe input graph is of bounded degeneracy or nowhere-dense. As a corollary, we\nanswer positively an open question concerning the parameterized complexity of\nthe problem on graphs of bounded treewidth. Moreover, our techniques generalize\nrecent results showing that ISR is fixed-parameter tractable on planar graphs\nand graphs of bounded degree. For DSR, we show the problem fixed-parameter\ntractable parameterized by k when the input graph does not contain large\nbicliques, a class of graphs which includes graphs of bounded degeneracy and\nnowhere-dense graphs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 05:38:16 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Lokshtanov", "Daniel", ""], ["Mouawad", "Amer E.", ""], ["Panolan", "Fahad", ""], ["Ramanujan", "M. S.", ""], ["Saurabh", "Saket", ""]]}, {"id": "1502.05086", "submitter": "Stanislav Zivny", "authors": "Peter Fulla and Stanislav Zivny", "title": "A Galois Connection for Weighted (Relational) Clones of Infinite Size", "comments": null, "journal-ref": "ACM Transactions on Computation Theory 8(3) Article no. 9 (2016)", "doi": "10.1145/2898438", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Galois connection between clones and relational clones on a fixed finite\ndomain is one of the cornerstones of the so-called algebraic approach to the\ncomputational complexity of non-uniform Constraint Satisfaction Problems\n(CSPs). Cohen et al. established a Galois connection between finitely-generated\nweighted clones and finitely-generated weighted relational clones [SICOMP'13],\nand asked whether this connection holds in general. We answer this question in\nthe affirmative for weighted (relational) clones with real weights and show\nthat the complexity of the corresponding valued CSPs is preserved.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 23:02:32 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2015 07:46:58 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Fulla", "Peter", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1502.05301", "submitter": "Stanislav Zivny", "authors": "Johan Thapper and Stanislav Zivny", "title": "Sherali-Adams relaxations for valued CSPs", "comments": null, "journal-ref": "Proc. of ICALP'15 1058-1069 (2015)", "doi": "10.1007/978-3-662-47672-7_86", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Sherali-Adams linear programming relaxations for solving valued\nconstraint satisfaction problems to optimality. The utility of linear\nprogramming relaxations in this context have previously been demonstrated using\nthe lowest possible level of this hierarchy under the name of the basic linear\nprogramming relaxation (BLP). It has been shown that valued constraint\nlanguages containing only finite-valued weighted relations are tractable if,\nand only if, the integrality gap of the BLP is 1. In this paper, we demonstrate\nthat almost all of the known tractable languages with arbitrary weighted\nrelations have an integrality gap 1 for the Sherali-Adams relaxation with\nparameters (2,3). The result is closely connected to the notion of bounded\nrelational width for the ordinary constraint satisfaction problem and its\nrecent characterisation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 17:02:42 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Thapper", "Johan", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1502.05361", "submitter": "Martin Koutecky", "authors": "Petr Kolman, Martin Kouteck\\'y", "title": "Extended Formulation for CSP that is Compact for Instances of Bounded\n  Treewidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide an extended formulation for the class of constraint\nsatisfaction problems and prove that its size is polynomial for instances whose\nconstraint graph has bounded treewidth. This implies new upper bounds on\nextension complexity of several important NP-hard problems on graphs of bounded\ntreewidth.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 20:00:10 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2015 08:17:39 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Kolman", "Petr", ""], ["Kouteck\u00fd", "Martin", ""]]}, {"id": "1502.05533", "submitter": "Kousha Etessami", "authors": "Kousha Etessami, Alistair Stewart, Mihalis Yannakakis", "title": "Greatest Fixed Points of Probabilistic Min/Max Polynomial Equations, and\n  Reachability for Branching Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give polynomial time algorithms for quantitative (and qualitative)\nreachability analysis for Branching Markov Decision Processes (BMDPs).\nSpecifically, given a BMDP, and given an initial population, where the\nobjective of the controller is to maximize (or minimize) the probability of\neventually reaching a population that contains an object of a desired (or\nundesired) type, we give algorithms for approximating the supremum (infimum)\nreachability probability, within desired precision epsilon > 0, in time\npolynomial in the encoding size of the BMDP and in log(1/epsilon). We\nfurthermore give P-time algorithms for computing epsilon-optimal strategies for\nboth maximization and minimization of reachability probabilities. We also give\nP-time algorithms for all associated qualitative analysis problems, namely:\ndeciding whether the optimal (supremum or infimum) reachability probabilities\nare 0 or 1. Prior to this paper, approximation of optimal reachability\nprobabilities for BMDPs was not even known to be decidable.\n  Our algorithms exploit the following basic fact: we show that for any BMDP,\nits maximum (minimum) non-reachability probabilities are given by the greatest\nfixed point (GFP) solution g* in [0,1]^n of a corresponding monotone max (min)\nProbabilistic Polynomial System of equations (max/min-PPS), x=P(x), which are\nthe Bellman optimality equations for a BMDP with non-reachability objectives.\nWe show how to compute the GFP of max/min PPSs to desired precision in P-time.\n  We also study more general Branching Simple Stochastic Games (BSSGs) with\n(non-)reachability objectives. We show that: (1) the value of these games is\ncaptured by the GFP of a corresponding max-minPPS; (2) the quantitative problem\nof approximating the value is in TFNP; and (3) the qualitative problems\nassociated with the value are all solvable in P-time.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 11:39:01 GMT"}, {"version": "v2", "created": "Sat, 21 Feb 2015 09:58:34 GMT"}, {"version": "v3", "created": "Wed, 25 Feb 2015 18:49:37 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2015 10:39:34 GMT"}, {"version": "v5", "created": "Thu, 7 Apr 2016 12:22:18 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Etessami", "Kousha", ""], ["Stewart", "Alistair", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "1502.05675", "submitter": "Malik Magdon-Ismail", "authors": "Malik Magdon-Ismail", "title": "NP-Hardness and Inapproximability of Sparse PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a reduction from {\\sc clique} to establish that sparse PCA is\nNP-hard. The reduction has a gap which we use to exclude an FPTAS for sparse\nPCA (unless P=NP). Under weaker complexity assumptions, we also exclude\npolynomial constant-factor approximation algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 19:30:46 GMT"}, {"version": "v2", "created": "Fri, 20 Feb 2015 13:00:17 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Magdon-Ismail", "Malik", ""]]}, {"id": "1502.05828", "submitter": "Michael Lampis", "authors": "\\'Edouard Bonnet, Michael Lampis, Vangelis Th. Paschos", "title": "Time-Approximation Trade-offs for Inapproximable Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on problems which do not admit a constant-factor\napproximation in polynomial time and explore how quickly their approximability\nimproves as the allowed running time is gradually increased from polynomial to\n(sub-)exponential.\n  We tackle a number of problems: For Min Independent Dominating Set, Max\nInduced Path, Forest and Tree, for any $r(n)$, a simple, known scheme gives an\napproximation ratio of $r$ in time roughly $r^{n/r}$. We show that, for most\nvalues of $r$, if this running time could be significantly improved the ETH\nwould fail. For Max Minimal Vertex Cover we give a non-trivial\n$\\sqrt{r}$-approximation in time $2^{n/r}$. We match this with a similarly\ntight result. We also give a $\\log r$-approximation for Min ATSP in time\n$2^{n/r}$ and an $r$-approximation for Max Grundy Coloring in time $r^{n/r}$.\n  Furthermore, we show that Min Set Cover exhibits a curious behavior in this\nsuper-polynomial setting: for any $\\delta > 0$ it admits an\n$m^\\delta$-approximation, where $m$ is the number of sets, in just\nquasi-polynomial time. We observe that if such ratios could be achieved in\npolynomial time, the ETH or the Projection Games Conjecture would fail.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 11:07:52 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Lampis", "Michael", ""], ["Paschos", "Vangelis Th.", ""]]}, {"id": "1502.05910", "submitter": "Jannis Bulian", "authors": "Jannis Bulian and Anuj Dawar", "title": "Fixed-parameter Tractable Distances to Sparse Graph Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for various classes C of sparse graphs, and several measures of\ndistance to such classes (such as edit distance and elimination distance), the\nproblem of determining the distance of a given graph G to C is fixed-parameter\ntractable. The results are based on two general techniques. The first of these,\nbuilding on recent work of Grohe et al. establishes that any class of graphs\nthat is slicewise nowhere dense and slicewise first-order definable is FPT. The\nsecond shows that determining the elimination distance of a graph G to a\nminor-closed class C is FPT.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 15:44:17 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Bulian", "Jannis", ""], ["Dawar", "Anuj", ""]]}, {"id": "1502.05912", "submitter": "Martin Grohe", "authors": "Christoph Berkholz and Martin Grohe", "title": "Limitations of Algebraic Approaches to Graph Isomorphism Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the power of graph isomorphism algorithms based on algebraic\nreasoning techniques like Gr\\\"obner basis computation. The idea of these\nalgorithms is to encode two graphs into a system of equations that are\nsatisfiable if and only if if the graphs are isomorphic, and then to (try to)\ndecide satisfiability of the system using, for example, the Gr\\\"obner basis\nalgorithm. In some cases this can be done in polynomial time, in particular, if\nthe equations admit a bounded degree refutation in an algebraic proof systems\nsuch as Nullstellensatz or polynomial calculus. We prove linear lower bounds on\nthe polynomial calculus degree over all fields of characteristic different from\n2 and also linear lower bounds for the degree of Positivstellensatz calculus\nderivations.\n  We compare this approach to recently studied linear and semidefinite\nprogramming approaches to isomorphism testing, which are known to be related to\nthe combinatorial Weisfeiler-Lehman algorithm. We exactly characterise the\npower of the Weisfeiler-Lehman algorithm in terms of an algebraic proof system\nthat lies between degree-k Nullstellensatz and degree-k polynomial calculus.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 15:50:43 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Berkholz", "Christoph", ""], ["Grohe", "Martin", ""]]}, {"id": "1502.06144", "submitter": "Quentin Berthet", "authors": "Quentin Berthet and Jordan S. Ellenberg", "title": "Detection of Planted Solutions for Flat Satisfiability Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the detection problem of finding planted solutions in random\ninstances of flat satisfiability problems, a generalization of boolean\nsatisfiability formulas. We describe the properties of random instances of flat\nsatisfiability, as well of the optimal rates of detection of the associated\nhypothesis testing problem. We also study the performance of an algorithmically\nefficient testing procedure. We introduce a modification of our model, the\nlight planting of solutions, and show that it is as hard as the problem of\nlearning parity with noise. This hints strongly at the difficulty of detecting\nplanted flat satisfiability for a wide class of tests.\n", "versions": [{"version": "v1", "created": "Sat, 21 Feb 2015 22:14:04 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 15:07:54 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Berthet", "Quentin", ""], ["Ellenberg", "Jordan S.", ""]]}, {"id": "1502.06208", "submitter": "Aryeh Kontorovich", "authors": "Lee-Ad Gottlieb and Aryeh Kontorovich", "title": "Nearly optimal classification for semimetrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the rigorous study of classification in semimetric spaces, which\nare point sets with a distance function that is non-negative and symmetric, but\nneed not satisfy the triangle inequality. For metric spaces, the doubling\ndimension essentially characterizes both the runtime and sample complexity of\nclassification algorithms --- yet we show that this is not the case for\nsemimetrics. Instead, we define the {\\em density dimension} and discover that\nit plays a central role in the statistical and algorithmic feasibility of\nlearning in semimetric spaces. We present nearly optimal sample compression\nalgorithms and use these to obtain generalization guarantees, including fast\nrates. The latter hold for general sample compression schemes and may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Sun, 22 Feb 2015 10:42:52 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "1502.06590", "submitter": "Yash Deshpande", "authors": "Yash Deshpande and Andrea Montanari", "title": "Improved Sum-of-Squares Lower Bounds for Hidden Clique and Hidden\n  Submatrix Problems", "comments": "40 pages, 1 table, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a large data matrix $A\\in\\mathbb{R}^{n\\times n}$, we consider the\nproblem of determining whether its entries are i.i.d. with some known marginal\ndistribution $A_{ij}\\sim P_0$, or instead $A$ contains a principal submatrix\n$A_{{\\sf Q},{\\sf Q}}$ whose entries have marginal distribution $A_{ij}\\sim\nP_1\\neq P_0$. As a special case, the hidden (or planted) clique problem\nrequires to find a planted clique in an otherwise uniformly random graph.\n  Assuming unbounded computational resources, this hypothesis testing problem\nis statistically solvable provided $|{\\sf Q}|\\ge C \\log n$ for a suitable\nconstant $C$. However, despite substantial effort, no polynomial time algorithm\nis known that succeeds with high probability when $|{\\sf Q}| = o(\\sqrt{n})$.\nRecently Meka and Wigderson \\cite{meka2013association}, proposed a method to\nestablish lower bounds within the Sum of Squares (SOS) semidefinite hierarchy.\n  Here we consider the degree-$4$ SOS relaxation, and study the construction of\n\\cite{meka2013association} to prove that SOS fails unless $k\\ge C\\,\nn^{1/3}/\\log n$. An argument presented by Barak implies that this lower bound\ncannot be substantially improved unless the witness construction is changed in\nthe proof. Our proof uses the moments method to bound the spectrum of a certain\nrandom association scheme, i.e. a symmetric random matrix whose rows and\ncolumns are indexed by the edges of an Erd\\\"os-Renyi random graph.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 20:45:11 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Deshpande", "Yash", ""], ["Montanari", "Andrea", ""]]}, {"id": "1502.06761", "submitter": "Miki Hermann", "authors": "Mike Behrisch, Miki Hermann, Stefan Mengel, Gernot Salzer", "title": "Minimal Distance of Propositional Models", "comments": null, "journal-ref": "Theory of Computing Systems (2018) 1-54", "doi": "10.1007/s00224-018-9896-8", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the complexity of three optimization problems in Boolean\npropositional logic related to information theory: Given a conjunctive formula\nover a set of relations, find a satisfying assignment with minimal Hamming\ndistance to a given assignment that satisfies the formula\n($\\mathsf{NeareastOtherSolution}$, $\\mathsf{NOSol}$) or that does not need to\nsatisfy it ($\\mathsf{NearestSolution}$, $\\mathsf{NSol}$). The third problem\nasks for two satisfying assignments with a minimal Hamming distance among all\nsuch assignments ($\\mathsf{MinSolutionDistance}$, $\\mathsf{MSD}$).\n  For all three problems we give complete classifications with respect to the\nrelations admitted in the formula. We give polynomial time algorithms for\nseveral classes of constraint languages. For all other cases we prove hardness\nor completeness regarding APX, APX, NPO, or equivalence to well-known hard\noptimization problems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 11:06:04 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 23:48:07 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Behrisch", "Mike", ""], ["Hermann", "Miki", ""], ["Mengel", "Stefan", ""], ["Salzer", "Gernot", ""]]}, {"id": "1502.07258", "submitter": "Shuichi Hirahara", "authors": "Shuichi Hirahara", "title": "Identifying an Honest ${\\rm EXP}^{\\rm NP}$ Oracle Among Many", "comments": "20 pages; a simplified proof for the main theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a general framework to remove short advice by formulating the\nfollowing computational task for a function $f$: given two oracles at least one\nof which is honest (i.e. correctly computes $f$ on all inputs) as well as an\ninput, the task is to compute $f$ on the input with the help of the oracles by\na probabilistic polynomial-time machine, which we shall call a selector. We\ncharacterize the languages for which short advice can be removed by the notion\nof selector: a paddable language has a selector if and only if short advice of\na probabilistic machine that accepts the language can be removed under any\nrelativized world. Previously, instance checkers have served as a useful tool\nto remove short advice of probabilistic computation. We indicate that existence\nof instance checkers is a property stronger than that of removing short advice:\nalthough no instance checker for ${\\rm EXP}^{\\rm NP}$-complete languages exists\nunless ${\\rm EXP}^{\\rm NP} = {\\rm NEXP}$, we prove that there exists a selector\nfor any ${\\rm EXP}^{\\rm NP}$-complete language, by building on the proof of\n${\\rm MIP} = {\\rm NEXP}$ by Babai, Fortnow, and Lund (1991).\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 17:16:44 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2015 05:19:54 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Hirahara", "Shuichi", ""]]}, {"id": "1502.07327", "submitter": "Vladimir Kolmogorov", "authors": "Vladimir Kolmogorov, Andrei Krokhin, Michal Rolinek", "title": "The Complexity of General-Valued CSPs", "comments": "accepted to SIAM Journal on Computing (SICOMP). An extended abstract\n  of this work (without proofs) has appeared in FOCS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An instance of the Valued Constraint Satisfaction Problem (VCSP) is given by\na finite set of variables, a finite domain of labels, and a sum of functions,\neach function depending on a subset of the variables. Each function can take\nfinite values specifying costs of assignments of labels to its variables or the\ninfinite value, which indicates infeasible assignments. The goal is to find an\nassignment of labels to the variables that minimizes the sum.\n  We study (assuming that P $\\ne$ NP) how the complexity of this very general\nproblem depends on the set of functions allowed in the instances, the so-called\nconstraint language. The case when all allowed functions take values in\n$\\{0,\\infty\\}$ corresponds to ordinary CSPs, where one deals only with the\nfeasibility issue and there is no optimization. This case is the subject of the\nAlgebraic CSP Dichotomy Conjecture predicting for which constraint languages\nCSPs are tractable and for which NP-hard. The case when all allowed functions\ntake only finite values corresponds to finite-valued CSP, where the feasibility\naspect is trivial and one deals only with the optimization issue. The\ncomplexity of finite-valued CSPs was fully classified by Thapper and\n\\v{Z}ivn\\'y.\n  An algebraic necessary condition for tractability of a general-valued CSP\nwith a fixed constraint language was recently given by Kozik and Ochremiak. As\nour main result, we prove that if a constraint language satisfies this\nalgebraic necessary condition, and the feasibility CSP corresponding to the\nVCSP with this language is tractable, then the VCSP is tractable. The algorithm\nis a simple combination of the assumed algorithm for the feasibility CSP and\nthe standard LP relaxation. As a corollary, we obtain that a dichotomy for\nordinary CSPs would imply a dichotomy for general-valued CSPs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 20:26:26 GMT"}, {"version": "v2", "created": "Thu, 26 Feb 2015 15:37:27 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2015 08:32:17 GMT"}, {"version": "v4", "created": "Mon, 20 Jun 2016 15:48:50 GMT"}, {"version": "v5", "created": "Mon, 13 Feb 2017 09:50:48 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Kolmogorov", "Vladimir", ""], ["Krokhin", "Andrei", ""], ["Rolinek", "Michal", ""]]}, {"id": "1502.07410", "submitter": "Karthekeyan Chandrasekaran", "authors": "Karthekeyan Chandrasekaran, Ameya Velingker", "title": "Towards Constructing Ramanujan Graphs Using Shift Lifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a breakthrough work, Marcus-Spielman-Srivastava recently showed that every\n$d$-regular bipartite Ramanujan graph has a 2-lift that is also $d$-regular\nbipartite Ramanujan. As a consequence, a straightforward iterative brute-force\nsearch algorithm leads to the construction of a $d$-regular bipartite Ramanujan\ngraph on $N$ vertices in time $2^{O(dN)}$. Shift $k$-lifts studied by\nAgarwal-Kolla-Madan lead to a natural approach for constructing Ramanujan\ngraphs more efficiently. The number of possible shift $k$-lifts of a\n$d$-regular $n$-vertex graph is $k^{nd/2}$. Suppose the following holds for\n$k=2^{\\Omega(n)}$:\n  There exists a shift $k$-lift that maintains the Ramanujan property of\n$d$-regular bipartite graphs on $n$ vertices for all $n$. (*)\n  Then, by performing a similar brute-force search algorithm, one would be able\nto construct an $N$-vertex bipartite Ramanujan graph in time $2^{O(d\\,log^2\nN)}$. Furthermore, if (*) holds for all $k \\geq 2$, then one would obtain an\nalgorithm that runs in $\\mathrm{poly}_d(N)$ time. In this work, we take a first\nstep towards proving (*) by showing the existence of shift $k$-lifts that\npreserve the Ramanujan property in $d$-regular bipartite graphs for $k=3,4$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 01:06:55 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2015 02:32:47 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2015 13:09:42 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Chandrasekaran", "Karthekeyan", ""], ["Velingker", "Ameya", ""]]}, {"id": "1502.07467", "submitter": "Thomas Zeume", "authors": "Samir Datta, Raghav Kulkarni, Anish Mukherjee, Thomas Schwentick,\n  Thomas Zeume", "title": "Reachability is in DynFO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patnaik and Immerman introduced the dynamic complexity class DynFO of\ndatabase queries that can be maintained by first-order dynamic programs with\nthe help of auxiliary relations under insertions and deletions of edges\n(Patnaik and Immerman 1997). This article confirms their conjecture that the\nReachability query is in DynFO.\n  As a byproduct it is shown that the rank of a matrix with small values can be\nmaintained in DynFO(+,x). It is further shown that the (size of the) maximum\nmatching of a graph can be maintained in non-uniform DynFO, another extension\nof DynFO, with non-uniform initialisation of the auxiliary relations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 08:30:57 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2015 17:54:46 GMT"}, {"version": "v3", "created": "Wed, 5 Apr 2017 07:28:08 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Datta", "Samir", ""], ["Kulkarni", "Raghav", ""], ["Mukherjee", "Anish", ""], ["Schwentick", "Thomas", ""], ["Zeume", "Thomas", ""]]}, {"id": "1502.07545", "submitter": "Feng Pan Dr", "authors": "Feng Pan", "title": "SAT problem and statistical distance", "comments": "15 pages. arXiv admin note: text overlap with arXiv:quant-ph/0311110\n  by other authors without attribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper with two equivalent representations of the information\ncontained by a SAT formula, the reason why string generated by succinct SAT\nformula can be greatly compressed is firstly presented based on Kolmogorov\ncomplexity theory. Then what strings can be greatly compressed were classified\nand discussed. In this way we discovered the SAT problem was composed of a\nbasic distinguish problem: distinguish two different distributions induced\nunder the computer with certain SAT formula ensemble. We then tried to map this\nproblem into quantum mechanics, or the quantum version basic distinguish\nproblem: this time two different distributions are induced under quantum\nmechanics. Based on the equivalence of statistical distance between probability\nspace and Hilbert space, in the same time this distance is invariant under all\nunitary transformations. The quantum version basic problem cannot be\nefficiently solved by any quantum computer. In the worst case, any quantum\ncomputer must perform exponential times measurement in order to solve it. In\nthe end we proposed the main theorem : The statistical distance in program\nspace and probability space are identical. We tried to prove it using the\nrelationship of Kolmogorov complexity and entropy. It showed there is no\ndifference to solve the basic problem in SAT formula space or probability\nspace. In the worst case, exponential trials must be performed to solve it.\nNP!=P.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 13:28:06 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2015 01:38:04 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2015 00:22:04 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Pan", "Feng", ""]]}, {"id": "1502.07591", "submitter": "Cristopher Moore", "authors": "Cristopher Moore", "title": "The phase transition in random regular exact cover", "comments": "Added sentence pointing out that the threshold is never an integer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cond-mat.stat-mech math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $k$-uniform, $d$-regular instance of Exact Cover is a family of $m$ sets\n$F_{n,d,k} = \\{ S_j \\subseteq \\{1,...,n\\} \\}$, where each subset has size $k$\nand each $1 \\le i \\le n$ is contained in $d$ of the $S_j$. It is satisfiable if\nthere is a subset $T \\subseteq \\{1,...,n\\}$ such that $|T \\cap S_j|=1$ for all\n$j$. Alternately, we can consider it a $d$-regular instance of Positive\n1-in-$k$ SAT, i.e., a Boolean formula with $m$ clauses and $n$ variables where\neach clause contains $k$ variables and demands that exactly one of them is\ntrue. We determine the satisfiability threshold for random instances of this\ntype with $k > 2$. Letting $d^\\star = \\frac{\\ln k}{(k-1)(- \\ln (1-1/k))} + 1$,\nwe show that $F_{n,d,k}$ is satisfiable with high probability if $d < d^\\star$\nand unsatisfiable with high probability if $d > d^\\star$. We do this with a\nsimple application of the first and second moment methods, boosting the\nprobability of satisfiability below $d^\\star$ to $1-o(1)$ using the small\nsubgraph conditioning method.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 15:22:02 GMT"}, {"version": "v2", "created": "Fri, 27 Feb 2015 01:45:31 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2015 17:49:19 GMT"}], "update_date": "2015-03-05", "authors_parsed": [["Moore", "Cristopher", ""]]}, {"id": "1502.07661", "submitter": "George Danezis", "authors": "Nadia Alshahwan and Earl T. Barr and David Clark and George Danezis", "title": "Detecting Malware with Information Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on a specific front of the malware detection arms-race,\nnamely the detection of persistent, disk-resident malware. We exploit\nnormalised compression distance (NCD), an information theoretic measure,\napplied directly to binaries. Given a zoo of labelled malware and benign-ware,\nwe ask whether a suspect program is more similar to our malware or to our\nbenign-ware. Our approach classifies malware with 97.1% accuracy and a false\npositive rate of 3%. We achieve our results with off-the-shelf compressors and\na standard machine learning classifier and without any specialised knowledge.\nAn end-user need only collect a zoo of malware and benign-ware and then can\nimmediately apply our techniques.\n  We apply statistical rigour to our experiments and our selection of data. We\ndemonstrate that accuracy can be optimised by combining NCD with the\ncompressibility rates of the executables. We demonstrate that malware reported\nwithin a more narrow time frame of a few days is more homogenous than malware\nreported over a longer one of two years but that our method still classifies\nthe latter with 95.2% accuracy and a 5% false positive rate. Due to the use of\ncompression, the time and computation cost of our method is non-trivial. We\nshow that simple approximation techniques can improve the time complexity of\nour approach by up to 63%.\n  We compare our results to the results of applying the 59 anti-malware\nprograms used on the VirusTotal web site to our malware. Our approach does\nbetter than any single one of them as well as the 59 used collectively.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 18:21:07 GMT"}], "update_date": "2015-02-27", "authors_parsed": [["Alshahwan", "Nadia", ""], ["Barr", "Earl T.", ""], ["Clark", "David", ""], ["Danezis", "George", ""]]}]