[{"id": "1202.0313", "submitter": "Leslie Ann Goldberg", "authors": "Leslie Ann Goldberg and Mark Jerrum", "title": "The Complexity of Computing the Sign of the Tutte Polynomial", "comments": "minor updates. This is the final version (to appear in SICOMP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of computing the sign of the Tutte polynomial of a\ngraph. As there are only three possible outcomes (positive, negative, and\nzero), this seems at first sight more like a decision problem than a counting\nproblem. Surprisingly, however, there are large regions of the parameter space\nfor which computing the sign of the Tutte polynomial is actually #P-hard. As a\ntrivial consequence, approximating the polynomial is also #P-hard in this case.\nThus, approximately evaluating the Tutte polynomial in these regions is as hard\nas exactly counting the satisfying assignments to a CNF Boolean formula. For\nmost other points in the parameter space, we show that computing the sign of\nthe polynomial is in FP, whereas approximating the polynomial can be done in\npolynomial time with an NP oracle. As a special case, we completely resolve the\ncomplexity of computing the sign of the chromatic polynomial - this is easily\ncomputable at q=2 and when q is less than or equal to 32/27, and is NP-hard to\ncompute for all other values of the parameter q.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2012 22:23:34 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2012 11:02:23 GMT"}, {"version": "v3", "created": "Fri, 4 Apr 2014 13:17:10 GMT"}, {"version": "v4", "created": "Fri, 25 Apr 2014 13:59:54 GMT"}, {"version": "v5", "created": "Wed, 8 Oct 2014 21:17:36 GMT"}], "update_date": "2014-10-10", "authors_parsed": [["Goldberg", "Leslie Ann", ""], ["Jerrum", "Mark", ""]]}, {"id": "1202.0535", "submitter": "Carol Wang", "authors": "Venkatesan Guruswami, Srivatsan Narayanan, Carol Wang", "title": "List decoding subspace codes from insertions and deletions", "comments": "13 pages. A conference version appeared at ITCS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a construction of subspace codes along with an efficient algorithm\nfor list decoding from both insertions and deletions, handling an\ninformation-theoretically maximum fraction of these with polynomially small\nrate. Our construction is based on a variant of the folded Reed-Solomon codes\nin the world of linearized polynomials, and the algorithm is inspired by the\nrecent linear-algebraic approach to list decoding. Ours is the first list\ndecoding algorithm for subspace codes that can handle deletions; even one\ndeletion can totally distort the structure of the basis of a subspace and is\nthus challenging to handle. When there are only insertions, we also present\nresults for list decoding subspace codes that are the linearized analog of\nReed-Solomon codes (proposed previously, and closely related to the Gabidulin\ncodes for rank-metric), obtaining some improvements over similar results in\nprevious work.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2012 20:13:47 GMT"}], "update_date": "2012-02-03", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Narayanan", "Srivatsan", ""], ["Wang", "Carol", ""]]}, {"id": "1202.0664", "submitter": "Urban Larsson Mr", "authors": "Urban Larsson and Johan W\\\"astlund", "title": "From heaps of matches to the limits of computability", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study so-called invariant games played with a fixed number $d$ of heaps of\nmatches. A game is described by a finite list $\\mathcal{M}$ of integer vectors\nof length $d$ specifying the legal moves. A move consists in changing the\ncurrent game-state by adding one of the vectors in $\\mathcal{M}$, provided all\nelements of the resulting vector are nonnegative. For instance, in a two-heap\ngame, the vector $(1,-2)$ would mean adding one match to the first heap and\nremoving two matches from the second heap. If $(1,-2) \\in \\mathcal{M}$, such a\nmove would be permitted provided there are at least two matches in the second\nheap. Two players take turns, and a player unable to make a move loses. We show\nthat these games embrace computational universality, and that therefore a\nnumber of basic questions about them are algorithmically undecidable. In\nparticular, we prove that there is no algorithm that takes two games\n$\\mathcal{M}$ and $\\mathcal{M}'$ (with the same number of heaps) as input, and\ndetermines whether or not they are equivalent in the sense that every\nstarting-position which is a first player win in one of the games is a first\nplayer win in the other.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2012 11:21:43 GMT"}], "update_date": "2012-02-06", "authors_parsed": [["Larsson", "Urban", ""], ["W\u00e4stlund", "Johan", ""]]}, {"id": "1202.0847", "submitter": "Jan Kyn\\v{c}l", "authors": "Josef Cibulka, Jan Kyn\\v{c}l, Viola M\\'esz\\'aros, Rudolf Stola\\v{r},\n  Pavel Valtr", "title": "Graph sharing games: complexity and connectivity", "comments": "22 pages, 11 figures; updated references, minor stylistical changes", "journal-ref": "Theoretical Computer Science 494 (2013), 49-62", "doi": "10.1016/j.tcs.2012.12.029", "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following combinatorial game played by two players, Alice and\nBob, which generalizes the Pizza game considered by Brown, Winkler and others.\nGiven a connected graph G with nonnegative weights assigned to its vertices,\nthe players alternately take one vertex of G in each turn. The first turn is\nAlice's. The vertices are to be taken according to one (or both) of the\nfollowing two rules: (T) the subgraph of G induced by the taken vertices is\nconnected during the whole game, (R) the subgraph of G induced by the remaining\nvertices is connected during the whole game. We show that if rules (T) and/or\n(R) are required then for every epsilon > 0 and for every positive integer k\nthere is a k-connected graph G for which Bob has a strategy to obtain\n(1-epsilon) of the total weight of the vertices. This contrasts with the\noriginal Pizza game played on a cycle, where Alice is known to have a strategy\nto obtain 4/9 of the total weight.\n  We show that the problem of deciding whether Alice has a winning strategy\n(i.e., a strategy to obtain more than half of the total weight) is\nPSPACE-complete if condition (R) or both conditions (T) and (R) are required.\nWe also consider a game played on connected graphs (without weights) where the\nfirst player who violates condition (T) or (R) loses the game. We show that\ndeciding who has the winning strategy is PSPACE-complete.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2012 00:13:38 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2012 21:55:12 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Cibulka", "Josef", ""], ["Kyn\u010dl", "Jan", ""], ["M\u00e9sz\u00e1ros", "Viola", ""], ["Stola\u0159", "Rudolf", ""], ["Valtr", "Pavel", ""]]}, {"id": "1202.1194", "submitter": "Koji Kobayashi", "authors": "Koji Kobayashi", "title": "Topological approach to solve P versus NP", "comments": "7 pages, English and Japanese (see Other formats - Source)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper talks about difference between P and NP by using topological space\nthat mean resolution principle. I pay attention to restrictions of antecedent\nand consequent in resolution, and show what kind of influence the restrictions\nhave for difference of structure between P and NP regarding relations of\nrelation.\n  First, I show the restrictions of antecedent and consequent in resolution\nprinciple. Antecedents connect each other, and consequent become a linkage\nbetween these antecedents. And we can make consequent as antecedents product by\nusing some resolutions which have same joint variable. We can determine these\nconsequents reducible and irreducible.\n  Second, I introduce RCNF that mean topology of resolution principle in CNF.\nRCNF is HornCNF and that variable values are presence of restrictions of CNF\nformula clauses. RCNF is P-Complete.\n  Last, I introduce TCNF that have 3CNF's character which relate 2 variables\nrelations with 1 variable. I show CNF complexity by using CCNF that combine\nsome TCNF. TCNF is NP-Complete and product irreducible. I introduce CCNF that\nconnect TCNF like Moore graph. We cannot reduce CCNF to RCNF with polynomial\nsize. Therefore, TCNF is not in P.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 16:26:23 GMT"}, {"version": "v10", "created": "Sun, 20 May 2012 16:23:38 GMT"}, {"version": "v11", "created": "Sun, 14 Oct 2012 04:17:38 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2012 15:42:45 GMT"}, {"version": "v3", "created": "Tue, 21 Feb 2012 17:24:24 GMT"}, {"version": "v4", "created": "Wed, 22 Feb 2012 17:23:33 GMT"}, {"version": "v5", "created": "Thu, 23 Feb 2012 15:07:01 GMT"}, {"version": "v6", "created": "Sun, 26 Feb 2012 04:27:08 GMT"}, {"version": "v7", "created": "Wed, 14 Mar 2012 17:39:37 GMT"}, {"version": "v8", "created": "Sun, 25 Mar 2012 14:35:46 GMT"}, {"version": "v9", "created": "Thu, 3 May 2012 16:01:41 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Kobayashi", "Koji", ""]]}, {"id": "1202.1936", "submitter": "Bodo Manthey", "authors": "Markus Bl\\\"aser and Bodo Manthey", "title": "Smoothed Complexity Theory", "comments": "to be presented at MFCS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothed analysis is a new way of analyzing algorithms introduced by Spielman\nand Teng (J. ACM, 2004). Classical methods like worst-case or average-case\nanalysis have accompanying complexity classes, like P and AvgP, respectively.\nWhile worst-case or average-case analysis give us a means to talk about the\nrunning time of a particular algorithm, complexity classes allows us to talk\nabout the inherent difficulty of problems.\n  Smoothed analysis is a hybrid of worst-case and average-case analysis and\ncompensates some of their drawbacks. Despite its success for the analysis of\nsingle algorithms and problems, there is no embedding of smoothed analysis into\ncomputational complexity theory, which is necessary to classify problems\naccording to their intrinsic difficulty.\n  We propose a framework for smoothed complexity theory, define the relevant\nclasses, and prove some first hardness results (of bounded halting and tiling)\nand tractability results (binary optimization problems, graph coloring,\nsatisfiability). Furthermore, we discuss extensions and shortcomings of our\nmodel and relate it to semi-random models.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 10:17:53 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2012 07:11:04 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Bl\u00e4ser", "Markus", ""], ["Manthey", "Bodo", ""]]}, {"id": "1202.3173", "submitter": "Olga Holtz", "authors": "Grey Ballard, James Demmel, Olga Holtz, Benjamin Lipshitz, Oded\n  Schwartz", "title": "Communication-Optimal Parallel Algorithm for Strassen's Matrix\n  Multiplication", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC cs.NA math.CO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel matrix multiplication is one of the most studied fundamental\nproblems in distributed and high performance computing. We obtain a new\nparallel algorithm that is based on Strassen's fast matrix multiplication and\nminimizes communication. The algorithm outperforms all known parallel matrix\nmultiplication algorithms, classical and Strassen-based, both asymptotically\nand in practice.\n  A critical bottleneck in parallelizing Strassen's algorithm is the\ncommunication between the processors. Ballard, Demmel, Holtz, and Schwartz\n(SPAA'11) prove lower bounds on these communication costs, using expansion\nproperties of the underlying computation graph. Our algorithm matches these\nlower bounds, and so is communication-optimal. It exhibits perfect strong\nscaling within the maximum possible range.\n  Benchmarking our implementation on a Cray XT4, we obtain speedups over\nclassical and Strassen-based algorithms ranging from 24% to 184% for a fixed\nmatrix dimension n=94080, where the number of nodes ranges from 49 to 7203.\n  Our parallelization approach generalizes to other fast matrix multiplication\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 23:12:23 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Ballard", "Grey", ""], ["Demmel", "James", ""], ["Holtz", "Olga", ""], ["Lipshitz", "Benjamin", ""], ["Schwartz", "Oded", ""]]}, {"id": "1202.3177", "submitter": "Olga Holtz", "authors": "Grey Ballard, James Demmel, Olga Holtz, Benjamin Lipshitz, Oded\n  Schwartz", "title": "Strong Scaling of Matrix Multiplication Algorithms and\n  Memory-Independent Communication Lower Bounds", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC cs.NA math.CO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parallel algorithm has perfect strong scaling if its running time on P\nprocessors is linear in 1/P, including all communication costs.\nDistributed-memory parallel algorithms for matrix multiplication with perfect\nstrong scaling have only recently been found. One is based on classical matrix\nmultiplication (Solomonik and Demmel, 2011), and one is based on Strassen's\nfast matrix multiplication (Ballard, Demmel, Holtz, Lipshitz, and Schwartz,\n2012). Both algorithms scale perfectly, but only up to some number of\nprocessors where the inter-processor communication no longer scales.\n  We obtain a memory-independent communication cost lower bound on classical\nand Strassen-based distributed-memory matrix multiplication algorithms. These\nbounds imply that no classical or Strassen-based parallel matrix multiplication\nalgorithm can strongly scale perfectly beyond the ranges already attained by\nthe two parallel algorithms mentioned above. The memory-independent bounds and\nthe strong scaling bounds generalize to other algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 23:42:19 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Ballard", "Grey", ""], ["Demmel", "James", ""], ["Holtz", "Olga", ""], ["Lipshitz", "Benjamin", ""], ["Schwartz", "Oded", ""]]}, {"id": "1202.3317", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago, Paolo Parisen Toldin", "title": "An Higher-Order Characterization of Probabilistic Polynomial Time (Long\n  Version)", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present RSLR, an implicit higher-order characterization of the class PP of\nthose problems which can be decided in probabilistic polynomial time with error\nprobability smaller than 1/2. Analogously, a (less implicit) characterization\nof the class BPP can be obtained. RSLR is an extension of Hofmann's SLR with a\nprobabilistic primitive, which enjoys basic properties such as subject\nreduction and confluence. Polynomial time soundness of RSLR is obtained by\nsyntactical means, as opposed to the standard literature on SLR-derived\nsystems, which use semantics in an essential way.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2012 14:21:42 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Toldin", "Paolo Parisen", ""]]}, {"id": "1202.3479", "submitter": "Pooya Hatami", "authors": "Pooya Hatami", "title": "Lower Bounds on Testing Functions of Low Fourier Degree", "comments": "This paper has been withdrawn in order to be replaced with a new\n  joint paper with a coauthor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of testing whether a Boolean function has Fourier\ndegree $\\leq k$ or it is $\\epsilon$-far from any Boolean function with Fourier\ndegree $\\leq k$. We improve the known lower bound of $\\Omega(k)$\n\\cite{BBM11,CGM10}, to $\\Omega(k/\\sqrt{\\epsilon})$. The lower bound uses the\nrecently discovered connections between property testing and communication\ncomplexity by Blais \\textit{et. al.} \\cite{BBM11}\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 00:23:15 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2012 06:51:15 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2012 00:17:26 GMT"}, {"version": "v4", "created": "Sat, 24 Aug 2013 18:19:50 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Hatami", "Pooya", ""]]}, {"id": "1202.3855", "submitter": "Paul Potgieter", "authors": "Paul Potgieter (Unisa)", "title": "The rapid points of a complex oscillation", "comments": "11 pages", "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 9,\n  2012) lmcs:1188", "doi": "10.2168/LMCS-8(1:23)2012", "report-no": null, "categories": "cs.CC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By considering a counting-type argument on Brownian sample paths, we prove a\nresult similar to that of Orey and Taylor on the exact Hausdorff dimension of\nthe rapid points of Brownian motion. Because of the nature of the proof we can\nthen apply the concepts to so-called complex oscillations (or 'algorithmically\nrandom Brownian motion'), showing that their rapid points have the same\ndimension.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2012 09:27:41 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2012 13:46:08 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Potgieter", "Paul", "", "Unisa"]]}, {"id": "1202.3949", "submitter": "Niel de Beaudrap", "authors": "Niel de Beaudrap (DAMTP, Centre for Mathematical Studies, University\n  of Cambridge)", "title": "On the complexity of solving linear congruences and computing nullspaces\n  modulo a constant", "comments": "17 pages, one Appendix; minor corrections and revisions to\n  presentation, new observations regarding the prospect of oracle closures.\n  Comments welcome", "journal-ref": "Chicago Journal of Theoretical Computer Science vol.2013 (#10),\n  July 2013", "doi": "10.4086/cjtcs.2013.010", "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We consider the problems of determining the feasibility of a linear\ncongruence, producing a solution to a linear congruence, and finding a spanning\nset for the nullspace of an integer matrix, where each problem is considered\nmodulo an arbitrary constant k>1. These problems are known to be complete for\nthe logspace modular counting classes {Mod_k L} = {coMod_k L} in special case\nthat k is prime (Buntrock et al, 1992). By considering variants of standard\nlogspace function classes --- related to #L and functions computable by UL\nmachines, but which only characterize the number of accepting paths modulo k\n--- we show that these problems of linear algebra are also complete for\n{coMod_k L} for any constant k>1.\n  Our results are obtained by defining a class of functions FUL_k which are low\nfor {Mod_k L} and {coMod_k L} for k>1, using ideas similar to those used in the\ncase of k prime in (Buntrock et al, 1992) to show closure of Mod_k L under NC^1\nreductions (including {Mod_k L} oracle reductions). In addition to the results\nabove, we briefly consider the relationship of the class FUL_k for arbitrary\nmoduli k to the class {F.coMod_k L} of functions whose output symbols are\nverifiable by {coMod_k L} algorithms; and consider what consequences such a\ncomparison may have for oracle closure results of the form {Mod_k L}^{Mod_k L}\n= {Mod_k L} for composite k.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2012 16:18:46 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2012 18:31:26 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2013 14:40:12 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["de Beaudrap", "Niel", "", "DAMTP, Centre for Mathematical Studies, University\n  of Cambridge"]]}, {"id": "1202.4301", "submitter": "Johannes Mittmann", "authors": "Johannes Mittmann, Nitin Saxena and Peter Scheiblechner", "title": "Algebraic Independence in Positive Characteristic -- A p-Adic Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set of multivariate polynomials, over a field of zero or large\ncharacteristic, can be tested for algebraic independence by the well-known\nJacobian criterion. For fields of other characteristic p>0, there is no\nanalogous characterization known. In this paper we give the first such\ncriterion. Essentially, it boils down to a non-degeneracy condition on a lift\nof the Jacobian polynomial over (an unramified extension of) the ring of p-adic\nintegers.\n  Our proof builds on the de Rham-Witt complex, which was invented by Illusie\n(1979) for crystalline cohomology computations, and we deduce a natural\ngeneralization of the Jacobian. This new avatar we call the Witt-Jacobian. In\nessence, we show how to faithfully differentiate polynomials over F_p (i.e.\nsomehow avoid dx^p/dx=0) and thus capture algebraic independence.\n  We apply the new criterion to put the problem of testing algebraic\nindependence in the complexity class NP^#P (previously best was PSPACE). Also,\nwe give a modest application to the problem of identity testing in algebraic\ncomplexity theory.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 12:25:20 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Mittmann", "Johannes", ""], ["Saxena", "Nitin", ""], ["Scheiblechner", "Peter", ""]]}, {"id": "1202.4331", "submitter": "Serge Gaspers", "authors": "Serge Gaspers and Stefan Szeider", "title": "Strong Backdoors to Nested Satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knuth (1990) introduced the class of nested formulas and showed that their\nsatisfiability can be decided in polynomial time. We show that, parameterized\nby the size of a smallest strong backdoor set to the target class of nested\nformulas, checking the satisfiability of any CNF formula is fixed-parameter\ntractable. Thus, for any k>0, the satisfiability problem can be solved in\npolynomial time for any formula F for which there exists a variable set B of\nsize at most k such that for every truth assignment t to B, the formula F[t] is\nnested; moreover, the degree of the polynomial is independent of k.\n  Our algorithm uses the grid-minor theorem of Robertson and Seymour (1986) to\neither find that the incidence graph of the formula has bounded treewidth - a\ncase that is solved using model checking for monadic second order logic - or to\nfind many vertex-disjoint obstructions in the incidence graph. For the latter\ncase, new combinatorial arguments are used to find a small backdoor set.\nCombining both cases leads to an approximation algorithm producing a strong\nbackdoor set whose size is upper bounded by a function of the optimum. Going\nthrough all assignments to this set of variables and using Knuth's algorithm,\nthe satisfiability of the input formula is decided.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 14:10:02 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2012 16:26:35 GMT"}], "update_date": "2012-03-07", "authors_parsed": [["Gaspers", "Serge", ""], ["Szeider", "Stefan", ""]]}, {"id": "1202.4406", "submitter": "Oleg Verbitsky", "authors": "Johannes K\\\"obler, Sebastian Kuhnert, Oleg Verbitsky", "title": "Solving the Canonical Representation and Star System Problems for Proper\n  Circular-Arc Graphs in Log-Space", "comments": "19 pages, 3 figures, major revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a logspace algorithm that constructs a canonical intersection\nmodel for a given proper circular-arc graph, where `canonical' means that\nmodels of isomorphic graphs are equal. This implies that the recognition and\nthe isomorphism problems for this class of graphs are solvable in logspace. For\na broader class of concave-round graphs, that still possess (not necessarily\nproper) circular-arc models, we show that those can also be constructed\ncanonically in logspace. As a building block for these results, we show how to\ncompute canonical models of circular-arc hypergraphs in logspace, which are\nalso known as matrices with the circular-ones property. Finally, we consider\nthe search version of the Star System Problem that consists in reconstructing a\ngraph from its closed neighborhood hypergraph. We solve it in logspace for the\nclasses of proper circular-arc, concave-round, and co-convex graphs.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 18:06:08 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2012 10:05:17 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2012 09:23:07 GMT"}, {"version": "v4", "created": "Tue, 8 May 2012 08:07:27 GMT"}, {"version": "v5", "created": "Thu, 5 Dec 2013 12:22:31 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["K\u00f6bler", "Johannes", ""], ["Kuhnert", "Sebastian", ""], ["Verbitsky", "Oleg", ""]]}, {"id": "1202.4407", "submitter": "Amaury Pouly", "authors": "Olivier Bournez, Daniel S. Gra\\c{c}a, Amaury Pouly", "title": "On the complexity of solving initial value problems", "comments": "8 pages (two columns per page), submitted to ISSAC'12 conference", "journal-ref": null, "doi": "10.1145/2442829.2442849", "report-no": null, "categories": "cs.NA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove that computing the solution of an initial-value\nproblem $\\dot{y}=p(y)$ with initial condition $y(t_0)=y_0\\in\\R^d$ at time\n$t_0+T$ with precision $e^{-\\mu}$ where $p$ is a vector of polynomials can be\ndone in time polynomial in the value of $T$, $\\mu$ and $Y=\\sup_{t_0\\leqslant\nu\\leqslant T}\\infnorm{y(u)}$. Contrary to existing results, our algorithm works\nfor any vector of polynomials $p$ over any bounded or unbounded domain and has\na guaranteed complexity and precision. In particular we do not assume $p$ to be\nfixed, nor the solution to lie in a compact domain, nor we assume that $p$ has\na Lipschitz constant.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 18:09:18 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Bournez", "Olivier", ""], ["Gra\u00e7a", "Daniel S.", ""], ["Pouly", "Amaury", ""]]}, {"id": "1202.4798", "submitter": "Kousha Etessami", "authors": "Kousha Etessami, Alistair Stewart, Mihalis Yannakakis", "title": "Polynomial Time Algorithms for Branching Markov Decision Processes and\n  Probabilistic Min(Max) Polynomial Bellman Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that one can approximate the least fixed point solution for a\nmultivariate system of monotone probabilistic max(min) polynomial equations,\nreferred to as maxPPSs (and minPPSs, respectively), in time polynomial in both\nthe encoding size of the system of equations and in log(1/epsilon), where\nepsilon > 0 is the desired additive error bound of the solution. (The model of\ncomputation is the standard Turing machine model.) We establish this result\nusing a generalization of Newton's method which applies to maxPPSs and minPPSs,\neven though the underlying functions are only piecewise-differentiable. This\ngeneralizes our recent work which provided a P-time algorithm for purely\nprobabilistic PPSs.\n  These equations form the Bellman optimality equations for several important\nclasses of infinite-state Markov Decision Processes (MDPs). Thus, as a\ncorollary, we obtain the first polynomial time algorithms for computing to\nwithin arbitrary desired precision the optimal value vector for several classes\nof infinite-state MDPs which arise as extensions of classic, and heavily\nstudied, purely stochastic processes. These include both the problem of\nmaximizing and mininizing the termination (extinction) probability of\nmulti-type branching MDPs, stochastic context-free MDPs, and 1-exit Recursive\nMDPs.\n  Furthermore, we also show that we can compute in P-time an epsilon-optimal\npolicy for both maximizing and minimizing branching, context-free, and\n1-exit-Recursive MDPs, for any given desired epsilon > 0. This is despite the\nfact that actually computing optimal strategies is Sqrt-Sum-hard and\nPosSLP-hard in this setting.\n  We also derive, as an easy consequence of these results, an FNP upper bound\non the complexity of computing the value (within arbitrary desired precision)\nof branching simple stochastic games (BSSGs).\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 00:14:20 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2012 10:43:38 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Etessami", "Kousha", ""], ["Stewart", "Alistair", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "1202.4883", "submitter": "Tomoyuki Yamakami", "authors": "Tomoyuki Yamakami and Yuichi Kato", "title": "The Dissecting Power of Regular Languages", "comments": "A4, 10pt, 9 pages, 2 figures", "journal-ref": "Information Processing Letters, Vol.113, pp.116-122, 2013", "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent study on structural properties of regular and context-free languages\nhas greatly promoted our basic understandings of the complex behaviors of those\nlanguages. We continue the study to examine how regular languages behave when\nthey need to cut numerous infinite languages. A particular interest rests on a\nsituation in which a regular language needs to \"dissect\" a given infinite\nlanguage into two subsets of infinite size. Every context-free language is\ndissected by carefully chosen regular languages (or it is REG-dissectible). In\na larger picture, we show that constantly-growing languages and semi-linear\nlanguages are REG-dissectible. Under certain natural conditions, complements\nand finite intersections of semi-linear languages also become REG-dissectible.\nRestricted to bounded languages, the intersections of finitely many\ncontext-free languages and, more surprisingly, the entire Boolean hierarchy\nover bounded context-free languages are REG-dissectible. As an immediate\napplication of the REG-dissectibility, we show another structural property, in\nwhich an appropriate bounded context-free language can \"separate with infinite\nmargins\" two given nested infinite bounded context-free languages.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 11:16:47 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2012 16:00:33 GMT"}, {"version": "v3", "created": "Wed, 12 Dec 2012 12:38:14 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Yamakami", "Tomoyuki", ""], ["Kato", "Yuichi", ""]]}, {"id": "1202.5184", "submitter": "Florian Sikora", "authors": "Romeo Rizzi and Florian Sikora", "title": "Some results on more flexible versions of Graph Motif", "comments": null, "journal-ref": null, "doi": "10.1007/s00224-014-9564-6", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problems studied in this paper originate from Graph Motif, a problem\nintroduced in 2006 in the context of biological networks. Informally speaking,\nit consists in deciding if a multiset of colors occurs in a connected subgraph\nof a vertex-colored graph. Due to the high rate of noise in the biological\ndata, more flexible definitions of the problem have been outlined. We present\nin this paper two inapproximability results for two different optimization\nvariants of Graph Motif: one where the size of the solution is maximized, the\nother when the number of substitutions of colors to obtain the motif from the\nsolution is minimized. We also study a decision version of Graph Motif where\nthe connectivity constraint is replaced by the well known notion of graph\nmodularity. While the problem remains NP-complete, it allows algorithms in FPT\nfor biologically relevant parameterizations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 14:11:29 GMT"}, {"version": "v2", "created": "Wed, 10 Sep 2014 08:15:07 GMT"}], "update_date": "2014-09-11", "authors_parsed": [["Rizzi", "Romeo", ""], ["Sikora", "Florian", ""]]}, {"id": "1202.5258", "submitter": "Anindya De", "authors": "Anindya De and Elchanan Mossel", "title": "Explicit Optimal Hardness via Gaussian stability results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The results of Raghavendra (2008) show that assuming Khot's Unique Games\nConjecture (2002), for every constraint satisfaction problem there exists a\ngeneric semi-definite program that achieves the optimal approximation factor.\nThis result is existential as it does not provide an explicit optimal rounding\nprocedure nor does it allow to calculate exactly the Unique Games hardness of\nthe problem.\n  Obtaining an explicit optimal approximation scheme and the corresponding\napproximation factor is a difficult challenge for each specific approximation\nproblem. An approach for determining the exact approximation factor and the\ncorresponding optimal rounding was established in the analysis of MAX-CUT (KKMO\n2004) and the use of the Invariance Principle (MOO 2005). However, this\napproach crucially relies on results explicitly proving optimal partitions in\nGaussian space. Until recently, Borell's result (Borell 1985) was the only\nnon-trivial Gaussian partition result known.\n  In this paper we derive the first explicit optimal approximation algorithm\nand the corresponding approximation factor using a new result on Gaussian\npartitions due to Isaksson and Mossel (2012). This Gaussian result allows us to\ndetermine exactly the Unique Games Hardness of MAX-3-EQUAL. In particular, our\nresults show that Zwick algorithm for this problem achieves the optimal\napproximation factor and prove that the approximation achieved by the algorithm\nis $\\approx 0.796$ as conjectured by Zwick.\n  We further use the previously known optimal Gaussian partitions results to\nobtain a new Unique Games Hardness factor for MAX-k-CSP : Using the well known\nfact that jointly normal pairwise independent random variables are fully\nindependent, we show that the the UGC hardness of Max-k-CSP is $\\frac{\\lceil\n(k+1)/2 \\rceil}{2^{k-1}}$, improving on results of Austrin and Mossel (2009).\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 18:28:22 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2012 19:00:42 GMT"}, {"version": "v3", "created": "Tue, 24 Jul 2012 15:53:05 GMT"}, {"version": "v4", "created": "Sat, 5 Jan 2013 17:01:55 GMT"}, {"version": "v5", "created": "Sat, 27 Jul 2013 23:08:56 GMT"}, {"version": "v6", "created": "Thu, 8 Aug 2013 23:07:31 GMT"}], "update_date": "2013-08-12", "authors_parsed": [["De", "Anindya", ""], ["Mossel", "Elchanan", ""]]}, {"id": "1202.5749", "submitter": "Marcin Pilipczuk", "authors": "Stefan Kratsch and Marcin Pilipczuk and Micha{\\l} Pilipczuk and Magnus\n  Wahlstr\\\"om", "title": "Fixed-parameter tractability of multicut in directed acyclic graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MULTICUT problem, given a graph G, a set of terminal pairs T={(s_i,t_i) |\n1 <= i <= r} and an integer p, asks whether one can find a cutset consisting of\nat most p non-terminal vertices that separates all the terminal pairs, i.e.,\nafter removing the cutset, t_i is not reachable from s_i for each 1 <= i <= r.\nThe fixed-parameter tractability of MULTICUT in undirected graphs,\nparameterized by the size of the cutset only, has been recently proven by Marx\nand Razgon (STOC'11) and, independently, by Bousquet et al. (STOC'11), after\nresisting attacks as a long-standing open problem. In this paper we prove that\nMULTICUT is fixed-parameter tractable on directed acyclic graphs, when\nparameterized both by the size of the cutset and the number of terminal pairs.\nWe complement this result by showing that this is implausible for\nparameterization by the size of the cutset only, as this version of the problem\nremains W[1]-hard.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2012 12:16:44 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Kratsch", "Stefan", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""], ["Wahlstr\u00f6m", "Magnus", ""]]}, {"id": "1202.5762", "submitter": "Kyle Burke", "authors": "Gabriel Beaulieu, Kyle Burke, Eric Duch\\^ene", "title": "Impartial coloring games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coloring games are combinatorial games where the players alternate painting\nuncolored vertices of a graph one of $k > 0$ colors. Each different ruleset\nspecifies that game's coloring constraints. This paper investigates six\nimpartial rulesets (five new), derived from previously-studied graph coloring\nschemes, including proper map coloring, oriented coloring, 2-distance coloring,\nweak coloring, and sequential coloring. For each, we study the outcome classes\nfor special cases and general computational complexity. In some cases we pay\nspecial attention to the Grundy function.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2012 14:46:28 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Beaulieu", "Gabriel", ""], ["Burke", "Kyle", ""], ["Duch\u00eane", "Eric", ""]]}, {"id": "1202.5797", "submitter": "Rishi Saket", "authors": "Inge Li Goertz, Viswanath Nagarajan and Rishi Saket", "title": "Stochastic Vehicle Routing with Recourse", "comments": "20 Pages, 1 figure Revision corrects the statement and proof of\n  Theorem 1.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the classic Vehicle Routing Problem in the setting of stochastic\noptimization with recourse. StochVRP is a two-stage optimization problem, where\ndemand is satisfied using two routes: fixed and recourse. The fixed route is\ncomputed using only a demand distribution. Then after observing the demand\ninstantiations, a recourse route is computed -- but costs here become more\nexpensive by a factor lambda.\n  We present an O(log^2 n log(n lambda))-approximation algorithm for this\nstochastic routing problem, under arbitrary distributions. The main idea in\nthis result is relating StochVRP to a special case of submodular orienteering,\ncalled knapsack rank-function orienteering. We also give a better approximation\nratio for knapsack rank-function orienteering than what follows from prior\nwork. Finally, we provide a Unique Games Conjecture based omega(1) hardness of\napproximation for StochVRP, even on star-like metrics on which our algorithm\nachieves a logarithmic approximation.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2012 22:38:06 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2012 20:43:00 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Goertz", "Inge Li", ""], ["Nagarajan", "Viswanath", ""], ["Saket", "Rishi", ""]]}, {"id": "1202.6038", "submitter": "Marjan Baghaie", "authors": "Marjan Baghaie, Dorit S. Hochbaum, Bhaskar Krishnamachari", "title": "Multiflow Transmission in Delay Constrained Cooperative Wireless\n  Networks", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of energy-efficient transmission in\nmulti-flow multihop cooperative wireless networks. Although the performance\ngains of cooperative approaches are well known, the combinatorial nature of\nthese schemes makes it difficult to design efficient polynomial-time algorithms\nfor joint routing, scheduling and power control. This becomes more so when\nthere is more than one flow in the network. It has been conjectured by many\nauthors, in the literature, that the multiflow problem in cooperative networks\nis an NP-hard problem. In this paper, we formulate the problem, as a\ncombinatorial optimization problem, for a general setting of $k$-flows, and\nformally prove that the problem is not only NP-hard but it is\n$o(n^{1/7-\\epsilon})$ inapproxmiable. To our knowledge*, these results provide\nthe first such inapproxmiablity proof in the context of multiflow cooperative\nwireless networks. We further prove that for a special case of k = 1 the\nsolution is a simple path, and devise a polynomial time algorithm for jointly\noptimizing routing, scheduling and power control. We then use this algorithm to\nestablish analytical upper and lower bounds for the optimal performance for the\ngeneral case of $k$ flows. Furthermore, we propose a polynomial time heuristic\nfor calculating the solution for the general case and evaluate the performance\nof this heuristic under different channel conditions and against the analytical\nupper and lower bounds.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 19:45:16 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Baghaie", "Marjan", ""], ["Hochbaum", "Dorit S.", ""], ["Krishnamachari", "Bhaskar", ""]]}, {"id": "1202.6043", "submitter": "Marcello Mamino", "authors": "Marcello Mamino", "title": "On the computational complexity of a game of cops and robbers", "comments": "15 pages, 2 figures. Final accepted version, to be published in\n  Theoretical Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of a perfect-information two-player\ngame proposed by Aigner and Fromme. The game takes place on an undirected graph\nwhere n simultaneously moving cops attempt to capture a single robber, all\nmoving at the same speed. The players are allowed to pick their starting\npositions at the first move. The question of the computational complexity of\ndeciding this game was raised in the '90s by Goldstein and Reingold. We prove\nthat the game is hard for PSPACE.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 20:22:56 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2012 16:58:22 GMT"}], "update_date": "2012-12-19", "authors_parsed": [["Mamino", "Marcello", ""]]}, {"id": "1202.6071", "submitter": "Yuan Zhou", "authors": "Venkatesan Guruswami, Ali Kemal Sinop, Yuan Zhou", "title": "Constant Factor Lasserre Integrality Gaps for Graph Partitioning\n  Problems", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partitioning the vertices of a graph into two roughly equal parts while\nminimizing the number of edges crossing the cut is a fundamental problem\n(called Balanced Separator) that arises in many settings. For this problem, and\nvariants such as the Uniform Sparsest Cut problem where the goal is to minimize\nthe fraction of pairs on opposite sides of the cut that are connected by an\nedge, there are large gaps between the known approximation algorithms and\nnon-approximability results. While no constant factor approximation algorithms\nare known, even APX-hardness is not known either.\n  In this work we prove that for balanced separator and uniform sparsest cut,\nsemidefinite programs from the Lasserre hierarchy (which are the most powerful\nrelaxations studied in the literature) have an integrality gap bounded away\nfrom $1$, even for $\\Omega(n)$ levels of the hierarchy. This complements recent\nalgorithmic results in Guruswami and Sinop (2011) which used the Lasserre\nhierarchy to give an approximation scheme for these problems (with runtime\ndepending on the spectrum of the graph). Along the way, we make an observation\nthat simplifies the task of lifting \"polynomial constraints\" (such as the\nglobal balance constraint in balanced separator) to higher levels of the\nLasserre hierarchy.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 21:14:14 GMT"}, {"version": "v2", "created": "Wed, 29 Feb 2012 03:00:20 GMT"}, {"version": "v3", "created": "Mon, 11 Aug 2014 17:13:26 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Sinop", "Ali Kemal", ""], ["Zhou", "Yuan", ""]]}, {"id": "1202.6086", "submitter": "Venkatesan Guruswami", "authors": "Venkatesan Guruswami and Srivatsan Narayanan", "title": "Combinatorial limitations of average-radius list-decoding", "comments": "28 pages. Extended abstract in RANDOM 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study certain combinatorial aspects of list-decoding, motivated by the\nexponential gap between the known upper bound (of $O(1/\\gamma)$) and lower\nbound (of $\\Omega_p(\\log (1/\\gamma))$) for the list-size needed to decode up to\nradius $p$ with rate $\\gamma$ away from capacity, i.e., $1-\\h(p)-\\gamma$ (here\n$p\\in (0,1/2)$ and $\\gamma > 0$). Our main result is the following:\n  We prove that in any binary code $C \\subseteq \\{0,1\\}^n$ of rate\n$1-\\h(p)-\\gamma$, there must exist a set $\\mathcal{L} \\subset C$ of\n$\\Omega_p(1/\\sqrt{\\gamma})$ codewords such that the average distance of the\npoints in $\\mathcal{L}$ from their centroid is at most $pn$. In other words,\nthere must exist $\\Omega_p(1/\\sqrt{\\gamma})$ codewords with low \"average\nradius.\" The standard notion of list-decoding corresponds to working with the\nmaximum distance of a collection of codewords from a center instead of average\ndistance. The average-radius form is in itself quite natural and is implied by\nthe classical Johnson bound.\n  The remaining results concern the standard notion of list-decoding, and help\nclarify the combinatorial landscape of list-decoding:\n  1. We give a short simple proof, over all fixed alphabets, of the\nabove-mentioned $\\Omega_p(\\log (\\gamma))$ lower bound. Earlier, this bound\nfollowed from a complicated, more general result of Blinovsky.\n  2. We show that one {\\em cannot} improve the $\\Omega_p(\\log (1/\\gamma))$\nlower bound via techniques based on identifying the zero-rate regime for list\ndecoding of constant-weight codes.\n  3. We show a \"reverse connection\" showing that constant-weight codes for list\ndecoding imply general codes for list decoding with higher rate.\n  4. We give simple second moment based proofs of tight (up to constant\nfactors) lower bounds on the list-size needed for list decoding random codes\nand random linear codes from errors as well as erasures.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 22:28:23 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2013 19:15:05 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Narayanan", "Srivatsan", ""]]}, {"id": "1202.6395", "submitter": "Stephen A. Fenner", "authors": "Stephen A. Fenner", "title": "Functions that preserve p-randomness", "comments": "24 pages, 2 figures. An extended abstract of this paper appeared in\n  Proceedings of the 18th International Symposium on Fundamentals of\n  Computation Theory (FCT), volume 6914 of Lecture Notes in Computer Science,\n  Springer-Verlag, pages 336-347, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that polynomial-time randomness (p-randomness) is preserved under a\nvariety of familiar operations, including addition and multiplication by a\nnonzero polynomial-time computable real number. These results follow from a\ngeneral theorem: If $I$ is an open interval in the reals, $f$ is a function\nmapping $I$ into the reals, and $r$ in $I$ is p-random, then $f(r)$ is p-random\nprovided\n  1. $f$ is p-computable on the dyadic rational points in $I$, and\n  2. $f$ varies sufficiently at $r$, i.e., there exists a real constant $C > 0$\nsuch that either (a) $(f(x) - f(r))/(x-r) > C$ for all $x$ in $I$ with $x \\ne\nr$, or (b) $(f(x) - f(r))(x-r) < -C$ for all $x$ in $I$ with $x \\ne r$.\n  Our theorem implies in particular that any analytic function about a\np-computable point whose power series has uniformly p-computable coefficients\npreserves p-randomness in its open interval of absolute convergence. Such\nfunctions include all the familiar functions from first-year calculus.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 22:03:38 GMT"}], "update_date": "2012-03-01", "authors_parsed": [["Fenner", "Stephen A.", ""]]}, {"id": "1202.6444", "submitter": "Marcos Villagra", "authors": "Marcos Villagra, Masaki Nakanishi, Shigeru Yamashita, Yasuhiko\n  Nakashima", "title": "Tensor Rank and Strong Quantum Nondeterminism in Multiparty\n  Communication", "comments": "In v3 corrected some lesser typos. Extended abstract in Proc. of\n  TAMC'12, LNCS 7287, pp. 400-411, 2012", "journal-ref": "IEICE Transactions on Information and Systems Vol. E96.D (2013)\n  No. 1 pp. 1-8", "doi": "10.1587/transinf.E96.D.1", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study quantum nondeterminism in multiparty communication.\nThere are three (possibly) different types of nondeterminism in quantum\ncomputation: i) strong, ii) weak with classical proofs, and iii) weak with\nquantum proofs. Here we focus on the first one. A strong quantum\nnondeterministic protocol accepts a correct input with positive probability,\nand rejects an incorrect input with probability 1. In this work we relate\nstrong quantum nondeterministic multiparty communication complexity to the rank\nof the communication tensor in the Number-On-Forehead and Number-In-Hand\nmodels. In particular, by extending the definition proposed by de Wolf to {\\it\nnondeterministic tensor-rank} ($nrank$), we show that for any boolean function\n$f$ when there is no prior shared entanglement between the players, 1) in the\nNumber-On-Forehead model, the cost is upper-bounded by the logarithm of\n$nrank(f)$; 2) in the Number-In-Hand model, the cost is lower-bounded by the\nlogarithm of $nrank(f)$. Furthermore, we show that when the number of players\nis $o(\\log\\log n)$ we have that $NQP\\nsubseteq BQP$ for Number-On-Forehead\ncommunication.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 05:18:13 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2012 08:11:31 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2012 01:34:34 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Villagra", "Marcos", ""], ["Nakanishi", "Masaki", ""], ["Yamashita", "Shigeru", ""], ["Nakashima", "Yasuhiko", ""]]}, {"id": "1202.6530", "submitter": "Li Yang", "authors": "Min Liang, Li Yang", "title": "On Quantum Turing Machine Halting Deterministically", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a subclass of quantum Turing machine (QTM) named SR-QTM, which\nhalts deterministically and has deterministic tape head position. A quantum\nstate transition diagram (QSTD) is proposed to describe SR-QTM. With the help\nof QSTD, we construct a SR-QTM which is universal for all near-trivial\ntransformations. This means there exists a QTM which is universal for the above\nsubclass. Finally we prove that SR-QTM is computational equivalent with\nordinary QTM in the bounded error setting. It can be seen that, because SR-QTM\nhas the same time steps for different branches of computation, the halting\nscheme problem will not exist when considering SR-QTM as a model of quantum\ncomputing.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 12:28:20 GMT"}], "update_date": "2012-03-01", "authors_parsed": [["Liang", "Min", ""], ["Yang", "Li", ""]]}, {"id": "1202.6581", "submitter": "Giovanni Viglietta", "authors": "Giovanni Viglietta", "title": "Lemmings is PSPACE-complete", "comments": "26 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lemmings is a computer puzzle game developed by DMA Design and published by\nPsygnosis in 1991, in which the player has to guide a tribe of lemming\ncreatures to safety through a hazardous landscape, by assigning them specific\nskills that modify their behavior in different ways. In this paper we study the\noptimization problem of saving the highest number of lemmings in a given\nlandscape with a given number of available skills.\n  We prove that the game is PSPACE-complete, even if there is only one lemming\nto save, and only Builder and Basher skills are available. We thereby settle an\nopen problem posed by Cormode in 2004, and again by Forisek in 2010. However we\nalso prove that, if we restrict the game to levels in which the available\nBuilder skills are only polynomially many (and there is any number of other\nskills), then the game is solvable in NP. Similarly, if the available Basher,\nMiner, and Digger skills are polynomially many, the game is solvable in NP.\n  Furthermore, we show that saving the maximum number of lemmings is APX-hard,\neven when only one type of skill is available, whatever this skill is. This\ncontrasts with the membership in P of the decision problem restricted to levels\nwith no \"deadly areas\" (such as water or traps) and only Climber and Floater\nskills, as previously established by Cormode.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 15:55:22 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2014 03:44:36 GMT"}, {"version": "v3", "created": "Sun, 19 Jan 2014 21:10:31 GMT"}, {"version": "v4", "created": "Sun, 29 Jun 2014 17:35:08 GMT"}, {"version": "v5", "created": "Wed, 1 Oct 2014 02:35:29 GMT"}, {"version": "v6", "created": "Sat, 31 Jan 2015 06:21:18 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Viglietta", "Giovanni", ""]]}, {"id": "1202.6641", "submitter": "Lane A. Hemaspaandra", "authors": "Edith Hemaspaandra, Lane A. Hemaspaandra and Curtis Menton", "title": "Search versus Decision for Election Manipulation Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "URCS-TR-2012-971", "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most theoretical definitions about the complexity of manipulating elections\nfocus on the decision problem of recognizing which instances can be\nsuccessfully manipulated, rather than the search problem of finding the\nsuccessful manipulative actions. Since the latter is a far more natural goal\nfor manipulators, that definitional focus may be misguided if these two\ncomplexities can differ. Our main result is that they probably do differ: If\ninteger factoring is hard, then for election manipulation, election bribery,\nand some types of election control, there are election systems for which\nrecognizing which instances can be successfully manipulated is in polynomial\ntime but producing the successful manipulations cannot be done in polynomial\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 18:48:08 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2012 22:58:00 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Hemaspaandra", "Lane A.", ""], ["Menton", "Curtis", ""]]}, {"id": "1202.6649", "submitter": "Joerg Rothe", "authors": "Edith Hemaspaandra, Lane A. Hemaspaandra, and Joerg Rothe", "title": "The Complexity of Controlling Candidate-Sequential Elections", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Candidate control of elections is the study of how adding or removing\ncandidates can affect the outcome. However, the traditional study of the\ncomplexity of candidate control is in the model in which all candidates and\nvotes are known up front. This paper develops a model for studying online\ncontrol for elections where the structure is sequential with respect to the\ncandidates, and in which the decision regarding adding and deleting must be\nirrevocably made at the moment the candidate is presented. We show that great\ncomplexity---PSPACE-completeness---can occur in this setting, but we also\nprovide within this setting polynomial-time algorithms for the most important\nof election systems, plurality.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 19:14:11 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 23:42:47 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Hemaspaandra", "Lane A.", ""], ["Rothe", "Joerg", ""]]}, {"id": "1202.6655", "submitter": "Joerg Rothe", "authors": "Edith Hemaspaandra, Lane A. Hemaspaandra, and Joerg Rothe", "title": "The Complexity of Online Manipulation of Sequential Elections", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": "URCS-TR-2012-974", "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work on manipulation assumes that all preferences are known to the\nmanipulators. However, in many settings elections are open and sequential, and\nmanipulators may know the already cast votes but may not know the future votes.\nWe introduce a framework, in which manipulators can see the past votes but not\nthe future ones, to model online coalitional manipulation of sequential\nelections, and we show that in this setting manipulation can be extremely\ncomplex even for election systems with simple winner problems. Yet we also show\nthat for some of the most important election systems such manipulation is\nsimple in certain settings. This suggests that when using sequential voting,\none should pay great attention to the details of the setting in choosing one's\nvoting rule. Among the highlights of our classifications are: We show that,\ndepending on the size of the manipulative coalition, the online manipulation\nproblem can be complete for each level of the polynomial hierarchy or even for\nPSPACE. We obtain the most dramatic contrast to date between the\nnonunique-winner and unique-winner models: Online weighted manipulation for\nplurality is in P in the nonunique-winner model, yet is coNP-hard (constructive\ncase) and NP-hard (destructive case) in the unique-winner model. And we obtain\nwhat to the best of our knowledge are the first P^NP[1]-completeness and\nP^NP-completeness results in the field of computational social choice, in\nparticular proving such completeness for, respectively, the complexity of\n3-candidate and 4-candidate (and unlimited-candidate) online weighted coalition\nmanipulation of veto elections.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 19:24:53 GMT"}, {"version": "v2", "created": "Sat, 12 May 2012 08:41:45 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2012 06:34:35 GMT"}, {"version": "v4", "created": "Fri, 28 Sep 2012 05:04:19 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Hemaspaandra", "Lane A.", ""], ["Rothe", "Joerg", ""]]}, {"id": "1202.6668", "submitter": "Bruno Bauwens", "authors": "Bruno Bauwens, Alexander Shen", "title": "Complexity of complexity and strings with maximal plain and prefix\n  Kolmogorov complexity", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Peter Gacs showed (Gacs 1974) that for every n there exists a bit string x of\nlength n whose plain complexity C(x) has almost maximal conditional complexity\nrelative to x, i.e., C(C(x)|x) > log n - log^(2) n - O(1). (Here log^(2) i =\nlog log i.) Following Elena Kalinina (Kalinina 2011), we provide a simple\ngame-based proof of this result; modifying her argument, we get a better (and\ntight) bound log n - O(1). We also show the same bound for prefix-free\ncomplexity.\n  Robert Solovay showed (Solovay 1975) that infinitely many strings x have\nmaximal plain complexity but not maximal prefix complexity (among the strings\nof the same length): for some c there exist infinitely many x such that |x| -\nC(x) < c and |x| + K(|x|) - K(x) > log^(2) |x| - c log^(3) |x|. In fact, the\nresults of Solovay and Gacs are closely related. Using the result above, we\nprovide a short proof for Solovay's result. We also generalize it by showing\nthat for some c and for all n there are strings x of length n with n - C (x) <\nc and n + K(n) - K(x) > K(K(n)|n) - 3 K(K(K(n)|n)|n) - c. We also prove a close\nupper bound K(K(n)|n) + O(1).\n  Finally, we provide a direct game proof for Joseph Miller's generalization\n(Miller 2006) of the same Solovay's theorem: if a co-enumerable set (a set with\nc.e. complement) contains for every length a string of this length, then it\ncontains infinitely many strings x such that |x| + K(|x|) - K(x) > log^(2) |x|\n+ O(log^(3) |x|).\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 20:09:17 GMT"}, {"version": "v2", "created": "Fri, 3 May 2013 15:54:59 GMT"}], "update_date": "2013-05-06", "authors_parsed": [["Bauwens", "Bruno", ""], ["Shen", "Alexander", ""]]}, {"id": "1202.6680", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Ragesh Jaiswal and Rocco A. Servedio and\n  Li-Yang Tan and Andrew Wan", "title": "On the Distribution of the Fourier Spectrum of Halfspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bourgain showed that any noise stable Boolean function $f$ can be\nwell-approximated by a junta. In this note we give an exponential sharpening of\nthe parameters of Bourgain's result under the additional assumption that $f$ is\na halfspace.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 20:50:51 GMT"}], "update_date": "2012-03-01", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Jaiswal", "Ragesh", ""], ["Servedio", "Rocco A.", ""], ["Tan", "Li-Yang", ""], ["Wan", "Andrew", ""]]}]