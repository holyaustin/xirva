[{"id": "1106.0108", "submitter": "Shenghui Su", "authors": "Shenghui Su, Shuwang Lv, and Xiubin Fan", "title": "Asymptotic Granularity Reduction and Its Application", "comments": "13 pages", "journal-ref": "Theoretical Computer Science, vol. 412, issue 39, Sep. 2011, pp.\n  5374-5386", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the inverse function of y = x with the derivative y' =\n1 is x = y, the inverse function of y = c with the derivative y' = 0 is\ninexistent, and so on. Hence, on the assumption that the noninvertibility of\nthe univariate increasing function y = f(x) with x > 0 is in direct proportion\nto the growth rate reflected by its derivative, the authors put forward a\nmethod of comparing difficulties in inverting two functions on a continuous or\ndiscrete interval called asymptotic granularity reduction (AGR) which\nintegrates asymptotic analysis with logarithmic granularities, and is an\nextension and a complement to polynomial time (Turing) reduction (PTR). Prove\nby AGR that inverting y = x ^ x (mod p) is computationally harder than\ninverting y = g ^ x (mod p), and inverting y = g ^ (x ^ n) (mod p) is\ncomputationally equivalent to inverting y = g ^ x (mod p), which are compatible\nwith the results from PTR. Besides, apply AGR to the comparison of inverting y\n= x ^ n (mod p) with y = g ^ x (mod p), y = g ^ (g1 ^ x) (mod p) with y = g ^ x\n(mod p), and y = x ^ n + x + 1 (mod p) with y = x ^ n (mod p) in difficulty,\nand observe that the results are consistent with existing facts, which further\nillustrates that AGR is suitable for comparison of inversion problems in\ndifficulty. Last, prove by AGR that inverting y = (x ^ n)(g ^ x) (mod p) is\ncomputationally equivalent to inverting y = g ^ x (mod p) when PTR can not be\nutilized expediently. AGR with the assumption partitions the complexities of\nproblems more detailedly, and finds out some new evidence for the security of\ncryptosystems.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 07:29:19 GMT"}, {"version": "v2", "created": "Sun, 11 Dec 2011 08:23:55 GMT"}, {"version": "v3", "created": "Tue, 23 Sep 2014 02:55:34 GMT"}, {"version": "v4", "created": "Sat, 1 Nov 2014 14:38:06 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Su", "Shenghui", ""], ["Lv", "Shuwang", ""], ["Fan", "Xiubin", ""]]}, {"id": "1106.0485", "submitter": "Gil Kalai", "authors": "Gil Kalai", "title": "How Quantum Computers Fail: Quantum Codes, Correlations in Physical\n  Systems, and Noise Accumulation", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The feasibility of computationally superior quantum computers is one of the\nmost exciting and clear-cut scientific questions of our time. The question\ntouches on fundamental issues regarding probability, physics, and\ncomputability, as well as on exciting problems in experimental physics,\nengineering, computer science, and mathematics. We propose three related\ndirections towards a negative answer. The first is a conjecture about physical\nrealizations of quantum codes, the second has to do with correlations in\nstochastic physical systems, and the third proposes a model for quantum\nevolutions when noise accumulates. The paper is dedicated to the memory of\nItamar Pitowsky.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2011 19:16:04 GMT"}], "update_date": "2011-06-03", "authors_parsed": [["Kalai", "Gil", ""]]}, {"id": "1106.0518", "submitter": "Homin Lee", "authors": "Mahdi Cheraghchi, Adam Klivans, Pravesh Kothari, Homin K. Lee", "title": "Submodular Functions Are Noise Stable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that all non-negative submodular functions have high {\\em\nnoise-stability}. As a consequence, we obtain a polynomial-time learning\nalgorithm for this class with respect to any product distribution on\n$\\{-1,1\\}^n$ (for any constant accuracy parameter $\\epsilon$). Our algorithm\nalso succeeds in the agnostic setting. Previous work on learning submodular\nfunctions required either query access or strong assumptions about the types of\nsubmodular functions to be learned (and did not hold in the agnostic setting).\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2011 21:30:50 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2011 14:32:55 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Cheraghchi", "Mahdi", ""], ["Klivans", "Adam", ""], ["Kothari", "Pravesh", ""], ["Lee", "Homin K.", ""]]}, {"id": "1106.0566", "submitter": "Tianshi Chen", "authors": "Tianshi Chen, Yunji Chen, Ke Tang, Guoliang Chen, and Xin Yao", "title": "The Impact of Mutation Rate on the Computation Time of Evolutionary\n  Dynamic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutation has traditionally been regarded as an important operator in\nevolutionary algorithms. In particular, there have been many experimental\nstudies which showed the effectiveness of adapting mutation rates for various\nstatic optimization problems. Given the perceived effectiveness of adaptive and\nself-adaptive mutation for static optimization problems, there have been\nspeculations that adaptive and self-adaptive mutation can benefit dynamic\noptimization problems even more since adaptation and self-adaptation are\ncapable of following a dynamic environment. However, few theoretical results\nare available in analyzing rigorously evolutionary algorithms for dynamic\noptimization problems. It is unclear when adaptive and self-adaptive mutation\nrates are likely to be useful for evolutionary algorithms in solving dynamic\noptimization problems. This paper provides the first rigorous analysis of\nadaptive mutation and its impact on the computation times of evolutionary\nalgorithms in solving certain dynamic optimization problems. More specifically,\nfor both individual-based and population-based EAs, we have shown that any\ntime-variable mutation rate scheme will not significantly outperform a fixed\nmutation rate on some dynamic optimization problem instances. The proofs also\noffer some insights into conditions under which any time-variable mutation\nscheme is unlikely to be useful and into the relationships between the problem\ncharacteristics and algorithmic features (e.g., different mutation schemes).\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 05:31:34 GMT"}], "update_date": "2011-06-06", "authors_parsed": [["Chen", "Tianshi", ""], ["Chen", "Yunji", ""], ["Tang", "Ke", ""], ["Chen", "Guoliang", ""], ["Yao", "Xin", ""]]}, {"id": "1106.0572", "submitter": "Joseph Bebel", "authors": "Joseph Bebel, Henry Yuen", "title": "BQP_p = PP for integer p > 2", "comments": "This paper has been withdrawn by the authors due to the fact that\n  strong error reduction for BQP_p problems is significantly more subtle than\n  demonstrated, which compromises the main result", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There's something really strange about quantum mechanics. It's not just that\ncats can be dead and alive at the same time, and that entanglement seems to\nviolate the principle of locality; quantum mechanics seems to be what Aaronson\ncalls \"an island in theoryspace\", because even slight perturbations to the\ntheory of quantum mechanics seem to generate absurdities. In [Aar 04] and [Aar\n05], he explores these perturbations and the corresponding absurdities in the\ncontext of computation. In particular, he shows that a quantum theory where the\nmeasurement probabilities are computed using p-norm instead of the standard\n2-norm has the effect of blowing up the class BQP (the class of problems that\ncan be efficiently solved on a quantum computer) to at least PP (the class of\nproblems that can be solved in probabilistic polynomial time). He showed that\nPP \\subseteq BQP_p \\subseteq PSPACE for all constants p != 2, and that BQP_p =\nPP for even integers p > 2. Here, we show that this equality holds for all\nintegers p > 2.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 06:59:26 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2011 07:36:27 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Bebel", "Joseph", ""], ["Yuen", "Henry", ""]]}, {"id": "1106.0683", "submitter": "Matthew Groff S.", "authors": "Matt Groff", "title": "Towards P = NP via k-SAT: A k-SAT Algorithm Using Linear Algebra on\n  Finite Fields", "comments": "28 pages, 25 figures, 1 picture", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of P vs. NP is very serious, and solutions to the problem can\nhelp save lives. This article is an attempt at solving the problem using a\ncomputer algorithm. It is presented in a fashion that will hopefully allow for\neasy understanding for many people and scientists from many diverse fields.\n  In technical terms, a novel method for solving k-SAT is explained. This\nmethod is primarily based on linear algebra and finite fields. Evidence is\ngiven that this method may require rougly O(n^3) time and space for\ndeterministic models. More specifically the algorithm runs in time O(P\nV(n+V)^2) with mistaking satisfiable Boolean expressions as unsatisfiable with\nan approximate probablity 1 / \\Theta(V(n+V)^2)^P, where n is the number of\nclauses and V is the number of variables. It's concluded that significant\nevidence exists that P=NP.\n  There is a forum devoted to this paper at http://482527.ForumRomanum.com. All\nare invited to correspond here and help with the analysis of the algorithm.\nSource code for the associated algorithm can be found at\nhttps://sourceforge.net/p/la3sat.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 15:04:59 GMT"}, {"version": "v2", "created": "Sat, 1 Oct 2011 19:52:20 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Groff", "Matt", ""]]}, {"id": "1106.0851", "submitter": "Wajeb Gharibi", "authors": "Wajeb Gharibi, Yong Xia", "title": "A Dual Approach for Solving Nonlinear Infinite-Norm Minimization\n  Problems with Applications in Separable Cases", "comments": "10 pages", "journal-ref": "Numer. Math. J. Chinese Univ. (English Ser.), Issue 3, Vol. 16,\n  pp. 265-270, 2007", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on nonlinear infinite-norm minimization problems that\nhave many applications, especially in computer science and operations research.\nWe set a reliable Lagrangian dual aproach for solving this kind of problems in\ngeneral, and based on this method, we propose an algorithm for the mixed linear\nand nonlinear infinite-norm minimization cases with numerical results.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2011 19:17:30 GMT"}], "update_date": "2011-06-07", "authors_parsed": [["Gharibi", "Wajeb", ""], ["Xia", "Yong", ""]]}, {"id": "1106.1049", "submitter": "Gregory Gutin", "authors": "Gregory Gutin and Anders Yeo", "title": "Hypercontractive Inequality for Pseudo-Boolean Functions of Bounded\n  Fourier Width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A function $f:\\ \\{-1,1\\}^n\\rightarrow \\mathbb{R}$ is called pseudo-Boolean.\nIt is well-known that each pseudo-Boolean function $f$ can be written as\n$f(x)=\\sum_{I\\in {\\cal F}}\\hat{f}(I)\\chi_I(x),$ where ${\\cal F}\\subseteq \\{I:\\\nI\\subseteq [n]\\}$, $[n]=\\{1,2,...,n\\}$, and $\\chi_I(x)=\\prod_{i\\in I}x_i$ and\n$\\hat{f}(I)$ are non-zero reals. The degree of $f$ is $\\max \\{|I|:\\ I\\in {\\cal\nF}\\}$ and the width of $f$ is the minimum integer $\\rho$ such that every $i\\in\n[n]$ appears in at most $\\rho$ sets in $\\cal F$. For $i\\in [n]$, let\n$\\mathbf{x}_i$ be a random variable taking values 1 or -1 uniformly and\nindependently from all other variables $\\mathbf{x}_j$, $j\\neq i.$ Let\n$\\mathbf{x}=(\\mathbf{x}_1,...,\\mathbf{x}_n)$. The $p$-norm of $f$ is\n$||f||_p=(\\mathbb E[|f(\\mathbf{x})|^p])^{1/p}$ for any $p\\ge 1$. It is\nwell-known that $||f||_q\\ge ||f||_p$ whenever $q> p\\ge 1$. However, the higher\nnorm can be bounded by the lower norm times a coefficient not directly\ndepending on $f$: if $f$ is of degree $d$ and $q> p>1$ then $ ||f||_q\\le\n(\\frac{q-1}{p-1})^{d/2}||f||_p.$ This inequality is called the Hypercontractive\nInequality. We show that one can replace $d$ by $\\rho$ in the Hypercontractive\nInequality for each $q> p\\ge 2$ as follows: $ ||f||_q\\le\n((2r)!\\rho^{r-1})^{1/(2r)}||f||_p,$ where $r=\\lceil q/2\\rceil$. For the case\n$q=4$ and $p=2$, which is important in many applications, we prove a stronger\ninequality: $ ||f||_4\\le (2\\rho+1)^{1/4}||f||_2.$\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 12:47:37 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2011 14:34:27 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2012 13:07:33 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Gutin", "Gregory", ""], ["Yeo", "Anders", ""]]}, {"id": "1106.1150", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra, Kyle Murray and Xiaoqing Tang", "title": "Barbosa, Uniform Polynomial Time Bounds, and Promises", "comments": null, "journal-ref": null, "doi": null, "report-no": "URCS TR-2011-969", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is a commentary on, and critique of, Andre Luiz Barbosa's paper\nentitled \"P != NP Proof.\" Despite its provocative title, what the paper is\nseeking to do is not to prove P \\neq NP in the standard sense in which that\nnotation is used in the literature. Rather, Barbosa is (and is aware that he\nis) arguing that a different meaning should be associated with the notation P\n\\neq NP, and he claims to prove the truth of the statement P \\neq NP in his\nquite different sense of that statement. However, we note that (1) the paper\nfails even on its own terms, as due to a uniformity problem, the paper's proof\ndoes not establish, even in its unusual sense of the notation, that P \\neq NP;\nand (2) what the paper means by the claim P \\neq NP in fact implies that P \\neq\nNP holds even under the standard meaning that that notation has in the\nliterature (and so it is exceedingly unlikely that Barbosa's proof can be fixed\nany time soon).\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 18:59:06 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Hemaspaandra", "Lane A.", ""], ["Murray", "Kyle", ""], ["Tang", "Xiaoqing", ""]]}, {"id": "1106.1236", "submitter": "EPTCS", "authors": "Sten Gr\\\"uner, Frank G. Radmacher, Wolfgang Thomas (RWTH Aachen\n  University)", "title": "Connectivity Games over Dynamic Networks", "comments": "In Proceedings GandALF 2011, arXiv:1106.0814", "journal-ref": "EPTCS 54, 2011, pp. 131-145", "doi": "10.4204/EPTCS.54.10", "report-no": null, "categories": "cs.GT cs.CC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A game-theoretic model for the study of dynamic networks is analyzed. The\nmodel is motivated by communication networks that are subject to failure of\nnodes and where the restoration needs resources. The corresponding two-player\ngame is played between \"Destructor\" (who can delete nodes) and \"Constructor\"\n(who can restore or even create nodes under certain conditions). We also\ninclude the feature of information flow by allowing Constructor to change\nlabels of adjacent nodes. As objective for Constructor the network property to\nbe connected is considered, either as a safety condition or as a reachability\ncondition (in the latter case starting from a non-connected network). We show\nunder which conditions the solvability of the corresponding games for\nConstructor is decidable, and in this case obtain upper and lower complexity\nbounds, as well as algorithms derived from winning strategies. Due to the\nasymmetry between the players, safety and reachability objectives are not dual\nto each other and are treated separately.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2011 01:06:40 GMT"}], "update_date": "2011-06-08", "authors_parsed": [["Gr\u00fcner", "Sten", "", "RWTH Aachen\n  University"], ["Radmacher", "Frank G.", "", "RWTH Aachen\n  University"], ["Thomas", "Wolfgang", "", "RWTH Aachen\n  University"]]}, {"id": "1106.1241", "submitter": "EPTCS", "authors": "Davide Bresolin (University of Verona), Angelo Montanari (University\n  of Udine), Pietro Sala (University of Verona), Guido Sciavicco (University of\n  Murcia)", "title": "An Optimal Decision Procedure for MPNL over the Integers", "comments": "In Proceedings GandALF 2011, arXiv:1106.0814", "journal-ref": "EPTCS 54, 2011, pp. 192-206", "doi": "10.4204/EPTCS.54.14", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interval temporal logics provide a natural framework for qualitative and\nquantitative temporal reason- ing over interval structures, where the truth of\nformulae is defined over intervals rather than points. In this paper, we study\nthe complexity of the satisfiability problem for Metric Propositional Neigh-\nborhood Logic (MPNL). MPNL features two modalities to access intervals \"to the\nleft\" and \"to the right\" of the current one, respectively, plus an infinite set\nof length constraints. MPNL, interpreted over the naturals, has been recently\nshown to be decidable by a doubly exponential procedure. We improve such a\nresult by proving that MPNL is actually EXPSPACE-complete (even when length\nconstraints are encoded in binary), when interpreted over finite structures,\nthe naturals, and the in- tegers, by developing an EXPSPACE decision procedure\nfor MPNL over the integers, which can be easily tailored to finite linear\norders and the naturals (EXPSPACE-hardness was already known).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2011 01:07:12 GMT"}], "update_date": "2011-06-08", "authors_parsed": [["Bresolin", "Davide", "", "University of Verona"], ["Montanari", "Angelo", "", "University\n  of Udine"], ["Sala", "Pietro", "", "University of Verona"], ["Sciavicco", "Guido", "", "University of\n  Murcia"]]}, {"id": "1106.1910", "submitter": "Vahid Majid Nezhad", "authors": "Vahid Majid Nezhad, Habib Motee Gader and Evgueni Efimov", "title": "A Novel Hybrid Algorithm for Task Graph Scheduling", "comments": null, "journal-ref": "IJCSI, Vol 8, Issue 2, March 2011, p32-38", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the important problems in multiprocessor systems is Task Graph\nScheduling. Task Graph Scheduling is an NP-Hard problem. Both learning automata\nand genetic algorithms are search tools which are used for solving many NP-Hard\nproblems. In this paper a new hybrid method based on Genetic Algorithm and\nLearning Automata is proposed. The proposed algorithm begins with an initial\npopulation of randomly generated chromosomes and after some stages, each\nchromosome maps to an automaton. Experimental results show that superiority of\nthe proposed algorithm over the current approaches.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 20:26:22 GMT"}], "update_date": "2011-06-13", "authors_parsed": [["Nezhad", "Vahid Majid", ""], ["Gader", "Habib Motee", ""], ["Efimov", "Evgueni", ""]]}, {"id": "1106.2104", "submitter": "Martyn Amos", "authors": "Robin Houston, Joseph White and Martyn Amos", "title": "Zen Puzzle Garden is NP-complete", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zen Puzzle Garden (ZPG) is a one-player puzzle game. In this paper, we prove\nthat deciding the solvability of ZPG is NP-complete.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 15:59:30 GMT"}], "update_date": "2011-06-13", "authors_parsed": [["Houston", "Robin", ""], ["White", "Joseph", ""], ["Amos", "Martyn", ""]]}, {"id": "1106.2122", "submitter": "Praveen Manjunatha", "authors": "M. Praveen and Kamal Lodaya", "title": "Parameterized complexity results for 1-safe Petri nets", "comments": "Full version of the paper appearing in CONCUR 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We associate a graph with a 1-safe Petri net and study the parameterized\ncomplexity of various problems with parameters derived from the graph. With\ntreewidth as the parameter, we give W[1]-hardness results for many problems\nabout 1-safe Petri nets. As a corollary, this proves a conjecture of Downey et.\nal. about the hardness of some graph pebbling problems. We consider the\nparameter benefit depth (that is known to be helpful in getting better\nalgorithms for general Petri nets) and again give W[1]-hardness results for\nvarious problems on 1-safe Petri nets. We also consider the stronger parameter\nvertex cover number. Combining the well known automata-theoretic method and a\npowerful fixed parameter tractability (FPT) result about Integer Linear\nProgramming, we give a FPT algorithm for model checking Monadic Second Order\n(MSO) formulas on 1-safe Petri nets, with parameters vertex cover number and\nthe size of the formula.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 17:11:53 GMT"}], "update_date": "2011-06-13", "authors_parsed": [["Praveen", "M.", ""], ["Lodaya", "Kamal", ""]]}, {"id": "1106.2378", "submitter": "Atsushi  Iwasaki", "authors": "Atsushi Iwasaki, David Kempe, Mahyar Salek, Makoto Yokoo", "title": "False-name-proof Mechanisms for Hiring a Team", "comments": "23 pages, 3 figures, This paper is an extented version of\n  \"False-name-proof Mechanisms for Hiring a Team\" in the Proceedings of the\n  Workshop on Internet and Network Economics, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of hiring a team of selfish agents to perform a task.\nEach agent is assumed to own one or more elements of a set system, and the\nauctioneer is trying to purchase a feasible solution by conducting an auction.\nOur goal is to design auctions that are truthful and false-name-proof, meaning\nthat it is in the agents' best interest to reveal ownership of all elements\n(which may not be known to the auctioneer a priori) as well as their true\nincurred costs.\n  We first propose and analyze a false-name-proof mechanism for the special\ncase where each agent owns only one element in reality, but may pretend that\nthis element is in fact a set of multiple elements. We prove that its frugality\nratio is bounded by $2^n$, which, up to constants, matches a lower bound of\n$\\Omega(2^n)$ for all false-name-proof mechanisms in this scenario. We then\npropose a second mechanism for the general case in which agents may own\nmultiple elements. It requires the auctioneer to choose a reserve cost a\npriori, and thus does not always purchase a solution. In return, it is\nfalse-name-proof even when agents own multiple elements. We experimentally\nevaluate the payment (as well as social surplus) of the second mechanism\nthrough simulation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 03:14:54 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Iwasaki", "Atsushi", ""], ["Kempe", "David", ""], ["Salek", "Mahyar", ""], ["Yokoo", "Makoto", ""]]}, {"id": "1106.2481", "submitter": "Tianrong Lin", "authors": "Tianrong Lin", "title": "Another approach to the equivalence of measure-many one-way quantum\n  finite automata and its application", "comments": "V 10: Corollary 3 is deleted, since it is folk. (V 9: Revised in\n  terms of the referees's comments) All comments, especially the linguistic\n  comments, are welcome", "journal-ref": "J. Comput. Syst. Sci. 78 (2012) 807-821; J. Comput. Syst. Sci. 81\n  (2015) 1413", "doi": "10.1016/j.jcss.2012.01.004", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper, we present a much simpler, direct and elegant approach to the\nequivalence problem of {\\it measure many one-way quantum finite automata}\n(MM-1QFAs). The approach is essentially generalized from the work of Carlyle\n[J. Math. Anal. Appl. 7 (1963) 167-175]. Namely, we reduce the equivalence\nproblem of MM-1QFAs to that of two (initial) vectors.\n  As an application of the approach, we utilize it to address the equivalence\nproblem of {\\it Enhanced one-way quantum finite automata} (E-1QFAs) introduced\nby Nayak [Proceedings of the 40th Annual IEEE Symposium on Foundations of\nComputer Science, 1999, pp.~369-376]. We prove that two E-1QFAs $\\mathcal{A}_1$\nand $\\mathcal{A}_2$ over $\\Sigma$ are equivalence if and only if they are\n$n_1^2+n_2^2-1$-equivalent where $n_1$ and $n_2$ are the numbers of states in\n$\\mathcal{A}_1$ and $\\mathcal{A}_2$, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 16:27:34 GMT"}, {"version": "v10", "created": "Fri, 6 Jan 2012 02:26:59 GMT"}, {"version": "v11", "created": "Tue, 28 Apr 2015 09:46:34 GMT"}, {"version": "v2", "created": "Sat, 18 Jun 2011 03:27:12 GMT"}, {"version": "v3", "created": "Sun, 17 Jul 2011 05:02:23 GMT"}, {"version": "v4", "created": "Tue, 19 Jul 2011 06:11:49 GMT"}, {"version": "v5", "created": "Thu, 21 Jul 2011 07:45:14 GMT"}, {"version": "v6", "created": "Mon, 15 Aug 2011 10:21:47 GMT"}, {"version": "v7", "created": "Fri, 23 Sep 2011 08:34:00 GMT"}, {"version": "v8", "created": "Wed, 2 Nov 2011 00:31:01 GMT"}, {"version": "v9", "created": "Mon, 21 Nov 2011 09:46:42 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Lin", "Tianrong", ""]]}, {"id": "1106.2619", "submitter": "Chandan K. Dubey", "authors": "Chandan Dubey, Thomas Holenstein", "title": "Approximating the Closest Vector Problem Using an Approximate Shortest\n  Vector Oracle", "comments": "10 pages, Published in APPROX 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a polynomial time Turing reduction from the\n$\\gamma^2\\sqrt{n}$-approximate closest vector problem on a lattice of dimension\n$n$ to a $\\gamma$-approximate oracle for the shortest vector problem. This is\nan improvement over a reduction by Kannan, which achieved $\\gamma^2n^{3/2}$.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 06:30:29 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2011 10:14:34 GMT"}], "update_date": "2011-06-20", "authors_parsed": [["Dubey", "Chandan", ""], ["Holenstein", "Thomas", ""]]}, {"id": "1106.2844", "submitter": "Leonid Gurvits", "authors": "Leonid Gurvits", "title": "Unleashing the power of Schrijver's permanental inequality with the help\n  of the Bethe Approximation", "comments": "30 pages, more typos are fixed, more remarks are added, importantly a\n  concrete counter-example to [Lu,Mohr,Szekely] positive correlation conjecture\n  is presented", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.IT math-ph math.IT math.MP", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Let $A \\in \\Omega_n$ be doubly-stochastic $n \\times n$ matrix. Alexander\nSchrijver proved in 1998 the following remarkable inequality per(\\widetilde{A})\n\\geq \\prod_{1 \\leq i,j \\leq n} (1- A(i,j)); \\widetilde{A}(i,j) =:\nA(i,j)(1-A(i,j)), 1 \\leq i,j \\leq n.\n  We use the above Shrijver's inequality to prove the following lower bound:\n  \\frac{per(A)}{F(A)} \\geq 1; F(A) =: \\prod_{1 \\leq i,j \\leq n} (1- A(i,j))^{1-\nA(i,j)}.\n  We use this new lower bound to prove S.Friedland's Asymptotic Lower Matching\nConjecture(LAMC) on monomer-dimer problem.\n  We use some ideas of our proof of (LAMC) to disprove [Lu,Mohr,Szekely]\npositive correlation conjecture.\n  We present explicit doubly-stochastic $n \\times n$ matrices $A$ with the\nratio $\\frac{per(A)}{F(A)} = \\sqrt{2}^{n}$; conjecture that\n  \\max_{A \\in \\Omega_n}\\frac{per(A)}{F(A)} \\approx (\\sqrt{2})^{n} and give some\nexamples supporting the conjecture.\n  If true, the conjecture (and other ones stated in the paper) would imply a\ndeterministic poly-time algorithm to approximate the permanent of $n \\times n$\nnonnegative matrices within the relative factor $(\\sqrt{2})^{n}$. The best\ncurrent such factor is $e^n$.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 23:43:36 GMT"}, {"version": "v10", "created": "Thu, 24 May 2012 00:39:10 GMT"}, {"version": "v11", "created": "Wed, 20 Jun 2012 00:55:40 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2011 01:59:57 GMT"}, {"version": "v3", "created": "Thu, 8 Dec 2011 02:48:37 GMT"}, {"version": "v4", "created": "Tue, 13 Dec 2011 00:09:54 GMT"}, {"version": "v5", "created": "Tue, 20 Dec 2011 21:55:38 GMT"}, {"version": "v6", "created": "Thu, 1 Mar 2012 05:41:56 GMT"}, {"version": "v7", "created": "Fri, 2 Mar 2012 01:49:40 GMT"}, {"version": "v8", "created": "Mon, 5 Mar 2012 22:06:20 GMT"}, {"version": "v9", "created": "Thu, 15 Mar 2012 01:34:59 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Gurvits", "Leonid", ""]]}, {"id": "1106.3059", "submitter": "Nicolas Gauvrit", "authors": "Nicolas Gauvrit, Hector Zenil, Jean-Paul Delahaye, Fernando\n  Soler-Toscano", "title": "Algorithmic Complexity for Short Binary Strings Applied to Psychology: A\n  Primer", "comments": "To appear in Behavior Research Methods", "journal-ref": null, "doi": "10.3758/s13428-013-0416-0", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since human randomness production has been studied and widely used to assess\nexecutive functions (especially inhibition), many measures have been suggested\nto assess the degree to which a sequence is random-like. However, each of them\nfocuses on one feature of randomness, leading authors to have to use multiple\nmeasures. Here we describe and advocate for the use of the accepted universal\nmeasure for randomness based on algorithmic complexity, by means of a novel\npreviously presented technique using the the definition of algorithmic\nprobability. A re-analysis of the classical Radio Zenith data in the light of\nthe proposed measure and methodology is provided as a study case of an\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2011 19:25:10 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2013 05:59:38 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2013 08:24:04 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Gauvrit", "Nicolas", ""], ["Zenil", "Hector", ""], ["Delahaye", "Jean-Paul", ""], ["Soler-Toscano", "Fernando", ""]]}, {"id": "1106.3161", "submitter": "Dimitrios Thilikos", "authors": "Rodney G. Downey and Dimitrios M. Thilikos", "title": "Confronting Intractability via Parameters", "comments": "Accepted for publication in Computer Science Review [with some\n  additional corrections]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One approach to confronting computational hardness is to try to understand\nthe contribution of various parameters to the running time of algorithms and\nthe complexity of computational tasks. Almost no computational tasks in real\nlife are specified by their size alone. It is not hard to imagine that some\nparameters contribute more intractability than others and it seems reasonable\nto develop a theory of computational complexity which seeks to exploit this\nfact. Such a theory should be able to address the needs of practicioners in\nalgorithmics. The last twenty years have seen the development of such a theory.\nThis theory has a large number of successes in terms of a rich collection of\nalgorithmic techniques both practical and theoretical, and a fine-grained\nintractability theory. Whilst the theory has been widely used in a number of\nareas of applications including computational biology, linguistics, VLSI\ndesign, learning theory and many others, knowledge of the area is highly\nvaried. We hope that this article will show both the basic theory and point at\nthe wide array of techniques available. Naturally the treatment is condensed,\nand the reader who wants more should go to the texts, Downey and Fellows, Flum\nand Grohe, Niedermeier, and the upcoming undergraduate text Downey and Fellows.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2011 07:19:22 GMT"}, {"version": "v2", "created": "Sun, 19 Jun 2011 18:41:59 GMT"}, {"version": "v3", "created": "Mon, 27 Jun 2011 22:59:00 GMT"}, {"version": "v4", "created": "Mon, 12 Sep 2011 15:44:01 GMT"}, {"version": "v5", "created": "Wed, 14 Sep 2011 02:33:50 GMT"}, {"version": "v6", "created": "Tue, 22 Nov 2011 16:39:27 GMT"}], "update_date": "2011-11-23", "authors_parsed": [["Downey", "Rodney G.", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "1106.3498", "submitter": "Olivier Bailleux", "authors": "Olivier Bailleux", "title": "On the expressive power of unit resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This preliminary report addresses the expressive power of unit resolution\nregarding input data encoded with partial truth assignments of propositional\nvariables. A characterization of the functions that are computable in this way,\nwhich we propose to call propagatable functions, is given. By establishing that\npropagatable functions can also be computed using monotone circuits, we show\nthat there exist polynomial time complexity propagable functions requiring an\nexponential amount of clauses to be computed using unit resolution. These\nresults shed new light on studying CNF encodings of NP-complete problems in\norder to solve them using propositional satisfiability algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 14:35:28 GMT"}], "update_date": "2011-06-20", "authors_parsed": [["Bailleux", "Olivier", ""]]}, {"id": "1106.3595", "submitter": "Anup Rao", "authors": "Mark Braverman and Anup Rao", "title": "Information Equals Amortized Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to efficiently simulate the sending of a message M to a receiver\nwho has partial information about the message, so that the expected number of\nbits communicated in the simulation is close to the amount of additional\ninformation that the message reveals to the receiver. This is a generalization\nand strengthening of the Slepian-Wolf theorem, which shows how to carry out\nsuch a simulation with low amortized communication in the case that M is a\ndeterministic function of X. A caveat is that our simulation is interactive.\n  As a consequence, we prove that the internal information cost (namely the\ninformation revealed to the parties) involved in computing any relation or\nfunction using a two party interactive protocol is exactly equal to the\namortized communication complexity of computing independent copies of the same\nrelation or function. We also show that the only way to prove a strong direct\nsum theorem for randomized communication complexity is by solving a particular\nvariant of the pointer jumping problem that we define. Our work implies that a\nstrong direct sum theorem for communication complexity holds if and only if\nefficient compression of communication protocols is possible.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 23:49:11 GMT"}], "update_date": "2011-06-21", "authors_parsed": [["Braverman", "Mark", ""], ["Rao", "Anup", ""]]}, {"id": "1106.3625", "submitter": "Sergey Yekhanin", "authors": "Parikshit Gopalan and Cheng Huang and Huseyin Simitci and Sergey\n  Yekhanin", "title": "On the Locality of Codeword Symbols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a linear [n,k,d]_q code C. We say that that i-th coordinate of C has\nlocality r, if the value at this coordinate can be recovered from accessing\nsome other r coordinates of C. Data storage applications require codes with\nsmall redundancy, low locality for information coordinates, large distance, and\nlow locality for parity coordinates. In this paper we carry out an in-depth\nstudy of the relations between these parameters.\n  We establish a tight bound for the redundancy n-k in terms of the message\nlength, the distance, and the locality of information coordinates. We refer to\ncodes attaining the bound as optimal. We prove some structure theorems about\noptimal codes, which are particularly strong for small distances. This gives a\nfairly complete picture of the tradeoffs between codewords length, worst-case\ndistance and locality of information symbols.\n  We then consider the locality of parity check symbols and erasure correction\nbeyond worst case distance for optimal codes. Using our structure theorem, we\nobtain a tight bound for the locality of parity symbols possible in such codes\nfor a broad class of parameter settings. We prove that there is a tradeoff\nbetween having good locality for parity checks and the ability to correct\nerasures beyond the minimum distance.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2011 08:07:12 GMT"}], "update_date": "2011-06-21", "authors_parsed": [["Gopalan", "Parikshit", ""], ["Huang", "Cheng", ""], ["Simitci", "Huseyin", ""], ["Yekhanin", "Sergey", ""]]}, {"id": "1106.3951", "submitter": "Venkatesan Guruswami", "authors": "Venkatesan Guruswami, Carol Wang", "title": "Optimal rate list decoding via derivative codes", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical family of $[n,k]_q$ Reed-Solomon codes over a field $\\F_q$\nconsist of the evaluations of polynomials $f \\in \\F_q[X]$ of degree $< k$ at\n$n$ distinct field elements. In this work, we consider a closely related family\nof codes, called (order $m$) {\\em derivative codes} and defined over fields of\nlarge characteristic, which consist of the evaluations of $f$ as well as its\nfirst $m-1$ formal derivatives at $n$ distinct field elements. For large enough\n$m$, we show that these codes can be list-decoded in polynomial time from an\nerror fraction approaching $1-R$, where $R=k/(nm)$ is the rate of the code.\nThis gives an alternate construction to folded Reed-Solomon codes for achieving\nthe optimal trade-off between rate and list error-correction radius. Our\ndecoding algorithm is linear-algebraic, and involves solving a linear system to\ninterpolate a multivariate polynomial, and then solving another structured\nlinear system to retrieve the list of candidate polynomials $f$. The algorithm\nfor derivative codes offers some advantages compared to a similar one for\nfolded Reed-Solomon codes in terms of efficient unique decoding in the presence\nof side information.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2011 15:51:22 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Wang", "Carol", ""]]}, {"id": "1106.4141", "submitter": "Stefan Kratsch", "authors": "Hans L. Bodlaender and Bart M. P. Jansen and Stefan Kratsch", "title": "Kernel Bounds for Path and Cycle Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectivity problems like k-Path and k-Disjoint Paths relate to many\nimportant milestones in parameterized complexity, namely the Graph Minors\nProject, color coding, and the recent development of techniques for obtaining\nkernelization lower bounds. This work explores the existence of polynomial\nkernels for various path and cycle problems, by considering nonstandard\nparameterizations. We show polynomial kernels when the parameters are a given\nvertex cover, a modulator to a cluster graph, or a (promised) max leaf number.\nWe obtain lower bounds via cross-composition, e.g., for Hamiltonian Cycle and\nrelated problems when parameterized by a modulator to an outerplanar graph.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 09:14:42 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2011 10:51:54 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Jansen", "Bart M. P.", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1106.4142", "submitter": "Dai Tri Man Le", "authors": "Stephen A. Cook, Dai Tri Man Le, Yuli Ye", "title": "Complexity Classes and Theories for the Comparator Circuit Value Problem", "comments": "This version was substantially rewritten, where several proofs were\n  rewritten and many typos and mistakes were fixed. A shorter version of this\n  paper appeared in CSL 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subramanian defined the complexity class CC as the set of problems log-space\nreducible to the comparator circuit value problem. He proved that several other\nproblems are complete for CC, including the stable marriage problem, and\nfinding the lexicographical first maximal matching in a bipartite graph. We\nsuggest alternative definitions of CC based on different reducibilities and\nintroduce a two-sorted theory VCC* based on one of them. We sharpen and\nsimplify Subramanian's completeness proofs for the above two problems and\nformalize them in VCC*.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 09:15:01 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2011 23:51:45 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Cook", "Stephen A.", ""], ["Le", "Dai Tri Man", ""], ["Ye", "Yuli", ""]]}, {"id": "1106.4454", "submitter": "Gregory Gutin", "authors": "Robert Crowston, Gregory Gutin, Mark Jones and Anders Yeo", "title": "Parameterized Eulerian Strong Component Arc Deletion Problem on\n  Tournaments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem {\\sc Min-DESC}, we are given a digraph $D$ and an integer $k$,\nand asked if there exists a set $A'$ of at most $k$ arcs in $D$, such that if\nwe remove the arcs of $A'$, in the resulting digraph every strong component is\nEulerian. {\\sc Min-DESC} is NP-hard; Cechl\\'{a}rov\\'{a} and Schlotter (IPEC\n2010) asked if the problem is fixed-parameter tractable when parameterized by\n$k$. We consider the subproblem of{\\sc Min-DESC} when $D$ is a tournament. We\nshow that this problem is fixed-parameter tractable with respect to $k$.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 14:13:10 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2011 10:02:19 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Crowston", "Robert", ""], ["Gutin", "Gregory", ""], ["Jones", "Mark", ""], ["Yeo", "Anders", ""]]}, {"id": "1106.4606", "submitter": "Prabhu Manyem", "authors": "Prabhu Manyem", "title": "Expressibility at the machine level versus structure level: ESO\n  universal Horn Logic and the class P", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that ESO universal Horn logic (existential second logic where the\nfirst order part is a universal Horn formula) is insufficient to capture P, the\nclass of problems decidable in polynomial time. This statement is true in the\npresence of a successor relation in the input vocabulary. We provide two proofs\n--- one based on reduced products of two structures, and another based on\napproximability theory (the second proof is under the assumption that P is not\nthe same as NP). We show that the difference between the results here and those\nin Gr\\\"{a}del (1991), is due to the fact that the expressions this paper deals\nwith are at the \"structure level\", whereas the expressions in Gr\\\"{a}del (1991)\nare at the \"machine level\" --- a case of Easier done than said.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2011 01:55:56 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2011 12:53:31 GMT"}, {"version": "v3", "created": "Fri, 18 Nov 2011 10:13:10 GMT"}, {"version": "v4", "created": "Mon, 9 Jan 2012 04:55:50 GMT"}, {"version": "v5", "created": "Mon, 23 Jul 2012 07:55:27 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Manyem", "Prabhu", ""]]}, {"id": "1106.4719", "submitter": "Marc Thurley", "authors": "Lukas Moll, Siamak Tazari, Marc Thurley", "title": "Computing hypergraph width measures exactly", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypergraph width measures are a class of hypergraph invariants important in\nstudying the complexity of constraint satisfaction problems (CSPs). We present\na general exact exponential algorithm for a large variety of these measures. A\nconnection between these and tree decompositions is established. This enables\nus to almost seamlessly adapt the combinatorial and algorithmic results known\nfor tree decompositions of graphs to the case of hypergraphs and obtain fast\nexact algorithms.\n  As a consequence, we provide algorithms which, given a hypergraph H on n\nvertices and m hyperedges, compute the generalized hypertree-width of H in time\nO*(2^n) and compute the fractional hypertree-width of H in time\nO(m*1.734601^n).\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2011 13:51:33 GMT"}], "update_date": "2011-06-24", "authors_parsed": [["Moll", "Lukas", ""], ["Tazari", "Siamak", ""], ["Thurley", "Marc", ""]]}, {"id": "1106.5223", "submitter": "Lin Tianrong", "authors": "Tianrong Lin", "title": "Some results on equivalence of multi-letter quantum finite automata", "comments": "This paper has been withdrawn by the author due to a more general\n  result having been obtained in arXiv:1203.0113", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Two quantum finite automata are equivalent if for all input string $\\omega$\nover the input alphabet the two automata accept $\\omega$ with equal\nprobability. In [Theoret. Comput. Sci. 410 (2009) 3006-3017], it was shown that\na $k_1$-letter QFA $\\mathcal{A}_1$ and a $k_2$-letter QFA $\\mathcal{A}_2$ over\n$\\Sigma=\\{\\sigma\\}$, are equivalent if and only if they are\n$(n_1+n_2)^4+k-1$-equivalent where $n_i$ is the number of states of\n$\\mathcal{A}_i$, $i=1,2$, and $k=\\max\\{k_1,k_2\\}$. In this letter, we improve\nthe above upper-bound to $(n_1^2+n_2^2-1)+k$. This also answers an open problem\nof Qiu et al. [Acta Informatica 48 (2011) 271-290]. Further, we show that, in\nthe case of $\\Sigma=\\{\\sigma_1,...,\\sigma_t\\}$ with $2\\leq t<\\infty$, there\nexists an integer $z$ such that $\\mathcal{A}_1$ and $\\mathcal{A}_2$ are\nequivalent if and only if they satisfy $z$-equivalent.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2011 13:53:02 GMT"}, {"version": "v2", "created": "Mon, 4 Jul 2011 03:31:38 GMT"}, {"version": "v3", "created": "Wed, 24 Aug 2011 02:11:57 GMT"}, {"version": "v4", "created": "Mon, 31 Oct 2011 05:56:35 GMT"}, {"version": "v5", "created": "Wed, 14 Dec 2011 01:49:46 GMT"}, {"version": "v6", "created": "Fri, 6 Jan 2012 00:17:46 GMT"}, {"version": "v7", "created": "Fri, 5 Jul 2013 17:52:23 GMT"}], "update_date": "2013-07-08", "authors_parsed": [["Lin", "Tianrong", ""]]}, {"id": "1106.5448", "submitter": "Lirong Xia", "authors": "Vincent Conitzer and Toby Walsh and Lirong Xia", "title": "Dominating Manipulations in Voting with Partial Information", "comments": "7 pages by arxiv pdflatex, 1 figure. The 6-page version has the same\n  content and will be published in Proceedings of the Twenty-Fifth AAAI\n  Conference on Artificial Intelligence (AAAI-11)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider manipulation problems when the manipulator only has partial\ninformation about the votes of the nonmanipulators. Such partial information is\ndescribed by an information set, which is the set of profiles of the\nnonmanipulators that are indistinguishable to the manipulator. Given such an\ninformation set, a dominating manipulation is a non-truthful vote that the\nmanipulator can cast which makes the winner at least as preferable (and\nsometimes more preferable) as the winner when the manipulator votes truthfully.\nWhen the manipulator has full information, computing whether or not there\nexists a dominating manipulation is in P for many common voting rules (by known\nresults). We show that when the manipulator has no information, there is no\ndominating manipulation for many common voting rules. When the manipulator's\ninformation is represented by partial orders and only a small portion of the\npreferences are unknown, computing a dominating manipulation is NP-hard for\nmany common voting rules. Our results thus throw light on whether we can\nprevent strategic behavior by limiting information about the votes of other\nvoters.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 17:10:55 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Conitzer", "Vincent", ""], ["Walsh", "Toby", ""], ["Xia", "Lirong", ""]]}, {"id": "1106.5601", "submitter": "Jun-Yi Chai", "authors": "Junyi Chai, James N.K. Liu", "title": "Class-based Rough Approximation with Dominance Principle", "comments": "Submitted to IEEE-GrC2011", "journal-ref": null, "doi": "10.1109/GRC.2011.6122571", "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dominance-based Rough Set Approach (DRSA), as the extension of Pawlak's Rough\nSet theory, is effective and fundamentally important in Multiple Criteria\nDecision Analysis (MCDA). In previous DRSA models, the definitions of the upper\nand lower approximations are preserving the class unions rather than the\nsingleton class. In this paper, we propose a new Class-based Rough\nApproximation with respect to a series of previous DRSA models, including\nClassical DRSA model, VC-DRSA model and VP-DRSA model. In addition, the new\nclass-based reducts are investigated.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2011 09:12:31 GMT"}, {"version": "v2", "created": "Tue, 5 Jul 2011 02:50:26 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Chai", "Junyi", ""], ["Liu", "James N. K.", ""]]}, {"id": "1106.5736", "submitter": "Erik Demaine", "authors": "Erik D. Demaine, Martin L. Demaine, Sarah Eisenstat, Anna Lubiw,\n  Andrew Winslow", "title": "Algorithms for Solving Rubik's Cubes", "comments": "34 pages, 9 figures. A short version of this paper is to appear at\n  the 19th Annual European Symposium on Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rubik's Cube is perhaps the world's most famous and iconic puzzle,\nwell-known to have a rich underlying mathematical structure (group theory). In\nthis paper, we show that the Rubik's Cube also has a rich underlying\nalgorithmic structure. Specifically, we show that the n x n x n Rubik's Cube,\nas well as the n x n x 1 variant, has a \"God's Number\" (diameter of the\nconfiguration space) of Theta(n^2/log n). The upper bound comes from\neffectively parallelizing standard Theta(n^2) solution algorithms, while the\nlower bound follows from a counting argument. The upper bound gives an\nasymptotically optimal algorithm for solving a general Rubik's Cube in the\nworst case. Given a specific starting state, we show how to find the shortest\nsolution in an n x O(1) x O(1) Rubik's Cube. Finally, we show that finding this\noptimal solution becomes NP-hard in an n x n x 1 Rubik's Cube when the\npositions and colors of some of the cubies are ignored (not used in determining\nwhether the cube is solved).\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2011 17:35:09 GMT"}], "update_date": "2011-06-29", "authors_parsed": [["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Eisenstat", "Sarah", ""], ["Lubiw", "Anna", ""], ["Winslow", "Andrew", ""]]}]