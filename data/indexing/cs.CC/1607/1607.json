[{"id": "1607.00242", "submitter": "Mikhail Raskin", "authors": "M. Raskin", "title": "A linear lower bound for incrementing a space-optimal integer\n  representation in the bit-probe model", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first linear lower bound for the number of bits required to be\naccessed in the worst case to increment an integer in an arbitrary space-\noptimal binary representation. The best previously known lower bound was\nlogarithmic. It is known that a logarithmic number of read bits in the worst\ncase is enough to increment some of the integer representations that use one\nbit of redundancy, therefore we show an exponential gap between space-optimal\nand redundant counters.\n  Our proof is based on considering the increment procedure for a space optimal\ncounter as a permutation and calculating its parity. For every space optimal\ncounter, the permutation must be odd, and implementing an odd permutation\nrequires reading at least half the bits in the worst case. The combination of\nthese two observations explains why the worst-case space-optimal problem is\nsubstantially different from both average-case approach with constant expected\nnumber of reads and almost space optimal representations with logarithmic\nnumber of reads in the worst case.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 13:39:44 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 08:05:27 GMT"}, {"version": "v3", "created": "Wed, 15 Feb 2017 16:51:20 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Raskin", "M.", ""]]}, {"id": "1607.00259", "submitter": "Nathanael Fijalkow", "authors": "Nathana\\\"el Fijalkow", "title": "Lower Bounds for Alternating Online State Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of Online State Complexity, introduced by Karp in 1967, quantifies\nthe amount of states required to solve a given problem using an online\nalgorithm, which is represented by a deterministic machine scanning the input\nfrom left to right in one pass. In this paper, we extend the setting to\nalternating machines as introduced by Chandra, Kozen and Stockmeyer in 1976:\nsuch machines run independent passes scanning the input from left to right and\ngather their answers through boolean combinations. We devise a lower bound\ntechnique relying on boundedly generated lattices of languages, and give two\napplications of this technique. The first is a hierarchy theorem , stating that\nthe polynomial hierarchy of alternating online state complexity is infinite,\nand the second is a linear lower bound on the alternating online state\ncomplexity of the prime numbers written in binary. This second result\nstrengthens a result of Hartmanis and Shank from 1968, which implies an\nexponentially worse lower bound for the same model.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 14:30:00 GMT"}, {"version": "v2", "created": "Wed, 9 Nov 2016 09:33:31 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", ""]]}, {"id": "1607.00443", "submitter": "Iddo Tzameret", "authors": "Tonnian Pitassi, Iddo Tzameret", "title": "Algebraic Proof Complexity: Progress, Frontiers and Challenges", "comments": "Complexity Column of the ACM SIGLOG News, ACM New York, NY, USA, July\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey recent progress in the proof complexity of strong proof systems and\nits connection to algebraic circuit complexity, showing how the synergy between\nthe two gives rise to new approaches to fundamental open questions, solutions\nto old problems, and new directions of research. In particular, we focus on\ntight connections between proof complexity lower bounds (namely, lower bounds\non the size of proofs of certain tautologies), algebraic circuit lower bounds,\nand the Polynomial Identity Testing problem from derandomization theory.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jul 2016 01:01:12 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Pitassi", "Tonnian", ""], ["Tzameret", "Iddo", ""]]}, {"id": "1607.00574", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae", "title": "Quantum state and circuit distinguishability with single-qubit\n  measurements", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Quantum State Distinguishability (QSD), which is a\nQSZK-complete problem, and the Quantum Circuit Distinguishability (QCD), which\nis a QIP-complete problem, can be solved by the verifier who can perform only\nsingle-qubit measurements. To show these results, we use measurement-based\nquantum computing: the honest prover sends a graph state to the verifier, and\nthe verifier can perform universal quantum computing on it with only\nsingle-qubit measurements. If the prover is malicious, he does not necessarily\ngenerate the correct graph state, but the verifier can verify the correctness\nof the graph state by measuring the stabilizer operators.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jul 2016 01:18:09 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Morimae", "Tomoyuki", ""]]}, {"id": "1607.00932", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam (CWI) and Ronald de Wolf (CWI and U of\n  Amsterdam)", "title": "Optimal Quantum Sample Complexity of Learning Algorithms", "comments": "31 pages LaTeX. Arxiv abstract shortened to fit in their\n  1920-character limit. Version 3: many small changes, no change in results", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $ \\newcommand{\\eps}{\\varepsilon} $In learning theory, the VC dimension of a\nconcept class $C$ is the most common way to measure its \"richness.\" In the PAC\nmodel $$ \\Theta\\Big(\\frac{d}{\\eps} + \\frac{\\log(1/\\delta)}{\\eps}\\Big) $$\nexamples are necessary and sufficient for a learner to output, with probability\n$1-\\delta$, a hypothesis $h$ that is $\\eps$-close to the target concept $c$. In\nthe related agnostic model, where the samples need not come from a $c\\in C$, we\nknow that $$ \\Theta\\Big(\\frac{d}{\\eps^2} + \\frac{\\log(1/\\delta)}{\\eps^2}\\Big)\n$$ examples are necessary and sufficient to output an hypothesis $h\\in C$ whose\nerror is at most $\\eps$ worse than the best concept in $C$.\n  Here we analyze quantum sample complexity, where each example is a coherent\nquantum state. This model was introduced by Bshouty and Jackson, who showed\nthat quantum examples are more powerful than classical examples in some\nfixed-distribution settings. However, Atici and Servedio, improved by Zhang,\nshowed that in the PAC setting, quantum examples cannot be much more powerful:\nthe required number of quantum examples is $$\n\\Omega\\Big(\\frac{d^{1-\\eta}}{\\eps} + d + \\frac{\\log(1/\\delta)}{\\eps}\\Big)\\mbox{\nfor all }\\eta> 0. $$ Our main result is that quantum and classical sample\ncomplexity are in fact equal up to constant factors in both the PAC and\nagnostic models. We give two approaches. The first is a fairly simple\ninformation-theoretic argument that yields the above two classical bounds and\nyields the same bounds for quantum sample complexity up to a $\\log(d/\\eps)$\nfactor. We then give a second approach that avoids the log-factor loss, based\non analyzing the behavior of the \"Pretty Good Measurement\" on the quantum state\nidentification problems that correspond to learning. This shows classical and\nquantum sample complexity are equal up to constant factors.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2016 15:31:32 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 16:57:38 GMT"}, {"version": "v3", "created": "Tue, 6 Jun 2017 21:14:58 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Arunachalam", "Srinivasan", "", "CWI"], ["de Wolf", "Ronald", "", "CWI and U of\n  Amsterdam"]]}, {"id": "1607.00945", "submitter": "Fernando S\\'anchez Villaamil", "authors": "Li-Hsuan Chen, Felix Reidl, Peter Rossmanith, Fernando S\\'anchez\n  Villaamil", "title": "Width, depth and space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The width measure treedepth, also known as vertex ranking, centered coloring\nand elimination tree height, is a well-established notion which has recently\nseen a resurgence of interest. Since graphs of bounded treedepth are more\nrestricted than graphs of bounded tree- or pathwidth, we are interested in the\nalgorithmic utility of this additional structure.\n  On the negative side, we show that every dynamic programming algorithm on\ntreedepth decompositions of depth~$t$ cannot solve Dominating Set with\n$O((3-\\epsilon)^t \\cdot \\log n)$ space for any $\\epsilon > 0$. This result\nimplies the same space lower bound for dynamic programming algorithms on tree\nand path decompositions. We supplement this result by showing a space lower\nbound of $O((3-\\epsilon)^t \\cdot \\log n)$ for 3-Coloring and $O((2-\\epsilon)^t\n\\cdot \\log n)$ for Vertex Cover. This formalizes the common intuition that\ndynamic programming algorithms on graph decompositions necessarily consume a\nlot of space and complements known results of the time-complexity of problems\nrestricted to low-treewidth classes.\n  We then show that treedepth lends itself to the design of branching\nalgorithms. This class of algorithms has in general distinct advantages over\ndynamic programming algorithms: a) They use less space than algorithms based on\ndynamic programming, b) they are easy to parallelize and c) they provide\npossible solutions before terminating.\n  Specifically, we design for Dominating Set a pure branching algorithm that\nruns in time $t^{O(t^2)}\\cdot n$ and uses space $O(t^3 \\log t + t \\log n)$ and\na hybrid of branching and dynamic programming that achieves a running time of\n$O(3^t \\log t \\cdot n)$ while using $O(2^t t \\log t + t \\log n)$ space.\nAlgorithms for 3-Coloring and Vertex Cover with space complexity $O(t \\cdot\n\\log n)$ and time complexity $O(3^t \\cdot n)$ and $O(2^t\\cdot n)$,\nrespectively, are included for completeness.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2016 16:06:41 GMT"}, {"version": "v2", "created": "Sat, 6 Aug 2016 14:04:33 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Chen", "Li-Hsuan", ""], ["Reidl", "Felix", ""], ["Rossmanith", "Peter", ""], ["Villaamil", "Fernando S\u00e1nchez", ""]]}, {"id": "1607.01167", "submitter": "Guus Regts", "authors": "Viresh Patel, Guus Regts", "title": "Deterministic polynomial-time approximation algorithms for partition\n  functions and graph polynomials", "comments": "27 pages; some changes have been made based on referee comments. In\n  particular a tiny error in Proposition 4.4 has been fixed. The introduction\n  and concluding remarks have also been rewritten to incorporate the most\n  recent developments. Accepted for publication in SIAM Journal on Computation", "journal-ref": "SIAM J. Comput., 46(6), 1893-1919", "doi": "10.1137/16M1101003", "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show a new way of constructing deterministic polynomial-time\napproximation algorithms for computing complex-valued evaluations of a large\nclass of graph polynomials on bounded degree graphs. In particular, our\napproach works for the Tutte polynomial and independence polynomial, as well as\npartition functions of complex-valued spin and edge-coloring models.\n  More specifically, we define a large class of graph polynomials $\\mathcal C$\nand show that if $p\\in \\cal C$ and there is a disk $D$ centered at zero in the\ncomplex plane such that $p(G)$ does not vanish on $D$ for all bounded degree\ngraphs $G$, then for each $z$ in the interior of $D$ there exists a\ndeterministic polynomial-time approximation algorithm for evaluating $p(G)$ at\n$z$. This gives an explicit connection between absence of zeros of graph\npolynomials and the existence of efficient approximation algorithms, allowing\nus to show new relationships between well-known conjectures.\n  Our work builds on a recent line of work initiated by. Barvinok, which\nprovides a new algorithmic approach besides the existing Markov chain Monte\nCarlo method and the correlation decay method for these types of problems.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 09:34:32 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 17:24:22 GMT"}, {"version": "v3", "created": "Tue, 18 Jul 2017 11:20:32 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Patel", "Viresh", ""], ["Regts", "Guus", ""]]}, {"id": "1607.01438", "submitter": "Bhaskar DasGupta", "authors": "Tanima Chatterjee, Bhaskar DasGupta, Nasim Mobasheri, Venkatkumar\n  Srinivasan, Ismael G. Yero", "title": "On the Computational Complexities of Three Privacy Measures for Large\n  Networks Under Active Attack", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the arrival of modern internet era, large public networks of various\ntypes have come to existence to benefit the society as a whole and several\nresearch areas such as sociology, economics and geography in particular.\nHowever, the societal and research benefits of these networks have also given\nrise to potentially significant privacy issues in the sense that malicious\nentities may violate the privacy of the users of such a network by analyzing\nthe network and deliberately using such privacy violations for deleterious\npurposes. Such considerations have given rise to a new active research area\nthat deals with the quantification of privacy of users in large networks and\nthe corresponding investigation of computational complexity issues of computing\nsuch quantified privacy measures. In this paper, we formalize three such\nprivacy measures for large networks and provide non-trivial theoretical\ncomputational complexity results for computing these measures. Our results show\nthe first two measures can be computed efficiently, whereas the third measure\nis provably hard to compute within a logarithmic approximation factor.\nFurthermore, we also provide computational complexity results for the case when\nthe privacy requirement of the network is severely restricted, including an\nefficient logarithmic approximation.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 23:37:49 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Chatterjee", "Tanima", ""], ["DasGupta", "Bhaskar", ""], ["Mobasheri", "Nasim", ""], ["Srinivasan", "Venkatkumar", ""], ["Yero", "Ismael G.", ""]]}, {"id": "1607.01684", "submitter": "Swagato Sanyal", "authors": "Jaikumar Radhakrishnan and Swagato Sanyal", "title": "The zero-error randomized query complexity of the pointer function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pointer function of G{\\\"{o}}{\\\"{o}}s, Pitassi and Watson\n\\cite{DBLP:journals/eccc/GoosP015a} and its variants have recently been used to\nprove separation results among various measures of complexity such as\ndeterministic, randomized and quantum query complexities, exact and approximate\npolynomial degrees, etc. In particular, the widest possible (quadratic)\nseparations between deterministic and zero-error randomized query complexity,\nas well as between bounded-error and zero-error randomized query complexity,\nhave been obtained by considering {\\em\nvariants}~\\cite{DBLP:journals/corr/AmbainisBBL15} of this pointer function.\n  However, as was pointed out in \\cite{DBLP:journals/corr/AmbainisBBL15}, the\nprecise zero-error complexity of the original pointer function was not known.\nWe show a lower bound of $\\widetilde{\\Omega}(n^{3/4})$ on the zero-error\nrandomized query complexity of the pointer function on $\\Theta(n \\log n)$ bits;\nsince an $\\widetilde{O}(n^{3/4})$ upper bound is already known\n\\cite{DBLP:conf/fsttcs/MukhopadhyayS15}, our lower bound is optimal up to a\nfactor of $\\polylog\\, n$.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2016 15:49:30 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Radhakrishnan", "Jaikumar", ""], ["Sanyal", "Swagato", ""]]}, {"id": "1607.01760", "submitter": "Jess Banks", "authors": "Jess Banks, Cristopher Moore, Joe Neeman, Praneeth Netrapalli", "title": "Information-theoretic thresholds for community detection in sparse\n  networks", "comments": "This paper is a combination of arXiv:1601.02658 and arXiv:1404.6304\n  which appeared in COLT 2016", "journal-ref": "29th Annual Conference on Learning Theory (pp. 383-416) (2016)", "doi": null, "report-no": null, "categories": "math.PR cond-mat.stat-mech cs.CC cs.IT cs.SI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give upper and lower bounds on the information-theoretic threshold for\ncommunity detection in the stochastic block model. Specifically, consider the\nsymmetric stochastic block model with $q$ groups, average degree $d$, and\nconnection probabilities $c_\\text{in}/n$ and $c_\\text{out}/n$ for within-group\nand between-group edges respectively; let $\\lambda =\n(c_\\text{in}-c_\\text{out})/(qd)$. We show that, when $q$ is large, and $\\lambda\n= O(1/q)$, the critical value of $d$ at which community detection becomes\npossible---in physical terms, the condensation threshold---is \\[ d_\\text{c} =\n\\Theta\\!\\left( \\frac{\\log q}{q \\lambda^2} \\right) \\, , \\] with tighter results\nin certain regimes. Above this threshold, we show that any partition of the\nnodes into $q$ groups which is as `good' as the planted one, in terms of the\nnumber of within- and between-group edges, is correlated with it. This gives an\nexponential-time algorithm that performs better than chance; specifically,\ncommunity detection becomes possible below the Kesten-Stigum bound for $q \\ge\n5$ in the disassortative case $\\lambda < 0$, and for $q \\ge 11$ in the\nassortative case $\\lambda >0$ (similar upper bounds were obtained independently\nby Abbe and Sandon). Conversely, below this threshold, we show that no\nalgorithm can label the vertices better than chance, or even distinguish the\nblock model from an \\ER\\ random graph with high probability.\n  Our lower bound on $d_\\text{c}$ uses Robinson and Wormald's small subgraph\nconditioning method, and we also give (less explicit) results for non-symmetric\nstochastic block models. In the symmetric case, we obtain explicit results by\nusing bounds on certain functions of doubly stochastic matrices due to\nAchlioptas and Naor; indeed, our lower bound on $d_\\text{c}$ is their second\nmoment lower bound on the $q$-colorability threshold for random graphs with a\ncertain effective degree.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2016 19:42:06 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Banks", "Jess", ""], ["Moore", "Cristopher", ""], ["Neeman", "Joe", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1607.01826", "submitter": "Kyle Burke", "authors": "Kyle Burke, Erik D. Demaine, Harrison Gregg, Robert A. Hearn, Adam\n  Hesterberg, Michael Hoffmann, Hiro Ito, Irina Kostitsyna, Jody Leonard,\n  Maarten L\\\"offler, Aaron Santiago, Christiane Schmidt, Ryuhei Uehara, Yushi\n  Uno, Aaron Williams", "title": "Single-Player and Two-Player Buttons & Scissors Games", "comments": "21 pages, 15 figures. Presented at JCDCG2 2015, Kyoto University,\n  Kyoto, Japan, September 14 - 16, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of the Buttons \\& Scissors game and\nobtain sharp thresholds with respect to several parameters. Specifically we\nshow that the game is NP-complete for $C = 2$ colors but polytime solvable for\n$C = 1$. Similarly the game is NP-complete if every color is used by at most $F\n= 4$ buttons but polytime solvable for $F \\leq 3$. We also consider\nrestrictions on the board size, cut directions, and cut sizes. Finally, we\nintroduce several natural two-player versions of the game and show that they\nare PSPACE-complete.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2016 22:06:43 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Burke", "Kyle", ""], ["Demaine", "Erik D.", ""], ["Gregg", "Harrison", ""], ["Hearn", "Robert A.", ""], ["Hesterberg", "Adam", ""], ["Hoffmann", "Michael", ""], ["Ito", "Hiro", ""], ["Kostitsyna", "Irina", ""], ["Leonard", "Jody", ""], ["L\u00f6ffler", "Maarten", ""], ["Santiago", "Aaron", ""], ["Schmidt", "Christiane", ""], ["Uehara", "Ryuhei", ""], ["Uno", "Yushi", ""], ["Williams", "Aaron", ""]]}, {"id": "1607.02346", "submitter": "Giordano Da Lozzo", "authors": "Giordano Da Lozzo and Ignaz Rutter", "title": "Strengthening Hardness Results to 3-Connected Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend some classical NP-hardness results from the class of\n2-connected planar graphs to subclasses of 3-connected planar graphs. The\nreduction are partly based on a new graph augmentation, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 12:52:45 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Da Lozzo", "Giordano", ""], ["Rutter", "Ignaz", ""]]}, {"id": "1607.02986", "submitter": "Pasin Manurangsi", "authors": "Pasin Manurangsi, Prasad Raghavendra", "title": "A Birthday Repetition Theorem and Complexity of Approximating Dense CSPs", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $(k \\times l)$-birthday repetition $\\mathcal{G}^{k \\times l}$ of a\ntwo-prover game $\\mathcal{G}$ is a game in which the two provers are sent\nrandom sets of questions from $\\mathcal{G}$ of sizes $k$ and $l$ respectively.\nThese two sets are sampled independently uniformly among all sets of questions\nof those particular sizes. We prove the following birthday repetition theorem:\nwhen $\\mathcal{G}$ satisfies some mild conditions, $val(\\mathcal{G}^{k \\times\nl})$ decreases exponentially in $\\Omega(kl/n)$ where $n$ is the total number of\nquestions. Our result positively resolves an open question posted by Aaronson,\nImpagliazzo and Moshkovitz (CCC 2014).\n  As an application of our birthday repetition theorem, we obtain new\nfine-grained hardness of approximation results for dense CSPs. Specifically, we\nestablish a tight trade-off between running time and approximation ratio for\ndense CSPs by showing conditional lower bounds, integrality gaps and\napproximation algorithms. In particular, for any sufficiently large $i$ and for\nevery $k \\geq 2$, we show the following results:\n  - We exhibit an $O(q^{1/i})$-approximation algorithm for dense Max $k$-CSPs\nwith alphabet size $q$ via $O_k(i)$-level of Sherali-Adams relaxation.\n  - Through our birthday repetition theorem, we obtain an integrality gap of\n$q^{1/i}$ for $\\tilde\\Omega_k(i)$-level Lasserre relaxation for fully-dense Max\n$k$-CSP.\n  - Assuming that there is a constant $\\epsilon > 0$ such that Max 3SAT cannot\nbe approximated to within $(1-\\epsilon)$ of the optimal in sub-exponential\ntime, our birthday repetition theorem implies that any algorithm that\napproximates fully-dense Max $k$-CSP to within a $q^{1/i}$ factor takes\n$(nq)^{\\tilde \\Omega_k(i)}$ time, almost tightly matching the algorithmic\nresult based on Sherali-Adams relaxation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2016 14:54:04 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Manurangsi", "Pasin", ""], ["Raghavendra", "Prasad", ""]]}, {"id": "1607.03272", "submitter": "Nizar Ouni", "authors": "Nizar Ouni, Ridha Bouallegue", "title": "Performance and Complexity Analysis of a Reduced Iterations LLL\n  Algorithm", "comments": "arXiv admin note: text overlap with arXiv:1607.03260", "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC) Vol.8, No.3, May 2016", "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-input multiple-output (MIMO) systems are playing an increasing and\ninteresting role in the recent wireless communication. The complexity and the\nperformance of the systems are driving the different studies and researches.\nLattices Reduction techniques bring more resources to investigate the\ncomplexity and performances of such systems. In this paper, we look to modify a\nfixed complexity verity of the LLL algorithm to reduce the computation\noperations by reducing the number of iterations without important performance\ndegradation. Our proposal shows that we can achieve a good performance results\nwhile avoiding extra iteration that does not bring much performance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 09:09:29 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Ouni", "Nizar", ""], ["Bouallegue", "Ridha", ""]]}, {"id": "1607.03432", "submitter": "Marcin Wrochna", "authors": "Marthe Bonamy, {\\L}ukasz Kowalik, Micha{\\l} Pilipczuk, Arkadiusz\n  Soca{\\l}a, Marcin Wrochna", "title": "Tight lower bounds for the complexity of multicoloring", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the multicoloring problem, also known as ($a$:$b$)-coloring or $b$-fold\ncoloring, we are given a graph G and a set of $a$ colors, and the task is to\nassign a subset of $b$ colors to each vertex of G so that adjacent vertices\nreceive disjoint color subsets. This natural generalization of the classic\ncoloring problem (the $b=1$ case) is equivalent to finding a homomorphism to\nthe Kneser graph $KG_{a,b}$, and gives relaxations approaching the fractional\nchromatic number.\n  We study the complexity of determining whether a graph has an\n($a$:$b$)-coloring. Our main result is that this problem does not admit an\nalgorithm with running time $f(b)\\cdot 2^{o(\\log b)\\cdot n}$, for any\ncomputable $f(b)$, unless the Exponential Time Hypothesis (ETH) fails. A\n$(b+1)^n\\cdot \\text{poly}(n)$-time algorithm due to Nederlof [2008] shows that\nthis is tight. A direct corollary of our result is that the graph homomorphism\nproblem does not admit a $2^{O(n+h)}$ algorithm unless ETH fails, even if the\ntarget graph is required to be a Kneser graph. This refines the understanding\ngiven by the recent lower bound of Cygan et al. [SODA 2016].\n  The crucial ingredient in our hardness reduction is the usage of detecting\nmatrices of Lindstr\\\"om [Canad. Math. Bull., 1965], which is a combinatorial\ntool that, to the best of our knowledge, has not yet been used for proving\ncomplexity lower bounds. As a side result, we prove that the running time of\nthe algorithms of Abasi et al. [MFCS 2014] and of Gabizon et al. [ESA 2015] for\nthe r-monomial detection problem are optimal under ETH.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 16:38:13 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 14:03:54 GMT"}, {"version": "v3", "created": "Thu, 16 Feb 2017 19:34:13 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Bonamy", "Marthe", ""], ["Kowalik", "\u0141ukasz", ""], ["Pilipczuk", "Micha\u0142", ""], ["Soca\u0142a", "Arkadiusz", ""], ["Wrochna", "Marcin", ""]]}, {"id": "1607.03718", "submitter": "Elazar Goldenberg", "authors": "Diptarka Chakraborty, Elazar Goldenberg and Michal Kouck\\'y", "title": "Streaming Algorithms For Computing Edit Distance Without Exploiting\n  Suffix Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The edit distance is a way of quantifying how similar two strings are to one\nanother by counting the minimum number of character insertions, deletions, and\nsubstitutions required to transform one string into the other.\n  In this paper we study the computational problem of computing the edit\ndistance between a pair of strings where their distance is bounded by a\nparameter $k\\ll n$. We present two streaming algorithms for computing edit\ndistance: One runs in time $O(n+k^2)$ and the other $n+O(k^3)$. By writing\n$n+O(k^3)$ we want to emphasize that the number of operations per an input\nsymbol is a small constant. In particular, the running time does not depend on\nthe alphabet size, and the algorithm should be easy to implement.\n  Previously a streaming algorithm with running time $O(n+k^4)$ was given in\nthe paper by the current authors (STOC'16). The best off-line algorithm runs in\ntime $O(n+k^2)$ (Landau et al., 1998) which is known to be optimal under the\nStrong Exponential Time Hypothesis.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 13:16:17 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Chakraborty", "Diptarka", ""], ["Goldenberg", "Elazar", ""], ["Kouck\u00fd", "Michal", ""]]}, {"id": "1607.03810", "submitter": "Yue Liu", "authors": "Yue Liu", "title": "On the Algebraic Representation of One-Tape Deterministic Turing Machine", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algebraic representation of the Turing machines is given, where the\nconfigurations of Turing machines are represented by 4 order tensors, and the\ntransition functions by 8 order tensors. Two types of tensor product are\ndefined, one is to model the evolution of the Turing machines, and the other is\nto model the compositions of transition functions. It is shown that the two\ntypes of tensor product are harmonic in the sense that the associate law is\nobeyed.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 16:09:09 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Liu", "Yue", ""]]}, {"id": "1607.03938", "submitter": "Cl\\'ement Canonne", "authors": "Eric Blais, Cl\\'ement L. Canonne, Talya Eden, Amit Levi, Dana Ron", "title": "Tolerant Junta Testing and the Connection to Submodular Optimization and\n  Function Isomorphism", "comments": "Polished the writing, corrected typos, and fixed an issue in the\n  proof of Theorem 1.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A function $f\\colon \\{-1,1\\}^n \\to \\{-1,1\\}$ is a $k$-junta if it depends on\nat most $k$ of its variables. We consider the problem of tolerant testing of\n$k$-juntas, where the testing algorithm must accept any function that is\n$\\epsilon$-close to some $k$-junta and reject any function that is\n$\\epsilon'$-far from every $k'$-junta for some $\\epsilon'= O(\\epsilon)$ and $k'\n= O(k)$.\n  Our first result is an algorithm that solves this problem with query\ncomplexity polynomial in $k$ and $1/\\epsilon$. This result is obtained via a\nnew polynomial-time approximation algorithm for submodular function\nminimization (SFM) under large cardinality constraints, which holds even when\nonly given an approximate oracle access to the function.\n  Our second result considers the case where $k'=k$. We show how to obtain a\nsmooth tradeoff between the amount of tolerance and the query complexity in\nthis setting. Specifically, we design an algorithm that given $\\rho\\in(0,1/2)$\naccepts any function that is $\\frac{\\epsilon\\rho}{16}$-close to some $k$-junta\nand rejects any function that is $\\epsilon$-far from every $k$-junta. The query\ncomplexity of the algorithm is $O\\big( \\frac{k\\log k}{\\epsilon\\rho(1-\\rho)^k}\n\\big)$.\n  Finally, we show how to apply the second result to the problem of tolerant\nisomorphism testing between two unknown Boolean functions $f$ and $g$. We give\nan algorithm for this problem whose query complexity only depends on the\n(unknown) smallest $k$ such that either $f$ or $g$ is close to being a\n$k$-junta.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 21:31:56 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 17:16:20 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Blais", "Eric", ""], ["Canonne", "Cl\u00e9ment L.", ""], ["Eden", "Talya", ""], ["Levi", "Amit", ""], ["Ron", "Dana", ""]]}, {"id": "1607.03959", "submitter": "Serge Lawrencenko", "authors": "S. Lawrencenko, M.N. Vyalyi, L.V. Zgonnik", "title": "Gr\\\"unbaum coloring and its generalization to arbitrary dimension", "comments": "13 pages", "journal-ref": "Australasian Journal of Combinatorics. 2017. Volume 67(2). Pages\n  119-130", "doi": null, "report-no": null, "categories": "math.CO cs.CC math.GT math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a collection of thoughts and observations, being partly a\nreview and partly a report of current research, on recent work in various\naspects of Gr\\\"unbaum colorings, their existence and usage. In particular, one\nof the most striking significances of Gr\\\"unbaum's Conjecture in the\n2-dimensional case is its equivalence to the 4-Color Theorem. The notion of\nGr\\\"unbaum coloring is extended from the 2-dimensional case to the case of\narbitrary finite hyper-dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 23:36:55 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Lawrencenko", "S.", ""], ["Vyalyi", "M. N.", ""], ["Zgonnik", "L. V.", ""]]}, {"id": "1607.04220", "submitter": "William S. Moses", "authors": "William S. Moses and Erik D. Demaine", "title": "Computational Complexity of Arranging Music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proves that arrangement of music is NP-hard when subject to\nvarious constraints: avoiding musical dissonance, limiting how many notes can\nbe played simultaneously, and limiting transition speed between chords. These\nresults imply the computational complexity of related musical problems,\nincluding musical choreography and rhythm games.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 17:32:24 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Moses", "William S.", ""], ["Demaine", "Erik D.", ""]]}, {"id": "1607.04229", "submitter": "Arturs Backurs", "authors": "Arturs Backurs, Christos Tzamos", "title": "Improving Viterbi is Hard: Better Runtimes Imply Faster Clique\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic algorithm of Viterbi computes the most likely path in a Hidden\nMarkov Model (HMM) that results in a given sequence of observations. It runs in\ntime $O(Tn^2)$ given a sequence of $T$ observations from a HMM with $n$ states.\nDespite significant interest in the problem and prolonged effort by different\ncommunities, no known algorithm achieves more than a polylogarithmic speedup.\n  In this paper, we explain this difficulty by providing matching conditional\nlower bounds. We show that the Viterbi algorithm runtime is optimal up to\nsubpolynomial factors even when the number of distinct observations is small.\nOur lower bounds are based on assumptions that the best known algorithms for\nthe All-Pairs Shortest Paths problem (APSP) and for the Max-Weight $k$-Clique\nproblem in edge-weighted graphs are essentially tight.\n  Finally, using a recent algorithm by Green Larsen and Williams for online\nBoolean matrix-vector multiplication, we get a $2^{\\Omega(\\sqrt {\\log n})}$\nspeedup for the Viterbi algorithm when there are few distinct transition\nprobabilities in the HMM.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 17:58:09 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 18:19:54 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Backurs", "Arturs", ""], ["Tzamos", "Christos", ""]]}, {"id": "1607.04287", "submitter": "Martin Grohe", "authors": "Christoph Berkholz and Martin Grohe", "title": "Linear Diophantine Equations, Group CSPs, and Graph Isomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, we have seen several approaches to the graph isomorphism\nproblem based on \"generic\" mathematical programming or algebraic (Gr\\\"obner\nbasis) techniques. For most of these, lower bounds have been established. In\nfact, it has been shown that the pairs of nonisomorphic CFI-graphs (introduced\nby Cai, F\\\"urer, and Immerman in 1992 as hard examples for the combinatorial\nWeisfeiler-Leman algorithm) cannot be distinguished by these mathematical\nalgorithms. A notable exception were the algebraic algorithms over the field\nGF(2), for which no lower bound was known. Another, in some way even stronger,\napproach to graph isomorphism testing is based on solving systems of linear\nDiophantine equations (that is, linear equations over the integers), which is\nknown to be possible in polynomial time. So far, no lower bounds for this\napproach were known.\n  Lower bounds for the algebraic algorithms can best be proved in the framework\nof proof complexity, where they can be phrased as lower bounds for algebraic\nproof systems such as Nullstellensatz or the (more powerful) polynomial\ncalculus. We give new hard examples for these systems: families of pairs of\nnon-isomorphic graphs that are hard to distinguish by polynomial calculus\nproofs simultaneously over all prime fields, including GF(2), as well as\nexamples that are hard to distinguish by the\nsystems-of-linear-Diophantine-equations approach.\n  In a previous paper, we observed that the CFI-graphs are closely related to\nwhat we call \"group CSPs\": constraint satisfaction problems where the\nconstraints are membership tests in some coset of a subgroup of a cartesian\npower of a base group (Z_2 in the case of the classical CFI-graphs). Our new\nexamples are also based on group CSPs (for Abelian groups), but here we extend\nthe CSPs by a few non-group constraints to obtain even harder instances for\ngraph isomorphism.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 20:00:11 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Berkholz", "Christoph", ""], ["Grohe", "Martin", ""]]}, {"id": "1607.04322", "submitter": "Pritish Kamath", "authors": "Badih Ghazi, Pritish Kamath, Madhu Sudan", "title": "Decidability of Non-Interactive Simulation of Joint Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present decidability results for a sub-class of \"non-interactive\"\nsimulation problems, a well-studied class of problems in information theory. A\nnon-interactive simulation problem is specified by two distributions $P(x,y)$\nand $Q(u,v)$: The goal is to determine if two players, Alice and Bob, that\nobserve sequences $X^n$ and $Y^n$ respectively where $\\{(X_i, Y_i)\\}_{i=1}^n$\nare drawn i.i.d. from $P(x,y)$ can generate pairs $U$ and $V$ respectively\n(without communicating with each other) with a joint distribution that is\narbitrarily close in total variation to $Q(u,v)$. Even when $P$ and $Q$ are\nextremely simple: e.g., $P$ is uniform on the triples $\\{(0,0), (0,1), (1,0)\\}$\nand $Q$ is a \"doubly symmetric binary source\", i.e., $U$ and $V$ are uniform\n$\\pm 1$ variables with correlation say $0.49$, it is open if $P$ can simulate\n$Q$.\n  In this work, we show that whenever $P$ is a distribution on a finite domain\nand $Q$ is a $2 \\times 2$ distribution, then the non-interactive simulation\nproblem is decidable: specifically, given $\\delta > 0$ the algorithm runs in\ntime bounded by some function of $P$ and $\\delta$ and either gives a\nnon-interactive simulation protocol that is $\\delta$-close to $Q$ or asserts\nthat no protocol gets $O(\\delta)$-close to $Q$. The main challenge to such a\nresult is determining explicit (computable) convergence bounds on the number\n$n$ of samples that need to be drawn from $P(x,y)$ to get $\\delta$-close to\n$Q$. We invoke contemporary results from the analysis of Boolean functions such\nas the invariance principle and a regularity lemma to obtain such explicit\nbounds.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 21:14:06 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Ghazi", "Badih", ""], ["Kamath", "Pritish", ""], ["Sudan", "Madhu", ""]]}, {"id": "1607.04604", "submitter": "Marek Suchenek", "authors": "Marek A. Suchenek", "title": "Best-case Analysis of MergeSort with an Application to the Sum of Digits\n  Problem, A manuscript (MS) v2", "comments": "This is a longer (12 pages added) version v2 of the article deposited\n  at ArXive on July 15, 2016, under the same title. These new Sections 7, 8,\n  and 9 contain proofs of Theorems 2.2, 3.1, and 4.1. Other than that, the\n  current version v2 is identical with the original version v1. 37 pages, 14\n  figures, a draft of a manuscript intended for future journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An exact formula \\[ B(n) = \\frac{n}{2}(\\lfloor \\lg n \\rfloor + 1) - \\sum\n_{k=0} ^{\\lfloor \\lg n \\rfloor} 2^k Zigzag(\\frac{n}{2^{k+1}}), \\] where \\[\nZigzag (x) = \\min (x - \\lfloor x \\rfloor, \\lceil x \\rceil - x), \\] for the\nminimal number $ B(n) $ of comparisons of keys performed by $ {\\tt MergeSort} $\non an $ n $-element array is derived and analyzed. The said formula is less\ncomplex than any other known formula for the same and can be evaluated in $\nO(\\log ^{c}) $ time, where $ c $ is a constant. It is shown that there is no\nclosed-form formula for the above.\n  Since the recurrence relation for the minimal number of comparisons of keys\nfor $ {\\tt MergeSort} $ is identical with a recurrence relation for the number\nof 1s in binary expansions of all integers between $ 0 $ and $ n $\n(exclusively), the above results extend to the sum of binary digits problem.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2016 18:21:48 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2016 19:52:33 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Suchenek", "Marek A.", ""]]}, {"id": "1607.04787", "submitter": "Jakub Opr\\v{s}al", "authors": "V\\'ictor Dalmau, Marcin Kozik, Andrei Krokhin, Konstantin Makarychev,\n  Yury Makarychev, Jakub Opr\\v{s}al", "title": "Robust algorithms with polynomial loss for near-unanimity CSPs", "comments": "A preliminary version of this paper appeared in SODA 2017. Journal\n  referees' comments are incorporated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An instance of the Constraint Satisfaction Problem (CSP) is given by a family\nof constraints on overlapping sets of variables, and the goal is to assign\nvalues from a fixed domain to the variables so that all constraints are\nsatisfied. In the optimization version, the goal is to maximize the number of\nsatisfied constraints. An approximation algorithm for CSP is called robust if\nit outputs an assignment satisfying a $(1-g(\\varepsilon))$-fraction of\nconstraints on any $(1-\\varepsilon)$-satisfiable instance, where the loss\nfunction $g$ is such that $g(\\varepsilon)\\rightarrow 0$ as\n$\\varepsilon\\rightarrow 0$.\n  We study how the robust approximability of CSPs depends on the set of\nconstraint relations allowed in instances, the so-called constraint language.\nAll constraint languages admitting a robust polynomial-time algorithm (with\nsome $g$) have been characterised by Barto and Kozik, with the general bound on\nthe loss $g$ being doubly exponential, specifically\n$g(\\varepsilon)=O((\\log\\log(1/\\varepsilon))/\\log(1/\\varepsilon))$. It is\nnatural to ask when a better loss can be achieved: in particular, polynomial\nloss $g(\\varepsilon)=O(\\varepsilon^{1/k})$ for some constant $k$. In this\npaper, we consider CSPs with a constraint language having a near-unanimity\npolymorphism. We give two randomized robust algorithms with polynomial loss for\nsuch CSPs: one works for any near-unanimity polymorphism and the parameter $k$\nin the loss depends on the size of the domain and the arity of the relations in\n$\\Gamma$, while the other works for a special ternary near-unanimity operation\ncalled dual discriminator with $k=2$ for any domain size. In the latter case,\nthe CSP is a common generalisation of Unique Games with a fixed domain and\n2-SAT. In the former case, we use the algebraic approach to the CSP. Both cases\nuse the standard semidefinite programming relaxation for CSP.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jul 2016 18:52:51 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 09:52:26 GMT"}, {"version": "v3", "created": "Mon, 8 Jan 2018 12:44:41 GMT"}, {"version": "v4", "created": "Tue, 4 Dec 2018 10:43:40 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Dalmau", "V\u00edctor", ""], ["Kozik", "Marcin", ""], ["Krokhin", "Andrei", ""], ["Makarychev", "Konstantin", ""], ["Makarychev", "Yury", ""], ["Opr\u0161al", "Jakub", ""]]}, {"id": "1607.04842", "submitter": "Alexander Golovnev", "authors": "Alexander Golovnev, Oded Regev, Omri Weinstein", "title": "The Minrank of Random Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minrank of a graph $G$ is the minimum rank of a matrix $M$ that can be\nobtained from the adjacency matrix of $G$ by switching some ones to zeros\n(i.e., deleting edges) and then setting all diagonal entries to one. This\nquantity is closely related to the fundamental information-theoretic problems\nof (linear) index coding (Bar-Yossef et al., FOCS'06), network coding and\ndistributed storage, and to Valiant's approach for proving superlinear circuit\nlower bounds (Valiant, Boolean Function Complexity '92).\n  We prove tight bounds on the minrank of random Erd\\H{o}s-R\\'enyi graphs\n$G(n,p)$ for all regimes of $p\\in[0,1]$. In particular, for any constant $p$,\nwe show that $\\mathsf{minrk}(G) = \\Theta(n/\\log n)$ with high probability,\nwhere $G$ is chosen from $G(n,p)$. This bound gives a near quadratic\nimprovement over the previous best lower bound of $\\Omega(\\sqrt{n})$ (Haviv and\nLangberg, ISIT'12), and partially settles an open problem raised by Lubetzky\nand Stav (FOCS '07). Our lower bound matches the well-known upper bound\nobtained by the \"clique covering\" solution, and settles the linear index coding\nproblem for random graphs.\n  Finally, our result suggests a new avenue of attack, via derandomization, on\nValiant's approach for proving superlinear lower bounds for logarithmic-depth\nsemilinear circuits.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jul 2016 09:25:49 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 13:06:13 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Golovnev", "Alexander", ""], ["Regev", "Oded", ""], ["Weinstein", "Omri", ""]]}, {"id": "1607.05133", "submitter": "Euiwoong Lee", "authors": "Euiwoong Lee", "title": "Improved Hardness for Cut, Interdiction, and Firefighter Problems", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study variants of the classic $s$-$t$ cut problem and prove the following\nimproved hardness results assuming the Unique Games Conjecture (UGC).\n  - For any constant $k \\geq 2$ and $\\epsilon > 0$, we show that Directed\nMulticut with $k$ source-sink pairs is hard to approximate within a factor $k -\n\\epsilon$. This matches the trivial $k$-approximation algorithm. By a simple\nreduction, our result for $k = 2$ implies that Directed Multiway Cut with two\nterminals (also known as $s$-$t$ Bicut) is hard to approximate within a factor\n$2 - \\epsilon$, matching the trivial $2$-approximation algorithm. Previously,\nthe best hardness factor for these problems (for constant $k$) was $1.5 -\n\\epsilon$ under the UGC.\n  - For Length-Bounded Cut and Shortest Path Interdiction, we show that both\nproblems are hard to approximate within any constant factor, even if we allow\nbicriteria approximation. If we want to cut vertices or the graph is directed,\nour hardness factor for Length-Bounded Cut matches the best approximation ratio\nup to a constant. Previously, the best hardness factor was $1.1377$ for\nLength-Bounded Cut and $2$ for Shortest Path Interdiction.\n  - Assuming a variant of the UGC (implied by another variant of Bansal and\nKhot), we prove that it is hard to approximate Resource Minimization Fire\nContainment within any constant factor. Previously, the best hardness factor\nwas $2$.\n  Our results are based on a general method of converting an integrality gap\ninstance to a length-control dictatorship test for variants of the $s$-$t$ cut\nproblem, which may be useful for other problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 15:39:21 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Lee", "Euiwoong", ""]]}, {"id": "1607.05189", "submitter": "Karthik C. S.", "authors": "Karthik C. S. and S\\'ebastien Tavenas", "title": "On the Sensitivity Conjecture for Disjunctive Normal Forms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sensitivity conjecture of Nisan and Szegedy [CC '94] asks whether for any\nBoolean function $f$, the maximum sensitivity $s(f)$, is polynomially related\nto its block sensitivity $bs(f)$, and hence to other major complexity measures.\nDespite major advances in the analysis of Boolean functions over the last\ndecade, the problem remains widely open.\n  In this paper, we consider a restriction on the class of Boolean functions\nthrough a model of computation (DNF), and refer to the functions adhering to\nthis restriction as admitting the Normalized Block property. We prove that for\nany function $f$ admitting the Normalized Block property, $bs(f) \\leq 4s(f)^2$.\nWe note that (almost) all the functions mentioned in literature that achieve a\nquadratic separation between sensitivity and block sensitivity admit the\nNormalized Block property.\n  Recently, Gopalan et al. [ITCS '16] showed that every Boolean function $f$ is\nuniquely specified by its values on a Hamming ball of radius at most $2s(f)$.\nWe extend this result and also construct examples of Boolean functions which\nprovide the matching lower bounds.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 17:00:44 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 18:47:03 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["S.", "Karthik C.", ""], ["Tavenas", "S\u00e9bastien", ""]]}, {"id": "1607.05256", "submitter": "Scott Aaronson", "authors": "Scott Aaronson", "title": "The Complexity of Quantum States and Transformations: From Quantum Money\n  to Black Holes", "comments": "111 pages, 10 figures. Includes a special guest lecture by Adam\n  Bouland and Luke Schaeffer. Enormous thanks to them, Anil Ada, Denis Therien,\n  and the scribes, without whom these notes wouldn't have happened. Comments\n  welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are lecture notes from a weeklong course in quantum complexity theory\ntaught at the Bellairs Research Institute in Barbados, February 21-25, 2016.\nThe focus is quantum circuit complexity---i.e., the minimum number of gates\nneeded to prepare a given quantum state or apply a given unitary\ntransformation---as a unifying theme tying together several topics of recent\ninterest in the field. Those topics include the power of quantum proofs and\nadvice states; how to construct quantum money schemes secure against\ncounterfeiting; and the role of complexity in the black-hole information\nparadox and the AdS/CFT correspondence (through connections made by\nHarlow-Hayden, Susskind, and others). The course was taught to a mixed audience\nof theoretical computer scientists and quantum gravity / string theorists, and\nstarts out with a crash course on quantum information and computation in\ngeneral.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 19:46:48 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Aaronson", "Scott", ""]]}, {"id": "1607.05420", "submitter": "Ignacio Garcia-Marco", "authors": "Ignacio Garcia-Marco (LIP), Pascal Koiran (LIP), Timoth\\'ee Pecatte\n  (LIP)", "title": "Reconstruction Algorithms for Sums of Affine Powers", "comments": "This version improves on several algorithmic results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study sums of powers of affine functions in (mostly) one\nvariable. Although quite simple, this model is a generalization of two\nwell-studied models: Waring decomposition and sparsest shift. For these three\nmodels there are natural extensions to several variables, but this paper is\nmostly focused on univariate polynomials. We present structural results which\ncompare the expressive power of the three models; and we propose algorithms\nthat find the smallest decomposition of f in the first model (sums of affine\npowers) for an input polynomial f given in dense representation. We also begin\na study of the multivariate case. This work could be extended in several\ndirections. In particular, just as for Sparsest Shift and Waring decomposition,\none could consider extensions to \"supersparse\" polynomials and attempt a fuller\nstudy of the multi-variate case. We also point out that the basic univariate\nproblem studied in the present paper is far from completely solved: our\nalgorithms all rely on some assumptions for the exponents in an optimal\ndecomposition, and some algorithms also rely on a distinctness assumption for\nthe shifts. It would be very interesting to weaken these assumptions, or even\nto remove them entirely. Another related and poorly understood issue is that of\nthe bit size of the constants appearing in an optimal decomposition: is it\nalways polynomially related to the bit size of the input polynomial given in\ndense representation?\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2016 06:28:56 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 13:00:34 GMT"}, {"version": "v3", "created": "Tue, 24 Oct 2017 11:45:46 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Garcia-Marco", "Ignacio", "", "LIP"], ["Koiran", "Pascal", "", "LIP"], ["Pecatte", "Timoth\u00e9e", "", "LIP"]]}, {"id": "1607.05494", "submitter": "Pascal Koiran", "authors": "Ignacio Garcia-Marco, Pascal Koiran, Timoth\\'ee Pecatte, St\\'ephan\n  Thomass\\'e (LIP, ENS Lyon)", "title": "On the complexity of partial derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of partial derivatives is one of the most successful lower bound\nmethods for arithmetic circuits. It uses as a complexity measure the dimension\nof the span of the partial derivatives of a polynomial. In this paper, we\nconsider this complexity measure as a computational problem: for an input\npolynomial given as the sum of its nonzero monomials, what is the complexity of\ncomputing the dimension of its space of partial derivatives? We show that this\nproblem is #P-hard and we ask whether it belongs to #P. We analyze the \"trace\nmethod\", recently used in combinatorics and in algebraic complexity to lower\nbound the rank of certain matrices. We show that this method provides a\npolynomial-time computable lower bound on the dimension of the span of partial\nderivatives, and from this method we derive closed-form lower bounds. We leave\nas an open problem the existence of an approximation algorithm with reasonable\nperformance guarantees.A slightly shorter version of this paper was presented\nat STACS'17. In this new version we have corrected a typo in Section 4.1, and\nadded a reference to Shitov's work on tensor rank.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2016 09:49:19 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 12:56:58 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Garcia-Marco", "Ignacio", "", "LIP, ENS Lyon"], ["Koiran", "Pascal", "", "LIP, ENS Lyon"], ["Pecatte", "Timoth\u00e9e", "", "LIP, ENS Lyon"], ["Thomass\u00e9", "St\u00e9phan", "", "LIP, ENS Lyon"]]}, {"id": "1607.05786", "submitter": "Nithin Varma", "authors": "Kashyap Dixit, Sofya Raskhodnikova, Abhradeep Thakurta and Nithin\n  Varma", "title": "Erasure-Resilient Property Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Property testers form an important class of sublinear algorithms. In the\nstandard property testing model, an algorithm accesses the input function via\nan oracle that returns function values at all queried domain points. In many\nrealistic situations, the oracle may be unable to reveal the function values at\nsome domain points due to privacy concerns, or when some of the values get\nerased by mistake or by an adversary.\n  We initiate a study of property testers that are resilient to the presence of\nadversarially erased function values. An alpha-erasure-resilient epsilon-tester\nfor a property P is given parameters alpha, epsilon in (0,1), along with oracle\naccess to a function f such that at most an alpha fraction of the function\nvalues have been erased. The tester does not know whether a point is erased\nunless it queries that point. The tester has to accept with high probability if\nthere is a way to assign values to the erased points such that the resulting\nfunction satisfies P. It has to reject with high probability if, for all\nassignments of values to the erased points, the resulting function has to be\nchanged in at least an epsilon-fraction of the nonerased domain points to\nsatisfy P.\n  We design erasure-resilient property testers for a large class of properties.\nFor some properties, it is possible to obtain erasure-resilient testers by\nusing standard testers as a black box. But there are more challenging\nproperties for which all known testers rely on querying a specific point. If\nthis point is erased, all these testers break. We give efficient\nerasure-resilient testers for several classes of such properties including\nmonotonicity, the Lipschitz property, and convexity. Finally, we describe a\nproperty that can be epsilon-tested with O(1/epsilon) queries in the standard\nmodel, whereas testing it in the erasure-resilient model requires number of\nqueries polynomial in the input size.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2016 00:32:23 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Dixit", "Kashyap", ""], ["Raskhodnikova", "Sofya", ""], ["Thakurta", "Abhradeep", ""], ["Varma", "Nithin", ""]]}, {"id": "1607.06173", "submitter": "Ei Ando", "authors": "Ei Ando and Shuji Kijima", "title": "An FPTAS for the Volume of a ${\\cal V}$-polytope ---It is Hard to\n  Compute The Volume of The Intersection of Two Cross-polytopes", "comments": "32 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an $n$-dimensional convex body by a membership oracle in general, it is\nknown that any polynomial-time deterministic algorithm cannot approximate its\nvolume within ratio $(n/\\log n)^n$. There is a substantial progress on\nrandomized approximation such as Markov chain Monte Carlo for a\nhigh-dimensional volume, and for many #P-hard problems, while some\ndeterministic approximation algorithms are recently developed only for a few\n#P-hard problems. Motivated by a deterministic approximation of the volume of a\n${\\cal V}$-polytope, that is a polytope with few vertices and (possibly)\nexponentially many facets, this paper investigates the volume of a \"knapsack\ndual polytope,\" which is known to be #P-hard due to Khachiyan (1989). We reduce\nan approximate volume of a knapsack dual polytope to that of the intersection\nof two cross-polytopes, and give FPTASs for those volume computations.\nInterestingly, the volume of the intersection of two cross-polytopes (i.e.,\n$L_1$-balls) is #P-hard, unlike the cases of $L_{\\infty}$-balls or $L_2$-balls.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2016 02:40:30 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Ando", "Ei", ""], ["Kijima", "Shuji", ""]]}, {"id": "1607.06444", "submitter": "Krzysztof Fleszar", "authors": "Steven Chaplick, Krzysztof Fleszar, Fabian Lipp, Alexander Ravsky,\n  Oleg Verbitsky, Alexander Wolff", "title": "The Complexity of Drawing Graphs on Few Lines and Few Planes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that any graph admits a crossing-free straight-line drawing\nin $\\mathbb{R}^3$ and that any planar graph admits the same even in\n$\\mathbb{R}^2$. For a graph $G$ and $d \\in \\{2,3\\}$, let $\\rho^1_d(G)$ denote\nthe minimum number of lines in $\\mathbb{R}^d$ that together can cover all edges\nof a drawing of $G$. For $d=2$, $G$ must be planar. We investigate the\ncomplexity of computing these parameters and obtain the following hardness and\nalgorithmic results.\n  - For $d\\in\\{2,3\\}$, we prove that deciding whether $\\rho^1_d(G)\\le k$ for a\ngiven graph $G$ and integer $k$ is ${\\exists\\mathbb{R}}$-complete.\n  - Since $\\mathrm{NP}\\subseteq{\\exists\\mathbb{R}}$, deciding $\\rho^1_d(G)\\le\nk$ is NP-hard for $d\\in\\{2,3\\}$. On the positive side, we show that the problem\nis fixed-parameter tractable with respect to $k$.\n  - Since ${\\exists\\mathbb{R}}\\subseteq\\mathrm{PSPACE}$, both $\\rho^1_2(G)$ and\n$\\rho^1_3(G)$ are computable in polynomial space. On the negative side, we show\nthat drawings that are optimal with respect to $\\rho^1_2$ or $\\rho^1_3$\nsometimes require irrational coordinates.\n  - Let $\\rho^2_3(G)$ be the minimum number of planes in $\\mathbb{R}^3$ needed\nto cover a straight-line drawing of a graph $G$. We prove that deciding whether\n$\\rho^2_3(G)\\le k$ is NP-hard for any fixed $k \\ge 2$. Hence, the problem is\nnot fixed-parameter tractable with respect to $k$ unless\n$\\mathrm{P}=\\mathrm{NP}$.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2016 19:50:36 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 08:56:26 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Chaplick", "Steven", ""], ["Fleszar", "Krzysztof", ""], ["Lipp", "Fabian", ""], ["Ravsky", "Alexander", ""], ["Verbitsky", "Oleg", ""], ["Wolff", "Alexander", ""]]}, {"id": "1607.06473", "submitter": "Zhi-Cheng Yang", "authors": "Zhi-Cheng Yang, Armin Rahmani, Alireza Shabani, Hartmut Neven, and\n  Claudio Chamon", "title": "Optimizing Variational Quantum Algorithms using Pontryagin's Minimum\n  Principle", "comments": "Added new simulations on the effect of weak coupling to the\n  environment. 9 pages, 5 figures", "journal-ref": "Phys. Rev. X 7, 021027 (2017)", "doi": "10.1103/PhysRevX.7.021027", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Pontryagin's minimum principle to optimize variational quantum\nalgorithms. We show that for a fixed computation time, the optimal evolution\nhas a bang-bang (square pulse) form, both for closed and open quantum systems\nwith Markovian decoherence. Our findings support the choice of evolution ansatz\nin the recently proposed Quantum Approximate Optimization Algorithm. Focusing\non the Sherrington-Kirkpatrick spin-glass as an example, we find a system-size\nindependent distribution of the duration of pulses, with characteristic time\nscale set by the inverse of the coupling constants in the Hamiltonian. The\noptimality of the bang-bang protocols and the characteristic time scale of the\npulses provide an efficient parameterization of the protocol and inform the\nsearch for effective hybrid (classical and quantum) schemes for tackling\ncombinatorial optimization problems. For the particular systems we study, we\nfind numerically that the optimal nonadiabatic bang-bang protocols outperform\nconventional quantum annealing in the presence of weak white additive external\nnoise and weak coupling to a thermal bath modeled with the Redfield master\nequation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2016 20:00:55 GMT"}, {"version": "v2", "created": "Sun, 20 Nov 2016 16:35:37 GMT"}, {"version": "v3", "created": "Sat, 11 Mar 2017 21:44:16 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Yang", "Zhi-Cheng", ""], ["Rahmani", "Armin", ""], ["Shabani", "Alireza", ""], ["Neven", "Hartmut", ""], ["Chamon", "Claudio", ""]]}, {"id": "1607.06509", "submitter": "Saleh Soltan", "authors": "Saleh Soltan, Mihalis Yannakakis, and Gil Zussman", "title": "Doubly Balanced Connected Graph Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study the Doubly Balanced Connected graph Partitioning\n(DBCP) problem: Let $G=(V,E)$ be a connected graph with a weight\n(supply/demand) function $p:V\\rightarrow \\{-1,+1\\}$ satisfying $p(V)=\\sum_{j\\in\nV} p(j)=0$. The objective is to partition $G$ into $(V_1,V_2)$ such that\n$G[V_1]$ and $G[V_2]$ are connected, $|p(V_1)|,|p(V_2)|\\leq c_p$, and\n$\\max\\{\\frac{|V_1|}{|V_2|},\\frac{|V_2|}{|V_1|}\\}\\leq c_s$, for some constants\n$c_p$ and $c_s$. When $G$ is 2-connected, we show that a solution with $c_p=1$\nand $c_s=3$ always exists and can be found in polynomial time. Moreover, when\n$G$ is 3-connected, we show that there is always a `perfect' solution (a\npartition with $p(V_1)=p(V_2)=0$ and $|V_1|=|V_2|$, if $|V|\\equiv 0\n(\\mathrm{mod}~4)$), and it can be found in polynomial time. Our techniques can\nbe extended, with similar results, to the case in which the weights are\narbitrary (not necessarily $\\pm 1$), and to the case that $p(V)\\neq 0$ and the\nexcess supply/demand should be split evenly. They also apply to the problem of\npartitioning a graph with two types of nodes into two large connected subgraphs\nthat preserve approximately the proportion of the two types.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2016 21:24:00 GMT"}], "update_date": "2016-07-25", "authors_parsed": [["Soltan", "Saleh", ""], ["Yannakakis", "Mihalis", ""], ["Zussman", "Gil", ""]]}, {"id": "1607.06711", "submitter": "Ankit Garg", "authors": "Ankit Garg and Leonid Gurvits and Rafael Oliveira and Avi Wigderson", "title": "Algorithmic and optimization aspects of Brascamp-Lieb inequalities, via\n  Operator Scaling", "comments": "Fixed a bug in the proof of Lemma 8.1. We would like to thank\n  Nisheeth Vishnoi and Damian Straszak for pointing out this bug and also\n  allowing us to use their fix for it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Brascamp-Lieb (BL) inequalities (and their extensions) are an\nimportant mathematical tool, unifying and generalizing numerous inequalities in\nanalysis, convex geometry and information theory. While their structural theory\nis very well understood, far less is known about computing their main\nparameters.\n  We give polynomial time algorithms to compute feasibility of BL-datum, the\noptimal BL-constant and a weak separation oracle for the BL-polytope. The same\nresult holds for the so-called Reverse BL inequalities of Barthe. The best\nknown algorithms for any of these tasks required at least exponential time.\n  The algorithms are obtained by a simple efficient reduction of a given\nBL-datum to an instance of the Operator Scaling problem defined by Gurvits, for\nwhich the present authors have provided a polynomial time algorithm. This\nreduction implies algorithmic versions of many of the known structural results,\nand in some cases provide proofs that are different or simpler than existing\nones.\n  Of particular interest is the fact that the operator scaling algorithm is\ncontinuous in its input. Thus as a simple corollary of our reduction we obtain\nexplicit bounds on the magnitude and continuity of the BL-constant in terms of\nthe BL-data. To the best of our knowledge no such bounds were known, as past\narguments relied on compactness. The continuity of BL-constants is important\nfor developing non-linear BL inequalities that have recently found so many\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jul 2016 15:27:42 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 21:28:05 GMT"}, {"version": "v3", "created": "Mon, 18 Dec 2017 19:05:35 GMT"}, {"version": "v4", "created": "Fri, 13 Apr 2018 00:00:12 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Garg", "Ankit", ""], ["Gurvits", "Leonid", ""], ["Oliveira", "Rafael", ""], ["Wigderson", "Avi", ""]]}, {"id": "1607.06757", "submitter": "Konrad Dabrowski", "authors": "Alexandre Blanch\\'e and Konrad K. Dabrowski and Matthew Johnson and\n  Dani\\\"el Paulusma", "title": "Hereditary Graph Classes: When the Complexities of Colouring and Clique\n  Cover Coincide", "comments": "19 Pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is $(H_1,H_2)$-free for a pair of graphs $H_1,H_2$ if it contains no\ninduced subgraph isomorphic to $H_1$ or $H_2$. In 2001, Kr\\'al',\nKratochv\\'{\\i}l, Tuza, and Woeginger initiated a study into the complexity of\nColouring for $(H_1,H_2)$-free graphs. Since then, others have tried to\ncomplete their study, but many cases remain open. We focus on those\n$(H_1,H_2)$-free graphs where $H_2$ is $\\overline{H_1}$, the complement of\n$H_1$. As these classes are closed under complementation, the computational\ncomplexities of Colouring and Clique Cover coincide. By combining new and known\nresults, we are able to classify the complexity of Colouring and Clique Cover\nfor $(H,\\overline{H})$-free graphs for all cases except when $H=sP_1+ P_3$ for\n$s\\geq 3$ or $H=sP_1+P_4$ for $s\\geq 2$. We also classify the complexity of\nColouring on graph classes characterized by forbidding a finite number of\nself-complementary induced subgraphs, and we initiate a study of $k$-Colouring\nfor $(P_r,\\overline{P_r})$-free graphs.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jul 2016 17:32:39 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 20:29:41 GMT"}, {"version": "v3", "created": "Wed, 7 Jun 2017 11:10:25 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Blanch\u00e9", "Alexandre", ""], ["Dabrowski", "Konrad K.", ""], ["Johnson", "Matthew", ""], ["Paulusma", "Dani\u00ebl", ""]]}, {"id": "1607.07011", "submitter": "Yara Elias", "authors": "Yara Elias, Pierre McKenzie", "title": "On Generalized Addition Chains", "comments": "13 pages", "journal-ref": "INTEGERS, Volume 14, A16, 2014,\n  http://www.integers-ejcnt.org/vol14.html", "doi": null, "report-no": null, "categories": "math.NT cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given integers d >= 1, and g >= 2, a g-addition chain for d is a sequence of\nintegers a_0=1, a_1, a_2,..., a_{r-1}, a_r=d where\na_i=a_{j_1}+a_{j_2}+...+a_{j_k}, with 2 =< k =< g, and 0 =< j_1 =< j_2 =< ...\n=< j_k =< i-1. The length of a g-addition chain is r, the number of terms\nfollowing 1 in the sequence. We denote by l_g(d) the length of a shortest\naddition chain for d. Many results have been established in the case g=2. Our\naim is to establish the same sort of results for arbitrary fixed g. In\nparticular, we adapt methods for constructing g-addition chains when g=2 to the\ncase g>2 and we study the asymptotic behavior of l_g.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jul 2016 08:28:54 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Elias", "Yara", ""], ["McKenzie", "Pierre", ""]]}, {"id": "1607.07130", "submitter": "Govind Ramnarayan", "authors": "Dana Moshkovitz, Govind Ramnarayan, Henry Yuen", "title": "A No-Go Theorem for Derandomized Parallel Repetition: Beyond\n  Feige-Kilian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show a barrier towards proving a randomness-efficient\nparallel repetition, a promising avenue for achieving many tight\ninapproximability results. Feige and Kilian (STOC'95) proved an impossibility\nresult for randomness-efficient parallel repetition for two prover games with\nsmall degree, i.e., when each prover has only few possibilities for the\nquestion of the other prover. In recent years, there have been indications that\nrandomness-efficient parallel repetition (also called derandomized parallel\nrepetition) might be possible for games with large degree, circumventing the\nimpossibility result of Feige and Kilian. In particular, Dinur and Meir\n(CCC'11) construct games with large degree whose repetition can be derandomized\nusing a theorem of Impagliazzo, Kabanets and Wigderson (SICOMP'12). However,\nobtaining derandomized parallel repetition theorems that would yield optimal\ninapproximability results has remained elusive.\n  This paper presents an explanation for the current impasse in progress, by\nproving a limitation on derandomized parallel repetition. We formalize two\nproperties which we call \"fortification-friendliness\" and \"yields robust\nembeddings.\" We show that any proof of derandomized parallel repetition\nachieving almost-linear blow-up cannot both (a) be fortification-friendly and\n(b) yield robust embeddings. Unlike Feige and Kilian, we do not require the\nsmall degree assumption.\n  Given that virtually all existing proofs of parallel repetition, including\nthe derandomized parallel repetition result of Dinur and Meir, share these two\nproperties, our no-go theorem highlights a major barrier to achieving\nalmost-linear derandomized parallel repetition.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 02:43:54 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Moshkovitz", "Dana", ""], ["Ramnarayan", "Govind", ""], ["Yuen", "Henry", ""]]}, {"id": "1607.07156", "submitter": "Marcel Jackson G", "authors": "Marcel Jackson", "title": "Low growth equational complexity", "comments": null, "journal-ref": "Proceedings of the Edinburgh Mathematical Society 62 (2019)\n  197-210", "doi": "10.1017/S0013091518000354", "report-no": null, "categories": "math.GR cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The equational complexity function\n$\\beta_\\mathscr{V}:\\mathbb{N}\\to\\mathbb{N}$ of an equational class of algebras\n$\\mathscr{V}$ bounds the size of equation required to determine membership of\n$n$-element algebras in $\\mathscr{V}$. Known examples of finitely generated\nvarieties $\\mathscr{V}$ with unbounded equational complexity have growth in\n$\\Omega(n^c)$, usually for $c\\geq \\frac{1}{2}$. We show that much slower growth\nis possible, exhibiting $O(\\log_2^3(n))$ growth amongst varieties of\nsemilattice ordered inverse semigroups and additive idempotent semirings. We\nalso examine a quasivariety analogue of equational complexity, and show that a\nfinite group has polylogarithmic quasi-equational complexity function, bounded\nif and only if all Sylow subgroups are abelian.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 05:19:30 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 22:05:12 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Jackson", "Marcel", ""]]}, {"id": "1607.07200", "submitter": "Vivek Madan", "authors": "Chandra Chekuri, Vivek Madan", "title": "Approximating Multicut and the Demand Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the minimum Multicut problem, the input is an edge-weighted supply graph\n$G=(V,E)$ and a simple demand graph $H=(V,F)$. Either $G$ and $H$ are directed\n(DMulC) or both are undirected (UMulC). The goal is to remove a minimum weight\nset of edges in $G$ such that there is no path from $s$ to $t$ in the remaining\ngraph for any $(s,t) \\in F$. UMulC admits an $O(\\log k)$-approximation where\n$k$ is the vertex cover size of $H$ while the best known approximation for\nDMulC is $\\min\\{k, \\tilde{O}(n^{11/23})\\}$. These approximations are obtained\nby proving corresponding results on the multicommodity flow-cut gap. In\ncontrast to these results some special cases of Multicut, such as the\nwell-studied Multiway Cut problem, admit a constant factor approximation in\nboth undirected and directed graphs. Motivated by both concrete instances from\napplications and abstract considerations, we consider the role that the\nstructure of the demand graph $H$ plays in determining the approximability of\nMulticut.\n  In undirected graphs our main result is a $2$-approximation in $n^{O(t)}$\ntime when the demand graph $H$ excludes an induced matching of size $t$. This\ngives a constant factor approximation for a specific demand graph that\nmotivated this work.\n  In contrast to undirected graphs, we prove that in directed graphs such\napproximation algorithms can not exist. Assuming the Unique Games Conjecture\n(UGC), for a large class of fixed demand graphs DMulC cannot be approximated to\na factor better than worst-case flow-cut gap. As a consequence we prove that\nfor any fixed $k$, assuming UGC, DMulC with $k$ demand pairs is hard to\napproximate to within a factor better than $k$. On the positive side, we prove\nan approximation of $k$ when the demand graph excludes certain graphs as an\ninduced subgraph. This generalizes the Multiway Cut result to a much larger\nclass of demand graphs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 10:54:18 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Chekuri", "Chandra", ""], ["Madan", "Vivek", ""]]}, {"id": "1607.07306", "submitter": "Ragavendran Gopalakrishnan", "authors": "Ragavendran Gopalakrishnan and Koyel Mukherjee and Theja Tulabandhula", "title": "The Costs and Benefits of Sharing: Sequential Individual Rationality and\n  Sequential Fairness", "comments": "Presented as a poster at EC 2016. Presented as an invited talk\n  (sponsored session) at INFORMS Annual Meeting 2016. Presented at MSOM Service\n  Operations SIG 2017. Currently under review at Management Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In designing dynamic shared service systems that incentivize customers to opt\nfor shared rather than exclusive service, the traditional notion of individual\nrationality may be insufficient, as a customer's estimated utility could\nfluctuate arbitrarily during their time in the shared system, as long as their\nrealized utility at service completion is not worse than that for exclusive\nservice. In this work, within a model that explicitly considers the\n\"inconvenience costs\" incurred by customers due to sharing, we introduce the\nnotion of sequential individual rationality (SIR) that requires that the\ndisutility of existing customers is nonincreasing as the system state changes\ndue to new customer arrivals. Next, under SIR, we observe that cost sharing can\nalso be viewed as benefit sharing, which inspires a natural definition of\nsequential fairness (SF) - the total incremental benefit due to a new customer\nis shared among existing customers in proportion to the incremental\ninconvenience suffered.\n  We demonstrate the effectiveness of these notions by applying them to a\nridesharing system, where unexpected detours to pick up subsequent passengers\ninconvenience the existing passengers. Imposing SIR and SF reveals interesting\nand surprising results, including: (a) natural limits on the incremental\ndetours permissible, (b) exact characterization of \"SIR-feasible\" routes, which\nboast sublinear upper and lower bounds on the fractional detours, (c) exact\ncharacterization of sequentially fair cost sharing schemes, which includes a\nstrong requirement that passengers must compensate each other for the detour\ninconveniences that they cause, and (d) new algorithmic problems related to and\nmotivated by SIR.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 15:08:45 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 22:08:08 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Gopalakrishnan", "Ragavendran", ""], ["Mukherjee", "Koyel", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1607.07497", "submitter": "Greg Bodwin", "authors": "Amir Abboud, Greg Bodwin, and Seth Pettie", "title": "A Hierarchy of Lower Bounds for Sublinear Additive Spanners", "comments": "Accepted to SODA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spanners, emulators, and approximate distance oracles can be viewed as lossy\ncompression schemes that represent an unweighted graph metric in small space,\nsay $\\tilde{O}(n^{1+\\delta})$ bits. There is an inherent tradeoff between the\nsparsity parameter $\\delta$ and the stretch function $f$ of the compression\nscheme, but the qualitative nature of this tradeoff has remained a persistent\nopen problem.\n  In this paper we show that the recent additive spanner lower bound of Abboud\nand Bodwin is just the first step in a hierarchy of lower bounds that fully\ncharacterize the asymptotic behavior of the optimal stretch function $f$ as a\nfunction of $\\delta \\in (0,1/3)$. Specifically, for any integer $k\\ge 2$, any\ncompression scheme with size $O(n^{1+\\frac{1}{2^k-1} - \\epsilon})$ has a\nsublinear additive stretch function $f$: $$f(d) = d +\n\\Omega(d^{1-\\frac{1}{k}}).$$ This lower bound matches Thorup and Zwick's (2006)\nconstruction of sublinear additive emulators. It also shows that Elkin and\nPeleg's $(1+\\epsilon,\\beta)$-spanners have an essentially optimal tradeoff\nbetween $\\delta,\\epsilon,$ and $\\beta$, and that the sublinear additive\nspanners of Pettie (2009) and Chechik (2013) are not too far from optimal.\n  To complement these lower bounds we present a new construction of\n$(1+\\epsilon, O(k/\\epsilon)^{k-1})$-spanners with size $O((k/\\epsilon)^{h_k}\nkn^{1+\\frac{1}{2^{k+1}-1}})$, where $h_k < 3/4$. This size bound improves on\nthe spanners of Elkin and Peleg (2004), Thorup and Zwick (2006), and Pettie\n(2009). According to our lower bounds neither the size nor stretch function can\nbe substantially improved.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 22:05:27 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2016 00:47:37 GMT"}, {"version": "v3", "created": "Tue, 10 Jan 2017 14:11:00 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Abboud", "Amir", ""], ["Bodwin", "Greg", ""], ["Pettie", "Seth", ""]]}, {"id": "1607.07516", "submitter": "Dave Touchette", "authors": "Juan Miguel Arrazola, Dave Touchette", "title": "Quantum Advantage on Information Leakage for Equality", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a lower bound on the information leakage of any classical protocol\ncomputing the equality function in the simultaneous message passing (SMP)\nmodel. Our bound is valid in the finite length regime and is strong enough to\ndemonstrate a quantum advantage in terms of information leakage for practical\nquantum protocols. We prove our bound by obtaining an improved finite size\nversion of the communication bound due to Babai and Kimmel, relating randomized\ncommunication to deterministic communication in the SMP model. We then relate\ninformation leakage to randomized communication through a series of reductions.\nWe first provide alternative characterizations for information leakage,\nallowing us to link it to average length communication while allowing for\nshared randomness (pairwise, with the referee). A Markov inequality links this\nwith bounded length communication, and a Newman type argument allows us to go\nfrom shared to private randomness. The only reduction in which we incur more\nthan a logarithmic additive factor is in the Markov inequality; in particular,\nour compression method is essentially tight for the SMP model with average\nlength communication.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2016 01:33:28 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Arrazola", "Juan Miguel", ""], ["Touchette", "Dave", ""]]}, {"id": "1607.07676", "submitter": "Pawe{\\l} Rz\\k{a}\\.zewski", "authors": "\\'Edouard Bonnet, Tillmann Miltzow, Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Complexity of Token Swapping and its Variants", "comments": "23 pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Token Swapping problem we are given a graph with a token placed on\neach vertex. Each token has exactly one destination vertex, and we try to move\nall the tokens to their destinations, using the minimum number of swaps, i.e.,\noperations of exchanging the tokens on two adjacent vertices. As the main\nresult of this paper, we show that Token Swapping is $W[1]$-hard parameterized\nby the length $k$ of a shortest sequence of swaps. In fact, we prove that, for\nany computable function $f$, it cannot be solved in time $f(k)n^{o(k / \\log\nk)}$ where $n$ is the number of vertices of the input graph, unless the ETH\nfails. This lower bound almost matches the trivial $n^{O(k)}$-time algorithm.\n  We also consider two generalizations of the Token Swapping, namely Colored\nToken Swapping (where the tokens have different colors and tokens of the same\ncolor are indistinguishable), and Subset Token Swapping (where each token has a\nset of possible destinations). To complement the hardness result, we prove that\neven the most general variant, Subset Token Swapping, is FPT in nowhere-dense\ngraph classes.\n  Finally, we consider the complexities of all three problems in very\nrestricted classes of graphs: graphs of bounded treewidth and diameter, stars,\ncliques, and paths, trying to identify the borderlines between polynomial and\nNP-hard cases.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2016 13:09:50 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 12:25:23 GMT"}, {"version": "v3", "created": "Fri, 5 Jan 2018 11:05:30 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Miltzow", "Tillmann", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "1607.07950", "submitter": "Pierre Le Bodic", "authors": "C\\'edric Bentz and Pierre Le Bodic", "title": "A note on \"Approximation schemes for a subclass of subset selection\n  problems\", and a faster FPTAS for the Minimum Knapsack Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruhs and Woeginger prove the existence of FPTAS's for a general class of\nminimization and maximization subset selection problems. Without losing\ngenerality from the original framework, we prove how better asymptotic\nworst-case running times can be achieved if a $\\rho$-approximation algorithm is\navailable, and in particular we obtain matching running times between\nmaximization and minimization subset selection problems. We directly apply this\nresult to the Minimum Knapsack Problem, for which the original framework yields\nan FPTAS with running time $O(n^5/\\epsilon)$, where $\\epsilon$ is the required\naccuracy and $n$ is the number of items, and obtain an FPTAS with running time\n$O(n^3/\\epsilon)$, thus improving the running time by a quadratic factor in the\nworst case.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2016 04:13:46 GMT"}], "update_date": "2016-07-28", "authors_parsed": [["Bentz", "C\u00e9dric", ""], ["Bodic", "Pierre Le", ""]]}, {"id": "1607.08067", "submitter": "Oleg Verbitsky", "authors": "Oleg Verbitsky and Maksim Zhukovskii", "title": "The Descriptive Complexity of Subgraph Isomorphism without Numerics", "comments": "20 pages, 2 figures, 1 table. Sections 6 and 7.1 are new. The result\n  of Section 6 in the preceding version is removed and will appear in an\n  accompanying paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $F$ be a connected graph with $\\ell$ vertices. The existence of a\nsubgraph isomorphic to $F$ can be defined in first-order logic with quantifier\ndepth no better than $\\ell$, simply because no first-order formula of smaller\nquantifier depth can distinguish between the complete graphs $K_\\ell$ and\n$K_{\\ell-1}$. We show that, for some $F$, the existence of an $F$ subgraph in\n\\emph{sufficiently large} connected graphs is definable with quantifier depth\n$\\ell-3$. On the other hand, this is never possible with quantifier depth\nbetter than $\\ell/2$. If we, however, consider definitions over connected\ngraphs with sufficiently large treewidth, the quantifier depth can for some $F$\nbe arbitrarily small comparing to $\\ell$ but never smaller than the treewidth\nof $F$. Moreover, the definitions over highly connected graphs require\nquantifier depth strictly more than the density of $F$. Finally, we determine\nthe exact values of these descriptive complexity parameters for all connected\npattern graphs $F$ on 4 vertices.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2016 12:53:57 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 10:25:17 GMT"}, {"version": "v3", "created": "Tue, 7 Feb 2017 15:08:30 GMT"}, {"version": "v4", "created": "Mon, 11 Sep 2017 09:03:01 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Verbitsky", "Oleg", ""], ["Zhukovskii", "Maksim", ""]]}, {"id": "1607.08077", "submitter": "Nikolay Vereshchagin", "authors": "Nikolai Vereshchagin, Alexander Shen", "title": "Algorithmic statistics: forty years later", "comments": "Missing proofs added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic statistics has two different (and almost orthogonal) motivations.\nFrom the philosophical point of view, it tries to formalize how the statistics\nworks and why some statistical models are better than others. After this notion\nof a \"good model\" is introduced, a natural question arises: it is possible that\nfor some piece of data there is no good model? If yes, how often these bad\n(\"non-stochastic\") data appear \"in real life\"?\n  Another, more technical motivation comes from algorithmic information theory.\nIn this theory a notion of complexity of a finite object (=amount of\ninformation in this object) is introduced; it assigns to every object some\nnumber, called its algorithmic complexity (or Kolmogorov complexity).\nAlgorithmic statistic provides a more fine-grained classification: for each\nfinite object some curve is defined that characterizes its behavior. It turns\nout that several different definitions give (approximately) the same curve.\n  In this survey we try to provide an exposition of the main results in the\nfield (including full proofs for the most important ones), as well as some\nhistorical comments. We assume that the reader is familiar with the main\nnotions of algorithmic information (Kolmogorov complexity) theory.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2016 13:16:35 GMT"}, {"version": "v2", "created": "Tue, 2 Aug 2016 09:52:39 GMT"}, {"version": "v3", "created": "Tue, 7 Mar 2017 17:46:51 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Vereshchagin", "Nikolai", ""], ["Shen", "Alexander", ""]]}, {"id": "1607.08078", "submitter": "Ross King", "authors": "Andrew Currin, Konstantin Korovin, Maria Ababi, Katherine Roper,\n  Douglas B. Kell, Philip J. Day, Ross D. King", "title": "Computing exponentially faster: Implementing a nondeterministic\n  universal Turing machine using DNA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.ET q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of computer science is based around Universal Turing Machines\n(UTMs): abstract machines able to execute all possible algorithms. Modern\ndigital computers are physical embodiments of UTMs. The nondeterministic\npolynomial (NP) time complexity class of problems is the most significant in\ncomputer science, and an efficient (i.e. polynomial P) way to solve such\nproblems would be of profound economic and social importance. By definition\nnondeterministic UTMs (NUTMs) solve NP complete problems in P time. However,\nNUTMs have previously been believed to be physically impossible to construct.\nThue string rewriting systems are computationally equivalent to UTMs, and are\nnaturally nondeterministic. Here we describe the physical design for a NUTM\nthat implements a universal Thue system. The design exploits the ability of DNA\nto replicate to execute an exponential number of computational paths in P time.\nEach Thue rewriting step is embodied in a DNA edit implemented using a novel\ncombination of polymerase chain reactions and site-directed mutagenesis. We\ndemonstrate that this design works using both computational modelling and in\nvitro molecular biology experimentation. The current design has limitations,\nsuch as restricted error-correction. However, it opens up the prospect of\nengineering NUTM based computers able to outperform all standard computers on\nimportant practical problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2016 13:17:02 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Currin", "Andrew", ""], ["Korovin", "Konstantin", ""], ["Ababi", "Maria", ""], ["Roper", "Katherine", ""], ["Kell", "Douglas B.", ""], ["Day", "Philip J.", ""], ["King", "Ross D.", ""]]}, {"id": "1607.08192", "submitter": "Radu Curticapean", "authors": "Radu Curticapean", "title": "Counting matchings with k unmatched vertices in planar graphs", "comments": "16 pages, to appear in ESA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of counting matchings in planar graphs. While perfect\nmatchings in planar graphs can be counted by a classical polynomial-time\nalgorithm, the problem of counting all matchings (possibly containing unmatched\nvertices, also known as defects) is known to be #P-complete on planar graphs.\nTo interpolate between the hard case of counting matchings and the easy case of\ncounting perfect matchings, we study the parameterized problem of counting\nmatchings with exactly k unmatched vertices in a planar graph G, on input G and\nk. This setting has a natural interpretation in statistical physics, and it is\na special case of counting perfect matchings in k-apex graphs (graphs that can\nbe turned planar by removing at most k vertices).\n  Starting from a recent #W[1]-hardness proof for counting perfect matchings on\nk-apex graphs, we obtain that counting matchings with k unmatched vertices in\nplanar graphs is #W[1]-hard. In contrast, given a plane graph G with s\ndistinguished faces, there is an $O(2^s \\cdot n^3)$ time algorithm for counting\nthose matchings with k unmatched vertices such that all unmatched vertices lie\non the distinguished faces. This implies an $f(k,s)\\cdot n^{O(1)}$ time\nalgorithm for counting perfect matchings in k-apex graphs whose apex\nneighborhood is covered by s faces.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2016 17:42:52 GMT"}], "update_date": "2016-07-28", "authors_parsed": [["Curticapean", "Radu", ""]]}]