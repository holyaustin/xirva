[{"id": "1807.00404", "submitter": "Oliver Hinder", "authors": "Oliver Hinder, Yinyu Ye", "title": "Worst-case iteration bounds for log barrier methods for problems with\n  nonconvex constraints", "comments": "Minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interior point methods (IPMs) that handle nonconvex constraints such as\nIPOPT, KNITRO and LOQO have had enormous practical success. We consider IPMs in\nthe setting where the objective and constraints have Lipschitz first and second\nderivatives. Unfortunately, previous analyses of log barrier methods in this\nsetting implicitly prove guarantees with exponential dependencies on $1/\\mu$,\nwhere $\\mu$ is the barrier penalty parameter. We provide an IPM that finds a\n$\\mu$-approximate Fritz John point by solving $\\mathcal{O}( \\mu^{-7/4})$\ntrust-region subproblems. For this setup, the results represent both the first\niteration bound with a polynomial dependence on $1/\\mu$ for a log barrier\nmethod and the best-known guarantee for finding Fritz John points. We also show\nthat, given convexity and regularity conditions, our algorithm finds an\n$\\epsilon$-optimal solution in at most $\\mathcal{O}(\\epsilon^{-2/3})$\ntrust-region steps.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 21:52:23 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2019 01:56:27 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 18:22:35 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 17:15:06 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Hinder", "Oliver", ""], ["Ye", "Yinyu", ""]]}, {"id": "1807.00590", "submitter": "Jacob Focke", "authors": "Jacob Focke, Leslie Ann Goldberg and Stanislav Zivny", "title": "The Complexity of Approximately Counting Retractions", "comments": null, "journal-ref": "ACM Transactions on Computation Theory 12(3) Article No. 15 (2020)", "doi": "10.1145/3397472", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a graph that contains an induced subgraph $H$. A retraction from\n$G$ to $H$ is a homomorphism from $G$ to $H$ that is the identity function on\n$H$. Retractions are very well-studied: Given $H$, the complexity of deciding\nwhether there is a retraction from an input graph $G$ to $H$ is completely\nclassified, in the sense that it is known for which $H$ this problem is\ntractable (assuming $\\mathrm{P}\\neq \\mathrm{NP}$). Similarly, the complexity of\n(exactly) counting retractions from $G$ to $H$ is classified (assuming\n$\\mathrm{FP}\\neq \\#\\mathrm{P}$). However, almost nothing is known about\napproximately counting retractions. Our first contribution is to give a\ncomplete trichotomy for approximately counting retractions to graphs of girth\nat least $5$. Our second contribution is to locate the retraction counting\nproblem for each $H$ in the complexity landscape of related approximate\ncounting problems. Interestingly, our results are in contrast to the situation\nin the exact counting context. We show that the problem of approximately\ncounting retractions is separated both from the problem of approximately\ncounting homomorphisms and from the problem of approximately counting list\nhomomorphisms --- whereas for exact counting all three of these problems are\ninterreducible. We also show that the number of retractions is at least as hard\nto approximate as both the number of surjective homomorphisms and the number of\ncompactions. In contrast, exactly counting compactions is the hardest of all of\nthese exact counting problems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 10:47:52 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 17:32:35 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 12:18:22 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Focke", "Jacob", ""], ["Goldberg", "Leslie Ann", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1807.00645", "submitter": "Nicholas Coxon", "authors": "Nicholas Coxon (GRACE)", "title": "Fast Hermite interpolation and evaluation over finite fields of\n  characteristic two", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents new fast algorithms for Hermite interpolation and\nevaluation over finite fields of characteristic two. The algorithms reduce the\nHermite problems to instances of the standard multipoint interpolation and\nevaluation problems, which are then solved by existing fast algorithms. The\nreductions are simple to implement and free of multiplications, allowing low\noverall multiplicative complexities to be obtained. The algorithms are suitable\nfor use in encoding and decoding algorithms for multiplicity codes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 13:19:18 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Coxon", "Nicholas", "", "GRACE"]]}, {"id": "1807.00936", "submitter": "Pasin Manurangsi", "authors": "Pasin Manurangsi", "title": "A Note on Degree vs Gap of Min-Rep Label Cover and Improved\n  Inapproximability for Connectivity Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note concerns the trade-off between the degree of the constraint graph\nand the gap in hardness of approximating the Min-Rep variant of Label Cover\n(aka Projection Game). We make a very simple observation that, for NP-hardness\nwith gap $g$, the degree can be made as small as $O(g \\log g)$, which improves\nupon the previous $\\tilde{O}(g^{1/2})$ bound from a work of Laekhanukit\n(SODA'14). Note that our bound is optimal up to a logarithmic factor since\nthere is a trivial $\\Delta$-approximation for Min-Rep where $\\Delta$ is the\nmaximum degree of the constraint graph.\n  Thanks to known reductions, this improvement implies better hardness of\napproximation results for Rooted $k$-Connectivity, Vertex-Connectivity\nSurvivable Network Design and Vertex-Connectivity $k$-Route Cut.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 00:38:03 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Manurangsi", "Pasin", ""]]}, {"id": "1807.00985", "submitter": "Manuel Bodirsky", "authors": "Manuel Bodirsky, Barnaby Martin, Marcello Mamino, Antoine Mottet", "title": "The complexity of disjunctive linear Diophantine constraints", "comments": "To appear in the proceedings of MFCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the Constraint Satisfaction Problem CSP(A), where A is first-order\ndefinable in (Z;+,1) and contains +. We prove such problems are either in P or\nNP-complete.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 05:39:07 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Martin", "Barnaby", ""], ["Mamino", "Marcello", ""], ["Mottet", "Antoine", ""]]}, {"id": "1807.01064", "submitter": "Chen Yuan", "authors": "Venkatesan Guruswami, Chaoping Xing, Chen Yuan", "title": "How long can optimal locally repairable codes be?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A locally repairable code (LRC) with locality $r$ allows for the recovery of\nany erased codeword symbol using only $r$ other codeword symbols. A\nSingleton-type bound dictates the best possible trade-off between the dimension\nand distance of LRCs --- an LRC attaining this trade-off is deemed\n\\emph{optimal}. Such optimal LRCs have been constructed over alphabets growing\nlinearly in the block length. Unlike the classical Singleton bound, however, it\nwas not known if such a linear growth in the alphabet size is necessary, or for\nthat matter even if the alphabet needs to grow at all with the block length.\nIndeed, for small code distances $3,4$, arbitrarily long optimal LRCs were\nknown over fixed alphabets.\n  Here, we prove that for distances $d \\ge 5$, the code length $n$ of an\noptimal LRC over an alphabet of size $q$ must be at most roughly $O(d q^3)$.\nFor the case $d=5$, our upper bound is $O(q^2)$. We complement these bounds by\nshowing the existence of optimal LRCs of length\n$\\Omega_{d,r}(q^{1+1/\\lfloor(d-3)/2\\rfloor})$ when $d \\le r+2$. These bounds\nmatch when $d=5$, thus pinning down $n=\\Theta(q^2)$ as the asymptotically\nlargest length of an optimal LRC for this case.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 10:13:09 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Xing", "Chaoping", ""], ["Yuan", "Chen", ""]]}, {"id": "1807.01369", "submitter": "Michael Fiske S", "authors": "Michael Stephen Fiske", "title": "Quantum Random Self-Modifiable Computation", "comments": "50 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the fundamental questions in computer science, at least two have a deep\nimpact on mathematics. What can computation compute? How many steps does a\ncomputation require to solve an instance of the 3-SAT problem? Our work\naddresses the first question, by introducing a new model called the ex-machine.\nThe ex-machine executes Turing machine instructions and two special types of\ninstructions. Quantum random instructions are physically realizable with a\nquantum random number generator. Meta instructions can add new states and add\nnew instructions to the ex-machine. A countable set of ex-machines is\nconstructed, each with a finite number of states and instructions; each\nex-machine can compute a Turing incomputable language, whenever the quantum\nrandomness measurements behave like unbiased Bernoulli trials. In 1936, Alan\nTuring posed the halting problem for Turing machines and proved that this\nproblem is unsolvable for Turing machines. Consider an enumeration E_a(i) =\n(M_i, T_i) of all Turing machines M_i and initial tapes T_i. Does there exist\nan ex-machine X that has at least one evolutionary path X --> X_1 --> X_2 --> .\n. . --> X_m, so at the mth stage ex-machine X_m can correctly determine for 0\n<= i <= m whether M_i's execution on tape T_i eventually halts? We demonstrate\nan ex-machine Q(x) that has one such evolutionary path. The existence of this\nevolutionary path suggests that David Hilbert was not misguided to propose in\n1900 that mathematicians search for finite processes to help construct\nmathematical proofs. Our refinement is that we cannot use a fixed computer\nprogram that behaves according to a fixed set of mechanical rules. We must\npursue methods that exploit randomness and self-modification so that the\ncomplexity of the program can increase as it computes.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 22:45:10 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 02:34:17 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 21:16:50 GMT"}, {"version": "v4", "created": "Sat, 22 Sep 2018 00:04:38 GMT"}, {"version": "v5", "created": "Wed, 5 Dec 2018 18:46:36 GMT"}, {"version": "v6", "created": "Thu, 6 Dec 2018 18:49:34 GMT"}, {"version": "v7", "created": "Mon, 31 Dec 2018 15:37:44 GMT"}, {"version": "v8", "created": "Fri, 3 May 2019 19:55:40 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Fiske", "Michael Stephen", ""]]}, {"id": "1807.01680", "submitter": "Kun He", "authors": "Heng Guo, Kun He", "title": "Tight bounds for popping algorithms", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We sharpen run-time analysis for algorithms under the partial rejection\nsampling framework. Our method yields improved bounds for: the cluster-popping\nalgorithm for approximating all-terminal network reliability; the cycle-popping\nalgorithm for sampling rooted spanning trees; the sink-popping algorithm for\nsampling sink-free orientations. In all three applications, our bounds are not\nonly tight in order, but also optimal in constants.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:57:06 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 16:47:13 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Guo", "Heng", ""], ["He", "Kun", ""]]}, {"id": "1807.01920", "submitter": "Marc Roth", "authors": "Marc Roth and Johannes Schmitt", "title": "Counting Induced Subgraphs: A Topological Approach to #W[1]-hardness", "comments": "20 pages, 2 figures, IPEC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the problem $\\#\\mathsf{IndSub}(\\Phi)$ of counting all induced\nsubgraphs of size $k$ in a graph $G$ that satisfy a given property $\\Phi$. This\ncontinues the work of Jerrum and Meeks who proved the problem to be\n$\\#\\mathrm{W[1]}$-hard for some families of properties which include, among\nothers, (dis)connectedness [JCSS 15] and even- or oddness of the number of\nedges [Combinatorica 17]. Using the recent framework of graph motif parameters\ndue to Curticapean, Dell and Marx [STOC 17], we discover that for monotone\nproperties $\\Phi$, the problem $\\#\\mathsf{IndSub}(\\Phi)$ is hard for\n$\\#\\mathrm{W[1]}$ if the reduced Euler characteristic of the associated\nsimplicial (graph) complex of $\\Phi$ is non-zero. This observation links\n$\\#\\mathsf{IndSub}(\\Phi)$ to Karp's famous Evasiveness Conjecture, as every\ngraph complex with non-vanishing reduced Euler characteristic is known to be\nevasive. Applying tools from the \"topological approach to evasiveness\" which\nwas introduced in the seminal paper of Khan, Saks and Sturtevant [FOCS 83], we\nprove that $\\#\\mathsf{IndSub}(\\Phi)$ is $\\#\\mathrm{W[1]}$-hard for every\nmonotone property $\\Phi$ that does not hold on the Hamilton cycle as well as\nfor some monotone properties that hold on the Hamilton cycle such as being\ntriangle-free or not $k$-edge-connected for $k > 2$. Moreover, we show that for\nthose properties $\\#\\mathsf{IndSub}(\\Phi)$ can not be solved in time $f(k)\\cdot\nn^{o(k)}$ for any computable function $f$ unless the Exponential Time\nHypothesis (ETH) fails. In the final part of the paper, we investigate\nnon-monotone properties and prove that $\\#\\mathsf{IndSub}(\\Phi)$ is\n$\\#\\mathrm{W[1]}$-hard if $\\Phi$ is any non-trivial modularity constraint on\nthe number of edges with respect to some prime $q$ or if $\\Phi$ enforces the\npresence of a fixed isolated subgraph.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 09:51:21 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Roth", "Marc", ""], ["Schmitt", "Johannes", ""]]}, {"id": "1807.02075", "submitter": "Zhengjun Cao", "authors": "Zhengjun Cao and Zhen Chen and Lihua Liu", "title": "Analysis of Nederlof's algorithm for subset sum", "comments": "page 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Nederlof's algorithm [Information Processing Letters, 118\n(2017), 15-16] for constructing a proof that the number of subsets summing to a\nparticular integer equals a claimed quantity is flawed because: 1) its\nconsistence is not kept; 2) the proposed recurrence formula is incorrect.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 03:41:09 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 02:50:00 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Cao", "Zhengjun", ""], ["Chen", "Zhen", ""], ["Liu", "Lihua", ""]]}, {"id": "1807.02551", "submitter": "Gonzalo Mu\\~noz", "authors": "Yuri Faenza, Gonzalo Mu\\~noz and Sebastian Pokutta", "title": "New Limits of Treewidth-based tractability in Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse structures are frequently sought when pursuing tractability in\noptimization problems. They are exploited from both theoretical and\ncomputational perspectives to handle complex problems that become manageable\nwhen sparsity is present. An example of this type of structure is given by\ntreewidth: a graph theoretical parameter that measures how \"tree-like\" a graph\nis. This parameter has been used for decades for analyzing the complexity of\nvarious optimization problems and for obtaining tractable algorithms for\nproblems where this parameter is bounded. The goal of this work is to\ncontribute to the understanding of the limits of the treewidth-based\ntractability in optimization. Our results are as follows. First, we prove that,\nin a certain sense, the already known positive results on extension complexity\nbased on low treewidth are the best possible. Secondly, under mild assumptions,\nwe prove that treewidth is the only graph-theoretical parameter that yields\ntractability a wide class of optimization problems, a fact well known in\nGraphical Models in Machine Learning and in Constraint Satisfaction Problems,\nwhich here we extend to an approximation setting in Optimization.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 19:13:45 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 14:51:33 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2018 15:15:34 GMT"}, {"version": "v4", "created": "Wed, 20 Mar 2019 17:10:56 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Faenza", "Yuri", ""], ["Mu\u00f1oz", "Gonzalo", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "1807.02648", "submitter": "Chairi Kiourt", "authors": "Chairi Kiourt, Dimitris Kalles and Panagiotis Kanellopoulos", "title": "How game complexity affects the playing behavior of synthetic agents", "comments": "15th European Conference on Multi-Agent Systems, Evry, France, 14-15\n  December 2017", "journal-ref": "Multi-Agent Systems and Agreement Technologies. EUMAS 2017, AT\n  2017. Lecture Notes in Computer Science", "doi": "10.1007/978-3-030-01713-2_22", "report-no": null, "categories": "cs.AI cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent based simulation of social organizations, via the investigation of\nagents' training and learning tactics and strategies, has been inspired by the\nability of humans to learn from social environments which are rich in agents,\ninteractions and partial or hidden information. Such richness is a source of\ncomplexity that an effective learner has to be able to navigate. This paper\nfocuses on the investigation of the impact of the environmental complexity on\nthe game playing-and-learning behavior of synthetic agents. We demonstrate our\napproach using two independent turn-based zero-sum games as the basis of\nforming social events which are characterized both by competition and\ncooperation. The paper's key highlight is that as the complexity of a social\nenvironment changes, an effective player has to adapt its learning and playing\nprofile to maintain a given performance profile\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 11:57:21 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Kiourt", "Chairi", ""], ["Kalles", "Dimitris", ""], ["Kanellopoulos", "Panagiotis", ""]]}, {"id": "1807.02790", "submitter": "Dmitry Gribanov", "authors": "A. Yu. Chirkov, D. V. Gribanov, D. S. Malyshev, P. M. Pardalos, S. I.\n  Veselov, N. Yu. Zolotykh", "title": "On the complexity of quasiconvex integer minimization problem", "comments": "Some new proofs have been added. Some fixes are done", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the class of quasiconvex functions and its proper\nsubclass of conic functions. The integer minimization problem of these\nfunctions is considered in the paper, assuming that an optimized function is\ndefined by the comparison oracle. We will show that there is no a polynomial\nalgorithm on $\\log R$ to optimize quasiconvex functions in the ball of integer\nradius $R$ using only the comparison oracle. On the other hand, if an optimized\nfunction is conic, then we show that there is a polynomial on $\\log R$\nalgorithm. We also present an exponential on the dimension lower bound for the\noracle complexity of the conic function integer optimization problem.\nAdditionally, we give examples of known problems that can be polynomially\nreduced to the minimization problem of functions in our classes.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 09:27:33 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 06:25:54 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 12:52:27 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Chirkov", "A. Yu.", ""], ["Gribanov", "D. V.", ""], ["Malyshev", "D. S.", ""], ["Pardalos", "P. M.", ""], ["Veselov", "S. I.", ""], ["Zolotykh", "N. Yu.", ""]]}, {"id": "1807.03074", "submitter": "Jon Lee", "authors": "Marcia Fampa, Jon Lee", "title": "On Sparse Reflexive Generalized Inverses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sparse generalized inverses $H$ of a rank-$r$ real matrix $A$. We\ngive a construction for reflexive generalized inverses having at most $r^2$\nnonzeros. For $r=1$ and for $r=2$ with $A$ nonnegative, we demonstrate how to\nminimize the (vector) 1-norm over reflexive generalized inverses. For general\n$r$, we efficiently find reflexive generalized inverses with 1-norm within\napproximately a factor of $r^2$ of the minimum 1-norm generalized inverse.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 12:33:36 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 14:45:06 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Fampa", "Marcia", ""], ["Lee", "Jon", ""]]}, {"id": "1807.03604", "submitter": "Max Bannach", "authors": "Max Bannach and Till Tantau", "title": "Computing Kernels in Parallel: Lower and Upper Bounds", "comments": "IPEC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel fixed-parameter tractability studies how parameterized problems can\nbe solved in parallel. A surprisingly large number of parameterized problems\nadmit a high level of parallelization, but this does not mean that we can also\nefficiently compute small problem kernels in parallel: known kernelization\nalgorithms are typically highly sequential. In the present paper, we establish\na number of upper and lower bounds concerning the sizes of kernels that can be\ncomputed in parallel. An intriguing finding is that there are complex\ntrade-offs between kernel size and the depth of the circuits needed to compute\nthem: For the vertex cover problem, an exponential kernel can be computed by\nAC$^0$-circuits, a quadratic kernel by TC$^0$-circuits, and a linear kernel by\nrandomized NC-circuits with derandomization being possible only if it is also\npossible for the matching problem. Other natural problems for which similar\n(but quantitatively different) effects can be observed include tree\ndecomposition problems parameterized by the vertex cover number, the undirected\nfeedback vertex set problem, the matching problem, or the point line cover\nproblem. We also present natural problems for which computing kernels is\ninherently sequential.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 13:07:37 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Bannach", "Max", ""], ["Tantau", "Till", ""]]}, {"id": "1807.03663", "submitter": "Pascal Koiran", "authors": "Pascal Koiran (LIP), Nicolas Ressayre (ICJ)", "title": "Orbits of monomials and factorization into products of linear forms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.SC math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the factorization of multivariate polynomials into\nproducts of linear forms, a problem which has applications to differential\nalgebra, to the resolution of systems of polynomial equations and to Waring\ndecomposition (i.e., decomposition in sums of d-th powers of linear forms; this\nproblem is also known as symmetric tensor decomposition). We provide three\nblack box algorithms for this problem. Our main contribution is an algorithm\nmotivated by the application to Waring decomposition. This algorithm reduces\nthe corresponding factorization problem to simultaenous matrix diagonalization,\na standard task in linear algebra. The algorithm relies on ideas from invariant\ntheory, and more specifically on Lie algebras. Our second algorithm\nreconstructs a factorization from several bi-variate projections. Our third\nalgorithm reconstructs it from the determination of the zero set of the input\npolynomial, which is a union of hyperplanes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 14:13:57 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Koiran", "Pascal", "", "LIP"], ["Ressayre", "Nicolas", "", "ICJ"]]}, {"id": "1807.03739", "submitter": "Naoto Shiraishi", "authors": "Naoto Shiraishi and Jun Takahashi", "title": "Constructing Concrete Hard Instances of the Maximum Independent Set\n  Problem", "comments": "9 pages, 5 figures", "journal-ref": "J. Stat. Mech. (2019) 113401", "doi": "10.1088/1742-5468/ab409d", "report-no": null, "categories": "cs.DS cond-mat.dis-nn cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a deterministic construction of hard instances for the maximum\nindependent set problem (MIS). The constructed hard instances form an infinite\ngraph sequence with increasing size, which possesses similar characteristics to\nsparse random graphs and in which MIS cannot be solved efficiently. We\nanalytically and numerically show that all algorithms employing cycle-chain\nrefutation, which is a general refutation method we introduce for capturing the\nability of many known algorithms, cannot upper bound the size of the maximum\nindependent set tightly.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 05:56:13 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Shiraishi", "Naoto", ""], ["Takahashi", "Jun", ""]]}, {"id": "1807.04263", "submitter": "Florent Capelli", "authors": "Florent Capelli and Stefan Mengel", "title": "Knowledge Compilation, Width and Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize many results concerning the tractability of SAT and #SAT on\nbounded treewidth CNF-formula in the context of Quantified Boolean Formulas\n(QBF). To this end, we start by studying the notion of width for OBDD and\nobserve that the blow up in size while existentially or universally projecting\na block of variables in an OBDD only affects its width. We then generalize this\nnotion of width to the more general representation of structured\n(deterministic) DNNF and give a similar algorithm to existentially or\nuniversally project a block of variables. Using a well-known algorithm\ntransforming bounded treewidth CNF formula into deterministic DNNF, we are able\nto generalize this connection to quantified CNF which gives us as a byproduct\nthat one can count the number of models of a bounded treewidth and bounded\nquantifier alternation quantified CNF in FPT time. We also give an extensive\nstudy of bounded width d-DNNF and proves the optimality of several of our\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 17:53:30 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Capelli", "Florent", ""], ["Mengel", "Stefan", ""]]}, {"id": "1807.04421", "submitter": "Aaron Potechin", "authors": "Aaron Potechin", "title": "On the Approximation Resistance of Balanced Linear Threshold Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that there exists a balanced linear threshold function\n(LTF) which is unique games hard to approximate, refuting a conjecture of\nAustrin, Benabbas, and Magen. We also show that the almost monarchy predicate\non k variables is approximable for sufficiently large k.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 04:39:12 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 18:02:18 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Potechin", "Aaron", ""]]}, {"id": "1807.04724", "submitter": "Diogo Costa", "authors": "Diogo M. Costa", "title": "Computational Complexity of Games and Puzzles", "comments": "Master's thesis (Jul 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we survey techniques and results from the study of Complexity\nTheory and Games. We then apply these techniques to obtain new results for\npreviously unstudied games. Our contributions in the games Hexiom, Cut the\nRope, and Back to Bed may be helpful in further studies by exploiting structure\ncommon to several games. We also highlight some interesting paths for further\nstudy related to uncertainty that have yet to receive thorough study given\ntheir prevalence in today's games.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 17:00:03 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Costa", "Diogo M.", ""]]}, {"id": "1807.04735", "submitter": "Maksims Dimitrijevs", "authors": "Maksims Dimitrijevs, Abuzer Yakary{\\i}lmaz", "title": "Probabilistic verification of all languages", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present three protocols for verifying all languages: (i) For any unary\n(binary) language, there is a log-space (linear-space) interactive proof system\n(IPS); (ii) for any language, there is a constant-space weak-IPS (the\nnon-members may not be rejected with high probability); and, (iii) for any\nlanguage, there is a constant-space IPS with two provers where the verifier\nreads the input once. Additionally, we show that uncountably many binary\n(unary) languages can be verified in constant space and in linear (quadratic)\nexpected time.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 17:20:27 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Dimitrijevs", "Maksims", ""], ["Yakary\u0131lmaz", "Abuzer", ""]]}, {"id": "1807.04920", "submitter": "Stefan Kiefer", "authors": "Nikhil Balaji, Stefan Kiefer, Petr Novotn\\'y, Guillermo A. P\\'erez,\n  and Mahsa Shirmohammadi", "title": "On the Complexity of Value Iteration", "comments": "Full version of an ICALP'19 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value iteration is a fundamental algorithm for solving Markov Decision\nProcesses (MDPs). It computes the maximal $n$-step payoff by iterating $n$\ntimes a recurrence equation which is naturally associated to the MDP. At the\nsame time, value iteration provides a policy for the MDP that is optimal on a\ngiven finite horizon $n$. In this paper, we settle the computational complexity\nof value iteration. We show that, given a horizon $n$ in binary and an MDP,\ncomputing an optimal policy is EXP-complete, thus resolving an open problem\nthat goes back to the seminal 1987 paper on the complexity of MDPs by\nPapadimitriou and Tsitsiklis. As a stepping stone, we show that it is\nEXP-complete to compute the $n$-fold iteration (with $n$ in binary) of a\nfunction given by a straight-line program over the integers with $\\max$ and $+$\nas operators.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 05:28:11 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 13:32:27 GMT"}, {"version": "v3", "created": "Sat, 27 Apr 2019 11:03:47 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Balaji", "Nikhil", ""], ["Kiefer", "Stefan", ""], ["Novotn\u00fd", "Petr", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Shirmohammadi", "Mahsa", ""]]}, {"id": "1807.04930", "submitter": "Andreas Galanis", "authors": "Ivona Bezakova, Andreas Galanis, Leslie Ann Goldberg, Daniel\n  Stefankovic", "title": "The complexity of approximating the matching polynomial in the complex\n  plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximating the value of the matching polynomial on\ngraphs with edge parameter $\\gamma$, where $\\gamma$ takes arbitrary values in\nthe complex plane.\n  When $\\gamma$ is a positive real, Jerrum and Sinclair showed that the problem\nadmits an FPRAS on general graphs. For general complex values of $\\gamma$,\nPatel and Regts, building on methods developed by Barvinok, showed that the\nproblem admits an FPTAS on graphs of maximum degree $\\Delta$ as long as\n$\\gamma$ is not a negative real number less than or equal to\n$-1/(4(\\Delta-1))$. Our first main result completes the picture for the\napproximability of the matching polynomial on bounded degree graphs. We show\nthat for all $\\Delta\\geq 3$ and all real $\\gamma$ less than $-1/(4(\\Delta-1))$,\nthe problem of approximating the value of the matching polynomial on graphs of\nmaximum degree $\\Delta$ with edge parameter $\\gamma$ is #P-hard.\n  We then explore whether the maximum degree parameter can be replaced by the\nconnective constant. Sinclair et al. showed that for positive real $\\gamma$ it\nis possible to approximate the value of the matching polynomial using a\ncorrelation decay algorithm on graphs with bounded connective constant (and\npotentially unbounded maximum degree). We first show that this result does not\nextend in general in the complex plane; in particular, the problem is #P-hard\non graphs with bounded connective constant for a dense set of $\\gamma$ values\non the negative real axis. Nevertheless, we show that the result does extend\nfor any complex value $\\gamma$ that does not lie on the negative real axis. Our\nanalysis accounts for complex values of $\\gamma$ using geodesic distances in\nthe complex plane in the metric defined by an appropriate density function.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 06:30:08 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 17:38:05 GMT"}, {"version": "v3", "created": "Fri, 26 Apr 2019 09:31:45 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 21:19:53 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Bezakova", "Ivona", ""], ["Galanis", "Andreas", ""], ["Goldberg", "Leslie Ann", ""], ["Stefankovic", "Daniel", ""]]}, {"id": "1807.05112", "submitter": "Jens Quedenfeld", "authors": "Susanne Albers and Jens Quedenfeld", "title": "Optimal Algorithms for Right-Sizing Data Centers - Extended Version", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electricity cost is a dominant and rapidly growing expense in data centers.\nUnfortunately, much of the consumed energy is wasted because servers are idle\nfor extended periods of time. We study a capacity management problem that\ndynamically right-sizes a data center, matching the number of active servers\nwith the varying demand for computing capacity. We resort to a data-center\noptimization problem introduced by Lin, Wierman, Andrew and Thereska that, over\na time horizon, minimizes a combined objective function consisting of operating\ncost, modeled by a sequence of convex functions, and server switching cost. All\nprior work addresses a continuous setting in which the number of active\nservers, at any time, may take a fractional value.\n  In this paper, we investigate for the first time the discrete data-center\noptimization problem where the number of active servers, at any time, must be\ninteger valued. Thereby we seek truly feasible solutions. First, we show that\nthe offline problem can be solved in polynomial time. Our algorithm relies on a\nnew, yet intuitive graph theoretic model of the optimization problem and\nperforms binary search in a layered graph. Second, we study the online problem\nand extend the algorithm Lazy Capacity Provisioning (LCP) by Lin et al. to the\ndiscrete setting. We prove that LCP is 3-competitive. Moreover, we show that no\ndeterministic online algorithm can achieve a competitive ratio smaller than 3.\nWe develop a randomized online algorithm that is 2-competitive against an\noblivious adversary and prove that 2 is a lower bound for the competitive ratio\nof randomized online algorithms.\n  Finally, we address the continuous setting and give a lower bound of 2 on the\nbest competitiveness of online algorithms. All lower bounds mentioned above\nalso holds in a problem variant with more restricted operating cost functions,\nintroduced by Lin et al.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 14:48:57 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Albers", "Susanne", ""], ["Quedenfeld", "Jens", ""]]}, {"id": "1807.05135", "submitter": "Jelani Nelson", "authors": "Jelani Nelson, Huacheng Yu", "title": "Optimal Lower Bounds for Distributed and Streaming Spanning Forest\n  Computation", "comments": "v3: corrected another error in the proof of Lemma 3 and slightly\n  changed statement as well as Lemma 5 to fit new statement; again final\n  results are unchanged; v2: the proof of Lemma 3 in version 1 was incorrect,\n  and we have replaced it with a slightly different statement, as well as\n  modifying Lemma 5 to fit in with our new Lemma 3 -- our final results are\n  unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show optimal lower bounds for spanning forest computation in two different\nmodels:\n  * One wants a data structure for fully dynamic spanning forest in which\nupdates can insert or delete edges amongst a base set of $n$ vertices. The sole\nallowed query asks for a spanning forest, which the data structure should\nsuccessfully answer with some given (potentially small) constant probability\n$\\epsilon>0$. We prove that any such data structure must use $\\Omega(n\\log^3\nn)$ bits of memory.\n  * There is a referee and $n$ vertices in a network sharing public randomness,\nand each vertex knows only its neighborhood; the referee receives no input. The\nvertices each send a message to the referee who then computes a spanning forest\nof the graph with constant probability $\\epsilon>0$. We prove the average\nmessage length must be $\\Omega(\\log^3 n)$ bits.\n  Both our lower bounds are optimal, with matching upper bounds provided by the\nAGM sketch [AGM12] (which even succeeds with probability $1 -\n1/\\mathrm{poly}(n)$). Furthermore, for the first setting we show optimal lower\nbounds even for low failure probability $\\delta$, as long as $\\delta >\n2^{-n^{1-\\epsilon}}$.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:26:10 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 19:34:46 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 19:22:34 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Nelson", "Jelani", ""], ["Yu", "Huacheng", ""]]}, {"id": "1807.05169", "submitter": "Maksims Dimitrijevs", "authors": "Maksims Dimitrijevs, Abuzer Yakary{\\i}lmaz", "title": "Postselecting probabilistic finite state recognizers and verifiers", "comments": "18 pages. Accepted to NCMA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the computational and verification power of\nbounded-error postselecting realtime probabilistic finite state automata\n(PostPFAs). We show that PostPFAs using rational-valued transitions can do\ndifferent variants of equality checks and they can verify some nonregular unary\nlanguages. Then, we allow them to use real-valued transitions (magic-coins) and\nshow that they can recognize uncountably many binary languages by help of a\ncounter and verify uncountably many unary languages by help of a prover. We\nalso present some corollaries on probabilistic counter automata.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 16:37:13 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Dimitrijevs", "Maksims", ""], ["Yakary\u0131lmaz", "Abuzer", ""]]}, {"id": "1807.05194", "submitter": "Joshua Brakensiek", "authors": "Joshua Brakensiek and Venkatesan Guruswami", "title": "An Algorithmic Blend of LPs and Ring Equations for Promise CSPs", "comments": "41 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promise CSPs are a relaxation of constraint satisfaction problems where the\ngoal is to find an assignment satisfying a relaxed version of the constraints.\nSeveral well-known problems can be cast as promise CSPs including approximate\ngraph coloring, discrepancy minimization, and interesting variants of\nsatisfiability. Similar to CSPs, the tractability of promise CSPs can be tied\nto the structure of operations on the solution space called polymorphisms,\nthough in the promise world these operations are much less constrained. Under\nthe thesis that non-trivial polymorphisms govern tractability, promise CSPs\ntherefore provide a fertile ground for the discovery of novel algorithms.\n  In previous work, we classified Boolean promise CSPs when the constraint\npredicates are symmetric. In this work, we vastly generalize these algorithmic\nresults. Specifically, we show that promise CSPs that admit a family of\n\"regional-periodic\" polymorphisms are in P, assuming that determining which\nregion a point is in can be computed in polynomial time. Such polymorphisms are\nquite general and are obtained by gluing together several functions that are\nperiodic in the Hamming weights in different blocks of the input.\n  Our algorithm is based on a novel combination of linear programming and\nsolving linear systems over rings. We also abstract a framework based on\nreducing a promise CSP to a CSP over an infinite domain, solving it there, and\nthen rounding the solution to an assignment for the promise CSP instance. The\nrounding step is intimately tied to the family of polymorphisms and clarifies\nthe connection between polymorphisms and algorithms in this context. As a key\ningredient, we introduce the technique of finding a solution to a linear\nprogram with integer coefficients that lies in a different ring (such as\n$\\mathbb Z[\\sqrt{2}]$) to bypass ad-hoc adjustments for lying on a rounding\nboundary.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 17:29:50 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Brakensiek", "Joshua", ""], ["Guruswami", "Venkatesan", ""]]}, {"id": "1807.05385", "submitter": "Alejandro D\\'iaz-Caro", "authors": "Alejandro D\\'iaz-Caro and Marcos Villagra", "title": "Classically Time-Controlled Quantum Automata: Definition and Properties", "comments": "Long revisited version of LNCS 11324:266-278, 2018 (TPNC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce classically time-controlled quantum automata or\nCTQA, which is a reasonable modification of Moore-Crutchfield quantum finite\nautomata that uses time-dependent evolution and a \"scheduler\" defining how long\neach Hamiltonian will run. Surprisingly enough, time-dependent evolution\nprovides a significant change in the computational power of quantum automata\nwith respect to a discrete quantum model. Indeed, we show that if a scheduler\nis not computationally restricted, then a CTQA can decide the Halting problem.\nIn order to unearth the computational capabilities of CTQAs we study the case\nof a computationally restricted scheduler. In particular we showed that\ndepending on the type of restriction imposed on the scheduler, a CTQA can (i)\nrecognize non-regular languages with cut-point, even in the presence of\nKarp-Lipton advice, and (ii) recognize non-regular languages with\nbounded-error. Furthermore, we study the closure of concatenation and union of\nlanguages by introducing a new model of Moore-Crutchfield quantum finite\nautomata with a rotating tape head. CTQA presents itself as a new model of\ncomputation that provides a different approach to a formal study of \"classical\ncontrol, quantum data\" schemes in quantum computing.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 11:57:37 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 18:49:31 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 00:05:00 GMT"}, {"version": "v4", "created": "Sun, 3 May 2020 14:22:21 GMT"}, {"version": "v5", "created": "Thu, 1 Oct 2020 22:52:05 GMT"}, {"version": "v6", "created": "Fri, 18 Dec 2020 17:25:26 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["D\u00edaz-Caro", "Alejandro", ""], ["Villagra", "Marcos", ""]]}, {"id": "1807.05665", "submitter": "Charles Carlson", "authors": "Ali Bibak (1), Charles Carlson (2), Karthekeyan Chandrasekaran (1)\n  ((1) University of Illinois Urbana-Champaign, (2) University of Colorado\n  Boulder)", "title": "Improving the smoothed complexity of FLIP for max cut problems", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding locally optimal solutions for max-cut and max-$k$-cut are well-known\nPLS-complete problems. An instinctive approach to finding such a locally\noptimum solution is the FLIP method. Even though FLIP requires exponential time\nin worst-case instances, it tends to terminate quickly in practical instances.\nTo explain this discrepancy, the run-time of FLIP has been studied in the\nsmoothed complexity framework. Etscheid and R\\\"{o}glin showed that the smoothed\ncomplexity of FLIP for max-cut in arbitrary graphs is quasi-polynomial. Angel,\nBubeck, Peres, and Wei showed that the smoothed complexity of FLIP for max-cut\nin complete graphs is $O(\\phi^5n^{15.1})$, where $\\phi$ is an upper bound on\nthe random edge-weight density and $n$ is the number of vertices in the input\ngraph.\n  While Angel et al.'s result showed the first polynomial smoothed complexity,\nthey also conjectured that their run-time bound is far from optimal. In this\nwork, we make substantial progress towards improving the run-time bound. We\nprove that the smoothed complexity of FLIP in complete graphs is $O(\\phi\nn^{7.83})$. Our results are based on a carefully chosen matrix whose rank\ncaptures the run-time of the method along with improved rank bounds for this\nmatrix and an improved union bound based on this matrix. In addition, our\ntechniques provide a general framework for analyzing FLIP in the smoothed\nframework. We illustrate this general framework by showing that the smoothed\ncomplexity of FLIP for max-$3$-cut in complete graphs is polynomial and for\nmax-$k$-cut in arbitrary graphs is quasi-polynomial. We believe that our\ntechniques should also be of interest towards addressing the smoothed\ncomplexity of FLIP for max-$k$-cut in complete graphs for larger constants $k$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 03:05:41 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Bibak", "Ali", ""], ["Carlson", "Charles", ""], ["Chandrasekaran", "Karthekeyan", ""]]}, {"id": "1807.05777", "submitter": "Peter Chini", "authors": "Peter Chini, Rehab Massoud, Roland Meyer, Prakash Saivasan", "title": "Fast Witness Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the witness-counting problem: given a set of vectors $V$ in the\n$d$-dimensional vector space over $\\mathbb{F}_2$, a target vector $t$, and an\ninteger $k$, count all ways to sum-up exactly $k$ different vectors from $V$ to\nreach $t$. The problem is well-known in coding theory and received considerable\nattention in complexity theory. Recently, it appeared in the context of\nhardware monitoring.\n  Our contribution is an algorithm for witness counting that is optimal in the\nsense of fine-grained complexity. It runs in time $\\mathcal{O}^*(2^d)$ with\nonly a logarithmic dependence on $m=|V|$. The algorithm makes use of the\nWalsh-Hadamard transform to compute convolutions over $\\mathbb{F}_2^d$. The\ntransform, however, overcounts the solutions. Inspired by the\ninclusion-exclusion principle, we introduce correction terms. The correction\nleads to a recurrence that we show how to solve efficiently. The correction\nterms are obtained from equivalence relations over $\\mathbb{F}_2^d$.\n  We complement our upper bound with two lower bounds on the problem. The first\nrelies on $\\# ETH$ and prohibits an $2^{o(d)}$-time algorithm. The second bound\nstates the non-existence of a polynomial kernel for the decision version of the\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 10:39:34 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Chini", "Peter", ""], ["Massoud", "Rehab", ""], ["Meyer", "Roland", ""], ["Saivasan", "Prakash", ""]]}, {"id": "1807.06101", "submitter": "Frank Ban", "authors": "Frank Ban, Vijay Bhattiprolu, Karl Bringmann, Pavel Kolev, Euiwoong\n  Lee, David P. Woodruff", "title": "A PTAS for $\\ell_p$-Low Rank Approximation", "comments": "Accepted at SODA'19, 65 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of recent works have studied algorithms for entrywise $\\ell_p$-low\nrank approximation, namely, algorithms which given an $n \\times d$ matrix $A$\n(with $n \\geq d$), output a rank-$k$ matrix $B$ minimizing\n$\\|A-B\\|_p^p=\\sum_{i,j}|A_{i,j}-B_{i,j}|^p$ when $p > 0$; and\n$\\|A-B\\|_0=\\sum_{i,j}[A_{i,j}\\neq B_{i,j}]$ for $p=0$.\n  On the algorithmic side, for $p \\in (0,2)$, we give the first\n$(1+\\epsilon)$-approximation algorithm running in time\n$n^{\\text{poly}(k/\\epsilon)}$. Further, for $p = 0$, we give the first\nalmost-linear time approximation scheme for what we call the Generalized Binary\n$\\ell_0$-Rank-$k$ problem. Our algorithm computes $(1+\\epsilon)$-approximation\nin time $(1/\\epsilon)^{2^{O(k)}/\\epsilon^{2}} \\cdot nd^{1+o(1)}$.\n  On the hardness of approximation side, for $p \\in (1,2)$, assuming the Small\nSet Expansion Hypothesis and the Exponential Time Hypothesis (ETH), we show\nthat there exists $\\delta := \\delta(\\alpha) > 0$ such that the entrywise\n$\\ell_p$-Rank-$k$ problem has no $\\alpha$-approximation algorithm running in\ntime $2^{k^{\\delta}}$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 20:48:13 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 18:12:11 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 00:11:16 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ban", "Frank", ""], ["Bhattiprolu", "Vijay", ""], ["Bringmann", "Karl", ""], ["Kolev", "Pavel", ""], ["Lee", "Euiwoong", ""], ["Woodruff", "David P.", ""]]}, {"id": "1807.06256", "submitter": "Robin Kothari", "authors": "Shalev Ben-David, Adam Bouland, Ankit Garg, Robin Kothari", "title": "Classical lower bounds from quantum upper bounds", "comments": "46 pages; to appear at FOCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove lower bounds on complexity measures, such as the approximate degree\nof a Boolean function and the approximate rank of a Boolean matrix, using\nquantum arguments. We prove these lower bounds using a quantum query algorithm\nfor the combinatorial group testing problem.\n  We show that for any function f, the approximate degree of computing the OR\nof n copies of f is Omega(sqrt{n}) times the approximate degree of f, which is\noptimal. No such general result was known prior to our work, and even the lower\nbound for the OR of ANDs function was only resolved in 2013.\n  We then prove an analogous result in communication complexity, showing that\nthe logarithm of the approximate rank (or more precisely, the approximate\ngamma_2 norm) of F: X x Y -> {0,1} grows by a factor of Omega~(sqrt{n}) when we\ntake the OR of n copies of F, which is also essentially optimal. As a\ncorollary, we give a new proof of Razborov's celebrated Omega(sqrt{n}) lower\nbound on the quantum communication complexity of the disjointness problem.\n  Finally, we generalize both these results from composition with the OR\nfunction to composition with arbitrary symmetric functions, yielding nearly\noptimal lower bounds in this setting as well.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 07:12:45 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ben-David", "Shalev", ""], ["Bouland", "Adam", ""], ["Garg", "Ankit", ""], ["Kothari", "Robin", ""]]}, {"id": "1807.06323", "submitter": "Anamay Tengse", "authors": "Mrinal Kumar and Ramprasad Saptharishi and Anamay Tengse", "title": "Near-optimal Bootstrapping of Hitting Sets for Algebraic Models", "comments": "The main result has been strengthened significantly, compared to the\n  older version of the paper. Additionally, the stronger theorem now holds even\n  for subclasses of algebraic circuits, such as algebraic formulas and\n  algebraic branching programs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The classical lemma of Ore-DeMillo-Lipton-Schwartz-Zippel\n[Ore22,DL78,Zip79,Sch80] states that any nonzero polynomial $f(x_1,\\ldots,\nx_n)$ of degree at most $s$ will evaluate to a nonzero value at some point on a\ngrid $S^n \\subseteq \\mathbb{F}^n$ with $|S| > s$. Thus, there is an explicit\nhitting set for all $n$-variate degree $s$, size $s$ algebraic circuits of size\n$(s+1)^n$.\n  In this paper, we prove the following results:\n  - Let $\\epsilon > 0$ be a constant. For a sufficiently large constant $n$ and\nall $s > n$, if we have an explicit hitting set of size $(s+1)^{n-\\epsilon}$\nfor the class of $n$-variate degree $s$ polynomials that are computable by\nalgebraic circuits of size $s$, then for all $s$, we have an explicit hitting\nset of size $s^{\\exp \\circ \\exp (O(\\log^\\ast s))}$ for $s$-variate circuits of\ndegree $s$ and size $s$. That is, if we can obtain a barely non-trivial\nexponent compared to the trivial $(s+1)^{n}$ sized hitting set even for\nconstant variate circuits, we can get an almost complete derandomization of\nPIT.\n  - The above result holds when \"circuits\" are replaced by \"formulas\" or\n\"algebraic branching programs\".\n  This extends a recent surprising result of Agrawal, Ghosh and Saxena [AGS18]\nwho proved the same conclusion for the class of algebraic circuits, if the\nhypothesis provided a hitting set of size at most $(s^{n^{0.5 - \\delta}})$\n(where $\\delta>0$ is any constant). Hence, our work significantly weakens the\nhypothesis of Agrawal, Ghosh and Saxena to only require a slightly non-trivial\nsaving over the trivial hitting set, and also presents the first such result\nfor algebraic branching programs and formulas.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 10:31:46 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 19:16:15 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Kumar", "Mrinal", ""], ["Saptharishi", "Ramprasad", ""], ["Tengse", "Anamay", ""]]}, {"id": "1807.06397", "submitter": "Ronald de Haan", "authors": "Ronald de Haan", "title": "Expressing Linear Orders Requires Exponential-Size DNNFs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any DNNF circuit that expresses the set of linear orders over a\nset of $n$ candidates must be of size $2^{\\Omega(n)}$. Moreover, we show that\nthere exist DNNF circuits of size $2^{O(n)}$ expressing linear orders over $n$\ncandidates.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 13:02:55 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 15:45:40 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 12:15:48 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["de Haan", "Ronald", ""]]}, {"id": "1807.06456", "submitter": "Yassine Hamoudi", "authors": "Yassine Hamoudi and Fr\\'ed\\'eric Magniez", "title": "Quantum Chebyshev's Inequality and Applications", "comments": "27 pages; v3: better presentation, lower bound in Theorem 4.3 is new", "journal-ref": "Proceedings of the 46th International Colloquium on Automata,\n  Languages, and Programming (ICALP), volume 132 of LIPIcs, pages 69:1-99:16,\n  2019", "doi": "10.4230/LIPIcs.ICALP.2019.69", "report-no": null, "categories": "quant-ph cs.CC cs.DS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide new quantum algorithms with polynomial speed-up for\na range of problems for which no such results were known, or we improve\nprevious algorithms. First, we consider the approximation of the frequency\nmoments $F_k$ of order $k \\geq 3$ in the multi-pass streaming model with\nupdates (turnstile model). We design a $P$-pass quantum streaming algorithm\nwith memory $M$ satisfying a tradeoff of $P^2 M = \\tilde{O}(n^{1-2/k})$,\nwhereas the best classical algorithm requires $P M = \\Theta(n^{1-2/k})$. Then,\nwe study the problem of estimating the number $m$ of edges and the number $t$\nof triangles given query access to an $n$-vertex graph. We describe optimal\nquantum algorithms that perform $\\tilde{O}(\\sqrt{n}/m^{1/4})$ and\n$\\tilde{O}(\\sqrt{n}/t^{1/6} + m^{3/4}/\\sqrt{t})$ queries respectively. This is\na quadratic speed-up compared to the classical complexity of these problems.\n  For this purpose we develop a new quantum paradigm that we call Quantum\nChebyshev's inequality. Namely we demonstrate that, in a certain model of\nquantum sampling, one can approximate with relative error the mean of any\nrandom variable with a number of quantum samples that is linear in the ratio of\nthe square root of the variance to the mean. Classically the dependency is\nquadratic. Our algorithm subsumes a previous result of Montanaro [Mon15]. This\nnew paradigm is based on a refinement of the Amplitude Estimation algorithm of\nBrassard et al. [BHMT02] and of previous quantum algorithms for the mean\nestimation problem. We show that this speed-up is optimal, and we identify\nanother common model of quantum sampling where it cannot be obtained. For our\napplications, we also adapt the variable-time amplitude amplification technique\nof Ambainis [Amb10] into a variable-time amplitude estimation algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 14:09:38 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 09:59:01 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 18:09:46 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hamoudi", "Yassine", ""], ["Magniez", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1807.06469", "submitter": "Jiehua Chen", "authors": "Jiehua Chen and Danny Hermelin and Manuel Sorge", "title": "On Computing Centroids According to the $p$-Norms of Hamming Distance\n  Vectors", "comments": "To appear at ESA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the $p$-Norm Hamming Centroid problem which asks to\ndetermine whether some given binary strings have a centroid with a bound on the\n$p$-norm of its Hamming distances to the strings. Specifically, given a set of\nstrings $S$ and a real $k$, we consider the problem of determining whether\nthere exists a string $s^*$ with $\\big(\\sum_{s \\in S}d^p(s^*,s)\\big)^{1/p} \\leq\nk$, where $d(,)$ denotes the Hamming distance metric. This problem has\nimportant applications in data clustering, and is a generalization of the\nwell-known polynomial-time solvable \\textsc{Consensus String} $(p=1)$ problem,\nas well as the NP-hard \\textsc{Closest String} $(p=\\infty)$ problem.\n  Our main result shows that the problem is NP-hard for all fixed rational $p >\n1$, closing the gap for all rational values of $p$ between $1$ and $\\infty$.\nUnder standard complexity assumptions the reduction also implies that the\nproblem has no $2^{o(n+m)}$-time or $2^{o(k^{\\frac{p}{(p+1)}})}$-time\nalgorithm, where $m$ denotes the number of input strings and $n$ denotes the\nlength of each string, for any fixed $p > 1$. Both running time lower bounds\nare tight. In particular, we provide a\n$2^{k^{\\frac{p}{(p+1)}+\\varepsilon}}$-time algorithm for each fixed\n$\\varepsilon > 0$. In the last part of the paper, we complement our hardness\nresult by presenting a fixed-parameter algorithm and a factor-$2$ approximation\nalgorithm for the problem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 14:30:03 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 21:08:27 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 19:31:31 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Chen", "Jiehua", ""], ["Hermelin", "Danny", ""], ["Sorge", "Manuel", ""]]}, {"id": "1807.06933", "submitter": "Sandor Kisfaludi-Bak", "authors": "Mark de Berg, Hans L. Bodlaender, S\\'andor Kisfaludi-Bak, Sudeshna\n  Kolay", "title": "An ETH-Tight Exact Algorithm for Euclidean TSP", "comments": "To appear in FOCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study exact algorithms for {\\sc Euclidean TSP} in $\\mathbb{R}^d$. In the\nearly 1990s algorithms with $n^{O(\\sqrt{n})}$ running time were presented for\nthe planar case, and some years later an algorithm with $n^{O(n^{1-1/d})}$\nrunning time was presented for any $d\\geq 2$. Despite significant interest in\nsubexponential exact algorithms over the past decade, there has been no\nprogress on {\\sc Euclidean TSP}, except for a lower bound stating that the\nproblem admits no $2^{O(n^{1-1/d-\\epsilon})}$ algorithm unless ETH fails. Up to\nconstant factors in the exponent, we settle the complexity of {\\sc Euclidean\nTSP} by giving a $2^{O(n^{1-1/d})}$ algorithm and by showing that a\n$2^{o(n^{1-1/d})}$ algorithm does not exist unless ETH fails.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:52:28 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 09:48:44 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["de Berg", "Mark", ""], ["Bodlaender", "Hans L.", ""], ["Kisfaludi-Bak", "S\u00e1ndor", ""], ["Kolay", "Sudeshna", ""]]}, {"id": "1807.06965", "submitter": "Kitty Meeks", "authors": "Kitty Meeks and Fiona Skerman", "title": "The parameterised complexity of computing the maximum modularity of a\n  graph", "comments": "Author final version, accepted to Algorithmica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum modularity of a graph is a parameter widely used to describe the\nlevel of clustering or community structure in a network. Determining the\nmaximum modularity of a graph is known to be NP-complete in general, and in\npractice a range of heuristics are used to construct partitions of the\nvertex-set which give lower bounds on the maximum modularity but without any\nguarantee on how close these bounds are to the true maximum. In this paper we\ninvestigate the parameterised complexity of determining the maximum modularity\nwith respect to various standard structural parameterisations of the input\ngraph G. We show that the problem belongs to FPT when parameterised by the size\nof a minimum vertex cover for G, and is solvable in polynomial time whenever\nthe treewidth or max leaf number of G is bounded by some fixed constant; we\nalso obtain an FPT algorithm, parameterised by treewidth, to compute any\nconstant-factor approximation to the maximum modularity. On the other hand we\nshow that the problem is W[1]-hard (and hence unlikely to admit an FPT\nalgorithm) when parameterised simultaneously by pathwidth and the size of a\nminimum feedback vertex set.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 14:25:30 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 08:33:18 GMT"}, {"version": "v3", "created": "Wed, 22 Aug 2018 12:43:03 GMT"}, {"version": "v4", "created": "Fri, 26 Oct 2018 10:58:01 GMT"}, {"version": "v5", "created": "Tue, 29 Oct 2019 15:53:26 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Meeks", "Kitty", ""], ["Skerman", "Fiona", ""]]}, {"id": "1807.07156", "submitter": "Fahad Panolan", "authors": "Fedor V. Fomin, Petr A. Golovach, Daniel Lokshtanov, Fahad Panolan,\n  Saket Saurabh", "title": "Approximation Schemes for Low-Rank Binary Matrix Approximation Problems", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a randomized linear time approximation scheme for a generic\nproblem about clustering of binary vectors subject to additional constrains.\nThe new constrained clustering problem encompasses a number of problems and by\nsolving it, we obtain the first linear time-approximation schemes for a number\nof well-studied fundamental problems concerning clustering of binary vectors\nand low-rank approximation of binary matrices. Among the problems solvable by\nour approach are \\textsc{Low GF(2)-Rank Approximation}, \\textsc{Low\nBoolean-Rank Approximation}, and various versions of \\textsc{Binary\nClustering}. For example, for \\textsc{Low GF(2)-Rank Approximation} problem,\nwhere for an $m\\times n$ binary matrix $A$ and integer $r>0$, we seek for a\nbinary matrix $B$ of $GF_2$ rank at most $r$ such that $\\ell_0$ norm of matrix\n$A-B$ is minimum, our algorithm, for any $\\epsilon>0$ in time $\nf(r,\\epsilon)\\cdot n\\cdot m$, where $f$ is some computable function, outputs a\n$(1+\\epsilon)$-approximate solution with probability at least\n$(1-\\frac{1}{e})$. Our approximation algorithms substantially improve the\nrunning times and approximation factors of previous works. We also give\n(deterministic) PTASes for these problems running in time\n$n^{f(r)\\frac{1}{\\epsilon^2}\\log \\frac{1}{\\epsilon}}$, where $f$ is some\nfunction depending on the problem. Our algorithm for the constrained clustering\nproblem is based on a novel sampling lemma, which is interesting in its own.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 21:11:35 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Lokshtanov", "Daniel", ""], ["Panolan", "Fahad", ""], ["Saurabh", "Saket", ""]]}, {"id": "1807.07762", "submitter": "Hartmut Klauck", "authors": "Hartmut Klauck and Debbie Lim", "title": "The Power of One Clean Qubit in Communication Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study quantum communication protocols, in which the players' storage\nstarts out in a state where one qubit is in a pure state, and all other qubits\nare totally mixed (i.e. in a random state), and no other storage is available\n(for messages or internal computations). This restriction on the available\nquantum memory has been studied extensively in the model of quantum circuits,\nand it is known that classically simulating quantum circuits operating on such\nmemory is hard when the additive error of the simulation is exponentially small\n(in the input length), under the assumption that the polynomial hierarchy does\nnot collapse.\n  We study this setting in communication complexity. The goal is to consider\nlarger additive error for simulation-hardness results, and to not use unproven\nassumptions.\n  We define a complexity measure for this model that takes into account that\nstandard error reduction techniques do not work here. We define a clocked and a\nsemi-unclocked model, and describe efficient simulations between those.\n  We characterize a one-way communication version of the model in terms of\nweakly unbounded error communication complexity.\n  Our main result is that there is a quantum protocol using one clean qubit\nonly and using $O(\\log n)$ qubits of communication, such that any classical\nprotocol simulating the acceptance behaviour of the quantum protocol within\nadditive error $1/poly(n)$ needs communication $\\Omega(n)$.\n  We also describe a candidate problem, for which an exponential gap between\nthe one-clean-qubit communication complexity and the randomized complexity is\nlikely to hold, and hence a classical simulation of the one-clean-qubit model\nwithin {\\em constant} additive error might be hard in communication complexity.\nWe describe a geometrical conjecture that implies the lower bound.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 10:04:12 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 08:40:42 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Klauck", "Hartmut", ""], ["Lim", "Debbie", ""]]}, {"id": "1807.07785", "submitter": "Nicholas Coxon", "authors": "Nicholas Coxon (GRACE)", "title": "Fast transforms over finite fields of characteristic two", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An additive fast Fourier transform over a finite field of characteristic two\nefficiently evaluates polynomials at every element of an $\\mathbb{F}_2$-linear\nsubspace of the field. We view these transforms as performing a change of basis\nfrom the monomial basis to the associated Lagrange basis, and consider the\nproblem of performing the various conversions between these two bases, the\nassociated Newton basis, and the '' novel '' basis of Lin, Chung and Han (FOCS\n2014). Existing algorithms are divided between two families, those designed for\narbitrary subspaces and more efficient algorithms designed for specially\nconstructed subspaces of fields with degree equal to a power of two. We\ngeneralise techniques from both families to provide new conversion algorithms\nthat may be applied to arbitrary subspaces, but which benefit equally from the\nspecially constructed subspaces. We then construct subspaces of fields with\nsmooth degree for which our algorithms provide better performance than existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 10:51:22 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Coxon", "Nicholas", "", "GRACE"]]}, {"id": "1807.08579", "submitter": "Xin Han", "authors": "Xin Han, Liang Zhao, Zhishan Guo, Xingwu Liu", "title": "An Improved Speedup Factor for Sporadic Tasks with Constrained Deadlines\n  under Dynamic Priority Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schedulability is a fundamental problem in real-time scheduling, but it has\nto be approximated due to the intrinsic computational hardness. As the most\npopular algorithm for deciding schedulability on multiprocess platforms, the\nspeedup factor of partitioned-EDF is challenging to analyze and is far from\nbeen determined. Partitioned-EDF was first proposed in 2005 by Barush and\nFisher [1], and was shown to have a speedup factor at most 3-1/m, meaning that\nif the input of sporadic tasks is feasible on m processors with speed one,\npartitioned-EDF will always return succeeded on m processors with speed 3-1/m.\nIn 2011, this upper bound was improved to 2.6322-1/m by Chen and Chakraborty\n[2], and no more improvements have appeared ever since then. In this paper, we\ndevelop a novel method to discretize and regularize sporadic tasks, which\nenables us to improve, in the case of constrained deadlines, the speedup factor\nof partitioned-EDF to 2.5556-1/m, very close to the asymptotic lower bound 2.5\nin [2].\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 07:46:32 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Han", "Xin", ""], ["Zhao", "Liang", ""], ["Guo", "Zhishan", ""], ["Liu", "Xingwu", ""]]}, {"id": "1807.08630", "submitter": "Bastian Prasse", "authors": "Bastian Prasse and Piet Van Mieghem", "title": "Maximum-Likelihood Network Reconstruction for SIS Processes is NP-Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knowledge of the network topology is imperative to precisely describing\nthe viral dynamics of an SIS epidemic process. In scenarios for which the\nnetwork topology is unknown, one resorts to reconstructing the network from\nobserving the viral state trace. This work focusses on the impact of the viral\nstate observations on the computational complexity of the resulting network\nreconstruction problem. We propose a novel method of constructing a specific\nclass of viral state traces from which the inference of the presence or absence\nof links is either easy or difficult. In particular, we use this construction\nto prove that the maximum-likelihood SIS network reconstruction is NP-hard. The\nNP-hardness holds for any adjacency matrix of a graph which is connected.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 14:02:38 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Prasse", "Bastian", ""], ["Van Mieghem", "Piet", ""]]}, {"id": "1807.08949", "submitter": "Jiehua Chen", "authors": "Jiehua Chen and Danny Hermelin and Manuel Sorge", "title": "A Note on Clustering Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the clustering aggregation problem in which we are given a set of\nclusterings and want to find an aggregated clustering which minimizes the sum\nof mismatches to the input clusterings. In the binary case (each clustering is\na bipartition) this problem was known to be NP-hard under Turing reduction. We\nstrengthen this result by providing a polynomial-time many-one reduction. Our\nresult also implies that no $2^{o(n)} \\cdot |I|^{O(1)}$-time algorithm exists\nfor any clustering instance $I$ with $n$ elements, unless the Exponential Time\nHypothesis fails. On the positive side, we show that the problem is\nfixed-parameter tractable with respect to the number of input clusterings.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 08:15:08 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Chen", "Jiehua", ""], ["Hermelin", "Danny", ""], ["Sorge", "Manuel", ""]]}, {"id": "1807.08970", "submitter": "Vedran Dunjko", "authors": "Vedran Dunjko, Yimin Ge, J. Ignacio Cirac", "title": "Computational speedups using small quantum devices", "comments": "5+12 pages", "journal-ref": "Phys. Rev. Lett. 121, 250501 (2018)", "doi": "10.1103/PhysRevLett.121.250501", "report-no": null, "categories": "quant-ph cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we have a small quantum computer with only M qubits. Can such a\ndevice genuinely speed up certain algorithms, even when the problem size is\nmuch larger than M? Here we answer this question to the affirmative. We present\na hybrid quantum-classical algorithm to solve 3SAT problems involving n>>M\nvariables that significantly speeds up its fully classical counterpart. This\nquestion may be relevant in view of the current quest to build small quantum\ncomputers.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 09:01:50 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 07:00:34 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Dunjko", "Vedran", ""], ["Ge", "Yimin", ""], ["Cirac", "J. Ignacio", ""]]}, {"id": "1807.09675", "submitter": "Javad Doliskani", "authors": "Javad Doliskani", "title": "Toward an Optimal Quantum Algorithm for Polynomial Factorization over\n  Finite Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC math.NT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a randomized quantum algorithm for polynomial factorization over\nfinite fields. For polynomials of degree $n$ over a finite field $\\F_q$, the\naverage-case complexity of our algorithm is an expected $O(n^{1 + o(1)} \\log^{2\n+ o(1)}q)$ bit operations. Only for a negligible subset of polynomials of\ndegree $n$ our algorithm has a higher complexity of $O(n^{4 / 3 + o(1)} \\log^{2\n+ o(1)}q)$ bit operations. This breaks the classical $3/2$-exponent barrier for\npolynomial factorization over finite fields \\cite{guo2016alg}.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 15:49:49 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Doliskani", "Javad", ""]]}, {"id": "1807.10464", "submitter": "Aurelien Hazan", "authors": "Aur\\'elien Hazan (LISSI)", "title": "A maximum entropy network reconstruction of macroeconomic models", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2018.12.020", "report-no": null, "categories": "econ.GN cs.CC physics.data-an physics.soc-ph q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article the problem of reconstructing the pattern of connection\nbetween agents from partial empirical data in a macro-economic model is\naddressed, given a set of behavioral equations. This systemic point of view\nputs the focus on distributional and network effects, rather than\ntime-dependence. Using the theory of complex networks we compare several models\nto reconstruct both the topology and the flows of money of the different types\nof monetary transactions, while imposing a series of constraints related to\nnational accounts, and to empirical network sparsity. Some properties of\nreconstructed networks are compared with their empirical counterpart.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 07:30:19 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 15:29:42 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Hazan", "Aur\u00e9lien", "", "LISSI"]]}, {"id": "1807.10546", "submitter": "Marcin Jurdzi\\'nski", "authors": "Wojciech Czerwi\\'nski, Laure Daviaud, Nathana\\\"el Fijalkow, Marcin\n  Jurdzi\\'nski, Ranko Lazi\\'c, Pawe{\\l} Parys", "title": "Universal trees grow inside separating automata: Quasi-polynomial lower\n  bounds for parity games", "comments": "To appear in SODA 2019", "journal-ref": null, "doi": "10.1137/1.9781611975482.142", "report-no": null, "categories": "cs.FL cs.CC cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several distinct techniques have been proposed to design quasi-polynomial\nalgorithms for solving parity games since the breakthrough result of Calude,\nJain, Khoussainov, Li, and Stephan (2017): play summaries, progress measures\nand register games. We argue that all those techniques can be viewed as\ninstances of the separation approach to solving parity games, a key technical\ncomponent of which is constructing (explicitly or implicitly) an automaton that\nseparates languages of words encoding plays that are (decisively) won by either\nof the two players. Our main technical result is a quasi-polynomial lower bound\non the size of such separating automata that nearly matches the current best\nupper bounds. This forms a barrier that all existing approaches must overcome\nin the ongoing quest for a polynomial-time algorithm for solving parity games.\nThe key and fundamental concept that we introduce and study is a universal\nordered tree. The technical highlights are a quasi-polynomial lower bound on\nthe size of universal ordered trees and a proof that every separating safety\nautomaton has a universal tree hidden in its state space.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 12:05:29 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 12:02:01 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Czerwi\u0144ski", "Wojciech", ""], ["Daviaud", "Laure", ""], ["Fijalkow", "Nathana\u00ebl", ""], ["Jurdzi\u0144ski", "Marcin", ""], ["Lazi\u0107", "Ranko", ""], ["Parys", "Pawe\u0142", ""]]}, {"id": "1807.10563", "submitter": "EPTCS", "authors": "Michael Cuffaro, Philippos Papayannopoulos", "title": "Proceedings of the 9th International Workshop on Physics and Computation", "comments": null, "journal-ref": "EPTCS 273, 2018", "doi": "10.4204/EPTCS.273", "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 9th International Workshop on Physics and Computation (PC 2018) was held\nas a satellite workshop of the 17th International Conference on Unconventional\nComputation and Natural Computation (UCNC 2018) in Fontainebleau, France, which\nwas held from 25-29 June 2018. PC 2018 was an interdisciplinary meeting which\nbrought together researchers from various domains with interests in physics and\ncomputation. Research and important issues relating to the interface between\nphysics and the theories of computation, computability and information,\nincluding their application to physical systems, were presented and discussed.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 14:04:50 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Cuffaro", "Michael", ""], ["Papayannopoulos", "Philippos", ""]]}, {"id": "1807.10983", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra and Holger Spakowski", "title": "Team Diagonalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ten years ago, Gla{\\ss}er, Pavan, Selman, and Zhang [GPSZ08] proved that if P\n$\\neq$ NP, then all NP-complete sets can be simply split into two NP-complete\nsets.\n  That advance might naturally make one wonder about a quite different\npotential consequence of NP-completeness: Can the union of easy NP sets ever be\nhard? In particular, can the union of two non-NP-complete NP sets ever be\nNP-complete?\n  Amazingly, Ladner [Lad75] resolved this more than forty years ago: If P\n$\\neq$ NP, then all NP-complete sets can be simply split into two\nnon-NP-complete NP sets. Indeed, this holds even when one requires the two\nnon-NP-complete NP sets to be disjoint.\n  We present this result as a mini-tutorial. We give a relatively detailed\nproof of this result, using the same technique and idea Ladner [Lad75] invented\nand used in proving a rich collection of results that include many that are\nmore general than this result: delayed diagonalization. In particular, the\nproof presented is based on what one can call team diagonalization (or if one\nis being playful, perhaps even tag-team diagonalization): Multiple sets are\nformed separately by delayed diagonalization, yet those diagonalizations are\nmutually aware and delay some of their actions until their partner(s) have also\nsucceeded in some coordinated action.\n  We relatedly note that, as a consequence of Ladner's result, if P $\\neq$ NP,\nthere exist OptP functions f and g whose composition is NP-hard yet neither f\nnor g is NP-hard.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 23:30:29 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Hemaspaandra", "Lane A.", ""], ["Spakowski", "Holger", ""]]}, {"id": "1807.11027", "submitter": "Yuan Zhang", "authors": "Yuan Zhang", "title": "Consistent polynomial-time unseeded graph matching for Lipschitz\n  graphons", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a consistent polynomial-time method for the unseeded node matching\nproblem for networks with smooth underlying structures. Despite widely\nconjectured by the research community that the structured graph matching\nproblem to be significantly easier than its worst case counterpart, well-known\nto be NP-hard, the statistical version of the problem has stood a challenge\nthat resisted any solution both provable and polynomial-time. The closest\nexisting work requires quasi-polynomial time. Our method is based on the latest\nadvances in graphon estimation techniques and analysis on the concentration of\nempirical Wasserstein distances. Its core is a simple yet unconventional\nsampling-and-matching scheme that reduces the problem from unseeded to seeded.\nOur method allows flexible efficiencies, is convenient to analyze and\npotentially can be extended to more general settings. Our work enables a rich\nvariety of subsequent estimations and inferences.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 09:25:37 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zhang", "Yuan", ""]]}, {"id": "1807.11137", "submitter": "EPTCS", "authors": "Richard Whyman (The University of Leeds)", "title": "An Atemporal Model of Physical Complexity", "comments": "In Proceedings PC 2018, arXiv:1807.10563", "journal-ref": "EPTCS 273, 2018, pp. 39-51", "doi": "10.4204/EPTCS.273.4", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the finite first-order theory (FFOT) machine, which provides an\natemporal description of computation. We then develop a concept of complexity\nfor the FFOT machine, and prove that the class of problems decidable by a FFOT\nmachine with polynomial resources is NP intersect co-NP.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 01:30:33 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Whyman", "Richard", "", "The University of Leeds"]]}, {"id": "1807.11419", "submitter": "Tselil Schramm", "authors": "Prasad Raghavendra, Tselil Schramm, David Steurer", "title": "High-dimensional estimation via sum-of-squares proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation is the computational task of recovering a hidden parameter $x$\nassociated with a distribution $D_x$, given a measurement $y$ sampled from the\ndistribution. High dimensional estimation problems arise naturally in\nstatistics, machine learning, and complexity theory.\n  Many high dimensional estimation problems can be formulated as systems of\npolynomial equations and inequalities, and thus give rise to natural\nprobability distributions over polynomial systems. Sum-of-squares proofs\nprovide a powerful framework to reason about polynomial systems, and further\nthere exist efficient algorithms to search for low-degree sum-of-squares\nproofs.\n  Understanding and characterizing the power of sum-of-squares proofs for\nestimation problems has been a subject of intense study in recent years. On one\nhand, there is a growing body of work utilizing sum-of-squares proofs for\nrecovering solutions to polynomial systems when the system is feasible. On the\nother hand, a general technique referred to as pseudocalibration has been\ndeveloped towards showing lower bounds on the degree of sum-of-squares proofs.\nFinally, the existence of sum-of-squares refutations of a polynomial system has\nbeen shown to be intimately connected to the existence of spectral algorithms.\nIn this article we survey these developments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 16:13:57 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 00:56:07 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Raghavendra", "Prasad", ""], ["Schramm", "Tselil", ""], ["Steurer", "David", ""]]}, {"id": "1807.11518", "submitter": "Ioannis Katsikarelis", "authors": "Tesshu Hanaka, Ioannis Katsikarelis, Michael Lampis, Yota Otachi,\n  Florian Sikora", "title": "Parameterized Orientable Deletion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is $d$-orientable if its edges can be oriented so that the maximum\nin-degree of the resulting digraph is at most $d$. $d$-orientability is a\nwell-studied concept with close connections to fundamental graph-theoretic\nnotions and applications as a load balancing problem. In this paper we consider\nthe d-ORIENTABLE DELETION problem: given a graph $G=(V,E)$, delete the minimum\nnumber of vertices to make $G$ $d$-orientable. We contribute a number of\nresults that improve the state of the art on this problem. Specifically:\n  - We show that the problem is W[2]-hard and $\\log n$-inapproximable with\nrespect to $k$, the number of deleted vertices. This closes the gap in the\nproblem's approximability.\n  - We completely characterize the parameterized complexity of the problem on\nchordal graphs: it is FPT parameterized by $d+k$, but W-hard for each of the\nparameters $d,k$ separately.\n  - We show that, under the SETH, for all $d,\\epsilon$, the problem does not\nadmit a $(d+2-\\epsilon)^{tw}$, algorithm where $tw$ is the graph's treewidth,\nresolving as a special case an open problem on the complexity of PSEUDOFOREST\nDELETION.\n  - We show that the problem is W-hard parameterized by the input graph's\nclique-width. Complementing this, we provide an algorithm running in time\n$d^{O(d\\cdot cw)}$, showing that the problem is FPT by $d+cw$, and improving\nthe previously best known algorithm for this case.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 18:21:42 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 14:49:29 GMT"}, {"version": "v3", "created": "Sun, 26 Jan 2020 14:19:13 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Hanaka", "Tesshu", ""], ["Katsikarelis", "Ioannis", ""], ["Lampis", "Michael", ""], ["Otachi", "Yota", ""], ["Sikora", "Florian", ""]]}, {"id": "1807.11773", "submitter": "Saveliy Skresanov", "authors": "Saveliy V. Skresanov", "title": "Subgroups of minimal index in polynomial time", "comments": "In the second version we gave the reference to Theorem 1, since it\n  was obtained by Y. Berkovich earlier (as communcated by A. Mann), and added\n  Theorem 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a finite group and let $H$ be a proper subgroup of $G$ of minimal\nindex. By applying an old result of Y. Berkovich, we provide a polynomial\nalgorithm for computing $|G : H|$ for a permutation group $G$. Moreover, we\nfind $H$ explicitly if $G$ is given by a Cayley table. As a corollary, we get\nan algorithm for testing whether a finite permutation group acts on a tree or\nnot.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 11:55:40 GMT"}, {"version": "v2", "created": "Sat, 1 Sep 2018 11:17:11 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Skresanov", "Saveliy V.", ""]]}, {"id": "1807.11845", "submitter": "Sai Vinjanampathy", "authors": "Carlos Perez-Delgado and Sai Vinjanampathy", "title": "Quantum Correlations Can Speed Up All Classical Computation", "comments": "8 pages, 1 figure, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum algorithms that can speed up certain tasks, such as factorisation and\nunstructured search, have driven a decades-long development of quantum\ncomputers and quantum technologies. Yet, outside specialized applications,\nquantum computers are believed to offer no advantage over classical computers.\nHere, we present a method which exploits quantum effects to speed up all\npossible classical computations. This method-which we call Coherent\nParallelization (CP)-exploits quantum correlations generated by higher-order\nHamiltonians to speed up any possible classical computation by a factor that\ndepends on the classical algorithm. This factor is quadratic in the size of the\ninput for a large set of interesting problems, leading to a strong commercial\napplication in the emergent area of quantum technologies. We present important\ntheoretical consequences of CP for both quantum physics and the theory of\nalgorithmic complexity and computability, and discuss how CP can be implemented\nusing real-world systems with natural or engineered Hamiltonians.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 14:54:50 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 14:44:01 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Perez-Delgado", "Carlos", ""], ["Vinjanampathy", "Sai", ""]]}, {"id": "1807.11869", "submitter": "Hans Bodlaender", "authors": "Hans L. Bodlaender and Tom C. van der Zanden", "title": "On Exploring Temporal Graphs of Small Pathwidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Temporal Graph Exploration Problem is NP-complete, even when\nthe underlying graph has pathwidth 2 and at each time step, the current graph\nis connected.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 15:31:37 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["van der Zanden", "Tom C.", ""]]}]