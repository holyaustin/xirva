[{"id": "1601.00335", "submitter": "Hector Zenil", "authors": "Hector Zenil and J\\\"urgen Riedel", "title": "Asymptotic Intrinsic Universality and Reprogrammability by Behavioural\n  Emulation", "comments": "16 pages, 7 images. Invited contribution in Advances in\n  Unconventional Computation. A. Adamatzky (ed), Springer Verlag", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advance a Bayesian concept of 'intrinsic asymptotic universality' taking\nto its final conclusions previous conceptual and numerical work based upon a\nconcept of a reprogrammability test and an investigation of the complex\nqualitative behaviour of computer programs. Our method may quantify the trust\nand confidence of the computing capabilities of natural and classical systems,\nand quantify computers by their degree of reprogrammability. We test the method\nto provide evidence in favour of a conjecture concerning the computing\ncapabilities of Busy Beaver Turing machines as candidates for Turing\nuniversality. The method has recently been used to quantify the number of\n'intrinsically universal' cellular automata, with results that point towards\nthe pervasiveness of universality due to a widespread capacity for emulation.\nOur method represents an unconventional approach to the classical and seminal\nconcept of Turing universality, and it may be extended and applied in a broader\ncontext to natural computation, by (in something like the spirit of the Turing\ntest) observing the behaviour of a system under circumstances where formal\nproofs of universality are difficult, if not impossible to come by.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2016 20:11:06 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2016 14:24:25 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2016 17:44:14 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Zenil", "Hector", ""], ["Riedel", "J\u00fcrgen", ""]]}, {"id": "1601.00479", "submitter": "Dennis Kraft", "authors": "Susanne Albers and Dennis Kraft", "title": "Motivating Time-Inconsistent Agents: A Computational Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the computational complexity of motivating\ntime-inconsistent agents to complete long term projects. We resort to an\nelegant graph-theoretic model, introduced by Kleinberg and Oren, which consists\nof a task graph $G$ with $n$ vertices, including a source $s$ and target $t$,\nand an agent that incrementally constructs a path from $s$ to $t$ in order to\ncollect rewards. The twist is that the agent is present-biased and discounts\nfuture costs and rewards by a factor $\\beta\\in [0,1]$. Our design objective is\nto ensure that the agent reaches $t$ i.e.\\ completes the project, for as little\nreward as possible. Such graphs are called motivating. We consider two\nstrategies. First, we place a single reward $r$ at $t$ and try to guide the\nagent by removing edges from $G$. We prove that deciding the existence of such\nmotivating subgraphs is NP-complete if $r$ is fixed. More importantly, we\ngeneralize our reduction to a hardness of approximation result for computing\nthe minimum $r$ that admits a motivating subgraph. In particular, we show that\nno polynomial-time approximation to within a ratio of $\\sqrt{n}/4$ or less is\npossible, unless ${\\rm P}={\\rm NP}$. Furthermore, we develop a\n$(1+\\sqrt{n})$-approximation algorithm and thus settle the approximability of\ncomputing motivating subgraphs. Secondly, we study motivating reward\nconfigurations, where non-negative rewards $r(v)$ may be placed on arbitrary\nvertices $v$ of $G$. The agent only receives the rewards of visited vertices.\nAgain we give an NP-completeness result for deciding the existence of a\nmotivating reward configuration within a fixed budget $b$. This result even\nholds if $b=0$, which in turn implies that no efficient approximation of a\nminimum $b$ within a ration grater or equal to $1$ is possible, unless ${\\rm\nP}={\\rm NP}$.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 12:27:54 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Albers", "Susanne", ""], ["Kraft", "Dennis", ""]]}, {"id": "1601.00691", "submitter": "Ohad Asor", "authors": "Ohad Asor", "title": "Spectral and Modular Analysis of #P Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present various analytic and number theoretic results concerning the #SAT\nproblem as reflected when reduced into a #PART problem. As an application we\npropose a heuristic to probabilistically estimate the solution of #SAT\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 22:35:37 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 03:44:13 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Asor", "Ohad", ""]]}, {"id": "1601.01067", "submitter": "Xiao-Shan Gao", "authors": "Rui-Juan Jing, Chun-Ming Yuan, Xiao-Shan Gao", "title": "A Polynomial-time Algorithm to Compute Generalized Hermite Normal Form\n  of Matrices over Z[x]", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a polynomial-time algorithm is given to compute the\ngeneralized Hermite normal form for a matrix F over Z[x], or equivalently, the\nreduced Groebner basis of the Z[x]-module generated by the column vectors of F.\nThe algorithm is also shown to be practically more efficient than existing\nalgorithms. The algorithm is based on three key ingredients. First, an F4 style\nalgorithm to compute the Groebner basis is adopted, where a novel prolongation\nis designed such that the coefficient matrices under consideration have\npolynomial sizes. Second, fast algorithms to compute Hermite normal forms of\nmatrices over Z are used. Third, the complexity of the algorithm are guaranteed\nby a nice estimation for the degree and height bounds of the polynomials in the\ngeneralized Hermite normal form.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 03:32:37 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2016 10:43:53 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Jing", "Rui-Juan", ""], ["Yuan", "Chun-Ming", ""], ["Gao", "Xiao-Shan", ""]]}, {"id": "1601.01118", "submitter": "Tomoyuki Yamakami", "authors": "Tomoyuki Yamakami", "title": "Uniform-Circuit and Logarithmic-Space Approximations of Refined\n  Combinatorial Optimization Problems", "comments": "(37 pages, A4, 10pt, 1 figure) This is a complete version of a\n  preliminary report, which appeared in the Proceedings of the 7th\n  International Conference on Combinatorial Optimization and Applications\n  (COCOA 2013), Chengdu, China, December 12--14, 2013, Lecture Notes in\n  Computer Science, Springer-Verlag, vol.8287, pp.318--329, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant progress has been made in the past three decades over the study\nof combinatorial NP optimization problems and their associated optimization and\napproximate classes, such as NPO, PO, APX (or APXP), and PTAS. Unfortunately, a\ncollection of problems that are simply placed inside the P-solvable\noptimization class PO never have been studiously analyzed regarding their exact\ncomputational complexity. To improve this situation, the existing framework\nbased on polynomial-time computability needs to be expanded and further refined\nfor an insightful analysis of various approximation algorithms targeting\noptimization problems within PO. In particular, we deal with those problems\ncharacterized in terms of logarithmic-space computations and uniform-circuit\ncomputations. We are focused on nondeterministic logarithmic-space (NL)\noptimization problems or NPO problems. Our study covers a wide range of\noptimization and approximation classes, dubbed as, NLO, LO, APXL, and LSAS as\nwell as new classes NC1O, APXNC1, NC1AS, and AC0O, which are founded on uniform\nfamilies of Boolean circuits. Although many NL decision problems can be\nnaturally converted into NL optimization (NLO) problems, few NLO problems have\nbeen studied vigorously. We thus provide a number of new NLO problems falling\ninto those low-complexity classes. With the help of NC1 or AC0\napproximation-preserving reductions, we also identify the most difficult\nproblems (known as complete problems) inside those classes. Finally, we\ndemonstrate a number of collapses and separations among those refined\noptimization and approximation classes with or without unproven\ncomplexity-theoretical assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 09:44:05 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Yamakami", "Tomoyuki", ""]]}, {"id": "1601.01744", "submitter": "Yechao Zhu", "authors": "Cedric Yen-Yu Lin, Yechao Zhu", "title": "Performance of QAOA on Typical Instances of Constraint Satisfaction\n  Problems with Bounded Degree", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": "MIT-CTP-4751", "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider constraint satisfaction problems of bounded degree, with a good\nnotion of \"typicality\", e.g. the negation of the variables in each constraint\nis taken independently at random. Using the quantum approximate optimization\nalgorithm (QAOA), we show that $ \\mu+\\Omega(1/\\sqrt{D}) $ fraction of the\nconstraints can be satisfied for typical instances, with the assignment\nefficiently produced by QAOA. We do so by showing that the averaged fraction of\nconstraints being satisfied is $ \\mu+\\Omega(1/\\sqrt{D}) $, with small variance.\nHere $ \\mu $ is the fraction that would be satisfied by a uniformly random\nassignment, and $ D $ is the number of constraints that each variable can\nappear. CSPs with typicality include Max-$ k $XOR and Max-$ k $SAT. We point\nout how it can be applied to determine the typical ground-state energy of some\nlocal Hamiltonians. We also give a similar result for instances with \"no\noverlapping constraints\", using the quantum algorithm. We sketch how the\nclassical algorithm might achieve some partial result.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 01:44:13 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Lin", "Cedric Yen-Yu", ""], ["Zhu", "Yechao", ""]]}, {"id": "1601.01958", "submitter": "Guillaume Ducoffe", "authors": "Guillaume Ducoffe and Sylvain Legay and Nicolas Nisse", "title": "On computing tree and path decompositions with metric constraints on the\n  bags", "comments": "50 pages, 39 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We here investigate on the complexity of computing the \\emph{tree-length} and\nthe \\emph{tree-breadth} of any graph $G$, that are respectively the best\npossible upper-bounds on the diameter and the radius of the bags in a tree\ndecomposition of $G$. \\emph{Path-length} and \\emph{path-breadth} are similarly\ndefined and studied for path decompositions. So far, it was already known that\ntree-length is NP-hard to compute. We here prove it is also the case for\ntree-breadth, path-length and path-breadth. Furthermore, we provide a more\ndetailed analysis on the complexity of computing the tree-breadth. In\nparticular, we show that graphs with tree-breadth one are in some sense the\nhardest instances for the problem of computing the tree-breadth. We give new\nproperties of graphs with tree-breadth one. Then we use these properties in\norder to recognize in polynomial-time all graphs with tree-breadth one that are\nplanar or bipartite graphs. On the way, we relate tree-breadth with the notion\nof \\emph{$k$-good} tree decompositions (for $k=1$), that have been introduced\nin former work for routing. As a byproduct of the above relation, we prove that\ndeciding on the existence of a $k$-good tree decomposition is NP-complete (even\nif $k=1$). All this answers open questions from the literature.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 17:57:40 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Ducoffe", "Guillaume", ""], ["Legay", "Sylvain", ""], ["Nisse", "Nicolas", ""]]}, {"id": "1601.01975", "submitter": "Bill Fefferman", "authors": "Bill Fefferman and Cedric Lin", "title": "Quantum Merlin Arthur with Exponentially Small Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of QMA proof systems with inverse exponentially small\npromise gap. We show that this class can be exactly characterized by PSPACE,\nthe class of problems solvable with a polynomial amount of memory. As\napplications we show that a \"precise\" version of the Local Hamiltonian problem\nis PSPACE-complete, and give a provable setting in which the ability to prepare\nPEPS states is not as powerful as the ability to prepare the ground state of\ngeneral Local Hamiltonians.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 18:47:42 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Fefferman", "Bill", ""], ["Lin", "Cedric", ""]]}, {"id": "1601.02258", "submitter": "Jakub Szymanik", "authors": "Ronald de Haan and Jakub Szymanik", "title": "Characterizing Polynomial Ramsey Quantifiers", "comments": null, "journal-ref": "Math. Struct. Comp. Sci. 29 (2019) 896-908", "doi": "10.1017/S0960129518000397", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ramsey quantifiers are a natural object of study not only for logic and\ncomputer science, but also for the formal semantics of natural language.\nRestricting attention to finite models leads to the natural question whether\nall Ramsey quantifiers are either polynomial-time computable or NP-hard, and\nwhether we can give a natural characterization of the polynomial-time\ncomputable quantifiers. In this paper, we first show that there exist\nintermediate Ramsey quantifiers and then we prove a dichotomy result for a\nlarge and natural class of Ramsey quantifiers, based on a reasonable and\nwidely-believed complexity assumption. We show that the polynomial-time\ncomputable quantifiers in this class are exactly the constant-log-bounded\nRamsey quantifiers.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2016 19:25:25 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 11:37:30 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["de Haan", "Ronald", ""], ["Szymanik", "Jakub", ""]]}, {"id": "1601.02311", "submitter": "Troy Lee", "authors": "Troy Lee and Anupam Prakash and Ronald de Wolf and Henry Yuen", "title": "On the sum-of-squares degree of symmetric quadratic functions", "comments": "33 pages. Second version fixes some typos and adds references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how well functions over the boolean hypercube of the form\n$f_k(x)=(|x|-k)(|x|-k-1)$ can be approximated by sums of squares of low-degree\npolynomials, obtaining good bounds for the case of approximation in\n$\\ell_{\\infty}$-norm as well as in $\\ell_1$-norm. We describe three\ncomplexity-theoretic applications: (1) a proof that the recent breakthrough\nlower bound of Lee, Raghavendra, and Steurer on the positive semidefinite\nextension complexity of the correlation and TSP polytopes cannot be improved\nfurther by showing better sum-of-squares degree lower bounds on\n$\\ell_1$-approximation of $f_k$; (2) a proof that Grigoriev's lower bound on\nthe degree of Positivstellensatz refutations for the knapsack problem is\noptimal, answering an open question from his work; (3) bounds on the query\ncomplexity of quantum algorithms whose expected output approximates such\nfunctions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 03:16:23 GMT"}, {"version": "v2", "created": "Tue, 8 Mar 2016 13:01:04 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Lee", "Troy", ""], ["Prakash", "Anupam", ""], ["de Wolf", "Ronald", ""], ["Yuen", "Henry", ""]]}, {"id": "1601.02658", "submitter": "Jess Banks", "authors": "Jess Banks and Cristopher Moore", "title": "Information-theoretic thresholds for community detection in sparse\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cond-mat.stat-mech cs.CC cs.IT cs.SI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give upper and lower bounds on the information-theoretic threshold for\ncommunity detection in the stochastic block model. Specifically, let $k$ be the\nnumber of groups, $d$ be the average degree, the probability of edges between\nvertices within and between groups be $c_\\mathrm{in}/n$ and $c_\\mathrm{out}/n$\nrespectively, and let $\\lambda = (c_\\mathrm{in}-c_\\mathrm{out})/(kd)$. We show\nthat, when $k$ is large, and $\\lambda = O(1/k)$, the critical value of $d$ at\nwhich community detection becomes possible -- in physical terms, the\ncondensation threshold -- is \\[ d_c = \\Theta\\!\\left( \\frac{\\log k}{k \\lambda^2}\n\\right) \\, , \\] with tighter results in certain regimes. Above this threshold,\nwe show that the only partitions of the nodes into $k$ groups are correlated\nwith the ground truth, giving an exponential-time algorithm that performs\nbetter than chance -- in particular, detection is possible for $k \\ge 5$ in the\ndisassortative case $\\lambda < 0$ and for $k \\ge 11$ in the assortative case\n$\\lambda > 0$. (Similar upper bounds were obtained independently by Abbe and\nSandon.) Below this threshold, we use recent results of Neeman and Netrapalli\n(who generalized arguments of Mossel, Neeman, and Sly) to show that no\nalgorithm can label the vertices better than chance, or even distinguish the\nblock model from an Erd\\H{o}s-R\\'enyi random graph with high probability. We\nalso rely on bounds on certain functions of doubly stochastic matrices due to\nAchlioptas and Naor; indeed, our lower bound on $d_c$ is the second moment\nlower bound on the $k$-colorability threshold for random graphs with a certain\neffective degree.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 21:29:42 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2016 22:03:01 GMT"}, {"version": "v3", "created": "Fri, 4 Mar 2016 19:56:28 GMT"}, {"version": "v4", "created": "Thu, 21 Apr 2016 20:45:14 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Banks", "Jess", ""], ["Moore", "Cristopher", ""]]}, {"id": "1601.02697", "submitter": "Saber Mirzaei", "authors": "Saber Mirzaei", "title": "Minimum Average Delay of Routing Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general communication tree embedding problem is the problem of mapping a\nset of communicating terminals, represented by a graph G, into the set of\nvertices of some physical network represented by a tree T. In the case where\nthe vertices of G are mapped into the leaves of the host tree T the underlying\ntree is called a routing tree and if the internal vertices of T are forced to\nhave degree 3, the host tree is known as layout tree. Different optimization\nproblems have been studied in the class of communication tree problems such as\nwell-known minimum edge dilation and minimum edge congestion problems. In this\nreport we study the less investigate measure i.e. tree length, which is a\nrepresentative for average edge dilation (communication delay) measure and also\nfor average edge congestion measure. We show that finding a routing tree T for\nan arbitrary graph G with minimum tree length is an NP-Hard problem.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 00:05:24 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Mirzaei", "Saber", ""]]}, {"id": "1601.02771", "submitter": "Boris Adamczewski", "authors": "Boris Adamczewski, Julien Cassaigne, and Marion Le Gonidec", "title": "On the computational complexity of algebraic numbers: the\n  Hartmanis--Stearns problem revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the complexity of integer base expansions of algebraic irrational\nnumbers from a computational point of view. We show that the Hartmanis--Stearns\nproblem can be solved in a satisfactory way for the class of multistack\nmachines. In this direction, our main result is that the base-$b$ expansion of\nan algebraic irrational real number cannot be generated by a deterministic\npushdown automaton. We also confirm an old claim of Cobham proving that such\nnumbers cannot be generated by a tag machine with dilation factor larger than\none.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 09:02:28 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 08:40:10 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Adamczewski", "Boris", ""], ["Cassaigne", "Julien", ""], ["Gonidec", "Marion Le", ""]]}, {"id": "1601.02939", "submitter": "Andrew Gainer-Dewar", "authors": "Andrew Gainer-Dewar and Paola Vera-Licona", "title": "The minimal hitting set generation problem: algorithms and computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding inclusion-minimal \"hitting sets\" for a given collection of sets is a\nfundamental combinatorial problem with applications in domains as diverse as\nBoolean algebra, computational biology, and data mining. Much of the\nalgorithmic literature focuses on the problem of *recognizing* the collection\nof minimal hitting sets; however, in many of the applications, it is more\nimportant to *generate* these hitting sets. We survey twenty algorithms from\nacross a variety of domains, considering their history, classification, useful\nfeatures, and computational performance on a variety of synthetic and\nreal-world inputs. We also provide a suite of implementations of these\nalgorithms with a ready-to-use, platform-agnostic interface based on Docker\ncontainers and the AlgoRun framework, so that interested computational\nscientists can easily perform similar tests with inputs from their own research\nareas on their own computers or through a convenient Web interface.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 19:24:25 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Gainer-Dewar", "Andrew", ""], ["Vera-Licona", "Paola", ""]]}, {"id": "1601.03174", "submitter": "Petr Golovach", "authors": "Petr A. Golovach and George B. Mertzios", "title": "Graph Editing to a Given Degree Sequence", "comments": "arXiv admin note: text overlap with arXiv:1311.4768", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the parameterized complexity of the graph editing problem\ncalled Editing to a Graph with a Given Degree Sequence, where the aim is to\nobtain a graph with a given degree sequence \\sigma by at most k vertex or edge\ndeletions and edge additions. We show that the problem is W[1]-hard when\nparameterized by k for any combination of the allowed editing operations. From\nthe positive side, we show that the problem can be solved in time\n2^{O(k(\\Delta+k)^2)}n^2 log n for n-vertex graphs, where \\Delta=max \\sigma,\ni.e., the problem is FPT when parameterized by k+\\Delta. We also show that\nEditing to a Graph with a Given Degree Sequence has a polynomial kernel when\nparameterized by k+\\Delta if only edge additions are allowed, and there is no\npolynomial kernel unless NP\\subseteq coNP/poly for all other combinations of\nallowed editing operations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 09:09:43 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Golovach", "Petr A.", ""], ["Mertzios", "George B.", ""]]}, {"id": "1601.03195", "submitter": "Alberto Molinari", "authors": "A. Molinari, A. Montanari, A. Murano, G. Perelli, A. Peron", "title": "Checking Interval Properties of Computations", "comments": "In Journal: Acta Informatica, Springer Berlin Heidelber, 2015", "journal-ref": "Acta Informatica 53 (2016) 587-619", "doi": "10.1007/s00236-015-0250-1", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking is a powerful method widely explored in formal verification.\nGiven a model of a system, e.g., a Kripke structure, and a formula specifying\nits expected behaviour, one can verify whether the system meets the behaviour\nby checking the formula against the model.\n  Classically, system behaviour is expressed by a formula of a temporal logic,\nsuch as LTL and the like. These logics are \"point-wise\" interpreted, as they\ndescribe how the system evolves state-by-state. However, there are relevant\nproperties, such as those constraining the temporal relations between pairs of\ntemporally extended events or involving temporal aggregations, which are\ninherently \"interval-based\", and thus asking for an interval temporal logic.\n  In this paper, we give a formalization of the model checking problem in an\ninterval logic setting. First, we provide an interpretation of formulas of\nHalpern and Shoham's interval temporal logic HS over finite Kripke structures,\nwhich allows one to check interval properties of computations. Then, we prove\nthat the model checking problem for HS against finite Kripke structures is\ndecidable by a suitable small model theorem, and we provide a lower bound to\nits computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 10:41:32 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Molinari", "A.", ""], ["Montanari", "A.", ""], ["Murano", "A.", ""], ["Perelli", "G.", ""], ["Peron", "A.", ""]]}, {"id": "1601.03202", "submitter": "Alberto Molinari", "authors": "A. Molinari, A. Montanari, A. Peron", "title": "Complexity of ITL model checking: some well-behaved fragments of the\n  interval logic HS", "comments": null, "journal-ref": "In proceedings of 22nd TIME, Pages 90-100, 2015 IEEE", "doi": "10.1109/TIME.2015.12", "report-no": null, "categories": "cs.LO cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking has been successfully used in many computer science fields,\nincluding artificial intelligence, theoretical computer science, and databases.\nMost of the proposed solutions make use of classical, point-based temporal\nlogics, while little work has been done in the interval temporal logic setting.\nRecently, a non-elementary model checking algorithm for Halpern and Shoham's\nmodal logic of time intervals HS over finite Kripke structures (under the\nhomogeneity assumption) and an EXPSPACE model checking procedure for two\nmeaningful fragments of it have been proposed. In this paper, we show that more\nefficient model checking procedures can be developed for some expressive enough\nfragments of HS.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 11:17:36 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Molinari", "A.", ""], ["Montanari", "A.", ""], ["Peron", "A.", ""]]}, {"id": "1601.03240", "submitter": "Hubie Chen", "authors": "Hubie Chen, Stefan Mengel", "title": "Counting Answers to Existential Positive Queries: A Complexity\n  Classification", "comments": "arXiv admin note: substantial text overlap with arXiv:1501.07195", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existential positive formulas form a fragment of first-order logic that\nincludes and is semantically equivalent to unions of conjunctive queries, one\nof the most important and well-studied classes of queries in database theory.\nWe consider the complexity of counting the number of answers to existential\npositive formulas on finite structures and give a trichotomy theorem on query\nclasses, in the setting of bounded arity. This theorem generalizes and unifies\nseveral known results on the complexity of conjunctive queries and unions of\nconjunctive queries.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 13:40:55 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2016 13:42:55 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Chen", "Hubie", ""], ["Mengel", "Stefan", ""]]}, {"id": "1601.03619", "submitter": "Daniel Uribe", "authors": "Daniel Uribe", "title": "P vs. NP", "comments": "1 cover page, 1 page table of contents, 38 pages of content, 1 page\n  bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method for analyzing algorithmic runtime complexity using decision trees\nis discussed using the sorting algorithm. This method is then extended to\noptimal algorithms which may find all cliques of size q in network N, or simply\nthe first clique of size q in network N. Finally, the lower bound of such\ndecision trees is demonstrated to not be in P.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 13:19:55 GMT"}], "update_date": "2016-01-15", "authors_parsed": [["Uribe", "Daniel", ""]]}, {"id": "1601.04125", "submitter": "Zhang Zhujun", "authors": "Zhujun Zhang, Qiang Sun", "title": "Complexity Analysis of 2-Heterogeneous Minimum Spanning Forest Problem", "comments": "3 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For complexity of the heterogeneous minimum spanning forest problem has not\nbeen determined, we reduce 3-SAT which is NP-complete to 2-heterogeneous\nminimum spanning forest problem to prove this problem is NP-hard and spread\nresult to general problem, which determines complexity of this problem. It\nprovides a theoretical basis for the future designing of approximation\nalgorithms for the problem.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2016 05:34:09 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Zhang", "Zhujun", ""], ["Sun", "Qiang", ""]]}, {"id": "1601.04520", "submitter": "Ale\\v{s} Bizjak", "authors": "Manuel Bodirsky and Antoine Mottet", "title": "A Dichotomy for First-Order Reducts of Unary Structures", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (May 22,\n  2018) lmcs:4521", "doi": "10.23638/LMCS-14(2:13)2018", "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many natural decision problems can be formulated as constraint satisfaction\nproblems for reducts $\\mathbb{A}$ of finitely bounded homogeneous structures.\nThis class of problems is a large generalisation of the class of CSPs over\nfinite domains. Our first result is a general polynomial-time reduction from\nsuch infinite-domain CSPs to finite-domain CSPs. We use this reduction to\nobtain new powerful polynomial-time tractability conditions that can be\nexpressed in terms of the topological polymorphism clone of $\\mathbb{A}$.\nMoreover, we study the subclass $\\mathcal{C}$ of CSPs for structures\n$\\mathbb{A}$ that are reducts of a structure with a unary language. Also this\nclass $\\mathcal{C}$ properly extends the class of all finite-domain CSPs. We\napply our new tractability conditions to prove the general tractability\nconjecture of Bodirsky and Pinsker for reducts of finitely bounded homogeneous\nstructures for the class $\\mathcal{C}$.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 14:05:00 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 09:26:26 GMT"}, {"version": "v3", "created": "Fri, 31 Mar 2017 14:54:05 GMT"}, {"version": "v4", "created": "Tue, 11 Apr 2017 16:58:28 GMT"}, {"version": "v5", "created": "Sat, 2 Dec 2017 09:39:32 GMT"}, {"version": "v6", "created": "Sun, 20 May 2018 10:24:36 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Mottet", "Antoine", ""]]}, {"id": "1601.04661", "submitter": "Christoph Haase", "authors": "Christoph Haase and Stefan Kiefer and Markus Lohrey", "title": "Efficient Quantile Computation in Markov Chains via Counting Problems\n  for Parikh Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cost Markov chain is a Markov chain whose transitions are labelled with\nnon-negative integer costs. A fundamental problem on this model, with\napplications in the verification of stochastic systems, is to compute\ninformation about the distribution of the total cost accumulated in a run. This\nincludes the probability of large total costs, the median cost, and other\nquantiles. While expectations can be computed in polynomial time, previous work\nhas demonstrated that the computation of cost quantiles is harder but can be\ndone in PSPACE. In this paper we show that cost quantiles in cost Markov chains\ncan be computed in the counting hierarchy, thus providing evidence that\ncomputing those quantiles is likely not PSPACE-hard. We obtain this result by\nexhibiting a tight link to a problem in formal language theory: counting the\nnumber of words that are both accepted by a given automaton and have a given\nParikh image. Motivated by this link, we comprehensively investigate the\ncomplexity of the latter problem. Among other techniques, we rely on the\nso-called BEST theorem for efficiently computing the number of Eulerian\ncircuits in a directed graph.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 19:31:03 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Haase", "Christoph", ""], ["Kiefer", "Stefan", ""], ["Lohrey", "Markus", ""]]}, {"id": "1601.04743", "submitter": "Ryan Williams", "authors": "Ryan Williams", "title": "Strong ETH Breaks With Merlin and Arthur: Short Non-Interactive Proofs\n  of Batch Evaluation", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient proof system for Multipoint Arithmetic Circuit\nEvaluation: for every arithmetic circuit $C(x_1,\\ldots,x_n)$ of size $s$ and\ndegree $d$ over a field ${\\mathbb F}$, and any inputs $a_1,\\ldots,a_K \\in\n{\\mathbb F}^n$,\n  $\\bullet$ the Prover sends the Verifier the values $C(a_1), \\ldots, C(a_K)\n\\in {\\mathbb F}$ and a proof of $\\tilde{O}(K \\cdot d)$ length, and\n  $\\bullet$ the Verifier tosses $\\textrm{poly}(\\log(dK|{\\mathbb\nF}|/\\varepsilon))$ coins and can check the proof in about $\\tilde{O}(K \\cdot(n\n+ d) + s)$ time, with probability of error less than $\\varepsilon$.\n  For small degree $d$, this \"Merlin-Arthur\" proof system (a.k.a. MA-proof\nsystem) runs in nearly-linear time, and has many applications. For example, we\nobtain MA-proof systems that run in $c^{n}$ time (for various $c < 2$) for the\nPermanent, $\\#$Circuit-SAT for all sublinear-depth circuits, counting\nHamiltonian cycles, and infeasibility of $0$-$1$ linear programs. In general,\nthe value of any polynomial in Valiant's class ${\\sf VP}$ can be certified\nfaster than \"exhaustive summation\" over all possible assignments. These results\nstrongly refute a Merlin-Arthur Strong ETH and Arthur-Merlin Strong ETH posed\nby Russell Impagliazzo and others.\n  We also give a three-round (AMA) proof system for quantified Boolean formulas\nrunning in $2^{2n/3+o(n)}$ time, nearly-linear time MA-proof systems for\ncounting orthogonal vectors in a collection and finding Closest Pairs in the\nHamming metric, and a MA-proof system running in $n^{k/2+O(1)}$-time for\ncounting $k$-cliques in graphs.\n  We point to some potential future directions for refuting the\nNondeterministic Strong ETH.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 22:21:36 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Williams", "Ryan", ""]]}, {"id": "1601.04794", "submitter": "Changqing Liu", "authors": "Changqing Liu", "title": "Solutions to the Problem of K-SAT / K-COL Phase Transition Location", "comments": "Extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As general theories, currently there are concentration inequalities (of\nrandom walk) only for the cases of independence and martingale differences. In\nthis paper, the concentration inequalities are extended to more general\nsituations. In terms of the theory presented in the paper, the condition of\nindependence is $\\frac { \\partial y } {\\partial t}=$ constant and martingale\ndifference's is $\\frac { \\partial y } {\\partial t} = 0 $. This paper relaxes\nthese conditions to $\\frac { \\partial^2 y } {\\partial u_i \\partial t} \\le L$;\ni.e. $\\frac { \\partial y } {\\partial t}$ can vary. Further, the concentration\ninequalities are extended to branching random walk, the applications of which\nsolve some long standing open problems, including the well known problems of\nK-SAT and K-COL phase transition locations, among others.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 04:10:52 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Liu", "Changqing", ""]]}, {"id": "1601.04935", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet, L\\'aszl\\'o Egri, Bingkai Lin, D\\'aniel Marx", "title": "Fixed-parameter Approximability of Boolean MinCSPs", "comments": "A preliminary version of this paper has appeared in the proceedings\n  of ESA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum unsatisfiability version of a constraint satisfaction problem\n(MinCSP) asks for an assignment where the number of unsatisfied constraints is\nminimum possible, or equivalently, asks for a minimum-size set of constraints\nwhose deletion makes the instance satisfiable. For a finite set $\\Gamma$ of\nconstraints, we denote by MinCSP($\\Gamma$) the restriction of the problem where\neach constraint is from $\\Gamma$. The polynomial-time solvability and the\npolynomial-time approximability of MinCSP($\\Gamma$) were fully characterized by\nKhanna et al. [Siam J. Comput. '00]. Here we study the fixed-parameter (FP-)\napproximability of the problem: given an instance and an integer $k$, one has\nto find a solution of size at most $g(k)$ in time $f(k)n^{O(1)}$ if a solution\nof size at most $k$ exists. We especially focus on the case of constant-factor\nFP-approximability. We show the following dichotomy: for each finite constraint\nlanguage $\\Gamma$, either we exhibit a constant-factor FP-approximation for\nMinCSP($\\Gamma$); or we prove that MinCSP($\\Gamma$) has no constant-factor\nFP-approximation unless FPT$=$W[1]. In particular, we show that approximating\nthe so-called Nearest Codeword within some constant factor is W[1]-hard.\nRecently, Arnab et al. [ICALP '18] showed that such a W[1]-hardness of\napproximation implies that Even Set is W[1]-hard under randomized reductions.\nCombining our results, we therefore settle the parameterized complexity of Even\nSet, a famous open question in the field.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 14:28:37 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 12:31:19 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Egri", "L\u00e1szl\u00f3", ""], ["Lin", "Bingkai", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "1601.05353", "submitter": "Amaury Pouly", "authors": "Hugo Bazille, Olivier Bournez, Walid Gomaa, Amaury Pouly", "title": "On the complexity of bounded time and precision reachability for\n  piecewise affine systems", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2016.09.021", "report-no": null, "categories": "cs.CC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reachability for piecewise affine systems is known to be undecidable,\nstarting from dimension $2$. In this paper we investigate the exact complexity\nof several decidable variants of reachability and control questions for\npiecewise affine systems. We show in particular that the region to region\nbounded time versions leads to $NP$-complete or co-$NP$-complete problems,\nstarting from dimension $2$. We also prove that a bounded precision version\nleads to $PSPACE$-complete problems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 17:58:43 GMT"}, {"version": "v2", "created": "Tue, 5 Jul 2016 02:37:55 GMT"}, {"version": "v3", "created": "Tue, 17 Jan 2017 16:41:55 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Bazille", "Hugo", ""], ["Bournez", "Olivier", ""], ["Gomaa", "Walid", ""], ["Pouly", "Amaury", ""]]}, {"id": "1601.05360", "submitter": "Amaury Pouly", "authors": "Olivier Bournez, Daniel S. Gra\\c{c}a, Amaury Pouly", "title": "Polynomial Time corresponds to Solutions of Polynomial Ordinary\n  Differential Equations of Polynomial Length", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2016.109", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an implicit characterization of polynomial time computation in\nterms of ordinary differential equations: we characterize the class\n$\\operatorname{PTIME}$ of languages computable in polynomial time in terms of\ndifferential equations with polynomial right-hand side.\n  This result gives a purely continuous (time and space) elegant and simple\ncharacterization of $\\operatorname{PTIME}$. This is the first time such classes\nare characterized using only ordinary differential equations. Our\ncharacterization extends to functions computable in polynomial time over the\nreals in the sense of computable analysis. This extends to deterministic\ncomplexity classes above polynomial time.\n  This may provide a new perspective on classical complexity, by giving a way\nto define complexity classes, like $\\operatorname{PTIME}$, in a very simple\nway, without any reference to a notion of (discrete) machine. This may also\nprovide ways to state classical questions about computational complexity via\nordinary differential equations, i.e.~by using the framework of analysis.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 18:19:15 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 13:50:24 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Bournez", "Olivier", ""], ["Gra\u00e7a", "Daniel S.", ""], ["Pouly", "Amaury", ""]]}, {"id": "1601.05494", "submitter": "John Hitchcock", "authors": "John M. Hitchcock and Hadi Shafei", "title": "Autoreducibility of NP-Complete Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the polynomial-time autoreducibility of NP-complete sets and obtain\nseparations under strong hypotheses for NP. Assuming there is a p-generic set\nin NP, we show the following:\n  - For every $k \\geq 2$, there is a $k$-T-complete set for NP that is $k$-T\nautoreducible, but is not $k$-tt autoreducible or $(k-1)$-T autoreducible.\n  - For every $k \\geq 3$, there is a $k$-tt-complete set for NP that is $k$-tt\nautoreducible, but is not $(k-1)$-tt autoreducible or $(k-2)$-T autoreducible.\n  - There is a tt-complete set for NP that is tt-autoreducible, but is not\nbtt-autoreducible.\n  Under the stronger assumption that there is a p-generic set in NP $\\cap$\ncoNP, we show:\n  - For every $k \\geq 2$, there is a $k$-tt-complete set for NP that is $k$-tt\nautoreducible, but is not $(k-1)$-T autoreducible.\n  Our proofs are based on constructions from separating NP-completeness\nnotions. For example, the construction of a 2-T-complete set for NP that is not\n2-tt-complete also separates 2-T-autoreducibility from 2-tt-autoreducibility.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 02:31:55 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["Hitchcock", "John M.", ""], ["Shafei", "Hadi", ""]]}, {"id": "1601.05683", "submitter": "Amaury Pouly", "authors": "Olivier Bournez, Daniel Gra\\c{c}a, Amaury Pouly", "title": "Computing with Polynomial Ordinary Differential Equations", "comments": "arXiv admin note: substantial text overlap with arXiv:1601.05360", "journal-ref": null, "doi": "10.1016/j.jco.2016.05.002", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1941, Claude Shannon introduced the General Purpose Analog Computer(GPAC)\nas a mathematical model of Differential Analysers, that is to say as a model of\ncontinuous-time analog (mechanical, and later one electronic) machines of that\ntime.\n  Following Shannon's arguments, functions generated by GPACs must be\ndifferentially algebraic. As it is known that some computable functions like\nEuler's $\\Gamma(x)=\\int_{0}^{\\infty}t^{x-1}e^{-t}dt$ or Riemann's Zeta function\n$\\zeta(x)=\\sum_{k=0}^\\infty \\frac1{k^x}$ are not differentially algebraic, this\nargument has been often used to demonstrate in the past that the GPAC is less\npowerful than digital computation.\n  It was proved in JOC2007, that if a more modern notion of computation is\nconsidered, i.e. in particular if computability is not restricted to real-time\ngeneration of functions, the GPAC is actually equivalent to Turing machines.\n  Our purpose is first to discuss the robustness of the notion of computation\ninvolved in JOC2007, by establishing that natural variants of the notion of\ncomputation from this paper leads to the same computability result.\n  Second, to go considerations about (time) complexity, we explore several\nnatural variants for measuring time/space complexity of a computation.\n  Rather surprisingly, whereas defining a robust time complexity for general\ncontinuous time systems is a well known open problem, we prove that all\nvariants are actually equivalent even at the complexity level. As a\nconsequence, it seems that a robust and well defined notion of time complexity\nexists for the GPAC, or equivalently for computations by polynomial ordinary\ndifferential equations.\n  Another side effect of our proof is also that we show in some way that\npolynomial ordinary differential equations can be used as a kind of programming\nmodel, and that there is a rather nice and robust notion of ODE programming.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 15:47:59 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 13:59:38 GMT"}, {"version": "v3", "created": "Wed, 30 Nov 2016 16:14:04 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Bournez", "Olivier", ""], ["Gra\u00e7a", "Daniel", ""], ["Pouly", "Amaury", ""]]}, {"id": "1601.06101", "submitter": "David Elkouss Coronas", "authors": "David Elkouss and David P\\'erez-Garc\\'ia", "title": "Memory effects can make the transmission capability of a communication\n  channel uncomputable", "comments": "Improved presentation and clarified claims", "journal-ref": "Nature Communications vol 9 no 1149 (2018)", "doi": "10.1038/s41467-018-03428-0", "report-no": null, "categories": "cs.IT cs.CC cs.FL math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most communication channels are subjected to noise. One of the goals of\nInformation Theory is to add redundancy in the transmission of information so\nthat the information is transmitted reliably and the amount of information\ntransmitted through the channel is as large as possible. The maximum rate at\nwhich reliable transmission is possible is called the capacity. If the channel\ndoes not keep memory of its past, the capacity is given by a simple\noptimization problem and can be efficiently computed. The situation of channels\nwith memory is less clear. Here we show that for channels with memory the\ncapacity cannot be computed to within precision 1/5. Our result holds even if\nwe consider one of the simplest families of such channels -information-stable\nfinite state machine channels-, restrict the input and output of the channel to\n4 and 1 bit respectively and allow 6 bits of memory.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 19:05:23 GMT"}, {"version": "v2", "created": "Thu, 19 May 2016 12:52:59 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 11:40:50 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Elkouss", "David", ""], ["P\u00e9rez-Garc\u00eda", "David", ""]]}, {"id": "1601.06291", "submitter": "C.S. Rahul", "authors": "N S Narayanaswamy and C S Rahul", "title": "A Characterization for the Existence of Connected $f$-Factors of\n  $\\textit{ Large}$ Minimum Degree", "comments": "10 pages, Presented in 9th International colloquium on graph theory\n  and combinatorics, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is well known that when $f(v)$ is a constant for each vertex $v$, the\nconnected $f$-factor problem is NP-Complete. In this note we consider the case\nwhen $f(v) \\geq \\lceil \\frac{n}{2.5}\\rceil$ for each vertex $v$, where $n$ is\nthe number of vertices. We present a diameter based characterization of graphs\nhaving a connected $f$-factor (for such $f$). We show that if a graph $G$ has a\nconnected $f$-factor and an $f$-factor with 2 connected components, then it has\na connected $f$-factor of diameter at least 3. This result yields a polynomial\ntime algorithm which first executes the Tutte's $f$-factor algorithm, and if\nthe output has 2 connected components, our algorithm searches for a connected\n$f$-factor of diameter at least 3.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2016 17:14:24 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Narayanaswamy", "N S", ""], ["Rahul", "C S", ""]]}, {"id": "1601.06319", "submitter": "Rohit Gurjar", "authors": "Stephen A. Fenner, Rohit Gurjar, Thomas Thierauf", "title": "Bipartite Perfect Matching is in quasi-NC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the bipartite perfect matching problem is in quasi-NC$^2$. That\nis, it has uniform circuits of quasi-polynomial size $n^{O(\\log n)}$, and\n$O(log^2 n)$ depth. Previously, only an exponential upper bound was known on\nthe size of such circuits with poly-logarithmic depth.\n  We obtain our result by an almost complete derandomization of the famous\nIsolation Lemma when applied to yield an efficient randomized parallel\nalgorithm for the bipartite perfect matching problem.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2016 22:50:22 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 17:47:47 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Fenner", "Stephen A.", ""], ["Gurjar", "Rohit", ""], ["Thierauf", "Thomas", ""]]}, {"id": "1601.06522", "submitter": "\\\"Amin Baumeler", "authors": "\\\"Amin Baumeler and Stefan Wolf", "title": "Non-causal computation", "comments": "6 pages, 4 figures", "journal-ref": "Entropy 19(7), 326, 2017", "doi": "10.3390/e19070326", "report-no": null, "categories": "quant-ph cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation models such as circuits describe sequences of computation steps\nthat are carried out one after the other. In other words, algorithm design is\ntraditionally subject to the restriction imposed by a fixed causal order. We\naddress a novel computing paradigm beyond quantum computing, replacing this\nassumption by mere logical consistency: We study non-causal circuits, where a\nfixed time structure within a gate is locally assumed whilst the global causal\nstructure between the gates is dropped. We present examples of logically\nconsistent non- causal circuits outperforming all causal ones; they imply that\nsuppressing loops entirely is more restrictive than just avoiding the\ncontradictions they can give rise to. That fact is already known for\ncorrelations as well as for communication, and we here extend it to\ncomputation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 09:18:22 GMT"}, {"version": "v2", "created": "Wed, 5 Apr 2017 16:01:10 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Baumeler", "\u00c4min", ""], ["Wolf", "Stefan", ""]]}, {"id": "1601.07629", "submitter": "Lek-Heng Lim", "authors": "Shmuel Friedland and Lek-Heng Lim", "title": "The Computational Complexity of Duality", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for any given norm ball or proper cone, weak membership in its\ndual ball or dual cone is polynomial-time reducible to weak membership in the\ngiven ball or cone. A consequence is that the weak membership or membership\nproblem for a ball or cone is NP-hard if and only if the corresponding problem\nfor the dual ball or cone is NP-hard. In a similar vein, we show that\ncomputation of the dual norm of a given norm is polynomial-time reducible to\ncomputation of the given norm. This extends to convex functions satisfying a\npolynomial growth condition: for such a given function, computation of its\nFenchel dual/conjugate is polynomial-time reducible to computation of the given\nfunction. Hence the computation of a norm or a convex function of\npolynomial-growth is NP-hard if and only if the computation of its dual norm or\nFenchel dual is NP-hard. We discuss implications of these results on the weak\nmembership problem for a symmetric convex body and its polar dual, the\npolynomial approximability of Mahler volume, and the weak membership problem\nfor the epigraph of a convex function with polynomial growth and that of its\nFenchel dual.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 02:44:53 GMT"}, {"version": "v2", "created": "Sat, 23 Jul 2016 22:03:42 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Friedland", "Shmuel", ""], ["Lim", "Lek-Heng", ""]]}, {"id": "1601.08031", "submitter": "Rohit Gurjar", "authors": "Rohit Gurjar and Arpita Korwar and Nitin Saxena", "title": "Identity Testing for Constant-Width, and Any-Order, Read-Once Oblivious\n  Arithmetic Branching Programs", "comments": "Published in Theory of Computing, Volume 13 (2017), Article 2;\n  Received: June 15, 2016, Revised: April 9, 2017, Published: May 15, 2017", "journal-ref": "Theory of Computing 13(2):1-21, 2017", "doi": "10.4086/toc.2017.v013a002", "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give improved hitting sets for two special cases of Read-once Oblivious\nArithmetic Branching Programs (ROABP). First is the case of an ROABP with known\norder of the variables. The best previously known hitting set for this case had\nsize $(nw)^{O(\\log n)}$ where $n$ is the number of variables and $w$ is the\nwidth of the ROABP. Even for a constant-width ROABP, nothing better than a\nquasi-polynomial bound was known. We improve the hitting-set size for the\nknown-order case to $n^{O(\\log w)}$. In particular, this gives the first\npolynomial-size hitting set for constant-width ROABP (known-order). However,\nour hitting set only works when the characteristic of the field is zero or\nlarge enough. To construct the hitting set, we use the concept of the rank of\nthe partial derivative matrix. Unlike previous approaches which build up from\nmapping variables to monomials, we map variables to polynomials directly.\n  The second case we consider is that of polynomials computable by width-$w$\nROABPs in any order of the variables. The best previously known hitting set for\nthis case had size $d^{O(\\log w)}(nw)^{O(\\log \\log w)}$, where $d$ is the\nindividual degree. We improve the hitting-set size to $(ndw)^{O(\\log \\log w)}$.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 10:22:51 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 14:47:34 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Gurjar", "Rohit", ""], ["Korwar", "Arpita", ""], ["Saxena", "Nitin", ""]]}, {"id": "1601.08229", "submitter": "J. M. Landsberg", "authors": "J.M. Landsberg, Mateusz Micha{\\l}ek", "title": "On the geometry of border rank algorithms for matrix multiplication and\n  other tensors with symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish basic information about border rank algorithms for the matrix\nmultiplication tensor and other tensors with symmetry. We prove that border\nrank algorithms for tensors with symmetry (such as matrix multiplication and\nthe determinant polynomial) come in families that include representatives with\nnormal forms. These normal forms will be useful both to develop new efficient\nalgorithms and to prove lower complexity bounds. We derive a border rank\nversion of the substitution method used in proving lower bounds for tensor\nrank. We use this border-substitution method and a normal form to improve the\nlower bound on the border rank of matrix multiplication by one, to 2n^2- n+1.\nWe also point out difficulties that will be formidable obstacles to future\nprogress on lower complexity bounds for tensors because of the \"wild\" structure\nof the Hilbert scheme of points.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 19:49:33 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Landsberg", "J. M.", ""], ["Micha\u0142ek", "Mateusz", ""]]}]