[{"id": "1606.00596", "submitter": "S Raja", "authors": "V. Arvind, Partha Mukhopadhyay, S. Raja", "title": "Randomized Polynomial Time Identity Testing for Noncommutative Circuits", "comments": "As the number of monomials in a noncommutative polynomial which has\n  anarithmetic circuit of size $s$ can actually be doubly exponential in $s$,\n  our result does not imply a randomized polynomial-time identity test for all\n  size s noncommutative circuits. The algorithm works only for noncommutative\n  size s circuits which computes a polynomial with exp(s) many monomials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that the black-box polynomial identity testing for\nnoncommutative polynomials $f\\in\\mathbb{F}\\langle z_1,z_2,\\cdots,z_n \\rangle$\nof degree $D$ and sparsity $t$, can be done in randomized $\\poly(n,\\log t,\\log\nD)$ time. As a consequence, if the black-box contains a circuit $C$ of size $s$\ncomputing $f\\in\\mathbb{F}\\langle z_1,z_2,\\cdots,z_n \\rangle$ which has at most\n$t$ non-zero monomials, then the identity testing can be done by a randomized\nalgorithm with running time polynomial in $s$ and $n$ and $\\log t$. This makes\nsignificant progress on a question that has been open for over ten years.\n  The earlier result by Bogdanov and Wee [BW05], using the classical\nAmitsur-Levitski theorem, gives a randomized polynomial-time algorithm only for\ncircuits of polynomially bounded syntactic degree. In our result, we place no\nrestriction on the degree of the circuit.\n  Our algorithm is based on automata-theoretic ideas introduced in\n[AMS08,AM08]. In those papers, the main idea was to construct deterministic\nfinite automata that isolate a single monomial from the set of nonzero\nmonomials of a polynomial $f$ in $\\mathbb{F}\\langle z_1,z_2,\\cdots,z_n\n\\rangle$. In the present paper, since we need to deal with exponential degree\nmonomials, we carry out a different kind of monomial isolation using\nnondeterministic automata.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 09:33:02 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2016 10:28:27 GMT"}, {"version": "v3", "created": "Mon, 6 Jun 2016 09:24:19 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Arvind", "V.", ""], ["Mukhopadhyay", "Partha", ""], ["Raja", "S.", ""]]}, {"id": "1606.00898", "submitter": "Anand Kumar Narayanan", "authors": "Anand Kumar Narayanan", "title": "Factoring Polynomials over Finite Fields using Drinfeld Modules with\n  Complex Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC cs.DS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel algorithms to factor polynomials over a finite field $\\F_q$\nof odd characteristic using rank $2$ Drinfeld modules with complex\nmultiplication. The main idea is to compute a lift of the Hasse invariant\n(modulo the polynomial $f(x) \\in \\F_q[x]$ to be factored) with respect to a\nDrinfeld module $\\phi$ with complex multiplication. Factors of $f(x)$ supported\non prime ideals with supersingular reduction at $\\phi$ have vanishing Hasse\ninvariant and can be separated from the rest. A Drinfeld module analogue of\nDeligne's congruence plays a key role in computing the Hasse invariant lift. We\npresent two algorithms based on this idea. The first algorithm chooses Drinfeld\nmodules with complex multiplication at random and has a quadratic expected run\ntime. The second is a deterministic algorithm with $O(\\sqrt{p})$ run time\ndependence on the characteristic $p$ of $\\F_q$.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 21:09:01 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Narayanan", "Anand Kumar", ""]]}, {"id": "1606.01091", "submitter": "Eleni Akrida", "authors": "Eleni C. Akrida, Jurek Czyzowicz, Leszek Gasieniec, Lukasz Kuszner,\n  Paul G. Spirakis", "title": "Temporal flows in Temporal networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce temporal flows on temporal networks, i.e., networks the links of\nwhich exist only at certain moments of time. Such networks are ephemeral in the\nsense that no link exists after some time. Our flow model is new and differs\nfrom the \"flows over time\" model, also called \"dynamic flows\" in the\nliterature. We show that the problem of finding the maximum amount of flow that\ncan pass from a source vertex s to a sink vertex t up to a given time is\nsolvable in Polynomial time, even when node buffers are bounded. We then\nexamine mainly the case of unbounded node buffers. We provide a simplified\nstatic Time-Extended network (STEG), which is of polynomial size to the input\nand whose static flow rates are equivalent to the respective temporal flow of\nthe temporal network, using STEG, we prove that the maximum temporal flow is\nequal to the minimum temporal s-t cut. We further show that temporal flows can\nalways be decomposed into flows, each of which moves only through a journey,\ni.e., a directed path whose successive edges have strictly increasing moments\nof existence. We partially characterise networks with random edge\navailabilities that tend to eliminate the s-t temporal flow. We then consider\nmixed temporal networks, which have some edges with specified availabilities\nand some edges with random availabilities, we show that it is #P-hard to\ncompute the tails and expectations of the maximum temporal flow (which is now a\nrandom variable) in a mixed temporal network.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 13:56:54 GMT"}, {"version": "v2", "created": "Fri, 20 Jan 2017 13:04:05 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Akrida", "Eleni C.", ""], ["Czyzowicz", "Jurek", ""], ["Gasieniec", "Leszek", ""], ["Kuszner", "Lukasz", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1606.01172", "submitter": "Alexander Ushakov", "authors": "Alexei Miasnikov, Alexander Ushakov", "title": "Generic case completeness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we introduce a notion of a generically (strongly generically)\nNP-complete problem and show that the randomized bounded version of the halting\nproblem is strongly generically NP-complete.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 19:56:51 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Miasnikov", "Alexei", ""], ["Ushakov", "Alexander", ""]]}, {"id": "1606.01844", "submitter": "David Mass", "authors": "Tali Kaufman, David Mass", "title": "Walking on the Edge and Cosystolic Expansion", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walks on regular bounded degree expander graphs have numerous\napplications. A key property of these walks is that they converge rapidly to\nthe uniform distribution on the vertices. The recent study of expansion of high\ndimensional simplicial complexes, which are the high dimensional analogues of\ngraphs, calls for the natural generalization of random walks to higher\ndimensions. In particular, a high order random walk on a $2$-dimensional\nsimplicial complex moves at random between neighboring edges of the complex,\nwhere two edges are considered neighbors if they share a common triangle. We\nshow that if a regular $2$-dimensional simplicial complex is a cosystolic\nexpander and the underlying graph of the complex has a spectral gap larger than\n$1/2$, then the random walk on the edges of the complex converges rapidly to\nthe uniform distribution on the edges.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 17:40:13 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Kaufman", "Tali", ""], ["Mass", "David", ""]]}, {"id": "1606.02577", "submitter": "Stanislav Zivny", "authors": "Johan Thapper, Stanislav Zivny", "title": "The power of Sherali-Adams relaxations for general-valued CSPs", "comments": "Full version of an ICALP'15 paper (arXiv:1502.05301)", "journal-ref": "SIAM Journal on Computing 46(4) (2017) 1241-1279", "doi": "10.1137/16M1079245", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a precise algebraic characterisation of the power of Sherali-Adams\nrelaxations for solvability of valued constraint satisfaction problems to\noptimality. The condition is that of bounded width which has already been shown\nto capture the power of local consistency methods for decision CSPs and the\npower of semidefinite programming for robust approximation of CSPs.\n  Our characterisation has several algorithmic and complexity consequences. On\nthe algorithmic side, we show that several novel and many known valued\nconstraint languages are tractable via the third level of the Sherali-Adams\nrelaxation. For the known languages, this is a significantly simpler algorithm\nthan the previously obtained ones. On the complexity side, we obtain a\ndichotomy theorem for valued constraint languages that can express an injective\nunary function. This implies a simple proof of the dichotomy theorem for\nconservative valued constraint languages established by Kolmogorov and Zivny\n[JACM'13], and also a dichotomy theorem for the exact solvability of\nMinimum-Solution problems. These are generalisations of Minimum-Ones problems\nto arbitrary finite domains. Our result improves on several previous\nclassifications by Khanna et al. [SICOMP'00], Jonsson et al. [SICOMP'08], and\nUppman [ICALP'13].\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 14:32:44 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 18:10:53 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Thapper", "Johan", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1606.02889", "submitter": "Tarun Yadav", "authors": "Tarun Yadav, Koustav Sadhukhan, Rao Arvind Mallari", "title": "Approximation Algorithm for N-distance Minimal Vertex Cover Problem", "comments": "5 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution of large scale networks demand for efficient way of communication\nin the networks. One way to propagate information in the network is to find\nvertex cover. In this paper we describe a variant of vertex cover problem\nnaming it N-distance Vertex Minimal Cover(N-MVC) Problem to optimize\ninformation propagation throughout the network. A minimum subset of vertices of\na unweighted and undirected graph G = (V, E) is called N-MVC if for all v in V\n, v is at distance less than or equal to N from at least one of the the\nvertices in N-MVC. In the following paper, this problem is defined, formulated\nand an approximation algorithm is proposed with discussion on its correctness\nand upper bound.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 09:58:17 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Yadav", "Tarun", ""], ["Sadhukhan", "Koustav", ""], ["Mallari", "Rao Arvind", ""]]}, {"id": "1606.03233", "submitter": "Astrid Pieterse", "authors": "Bart M.P. Jansen and Astrid Pieterse", "title": "Optimal Sparsification for Some Binary CSPs Using Low-degree Polynomials", "comments": "Updated the cross-composition in lemma 18 (minor update), since the\n  previous version did NOT satisfy requirement 4 of lemma 18 (the proof of\n  Claim 20 was incorrect)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes to what extent it is possible to efficiently reduce the\nnumber of clauses in NP-hard satisfiability problems, without changing the\nanswer. Upper and lower bounds are established using the concept of\nkernelization. Existing results show that if NP is not contained in coNP/poly,\nno efficient preprocessing algorithm can reduce n-variable instances of CNF-SAT\nwith d literals per clause, to equivalent instances with $O(n^{d-e})$ bits for\nany e > 0. For the Not-All-Equal SAT problem, a compression to size\n$\\~O(n^{d-1})$ exists. We put these results in a common framework by analyzing\nthe compressibility of binary CSPs. We characterize constraint types based on\nthe minimum degree of multivariate polynomials whose roots correspond to the\nsatisfying assignments, obtaining (nearly) matching upper and lower bounds in\nseveral settings. Our lower bounds show that not just the number of\nconstraints, but also the encoding size of individual constraints plays an\nimportant role. For example, for Exact Satisfiability with unbounded clause\nlength it is possible to efficiently reduce the number of constraints to n+1,\nyet no polynomial-time algorithm can reduce to an equivalent instance with\n$O(n^{2-e})$ bits for any e > 0, unless NP is a subset of coNP/poly.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 08:54:12 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 09:07:02 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 13:10:53 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Jansen", "Bart M. P.", ""], ["Pieterse", "Astrid", ""]]}, {"id": "1606.03326", "submitter": "Zhi-Hua Zhou", "authors": "Chao Qian, Yang Yu, Zhi-Hua Zhou", "title": "A Lower Bound Analysis of Population-based Evolutionary Algorithms for\n  Pseudo-Boolean Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms (EAs) are population-based general-purpose\noptimization algorithms, and have been successfully applied in various\nreal-world optimization tasks. However, previous theoretical studies often\nemploy EAs with only a parent or offspring population and focus on specific\nproblems. Furthermore, they often only show upper bounds on the running time,\nwhile lower bounds are also necessary to get a complete understanding of an\nalgorithm. In this paper, we analyze the running time of the\n($\\mu$+$\\lambda$)-EA (a general population-based EA with mutation only) on the\nclass of pseudo-Boolean functions with a unique global optimum. By applying the\nrecently proposed switch analysis approach, we prove the lower bound $\\Omega(n\n\\ln n+ \\mu + \\lambda n\\ln\\ln n/ \\ln n)$ for the first time. Particularly on the\ntwo widely-studied problems, OneMax and LeadingOnes, the derived lower bound\ndiscloses that the ($\\mu$+$\\lambda$)-EA will be strictly slower than the\n(1+1)-EA when the population size $\\mu$ or $\\lambda$ is above a moderate order.\nOur results imply that the increase of population size, while usually desired\nin practice, bears the risk of increasing the lower bound of the running time\nand thus should be carefully considered.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 13:59:16 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Qian", "Chao", ""], ["Yu", "Yang", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1606.03585", "submitter": "Aarthi Sundaram", "authors": "Itai Arad, Adam Bouland, Daniel Grier, Miklos Santha, Aarthi Sundaram\n  and Shengyu Zhang", "title": "On the complexity of probabilistic trials for hidden satisfiability\n  problems", "comments": "24 pages, 2 figures. To appear in the 41st International Symposium on\n  Mathematical Foundations of Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the minimum amount of information and time needed to solve 2SAT? When\nthe instance is known, it can be solved in polynomial time, but is this also\npossible without knowing the instance? Bei, Chen and Zhang (STOC '13)\nconsidered a model where the input is accessed by proposing possible\nassignments to a special oracle. This oracle, on encountering some constraint\nunsatisfied by the proposal, returns only the constraint index. It turns out\nthat, in this model, even 1SAT cannot be solved in polynomial time unless P=NP.\nHence, we consider a model in which the input is accessed by proposing\nprobability distributions over assignments to the variables. The oracle then\nreturns the index of the constraint that is most likely to be violated by this\ndistribution. We show that the information obtained this way is sufficient to\nsolve 1SAT in polynomial time, even when the clauses can be repeated. For 2SAT,\nas long as there are no repeated clauses, in polynomial time we can even learn\nan equivalent formula for the hidden instance and hence also solve it.\nFurthermore, we extend these results to the quantum regime. We show that in\nthis setting 1QSAT can be solved in polynomial time up to constant precision,\nand 2QSAT can be learnt in polynomial time up to inverse polynomial precision.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 12:44:40 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Arad", "Itai", ""], ["Bouland", "Adam", ""], ["Grier", "Daniel", ""], ["Santha", "Miklos", ""], ["Sundaram", "Aarthi", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1606.03634", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra, David E. Narv\\'aez", "title": "The Opacity of Backbones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper approaches, using structural complexity theory, the question of\nwhether there is a chasm between knowing an object exists and getting one's\nhands on the object or its properties. In particular, we study the\nnontransparency of so-called backbones. A backbone of a boolean formula $F$ is\na collection $S$ of its variables for which there is a unique partial\nassignment $a_S$ such that $F[a_S]$ is satisfiable [MZK+99,WGS03]. We show\nthat, under the widely believed assumption that integer factoring is hard,\nthere exist sets of boolean formulas that have obvious, nontrivial backbones\nyet finding the values, $a_S$, of those backbones is intractable. We also show\nthat, under the same assumption, there exist sets of boolean formulas that\nobviously have large backbones yet producing such a backbone $S$ is\nintractable. Furthermore, we show that if integer factoring is not merely\nworst-case hard but is frequently hard, as is widely believed, then the\nfrequency of hardness in our two results is not too much less than that\nfrequency. These results hold more generally, namely, in the settings where,\nrespectively, one's assumption is that P $\\neq$ NP $\\cap$ coNP or that some\nproblem in NP $\\cap$ coNP is frequently hard.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 21:49:24 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 16:12:11 GMT"}, {"version": "v3", "created": "Sun, 18 Dec 2016 23:54:22 GMT"}, {"version": "v4", "created": "Sat, 28 Jan 2017 20:47:18 GMT"}, {"version": "v5", "created": "Mon, 14 Jan 2019 15:13:28 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Hemaspaandra", "Lane A.", ""], ["Narv\u00e1ez", "David E.", ""]]}, {"id": "1606.03878", "submitter": "Zhaohui Wei", "authors": "Jamie Sikora and Antonios Varvitsiotis and Zhaohui Wei", "title": "Device-independent dimension tests in the prepare-and-measure scenario", "comments": "To appear in Phys. Rev. A", "journal-ref": "Phys. Rev. A 94, 042125 (2016)", "doi": "10.1103/PhysRevA.94.042125", "report-no": null, "categories": "quant-ph cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing the dimension of an unknown quantum system in a device-independent\nmanner, i.e., using only the measurement statistics, is a fundamental task in\nquantum physics and quantum information theory. In this paper, we consider this\nproblem in the prepare-and-measure scenario. Specifically, we provide a lower\nbound on the dimension of the prepared quantum systems which is a function that\nonly depends on the measurement statistics. Furthermore, we show that our bound\nperforms well on several examples. {In particular}, we show that our bound\nprovides new insights into the notion of dimension witness, and we also use it\nto show that the sets of restricted-dimensional prepare-and-measure\ncorrelations are not always convex.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 09:49:30 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2016 12:45:56 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Sikora", "Jamie", ""], ["Varvitsiotis", "Antonios", ""], ["Wei", "Zhaohui", ""]]}, {"id": "1606.04016", "submitter": "Lijie Chen", "authors": "Lijie Chen", "title": "Adaptivity vs Postselection", "comments": "accepted for presentation in ISAAC 2016; updated to the latest\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following problem: with the power of postselection (classically\nor quantumly), what is your ability to answer adaptive queries to certain\nlanguages? More specifically, for what kind of computational classes\n$\\mathcal{C}$, we have $\\mathsf{P}^{\\mathcal{C}}$ belongs to $\\mathsf{PostBPP}$\nand $\\mathsf{PostBQP}$? While a complete answer to the above question seems\nimpossible given the development of present computational complexity theory. We\nstudy the analogous question in query complexity, which sheds light on the\nlimitation of {\\em relativized} methods (the relativization barrier) to the\nabove question.\n  Informally, we show that, for a partial function $f$, if there is no\nefficient (In the world of query complexity, being efficient means using\n$O(\\operatorname*{polylog}(n))$ time.) {\\em small bounded-error} algorithm for\n$f$ classically or quantumly, then there is no efficient postselection\nbounded-error algorithm to answer adaptive queries to $f$ classically or\nquantumly. Our results imply a new proof for the classical oracle separation\n$\\mathsf{P}^{\\mathsf{NP}^{\\mathcal{O}}} \\not\\subset \\mathsf{PP}^{\\mathcal{O}}$.\nThey also lead to a new oracle separation\n$\\mathsf{P}^{\\mathsf{SZK}^{\\mathcal{O}}} \\not\\subset\n\\mathsf{PP}^{\\mathcal{O}}$.\n  Our result also implies a hardness amplification construction for polynomial\napproximation: given a function $f$ on $n$ bits, we construct an\nadaptive-version of $f$, denoted by $F$, on $O(m \\cdot n)$ bits, such that if\n$f$ requires large degree to approximate to error $2/3$ in a certain one-sided\nsense, then $F$ requires large degree to approximate even to error $1/2 -\n2^{-m}$. Our construction achieves the same amplification in the work of Thaler\n(ICALP, 2016), by composing a function with $O(\\log n)$ {\\em deterministic\nquery complexity}.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 16:13:28 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2016 16:58:33 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Chen", "Lijie", ""]]}, {"id": "1606.04069", "submitter": "Saugata Basu", "authors": "Saugata Basu and Cordian Riener", "title": "Bounds on the individual Betti numbers of complex varieties, stability\n  and algorithms", "comments": "Stronger results follow using the Lefschetz hyperplane theorem for\n  singular varieties", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove graded bounds on the individual Betti numbers of affine and\nprojective complex varieties. In particular, we give for each $p,d,r$, explicit\nbounds on the $p$-th Betti numbers of affine and projective subvarieties of\n$\\mathrm{C}^k$, $\\mathbb{P}^k_{\\mathrm{C}}$, as well as products of projective\nspaces, defined by $r$ polynomials of degrees at most $d$ as a function of\n$p,d$ and $r$. Unlike previous bounds these bounds are independent of $k$, the\ndimension of the ambient space. We also prove as consequences of our technique\ncertain homological and representational stability results for sequences of\ncomplex projective varieties which could be of independent interest. Finally,\nwe highlight differences in computational complexities of the problem of\ncomputing Betti numbers of complex as opposed to real projective varieties.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 19:06:45 GMT"}, {"version": "v2", "created": "Fri, 1 Jul 2016 00:52:59 GMT"}, {"version": "v3", "created": "Tue, 19 Jul 2016 14:10:33 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Basu", "Saugata", ""], ["Riener", "Cordian", ""]]}, {"id": "1606.04085", "submitter": "Jeroen Zuiddam", "authors": "Matthias Christandl and Jeroen Zuiddam", "title": "Tensor surgery and tensor rank", "comments": "(accepted for publication in Comm. Complexity)", "journal-ref": "J. comput. complex. (2018)", "doi": "10.1007/s00037-018-0164-8", "report-no": null, "categories": "math.CO cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for transforming low-order tensors into higher-order\ntensors and apply it to tensors defined by graphs and hypergraphs. The\ntransformation proceeds according to a surgery-like procedure that splits\nvertices, creates and absorbs virtual edges and inserts new vertices and edges.\nWe show that tensor surgery is capable of preserving the low rank structure of\nan initial tensor decomposition and thus allows to prove nontrivial upper\nbounds on tensor rank, border rank and asymptotic rank of the final tensors. We\nillustrate our method with a number of examples. Tensor surgery on the triangle\ngraph, which corresponds to the matrix multiplication tensor, leads to\nnontrivial rank upper bounds for all odd cycle graphs, which correspond to the\ntensors of iterated matrix multiplication. In the asymptotic setting we obtain\nupper bounds in terms of the matrix multiplication exponent $\\omega$ and the\nrectangular matrix multiplication parameter $\\alpha$. These bounds are optimal\nif $\\omega$ equals two. We also give examples that illustrate that tensor\nsurgery on general graphs might involve the absorption of virtual hyperedges\nand we provide an example of tensor surgery on a hypergraph. Besides its\nrelevance in algebraic complexity theory, our work has applications in quantum\ninformation theory and communication complexity.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 19:55:05 GMT"}, {"version": "v2", "created": "Tue, 23 Aug 2016 14:51:31 GMT"}, {"version": "v3", "created": "Fri, 26 Jan 2018 12:20:44 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Christandl", "Matthias", ""], ["Zuiddam", "Jeroen", ""]]}, {"id": "1606.04200", "submitter": "Mrinal Kumar", "authors": "Suryajith Chillara, Mrinal Kumar, Ramprasad Saptharishi, V Vinay", "title": "The Chasm at Depth Four, and Tensor Rank : Old results, new insights", "comments": "Correction - tensor rank is sub-multiplicative. The earlier version\n  incorrectly mentioned that it is multiplicative", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agrawal and Vinay [AV08] showed how any polynomial size arithmetic circuit\ncan be thought of as a depth four arithmetic circuit of subexponential size.\nThe resulting circuit size in this simulation was more carefully analyzed by\nKorian [Koiran] and subsequently by Tavenas [Tav13]. We provide a simple proof\nof this chain of results. We then abstract the main ingredient to apply it to\nformulas and constant depth circuits, and show more structured depth reductions\nfor them.\n  In an apriori surprising result, Raz [Raz10] showed that for any $n$ and $d$,\nsuch that $ \\omega(1) \\leq d \\leq O\\left(\\frac{\\log n}{\\log\\log n}\\right)$,\nconstructing explicit tensors $T:[n]^d \\rightarrow F$ of high enough rank would\nimply superpolynomial lower bounds for arithmetic formulas over the field $F$.\nUsing the additional structure we obtain from our proof of the depth reduction\nfor arithmetic formulas, we give a new and arguably simpler proof of this\nconnection. We also extend this result for homogeneous formulas to show that,\nin fact, the connection holds for any $d$ such that $\\omega(1) \\leq d \\leq\nn^{o(1)}$.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 04:37:17 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 03:42:53 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Chillara", "Suryajith", ""], ["Kumar", "Mrinal", ""], ["Saptharishi", "Ramprasad", ""], ["Vinay", "V", ""]]}, {"id": "1606.04253", "submitter": "Vladimir Lysikov", "authors": "Markus Bl\\\"aser, Vladimir Lysikov", "title": "On degeneration of tensors and algebras", "comments": "11 pages; accepted at MFCS 2016", "journal-ref": "41st International Symposium on Mathematical Foundations of\n  Computer Science (MFCS 2016), LIPIcs vol.58, pp. 19:1--19:11, 2016", "doi": "10.4230/LIPIcs.MFCS.2016.19", "report-no": null, "categories": "cs.CC math.AG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important building block in all current asymptotically fast algorithms for\nmatrix multiplication are tensors with low border rank, that is, tensors whose\nborder rank is equal or very close to their size. To find new asymptotically\nfast algorithms for matrix multiplication, it seems to be important to\nunderstand those tensors whose border rank is as small as possible, so called\ntensors of minimal border rank.\n  We investigate the connection between degenerations of associative algebras\nand degenerations of their structure tensors in the sense of Strassen. It\nallows us to describe an open subset of $n \\times n \\times n$ tensors of\nminimal border rank in terms of smoothability of commutative algebras. We\ndescribe the smoothable algebra associated to the Coppersmith-Winograd tensor\nand prove a lower bound for the border rank of the tensor used in the \"easy\nconstruction\" of Coppersmith and Winograd.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 08:47:35 GMT"}], "update_date": "2016-08-25", "authors_parsed": [["Bl\u00e4ser", "Markus", ""], ["Lysikov", "Vladimir", ""]]}, {"id": "1606.04315", "submitter": "Ammar Daskin", "authors": "Ammar Daskin and Sabre Kais", "title": "An Ancilla Based Quantum Simulation Framework for Non-Unitary Matrices", "comments": null, "journal-ref": null, "doi": "10.1007/s11128-016-1452-3", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success probability in an ancilla based circuit generally decreases\nexponentially in the number of qubits consisted in the ancilla. Although the\nprobability can be amplified through the amplitude amplification process, the\ninput dependence of the amplitude amplification makes difficult to sequentially\ncombine two or more ancilla based circuits. A new version of the amplitude\namplification known as the oblivious amplitude amplification runs independently\nof the input to the system register. This allow us to to sequentially combine\ntwo or more ancilla based circuits. However, this type of the amplification\nonly works when the considered system is unitary or non-unitary but somehow\nclose to a unitary.\n  In this paper, we present a general framework to simulate non-unitary\nmatrices on ancilla based quantum circuits in which the success probability is\nmaximized by using the oblivious amplitude amplification. In particular, we\nshow how to extend a non-unitary matrix to an almost unitary matrix. We then\nsimulate the extended matrix by using an ancilla based circuit design along\nwith the oblivious amplitude amplification. Measuring the distance of the\nproduced matrix to the closest unitary unitary matrix, a lower bound for the\nfidelity of the final state obtained from the oblivious amplitude amplification\nprocess is presented. Numerical simulations for random matrices of different\nsizes show that independent of the system size, the final amplified\nprobabilities are generally around 0.75 and the fidelity of the final state is\nmostly high and around 0.95. Furthermore, we discuss the complexity analysis\nand show that combining two such ancilla based circuits, a matrix product can\nbe implemented. This may lead us to efficiently implement matrix functions\nrepresented as infinite matrix products on quantum computers.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 11:32:06 GMT"}, {"version": "v2", "created": "Sat, 10 Dec 2016 12:27:35 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Daskin", "Ammar", ""], ["Kais", "Sabre", ""]]}, {"id": "1606.04383", "submitter": "Sebastian Kuhnert", "authors": "V. Arvind, Frank Fuhlbr\\\"uck, Johannes K\\\"obler, Sebastian Kuhnert and\n  Gaurav Rattan", "title": "The Parameterized Complexity of Fixing Number and Vertex\n  Individualization in Graphs", "comments": "An abridged version of this article appears in the proceedings of\n  MFCS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the complexity of the following problems:\n  Given a colored graph X=(V,E,c), compute a minimum cardinality set S of\nvertices such that no nontrivial automorphism of X fixes all vertices in S. A\nclosely related problem is computing a minimum base S for a permutation group G\non [n] given by generators, i.e., a minimum cardinality subset S of [n] such\nthat no nontrivial permutation in G fixes all elements of S. Our focus is\nmainly on the parameterized complexity of these problems. We show that when\nk=|S| is treated as parameter, then both problems are MINI[1]-hard. For the\ndual problems, where k=n-|S| is the parameter, we give FPT algorithms.\n  A notion closely related to fixing is called individualization.\nIndividualization combined with the Weisfeiler-Leman procedure is a fundamental\ntechnique in algorithms for Graph Isomorphism. Motivated by the power of\nindividualization, in the present paper we explore the complexity of\nindividualization: what is the minimum number of vertices we need to\nindividualize in a given graph such that color refinement \"succeeds\" on it.\nHere \"succeeds\" could have different interpretations, and we consider the\nfollowing: It could mean the individualized graph becomes: (a) discrete, (b)\namenable, (c) compact, or (d) refinable. In particular, we study the\nparameterized versions of these problems where the parameter is the number of\nvertices individualized. We show a dichotomy: For graphs with color classes of\nsize at most 3 these problems can be solved in polynomial time (even in\nlogspace), while starting from color class size 4 they become W[P]-hard.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 14:19:09 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Arvind", "V.", ""], ["Fuhlbr\u00fcck", "Frank", ""], ["K\u00f6bler", "Johannes", ""], ["Kuhnert", "Sebastian", ""], ["Rattan", "Gaurav", ""]]}, {"id": "1606.04550", "submitter": "Aviad Rubinstein", "authors": "Aviad Rubinstein", "title": "Settling the complexity of computing approximate two-player Nash\n  equilibria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that there exists a constant $\\epsilon>0$ such that, assuming the\nExponential Time Hypothesis for PPAD, computing an $\\epsilon$-approximate Nash\nequilibrium in a two-player (nXn) game requires quasi-polynomial time,\n$n^{\\log^{1-o(1)} n}$. This matches (up to the o(1) term) the algorithm of\nLipton, Markakis, and Mehta [LMM03].\n  Our proof relies on a variety of techniques from the study of\nprobabilistically checkable proofs (PCP); this is the first time that such\nideas are used for a reduction between problems inside PPAD.\n  En route, we also prove new hardness results for computing Nash equilibria in\ngames with many players. In particular, we show that computing an\n$\\epsilon$-approximate Nash equilibrium in a game with n players requires\n$2^{\\Omega(n)}$ oracle queries to the payoff tensors. This resolves an open\nproblem posed by Hart and Nisan [HN13], Babichenko [Bab14], and Chen et al.\n[CCT15]. In fact, our results for n-player games are stronger: they hold with\nrespect to the $(\\epsilon,\\delta)$-WeakNash relaxation recently introduced by\nBabichenko et al. [BPR16].\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 20:22:28 GMT"}, {"version": "v2", "created": "Mon, 29 Aug 2016 20:35:38 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["Rubinstein", "Aviad", ""]]}, {"id": "1606.04592", "submitter": "Anand Kumar Narayanan", "authors": "Zeyu Guo, Anand Kumar Narayanan and Chris Umans", "title": "Algebraic Problems Equivalent to Beating Exponent 3/2 for Polynomial\n  Factorization over Finite Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fastest known algorithm for factoring univariate polynomials over finite\nfields is the Kedlaya-Umans (fast modular composition) implementation of the\nKaltofen-Shoup algorithm. It is randomized and takes $\\widetilde{O}(n^{3/2}\\log\nq + n \\log^2 q)$ time to factor polynomials of degree $n$ over the finite field\n$\\mathbb{F}_q$ with $q$ elements. A significant open problem is if the $3/2$\nexponent can be improved. We study a collection of algebraic problems and\nestablish a web of reductions between them. A consequence is that an algorithm\nfor any one of these problems with exponent better than $3/2$ would yield an\nalgorithm for polynomial factorization with exponent better than $3/2$.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 23:32:48 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Guo", "Zeyu", ""], ["Narayanan", "Anand Kumar", ""], ["Umans", "Chris", ""]]}, {"id": "1606.04649", "submitter": "Raghunath Tewari", "authors": "Vivek Anand T Kallampally and Raghunath Tewari", "title": "Trading Determinism for Time in Space Bounded Computations", "comments": "Accepted in MFCS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Savitch showed in $1970$ that nondeterministic logspace (NL) is contained in\ndeterministic $\\mathcal{O}(\\log^2 n)$ space but his algorithm requires\nquasipolynomial time. The question whether we can have a deterministic\nalgorithm for every problem in NL that requires polylogarithmic space and\nsimultaneously runs in polynomial time was left open.\n  In this paper we give a partial solution to this problem and show that for\nevery language in NL there exists an unambiguous nondeterministic algorithm\nthat requires $\\mathcal{O}(\\log^2 n)$ space and simultaneously runs in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 05:51:08 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Kallampally", "Vivek Anand T", ""], ["Tewari", "Raghunath", ""]]}, {"id": "1606.05050", "submitter": "Michael A. Forbes", "authors": "Michael A. Forbes, Amir Shpilka, Iddo Tzameret, Avi Wigderson", "title": "Proof Complexity Lower Bounds from Algebraic Circuit Complexity", "comments": null, "journal-ref": "Conference on Computational Complexity (CCC 2016)", "doi": "10.4230/LIPIcs.CCC.2016.32", "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give upper and lower bounds on the power of subsystems of the Ideal Proof\nSystem (IPS), the algebraic proof system recently proposed by Grochow and\nPitassi, where the circuits comprising the proof come from various restricted\nalgebraic circuit classes. This mimics an established research direction in the\nboolean setting for subsystems of Extended Frege proofs, where proof-lines are\ncircuits from restricted boolean circuit classes. Except one, all of the\nsubsystems considered in this paper can simulate the well-studied\nNullstellensatz proof system, and prior to this work there were no known lower\nbounds when measuring proof size by the algebraic complexity of the polynomials\n(except with respect to degree, or to sparsity).\n  We give two general methods of converting certain algebraic lower bounds into\nproof complexity ones. Our methods require stronger notions of lower bounds,\nwhich lower bound a polynomial as well as an entire family of polynomials it\ndefines. Our techniques are reminiscent of existing methods for converting\nboolean circuit lower bounds into related proof complexity results, such as\nfeasible interpolation. We obtain the relevant types of lower bounds for a\nvariety of classes (sparse polynomials, depth-3 powering formulas, read-once\noblivious algebraic branching programs, and multilinear formulas), and infer\nthe relevant proof complexity results. We complement our lower bounds by giving\nshort refutations of the previously-studied subset-sum axiom using IPS\nsubsystems, allowing us to conclude strict separations between some of these\nsubsystems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 05:01:58 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Forbes", "Michael A.", ""], ["Shpilka", "Amir", ""], ["Tzameret", "Iddo", ""], ["Wigderson", "Avi", ""]]}, {"id": "1606.05331", "submitter": "Bruce Smith", "authors": "Bruce K. Smith", "title": "The Pattern Basis Approach to Circuit Complexity", "comments": "101 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and motivate a proposed new approach to lowerbounding the circuit\ncomplexity of boolean functions, based on a new formalization of \"patterns\" as\nelements of a special basis of the vector space of all truth table properties.\nWe prove that a \"pattern basis\" with certain properties would lead to a useful\ncomplexity formula of a specific form, and speculate on how to find such a\nbasis. This formula might take as long to compute on arbitrary functions as a\nbrute-force search among circuits, thus addressing the natural proofs barrier,\nbut has a form amenable to proving lower bounds for well-understood explicit\nfunctions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 19:43:28 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Smith", "Bruce K.", ""]]}, {"id": "1606.05626", "submitter": "Justin Yirka", "authors": "Sevag Gharibian and Justin Yirka", "title": "The complexity of simulating local measurements on quantum systems", "comments": "38 pages, 0 figures. Fixed bug in proof of Lemma 4.3 by extending\n  Lemma 4.1 and redefining gamma' (see footnote 13)", "journal-ref": "Quantum 3, 189 (2019)", "doi": "10.22331/q-2019-09-30-189", "report-no": null, "categories": "quant-ph cond-mat.str-el cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important task in quantum physics is the estimation of local quantities\nfor ground states of local Hamiltonians. Recently, [Ambainis, CCC 2014] defined\nthe complexity class P^QMA[log], and motivated its study by showing that the\nphysical task of estimating the expectation value of a local observable against\nthe ground state of a local Hamiltonian is P^QMA[log]-complete. In this paper,\nwe continue the study of P^QMA[log], obtaining the following lower and upper\nbounds.\n  Lower bounds (hardness results): (1) The P^QMA[log]-completeness result of\n[Ambainis, CCC 2014] requires O(log n)-local observables and Hamiltonians. We\nshow that simulating even a single qubit measurement on ground states of\n5-local Hamiltonians is P^QMA[log]-complete, resolving an open question of\nAmbainis. (2) We formalize the complexity theoretic study of estimating\ntwo-point correlation functions against ground states, and show that this task\nis similarly P^QMA[log]-complete. (3) We identify a flaw in [Ambainis, CCC\n2014] regarding a P^UQMA[log]-hardness proof for estimating spectral gaps of\nlocal Hamiltonians. By introducing a \"query validation\" technique, we build on\n[Ambainis, CCC 2014] to obtain P^UQMA[log]-hardness for estimating spectral\ngaps under polynomial-time Turing reductions.\n  Upper bounds (containment in complexity classes): P^QMA[log] is thought of as\n\"slightly harder\" than QMA. We justify this formally by exploiting the\nhierarchical voting technique of [Beigel, Hemachandra, Wechsung, SCT 1989] to\nshow P^QMA[log] is in PP. This improves the containment QMA is in PP [Kitaev,\nWatrous, STOC 2000].\n  This work contributes a rigorous treatment of the subtlety involved in\nstudying oracle classes in which the oracle solves a promise problem. This is\nparticularly relevant for quantum complexity theory, where most natural classes\nsuch as BQP and QMA are defined as promise classes.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 19:09:38 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 16:20:56 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 20:49:22 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 19:47:26 GMT"}, {"version": "v5", "created": "Tue, 7 Apr 2020 20:51:47 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Gharibian", "Sevag", ""], ["Yirka", "Justin", ""]]}, {"id": "1606.06581", "submitter": "Cornelius Brand", "authors": "Cornelius Brand, Holger Dell, Marc Roth", "title": "Fine-grained dichotomies for the Tutte plane and Boolean #CSP", "comments": "16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Jaeger, Vertigan, and Welsh [15] proved a dichotomy for the complexity of\nevaluating the Tutte polynomial at fixed points: The evaluation is #P-hard\nalmost everywhere, and the remaining points admit polynomial-time algorithms.\nDell, Husfeldt, and Wahl\\'en [9] and Husfeldt and Taslaman [12], in combination\nwith Curticapean [7], extended the #P-hardness results to tight lower bounds\nunder the counting exponential time hypothesis #ETH, with the exception of the\nline $y=1$, which was left open. We complete the dichotomy theorem for the\nTutte polynomial under #ETH by proving that the number of all acyclic subgraphs\nof a given $n$-vertex graph cannot be determined in time $exp(o(n))$ unless\n#ETH fails.\n  Another dichotomy theorem we strengthen is the one of Creignou and Hermann\n[6] for counting the number of satisfying assignments to a constraint\nsatisfaction problem instance over the Boolean domain. We prove that all\n#P-hard cases are also hard under #ETH. The main ingredient is to prove that\nthe number of independent sets in bipartite graphs with $n$ vertices cannot be\ncomputed in time $exp(o(n))$ unless #ETH fails. In order to prove our results,\nwe use the block interpolation idea by Curticapean [7] and transfer it to\nsystems of linear equations that might not directly correspond to\ninterpolation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 14:06:11 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Brand", "Cornelius", ""], ["Dell", "Holger", ""], ["Roth", "Marc", ""]]}, {"id": "1606.06801", "submitter": "EPTCS", "authors": "Ciar\\'an M. Lee (University of Oxford), Matty J. Hoban (University of\n  Oxford)", "title": "The Information Content of Systems in General Physical Theories", "comments": "In Proceedings PC 2016, arXiv:1606.06513", "journal-ref": "EPTCS 214, 2016, pp. 22-28", "doi": "10.4204/EPTCS.214.5", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What kind of object is a quantum state? Is it an object that encodes an\nexponentially growing amount of information (in the size of the system) or more\nakin to a probability distribution? It turns out that these questions are\nsensitive to what we do with the information. For example, Holevo's bound tells\nus that n qubits only encode n bits of classical information but for certain\ncommunication complexity tasks there is an exponential separation between\nquantum and classical resources. Instead of just contrasting quantum and\nclassical physics, we can place both within a broad landscape of physical\ntheories and ask how non-quantum (and non-classical) theories are different\nfrom, or more powerful than quantum theory. For example, in communication\ncomplexity, certain (non-quantum) theories can trivialise all communication\ncomplexity tasks. In recent work [C. M. Lee and M. J. Hoban, Proc. Royal Soc. A\n472 (2190), 2016], we showed that the immense power of the information content\nof states in general (non-quantum) physical theories is not limited to\ncommunication complexity. We showed that, in general physical theories, states\ncan be taken as \"advice\" for computers in these theories and this advice allows\nthe computers to easily solve any decision problem. Aaronson has highlighted\nthe close connection between quantum communication complexity and quantum\ncomputations that take quantum advice, and our work gives further indications\nthat this is a very general connection. In this work, we review the results in\nour previous work and discuss the intricate relationship between communication\ncomplexity and computers taking advice for general theories.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 01:59:09 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Lee", "Ciar\u00e1n M.", "", "University of Oxford"], ["Hoban", "Matty J.", "", "University of\n  Oxford"]]}, {"id": "1606.06803", "submitter": "EPTCS", "authors": "Richard Whyman (The University of Leeds)", "title": "Physical Computation, P/poly and P/log*", "comments": "In Proceedings PC 2016, arXiv:1606.06513", "journal-ref": "EPTCS 214, 2016, pp. 41-52", "doi": "10.4204/EPTCS.214.7", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give a framework for describing how abstract systems can be\nused to compute if no randomness or error is involved. Using this we describe a\nclass of classical \"physical\" computation systems whose computational\ncapabilities in polynomial time are equivalent to P/poly. We then extend our\nframework to describe how measurement and transformation times may vary\ndepending on their input. Finally we describe two classes of classical\n\"physical\" computation systems in this new framework whose computational\ncapabilities in polynomial time are equivalent to P/poly and P/log*.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 01:59:29 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Whyman", "Richard", "", "The University of Leeds"]]}, {"id": "1606.06872", "submitter": "Adi Rosen", "authors": "Iordanis Kerenidis, Adi Ros\\'en, Florent Urrutia", "title": "Multi-Party Protocols, Information Complexity and Privacy", "comments": "32 pages ; MFCS2016 ; ACM Transactions on Computation Theory, to\n  appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new information theoretic measure that we call Public\nInformation Complexity (PIC), as a tool for the study of multi-party\ncomputation protocols, and of quantities such as their communication\ncomplexity, or the amount of randomness they require in the context of\ninformation-theoretic private computations. We are able to use this measure\ndirectly in the natural asynchronous message-passing peer-to-peer model and\nshow a number of interesting properties and applications of our new notion: the\nPublic Information Complexity is a lower bound on the Communication Complexity\nand an upper bound on the Information Complexity; the difference between the\nPublic Information Complexity and the Information Complexity provides a lower\nbound on the amount of randomness used in a protocol; any communication\nprotocol can be compressed to its Public Information Cost; an explicit\ncalculation of the zero-error Public Information Complexity of the $k$-party,\n$n$-bit Parity function, where a player outputs the bit-wise parity of the\ninputs. The latter result also establishes that the amount of randomness needed\nby a private protocol that computes this function is $\\Omega(n)$.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 10:00:41 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 19:59:18 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2018 17:55:10 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Kerenidis", "Iordanis", ""], ["Ros\u00e9n", "Adi", ""], ["Urrutia", "Florent", ""]]}, {"id": "1606.06913", "submitter": "Oded Regev", "authors": "Daniel Dadush and Oded Regev", "title": "Towards Strong Reverse Minkowski-type Inequalities for Lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CC math.FA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a natural reverse Minkowski-type inequality for lattices, which\ngives upper bounds on the number of lattice points in a Euclidean ball in terms\nof sublattice determinants, and conjecture its optimal form. The conjecture\nexhibits a surprising wealth of connections to various areas in mathematics and\ncomputer science, including a conjecture motivated by integer programming by\nKannan and Lov\\'asz (Annals of Math. 1988), a question from additive\ncombinatorics asked by Green, a question on Brownian motions asked by\nSaloff-Coste (Colloq. Math. 2010), a theorem by Milman and Pisier from convex\ngeometry (Ann. Probab. 1987), worst-case to average-case reductions in\nlattice-based cryptography, and more. We present these connections, provide\nevidence for the conjecture, and discuss possible approaches towards a proof.\nOur main technical contribution is in proving that our conjecture implies the\n$\\ell_2$ case of the Kannan and Lov\\'asz conjecture. The proof relies on a\nnovel convex relaxation for the covering radius, and a rounding procedure for\nbased on \"uncrossing\" lattice subspaces.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 11:50:09 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Dadush", "Daniel", ""], ["Regev", "Oded", ""]]}, {"id": "1606.07467", "submitter": "Zoltan Toroczkai", "authors": "Xunzhao Yin, Behnam Sedighi, Melinda Varga, Maria Ercsey-Ravasz,\n  Zoltan Toroczkai and Xiaobo Sharon Hu", "title": "Efficient Analog Circuits for Boolean Satisfiability", "comments": "9 pages, 9 Figures, 1 Table. Added journal info in version 2: IEEE\n  Transactions on Very Large Scale Integration Systems (TVLSI) vol 26, No 1,\n  January 2018, pp 155-167. DOI: 10.1109/TVLSI.2017.2754192", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.CC physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient solutions to NP-complete problems would significantly benefit both\nscience and industry. However, such problems are intractable on digital\ncomputers based on the von Neumann architecture, thus creating the need for\nalternative solutions to tackle such problems. Recently, a deterministic,\ncontinuous-time dynamical system (CTDS) was proposed (Nat.Phys. {\\bf 7}(12),\n966 (2011)) to solve a representative NP-complete problem, Boolean\nSatisfiability (SAT). This solver shows polynomial analog time-complexity on\neven the hardest benchmark $k$-SAT ($k \\geq 3$) formulas, but at an energy cost\nthrough exponentially driven auxiliary variables. This paper presents a novel\nanalog hardware SAT solver, AC-SAT, implementing the CTDS via incorporating\nnovel, analog circuit design ideas. AC-SAT is intended to be used as a\nco-processor and is programmable for handling different problem specifications.\nIt is especially effective for solving hard $k$-SAT problem instances that are\nchallenging for algorithms running on digital machines. Furthermore, with its\nmodular design, AC-SAT can readily be extended to solve larger size problems,\nwhile the size of the circuit grows linearly with the product of the number of\nvariables and number of clauses. The circuit is designed and simulated based on\na 32nm CMOS technology. SPICE simulation results show speedup factors of\n$\\sim$10$^4$ on even the hardest 3-SAT problems, when compared with a\nstate-of-the-art SAT solver on digital computers. As an example, for hard\nproblems with $N=50$ variables and $M=212$ clauses, solutions are found within\nfrom a few $ns$ to a few hundred $ns$.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 09:30:59 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 22:41:46 GMT"}, {"version": "v3", "created": "Sun, 11 Feb 2018 20:30:52 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Yin", "Xunzhao", ""], ["Sedighi", "Behnam", ""], ["Varga", "Melinda", ""], ["Ercsey-Ravasz", "Maria", ""], ["Toroczkai", "Zoltan", ""], ["Hu", "Xiaobo Sharon", ""]]}, {"id": "1606.07528", "submitter": "EPTCS", "authors": "Quan Yu (Sun Yat-sen University, Qiannan Normal College for\n  Nationalities), Yanjun Li (Peking University, University of Groningen),\n  Yanjing Wang (Peking University)", "title": "A Dynamic Epistemic Framework for Conformant Planning", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 298-318", "doi": "10.4204/EPTCS.215.21", "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a lightweight dynamic epistemic logical framework\nfor automated planning under initial uncertainty. We reduce plan verification\nand conformant planning to model checking problems of our logic. We show that\nthe model checking problem of the iteration-free fragment is PSPACE-complete.\nBy using two non-standard (but equivalent) semantics, we give novel model\nchecking algorithms to the full language and the iteration-free language.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:33:19 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Yu", "Quan", "", "Sun Yat-sen University, Qiannan Normal College for\n  Nationalities"], ["Li", "Yanjun", "", "Peking University, University of Groningen"], ["Wang", "Yanjing", "", "Peking University"]]}, {"id": "1606.07585", "submitter": "Peng Wang", "authors": "Peng Wang, Kai-Yuan Cai", "title": "Representing Extended Finite State Machines for SDL by A Novel Control\n  Model of Discrete Event Systems", "comments": "Sixth International Conference on Quality Software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses EFSM for SDL and transforms EFSM into a novel control\nmodel of discrete event systems. We firstly propose a control model of discrete\nevent systems, where the event set is made up of several conflicting pairs and\ncontrol is implemented to select one event of the pair. Then we transform EFSM\nfor SDL to the control model to clarify the control mechanism functioning in\nSDL flow graphs. This work views the EFSM for SDL in the perspective of\nsupervisory control theory, and this contributes to the field of software\ncybernetics, which explores the theoretically justified interplay of software\nand the control.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 07:26:38 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Wang", "Peng", ""], ["Cai", "Kai-Yuan", ""]]}, {"id": "1606.07910", "submitter": "George Barmpalias Dr", "authors": "George Barmpalias and Andrew Lewis-Pye", "title": "Optimal redundancy in computations from random oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic result in algorithmic information theory is that every infinite\nbinary sequence is computable from a Martin-Loef random infinite binary\nsequence. Proved independently by Kucera and Gacs, this result answered a\nquestion by Charles Bennett and has seen numerous applications in the last 30\nyears. The optimal redundancy in such a coding process has, however, remained\nunknown. If the computation of the first n bits of a sequence requires n + g(n)\nbits of the random oracle, then g is the redundancy of the computation. Kucera\nimplicitly achieved redundancy n log n while Gacs used a more elaborate\nblock-coding procedure which achieved redundancy sqrt(n) log n. Different\napproaches to coding such as the one by Merkle and Mihailovic have not improved\nthis redundancy bound. In this paper we devise a new coding method that\nachieves optimal logarithmic redundancy. Our redundancy bound is exponentially\nsmaller than the previously best known bound and is known to be the best\npossible. It follows that redundancy r log n in computation from a random\noracle is possible for every stream, if and only if r > 1.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2016 13:10:09 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 05:20:36 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Barmpalias", "George", ""], ["Lewis-Pye", "Andrew", ""]]}, {"id": "1606.08014", "submitter": "Yijia Chen", "authors": "Yijia Chen and Joerg Flum", "title": "Some lower bounds in parameterized ${\\rm AC}^0$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate some lower bounds for parameterized problems via parameterized\nclasses corresponding to the classical ${\\rm AC}^0$. Among others, we derive\nsuch a lower bound for all fpt-approximations of the parameterized clique\nproblem and for a parameterized halting problem, which recently turned out to\nlink problems of computational complexity, descriptive complexity, and proof\ntheory. To show the first lower bound, we prove a strong ${\\rm AC}^0$ version\nof the planted clique conjecture: ${\\rm AC}^0$-circuits asymptotically almost\nsurely can not distinguish between a random graph and this graph with a\nrandomly planted clique of any size $\\le n^\\xi$ (where $0 \\le \\xi < 1$).\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2016 09:27:38 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Chen", "Yijia", ""], ["Flum", "Joerg", ""]]}, {"id": "1606.08141", "submitter": "Yixin Cao", "authors": "Yixin Cao and R. B. Sandeep", "title": "Minimum Fill-In: Inapproximability and Almost Tight Lower Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an $n*n$ sparse symmetric matrix with $m$ nonzero entries, performing\nGaussian elimination may turn some zeroes into nonzero values. To maintain the\nmatrix sparse, we would like to minimize the number $k$ of these changes, hence\ncalled the minimum fill-in problem. Agrawal et al.~[FOCS'90] developed the\nfirst approximation algorithm, based on early heuristics by George [SIAM J\nNumer Anal 10] and by Lipton et al.~[SIAM J Numer Anal 16]. The objective\nfunction they used is $m+k$, the number of nonzero elements after elimination.\nAn approximation algorithm using $k$ as the objective function was presented by\nNatanzon et al.~[STOC'98]. These two versions are incomparable in terms of\napproximation.\n  Parameterized algorithms for the problem was first studied by Kaplan et\nal.~[FOCS'94]. Fomin & Villanger [SODA'12] recently gave an algorithm running\nin time $2^{O(\\sqrt{k} \\log k)}+n^{O(1)}$.\n  Hardness results of this problem are surprisingly scarce, and the few known\nones are either weak or have to use nonstandard complexity conjectures. The\nonly inapproximability result by Wu et al.~[IJCAI'15] applies to only the\nobjective function $m+k$, and is grounded on the Small Set Expansion\nConjecture. The only nontrivial parameterized lower bounds, by Bliznets et\nal.~[SODA'16], include a very weak one based on ETH, and a strong one based on\nhardness of subexponential-time approximation of the minimum bisection problem\non regular graphs. For both versions of the problem, we exclude the existence\nof PTASs, assuming P$\\ne$NP, and the existence of $2^{O(n^{1-\\delta})}$-time\napproximation schemes for any positive $\\delta$, assuming ETH. It also implies\na $2^{O(k^{1/2-\\delta})} n^{O(1)}$ parameterized lower bound. Behind these\nresults is a new reduction from vertex cover, which might be of its own\ninterest: All previous reductions for similar problems are from some kind of\ngraph layout problems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 07:02:18 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Cao", "Yixin", ""], ["Sandeep", "R. B.", ""]]}, {"id": "1606.08764", "submitter": "Tomoyuki Yamakami", "authors": "Tomoyuki Yamakami", "title": "Complexity Bounds of Constant-Space Quantum Computation", "comments": "A4, 10pt, pp.26. This is a complete version of an extended abstract\n  that appeared in the Proceedings of the 19th International Conference on\n  Developments in Language Theory (DLT 2015), Liverpool, United Kingdom, July\n  27--30, 2015, Lecture Notes in Computer Science, Springer, vol.9168,\n  pp.426--438, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We realize constant-space quantum computation by measure-many two-way quantum\nfinite automata and evaluate their language recognition power by analyzing\npatterns of their exotic behaviors and by exploring their structural\nproperties. In particular, we show that, when the automata halt \"in finite\nsteps\" along all computation paths, they must terminate in worst-case liner\ntime. In the bounded-error probability case, the acceptance of the automata\ndepends only on the computation paths that terminate within exponentially many\nsteps even if not all computation paths may terminate. We also present a\nclassical simulation of those automata on two-way multi-head probabilistic\nfinite automata with cut points. Moreover, we discuss how the recognition power\nof the automata varies as the automata's acceptance criteria change to error\nfree, one-sided error, bounded error, and unbounded error by comparing the\ncomplexity of their computational powers. We further note that, with the use of\narbitrary complex transition amplitudes, two-way unbounded-error quantum finite\nautomata and two-way bounded-error 2-head quantum finite automata can recognize\ncertain non-recursive languages, whereas two-way error-free quantum finite\nautomata recognize only recursive languages.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 15:56:10 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Yamakami", "Tomoyuki", ""]]}, {"id": "1606.09000", "submitter": "Till Fluschnik", "authors": "Ren\\'e van Bevern, Till Fluschnik, George B. Mertzios, Hendrik Molter,\n  Manuel Sorge, and Ond\\v{r}ej Such\\'y", "title": "The parameterized complexity of finding secluded solutions to some\n  classical optimization problems on graphs", "comments": "Compared to the previous version, this version additionally shows\n  that Small Secluded s-t-Separator is fixed-parameter tractable parameterized\n  by the combination of the solution size and the open neighborhood size\n  (Theorem 3.5). To appear in Discrete Optimization", "journal-ref": "Discrete Optimzation 30:20-50, 2018", "doi": "10.1016/j.disopt.2018.05.002", "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the parameterized complexity of finding secluded solutions\nto classical combinatorial optimization problems on graphs such as finding\nminimum s-t separators, feedback vertex sets, dominating sets, maximum\nindependent sets, and vertex deletion problems for hereditary graph properties:\nHerein, one searches not only to minimize or maximize the size of the solution,\nbut also to minimize the size of its neighborhood. This restriction has\napplications in secure routing and community detection.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 08:42:35 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 09:41:17 GMT"}, {"version": "v3", "created": "Wed, 31 May 2017 12:33:05 GMT"}, {"version": "v4", "created": "Thu, 1 Jun 2017 07:04:31 GMT"}, {"version": "v5", "created": "Tue, 22 May 2018 12:16:02 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["van Bevern", "Ren\u00e9", ""], ["Fluschnik", "Till", ""], ["Mertzios", "George B.", ""], ["Molter", "Hendrik", ""], ["Sorge", "Manuel", ""], ["Such\u00fd", "Ond\u0159ej", ""]]}, {"id": "1606.09065", "submitter": "Yaroslav Shitov", "authors": "Yaroslav Shitov", "title": "The complexity of positive semidefinite matrix factorization", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A$ be a matrix with nonnegative real entries. The PSD rank of $A$ is the\nsmallest integer $k$ for which there exist $k\\times k$ real PSD matrices\n$B_1,\\ldots,B_m$, $C_1,\\ldots,C_n$ satisfying\n$A(i|j)=\\operatorname{tr}(B_iC_j)$ for all $i,j$. This paper determines the\ncomputational complexity status of the PSD rank. Namely, we show that the\nproblem of computing this function is polynomial-time equivalent to the\nexistential theory of the reals.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 12:16:05 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Shitov", "Yaroslav", ""]]}, {"id": "1606.09449", "submitter": "Sebastian Ordyniak", "authors": "Bernhard Bliem, Sebastian Ordyniak, Stefan Woltran", "title": "Clique-Width and Directed Width Measures for Answer-Set Programming", "comments": "A short version of this paper has been accepted to ECAI 2016 and\n  TAASP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disjunctive Answer Set Programming (ASP) is a powerful declarative\nprogramming paradigm whose main decision problems are located on the second\nlevel of the polynomial hierarchy. Identifying tractable fragments and\ndeveloping efficient algorithms for such fragments are thus important\nobjectives in order to complement the sophisticated ASP systems available to\ndate. Hard problems can become tractable if some problem parameter is bounded\nby a fixed constant; such problems are then called fixed-parameter tractable\n(FPT). While several FPT results for ASP exist, parameters that relate to\ndirected or signed graphs representing the program at hand have been neglected\nso far. In this paper, we first give some negative observations showing that\ndirected width measures on the dependency graph of a program do not lead to FPT\nresults. We then consider the graph parameter of signed clique-width and\npresent a novel dynamic programming algorithm that is FPT w.r.t. this\nparameter. Clique-width is more general than the well-known treewidth, and, to\nthe best of our knowledge, ours is the first FPT algorithm for bounded\nclique-width for reasoning problems beyond SAT.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 12:14:33 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2016 12:00:28 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Bliem", "Bernhard", ""], ["Ordyniak", "Sebastian", ""], ["Woltran", "Stefan", ""]]}, {"id": "1606.09514", "submitter": "Gabriel Senno", "authors": "Sophie Laplante, Mathieu Lauri\\`ere, Alexandre Nolin, J\\'er\\'emie\n  Roland, Gabriel Senno", "title": "Robust Bell inequalities from communication complexity", "comments": "Final version for publication in Quantum", "journal-ref": "Quantum 2, 72 (2018)", "doi": "10.22331/q-2018-06-07-72", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The question of how large Bell inequality violations can be, for quantum\ndistributions, has been the object of much work in the past several years. We\nsay that a Bell inequality is normalized if its absolute value does not exceed\n1 for any classical (i.e. local) distribution. Upper and (almost) tight lower\nbounds have been given for the quantum violation of these Bell inequalities in\nterms of number of outputs of the distribution, number of inputs, and the\ndimension of the shared quantum states. In this work, we revisit normalized\nBell inequalities together with another family: inefficiency-resistant Bell\ninequalities. To be inefficiency-resistant, the Bell value must not exceed 1\nfor any local distribution, including those that can abort. This makes the Bell\ninequality resistant to the detection loophole, while a normalized Bell\ninequality is resistant to general local noise. Both these families of Bell\ninequalities are closely related to communication complexity lower bounds. We\nshow how to derive large violations from any gap between classical and quantum\ncommunication complexity, provided the lower bound on classical communication\nis proven using these lower bound techniques. This leads to\ninefficiency-resistant violations that can be exponential in the size of the\ninputs. Finally, we study resistance to noise and inefficiency for these Bell\ninequalities.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 14:40:58 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 16:02:15 GMT"}, {"version": "v3", "created": "Mon, 4 Jun 2018 08:59:51 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Laplante", "Sophie", ""], ["Lauri\u00e8re", "Mathieu", ""], ["Nolin", "Alexandre", ""], ["Roland", "J\u00e9r\u00e9mie", ""], ["Senno", "Gabriel", ""]]}]