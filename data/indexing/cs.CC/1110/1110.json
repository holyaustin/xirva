[{"id": "1110.0187", "submitter": "Minghui Jiang", "authors": "Minghui Jiang and Yong Zhang", "title": "Parameterized complexity in multiple-interval graphs: domination,\n  partition, separation, irredundancy", "comments": "A preliminary version of this article appeared in two parts in COCOON\n  2011 and IPEC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the problem k-Dominating Set and its several variants including\nk-Connected Dominating Set, k-Independent Dominating Set, and k-Dominating\nClique, when parameterized by the solution size k, are W[1]-hard in either\nmultiple-interval graphs or their complements or both. On the other hand, we\nshow that these problems belong to W[1] when restricted to multiple-interval\ngraphs and their complements. This answers an open question of Fellows et al.\nIn sharp contrast, we show that d-Distance k-Dominating Set for d >= 2 is\nW[2]-complete in multiple-interval graphs and their complements. We also show\nthat k-Perfect Code and d-Distance k-Perfect Code for d >= 2 are W[1]-complete\neven in unit 2-track interval graphs. In addition, we present various new\nresults on the parameterized complexities of k-Vertex Clique Partition and\nk-Separating Vertices in multiple-interval graphs and their complements, and\npresent a very simple alternative proof of the W[1]-hardness of k-Irredundant\nSet in general graphs.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2011 14:06:59 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Jiang", "Minghui", ""], ["Zhang", "Yong", ""]]}, {"id": "1110.0200", "submitter": "Koji Kobayashi", "authors": "Koji Kobayashi", "title": "NP is not AL and P is not NC is not NL is not L", "comments": "7 pages, in English and Japanese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper talk about that NP is not AL and P, P is not NC, NC is not NL, and\nNL is not L. The point about this paper is the depend relation of the problem\nthat need other problem's result to compute it. I show the structure of depend\nrelation that could divide each complexity classes.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2011 16:28:44 GMT"}, {"version": "v2", "created": "Sun, 9 Oct 2011 14:08:23 GMT"}, {"version": "v3", "created": "Mon, 17 Oct 2011 14:36:16 GMT"}, {"version": "v4", "created": "Mon, 24 Oct 2011 18:02:30 GMT"}, {"version": "v5", "created": "Mon, 21 Nov 2011 17:55:48 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Kobayashi", "Koji", ""]]}, {"id": "1110.0259", "submitter": "Rajesh Chitnis", "authors": "Rajesh Chitnis, MohammadTaghi Hajiaghayi and D\\'aniel Marx", "title": "Fixed-Parameter Tractability of Directed Multiway Cut Parameterized by\n  the Size of the Cutset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a directed graph $G$, a set of $k$ terminals and an integer $p$, the\n\\textsc{Directed Vertex Multiway Cut} problem asks if there is a set $S$ of at\nmost $p$ (nonterminal) vertices whose removal disconnects each terminal from\nall other terminals. \\textsc{Directed Edge Multiway Cut} is the analogous\nproblem where $S$ is a set of at most $p$ edges. These two problems indeed are\nknown to be equivalent. A natural generalization of the multiway cut is the\n\\emph{multicut} problem, in which we want to disconnect only a set of $k$ given\npairs instead of all pairs. Marx (Theor. Comp. Sci. 2006) showed that in\nundirected graphs multiway cut is fixed-parameter tractable (FPT) parameterized\nby $p$. Marx and Razgon (STOC 2011) showed that undirected multicut is FPT and\ndirected multicut is W[1]-hard parameterized by $p$. We complete the picture\nhere by our main result which is that both \\textsc{Directed Vertex Multiway\nCut} and \\textsc{Directed Edge Multiway Cut} can be solved in time\n$2^{2^{O(p)}}n^{O(1)}$, i.e., FPT parameterized by size $p$ of the cutset of\nthe solution. This answers an open question raised by Marx (Theor. Comp. Sci.\n2006) and Marx and Razgon (STOC 2011). It follows from our result that\n\\textsc{Directed Multicut} is FPT for the case of $k=2$ terminal pairs, which\nanswers another open problem raised in Marx and Razgon (STOC 2011).\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2011 03:32:01 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2013 10:55:10 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Chitnis", "Rajesh", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "1110.0271", "submitter": "Miguel Angel Martin-Delgado", "authors": "Miguel-Angel Martin-Delgado", "title": "Alan Turing and the Origins of Complexity", "comments": "Invited contribution to 'ARBOR: scientific journal of CSIC' special\n  edition devoted to commemorate the Year of Alan Turing. This special issue is\n  entitled \"The Legacy of Alan Turing\". Coordinators: Manuel de Leon, Alberto\n  Ibort and David Martin de Diego", "journal-ref": "ARBOR Vol 189, No 764 (2013), a083", "doi": "10.3989/arbor.2013.i764.", "report-no": null, "categories": "cs.CC cond-mat.stat-mech quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 75th anniversary of Turing's seminal paper and his centennial year\nanniversary occur in 2011 and 2012, respectively. It is natural to review and\nassess Turing's contributions in diverse fields in the light of new\ndevelopments that his thoughts has triggered in many scientific communities.\nHere, the main idea is to discuss how the work of Turing allows us to change\nour views on the foundations of Mathematics, much like quantum mechanics\nchanged our conception of the world of Physics. Basic notions like\ncomputability and universality are discussed in a broad context, making special\nemphasis on how the notion of complexity can be given a precise meaning after\nTuring, i.e., not just qualitative but also quantitative. Turing's work is\ngiven some historical perspective with respect to some of his precursors,\ncontemporaries and mathematicians who took up his ideas farther.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2011 06:21:55 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Martin-Delgado", "Miguel-Angel", ""]]}, {"id": "1110.0367", "submitter": "Jukka Suomela", "authors": "Juho Hirvonen and Jukka Suomela", "title": "Distributed Maximal Matching: Greedy is Optimal", "comments": "1+15 pages", "journal-ref": null, "doi": "10.1145/2332432.2332464", "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed algorithms that find a maximal matching in an anonymous,\nedge-coloured graph. If the edges are properly coloured with $k$ colours, there\nis a trivial greedy algorithm that finds a maximal matching in $k-1$\nsynchronous communication rounds. The present work shows that the greedy\nalgorithm is optimal in the general case: any algorithm that finds a maximal\nmatching in anonymous, $k$-edge-coloured graphs requires $k-1$ rounds.\n  If we focus on graphs of maximum degree $\\Delta$, it is known that a maximal\nmatching can be found in $O(\\Delta + \\log^* k)$ rounds, and prior work implies\na lower bound of $\\Omega(\\polylog(\\Delta) + \\log^* k)$ rounds. Our work closes\nthe gap between upper and lower bounds: the complexity is $\\Theta(\\Delta +\n\\log^* k)$ rounds. To our knowledge, this is the first linear-in-$\\Delta$ lower\nbound for the distributed complexity of a classical graph problem.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2011 14:28:26 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Hirvonen", "Juho", ""], ["Suomela", "Jukka", ""]]}, {"id": "1110.0461", "submitter": "Colin McQuillan", "authors": "Colin McQuillan", "title": "LSM is not generated by binary functions", "comments": "Superseded by arXiv:1108.5288v4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The material in this note is now superseded by arXiv:1108.5288v4.\n  Bulatov et al. [1] defined the operation of (efficient)\npps_\\omega-definability in order to study the computational complexity of\ncertain approximate counting problems. They asked whether all log-supermodular\nfunctions can be defined by binary implication and unary functions in this\nsense. We give a negative answer to this question.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2011 19:58:32 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2012 12:16:58 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["McQuillan", "Colin", ""]]}, {"id": "1110.0550", "submitter": "Sunil Khatri", "authors": "Pey-Chang Kent Lin, Ayan Mandal, Sunil P Khatri", "title": "Boolean Satisfiability using Noise Based Logic", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel algorithm to solve the Boolean\nSatisfiability (SAT) problem, using noise-based logic (NBL). Contrary to what\nthe name may suggest, NBL is not a random/fuzzy logic system. In fact, it is a\ncompletely deterministic logic system. A key property of NBL is that it allows\nus to apply a superposition of many input vectors to a SAT instance at the same\ntime, circumventing a key restriction and assumption in the traditional\napproach to solving SAT. By exploiting the superposition property of NBL, our\nNBL-based SAT algorithm can determine whether an instance is SAT or not in a\nsingle operation. A satisfying solution can be found by iteratively performing\nSAT check operations up to n times, where n is the number of variables in the\nSAT instance. Although this paper does not focus on the realization of an\nNBL-based SAT engine, such an engine can be conceived using analog circuits\n(wide-band amplifiers, adders and multipliers), FPGAs or ASICs. Additionally,\nwe also discus scalability of our approach, which can apply to NBL in general.\nThe NBL-based SAT engine described in this paper has been simulated in software\nfor validation purposes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 00:32:40 GMT"}], "update_date": "2011-10-05", "authors_parsed": [["Lin", "Pey-Chang Kent", ""], ["Mandal", "Ayan", ""], ["Khatri", "Sunil P", ""]]}, {"id": "1110.0623", "submitter": "Arne Meier", "authors": "Arne Meier, Johannes Schmidt, Michael Thomas, Heribert Vollmer", "title": "On the Parameterized Complexity of Default Logic and Autoepistemic Logic", "comments": "12 pages + 2 pages appendix, 1 figure, Version without Appendix\n  submitted to LATA 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the application of Courcelle's Theorem and the logspace\nversion of Elberfeld etal. in the context of the implication problem for\npropositional sets of formulae, the extension existence problem for default\nlogic, as well as the expansion existence problem for autoepistemic logic and\nobtain fixed-parameter time and space efficient algorithms for these problems.\nOn the other hand, we exhibit, for each of the above problems, families of\ninstances of a very simple structure that, for a wide range of different\nparameterizations, do not have efficient fixed-parameter algorithms (even in\nthe sense of the large class XPnu), unless P=NP.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 09:51:25 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2011 19:47:26 GMT"}], "update_date": "2011-10-07", "authors_parsed": [["Meier", "Arne", ""], ["Schmidt", "Johannes", ""], ["Thomas", "Michael", ""], ["Vollmer", "Heribert", ""]]}, {"id": "1110.0693", "submitter": "Manuel Bodirsky", "authors": "Manuel Bodirsky (CNRS/LIX, Ecole Polytechnique, Palaiseau, France),\n  Jens K Mueller (Friedrich-Schiller-University Jena, Germany)", "title": "The Complexity of Rooted Phylogeny Problems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 4 (November\n  24, 2011) lmcs:906", "doi": "10.2168/LMCS-7(4:6)2011", "report-no": null, "categories": "cs.CC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several computational problems in phylogenetic reconstruction can be\nformulated as restrictions of the following general problem: given a formula in\nconjunctive normal form where the literals are rooted triples, is there a\nrooted binary tree that satisfies the formula? If the formulas do not contain\ndisjunctions, the problem becomes the famous rooted triple consistency problem,\nwhich can be solved in polynomial time by an algorithm of Aho, Sagiv,\nSzymanski, and Ullman. If the clauses in the formulas are restricted to\ndisjunctions of negated triples, Ng, Steel, and Wormald showed that the problem\nremains NP-complete. We systematically study the computational complexity of\nthe problem for all such restrictions of the clauses in the input formula. For\ncertain restricted disjunctions of triples we present an algorithm that has\nsub-quadratic running time and is asymptotically as fast as the fastest known\nalgorithm for the rooted triple consistency problem. We also show that any\nrestriction of the general rooted phylogeny problem that does not fall into our\ntractable class is NP-complete, using known results about the complexity of\nBoolean constraint satisfaction problems. Finally, we present a pebble game\nargument that shows that the rooted triple consistency problem (and also all\ngeneralizations studied in this paper) cannot be solved by Datalog.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 14:09:06 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2011 10:14:46 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bodirsky", "Manuel", "", "CNRS/LIX, Ecole Polytechnique, Palaiseau, France"], ["Mueller", "Jens K", "", "Friedrich-Schiller-University Jena, Germany"]]}, {"id": "1110.0812", "submitter": "Igor Shparlinski", "authors": "Jean Bourgain, Moubariz Z. Garaev, Sergei V. Konyagin and Igor E.\n  Shparlinski", "title": "On the Hidden Shifted Power Problem", "comments": "Moubariz Garaev (who has now become a co-author) has introduced some\n  new ideas that have led to stronger results. Several imprecision of the\n  previous version have been corrected too", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering a hidden element $s$ of a finite field\n$\\F_q$ of $q$ elements from queries to an oracle that for a given $x\\in \\F_q$\nreturns $(x+s)^e$ for a given divisor $e\\mid q-1$. We use some techniques from\nadditive combinatorics and analytic number theory that lead to more efficient\nalgorithms than the naive interpolation algorithm, for example, they use\nsubstantially fewer queries to the oracle.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 19:25:24 GMT"}, {"version": "v2", "created": "Sat, 31 Dec 2011 23:24:08 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Bourgain", "Jean", ""], ["Garaev", "Moubariz Z.", ""], ["Konyagin", "Sergei V.", ""], ["Shparlinski", "Igor E.", ""]]}, {"id": "1110.0892", "submitter": "Swapnoneel  Roy", "authors": "N. S. Narayanaswamy and Swapnoneel Roy", "title": "On Approximability of Block Sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block Sorting is a well studied problem, motivated by its applications in\nOptical Character Recognition (OCR), and Computational Biology. Block Sorting\nhas been shown to be NP-Hard, and two separate polynomial time 2-approximation\nalgorithms have been designed for the problem. But questions like whether a\nbetter approximation algorithm can be designed, and whether the problem is\nAPX-Hard have been open for quite a while now.\n  In this work we answer the latter question by proving Block Sorting to be\nMax-SNP-Hard (APX-Hard). The APX-Hardness result is based on a linear reduction\nof Max-3SAT to Block Sorting. We also provide a new lower bound for the problem\nvia a new parametrized problem k-Block Merging.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2011 04:12:09 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Narayanaswamy", "N. S.", ""], ["Roy", "Swapnoneel", ""]]}, {"id": "1110.0976", "submitter": "Stefan Kratsch", "authors": "Danny Hermelin and Stefan Kratsch and Karolina So{\\l}tys and Magnus\n  Wahlstr\\\"om and Xi Wu", "title": "Hierarchies of Inefficient Kernelizability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework of Bodlaender et al. (ICALP 2008) and Fortnow and Santhanam\n(STOC 2008) allows us to exclude the existence of polynomial kernels for a\nrange of problems under reasonable complexity-theoretical assumptions. However,\nthere are also some issues that are not addressed by this framework, including\nthe existence of Turing kernels such as the \"kernelization\" of Leaf Out\nBranching(k) into a disjunction over n instances of size poly(k). Observing\nthat Turing kernels are preserved by polynomial parametric transformations, we\ndefine a kernelization hardness hierarchy, akin to the M- and W-hierarchy of\nordinary parameterized complexity, by the PPT-closure of problems that seem\nlikely to be fundamentally hard for efficient Turing kernelization. We find\nthat several previously considered problems are complete for our fundamental\nhardness class, including Min Ones d-SAT(k), Binary NDTM Halting(k), Connected\nVertex Cover(k), and Clique(k log n), the clique problem parameterized by k log\nn.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2011 13:14:58 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Hermelin", "Danny", ""], ["Kratsch", "Stefan", ""], ["So\u0142tys", "Karolina", ""], ["Wahlstr\u00f6m", "Magnus", ""], ["Wu", "Xi", ""]]}, {"id": "1110.1052", "submitter": "Jesse Stern A", "authors": "Jesse Stern", "title": "Spider Solitaire is NP-Complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This project investigates the potential of computers to solve complex tasks\nsuch as games. The paper proves that the complexity of a generalized version of\nspider solitaire is NP-Complete and uses much of structure of the proof that\nFreeCell is NP-Hard in the paper Helmert, M. \"Complexity Results for Standard\nBenchmark Domains in Planning.\" Artificial Intelligence 143.2 (2003): 219-62.\nPrint. A given decision problem falls in to the class NP-Complete if it is\nproven to be both in NP and in NP-Hard. To prove that this is the case the\npaper shows that, not only do the kinds of possible moves that can be reversed\nprove this, but it is also shown that no spider solitaire game of size n will\ntake more than a polynomial number of moves to complete if such a completion is\npossible. The paper reduces 3-SAT to SpiderSolitaire (the name used throughout\nthe proof when referring to the generalized version of popular solitaire\nvariant \"Spider Solitaire\") by showing that any 3-SAT instance can be\nreplicated using an appropriately arranged initial tableau. The example\nprovided reinforces the proof of NP-Hardness and helps to make the proof easier\nto understand, but the definitive proof lies in the equations providing\ninstruction on how to set up any 3-SAT instance of clause size C as a instance\nof SpiderSolitaire.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2011 17:32:00 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Stern", "Jesse", ""]]}, {"id": "1110.1263", "submitter": "Giovanni Pighizzini", "authors": "Viliam Geffert, Bruno Guillon, Giovanni Pighizzini", "title": "Two-Way Automata Making Choices Only at the Endmarkers", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of the state-size cost for simulation of two-way\nnondeterministic automata (2NFAs) by two-way deterministic automata (2DFAs) was\nraised in 1978 and, despite many attempts, it is still open. Subsequently, the\nproblem was attacked by restricting the power of 2DFAs (e.g., using a\nrestricted input head movement) to the degree for which it was already possible\nto derive some exponential gaps between the weaker model and the standard\n2NFAs. Here we use an opposite approach, increasing the power of 2DFAs to the\ndegree for which it is still possible to obtain a subexponential conversion\nfrom the stronger model to the standard 2DFAs. In particular, it turns out that\nsubexponential conversion is possible for two-way automata that make\nnondeterministic choices only when the input head scans one of the input tape\nendmarkers. However, there is no restriction on the input head movement. This\nimplies that an exponential gap between 2NFAs and 2DFAs can be obtained only\nfor unrestricted 2NFAs using capabilities beyond the proposed new model. As an\nadditional bonus, conversion into a machine for the complement of the original\nlanguage is polynomial in this model. The same holds for making such machines\nself-verifying, halting, or unambiguous. Finally, any superpolynomial lower\nbound for the simulation of such machines by standard 2DFAs would imply L<>NL.\nIn the same way, the alternating version of these machines is related to L =?\nNL =? P, the classical computational complexity problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2011 13:52:34 GMT"}], "update_date": "2011-10-07", "authors_parsed": [["Geffert", "Viliam", ""], ["Guillon", "Bruno", ""], ["Pighizzini", "Giovanni", ""]]}, {"id": "1110.1360", "submitter": "Aravindan Vijayaraghavan", "authors": "Aditya Bhaskara, Moses Charikar, Venkatesan Guruswami, Aravindan\n  Vijayaraghavan, Yuan Zhou", "title": "Polynomial integrality gaps for strong SDP relaxations of Densest\n  k-subgraph", "comments": "26 ages, 1 figure. To appear in Symposium on Discrete Algorithms\n  (SODA) 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The densest k-subgraph (DkS) problem (i.e. find a size k subgraph with\nmaximum number of edges), is one of the notorious problems in approximation\nalgorithms. There is a significant gap between known upper and lower bounds for\nDkS: the current best algorithm gives an ~ O(n^{1/4}) approximation, while even\nshowing a small constant factor hardness requires significantly stronger\nassumptions than P != NP. In addition to interest in designing better\nalgorithms, a number of recent results have exploited the conjectured hardness\nof densest k-subgraph and its variants. Thus, understanding the approximability\nof DkS is an important challenge.\n  In this work, we give evidence for the hardness of approximating DkS within\npolynomial factors. Specifically, we expose the limitations of strong\nsemidefinite programs from SDP hierarchies in solving densest k-subgraph. Our\nresults include:\n  * A lower bound of Omega(n^{1/4}/log^3 n) on the integrality gap for\nOmega(log n/log log n) rounds of the Sherali-Adams relaxation for DkS. This\nalso holds for the relaxation obtained from Sherali-Adams with an added SDP\nconstraint. Our gap instances are in fact Erdos-Renyi random graphs.\n  * For every epsilon > 0, a lower bound of n^{2/53-eps} on the integrality gap\nof n^{Omega(eps)} rounds of the Lasserre SDP relaxation for DkS, and an\nn^{Omega_eps(1)} gap for n^{1-eps} rounds. Our construction proceeds via a\nreduction from random instances of a certain Max-CSP over large domains.\n  In the absence of inapproximability results for DkS, our results show that\neven the most powerful SDPs are unable to beat a factor of n^{Omega(1)}, and in\nfact even improving the best known n^{1/4} factor is a barrier for current\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2011 19:29:01 GMT"}], "update_date": "2011-10-07", "authors_parsed": [["Bhaskara", "Aditya", ""], ["Charikar", "Moses", ""], ["Guruswami", "Venkatesan", ""], ["Vijayaraghavan", "Aravindan", ""], ["Zhou", "Yuan", ""]]}, {"id": "1110.1510", "submitter": "Andr\\'e Nichterlein", "authors": "Sepp Hartung and Andr\\'e Nichterlein", "title": "NP-Hardness and Fixed-Parameter Tractability of Realizing Degree\n  Sequences with Directed Acyclic Graphs", "comments": "new author Sepp Hartung, new section with fixed-parameter\n  tractability result; 25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In graph realization problems one is given a degree sequence and the task is\nto decide whether there is a graph whose vertex degrees match to the given\nsequence. This realization problem is known to be polynomial-time solvable when\nthe graph is directed or undirected. In contrary, we show NP-completeness for\nthe problem of realizing a given sequence of pairs of positive integers\n(representing indegrees and outdegrees) with a directed acyclic graph,\nanswering an open question of Berger and M\\\"uller-Hannemann [FCT 2011].\nFurthermore, we classify the problem as fixed-parameter tractable with respect\nto the parameter \"maximum degree\".\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2011 12:52:19 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2012 17:42:17 GMT"}], "update_date": "2012-01-18", "authors_parsed": [["Hartung", "Sepp", ""], ["Nichterlein", "Andr\u00e9", ""]]}, {"id": "1110.1658", "submitter": "Jason Steinmetz Mr", "authors": "Jason W. Steinmetz", "title": "Algorithm that Solves 3-SAT in Polynomial Time", "comments": "This paper has been withdrawn by the author because the integer\n  operations within the algorithm cannot be proven to have a polynomial run\n  time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of whether the complexity class P is equal to the complexity\nclass NP has been a seemingly intractable problem for over 4 decades. It has\nbeen clear that if an algorithm existed that would solve the problems in the NP\nclass in polynomial time then P would equal NP. However, no one has yet been\nable to create that algorithm or to successfully prove that such an algorithm\ncannot exist. The algorithm that will be presented in this paper solves the\n3-satisfiability or 3-CNF-SAT problem, which has been proven to be NP-complete.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2011 23:04:24 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2015 20:39:54 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Steinmetz", "Jason W.", ""]]}, {"id": "1110.1821", "submitter": "Stephan Mertens", "authors": "Stephan Mertens and Cristopher Moore", "title": "The complexity of the fermionant, and immanants of constant width", "comments": "7 pages, 1 figure", "journal-ref": "Theory of Computing 9 (2013) 273", "doi": "10.4086/toc.2013.v009a006", "report-no": null, "categories": "cs.CC cond-mat.str-el math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of statistical physics, Chandrasekharan and Wiese recently\nintroduced the \\emph{fermionant} $\\Ferm_k$, a determinant-like quantity where\neach permutation $\\pi$ is weighted by $-k$ raised to the number of cycles in\n$\\pi$. We show that computing $\\Ferm_k$ is #P-hard under Turing reductions for\nany constant $k > 2$, and is $\\oplusP$-hard for $k=2$, even for the adjacency\nmatrices of planar graphs. As a consequence, unless the polynomial hierarchy\ncollapses, it is impossible to compute the immanant $\\Imm_\\lambda \\,A$ as a\nfunction of the Young diagram $\\lambda$ in polynomial time, even if the width\nof $\\lambda$ is restricted to be at most 2. In particular, if $\\Ferm_2$ is in\nP, or if $\\Imm_\\lambda$ is in P for all $\\lambda$ of width 2, then $\\NP\n\\subseteq \\RP$ and there are randomized polynomial-time algorithms for\nNP-complete problems.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2011 11:16:48 GMT"}, {"version": "v2", "created": "Sun, 16 Oct 2011 21:58:04 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Mertens", "Stephan", ""], ["Moore", "Cristopher", ""]]}, {"id": "1110.1864", "submitter": "George Barmpalias Dr", "authors": "George Barmpalias", "title": "Universal computably enumerable sets and initial segment prefix-free\n  complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there are Turing complete computably enumerable sets of\narbitrarily low non-trivial initial segment prefix-free complexity. In\nparticular, given any computably enumerable set $A$ with non-trivial\nprefix-free initial segment complexity, there exists a Turing complete\ncomputably enumerable set $B$ with complexity strictly less than the complexity\nof $A$. On the other hand it is known that sets with trivial initial segment\nprefix-free complexity are not Turing complete.\n  Moreover we give a generalization of this result for any finite collection of\ncomputably enumerable sets $A_i, i<k$ with non-trivial initial segment\nprefix-free complexity. An application of this gives a negative answer to a\nquestion from \\cite[Section 11.12]{rodenisbook} and \\cite{MRmerstcdhdtd} which\nasked for minimal pairs in the structure of the c.e.\\ reals ordered by their\ninitial segment prefix-free complexity.\n  Further consequences concern various notions of degrees of randomness. For\nexample, the Solovay degrees and the $K$-degrees of computably enumerable reals\nand computably enumerable sets are not elementarily equivalent. Also, the\ndegrees of randomness based on plain and prefix-free complexity are not\nelementarily equivalent; the same holds for their $\\Delta^0_2$ and $\\Sigma^0_1$\nsubstructures.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2011 17:56:10 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2011 15:40:05 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2013 06:12:07 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2013 12:04:54 GMT"}], "update_date": "2013-11-28", "authors_parsed": [["Barmpalias", "George", ""]]}, {"id": "1110.1894", "submitter": "Paris Siminelakis", "authors": "Dimitris Fotakis and Paris Siminelakis", "title": "On the Efficiency of Influence-and-Exploit Strategies for Revenue\n  Maximization under Positive Externalities", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of revenue maximization in the marketing model for\nsocial networks introduced by (Hartline, Mirrokni, Sundararajan, WWW '08). We\nrestrict our attention to the Uniform Additive Model and mostly focus on\nInfluence-and-Exploit (IE) marketing strategies. We obtain a comprehensive\ncollection of results on the efficiency and the approximability of IE\nstrategies, which also imply a significant improvement on the best known\napproximation ratios for revenue maximization. Specifically, we show that in\nthe Uniform Additive Model, both computing the optimal marketing strategy and\ncomputing the best IE strategy are $\\NP$-hard for undirected social networks.\nWe observe that allowing IE strategies to offer prices smaller than the myopic\nprice in the exploit step leads to a measurable improvement on their\nperformance. Thus, we show that the best IE strategy approximates the maximum\nrevenue within a factor of 0.911 for undirected and of roughly 0.553 for\ndirected networks. Moreover, we present a natural generalization of IE\nstrategies, with more than two pricing classes, and show that they approximate\nthe maximum revenue within a factor of roughly 0.7 for undirected and of\nroughly 0.35 for directed networks. Utilizing a connection between good IE\nstrategies and large cuts in the underlying social network, we obtain\npolynomial-time algorithms that approximate the revenue of the best IE strategy\nwithin a factor of roughly 0.9. Hence, we significantly improve on the best\nknown approximation ratio for revenue maximization to 0.8229 for undirected and\nto 0.5011 for directed networks (from 2/3 and 1/3, respectively, by Hartline et\nal.).\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 00:09:55 GMT"}], "update_date": "2011-10-11", "authors_parsed": [["Fotakis", "Dimitris", ""], ["Siminelakis", "Paris", ""]]}, {"id": "1110.1896", "submitter": "Hao  Chen", "authors": "Hao Chen", "title": "Restricted Parameter Range Promise Set Cover Problems Are Easy", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $({\\bf U},{\\bf S},d)$ be an instance of Set Cover Problem, where ${\\bf\nU}=\\{u_1,...,u_n\\}$ is a $n$ element ground set, ${\\bf S}=\\{S_1,...,S_m\\}$ is a\nset of $m$ subsets of ${\\bf U}$ satisfying $\\bigcup_{i=1}^m S_i={\\bf U}$ and\n$d$ is a positive integer. In STOC 1993 M. Bellare, S. Goldwasser, C. Lund and\nA. Russell proved the NP-hardness to distinguish the following two cases of\n${\\bf GapSetCover_{\\eta}}$ for any constant $\\eta > 1$. The Yes case is the\ninstance for which there is an exact cover of size $d$ and the No case is the\ninstance for which any cover of ${\\bf U}$ from ${\\bf S}$ has size at least\n$\\eta d$. This was improved by R. Raz and S. Safra in STOC 1997 about the\nNP-hardness for ${\\bf GapSetCover}_{clogm}$ for some constant $c$. In this\npaper we prove that restricted parameter range subproblem is easy. For any\ngiven function of $n$ satisfying $\\eta(n) \\geq 1$, we give a polynomial time\nalgorithm not depending on $\\eta(n)$ to distinguish between\n  {\\bf YES:} The instance $({\\bf U},{\\bf S}, d)$ where $d>\\frac{2 |{\\bf\nS}|}{3\\eta(n)-1}$, for which there exists an exact cover of size at most $d$;\n  {\\bf NO:} The instance $({\\bf U},{\\bf S}, d)$ where $d>\\frac{2 |{\\bf\nS}|}{3\\eta(n)-1}$, for which any cover from ${\\bf S}$ has size larger than\n$\\eta(n) d$.\n  The polynomial time reduction of this restricted parameter range set cover\nproblem is constructed by using the lattice.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 00:40:28 GMT"}], "update_date": "2011-10-11", "authors_parsed": [["Chen", "Hao", ""]]}, {"id": "1110.1915", "submitter": "Xueliang Li", "authors": "Lily Chen, Xueliang Li, Huishu Lian", "title": "Further hardness results on the rainbow vertex-connection number of\n  graphs", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vertex-colored graph $G$ is {\\it rainbow vertex-connected} if any pair of\nvertices in $G$ are connected by a path whose internal vertices have distinct\ncolors, which was introduced by Krivelevich and Yuster. The {\\it rainbow\nvertex-connection number} of a connected graph $G$, denoted by $rvc(G)$, is the\nsmallest number of colors that are needed in order to make $G$ rainbow\nvertex-connected. In a previous paper we showed that it is NP-Complete to\ndecide whether a given graph $G$ has $rvc(G)=2$. In this paper we show that for\nevery integer $k\\geq 2$, deciding whether $rvc(G)\\leq k$ is NP-Hard. We also\nshow that for any fixed integer $k\\geq 2$, this problem belongs to NP-class,\nand so it becomes NP-Complete.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 03:19:42 GMT"}], "update_date": "2011-10-11", "authors_parsed": [["Chen", "Lily", ""], ["Li", "Xueliang", ""], ["Lian", "Huishu", ""]]}, {"id": "1110.2065", "submitter": "Sumedha", "authors": "Supriya Krishnamurthy and Sumedha", "title": "On the behaviour of random K-SAT on trees", "comments": "22 pages, 5 figures,accepted for publication in J. Stat. Mech", "journal-ref": "J. Stat. Mech. (2012) P05009", "doi": "10.1088/1742-5468/2012/05/P05009", "report-no": null, "categories": "cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the K-satisfiability problem on a regular d-ary rooted tree. For\nthis model, we demonstrate how we can calculate in closed form, the moments of\nthe total number of solutions as a function of d and K, where the average is\nover all realizations, for a fixed assignment of the surface variables. We find\nthat different moments pick out different 'critical' values of d, below which\nthey diverge as the total number of variables on the tree goes to infinity and\nabove which they decay. We show that K-SAT on the random graph also behaves\nsimilarly. We also calculate exactly the fraction of instances that have\nsolutions for all K. On the tree, this quantity decays to 0 (as the number of\nvariables increases) for any d>1. However the recursion relations for this\nquantity have a non-trivial fixed-point solution which indicates the existence\nof a different transition in the interior of an infinite rooted tree.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 15:04:33 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2012 00:58:00 GMT"}], "update_date": "2015-05-30", "authors_parsed": [["Krishnamurthy", "Supriya", ""], ["Sumedha", "", ""]]}, {"id": "1110.2196", "submitter": "Bart Kuijpers", "authors": "Marc Giusti, Joos Heintz and Bart Kuijpers", "title": "The evaluation of geometric queries: constraint databases and quantifier\n  elimination", "comments": "This paper is representing work in progress of the authors. It is not\n  aimed for publication in the present form", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model the algorithmic task of geometric elimination (e.g., quantifier\nelimination in the elementary field theories of real and complex numbers) by\nmeans of certain constraint database queries, called geometric queries. As a\nparticular case of such a geometric elimination task, we consider sample point\nqueries. We show exponential lower complexity bounds for evaluating geometric\nqueries in the general and in the particular case of sample point queries.\nAlthough this paper is of theoretical nature, its aim is to explore the\npossibilities and (complexity-)limits of computer implemented query evaluation\nalgorithms for Constraint Databases, based on the principles of the most\nadvanced geometric elimination procedures and their implementations, like,\ne.g., the software package \"Kronecker\".\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 20:55:17 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2011 18:59:22 GMT"}], "update_date": "2011-10-14", "authors_parsed": [["Giusti", "Marc", ""], ["Heintz", "Joos", ""], ["Kuijpers", "Bart", ""]]}, {"id": "1110.2230", "submitter": "Turlough Neary", "authors": "Turlough Neary and Damien Woods", "title": "The complexity of small universal Turing machines: a survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey some work concerned with small universal Turing machines, cellular\nautomata, tag systems, and other simple models of computation. For example it\nhas been an open question for some time as to whether the smallest known\nuniversal Turing machines of Minsky, Rogozhin, Baiocchi and Kudlek are\nefficient (polynomial time) simulators of Turing machines. These are some of\nthe most intuitively simple computational devices and previously the best known\nsimulations were exponentially slow. We discuss recent work that shows that\nthese machines are indeed efficient simulators. In addition, another related\nresult shows that Rule 110, a well-known elementary cellular automaton, is\nefficiently universal. We also discuss some old and new universal program size\nresults, including the smallest known universal Turing machines. We finish the\nsurvey with results on generalised and restricted Turing machine models\nincluding machines with a periodic background on the tape (instead of a blank\nsymbol), multiple tapes, multiple dimensions, and machines that never write to\ntheir tape. We then discuss some ideas for future work.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 23:22:17 GMT"}], "update_date": "2011-10-12", "authors_parsed": [["Neary", "Turlough", ""], ["Woods", "Damien", ""]]}, {"id": "1110.2809", "submitter": "Vladimir Kolmogorov", "authors": "Vladimir Kolmogorov, Stanislav Zivny", "title": "The complexity of conservative valued CSPs", "comments": "38 pages. Full version of the paper that will appear in SODA 12", "journal-ref": "Journal of the ACM 60(2) Article No. 10 (2013)", "doi": "10.1145/2450142.2450146", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of valued constraint satisfaction problems (VCSP). A\nproblem from VCSP is characterised by a \\emph{constraint language}, a fixed set\nof cost functions over a finite domain. An instance of the problem is specified\nby a sum of cost functions from the language and the goal is to minimise the\nsum.\n  We consider the case of languages containing all possible unary cost\nfunctions. In the case of languages consisting of only $\\{0,\\infty\\}$-valued\ncost functions (i.e. relations), such languages have been called\n\\emph{conservative} and studied by Bulatov [LICS'03] and recently by Barto\n[LICS'11]. Since we study valued languages, we call a language conservative if\nit contains all finite-valued unary cost functions. The complexity of\nconservative valued languages has been studied by Cohen et al. [AIJ'06] for\nlanguages over Boolean domains, by Deineko et al. [JACM'08] for\n$\\{0,1\\}$-valued languages (a.k.a Max-CSP), and by Takhanov [STACS'10] for\n$\\{0,\\infty\\}$-valued languages containing all finite-valued unary cost\nfunctions (a.k.a. Min-Cost-Hom).\n  We prove a Schaefer-like dichotomy theorem for conservative valued languages:\nif all cost functions in the language satisfy a certain condition (specified by\na complementary combination of \\emph{STP and MJN multimorphisms}), then any\ninstance can be solved in polytime (via a new algorithm developed in this\npaper), otherwise the language is NP-hard. This is the \\emph{first} complete\ncomplexity classification of \\emph{general-valued constraint languages} over\nnon-Boolean domains.\n  This generalises previous results by Takhanov [STACS'10] and (a subset of\nresults) by Cohen et al. [AIJ'06] and Deineko et al. [JACM'08]. Moreover, our\nresults do not rely on any computer-assisted search as in Deineko et al.\n[JACM'08], and provide a powerful tool for proving hardness of finite- and\ngeneral-valued languages.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2011 22:25:10 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Kolmogorov", "Vladimir", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1110.2953", "submitter": "Hang Zhou", "authors": "Walter Bach, Hang Zhou", "title": "Approximation for Maximum Surjective Constraint Satisfaction Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum surjective constraint satisfaction problems (Max-Sur-CSPs) are\ncomputational problems where we are given a set of variables denoting values\nfrom a finite domain B and a set of constraints on the variables. A solution to\nsuch a problem is a surjective mapping from the set of variables to B such that\nthe number of satisfied constraints is maximized. We study the approximation\nperformance that can be acccchieved by algorithms for these problems, mainly by\ninvestigating their relation with Max-CSPs (which are the corresponding\nproblems without the surjectivity requirement). Our work gives a complexity\ndichotomy for Max-Sur-CSP(B) between PTAS and APX-complete, under the\nassumption that there is a complexity dichotomy for Max-CSP(B) between PO and\nAPX-complete, which has already been proved on the Boolean domain and 3-element\ndomains.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 14:12:41 GMT"}], "update_date": "2011-10-14", "authors_parsed": [["Bach", "Walter", ""], ["Zhou", "Hang", ""]]}, {"id": "1110.3030", "submitter": "Bart Kuijpers", "authors": "Joos Heintz, Bart Kuijpers and Andres Rojas Paredes", "title": "Software Engineering and Complexity in Effective Algebraic Geometry", "comments": "70 pages. arXiv admin note: substantial text overlap with\n  arXiv:1201.4344", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of a robust parameterized arithmetic circuit for the\nevaluation of algebraic families of multivariate polynomials. Based on this\nnotion, we present a computation model, adapted to Scientific Computing, which\ncaptures all known branching parsimonious symbolic algorithms in effective\nAlgebraic Geometry. We justify this model by arguments from Software\nEngineering. Finally we exhibit a class of simple elimination problems of\neffective Algebraic Geometry which require exponential time to be solved by\nbranching parsimonious algorithms of our computation model.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 18:58:45 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2011 19:06:43 GMT"}, {"version": "v3", "created": "Wed, 25 Apr 2012 19:56:08 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["Heintz", "Joos", ""], ["Kuijpers", "Bart", ""], ["Paredes", "Andres Rojas", ""]]}, {"id": "1110.3147", "submitter": "Xueliang Li", "authors": "Xiaolong Huang, Xueliang Li, Yongtang Shi", "title": "Rainbow connections for planar graphs and line graphs", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An edge-colored graph $G$ is rainbow connected if any two vertices are\nconnected by a path whose edges have distinct colors. The rainbow connection\nnumber of a connected graph $G$, denoted by $rc(G)$, is the smallest number of\ncolors that are needed in order to make $G$ rainbow connected. It was proved\nthat computing $rc(G)$ is an NP-Hard problem, as well as that even deciding\nwhether a graph has $rc(G)=2$ is NP-Complete. It is known that deciding whether\na given edge-colored graph is rainbow connected is NP-Complete. We will prove\nthat it is still NP-Complete even when the edge-colored graph is a planar\nbipartite graph. We also give upper bounds of the rainbow connection number of\nouterplanar graphs with small diameters. A vertex-colored graph is rainbow\nvertex-connected if any two vertices are connected by a path whose internal\nvertices have distinct colors. The rainbow vertex-connection number of a\nconnected graph $G$, denoted by $rvc(G)$, is the smallest number of colors that\nare needed in order to make $G$ rainbow vertex-connected. It is known that\ndeciding whether a given vertex-colored graph is rainbow vertex-connected is\nNP-Complete. We will prove that it is still NP-Complete even when the\nvertex-colored graph is a line graph.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2011 08:53:50 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2011 09:18:47 GMT"}], "update_date": "2011-11-15", "authors_parsed": [["Huang", "Xiaolong", ""], ["Li", "Xueliang", ""], ["Shi", "Yongtang", ""]]}, {"id": "1110.3189", "submitter": "Anatoly Plotnikov D.", "authors": "Anatoly D. Plotnikov", "title": "About set-theoretic properties of one-way functions", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of cryptanalysis as a problem belonging to the\nclass NP. A class of problems UF is defined for which the time constructing any\nfeasible solution is polynomial. The properties of the problems of NP, which\nmay be one-way functions, are established.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2011 12:35:24 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Plotnikov", "Anatoly D.", ""]]}, {"id": "1110.3211", "submitter": "Tillmann Miltzow", "authors": "Tillmann Miltzow", "title": "Tron, a combinatorial Game on abstract Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.GT math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the combinatorial two-player game Tron. We answer the extremal\nquestion on general graphs and also consider smaller graph classes. Bodlaender\nand Kloks conjectured in [2] PSPACE- completeness. We proof this conjecture.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2011 13:48:47 GMT"}], "update_date": "2011-10-17", "authors_parsed": [["Miltzow", "Tillmann", ""]]}, {"id": "1110.3546", "submitter": "Bhaskar DasGupta", "authors": "Piotr Berman, Bhaskar DasGupta, Lakshmi Kaligounder, Marek Karpinski", "title": "On the Computational Complexity of Measuring Global Stability of Banking\n  Networks", "comments": "to appear in Algorithmica", "journal-ref": "Algorithmica, 70(4), 595-647, 2014", "doi": "10.1007/s00453-013-9769-0", "report-no": null, "categories": "q-fin.RM cs.CC cs.CE cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threats on the stability of a financial system may severely affect the\nfunctioning of the entire economy, and thus considerable emphasis is placed on\nthe analyzing the cause and effect of such threats. The financial crisis in the\ncurrent and past decade has shown that one important cause of instability in\nglobal markets is the so-called financial contagion, namely the spreading of\ninstabilities or failures of individual components of the network to other,\nperhaps healthier, components. This leads to a natural question of whether the\nregulatory authorities could have predicted and perhaps mitigated the current\neconomic crisis by effective computations of some stability measure of the\nbanking networks. Motivated by such observations, we consider the problem of\ndefining and evaluating stabilities of both homogeneous and heterogeneous\nbanking networks against propagation of synchronous idiosyncratic shocks given\nto a subset of banks. We formalize the homogeneous banking network model of\nNier et al. and its corresponding heterogeneous version, formalize the\nsynchronous shock propagation procedures, define two appropriate stability\nmeasures and investigate the computational complexities of evaluating these\nmeasures for various network topologies and parameters of interest. Our results\nand proofs also shed some light on the properties of topologies and parameters\nof the network that may lead to higher or lower stabilities.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2011 00:53:36 GMT"}, {"version": "v2", "created": "Sat, 12 Nov 2011 17:07:56 GMT"}, {"version": "v3", "created": "Wed, 15 Feb 2012 15:13:02 GMT"}, {"version": "v4", "created": "Tue, 27 Mar 2012 09:47:43 GMT"}, {"version": "v5", "created": "Sat, 9 Mar 2013 17:16:26 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Berman", "Piotr", ""], ["DasGupta", "Bhaskar", ""], ["Kaligounder", "Lakshmi", ""], ["Karpinski", "Marek", ""]]}, {"id": "1110.3639", "submitter": "Tomer Kotek", "authors": "Tomer Kotek", "title": "Complexity of Ising Polynomials", "comments": null, "journal-ref": "Combinatorics, Probability and Computing, Volume 21, Issue 5\n  (2012), pp. 743-772", "doi": "10.1017/S0963548312000259", "report-no": null, "categories": "cs.CC cond-mat.stat-mech math-ph math.CO math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the partition function of the Ising model from\nstatistical mechanics, which is used to study phase transitions in physical\nsystems. A special case of interest is that of the Ising model with constant\nenergies and external field. One may consider such an Ising system as a simple\ngraph together with vertex and edge weights. When these weights are considered\nindeterminates, the partition function for the constant case is a trivariate\npolynomial Z(G;x,y,z). This polynomial was studied with respect to its\napproximability by L. A. Goldberg, M. Jerrum and M. Paterson in 2003.\nZ(G;x,y,z) generalizes a bivariate polynomial Z(G;t,y), which was studied by D.\nAndr\\'{e}n and K. Markstr\\\"{o}m in 2009.\n  We consider the complexity of Z(G;t,y) and Z(G;x,y,z) in comparison to that\nof the Tutte polynomial, which is well-known to be closely related to the Potts\nmodel in the absence of an external field. We show that Z(G;\\x,\\y,\\z) is\n#P-hard to evaluate at all points in $mathbb{Q}^3$, except those in an\nexception set of low dimension, even when restricted to simple graphs which are\nbipartite and planar. A counting version of the Exponential Time Hypothesis,\n#ETH, was introduced by H. Dell, T. Husfeldt and M. Wahl\\'{e}n in 2010 in order\nto study the complexity of the Tutte polynomial. In analogy to their results,\nwe give a dichotomy theorem stating that evaluations of Z(G;t,y) either take\nexponential time in the number of vertices of $G$ to compute, or can be done in\npolynomial time. Finally, we give an algorithm for computing Z(G;x,y,z) in\npolynomial time on graphs of bounded clique-width, which is not known in the\ncase of the Tutte polynomial.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2011 11:25:51 GMT"}, {"version": "v2", "created": "Wed, 26 Oct 2011 14:28:26 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2012 09:31:39 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["Kotek", "Tomer", ""]]}, {"id": "1110.4077", "submitter": "Kitty Meeks", "authors": "Kitty Meeks and Alexander Scott", "title": "The Parameterised Complexity of List Problems on Graphs of Bounded\n  Treewidth", "comments": "Author final version, to appear in Information and Computation.\n  Changes from previous version include improved literature references and\n  restructured proof in Section 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the parameterised complexity of several list problems on graphs,\nwith parameter treewidth or pathwidth. In particular, we show that List Edge\nChromatic Number and List Total Chromatic Number are fixed parameter tractable,\nparameterised by treewidth, whereas List Hamilton Path is W[1]-hard, even\nparameterised by pathwidth. These results resolve two open questions of\nFellows, Fomin, Lokshtanov, Rosamond, Saurabh, Szeider and Thomassen (2011).\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2011 18:31:30 GMT"}, {"version": "v2", "created": "Thu, 12 Jan 2012 16:17:51 GMT"}, {"version": "v3", "created": "Thu, 4 Aug 2016 13:29:25 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Meeks", "Kitty", ""], ["Scott", "Alexander", ""]]}, {"id": "1110.4201", "submitter": "Arnaud Durand", "authors": "Arnaud Durand and Stefan Mengel", "title": "The Complexity of Weighted Counting for Acyclic Conjunctive Queries", "comments": "28 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a study of weighted counting of the solutions of acyclic\nconjunctive queries ($\\ACQ$). The unweighted quantifier free version of this\nproblem is known to be tractable (for combined complexity), but it is also\nknown that introducing even a single quantified variable makes it $\\sP$-hard.\nWe first show that weighted counting for quantifier-free $\\ACQ$ is still\ntractable and that even minimalistic extensions of the problem lead to hard\ncases. We then introduce a new parameter for quantified queries that permits to\nisolate large island of tractability. We show that, up to a standard assumption\nfrom parameterized complexity, this parameter fully characterizes tractable\nsubclasses for counting weighted solutions of $\\ACQ$ queries. Thus we\ncompletely determine the tractability frontier for weighted counting for\n$\\ACQ$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2011 07:49:15 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2011 20:38:22 GMT"}], "update_date": "2011-12-08", "authors_parsed": [["Durand", "Arnaud", ""], ["Mengel", "Stefan", ""]]}, {"id": "1110.4301", "submitter": "Bireswar Das", "authors": "Bireswar Das, Manjish Pal, Vijay Visavaliya", "title": "The Entropy Influence Conjecture Revisited", "comments": "We thank Kunal Dutta and Justin Salez for pointing out that our\n  result can be extended to a high probability statement", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove that most of the boolean functions, $f : \\{-1,1\\}^n\n\\rightarrow \\{-1,1\\}$ satisfy the Fourier Entropy Influence (FEI) Conjecture\ndue to Friedgut and Kalai (Proc. AMS'96). The conjecture says that the Entropy\nof a boolean function is at most a constant times the Influence of the\nfunction. The conjecture has been proven for families of functions of smaller\nsizes. O'donnell, Wright and Zhou (ICALP'11) verified the conjecture for the\nfamily of symmetric functions, whose size is $2^{n+1}$. They are in fact able\nto prove the conjecture for the family of $d$-part symmetric functions for\nconstant $d$, the size of whose is $2^{O(n^d)}$. Also it is known that the\nconjecture is true for a large fraction of polynomial sized DNFs (COLT'10).\nUsing elementary methods we prove that a random function with high probability\nsatisfies the conjecture with the constant as $(2 + \\delta)$, for any constant\n$\\delta > 0$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2011 14:49:48 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2011 15:24:12 GMT"}], "update_date": "2011-10-21", "authors_parsed": [["Das", "Bireswar", ""], ["Pal", "Manjish", ""], ["Visavaliya", "Vijay", ""]]}, {"id": "1110.5353", "submitter": "Scott Aaronson", "authors": "Scott Aaronson", "title": "Quantum Copy-Protection and Quantum Money", "comments": "14-page conference abstract; full version hasn't appeared and will\n  never appear. Being posted to arXiv mostly for archaeological purposes.\n  Explicit money scheme has since been broken by Lutomirski et al\n  (arXiv:0912.3825). Other quantum money material has been superseded by\n  results of Aaronson and Christiano (coming soon). Quantum copy-protection\n  ideas will hopefully be developed in separate work", "journal-ref": "Proceedings of IEEE Conference on Computational Complexity, pages\n  229-242, 2009", "doi": "10.1109/CCC.2009.42", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forty years ago, Wiesner proposed using quantum states to create money that\nis physically impossible to counterfeit, something that cannot be done in the\nclassical world. However, Wiesner's scheme required a central bank to verify\nthe money, and the question of whether there can be unclonable quantum money\nthat anyone can verify has remained open since. One can also ask a related\nquestion, which seems to be new: can quantum states be used as copy-protected\nprograms, which let the user evaluate some function f, but not create more\nprograms for f? This paper tackles both questions using the arsenal of modern\ncomputational complexity. Our main result is that there exist quantum oracles\nrelative to which publicly-verifiable quantum money is possible, and any family\nof functions that cannot be efficiently learned from its input-output behavior\ncan be quantumly copy-protected. This provides the first formal evidence that\nthese tasks are achievable. The technical core of our result is a\n\"Complexity-Theoretic No-Cloning Theorem,\" which generalizes both the standard\nNo-Cloning Theorem and the optimality of Grover search, and might be of\nindependent interest. Our security argument also requires explicit\nconstructions of quantum t-designs. Moving beyond the oracle world, we also\npresent an explicit candidate scheme for publicly-verifiable quantum money,\nbased on random stabilizer states; as well as two explicit schemes for\ncopy-protecting the family of point functions. We do not know how to base the\nsecurity of these schemes on any existing cryptographic assumption. (Note that\nwithout an oracle, we can only hope for security under some computational\nassumption.)\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2011 21:06:00 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Aaronson", "Scott", ""]]}, {"id": "1110.5355", "submitter": "Jos\\'e Ignacio Alvarez-Hamelin Phd.", "authors": "Jos\\'e Ignacio Alvarez-Hamelin", "title": "Is it possible to find the maximum clique in general graphs?", "comments": "http://hal.archives-ouvertes.fr/hal-00625917/en", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the maximum clique is a known NP-Complete problem and it is also hard\nto approximate. This work proposes two efficient algorithms to obtain it.\nNevertheless, the first one is able to fins the maximum for some special cases,\nwhile the second one has its execution time bounded by the number of cliques\nthat each vertex belongs to.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2011 21:12:43 GMT"}, {"version": "v2", "created": "Wed, 26 Oct 2011 20:20:36 GMT"}, {"version": "v3", "created": "Fri, 17 Feb 2012 21:35:05 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Alvarez-Hamelin", "Jos\u00e9 Ignacio", ""]]}, {"id": "1110.5696", "submitter": "Zeev Dvir", "authors": "Zeev Dvir and Shachar Lovett", "title": "Subspace Evasive Sets", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe an explicit, simple, construction of large subsets\nof F^n, where F is a finite field, that have small intersection with every\nk-dimensional affine subspace. Interest in the explicit construction of such\nsets, termed subspace-evasive sets, started in the work of Pudlak and Rodl\n(2004) who showed how such constructions over the binary field can be used to\nconstruct explicit Ramsey graphs. More recently, Guruswami (2011) showed that,\nover large finite fields (of size polynomial in n), subspace evasive sets can\nbe used to obtain explicit list-decodable codes with optimal rate and constant\nlist-size. In this work we construct subspace evasive sets over large fields\nand use them to reduce the list size of folded Reed-Solomon codes form poly(n)\nto a constant.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2011 02:24:48 GMT"}], "update_date": "2011-10-27", "authors_parsed": [["Dvir", "Zeev", ""], ["Lovett", "Shachar", ""]]}, {"id": "1110.5915", "submitter": "Gregory Gutin", "authors": "R. Crowston, G. Gutin, M. Jones, and A. Yeo", "title": "Parameterized Complexity of Satisfying Almost All Linear Equations over\n  $\\mathbb{F}_2$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem MaxLin2 can be stated as follows. We are given a system $S$ of\n$m$ equations in variables $x_1,...,x_n$, where each equation is $\\sum_{i \\in\nI_j}x_i = b_j$ is assigned a positive integral weight $w_j$ and $x_i,b_j \\in\n\\mathbb{F}_2$, $I_j \\subseteq \\{1,2,...,n\\}$ for $j=1,...,m$. We are required\nto find an assignment of values to the variables in order to maximize the total\nweight of the satisfied equations.\n  Let $W$ be the total weight of all equations in $S$. We consider the\nfollowing parameterized version of MaxLin2: decide whether there is an\nassignment satisfying equations of total weight at least $W-k$, where $k$ is a\nnonnegative parameter. We prove that this parameterized problem is W[1]-hard\neven if each equation of $S$ has exactly three variables and every variable\nappears in exactly three equations and, moreover, each weight $w_j$ equals 1\nand no two equations have the same left-hand side. We show the tightness of\nthis result by proving that if each equation has at most two variables then the\nparameterized problem is fixed-parameter tractable. We also prove that if no\nvariable appears in more than two equations then we can maximize the total\nweight of satisfied equations in polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2011 20:02:03 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2012 13:01:09 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Crowston", "R.", ""], ["Gutin", "G.", ""], ["Jones", "M.", ""], ["Yeo", "A.", ""]]}, {"id": "1110.6126", "submitter": "Scott Aaronson", "authors": "Scott Aaronson", "title": "A Counterexample to the Generalized Linial-Nisan Conjecture", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In earlier work, we gave an oracle separating the relational versions of BQP\nand the polynomial hierarchy, and showed that an oracle separating the decision\nversions would follow from what we called the Generalized Linial-Nisan (GLN)\nConjecture: that \"almost k-wise independent\" distributions are\nindistinguishable from the uniform distribution by constant-depth circuits. The\noriginal Linial-Nisan Conjecture was recently proved by Braverman; we offered a\n$200 prize for the generalized version. In this paper, we save ourselves $200\nby showing that the GLN Conjecture is false, at least for circuits of depth 3\nand higher. As a byproduct, our counterexample also implies that Pi2P is not\ncontained in P^NP relative to a random oracle with probability 1. It has been\nconjectured since the 1980s that PH is infinite relative to a random oracle,\nbut the highest levels of PH previously proved separate were NP and coNP.\nFinally, our counterexample implies that the famous results of Linial, Mansour,\nand Nisan, on the structure of AC0 functions, cannot be improved in several\ninteresting respects.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2011 16:05:23 GMT"}], "update_date": "2011-10-28", "authors_parsed": [["Aaronson", "Scott", ""]]}, {"id": "1110.6271", "submitter": "Herv\\'e Fournier", "authors": "Herv\\'e Fournier and Guillaume Malod and Stefan Mengel", "title": "Monomials in arithmetic circuits: Complete problems in the counting\n  hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the complexity of two questions on polynomials given by\narithmetic circuits: testing whether a monomial is present and counting the\nnumber of monomials. We show that these problems are complete for subclasses of\nthe counting hierarchy which had few or no known natural complete problems. We\nalso study these questions for circuits computing multilinear polynomials.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2011 07:45:34 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2012 07:29:16 GMT"}], "update_date": "2012-03-28", "authors_parsed": [["Fournier", "Herv\u00e9", ""], ["Malod", "Guillaume", ""], ["Mengel", "Stefan", ""]]}, {"id": "1110.6384", "submitter": "Serge Gaspers", "authors": "Serge Gaspers and Stefan Szeider", "title": "Backdoors to Acyclic SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor sets, a notion introduced by Williams et al. in 2003, are certain\nsets of key variables of a CNF formula F that make it easy to solve the\nformula; by assigning truth values to the variables in a backdoor set, the\nformula gets reduced to one or several polynomial-time solvable formulas. More\nspecifically, a weak backdoor set of F is a set X of variables such that there\nexits a truth assignment t to X that reduces F to a satisfiable formula F[t]\nthat belongs to a polynomial-time decidable base class C. A strong backdoor set\nis a set X of variables such that for all assignments t to X, the reduced\nformula F[t] belongs to C.\n  We study the problem of finding backdoor sets of size at most k with respect\nto the base class of CNF formulas with acyclic incidence graphs, taking k as\nthe parameter. We show that\n  1. the detection of weak backdoor sets is W[2]-hard in general but\nfixed-parameter tractable for r-CNF formulas, for any fixed r>=3, and\n  2. the detection of strong backdoor sets is fixed-parameter approximable.\n  Result 1 is the the first positive one for a base class that does not have a\ncharacterization with obstructions of bounded size. Result 2 is the first\npositive one for a base class for which strong backdoor sets are more powerful\nthan deletion backdoor sets.\n  Not only SAT, but also #SAT can be solved in polynomial time for CNF formulas\nwith acyclic incidence graphs. Hence Result 2 establishes a new structural\nparameter that makes #SAT fixed-parameter tractable and that is incomparable\nwith known parameters such as treewidth and clique-width.\n  We obtain the algorithms by a combination of an algorithmic version of the\nErd\\\"os-P\\'osa Theorem, Courcelle's model checking for monadic second order\nlogic, and new combinatorial results on how disjoint cycles can interact with\nthe backdoor set.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2011 16:10:32 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2011 15:09:42 GMT"}, {"version": "v3", "created": "Tue, 21 Feb 2012 17:15:41 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["Gaspers", "Serge", ""], ["Szeider", "Stefan", ""]]}, {"id": "1110.6387", "submitter": "Serge Gaspers", "authors": "Serge Gaspers and Stefan Szeider", "title": "Backdoors to Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A backdoor set is a set of variables of a propositional formula such that\nfixing the truth values of the variables in the backdoor set moves the formula\ninto some polynomial-time decidable class. If we know a small backdoor set we\ncan reduce the question of whether the given formula is satisfiable to the same\nquestion for one or several easy formulas that belong to the tractable class\nunder consideration. In this survey we review parameterized complexity results\nfor problems that arise in the context of backdoor sets, such as the problem of\nfinding a backdoor set of size at most k, parameterized by k. We also discuss\nrecent results on backdoor sets for problems that are beyond NP.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2011 16:23:45 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2011 14:54:50 GMT"}], "update_date": "2011-11-01", "authors_parsed": [["Gaspers", "Serge", ""], ["Szeider", "Stefan", ""]]}]