[{"id": "1201.0043", "submitter": "Mathew Francis", "authors": "Mathew C. Francis, Daniel Gon\\c{c}alves, Pascal Ochem", "title": "The Maximum Clique Problem in Multiple Interval Graphs", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple interval graphs are variants of interval graphs where instead of a\nsingle interval, each vertex is assigned a set of intervals on the real line.\nWe study the complexity of the MAXIMUM CLIQUE problem in several classes of\nmultiple interval graphs. The MAXIMUM CLIQUE problem, or the problem of finding\nthe size of the maximum clique, is known to be NP-complete for $t$-interval\ngraphs when $t\\geq 3$ and polynomial-time solvable when $t=1$. The problem is\nalso known to be NP-complete in $t$-track graphs when $t\\geq 4$ and\npolynomial-time solvable when $t\\leq 2$. We show that MAXIMUM CLIQUE is already\nNP-complete for unit 2-interval graphs and unit 3-track graphs. Further, we\nshow that the problem is APX-complete for 2-interval graphs, 3-track graphs,\nunit 3-interval graphs and unit 4-track graphs. We also introduce two new\nclasses of graphs called $t$-circular interval graphs and $t$-circular track\ngraphs and study the complexity of the MAXIMUM CLIQUE problem in them. On the\npositive side, we present a polynomial time $t$-approximation algorithm for\nWEIGHTED MAXIMUM CLIQUE on $t$-interval graphs, improving earlier work with\napproximation ratio $4t$.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2011 00:38:07 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2012 10:03:51 GMT"}], "update_date": "2012-03-12", "authors_parsed": [["Francis", "Mathew C.", ""], ["Gon\u00e7alves", "Daniel", ""], ["Ochem", "Pascal", ""]]}, {"id": "1201.0253", "submitter": "Sumit Ganguly", "authors": "Sumit Ganguly", "title": "A Lower Bound for Estimating High Moments of a Data Stream", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show an improved lower bound for the Fp estimation problem in a data\nstream setting for p>2. A data stream is a sequence of items from the domain\n[n] with possible repetitions. The frequency vector x is an n-dimensional\nnon-negative integer vector x such that x(i) is the number of occurrences of i\nin the sequence. Given an accuracy parameter Omega(n^{-1/p}) < \\epsilon < 1,\nthe problem of estimating Fp is to estimate \\norm{x}_p^p = \\sum_{i \\in [n]}\n\\abs{x(i)}^p correctly to within a relative accuracy of 1\\pm \\epsilon with high\nconstant probability in an online fashion and using as little space as\npossible. The current space lower bound for this problem is Omega(n^{1-2/p}\n\\epsilon^{-2/p}+ n^{1-2/p}\\epsilon^{-4/p}/ \\log^{O(1)}(n)+ (\\epsilon^{-2} +\n\\log (n))). The first term in the lower bound expression was proved in\n\\cite{B-YJKS:stoc02,cks:ccc03}, the second in \\cite{wz:arxiv11} and the third\nin \\cite{wood:soda04}. In this note, we show an Omega(p^2 n^{1-2/p}\n\\epsilon^{-2}/\\log (n)) bits space bound, for Omega(pn^{-1/p}) \\le \\epsilon \\le\n1/10.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2011 12:56:24 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Ganguly", "Sumit", ""]]}, {"id": "1201.0330", "submitter": "Arnab Bhattacharyya", "authors": "Arnab Bhattacharyya, Eldar Fischer, Shachar Lovett", "title": "Testing Low Complexity Affine-Invariant Properties", "comments": "38 pages, appears in SODA '13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariance with respect to linear or affine transformations of the domain is\narguably the most common symmetry exhibited by natural algebraic properties. In\nthis work, we show that any low complexity affine-invariant property of\nmultivariate functions over finite fields is testable with a constant number of\nqueries. This immediately reproves, for instance, that the Reed-Muller code\nover F_p of degree d < p is testable, with an argument that uses no detailed\nalgebraic information about polynomials except that low degree is preserved by\ncomposition with affine maps.\n  The complexity of an affine-invariant property P refers to the maximum\ncomplexity, as defined by Green and Tao (Ann. Math. 2008), of the sets of\nlinear forms used to characterize P. A more precise statement of our main\nresult is that for any fixed prime p >=2 and fixed integer R >= 2, any\naffine-invariant property P of functions f: F_p^n -> [R] is testable, assuming\nthe complexity of the property is less than p. Our proof involves developing\nanalogs of graph-theoretic techniques in an algebraic setting, using tools from\nhigher-order Fourier analysis.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2012 05:51:54 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2012 05:19:47 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Fischer", "Eldar", ""], ["Lovett", "Shachar", ""]]}, {"id": "1201.0345", "submitter": "EPTCS", "authors": "Jean-Yves Marion (LORIA)", "title": "Proceedings Second Workshop on Developments in Implicit Computational\n  Complexity", "comments": "EPTCS 75, 2012", "journal-ref": null, "doi": "10.4204/EPTCS.75", "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Second International Workshop on\nDevelopments in Implicit Computational complExity (DICE 2011), which took place\non April 2-3 2011 in Saarbruecken, Germany, as a satellite event of the Joint\nEuropean Conference on Theory and Practice of Software, ETAPS 2011. Implicit\nComputational Complexity aims at studying computational complexity without\nreferring to external measuring conditions or particular machine models, but\ninstead by considering restrictions on programming languages or logical\nprinciples implying complexity properties. The aim of this workshop was to\nbring together researchers working on implicit computational complexity, from\nits logical and semantics aspects to those related to the static analysis of\nprograms, so as to foster their interaction and to give newcomers an overview\nof the current trends in this area.\n  The first DICE workshop was held in 2010 at ETAPS and published in EPTCS,\nvolume 23 (http://eptcs.org/content.cgi?DICE2010).\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2012 11:55:08 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Marion", "Jean-Yves", "", "LORIA"]]}, {"id": "1201.0410", "submitter": "Zhigang Cao", "authors": "Zhigang Cao and Xiaoguang Yang", "title": "A note on anti-coordination and social interactions", "comments": "7 pages", "journal-ref": null, "doi": "10.1007/s10878-012-9486-7", "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note confirms a conjecture of [Bramoull\\'{e}, Anti-coordination and\nsocial interactions, Games and Economic Behavior, 58, 2007: 30-49]. The\nproblem, which we name the maximum independent cut problem, is a restricted\nversion of the MAX-CUT problem, requiring one side of the cut to be an\nindependent set. We show that the maximum independent cut problem does not\nadmit any polynomial time algorithm with approximation ratio better than\n$n^{1-\\epsilon}$, where $n$ is the number of nodes, and $\\epsilon$ arbitrarily\nsmall, unless P=NP. For the rather special case where each node has a degree of\nat most four, the problem is still MAXSNP-hard.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2012 01:42:20 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2012 04:26:19 GMT"}], "update_date": "2012-04-03", "authors_parsed": [["Cao", "Zhigang", ""], ["Yang", "Xiaoguang", ""]]}, {"id": "1201.0478", "submitter": "Wolfgang Dvo\\v{r}\\'ak", "authors": "Wolfgang Dvo\\v{r}\\'ak", "title": "Technical Note: Exploring \\Sigma^P_2 / \\Pi^P_2-hardness for\n  Argumentation Problems with fixed distance to tractable classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of reasoning in abstracts argumentation frameworks\nclose to graph classes that allow for efficient reasoning methods, i.e.\\ to one\nof the classes of acyclic, noeven, biparite and symmetric AFs. In this work we\nshow that certain reasoning problems on the second level of the polynomial\nhierarchy still maintain their full complexity when restricted to instances of\nfixed distance to one of the above graph classes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2012 14:59:11 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Dvo\u0159\u00e1k", "Wolfgang", ""]]}, {"id": "1201.0488", "submitter": "Cristobal Rojas", "authors": "Mark Braverman, Alexander Grigo, Cristobal Rojas", "title": "Noise vs computational intractability in dynamics", "comments": "ITCS 2012. 37 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.DS nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation plays a key role in predicting and analyzing natural phenomena.\nThere are two fundamental barriers to our ability to computationally understand\nthe long-term behavior of a dynamical system that describes a natural process.\nThe first one is unaccounted-for errors, which may make the system\nunpredictable beyond a very limited time horizon. This is especially true for\nchaotic systems, where a small change in the initial conditions may cause a\ndramatic shift in the trajectories. The second one is Turing-completeness. By\nthe undecidability of the Halting Problem, the long-term prospects of a system\nthat can simulate a Turing Machine cannot be determined computationally.\n  We investigate the interplay between these two forces -- unaccounted-for\nerrors and Turing-completeness. We show that the introduction of even a small\namount of noise into a dynamical system is sufficient to \"destroy\"\nTuring-completeness, and to make the system's long-term behavior\ncomputationally predictable. On a more technical level, we deal with long-term\nstatistical properties of dynamical systems, as described by invariant\nmeasures. We show that while there are simple dynamical systems for which the\ninvariant measures are non-computable, perturbing such systems makes the\ninvariant measures efficiently computable. Thus, noise that makes the short\nterm behavior of the system harder to predict, may make its long term\nstatistical behavior computationally tractable. We also obtain some insight\ninto the computational complexity of predicting systems affected by random\nnoise.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2012 16:39:05 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Braverman", "Mark", ""], ["Grigo", "Alexander", ""], ["Rojas", "Cristobal", ""]]}, {"id": "1201.0824", "submitter": "Hector Zenil", "authors": "Hector Zenil", "title": "On the Dynamic Qualitative Behaviour of Universal Computation", "comments": "forthcoming in Complex Systems vol. 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.DS nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the possible connections between the dynamic behaviour of a system\nand Turing universality in terms of the system's ability to (effectively)\ntransmit and manipulate information. Some arguments will be provided using a\ndefined compression-based transition coefficient which quantifies the\nsensitivity of a system to being programmed. In the same spirit, a list of\nconjectures concerning the ability of Busy Beaver Turing machines to perform\nuniversal computation will be formulated. The main working hypothesis is that\nuniversality is deeply connected to the qualitative behaviour of a system,\nparticularly to its ability to react to external stimulus--as it needs to be\nprogrammed--and to its capacity for transmitting this information.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 05:30:43 GMT"}], "update_date": "2012-01-05", "authors_parsed": [["Zenil", "Hector", ""]]}, {"id": "1201.0825", "submitter": "Hector Zenil", "authors": "Hector Zenil", "title": "Computer Runtimes and the Length of Proofs: On an Algorithmic\n  Probabilistic Application to Waiting Times in Automatic Theorem Proving", "comments": "forthcoming in M.J. Dinneen, B Khoussainov and A. Nies (eds),\n  \"Computation, Physics and Beyond\", LNCS, Springer (Cristian S. Calude\n  festschrift)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an experimental exploration of the relationship between the\nruntimes of Turing machines and the length of proofs in formal axiomatic\nsystems. We compare the number of halting Turing machines of a given size to\nthe number of provable theorems of first-order logic of a given size, and the\nruntime of the longest-running Turing machine of a given size to the proof\nlength of the most-difficult-to-prove theorem of a given size. It is suggested\nthat theorem provers are subject to the same non-linear tradeoff between time\nand size as computer programs are, affording the possibility of determining\noptimal timeouts and waiting times in automatic theorem proving. I provide the\nstatistics for some small choices of parameters for both of these systems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 05:44:14 GMT"}], "update_date": "2012-01-05", "authors_parsed": [["Zenil", "Hector", ""]]}, {"id": "1201.0856", "submitter": "Manuel Bodirsky", "authors": "Manuel Bodirsky", "title": "Complexity Classification in Infinite-Domain Constraint Satisfaction", "comments": "M\\'emoire pour l'obtention d'une HDR \\`a l'universit\\'e Paris 7. 265\n  pages. Version 2 has been prepared after the defence, and contains the\n  official header with information about the HDR jury. Version 10: some more\n  mistakes have been removed. This is the final version of the text, it will no\n  longer be updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DM cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A constraint satisfaction problem (CSP) is a computational problem where the\ninput consists of a finite set of variables and a finite set of constraints,\nand where the task is to decide whether there exists a satisfying assignment of\nvalues to the variables. Depending on the type of constraints that we allow in\nthe input, a CSP might be tractable, or computationally hard. In recent years,\ngeneral criteria have been discovered that imply that a CSP is polynomial-time\ntractable, or that it is NP-hard. Finite-domain CSPs have become a major common\nresearch focus of graph theory, artificial intelligence, and finite model\ntheory. It turned out that the key questions for complexity classification of\nCSPs are closely linked to central questions in universal algebra.\n  This thesis studies CSPs where the variables can take values from an infinite\ndomain. This generalization enhances dramatically the range of computational\nproblems that can be modeled as a CSP. Many problems from areas that have so\nfar seen no interaction with constraint satisfaction theory can be formulated\nusing infinite domains, e.g. problems from temporal and spatial reasoning,\nphylogenetic reconstruction, and operations research.\n  It turns out that the universal-algebraic approach can also be applied to\nstudy large classes of infinite-domain CSPs, yielding elegant complexity\nclassification results. A new tool in this thesis that becomes relevant\nparticularly for infinite domains is Ramsey theory. We demonstrate the\nfeasibility of our approach with two complete complexity classification\nresults: one on CSPs in temporal reasoning, the other on a generalization of\nSchaefer's theorem for propositional logic to logic over graphs. We also study\nthe limits of complexity classification, and present classes of computational\nproblems provably do not exhibit a complexity dichotomy into hard and easy\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 09:39:46 GMT"}, {"version": "v10", "created": "Sat, 20 Apr 2019 07:03:06 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2012 22:21:28 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2012 08:40:59 GMT"}, {"version": "v4", "created": "Thu, 20 Jun 2013 21:36:07 GMT"}, {"version": "v5", "created": "Sat, 13 Jun 2015 06:56:24 GMT"}, {"version": "v6", "created": "Sat, 29 Aug 2015 06:57:29 GMT"}, {"version": "v7", "created": "Mon, 7 Dec 2015 15:33:28 GMT"}, {"version": "v8", "created": "Wed, 14 Sep 2016 14:41:07 GMT"}, {"version": "v9", "created": "Tue, 5 Sep 2017 11:20:55 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Bodirsky", "Manuel", ""]]}, {"id": "1201.1119", "submitter": "EPTCS", "authors": "Daniel Leivant (Indiana University and LORIA Nancy), Ramyaa Ramyaa\n  (Indiana University and Ludwig-Maximilians-Universit\\\"at M\\\"unchen)", "title": "Implicit complexity for coinductive data: a characterization of\n  corecurrence", "comments": "In Proceedings DICE 2011, arXiv:1201.0345", "journal-ref": "EPTCS 75, 2012, pp. 1-14", "doi": "10.4204/EPTCS.75.1", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for reasoning about programs that manipulate\ncoinductive data as well as inductive data. Our approach is based on using\nequational programs, which support a seamless combination of computation and\nreasoning, and using productivity (fairness) as the fundamental assertion,\nrather than bi-simulation. The latter is expressible in terms of the former. As\nan application to this framework, we give an implicit characterization of\ncorecurrence: a function is definable using corecurrence iff its productivity\nis provable using coinduction for formulas in which data-predicates do not\noccur negatively. This is an analog, albeit in weaker form, of a\ncharacterization of recurrence (i.e. primitive recursion) in [Leivant, Unipolar\ninduction, TCS 318, 2004].\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 11:06:38 GMT"}], "update_date": "2012-01-06", "authors_parsed": [["Leivant", "Daniel", "", "Indiana University and LORIA Nancy"], ["Ramyaa", "Ramyaa", "", "Indiana University and Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen"]]}, {"id": "1201.1120", "submitter": "EPTCS", "authors": "Cl\\'ement Aubert (LIPN - UMR7030 CNRS - Universit\\'e Paris 13)", "title": "Sublogarithmic uniform Boolean proof nets", "comments": "In Proceedings DICE 2011, arXiv:1201.0345", "journal-ref": "EPTCS 75, 2012, pp. 15-27", "doi": "10.4204/EPTCS.75.2", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a proofs-as-programs correspondence, Terui was able to compare two\nmodels of parallel computation: Boolean circuits and proof nets for\nmultiplicative linear logic. Mogbil et. al. gave a logspace translation\nallowing us to compare their computational power as uniform complexity classes.\nThis paper presents a novel translation in AC0 and focuses on a simpler\nrestricted notion of uniform Boolean proof nets. We can then encode\nconstant-depth circuits and compare complexity classes below logspace, which\nwere out of reach with the previous translations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 11:06:50 GMT"}], "update_date": "2012-01-06", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "LIPN - UMR7030 CNRS - Universit\u00e9 Paris 13"]]}, {"id": "1201.1122", "submitter": "EPTCS", "authors": "Lucien Capedevielle (ENS de Lyon)", "title": "A type system for PSPACE derived from light linear logic", "comments": "In Proceedings DICE 2011, arXiv:1201.0345", "journal-ref": "EPTCS 75, 2012, pp. 33-46", "doi": "10.4204/EPTCS.75.4", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a polymorphic type system for lambda calculus ensuring that\nwell-typed programs can be executed in polynomial space: dual light affine\nlogic with booleans (DLALB).\n  To build DLALB we start from DLAL (which has a simple type language with a\nlinear and an intuitionistic type arrow, as well as one modality) which\ncharacterizes FPTIME functions. In order to extend its expressiveness we add\ntwo boolean constants and a conditional constructor in the same way as with the\nsystem STAB.\n  We show that the value of a well-typed term can be computed by an alternating\nmachine in polynomial time, thus such a term represents a program of PSPACE\n(given that PSPACE = APTIME).\n  We also prove that all polynomial space decision functions can be represented\nin DLALB.\n  Therefore DLALB characterizes PSPACE predicates.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 11:06:58 GMT"}], "update_date": "2012-01-06", "authors_parsed": [["Capedevielle", "Lucien", "", "ENS de Lyon"]]}, {"id": "1201.1214", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman, Elena Grigorescu, Lev Reyzin, Santosh Vempala, Ying\n  Xiao", "title": "Statistical Algorithms and a Lower Bound for Detecting Planted Clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for proving lower bounds on computational problems\nover distributions against algorithms that can be implemented using access to a\nstatistical query oracle. For such algorithms, access to the input distribution\nis limited to obtaining an estimate of the expectation of any given function on\na sample drawn randomly from the input distribution, rather than directly\naccessing samples. Most natural algorithms of interest in theory and in\npractice, e.g., moments-based methods, local search, standard iterative methods\nfor convex optimization, MCMC and simulated annealing can be implemented in\nthis framework. Our framework is based on, and generalizes, the statistical\nquery model in learning theory (Kearns, 1998).\n  Our main application is a nearly optimal lower bound on the complexity of any\nstatistical query algorithm for detecting planted bipartite clique\ndistributions (or planted dense subgraph distributions) when the planted clique\nhas size $O(n^{1/2-\\delta})$ for any constant $\\delta > 0$. The assumed\nhardness of variants of these problems has been used to prove hardness of\nseveral other problems and as a guarantee for security in cryptographic\napplications. Our lower bounds provide concrete evidence of hardness, thus\nsupporting these assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 16:39:21 GMT"}, {"version": "v2", "created": "Wed, 9 May 2012 19:34:30 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2013 03:54:58 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2013 15:08:58 GMT"}, {"version": "v5", "created": "Mon, 8 Jun 2015 17:38:56 GMT"}, {"version": "v6", "created": "Mon, 15 Aug 2016 01:17:38 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Feldman", "Vitaly", ""], ["Grigorescu", "Elena", ""], ["Reyzin", "Lev", ""], ["Vempala", "Santosh", ""], ["Xiao", "Ying", ""]]}, {"id": "1201.1223", "submitter": "Paul Vitanyi", "authors": "P. M. B. Vitanyi (National Research Center for Mathematics and\n  Computer Science in the Netherlands (CWI))", "title": "Turing Machines and Understanding Computational Complexity", "comments": "9 pages, 1 figure, LaTeX. To appear in: Alan Turing - His Work and\n  Impact, Elsevier", "journal-ref": "In: S. Barry Cooper, Jan van Leeuwen (eds.), \"Alan Turing: His\n  Work and Impact\", Elsevier, Amsterdam, London, New York, Tokyo, 2013,\n  pp.57-63", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the Turing Machine, list some of its many influences on the\ntheory of computation and complexity of computations, and illustrate its\nimportance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 17:24:33 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Vitanyi", "P. M. B.", "", "National Research Center for Mathematics and\n  Computer Science in the Netherlands"]]}, {"id": "1201.1650", "submitter": "Matthew Patitz", "authors": "Sarah Cannon, Erik D. Demaine, Martin L. Demaine, Sarah Eisenstat,\n  Matthew J. Patitz, Robert Schweller, Scott M. Summers, Andrew Winslow", "title": "Two Hands Are Better Than One (up to constant factors)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the difference between the standard seeded model of tile\nself-assembly, and the \"seedless\" two-handed model of tile self-assembly. Most\nof our results suggest that the two-handed model is more powerful. In\nparticular, we show how to simulate any seeded system with a two-handed system\nthat is essentially just a constant factor larger. We exhibit finite shapes\nwith a busy-beaver separation in the number of distinct tiles required by\nseeded versus two-handed, and exhibit an infinite shape that can be constructed\ntwo-handed but not seeded. Finally, we show that verifying whether a given\nsystem uniquely assembles a desired supertile is co-NP-complete in the\ntwo-handed model, while it was known to be polynomially solvable in the seeded\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2012 18:51:32 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Cannon", "Sarah", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Eisenstat", "Sarah", ""], ["Patitz", "Matthew J.", ""], ["Schweller", "Robert", ""], ["Summers", "Scott M.", ""], ["Winslow", "Andrew", ""]]}, {"id": "1201.1666", "submitter": "Rahul Jain", "authors": "Rahul Jain, Attila Pereszlenyi, Penghui Yao", "title": "A direct product theorem for bounded-round public-coin randomized\n  communication complexity", "comments": "19 pages, version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show a direct product theorm in the model of two-party\nbounded-round public-coin randomized communication complexity. For a relation f\nsubset of X times Y times Z (X,Y,Z are finite sets), let R^{(t), pub}_e (f)\ndenote the two-party t-message public-coin communication complexity of f with\nworst case error e. We show that for any relation f and positive integer k:\nR^{(t), pub}_{1 - 2^{-Omega(k/t^2)}}(f^k) = Omega(k/t (R^{(t), pub}_{1/3}(f) -\nO(t^2))) . In particular, it implies a strong direct product theorem for the\ntwo-party constant-message public-coin randomized communication complexity of\nall relations f.\n  Our result for example implies a strong direct product theorem for the\npointer chasing problem. This problem has been well studied for understanding\nround v/s communication trade-offs in both classical and quantum communication\nprotocols.\n  We show our result using information theoretic arguments. Our arguments and\ntechniques build on the ones used in [Jain 2011], where a strong direct product\ntheorem for the two-party one-way public-coin communication complexity of all\nrelations is shown (that is the special case of our result when t=1). One key\ntool used in our work and also in [Jain 2011] is a message compression\ntechnique due to [Braverman and Rao 2011], who used it to show a direct sum\ntheorem for the two-party bounded-round public-coin randomized communication\ncomplexity of all relations. Another important tool that we use is a correlated\nsampling protocol, which for example, has been used in [Holenstein 2007] for\nproving a parallel repetition theorem for two-prover games.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2012 23:31:01 GMT"}], "update_date": "2012-01-10", "authors_parsed": [["Jain", "Rahul", ""], ["Pereszlenyi", "Attila", ""], ["Yao", "Penghui", ""]]}, {"id": "1201.1814", "submitter": "Alexander K. Hartmann", "authors": "Timo Dewenter and Alexander K. Hartmann", "title": "Phase transition for cutting-plane approach to vertex-cover problem", "comments": "4 pages, 3 figures", "journal-ref": "Phys. Rev. E 86, 041128 (2012)", "doi": "10.1103/PhysRevE.86.041128", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the vertex-cover problem which is an NP-hard optimization problem\nand a prototypical model exhibiting phase transitions on random graphs, e.g.,\nErdoes-Renyi (ER) random graphs. These phase transitions coincide with changes\nof the solution space structure, e.g, for the ER ensemble at connectivity\nc=e=2.7183 from replica symmetric to replica-symmetry broken. For the\nvertex-cover problem, also the typical complexity of exact branch-and-bound\nalgorithms, which proceed by exploring the landscape of feasible\nconfigurations, change close to this phase transition from \"easy\" to \"hard\". In\nthis work, we consider an algorithm which has a completely different strategy:\nThe problem is mapped onto a linear programming problem augmented by a\ncutting-plane approach, hence the algorithm operates in a space OUTSIDE the\nspace of feasible configurations until the final step, where a solution is\nfound. Here we show that this type of algorithm also exhibits an \"easy-hard\"\ntransition around c=e, which strongly indicates that the typical hardness of a\nproblem is fundamental to the problem and not due to a specific representation\nof the problem.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2012 16:01:01 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Dewenter", "Timo", ""], ["Hartmann", "Alexander K.", ""]]}, {"id": "1201.2374", "submitter": "Kousha Etessami", "authors": "Kousha Etessami, Alistair Stewart, Mihalis Yannakakis", "title": "Polynomial Time Algorithms for Multi-Type Branching Processes and\n  Stochastic Context-Free Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that one can approximate the least fixed point solution for a\nmultivariate system of monotone probabilistic polynomial equations in time\npolynomial in both the encoding size of the system of equations and in\nlog(1/\\epsilon), where \\epsilon > 0 is the desired additive error bound of the\nsolution. (The model of computation is the standard Turing machine model.)\n  We use this result to resolve several open problems regarding the\ncomputational complexity of computing key quantities associated with some\nclassic and heavily studied stochastic processes, including multi-type\nbranching processes and stochastic context-free grammars.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2012 18:42:46 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2013 11:11:01 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Etessami", "Kousha", ""], ["Stewart", "Alistair", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "1201.2474", "submitter": "Yibei Ling", "authors": "Yibei Ling, Scott Alexander, Richard Lau", "title": "On Quantification of Anchor Placement", "comments": "infocom 1012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to answer a question: for a given traversal area, how to\nquantify the geometric impact of anchor placement on localization performance.\nWe present a theoretical framework for quantifying the anchor placement impact.\nAn experimental study, as well as the field test using a UWB ranging\ntechnology, is presented. These experimental results validate the theoretical\nanalysis. As a byproduct, we propose a two-phase localization method (TPLM) and\nshow that TPLM outperforms the least-square method in localization accuracy by\na huge margin. TPLM performs much faster than the gradient descent method and\nslightly better than the gradient descent method in localization accuracy. Our\nfield test suggests that TPLM is more robust against noise than the\nleast-square and gradient descent methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 04:20:46 GMT"}], "update_date": "2012-01-13", "authors_parsed": [["Ling", "Yibei", ""], ["Alexander", "Scott", ""], ["Lau", "Richard", ""]]}, {"id": "1201.2553", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Naohi Eguchi and Georg Moser", "title": "A New Order-theoretic Characterisation of the Polytime Computable\n  Functions", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new order, the small polynomial path order (sPOP* for short).\nThe order sPOP* provides a characterisation of the class of polynomial time\ncomputable function via term rewrite systems. Any polynomial time computable\nfunction gives rise to a rewrite system that is compatible with sPOP*. On the\nother hand any function defined by a rewrite system compatible with sPOP* is\npolynomial time computable. Technically sPOP* is a tamed recursive path order\nwith product status. Its distinctive feature is the precise control provided.\nFor any rewrite system that is compatible with sPOP* that makes use of\nrecursion up to depth d, the (innermost) runtime complexity is bounded from\nabove by a polynomial of degree d.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 12:57:40 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2012 12:20:25 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Avanzini", "Martin", ""], ["Eguchi", "Naohi", ""], ["Moser", "Georg", ""]]}, {"id": "1201.2780", "submitter": "Somnath Sikdar", "authors": "Alexander Langer and Felix Reidl and Peter Rossmanith and Somnath\n  Sikdar", "title": "Linear Kernels on Graphs Excluding Topological Minors", "comments": "19 pages. A simpler proof of the results of this paper appears in\n  http://arxiv.org/abs/1207.0835. This new paper contains additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that problems which have finite integer index and satisfy a\nrequirement we call treewidth-bounding admit linear kernels on the class of\n$H$-topological-minor free graphs, for an arbitrary fixed graph $H$. This\nbuilds on earlier results by Fomin et al.\\ on linear kernels for $H$-minor-free\ngraphs and by Bodlaender et al.\\ on graphs of bounded genus. Our framework\nencompasses several problems, the prominent ones being Chordal Vertex Deletion,\nFeedback Vertex Set and Edge Dominating Set.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 09:42:53 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2012 09:30:06 GMT"}, {"version": "v3", "created": "Thu, 26 Jan 2012 09:15:33 GMT"}, {"version": "v4", "created": "Fri, 13 Jul 2012 07:26:15 GMT"}], "update_date": "2012-07-16", "authors_parsed": [["Langer", "Alexander", ""], ["Reidl", "Felix", ""], ["Rossmanith", "Peter", ""], ["Sikdar", "Somnath", ""]]}, {"id": "1201.2892", "submitter": "Amir Ali Ahmadi", "authors": "Amir Ali Ahmadi", "title": "Algebraic Relaxations and Hardness Results in Polynomial Optimization\n  and Lyapunov Analysis", "comments": "PhD Thesis, MIT, September, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis settles a number of questions related to computational complexity\nand algebraic, semidefinite programming based relaxations in optimization and\ncontrol.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 16:34:57 GMT"}], "update_date": "2012-01-16", "authors_parsed": [["Ahmadi", "Amir Ali", ""]]}, {"id": "1201.3091", "submitter": "Robert Ganian", "authors": "Robert Ganian", "title": "Using Neighborhood Diversity to Solve Hard Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized algorithms are a very useful tool for dealing with NP-hard\nproblems on graphs. Yet, to properly utilize parameterized algorithms it is\nnecessary to choose the right parameter based on the type of problem and\nproperties of the target graph class. Tree-width is an example of a very\nsuccessful graph parameter, however it cannot be used on dense graph classes\nand there also exist problems which are hard even on graphs of bounded\ntree-width. Such problems can be tackled by using vertex cover as a parameter,\nhowever this places severe restrictions on admissible graph classes.\n  Michael Lampis has recently introduced neighborhood diversity, a new graph\nparameter which generalizes vertex cover to dense graphs. Among other results,\nhe has shown that simple parameterized algorithms exist for a few problems on\ngraphs of bounded neighborhood diversity. Our article further studies this area\nand provides new algorithms parameterized by neighborhood diversity for the\np-Vertex-Disjoint Paths, Graph Motif and Precoloring Extension problems -- the\nlatter two being hard even on graphs of bounded tree-width.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 14:52:50 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2012 13:13:47 GMT"}], "update_date": "2012-01-18", "authors_parsed": [["Ganian", "Robert", ""]]}, {"id": "1201.3181", "submitter": "Yadu Vasudev", "authors": "V. Arvind, Partha Mukhopadhyay, Prajakta Nimbhorkar, Yadu Vasudev", "title": "Near-Optimal Expanding Generating Sets for Solvable Permutation Groups", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G =<S>$ be a solvable permutation group of the symmetric group $S_n$\ngiven as input by the generating set $S$. We give a deterministic\npolynomial-time algorithm that computes an \\emph{expanding generating set} of\nsize $\\tilde{O}(n^2)$ for $G$. More precisely, the algorithm computes a subset\n$T\\subset G$ of size $\\tilde{O}(n^2)(1/\\lambda)^{O(1)}$ such that the\nundirected Cayley graph $Cay(G,T)$ is a $\\lambda$-spectral expander (the\n$\\tilde{O}$ notation suppresses $\\log ^{O(1)}n$ factors). As a byproduct of our\nproof, we get a new explicit construction of $\\varepsilon$-bias spaces of size\n$\\tilde{O}(n\\poly(\\log d))(\\frac{1}{\\varepsilon})^{O(1)}$ for the groups\n$\\Z_d^n$. The earlier known size bound was $O((d+n/\\varepsilon^2))^{11/2}$\ngiven by \\cite{AMN98}.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 09:20:37 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Arvind", "V.", ""], ["Mukhopadhyay", "Partha", ""], ["Nimbhorkar", "Prajakta", ""], ["Vasudev", "Yadu", ""]]}, {"id": "1201.3184", "submitter": "Peng Zhang", "authors": "Peng Zhang", "title": "Partial Degree Bounded Edge Packing Problem", "comments": "9 pages. Being reviewed in FAW 2012. A model of edge packing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [1], whether a target binary string s can be represented from a boolean\nformula with operands chosen from a set of binary strings W was studied. In\nthis paper, we first examine selecting a maximum subset X from W, so that for\nany string t in X, t is not representable by X\\{t}. We rephrase this problem as\ngraph, and surprisingly find it give rise to a broad model of edge packing\nproblem, which itself falls into the model of forbidden subgraph problem.\nSpecifically, given a graph G(V;E) and a constant c, the problem asks to choose\nas many as edges to form a subgraph G'. So that in G', for each edge, at least\none of its endpoints has degree no more than c. We call such G' partial c\ndegree bounded. When c = 1, it turns out to be the complement of dominating\nset. We present several results about hardness, approximation for the general\ngraph and efficient exact algorithm on trees. This edge packing problem model\nalso has a direct interpretation in resource allocation. There are n types of\nresources and m jobs. Each job needs two types of resources. A job can be\naccomplished if either one of its necessary resources is shared by no more than\nc other jobs. The problem then asks to nish as many jobs as possible. We\nbelieve this partial degree bounded graph problem merits more attention.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 09:29:41 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Zhang", "Peng", ""]]}, {"id": "1201.3306", "submitter": "Kenneth Regan", "authors": "Richard J. Lipton and Kenneth W. Regan and Atri Rudra", "title": "Simulating Special but Natural Quantum Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a sub-class of BQP that captures certain structural commonalities\namong many quantum algorithms including Shor's algorithms. This class does not\ncontain all of BQP (e.g. Grover's algorithm does not fall into this class). Our\nmain result is that any algorithm in this class that measures at most O(log n)\nqubits can be simulated by classical randomized polynomial time algorithms.\nThis does not dequantize Shor's algorithm (as the latter measures n qubits) but\nour work also highlights a new potentially hard function for cryptographic\napplications.\n  Our main technical contribution is (to the best of our knowledge) a new exact\ncharacterization of certain sums of Fourier-type coefficients (with\nexponentially many summands).\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 16:22:44 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Lipton", "Richard J.", ""], ["Regan", "Kenneth W.", ""], ["Rudra", "Atri", ""]]}, {"id": "1201.3868", "submitter": "Martin Cooper", "authors": "Martin C. Cooper and Guillaume Escamocher", "title": "A Dichotomy for 2-Constraint Forbidden CSP Patterns", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the CSP (constraint satisfaction problem) is NP-complete, even in\nthe case when all constraints are binary, certain classes of instances are\ntractable. We study classes of instances defined by excluding subproblems. This\napproach has recently led to the discovery of novel tractable classes. The\ncomplete characterisation of all tractable classes defined by forbidding\npatterns (where a pattern is simply a compact representation of a set of\nsubproblems) is a challenging problem. We demonstrate a dichotomy in the case\nof forbidden patterns consisting of either one or two constraints. This has\nallowed us to discover new tractable classes including, for example, a novel\ngeneralisation of 2SAT.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 18:09:36 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Cooper", "Martin C.", ""], ["Escamocher", "Guillaume", ""]]}, {"id": "1201.4344", "submitter": "Bart Kuijpers", "authors": "Joos Heintz, Bart Kuijpers, Andres Rojas Paredes", "title": "On the intrinsic complexity of elimination problems in effective\n  Algebraic Geometry", "comments": "37 pages. arXiv admin note: substantial text overlap with\n  arXiv:1110.3030", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representation of polynomials by arithmetic circuits evaluating them is\nan alternative data structure which allowed considerable progress in polynomial\nequation solving in the last fifteen years. We present a circuit based\ncomputation model which captures all known symbolic elimination algorithms in\neffective algebraic geometry and show the intrinsically exponential complexity\ncharacter of elimination in this complexity model.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2012 17:16:22 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2012 19:57:59 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["Heintz", "Joos", ""], ["Kuijpers", "Bart", ""], ["Paredes", "Andres Rojas", ""]]}, {"id": "1201.4363", "submitter": "Murray Elder", "authors": "Murray Elder and Gillian Elston and Gretchen Ostheimer", "title": "On groups that have normal forms computable in logspace", "comments": "24 pages, 1 figure. Minor corrections from previous version", "journal-ref": null, "doi": "10.1016/j.jalgebra.2013.01.036", "report-no": null, "categories": "math.GR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the class of finitely generated groups which have a normal form\ncomputable in logspace. We prove that the class of such groups is closed under\nfinite extensions, finite index subgroups, direct products, wreath products,\nand also certain free products, and includes the solvable Baumslag-Solitar\ngroups, as well as non-residually finite (and hence non-linear) examples. We\ndefine a group to be logspace embeddable if it embeds in a group with normal\nforms computable in logspace. We prove that finitely generated nilpotent groups\nare logspace embeddable. It follows that all groups of polynomial growth are\nlogspace embeddable.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2012 18:38:44 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2012 04:11:25 GMT"}, {"version": "v3", "created": "Thu, 3 Jan 2013 03:38:59 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Elder", "Murray", ""], ["Elston", "Gillian", ""], ["Ostheimer", "Gretchen", ""]]}, {"id": "1201.4504", "submitter": "Matthew Szudzik", "authors": "Matthew P. Szudzik (Carnegie Mellon)", "title": "Is Turing's Thesis the Consequence of a More General Physical Principle?", "comments": "10 pages, 0 figures; section 1 revised, other minor changes", "journal-ref": "Lecture Notes in Computer Science, vol. 7318, Springer, 2012, pp.\n  714-722", "doi": "10.1007/978-3-642-30870-3_72", "report-no": null, "categories": "math.LO cs.CC cs.LO math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss historical attempts to formulate a physical hypothesis from which\nTuring's thesis may be derived, and also discuss some related attempts to\nestablish the computability of mathematical models in physics. We show that\nthese attempts are all related to a single, unified hypothesis.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2012 19:42:35 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2012 06:43:25 GMT"}, {"version": "v3", "created": "Mon, 2 Apr 2012 09:25:27 GMT"}], "update_date": "2012-07-23", "authors_parsed": [["Szudzik", "Matthew P.", "", "Carnegie Mellon"]]}, {"id": "1201.4856", "submitter": "Matthew  Bauer", "authors": "Matthew S. Bauer", "title": "A PSPACE-Complete First Order Fragment of Computability Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recently launched research program for developing logic as a formal\ntheory of (interactive) computability, several very interesting logics have\nbeen introduced and axiomatized. These fragments of the larger Computability\nLogic aim not only to describe \"what\" can be computed, but also provide a\nmechanism for extracting computational algorithms from proofs. Among the most\nexpressive and fundamental of these is CL4, known to be (constructively) sound\nand complete with respect to the underlying computational semantics.\nFurthermore, the fragment of CL4 not containing blind quantifiers was shown to\nbe decidable in polynomial space. The present work extends this result and\nproves that this fragment is, in fact, PSPACE-complete.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2012 20:59:22 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2012 20:00:30 GMT"}, {"version": "v3", "created": "Sun, 31 Mar 2013 20:16:31 GMT"}], "update_date": "2013-04-02", "authors_parsed": [["Bauer", "Matthew S.", ""]]}, {"id": "1201.4995", "submitter": "Giovanni Viglietta", "authors": "Giovanni Viglietta", "title": "Gaming is a hard job, but someone has to do it!", "comments": "37 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish some general schemes relating the computational complexity of a\nvideo game to the presence of certain common elements or mechanics, such as\ndestroyable paths, collectible items, doors opened by keys or activated by\nbuttons or pressure plates, etc. Then we apply such \"metatheorems\" to several\nvideo games published between 1980 and 1998, including Pac-Man, Tron, Lode\nRunner, Boulder Dash, Deflektor, Mindbender, Pipe Mania, Skweek, Prince of\nPersia, Lemmings, Doom, Puzzle Bobble~3, and Starcraft. We obtain both new\nresults, and improvements or alternative proofs of previously known results.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2012 14:56:45 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2012 00:53:26 GMT"}, {"version": "v3", "created": "Wed, 14 Mar 2012 10:05:07 GMT"}, {"version": "v4", "created": "Thu, 20 Sep 2012 14:49:08 GMT"}, {"version": "v5", "created": "Mon, 28 Oct 2013 16:54:01 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Viglietta", "Giovanni", ""]]}, {"id": "1201.5298", "submitter": "Karolina So{\\l}tys", "authors": "Michael Lampis, Valia Mitsou, and Karolina So{\\l}tys", "title": "Scrabble is PSPACE-Complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the computational complexity of the game of Scrabble.\nWe prove the PSPACE-completeness of a derandomized model of the game, answering\nan open question of Erik Demaine and Robert Hearn.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2012 15:27:31 GMT"}], "update_date": "2012-01-26", "authors_parsed": [["Lampis", "Michael", ""], ["Mitsou", "Valia", ""], ["So\u0142tys", "Karolina", ""]]}, {"id": "1201.5821", "submitter": "Richard Schmied", "authors": "Marek Karpinski and Richard Schmied", "title": "On Approximation Lower Bounds for TSP with Bounded Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new method for proving explicit approximation lower bounds for\nTSP problems with bounded metrics improving on the best up to now known bounds.\nThey almost match the best known bounds for unbounded metric TSP problems. In\nparticular, we prove the best known lower bound for TSP with bounded metrics\nfor the metric bound equal to 4.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2012 16:31:43 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2012 12:33:40 GMT"}], "update_date": "2012-08-09", "authors_parsed": [["Karpinski", "Marek", ""], ["Schmied", "Richard", ""]]}, {"id": "1201.5853", "submitter": "Fr\\'ed\\'eric Olive", "authors": "Etienne Grandjean and Fr\\'ed\\'eric Olive and Ga\\'etan richard", "title": "Descriptive complexity for pictures languages (extended abstract)", "comments": "33 pages - Submited to Lics 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with descriptive complexity of picture languages of any\ndimension by syntactical fragments of existential second-order logic.\n  - We uniformly generalize to any dimension the characterization by\nGiammarresi et al. \\cite{GRST96} of the class of \\emph{recognizable} picture\nlanguages in existential monadic second-order logic. - We state several logical\ncharacterizations of the class of picture languages recognized in linear time\non nondeterministic cellular automata of any dimension. They are the first\nmachine-independent characterizations of complexity classes of cellular\nautomata.\n  Our characterizations are essentially deduced from normalization results we\nprove for first-order and existential second-order logics over pictures. They\nare obtained in a general and uniform framework that allows to extend them to\nother \"regular\" structures. Finally, we describe some hierarchy results that\nshow the optimality of our logical characterizations and delineate their\nlimits.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2012 18:07:42 GMT"}], "update_date": "2012-01-30", "authors_parsed": [["Grandjean", "Etienne", ""], ["Olive", "Fr\u00e9d\u00e9ric", ""], ["richard", "Ga\u00e9tan", ""]]}, {"id": "1201.5972", "submitter": "Daniel Dadush", "authors": "Daniel Dadush and Santosh Vempala", "title": "Near-Optimal Deterministic Algorithms for Volume Computation and Lattice\n  Problems via M-Ellipsoids", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1203863110", "report-no": null, "categories": "cs.CC cs.DS math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a deterministic 2^{O(n)} algorithm for computing an M-ellipsoid of a\nconvex body, matching a known lower bound. This has several interesting\nconsequences including improved deterministic algorithms for volume estimation\nof convex bodies and the shortest and closest lattice vector problems under\ngeneral norms.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 16:58:45 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2012 13:08:16 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Dadush", "Daniel", ""], ["Vempala", "Santosh", ""]]}, {"id": "1201.6306", "submitter": "Hubie Chen", "authors": "Hubie Chen", "title": "Meditations on Quantified Constraint Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantified constraint satisfaction problem (QCSP) is the problem of\ndeciding, given a structure and a first-order prenex sentence whose\nquantifier-free part is the conjunction of atoms, whether or not the sentence\nholds on the structure. One obtains a family of problems by defining, for each\nstructure B, the problem QCSP(B) to be the QCSP where the structure is fixed to\nbe B. In this article, we offer a viewpoint on the research program of\nunderstanding the complexity of the problems QCSP(B) on finite structures. In\nparticular, we propose and discuss a group of conjectures; throughout, we\nattempt to place the conjectures in relation to existing results and to\nemphasize open issues and potential research directions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2012 18:04:56 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Chen", "Hubie", ""]]}, {"id": "1201.6578", "submitter": "Hannah Alpert", "authors": "Hannah Alpert and Jennifer Iglesias", "title": "Length 3 Edge-Disjoint Paths and Partial Orientation", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2003, it was claimed that the following problem was solvable in polynomial\ntime: do there exist k edge-disjoint paths of length exactly 3 between vertices\ns and t in a given graph? The proof was flawed, and we show that this problem\nis NP-hard even if we disallow multiple edges. We use a reduction from Partial\nOrientation, a problem recently shown by P\\'alv\\\"olgyi to be NP-hard.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 15:37:16 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Alpert", "Hannah", ""], ["Iglesias", "Jennifer", ""]]}]