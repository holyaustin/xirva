[{"id": "0903.0050", "submitter": "Abuzer Yakaryilmaz", "authors": "Abuzer Yakaryilmaz and A. C. Cem Say", "title": "Succinctness of two-way probabilistic and quantum finite automata", "comments": "A new version, 21 pages, latex", "journal-ref": "Discrete Mathematics & Theoretical Computer Science, Vol 12, No 4\n  (2010)", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that two-way probabilistic and quantum finite automata (2PFA's and\n2QFA's) can be considerably more concise than both their one-way versions\n(1PFA's and 1QFA's), and two-way nondeterministic finite automata (2NFA's). For\nthis purpose, we demonstrate several infinite families of regular languages\nwhich can be recognized with some fixed probability greater than $ {1/2} $ by\njust tuning the transition amplitudes of a 2QFA (and, in one case, a 2PFA) with\na constant number of states, whereas the sizes of the corresponding 1PFA's,\n1QFA's and 2NFA's grow without bound. We also show that 2QFA's with mixed\nstates can support highly efficient probability amplification. The weakest\nknown model of computation where quantum computers recognize more languages\nwith bounded error than their classical counterparts is introduced.\n", "versions": [{"version": "v1", "created": "Sat, 28 Feb 2009 07:33:50 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2009 13:14:43 GMT"}], "update_date": "2014-01-29", "authors_parsed": [["Yakaryilmaz", "Abuzer", ""], ["Say", "A. C. Cem", ""]]}, {"id": "0903.0173", "submitter": "Alexander Gutfraind", "authors": "Alexander Gutfraind and Aric Hagberg and Feng Pan", "title": "Optimal Interdiction of Unreactive Markovian Evaders", "comments": "Accepted at the Sixth International Conference on integration of AI\n  and OR Techniques in Constraint Programming for Combinatorial Optimization\n  Problems (CPAIOR 2009)", "journal-ref": "CPAIOR 2009", "doi": null, "report-no": "LA-UR-09-00560", "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interdiction problem arises in a variety of areas including military\nlogistics, infectious disease control, and counter-terrorism. In the typical\nformulation of network interdiction, the task of the interdictor is to find a\nset of edges in a weighted network such that the removal of those edges would\nmaximally increase the cost to an evader of traveling on a path through the\nnetwork.\n  Our work is motivated by cases in which the evader has incomplete information\nabout the network or lacks planning time or computational power, e.g. when\nauthorities set up roadblocks to catch bank robbers, the criminals do not know\nall the roadblock locations or the best path to use for their escape.\n  We introduce a model of network interdiction in which the motion of one or\nmore evaders is described by Markov processes and the evaders are assumed not\nto react to interdiction decisions. The interdiction objective is to find an\nedge set of size B, that maximizes the probability of capturing the evaders.\n  We prove that similar to the standard least-cost formulation for\ndeterministic motion this interdiction problem is also NP-hard. But unlike that\nproblem our interdiction problem is submodular and the optimal solution can be\napproximated within 1-1/e using a greedy algorithm. Additionally, we exploit\nsubmodularity through a priority evaluation strategy that eliminates the linear\ncomplexity scaling in the number of network edges and speeds up the solution by\norders of magnitude. Taken together the results bring closer the goal of\nfinding realistic solutions to the interdiction problem on global-scale\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2009 20:10:51 GMT"}], "update_date": "2009-03-03", "authors_parsed": [["Gutfraind", "Alexander", ""], ["Hagberg", "Aric", ""], ["Pan", "Feng", ""]]}, {"id": "0903.0422", "submitter": "Hirotaka Ono", "authors": "Kazuhisa Makino and Hirotaka Ono", "title": "Deductive Inference for the Interiors and Exteriors of Horn Theories", "comments": "20 pages, 1 figure, An extended abstract of this article was\n  presented in Proceedings of Algorithms and Computation, 19th International\n  Symposium (ISAAC 2008), Lecture Notes in Computer Science, Vol. 5369, pp.\n  390-401, Springer-Verlag Berlin Heidelberg, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the deductive inference for the interiors and\nexteriors of Horn knowledge bases, where the interiors and exteriors were\nintroduced by Makino and Ibaraki to study stability properties of knowledge\nbases. We present a linear time algorithm for the deduction for the interiors\nand show that it is co-NP-complete for the deduction for the exteriors. Under\nmodel-based representation, we show that the deduction problem for interiors is\nNP-complete while the one for exteriors is co-NP-complete. As for Horn\nenvelopes of the exteriors, we show that it is linearly solvable under\nmodel-based representation, while it is co-NP-complete under formula-based\nrepresentation. We also discuss the polynomially solvable cases for all the\nintractable problems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2009 01:58:52 GMT"}], "update_date": "2009-03-04", "authors_parsed": [["Makino", "Kazuhisa", ""], ["Ono", "Hirotaka", ""]]}, {"id": "0903.0467", "submitter": "Toby Walsh", "authors": "Christian Bessiere and Emmanuel Hebrard and Brahim Hnich and Zeynep\n  Kiziltan and Toby Walsh", "title": "The Parameterized Complexity of Global Constraints", "comments": "Proceedings of the Twenty-Third AAAI Conference on Artificial\n  Intelligence", "journal-ref": "AAAI-2008, 235-240, 2008", "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that parameterized complexity is a useful tool with which to study\nglobal constraints. In particular, we show that many global constraints which\nare intractable to propagate completely have natural parameters which make them\nfixed-parameter tractable and which are easy to compute. This tractability\ntends either to be the result of a simple dynamic program or of a decomposition\nwhich has a strong backdoor of bounded size. This strong backdoor is often a\ncycle cutset. We also show that parameterized complexity can be used to study\nother aspects of constraint programming like symmetry breaking. For instance,\nwe prove that value symmetry is fixed-parameter tractable to break in the\nnumber of symmetries. Finally, we argue that parameterized complexity can be\nused to derive results about the approximability of constraint propagation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2009 08:44:47 GMT"}], "update_date": "2009-03-04", "authors_parsed": [["Bessiere", "Christian", ""], ["Hebrard", "Emmanuel", ""], ["Hnich", "Brahim", ""], ["Kiziltan", "Zeynep", ""], ["Walsh", "Toby", ""]]}, {"id": "0903.0471", "submitter": "Toby Walsh", "authors": "Christian Bessiere, Emmanuel Hebrard, Brahim Hnich, Zeynep Kiziltan,\n  Toby Walsh", "title": "SLIDE: A Useful Special Case of the CARDPATH Constraint", "comments": "18th European Conference on Artificial Intelligence", "journal-ref": "ECAI 2008: 475-479", "doi": "10.3233/978-1-58603-891-5-475", "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the CardPath constraint. This ensures a given constraint holds a\nnumber of times down a sequence of variables. We show that SLIDE, a special\ncase of CardPath where the slid constraint must hold always, can be used to\nencode a wide range of sliding sequence constraints including CardPath itself.\nWe consider how to propagate SLIDE and provide a complete propagator for\nCardPath. Since propagation is NP-hard in general, we identify special cases\nwhere propagation takes polynomial time. Our experiments demonstrate that using\nSLIDE to encode global constraints can be as efficient and effective as\nspecialised propagators.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2009 09:06:22 GMT"}], "update_date": "2009-03-04", "authors_parsed": [["Bessiere", "Christian", ""], ["Hebrard", "Emmanuel", ""], ["Hnich", "Brahim", ""], ["Kiziltan", "Zeynep", ""], ["Walsh", "Toby", ""]]}, {"id": "0903.0544", "submitter": "Robin Moser", "authors": "Robin A. Moser, G\\'abor Tardos", "title": "A constructive proof of the general Lovasz Local Lemma", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lovasz Local Lemma [EL75] is a powerful tool to non-constructively prove\nthe existence of combinatorial objects meeting a prescribed collection of\ncriteria. In his breakthrough paper [Bec91], Beck demonstrated that a\nconstructive variant can be given under certain more restrictive conditions.\nSimplifications of his procedure and relaxations of its restrictions were\nsubsequently exhibited in several publications [Alo91, MR98, CS00, Mos06,\nSri08, Mos08]. In [Mos09], a constructive proof was presented that works under\nnegligible restrictions, formulated in terms of the Bounded Occurrence\nSatisfiability problem. In the present paper, we reformulate and improve upon\nthese findings so as to directly apply to almost all known applications of the\ngeneral Local Lemma.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2009 14:42:01 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2009 21:10:07 GMT"}, {"version": "v3", "created": "Wed, 20 May 2009 23:30:04 GMT"}], "update_date": "2009-05-21", "authors_parsed": [["Moser", "Robin A.", ""], ["Tardos", "G\u00e1bor", ""]]}, {"id": "0903.1136", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Symmetry Breaking Using Value Precedence", "comments": "17th European Conference on Artificial Intelligence", "journal-ref": "ECAI 2006, 168-172", "doi": "10.1088/1126-6708/2009/06/075", "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comprehensive study of the use of value precedence constraints\nto break value symmetry. We first give a simple encoding of value precedence\ninto ternary constraints that is both efficient and effective at breaking\nsymmetry. We then extend value precedence to deal with a number of\ngeneralizations like wreath value and partial interchangeability. We also show\nthat value precedence is closely related to lexicographical ordering. Finally,\nwe consider the interaction between value precedence and symmetry breaking\nconstraints for variable symmetries.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2009 01:04:50 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "0903.1137", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Complexity of Terminating Preference Elicitation", "comments": "7th International Joint Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2008)", "journal-ref": "AAMAS 2008: 967-974", "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complexity theory is a useful tool to study computational issues surrounding\nthe elicitation of preferences, as well as the strategic manipulation of\nelections aggregating together preferences of multiple agents. We study here\nthe complexity of determining when we can terminate eliciting preferences, and\nprove that the complexity depends on the elicitation strategy. We show, for\ninstance, that it may be better from a computational perspective to elicit all\npreferences from one agent at a time than to elicit individual preferences from\nmultiple agents. We also study the connection between the strategic\nmanipulation of an election and preference elicitation. We show that what we\ncan manipulate affects the computational complexity of manipulation. In\nparticular, we prove that there are voting rules which are easy to manipulate\nif we can change all of an agent's vote, but computationally intractable if we\ncan change only some of their preferences. This suggests that, as with\npreference elicitation, a fine-grained view of manipulation may be informative.\nFinally, we study the connection between predicting the winner of an election\nand preference elicitation. Based on this connection, we identify a voting rule\nwhere it is computationally difficult to decide the probability of a candidate\nwinning given a probability distribution over the votes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2009 01:14:44 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "0903.1139", "submitter": "Toby Walsh", "authors": "Christian Bessiere and Emmanuel Hebrard and Brahim Hnich and Toby\n  Walsh", "title": "The Complexity of Reasoning with Global Constraints", "comments": null, "journal-ref": "Constraints 12(2): 239-259 (2007)", "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint propagation is one of the techniques central to the success of\nconstraint programming. To reduce search, fast algorithms associated with each\nconstraint prune the domains of variables. With global (or non-binary)\nconstraints, the cost of such propagation may be much greater than the\nquadratic cost for binary constraints. We therefore study the computational\ncomplexity of reasoning with global constraints. We first characterise a number\nof important questions related to constraint propagation. We show that such\nquestions are intractable in general, and identify dependencies between the\ntractability and intractability of the different questions. We then demonstrate\nhow the tools of computational complexity can be used in the design and\nanalysis of specific global constraints. In particular, we illustrate how\ncomputational complexity can be used to determine when a lesser level of local\nconsistency should be enforced, when constraints can be safely generalized,\nwhen decomposing constraints will reduce the amount of pruning, and when\ncombining constraints is tractable.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2009 01:32:14 GMT"}], "update_date": "2009-03-09", "authors_parsed": [["Bessiere", "Christian", ""], ["Hebrard", "Emmanuel", ""], ["Hnich", "Brahim", ""], ["Walsh", "Toby", ""]]}, {"id": "0903.1146", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Breaking Value Symmetry", "comments": "Principles and Practice of Constraint Programming - CP 2007, 13th\n  International Conference, CP 2007, Providence, RI, USA, September 23-27,\n  2007, Proceedings. Lecture Notes in Computer Science 4741 Springer 2007, ISBN\n  978-3-540-74969-", "journal-ref": null, "doi": null, "report-no": "COMIC-2007-008", "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One common type of symmetry is when values are symmetric. For example, if we\nare assigning colours (values) to nodes (variables) in a graph colouring\nproblem then we can uniformly interchange the colours throughout a colouring.\nFor a problem with value symmetries, all symmetric solutions can be eliminated\nin polynomial time. However, as we show here, both static and dynamic methods\nto deal with symmetry have computational limitations. With static methods,\npruning all symmetric values is NP-hard in general. With dynamic methods, we\ncan take exponential time on problems which static methods solve without\nsearch.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2009 03:50:17 GMT"}], "update_date": "2009-03-09", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "0903.1147", "submitter": "Toby Walsh", "authors": "Yasuhiko Takenaga and Toby Walsh", "title": "Tetravex is NP-complete", "comments": null, "journal-ref": "Inf. Process. Lett. 99(5): 171-174 (2006)", "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tetravex is a widely played one person computer game in which you are given\n$n^2$ unit tiles, each edge of which is labelled with a number. The objective\nis to place each tile within a $n$ by $n$ square such that all neighbouring\nedges are labelled with an identical number. Unfortunately, playing Tetravex is\ncomputationally hard. More precisely, we prove that deciding if there is a\ntiling of the Tetravex board is NP-complete. Deciding where to place the tiles\nis therefore NP-hard. This may help to explain why Tetravex is a good puzzle.\nThis result compliments a number of similar results for one person games\ninvolving tiling. For example, NP-completeness results have been shown for: the\noffline version of Tetris, KPlumber (which involves rotating tiles containing\ndrawings of pipes to make a connected network), and shortest sliding puzzle\nproblems. It raises a number of open questions. For example, is the infinite\nversion Turing-complete? How do we generate Tetravex problems which are truly\npuzzling as random NP-complete problems are often surprising easy to solve? Can\nwe observe phase transition behaviour? What about the complexity of the problem\nwhen it is guaranteed to have an unique solution? How do we generate puzzles\nwith unique solutions?\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2009 04:00:47 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Takenaga", "Yasuhiko", ""], ["Walsh", "Toby", ""]]}, {"id": "0903.1291", "submitter": "Andrew M. Childs", "authors": "Andris Ambainis, Andrew M. Childs, Fran\\c{c}ois Le Gall, Seiichiro\n  Tani", "title": "The quantum query complexity of certification", "comments": "8 pages; Updated to reflect changes in final journal version and to\n  point out that the main result only applies for k>1", "journal-ref": "Quantum Information and Computation 10, 181-188 (2010)", "doi": "10.26421/QIC10.3-4", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the quantum query complexity of finding a certificate for a\nd-regular, k-level balanced NAND formula. Up to logarithmic factors, we show\nthat the query complexity is Theta(d^{(k+1)/2}) for 0-certificates, and\nTheta(d^{k/2}) for 1-certificates. In particular, this shows that the\nzero-error quantum query complexity of evaluating such formulas is\nO(d^{(k+1)/2}) (again neglecting a logarithmic factor). Our lower bound relies\non the fact that the quantum adversary method obeys a direct sum theorem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2009 21:22:18 GMT"}, {"version": "v2", "created": "Mon, 6 Oct 2014 18:40:56 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Ambainis", "Andris", ""], ["Childs", "Andrew M.", ""], ["Gall", "Fran\u00e7ois Le", ""], ["Tani", "Seiichiro", ""]]}, {"id": "0903.1904", "submitter": "Christopher Laumann", "authors": "C.R. Laumann, R. Moessner, A. Scardicchio, S.L. Sondhi", "title": "Phase transitions and random quantum satisfiability", "comments": "9 pages, 3 figures", "journal-ref": "Quant. Inf. and Comp. (2010) vol. 10 (1) 1 pp. 0001-0015", "doi": null, "report-no": null, "categories": "quant-ph cond-mat.dis-nn cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alongside the effort underway to build quantum computers, it is important to\nbetter understand which classes of problems they will find easy and which\nothers even they will find intractable. We study random ensembles of the\nQMA$_1$-complete quantum satisfiability (QSAT) problem introduced by Bravyi.\nQSAT appropriately generalizes the NP-complete classical satisfiability (SAT)\nproblem. We show that, as the density of clauses/projectors is varied, the\nensembles exhibit quantum phase transitions between phases that are satisfiable\nand unsatisfiable. Remarkably, almost all instances of QSAT for any hypergraph\nexhibit the same dimension of the satisfying manifold. This establishes the\nQSAT decision problem as equivalent to a, potentially new, graph theoretic\nproblem and that the hardest typical instances are likely to be localized in a\nbounded range of clause density.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2009 04:16:16 GMT"}], "update_date": "2010-04-29", "authors_parsed": [["Laumann", "C. R.", ""], ["Moessner", "R.", ""], ["Scardicchio", "A.", ""], ["Sondhi", "S. L.", ""]]}, {"id": "0903.2265", "submitter": "Rolf Harren", "authors": "Rolf Harren, Rob van Stee", "title": "An Absolute 2-Approximation Algorithm for Two-Dimensional Bin Packing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of packing rectangles into bins that are unit\nsquares, where the goal is to minimize the number of bins used. All rectangles\nhave to be packed non-overlapping and orthogonal, i.e., axis-parallel. We\npresent an algorithm for this problem with an absolute worst-case ratio of 2,\nwhich is optimal provided P != NP.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2009 11:39:14 GMT"}], "update_date": "2009-03-16", "authors_parsed": [["Harren", "Rolf", ""], ["van Stee", "Rob", ""]]}, {"id": "0903.2410", "submitter": "Jean-Yves Marion", "authors": "Jean-Yves Marion", "title": "On tiered small jump operators", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 1 (March 31,\n  2009) lmcs:1146", "doi": "10.2168/LMCS-5(1:7)2009", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicative analysis of recursion schema is a method to characterize\ncomplexity classes like the class FPTIME of polynomial time computable\nfunctions. This analysis comes from the works of Bellantoni and Cook, and\nLeivant by data tiering. Here, we refine predicative analysis by using a\nramified Ackermann's construction of a non-primitive recursive function. We\nobtain a hierarchy of functions which characterizes exactly functions, which\nare computed in O(n^k) time over register machine model of computation. For\nthis, we introduce a strict ramification principle. Then, we show how to\ndiagonalize in order to obtain an exponential function and to jump outside\ndeterministic polynomial time. Lastly, we suggest a dependent typed\nlambda-calculus to represent this construction.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2009 15:36:42 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2009 00:32:12 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Marion", "Jean-Yves", ""]]}, {"id": "0903.2825", "submitter": "Susmit Jha", "authors": "Susmit Jha, Sanjit A. Seshia and Rhishikesh Limaye", "title": "On the Computational Complexity of Satisfiability Solving for String\n  Theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satisfiability solvers are increasingly playing a key role in software\nverification, with particularly effective use in the analysis of security\nvulnerabilities. String processing is a key part of many software applications,\nsuch as browsers and web servers. These applications are susceptible to attacks\nthrough malicious data received over network. Automated tools for analyzing the\nsecurity of such applications, thus need to reason about strings. For\nefficiency reasons, it is desirable to have a solver that treats strings as\nfirst-class types. In this paper, we present some theories of strings that are\nuseful in a software security context and analyze the computational complexity\nof the presented theories. We use this complexity analysis to motivate a\nbyte-blast approach which employs a Boolean encoding of the string constraints\nto a corresponding Boolean satisfiability problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2009 18:25:54 GMT"}], "update_date": "2009-03-17", "authors_parsed": [["Jha", "Susmit", ""], ["Seshia", "Sanjit A.", ""], ["Limaye", "Rhishikesh", ""]]}, {"id": "0903.2908", "submitter": "Haijun Zhou", "authors": "Haijun Zhou and Hui Ma", "title": "Communities of solutions in single solution clusters of a random\n  K-Satisfiability formula", "comments": "Extensively revised and expanded into 15 pages with 10 figures. New\n  mean-field calculations and simulation results added", "journal-ref": "Phys. Rev. E 80, 066108 (2009)", "doi": "10.1103/PhysRevE.80.066108", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The solution space of a K-satisfiability (K-SAT) formula is a collection of\nsolution clusters, each of which contains all the solutions that are mutually\nreachable through a sequence of single-spin flips. Knowledge of the statistical\nproperty of solution clusters is valuable for a complete understanding of the\nsolution space structure and the computational complexity of the random K-SAT\nproblem. This paper explores single solution clusters of random 3- and 4-SAT\nformulas through unbiased and biased random walk processes and the\nreplica-symmetric cavity method of statistical physics. We find that the giant\nconnected component of the solution space has already formed many different\ncommunities when the constraint density of the formula is still lower than the\nsolution space clustering transition point. Solutions of the same community are\nmore similar with each other and more densely connected with each other than\nwith the other solutions. The entropy density of a solution community is\ncalculated using belief propagation and is found to be different for different\ncommunities of the same cluster. When the constraint density is beyond the\nclustering transition point, the same behavior is observed for the solution\nclusters reached by several stochastic search algorithms. Taking together, the\nresults of this work suggests a refined picture on the evolution of the\nsolution space structure of the random K-SAT problem; they may also be helpful\nfor designing new heuristic algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2009 06:48:28 GMT"}, {"version": "v2", "created": "Thu, 21 May 2009 06:33:14 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2009 01:15:05 GMT"}], "update_date": "2009-12-20", "authors_parsed": [["Zhou", "Haijun", ""], ["Ma", "Hui", ""]]}, {"id": "0903.3106", "submitter": "Sebastien Tixeuil", "authors": "Toshimitsu Masuzawa, S\\'ebastien Tixeuil (LIP6)", "title": "Stabilizing Maximal Independent Set in Unidirectional Networks is Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6880", "categories": "cs.DS cs.CC cs.DC cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed algorithm is self-stabilizing if after faults and attacks hit\nthe system and place it in some arbitrary global state, the system recovers\nfrom this catastrophic situation without external intervention in finite time.\nIn this paper, we consider the problem of constructing self-stabilizingly a\n\\emph{maximal independent set} in uniform unidirectional networks of arbitrary\nshape. On the negative side, we present evidence that in uniform networks,\n\\emph{deterministic} self-stabilization of this problem is \\emph{impossible}.\nAlso, the \\emph{silence} property (\\emph{i.e.} having communication fixed from\nsome point in every execution) is impossible to guarantee, either for\ndeterministic or for probabilistic variants of protocols. On the positive side,\nwe present a deterministic protocol for networks with arbitrary unidirectional\nnetworks with unique identifiers that exhibits polynomial space and time\ncomplexity in asynchronous scheduling. We complement the study with\nprobabilistic protocols for the uniform case: the first probabilistic protocol\nrequires infinite memory but copes with asynchronous scheduling, while the\nsecond probabilistic protocol has polynomial space complexity but can only\nhandle synchronous scheduling. Both probabilistic solutions have expected\npolynomial time complexity.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2009 08:42:02 GMT"}], "update_date": "2009-04-20", "authors_parsed": [["Masuzawa", "Toshimitsu", "", "LIP6"], ["Tixeuil", "S\u00e9bastien", "", "LIP6"]]}, {"id": "0903.3433", "submitter": "Kohtaro Tadaki", "authors": "Kohtaro Tadaki", "title": "Fixed point theorems on partial randomness", "comments": "19 pages, LaTeX2e, no figures", "journal-ref": "Ann. Pure Appl. Logic 163 (2012) 763-774", "doi": "10.1016/j.apal.2011.09.018", "report-no": null, "categories": "cs.IT cs.CC math.IT math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our former work [K. Tadaki, Local Proceedings of CiE 2008, pp.425-434,\n2008], we developed a statistical mechanical interpretation of algorithmic\ninformation theory by introducing the notion of thermodynamic quantities at\ntemperature T, such as free energy F(T), energy E(T), and statistical\nmechanical entropy S(T), into the theory. These quantities are real functions\nof real argument T>0. We then discovered that, in the interpretation, the\ntemperature T equals to the partial randomness of the values of all these\nthermodynamic quantities, where the notion of partial randomness is a stronger\nrepresentation of the compression rate by program-size complexity. Furthermore,\nwe showed that this situation holds for the temperature itself as a\nthermodynamic quantity. Namely, the computability of the value of partition\nfunction Z(T) gives a sufficient condition for T in (0,1) to be a fixed point\non partial randomness. In this paper, we show that the computability of each of\nall the thermodynamic quantities above gives the sufficient condition also.\nMoreover, we show that the computability of F(T) gives completely different\nfixed points from the computability of Z(T).\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2009 22:04:07 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tadaki", "Kohtaro", ""]]}, {"id": "0903.3889", "submitter": "Marius Zimand", "authors": "Marius Zimand", "title": "On generating independent random strings", "comments": "CiE 2009, Heidelberg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that from two strings that are partially random and independent\n(in the sense of Kolmogorov complexity) it is possible to effectively construct\npolynomially many strings that are random and pairwise independent. If the two\ninitial strings are random, then the above task can be performed in polynomial\ntime. It is also possible to construct in polynomial time a random string, from\ntwo strings that have constant randomness rate.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2009 16:03:08 GMT"}], "update_date": "2009-03-24", "authors_parsed": [["Zimand", "Marius", ""]]}, {"id": "0903.4101", "submitter": "Evira Mayordomo", "authors": "Elvira Mayordomo, Philippe Moser, Sylvain Perifel", "title": "Polylog space compression, pushdown compression, and Lempel-Ziv are\n  incomparable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pressing need for efficient compression schemes for XML documents has\nrecently been focused on stack computation, and in particular calls for a\nformulation of information-lossless stack or pushdown compressors that allows a\nformal analysis of their performance and a more ambitious use of the stack in\nXML compression, where so far it is mainly connected to parsing mechanisms. In\nthis paper we introduce the model of pushdown compressor, based on pushdown\ntransducers that compute a single injective function while keeping the widest\ngenerality regarding stack computation.\n  We also consider online compression algorithms that use at most\npolylogarithmic space (plogon). These algorithms correspond to compressors in\nthe data stream model.\n  We compare the performance of these two families of compressors with each\nother and with the general purpose Lempel-Ziv algorithm. This comparison is\nmade without any a priori assumption on the data's source and considering the\nasymptotic compression ratio for infinite sequences. We prove that in all cases\nthey are incomparable.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2009 15:37:21 GMT"}], "update_date": "2009-03-25", "authors_parsed": [["Mayordomo", "Elvira", ""], ["Moser", "Philippe", ""], ["Perifel", "Sylvain", ""]]}, {"id": "0903.4615", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM, Lip)", "title": "On Decidability Properties of One-Dimensional Cellular Automata", "comments": "Final version; to appear in the Journal of Cellular Automata", "journal-ref": "Journal of Cellular Automata 6, 2-3 (2011) 181-193", "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper Sutner proved that the first-order theory of the\nphase-space $\\mathcal{S}_\\mathcal{A}=(Q^\\mathbb{Z}, \\longrightarrow)$ of a\none-dimensional cellular automaton $\\mathcal{A}$ whose configurations are\nelements of $Q^\\mathbb{Z}$, for a finite set of states $Q$, and where\n$\\longrightarrow$ is the \"next configuration relation\", is decidable. He asked\nwhether this result could be extended to a more expressive logic. We prove in\nthis paper that this is actuallly the case. We first show that, for each\none-dimensional cellular automaton $\\mathcal{A}$, the phase-space\n$\\mathcal{S}_\\mathcal{A}$ is an omega-automatic structure. Then, applying\nrecent results of Kuske and Lohrey on omega-automatic structures, it follows\nthat the first-order theory, extended with some counting and cardinality\nquantifiers, of the structure $\\mathcal{S}_\\mathcal{A}$, is decidable. We give\nsome examples of new decidable properties for one-dimensional cellular\nautomata. In the case of surjective cellular automata, some more efficient\nalgorithms can be deduced from results of Kuske and Lohrey on structures of\nbounded degree. On the other hand we show that the case of cellular automata\ngive new results on automatic graphs.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2009 15:39:35 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2009 19:14:13 GMT"}], "update_date": "2010-10-01", "authors_parsed": [["Finkel", "Olivier", "", "ELM, Lip"]]}, {"id": "0903.4728", "submitter": "Xi Chen", "authors": "Jin-Yi Cai, Xi Chen, and Pinyan Lu", "title": "Graph Homomorphisms with Complex Values: A Dichotomy Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph homomorphism has been studied intensively. Given an m x m symmetric\nmatrix A, the graph homomorphism function is defined as \\[Z_A (G) =\n\\sum_{f:V->[m]} \\prod_{(u,v)\\in E} A_{f(u),f(v)}, \\] where G = (V,E) is any\nundirected graph. The function Z_A can encode many interesting graph\nproperties, including counting vertex covers and k-colorings. We study the\ncomputational complexity of Z_A for arbitrary symmetric matrices A with\nalgebraic complex values. Building on work by Dyer and Greenhill, Bulatov and\nGrohe, and especially the recent beautiful work by Goldberg, Grohe, Jerrum and\nThurley, we prove a complete dichotomy theorem for this problem. We show that\nZ_A is either computable in polynomial-time or #P-hard, depending explicitly on\nthe matrix A. We further prove that the tractability criterion on A is\npolynomial-time decidable.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2009 02:57:32 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2011 00:29:18 GMT"}], "update_date": "2011-10-10", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Chen", "Xi", ""], ["Lu", "Pinyan", ""]]}, {"id": "0903.5392", "submitter": "J\\\"urgen Koslowski", "authors": "Paola Bruscoli, Alessio Guglielmi, Tom Gundersen and Michel Parigot", "title": "Quasipolynomial Normalisation in Deep Inference via Atomic Flows and\n  Threshold Formulae", "comments": "Accepted by Logical Methods in Computer Science", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 2 (May 3,\n  2016) lmcs:1637", "doi": "10.1007/978-3-642-17511-4_9", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Je\\v{r}\\'abek showed that cuts in classical propositional logic proofs in\ndeep inference can be eliminated in quasipolynomial time. The proof is indirect\nand it relies on a result of Atserias, Galesi and Pudl\\'ak about monotone\nsequent calculus and a correspondence between that system and cut-free\ndeep-inference proofs. In this paper we give a direct proof of Je\\v{r}\\'abek's\nresult: we give a quasipolynomial-time cut-elimination procedure for classical\npropositional logic in deep inference. The main new ingredient is the use of a\ncomputational trace of deep-inference proofs called atomic flows, which are\nboth very simple (they only trace structural rules and forget logical rules)\nand strong enough to faithfully represent the cut-elimination procedure.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2009 10:37:42 GMT"}, {"version": "v2", "created": "Tue, 29 Apr 2014 13:49:34 GMT"}, {"version": "v3", "created": "Mon, 5 May 2014 16:06:34 GMT"}, {"version": "v4", "created": "Wed, 24 Feb 2016 13:07:34 GMT"}, {"version": "v5", "created": "Mon, 2 May 2016 06:36:04 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Bruscoli", "Paola", ""], ["Guglielmi", "Alessio", ""], ["Gundersen", "Tom", ""], ["Parigot", "Michel", ""]]}]