[{"id": "1310.0398", "submitter": "Lin Chen", "authors": "Lin Chen, Klaus Jansen, Guochuan Zhang", "title": "On the optimality of approximation schemes for the classical scheduling\n  problem", "comments": "33 pages, to appear in SODA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical scheduling problem on parallel identical machines\nto minimize the makespan, and achieve the following results under the\nExponential Time Hypothesis (ETH)\n  1. The scheduling problem on a constant number $m$ of identical machines,\nwhich is denoted as $Pm||C_{max}$, is known to admit a fully polynomial time\napproximation scheme (FPTAS) of running time $O(n) + (1/\\epsilon)^{O(m)}$\n(indeed, the algorithm works for an even more general problem where machines\nare unrelated). We prove this algorithm is essentially the best possible in the\nsense that a $(1/\\epsilon)^{O(m^{1-\\delta})}+n^{O(1)}$ time FPTAS for any\n$\\delta>0$ implies that ETH fails.\n  2. The scheduling problem on an arbitrary number of identical machines, which\nis denoted as $P||C_{max}$, is known to admit a polynomial time approximation\nscheme (PTAS) of running time $2^{O(1/\\epsilon^2\\log^3(1/\\epsilon))}+n^{O(1)}$.\nWe prove this algorithm is nearly optimal in the sense that a\n$2^{O((1/\\epsilon)^{1-\\delta})}+n^{O(1)}$ time PTAS for any $\\delta>0$ implies\nthat ETH fails, leaving a small room for improvement.\n  To obtain these results we will provide two new reductions from 3SAT, one for\n$Pm||C_{max}$ and another for $P||C_{max}$. Indeed, the new reductions explore\nthe structure of scheduling problems and can also lead to other interesting\nresults. For example, using the framework of our reduction for $P||C_{max}$,\nChen et al. (arXiv:1306.3727) is able to prove the APX-hardness of the\nscheduling problem in which the matrix of job processing times\n$P=(p_{ij})_{m\\times n}$ is of rank 3, solving the open problem mentioned by\nBhaskara et al. (SODA 2013).\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 17:25:57 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Chen", "Lin", ""], ["Jansen", "Klaus", ""], ["Zhang", "Guochuan", ""]]}, {"id": "1310.0933", "submitter": "Arkadius Kalka", "authors": "Murray Elder and Arkadius Kalka", "title": "Logspace computations for Garside groups of spindle type", "comments": "22 pages; short version as v1. Terminolgy and title changed. In\n  particular, in previous versions we called Garside groups of spindle type\n  \"rigid Garside groups\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  M. Picantin introduced the notion of Garside groups of spindle type,\ngeneralizing the 3-strand braid group. We show that, for linear Garside groups\nof spindle type, a normal form and a solution to the conjugacy problem are\nlogspace computable. For linear Garside groups of spindle type with homogenous\npresentation we compute a geodesic normal form in logspace.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2013 10:01:19 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2013 09:04:32 GMT"}, {"version": "v3", "created": "Sun, 27 Oct 2013 13:44:40 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Elder", "Murray", ""], ["Kalka", "Arkadius", ""]]}, {"id": "1310.0967", "submitter": "Marco Bardoscia", "authors": "Marco Bardoscia, Daniel Nagaj, Antonello Scardicchio", "title": "The SAT-UNSAT transition in the adversarial SAT problem", "comments": "13 pages, 8 figures", "journal-ref": "Phys. Rev. E 89, 032128 (2014)", "doi": "10.1103/PhysRevE.89.032128", "report-no": null, "categories": "cs.CC cond-mat.dis-nn cond-mat.stat-mech cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial SAT (AdSAT) is a generalization of the satisfiability (SAT)\nproblem in which two players try to make a boolean formula true (resp. false)\nby controlling their respective sets of variables. AdSAT belongs to a higher\ncomplexity class in the polynomial hierarchy than SAT and therefore the nature\nof the critical region and the transition are not easily paralleled to those of\nSAT and worth of independent study. AdSAT also provides an upper bound for the\ntransition threshold of the quantum satisfiability problem (QSAT). We present a\ncomplete algorithm for AdSAT, show that 2-AdSAT is in $\\mathbf{P}$, and then\nstudy two stochastic algorithms (simulated annealing and its improved variant)\nand compare their performances in detail for 3-AdSAT. Varying the density of\nclauses $\\alpha$ we find a sharp SAT-UNSAT transition at a critical value whose\nupper bound is $\\alpha_c \\lesssim 1.5$, thus providing a much stricter upper\nbound for the QSAT transition than those previously found.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2013 13:03:20 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2013 05:28:38 GMT"}, {"version": "v3", "created": "Fri, 7 Mar 2014 19:07:59 GMT"}], "update_date": "2014-04-02", "authors_parsed": [["Bardoscia", "Marco", ""], ["Nagaj", "Daniel", ""], ["Scardicchio", "Antonello", ""]]}, {"id": "1310.1362", "submitter": "J. M. Landsberg", "authors": "Fulvio Gesmundo, Jonathan Hauenstein, Christian Ikenmeyer, and JM\n  Landsberg", "title": "Complexity of linear circuits and geometry", "comments": "29 pages, final version to appear in FOCM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use algebraic geometry to study matrix rigidity, and more generally, the\ncomplexity of computing a matrix-vector product, continuing a study initiated\nby Kumar, et. al. We (i) exhibit many non-obvious equations testing for\n(border) rigidity, (ii) compute degrees of varieties associated to rigidity,\n(iii) describe algebraic varieties associated to families of matrices that are\nexpected to have super-linear rigidity, and (iv) prove results about the ideals\nand degrees of cones that are of interest in their own right.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2013 18:34:45 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2015 19:36:21 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Gesmundo", "Fulvio", ""], ["Hauenstein", "Jonathan", ""], ["Ikenmeyer", "Christian", ""], ["Landsberg", "JM", ""]]}, {"id": "1310.1428", "submitter": "James Whitfield", "authors": "J. D. Whitfield, M.-H. Yung, D. G. Tempel, S. Boixo, A. Aspuru-Guzik", "title": "Computational complexity of time-dependent density functional theory", "comments": null, "journal-ref": "New J. Phys. 16 (2014) 083035", "doi": "10.1088/1367-2630/16/8/083035", "report-no": null, "categories": "quant-ph cs.CC physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-dependent density functional theory (TDDFT) is rapidly emerging as a\npremier method for solving dynamical many-body problems in physics and\nchemistry. The mathematical foundations of TDDFT are established through the\nformal existence of a fictitious non-interacting system (known as the Kohn-Sham\nsystem), which can reproduce the one-electron reduced probability density of\nthe actual system. We build upon these works and show that on the interior of\nthe domain of existence, the Kohn-Sham system can be efficiently obtained given\nthe time-dependent density. Since a quantum computer can efficiently produce\nsuch time-dependent densities, we present a polynomial time quantum algorithm\nto generate the time-dependent Kohn-Sham potential with controllable error\nbounds. As a consequence, in contrast to the known intractability result for\nground state density functional theory (DFT), the computation of the necessary\ntime-dependent potentials given the initial state is in the complexity class\ndescribed by bounded error quantum computation in polynomial time (BQP).\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2013 02:10:07 GMT"}, {"version": "v2", "created": "Thu, 21 Aug 2014 12:13:37 GMT"}], "update_date": "2014-08-22", "authors_parsed": [["Whitfield", "J. D.", ""], ["Yung", "M. -H.", ""], ["Tempel", "D. G.", ""], ["Boixo", "S.", ""], ["Aspuru-Guzik", "A.", ""]]}, {"id": "1310.1493", "submitter": "Tselil Schramm", "authors": "Prasad Raghavendra and Tselil Schramm", "title": "Gap Amplification for Small-Set Expansion via Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we achieve gap amplification for the Small-Set Expansion\nproblem. Specifically, we show that an instance of the Small-Set Expansion\nProblem with completeness $\\epsilon$ and soundness $\\frac{1}{2}$ is at least as\ndifficult as Small-Set Expansion with completeness $\\epsilon$ and soundness\n$f(\\epsilon)$, for any function $f(\\epsilon)$ which grows faster than\n$\\sqrt{\\epsilon}$. We achieve this amplification via random walks -- our gadget\nis the graph with adjacency matrix corresponding to a random walk on the\noriginal graph. An interesting feature of our reduction is that unlike gap\namplification via parallel repetition, the size of the instances (number of\nvertices) produced by the reduction remains the same.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2013 16:35:35 GMT"}, {"version": "v2", "created": "Sun, 4 May 2014 17:34:55 GMT"}, {"version": "v3", "created": "Wed, 2 Jul 2014 07:18:59 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Raghavendra", "Prasad", ""], ["Schramm", "Tselil", ""]]}, {"id": "1310.1930", "submitter": "Nikos Vlassis", "authors": "Nikos Vlassis, Rapha\\\"el Jungers", "title": "Polytopic uncertainty for linear systems: New and old complexity results", "comments": "Fixed some typos and added some references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey the problem of deciding the stability or stabilizability of\nuncertain linear systems whose region of uncertainty is a polytope. This\nnatural setting has applications in many fields of applied science, from\nControl Theory to Systems Engineering to Biology. We focus on the algorithmic\ndecidability of this property when one is given a particular polytope. This\nsetting gives rise to several different algorithmic questions, depending on the\nnature of time (discrete/continuous), the property asked\n(stability/stabilizability), or the type of uncertainty (fixed/switching).\nSeveral of these questions have been answered in the literature in the last\nthirty years. We point out the ones that have remained open, and we answer all\nof them, except one which we raise as an open question. In all the cases, the\nresults are negative in the sense that the questions are NP-hard. As a\nbyproduct, we obtain complexity results for several other matrix problems in\nSystems and Control.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 20:01:30 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2014 15:22:06 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Vlassis", "Nikos", ""], ["Jungers", "Rapha\u00ebl", ""]]}, {"id": "1310.1971", "submitter": "Frederic Gillet", "authors": "Frederic Gillet", "title": "Solving 3-SAT and 3-dimensional matching in polynomial time", "comments": "The proposed method does not work. Updated the article with an\n  analysis of why the general method suggested cannot work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how the implementation of conservative logic gates on flow networks\nsuggests a way to solve 3SAT and 3-dimensional matching problems in polynomial\ntime by using standard minimum-cost flow methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 22:56:21 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2013 14:37:38 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2013 04:11:53 GMT"}, {"version": "v4", "created": "Sun, 13 Oct 2013 14:11:43 GMT"}, {"version": "v5", "created": "Wed, 27 Nov 2013 19:51:07 GMT"}, {"version": "v6", "created": "Tue, 4 Feb 2014 20:07:45 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Gillet", "Frederic", ""]]}, {"id": "1310.2017", "submitter": "Igor Shinkar", "authors": "Itai Benjamini, Gil Cohen, Igor Shinkar", "title": "Bi-Lipschitz Bijection between the Boolean Cube and the Hamming Ball", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a bi-Lipschitz bijection from the Boolean cube to the Hamming\nball of equal volume. More precisely, we show that for all even n there exists\nan explicit bijection f from the n-dimensional Boolean cube to the Hamming ball\nof equal volume embedded in (n+1)-dimensional Boolean cube, such that for all x\nand y it holds that distance(x,y) / 5 <= distance(f(x),f(y)) <= 4 distance(x,y)\nwhere distance(,) denotes the Hamming distance. In particular, this implies\nthat the Hamming ball is bi-Lipschitz transitive.\n  This result gives a strong negative answer to an open problem of Lovett and\nViola [CC 2012], who raised the question in the context of sampling\ndistributions in low-level complexity classes. The conceptual implication is\nthat the problem of proving lower bounds in the context of sampling\ndistributions will require some new ideas beyond the sensitivity-based\nstructural results of Boppana [IPL 97].\n  We study the mapping f further and show that it (and its inverse) are\ncomputable in DLOGTIME-uniform TC0, but not in AC0. Moreover, we prove that f\nis \"approximately local\" in the sense that all but the last output bit of f are\nessentially determined by a single input bit.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 06:58:09 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Benjamini", "Itai", ""], ["Cohen", "Gil", ""], ["Shinkar", "Igor", ""]]}, {"id": "1310.2447", "submitter": "Pascal Koiran", "authors": "Pascal Koiran (LIP), Natacha Portier (LIP), S\\'ebastien Tavenas (LIP)", "title": "On the intersection of a sparse curve and a low-degree curve: A\n  polynomial version of the lost theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a system of two polynomial equations in two variables:\n$$F(X,Y)=G(X,Y)=0$$ where $F \\in \\rr[X,Y]$ has degree $d \\geq 1$ and $G \\in\n\\rr[X,Y]$ has $t$ monomials. We show that the system has only $O(d^3t+d^2t^3)$\nreal solutions when it has a finite number of real solutions. This is the first\npolynomial bound for this problem. In particular, the bounds coming from the\ntheory of fewnomials are exponential in $t$, and count only nondegenerate\nsolutions. More generally, we show that if the set of solutions is infinite, it\nstill has at most $O(d^3t+d^2t^3)$ connected components. By contrast, the\nfollowing question seems to be open: if $F$ and $G$ have at most $t$ monomials,\nis the number of (nondegenerate) solutions polynomial in $t$? The authors'\ninterest for these problems was sparked by connections between lower bounds in\nalgebraic complexity theory and upper bounds on the number of real roots of\n\"sparse like\" polynomials.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 12:11:39 GMT"}, {"version": "v2", "created": "Wed, 23 Jul 2014 13:53:41 GMT"}], "update_date": "2014-07-24", "authors_parsed": [["Koiran", "Pascal", "", "LIP"], ["Portier", "Natacha", "", "LIP"], ["Tavenas", "S\u00e9bastien", "", "LIP"]]}, {"id": "1310.2711", "submitter": "Mohammad Hajiaghayi", "authors": "Mohammad T. Hajiaghayi and Rohit Khandekar and Guy Kortsarz", "title": "Fixed Parameter Inapproximability for Clique and SetCover in Time\n  Super-exponential in OPT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider proving inapproximability in terms of OPT and thus\nwe base the foundations of fixed parameter inapproximability.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 06:08:03 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2013 01:13:16 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Hajiaghayi", "Mohammad T.", ""], ["Khandekar", "Rohit", ""], ["Kortsarz", "Guy", ""]]}, {"id": "1310.2885", "submitter": "Henry Yuen", "authors": "Henry Yuen", "title": "A quantum lower bound for distinguishing random functions from random\n  permutations", "comments": "9 pages. Comments welcome. Fixed minor errors and typos in v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of distinguishing between a random function and a random\npermutation on a domain of size $N$ is important in theoretical cryptography,\nwhere the security of many primitives depend on the problem's hardness. We\nstudy the quantum query complexity of this problem, and show that any quantum\nalgorithm that solves this problem with bounded error must make\n$\\Omega(N^{1/5}/\\log N)$ queries to the input function. Our lower bound proof\nuses a combination of the Collision Problem lower bound and Ambainis's\nadversary theorem.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 17:02:19 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2013 04:50:18 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["Yuen", "Henry", ""]]}, {"id": "1310.3311", "submitter": "Lucas Kang", "authors": "Lucas Kang", "title": "Investigation of Rule 73 as Case Study of Class 4 Long-Distance Cellular\n  Automata", "comments": "23 pages (including references and comments), 25 figures, independent\n  research, to be published in nlin.CG, nlin.PS and cs.CC", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CG cs.CC nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular automata (CA) have been utilized for decades as discrete models of\nmany physical, mathematical, chemical, biological, and computing systems. The\nmost widely known form of CA, the elementary cellular automaton (ECA), has been\nstudied in particular due to its simple form and versatility. However, these\ndynamic computation systems possess evolutionary rules dependent on a\nneighborhood of adjacent cells, which limits their sampling radius and the\nenvironments that they can be used in.\n  The purpose of this study was to explore the complex nature of\none-dimensional CA in configurations other than that of the standard ECA.\nNamely, \"long-distance cellular automata\" (LDCA), a construct that had been\ndescribed in the past, but never studied. I experimented with a class of LDCA\nthat used spaced sample cells unlike ECA, and were described by the notation\nLDCA-x-y-n, where x and y represented the amount of spacing between the cell\nand its left and right neighbors, and n denoted the length of the initial tape\nfor tapes of finite size. Some basic characteristics of ECA are explored in\nthis paper, such as seemingly universal behavior, the prevalence of complexity\nwith varying neighborhoods, and qualitative behavior as a function of x and y\nspacing.\n  Focusing mainly on purely Class 4 behavior in LDCA-1-2, I found that Rule 73\ncould potentially be Turing universal through the emulation of a cyclic tag\nsystem, and revealed a connection between the mathematics of binary trees and\nEulerian numbers that might provide insight into unsolved problems in both\nfields.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2013 23:34:07 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Kang", "Lucas", ""]]}, {"id": "1310.3673", "submitter": "Tongu\\c{c} \\\"Unl\\\"uyurt", "authors": "Sarah R. Allen, Lisa Hellerstein, Devorah Kletenik, Tongu\\c{c}\n  \\\"Unl\\\"uyurt", "title": "Evaluation of DNF Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Boolean Function Evaluation (SBFE) is the problem of determining\nthe value of a given Boolean function $f$ on an unknown input $x$, when each\nbit of $x_i$ of $x$ can only be determined by paying a given associated cost\n$c_i$. Further, $x$ is drawn from a given product distribution: for each $x_i$,\n$Prob[x_i=1] = p_i$, and the bits are independent. The goal is to minimize the\nexpected cost of evaluation. Stochastic Boolean Function Evaluation (SBFE) is\nthe problem of determining the value of a given Boolean function $f$ on an\nunknown input $x$, when each bit of $x_i$ of $x$ can only be determined by\npaying a given associated cost $c_i$. Further, $x$ is drawn from a given\nproduct distribution: for each $x_i$, $Prob[x_i=1] = p_i$, and the bits are\nindependent. The goal is to minimize the expected cost of evaluation. In this\npaper, we study the complexity of the SBFE problem for classes of DNF formulas.\nWe consider both exact and approximate versions of the problem for subclasses\nof DNF, for arbitrary costs and product distributions, and for unit costs\nand/or the uniform distribution.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 13:19:56 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2013 12:38:22 GMT"}, {"version": "v3", "created": "Wed, 8 Oct 2014 14:26:10 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Allen", "Sarah R.", ""], ["Hellerstein", "Lisa", ""], ["Kletenik", "Devorah", ""], ["\u00dcnl\u00fcyurt", "Tongu\u00e7", ""]]}, {"id": "1310.3674", "submitter": "Victor Lagerkvist Mr", "authors": "Victor Lagerkvist", "title": "Weak Bases of Boolean Co-Clones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal algebra and clone theory have proven to be a useful tool in the\nstudy of constraint satisfaction problems since the complexity, up to logspace\nreductions, is determined by the set of polymorphisms of the constraint\nlanguage. For classifications where primitive positive definitions are\nunsuitable, such as size-preserving reductions, weaker closure operations may\nbe necessary. In this article we consider strong partial clones which can be\nseen as a more fine-grained framework than Post's lattice where each clone\nsplits into an interval of strong partial clones. We investigate these\nintervals and give simple relational descriptions, weak bases, of the largest\nelements. The weak bases have a highly regular form and are in many cases\neasily relatable to the smallest members in the intervals, which suggests that\nthe lattice of strong partial clones is considerably simpler than the full\nlattice of partial clones.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 13:24:03 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Lagerkvist", "Victor", ""]]}, {"id": "1310.3794", "submitter": "Zhengfeng Ji", "authors": "Zhengfeng Ji", "title": "Binary Constraint System Games and Locally Commutative Reductions", "comments": "21 pages, 6 figures; v2 contains an explicit proof of Lemma 4, a\n  theorem on HORN-SAT* and several extended discussions", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A binary constraint system game is a two-player one-round non-local game\ndefined by a system of Boolean constraints. The game has a perfect quantum\nstrategy if and only if the constraint system has a quantum satisfying\nassignment [R. Cleve and R. Mittal, arXiv:1209.2729]. We show that several\nconcepts including the quantum chromatic number and the Kochen-Specker sets\nthat arose from different contexts fit naturally in the binary constraint\nsystem framework. The structure and complexity of the quantum satisfiability\nproblems for these constraint systems are investigated. Combined with a new\nconstruct called the commutativity gadget for each problem, several classic\nNP-hardness reductions are lifted to their corresponding quantum versions. We\nalso provide a simple parity constraint game that requires $\\Omega(\\sqrt{n})$\nEPR pairs in perfect strategies where $n$ is the number of variables in the\nconstraint system.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 19:08:50 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2013 18:17:24 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Ji", "Zhengfeng", ""]]}, {"id": "1310.4113", "submitter": "Thomas Vidick", "authors": "Irit Dinur, David Steurer, Thomas Vidick", "title": "A parallel repetition theorem for entangled projection games", "comments": "30 pages. v2: improved exponent for expanding games; typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of the entangled value of two-player one-round\nprojection games under parallel repetition. We show that for any projection\ngame $G$ of entangled value 1-eps < 1, the value of the $k$-fold repetition of\nG goes to zero as O((1-eps^c)^k), for some universal constant c\\geq 1.\nPreviously parallel repetition with an exponential decay in $k$ was only known\nfor the case of XOR and unique games. To prove the theorem we extend an\nanalytical framework recently introduced by Dinur and Steurer for the study of\nthe classical value of projection games under parallel repetition. Our proof,\nas theirs, relies on the introduction of a simple relaxation of the entangled\nvalue that is perfectly multiplicative. The main technical component of the\nproof consists in showing that the relaxed value remains tightly connected to\nthe entangled value, thereby establishing the parallel repetition theorem. More\ngenerally, we obtain results on the behavior of the entangled value under\nproducts of arbitrary (not necessarily identical) projection games. Relating\nour relaxed value to the entangled value is done by giving an algorithm for\nconverting a relaxed variant of quantum strategies that we call \"vector quantum\nstrategy\" to a quantum strategy. The algorithm is considerably simpler in case\nthe bipartite distribution of questions in the game has good expansion\nproperties. When this is not the case, rounding relies on a quantum analogue of\nHolenstein's correlated sampling lemma which may be of independent interest.\nOur \"quantum correlated sampling lemma\" generalizes results of van Dam and\nHayden on universal embezzlement.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 16:51:36 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2015 22:38:58 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Dinur", "Irit", ""], ["Steurer", "David", ""], ["Vidick", "Thomas", ""]]}, {"id": "1310.4127", "submitter": "Seiichiro Tani", "authors": "Fran\\c{c}ois Le Gall, Harumichi Nishimura, Seiichiro Tani", "title": "Quantum Algorithms for Finding Constant-sized Sub-hypergraphs", "comments": "18 pages; v2: changed title, added more backgrounds to the\n  introduction, added another application", "journal-ref": "Theoretical Computer Science 609, pp. 569-582, 2016", "doi": "10.1016/j.tcs.2015.10.006", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general framework to construct quantum algorithms that detect if\na $3$-uniform hypergraph given as input contains a sub-hypergraph isomorphic to\na prespecified constant-sized hypergraph. This framework is based on the\nconcept of nested quantum walks recently proposed by Jeffery, Kothari and\nMagniez [SODA'13], and extends the methodology designed by Lee, Magniez and\nSantha [SODA'13] for similar problems over graphs. As applications, we obtain a\nquantum algorithm for finding a $4$-clique in a $3$-uniform hypergraph on $n$\nvertices with query complexity $O(n^{1.883})$, and a quantum algorithm for\ndetermining if a ternary operator over a set of size $n$ is associative with\nquery complexity $O(n^{2.113})$.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 17:44:17 GMT"}, {"version": "v2", "created": "Fri, 9 May 2014 00:55:31 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""], ["Nishimura", "Harumichi", ""], ["Tani", "Seiichiro", ""]]}, {"id": "1310.4141", "submitter": "Daniel Severin Dr.", "authors": "Javier Marenco, Marcelo Mydlarz, Daniel Severin", "title": "Topological Additive Numbering of Directed Acyclic Graphs", "comments": null, "journal-ref": "Information Processing Letters, Volume 115, Issue 2 (2015),\n  199--202", "doi": "10.1016/j.ipl.2014.09.011", "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to study a problem that arises naturally from both Topological\nNumbering of Directed Acyclic Graphs, and Additive Coloring (also known as\nLucky Labeling). Let $D$ be a digraph and $f$ a labeling of its vertices with\npositive integers; denote by $S(v)$ the sum of labels over all neighbors of\neach vertex $v$. The labeling $f$ is called \\emph{topological additive\nnumbering} if $S(u) < S(v)$ for each arc $(u,v)$ of the digraph. The problem\nasks to find the minimum number $k$ for which $D$ has a topological additive\nnumbering with labels belonging to $\\{ 1, \\ldots, k \\}$, denoted by\n$\\eta_t(D)$.\n  We characterize when a digraph has topological additive numberings, give a\nlower bound for $\\eta_t(D)$, and provide an integer programming formulation for\nour problem, characterizing when its coefficient matrix is totally unimodular.\nWe also present some families for which $\\eta_t(D)$ can be computed in\npolynomial time. Finally, we prove that this problem is \\np-Hard even when its\ninput is restricted to planar bipartite digraphs.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 18:41:31 GMT"}, {"version": "v2", "created": "Tue, 29 Apr 2014 20:21:43 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Marenco", "Javier", ""], ["Mydlarz", "Marcelo", ""], ["Severin", "Daniel", ""]]}, {"id": "1310.4588", "submitter": "Michael Brand", "authors": "Michael Brand", "title": "Arbitrary Sequence RAMs", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that in some cases a Random Access Machine (RAM) benefits from\nhaving an additional input that is an arbitrary number, satisfying only the\ncriterion of being sufficiently large. This is known as the ARAM model. We\nintroduce a new type of RAM, which we refer to as the Arbitrary Sequence RAM\n(ASRAM), that generalises the ARAM by allowing the generation of additional\narbitrary large numbers at will during execution time. We characterise the\npower contribution of this ability under several RAM variants.\n  In particular, we demonstrate that an arithmetic ASRAM is more powerful than\nan arithmetic ARAM, that a sufficiently equipped ASRAM can recognise any\nlanguage in the arithmetic hierarchy in constant time (and more, if it is given\nmore time), and that, on the other hand, in some cases the ASRAM is no more\npowerful than its underlying RAM.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 06:21:39 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Brand", "Michael", ""]]}, {"id": "1310.4656", "submitter": "Atsushi Miyauchi", "authors": "Atsushi Miyauchi and Noriyoshi Sukegawa", "title": "Maximizing Barber's bipartite modularity is also hard", "comments": "18 pages, 1 figure", "journal-ref": "Optimization Letters 9, 897-913 (2015)", "doi": "10.1007/s11590-014-0818-7", "report-no": null, "categories": "cs.SI cs.CC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modularity introduced by Newman and Girvan [Phys. Rev. E 69, 026113 (2004)]\nis a quality function for community detection. Numerous methods for modularity\nmaximization have been developed so far. In 2007, Barber [Phys. Rev. E 76,\n066102 (2007)] introduced a variant of modularity called bipartite modularity\nwhich is appropriate for bipartite networks. Although maximizing the standard\nmodularity is known to be NP-hard, the computational complexity of maximizing\nbipartite modularity has yet to be revealed. In this study, we prove that\nmaximizing bipartite modularity is also NP-hard. More specifically, we show the\nNP-completeness of its decision version by constructing a reduction from a\nclassical partitioning problem.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 11:12:47 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Miyauchi", "Atsushi", ""], ["Sukegawa", "Noriyoshi", ""]]}, {"id": "1310.5037", "submitter": "Riccardo Dondi", "authors": "Niko Beerenwinkel, Stefano Beretta, Paola Bonizzoni, Riccardo Dondi,\n  Yuri Pirola", "title": "Covering Pairs in Directed Acyclic Graphs", "comments": null, "journal-ref": "Proc. of Language and Automata Theory and Applications (LATA\n  2014), LNCS Vol. 8370, 2014, pp 126-137", "doi": "10.1007/978-3-319-04921-2_10", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Minimum Path Cover problem on directed acyclic graphs (DAGs) is a\nclassical problem that provides a clear and simple mathematical formulation for\nseveral applications in different areas and that has an efficient algorithmic\nsolution. In this paper, we study the computational complexity of two\nconstrained variants of Minimum Path Cover motivated by the recent introduction\nof next-generation sequencing technologies in bioinformatics. The first problem\n(MinPCRP), given a DAG and a set of pairs of vertices, asks for a minimum\ncardinality set of paths \"covering\" all the vertices such that both vertices of\neach pair belong to the same path. For this problem, we show that, while it is\nNP-hard to compute if there exists a solution consisting of at most three\npaths, it is possible to decide in polynomial time whether a solution\nconsisting of at most two paths exists. The second problem (MaxRPSP), given a\nDAG and a set of pairs of vertices, asks for a path containing the maximum\nnumber of the given pairs of vertices. We show its NP-hardness and also its\nW[1]-hardness when parametrized by the number of covered pairs. On the positive\nside, we give a fixed-parameter algorithm when the parameter is the maximum\noverlapping degree, a natural parameter in the bioinformatics applications of\nthe problem.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 14:33:06 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Beerenwinkel", "Niko", ""], ["Beretta", "Stefano", ""], ["Bonizzoni", "Paola", ""], ["Dondi", "Riccardo", ""], ["Pirola", "Yuri", ""]]}, {"id": "1310.5246", "submitter": "Andrey Nikolaev", "authors": "Alexei Myasnikov, Andrey Nikolaev, Alexander Ushakov", "title": "The Post correspondence problem in groups", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the classical Post correspondence problem ($\\mathbf{PCP}_n$)\nand its non-homogeneous variation ($\\mathbf{GPCP}_n$) to non-commutative groups\nand study the computational complexity of these new problems. We observe that\n$\\mathbf{PCP}_n$ is closely related to the equalizer problem in groups, while\n$\\mathbf{GPCP}_n$ is connected to the double twisted conjugacy problem for\nendomorphisms. Furthermore, it is shown that one of the strongest forms of the\nword problem in a group $G$ (we call it the {\\em hereditary word problem}) can\nbe reduced to $\\mathbf{GPCP}_n$ in $G$ in polynomial time.\n  The main results are that $\\mathbf{PCP}_n$ is decidable in a finitely\ngenerated nilpotent group in polynomial time, while $\\mathbf{GPCP}_n$ is\nundecidable in any group containing free non-abelian subgroup (though the\nargument is very different from the classical case of free semigroups). We show\nthat the double endomorphism twisted conjugacy problem is undecidable in free\ngroups of sufficiently large finite rank. We also consider the bounded\n$\\mathbf{PCP}$ and observe that it is in $\\mathbf{NP}$ for any group with\n$\\mathbf{P}$-time decidable word problem, meanwhile it is $\\mathbf{NP}$-hard in\nany group containing free non-abelian subgroup. In particular, the bounded\n$\\mathbf{PCP}$ is $\\mathbf{NP}$-complete in non-elementary hyperbolic groups\nand non-abelian right angle Artin groups.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2013 16:47:48 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2013 00:15:26 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Myasnikov", "Alexei", ""], ["Nikolaev", "Andrey", ""], ["Ushakov", "Alexander", ""]]}, {"id": "1310.5363", "submitter": "Apoloniusz Tyszka", "authors": "Apoloniusz Tyszka", "title": "MuPAD codes which implement limit-computable functions that cannot be\n  bounded by any computable function", "comments": "16 pages, Theorem 1 strengthened", "journal-ref": "Annals of Computer Science and Information Systems, vol. 2, pp.\n  623-629 (2014)", "doi": "10.15439/2014F91", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a positive integer n, let f(n) denote the smallest non-negative integer b\nsuch that for each system S \\subseteq {x_k=1,x_i+x_j=x_k,x_i*x_j=x_k: i,j,k \\in\n{1,...,n}} with a solution in non-negative integers x_1,...,x_n, there exists a\nsolution of S in {0,...,b}^n. We prove that the function f is strictly\nincreasing and dominates all computable functions. We present an infinite loop\nin MuPAD which takes as input a positive integer n and returns a non-negative\ninteger on each iteration. Let g(n,m) denote the number returned on the m-th\niteration, if n is taken as input. Then, g(n,m) \\leq m-1, 0=g(n,1)<1=g(n,2)\n\\leq g(n,3) \\leq g(n,4) \\leq ... and\ng(n,f(n))<f(n)=g(n,f(n)+1)=g(n,f(n)+2)=g(n,f(n)+3)=....\n  A MuPAD code constructed on another principle contains a repeat-until loop\nand implements a limit-computable function \\xi: N-->N that cannot be bounded by\nany computable function. This code takes as input a non-negative integer n,\nimmediately returns 0, and computes a system S of polynomial equations. If the\nloop terminates for S, then the next instruction is executed and returns\n\\xi(n).\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2013 19:33:20 GMT"}, {"version": "v10", "created": "Wed, 19 Feb 2014 23:34:43 GMT"}, {"version": "v11", "created": "Mon, 24 Feb 2014 02:37:35 GMT"}, {"version": "v12", "created": "Tue, 11 Mar 2014 02:12:02 GMT"}, {"version": "v13", "created": "Sat, 22 Mar 2014 07:31:51 GMT"}, {"version": "v14", "created": "Wed, 26 Mar 2014 02:48:27 GMT"}, {"version": "v15", "created": "Mon, 7 Apr 2014 00:58:28 GMT"}, {"version": "v16", "created": "Tue, 15 Apr 2014 00:18:37 GMT"}, {"version": "v17", "created": "Wed, 21 May 2014 13:23:58 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2013 01:07:32 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2013 22:37:00 GMT"}, {"version": "v4", "created": "Sun, 8 Dec 2013 19:37:24 GMT"}, {"version": "v5", "created": "Thu, 12 Dec 2013 00:29:48 GMT"}, {"version": "v6", "created": "Fri, 10 Jan 2014 01:56:15 GMT"}, {"version": "v7", "created": "Mon, 20 Jan 2014 02:30:24 GMT"}, {"version": "v8", "created": "Tue, 28 Jan 2014 03:00:39 GMT"}, {"version": "v9", "created": "Thu, 13 Feb 2014 20:31:19 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Tyszka", "Apoloniusz", ""]]}, {"id": "1310.5372", "submitter": "Or Sattath", "authors": "Or Sattath", "title": "An Almost Sudden Jump in Quantum Complexity", "comments": null, "journal-ref": "Quantum Information & Computation 15(11&12): 1048-1059 (2015)", "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quantum Satisfiability problem (QSAT) is the generalization of the\ncanonical NP-complete problem - Boolean Satisfiability. (k,s)-QSAT is the\nfollowing variant of the problem: given a set of projectors of rank 1, acting\nnon-trivially on k qubits out of n qubits, such that each qubit appears in at\nmost s projectors, decide whether there exists a quantum state in the null\nspace of all the projectors. Let f*(k) be the maximal integer s such that every\n(k,s)-QSAT instance is satisfiable. Deciding (k,f*(k))-QSAT is computationally\neasy: by definition the answer is \"satisfiable\". But, by relaxing the\nconditions slightly, we show that (k,f*(k)+2)-QSAT is QMA_1-hard, for k >=15.\nThis is a quantum analogue of a classical result by Kratochv\\'il et al.\n[KST93]. We use the term \"an almost sudden jump\" to stress that the complexity\nof (k,f*(k)+1)-QSAT is open, where the jump in the classical complexity is\nknown to be sudden.\n  We present an implication of this finding to the quantum PCP conjecture,\narguably one of the most important open problems in the field of Hamiltonian\ncomplexity. Our implications impose constraints on one possible way to refute\nthe quantum PCP.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2013 20:55:08 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Sattath", "Or", ""]]}, {"id": "1310.5541", "submitter": "\\\"Omer Demirel", "authors": "\\\"Omer Demirel, Ihor Smal, Wiro J. Niessen, Erik Meijering, Ivo F.\n  Sbalzarini", "title": "Piecewise Constant Sequential Importance Sampling for Fast Particle\n  Filtering", "comments": "8 pages; will appear in the proceedings of the IET Data Fusion &\n  Target Tracking Conference 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle filters are key algorithms for object tracking under non-linear,\nnon-Gaussian dynamics. The high computational cost of particle filters,\nhowever, hampers their applicability in cases where the likelihood model is\ncostly to evaluate, or where large numbers of particles are required to\nrepresent the posterior. We introduce the approximate sequential importance\nsampling/resampling (ASIR) algorithm, which aims at reducing the cost of\ntraditional particle filters by approximating the likelihood with a mixture of\nuniform distributions over pre-defined cells or bins. The particles in each bin\nare represented by a dummy particle at the center of mass of the original\nparticle distribution and with a state vector that is the average of the states\nof all particles in the same bin. The likelihood is only evaluated for the\ndummy particles, and the resulting weight is identically assigned to all\nparticles in the bin. We derive upper bounds on the approximation error of the\nso-obtained piecewise constant function representation, and analyze how bin\nsize affects tracking accuracy and runtime. Further, we show numerically that\nthe ASIR approximation error converges to that of sequential importance\nsampling/resampling (SIR) as the bin size is decreased. We present a set of\nnumerical experiments from the field of biological image processing and\ntracking that demonstrate ASIR's capabilities. Overall, we consider ASIR a\npromising candidate for simple, fast particle filtering in generic\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 13:42:47 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2013 09:53:30 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2014 11:28:24 GMT"}], "update_date": "2014-04-07", "authors_parsed": [["Demirel", "\u00d6mer", ""], ["Smal", "Ihor", ""], ["Niessen", "Wiro J.", ""], ["Meijering", "Erik", ""], ["Sbalzarini", "Ivo F.", ""]]}, {"id": "1310.5576", "submitter": "Edouard Bonnet", "authors": "Edouard Bonnet and Vangelis Th. Paschos", "title": "Parameterized (in)approximability of subset problems", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss approximability and inapproximability in FPT-time for a large\nclass of subset problems where a feasible solution $S$ is a subset of the input\ndata and the value of $S$ is $|S|$. The class handled encompasses many\nwell-known graph, set, or satisfiability problems such as Dominating Set,\nVertex Cover, Set Cover, Independent Set, Feedback Vertex Set, etc. In a first\ntime, we introduce the notion of intersective approximability that generalizes\nthe one of safe approximability and show strong parameterized inapproximability\nresults for many of the subset problems handled. Then, we study approximability\nof these problems with respect to the dual parameter $n-k$ where $n$ is the\nsize of the instance and $k$ the standard parameter. More precisely, we show\nthat under such a parameterization, many of these problems, while\nW[$\\cdot$]-hard, admit parameterized approximation schemata.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 14:46:23 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Bonnet", "Edouard", ""], ["Paschos", "Vangelis Th.", ""]]}, {"id": "1310.5664", "submitter": "Dorit Aharonov", "authors": "Dorit Aharonov and Lior Eldar", "title": "Quantum Locally Testable Codes", "comments": "Some of the results presented here appeared in an initial form in our\n  quant-ph submission arXiv:1301.3407. This is a much extended and improved\n  version. 30 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of quantum Locally Testable Codes (qLTCs). We provide a\ndefinition together with a simplification, denoted sLTCs, for the special case\nof stabilizer codes, together with some basic results using those definitions.\nThe most crucial parameter of such codes is their soundness, $R(\\delta)$,\nnamely, the probability that a randomly chosen constraint is violated as a\nfunction of the distance of a word from the code ($\\delta$, the relative\ndistance from the code, is called the proximity). We then proceed to study\nlimitations on qLTCs. In our first main result we prove a surprising,\ninherently quantum, property of sLTCs: for small values of proximity, the\nbetter the small-set expansion of the interaction graph of the constraints, the\nless sound the qLTC becomes. This phenomenon, which can be attributed to\nmonogamy of entanglement, stands in sharp contrast to the classical setting.\nThe complementary, more intuitive, result also holds: an upper bound on the\nsoundness when the code is defined on poor small-set expanders (a bound which\nturns out to be far more difficult to show in the quantum case). Together we\narrive at a quantum upper-bound on the soundness of stabilizer qLTCs set on any\ngraph, which does not hold in the classical case. Many open questions are\nraised regarding what possible parameters are achievable for qLTCs. In the\nappendix we also define a quantum analogue of PCPs of proximity (PCPPs) and\npoint out that the result of Ben-Sasson et. al. by which PCPPs imply LTCs with\nrelated parameters, carries over to the sLTCs. This creates a first link\nbetween qLTCs and quantum PCPs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 18:27:01 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Aharonov", "Dorit", ""], ["Eldar", "Lior", ""]]}, {"id": "1310.5714", "submitter": "Massimo Lauria", "authors": "Massimo Lauria", "title": "Short $\\mathsf{Res}^*(\\mathsf{polylog})$ refutations if and only if\n  narrow $\\mathsf{Res}$ refutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we show that any $k$-CNF which can be refuted by a\nquasi-polynomial $\\mathsf{Res}^*(\\mathsf{polylog})$ refutation has a \"narrow\"\nrefutation in $\\mathsf{Res}$ (i.e., of poly-logarithmic width). We also show\nthe converse implication: a narrow Resolution refutation can be simulated by a\nshort $\\mathsf{Res}^*(\\mathsf{polylog})$ refutation.\n  The author does not claim priority on this result. The technical part of this\nnote bears similarity with the relation between $d$-depth Frege refutations and\ntree-like $d+1$-depth Frege refutations outlined in (Kraj\\'i\\v{c}ek 1994,\nJournal of Symbolic Logic 59, 73). Part of it had already been specialized to\n$\\mathsf{Res}$ and $\\mathsf{Res}(k)$ in (Esteban et al. 2004, Theor. Comput.\nSci. 321, 347).\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 20:03:40 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Lauria", "Massimo", ""]]}, {"id": "1310.5746", "submitter": "Oliver Kullmann", "authors": "Matthew Gwynne and Oliver Kullmann", "title": "Trading inference effort versus size in CNF Knowledge Compilation", "comments": "43 pages, second version with literature updates. Proceeds with the\n  separation results from the discontinued arXiv:1302.4421", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Compilation (KC) studies compilation of boolean functions f into\nsome formalism F, which allows to answer all queries of a certain kind in\npolynomial time. Due to its relevance for SAT solving, we concentrate on the\nquery type \"clausal entailment\" (CE), i.e., whether a clause C follows from f\nor not, and we consider subclasses of CNF, i.e., clause-sets F with special\nproperties. In this report we do not allow auxiliary variables (except of the\nOutlook), and thus F needs to be equivalent to f.\n  We consider the hierarchies UC_k <= WC_k, which were introduced by the\nauthors in 2012. Each level allows CE queries. The first two levels are\nwell-known classes for KC. Namely UC_0 = WC_0 is the same as PI as studied in\nKC, that is, f is represented by the set of all prime implicates, while UC_1 =\nWC_1 is the same as UC, the class of unit-refutation complete clause-sets\nintroduced by del Val 1994. We show that for each k there are (sequences of)\nboolean functions with polysize representations in UC_{k+1}, but with an\nexponential lower bound on representations in WC_k. Such a separation was\npreviously only know for k=0. We also consider PC < UC, the class of\npropagation-complete clause-sets. We show that there are (sequences of) boolean\nfunctions with polysize representations in UC, while there is an exponential\nlower bound for representations in PC. These separations are steps towards a\ngeneral conjecture determining the representation power of the hierarchies PC_k\n< UC_k <= WC_k. The strong form of this conjecture also allows auxiliary\nvariables, as discussed in depth in the Outlook.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 22:20:02 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2013 04:56:02 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Gwynne", "Matthew", ""], ["Kullmann", "Oliver", ""]]}, {"id": "1310.6008", "submitter": "Maximilien Gadouleau", "authors": "Peter J. Cameron, Ben Fairbairn and Maximilien Gadouleau", "title": "Computing in permutation groups without memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memoryless computation is a new technique to compute any function of a set of\nregisters by updating one register at a time while using no memory. Its aim is\nto emulate how computations are performed in modern cores, since they typically\ninvolve updates of single registers. The memoryless computation model can be\nfully expressed in terms of transformation semigroups, or in the case of\nbijective functions, permutation groups. In this paper, we consider how\nefficiently permutations can be computed without memory. We determine the\nminimum number of basic updates required to compute any permutation, or any\neven permutation. The small number of required instructions shows that very\nsmall instruction sets could be encoded on cores to perform memoryless\ncomputation. We then start looking at a possible compromise between the size of\nthe instruction set and the length of the resulting programs. We consider\nupdates only involving a limited number of registers. In particular, we show\nthat binary instructions are not enough to compute all permutations without\nmemory when the alphabet size is even. These results, though expressed as\nproperties of special generating sets of the symmetric or alternating groups,\nprovide guidelines on the implementation of memoryless computation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 18:45:19 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Cameron", "Peter J.", ""], ["Fairbairn", "Ben", ""], ["Gadouleau", "Maximilien", ""]]}, {"id": "1310.6009", "submitter": "Maximilien Gadouleau", "authors": "Peter J. Cameron, Ben Fairbairn and Maximilien Gadouleau", "title": "Computing in matrix groups without memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memoryless computation is a novel means of computing any function of a set of\nregisters by updating one register at a time while using no memory. We aim to\nemulate how computations are performed on modern cores, since they typically\ninvolve updates of single registers. The computation model of memoryless\ncomputation can be fully expressed in terms of transformation semigroups, or in\nthe case of bijective functions, permutation groups. In this paper, we view\nregisters as elements of a finite field and we compute linear permutations\nwithout memory. We first determine the maximum complexity of a linear function\nwhen only linear instructions are allowed. We also determine which linear\nfunctions are hardest to compute when the field in question is the binary field\nand the number of registers is even. Secondly, we investigate some matrix\ngroups, thus showing that the special linear group is internally computable but\nnot fast. Thirdly, we determine the smallest set of instructions required to\ngenerate the special and general linear groups. These results are important for\nmemoryless computation, for they show that linear functions can be computed\nvery fast or that very few instructions are needed to compute any linear\nfunction. They thus indicate new advantages of using memoryless computation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 18:47:12 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Cameron", "Peter J.", ""], ["Fairbairn", "Ben", ""], ["Gadouleau", "Maximilien", ""]]}, {"id": "1310.6383", "submitter": "Jack H. Lutz", "authors": "Jack H. Lutz", "title": "The Frequent Paucity of Trivial Strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A 1976 theorem of Chaitin can be used to show that arbitrarily dense sets of\nlengths n have a paucity of trivial strings (only a bounded number of strings\nof length n having trivially low plain Kolmogorov complexities). We use the\nprobabilistic method to give a new proof of this fact. This proof is much\nsimpler than previously published proofs, and it gives a tighter paucity bound.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2013 20:33:14 GMT"}, {"version": "v2", "created": "Wed, 7 May 2014 02:36:42 GMT"}], "update_date": "2014-05-08", "authors_parsed": [["Lutz", "Jack H.", ""]]}, {"id": "1310.6398", "submitter": "Holger Petersen", "authors": "Holger Petersen", "title": "Some Remarks on Lower Bounds for Queue Machines (Preliminary Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first give an improved lower bound for the deterministic online simulation\nof tapes or pushdown stores by queues. Then we inspect some proofs in a\nclassical work on queue machines in the area of Formal Languages and outline\nwhy a main argument in the proofs is incomplete. Based on descriptional\ncomplexity, we show the intuition behind the argument to be correct.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2013 21:27:04 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2013 04:42:09 GMT"}, {"version": "v3", "created": "Fri, 4 Apr 2014 05:02:59 GMT"}, {"version": "v4", "created": "Tue, 6 Mar 2018 22:37:10 GMT"}, {"version": "v5", "created": "Sun, 11 Mar 2018 13:32:46 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Petersen", "Holger", ""]]}, {"id": "1310.6524", "submitter": "Kitty Meeks", "authors": "Mark Jerrum and Kitty Meeks", "title": "Some hard families of parameterised counting problems", "comments": "A few more minor changes. This version to appear in the ACM\n  Transactions on Computation Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider parameterised subgraph-counting problems of the following form:\ngiven a graph G, how many k-tuples of its vertices have a given property? A\nnumber of such problems are known to be #W[1]-complete; here we substantially\ngeneralise some of these existing results by proving hardness for two large\nfamilies of such problems. We demonstrate that it is #W[1]-hard to count the\nnumber of k-vertex subgraphs having any property where the number of distinct\nedge-densities of labelled subgraphs that satisfy the property is o(k^2). In\nthe special case that the property in question depends only on the number of\nedges in the subgraph, we give a strengthening of this result which leads to\nour second family of hard problems.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 08:20:01 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2014 16:22:34 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2014 09:22:47 GMT"}, {"version": "v4", "created": "Thu, 14 Aug 2014 08:51:34 GMT"}, {"version": "v5", "created": "Thu, 25 Sep 2014 09:42:38 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Jerrum", "Mark", ""], ["Meeks", "Kitty", ""]]}, {"id": "1310.6718", "submitter": "Adam Bouland", "authors": "Adam Bouland, Scott Aaronson", "title": "Generation of Universal Linear Optics by Any Beamsplitter", "comments": "14 pages; edited Lemma 3.3 and updated references. Results are\n  unchanged", "journal-ref": "Phys. Rev. A 89, 062316 (2014)", "doi": "10.1103/PhysRevA.89.062316", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1994, Reck et al. showed how to realize any unitary transformation on a\nsingle photon using a product of beamsplitters and phaseshifters. Here we show\nthat any single beamsplitter that nontrivially mixes two modes, also densely\ngenerates the set of unitary transformations (or orthogonal transformations, in\nthe real case) on the single-photon subspace with m>=3 modes. (We prove the\nsame result for any two-mode real optical gate, and for any two-mode optical\ngate combined with a generic phaseshifter.) Experimentally, this means that one\ndoes not need tunable beamsplitters or phaseshifters for universality: any\nnontrivial beamsplitter is universal for linear optics. Theoretically, it means\nthat one cannot produce \"intermediate\" models of linear optical computation\n(analogous to the Clifford group for qubits) by restricting the allowed\nbeamsplitters and phaseshifters: there is a dichotomy; one either gets a\ntrivial set or else a universal set. No similar classification theorem for\ngates acting on qubits is currently known. We leave open the problem of\nclassifying optical gates that act on three or more modes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 19:33:26 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2013 03:11:43 GMT"}, {"version": "v3", "created": "Wed, 14 May 2014 21:54:23 GMT"}, {"version": "v4", "created": "Fri, 13 Jun 2014 19:06:43 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Bouland", "Adam", ""], ["Aaronson", "Scott", ""]]}, {"id": "1310.6749", "submitter": "Martin Schwarz", "authors": "Martin Schwarz, Maarten Van den Nest", "title": "Simulating Quantum Circuits with Sparse Output Distributions", "comments": "21 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that several quantum circuit families can be simulated efficiently\nclassically if it is promised that their output distribution is approximately\nsparse i.e. the distribution is close to one where only a polynomially small, a\npriori unknown subset of the measurement probabilities are nonzero. Classical\nsimulations are thereby obtained for quantum circuits which---without the\nadditional sparsity promise---are considered hard to simulate. Our results\napply in particular to a family of Fourier sampling circuits (which have\nstructural similarities to Shor's factoring algorithm) but also to several\nother circuit families, such as IQP circuits. Our results provide examples of\nquantum circuits that cannot achieve exponential speed-ups due to the presence\nof too much destructive interference i.e. too many cancelations of amplitudes.\nThe crux of our classical simulation is an efficient algorithm for\napproximating the significant Fourier coefficients of a class of states called\ncomputationally tractable states. The latter result may have applications\nbeyond the scope of this work. In the proof we employ and extend sparse\napproximation techniques, in particular the Kushilevitz-Mansour algorithm, in\ncombination with probabilistic simulation methods for quantum circuits.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 20:00:03 GMT"}], "update_date": "2013-10-28", "authors_parsed": [["Schwarz", "Martin", ""], ["Nest", "Maarten Van den", ""]]}, {"id": "1310.6976", "submitter": "Paul Vitanyi", "authors": "L. Antunes (University of Porto), A. Souto (Techical University of\n  Lissabon), and P.M.B. Vitanyi (CWI and the University of Amsterdam)", "title": "On Logical Depth and the Running Time of Shortest Programs", "comments": "12 pages LaTex (this supercedes arXiv:1301.4451)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logical depth with significance $b$ of a finite binary string $x$ is the\nshortest running time of a binary program for $x$ that can be compressed by at\nmost $b$ bits. There is another definition of logical depth. We give two\ntheorems about the quantitative relation between these versions: the first\ntheorem concerns a variation of a known fact with a new proof, the second\ntheorem and its proof are new. We select the above version of logical depth and\nshow the following. There is an infinite sequence of strings of increasing\nlength such that for each $j$ there is a $b$ such that the logical depth of the\n$j$th string as a function of $j$ is incomputable (it rises faster than any\ncomputable function) but with $b$ replaced by $b+1$ the resuling function is\ncomputable. Hence the maximal gap between the logical depths resulting from\nincrementing appropriate $b$'s by 1 rises faster than any computable function.\nAll functions mentioned are upper bounded by the Busy Beaver function. Since\nfor every string its logical depth is nonincreasing in $b$, the minimal\ncomputation time of the shortest programs for the sequence of strings as a\nfunction of $j$ rises faster than any computable function but not so fast as\nthe Busy Beaver function.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2013 16:50:06 GMT"}], "update_date": "2013-10-28", "authors_parsed": [["Antunes", "L.", "", "University of Porto"], ["Souto", "A.", "", "Techical University of\n  Lissabon"], ["Vitanyi", "P. M. B.", "", "CWI and the University of Amsterdam"]]}, {"id": "1310.7321", "submitter": "Troy Lee", "authors": "Aya Hamed and Troy Lee", "title": "Rank and fooling set size", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Say that A is a Hadamard factorization of the identity I_n of size n if the\nentrywise product of A and the transpose of A is I_n. It can be easily seen\nthat the rank of any Hadamard factorization of the identity must be at least\nsqrt{n}. Dietzfelbinger et al. raised the question if this bound can be\nachieved, and showed a boolean Hadamard factorization of the identity of rank\nn^{0.792}. More recently, Klauck and Wolf gave a construction of Hadamard\nfactorizations of the identity of rank n^{0.613}. Over finite fields, Friesen\nand Theis resolved the question, showing for a prime p and r=p^t+1 a Hadamard\nfactorization of the identity A of size r(r-1)+1 and rank r over F_p.\n  Here we resolve the question for fields of zero characteristic, up to a\nconstant factor, giving a construction of Hadamard factorizations of the\nidentity of rank r and size (r+1)r/2. The matrices in our construction are\nblockwise Toeplitz, and have entries whose magnitudes are binomial\ncoefficients.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2013 06:18:19 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Hamed", "Aya", ""], ["Lee", "Troy", ""]]}, {"id": "1310.7627", "submitter": "Oliver Kullmann", "authors": "Olaf Beyersdorff and Oliver Kullmann", "title": "Hardness measures and resolution lower bounds", "comments": "43 pages, preliminary version (yet the application part is only\n  sketched, with proofs missing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various \"hardness\" measures have been studied for resolution, providing\ntheoretical insight into the proof complexity of resolution and its fragments,\nas well as explanations for the hardness of instances in SAT solving. In this\nreport we aim at a unified view of a number of hardness measures, including\ndifferent measures of width, space and size of resolution proofs. We also\nextend these measures to all clause-sets (possibly satisfiable).\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2013 21:17:10 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2014 16:02:54 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Beyersdorff", "Olaf", ""], ["Kullmann", "Oliver", ""]]}, {"id": "1310.7903", "submitter": "Boaz Tsaban", "authors": "Matan Banin, Boaz Tsaban", "title": "A reduction of semigroup DLP to classic DLP", "comments": "Improved discussion of the nonperiodic case", "journal-ref": "Designs Codes and Cryptography 81 (2006), 75--82", "doi": "10.1007/s10623-015-0130-2", "report-no": null, "categories": "cs.CR cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a polynomial-time reduction of the discrete logarithm problem in\nany periodic (a.k.a. torsion) semigroup (SGDLP) to the same problem in a\nsubgroup of the same semigroup. It follows that SGDLP can be solved in\npolynomial time by quantum computers, and that SGDLP has subexponential\nalgorithms whenever the classic DLP in the corresponding groups has\nsubexponential algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 18:03:33 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2013 16:45:20 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2013 20:02:59 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2013 11:21:46 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Banin", "Matan", ""], ["Tsaban", "Boaz", ""]]}, {"id": "1310.7954", "submitter": "Abel Molina", "authors": "Srinivasan Arunachalam, Abel Molina, Vincent Russo", "title": "Quantum hedging in two-round prover-verifier interactions", "comments": "34 pages, 1 figure. Added work on connections with other results", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of a particular kind of quantum correlation that\narises in some two-party games. In these games, one player is presented with a\nquestion they must answer, yielding an outcome of either 'win' or 'lose'.\nMolina and Watrous (arXiv:1104.1140) studied such a game that exhibited a\nperfect form of hedging, where the risk of losing a first game can completely\noffset the corresponding risk for a second game. This is a non-classical\nquantum phenomenon, and establishes the impossibility of performing strong\nerror-reduction for quantum interactive proof systems by parallel repetition,\nunlike for classical interactive proof systems. We take a step in this article\ntowards a better understanding of the hedging phenomenon by giving a complete\ncharacterization of when perfect hedging is possible for a natural\ngeneralization of the game in arXiv:1104.1140. Exploring in a different\ndirection the subject of quantum hedging, and motivated by implementation\nconcerns regarding loss-tolerance, we also consider a variation of the protocol\nwhere the player who receives the question can choose to restart the game\nrather than return an answer. We show that in this setting there is no possible\nhedging for any game played with state spaces corresponding to\nfinite-dimensional complex Euclidean spaces.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 20:20:48 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2013 07:46:12 GMT"}, {"version": "v3", "created": "Wed, 5 Mar 2014 06:42:15 GMT"}, {"version": "v4", "created": "Mon, 26 Sep 2016 18:18:33 GMT"}, {"version": "v5", "created": "Sun, 12 Mar 2017 05:39:53 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Molina", "Abel", ""], ["Russo", "Vincent", ""]]}, {"id": "1310.8186", "submitter": "Oliver Schaudt", "authors": "Henning Bruhn and Oliver Schaudt", "title": "Claw-free t-perfect graphs can be recognised in polynomial time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is called t-perfect if its stable set polytope is defined by\nnon-negativity, edge and odd-cycle inequalities. We show that it can be decided\nin polynomial time whether a given claw-free graph is t-perfect.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2013 15:06:11 GMT"}], "update_date": "2013-10-31", "authors_parsed": [["Bruhn", "Henning", ""], ["Schaudt", "Oliver", ""]]}, {"id": "1310.8313", "submitter": "Maya Stein", "authors": "Flavia Bonomo, Oliver Schaudt, Maya Stein, Mario Valencia-Pabon", "title": "b-coloring is NP-hard on co-bipartite graphs and polytime solvable on\n  tree-cographs", "comments": null, "journal-ref": "Algorithmica 73(2), 2015, 59-69", "doi": "10.1007/s00453-014-9921-5", "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A b-coloring of a graph is a proper coloring such that every color class\ncontains a vertex that is adjacent to all other color classes. The b-chromatic\nnumber of a graph G, denoted by \\chi_b(G), is the maximum number t such that G\nadmits a b-coloring with t colors. A graph G is called b-continuous if it\nadmits a b-coloring with t colors, for every t = \\chi(G),\\ldots,\\chi_b(G), and\nb-monotonic if \\chi_b(H_1) \\geq \\chi_b(H_2) for every induced subgraph H_1 of\nG, and every induced subgraph H_2 of H_1.\n  We investigate the b-chromatic number of graphs with stability number two.\nThese are exactly the complements of triangle-free graphs, thus including all\ncomplements of bipartite graphs. The main results of this work are the\nfollowing:\n  - We characterize the b-colorings of a graph with stability number two in\nterms of matchings with no augmenting paths of length one or three. We derive\nthat graphs with stability number two are b-continuous and b-monotonic.\n  - We prove that it is NP-complete to decide whether the b-chromatic number of\nco-bipartite graph is at most a given threshold.\n  - We describe a polynomial time dynamic programming algorithm to compute the\nb-chromatic number of co-trees.\n  - Extending several previous results, we show that there is a polynomial time\ndynamic programming algorithm for computing the b-chromatic number of\ntree-cographs. Moreover, we show that tree-cographs are b-continuous and\nb-monotonic.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2013 20:23:02 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2014 15:38:45 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Bonomo", "Flavia", ""], ["Schaudt", "Oliver", ""], ["Stein", "Maya", ""], ["Valencia-Pabon", "Mario", ""]]}, {"id": "1310.8317", "submitter": "Ramyaa Ramyaa", "authors": "Martin Hofmann and Ramyaa Ramyaa", "title": "Power of Nondetreministic JAGs on Cayley graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Immerman-Szelepcsenyi Theorem uses an algorithm for co-st- connectivity\nbased on inductive counting to prove that NLOGSPACE is closed un- der\ncomplementation. We want to investigate whether counting is necessary for this\ntheorem to hold. Concretely, we show that Nondeterministic Jumping Graph\nAutmata (ND-JAGs) (pebble automata on graphs), on several families of Cayley\ngraphs, are equal in power to nondeterministic logspace Turing machines that\nare given such graphs as a linear encoding. In particular, it follows that\nND-JAGs can solve co-st-connectivity on those graphs. This came as a surprise\nsince Cook and Rackoff showed that deterministic JAGs cannot solve\nst-connectivity on many Cayley graphs due to their high self-similarity (every\nneighbourhood looks the same). Thus, our results show that on these graphs,\nnondeterminism provably adds computational power. The families of Cayley graphs\nwe consider include Cayley graphs of abelian groups and of all finite simple\ngroups irrespective of how they are presented and graphs corresponding to\ngroups generated by various product constructions, in- cluding iterated ones.\nWe remark that assessing the precise power of nondeterministic JAGs and in par-\nticular whether they can solve co-st-connectivity on arbitrary graphs is left\nas an open problem by Edmonds, Poon and Achlioptas. Our results suggest a\npositive answer to this question and in particular considerably limit the\nsearch space for a potential counterexample.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2013 20:44:03 GMT"}], "update_date": "2013-11-01", "authors_parsed": [["Hofmann", "Martin", ""], ["Ramyaa", "Ramyaa", ""]]}]