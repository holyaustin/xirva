[{"id": "1508.00094", "submitter": "Anatoly Plotnikov D.", "authors": "Anatoly D. Plotnikov", "title": "On a logical model of combinatorial problems", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": "10.4236/oalib.1101479", "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The paper proposes a logical model of combinatorial problems, also it gives\nan example of a problem of the class NP that can not be solved in polynomial\ntime on the dimension of the problem.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2015 07:38:22 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Plotnikov", "Anatoly D.", ""]]}, {"id": "1508.00395", "submitter": "Raja S", "authors": "V. Arvind, Pushkar S Joglekar, S. Raja", "title": "Noncommutative Valiant's Classes: Structure and Complete Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the noncommutative analogues, $\\mathrm{VP}_{nc}$ and\n$\\mathrm{VNP}_{nc}$, of Valiant's algebraic complexity classes and show some\nstriking connections to classical formal language theory. Our main results are\nthe following: (1) We show that Dyck polynomials (defined from the Dyck\nlanguages of formal language theory) are complete for the class\n$\\mathrm{VP}_{nc}$ under $\\le_{abp}$ reductions. Likewise, it turns out that\n$\\mathrm{PAL}$ (Palindrome polynomials defined from palindromes) are complete\nfor the class $\\mathrm{VSKEW}_{nc}$ (defined by polynomial-size skew circuits)\nunder $\\le_{abp}$ reductions. The proof of these results is by suitably\nadapting the classical Chomsky-Sch\\\"{u}tzenberger theorem showing that Dyck\nlanguages are the hardest CFLs. (2) Next, we consider the class\n$\\mathrm{VNP}_{nc}$. It is known~\\cite{HWY10a} that, assuming the\nsum-of-squares conjecture, the noncommutative polynomial\n$\\sum_{w\\in\\{x_0,x_1\\}^n}ww$ requires exponential size circuits. We\nunconditionally show that $\\sum_{w\\in\\{x_0,x_1\\}^n}ww$ is not\n$\\mathrm{VNP}_{nc}$-complete under the projection reducibility. As a\nconsequence, assuming the sum-of-squares conjecture, we exhibit a strictly\ninfinite hierarchy of p-families under projections inside $\\mathrm{VNP}_{nc}$\n(analogous to Ladner's theorem~\\cite{Ladner75}). In the final section we\ndiscuss some new $\\mathrm{VNP}_{nc}$-complete problems under\n$\\le_{abp}$-reductions. (3) Inside $\\mathrm{VP}_{nc}$ too we show there is a\nstrict hierarchy of p-families (based on the nesting depth of Dyck polynomials)\nunder the $\\le_{abp}$ reducibility.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2015 12:23:07 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Arvind", "V.", ""], ["Joglekar", "Pushkar S", ""], ["Raja", "S.", ""]]}, {"id": "1508.00510", "submitter": "Nicolas Schabanel", "authors": "Cody Geary, Pierre-\\'Etienne Meunier, Nicolas Schabanel, Shinnosuke\n  Seki", "title": "Proving the Turing Universality of Oritatami Co-Transcriptional Folding\n  (Full Text)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the oritatami model for molecular co-transcriptional folding. In\noritatami systems, the transcript (the \"molecule\") folds as it is synthesized\n(transcribed), according to a local energy optimisation process, which is\nsimilar to how actual biomolecules such as RNA fold into complex shapes and\nfunctions as they are transcribed. We prove that there is an oritatami system\nembedding universal computation in the folding process itself.\n  Our result relies on the development of a generic toolbox, which is easily\nreusable for future work to design complex functions in oritatami systems. We\ndevelop \"low-level\" tools that allow to easily spread apart the encoding of\ndifferent \"functions\" in the transcript, even if they are required to be\napplied at the same geometrical location in the folding. We build upon these\nlow-level tools, a programming framework with increasing levels of abstraction,\nfrom encoding of instructions into the transcript to logical analysis. This\nframework is similar to the hardware-to-algorithm levels of abstractions in\nstandard algorithm theory. These various levels of abstractions allow to\nseparate the proof of correctness of the global behavior of our system, from\nthe proof of correctness of its implementation. Thanks to this framework, we\nwere able to computerize the proof of correctness of its implementation and\nproduce certificates, in the form of a relatively small number of proof trees,\ncompact and easily readable and checkable by human, while encapsulating huge\ncase enumerations. We believe this particular type of certificates can be\ngeneralized to other discrete dynamical systems, where proofs involve large\ncase enumerations as well.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2015 18:24:41 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 11:43:39 GMT"}, {"version": "v3", "created": "Fri, 13 Jul 2018 16:10:22 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Geary", "Cody", ""], ["Meunier", "Pierre-\u00c9tienne", ""], ["Schabanel", "Nicolas", ""], ["Seki", "Shinnosuke", ""]]}, {"id": "1508.00603", "submitter": "Venkatesan Guruswami", "authors": "Venkatesan Guruswami, Lingfei Jin, Chaoping Xing", "title": "Efficiently list-decodable punctured Reed-Muller codes", "comments": "14 pages, To appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Reed-Muller (RM) code encoding $n$-variate degree-$d$ polynomials over\n${\\mathbb F}_q$ for $d < q$, with its evaluation on ${\\mathbb F}_q^n$, has\nrelative distance $1-d/q$ and can be list decoded from a $1-O(\\sqrt{d/q})$\nfraction of errors. In this work, for $d \\ll q$, we give a length-efficient\npuncturing of such codes which (almost) retains the distance and list\ndecodability properties of the Reed-Muller code, but has much better rate.\nSpecificially, when $q =\\Omega( d^2/\\epsilon^2)$, we given an explicit rate\n$\\Omega\\left(\\frac{\\epsilon}{d!}\\right)$ puncturing of Reed-Muller codes which\nhave relative distance at least $(1-\\epsilon)$ and efficient list decoding up\nto $(1-\\sqrt{\\epsilon})$ error fraction. This almost matches the performance of\nrandom puncturings which work with the weaker field size requirement $q=\n\\Omega( d/\\epsilon^2)$. We can also improve the field size requirement to the\noptimal (up to constant factors) $q =\\Omega( d/\\epsilon)$, at the expense of a\nworse list decoding radius of $1-\\epsilon^{1/3}$ and rate\n$\\Omega\\left(\\frac{\\epsilon^2}{d!}\\right)$.\n  The first of the above trade-offs is obtained by substituting for the\nvariables functions with carefully chosen pole orders from an algebraic\nfunction field; this leads to a puncturing for which the RM code is a subcode\nof a certain algebraic-geometric code (which is known to be efficiently list\ndecodable). The second trade-off is obtained by concatenating this construction\nwith a Reed-Solomon based multiplication friendly pair, and using the list\nrecovery property of algebraic-geometric codes.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2015 21:33:26 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2015 15:54:06 GMT"}, {"version": "v3", "created": "Sun, 2 Apr 2017 15:07:26 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Jin", "Lingfei", ""], ["Xing", "Chaoping", ""]]}, {"id": "1508.00690", "submitter": "G\\'abor Ivanyos", "authors": "G\\'abor Ivanyos, Youming Qiao, K. V. Subrahmanyam", "title": "Non-commutative Edmonds' problem and matrix semi-invariants", "comments": "24 pages; Significantly improved presentation; References to recent\n  developments added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.AC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1967, Edmonds introduced the problem of computing the rank over the\nrational function field of an $n\\times n$ matrix $T$ with integral homogeneous\nlinear polynomials. In this paper, we consider the non-commutative version of\nEdmonds' problem: compute the rank of $T$ over the free skew field. It is known\nthat this problem relates to the ring of matrix semi-invariants. In particular,\nif the nullcone of matrix semi-invariants is defined by elements of degree\n$\\leq \\sigma$, then there follows a $\\mathrm{poly}(n, \\sigma)$-time randomized\nalgorithm to decide whether the non-commutative rank of $T$ is $<n$. To our\nknowledge, previously the best bound for $\\sigma$ was $O(n^2\\cdot 4^{n^2})$\nover algebraically closed fields of characteristic $0$ (Derksen, 2001).\n  In this article we prove the following results:\n  (1) We observe that by using an algorithm of Gurvits, and assuming the above\nbound $\\sigma$ for $R(n, m)$ over $\\mathbb{Q}$, deciding whether $T$ has\nnon-commutative rank $<n$ over $\\mathbb{Q}$ can be done deterministically in\ntime polynomial in the input size and $\\sigma$.\n  (2) When $\\mathbb{F}$ is large enough, we devise a deterministic algorithm\nfor non-commutative Edmonds' problem in time polynomial in $(n+1)!$, with the\nfollowing consequences.\n  (2.a) If the commutative rank and the non-commutative rank of $T$ differ by a\nconstant, then there exists a randomized efficient algorithm that computes the\nnon-commutative rank of $T$.\n  (2.b) We prove that $\\sigma\\leq (n+1)!$. This not only improves the bound\nobtained from Derksen's work over algebraically closed field of characteristic\n$0$ but, more importantly, also provides for the first time an explicit bound\non $\\sigma$ for matrix semi-invariants over fields of positive characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2015 07:39:16 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2016 09:24:44 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Ivanyos", "G\u00e1bor", ""], ["Qiao", "Youming", ""], ["Subrahmanyam", "K. V.", ""]]}, {"id": "1508.01014", "submitter": "Du\\v{s}an Knop", "authors": "Du\\v{s}an Knop and Tom\\'a\\v{s} Masa\\v{r}\\'ik", "title": "Computational complexity of distance edge labeling", "comments": "21 pages, IWOCA 2015", "journal-ref": "Discrete Applied Mathematics 246 (2018) 80-98", "doi": "10.1016/j.dam.2017.01.007", "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Distance Edge Labeling is a variant of Distance Vertex\nLabeling (also known as $L_{2,1}$ labeling) that has been studied for more than\ntwenty years and has many applications, such as frequency assignment.\n  The Distance Edge Labeling problem asks whether the edges of a given graph\ncan be labeled such that the labels of adjacent edges differ by at least two\nand the labels of edges of distance two differ by at least one. Labels are\nchosen from the set $\\{0,1,\\dots,\\lambda\\}$ for $\\lambda$ fixed.\n  We present a full classification of its computational complexity - a\ndichotomy between the polynomially solvable cases and the remaining cases which\nare NP-complete. We characterise graphs with $\\lambda \\le 4$ which leads to a\npolynomial-time algorithm recognizing the class and we show NP-completeness for\n$\\lambda \\ge 5$ by several reductions from Monotone Not All Equal 3-SAT.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 09:27:49 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Knop", "Du\u0161an", ""], ["Masa\u0159\u00edk", "Tom\u00e1\u0161", ""]]}, {"id": "1508.01110", "submitter": "Vladimir Burichenko", "authors": "V.P. Burichenko", "title": "Symmetries of matrix multiplication algorithms. I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work the algorithms of fast multiplication of matrices are\nconsidered. To any algorithm there associated a certain group of automorphisms.\nThese automorphism groups are found for some well-known algorithms, including\nalgorithms of Hopcroft, Laderman, and Pan. The automorphism group is isomorphic\nto $S_3\\times Z_2$ and $S_4$ for Hopcroft anf Laderman algorithms,\nrespectively. The studying of symmetry of algorithms may be a fruitful idea for\nfinding fast algorithms, by an analogy with well-known optimization problems\nfor codes, lattices, and graphs.\n  {\\em Keywords}: Strassen algorithm, symmetry, fast matrix multiplication.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 15:45:58 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["Burichenko", "V. P.", ""]]}, {"id": "1508.01115", "submitter": "Xin Li", "authors": "Xin Li", "title": "Improved Constructions of Two-Source Extractors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent breakthrough \\cite{CZ15}, Chattopadhyay and Zuckerman gave an\nexplicit two-source extractor for min-entropy $k \\geq \\log^C n$ for some large\nenough constant $C$. However, their extractor only outputs one bit. In this\npaper, we improve the output of the two-source extractor to $k^{\\Omega(1)}$,\nwhile the error remains $n^{-\\Omega(1)}$.\n  Our improvement is obtained by giving a better extractor for $(q, t, \\gamma)$\nnon-oblivious bit-fixing sources, which can output $t^{\\Omega(1)}$ bits instead\nof one bit as in \\cite{CZ15}.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 16:09:06 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["Li", "Xin", ""]]}, {"id": "1508.01554", "submitter": "Youming Qiao", "authors": "G\\'abor Ivanyos, Youming Qiao, K. V. Subrahmanyam", "title": "On generating the ring of matrix semi-invariants", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a field $\\mathbb{F}$, let $R(n, m)$ be the ring of invariant polynomials\nfor the action of $\\mathrm{SL}(n, \\mathbb{F}) \\times \\mathrm{SL}(n,\n\\mathbb{F})$ on tuples of matrices -- $(A, C)\\in\\mathrm{SL}(n, \\mathbb{F})\n\\times \\mathrm{SL}(n, \\mathbb{F})$ sends $(B_1, \\dots, B_m)\\in M(n,\n\\mathbb{F})^{\\oplus m}$ to $(AB_1C^{-1}, \\dots, AB_mC^{-1})$. In this paper we\ncall $R(n, m)$ the \\emph{ring of matrix semi-invariants}. Let $\\beta(R(n, m))$\nbe the smallest $D$ s.t. matrix semi-invariants of degree $\\leq D$ generate\n$R(n, m)$. Guided by the Procesi-Razmyslov-Formanek approach of proving a\nstrong degree bound for generating matrix invariants, we exhibit several\ninteresting structural results for the ring of matrix semi-invariants $R(n, m)$\nover fields of characteristic $0$. Using these results, we prove that\n$\\beta(R(n, m))=\\Omega(n^{3/2})$, and $\\beta(R(2, m))\\leq 4$.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 22:20:57 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Ivanyos", "G\u00e1bor", ""], ["Qiao", "Youming", ""], ["Subrahmanyam", "K. V.", ""]]}, {"id": "1508.01586", "submitter": "Ramesh Krishnamurti", "authors": "Rajeev Kohli, Ramesh Krishnamurti", "title": "Lower Bound for the Unique Games Problem", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a randomized algorithm for the unique games problem, using\nindependent multinomial probabilities to assign labels to the vertices of a\ngraph. The expected value of the solution obtained by the algorithm is\nexpressed as a function of the probabilities. Finding probabilities that\nmaximize this expected value is shown to be equivalent to obtaining an optimal\nsolution to the unique games problem. We attain an upper bound on the optimal\nsolution value by solving a semidefinite programming relaxation of the problem\nin polynomial time. We use a different but related formulation to show that\nthis upper bound is no greater than {\\pi}/2 times the value of the optimal\nsolution to the unique games problem.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 02:02:27 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Kohli", "Rajeev", ""], ["Krishnamurti", "Ramesh", ""]]}, {"id": "1508.02071", "submitter": "Daniel Reichman", "authors": "Daniel Reichman and Igor Shinkar", "title": "On Percolation and $NP$-Hardness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the robustness of computational hardness of problems whose input\nis obtained by applying independent random deletions to worst-case instances.\nFor some classical $NP$-hard problems on graphs, such as Coloring,\nVertex-Cover, and Hamiltonicity, we examine the complexity of these problems\nwhen edges (or vertices) of an arbitrary graph are deleted independently with\nprobability $1-p > 0$. We prove that for $n$-vertex graphs, these problems\nremain as hard as in the worst-case, as long as $p > \\frac{1}{n^{1-\\epsilon}}$\nfor arbitrary $\\epsilon \\in (0,1)$, unless $NP \\subseteq BPP$.\n  We also prove hardness results for Constraint Satisfaction Problems, where\nrandom deletions are applied to clauses or variables, as well as the Subset-Sum\nproblem, where items of a given instance are deleted at random.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2015 19:03:15 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Reichman", "Daniel", ""], ["Shinkar", "Igor", ""]]}, {"id": "1508.02149", "submitter": "Murray Elder", "authors": "Laura Ciobanu and Volker Diekert and Murray Elder", "title": "Solution sets for equations over free groups are EDT0L languages", "comments": "38 pages, 3 figures. A conference version of this paper was presented\n  at ICALP 2015, Kyoto (Japan), July 4-10, 2015, see\n  http://arxiv.org/abs/1502.03426", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, given an equation over a finitely generated free group, the set\nof all solutions in reduced words forms an effectively constructible EDT0L\nlanguage. In particular, the set of all solutions in reduced words is an\nindexed language in the sense of Aho. The language characterization we give, as\nwell as further questions about the existence or finiteness of solutions,\nfollow from our explicit construction of a finite directed graph which encodes\nall the solutions. Our result incorporates the recently invented recompression\ntechnique of Je\\.z, and a new way to integrate solutions of linear Diophantine\nequations into the process.\n  As a byproduct of our techniques, we improve the complexity from quadratic\nnondeterministic space in previous works to $\\mathsf{NSPACE}(n\\log n)$ here.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 07:32:10 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 06:53:43 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Ciobanu", "Laura", ""], ["Diekert", "Volker", ""], ["Elder", "Murray", ""]]}, {"id": "1508.02158", "submitter": "Ning Xie", "authors": "Hing Yin Tsang, Ning Xie, Shengyu Zhang", "title": "Fourier Sparsity of GF(2) Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a conjecture called \"linear rank conjecture\" recently raised in\n(Tsang et al., FOCS'13), which asserts that if many linear constraints are\nrequired to lower the degree of a GF(2) polynomial, then the Fourier sparsity\n(i.e. number of non-zero Fourier coefficients) of the polynomial must be large.\nWe notice that the conjecture implies a surprising phenomenon that if the\nhighest degree monomials of a GF(2) polynomial satisfy a certain condition,\nthen the Fourier sparsity of the polynomial is large regardless of the\nmonomials of lower degrees -- whose number is generally much larger than that\nof the highest degree monomials. We develop a new technique for proving lower\nbound on the Fourier sparsity of GF(2) polynomials, and apply it to certain\nspecial classes of polynomials to showcase the above phenomenon.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 08:07:59 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Tsang", "Hing Yin", ""], ["Xie", "Ning", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1508.02344", "submitter": "Jiaming Xu", "authors": "Elchanan Mossel and Jiaming Xu", "title": "Local Algorithms for Block Models with Side Information", "comments": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract here is shorter than that in the PDF file", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent interest in understanding the power of local\nalgorithms for optimization and inference problems on sparse graphs. Gamarnik\nand Sudan (2014) showed that local algorithms are weaker than global algorithms\nfor finding large independent sets in sparse random regular graphs. Montanari\n(2015) showed that local algorithms are suboptimal for finding a community with\nhigh connectivity in the sparse Erd\\H{o}s-R\\'enyi random graphs. For the\nsymmetric planted partition problem (also named community detection for the\nblock models) on sparse graphs, a simple observation is that local algorithms\ncannot have non-trivial performance.\n  In this work we consider the effect of side information on local algorithms\nfor community detection under the binary symmetric stochastic block model. In\nthe block model with side information each of the $n$ vertices is labeled $+$\nor $-$ independently and uniformly at random; each pair of vertices is\nconnected independently with probability $a/n$ if both of them have the same\nlabel or $b/n$ otherwise. The goal is to estimate the underlying vertex\nlabeling given 1) the graph structure and 2) side information in the form of a\nvertex labeling positively correlated with the true one. Assuming that the\nratio between in and out degree $a/b$ is $\\Theta(1)$ and the average degree $\n(a+b) / 2 = n^{o(1)}$, we characterize three different regimes under which a\nlocal algorithm, namely, belief propagation run on the local neighborhoods,\nmaximizes the expected fraction of vertices labeled correctly. Thus, in\ncontrast to the case of symmetric block models without side information, we\nshow that local algorithms can achieve optimal performance for the block model\nwith side information.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 18:23:27 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Mossel", "Elchanan", ""], ["Xu", "Jiaming", ""]]}, {"id": "1508.02388", "submitter": "Andrey Nikolaev", "authors": "Alexei Myasnikov, Andrey Nikolaev, and Alexander Ushakov", "title": "Non-commutative lattice problems", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider several subgroup-related algorithmic questions in groups, modeled\nafter the classic computational lattice problems, and study their computational\ncomplexity. We find polynomial time solutions to problems like finding a\nsubgroup element closest to a given group element, or finding a shortest\nnon-trivial element of a subgroup in the case of nilpotent groups, and a large\nclass of surface groups and Coxeter groups. We also provide polynomial time\nalgorithm to compute geodesics in given generators of a subgroup of a free\ngroup.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 20:02:10 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Myasnikov", "Alexei", ""], ["Nikolaev", "Andrey", ""], ["Ushakov", "Alexander", ""]]}, {"id": "1508.02420", "submitter": "Parikshit Gopalan", "authors": "Parikshit Gopalan, Noam Nisan, Rocco A. Servedio, Kunal Talwar and Avi\n  Wigderson", "title": "Smooth Boolean functions are easy: efficient algorithms for\n  low-sensitivity functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural measure of smoothness of a Boolean function is its sensitivity (the\nlargest number of Hamming neighbors of a point which differ from it in function\nvalue). The structure of smooth or equivalently low-sensitivity functions is\nstill a mystery. A well-known conjecture states that every such Boolean\nfunction can be computed by a shallow decision tree. While this conjecture\nimplies that smooth functions are easy to compute in the simplest computational\nmodel, to date no non-trivial upper bounds were known for such functions in any\ncomputational model, including unrestricted Boolean circuits. Even a bound on\nthe description length of such functions better than the trivial $2^n$ does not\nseem to have been known.\n  In this work, we establish the first computational upper bounds on smooth\nBoolean functions:\n  1) We show that every sensitivity s function is uniquely specified by its\nvalues on a Hamming ball of radius 2s. We use this to show that such functions\ncan be computed by circuits of size $n^{O(s)}$.\n  2) We show that sensitivity s functions satisfy a strong pointwise\nnoise-stability guarantee for random noise of rate O(1/s). We use this to show\nthat these functions have formulas of depth O(s log n).\n  3) We show that sensitivity s functions can be (locally) self-corrected from\nworst-case noise of rate $\\exp(-O(s))$.\n  All our results are simple, and follow rather directly from (variants of) the\nbasic fact that that the function value at few points in small neighborhoods of\na given point determine its function value via a majority vote. Our results\nconfirm various consequences of the conjecture. They may be viewed as providing\na new form of evidence towards its validity, as well as new directions towards\nattacking it.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 20:48:07 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Gopalan", "Parikshit", ""], ["Nisan", "Noam", ""], ["Servedio", "Rocco A.", ""], ["Talwar", "Kunal", ""], ["Wigderson", "Avi", ""]]}, {"id": "1508.02773", "submitter": "Daniel Paulusma", "authors": "Konrad K. Dabrowski, Petr A. Golovach, Pim van 't Hof, Daniel\n  Paulusma, Dimitrios M. Thilikos", "title": "Editing to a Planar Graph of Given Degrees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following graph modification problem. Let the input consist\nof a graph $G=(V,E)$, a weight function $w\\colon V\\cup E\\rightarrow\n\\mathbb{N}$, a cost function $c\\colon V\\cup E\\rightarrow \\mathbb{N}$ and a\ndegree function $\\delta\\colon V\\rightarrow \\mathbb{N}_0$, together with three\nintegers $k_v, k_e$ and $C$. The question is whether we can delete a set of\nvertices of total weight at most $k_v$ and a set of edges of total weight at\nmost $k_e$ so that the total cost of the deleted elements is at most $C$ and\nevery non-deleted vertex $v$ has degree $\\delta(v)$ in the resulting graph\n$G'$. We also consider the variant in which $G'$ must be connected. Both\nproblems are known to be NP-complete and W[1]-hard when parameterized by\n$k_v+k_e$. We prove that, when restricted to planar graphs, they stay\nNP-complete but have polynomial kernels when parameterized by $k_v+k_e$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 23:30:20 GMT"}], "update_date": "2015-08-13", "authors_parsed": [["Dabrowski", "Konrad K.", ""], ["Golovach", "Petr A.", ""], ["Hof", "Pim van 't", ""], ["Paulusma", "Daniel", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "1508.03061", "submitter": "Igor Carboni Oliveira", "authors": "Xi Chen, Igor C. Oliveira, Rocco A. Servedio", "title": "Addition is exponentially harder than counting for shallow monotone\n  circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $U_{k,N}$ denote the Boolean function which takes as input $k$ strings of\n$N$ bits each, representing $k$ numbers $a^{(1)},\\dots,a^{(k)}$ in\n$\\{0,1,\\dots,2^{N}-1\\}$, and outputs 1 if and only if $a^{(1)} + \\cdots +\na^{(k)} \\geq 2^N.$ Let THR$_{t,n}$ denote a monotone unweighted threshold gate,\ni.e., the Boolean function which takes as input a single string $x \\in\n\\{0,1\\}^n$ and outputs $1$ if and only if $x_1 + \\cdots + x_n \\geq t$. We refer\nto circuits that are composed of THR gates as monotone majority circuits.\n  The main result of this paper is an exponential lower bound on the size of\nbounded-depth monotone majority circuits that compute $U_{k,N}$. More\nprecisely, we show that for any constant $d \\geq 2$, any depth-$d$ monotone\nmajority circuit computing $U_{d,N}$ must have size\n$\\smash{2^{\\Omega(N^{1/d})}}$. Since $U_{k,N}$ can be computed by a single\nmonotone weighted threshold gate (that uses exponentially large weights), our\nlower bound implies that constant-depth monotone majority circuits require\nexponential size to simulate monotone weighted threshold gates. This answers a\nquestion posed by Goldmann and Karpinski (STOC'93) and recently restated by\nHastad (2010, 2014). We also show that our lower bound is essentially best\npossible, by constructing a depth-$d$, size-$2^{O(N^{1/d})}$ monotone majority\ncircuit for $U_{d,N}$.\n  As a corollary of our lower bound, we significantly strengthen a classical\ntheorem in circuit complexity due to Ajtai and Gurevich (JACM'87). They\nexhibited a monotone function that is in AC$^0$ but requires super-polynomial\nsize for any constant-depth monotone circuit composed of unbounded fan-in AND\nand OR gates. We describe a monotone function that is in depth-$3$ AC$^0$ but\nrequires exponential size monotone circuits of any constant depth, even if the\ncircuits are composed of THR gates.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 20:37:17 GMT"}], "update_date": "2015-08-14", "authors_parsed": [["Chen", "Xi", ""], ["Oliveira", "Igor C.", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1508.03280", "submitter": "Matthew Colbrook", "authors": "Jonathan Ben-Artzi, Matthew J. Colbrook, Anders C. Hansen, Olavi\n  Nevanlinna and Markus Seidel", "title": "Computing Spectra -- On the Solvability Complexity Index Hierarchy and\n  Towers of Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.NA math-ph math.LO math.MP math.NA math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes some of the fundamental barriers in the theory of\ncomputations and finally settles the long-standing computational spectral\nproblem. That is to determine the existence of algorithms that can compute\nspectra $\\mathrm{sp}(A)$ of classes of bounded operators $A = \\{a_{ij}\\}_{i,j\n\\in \\mathbb{N}} \\in \\mathcal{B}(l^2(\\mathbb{N}))$, given the matrix elements\n$\\{a_{ij}\\}_{i,j \\in \\mathbb{N}}$, that are sharp in the sense that they\nachieve the boundary of what a digital computer can achieve. Similarly, for a\nSchr\\\"odinger operator $H = -\\Delta+V$, determine the existence of algorithms\nthat can compute the spectrum $\\mathrm{sp}(H)$ given point samples of the\npotential function $V$. In order to solve these problems, we establish the\nSolvability Complexity Index (SCI) hierarchy and provide a collection of new\nalgorithms that allow for problems that were previously out of reach. The SCI\nis the smallest number of limits needed in the computation, yielding a\nclassification hierarchy for all types of problems in computational mathematics\nthat determines the boundaries of what computers can achieve in scientific\ncomputing. In addition, the SCI hierarchy provides classifications of\ncomputational problems that can be used in computer-assisted proofs. The SCI\nhierarchy captures many key computational issues in the history of mathematics\nincluding the insolvability of the quintic, Smale's problem on the existence of\niterative generally convergent algorithm for polynomial root finding, the\ncomputational spectral problem, inverse problems, optimisation etc.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2015 17:42:14 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 12:32:16 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 12:39:36 GMT"}, {"version": "v4", "created": "Mon, 16 Dec 2019 08:30:26 GMT"}, {"version": "v5", "created": "Mon, 15 Jun 2020 17:50:03 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ben-Artzi", "Jonathan", ""], ["Colbrook", "Matthew J.", ""], ["Hansen", "Anders C.", ""], ["Nevanlinna", "Olavi", ""], ["Seidel", "Markus", ""]]}, {"id": "1508.04099", "submitter": "Alexander Yu. Vlasov", "authors": "Alexander Yu. Vlasov", "title": "Permanents, Bosons and Linear Optics", "comments": "v5: 12pt, 12 pages, abstract rewritten, introduction extended", "journal-ref": "Laser Phys. Lett. 14 103001 (2017)", "doi": "10.1088/1612-202X/aa7d90", "report-no": null, "categories": "quant-ph cs.CC math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particular complexity of linear quantum optical networks is deserved recently\ncertain attention due to possible implications for theory of quantum\ncomputation. Two relevant models of bosons are discussed in presented work.\nSymmetric product of Hilbert spaces produces rather abstract model. The second\none is obtained by quantization of harmonic oscillator. In contrast to\nconsidered bosonic processes, so-called \"fermionic linear optics\" is\neffectively simulated on classical computer. The comparison of bosonic and\nfermionic case clarifies the controversy and the more elaborated oscillator\nmodel provides a deeper analogy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 17:54:46 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2015 13:13:19 GMT"}, {"version": "v3", "created": "Thu, 9 Mar 2017 13:46:24 GMT"}, {"version": "v4", "created": "Tue, 21 Mar 2017 15:57:50 GMT"}, {"version": "v5", "created": "Mon, 24 Apr 2017 13:45:18 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Vlasov", "Alexander Yu.", ""]]}, {"id": "1508.04125", "submitter": "Donald Stull", "authors": "Adam Case, Jack H. Lutz, D. M. Stull", "title": "Reachability Problems for Continuous Chemical Reaction Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical reaction networks (CRNs) model the behavior of molecules in a\nwell-mixed system. The emerging field of molecular programming uses CRNs not\nonly as a descriptive tool, but as a programming language for chemical\ncomputation. Recently, Chen, Doty and Soloveichik introduced a new model of\nchemical kinetics, rate-independent continuous CRNs (CCRNs), to study the\nchemical computation of continuous functions. A fundamental question of a CRN\nis whether a state of the system is reachable through a sequence of reactions\nin the network. This is known as the reachability problem. In this paper, we\ninvestigate CCRN-REACH, the reachability problem for this model of chemical\nreaction networks. We show that, for continuous CRNs, constructing a path to a\nstate of the network is computable in polynomial time. We also prove that a\nrelated problem, Sub-CCRN-REACH, is NP-complete.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 19:43:50 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2015 16:47:30 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2015 02:03:24 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Case", "Adam", ""], ["Lutz", "Jack H.", ""], ["Stull", "D. M.", ""]]}, {"id": "1508.04522", "submitter": "Palash Dey", "authors": "Arnab Bhattacharyya and Palash Dey", "title": "Fishing out Winners from Vote Streams", "comments": "Adding Acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DM cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of winner determination from computational social\nchoice theory in the data stream model. Specifically, we consider the task of\nsummarizing an arbitrarily ordered stream of $n$ votes on $m$ candidates into a\nsmall space data structure so as to be able to obtain the winner determined by\npopular voting rules. As we show, finding the exact winner requires storing\nessentially all the votes. So, we focus on the problem of finding an {\\em\n$\\eps$-winner}, a candidate who could win by a change of at most $\\eps$\nfraction of the votes. We show non-trivial upper and lower bounds on the space\ncomplexity of $\\eps$-winner determination for several voting rules, including\n$k$-approval, $k$-veto, scoring rules, approval, maximin, Bucklin, Copeland,\nand plurality with run off.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 04:09:03 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2015 04:27:41 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Dey", "Palash", ""]]}, {"id": "1508.05013", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh", "title": "Message Passing and Combinatorial Optimization", "comments": "Ravanbakhsh, S. (2015), Message Passing and Combinatorial\n  Optimization, PhD thesis, University of Alberta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DS math.AC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models use the intuitive and well-studied methods of graph theory\nto implicitly represent dependencies between variables in large systems. They\ncan model the global behaviour of a complex system by specifying only local\nfactors. This thesis studies inference in discrete graphical models from an\nalgebraic perspective and the ways inference can be used to express and\napproximate NP-hard combinatorial problems.\n  We investigate the complexity and reducibility of various inference problems,\nin part by organizing them in an inference hierarchy. We then investigate\ntractable approximations for a subset of these problems using distributive law\nin the form of message passing. The quality of the resulting message passing\nprocedure, called Belief Propagation (BP), depends on the influence of loops in\nthe graphical model. We contribute to three classes of approximations that\nimprove BP for loopy graphs A) loop correction techniques; B) survey\npropagation, another message passing technique that surpasses BP in some\nsettings; and C) hybrid methods that interpolate between deterministic message\npassing and Markov Chain Monte Carlo inference.\n  We then review the existing message passing solutions and provide novel\ngraphical models and inference techniques for combinatorial problems under\nthree broad classes: A) constraint satisfaction problems such as\nsatisfiability, coloring, packing, set / clique-cover and dominating /\nindependent set and their optimization counterparts; B) clustering problems\nsuch as hierarchical clustering, K-median, K-clustering, K-center and\nmodularity optimization; C) problems over permutations including assignment,\ngraph morphisms and alignment, finding symmetries and traveling salesman\nproblem. In many cases we show that message passing is able to find solutions\nthat are either near optimal or favourably compare with today's\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 15:50:45 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Ravanbakhsh", "Siamak", ""]]}, {"id": "1508.05117", "submitter": "Federico Ricci-Tersenghi", "authors": "Raffaele Marino, Giorgio Parisi and Federico Ricci-Tersenghi", "title": "The backtracking survey propagation algorithm for solving random K-SAT\n  problems", "comments": "11 pages, 10 figures. v2: data largely improved and manuscript\n  rewritten", "journal-ref": "Nature Communications 7, 12996 (2016)", "doi": "10.1038/ncomms12996", "report-no": null, "categories": "cs.CC cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete combinatorial optimization has a central role in many scientific\ndisciplines, however, for hard problems we lack linear time algorithms that\nwould allow us to solve very large instances. Moreover, it is still unclear\nwhat are the key features that make a discrete combinatorial optimization\nproblem hard to solve. Here we study random K-satisfiability problems with\n$K=3,4$, which are known to be very hard close to the SAT-UNSAT threshold,\nwhere problems stop having solutions. We show that the backtracking survey\npropagation algorithm, in a time practically linear in the problem size, is\nable to find solutions very close to the threshold, in a region unreachable by\nany other algorithm. All solutions found have no frozen variables, thus\nsupporting the conjecture that only unfrozen solutions can be found in linear\ntime, and that a problem becomes impossible to solve in linear time when all\nsolutions contain frozen variables.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 20:41:29 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2015 17:00:45 GMT"}, {"version": "v3", "created": "Tue, 19 Apr 2016 22:26:58 GMT"}, {"version": "v4", "created": "Thu, 6 Oct 2016 07:37:19 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Marino", "Raffaele", ""], ["Parisi", "Giorgio", ""], ["Ricci-Tersenghi", "Federico", ""]]}, {"id": "1508.05189", "submitter": "Hartmut Klauck", "authors": "Ralph C. Bottesch, Dmitry Gavinsky, Hartmut Klauck", "title": "Correlation in Hard Distributions in Communication Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect that the amount of correlation in a bipartite\ndistribution has on the communication complexity of a problem under that\ndistribution. We introduce a new family of complexity measures that\ninterpolates between the two previously studied extreme cases: the (standard)\nrandomised communication complexity and the case of distributional complexity\nunder product distributions.\n  We give a tight characterisation of the randomised complexity of Disjointness\nunder distributions with mutual information $k$, showing that it is\n$\\Theta(\\sqrt{n(k+1)})$ for all $0\\leq k\\leq n$. This smoothly interpolates\nbetween the lower bounds of Babai, Frankl and Simon for the product\ndistribution case ($k=0$), and the bound of Razborov for the randomised case.\nThe upper bounds improve and generalise what was known for product\ndistributions, and imply that any tight bound for Disjointness needs\n$\\Omega(n)$ bits of mutual information in the corresponding distribution.\n  We study the same question in the distributional quantum setting, and show a\nlower bound of $\\Omega((n(k+1))^{1/4})$, and an upper bound, matching up to a\nlogarithmic factor.\n  We show that there are total Boolean functions $f_d$ on $2n$ inputs that have\ndistributional communication complexity $O(\\log n)$ under all distributions of\ninformation up to $o(n)$, while the (interactive) distributional complexity\nmaximised over all distributions is $\\Theta(\\log d)$ for $6n\\leq d\\leq\n2^{n/100}$.\n  We show that in the setting of one-way communication under product\ndistributions, the dependence of communication cost on the allowed error\n$\\epsilon$ is multiplicative in $\\log(1/\\epsilon)$ -- the previous upper bounds\nhad the dependence of more than $1/\\epsilon$.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 07:05:39 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Bottesch", "Ralph C.", ""], ["Gavinsky", "Dmitry", ""], ["Klauck", "Hartmut", ""]]}, {"id": "1508.05282", "submitter": "Marek Cygan", "authors": "Ivan Bliznets, Marek Cygan, Pawel Komosa, Lukas Mach, Michal Pilipczuk", "title": "Lower bounds for the parameterized complexity of Minimum Fill-in and\n  other completion problems", "comments": "Accepted to SODA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on several completion problems for subclasses of\nchordal graphs: Minimum Fill-In, Interval Completion, Proper Interval\nCompletion, Threshold Completion, and Trivially Perfect Completion. In these\nproblems, the task is to add at most k edges to a given graph in order to\nobtain a chordal, interval, proper interval, threshold, or trivially perfect\ngraph, respectively. We prove the following lower bounds for all these\nproblems, as well as for the related Chain Completion problem: Assuming the\nExponential Time Hypothesis, none of these problems can be solved in time\n2^O(n^(1/2) / log^c n) or 2^O(k^(1/4) / log^c k) n^O(1), for some integer c.\nAssuming the non-existence of a subexponential-time approximation scheme for\nMin Bisection on d-regular graphs, for some constant d, none of these problems\ncan be solved in time 2^o(n) or 2^o(sqrt(k)) n^O(1).\n  For all the aforementioned completion problems, apart from Proper Interval\nCompletion, FPT algorithms with running time of the form 2^O(sqrt(k) log k)\nn^O(1) are known. Thus, the second result proves that a significant improvement\nof any of these algorithms would lead to a surprising breakthrough in the\ndesign of approximation algorithms for Min Bisection.\n  To prove our results, we use a reduction methodology based on combining the\nclassic approach of starting with a sparse instance of 3-Sat, prepared using\nthe Sparsification Lemma, with the existence of almost linear-size\nProbabilistically Checkable Proofs (PCPs). Apart from our main results, we also\nobtain lower bounds excluding the existence of subexponential algorithms for\nthe Optimum Linear Arrangement problem, as well as improved, yet still not\ntight, lower bounds for Feedback Arc Set in Tournaments.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 14:29:21 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2015 09:09:34 GMT"}], "update_date": "2015-10-16", "authors_parsed": [["Bliznets", "Ivan", ""], ["Cygan", "Marek", ""], ["Komosa", "Pawel", ""], ["Mach", "Lukas", ""], ["Pilipczuk", "Michal", ""]]}, {"id": "1508.05372", "submitter": "Jonathan Schneider", "authors": "Mark Braverman, Cristobal Rojas, and Jon Schneider", "title": "Tight space-noise tradeoffs in computing the ergodic measure", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we obtain tight bounds on the space-complexity of computing the\nergodic measure of a low-dimensional discrete-time dynamical system affected by\nGaussian noise. If the scale of the noise is $\\varepsilon$, and the function\ndescribing the evolution of the system is not by itself a source of\ncomputational complexity, then the density function of the ergodic measure can\nbe approximated within precision $\\delta$ in space polynomial in $\\log\n1/\\varepsilon+\\log\\log 1/\\delta$. We also show that this bound is tight up to\npolynomial factors.\n  In the course of showing the above, we prove a result of independent interest\nin space-bounded computation: that it is possible to exponentiate an $n$ by $n$\nmatrix to an exponentially large power in space polylogarithmic in $n$.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 19:04:45 GMT"}], "update_date": "2015-08-24", "authors_parsed": [["Braverman", "Mark", ""], ["Rojas", "Cristobal", ""], ["Schneider", "Jon", ""]]}, {"id": "1508.05573", "submitter": "Jonathan Noel", "authors": "Richard C. Brewster and Sean McGuinness and Benjamin Moore and\n  Jonathan A. Noel", "title": "A Dichotomy Theorem for Circular Colouring Reconfiguration", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"reconfiguration problem\" for circular colourings asks, given two\n$(p,q)$-colourings $f$ and $g$ of a graph $G$, is it possible to transform $f$\ninto $g$ by changing the colour of one vertex at a time such that every\nintermediate mapping is a $(p,q)$-colouring? We show that this problem can be\nsolved in polynomial time for $2\\leq p/q <4$ and is PSPACE-complete for\n$p/q\\geq 4$. This generalizes a known dichotomy theorem for reconfiguring\nclassical graph colourings.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2015 07:51:45 GMT"}, {"version": "v2", "created": "Wed, 13 Apr 2016 12:43:19 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Brewster", "Richard C.", ""], ["McGuinness", "Sean", ""], ["Moore", "Benjamin", ""], ["Noel", "Jonathan A.", ""]]}, {"id": "1508.05737", "submitter": "Peter Schneider-Kamp", "authors": "Michael Codish and Lu\\'is Cruz-Filipe and Michael Frank and Peter\n  Schneider-Kamp", "title": "When Six Gates are Not Enough", "comments": "IMADA-preprint-cs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the pigeonhole principle to show that there must exist Boolean\nfunctions on 7 inputs with a multiplicative complexity of at least 7, i.e.,\nthat cannot be computed with only 6 multiplications in the Galois field with\ntwo elements.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2015 10:04:28 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Codish", "Michael", ""], ["Cruz-Filipe", "Lu\u00eds", ""], ["Frank", "Michael", ""], ["Schneider-Kamp", "Peter", ""]]}, {"id": "1508.05766", "submitter": "Ale\\v{s} Bizjak", "authors": "Alexandr Kazda", "title": "$n$-permutability and linear Datalog implies symmetric Datalog", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (April 25,\n  2018) lmcs:4464", "doi": "10.23638/LMCS-14(2:3)2018", "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that if $\\mathbb A$ is a core relational structure such that\nCSP($\\mathbb A$) can be solved by a linear Datalog program, and $\\mathbb A$ is\n$n$-permutable for some $n$, then CSP($\\mathbb A$) can be solved by a symmetric\nDatalog program (and thus CSP($\\mathbb A$) lies in deterministic logspace). At\nthe moment, it is not known for which structures $\\mathbb A$ will CSP($\\mathbb\nA$) be solvable by a linear Datalog program. However, once somebody obtains a\ncharacterization of linear Datalog, our result immediately gives a\ncharacterization of symmetric Datalog.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2015 11:53:46 GMT"}, {"version": "v2", "created": "Mon, 12 Sep 2016 21:26:31 GMT"}, {"version": "v3", "created": "Sun, 24 Sep 2017 22:16:24 GMT"}, {"version": "v4", "created": "Wed, 15 Nov 2017 22:47:40 GMT"}, {"version": "v5", "created": "Mon, 20 Nov 2017 22:47:43 GMT"}, {"version": "v6", "created": "Tue, 24 Apr 2018 07:37:47 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Kazda", "Alexandr", ""]]}, {"id": "1508.05788", "submitter": "Nicolas Ressayre", "authors": "Joseph M. Landsberg (TAMU), Nicolas Ressayre (ICJ)", "title": "Permanent v. determinant: an exponential lower bound assumingsymmetry\n  and a potential path towards Valiant's conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a study of determinantal representations with symmetry. We show\nthat Grenet's determinantal representation for the permanent is optimal among\ndeterminantal representations respecting left multiplication by permutation and\ndiagonal matrices (roughly half the symmetry group of the permanent). In\nparticular, if any optimal determinantal representation of the permanent must\nbe polynomially related to one with such symmetry, then Valiant's conjecture on\npermanent v. determinant is true.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2015 12:52:23 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2015 15:10:06 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Landsberg", "Joseph M.", "", "TAMU"], ["Ressayre", "Nicolas", "", "ICJ"]]}, {"id": "1508.05814", "submitter": "Tomoyuki Yamakami", "authors": "Tomoyuki Yamakami", "title": "Structural Complexity of Multi-Valued Partial Functions Computed by\n  Nondeterministic Pushdown Automata", "comments": "(Extended Abstract, A4, 10pt, 8 pages) This extended abstract has\n  already appeared in the Proceedings of the 15th Italian Conference of\n  Theoretical Computer Science (ICTCS 2014), September 17-19, Perugia, Italy,\n  CEUR Workshop Proceedings, vol.1231, pp.225-236, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper continues a systematic and comprehensive study on the structural\nproperties of CFL functions, which are in general multi-valued partial\nfunctions computed by one-way one-head nondeterministic pushdown automata\nequipped with write-only output tapes (or pushdown transducers), where CFL\nrefers to a relevance to context-free languages. The CFL functions tend to\nbehave quite differently from their corresponding context-free languages. We\nextensively discuss containments, separations, and refinements among various\nclasses of functions obtained from the CFL functions by applying Boolean\noperations, functional composition, many-one relativization, and Turing\nrelativization. In particular, Turing relativization helps construct a\nhierarchy over the class of CFL functions. We also analyze the computational\ncomplexity of optimization functions, which are to find optimal values of CFL\nfunctions, and discuss their relationships to the associated languages.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2015 14:13:49 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Yamakami", "Tomoyuki", ""]]}, {"id": "1508.06019", "submitter": "Jesper Nederlof", "authors": "Per Austrin, Mikko Koivisto, Petteri Kaski, Jesper Nederlof", "title": "Dense Subset Sum may be the hardest", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Subset Sum problem asks whether a given set of $n$ positive integers\ncontains a subset of elements that sum up to a given target $t$. It is an\noutstanding open question whether the $O^*(2^{n/2})$-time algorithm for Subset\nSum by Horowitz and Sahni [J. ACM 1974] can be beaten in the worst-case setting\nby a \"truly faster\", $O^*(2^{(0.5-\\delta)n})$-time algorithm, with some\nconstant $\\delta > 0$. Continuing an earlier work [STACS 2015], we study Subset\nSum parameterized by the maximum bin size $\\beta$, defined as the largest\nnumber of subsets of the $n$ input integers that yield the same sum. For every\n$\\epsilon > 0$ we give a truly faster algorithm for instances with $\\beta \\leq\n2^{(0.5-\\epsilon)n}$, as well as instances with $\\beta \\geq 2^{0.661n}$.\nConsequently, we also obtain a characterization in terms of the popular density\nparameter $n/\\log_2 t$: if all instances of density at least $1.003$ admit a\ntruly faster algorithm, then so does every instance. This goes against the\ncurrent intuition that instances of density 1 are the hardest, and therefore is\na step toward answering the open question in the affirmative. Our results stem\nfrom novel combinations of earlier algorithms for Subset Sum and a study of an\nextremal question in additive combinatorics connected to the problem of\nUniquely Decodable Code Pairs in information theory.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 03:14:53 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Austrin", "Per", ""], ["Koivisto", "Mikko", ""], ["Kaski", "Petteri", ""], ["Nederlof", "Jesper", ""]]}, {"id": "1508.06340", "submitter": "Aarthi Sundaram", "authors": "Itai Arad, Miklos Santha, Aarthi Sundaram, Shengyu Zhang", "title": "Linear time algorithm for quantum 2SAT", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A canonical result about satisfiability theory is that the 2-SAT problem can\nbe solved in linear time, despite the NP-hardness of the 3-SAT problem. In the\nquantum 2-SAT problem, we are given a family of 2-qubit projectors $\\Pi_{ij}$\non a system of $n$ qubits, and the task is to decide whether the Hamiltonian\n$H=\\sum \\Pi_{ij}$ has a 0-eigenvalue, or it is larger than $1/n^\\alpha$ for\nsome $\\alpha=O(1)$. The problem is not only a natural extension of the\nclassical 2-SAT problem to the quantum case, but is also equivalent to the\nproblem of finding the ground state of 2-local frustration-free Hamiltonians of\nspin $\\frac{1}{2}$, a well-studied model believed to capture certain key\nproperties in modern condensed matter physics. While Bravyi has shown that the\nquantum 2-SAT problem has a classical polynomial-time algorithm, the running\ntime of his algorithm is $O(n^4)$. In this paper we give a classical algorithm\nwith linear running time in the number of local projectors, therefore achieving\nthe best possible complexity.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 01:46:20 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 04:17:33 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Arad", "Itai", ""], ["Santha", "Miklos", ""], ["Sundaram", "Aarthi", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1508.06395", "submitter": "Mohammad Bavarian", "authors": "Mohammad Bavarian, Dmitry Gavinsky, Tsuyoshi Ito", "title": "On the Role of Shared Randomness in Simultaneous Communication", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two parties wish to carry out certain distributed computational tasks, and\nthey are given access to a source of correlated random bits. It allows the\nparties to act in a correlated manner, which can be quite useful. But what\nhappens if the shared randomness is not perfect? In this work, we initiate the\nstudy of the power of different sources of shared randomness in communication\ncomplexity. This is done in the setting of simultaneous message passing (SMP)\nmodel of communication complexity, which is one of the most suitable models for\nstudying the resource of shared randomness. Toward characterising the power of\nvarious sources of shared randomness, we introduce a measure for the quality of\na source - we call it collision complexity. Our results show that the collision\ncomplexity tightly characterises the power of a (shared) randomness resource in\nthe SMP model.\n  Of independent interest is our demonstration that even the weakest sources of\nshared randomness can in some cases increase the power of SMP substantially:\nthe equality function can be solved very efficiently with virtually any\nnontrivial shared randomness.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 07:50:48 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Bavarian", "Mohammad", ""], ["Gavinsky", "Dmitry", ""], ["Ito", "Tsuyoshi", ""]]}, {"id": "1508.06420", "submitter": "Daniel Paulusma", "authors": "P\\'eter Bir\\'o and Walter Kern and Dani\\\"el Paulusma and P\\'eter\n  Wojuteczky", "title": "The Stable Fixtures Problem with Payments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize two well-known game-theoretic models by introducing multiple\npartners matching games, defined by a graph $G=(N,E)$, with an integer vertex\ncapacity function $b$ and an edge weighting $w$. The set $N$ consists of a\nnumber of players that are to form a set $M\\subseteq E$ of 2-player coalitions\n$ij$ with value $w(ij)$, such that each player $i$ is in at most $b(i)$\ncoalitions. A payoff vector is a mapping $p: N \\times N \\rightarrow {\\mathbb\nR}$ with $p(i,j)+p(j,i)=w(ij)$ if $ij\\in M$ and $p(i,j)=p(j,i)=0$ if $ij\\notin\nM$. The pair $(M,p)$ is called a solution. A pair of players $i,j$ with $ij\\in\nE\\setminus M$ blocks a solution $(M,p)$ if $i,j$ can form, possibly only after\nwithdrawing from one of their existing 2-player coalitions, a new 2-player\ncoalition in which they are mutually better off. A solution is stable if it has\nno blocking pairs.\n  We give a polynomial-time algorithm that either finds that a given multiple\npartners matching game has no stable solution, or obtains a stable solution for\nit. We characterize the set of stable solutions of a multiple partners matching\ngame in two different ways and show how this leads to simple proofs for a\nnumber of known results of Sotomayor (1992,1999,2007) for multiple partners\nssignment games and to generalizations of some of these results to multiple\npartners matching games. We also perform a study on the core of the\ncorresponding cooperative game, where coalitions of any size may be formed. In\nparticular we show that the standard relation between the existence of a stable\nsolution and the non-emptiness of the core, which holds in the other models\nwith payments, is no longer valid for our (most general) model. We also prove\nthat the problem of deciding if an allocation belongs to the core jumps from\nbeing polynomial-time solvable for $b\\leq 2$ to NP-complete for $b\\equiv 3$.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 09:25:17 GMT"}, {"version": "v2", "created": "Wed, 31 Aug 2016 16:37:44 GMT"}], "update_date": "2016-09-01", "authors_parsed": [["Bir\u00f3", "P\u00e9ter", ""], ["Kern", "Walter", ""], ["Paulusma", "Dani\u00ebl", ""], ["Wojuteczky", "P\u00e9ter", ""]]}, {"id": "1508.06511", "submitter": "Pushkar Joglekar", "authors": "N. R. Aravind, Pushkar S. Joglekar", "title": "On the expressive power of read-once determinants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study the notion of read-$k$ projections of the determinant:\na polynomial $f \\in \\mathbb{F}[x_1, \\ldots, x_n]$ is called a {\\it read-$k$\nprojection of determinant} if $f=det(M)$, where entries of matrix $M$ are\neither field elements or variables such that each variable appears at most $k$\ntimes in $M$. A monomial set $S$ is said to be expressible as read-$k$\nprojection of determinant if there is a read-$k$ projection of determinant $f$\nsuch that the monomial set of $f$ is equal to $S$. We obtain basic results\nrelating read-$k$ determinantal projections to the well-studied notion of\ndeterminantal complexity. We show that for sufficiently large $n$, the $n\n\\times n$ permanent polynomial $Perm_n$ and the elementary symmetric\npolynomials of degree $d$ on $n$ variables $S_n^d$ for $2 \\leq d \\leq n-2$ are\nnot expressible as read-once projection of determinant, whereas $mon(Perm_n)$\nand $mon(S_n^d)$ are expressible as read-once projections of determinant. We\nalso give examples of monomial sets which are not expressible as read-once\nprojections of determinant.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 14:31:50 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Aravind", "N. R.", ""], ["Joglekar", "Pushkar S.", ""]]}, {"id": "1508.06792", "submitter": "Jens Ma{\\ss}berg", "authors": "Jens Ma{\\ss}berg", "title": "The Depth-Restricted Rectilinear Steiner Arborescence Problem is\n  NP-complete", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the rectilinear Steiner arborescence problem the task is to build a\nshortest rectilinear Steiner tree connecting a given root and a set of\nterminals which are placed in the plane such that all root-terminal-paths are\nshortest paths. This problem is known to be NP-hard.\n  In this paper we consider a more restricted version of this problem. In our\ncase we have a depth restrictions $d(t)\\in\\mathbb{N}$ for every terminal $t$.\nWe are looking for a shortest binary rectilinear Steiner arborescence such that\neach terminal $t$ is at depth $d(t)$, that is, there are exactly $d(t)$ Steiner\npoints on the unique root-$t$-path is exactly $d(t)$. We prove that even this\nrestricted version is NP-hard.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 10:18:40 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Ma\u00dfberg", "Jens", ""]]}, {"id": "1508.06829", "submitter": "Gregory Gutin", "authors": "Gregory Gutin and Magnus Wahlstrom", "title": "Tight Lower Bounds for the Workflow Satisfiability Problem Based on the\n  Strong Exponential Time Hypothesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Workflow Satisfiability Problem (WSP) asks whether there exists an\nassignment of authorized users to the steps in a workflow specification,\nsubject to certain constraints on the assignment. The problem is NP-hard even\nwhen restricted to just not equals constraints. Since the number of steps $k$\nis relatively small in practice, Wang and Li (2010) introduced a\nparametrisation of WSP by $k$. Wang and Li (2010) showed that, in general, the\nWSP is W[1]-hard, i.e., it is unlikely that there exists a fixed-parameter\ntractable (FPT) algorithm for solving the WSP. Crampton et al. (2013) and Cohen\net al. (2014) designed FPT algorithms of running time $O^*(2^{k})$ and\n$O^*(2^{k\\log_2 k})$ for the WSP with so-called regular and user-independent\nconstraints, respectively. In this note, we show that there are no algorithms\nof running time $O^*(2^{ck})$ and $O^*(2^{ck\\log_2 k})$ for the two\nrestrictions of WSP, respectively, with any $c<1$, unless the Strong\nExponential Time Hypothesis fails.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 12:32:42 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Gutin", "Gregory", ""], ["Wahlstrom", "Magnus", ""]]}, {"id": "1508.06847", "submitter": "Thiago Marcilon", "authors": "Thiago Braga Marcilon and Rudini Menezes Sampaio", "title": "The maximum time of 2-neighbour bootstrap percolation in grid graphs and\n  some parameterized results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2-neighborhood bootstrap percolation on a graph $G$, an infection spreads\naccording to the following deterministic rule: infected vertices of $G$ remain\ninfected forever and in consecutive rounds healthy vertices with at least two\nalready infected neighbors become infected. Percolation occurs if eventually\nevery vertex is infected. The maximum time $t(G)$ is the maximum number of\nrounds needed to eventually infect the entire vertex set. In 2013, it was\nproved by Benevides et al \\cite{eurocomb13} that $t(G)$ is NP-hard for planar\ngraphs and that deciding whether $t(G)\\geq k$ is polynomial time solvable for\n$k\\leq 2$, but is NP-complete for $k\\geq 4$. They left two open problems about\nthe complexity for $k=3$ and for planar bipartite graphs. In 2014, we solved\nthe first problem\\cite{wg2014}. In this paper, we solve the second one by\nproving that $t(G)$ is NP-complete even in grid graphs with maximum degree 3.\nWe also prove that $t(G)$ is polynomial time solvable for solid grid graphs\nwith maximum degree 3. Moreover, we prove that the percolation time problem is\nW[1]-hard on the treewidth of the graph, but it is fixed parameter tractable\nwith parameters treewidth$+k$ and maxdegree$+k$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 13:16:44 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Marcilon", "Thiago Braga", ""], ["Sampaio", "Rudini Menezes", ""]]}, {"id": "1508.06874", "submitter": "Thiago Marcilon", "authors": "Thiago Braga Marcilon and Rudini Menezes Sampaio", "title": "The maximum time of 2-neighbor bootstrap percolation: complexity results", "comments": "arXiv admin note: text overlap with arXiv:1209.4339 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2-neighborhood bootstrap percolation on a graph G, an infection spreads\naccording to the following deterministic rule: infected vertices of G remain\ninfected forever and in consecutive rounds healthy vertices with at least 2\nalready infected neighbors become infected. Percolation occurs if eventually\nevery vertex is infected. The maximum time t(G) is the maximum number of rounds\nneeded to eventually infect the entire vertex set. In 2013, it was proved\n\\cite{eurocomb13} that deciding whether $t(G)\\geq k$ is polynomial time\nsolvable for k=2, but is NP-Complete for k=4 and, if the problem is restricted\nto bipartite graphs, it is NP-Complete for k=7. In this paper, we solve the\nopen questions. We obtain an $O(mn^5)$-time algorithm to decide whether\n$t(G)\\geq 3$. For bipartite graphs, we obtain an $O(mn^3)$-time algorithm to\ndecide whether $t(G)\\geq 3$, an $O(m^2n^9)$-time algorithm to decide whether\n$t(G)\\geq 4$ and we prove that $t(G)\\geq 5$ is NP-Complete.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 14:32:54 GMT"}], "update_date": "2015-08-31", "authors_parsed": [["Marcilon", "Thiago Braga", ""], ["Sampaio", "Rudini Menezes", ""]]}, {"id": "1508.07338", "submitter": "Sevag Gharibian", "authors": "Niel de Beaudrap, Sevag Gharibian", "title": "A linear time algorithm for quantum 2-SAT", "comments": "21 pages", "journal-ref": "Proceedings of 31st Conference on Computational Complexity (CCC),\n  volume 50 of Leibniz International Proceedings in Informatics (LIPIcs), pages\n  27:1-27:21, 2016", "doi": "10.4230/LIPIcs.CCC.2016.27", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Boolean constraint satisfaction problem 3-SAT is arguably the canonical\nNP-complete problem. In contrast, 2-SAT can not only be decided in polynomial\ntime, but in fact in deterministic linear time. In 2006, Bravyi proposed a\nphysically motivated generalization of k-SAT to the quantum setting, defining\nthe problem \"quantum k-SAT\". He showed that quantum 2-SAT is also solvable in\npolynomial time on a classical computer, in particular in deterministic time\nO(n^4), assuming unit-cost arithmetic over a field extension of the rational\nnumbers, where n is number of variables. In this paper, we present an algorithm\nfor quantum 2-SAT which runs in linear time, i.e. deterministic time O(n+m) for\nn and m the number of variables and clauses, respectively. Our approach\nexploits the transfer matrix techniques of Laumann et al. [QIC, 2010] used in\nthe study of phase transitions for random quantum 2-SAT, and bears similarities\nwith both the linear time 2-SAT algorithms of Even, Itai, and Shamir (based on\nbacktracking) [SICOMP, 1976] and Aspvall, Plass, and Tarjan (based on strongly\nconnected components) [IPL, 1979].\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 20:32:36 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["de Beaudrap", "Niel", ""], ["Gharibian", "Sevag", ""]]}, {"id": "1508.07677", "submitter": "Benjamin Rossman", "authors": "Benjamin Rossman", "title": "The Average Sensitivity of Bounded-Depth Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that unbounded fan-in boolean formulas of depth $d+1$ and size $s$\nhave average sensitivity $O(\\frac{1}{d}\\log s)^d$. In particular, this gives a\ntight $2^{\\Omega(d(n^{1/d}-1))}$ lower bound on the size of depth $d+1$\nformulas computing the \\textsc{parity} function. These results strengthen the\ncorresponding $2^{\\Omega(n^{1/d})}$ and $O(\\log s)^d$ bounds for circuits due\nto H{\\aa}stad (1986) and Boppana (1997). Our proof technique studies a random\nprocess where the Switching Lemma is applied to formulas in an efficient\nmanner.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 04:09:03 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Rossman", "Benjamin", ""]]}]