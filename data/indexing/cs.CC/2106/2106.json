[{"id": "2106.00287", "submitter": "Michael Whitmeyer", "authors": "Vishnu Iyer, Avishay Tal, Michael Whitmeyer", "title": "Junta Distance Approximation with Sub-Exponential Queries", "comments": "To appear in CCC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Leveraging tools of De, Mossel, and Neeman [FOCS, 2019], we show two\ndifferent results pertaining to the \\emph{tolerant testing} of juntas. Given\nblack-box access to a Boolean function $f:\\{\\pm1\\}^{n} \\to \\{\\pm1\\}$, we give a\n$poly(k, \\frac{1}{\\varepsilon})$ query algorithm that distinguishes between\nfunctions that are $\\gamma$-close to $k$-juntas and $(\\gamma+\\varepsilon)$-far\nfrom $k'$-juntas, where $k' = O(\\frac{k}{\\varepsilon^2})$.\n  In the non-relaxed setting, we extend our ideas to give a\n$2^{\\tilde{O}(\\sqrt{k/\\varepsilon})}$ (adaptive) query algorithm that\ndistinguishes between functions that are $\\gamma$-close to $k$-juntas and\n$(\\gamma+\\varepsilon)$-far from $k$-juntas. To the best of our knowledge, this\nis the first subexponential-in-$k$ query algorithm for approximating the\ndistance of $f$ to being a $k$-junta (previous results of Blais, Canonne, Eden,\nLevi, and Ron [SODA, 2018] and De, Mossel, and Neeman [FOCS, 2019] required\nexponentially many queries in $k$).\n  Our techniques are Fourier analytical and make use of the notion of\n\"normalized influences\" that was introduced by Talagrand [AoP, 1994].\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 07:39:26 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Iyer", "Vishnu", ""], ["Tal", "Avishay", ""], ["Whitmeyer", "Michael", ""]]}, {"id": "2106.00399", "submitter": "Matthias Naaf", "authors": "Matthias Naaf", "title": "Computing Least and Greatest Fixed Points in Absorptive Semirings", "comments": "submitted to RAMiCS, full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present two methods to algorithmically compute both least and greatest\nsolutions of polynomial equation systems over absorptive semirings (with\ncertain completeness and continuity assumptions), such as the tropical\nsemiring. Both methods require a polynomial number of semiring operations,\nincluding semiring addition, multiplication and an infinitary power operation.\nOur main result is a closed-form solution for least and greatest fixed points\nbased on the fixed-point iteration. The proof builds on the notion of (possibly\ninfinite) derivation trees; a careful analysis of the shape of these trees\nallows us to collapse the fixed-point iteration to a linear number of steps.\nThe second method is an iterative symbolic computation in the semiring of\ngeneralized absorptive polynomials, largely based on results on Kleene\nalgebras.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 11:18:18 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 18:49:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Naaf", "Matthias", ""]]}, {"id": "2106.00714", "submitter": "Kishlaya Jaiswal", "authors": "Samir Datta and Kishlaya Jaiswal", "title": "Parallel Polynomial Permanent Mod Powers of 2 and Shortest Disjoint\n  Cycles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a parallel algorithm for permanent mod 2^k of a matrix of\nunivariate integer polynomials. It places the problem in ParityL subset of\nNC^2. This extends the techniques of [Valiant], [Braverman, Kulkarni, Roy] and\n[Bj\\\"orklund, Husfeldt], and yields a (randomized) parallel algorithm for\nshortest 2-disjoint paths improving upon the recent result from (randomized)\npolynomial time.\n  We also recognize the disjoint paths problem as a special case of finding\ndisjoint cycles, and present (randomized) parallel algorithms for finding a\nshortest cycle and shortest 2-disjoint cycles passing through any given fixed\nnumber of vertices or edges.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 18:13:14 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Datta", "Samir", ""], ["Jaiswal", "Kishlaya", ""]]}, {"id": "2106.00875", "submitter": "Oliver Korten", "authors": "Oliver Korten", "title": "The Hardest Explicit Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the complexity of explicit construction problems, where the\ngoal is to produce a particular object of size $n$ possessing some pseudorandom\nproperty in time polynomial in $n$. We give overwhelming evidence that ${\\bf\nAPEPP}$, defined originally by Kleinberg et al., is the natural complexity\nclass associated with explicit constructions for objects whose existence\nfollows from the probabilistic method, by proving that a host of well-studied\nexplicit construction problems lie in this class. We then observe that a result\nof Je\\v{r}\\'{a}bek on provability in Bounded Arithmetic, when reinterpreted as\na reduction between search problems, shows that constructing a truth table of\nhigh circuit complexity is complete for ${\\bf APEPP}$ under ${\\bf P}^{\\bf NP}$\nreductions. This demonstrates that constructing a hard truth table is a\nuniversal explicit construction problem in a concrete sense. This result in\nfact gives a precise algorithmic characterization of proving $2^{\\Omega(n)}$\ncircuit lower bounds for ${\\bf E}^{\\bf NP}$: the complete problem for ${\\bf\nAPEPP}$ has a ${\\bf P}^{\\bf NP}$ algorithm if and only if such a lower bound\nholds. Together with our proof that pseudorandom generators can be constructed\nin ${\\bf APEPP}$, this also yields a self-contained and significantly\nsimplified proof of the celebrated result of Impagliazzo and Wigderson that\nworst-case-hard truth tables can be used to derandomize algorithms (although\nthe conclusion is weaker as our derandomization requires an ${\\bf NP}$ oracle).\nAs another corollary of this completeness result, we show that ${\\bf E}^{\\bf\nNP}$ contains a language of circuit complexity $2^{\\Omega(n)}$ if and only if\nit contains a language of circuit complexity $\\frac{2^n}{3n}$. Finally, for\nseveral of the problems shown to lie in ${\\bf APEPP}$, we demonstrate direct\npolynomial time reductions to the explicit construction of hard truth tables.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 01:14:23 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Korten", "Oliver", ""]]}, {"id": "2106.00937", "submitter": "Oren Ish Shalom", "authors": "Oren Ish Shalom, Shachar Itzhaky, Noam Rinetzky, Sharon Shoham", "title": "Putting the Squeeze on Array Programs: Loop Verification via Inductive\n  Rank Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic verification of array manipulating programs is a challenging\nproblem because it often amounts to the inference of in ductive quantified loop\ninvariants which, in some cases, may not even be firstorder expressible. In\nthis paper, we suggest a novel verification tech nique that is based on\ninduction on userdefined rank of program states as an alternative to\nloopinvariants. Our technique, dubbed inductive rank reduction, works in two\nsteps. Firstly, we simplify the verification problem and prove that the program\nis correct when the input state con tains an input array of length B or less,\nusing the length of the array as the rank of the state. Secondly, we employ a\nsqueezing function g which converts a program state sigma with an array of\nlength > B to a state g(sigma) containing an array of length minus 1 or less.\nWe prove that when g satisfies certain natural conditions then if the program\nviolates its specification on sigma then it does so also on g(sigma). The\ncorrectness of the program on inputs with arrays of arbitrary lengths follows\nby induction. We make our technique automatic for array programs whose length\nof execution is proportional to the length of the input arrays by (i) perform\ning the first step using symbolic execution, (ii) verifying the conditions\nrequired of g using Z3, and (iii) providing a heuristic procedure for syn\nthesizing g. We implemented our technique and applied it successfully to\nseveral interesting arraymanipulating programs, including a bidirec tional\nsummation program whose loop invariant cannot be expressed in firstorder logic\nwhile its specification is quantifier free.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 04:51:35 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Shalom", "Oren Ish", ""], ["Itzhaky", "Shachar", ""], ["Rinetzky", "Noam", ""], ["Shoham", "Sharon", ""]]}, {"id": "2106.01382", "submitter": "Matthias C. Caro", "authors": "Matthias C. Caro", "title": "Undecidability of Learnability", "comments": "21 pages (main body) + 7 pages (reference and appendix); 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning researchers and practitioners steadily enlarge the multitude\nof successful learning models. They achieve this through in-depth theoretical\nanalyses and experiential heuristics. However, there is no known\ngeneral-purpose procedure for rigorously evaluating whether newly proposed\nmodels indeed successfully learn from data. We show that such a procedure\ncannot exist. For PAC binary classification, uniform and universal online\nlearning, and exact learning through teacher-learner interactions, learnability\nis in general undecidable, both in the sense of independence of the axioms in a\nformal system and in the sense of uncomputability. Our proofs proceed via\ncomputable constructions of function classes that encode the consistency\nproblem for formal systems and the halting problem for Turing machines into\ncomplexity measures that characterize learnability. Our work shows that\nundecidability appears in the theoretical foundations of machine learning:\nThere is no one-size-fits-all algorithm for deciding whether a machine learning\nmodel can be successful. We cannot in general automatize the process of\nassessing new learning models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 18:00:04 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Caro", "Matthias C.", ""]]}, {"id": "2106.01496", "submitter": "Robin Weishaupt", "authors": "Robin Weishaupt and J\\\"org Rothe", "title": "Stability of Special Graph Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frei et al. [6] showed that the problem to decide whether a graph is stable\nwith respect to some graph parameter under adding or removing either edges or\nvertices is $\\Theta_2^{\\text{P}}$-complete. They studied the common graph\nparameters $\\alpha$ (independence number), $\\beta$ (vertex cover number),\n$\\omega$ (clique number), and $\\chi$ (chromatic number) for certain variants of\nthe stability problem. We follow their approach and provide a large number of\npolynomial-time algorithms solving these problems for special graph classes,\nnamely for graphs without edges, complete graphs, paths, trees, forests,\nbipartite graphs, and co-graphs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 22:33:09 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Weishaupt", "Robin", ""], ["Rothe", "J\u00f6rg", ""]]}, {"id": "2106.01853", "submitter": "Amaury Pouly", "authors": "Klara Nosan, Amaury Pouly, Mahsa Shirmohammadi, James Worrell", "title": "On the Computation of the Algebraic Closure of Finitely Generated Groups\n  of Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the complexity of computing the Zariski closure of a finitely\ngenerated group of matrices. The Zariski closure was previously shown to be\ncomputable by Derksen, Jeandel and Koiran, but the termination argument for\ntheir algorithm appears not to yield any complexity bound. In this paper we\nfollow a different approach and obtain a bound on the degree of the polynomials\nthat define the closure. Our bound shows that the closure can be computed in\nelementary time. We describe several applications of this result, e.g.,\nconcerning quantum automata and quantum universal gates. We also obtain an\nupper bound on the length of a strictly increasing chain of linear algebraic\ngroups, all of which are generated over a fixed number field.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 13:57:28 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Nosan", "Klara", ""], ["Pouly", "Amaury", ""], ["Shirmohammadi", "Mahsa", ""], ["Worrell", "James", ""]]}, {"id": "2106.02005", "submitter": "Florian Speelman", "authors": "Harry Buhrman, Bruno Loff, Subhasree Patro, Florian Speelman", "title": "Limits of quantum speed-ups for computational geometry and other\n  problems: Fine-grained complexity via quantum walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many computational problems are subject to a quantum speed-up: one might find\nthat a problem having an O(n^3)-time or O(n^2)-time classic algorithm can be\nsolved by a known O(n^1.5)-time or O(n)-time quantum algorithm. The question\nnaturally arises: how much quantum speed-up is possible?\n  The area of fine-grained complexity allows us to prove optimal lower-bounds\non the complexity of various computational problems, based on the conjectured\nhardness of certain natural, well-studied problems. This theory has recently\nbeen extended to the quantum setting, in two independent papers by Buhrman,\nPatro, and Speelman (arXiv:1911.05686), and by Aaronson, Chia, Lin, Wang, and\nZhang (arXiv:1911.01973).\n  In this paper, we further extend the theory of fine-grained complexity to the\nquantum setting. A fundamental conjecture in the classical setting states that\nthe 3SUM problem cannot be solved by (classical) algorithms in time O(n^{2-a}),\nfor any a>0. We formulate an analogous conjecture, the Quantum-3SUM-Conjecture,\nwhich states that there exist no sublinear O(n^{1-b})-time quantum algorithms\nfor the 3SUM problem.\n  Based on the Quantum-3SUM-Conjecture, we show new lower-bounds on the time\ncomplexity of quantum algorithms for several computational problems. Most of\nour lower-bounds are optimal, in that they match known upper-bounds, and hence\nthey imply tight limits on the quantum speedup that is possible for these\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:22:08 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Buhrman", "Harry", ""], ["Loff", "Bruno", ""], ["Patro", "Subhasree", ""], ["Speelman", "Florian", ""]]}, {"id": "2106.02114", "submitter": "Matthew Ferland", "authors": "Kyle Burke, Matthew Ferland, Shanghua Teng", "title": "Winning the War by (Strategically) Losing Battles: Settling the\n  Complexity of Grundy-Values in Undirected Geography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We settle two long-standing complexity-theoretical questions-open since 1981\nand 1993-in combinatorial game theory (CGT).\n  We prove that the Grundy value (a.k.a. nim-value, or nimber) of Undirected\nGeography is PSPACE-complete to compute. This exhibits a stark contrast with a\nresult from 1993 that Undirected Geography is polynomial-time solvable. By\ndistilling to a simple reduction, our proof further establishes a dichotomy\ntheorem, providing a \"phase transition to intractability\" in Grundy-value\ncomputation, sharply characterized by a maximum degree of four: The Grundy\nvalue of Undirected Geography over any degree-three graph is polynomial-time\ncomputable, but over degree-four graphs-even when planar and bipartite-is\nPSPACE-hard. Additionally, we show, for the first time, how to construct\nUndirected Geography instances with Grundy value $\\ast n$ and size polynomial\nin n.\n  We strengthen a result from 1981 showing that sums of tractable partisan\ngames are PSPACE-complete in two fundamental ways. First, since Undirected\nGeography is an impartial ruleset, we extend the hardness of sums to impartial\ngames, a strict subset of partisan. Second, the 1981 construction is not built\nfrom a natural ruleset, instead using a long sum of tailored short-depth game\npositions. We use the sum of two Undirected Geography positions to create our\nhard instances. Our result also has computational implications to\nSprague-Grundy Theory (1930s) which shows that the Grundy value of the\ndisjunctive sum of any two impartial games can be computed-in polynomial\ntime-from their Grundy values. In contrast, we prove that assuming PSPACE\n$\\neq$ P, there is no general polynomial-time method to summarize two\npolynomial-time solvable impartial games to efficiently solve their disjunctive\nsum.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 20:13:18 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Burke", "Kyle", ""], ["Ferland", "Matthew", ""], ["Teng", "Shanghua", ""]]}, {"id": "2106.02129", "submitter": "Brice Huang", "authors": "Guy Bresler, Brice Huang", "title": "The Algorithmic Phase Transition of Random $k$-SAT for Low Degree\n  Polynomials", "comments": "44 pages, added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math-ph math.MP math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\Phi$ be a uniformly random $k$-SAT formula with $n$ variables and $m$\nclauses. We study the algorithmic task of finding a satisfying assignment of\n$\\Phi$. It is known that a satisfying assignment exists with high probability\nat clause density $m/n < 2^k \\log 2 - \\frac{1}{2} (\\log 2 + 1) + o_k(1)$, while\nthe best polynomial-time algorithm known, the Fix algorithm of Coja-Oghlan,\nfinds a satisfying assignment at the much lower clause density $(1 - o_k(1))\n2^k \\log k / k$. This prompts the question: is it possible to efficiently find\na satisfying assignment at higher clause densities?\n  To understand the algorithmic threshold of random $k$-SAT, we study low\ndegree polynomial algorithms, which are a powerful class of algorithms\nincluding Fix, Survey Propagation guided decimation (with bounded or mildly\ngrowing number of message passing rounds), and paradigms such as message\npassing and local graph algorithms. We show that low degree polynomial\nalgorithms can find a satisfying assignment at clause density $(1 - o_k(1)) 2^k\n\\log k / k$, matching Fix, and not at clause density $(1 + o_k(1)) \\kappa^* 2^k\n\\log k / k$, where $\\kappa^* \\approx 4.911$. This shows the first sharp (up to\nconstant factor) computational phase transition of random $k$-SAT for a class\nof algorithms. Our proof establishes and leverages a new many-way overlap gap\nproperty tailored to random $k$-SAT.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 21:01:02 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 02:36:55 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Bresler", "Guy", ""], ["Huang", "Brice", ""]]}, {"id": "2106.02335", "submitter": "Mikkel Abrahamsen", "authors": "Mikkel Abrahamsen", "title": "Covering Polygons is Even Harder", "comments": "41 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.CV cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the MINIMUM CONVEX COVER (MCC) problem, we are given a simple polygon\n$\\mathcal P$ and an integer $k$, and the question is if there exist $k$ convex\npolygons whose union is $\\mathcal P$. It is known that MCC is\n$\\mathsf{NP}$-hard [Culberson & Reckhow: Covering polygons is hard, FOCS\n1988/Journal of Algorithms 1994] and in $\\exists\\mathbb{R}$ [O'Rourke: The\ncomplexity of computing minimum convex covers for polygons, Allerton 1982]. We\nprove that MCC is $\\exists\\mathbb{R}$-hard, and the problem is thus\n$\\exists\\mathbb{R}$-complete. In other words, the problem is equivalent to\ndeciding whether a system of polynomial equations and inequalities with integer\ncoefficients has a real solution.\n  If a cover for our constructed polygon exists, then so does a cover\nconsisting entirely of triangles. As a byproduct, we therefore also establish\nthat it is $\\exists\\mathbb{R}$-complete to decide whether $k$ triangles cover a\ngiven polygon.\n  The issue that it was not known if finding a minimum cover is in\n$\\mathsf{NP}$ has repeatedly been raised in the literature, and it was\nmentioned as a \"long-standing open question\" already in 2001 [Eidenbenz &\nWidmayer: An approximation algorithm for minimum convex cover with logarithmic\nperformance guarantee, ESA 2001/SIAM Journal on Computing 2003]. We prove that\nassuming the widespread belief that $\\mathsf{NP}\\neq\\exists\\mathbb{R}$, the\nproblem is not in $\\mathsf{NP}$.\n  An implication of the result is that many natural approaches to finding small\ncovers are bound to give suboptimal solutions in some cases, since irrational\ncoordinates of arbitrarily high algebraic degree can be needed for the corners\nof the pieces in an optimal solution.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 08:29:48 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Abrahamsen", "Mikkel", ""]]}, {"id": "2106.02397", "submitter": "Tillmann Miltzow", "authors": "Tillmann Miltzow and Reinier F. Schmiermann", "title": "On Classifying Continuous Constraint Satisfaction problems", "comments": "40 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.CL cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A continuous constraint satisfaction problem (CCSP) is a constraint\nsatisfaction problem (CSP) with a domain $U \\subset \\mathbb{R}$. We engage in a\nsystematic study to classify CCSPs that are complete of the Existential Theory\nof the Reals, i.e., ER-complete. To define this class, we first consider the\nproblem ETR, which also stands for Existential Theory of the Reals. In an\ninstance of this problem we are given some sentence of the form $\\exists x_1,\n\\ldots, x_n \\in \\mathbb{R} : \\Phi(x_1, \\ldots, x_n)$, where $\\Phi$ is a\nwell-formed quantifier-free formula consisting of the symbols $\\{0, 1, +,\n\\cdot, \\geq, >, \\wedge, \\vee, \\neg\\}$, the goal is to check whether this\nsentence is true. Now the class ER is the family of all problems that admit a\npolynomial-time reduction to ETR. It is known that NP $\\subseteq$ ER\n$\\subseteq$ PSPACE.\n  We restrict our attention on CCSPs with addition constraints ($x + y = z$)\nand some other mild technical condition. Previously, it was shown that\nmultiplication constraints ($x \\cdot y = z$), squaring constraints ($x^2 = y$),\nor inversion constraints ($x\\cdot y = 1$) are sufficient to establish\nER-completeness. We extend this in the strongest possible sense for equality\nconstraints as follows. We show that CCSPs (with addition constraints and some\nother mild technical condition) that have any one well-behaved curved equality\nconstraint ($f(x,y) = 0$) are ER-complete. We further extend our results to\ninequality constraints. We show that any well-behaved convexly curved and any\nwell-behaved concavely curved inequality constraint ($f(x,y) \\geq 0$ and\n$g(x,y) \\geq 0$) imply ER-completeness on the class of such CCSPs.\n  We apply our findings to geometric packing and answer an open question by\nAbrahamsen et al. [FOCS 2020]. Namely, we establish ER-completeness of packing\nconvex pieces into a square container under rotations and translations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 10:23:48 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Miltzow", "Tillmann", ""], ["Schmiermann", "Reinier F.", ""]]}, {"id": "2106.02947", "submitter": "Jacek Krzaczkowski", "authors": "Pawe{\\l} M. Idziak, Piotr Kawa{\\l}ek, Jacek Krzaczkowski", "title": "Complexity of Modular Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how the complexity of modular circuits computing AND depends on the\ndepth of the circuits and the prime factorization of the modulus they use. In\nparticular our construction of subexponential circuits of depth 2 for AND helps\nus to classify (modulo Exponential Time Hypothesis) modular circuits with\nrespect to the complexity of their satisfiability. We also study a precise\ncorrelation between this complexity and the sizes of modular circuits realizing\nAND. On the other hand showing that AND can be computed by a polynomial size\nprobabilistic modular circuit of depth 2 (with O(log n) random bits) providing\na probabilistic computational model that can not be derandomized.\n  We apply our methods to determine (modulo ETH) the complexity of solving\nequations over groups of symmetries of regular polygons with an odd number of\nsides. These groups form a paradigm for some of the remaining cases in\ncharacterizing finite groups with respect to the complexity of their equation\nsolving.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 19:13:27 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Idziak", "Pawe\u0142 M.", ""], ["Kawa\u0142ek", "Piotr", ""], ["Krzaczkowski", "Jacek", ""]]}, {"id": "2106.03107", "submitter": "Jannis Kurtz", "authors": "Jannis Kurtz", "title": "New complexity results and algorithms for min-max-min robust\n  combinatorial optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we investigate the min-max-min robust optimization problem\napplied to combinatorial problems with uncertain cost-vectors which are\ncontained in a convex uncertainty set. The idea of the approach is to calculate\na set of k feasible solutions which are worst-case optimal if in each possible\nscenario the best of the k solutions would be implemented. It is known that the\nmin-max-min robust problem can be solved efficiently if k is at least the\ndimension of the problem, while it is theoretically and computationally hard if\nk is small. While both cases are well studied in the literature nothing is\nknown about the intermediate case, namely if k is smaller than but close to the\ndimension of the problem. We approach this open question and show that for a\nselection of combinatorial problems the min-max-min problem can be solved\nexactly and approximately in polynomial time if some problem specific values\nare fixed. Furthermore we approach a second open question and present the first\nimplementable algorithm with oracle-pseudopolynomial runtime for the case that\nk is at least the dimension of the problem. The algorithm is based on a\nprojected subgradient method where the projection problem is solved by the\nclassical Frank-Wolfe algorithm. Additionally we derive a branch & bound method\nto solve the min-max-min problem for arbitrary values of k and perform tests on\nknapsack and shortest path instances. The experiments show that despite its\ntheoretical impact the projected subgradient method cannot compete with an\nalready existing method. On the other hand the performance of the branch &\nbound method scales very well with the number of solutions. Thus we are able to\nsolve instances where k is above some small threshold very efficiently.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 12:39:43 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 13:21:20 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kurtz", "Jannis", ""]]}, {"id": "2106.03214", "submitter": "Ben Lee Volk", "authors": "Shir Peleg, Amir Shpilka, Ben Lee Volk", "title": "Lower Bounds on Stabilizer Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stabilizer rank of a quantum state $\\psi$ is the minimal $r$ such that\n$\\left| \\psi \\right \\rangle = \\sum_{j=1}^r c_j \\left|\\varphi_j \\right\\rangle$\nfor $c_j \\in \\mathbb{C}$ and stabilizer states $\\varphi_j$. The running time of\nseveral classical simulation methods for quantum circuits is determined by the\nstabilizer rank of the $n$-th tensor power of single-qubit magic states.\n  We prove a lower bound of $\\Omega(n)$ on the stabilizer rank of such states,\nimproving a previous lower bound of $\\Omega(\\sqrt{n})$ of Bravyi, Smith and\nSmolin (arXiv:1506.01396). Further, we prove that for a sufficiently small\nconstant $\\delta$, the stabilizer rank of any state which is $\\delta$-close to\nthose states is $\\Omega(\\sqrt{n}/\\log n)$. This is the first non-trivial lower\nbound for approximate stabilizer rank.\n  Our techniques rely on the representation of stabilizer states as quadratic\nfunctions over affine subspaces of $\\mathbb{F}_2^n$, and we use tools from\nanalysis of boolean functions and complexity theory. The proof of the first\nresult involves a careful analysis of directional derivatives of quadratic\npolynomials, whereas the proof of the second result uses Razborov-Smolensky low\ndegree polynomial approximations and correlation bounds against the majority\nfunction.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 19:27:51 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Peleg", "Shir", ""], ["Shpilka", "Amir", ""], ["Volk", "Ben Lee", ""]]}, {"id": "2106.04086", "submitter": "Andrei Bulatov", "authors": "Andrei A.Bulatov and Amirhossein Kazeminia", "title": "Complexity classification of counting graph homomorphisms modulo a prime\n  number", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Counting graph homomorphisms and its generalizations such as the Counting\nConstraint Satisfaction Problem (CSP), its variations, and counting problems in\ngeneral have been intensively studied since the pioneering work of Valiant.\nWhile the complexity of exact counting of graph homomorphisms (Dyer and\nGreenhill, 2000) and the counting CSP (Bulatov, 2013, and Dyer and Richerby,\n2013) is well understood, counting modulo some natural number has attracted\nconsiderable interest as well. In their 2015 paper Faben and Jerrum suggested a\nconjecture stating that counting homomorphisms to a fixed graph H modulo a\nprime number is hard whenever it is hard to count exactly, unless H has\nautomorphisms of certain kind. In this paper we confirm this conjecture. As a\npart of this investigation we develop techniques that widen the spectrum of\nreductions available for modular counting and apply to the general CSP rather\nthan being limited to graph homomorphisms.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 03:52:21 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bulatov", "Andrei A.", ""], ["Kazeminia", "Amirhossein", ""]]}, {"id": "2106.04299", "submitter": "Srijita Kundu", "authors": "Rahul Jain, Srijita Kundu", "title": "A direct product theorem for quantum communication complexity with\n  applications to device-independent QKD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a direct product theorem for the entanglement-assisted interactive\nquantum communication complexity of an $l$-player predicate $\\mathsf{V}$. In\nparticular we show that for a distribution $p$ that is product across the input\nsets of the $l$ players, the success probability of any entanglement-assisted\nquantum communication protocol for computing $n$ copies of $\\mathsf{V}$, whose\ncommunication is $o(\\log(\\mathrm{eff}^*(\\mathsf{V},p))\\cdot n)$, goes down\nexponentially in $n$. Here $\\mathrm{eff}^*(\\mathsf{V}, p)$ is a distributional\nversion of the quantum efficiency or partition bound introduced by Laplante,\nLerays and Roland (2014), which is a lower bound on the distributional quantum\ncommunication complexity of computing a single copy of $\\mathsf{V}$ with\nrespect to $p$.\n  As an application of our result, we show that it is possible to do\ndevice-independent quantum key distribution (DIQKD) without the assumption that\ndevices do not leak any information after inputs are provided to them. We\nanalyze the DIQKD protocol given by Jain, Miller and Shi (2017), and show that\nwhen the protocol is carried out with devices that are compatible with $n$\ncopies of the Magic Square game, it is possible to extract $\\Omega(n)$ bits of\nkey from it, even in the presence of $O(n)$ bits of leakage. Our security proof\nis parallel, i.e., the honest parties can enter all their inputs into their\ndevices at once, and works for a leakage model that is arbitrarily interactive,\ni.e., the devices of the honest parties Alice and Bob can exchange information\nwith each other and with the eavesdropper Eve in any number of rounds, as long\nas the total number of bits or qubits communicated is bounded.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 12:52:10 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Jain", "Rahul", ""], ["Kundu", "Srijita", ""]]}, {"id": "2106.04332", "submitter": "Negar Heidari", "authors": "Negar Heidari and Alexandros Iosifidis", "title": "Progressive Spatio-Temporal Bilinear Network with Monte Carlo Dropout\n  for Landmark-based Facial Expression Recognition with Uncertainty Estimation", "comments": "6 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been widely used for feature learning in facial\nexpression recognition systems. However, small datasets and large intra-class\nvariability can lead to overfitting. In this paper, we propose a method which\nlearns an optimized compact network topology for real-time facial expression\nrecognition utilizing localized facial landmark features. Our method employs a\nspatio-temporal bilinear layer as backbone to capture the motion of facial\nlandmarks during the execution of a facial expression effectively. Besides, it\ntakes advantage of Monte Carlo Dropout to capture the model's uncertainty which\nis of great importance to analyze and treat uncertain cases. The performance of\nour method is evaluated on three widely used datasets and it is comparable to\nthat of video-based state-of-the-art methods while it has much less complexity.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 13:40:30 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Heidari", "Negar", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2106.05480", "submitter": "Kevin Tian", "authors": "Yin Tat Lee, Ruoqi Shen, Kevin Tian", "title": "Lower Bounds on Metropolized Sampling Methods for Well-Conditioned\n  Distributions", "comments": "47 pages, 1 figure, comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give lower bounds on the performance of two of the most popular sampling\nmethods in practice, the Metropolis-adjusted Langevin algorithm (MALA) and\nmulti-step Hamiltonian Monte Carlo (HMC) with a leapfrog integrator, when\napplied to well-conditioned distributions. Our main result is a nearly-tight\nlower bound of $\\widetilde{\\Omega}(\\kappa d)$ on the mixing time of MALA from\nan exponentially warm start, matching a line of algorithmic results up to\nlogarithmic factors and answering an open question of Chewi et. al. We also\nshow that a polynomial dependence on dimension is necessary for the relaxation\ntime of HMC under any number of leapfrog steps, and bound the gains achievable\nby changing the step count. Our HMC analysis draws upon a novel connection\nbetween leapfrog integration and Chebyshev polynomials, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 03:47:39 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Lee", "Yin Tat", ""], ["Shen", "Ruoqi", ""], ["Tian", "Kevin", ""]]}, {"id": "2106.05761", "submitter": "Diptapriyo Majumdar", "authors": "Jason Crampton, Eduard Eiben, Gregory Gutin, Daniel Karapetyan,\n  Diptapriyo Majumdar", "title": "Valued Authorization Policy Existence Problem: Theory and Experiments", "comments": "32 pages, 5 figures. Preliminary version appeared in SACMAT 2021\n  (https://doi.org/10.1145/3450569.3463571). Some of the theoretical results\n  (algorithms) have been improved. Computational experiments have been added to\n  this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that many problems of satisfiability and resiliency in\nworkflows may be viewed as special cases of the authorization policy existence\nproblem (APEP), which returns an authorization policy if one exists and 'No'\notherwise. However, in many practical settings it would be more useful to\nobtain a 'least bad' policy than just a 'No', where 'least bad' is\ncharacterized by some numerical value indicating the extent to which the policy\nviolates the base authorization relation and constraints. Accordingly, we\nintroduce the Valued APEP, which returns an authorization policy of minimum\nweight, where the (non-negative) weight is determined by the constraints\nviolated by the returned solution. We then establish a number of results\nconcerning the parameterized complexity of Valued APEP. We prove that the\nproblem is fixed-parameter tractable (FPT) if the set of constraints satisfies\ntwo restrictions, but is intractable if only one of these restrictions holds.\n(Most constraints known to be of practical use satisfy both restrictions.) We\nalso introduce a new type of resiliency for workflow satisfiability problem,\nshow how it can be addressed using Valued APEP and use this to build a set of\nbenchmark instances for Valued APEP. Following a set of computational\nexperiments with two mixed integer programming (MIP) formulations, we\ndemonstrate that the Valued APEP formulation based on the user profile concept\nhas FPT-like running time and usually significantly outperforms a naive\nformulation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 14:06:18 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 13:58:35 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Crampton", "Jason", ""], ["Eiben", "Eduard", ""], ["Gutin", "Gregory", ""], ["Karapetyan", "Daniel", ""], ["Majumdar", "Diptapriyo", ""]]}, {"id": "2106.06026", "submitter": "Mina Dalirrooyfard", "authors": "Mina Dalirrooyfard, Ray Li, Virginia Vassilevska Williams", "title": "Hardness of Approximate Diameter: Now for Undirected Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Approximating the graph diameter is a basic task of both theoretical and\npractical interest. A simple folklore algorithm can output a 2-approximation to\nthe diameter in linear time by running BFS from an arbitrary vertex. It has\nbeen open whether a better approximation is possible in near-linear time. A\nseries of papers on fine-grained complexity have led to strong hardness results\nfor diameter in directed graphs, culminating in a recent tradeoff curve\nindependently discovered by [Li, STOC'21] and [Dalirrooyfard and Wein,\nSTOC'21], showing that under the Strong Exponential Time Hypothesis (SETH), for\nany integer $k\\ge 2$ and $\\delta>0$, a $2-\\frac{1}{k}-\\delta$ approximation for\ndiameter in directed $m$-edge graphs requires $mn^{1+1/(k-1)-o(1)}$ time. In\nparticular, the simple linear time $2$-approximation algorithm is optimal for\ndirected graphs.\n  In this paper we prove that the same tradeoff lower bound curve is possible\nfor undirected graphs as well, extending results of [Roditty and Vassilevska\nW., STOC'13], [Li'20] and [Bonnet, ICALP'21] who proved the first few cases of\nthe curve, $k=2,3$ and $4$, respectively. Our result shows in particular that\nthe simple linear time $2$-approximation algorithm is also optimal for\nundirected graphs. To obtain our result we develop new tools for fine-grained\nreductions that could be useful for proving SETH-based hardness for other\nproblems in undirected graphs related to distance computation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 20:07:24 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Dalirrooyfard", "Mina", ""], ["Li", "Ray", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "2106.06249", "submitter": "Stefan Siemer", "authors": "Pawe{\\l} Gawrychowski, Florin Manea, Stefan Siemer", "title": "Matching Patterns with Variables under Hamming Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A pattern $\\alpha$ is a string of variables and terminal letters. We say that\n$\\alpha$ matches a word $w$, consisting only of terminal letters, if $w$ can be\nobtained by replacing the variables of $\\alpha$ by terminal words. The matching\nproblem, i.e., deciding whether a given pattern matches a given word, was\nheavily investigated: it is NP-complete in general, but can be solved\nefficiently for classes of patterns with restricted structure. In this paper,\nwe approach this problem in a generalized setting, by considering approximate\npattern matching under Hamming distance. More precisely, we are interested in\nwhat is the minimum Hamming distance between $w$ and any word $u$ obtained by\nreplacing the variables of $\\alpha$ by terminal words. Firstly, we address the\nclass of regular patterns (in which no variable occurs twice) and propose\nefficient algorithms for this problem, as well as matching conditional lower\nbounds. We show that the problem can still be solved efficiently if we allow\nrepeated variables, but restrict the way the different variables can be\ninterleaved according to a locality parameter. However, as soon as we allow a\nvariable to occur more than once and its occurrences can be interleaved\narbitrarily with those of other variables, even if none of them occurs more\nthan once, the problem becomes intractable.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 09:00:37 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Gawrychowski", "Pawe\u0142", ""], ["Manea", "Florin", ""], ["Siemer", "Stefan", ""]]}, {"id": "2106.06308", "submitter": "Davin Choo", "authors": "Davin Choo, Tommaso d'Orsi", "title": "The Complexity of Sparse Tensor PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sparse tensor principal component analysis: given a\ntensor $\\pmb Y = \\pmb W + \\lambda x^{\\otimes p}$ with $\\pmb W \\in\n\\otimes^p\\mathbb{R}^n$ having i.i.d. Gaussian entries, the goal is to recover\nthe $k$-sparse unit vector $x \\in \\mathbb{R}^n$. The model captures both sparse\nPCA (in its Wigner form) and tensor PCA.\n  For the highly sparse regime of $k \\leq \\sqrt{n}$, we present a family of\nalgorithms that smoothly interpolates between a simple polynomial-time\nalgorithm and the exponential-time exhaustive search algorithm. For any $1 \\leq\nt \\leq k$, our algorithms recovers the sparse vector for signal-to-noise ratio\n$\\lambda \\geq \\tilde{\\mathcal{O}} (\\sqrt{t} \\cdot (k/t)^{p/2})$ in time\n$\\tilde{\\mathcal{O}}(n^{p+t})$, capturing the state-of-the-art guarantees for\nthe matrix settings (in both the polynomial-time and sub-exponential time\nregimes).\n  Our results naturally extend to the case of $r$ distinct $k$-sparse signals\nwith disjoint supports, with guarantees that are independent of the number of\nspikes. Even in the restricted case of sparse PCA, known algorithms only\nrecover the sparse vectors for $\\lambda \\geq \\tilde{\\mathcal{O}}(k \\cdot r)$\nwhile our algorithms require $\\lambda \\geq \\tilde{\\mathcal{O}}(k)$.\n  Finally, by analyzing the low-degree likelihood ratio, we complement these\nalgorithmic results with rigorous evidence illustrating the trade-offs between\nsignal-to-noise ratio and running time. This lower bound captures the known\nlower bounds for both sparse PCA and tensor PCA. In this general model, we\nobserve a more intricate three-way trade-off between the number of samples $n$,\nthe sparsity $k$, and the tensor power $p$.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 10:57:00 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Choo", "Davin", ""], ["d'Orsi", "Tommaso", ""]]}, {"id": "2106.06453", "submitter": "Mark Simkin", "authors": "Nils Fleischhacker and Kasper Green Larsen and and Mark Simkin", "title": "Property-Preserving Hash Functions from Standard Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Property-preserving hash functions allow for compressing long inputs $x_0$\nand $x_1$ into short hashes $h(x_0)$ and $h(x_1)$ in a manner that allows for\ncomputing a predicate $P(x_0, x_1)$ given only the two hash values without\nhaving access to the original data. Such hash functions are said to be\nadversarially robust if an adversary that gets to pick $x_0$ and $x_1$ after\nthe hash function has been sampled, cannot find inputs for which the predicate\nevaluated on the hash values outputs the incorrect result.\n  In this work we construct robust property-preserving hash functions for the\nhamming-distance predicate which distinguishes inputs with a hamming distance\nat least some threshold $t$ from those with distance less than $t$. The\nsecurity of the construction is based on standard lattice hardness assumptions.\n  Our construction has several advantages over the best known previous\nconstruction by Fleischhacker and Simkin. Our construction relies on a single\nwell-studied hardness assumption from lattice cryptography whereas the previous\nwork relied on a newly introduced family of computational hardness assumptions.\nIn terms of computational effort, our construction only requires a small number\nof modular additions per input bit, whereas previously several exponentiations\nper bit as well as the interpolation and evaluation of high-degree polynomials\nover large fields were required. An additional benefit of our construction is\nthat the description of the hash function can be compressed to $\\lambda$ bits\nassuming a random oracle. Previous work has descriptions of length\n$\\mathcal{O}(\\ell \\lambda)$ bits for input bit-length $\\ell$, which has a\nsecret structure and thus cannot be compressed.\n  We prove a lower bound on the output size of any property-preserving hash\nfunction for the hamming distance predicate. The bound shows that the size of\nour hash value is not far from optimal.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 15:21:38 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Fleischhacker", "Nils", ""], ["Larsen", "Kasper Green", ""], ["Simkin", "and Mark", ""]]}, {"id": "2106.06580", "submitter": "Brandilyn Stigler", "authors": "Elena Dimitrova, Brandilyn Stigler, Claus Kadelka, David Murrugarra", "title": "Revealing the canalizing structure of Boolean functions: Algorithms and\n  applications", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean functions can be represented in many ways including logical forms,\ntruth tables, and polynomials. Additionally, Boolean functions have different\ncanonical representations such as minimal disjunctive normal forms. Other\ncanonical representation is based on the polynomial representation of Boolean\nfunctions where they can be written as a nested product of canalizing layers\nand a polynomial that contains the noncanalizing variables. In this paper we\nstudy the problem of identifying the canalizing layers format of Boolean\nfunctions. First, we show that the problem of finding the canalizing layers is\nNP-hard. Second, we present several algorithms for finding the canalizing\nlayers of a Boolean function, discuss their complexities, and compare their\nperformances. Third, we show applications where the computation of canalizing\nlayers can be used for finding a disjunctive normal form of a nested canalizing\nfunction. Another application deals with the reverse engineering of Boolean\nnetworks with a prescribed layering format. Finally, implementations of our\nalgorithms in Python and in the computer algebra system Macaulay2 are available\nat https://github.com/ckadelka/BooleanCanalization.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 19:02:24 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Dimitrova", "Elena", ""], ["Stigler", "Brandilyn", ""], ["Kadelka", "Claus", ""], ["Murrugarra", "David", ""]]}, {"id": "2106.06925", "submitter": "Warut Suksompong", "authors": "Naoyuki Kamiyama, Pasin Manurangsi, Warut Suksompong", "title": "On the Complexity of Fair House Allocation", "comments": null, "journal-ref": "Operations Research Letters, 49(4):572-577 (2021)", "doi": "10.1016/j.orl.2021.06.006", "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fairness in house allocation, where $m$ houses are to be allocated\namong $n$ agents so that every agent receives one house. We show that\nmaximizing the number of envy-free agents is hard to approximate to within a\nfactor of $n^{1-\\gamma}$ for any constant $\\gamma>0$, and that the exact\nversion is NP-hard even for binary utilities. Moreover, we prove that deciding\nwhether a proportional allocation exists is computationally hard, whereas the\ncorresponding problem for equitability can be solved efficiently.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 05:45:21 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Kamiyama", "Naoyuki", ""], ["Manurangsi", "Pasin", ""], ["Suksompong", "Warut", ""]]}, {"id": "2106.06950", "submitter": "Alberto Boffi", "authors": "Alberto Boffi", "title": "An efficient way to manage blocks of data with Wise Red-Black Trees", "comments": "Added references to order-statistic trees. Corrected some terms and\n  form. Results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper describes the most efficient way to manage operations on groups of\nconsecutive elements, or \"blocks\" of elements, within an ordered set. The goal\nis to improve existing solutions, by optimizing the average-case time\ncomplexity and getting rid of heavy multiplicative constants in the worst-case,\nwithout sacrificing space complexity. This is an high-impact operation in\npractical applications, and will be performed by introducing a new data\nstructure called Wise Red-Black Tree, an augmented version of the Red-Black\nTree.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 09:30:41 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 19:00:47 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Boffi", "Alberto", ""]]}, {"id": "2106.08078", "submitter": "Bosheng Song", "authors": "Yu Jin, Bosheng Song, Yanyan Li, Ying Zhu", "title": "Time-free solution to independent set problem using P systems with\n  active membranes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membrane computing is a branch of natural computingwhich abstracts fromthe\nstructure and the functioning of living cells. The computation models obtained\nin the field of membrane computing are usually called P systems. P systems have\nbeen used to solve computationally hard problems efficiently on the assumption\nthat the execution of each rule is completed in exactly one time-unit (a global\nclock is assumed for timing and synchronizing the execution of rules). However,\nin biological reality, different biological processes take different times to\nbe completed, which can also be influenced by many environmental factors. In\nthis work, with this biological reality, we give a time-free solution to\nindependent set problemusing P systems with active membranes, which solve the\nproblem independent of the execution time of the involved rules.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 12:11:18 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 14:53:05 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 04:28:09 GMT"}, {"version": "v4", "created": "Mon, 12 Jul 2021 12:58:39 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Jin", "Yu", ""], ["Song", "Bosheng", ""], ["Li", "Yanyan", ""], ["Zhu", "Ying", ""]]}, {"id": "2106.09374", "submitter": "Kamil Khadiev", "authors": "Kamil Khadiev and Dmitry Kravchenko", "title": "Quantum algorithm for Dyck Language with Multiple Types of Brackets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the recognition problem of the Dyck Language generalized for\nmultiple types of brackets. We provide an algorithm with quantum query\ncomplexity $O(\\sqrt{n}(\\log n)^{0.5k})$, where $n$ is the length of input and\n$k$ is the maximal nesting depth of brackets. Additionally, we show the lower\nbound for this problem which is $O(\\sqrt{n}c^{k})$ for some constant $c$.\n  Interestingly, classical algorithms solving the Dyck Language for multiple\ntypes of brackets substantially differ form the algorithm solving the original\nDyck language. At the same time, quantum algorithms for solving both kinds of\nthe Dyck language are of similar nature and requirements.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 10:48:19 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Khadiev", "Kamil", ""], ["Kravchenko", "Dmitry", ""]]}, {"id": "2106.09907", "submitter": "Imin Chen", "authors": "Imin Chen and David Sun", "title": "The dihedral hidden subgroup problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an exposition of the hidden subgroup problem for dihedral groups from\nthe point of view of the standard hidden subgroup quantum algorithm for finite\ngroups. In particular, we recall the obstructions for strong Fourier sampling\nto succeed, but at the same time, show how the standard algorithm can be\nmodified to establish polynomial quantum query complexity. Finally, we explain\na new connection between the dihedral coset problem and cloning of quantum\nstates.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 04:19:10 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Chen", "Imin", ""], ["Sun", "David", ""]]}, {"id": "2106.09917", "submitter": "Girija Limaye", "authors": "Girija Limaye", "title": "Envy-freeness and Relaxed Stability for Lower-Quotas: A Parameterized\n  Perspective", "comments": "19 pages, 2 figures. This submission essentially replaces the\n  following results from arXiv:1910.07159 - Theorem 4(I) MAXEFM result, Section\n  4.1 and 4.3 (Parameterized complexity). The consent of the remaining authors\n  of arXiv:1910.07159 is taken before making this submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of assigning agents to resources in the two-sided\npreference model with upper and lower-quota requirements on resources. This\nsetting (known as the HRLQ setting) models real-world applications like\nassigning students to colleges or courses, resident doctors to hospitals and so\non. In presence of lower-quotas, an instance may not admit a stable matching\nthat fulfils the lower-quotas. Prem Krishnaa et al. [SAGT 2020] study two\nalternative notions of optimality for the HRLQ instances -- envy-freeness and\nrelaxed stability. They investigate the complexity of computing a maximum size\nenvy-free matching (MAXEFM) and a maximum size relaxed stable matching(MAXRSM)\nthat fulfils the lower-quotas. They show that both these optimization problems\nare NP-hard and not approximable within a constant factor unless P=NP.\n  In this work, we investigate the parameterized complexity of MAXEFM and\nMAXRSM. We consider natural parameters derived from the instance -- the number\nof lower-quota hospitals, deficiency of the instance, size of a maximum\nmatching, size of a stable matching, length of the preference list of a\nlower-quota hospital, to name a few. We show that MAXEFM problem is W[1]-hard\nfor several interesting parameters but admits a polynomial size kernel for a\ncombination of parameters. We show that MAXRSM problem does not admit an FPT\nalgorithm unless P=NP for two natural parameters but admits a polynomial size\nkernel for a combination of parameters in a special case. We also show that\nboth these problems admit FPT algorithms on a set of parameters.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 04:55:04 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Limaye", "Girija", ""]]}, {"id": "2106.10049", "submitter": "Cl\\'ement Dallard", "authors": "Cl\\'ement Dallard, Robert Ganian, Meike Hatzel, Matja\\v{z} Krnc and\n  Martin Milani\\v{c}", "title": "Graphs with at most two moplexes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A moplex is a natural graph structure that arises when lifting Dirac's\nclassical theorem from chordal graphs to general graphs. However, while every\nnon-complete graph has at least two moplexes, little is known about structural\nproperties of graphs with a bounded number of moplexes. The study of these\ngraphs is motivated by the parallel between moplexes in general graphs and\nsimplicial modules in chordal graphs: Unlike in the moplex setting, properties\nof chordal graphs with a bounded number of simplicial modules are well\nunderstood. For instance, chordal graphs having at most two simplicial modules\nare interval. In this work we initiate an investigation of $k$-moplex graphs,\nwhich are defined as graphs containing at most $k$ moplexes. Of particular\ninterest is the smallest nontrivial case $k=2$, which forms a counterpart to\nthe class of interval graphs. As our main structural result, we show that the\nclass of connected $2$-moplex graphs is sandwiched between the classes of\nproper interval graphs and cocomparability graphs; moreover, both inclusions\nare tight for hereditary classes. From a complexity theoretic viewpoint, this\nleads to the natural question of whether the presence of at most two moplexes\nguarantees a sufficient amount of structure to efficiently solve problems that\nare known to be intractable on cocomparability graphs, but not on proper\ninterval graphs. We develop new reductions that answer this question negatively\nfor two prominent problems fitting this profile, namely Graph Isomorphism and\nMax-Cut. On the other hand, we prove that every connected $2$-moplex graph\ncontains a Hamiltonian path, generalising the same property of connected proper\ninterval graphs. Furthermore, for graphs with a higher number of moplexes, we\nlift the previously known result that graphs without asteroidal triples have at\nmost two moplexes to the more general setting of larger asteroidal sets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 10:52:12 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Dallard", "Cl\u00e9ment", ""], ["Ganian", "Robert", ""], ["Hatzel", "Meike", ""], ["Krnc", "Matja\u017e", ""], ["Milani\u010d", "Martin", ""]]}, {"id": "2106.10744", "submitter": "Min Jae Song", "authors": "Min Jae Song, Ilias Zadik, Joan Bruna", "title": "On the Cryptographic Hardness of Learning Single Periodic Neurons", "comments": "54 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a simple reduction which demonstrates the cryptographic hardness of\nlearning a single periodic neuron over isotropic Gaussian distributions in the\npresence of noise. More precisely, our reduction shows that any polynomial-time\nalgorithm (not necessarily gradient-based) for learning such functions under\nsmall noise implies a polynomial-time quantum algorithm for solving worst-case\nlattice problems, whose hardness form the foundation of lattice-based\ncryptography. Our core hard family of functions, which are well-approximated by\none-layer neural networks, take the general form of a univariate periodic\nfunction applied to an affine projection of the data. These functions have\nappeared in previous seminal works which demonstrate their hardness against\ngradient-based (Shamir'18), and Statistical Query (SQ) algorithms (Song et\nal.'17). We show that if (polynomially) small noise is added to the labels, the\nintractability of learning these functions applies to all polynomial-time\nalgorithms under the aforementioned cryptographic assumptions.\n  Moreover, we demonstrate the necessity of noise in the hardness result by\ndesigning a polynomial-time algorithm for learning certain families of such\nfunctions under exponentially small adversarial noise. Our proposed algorithm\nis not a gradient-based or an SQ algorithm, but is rather based on the\ncelebrated Lenstra-Lenstra-Lov\\'asz (LLL) lattice basis reduction algorithm.\nFurthermore, in the absence of noise, this algorithm can be directly applied to\nsolve CLWE detection (Bruna et al.'21) and phase retrieval with an optimal\nsample complexity of $d+1$ samples. In the former case, this improves upon the\nquadratic-in-$d$ sample complexity required in (Bruna et al.'21). In the latter\ncase, this improves upon the state-of-the-art AMP-based algorithm, which\nrequires approximately $1.128d$ samples (Barbier et al.'19).\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 20:03:52 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Song", "Min Jae", ""], ["Zadik", "Ilias", ""], ["Bruna", "Joan", ""]]}, {"id": "2106.11178", "submitter": "Jamie Tucker-Foltz", "authors": "Jamie Tucker-Foltz", "title": "Thou Shalt Covet The Average Of Thy Neighbors' Cakes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove an $\\Omega(n^2)$ lower bound on the query complexity of local\nproportionality in the Robertson-Webb cake-cutting model. Local proportionality\nrequires that each agent prefer their allocation to the average of their\nneighbors' allocations in some undirected social network. It is a weaker\nfairness notion than envy-freeness, which also has query complexity\n$\\Omega(n^2)$, and generally incomparable to proportionality, which has query\ncomplexity $\\Theta(n \\log n)$. This result separates the complexity of local\nproportionality from that of ordinary proportionality, confirming the intuition\nthat finding a locally proportional allocation is a more difficult\ncomputational problem.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 15:17:56 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Tucker-Foltz", "Jamie", ""]]}, {"id": "2106.11372", "submitter": "Sapna Grover", "authors": "Sapna Grover, Neelima Gupta and Rajni Dabas", "title": "First Approximation for Uniform Lower and Upper Bounded Facility\n  Location Problem avoiding violation in Lower Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With growing emphasis on e-commerce marketplace platforms where we have a\ncentral platform mediating between the seller and the buyer, it becomes\nimportant to keep a check on the availability and profitability of the central\nstore. A store serving too less clients can be non-profitable and a store\ngetting too many orders can lead to bad service to the customers which can be\ndetrimental for the business. In this paper, we study the facility location\nproblem(FL) with upper and lower bounds on the number of clients an open\nfacility serves. Constant factor approximations are known for the restricted\nvariants of the problem with only the upper bounds or only the lower bounds.\nThe only work that deals with bounds on both the sides violates both the bounds\n[8]. In this paper, we present the first (constant factor) approximation for\nthe problem violating the upper bound by a factor of (5/2) without violating\nthe lower bounds when both the lower and the upper bounds are uniform. We first\ngive a tri-criteria (constant factor) approximation violating both the upper\nand the lower bounds and then get rid of violation in lower bounds by\ntransforming the problem instance to an instance of capacitated facility\nlocation problem.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 19:12:01 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 09:21:52 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 17:22:39 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Grover", "Sapna", ""], ["Gupta", "Neelima", ""], ["Dabas", "Rajni", ""]]}, {"id": "2106.11689", "submitter": "Celine Swennenhuis", "authors": "Isja Mannens, Jesper Nederlof, C\\'eline Swennenhuis and Krisztina\n  Szil\\'agyi", "title": "On the Parameterized Complexity of the Connected Flow and Many Visits\n  TSP Problem", "comments": "To be included in the proceedings of the 'International Workshop on\n  Graph-Theoretic Concepts in Computer Science' (WG2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of Min Cost Flow in which the flow needs to be connected.\nSpecifically, in the Connected Flow problem one is given a directed graph $G$,\nalong with a set of demand vertices $D \\subseteq V(G)$ with demands\n$\\mathsf{dem}: D \\rightarrow \\mathbb{N}$, and costs and capacities for each\nedge. The goal is to find a minimum cost flow that satisfies the demands,\nrespects the capacities and induces a (strongly) connected subgraph. This\ngeneralizes previously studied problems like the (Many Visits) TSP.\n  We study the parameterized complexity of Connected Flow parameterized by\n$|D|$, the treewidth $tw$ and by vertex cover size $k$ of $G$ and provide:\n  (i) $\\mathsf{NP}$-completeness already for the case $|D|=2$ with only unit\ndemands and capacities and no edge costs, and fixed-parameter tractability if\nthere are no capacities,\n  (ii) a fixed-parameter tractable $\\mathcal{O}^{\\star}(k^{\\mathcal{O}(k)})$\ntime algorithm for the general case, and a kernel of size polynomial in $k$ for\nthe special case of Many Visits TSP,\n  (iii) a $|V(G)|^{\\mathcal{O}(tw)}$ time algorithm and a matching\n$|V(G)|^{o(tw)}$ time conditional lower bound conditioned on the Exponential\nTime Hypothesis.\n  To achieve some of our results, we significantly extend an approach by\nKowalik et al.~[ESA'20].\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 11:44:49 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 14:20:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Mannens", "Isja", ""], ["Nederlof", "Jesper", ""], ["Swennenhuis", "C\u00e9line", ""], ["Szil\u00e1gyi", "Krisztina", ""]]}, {"id": "2106.11877", "submitter": "Uma Girish", "authors": "Uma Girish, Ran Raz", "title": "Eliminating Intermediate Measurements using Pseudorandom Generators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that quantum algorithms of time $T$ and space $S\\ge \\log T$ with\nintermediate measurements can be simulated by quantum algorithms of time $T\n\\cdot \\mathrm{poly}(S)$ and space $O(S\\cdot \\log T )$ without intermediate\nmeasurements. The best simulations prior to this work required either\n$\\Omega(T)$ space (by the deferred measurement principle) or\n$\\mathrm{poly}(2^S)$ time [FR21, GRZ21]. Our result is thus a time-efficient\nand space-efficient simulation of algorithms with intermediate measurements by\nalgorithms without intermediate measurements.\n  To prove our result, we study pseudorandom generators for quantum\nspace-bounded algorithms. We show that (an instance of) the INW pseudorandom\ngenerator for classical space-bounded algorithms [INW94] also fools quantum\nspace-bounded algorithms. More precisely, we show that for quantum\nspace-bounded algorithms that have access to a read-once tape consisting of\nrandom bits, the final state of the algorithm when the random bits are drawn\nfrom the uniform distribution is nearly identical to the final state when the\nrandom bits are drawn using the INW pseudorandom generator.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:47:20 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Girish", "Uma", ""], ["Raz", "Ran", ""]]}, {"id": "2106.11886", "submitter": "Tianrong Lin", "authors": "Tianrong Lin", "title": "A Negative Answer to $P\\overset{?}{=}PSPACE$", "comments": "Thanks go to a net user in stackexchange (stackoverflow) for pointing\n  out a flaw in Lemma 2 in v1; v5: remark 2 re-written. Any comments are\n  welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a conjecture on $P\\overset{?}{=}PSPACE$ in computational complexity\nzoo. It is a widespread belief that $P\\neq PSPACE$, otherwise $P=NP$ which is\nextremely impossible. In this short work, we assert that $P\\neq PSPACE$ no\nmatter what outcome is on $P\\overset{?}{=}NP$. We accomplishe this via showing\n$NP\\neq PSPACE$. The method is by the result that Circuit-SAT is\n$\\leq_{\\log}$--complete for $NP$, Circuit-SAT$\\in DSPACE[n]$, the known result\n$DSPACE[n^c]\\subset DSPACE[n^{2c}]$ (indicated by the space complexity\nhierarchy theorem) and the fact that $PSPACE$ is the union set of all\n$DSPACE[n^k]$ where $k\\in\\mathbb{N}$. Closely related consequences are\nsummarized.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:55:00 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 10:25:26 GMT"}, {"version": "v3", "created": "Sun, 4 Jul 2021 00:11:16 GMT"}, {"version": "v4", "created": "Thu, 22 Jul 2021 11:35:29 GMT"}, {"version": "v5", "created": "Fri, 23 Jul 2021 20:56:27 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lin", "Tianrong", ""]]}, {"id": "2106.12341", "submitter": "Tristan St\\'erin", "authors": "Matthew Cook and Tristan St\\'erin and Damien Woods", "title": "Small tile sets that compute while solving mazes", "comments": "18 pages. 7 figures. 1 appendix. To appear at the 27th International\n  Conference on DNA Computing and Molecular Programming (DNA27)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We ask the question of how small a self-assembling set of tiles can be yet\nhave interesting computational behaviour. We study this question in a model\nwhere supporting walls are provided as an input structure for tiles to grow\nalong: we call it the Maze-Walking Tile Assembly Model. The model has a number\nof implementation prospects, one being DNA strands that attach to a DNA origami\nsubstrate. Intuitively, the model suggests a separation of signal routing and\ncomputation: the input structure (maze) supplies a routing diagram, and the\nprogrammer's tile set provides the computational ability. We ask how simple the\ncomputational part can be.\n  We give two tiny tile sets that are computationally universal in the\nMaze-Walking Tile Assembly Model. The first has four tiles and simulates\nBoolean circuits by directly implementing NAND, NXOR and NOT gates. Our second\ntile set has 6 tiles and is called the Collatz tile set as it produces patterns\nfound in binary/ternary representations of iterations of the Collatz function.\nUsing computer search we find that the Collatz tile set is expressive enough to\nencode Boolean circuits using blocks of these patterns. These two tile sets\ngive two different methods to find simple universal tile sets, and provide\nmotivation for using pre-assembled maze structures as circuit wiring diagrams\nin molecular self-assembly based computing.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 12:15:38 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Cook", "Matthew", ""], ["St\u00e9rin", "Tristan", ""], ["Woods", "Damien", ""]]}, {"id": "2106.12710", "submitter": "Sidhanth Mohanty", "authors": "Jun-Ting Hsieh, Sidhanth Mohanty, Jeff Xu", "title": "Certifying solution geometry in random CSPs: counts, clusters and\n  balance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An active topic in the study of random constraint satisfaction problems\n(CSPs) is the geometry of the space of satisfying or almost satisfying\nassignments as the function of the density, for which a precise landscape of\npredictions has been made via statistical physics-based heuristics. In\nparallel, there has been a recent flurry of work on refuting random constraint\nsatisfaction problems, via nailing refutation thresholds for spectral and\nsemidefinite programming-based algorithms, and also on counting solutions to\nCSPs. Inspired by this, the starting point for our work is the following\nquestion: what does the solution space for a random CSP look like to an\nefficient algorithm?\n  In pursuit of this inquiry, we focus on the following problems about random\nBoolean CSPs at the densities where they are unsatisfiable but no refutation\nalgorithm is known.\n  1. Counts. For every Boolean CSP we give algorithms that with high\nprobability certify a subexponential upper bound on the number of solutions. We\nalso give algorithms to certify a bound on the number of large cuts in a\nGaussian-weighted graph, and the number of large independent sets in a random\n$d$-regular graph.\n  2. Clusters. For Boolean $3$CSPs we give algorithms that with high\nprobability certify an upper bound on the number of clusters of solutions.\n  3. Balance. We also give algorithms that with high probability certify that\nthere are no \"unbalanced\" solutions, i.e., solutions where the fraction of\n$+1$s deviates significantly from $50\\%$.\n  Finally, we also provide hardness evidence suggesting that our algorithms for\ncounting are optimal.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 01:15:35 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Hsieh", "Jun-Ting", ""], ["Mohanty", "Sidhanth", ""], ["Xu", "Jeff", ""]]}, {"id": "2106.13078", "submitter": "Alexander Golovnev", "authors": "Chi-Ning Chou, Alexander Golovnev, Madhu Sudan, Ameya Velingker,\n  Santhoshini Velusamy", "title": "Linear Space Streaming Lower Bounds for Approximating CSPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the approximability of constraint satisfaction problems in the\nstreaming setting. For every constraint satisfaction problem (CSP) on $n$\nvariables taking values in $\\{0,\\ldots,q-1\\}$, we prove that improving over the\ntrivial approximability by a factor of $q$ requires $\\Omega(n)$ space even on\ninstances with $O(n)$ constraints. We also identify a broad subclass of\nproblems for which any improvement over the trivial approximability requires\n$\\Omega(n)$ space. The key technical core is an optimal,\n$q^{-(k-1)}$-inapproximability for the case where every constraint is given by\na system of $k-1$ linear equations $\\bmod\\; q$ over $k$ variables. Prior to our\nwork, no such hardness was known for an approximation factor less than $1/2$\nfor any CSP. Our work builds on and extends the work of Kapralov and Krachun\n(Proc. STOC 2019) who showed a linear lower bound on any non-trivial\napproximation of the max cut in graphs. This corresponds roughly to the case of\nMax $k$-LIN-$\\bmod\\; q$ with $k=q=2$. Each one of the extensions provides\nnon-trivial technical challenges that we overcome in this work.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 15:04:07 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Chou", "Chi-Ning", ""], ["Golovnev", "Alexander", ""], ["Sudan", "Madhu", ""], ["Velingker", "Ameya", ""], ["Velusamy", "Santhoshini", ""]]}, {"id": "2106.13154", "submitter": "Barnaby Martin", "authors": "Catarina Carvalho and Florent Madelaine and Barnaby Martin and Dmitriy\n  Zhuk", "title": "The complexity of quantified constraints: collapsibility, switchability\n  and the algebraic formulation", "comments": "arXiv admin note: substantial text overlap with arXiv:1701.04086,\n  arXiv:1501.04558, arXiv:1510.06298", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let A be an idempotent algebra on a finite domain. By mediating between\nresults of Chen and Zhuk, we argue that if A satisfies the polynomially\ngenerated powers property (PGP) and B is a constraint language invariant under\nA (that is, in Inv(A)), then QCSP(B) is in NP. In doing this we study the\nspecial forms of PGP, switchability and collapsibility, in detail, both\nalgebraically and logically, addressing various questions such as decidability\non the way.\n  We then prove a complexity-theoretic converse in the case of infinite\nconstraint languages encoded in propositional logic, that if Inv(A) satisfies\nthe exponentially generated powers property (EGP), then QCSP(Inv(A)) is\nco-NP-hard. Since Zhuk proved that only PGP and EGP are possible, we derive a\nfull dichotomy for the QCSP, justifying what we term the Revised Chen\nConjecture. This result becomes more significant now the original Chen\nConjecture is known to be false.\n  Switchability was introduced by Chen as a generalisation of the already-known\ncollapsibility. For three-element domain algebras A that are switchable and\nomit a G-set, we prove that, for every finite subset D of Inv(A), Pol(D) is\ncollapsible. The significance of this is that, for QCSP on finite structures\n(over a three-element domain), all QCSP tractability (in P) explained by\nswitchability is already explained by collapsibility.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 16:28:33 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Carvalho", "Catarina", ""], ["Madelaine", "Florent", ""], ["Martin", "Barnaby", ""], ["Zhuk", "Dmitriy", ""]]}, {"id": "2106.13210", "submitter": "Nikhil Vyas", "authors": "Mitali Bafna, Nikhil Vyas", "title": "Optimal Fine-grained Hardness of Approximation of Linear Equations", "comments": "To appear in ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of solving linear systems is one of the most fundamental problems\nin computer science, where given a satisfiable linear system $(A,b)$, for $A\n\\in \\mathbb{R}^{n \\times n}$ and $b \\in \\mathbb{R}^n$, we wish to find a vector\n$x \\in \\mathbb{R}^n$ such that $Ax = b$. The current best algorithms for\nsolving dense linear systems reduce the problem to matrix multiplication, and\nrun in time $O(n^{\\omega})$. We consider the problem of finding\n$\\varepsilon$-approximate solutions to linear systems with respect to the\n$L_2$-norm, that is, given a satisfiable linear system $(A \\in \\mathbb{R}^{n\n\\times n}, b \\in \\mathbb{R}^n)$, find an $x \\in \\mathbb{R}^n$ such that $||Ax -\nb||_2 \\leq \\varepsilon||b||_2$. Our main result is a fine-grained reduction\nfrom computing the rank of a matrix to finding $\\varepsilon$-approximate\nsolutions to linear systems. In particular, if the best known $O(n^\\omega)$\ntime algorithm for computing the rank of $n \\times O(n)$ matrices is optimal\n(which we conjecture is true), then finding an $\\varepsilon$-approximate\nsolution to a dense linear system also requires $\\tilde{\\Omega}(n^{\\omega})$\ntime, even for $\\varepsilon$ as large as $(1 - 1/\\text{poly}(n))$. We also\nprove (under some modified conjectures for the rank-finding problem) optimal\nhardness of approximation for sparse linear systems, linear systems over\npositive semidefinite matrices, well-conditioned linear systems, and\napproximately solving linear systems with respect to the $L_p$-norm, for $p\n\\geq 1$. At the heart of our results is a novel reduction from the rank problem\nto a decision version of the approximate linear systems problem. This reduction\npreserves properties such as matrix sparsity and bit complexity.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 17:43:57 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bafna", "Mitali", ""], ["Vyas", "Nikhil", ""]]}, {"id": "2106.13602", "submitter": "Kai Pfeiffer", "authors": "Kai Pfeiffer, Adrien Escande, Ludovic Righetti", "title": "$\\mathcal{N}$IPM-HLSP: An Efficient Interior-Point Method for\n  Hierarchical Least-Squares Programs", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.NA cs.PF cs.RO cs.SY eess.SY math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hierarchical least-squares programs with linear constraints (HLSP) are a type\nof optimization problem very common in robotics. Each priority level contains\nan objective in least-squares form which is subject to the linear constraints\nof the higher priority hierarchy levels. Active-set methods (ASM) are a popular\nchoice for solving them. However, they can perform poorly in terms of\ncomputational time if there are large changes of the active set. We therefore\npropose a computationally efficient primal-dual interior-point method (IPM) for\nHLSP's which is able to maintain constant numbers of solver iterations in these\nsituations. We base our IPM on the null-space method which requires only a\nsingle decomposition per Newton iteration instead of two as it is the case for\nother IPM solvers. After a priority level has converged we compose a set of\nactive constraints judging upon the dual and project lower priority levels into\ntheir null-space. We show that the IPM-HLSP can be expressed in least-squares\nform which avoids the formation of the quadratic Karush-Kuhn-Tucker (KKT)\nHessian. Due to our choice of the null-space basis the IPM-HLSP is as fast as\nthe state-of-the-art ASM-HLSP solver for equality only problems.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 12:54:31 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Pfeiffer", "Kai", ""], ["Escande", "Adrien", ""], ["Righetti", "Ludovic", ""]]}, {"id": "2106.14020", "submitter": "Suthee Ruangwises", "authors": "Suthee Ruangwises", "title": "An Improved Physical ZKP for Nonogram", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonogram is a logic puzzle consisting of a rectangular grid with an objective\nto color every cell black or white such that the lengths of blocks of\nconsecutive black cells in each row and column are equal to the given numbers.\nIn 2010, Chien and Hon developed the first physical zero-knowledge proof for\nNonogram, which allows a prover to physically show that he/she knows a solution\nof the puzzle without revealing it. However, their protocol requires special\ntools such as scratch-off cards and a machine to seal the cards, which are\ndifficult to find in everyday life. Their protocol also has a nonzero soundness\nerror. In this paper, we propose a more practical physical zero-knowledge proof\nfor Nonogram that uses only a deck of regular paper cards and also has perfect\nsoundness.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 13:32:25 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ruangwises", "Suthee", ""]]}, {"id": "2106.14354", "submitter": "Tytus Pikies", "authors": "Tytus Pikies (1), Hanna Furma\\'nczyk (2) ((1) Dept. of Algorithims and\n  System Modelling, ETI Faculty, Gda\\'nsk University of Technology, 11/12\n  Gabriela Narutowicza Street, 80-233 Gda\\'nsk, Poland, (2) Institute of\n  Informatics, Faculty of Mathematics, Physics and Informatics, University of\n  Gda\\'nsk, 57 Wita Stwosza Street, 80-309 Gda\\'nsk, Poland)", "title": "Scheduling on uniform and unrelated machines with bipartite\n  incompatibility graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problem of scheduling of jobs on parallel machines under\nincompatibility relation is considered. In this model a binary relation between\njobs is given and no two jobs that are in the relation can be scheduled on the\nsame machine. In particular, we consider job scheduling under incompatibility\nrelation forming bipartite graphs, under makespan optimality criterion, on\nuniform and unrelated machines. We show that no algorithm can achieve a good\napproximation ratio for uniform machines, even for a case of unit time jobs,\nunder $P \\neq NP$. We also provide an approximation algorithm that achieves the\nbest possible approximation ratio, even for the case of jobs of arbitrary\nlengths $p_j$, under the same assumption. Precisely, we present an\n$O(n^{1/2-\\epsilon})$ inapproximability bound, for any $\\epsilon > 0$; and\n$\\sqrt{p_{sum}}$-approximation algorithm, respectively. To enrich the analysis,\nbipartite graphs generated randomly according to Gilbert's model\n$\\mathcal{G}_{n,n,p(n)}$ are considered. For a broad class of $p(n)$ functions\nwe show that there exists an algorithm producing a schedule with makespan\nalmost surely at most twice the optimum. Due to our knowledge, this is the\nfirst study of randomly generated graphs in the context of scheduling in the\nconsidered model.\n  For unrelated machines, an FPTAS for $R2|G = bipartite|C_{\\max}$ is provided.\nWe also show that there is no algorithm of approximation ratio\n$O(n^bp_{\\max}^{1-\\epsilon})$, even for $Rm|G = bipartite|C_{max}$ for $m \\ge\n3$ and any $\\epsilon > 0$, $b > 0$, unless $P = NP$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 00:43:44 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Pikies", "Tytus", ""], ["Furma\u0144czyk", "Hanna", ""]]}, {"id": "2106.14408", "submitter": "Thomas Dag\\`es", "authors": "Thomas Dag\\`es, Alfred M. Bruckstein", "title": "A Bound on the Edge-Flipping Distance between Triangulations (Revisiting\n  the Proof)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit here a fundamental result on planar triangulations, namely that\nthe flip distance between two triangulations is upper-bounded by the number of\nproper intersections between their straight-segment edges. We provide a\ncomplete and detailed proof of this result in a slightly generalised setting\nusing a case-based analysis that fills several gaps left by previous proofs of\nthe result.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 05:50:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Dag\u00e8s", "Thomas", ""], ["Bruckstein", "Alfred M.", ""]]}, {"id": "2106.14601", "submitter": "Till Heller", "authors": "T. Heller and S.O. Krumke and K.-H. K\\\"ufer", "title": "The Reward-Penalty-Selection Problem", "comments": "24 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Set Cover Problem (SCP) and the Hitting Set Problem (HSP) are\nwell-studied optimization problems. In this paper we introduce the\nReward-Penalty-Selection Problem (RPSP) which can be understood as a\ncombination of the SCP and the HSP where the objectives of both problems are\ncontrary to each other. Applications of the RPSP can be found in the context of\ncombinatorial exchanges in order to solve the corresponding winner\ndetermination problem. We give complexity results for the minimization and the\nmaximization problem as well as for several variants with additional\nrestrictions. Further, we provide an algorithm that runs in polynomial time for\nthe special case of laminar sets and a dynamic programming approach for the\ncase where the instance can be represented by a tree or a graph with bounded\ntree-width. We further present a graph theoretical generalization of this\nproblem and results regarding its complexity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 12:12:02 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Heller", "T.", ""], ["Krumke", "S. O.", ""], ["K\u00fcfer", "K. -H.", ""]]}, {"id": "2106.14980", "submitter": "Christoph Glanzer", "authors": "Christoph Glanzer, Ingo Stallknecht, Robert Weismantel", "title": "Notes on $\\{a,b,c\\}$-Modular Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A \\in \\mathbb{Z}^{m \\times n}$ be an integral matrix and $a$, $b$, $c\n\\in \\mathbb{Z}$ satisfy $a \\geq b \\geq c \\geq 0$. The question is to recognize\nwhether $A$ is $\\{a,b,c\\}$-modular, i.e., whether the set of $n \\times n$\nsubdeterminants of $A$ in absolute value is $\\{a,b,c\\}$. We will succeed in\nsolving this problem in polynomial time unless $A$ possesses a duplicative\nrelation, that is, $A$ has nonzero $n \\times n$ subdeterminants $k_1$ and $k_2$\nsatisfying $2 \\cdot |k_1| = |k_2|$. This is an extension of the well-known\nrecognition algorithm for totally unimodular matrices. As a consequence of our\nanalysis, we present a polynomial time algorithm to solve integer programs in\nstandard form over $\\{a,b,c\\}$-modular constraint matrices for any constants\n$a$, $b$ and $c$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 20:53:28 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Glanzer", "Christoph", ""], ["Stallknecht", "Ingo", ""], ["Weismantel", "Robert", ""]]}, {"id": "2106.15018", "submitter": "Juris Smotrovs", "authors": "J\\=anis Iraids and Juris Smotrovs", "title": "Representing polynomial of CONNECTIVITY", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the coefficients of the representing polynomial of any monotone\nBoolean function are the values of a Moebius function of an atomistic lattice\nrelated to this function. Using this we determine the representing polynomial\nof any Boolean function corresponding to a direct acyclic graph connectivity\nproblem. Only monomials corresponding to unions of paths have non-zero\ncoefficients which are $(-1)^D$ where $D$ is an easily computable function of\nthe graph corresponding to the monomial (it is the number of plane regions in\nthe case of planar graphs). We estimate the number of monomials with non-zero\ncoefficients for the two-dimensional grid connectivity problem as being between\n$\\Omega(1.641^{2n^2})$ and $O(1.654^{2n^2})$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 23:06:06 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Iraids", "J\u0101nis", ""], ["Smotrovs", "Juris", ""]]}, {"id": "2106.15212", "submitter": "Thomas Spooner", "authors": "Thomas Spooner, Danial Dervovic, Jason Long, Jon Shepard, Jiahao Chen,\n  Daniele Magazzeni", "title": "Counterfactual Explanations for Arbitrary Regression Models", "comments": "20 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for counterfactual explanations (CFEs) based on\nBayesian optimisation that applies to both classification and regression\nmodels. Our method is a globally convergent search algorithm with support for\narbitrary regression models and constraints like feature sparsity and\nactionable recourse, and furthermore can answer multiple counterfactual\nquestions in parallel while learning from previous queries. We formulate CFE\nsearch for regression models in a rigorous mathematical framework using\ndifferentiable potentials, which resolves robustness issues in threshold-based\nobjectives. We prove that in this framework, (a) verifying the existence of\ncounterfactuals is NP-complete; and (b) that finding instances using such\npotentials is CLS-complete. We describe a unified algorithm for CFEs using a\nspecialised acquisition function that composes both expected improvement and an\nexponential-polynomial (EP) family with desirable properties. Our evaluation on\nreal-world benchmark domains demonstrate high sample-efficiency and precision.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:53:53 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Spooner", "Thomas", ""], ["Dervovic", "Danial", ""], ["Long", "Jason", ""], ["Shepard", "Jon", ""], ["Chen", "Jiahao", ""], ["Magazzeni", "Daniele", ""]]}, {"id": "2106.15256", "submitter": "Ronny Tredup", "authors": "Ronny Tredup", "title": "The Complexity of Synthesis of $b$-Bounded Petri Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a fixed type of Petri nets $\\tau$, \\textsc{$\\tau$-Synthesis} is the task\nof finding for a given transition system $A$ a Petri net $N$ of type $\\tau$\n($\\tau$-net, for short) whose reachability graph is isomorphic to $A$ if there\nis one. The decision version of this search problem is called\n\\textsc{$\\tau$-Solvability}. If an input $A$ allows a positive decision, then\nit is called $\\tau$-solvable and a sought net $N$ $\\tau$-solves $A$. As a well\nknown fact, $A$ is $\\tau$-solvable if and only if it has the so-called\n$\\tau$-\\emph{event state separation property} ($\\tau$-ESSP, for short) and the\n$\\tau$-\\emph{state separation property} ($\\tau$-SSP, for short). The question\nwhether $A$ has the $\\tau$-ESSP or the $\\tau$-SSP defines also decision\nproblems. In this paper, for all $b\\in \\mathbb{N}$, we completely characterize\nthe computational complexity of \\textsc{$\\tau$-Solvability},\n\\textsc{$\\tau$-ESSP} and \\textsc{$\\tau$-SSP} for the types of pure $b$-bounded\nPlace/Transition-nets, the $b$-bounded Place/Transition-nets and their\ncorresponding $\\mathbb{Z}_{b+1}$-extensions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 11:15:15 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Tredup", "Ronny", ""]]}, {"id": "2106.15585", "submitter": "Erik Demaine", "authors": "Erik D. Demaine, Jayson Lynch, Mikhail Rudoy, Yushi Uno", "title": "Yin-Yang Puzzles are NP-complete", "comments": "10 pages, 11 figures. Proceedings of CCCG 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove NP-completeness of Yin-Yang / Shiromaru-Kuromaru pencil-and-paper\npuzzles. Viewed as a graph partitioning problem, we prove NP-completeness of\npartitioning a rectangular grid graph into two induced trees (normal Yin-Yang),\nor into two induced connected subgraphs (Yin-Yang without $2 \\times 2$ rule),\nsubject to some vertices being pre-assigned to a specific tree/subgraph.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:21:16 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Demaine", "Erik D.", ""], ["Lynch", "Jayson", ""], ["Rudoy", "Mikhail", ""], ["Uno", "Yushi", ""]]}, {"id": "2106.15907", "submitter": "Celine Swennenhuis", "authors": "Hans L. Bodlaender, Carla Groenland and C\\'eline M. F. Swennenhuis", "title": "Parameterized Complexities of Dominating and Independent Set\n  Reconfiguration", "comments": "31 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We settle the parameterized complexities of several variants of independent\nset reconfiguration and dominating set reconfiguration, parameterized by the\nnumber of tokens. We show that both problems are XL-complete when there is no\nlimit on the number of moves and XNL-complete when a maximum length $\\ell$ for\nthe sequence is given in binary in the input. The problems are known to be\nXNLP-complete when $\\ell$ is given in unary instead, and $W[1]$- and\n$W[2]$-hard respectively when $\\ell$ is also a parameter. We complete the\npicture by showing membership in those classes.\n  Moreover, we show that for all the variants that we consider, token sliding\nand token jumping are equivalent under pl-reductions. We introduce partitioned\nvariants of token jumping and token sliding, and give pl-reductions between the\nfour variants that have precise control over the number of tokens and the\nlength of the reconfiguration sequence.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 08:51:54 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Groenland", "Carla", ""], ["Swennenhuis", "C\u00e9line M. F.", ""]]}, {"id": "2106.15969", "submitter": "Eugene Eberbach", "authors": "Eugene Eberbach", "title": "On Completeness of Cost Metrics and Meta-Search Algorithms in\n  \\$-Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we define three new complexity classes for Turing Machine\nundecidable problems inspired by the famous Cook/Levin's NP-complete complexity\nclass for intractable problems. These are U-complete (Universal complete),\nD-complete (Diagonalization complete) and H-complete (Hypercomputation\ncomplete) classes. We started the population process of these new classes. We\njustify that some super-Turing models of computation, i.e., models going beyond\nTuring machines, are tremendously expressive and they allow to accept arbitrary\nlanguages over a given alphabet including those undecidable ones. We prove also\nthat one of such super-Turing models of computation -- the \\$-Calculus,\ndesigned as a tool for automatic problem solving and automatic programming, has\nalso such tremendous expressiveness. We investigate also completeness of cost\nmetrics and meta-search algorithms in \\$-calculus.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 10:29:24 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Eberbach", "Eugene", ""]]}, {"id": "2106.16015", "submitter": "Hugo Jacob", "authors": "Hugo Jacob, Thomas Bellitto, Oscar Defrain, Marcin Pilipczuk", "title": "Close relatives (of Feedback Vertex Set), revisited", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  At IPEC 2020, Bergougnoux, Bonnet, Brettell, and Kwon showed that a number of\nproblems related to the classic Feedback Vertex Set (FVS) problem do not admit\na $2^{o(k \\log k)} \\cdot n^{\\mathcal{O}(1)}$-time algorithm on graphs of\ntreewidth at most $k$, assuming the Exponential Time Hypothesis. This contrasts\nwith the $3^{k} \\cdot k^{\\mathcal{O}(1)} \\cdot n$-time algorithm for FVS using\nthe Cut&Count technique.\n  During their live talk at IPEC 2020, Bergougnoux et al.~posed a number of\nopen questions, which we answer in this work.\n  - Subset Even Cycle Transversal, Subset Odd Cycle Transversal, Subset\nFeedback Vertex Set can be solved in time $2^{\\mathcal{O}(k \\log k)} \\cdot n$\nin graphs of treewidth at most $k$. This matches a lower bound for Even Cycle\nTransversal of Bergougnoux et al.~and improves the polynomial factor in some of\ntheir upper bounds.\n  - Subset Feedback Vertex Set and Node Multiway Cut can be solved in time\n$2^{\\mathcal{O}(k \\log k)} \\cdot n$, if the input graph is given as a\nclique-width expression of size $n$ and width $k$.\n  - Odd Cycle Transversal can be solved in time $4^k \\cdot k^{\\mathcal{O}(1)}\n\\cdot n$ if the input graph is given as a clique-width expression of size $n$\nand width $k$. Furthermore, the existence of a constant $\\varepsilon > 0$ and\nan algorithm performing this task in time $(4-\\varepsilon)^k \\cdot\nn^{\\mathcal{O}(1)}$ would contradict the Strong Exponential Time Hypothesis.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 12:30:32 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Jacob", "Hugo", ""], ["Bellitto", "Thomas", ""], ["Defrain", "Oscar", ""], ["Pilipczuk", "Marcin", ""]]}, {"id": "2106.16172", "submitter": "R. Teal Witter", "authors": "R. Teal Witter", "title": "Backgammon is Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We study the computational complexity of the popular board game backgammon.\nWe show that deciding whether a player can win from a given board configuration\nis NP-Hard, PSPACE-Hard, and EXPTIME-Hard under different settings of known and\nunknown opponents' strategies and dice rolls. Our work answers an open question\nposed by Erik Demaine in 2001. In particular, for the real life setting where\nthe opponent's strategy and dice rolls are unknown, we prove that determining\nwhether a player can win is EXPTIME-Hard. Interestingly, it is not clear what\ncomplexity class strictly contains each problem we consider because backgammon\ngames can theoretically continue indefinitely as a result of the capture rule.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 16:07:46 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Witter", "R. Teal", ""]]}, {"id": "2106.16213", "submitter": "William Merrill", "authors": "William Merrill and Yoav Goldberg and Roy Schwartz and Noah A. Smith", "title": "On the Power of Saturated Transformers: A View from Circuit Complexity", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have become a standard architecture for many NLP problems. This\nhas motivated theoretically analyzing their capabilities as models of language,\nin order to understand what makes them successful, and what their potential\nweaknesses might be. Recent work has shown that transformers with hard\nattention are quite limited in capacity, and in fact can be simulated by\nconstant-depth circuits. However, hard attention is a restrictive assumption,\nwhich may complicate the relevance of these results for practical transformers.\nIn this work, we analyze the circuit complexity of transformers with saturated\nattention: a generalization of hard attention that more closely captures the\nattention patterns learnable in practical transformers. We show that saturated\ntransformers transcend the limitations of hard-attention transformers. With\nsome minor assumptions, we prove that the number of bits needed to represent a\nsaturated transformer memory vector is $O(\\log n)$, which implies saturated\ntransformers can be simulated by log-depth circuits. Thus, the jump from hard\nto saturated attention can be understood as increasing the transformer's\neffective circuit depth by a factor of $O(\\log n)$.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 17:09:47 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Merrill", "William", ""], ["Goldberg", "Yoav", ""], ["Schwartz", "Roy", ""], ["Smith", "Noah A.", ""]]}, {"id": "2106.16218", "submitter": "Sandra Kiefer", "authors": "Martin Grohe, Sandra Kiefer", "title": "Logarithmic Weisfeiler-Leman Identifies All Planar Graphs", "comments": "21 pages, 2 figures, accepted at ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Weisfeiler-Leman (WL) algorithm is a well-known combinatorial procedure\nfor detecting symmetries in graphs and it is widely used in graph-isomorphism\ntests. It proceeds by iteratively refining a colouring of vertex tuples. The\nnumber of iterations needed to obtain the final output is crucial for the\nparallelisability of the algorithm.\n  We show that there is a constant k such that every planar graph can be\nidentified (that is, distinguished from every non-isomorphic graph) by the\nk-dimensional WL algorithm within a logarithmic number of iterations. This\ngeneralises a result due to Verbitsky (STACS 2007), who proved the same for\n3-connected planar graphs.\n  The number of iterations needed by the k-dimensional WL algorithm to identify\na graph corresponds to the quantifier depth of a sentence that defines the\ngraph in the (k+1)-variable fragment C^{k+1} of first-order logic with counting\nquantifiers. Thus, our result implies that every planar graph is definable with\na C^{k+1}-sentence of logarithmic quantifier depth.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 17:16:47 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Grohe", "Martin", ""], ["Kiefer", "Sandra", ""]]}]