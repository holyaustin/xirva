[{"id": "1701.00146", "submitter": "Erik Demaine", "authors": "Jeffrey Bosboom, Erik D. Demaine, Martin L. Demaine, Adam Hesterberg,\n  Pasin Manurangsi, Anak Yodpinyanee", "title": "Even $1 \\times n$ Edge-Matching and Jigsaw Puzzles are Really Hard", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the computational intractability of rotating and placing $n$ square\ntiles into a $1 \\times n$ array such that adjacent tiles are compatible--either\nequal edge colors, as in edge-matching puzzles, or matching tab/pocket shapes,\nas in jigsaw puzzles. Beyond basic NP-hardness, we prove that it is NP-hard\neven to approximately maximize the number of placed tiles (allowing blanks),\nwhile satisfying the compatibility constraint between nonblank tiles, within a\nfactor of 0.9999999851. (On the other hand, there is an easy $1 \\over\n2$-approximation.) This is the first (correct) proof of inapproximability for\nedge-matching and jigsaw puzzles. Along the way, we prove NP-hardness of\ndistinguishing, for a directed graph on $n$ nodes, between having a Hamiltonian\npath (length $n-1$) and having at most $0.999999284 (n-1)$ edges that form a\nvertex-disjoint union of paths. We use this gap hardness and gap-preserving\nreductions to establish similar gap hardness for $1 \\times n$ jigsaw and\nedge-matching puzzles.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2016 17:05:53 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Bosboom", "Jeffrey", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Hesterberg", "Adam", ""], ["Manurangsi", "Pasin", ""], ["Yodpinyanee", "Anak", ""]]}, {"id": "1701.00227", "submitter": "Ale\\v{s} Bizjak", "authors": "Carsten R\\\"osnick-Neugebauer", "title": "Closed Sets and Operators thereon: Representations, Computability and\n  Complexity", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (April 10,\n  2018) lmcs:4432", "doi": "10.23638/LMCS-14(2:1)2018", "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The TTE approach to Computable Analysis is the study of so-called\nrepresentations (encodings for continuous objects such as reals, functions, and\nsets) with respect to the notions of computability they induce. A rich variety\nof such representations had been devised over the past decades, particularly\nregarding closed subsets of Euclidean space plus subclasses thereof (like\ncompact subsets). In addition, they had been compared and classified with\nrespect to both non-uniform computability of single sets and uniform\ncomputability of operators on sets. In this paper we refine these\ninvestigations from the point of view of computational complexity. Benefiting\nfrom the concept of second-order representations and complexity recently\ndevised by Kawamura & Cook (2012), we determine parameterized complexity bounds\nfor operators such as union, intersection, projection, and more generally\nfunction image and inversion. By indicating natural parameters in addition to\nthe output precision, we get a uniform view on results by Ko (1991-2013),\nBraverman (2004/05) and Zhao & M\\\"uller (2008), relating these problems to the\nP/UP/NP question in discrete complexity theory.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2017 11:25:42 GMT"}, {"version": "v2", "created": "Sat, 20 Jan 2018 15:04:02 GMT"}, {"version": "v3", "created": "Sat, 10 Mar 2018 12:21:51 GMT"}, {"version": "v4", "created": "Mon, 9 Apr 2018 07:07:33 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["R\u00f6snick-Neugebauer", "Carsten", ""]]}, {"id": "1701.00637", "submitter": "EPTCS", "authors": "Ken-etsu Fujita (Gunma University)", "title": "On Upper Bounds on the Church-Rosser Theorem", "comments": "In Proceedings WPTE 2016, arXiv:1701.00233", "journal-ref": "EPTCS 235, 2017, pp. 16-31", "doi": "10.4204/EPTCS.235.2", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Church-Rosser theorem in the type-free lambda-calculus is well\ninvestigated both for beta-equality and beta-reduction. We provide a new proof\nof the theorem for beta-equality with no use of parallel reductions, but simply\nwith Takahashi's translation (Gross-Knuth strategy). Based on this, upper\nbounds for reduction sequences on the theorem are obtained as the fourth level\nof the Grzegorczyk hierarchy.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 10:38:06 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Fujita", "Ken-etsu", "", "Gunma University"]]}, {"id": "1701.01413", "submitter": "Matthieu Perrinel M.", "authors": "Matthieu Perrinel", "title": "Paths-based criteria and application to linear logic subsystems\n  characterizing polynomial time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several variants of linear logic have been proposed to characterize\ncomplexity classes in the proofs-as-programs correspondence. Light linear logic\n(LLL) ensures a polynomial bound on reduction time, and characterizes in this\nway polynomial time (Ptime). In this paper we study the complexity of linear\nlogic proof-nets and propose three semantic criteria based on context\nsemantics: stratification, dependence control and nesting. Stratification alone\nentails an elementary time bound, the three criteria entail together a\npolynomial time bound.\n  These criteria can be used to prove the complexity soundness of several\nexisting variants of linear logic. We define a decidable syntactic subsystem of\nlinear logic: SDNLL. We prove that the proof-nets of SDNLL satisfy the three\ncriteria, which implies that SDNLL is sound for Ptime. Several previous\nsubsystems of linear logic characterizing polynomial time (LLL, mL^4, maximal\nsystem of MS) are embedded in SDNLL, proving its Ptime completeness.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 18:25:37 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Perrinel", "Matthieu", ""]]}, {"id": "1701.01461", "submitter": "Florent Capelli", "authors": "Florent Capelli", "title": "Understanding the complexity of #SAT using knowledge compilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two main techniques have been used so far to solve the #P-hard problem #SAT.\nThe first one, used in practice, is based on an extension of DPLL for model\ncounting called exhaustive DPLL. The second approach, more theoretical,\nexploits the structure of the input to compute the number of satisfying\nassignments by usually using a dynamic programming scheme on a decomposition of\nthe formula. In this paper, we make a first step toward the separation of these\ntwo techniques by exhibiting a family of formulas that can be solved in\npolynomial time with the first technique but needs an exponential time with the\nsecond one. We show this by observing that both techniques implicitely\nconstruct a very specific boolean circuit equivalent to the input formula. We\nthen show that every beta-acyclic formula can be represented by a polynomial\nsize circuit corresponding to the first method and exhibit a family of\nbeta-acyclic formulas which cannot be represented by polynomial size circuits\ncorresponding to the second method. This result shed a new light on the\ncomplexity of #SAT and related problems on beta-acyclic formulas. As a\nbyproduct, we give new handy tools to design algorithms on beta-acyclic\nhypergraphs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 19:48:01 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Capelli", "Florent", ""]]}, {"id": "1701.01483", "submitter": "Anindya De", "authors": "Anindya De and Elchanan Mossel and Joe Neeman", "title": "Noise Stability is computable and low dimensional", "comments": "Minor edits made. Also, application to non-interactive simulation is\n  removed from this paper and completely subsumed by arXiv:1701.01485 [cs.CC]", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Questions of noise stability play an important role in hardness of\napproximation in computer science as well as in the theory of voting. In many\napplications, the goal is to find an optimizer of noise stability among all\npossible partitions of $\\mathbb{R}^n$ for $n \\geq 1$ to $k$ parts with given\nGaussian measures $\\mu_1,\\ldots,\\mu_k$. We call a partition $\\epsilon$-optimal,\nif its noise stability is optimal up to an additive $\\epsilon$. In this paper,\nwe give an explicit, computable function $n(\\epsilon)$ such that an\n$\\epsilon$-optimal partition exists in $\\mathbb{R}^{n(\\epsilon)}$. This result\nhas implications for the computability of certain problems in non-interactive\nsimulation, which are addressed in a subsequent work.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 21:26:30 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 19:46:36 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["De", "Anindya", ""], ["Mossel", "Elchanan", ""], ["Neeman", "Joe", ""]]}, {"id": "1701.01485", "submitter": "Anindya De", "authors": "Anindya De and Elchanan Mossel and Joe Neeman", "title": "Non interactive simulation of correlated distributions is decidable", "comments": "The reduction for non-interactive simulation for general source\n  distribution to the Gaussian case was incorrect in the previous version. It\n  has been rectified now", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic problem in information theory is the following: Let $\\mathbf{P} =\n(\\mathbf{X}, \\mathbf{Y})$ be an arbitrary distribution where the marginals\n$\\mathbf{X}$ and $\\mathbf{Y}$ are (potentially) correlated. Let Alice and Bob\nbe two players where Alice gets samples $\\{x_i\\}_{i \\ge 1}$ and Bob gets\nsamples $\\{y_i\\}_{i \\ge 1}$ and for all $i$, $(x_i, y_i) \\sim \\mathbf{P}$. What\njoint distributions $\\mathbf{Q}$ can be simulated by Alice and Bob without any\ninteraction?\n  Classical works in information theory by G{\\'a}cs-K{\\\"o}rner and Wyner answer\nthis question when at least one of $\\mathbf{P}$ or $\\mathbf{Q}$ is the\ndistribution on $\\{0,1\\} \\times \\{0,1\\}$ where each marginal is unbiased and\nidentical. However, other than this special case, the answer to this question\nis understood in very few cases. Recently, Ghazi, Kamath and Sudan showed that\nthis problem is decidable for $\\mathbf{Q}$ supported on $\\{0,1\\} \\times\n\\{0,1\\}$. We extend their result to $\\mathbf{Q}$ supported on any finite\nalphabet.\n  We rely on recent results in Gaussian geometry (by the authors) as well as a\nnew \\emph{smoothing argument} inspired by the method of \\emph{boosting} from\nlearning theory and potential function arguments from complexity theory and\nadditive combinatorics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 21:31:56 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 19:52:21 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["De", "Anindya", ""], ["Mossel", "Elchanan", ""], ["Neeman", "Joe", ""]]}, {"id": "1701.01717", "submitter": "Joshua Grochow", "authors": "Joshua A. Grochow and Mrinal Kumar and Michael Saks and Shubhangi\n  Saraf", "title": "Towards an algebraic natural proofs barrier via polynomial identity\n  testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe that a certain kind of algebraic proof - which covers essentially\nall known algebraic circuit lower bounds to date - cannot be used to prove\nlower bounds against VP if and only if what we call succinct hitting sets exist\nfor VP. This is analogous to the Razborov-Rudich natural proofs barrier in\nBoolean circuit complexity, in that we rule out a large class of lower bound\ntechniques under a derandomization assumption. We also discuss connections\nbetween this algebraic natural proofs barrier, geometric complexity theory, and\n(algebraic) proof complexity.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2017 18:27:48 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Grochow", "Joshua A.", ""], ["Kumar", "Mrinal", ""], ["Saks", "Michael", ""], ["Saraf", "Shubhangi", ""]]}, {"id": "1701.01939", "submitter": "Juho Lauri", "authors": "Marzio De Biasi, Juho Lauri", "title": "On the Complexity of Restoring Corrupted Colorings", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the \\probrFix problem, we are given a graph $G$, a (non-proper)\nvertex-coloring $c : V(G) \\to [r]$, and a positive integer $k$. The goal is to\ndecide whether a proper $r$-coloring $c'$ is obtainable from $c$ by recoloring\nat most $k$ vertices of $G$. Recently, Junosza-Szaniawski, Liedloff, and\nRz{\\k{a}}{\\.z}ewski [SOFSEM 2015] asked whether the problem has a polynomial\nkernel parameterized by the number of recolorings $k$. In a full version of the\nmanuscript, the authors together with Garnero and Montealegre, answered the\nquestion in the negative: for every $r \\geq 3$, the problem \\probrFix does not\nadmit a polynomial kernel unless $\\NP \\subseteq \\coNP / \\poly$. Independently\nof their work, we give an alternative proof of the theorem. Furthermore, we\nstudy the complexity of \\probrFixSwap, where the only difference from \\probrFix\nis that instead of $k$ recolorings we have a budget of $k$ color swaps. We show\nthat for every $r \\geq 3$, the problem \\probrFixSwap is $\\W[1]$-hard whereas\n\\probrFix is known to be FPT. Moreover, when $r$ is part of the input, we\nobserve both \\probFix and \\probFixSwap are $\\W[1]$-hard parameterized by\ntreewidth. We also study promise variants of the problems, where we are\nguaranteed that a proper $r$-coloring $c'$ is indeed obtainable from $c$ by\nsome finite number of swaps. For instance, we prove that for $r=3$, the\nproblems \\probrFixPromise and \\probrFixSwapPromise are $\\NP$-hard for planar\ngraphs. As a consequence of our reduction, the problems cannot be solved in\n$2^{o(\\sqrt{n})}$ time unless the Exponential Time Hypothesis (ETH) fails.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 10:43:55 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["De Biasi", "Marzio", ""], ["Lauri", "Juho", ""]]}, {"id": "1701.02062", "submitter": "Dave Touchette", "authors": "Mathieu Lauriere, Dave Touchette", "title": "The Flow of Information in Interactive Quantum Protocols: the Cost of\n  Forgetting", "comments": "v1, 39 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of two-party interactive quantum communication protocols, we\nstudy a recently defined notion of quantum information cost (QIC), which\npossesses most of the important properties of its classical analogue. Although\nthis definition has the advantage to be valid for fully quantum inputs and\ntasks, its interpretation for classical tasks remained rather obscure. Also,\nthe link between this new notion and other notions of information cost for\nquantum protocols that had previously appeared in the literature was not clear,\nif existent at all.\n  We settle both these issues: for quantum communication with classical inputs,\nwe provide an alternate characterization of QIC in terms of information about\nthe input registers, avoiding any reference to the notion of a purification of\nthe classical input state. We provide an exact operational interpretation of\nthis alternative characterization as the sum of the cost of transmitting\ninformation about the classical inputs and the cost of forgetting information\nabout these inputs. To obtain this characterization, we prove a general lemma,\nthe Information Flow Lemma, assessing exactly the transfer of information in\ngeneral interactive quantum processes. Furthermore, we clarify the link between\nQIC and IC of classical protocols by simulating quantumly classical protocols.\n  Finally, we apply these concepts to argue that any quantum protocol that does\nnot forget information solves Disjointness on n-bits in Omega (n)\ncommunication, completely losing the quadratic quantum speedup. This provides a\nspecific sense in which forgetting information is a necessary feature of\ninteractive quantum protocols. We also apply these concepts to prove that QIC\nat zero-error is exactly n for the Inner Product function, and n (1 - o(1)) for\na random Boolean function on n+n bits.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 04:40:02 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Lauriere", "Mathieu", ""], ["Touchette", "Dave", ""]]}, {"id": "1701.02162", "submitter": "Amaury Pouly", "authors": "Nathana\\\"el Fijalkow, Pierre Ohlmann, Jo\\\"el Ouaknine, Amaury Pouly,\n  James Worrell", "title": "Semialgebraic Invariant Synthesis for the Kannan-Lipton Orbit Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO cs.SC math.AG math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\emph{Orbit Problem} consists of determining, given a linear\ntransformation $A$ on $\\mathbb{Q}^d$, together with vectors $x$ and $y$,\nwhether the orbit of $x$ under repeated applications of $A$ can ever reach $y$.\nThis problem was famously shown to be decidable by Kannan and Lipton in the\n1980s.\n  In this paper, we are concerned with the problem of synthesising suitable\n\\emph{invariants} $\\mathcal{P} \\subseteq \\mathbb{R}^d$, \\emph{i.e.}, sets that\nare stable under $A$ and contain $x$ and not $y$, thereby providing compact and\nversatile certificates of non-reachability. We show that whether a given\ninstance of the Orbit Problem admits a semialgebraic invariant is decidable,\nand moreover in positive instances we provide an algorithm to synthesise\nsuitable invariants of polynomial size.\n  It is worth noting that the existence of \\emph{semilinear} invariants, on the\nother hand, is (to the best of our knowledge) not known to be decidable.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 13:00:53 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", ""], ["Ohlmann", "Pierre", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Pouly", "Amaury", ""], ["Worrell", "James", ""]]}, {"id": "1701.02188", "submitter": "Barnaby Martin", "authors": "Petr Golovach, Matthew Johnson. Barnaby Martin, Daniel Paulusma and\n  Anthony Stewart", "title": "Surjective H-Colouring: New Hardness Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A homomorphism from a graph G to a graph H is a vertex mapping f from the\nvertex set of G to the vertex set of H such that there is an edge between\nvertices f(u) and f(v) of H whenever there is an edge between vertices u and v\nof G. The H-Colouring problem is to decide whether or not a graph G allows a\nhomomorphism to a fixed graph H. We continue a study on a variant of this\nproblem, namely the Surjective H-Colouring problem, which imposes the\nhomomorphism to be vertex-surjective. We build upon previous results and show\nthat this problem is NP-complete for every connected graph H that has exactly\ntwo vertices with a self-loop as long as these two vertices are not adjacent.\nAs a result, we can classify the computational complexity of Surjective\nH-Colouring for every graph H on at most four vertices.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 14:17:28 GMT"}, {"version": "v2", "created": "Sun, 26 Mar 2017 15:31:15 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Golovach", "Petr", ""], ["Martin", "Matthew Johnson. Barnaby", ""], ["Paulusma", "Daniel", ""], ["Stewart", "Anthony", ""]]}, {"id": "1701.02231", "submitter": "Thorsten Wissmann", "authors": "Cristina Feier and Antti Kuusisto and Carsten Lutz", "title": "Rewritability in Monadic Disjunctive Datalog, MMSNP, and Expressive\n  Description Logics", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 2 (May 23,\n  2019) lmcs:5502", "doi": "10.23638/LMCS-15(2:15)2019", "report-no": null, "categories": "cs.LO cs.CC cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study rewritability of monadic disjunctive Datalog programs, (the\ncomplements of) MMSNP sentences, and ontology-mediated queries (OMQs) based on\nexpressive description logics of the ALC family and on conjunctive queries. We\nshow that rewritability into FO and into monadic Datalog (MDLog) are decidable,\nand that rewritability into Datalog is decidable when the original query\nsatisfies a certain condition related to equality. We establish\n2NExpTime-completeness for all studied problems except rewritability into MDLog\nfor which there remains a gap between 2NExpTime and 3ExpTime. We also analyze\nthe shape of rewritings, which in the MMSNP case correspond to obstructions,\nand give a new construction of canonical Datalog programs that is more\nelementary than existing ones and also applies to formulas with free variables.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 18:17:15 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 13:13:21 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 17:23:18 GMT"}, {"version": "v4", "created": "Wed, 22 May 2019 06:03:13 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Feier", "Cristina", ""], ["Kuusisto", "Antti", ""], ["Lutz", "Carsten", ""]]}, {"id": "1701.02274", "submitter": "Florian Steinberg", "authors": "Matthias Schr\\\"oder and Florian Steinberg", "title": "Bounded time computation on metric spaces and Banach spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the framework by Kawamura and Cook for investigating computational\ncomplexity for operators occurring in analysis. This model is based on\nsecond-order complexity theory for functions on the Baire space, which is\nlifted to metric spaces by means of representations. Time is measured in terms\nof the length of the input encodings and the required output precision. We\npropose the notions of a complete representation and of a regular\nrepresentation. We show that complete representations ensure that any\ncomputable function has a time bound. Regular representations generalize\nKawamura and Cook's more restrictive notion of a second-order representation,\nwhile still guaranteeing fast computability of the length of the encodings.\nApplying these notions, we investigate the relationship between purely metric\nproperties of a metric space and the existence of a representation such that\nthe metric is computable within bounded time. We show that a bound on the\nrunning time of the metric can be straightforwardly translated into size bounds\nof compact subsets of the metric space. Conversely, for compact spaces and for\nBanach spaces we construct a family of admissible, complete, regular\nrepresentations that allow for fast computation of the metric and provide short\nencodings. Here it is necessary to trade the time bound off against the length\nof encodings.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 17:42:12 GMT"}, {"version": "v2", "created": "Wed, 29 Mar 2017 16:18:40 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Schr\u00f6der", "Matthias", ""], ["Steinberg", "Florian", ""]]}, {"id": "1701.02302", "submitter": "Greg Yang", "authors": "Greg Yang", "title": "A Homological Theory of Functions", "comments": "72 pages, 22 figures. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AC cs.CC cs.DM cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computational complexity, a complexity class is given by a set of problems\nor functions, and a basic challenge is to show separations of complexity\nclasses $A \\not= B$ especially when $A$ is known to be a subset of $B$. In this\npaper we introduce a homological theory of functions that can be used to\nestablish complexity separations, while also providing other interesting\nconsequences. We propose to associate a topological space $S_A$ to each class\nof functions $A$, such that, to separate complexity classes $A \\subseteq B'$,\nit suffices to observe a change in \"the number of holes\", i.e. homology, in\n$S_A$ as a subclass $B$ of $B'$ is added to $A$. In other words, if the\nhomologies of $S_A$ and $S_{A \\cup B}$ are different, then $A \\not= B'$. We\ndevelop the underlying theory of functions based on combinatorial and\nhomological commutative algebra and Stanley-Reisner theory, and recover Minsky\nand Papert's 1969 result that parity cannot be computed by nonmaximal degree\npolynomial threshold functions. In the process, we derive a \"maximal principle\"\nfor polynomial threshold functions that is used to extend this result further\nto arbitrary symmetric functions. A surprising coincidence is demonstrated,\nwhere the maximal dimension of \"holes\" in $S_A$ upper bounds the VC dimension\nof $A$, with equality for common computational cases such as the class of\npolynomial threshold functions or the class of linear functionals in $\\mathbb\nF_2$, or common algebraic cases such as when the Stanley-Reisner ring of $S_A$\nis Cohen-Macaulay. As another interesting application of our theory, we prove a\nresult that a priori has nothing to do with complexity separation: it\ncharacterizes when a vector subspace intersects the positive cone, in terms of\nhomological conditions. By analogy to Farkas' result doing the same with\n*linear conditions*, we call our theorem the Homological Farkas Lemma.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 18:58:27 GMT"}, {"version": "v2", "created": "Sat, 14 Jan 2017 19:09:32 GMT"}, {"version": "v3", "created": "Thu, 6 Apr 2017 07:30:15 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Yang", "Greg", ""]]}, {"id": "1701.02374", "submitter": "Guangmo Tong", "authors": "Guangmo Tong, Weili Wu and Ding-Zhu Du", "title": "On Rivest-Vuillemin Conjecture for Fourteen Variables", "comments": "A technique report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A boolean function $f(x_1,...,x_n)$ is \\textit{weakly symmetric} if it is\ninvariant under a transitive permutation group on its variables. A boolean\nfunction $f(x_1,...,x_n)$ is \\textit{elusive} if we have to check all\n$x_1$,..., $x_n$ to determine the output of $f(x_1,...,x_n)$ in the worst-case.\nIt is conjectured that every nontrivial monotone weakly symmetric boolean\nfunction is elusive, which has been open for a long time. In this paper, we\nreport that this conjecture is true for $n=14$.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 22:08:15 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Tong", "Guangmo", ""], ["Wu", "Weili", ""], ["Du", "Ding-Zhu", ""]]}, {"id": "1701.02401", "submitter": "Jiang Liu", "authors": "Chengling Fang and Jiang Liu", "title": "A Linear Algebra Formulation for Boolean Satisfiability Testing", "comments": "Two algorithms for SAT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the article \\The State of SAT\", the authors asked whether a procedure\ndramatically different from DPLL can be found for handling unsatisfiable\ninstances. This study proposes a new linear programming approach to address\nthis issue efficiently. Our experiments showed that the new method works for\nmany unsatisfiable instances. However, we must concede that this method should\nbe incomplete; otherwise, it will imply P=co-NP.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 01:16:14 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 03:23:22 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Fang", "Chengling", ""], ["Liu", "Jiang", ""]]}, {"id": "1701.02409", "submitter": "Arash Rafiey", "authors": "Tom\\'as Feder, Jeff Kinne, Ashwin Murali, Arash Rafiey", "title": "Dichotomy for Digraph Homomorphism Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding a homomorphism from an input digraph $G$\nto a fixed digraph $H$. We show that if $H$ admits a weak-near-unanimity\npolymorphism $\\phi$ then deciding whether $G$ admits a homomorphism to $H$\n(HOM($H$)) is polynomial time solvable? This gives a proof of the dichotomy\nconjecture (now dichotomy theorem) by Feder and Vardi [29]. Our approach is\ncombinatorial, and it is simpler than the two algorithms found by Bulatov [9]\nand Zhuk [46] in 2017. We have implemented our algorithm and show some\nexperimental results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 02:07:33 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2017 03:09:48 GMT"}, {"version": "v3", "created": "Sat, 1 Jul 2017 13:36:10 GMT"}, {"version": "v4", "created": "Sat, 29 Jul 2017 00:00:44 GMT"}, {"version": "v5", "created": "Sun, 9 Aug 2020 21:37:47 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Feder", "Tom\u00e1s", ""], ["Kinne", "Jeff", ""], ["Murali", "Ashwin", ""], ["Rafiey", "Arash", ""]]}, {"id": "1701.02764", "submitter": "Yaroslav Shitov", "authors": "Yaroslav Shitov", "title": "Column subset selection is NP-complete", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $M$ be a real $r\\times c$ matrix and let $k$ be a positive integer. In\nthe column subset selection problem (CSSP), we need to minimize the quantity\n$\\|M-SA\\|$, where $A$ can be an arbitrary $k\\times c$ matrix, and $S$ runs over\nall $r\\times k$ submatrices of $M$. This problem and its applications in\nnumerical linear algebra are being discussed for several decades, but its\nalgorithmic complexity remained an open issue. We show that CSSP is\nNP-complete.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 19:40:09 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Shitov", "Yaroslav", ""]]}, {"id": "1701.02996", "submitter": "Ventsislav Chonev", "authors": "Ventsislav Chonev", "title": "Reachability in Augmented Interval Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose augmented interval Markov chains (AIMCs): a\ngeneralisation of the familiar interval Markov chains (IMCs) where uncertain\ntransition probabilities are in addition allowed to depend on one another. This\nnew model preserves the flexibility afforded by IMCs for describing stochastic\nsystems where the parameters are unclear, for example due to measurement error,\nbut also allows us to specify transitions with probabilities known to be\nidentical, thereby lending further expressivity.\n  The focus of this paper is reachability in AIMCs. We study the qualitative,\nexact quantitative and approximate reachability problem, as well as natural\nsubproblems thereof, and establish several upper and lower bounds for their\ncomplexity. We prove the exact reachability problem is at least as hard as the\nfamous square-root sum problem, but, encouragingly, the approximate version\nlies in $\\mathbf{NP}$ if the underlying graph is known, whilst the restriction\nof the exact problem to a constant number of uncertain edges is in\n$\\mathbf{P}$. Finally, we show that uncertainty in the graph structure affects\ncomplexity by proving $\\mathbf{NP}$-completeness for the qualitative\nsubproblem, in contrast with an easily-obtained upper bound of $\\mathbf{P}$ for\nthe same subproblem with known graph structure.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2017 14:57:30 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Chonev", "Ventsislav", ""]]}, {"id": "1701.03255", "submitter": "Sunil K. S.", "authors": "Balagopal Komarath, Jayalal Sarma, K. S. Sunil", "title": "On the Complexity of L-reachability", "comments": "14 pages, 4 figures, Published in Fundamenta Informaticae", "journal-ref": "Fundam. Inform., volume 145, number 4, pages 471-483 (2016)", "doi": "10.3233/FI-2016-1371", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a complexity theoretic study of the language based graph\nreachability problem (L-REACH) : Fix a language L. Given a graph whose edges\nare labeled with alphabet symbols of the language L and two special vertices s\nand t, test if there is path P from s to t in the graph such that the\nconcatenation of the symbols seen from s to t in the path P forms a string in\nthe language L. We study variants of this problem with different graph classes\nand different language classes and obtain complexity theoretic\ncharacterizations for all of them. Our main results are the following:\n1.Restricting the language using formal language theory we show that the\ncomplexity of L-REACH increases with the power of the formal language class. We\nshow that there is a regular language for which the L-REACH is NL-complete even\nfor undirected graphs. In the case of linear languages, the complexity of\nL-REACH does not go beyond the complexity of L itself. Further, there is a\ndeterministic context-free language L for which L-DAGREACH is LogCFL-complete.\n2.We use L-REACH as a lens to study structural complexity. In this direction we\nshow that there is a language A in TC0 for which A-DAGREACH is NP-complete.\nUsing this we show that P vs NP question is equivalent to P vs DAGREACH-1(P)\nquestion. This leads to the intriguing possibility that by proving\nDAGREACH-1(P) is contained in some subclass of P, we can prove an upward\ntranslation of separation of complexity classes. Note that we do not know a way\nto upward translate the separation of complexity classes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 06:47:46 GMT"}], "update_date": "2017-01-13", "authors_parsed": [["Komarath", "Balagopal", ""], ["Sarma", "Jayalal", ""], ["Sunil", "K. S.", ""]]}, {"id": "1701.03297", "submitter": "Murray Elder", "authors": "Volker Diekert and Murray Elder", "title": "Solutions to twisted word equations and equations in virtually free\n  groups", "comments": "70 pages, 13 figures. An extended abstract of a preliminary version\n  of this paper was presented at ICALP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the problem solving equations in virtually free groups\ncan be reduced to the problem of solving twisted word equations with regular\nconstraints over free monoids with involution. In this paper we prove that the\nset of all solutions of a twisted word equation is an EDT0L language whose\nspecification can be computed in $\\mathsf{PSPACE}$. Within the same complexity\nbound we can decide whether the solution set is empty, finite, or infinite.\n  In the second part of the paper we apply the results for twisted equations to\nobtain in $\\mathsf{PSPACE}$ an EDT0L description of the solution set of\nequations with rational constraints for finitely generated virtually free\ngroups in standard normal forms with respect to a natural set of generators. If\nthe rational constraints are given by a homomorphism into a fixed (or \"small\nenough\") finite monoid, then our algorithms can be implemented in\n$\\mathsf{NSPACE}(n^2\\log n)$, that is, in quasi-quadratic nondeterministic\nspace.\n  Our results generalize the work by Lohrey and S\\'enizergues (ICALP 2006) and\nDahmani and Guirardel (J. of Topology 2010) with respect to both complexity and\nexpressive power. Neither paper gave any concrete complexity bound and the\nresults in these papers are stated for subsets of solutions only, whereas our\nresults concern all solutions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 10:51:33 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 07:32:48 GMT"}, {"version": "v3", "created": "Sun, 18 Aug 2019 01:31:16 GMT"}, {"version": "v4", "created": "Tue, 20 Aug 2019 08:22:35 GMT"}, {"version": "v5", "created": "Sun, 1 Dec 2019 22:03:26 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Diekert", "Volker", ""], ["Elder", "Murray", ""]]}, {"id": "1701.03990", "submitter": "Shih-Han Hung", "authors": "Jianxin Chen, Andrew M. Childs, Shih-Han Hung", "title": "Quantum algorithm for multivariate polynomial interpolation", "comments": "15 pages, 0 figures. Comments are welcome", "journal-ref": "Proceedings of the Royal Society A 474: 20170480 (2017)", "doi": "10.1098/rspa.2017.0480", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many quantum queries are required to determine the coefficients of a\ndegree-$d$ polynomial in $n$ variables? We present and analyze quantum\nalgorithms for this multivariate polynomial interpolation problem over the\nfields $\\mathbb{F}_q$, $\\mathbb{R}$, and $\\mathbb{C}$. We show that\n$k_{\\mathbb{C}}$ and $2k_{\\mathbb{C}}$ queries suffice to achieve probability\n$1$ for $\\mathbb{C}$ and $\\mathbb{R}$, respectively, where\n$k_{\\mathbb{C}}=\\smash{\\lceil\\frac{1}{n+1}{n+d\\choose d}\\rceil}$ except for\n$d=2$ and four other special cases. For $\\mathbb{F}_q$, we show that\n$\\smash{\\lceil\\frac{d}{n+d}{n+d\\choose d}\\rceil}$ queries suffice to achieve\nprobability approaching $1$ for large field order $q$. The classical query\ncomplexity of this problem is $\\smash{n+d\\choose d}$, so our result provides a\nspeedup by a factor of $n+1$, $\\frac{n+1}{2}$, and $\\frac{n+d}{d}$ for\n$\\mathbb{C}$, $\\mathbb{R}$, and $\\mathbb{F}_q$, respectively. Thus we find a\nmuch larger gap between classical and quantum algorithms than the univariate\ncase, where the speedup is by a factor of $2$. For the case of $\\mathbb{F}_q$,\nwe conjecture that $2k_{\\mathbb{C}}$ queries also suffice to achieve\nprobability approaching $1$ for large field order $q$, although we leave this\nas an open problem.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 04:07:40 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 17:57:43 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Chen", "Jianxin", ""], ["Childs", "Andrew M.", ""], ["Hung", "Shih-Han", ""]]}, {"id": "1701.04086", "submitter": "Barnaby Martin", "authors": "Catarina Carvalho, Barnaby Martin and Dmitriy Zhuk", "title": "The complexity of quantified constraints using the algebraic formulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let A be an idempotent algebra on a finite domain. We combine results of\nChen, Zhuk and Carvalho et al. to argue that if A satisfies the polynomially\ngenerated powers property (PGP), then QCSP(Inv(A)) is in NP. We then use the\nresult of Zhuk to prove a converse, that if QCSP(Inv(A)) satisfies the\nexponentially generated powers property (EGP), then QCSP(Inv(A)) is co-NP-hard.\nSince Zhuk proved that only PGP and EGP are possible, we derive a full\ndichotomy for the QCSP, justifying the moral correctness of what we term the\nChen Conjecture.\n  We examine in closer detail the situation for domains of size three. Over any\nfinite domain, the only type of PGP that can occur is switchability.\nSwitchability was introduced by Chen as a generalisation of the already-known\nCollapsibility. For three-element domain algebras A that are Switchable, we\nprove that for every finite subset Delta of Inv(A), Pol(Delta) is Collapsible.\nThe significance of this is that, for QCSP on finite structures (over\nthree-element domain), all QCSP tractability explained by Switchability is\nalready explained by Collapsibility.\n  Finally, we present a three-element domain complexity classification\nvignette, using known as well as derived results.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 17:54:19 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 13:05:46 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Carvalho", "Catarina", ""], ["Martin", "Barnaby", ""], ["Zhuk", "Dmitriy", ""]]}, {"id": "1701.04108", "submitter": "Neil Lutz", "authors": "Neil Lutz and D. M. Stull", "title": "Dimension Spectra of Lines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the algorithmic dimension spectra of lines in the\nEuclidean plane. Given any line L with slope a and vertical intercept b, the\ndimension spectrum sp(L) is the set of all effective Hausdorff dimensions of\nindividual points on L. We draw on Kolmogorov complexity and geometrical\narguments to show that if the effective Hausdorff dimension dim(a, b) is equal\nto the effective packing dimension Dim(a, b), then sp(L) contains a unit\ninterval. We also show that, if the dimension dim(a, b) is at least one, then\nsp(L) is infinite. Together with previous work, this implies that the dimension\nspectrum of any line is infinite.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 20:43:11 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Lutz", "Neil", ""], ["Stull", "D. M.", ""]]}, {"id": "1701.04341", "submitter": "Pablo Solerno", "authors": "Amir Hashemi, Joos Heintz, Luis Miguel Pardo, Pablo Solern\\'o", "title": "On Bezout Inequalities for non-homogeneous Polynomial Ideals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC math.AC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a \"workable\" notion of degree for non-homogeneous polynomial\nideals and formulate and prove ideal theoretic B\\'ezout Inequalities for the\nsum of two ideals in terms of this notion of degree and the degree of\ngenerators. We compute probabilistically the degree of an equidimensional\nideal.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 15:59:40 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Hashemi", "Amir", ""], ["Heintz", "Joos", ""], ["Pardo", "Luis Miguel", ""], ["Solern\u00f3", "Pablo", ""]]}, {"id": "1701.04428", "submitter": "Donald Stull", "authors": "D. M. Stull", "title": "Some Results on Circuit Lower Bounds and Derandomization of\n  Arthur-Merlin Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a downward separation for $\\mathsf{\\Sigma}_2$-time classes.\nSpecifically, we prove that if $\\Sigma_2$E does not have polynomial size\nnon-deterministic circuits, then $\\Sigma_2$SubEXP does not have \\textit{fixed}\npolynomial size non-deterministic circuits. To achieve this result, we use\nSanthanam's technique on augmented Arthur-Merlin protocols defined by\nAydinlio\\u{g}lu and van Melkebeek. We show that augmented Arthur-Merlin\nprotocols with one bit of advice do not have fixed polynomial size\nnon-deterministic circuits. We also prove a weak unconditional derandomization\nof a certain type of promise Arthur-Merlin protocols. Using Williams' easy\nhitting set technique, we show that $\\Sigma_2$-promise AM problems can be\ndecided in $\\Sigma_2$SubEXP with $n^c$ advice, for some fixed constant $c$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 19:20:42 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Stull", "D. M.", ""]]}, {"id": "1701.04521", "submitter": "Ryan O'Donnell", "authors": "Pravesh K. Kothari and Ryuhei Mori and Ryan O'Donnell and David Witmer", "title": "Sum of squares lower bounds for refuting any CSP", "comments": "39 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P:\\{0,1\\}^k \\to \\{0,1\\}$ be a nontrivial $k$-ary predicate. Consider a\nrandom instance of the constraint satisfaction problem $\\mathrm{CSP}(P)$ on $n$\nvariables with $\\Delta n$ constraints, each being $P$ applied to $k$ randomly\nchosen literals. Provided the constraint density satisfies $\\Delta \\gg 1$, such\nan instance is unsatisfiable with high probability. The \\emph{refutation}\nproblem is to efficiently find a proof of unsatisfiability.\n  We show that whenever the predicate $P$ supports a $t$-\\emph{wise uniform}\nprobability distribution on its satisfying assignments, the sum of squares\n(SOS) algorithm of degree $d = \\Theta(\\frac{n}{\\Delta^{2/(t-1)} \\log \\Delta})$\n(which runs in time $n^{O(d)}$) \\emph{cannot} refute a random instance of\n$\\mathrm{CSP}(P)$. In particular, the polynomial-time SOS algorithm requires\n$\\widetilde{\\Omega}(n^{(t+1)/2})$ constraints to refute random instances of\nCSP$(P)$ when $P$ supports a $t$-wise uniform distribution on its satisfying\nassignments. Together with recent work of Lee et al. [LRS15], our result also\nimplies that \\emph{any} polynomial-size semidefinite programming relaxation for\nrefutation requires at least $\\widetilde{\\Omega}(n^{(t+1)/2})$ constraints.\n  Our results (which also extend with no change to CSPs over larger alphabets)\nsubsume all previously known lower bounds for semialgebraic refutation of\nrandom CSPs. For every constraint predicate~$P$, they give a three-way hardness\ntradeoff between the density of constraints, the SOS degree (hence running\ntime), and the strength of the refutation. By recent algorithmic results of\nAllen et al. [AOW15] and Raghavendra et al. [RRS16], this full three-way\ntradeoff is \\emph{tight}, up to lower-order factors.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 03:36:34 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Kothari", "Pravesh K.", ""], ["Mori", "Ryuhei", ""], ["O'Donnell", "Ryan", ""], ["Witmer", "David", ""]]}, {"id": "1701.04522", "submitter": "EPTCS", "authors": "Iliano Cervesato, Maribel Fern\\'andez", "title": "Proceedings Fourth International Workshop on Linearity", "comments": null, "journal-ref": "EPTCS 238, 2017", "doi": "10.4204/EPTCS.238", "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers presented at LINEARITY 2016, the Fourth\nInternational Workshop on Linearity, held on June 26, 2016 in Porto, Portugal.\nThe workshop was a one-day satellite event of FSCD 2016, the first\nInternational Conference on Formal Structures for Computation and Deduction.\n  The aim of this workshop was to bring together researchers who are developing\ntheory and applications of linear calculi, to foster their interaction and\nprovide a forum for presenting new ideas and work in progress, and enable\nnewcomers to learn about current activities in this area. Of interest were new\nresults that made a central use of linearity, ranging from foundational work to\napplications in any field. This included: sub-linear logics, linear term\ncalculi, linear type systems, linear proof-theory, linear programming\nlanguages, applications to concurrency, interaction-based systems, verification\nof linear systems, and biological and chemical models of computation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 03:45:13 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Cervesato", "Iliano", ""], ["Fern\u00e1ndez", "Maribel", ""]]}, {"id": "1701.05328", "submitter": "Ben Lee Volk", "authors": "Michael A. Forbes, Amir Shpilka, Ben Lee Volk", "title": "Succinct Hitting Sets and Barriers to Proving Algebraic Circuits Lower\n  Bounds", "comments": "Fixed typos and other small errors; added references to follow-up\n  work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize a framework of algebraically natural lower bounds for algebraic\ncircuits. Just as with the natural proofs notion of Razborov and Rudich for\nboolean circuit lower bounds, our notion of algebraically natural lower bounds\ncaptures nearly all lower bound techniques known. However, unlike the boolean\nsetting, there has been no concrete evidence demonstrating that this is a\nbarrier to obtaining super-polynomial lower bounds for general algebraic\ncircuits, as there is little understanding whether algebraic circuits are\nexpressive enough to support \"cryptography\" secure against algebraic circuits.\n  Following a similar result of Williams in the boolean setting, we show that\nthe existence of an algebraic natural proofs barrier is equivalent to the\nexistence of succinct derandomization of the polynomial identity testing\nproblem. That is, whether the coefficient vectors of polylog(N)-degree\npolylog(N)-size circuits is a hitting set for the class of poly(N)-degree\npoly(N)-size circuits. Further, we give an explicit universal construction\nshowing that if such a succinct hitting set exists, then our universal\nconstruction suffices.\n  Further, we assess the existing literature constructing hitting sets for\nrestricted classes of algebraic circuits and observe that none of them are\nsuccinct as given. Yet, we show how to modify some of these constructions to\nobtain succinct hitting sets. This constitutes the first evidence supporting\nthe existence of an algebraic natural proofs barrier.\n  Our framework is similar to the Geometric Complexity Theory (GCT) program of\nMulmuley and Sohoni, except that here we emphasize constructiveness of the\nproofs while the GCT program emphasizes symmetry. Nevertheless, our succinct\nhitting sets have relevance to the GCT program as they imply lower bounds for\nthe complexity of the defining equations of polynomials computed by small\ncircuits.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 08:33:31 GMT"}, {"version": "v2", "created": "Sun, 22 Jul 2018 08:37:01 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Forbes", "Michael A.", ""], ["Shpilka", "Amir", ""], ["Volk", "Ben Lee", ""]]}, {"id": "1701.05378", "submitter": "Burak Civek", "authors": "Burak C. Civek and Suleyman S. Kozat", "title": "Efficient Implementation Of Newton-Raphson Methods For Sequential Data\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of sequential linear data prediction for real life\nbig data applications. The second order algorithms, i.e., Newton-Raphson\nMethods, asymptotically achieve the performance of the \"best\" possible linear\ndata predictor much faster compared to the first order algorithms, e.g., Online\nGradient Descent. However, implementation of these methods is not usually\nfeasible in big data applications because of the extremely high computational\nneeds. Regular implementation of the Newton-Raphson Methods requires a\ncomputational complexity in the order of $O(M^2)$ for an $M$ dimensional\nfeature vector, while the first order algorithms need only $O(M)$. To this end,\nin order to eliminate this gap, we introduce a highly efficient implementation\nreducing the computational complexity of the Newton-Raphson Methods from\nquadratic to linear scale. The presented algorithm provides the well-known\nmerits of the second order methods while offering the computational complexity\nof $O(M)$. We utilize the shifted nature of the consecutive feature vectors and\ndo not rely on any statistical assumptions. Therefore, both regular and fast\nimplementations achieve the same performance in the sense of mean square error.\nWe demonstrate the computational efficiency of our algorithm on real life\nsequential big datasets. We also illustrate that the presented algorithm is\nnumerically stable.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 11:34:17 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Civek", "Burak C.", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1701.05382", "submitter": "Cynthia Kop", "authors": "Cynthia Kop and Jakob Grue Simonsen", "title": "The Power of Non-Determinism in Higher-Order Implicit Complexity", "comments": "pre-edition version of a paper accepted for publication at ESOP'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the power of non-determinism in purely functional programming\nlanguages with higher-order types. Specifically, we consider cons-free programs\nof varying data orders, equipped with explicit non-deterministic choice.\nCons-freeness roughly means that data constructors cannot occur in function\nbodies and all manipulation of storage space thus has to happen indirectly\nusing the call stack.\n  While cons-free programs have previously been used by several authors to\ncharacterise complexity classes, the work on non-deterministic programs has\nalmost exclusively considered programs of data order 0. Previous work has shown\nthat adding explicit non-determinism to cons-free programs taking data of order\n0 does not increase expressivity; we prove that this - dramatically - is not\nthe case for higher data orders: adding non-determinism to programs with data\norder at least 1 allows for a characterisation of the entire class of\nelementary-time decidable sets.\n  Finally we show how, even with non-deterministic choice, the original\nhierarchy of characterisations is restored by imposing different restrictions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 12:01:51 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2017 15:37:00 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Kop", "Cynthia", ""], ["Simonsen", "Jakob Grue", ""]]}, {"id": "1701.05492", "submitter": "Martin Milani\\v{c}", "authors": "Ademir Hujdurovi\\'c, Edin Husi\\'c, Martin Milani\\v{c}, Romeo Rizzi and\n  Alexandru I. Tomescu", "title": "Perfect phylogenies via branchings in acyclic digraphs and a\n  generalization of Dilworth's theorem", "comments": "29 pages, 10 figures, extended abstract appeared in Proceedings of WG\n  2017, full paper accepted for publication in ACM Transactions on Algorithms", "journal-ref": null, "doi": "10.1145/3182178", "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in cancer genomics and following the work of\nHajirasouliha and Raphael (WABI 2014), Hujdurovi\\'c et al. (IEEE TCBB, to\nappear) introduced the minimum conflict-free row split (MCRS) problem: split\neach row of a given binary matrix into a bitwise OR of a set of rows so that\nthe resulting matrix corresponds to a perfect phylogeny and has the minimum\npossible number of rows among all matrices with this property. Hajirasouliha\nand Raphael also proposed the study of a similar problem, in which the task is\nto minimize the number of distinct rows of the resulting matrix. Hujdurovi\\'c\net al. proved that both problems are NP-hard, gave a related characterization\nof transitively orientable graphs, and proposed a polynomial-time heuristic\nalgorithm for the MCRS problem based on coloring cocomparability graphs.\n  We give new, more transparent formulations of the two problems, showing that\nthe problems are equivalent to two optimization problems on branchings in a\nderived directed acyclic graph. Building on these formulations, we obtain new\nresults on the two problems, including: (i) a strengthening of the heuristic by\nHujdurovi\\'c et al. via a new min-max result in digraphs generalizing\nDilworth's theorem, which may be of independent interest, (ii) APX-hardness\nresults for both problems, (iii) approximation algorithms, and (iv)\nexponential-time algorithms solving the two problems to optimality faster than\nthe na\\\"ive brute-force approach. Our work relates to several well studied\nnotions in combinatorial optimization: chain partitions in partially ordered\nsets, laminar hypergraphs, and (classical and weighted) colorings of graphs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 16:05:48 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 20:52:16 GMT"}, {"version": "v3", "created": "Sat, 27 Jan 2018 08:20:45 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Hujdurovi\u0107", "Ademir", ""], ["Husi\u0107", "Edin", ""], ["Milani\u010d", "Martin", ""], ["Rizzi", "Romeo", ""], ["Tomescu", "Alexandru I.", ""]]}, {"id": "1701.05955", "submitter": "Amirsina Torfi", "authors": "Amirsina Torfi, Sobhan Soleymani, Seyed Mehdi Iranmanesh, Hadi Kazemi,\n  Rouzbeh Asghari Shirvani, Vahid Tabataba Vakili", "title": "Polar Coding for Achieving the Capacity of Marginal Channels in\n  Nonbinary-Input Setting", "comments": "Accepted to be published in \"51th Conference on Information Sciences\n  and Systems\", Baltimore, Maryland", "journal-ref": "51th Annual Conference on Information Sciences and Systems (CISS),\n  1-6 (2017)", "doi": "10.1109/CISS.2017.7926162", "report-no": null, "categories": "cs.IT cs.CC cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving information-theoretic security using explicit coding scheme in\nwhich unlimited computational power for eavesdropper is assumed, is one of the\nmain topics is security consideration. It is shown that polar codes are\ncapacity achieving codes and have a low complexity in encoding and decoding. It\nhas been proven that polar codes reach to secrecy capacity in the binary-input\nwiretap channels in symmetric settings for which the wiretapper's channel is\ndegraded with respect to the main channel. The first task of this paper is to\npropose a coding scheme to achieve secrecy capacity in asymmetric\nnonbinary-input channels while keeping reliability and security conditions\nsatisfied. Our assumption is that the wiretap channel is stochastically\ndegraded with respect to the main channel and message distribution is\nunspecified. The main idea is to send information set over good channels for\nBob and bad channels for Eve and send random symbols for channels that are good\nfor both. In this scheme the frozen vector is defined over all possible choices\nusing polar codes ensemble concept. We proved that there exists a frozen vector\nfor which the coding scheme satisfies reliability and security conditions. It\nis further shown that uniform distribution of the message is the necessary\ncondition for achieving secrecy capacity.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2017 00:32:34 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2017 22:18:32 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Torfi", "Amirsina", ""], ["Soleymani", "Sobhan", ""], ["Iranmanesh", "Seyed Mehdi", ""], ["Kazemi", "Hadi", ""], ["Shirvani", "Rouzbeh Asghari", ""], ["Vakili", "Vahid Tabataba", ""]]}, {"id": "1701.06064", "submitter": "Marc Goerigk", "authors": "Andr\\'e Chassein and Marc Goerigk and Adam Kasperski and Pawe{\\l}\n  Zieli\\'nski", "title": "On Recoverable and Two-Stage Robust Selection Problems with Budgeted\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problem of selecting $p$ out of $n$ available items is\ndiscussed, such that their total cost is minimized. We assume that costs are\nnot known exactly, but stem from a set of possible outcomes.\n  Robust recoverable and two-stage models of this selection problem are\nanalyzed. In the two-stage problem, up to $p$ items is chosen in the first\nstage, and the solution is completed once the scenario becomes revealed in the\nsecond stage. In the recoverable problem, a set of $p$ items is selected in the\nfirst stage, and can be modified by exchanging up to $k$ items in the second\nstage, after a scenario reveals.\n  We assume that uncertain costs are modeled through bounded uncertainty sets,\ni.e., the interval uncertainty sets with an additional linear (budget)\nconstraint, in their discrete and continuous variants. Polynomial algorithms\nfor recoverable and two-stage selection problems with continuous bounded\nuncertainty, and compact mixed integer formulations in the case of discrete\nbounded uncertainty are constructed.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2017 18:11:46 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 14:51:36 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Chassein", "Andr\u00e9", ""], ["Goerigk", "Marc", ""], ["Kasperski", "Adam", ""], ["Zieli\u0144ski", "Pawe\u0142", ""]]}, {"id": "1701.06268", "submitter": "Abhishek Bhrushundi", "authors": "Abhishek Bhrushundi, Prahladh Harsha, and Srikanth Srinivasan", "title": "On polynomial approximations over $\\mathbb{Z}/2^k\\mathbb{Z}$", "comments": null, "journal-ref": "In Proc. 34th Symposium on Theoretical Aspects of Computer Science\n  (STACS) (Hannover, Germany, 8-11 March), volume 66 of LiPiCS, pages\n  12:1-12:12, 2017", "doi": "10.4230/LIPIcs.STACS.2017.12", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study approximation of Boolean functions by low-degree polynomials over\nthe ring $\\mathbb{Z}/2^k\\mathbb{Z}$. More precisely, given a Boolean function\n$F:\\{0,1\\}^n \\rightarrow \\{0,1\\}$, define its $k$-lift to be $F_k:\\{0,1\\}^n\n\\rightarrow \\{0,2^{k-1}\\}$ by $F_k(x) = 2^{k-F(x)} \\pmod {2^k}$. We consider\nthe fractional agreement (which we refer to as $\\gamma_{d,k}(F)$) of $F_k$ with\ndegree $d$ polynomials from $\\mathbb{Z}/2^k\\mathbb{Z}[x_1,\\ldots,x_n]$. Our\nresults are the following:\n  - Increasing $k$ can help: We observe that as $k$ increases,\n$\\gamma_{d,k}(F)$ cannot decrease. We give two kinds of examples where\n$\\gamma_{d,k}(F)$ actually increases. The first is an infinite family of\nfunctions $F$ such that $\\gamma_{2d,2}(F) - \\gamma_{3d-1,1}(F) \\geq \\Omega(1)$.\nThe second is an infinite family of functions $F$ such that\n$\\gamma_{d,1}(F)\\leq\\frac{1}{2}+o(1)$ -- as small as possible -- but\n$\\gamma_{d,3}(F) \\geq \\frac{1}{2}+\\Omega(1)$.\n  - Increasing $k$ doesn't always help: Adapting a proof of Green [Comput.\nComplexity, 9(1):16-38, 2000], we show that irrespective of the value of $k$,\nthe Majority function $\\mathrm{Maj}_n$ satisfies $\\gamma_{d,k}(\\mathrm{Maj}_n)\n\\leq \\frac{1}{2}+\\frac{O(d)}{\\sqrt{n}}$. In other words, polynomials over\n$\\mathbb{Z}/2^k\\mathbb{Z}$ for large $k$ do not approximate the majority\nfunction any better than polynomials over $\\mathbb{Z}/2\\mathbb{Z}$.\n  We observe that the model we study subsumes the model of non-classical\npolynomials in the sense that proving bounds in our model implies bounds on the\nagreement of non-classical polynomials with Boolean functions. In particular,\nour results answer questions raised by Bhowmick and Lovett [In Proc. 30th\nComputational Complexity Conf., pages 72-87, 2015] that ask whether\nnon-classical polynomials approximate Boolean functions better than classical\npolynomials of the same degree.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 05:38:55 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Bhrushundi", "Abhishek", ""], ["Harsha", "Prahladh", ""], ["Srinivasan", "Srikanth", ""]]}, {"id": "1701.06386", "submitter": "Georgios Stamoulis", "authors": "Cassio P. de Campos and Georgios Stamoulis and Dennis Weyland", "title": "A Structured View on Weighted Counting with Relations to Counting,\n  Quantum Computation and Applications", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted counting problems are a natural generalization of counting problems\nwhere a weight is associated with every computational path of polynomial-time\nnon-deterministic Turing machines and the goal is to compute the sum of the\nweights of all paths (instead of just computing the number of accepting paths).\nUseful closure properties and plenty of applications make weighted counting\nproblems interesting. The general definition of these problems captures even\nundecidable problems, but it turns out that obtaining an exponentially small\nadditive approximation is just as hard as solving conventional counting\nproblems. In many cases such an approximation is sufficient and working with\nweighted counting problems tends to be very convenient. We present a structured\nview on weighted counting by defining classes that depend on the range of the\nfunction that assigns weights to paths and by showing the relationships between\nthese different classes. These classes constitute generalizations of the usual\ncounting problems. Weighted counting allows us to easily cast a number of\nfamous results of computational complexity in its terms, especially regarding\ncounting and quantum computation. Moreover, these classes are flexible enough\nand capture the complexity of various problems in fields such as probabilistic\ngraphical models and stochastic combinatorial optimization. Using the weighted\ncounting terminology and our results, we are able to simplify and answer some\nopen questions in those fields.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 13:46:59 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 14:01:05 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["de Campos", "Cassio P.", ""], ["Stamoulis", "Georgios", ""], ["Weyland", "Dennis", ""]]}, {"id": "1701.06639", "submitter": "Johann Makowsky", "authors": "A. Goodall and M. Hermann and T. Kotek and J.A. Makowsky and S.D.\n  Noble", "title": "On the complexity of generalized chromatic polynomials", "comments": "33 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  J. Makowsky and B. Zilber (2004) showed that many variations of graph\ncolorings, called CP-colorings in the sequel, give rise to graph polynomials.\nThis is true in particular for harmonious colorings, convex colorings,\nmcc_t-colorings, and rainbow colorings, and many more. N. Linial (1986) showed\nthat the chromatic polynomial $\\chi(G;X)$ is #P-hard to evaluate for all but\nthree values X=0,1,2, where evaluation is in P. This dichotomy includes\nevaluation at real or complex values, and has the further property that the set\nof points for which evaluation is in P is finite. We investigate how the\ncomplexity of evaluating univariate graph polynomials that arise from\nCP-colorings varies for different evaluation points. We show that for some\nCP-colorings (harmonious, convex) the complexity of evaluation follows a\nsimilar pattern to the chromatic polynomial. However, in other cases (proper\nedge colorings, mcc_t-colorings, H-free colorings) we could only obtain a\ndichotomy for evaluations at non-negative integer points. We also discuss some\nCP-colorings where we only have very partial results.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 21:34:56 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Goodall", "A.", ""], ["Hermann", "M.", ""], ["Kotek", "T.", ""], ["Makowsky", "J. A.", ""], ["Noble", "S. D.", ""]]}, {"id": "1701.06806", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam (CWI) and Ronald de Wolf (CWI and U of\n  Amsterdam)", "title": "A Survey of Quantum Learning Theory", "comments": "26 pages LaTeX. v2: many small changes to improve the presentation.\n  This version will appear as Complexity Theory Column in SIGACT News in June\n  2017. v3: fixed a small ambiguity in the definition of gamma(C) and updated a\n  reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys quantum learning theory: the theoretical aspects of\nmachine learning using quantum computers. We describe the main results known\nfor three models of learning: exact learning from membership queries, and\nProbably Approximately Correct (PAC) and agnostic learning from classical or\nquantum examples.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 10:53:07 GMT"}, {"version": "v2", "created": "Mon, 24 Apr 2017 16:48:10 GMT"}, {"version": "v3", "created": "Fri, 28 Jul 2017 09:40:37 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Arunachalam", "Srinivasan", "", "CWI"], ["de Wolf", "Ronald", "", "CWI and U of\n  Amsterdam"]]}, {"id": "1701.06942", "submitter": "J\\=anis Iraids", "authors": "Andris Ambainis, Janis Iraids", "title": "Optimal one-shot quantum algorithm for EQUALITY and AND", "comments": "10 pages. arXiv admin note: text overlap with arXiv:1608.02374", "journal-ref": "Baltic J. Modern Computing, Vol. 4 (2016), No. 4, pp. 721-730", "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computation complexity of Boolean functions in the quantum black\nbox model. In this model our task is to compute a function\n$f:\\{0,1\\}\\to\\{0,1\\}$ on an input $x\\in\\{0,1\\}^n$ that can be accessed by\nquerying the black box. Quantum algorithms are inherently probabilistic; we are\ninterested in the lowest possible probability that the algorithm outputs\nincorrect answer (the error probability) for a fixed number of queries. We show\nthat the lowest possible error probability for $AND_n$ and $EQUALITY_{n+1}$ is\n$1/2-n/(n^2+1)$.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 15:46:34 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Ambainis", "Andris", ""], ["Iraids", "Janis", ""]]}, {"id": "1701.06985", "submitter": "Lars Jaffke", "authors": "Lars Jaffke and Bart M. P. Jansen", "title": "Fine-Grained Parameterized Complexity Analysis of Graph Coloring\n  Problems", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $q$-Coloring problem asks whether the vertices of a graph can be properly\ncolored with $q$ colors. Lokshtanov et al. [SODA 2011] showed that $q$-Coloring\non graphs with a feedback vertex set of size $k$ cannot be solved in time\n$\\mathcal{O}^*((q-\\varepsilon)^k)$, for any $\\varepsilon > 0$, unless the\nStrong Exponential-Time Hypothesis (SETH) fails. In this paper we perform a\nfine-grained analysis of the complexity of $q$-Coloring with respect to a\nhierarchy of parameters. We show that even when parameterized by the vertex\ncover number, $q$ must appear in the base of the exponent: Unless ETH fails,\nthere is no universal constant $\\theta$ such that $q$-Coloring parameterized by\nvertex cover can be solved in time $\\mathcal{O}^*(\\theta^k)$ for all fixed $q$.\nWe apply a method due to Jansen and Kratsch [Inform. & Comput. 2013] to prove\nthat there are $\\mathcal{O}^*((q - \\varepsilon)^k)$ time algorithms where $k$\nis the vertex deletion distance to several graph classes $\\mathcal{F}$ for\nwhich $q$-Coloring is known to be solvable in polynomial time. We generalize\nearlier ad-hoc results by showing that if $\\mathcal{F}$ is a class of graphs\nwhose $(q+1)$-colorable members have bounded treedepth, then there exists some\n$\\varepsilon > 0$ such that $q$-Coloring can be solved in time\n$\\mathcal{O}^*((q-\\varepsilon)^k)$ when parameterized by the size of a given\nmodulator to $\\mathcal{F}$. In contrast, we prove that if $\\mathcal{F}$ is the\nclass of paths - some of the simplest graphs of unbounded treedepth - then no\nsuch algorithm can exist unless SETH fails.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 17:13:26 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Jaffke", "Lars", ""], ["Jansen", "Bart M. P.", ""]]}, {"id": "1701.07822", "submitter": "Michael Holzhauser", "authors": "Michael Holzhauser, Sven O. Krumke", "title": "An FPTAS for the parametric knapsack problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the parametric knapsack problem, in which the\nitem profits are affine functions depending on a real-valued parameter. The aim\nis to provide a solution for all values of the parameter. It is well-known that\nany exact algorithm for the problem may need to output an exponential number of\nknapsack solutions. We present a fully polynomial-time approximation scheme\n(FPTAS) for the problem that, for any desired precision $\\varepsilon \\in\n(0,1)$, computes $(1-\\varepsilon)$-approximate solutions for all values of the\nparameter. This is the first FPTAS for the parametric knapsack problem that\ndoes not require the slopes and intercepts of the affine functions to be\nnon-negative but works for arbitrary integral values. Our FPTAS outputs\n$\\mathcal{O}(\\frac{n^2}{\\varepsilon})$ knapsack solutions and runs in strongly\npolynomial-time $\\mathcal{O}(\\frac{n^4}{\\varepsilon^2})$. Even for the special\ncase of positive input data, this is the first FPTAS with a strongly polynomial\nrunning time. We also show that this time bound can be further improved to\n$\\mathcal{O}(\\frac{n^2}{\\varepsilon} \\cdot A(n,\\varepsilon))$, where\n$A(n,\\varepsilon)$ denotes the running time of any FPTAS for the traditional\n(non-parametric) knapsack problem.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 18:58:02 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2017 10:15:31 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Holzhauser", "Michael", ""], ["Krumke", "Sven O.", ""]]}, {"id": "1701.08108", "submitter": "Themistoklis Melissourgos", "authors": "Themistoklis Melissourgos and Paul Spirakis", "title": "Existence of Evolutionarily Stable Strategies Remains Hard to Decide for\n  a Wide Range of Payoff Values", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of an evolutionarily stable strategy (ESS), introduced by Smith\nand Price, is a refinement of Nash equilibrium in 2-player symmetric games in\norder to explain counter-intuitive natural phenomena, whose existence is not\nguaranteed in every game. The problem of deciding whether a game possesses an\nESS has been shown to be $\\Sigma_{2}^{P}$-complete by Conitzer using the\npreceding important work by Etessami and Lochbihler. The latter, among other\nresults, proved that deciding the existence of ESS is both NP-hard and\ncoNP-hard. In this paper we introduce a \"reduction robustness\" notion and we\nshow that deciding the existence of an ESS remains coNP-hard for a wide range\nof games even if we arbitrarily perturb within some intervals the payoff values\nof the game under consideration. In contrast, ESS exist almost surely for large\ngames with random and independent payoffs chosen from the same distribution.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 16:37:45 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Melissourgos", "Themistoklis", ""], ["Spirakis", "Paul", ""]]}, {"id": "1701.08557", "submitter": "Igor Sergeev S.", "authors": "M. I. Grinchuk, I. S. Sergeev", "title": "Thin circulant matrices and lower bounds on the complexity of some\n  Boolean operators", "comments": "15 pages", "journal-ref": "Diskretnyi Analiz i Issledovanie Operatsii (Discrete analysis and\n  operations research). 2011. 18(5), 38-53. (in Russian)", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a lower bound\n$\\Omega\\left(\\frac{k+l}{k^2l^2}N^{2-\\frac{k+l+2}{kl}}\\right)$ on the maximal\npossible weight of a $(k,l)$-free (that is, free of all-ones $k\\times l$\nsubmatrices) Boolean circulant $N \\times N$ matrix. The bound is close to the\nknown bound for the class of all $(k,l)$-free matrices. As a consequence, we\nobtain new bounds for several complexity measures of Boolean sums' systems and\na lower bound $\\Omega(N^2\\log^{-6} N)$ on the monotone complexity of the\nBoolean convolution of order $N$.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 11:39:38 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Grinchuk", "M. I.", ""], ["Sergeev", "I. S.", ""]]}, {"id": "1701.08925", "submitter": "Yue Zhao", "authors": "Sichen Zhong and Yue Zhao", "title": "Generic Cospark of a Matrix Can Be Computed in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cospark of a matrix is the cardinality of the sparsest vector in the\ncolumn space of the matrix. Computing the cospark of a matrix is well known to\nbe an NP hard problem. Given the sparsity pattern (i.e., the locations of the\nnon-zero entries) of a matrix, if the non-zero entries are drawn from\nindependently distributed continuous probability distributions, we prove that\nthe cospark of the matrix equals, with probability one, to a particular number\ntermed the generic cospark of the matrix. The generic cospark also equals to\nthe maximum cospark of matrices consistent with the given sparsity pattern. We\nprove that the generic cospark of a matrix can be computed in polynomial time,\nand offer an algorithm that achieves this.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 06:00:59 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Zhong", "Sichen", ""], ["Zhao", "Yue", ""]]}]