[{"id": "1711.00201", "submitter": "Lane A. Hemaspaandra", "authors": "Edith Hemaspaandra and Lane A. Hemaspaandra", "title": "Credimus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We believe that economic design and computational complexity---while already\nimportant to each other---should become even more important to each other with\neach passing year. But for that to happen, experts in on the one hand such\nareas as social choice, economics, and political science and on the other hand\ncomputational complexity will have to better understand each other's\nworldviews.\n  This article, written by two complexity theorists who also work in\ncomputational social choice theory, focuses on one direction of that process by\npresenting a brief overview of how most computational complexity theorists view\nthe world. Although our immediate motivation is to make the lens through which\ncomplexity theorists see the world be better understood by those in the social\nsciences, we also feel that even within computer science it is very important\nfor nontheoreticians to understand how theoreticians think, just as it is\nequally important within computer science for theoreticians to understand how\nnontheoreticians think.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 04:23:01 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 17:24:38 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Hemaspaandra", "Lane A.", ""]]}, {"id": "1711.00220", "submitter": "Ronny Tredup", "authors": "Christian Rosenke and Ronny Tredup", "title": "The Hardness of Synthesizing Elementary Net Systems from Highly\n  Restricted Inputs", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elementary net systems (ENS) are the most fundamental class of Petri nets.\nTheir synthesis problem has important applications in the design of digital\nhardware and commercial processes. Given a labeled transition system (TS) $A$,\nfeasibility is the NP-complete decision problem whether $A$ can be equivalently\nsynthesized into an ENS. It is well known that $A$ is feasible if and only if\nit has the event state separation property (ESSP) and the state separation\nproperty (SSP). Recently, these properties have also been studied individually\nfor their practical implications. A fast ESSP algorithm, for instance, would\nallow applications to at least validate the language equivalence of $A$ and a\nsynthesized ENS. Being able to efficiently decide SSP, on the other hand, could\nserve as a quick-fail preprocessing mechanism for synthesis. Although a few\ntractable subclasses have been found, this paper destroys much of the hope that\nmany practically meaningful input restrictions make feasibility or at least one\nof ESSP and SSP efficient. We show that all three problems remain NP-complete\neven if the input is restricted to linear TSs where every event occurs at most\nthree times or if the input is restricted to TSs where each event occurs at\nmost twice and each state has at most two successor and two predecessor states.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 06:28:52 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Rosenke", "Christian", ""], ["Tredup", "Ronny", ""]]}, {"id": "1711.00282", "submitter": "Andreas Galanis", "authors": "Ivona Bezakova, Andreas Galanis, Leslie Ann Goldberg, Daniel\n  Stefankovic", "title": "Inapproximability of the independent set polynomial in the complex plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of approximating the independent set polynomial\n$Z_G(\\lambda)$ of a graph $G$ with maximum degree $\\Delta$ when the activity\n$\\lambda$ is a complex number.\n  This problem is already well understood when $\\lambda$ is real using\nconnections to the $\\Delta$-regular tree $T$. The key concept in that case is\nthe \"occupation ratio\" of the tree $T$. This ratio is the contribution to\n$Z_T(\\lambda)$ from independent sets containing the root of the tree, divided\nby $Z_T(\\lambda)$ itself. If $\\lambda$ is such that the occupation ratio\nconverges to a limit, as the height of $T$ grows, then there is an FPTAS for\napproximating $Z_G(\\lambda)$ on a graph $G$ with maximum degree $\\Delta$.\nOtherwise, the approximation problem is NP-hard.\n  Unsurprisingly, the case where $\\lambda$ is complex is more challenging.\nPeters and Regts identified the complex values of $\\lambda$ for which the\noccupation ratio of the $\\Delta$-regular tree converges. These values carve a\ncardioid-shaped region $\\Lambda_\\Delta$ in the complex plane. Motivated by the\npicture in the real case, they asked whether $\\Lambda_\\Delta$ marks the true\napproximability threshold for general complex values $\\lambda$.\n  Our main result shows that for every $\\lambda$ outside of $\\Lambda_\\Delta$,\nthe problem of approximating $Z_G(\\lambda)$ on graphs $G$ with maximum degree\nat most $\\Delta$ is indeed NP-hard. In fact, when $\\lambda$ is outside of\n$\\Lambda_\\Delta$ and is not a positive real number, we give the stronger result\nthat approximating $Z_G(\\lambda)$ is actually #P-hard. If $\\lambda$ is a\nnegative real number outside of $\\Lambda_\\Delta$, we show that it is #P-hard to\neven decide whether $Z_G(\\lambda)>0$, resolving in the affirmative a conjecture\nof Harvey, Srivastava and Vondrak.\n  Our proof techniques are based around tools from complex analysis -\nspecifically the study of iterative multivariate rational maps.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 10:48:43 GMT"}, {"version": "v2", "created": "Sun, 18 Feb 2018 23:30:04 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 18:19:27 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Bezakova", "Ivona", ""], ["Galanis", "Andreas", ""], ["Goldberg", "Leslie Ann", ""], ["Stefankovic", "Daniel", ""]]}, {"id": "1711.00284", "submitter": "David Holzm\\\"uller", "authors": "David Holzm\\\"uller", "title": "Improved Approximation Schemes for the Restricted Shortest Path Problem", "comments": "Incorporated more review suggestions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Restricted Shortest Path (RSP) problem, also known as the\nDelay-Constrained Least-Cost (DCLC) problem, is an NP-hard bicriteria\noptimization problem on graphs with $n$ vertices and $m$ edges. In a graph\nwhere each edge is assigned a cost and a delay, the goal is to find a min-cost\npath which does not exceed a delay bound. In this paper, we present improved\napproximation schemes for RSP on several graph classes. For planar graphs,\nundirected graphs with positive integer resource (= delay) values, and graphs\nwith $m \\in \\Omega(n \\log n)$, we obtain $(1 + \\varepsilon)$-approximations in\ntime $O(mn/\\varepsilon)$. For general graphs and directed acyclic graphs, we\nmatch the results by Xue et al. (2008, [10]) and Ergun et al. (2002, [1]),\nrespectively, but with arguably simpler algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 10:55:17 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 11:11:19 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Holzm\u00fcller", "David", ""]]}, {"id": "1711.00465", "submitter": "Andr\\'as Gily\\'en", "authors": "Andr\\'as Gily\\'en, Srinivasan Arunachalam, Nathan Wiebe", "title": "Optimizing quantum optimization algorithms via faster quantum gradient\n  computation", "comments": "60 pages, 5 figures. Update: stated a separate general theorem about\n  hybrid-method based continuous input lower bound + added reference to work\n  showing optimality of our algorithm", "journal-ref": "In Proceedings of the 30th ACM-SIAM Symposium on Discrete\n  Algorithms (SODA 2019), pp. 1425-1444", "doi": "10.1137/1.9781611975482.87", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a generic framework of optimization algorithms based on gradient\ndescent. We develop a quantum algorithm that computes the gradient of a\nmulti-variate real-valued function $f:\\mathbb{R}^d\\rightarrow \\mathbb{R}$ by\nevaluating it at only a logarithmic number of points in superposition. Our\nalgorithm is an improved version of Stephen Jordan's gradient computation\nalgorithm, providing an approximation of the gradient $\\nabla f$ with\nquadratically better dependence on the evaluation accuracy of $f$, for an\nimportant class of smooth functions. Furthermore, we show that most objective\nfunctions arising from quantum optimization procedures satisfy the necessary\nsmoothness conditions, hence our algorithm provides a quadratic improvement in\nthe complexity of computing their gradient. We also show that in a continuous\nphase-query model, our gradient computation algorithm has optimal query\ncomplexity up to poly-logarithmic factors, for a particular class of smooth\nfunctions. Moreover, we show that for low-degree multivariate polynomials our\nalgorithm can provide exponential speedups compared to Jordan's algorithm in\nterms of the dimension $d$.\n  One of the technical challenges in applying our gradient computation\nprocedure for quantum optimization problems is the need to convert between a\nprobability oracle (which is common in quantum optimization procedures) and a\nphase oracle (which is common in quantum algorithms) of the objective function\n$f$. We provide efficient subroutines to perform this delicate interconversion\nbetween the two types of oracles incurring only a logarithmic overhead, which\nmight be of independent interest. Finally, using these tools we improve the\nruntime of prior approaches for training quantum auto-encoders, variational\nquantum eigensolvers (VQE), and quantum approximate optimization algorithms\n(QAOA).\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 17:59:47 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 17:58:02 GMT"}, {"version": "v3", "created": "Tue, 17 Apr 2018 15:11:05 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Gily\u00e9n", "Andr\u00e1s", ""], ["Arunachalam", "Srinivasan", ""], ["Wiebe", "Nathan", ""]]}, {"id": "1711.00565", "submitter": "William Hoza", "authors": "William M. Hoza", "title": "Typically-Correct Derandomization for Small Time and Space", "comments": "39 pages, 9 figures. Improved presentation, simplified content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose a language $L$ can be decided by a bounded-error randomized algorithm\nthat runs in space $S$ and time $n \\cdot \\text{poly}(S)$. We give a randomized\nalgorithm for $L$ that still runs in space $O(S)$ and time $n \\cdot\n\\text{poly}(S)$ that uses only $O(S)$ random bits; our algorithm has a low\nfailure probability on all but a negligible fraction of inputs of each length.\nAn immediate corollary is a deterministic algorithm for $L$ that runs in space\n$O(S)$ and succeeds on all but a negligible fraction of inputs of each length.\nWe also give several other complexity-theoretic applications of our technique.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 23:36:39 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 17:31:44 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 21:43:30 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Hoza", "William M.", ""]]}, {"id": "1711.00686", "submitter": "Ryan Mann", "authors": "Ryan L. Mann and Michael J. Bremner", "title": "On the Complexity of Random Quantum Computations and the Jones\n  Polynomial", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a natural relationship between Jones polynomials and quantum\ncomputation. We use this relationship to show that the complexity of evaluating\nrelative-error approximations of Jones polynomials can be used to bound the\nclassical complexity of approximately simulating random quantum computations.\nWe prove that random quantum computations cannot be classically simulated up to\na constant total variation distance, under the assumption that (1) the\nPolynomial Hierarchy does not collapse and (2) the average-case complexity of\nrelative-error approximations of the Jones polynomial matches the worst-case\ncomplexity over a constant fraction of random links. Our results provide a\nstraightforward relationship between the approximation of Jones polynomials and\nthe complexity of random quantum computations.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 11:15:58 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Mann", "Ryan L.", ""], ["Bremner", "Michael J.", ""]]}, {"id": "1711.00762", "submitter": "Rani Hod", "authors": "Rani Hod", "title": "Improved Lower Bounds for the Fourier Entropy/Influence Conjecture via\n  Lexicographic Functions", "comments": "20+7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every Boolean function can be uniquely represented as a multilinear\npolynomial. The entropy and the total influence are two ways to measure the\nconcentration of its Fourier coefficients, namely the monomial coefficients in\nthis representation: the entropy roughly measures their spread, while the total\ninfluence measures their average level. The Fourier Entropy/Influence\nconjecture of Friedgut and Kalai from 1996 states that the entropy to influence\nratio is bounded by a universal constant $C$.\n  Using lexicographic Boolean functions, we present three explicit asymptotic\nconstructions that improve upon the previously best known lower bound\n$C>6.278944$ by O'Donnell and Tan, obtained via recursive composition. The\nfirst uses their construction with the lexicographic function $\\ell\\left\\langle\n2/3\\right\\rangle $ of measure $2/3$ to demonstrate that\n$C\\ge4+3\\log_{4}3>6.377444$. The second generalizes their construction to\nbiased functions and obtains $C>6.413846$ using $\\ell\\left\\langle\n\\Phi\\right\\rangle $, where $\\Phi$ is the inverse golden ratio. The third,\nindependent, construction gives $C>6.454784$, even for monotone functions.\n  Beyond modest improvements to the value of $C$, our constructions shed some\nnew light on the properties sought in potential counterexamples to the\nconjecture.\n  Additionally, we prove a Lipschitz-type condition on the total influence and\nspectral entropy, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 14:28:07 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Hod", "Rani", ""]]}, {"id": "1711.00956", "submitter": "Chao Qian", "authors": "Chao Qian, Chao Bian, Wu Jiang, Ke Tang", "title": "Running Time Analysis of the (1+1)-EA for OneMax and LeadingOnes under\n  Bit-wise Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world optimization problems, the objective function evaluation\nis subject to noise, and we cannot obtain the exact objective value.\nEvolutionary algorithms (EAs), a type of general-purpose randomized\noptimization algorithm, have shown able to solve noisy optimization problems\nwell. However, previous theoretical analyses of EAs mainly focused on\nnoise-free optimization, which makes the theoretical understanding largely\ninsufficient. Meanwhile, the few existing theoretical studies under noise often\nconsidered the one-bit noise model, which flips a randomly chosen bit of a\nsolution before evaluation; while in many realistic applications, several bits\nof a solution can be changed simultaneously. In this paper, we study a natural\nextension of one-bit noise, the bit-wise noise model, which independently flips\neach bit of a solution with some probability. We analyze the running time of\nthe (1+1)-EA solving OneMax and LeadingOnes under bit-wise noise for the first\ntime, and derive the ranges of the noise level for polynomial and\nsuper-polynomial running time bounds. The analysis on LeadingOnes under\nbit-wise noise can be easily transferred to one-bit noise, and improves the\npreviously known results. Since our analysis discloses that the (1+1)-EA can be\nefficient only under low noise levels, we also study whether the sampling\nstrategy can bring robustness to noise. We prove that using sampling can\nsignificantly increase the largest noise level allowing a polynomial running\ntime, that is, sampling is robust to noise.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 22:00:21 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Qian", "Chao", ""], ["Bian", "Chao", ""], ["Jiang", "Wu", ""], ["Tang", "Ke", ""]]}, {"id": "1711.00963", "submitter": "Philipp Zschoche", "authors": "Philipp Zschoche, Till Fluschnik, Hendrik Molter, Rolf Niedermeier", "title": "The Complexity of Finding Small Separators in Temporal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal graphs are graphs with time-stamped edges. We study the problem of\nfinding a small vertex set (the separator) with respect to two designated\nterminal vertices such that the removal of the set eliminates all temporal\npaths connecting one terminal to the other. Herein, we consider two models of\ntemporal paths: paths that pass through arbitrarily many edges per time step\n(non-strict) and paths that pass through at most one edge per time step\n(strict). Regarding the number of time steps of a temporal graph, we show a\ncomplexity dichotomy (NP-hardness versus polynomial-time solvability) for both\nproblem variants. Moreover we prove both problem variants to be NP-complete\neven on temporal graphs whose underlying graph is planar. We further show that,\non temporal graphs with planar underlying graph, if additionally the number of\ntime steps is constant, then the problem variant for strict paths is solvable\nin quasi-linear time. Finally, we introduce and motivate the notion of a\ntemporal core (vertices whose incident edges change over time). We prove that\nthe non-strict variant is fixed-parameter tractable when parameterized by the\nsize of the temporal core, while the strict variant remains NP-complete, even\nfor constant-size temporal cores.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 22:30:07 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 14:20:43 GMT"}, {"version": "v3", "created": "Fri, 8 Dec 2017 15:50:52 GMT"}, {"version": "v4", "created": "Mon, 19 Feb 2018 14:14:05 GMT"}, {"version": "v5", "created": "Wed, 25 Jul 2018 08:16:25 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Zschoche", "Philipp", ""], ["Fluschnik", "Till", ""], ["Molter", "Hendrik", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "1711.01053", "submitter": "Scott Aaronson", "authors": "Scott Aaronson", "title": "Shadow Tomography of Quantum States", "comments": "29 pages, extended abstract appeared in Proceedings of STOC'2018,\n  revised to give slightly better upper bound (1/eps^4 rather than 1/eps^5) and\n  lower bounds with explicit dependence on the dimension D", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of *shadow tomography*: given an unknown\n$D$-dimensional quantum mixed state $\\rho$, as well as known two-outcome\nmeasurements $E_{1},\\ldots,E_{M}$, estimate the probability that $E_{i}$\naccepts $\\rho$, to within additive error $\\varepsilon$, for each of the $M$\nmeasurements. How many copies of $\\rho$ are needed to achieve this, with high\nprobability? Surprisingly, we give a procedure that solves the problem by\nmeasuring only $\\widetilde{O}\\left( \\varepsilon^{-4}\\cdot\\log^{4} M\\cdot\\log\nD\\right)$ copies. This means, for example, that we can learn the behavior of an\narbitrary $n$-qubit state, on all accepting/rejecting circuits of some fixed\npolynomial size, by measuring only $n^{O\\left( 1\\right)}$ copies of the state.\nThis resolves an open problem of the author, which arose from his work on\nprivate-key quantum money schemes, but which also has applications to quantum\ncopy-protected software, quantum advice, and quantum one-way communication.\nRecently, building on this work, Brand\\~ao et al. have given a different\napproach to shadow tomography using semidefinite programming, which achieves a\nsavings in computation time.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 08:07:11 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 07:14:02 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Aaronson", "Scott", ""]]}, {"id": "1711.01061", "submitter": "Andrew Ryzhikov", "authors": "Andrew Ryzhikov", "title": "On Automata Recognizing Birecurrent Sets", "comments": "A slightly updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we study automata recognizing birecurrent sets. A set of words\nis birecurrent if the minimal partial DFA recognizing this set and the minimal\npartial DFA recognizing the reversal of this set are both strongly connected.\nThis notion was introduced by Perrin, and Dolce et al. provided a\ncharacterization of such sets. We prove that deciding whether a partial DFA\nrecognizes a birecurrent set is a PSPACE-complete problem. We show that this\nproblem is PSPACE-complete even in the case of binary partial DFAs with all\nstates accepting and in the case of binary complete DFAs. We also consider a\nrelated problem of computing the rank of a partial DFA.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 08:45:49 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 12:46:25 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Ryzhikov", "Andrew", ""]]}, {"id": "1711.01250", "submitter": "Lane A. Hemaspaandra", "authors": "Edith Hemaspaandra, Lane A. Hemaspaandra, Holger Spakowski, Osamu\n  Watanabe", "title": "The Robustness of LWPP and WPP, with an Application to Graph\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the counting class LWPP [FFK94] remains unchanged even if one\nallows a polynomial number of gap values rather than one. On the other hand, we\nshow that it is impossible to improve this from polynomially many gap values to\na superpolynomial number of gap values by relativizable proof techniques.\n  The first of these results implies that the Legitimate Deck Problem (from the\nstudy of graph reconstruction) is in LWPP (and thus low for PP, i.e., $\\rm\nPP^{\\mbox{Legitimate Deck}} = PP$) if the weakened version of the\nReconstruction Conjecture holds in which the number of nonisomorphic preimages\nis assumed merely to be polynomially bounded. This strengthens the 1992 result\nof K\\\"{o}bler, Sch\\\"{o}ning, and Tor\\'{a}n [KST92] that the Legitimate Deck\nProblem is in LWPP if the Reconstruction Conjecture holds, and provides\nstrengthened evidence that the Legitimate Deck Problem is not NP-hard.\n  We additionally show on the one hand that our main LWPP robustness result\nalso holds for WPP, and also holds even when one allows both the rejection- and\nacceptance- gap-value targets to simultaneously be polynomial-sized lists; yet\non the other hand, we show that for the #P-based analog of LWPP the behavior\nmuch differs in that, in some relativized worlds, even two target values\nalready yield a richer class than one value does. Despite that nonrobustness\nresult for a #P-based class, we show that the #P-based \"exact counting\" class\n$\\rm C_{=}P$ remains unchanged even if one allows a polynomial number of target\nvalues for the number of accepting paths of the machine.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 17:24:52 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 22:35:56 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 14:21:08 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Hemaspaandra", "Lane A.", ""], ["Spakowski", "Holger", ""], ["Watanabe", "Osamu", ""]]}, {"id": "1711.01355", "submitter": "J. Maurice Rojas", "authors": "Qi Cheng, Shuhong Gao, J. Maurice Rojas, and Daqing Wan", "title": "Counting Roots of Polynomials Over Prime Power Rings", "comments": "title page, plus 11 pages, no illustrations, submitted to a\n  conference", "journal-ref": "Open Book Series 2 (2019) 191-205", "doi": "10.2140/obs.2019.2.191", "report-no": null, "categories": "math.NT cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose $p$ is a prime, $t$ is a positive integer, and\n$f\\!\\in\\!\\mathbb{Z}[x]$ is a univariate polynomial of degree $d$ with\ncoefficients of absolute value $<\\!p^t$. We show that for any fixed $t$, we can\ncompute the number of roots in $\\mathbb{Z}/(p^t)$ of $f$ in deterministic time\n$(d+\\log p)^{O(1)}$. This fixed parameter tractability appears to be new for\n$t\\!\\geq\\!3$. A consequence for arithmetic geometry is that we can efficiently\ncompute Igusa zeta functions $Z$, for univariate polynomials, assuming the\ndegree of $Z$ is fixed.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 23:02:22 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Cheng", "Qi", ""], ["Gao", "Shuhong", ""], ["Rojas", "J. Maurice", ""], ["Wan", "Daqing", ""]]}, {"id": "1711.01711", "submitter": "Hector Zenil", "authors": "Hector Zenil, Liliana Badillo, Santiago Hern\\'andez-Orozco, Francisco\n  Hern\\'andez-Quiroz", "title": "Coding-theorem Like Behaviour and Emergence of the Universal\n  Distribution from Resource-bounded Algorithmic Probability", "comments": "27 pages main text, 39 pages including supplement. Online complexity\n  calculator: http://complexitycalculator.com/", "journal-ref": "International Journal of Parallel, Emergent and Distributed\n  Systems, DOI: 10.1080/17445760.2018.1448932", "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previously referred to as `miraculous' in the scientific literature because\nof its powerful properties and its wide application as optimal solution to the\nproblem of induction/inference, (approximations to) Algorithmic Probability\n(AP) and the associated Universal Distribution are (or should be) of the\ngreatest importance in science. Here we investigate the emergence, the rates of\nemergence and convergence, and the Coding-theorem like behaviour of AP in\nTuring-subuniversal models of computation. We investigate empirical\ndistributions of computing models in the Chomsky hierarchy. We introduce\nmeasures of algorithmic probability and algorithmic complexity based upon\nresource-bounded computation, in contrast to previously thoroughly investigated\ndistributions produced from the output distribution of Turing machines. This\napproach allows for numerical approximations to algorithmic\n(Kolmogorov-Chaitin) complexity-based estimations at each of the levels of a\ncomputational hierarchy. We demonstrate that all these estimations are\ncorrelated in rank and that they converge both in rank and values as a function\nof computational power, despite fundamental differences between computational\nmodels. In the context of natural processes that operate below the Turing\nuniversal level because of finite resources and physical degradation, the\ninvestigation of natural biases stemming from algorithmic rules may shed light\non the distribution of outcomes. We show that up to 60\\% of the\nsimplicity/complexity bias in distributions produced even by the weakest of the\ncomputational models can be accounted for by Algorithmic Probability in its\napproximation to the Universal Distribution.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 03:37:46 GMT"}, {"version": "v10", "created": "Fri, 23 Mar 2018 14:00:21 GMT"}, {"version": "v11", "created": "Fri, 13 Apr 2018 11:25:47 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 22:41:46 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 17:04:49 GMT"}, {"version": "v4", "created": "Fri, 10 Nov 2017 13:18:51 GMT"}, {"version": "v5", "created": "Tue, 14 Nov 2017 00:13:49 GMT"}, {"version": "v6", "created": "Wed, 15 Nov 2017 01:56:57 GMT"}, {"version": "v7", "created": "Thu, 16 Nov 2017 16:28:52 GMT"}, {"version": "v8", "created": "Thu, 1 Feb 2018 21:18:20 GMT"}, {"version": "v9", "created": "Sat, 24 Feb 2018 15:35:00 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Zenil", "Hector", ""], ["Badillo", "Liliana", ""], ["Hern\u00e1ndez-Orozco", "Santiago", ""], ["Hern\u00e1ndez-Quiroz", "Francisco", ""]]}, {"id": "1711.01871", "submitter": "Janne H. Korhonen", "authors": "Alkida Balliu and Juho Hirvonen and Janne H. Korhonen and Tuomo\n  Lempi\\\"ainen and Dennis Olivetti and Jukka Suomela", "title": "New Classes of Distributed Time Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of recent papers -- e.g. Brandt et al. (STOC 2016), Chang et al.\n(FOCS 2016), Ghaffari & Su (SODA 2017), Brandt et al. (PODC 2017), and Chang &\nPettie (FOCS 2017) -- have advanced our understanding of one of the most\nfundamental questions in theory of distributed computing: what are the possible\ntime complexity classes of LCL problems in the LOCAL model? In essence, we have\na graph problem $\\Pi$ in which a solution can be verified by checking all\nradius-$O(1)$ neighbourhoods, and the question is what is the smallest $T$ such\nthat a solution can be computed so that each node chooses its own output based\non its radius-$T$ neighbourhood. Here $T$ is the distributed time complexity of\n$\\Pi$.\n  The time complexity classes for deterministic algorithms in bounded-degree\ngraphs that are known to exist by prior work are $\\Theta(1)$, $\\Theta(\\log^*\nn)$, $\\Theta(\\log n)$, $\\Theta(n^{1/k})$, and $\\Theta(n)$. It is also known\nthat there are two gaps: one between $\\omega(1)$ and $o(\\log \\log^* n)$, and\nanother between $\\omega(\\log^* n)$ and $o(\\log n)$. It has been conjectured\nthat many more gaps exist, and that the overall time hierarchy is relatively\nsimple -- indeed, this is known to be the case in restricted graph families\nsuch as cycles and grids.\n  We show that the picture is much more diverse than previously expected. We\npresent a general technique for engineering LCL problems with numerous\ndifferent deterministic time complexities, including $\\Theta(\\log^{\\alpha}n)$\nfor any $\\alpha\\ge1$, $2^{\\Theta(\\log^{\\alpha}n)}$ for any $\\alpha\\le 1$, and\n$\\Theta(n^{\\alpha})$ for any $\\alpha <1/2$ in the high end of the complexity\nspectrum, and $\\Theta(\\log^{\\alpha}\\log^* n)$ for any $\\alpha\\ge 1$,\n$\\smash{2^{\\Theta(\\log^{\\alpha}\\log^* n)}}$ for any $\\alpha\\le 1$, and\n$\\Theta((\\log^* n)^{\\alpha})$ for any $\\alpha \\le 1$ in the low end; here\n$\\alpha$ is a positive rational number.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 13:05:30 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 12:21:26 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Balliu", "Alkida", ""], ["Hirvonen", "Juho", ""], ["Korhonen", "Janne H.", ""], ["Lempi\u00e4inen", "Tuomo", ""], ["Olivetti", "Dennis", ""], ["Suomela", "Jukka", ""]]}, {"id": "1711.01904", "submitter": "Christian Ikenmeyer", "authors": "Christian Ikenmeyer, Balagopal Komarath, Christoph Lenzen, Vladimir\n  Lysikov, Andrey Mokhov, Karteek Sreenivasaiah", "title": "On the complexity of hazard-free circuits", "comments": null, "journal-ref": "J. ACM 66(4), Article 25 (2019)", "doi": "10.1145/3320123", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constructing hazard-free Boolean circuits dates back to the\n1940s and is an important problem in circuit design. Our main lower-bound\nresult unconditionally shows the existence of functions whose circuit\ncomplexity is polynomially bounded while every hazard-free implementation is\nprovably of exponential size. Previous lower bounds on the hazard-free\ncomplexity were only valid for depth 2 circuits. The same proof method yields\nthat every subcubic implementation of Boolean matrix multiplication must have\nhazards.\n  These results follow from a crucial structural insight: Hazard-free\ncomplexity is a natural generalization of monotone complexity to all (not\nnecessarily monotone) Boolean functions. Thus, we can apply known monotone\ncomplexity lower bounds to find lower bounds on the hazard-free complexity. We\nalso lift these methods from the monotone setting to prove exponential\nhazard-free complexity lower bounds for non-monotone functions.\n  As our main upper-bound result we show how to efficiently convert a Boolean\ncircuit into a bounded-bit hazard-free circuit with only a polynomially large\nblow-up in the number of gates. Previously, the best known method yielded\nexponentially large circuits in the worst case, so our algorithm gives an\nexponential improvement.\n  As a side result we establish the NP-completeness of several hazard detection\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 14:27:46 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 21:36:35 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ikenmeyer", "Christian", ""], ["Komarath", "Balagopal", ""], ["Lenzen", "Christoph", ""], ["Lysikov", "Vladimir", ""], ["Mokhov", "Andrey", ""], ["Sreenivasaiah", "Karteek", ""]]}, {"id": "1711.02124", "submitter": "Donald Stull", "authors": "Neil Lutz and D. M. Stull", "title": "Projection Theorems Using Effective Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use the theory of computing to study fractal dimensions of\nprojections in Euclidean spaces. A fundamental result in fractal geometry is\nMarstrand's projection theorem, which shows that for every analytic set E, for\nalmost every line L, the Hausdorff dimension of the orthogonal projection of E\nonto L is maximal. We use Kolmogorov complexity to give two new results on the\nHausdorff and packing dimensions of orthogonal projections onto lines. The\nfirst shows that the conclusion of Marstrand's theorem holds whenever the\nHausdorff and packing dimensions agree on the set E, even if E is not analytic.\nOur second result gives a lower bound on the packing dimension of projections\nof arbitrary sets. Finally, we give a new proof of Marstrand's theorem using\nthe theory of computing.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 19:17:02 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Lutz", "Neil", ""], ["Stull", "D. M.", ""]]}, {"id": "1711.02276", "submitter": "Mark Zhandry", "authors": "Mark Zhandry", "title": "Quantum Lightning Never Strikes the Same State Twice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public key quantum money can be seen as a version of the quantum no-cloning\ntheorem that holds even when the quantum states can be verified by the\nadversary. In this work, investigate quantum lightning, a formalization of\n\"collision-free quantum money\" defined by Lutomirski et al. [ICS'10], where\nno-cloning holds even when the adversary herself generates the quantum state to\nbe cloned. We then study quantum money and quantum lightning, showing the\nfollowing results:\n  - We demonstrate the usefulness of quantum lightning by showing several\npotential applications, such as generating random strings with a proof of\nentropy, to completely decentralized cryptocurrency without a block-chain,\nwhere transactions is instant and local.\n  - We give win-win results for quantum money/lightning, showing that either\nsignatures/hash functions/commitment schemes meet very strong recently proposed\nnotions of security, or they yield quantum money or lightning.\n  - We construct quantum lightning under the assumed multi-collision resistance\nof random degree-2 systems of polynomials.\n  - We show that instantiating the quantum money scheme of Aaronson and\nChristiano [STOC'12] with indistinguishability obfuscation that is secure\nagainst quantum computers yields a secure quantum money scheme\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 04:08:48 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 18:15:57 GMT"}, {"version": "v3", "created": "Wed, 15 Nov 2017 18:44:18 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Zhandry", "Mark", ""]]}, {"id": "1711.02455", "submitter": "Leqi Zhu", "authors": "Faith Ellen, Rati Gelashvili, Leqi Zhu", "title": "Revisionist Simulations: A New Approach to Proving Space Lower Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the space complexity of $x$-obstruction-free $k$-set agreement\nfor $x\\leq k$ is an open problem. In $x$-obstruction-free protocols, processes\nare required to return in executions where at most $x$ processes take steps.\nThe best known upper bound on the number of registers needed to solve this\nproblem among $n>k$ processes is $n-k+x$ registers. No general lower bound\nbetter than $2$ was known.\n  We prove that any $x$-obstruction-free protocol solving $k$-set agreement\namong $n>k$ processes uses at least $\\lfloor(n-x)/(k+1-x)\\rfloor+1$ registers.\nOur main tool is a simulation that serves as a reduction from the impossibility\nof deterministic wait-free $k$-set agreement: if a protocol uses fewer\nregisters, then it is possible for $k+1$ processes to simulate the protocol and\ndeterministically solve $k$-set agreement in a wait-free manner, which is\nimpossible. A critical component of the simulation is the ability of simulating\nprocesses to revise the past of simulated processes. We introduce a new\naugmented snapshot object, which facilitates this.\n  We also prove that any space lower bound on the number of registers used by\nobstruction-free protocols applies to protocols that satisfy nondeterministic\nsolo termination. Hence, our lower bound of $\\lfloor(n-1)/k\\rfloor+1$ for the\nobstruction-free ($x=1$) case also holds for randomized wait-free free\nprotocols. In particular, this gives a tight lower bound of exactly $n$\nregisters for solving obstruction-free and randomized wait-free consensus.\n  Finally, our new techniques can be applied to get a space lower of $\\lfloor\nn/2\\rfloor+1$ for $\\epsilon$-approximate agreement, for sufficiently small\n$\\epsilon$. It requires participating processes to return values within\n$\\epsilon$ of each other. The best known upper bounds are\n$\\lceil\\log(1/\\epsilon)\\rceil$ and $n$, while no general lower bounds were\nknown.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 13:34:52 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 21:42:50 GMT"}, {"version": "v3", "created": "Sat, 6 Jan 2018 04:01:03 GMT"}, {"version": "v4", "created": "Mon, 26 Feb 2018 11:00:07 GMT"}, {"version": "v5", "created": "Wed, 10 Oct 2018 17:18:27 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Ellen", "Faith", ""], ["Gelashvili", "Rati", ""], ["Zhu", "Leqi", ""]]}, {"id": "1711.03073", "submitter": "Anirbit Mukherjee", "authors": "Anirbit Mukherjee, Amitabh Basu", "title": "Lower bounds over Boolean inputs for deep neural networks with ReLU\n  gates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the resurgence of neural networks in being able to solve complex\nlearning tasks we undertake a study of high depth networks using ReLU gates\nwhich implement the function $x \\mapsto \\max\\{0,x\\}$. We try to understand the\nrole of depth in such neural networks by showing size lowerbounds against such\nnetwork architectures in parameter regimes hitherto unexplored. In particular\nwe show the following two main results about neural nets computing Boolean\nfunctions of input dimension $n$,\n  1. We use the method of random restrictions to show almost linear,\n$\\Omega(\\epsilon^{2(1-\\delta)}n^{1-\\delta})$, lower bound for completely weight\nunrestricted LTF-of-ReLU circuits to match the Andreev function on at least\n$\\frac{1}{2} +\\epsilon$ fraction of the inputs for $\\epsilon >\n\\sqrt{2\\frac{\\log^{\\frac {2}{2-\\delta}}(n)}{n}}$ for any $\\delta \\in (0,\\frac 1\n2)$\n  2. We use the method of sign-rank to show exponential in dimension lower\nbounds for ReLU circuits ending in a LTF gate and of depths upto $O(n^{\\xi})$\nwith $\\xi < \\frac{1}{8}$ with some restrictions on the weights in the bottom\nmost layer. All other weights in these circuits are kept unrestricted. This in\nturns also implies the same lowerbounds for LTF circuits with the same\narchitecture and the same weight restrictions on their bottom most layer.\n  Along the way we also show that there exists a $\\mathbb{R}^ n\\rightarrow\n\\mathbb{R}$ Sum-of-ReLU-of-ReLU function which Sum-of-ReLU neural nets can\nnever represent no matter how large they are allowed to be.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 18:02:47 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 02:35:25 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Mukherjee", "Anirbit", ""], ["Basu", "Amitabh", ""]]}, {"id": "1711.03399", "submitter": "Cynthia Kop", "authors": "Cynthia Kop", "title": "On First-order Cons-free Term Rewriting and PTIME", "comments": "workshop proceedings for DICE 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove that (first-order) cons-free term rewriting with a\ncall-by-value reduction strategy exactly characterises the class of\nPTIME-computable functions. We use this to give an alternative proof of the\nresult by Carvalho and Simonsen which states that cons-free term rewriting with\nlinearity constraints characterises this class.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 14:53:16 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 10:14:01 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Kop", "Cynthia", ""]]}, {"id": "1711.03407", "submitter": "Cynthia Kop", "authors": "Cynthia Kop, Jakob Grue Simonsen", "title": "Higher-order Cons-free Interpreters", "comments": "workshop proceedings for HOR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructor rewriting systems are said to be cons-free if any constructor\nterm occurring in the rhs of a rule must be a subterm of the lhs of the rule.\nRoughly, such systems cannot build new data structures during their evaluation.\nIn earlier work by several authors, (typed) cons-free systems have been used to\ncharacterise complexity classes such as polynomial or exponential time or space\nby varying the type orders, and the recursion forms allowed. This paper\nconcerns the construction of interpreters for cons-free term rewriting. Due to\ntheir connection with proofs by diagonalisation, interpreters may be of use\nwhen studying separation results between complexity classes in implicit\ncomputational complexity theory. We are interested in interpreters of type\norder $k > 1$ that can interpret any term of strictly lower type order; while\nthis gives us a well-known separation result E$^k$TIME $\\subseteq$\nE$^{k+1}$TIME, the hope is that more refined interpreters with syntactically\nlimited constraints can be used to obtain a notion of faux diagonalisation and\nbe used to attack open problems in complexity theory.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 15:01:55 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kop", "Cynthia", ""], ["Simonsen", "Jakob Grue", ""]]}, {"id": "1711.03415", "submitter": "Cynthia Kop", "authors": "Cynthia Kop", "title": "Non-deterministic Characterisations", "comments": "workshop proceedings for WST 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend Jones' result -- that cons-free programming with\n$k^{th}$-order data and a call-by-value strategy characterises EXP$^k$TIME --\nto a more general setting, including pattern-matching and non-deterministic\nchoice. We show that the addition of non-determinism is unexpectedly powerful\nin the higher-order setting. Nevertheless, we can obtain a non-deterministic\nparallel to Jones' hierarchy result by appropriate restricting rule formation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 15:12:27 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kop", "Cynthia", ""]]}, {"id": "1711.03420", "submitter": "Pierre Lairez", "authors": "Pierre Lairez", "title": "Rigid continuation paths I. Quasilinear average complexity for solving\n  polynomial systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many operations do we need on the average to compute an approximate root\nof a random Gaussian polynomial system? Beyond Smale's 17th problem that asked\nwhether a polynomial bound is possible, we prove a quasi-optimal bound\n$\\text{(input size)}^{1+o(1)}$. This improves upon the previously known\n$\\text{(input size)}^{\\frac32 +o(1)}$ bound.\n  The new algorithm relies on numerical continuation along \\emph{rigid\ncontinuation paths}. The central idea is to consider rigid motions of the\nequations rather than line segments in the linear space of all polynomial\nsystems. This leads to a better average condition number and allows for bigger\nsteps. We show that on the average, we can compute one approximate root of a\nrandom Gaussian polynomial system of~$n$ equations of degree at most $D$ in\n$n+1$ homogeneous variables with $O(n^5 D^2)$ continuation steps. This is a\ndecisive improvement over previous bounds that prove no better than\n$\\sqrt{2}^{\\min(n, D)}$ continuation steps on the average.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 15:23:28 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 09:18:54 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Lairez", "Pierre", ""]]}, {"id": "1711.03424", "submitter": "Cynthia Kop", "authors": "Cynthia Kop", "title": "Cons-free Programming with Immutable Functions", "comments": "workshop proceedings for DICE 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the power of non-determinism in purely functional programming\nlanguages with higher-order types. Specifically, we set out to characterise the\nhierarchy NP $\\subseteq$ NEXP $\\subseteq$ NEXP$^{(2)}$ $\\subseteq \\cdots\n\\subseteq$ NEXP$^{(k)}$ $\\subseteq \\cdots$ solely in terms of higher-typed,\npurely functional programs. Although the work is incomplete, we present an\ninitial approach using cons-free programs with immutable functions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 15:28:39 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Kop", "Cynthia", ""]]}, {"id": "1711.03886", "submitter": "D\\'aniel Marx", "authors": "D\\'aniel Marx", "title": "Completely inapproximable monotone and antimonotone parameterized\n  problems", "comments": "Conference version in CCC 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that weighted circuit satisfiability for monotone or antimonotone\ncircuits has no fixed-parameter tractable approximation algorithm with any\napproximation ratio function $\\rho$, unless $FPT\\neq W[1]$. In particular, not\nhaving such an fpt-approximation algorithm implies that these problems have no\npolynomial-time approximation algorithms with ratio $\\rho(OPT)$ for any\nnontrivial function $\\rho$.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 15:41:27 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Marx", "D\u00e1niel", ""]]}, {"id": "1711.03894", "submitter": "D\\'aniel Marx", "authors": "Andrei Krokhin and D\\'aniel Marx", "title": "On the hardness of losing weight", "comments": "Conference version in ICALP 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of local search for the Boolean constraint\nsatisfaction problem (CSP), in the following form: given a CSP instance, that\nis, a collection of constraints, and a solution to it, the question is whether\nthere is a better (lighter, i.e., having strictly less Hamming weight) solution\nwithin a given distance from the initial solution. We classify the complexity,\nboth classical and parameterized, of such problems by a Schaefer-style\ndichotomy result, that is, with a restricted set of allowed types of\nconstraints. Our results show that there is a considerable amount of such\nproblems that are NP-hard, but fixed-parameter tractable when parameterized by\nthe distance.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 15:48:24 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Krokhin", "Andrei", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "1711.03993", "submitter": "Mikhail Raskin", "authors": "Michael Raskin", "title": "A superpolynomial lower bound for the size of non-deterministic\n  complement of an unambiguous automaton", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unambiguous non-deterministic finite automata have intermediate expressive\npower and succinctness between deterministic and non-deterministic automata. It\nhas been conjectured that every unambiguous non-deterministic one-way finite\nautomaton (1UFA) recognizing some language L can be converted into a 1UFA\nrecognizing the complement of the original language L with polynomial increase\nin the number of states. We disprove this conjecture by presenting a family of\n1UFAs on a single-letter alphabet such that recognizing the complements of the\ncorresponding languages requires superpolynomial increase in the number of\nstates even for generic non-deterministic one-way finite automata. We also note\nthat both the languages and their complements can be recognized by sweeping\ndeterministic automata with a linear increase in the number of states.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 19:29:02 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 15:08:33 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 15:03:58 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Raskin", "Michael", ""]]}, {"id": "1711.04184", "submitter": "Ma{\\l}gorzata Moczurad", "authors": "Ma{\\l}gorzata Moczurad, Piotr Zgliczy\\'nski", "title": "Real-number Computability from the Perspective of Computer Assisted\n  Proofs in Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by computer assisted proofs in analysis, we present an interval\napproach to real-number computations.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 19:25:36 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 17:33:07 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 18:55:09 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Moczurad", "Ma\u0142gorzata", ""], ["Zgliczy\u0144ski", "Piotr", ""]]}, {"id": "1711.04412", "submitter": "Jackson Abascal", "authors": "Jackson Abascal, Shir Maimon", "title": "A Refutation of Guinea's \"Understanding SAT is in P\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we summarize and critique the paper \"Understanding SAT is in P\"\nby Alejandro S\\'anchez Guinea [arXiv:1504.00337]. The paper claims to present a\npolynomial-time solution for the NP-complete language 3-SAT. We show that\nGuinea's algorithm is flawed and does not prove 3-SAT is in P.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 03:48:03 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Abascal", "Jackson", ""], ["Maimon", "Shir", ""]]}, {"id": "1711.04427", "submitter": "Lek-Heng Lim", "authors": "Jinjie Zhang, Shmuel Friedland, and Lek-Heng Lim", "title": "Grothendieck constant is norm of Strassen matrix multiplication tensor", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that two important quantities from two disparate areas of complexity\ntheory --- Strassen's exponent of matrix multiplication $\\omega$ and\nGrothendieck's constant $K_G$ --- are intimately related. They are different\nmeasures of size for the same underlying object --- the matrix multiplication\ntensor, i.e., the $3$-tensor or bilinear operator $\\mu_{l,m,n} : \\mathbb{F}^{l\n\\times m} \\times \\mathbb{F}^{m \\times n} \\to \\mathbb{F}^{l \\times n}$, $(A,B)\n\\mapsto AB$ defined by matrix-matrix product over $\\mathbb{F} = \\mathbb{R}$ or\n$\\mathbb{C}$. It is well-known that Strassen's exponent of matrix\nmultiplication is the greatest lower bound on (the log of) a tensor rank of\n$\\mu_{l,m,n}$. We will show that Grothendieck's constant is the least upper\nbound on a tensor norm of $\\mu_{l,m,n}$, taken over all $l, m, n \\in\n\\mathbb{N}$. Aside from relating the two celebrated quantities, this insight\nallows us to rewrite Grothendieck's inequality as a norm inequality \\[\n\\lVert\\mu_{l,m,n}\\rVert_{1,2,\\infty}\n=\\max_{X,Y,M\\neq0}\\frac{|\\operatorname{tr}(XMY)|}{\\lVert X\\rVert_{1,2}\\lVert\nY\\rVert_{2,\\infty}\\lVert M\\rVert_{\\infty,1}}\\le K_G. \\] We prove that\nGrothendieck's inequality is unique: If we generalize the $(1,2,\\infty)$-norm\nto arbitrary $p,q, r \\in [1, \\infty]$, \\[\n\\lVert\\mu_{l,m,n}\\rVert_{p,q,r}=\\max_{X,Y,M\\neq0}\\frac{|\\operatorname{tr}(XMY)|}{\\|X\\|_{p,q}\\|Y\\|_{q,r}\\|M\\|_{r,p}},\n\\] then $(p,q,r )=(1,2,\\infty)$ is, up to cyclic permutations, the only choice\nfor which $\\lVert\\mu_{l,m,n}\\rVert_{p,q,r}$ is uniformly bounded by a constant\nindependent of $l,m,n$.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 06:10:54 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 19:10:06 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Zhang", "Jinjie", ""], ["Friedland", "Shmuel", ""], ["Lim", "Lek-Heng", ""]]}, {"id": "1711.04503", "submitter": "Aris Filos-Ratsikas", "authors": "Aris Filos-Ratsikas, Paul W. Goldberg", "title": "Consensus Halving is PPA-Complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the computational problem CONSENSUS-HALVING is PPA-complete, the\nfirst PPA-completeness result for a problem whose definition does not involve\nan explicit circuit. We also show that an approximate version of this problem\nis polynomial-time equivalent to NECKLACE SPLITTING, which establishes\nPPAD-hardness for NECKLACE SPLITTING, and suggests that it is also\nPPA-complete.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 10:29:43 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Filos-Ratsikas", "Aris", ""], ["Goldberg", "Paul W.", ""]]}, {"id": "1711.04604", "submitter": "Eva-Maria Hols", "authors": "Eva-Maria C. Hols and Stefan Kratsch", "title": "Smaller parameters for vertex cover kernelization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the topic of polynomial kernels for Vertex Cover relative to\nstructural parameters. Our starting point is a recent paper due to Fomin and\nStr{\\o}mme [WG 2016] who gave a kernel with $\\mathcal{O}(|X|^{12})$ vertices\nwhen $X$ is a vertex set such that each connected component of $G-X$ contains\nat most one cycle, i.e., $X$ is a modulator to a pseudoforest. We strongly\ngeneralize this result by using modulators to $d$-quasi-forests, i.e., graphs\nwhere each connected component has a feedback vertex set of size at most $d$,\nand obtain kernels with $\\mathcal{O}(|X|^{3d+9})$ vertices. Our result relies\non proving that minimal blocking sets in a $d$-quasi-forest have size at most\n$d+2$. This bound is tight and there is a related lower bound of\n$\\mathcal{O}(|X|^{d+2-\\epsilon})$ on the bit size of kernels.\n  In fact, we also get bounds for minimal blocking sets of more general graph\nclasses: For $d$-quasi-bipartite graphs, where each connected component can be\nmade bipartite by deleting at most $d$ vertices, we get the same tight bound of\n$d+2$ vertices. For graphs whose connected components each have a vertex cover\nof cost at most $d$ more than the best fractional vertex cover, which we call\n$d$-quasi-integral, we show that minimal blocking sets have size at most\n$2d+2$, which is also tight. Combined with existing randomized polynomial\nkernelizations this leads to randomized polynomial kernelizations for\nmodulators to $d$-quasi-bipartite and $d$-quasi-integral graphs. There are\nlower bounds of $\\mathcal{O}(|X|^{d+2-\\epsilon})$ and\n$\\mathcal{O}(|X|^{2d+2-\\epsilon})$ for the bit size of such kernels.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 14:48:26 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Hols", "Eva-Maria C.", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1711.05157", "submitter": "Lars Jaffke", "authors": "Lars Jaffke and O-joung Kwon and Jan Arne Telle", "title": "A note on the complexity of Feedback Vertex Set parameterized by\n  mim-width", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We complement the recent algorithmic result that Feedback Vertex Set is\nXP-time solvable parameterized by the mim-width of a given branch decomposition\nof the input graph [3] by showing that the problem is W[1]-hard in this\nparameterization. The hardness holds even for linear mim-width, as well as for\nH-graphs, where the parameter is the number of edges in H. To obtain this\nresult, we adapt a reduction due to Fomin, Golovach and Raymond [2], following\nthe same line of reasoning but adding a new gadget.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 15:56:37 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Jaffke", "Lars", ""], ["Kwon", "O-joung", ""], ["Telle", "Jan Arne", ""]]}, {"id": "1711.05408", "submitter": "Yining Chen", "authors": "Yining Chen, Sorcha Gilroy, Andreas Maletti, Jonathan May, Kevin\n  Knight", "title": "Recurrent Neural Networks as Weighted Language Recognizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the computational complexity of various problems for simple\nrecurrent neural networks (RNNs) as formal models for recognizing weighted\nlanguages. We focus on the single-layer, ReLU-activation, rational-weight RNNs\nwith softmax, which are commonly used in natural language processing\napplications. We show that most problems for such RNNs are undecidable,\nincluding consistency, equivalence, minimization, and the determination of the\nhighest-weighted string. However, for consistent RNNs the last problem becomes\ndecidable, although the solution length can surpass all computable bounds. If\nadditionally the string is limited to polynomial length, the problem becomes\nNP-complete and APX-hard. In summary, this shows that approximations and\nheuristic algorithms are necessary in practical applications of those RNNs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 04:54:08 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2018 18:27:59 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Chen", "Yining", ""], ["Gilroy", "Sorcha", ""], ["Maletti", "Andreas", ""], ["May", "Jonathan", ""], ["Knight", "Kevin", ""]]}, {"id": "1711.05762", "submitter": "Yi Zhou", "authors": "Guanghui Lan and Yi Zhou", "title": "Random gradient extrapolation for distributed and stochastic\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a class of finite-sum convex optimization problems\ndefined over a distributed multiagent network with $m$ agents connected to a\ncentral server. In particular, the objective function consists of the average\nof $m$ ($\\ge 1$) smooth components associated with each network agent together\nwith a strongly convex term. Our major contribution is to develop a new\nrandomized incremental gradient algorithm, namely random gradient extrapolation\nmethod (RGEM), which does not require any exact gradient evaluation even for\nthe initial point, but can achieve the optimal ${\\cal O}(\\log(1/\\epsilon))$\ncomplexity bound in terms of the total number of gradient evaluations of\ncomponent functions to solve the finite-sum problems. Furthermore, we\ndemonstrate that for stochastic finite-sum optimization problems, RGEM\nmaintains the optimal ${\\cal O}(1/\\epsilon)$ complexity (up to a certain\nlogarithmic factor) in terms of the number of stochastic gradient computations,\nbut attains an ${\\cal O}(\\log(1/\\epsilon))$ complexity in terms of\ncommunication rounds (each round involves only one agent). It is worth noting\nthat the former bound is independent of the number of agents $m$, while the\nlatter one only linearly depends on $m$ or even $\\sqrt m$ for ill-conditioned\nproblems. To the best of our knowledge, this is the first time that these\ncomplexity bounds have been obtained for distributed and stochastic\noptimization problems. Moreover, our algorithms were developed based on a novel\ndual perspective of Nesterov's accelerated gradient method.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 19:18:59 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Lan", "Guanghui", ""], ["Zhou", "Yi", ""]]}, {"id": "1711.05796", "submitter": "Austin Conner", "authors": "Austin Conner", "title": "A rank 18 Waring decomposition of $sM_{\\langle 3\\rangle}$ with 432\n  symmetries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent discovery that the exponent of matrix multiplication is determined\nby the rank of the symmetrized matrix multiplication tensor has invigorated\ninterest in better understanding symmetrized matrix multiplication. I present\nan explicit rank 18 Waring decomposition of $sM_{\\langle 3\\rangle}$ and\ndescribe its symmetry group.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 20:41:08 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Conner", "Austin", ""]]}, {"id": "1711.05807", "submitter": "Eugene Kogan", "authors": "Eugene Kogan", "title": "Set complexity of construction of a regular polygon", "comments": "6 pages, in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a subset of $\\mathbb C$ containing $x,y$, one can add $x + y,\\,x -\ny,\\,xy$ or (when $y\\ne0$) $x/y$ or any $z$ such that $z^2=x$. Let $p$ be a\nprime Fermat number. We prove that it is possible to obtain from $\\{1\\}$ a set\ncontaining all the $p$-th roots of 1 by $12 p^2$ above operations. This result\nis different from the standard estimation of complexity of an algorithm\ncomputing the $p$-th roots of 1.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 21:06:09 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 16:10:28 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Kogan", "Eugene", ""]]}, {"id": "1711.05893", "submitter": "Shay Moran", "authors": "Daniel M. Kane and Roi Livni and Shay Moran and Amir Yehudayoff", "title": "On Communication Complexity of Classification Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies distributed learning in the spirit of Yao's model of\ncommunication complexity: consider a two-party setting, where each of the\nplayers gets a list of labelled examples and they communicate in order to\njointly perform some learning task. To naturally fit into the framework of\nlearning theory, the players can send each other examples (as well as bits)\nwhere each example/bit costs one unit of communication. This enables a uniform\ntreatment of infinite classes such as half-spaces in $\\mathbb{R}^d$, which are\nubiquitous in machine learning.\n  We study several fundamental questions in this model. For example, we provide\ncombinatorial characterizations of the classes that can be learned with\nefficient communication in the proper-case as well as in the improper-case.\nThese findings imply unconditional separations between various learning\ncontexts, e.g.\\ realizable versus agnostic learning, proper versus improper\nlearning, etc.\n  The derivation of these results hinges on a type of decision problems we term\n\"{\\it realizability problems}\" where the goal is deciding whether a distributed\ninput sample is consistent with an hypothesis from a pre-specified class.\n  From a technical perspective, the protocols we use are based on ideas from\nmachine learning theory and the impossibility results are based on ideas from\ncommunication complexity theory.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 02:13:55 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 01:35:08 GMT"}, {"version": "v3", "created": "Mon, 23 Apr 2018 15:02:18 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Kane", "Daniel M.", ""], ["Livni", "Roi", ""], ["Moran", "Shay", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1711.07132", "submitter": "Jackson Abascal", "authors": "Jackson Abascal, Shir Maimon", "title": "Critique of Barbosa's \"P != NP Proof\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review Andr\\'e Luiz Barbosa's paper \"P != NP Proof,\" in which the classes\nP and NP are generalized and claimed to be proven separate. We highlight\ninherent ambiguities in Barbosa's definitions, and show that attempts to\nresolve this ambiguity lead to flaws in the proof of his main result.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 03:51:53 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Abascal", "Jackson", ""], ["Maimon", "Shir", ""]]}, {"id": "1711.07211", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane and Alistair Stewart", "title": "List-Decodable Robust Mean Estimation and Learning Mixtures of Spherical\n  Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of list-decodable Gaussian mean estimation and the\nrelated problem of learning mixtures of separated spherical Gaussians. We\ndevelop a set of techniques that yield new efficient algorithms with\nsignificantly improved guarantees for these problems.\n  {\\bf List-Decodable Mean Estimation.} Fix any $d \\in \\mathbb{Z}_+$ and $0<\n\\alpha <1/2$. We design an algorithm with runtime $O\n(\\mathrm{poly}(n/\\alpha)^{d})$ that outputs a list of $O(1/\\alpha)$ many\ncandidate vectors such that with high probability one of the candidates is\nwithin $\\ell_2$-distance $O(\\alpha^{-1/(2d)})$ from the true mean. The only\nprevious algorithm for this problem achieved error $\\tilde O(\\alpha^{-1/2})$\nunder second moment conditions. For $d = O(1/\\epsilon)$, our algorithm runs in\npolynomial time and achieves error $O(\\alpha^{\\epsilon})$. We also give a\nStatistical Query lower bound suggesting that the complexity of our algorithm\nis qualitatively close to best possible.\n  {\\bf Learning Mixtures of Spherical Gaussians.} We give a learning algorithm\nfor mixtures of spherical Gaussians that succeeds under significantly weaker\nseparation assumptions compared to prior work. For the prototypical case of a\nuniform mixture of $k$ identity covariance Gaussians we obtain: For any\n$\\epsilon>0$, if the pairwise separation between the means is at least\n$\\Omega(k^{\\epsilon}+\\sqrt{\\log(1/\\delta)})$, our algorithm learns the unknown\nparameters within accuracy $\\delta$ with sample complexity and running time\n$\\mathrm{poly} (n, 1/\\delta, (k/\\epsilon)^{1/\\epsilon})$. The previously best\nknown polynomial time algorithm required separation at least $k^{1/4}\n\\mathrm{polylog}(k/\\delta)$.\n  Our main technical contribution is a new technique, using degree-$d$\nmultivariate polynomials, to remove outliers from high-dimensional datasets\nwhere the majority of the points are corrupted.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 09:07:08 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""]]}, {"id": "1711.07214", "submitter": "Chao Qian", "authors": "Chao Qian, Yang Yu, Ke Tang, Xin Yao, Zhi-Hua Zhou", "title": "Maximizing Non-monotone/Non-submodular Functions by Multi-objective\n  Evolutionary Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms (EAs) are a kind of nature-inspired general-purpose\noptimization algorithm, and have shown empirically good performance in solving\nvarious real-word optimization problems. However, due to the highly randomized\nand complex behavior, the theoretical analysis of EAs is difficult and is an\nongoing challenge, which has attracted a lot of research attentions. During the\nlast two decades, promising results on the running time analysis (one essential\ntheoretical aspect) of EAs have been obtained, while most of them focused on\nisolated combinatorial optimization problems, which do not reflect the\ngeneral-purpose nature of EAs. To provide a general theoretical explanation of\nthe behavior of EAs, it is desirable to study the performance of EAs on a\ngeneral class of combinatorial optimization problems. To the best of our\nknowledge, this direction has been rarely touched and the only known result is\nthe provably good approximation guarantees of EAs for the problem class of\nmaximizing monotone submodular set functions with matroid constraints, which\nincludes many NP-hard combinatorial optimization problems. The aim of this work\nis to contribute to this line of research. As many combinatorial optimization\nproblems also involve non-monotone or non-submodular objective functions, we\nconsider these two general problem classes, maximizing non-monotone submodular\nfunctions without constraints and maximizing monotone non-submodular functions\nwith a size constraint. We prove that a simple multi-objective EA called GSEMO\ncan generally achieve good approximation guarantees in polynomial expected\nrunning time.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 09:21:19 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Qian", "Chao", ""], ["Yu", "Yang", ""], ["Tang", "Ke", ""], ["Yao", "Xin", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1711.07285", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam, Jop Bri\\\"et, Carlos Palazuelos", "title": "Quantum Query Algorithms are Completely Bounded Forms", "comments": "24 pages, 3 figures. v2: 27 pages, minor changes in response to\n  referee comments", "journal-ref": "SIAM Journal on Computing, Vol. 48, 903-925, 2019", "doi": "10.1137/18M117563X", "report-no": null, "categories": "quant-ph cs.CC math.FA math.OA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a characterization of $t$-query quantum algorithms in terms of the\nunit ball of a space of degree-$2t$ polynomials. Based on this, we obtain a\nrefined notion of approximate polynomial degree that equals the quantum query\ncomplexity, answering a question of Aaronson et al. (CCC'16). Our proof is\nbased on a fundamental result of Christensen and Sinclair (J. Funct. Anal.,\n1987) that generalizes the well-known Stinespring representation for quantum\nchannels to multilinear forms. Using our characterization, we show that many\npolynomials of degree four are far from those coming from two-query quantum\nalgorithms. We also give a simple and short proof of one of the results of\nAaronson et al. showing an equivalence between one-query quantum algorithms and\nbounded quadratic polynomials.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 12:30:20 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 00:17:08 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Bri\u00ebt", "Jop", ""], ["Palazuelos", "Carlos", ""]]}, {"id": "1711.07320", "submitter": "Albert Atserias", "authors": "Albert Atserias and Joanna Ochremiak", "title": "Proof Complexity Meets Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse how the standard reductions between constraint satisfaction\nproblems affect their proof complexity. We show that, for the most studied\npropositional, algebraic, and semi-algebraic proof systems, the classical\nconstructions of pp-interpretability, homomorphic equivalence and addition of\nconstants to a core preserve the proof complexity of the CSP. As a result, for\nthose proof systems, the classes of constraint languages for which small\nunsatisfiability certificates exist can be characterised algebraically. We\nillustrate our results by a gap theorem saying that a constraint language\neither has resolution refutations of constant width, or does not have\nbounded-depth Frege refutations of subexponential size. The former holds\nexactly for the widely studied class of constraint languages of bounded width.\nThis class is also known to coincide with the class of languages with\nrefutations of sublinear degree in Sums-of-Squares and Polynomial Calculus over\nthe real-field, for which we provide alternative proofs. We then ask for the\nexistence of a natural proof system with good behaviour with respect to\nreductions and simultaneously small size refutations beyond bounded width. We\ngive an example of such a proof system by showing that bounded-degree\nLov\\'asz-Schrijver satisfies both requirements. Finally, building on the known\nlower bounds, we demonstrate the applicability of the method of reducibilities\nand construct new explicit hard instances of the graph 3-coloring problem for\nall studied proof systems.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 14:37:34 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 08:49:54 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Atserias", "Albert", ""], ["Ochremiak", "Joanna", ""]]}, {"id": "1711.07474", "submitter": "Bernd Schuh", "authors": "Bernd. R. Schuh", "title": "XSAT of Linear CNF Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open questions with respect to the computational complexity of linear CNF\nformulas in connection with regularity and uniformity are addressed. In\nparticular it is proven that any l-regular monotone CNF formula is\nXSAT-unsatisfiable if its number of clauses m is not a multiple of l. For exact\nlinear formulas one finds surprisingly that l-regularity implies k-uniformity,\nwith m = 1 + k(l-1)) and allowed k-values obey k(k-1) = 0 (mod l). Then the\ncomputational complexity of the class of monotone exact linear and l-regular\nCNF formulas with respect to XSAT can be determined: XSAT-satisfiability is\neither trivial, if m is not a multiple of l, or it can be decided in\nsub-exponential time, namely O(exp(n^^1/2)). Sub-exponential time behaviour for\nthe wider class of regular and uniform linear CNF formulas can be shown for\ncertain subclasses.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 10:04:20 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 08:09:06 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Schuh", "Bernd. R.", ""]]}, {"id": "1711.07960", "submitter": "Quanquan C. Liu", "authors": "Erik D. Demaine, Andrea Lincoln, Quanquan C. Liu, Jayson Lynch,\n  Virginia Vassilevska Williams", "title": "Fine-Grained I/O Complexity via Reductions: New lower bounds, faster\n  algorithms, and a time hierarchy", "comments": "To appear in ITCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper initiates the study of I/O algorithms (minimizing cache misses)\nfrom the perspective of fine-grained complexity (conditional polynomial lower\nbounds). Specifically, we aim to answer why sparse graph problems are so hard,\nand why the Longest Common Subsequence problem gets a savings of a factor of\nthe size of cache times the length of a cache line, but no more. We take the\nreductions and techniques from complexity and fine-grained complexity and apply\nthem to the I/O model to generate new (conditional) lower bounds as well as\nfaster algorithms. We also prove the existence of a time hierarchy for the I/O\nmodel, which motivates the fine-grained reductions.\n  Using fine-grained reductions, we give an algorithm for distinguishing 2 vs.\n3 diameter and radius that runs in $O(|E|^2/(MB))$ cache misses, which for\nsparse graphs improves over the previous $O(|V|^2/B)$ running time. We give new\nreductions from radius and diameter to Wiener index and median. We show\nmeaningful reductions between problems that have linear-time solutions in the\nRAM model. The reductions use low I/O complexity (typically $O(n/B)$), and thus\nhelp to finely capture the relationship between \"I/O linear time\" $\\Theta(n/B)$\nand RAM linear time $\\Theta(n)$. We generate new I/O assumptions based on the\ndifficulty of improving sparse graph problem running times in the I/O model. We\ncreate conjectures that the current best known algorithms for Single Source\nShortest Paths (SSSP), diameter, and radius are optimal. From these I/O-model\nassumptions, we show that many of the known reductions in the word-RAM model\ncan naturally extend to hold in the I/O model as well (e.g., a lower bound on\nthe I/O complexity of Longest Common Subsequence that matches the best known\nrunning time). Finally, we prove an analog of the Time Hierarchy Theorem in the\nI/O model.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 18:37:27 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 21:39:31 GMT"}, {"version": "v3", "created": "Tue, 5 Dec 2017 01:22:10 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Demaine", "Erik D.", ""], ["Lincoln", "Andrea", ""], ["Liu", "Quanquan C.", ""], ["Lynch", "Jayson", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1711.08039", "submitter": "Michael Walter", "authors": "Peter B\\\"urgisser and Ankit Garg and Rafael Oliveira and Michael\n  Walter and Avi Wigderson", "title": "Alternating minimization, scaling algorithms, and the null-cone problem\n  from invariant theory", "comments": "48 pages", "journal-ref": "Proceedings of the 9th Innovations in Theoretical Computer Science\n  Conference (ITCS 2018), 24:1--24:20", "doi": "10.4230/LIPIcs.ITCS.2018.24", "report-no": null, "categories": "cs.CC math-ph math.AG math.MP quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating minimization heuristics seek to solve a (difficult) global\noptimization task through iteratively solving a sequence of (much easier) local\noptimization tasks on different parts (or blocks) of the input parameters.\nWhile popular and widely applicable, very few examples of this heuristic are\nrigorously shown to converge to optimality, and even fewer to do so\nefficiently.\n  In this paper we present a general framework which is amenable to rigorous\nanalysis, and expose its applicability. Its main feature is that the local\noptimization domains are each a group of invertible matrices, together\nnaturally acting on tensors, and the optimization problem is minimizing the\nnorm of an input tensor under this joint action. The solution of this\noptimization problem captures a basic problem in Invariant Theory, called the\nnull-cone problem.\n  This algebraic framework turns out to encompass natural computational\nproblems in combinatorial optimization, algebra, analysis, quantum information\ntheory, and geometric complexity theory. It includes and extends to high\ndimensions the recent advances on (2-dimensional) operator scaling.\n  Our main result is a fully polynomial time approximation scheme for this\ngeneral problem, which may be viewed as a multi-dimensional scaling algorithm.\nThis directly leads to progress on some of the problems in the areas above, and\na unified view of others. We explain how faster convergence of an algorithm for\nthe same problem will allow resolving central open problems.\n  Our main techniques come from Invariant Theory, and include its rich\nnon-commutative duality theory, and new bounds on the bitsizes of coefficients\nof invariant polynomials. They enrich the algorithmic toolbox of this very\ncomputational field of mathematics, and are directly related to some challenges\nin geometric complexity theory (GCT).\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 21:11:10 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["B\u00fcrgisser", "Peter", ""], ["Garg", "Ankit", ""], ["Oliveira", "Rafael", ""], ["Walter", "Michael", ""], ["Wigderson", "Avi", ""]]}, {"id": "1711.08082", "submitter": "Jakub Mare\\v{c}ek", "authors": "Jing Xu, Jakub Marecek", "title": "Parameter Estimation in Gaussian Mixture Models with Malicious Noise,\n  without Balanced Mixing Coefficients", "comments": null, "journal-ref": null, "doi": "10.1109/ALLERTON.2018.8635825", "report-no": null, "categories": "math.ST cs.CC cs.DS stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating means of two Gaussians in a 2-Gaussian\nmixture, which is not balanced and is corrupted by noise of an arbitrary\ndistribution. We present a robust algorithm to estimate the parameters,\ntogether with upper bounds on the numbers of samples required for the estimate\nto be correct, where the bounds are parametrised by the dimension, ratio of the\nmixing coefficients, a measure of the separation of the two Gaussians, related\nto Mahalanobis distance, and a condition number of the covariance matrix. In\ntheory, this is the first sample-complexity result for imbalanced mixtures\ncorrupted by adversarial noise. In practice, our algorithm outperforms the\nvanilla Expectation-Maximisation (EM) algorithm in terms of estimation error.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 23:20:12 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Xu", "Jing", ""], ["Marecek", "Jakub", ""]]}, {"id": "1711.08731", "submitter": "Jesper Larsson Tr\\\"aff", "authors": "Jesper Larsson Tr\\\"aff", "title": "On Optimal Trees for Irregular Gather and Scatter Collectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of finding communication trees with the lowest\npossible completion time for rooted, irregular gather and scatter collective\ncommunication operations in fully connected, $k$-ported communication networks\nunder a linear-time transmission cost model. Consecutively numbered processors\nspecify data blocks of possibly different sizes to be collected at or\ndistributed from some (given) root processor where they are stored in processor\norder. Data blocks can be combined into larger segments consisting of blocks\nfrom or to different processors, but individual blocks cannot be split. We\ndistinguish between ordered and non-ordered communication trees depending on\nwhether segments of blocks are maintained in processor order. We show that\nlowest completion time, ordered communication trees under one-ported\ncommunication can be found in polynomial time by giving simple, but costly\ndynamic programming algorithms. In contrast, we show that it is an NP-complete\nproblem to construct cost-optimal, non-ordered communication trees. We have\nimplemented the dynamic programming algorithms for homogeneous networks to\nevaluate the quality of different types of communication trees, in particular\nto analyze a recent, distributed, problem-adaptive tree construction algorithm.\nModel experiments show that this algorithm is close to the optimum for a\nselection of block size distributions. A concrete implementation for specially\nstructured problems shows that optimal, non-binomial trees can possibly have\neven further practical advantage.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 15:07:08 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 13:45:56 GMT"}, {"version": "v3", "created": "Wed, 13 Dec 2017 07:36:19 GMT"}, {"version": "v4", "created": "Tue, 27 Nov 2018 14:27:58 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Tr\u00e4ff", "Jesper Larsson", ""]]}, {"id": "1711.08852", "submitter": "Eleni Bakali", "authors": "Eleni Bakali", "title": "Relating counting complexity to non-uniform probability measures", "comments": "this article draws heavily from arXiv:1611.01706", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard method for designing randomized algorithms to approximately count\nthe number of solutions of a problem in $\\#$P, is by constructing a rapidly\nmixing Markov chain converging to the uniform distribution over this set of\nsolutions. This construction is not always an easy task, and it is conjectured\nthat it is not always possible. We want to investigate other possibilities for\nusing Markov Chains in relation to counting, and whether we can relate\nalgorithmic counting to other, non-uniform, probability distributions over the\nset we want to count.\n  In this paper we present a family of probability distributions over the set\nof solutions of a problem in TotP, and show how they relate to counting;\ncounting is equivalent to computing their normalizing factors. We analyse the\ncomplexity of sampling, of computing the normalizing factor, and of computing\nthe size support of these distributions. The latter is also equivalent to\ncounting. We also show how the above tasks relate to each other, and to other\nproblems in complexity theory as well.\n  In short, we prove that sampling and approximating the normalizing factor is\neasy. We do this by constructing a family of rapidly mixing Markov chains for\nwhich these distributions are stationary. At the same time we show that exactly\ncomputing the normalizing factor is TotP-hard. However the reduction proving\nthe latter is not approximation preserving, which conforms with the fact that\nTotP-hard problems are inapproximable if NP $\\neq$ RP.\n  The problem we consider is the Size-of-Subtree, a TotP-complete problem under\nparsimonious reductions. Therefore the results presented here extend to any\nproblem in TotP. TotP is the Karp-closure of self-reducible problems in $\\#$P,\nhaving decision version in P.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 01:24:55 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Bakali", "Eleni", ""]]}, {"id": "1711.08885", "submitter": "Murali Krishna Enduri", "authors": "Bireswar Das, Murali Krishna Enduri, I. Vinod Reddy", "title": "On the Parallel Parameterized Complexity of the Graph Isomorphism\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the parallel and the space complexity of the graph\nisomorphism problem (\\GI{}) for several parameterizations. Let\n$\\mathcal{H}=\\{H_1,H_2,\\cdots,H_l\\}$ be a finite set of graphs where\n$|V(H_i)|\\leq d$ for all $i$ and for some constant $d$. Let $\\mathcal{G}$ be an\n$\\mathcal{H}$-free graph class i.e., none of the graphs $G\\in \\mathcal{G}$\ncontain any $H \\in \\mathcal{H}$ as an induced subgraph. We show that \\GI{}\nparameterized by vertex deletion distance to $\\mathcal{G}$ is in a\nparameterized version of $\\AC^1$, denoted $\\PL$-$\\AC^1$, provided the colored\ngraph isomorphism problem for graphs in $\\mathcal{G}$ is in $\\AC^1$. From this,\nwe deduce that \\GI{} parameterized by the vertex deletion distance to cographs\nis in $\\PL$-$\\AC^1$.\n  The parallel parameterized complexity of \\GI{} parameterized by the size of a\nfeedback vertex set remains an open problem. Towards this direction we show\nthat the graph isomorphism problem is in $\\PL$-$\\TC^0$ when parameterized by\nvertex cover or by twin-cover.\n  Let $\\mathcal{G}'$ be a graph class such that recognizing graphs from\n$\\mathcal{G}'$ and the colored version of \\GI{} for $\\mathcal{G}'$ is in\nlogspace ($\\L$). We show that \\GI{} for bounded vertex deletion distance to\n$\\mathcal{G}'$ is in $\\L$. From this, we obtain logspace algorithms for \\GI{}\nfor graphs with bounded vertex deletion distance to interval graphs and graphs\nwith bounded vertex deletion distance to cographs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 07:14:33 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 11:01:38 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Das", "Bireswar", ""], ["Enduri", "Murali Krishna", ""], ["Reddy", "I. Vinod", ""]]}, {"id": "1711.09148", "submitter": "Wolfgang Dvo\\v{r}\\'ak", "authors": "Krishnendu Chatterjee, Wolfgang Dvo\\v{r}\\'ak, Monika Henzinger,\n  Veronika Loitzenbauer", "title": "Lower Bounds for Symbolic Computation on Graphs: Strongly Connected\n  Components, Liveness, Safety, and Diameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of computation that is widely used in the formal analysis of reactive\nsystems is symbolic algorithms. In this model the access to the input graph is\nrestricted to consist of symbolic operations, which are expensive in comparison\nto the standard RAM operations. We give lower bounds on the number of symbolic\noperations for basic graph problems such as the computation of the strongly\nconnected components and of the approximate diameter as well as for fundamental\nproblems in model checking such as safety, liveness, and co-liveness. Our lower\nbounds are linear in the number of vertices of the graph, even for\nconstant-diameter graphs. For none of these problems lower bounds on the number\nof symbolic operations were known before. The lower bounds show an interesting\nseparation of these problems from the reachability problem, which can be solved\nwith $O(D)$ symbolic operations, where $D$ is the diameter of the graph.\n  Additionally we present an approximation algorithm for the graph diameter\nwhich requires $\\tilde{O}(n \\sqrt{D})$ symbolic steps to achieve a\n$(1+\\epsilon)$-approximation for any constant $\\epsilon > 0$. This compares to\n$O(n \\cdot D)$ symbolic steps for the (naive) exact algorithm and $O(D)$\nsymbolic steps for a 2-approximation. Finally we also give a refined analysis\nof the strongly connected components algorithms of Gentilini et al., showing\nthat it uses an optimal number of symbolic steps that is proportional to the\nsum of the diameters of the strongly connected components.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 21:47:11 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Dvo\u0159\u00e1k", "Wolfgang", ""], ["Henzinger", "Monika", ""], ["Loitzenbauer", "Veronika", ""]]}, {"id": "1711.09426", "submitter": "Yuval Filmus", "authors": "Irit Dinur, Yuval Filmus, Prahladh Harsha", "title": "Agreement tests on graphs and hypergraphs", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agreement tests are a generalization of low degree tests that capture a\nlocal-to-global phenomenon, which forms the combinatorial backbone of most PCP\nconstructions. In an agreement test, a function is given by an ensemble of\nlocal restrictions. The agreement test checks that the restrictions agree when\nthey overlap, and the main question is whether average agreement of the local\npieces implies that there exists a global function that agrees with most local\nrestrictions.\n  There are very few structures that support agreement tests, essentially\neither coming from algebraic low degree tests or from direct product tests (and\nrecently also from high-dimensional expanders). In this work, we prove a new\nagreement theorem which extends direct product tests to higher dimensions,\nanalogous to how low degree tests extend linearity testing. As a corollary of\nour main theorem, it follows that an ensemble of small graphs on overlapping\nsets of vertices can be glued together to one global graph assuming they agree\nwith each other on average.\n  We prove the agreement theorem by (re)proving the agreement theorem for\ndimension 1, and then generalizing it to higher dimensions (with the dimension\n1 case being the direct product test, and dimension 2 being the graph case). A\nkey technical step in our proof is the reverse union bound, which allows us to\ntreat dependent events as if they are disjoint, and may be of independent\ninterest. An added benefit of the reverse union bound is that it can be used to\nshow that the \"majority decoded\" function also serves as a global function that\nexplains the local consistency of the agreement theorem, a fact that was not\nknown even in the direct product setting (dimension 1) prior to our work.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 17:20:35 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 13:32:15 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Dinur", "Irit", ""], ["Filmus", "Yuval", ""], ["Harsha", "Prahladh", ""]]}, {"id": "1711.09428", "submitter": "Yuval Filmus", "authors": "Irit Dinur, Yuval Filmus, Prahladh Harsha", "title": "Low degree almost Boolean functions are sparse juntas", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nisan and Szegedy showed that low degree Boolean functions are juntas.\nKindler and Safra showed that low degree functions which are almost Boolean are\nclose to juntas. Their result holds with respect to $\\mu_p$ for every constant\n$p$. When $p$ is allowed to be very small, new phenomena emerge. For example,\nthe function $y_1 + \\cdots + y_{\\epsilon/p}$ (where $y_i \\in \\{0,1\\}$) is close\nto Boolean but not close to a junta.\n  We show that low degree functions which are almost Boolean are close to a new\nclass of functions which we call *sparse juntas*. Roughly speaking, these are\nfunctions which on a random input look like juntas, in the sense that only a\nfinite number of their monomials are non-zero. This extends a result of the\nsecond author for the degree 1 case.\n  As applications of our result, we show that low degree almost Boolean\nfunctions must be very biased, and satisfy a large deviation bound.\n  An interesting aspect of our proof is that it relies on a local-to-global\nagreement theorem. We cover the $p$-biased hypercube by many smaller\ndimensional copies of the uniform hypercube, and approximate our function\nlocally via the Kindler--Safra theorem for constant $p$. We then stitch the\nlocal approximations together into one global function that is a sparse junta.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 17:25:52 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Dinur", "Irit", ""], ["Filmus", "Yuval", ""], ["Harsha", "Prahladh", ""]]}, {"id": "1711.09585", "submitter": "Alex B. Grilo", "authors": "Alex B. Grilo", "title": "A simple protocol for verifiable delegation of quantum computation in\n  one round", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of being able to verify quantum computation delegated to\nremote servers increases with recent development of quantum technologies. In\nsome of the proposed protocols for this task, a client delegates her quantum\ncomputation to non-communicating servers in multiple rounds of communication.\nIn this work, we propose the first protocol where the client delegates her\nquantum computation to two servers in one-round of communication. Another\nadvantage of our protocol is that it is conceptually simpler than previous\nprotocols. The parameters of our protocol also make it possible to prove\nsecurity even if the servers are allowed to communicate but respecting the\nplausible assumption that information cannot be propagated faster than speed of\nlight, making it the first relativistic protocol for quantum computation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 08:53:27 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 11:25:40 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Grilo", "Alex B.", ""]]}, {"id": "1711.10145", "submitter": "Makrand Sinha", "authors": "Makrand Sinha", "title": "Lower Bounds for Approximating the Matching Polytope", "comments": "To appear in proceedings of SODA '18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that any extended formulation that approximates the matching\npolytope on $n$-vertex graphs up to a factor of $(1+\\varepsilon)$ for any\n$\\frac2n \\le \\varepsilon \\le 1$ must have at least\n$\\binom{n}{{\\alpha}/{\\varepsilon}}$ defining inequalities where $0<\\alpha<1$ is\nan absolute constant. This is tight as exhibited by the $(1+\\varepsilon)$\napproximating linear program obtained by dropping the odd set constraints of\nsize larger than $({1+\\varepsilon})/{\\varepsilon}$ from the description of the\nmatching polytope. Previously, a tight lower bound of $2^{\\Omega(n)}$ was only\nknown for $\\varepsilon = O\\left(\\frac{1}{n}\\right)$ [Rothvoss, STOC '14; Braun\nand Pokutta, IEEE Trans. Information Theory '15] whereas for $\\frac2n \\le\n\\varepsilon \\le 1$, the best lower bound was\n$2^{\\Omega\\left({1}/{\\varepsilon}\\right)}$ [Rothvoss, STOC '14]. The key new\ningredient in our proof is a close connection to the non-negative rank of a\nlopsided version of the unique disjointness matrix.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 06:41:18 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Sinha", "Makrand", ""]]}, {"id": "1711.10176", "submitter": "Gleb Posobin", "authors": "Gleb Posobin", "title": "Computing majority with low-fan-in majority queries", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we examine the problem of computing majority function\n$\\mathrm{MAJ}_n$ on $n$ bits by depth-two formula, where each gate is a\nmajority function on at most $k$ inputs. We present such formula that gives the\nfirst nontrivial upper bound for this problem, with $k = \\frac{2}{3} n + 4$.\nThis answers an open question in [Kulikov, Podolskii, 2017].\n  We also look at this problem in adaptive setting - when we are allowed to\nquery for value of $\\mathrm{MAJ}_k$ on any subset, and wish to minimize the\nnumber of such queries. We give a simple lower bound for this setting with\n$\\lceil n/k \\rceil$ queries, and we present two algorithms for this model: the\nfirst one makes $\\approx 2\\frac{n}{k} \\log k$ queries in the case when we are\nlimited to the standard majority functions, and the second one makes\n$\\frac{n}{k} \\log k$ queries when we are allowed to change the threshold of\nmajority function.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 08:38:54 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Posobin", "Gleb", ""]]}, {"id": "1711.10436", "submitter": "Stephane Rivaud", "authors": "Stephane Rivaud, Fran\\c{c}ois Pachet", "title": "Sampling Markov Models under Constraints: Complexity Results for Binary\n  Equalities and Grammar Membership", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at enforcing hard constraints to impose a global structure on\nsequences generated from Markov models. In this report, we study the complexity\nof sampling Markov sequences under two classes of constraints: Binary\nEqualities and Grammar Membership Constraints. First, we give a sketch of proof\nof #P-completeness for binary equalities and identify three sub-cases where\nsampling is polynomial. We then give a proof of #P-completeness for grammar\nmembership, and identify two cases where sampling is tractable. The first\npolynomial sub-case where sampling is tractable is when the grammar is proven\nto be unambiguous. Our main contribution is to identify a new, broader class of\ngrammars for which sampling is tractable. We provide algorithm along with time\nand space complexity for all the polynomial cases we have identified.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 17:50:33 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Rivaud", "Stephane", ""], ["Pachet", "Fran\u00e7ois", ""]]}, {"id": "1711.10530", "submitter": "Florian Steinberg", "authors": "Eike Neumann and Florian Steinberg", "title": "Parametrised second-order complexity theory with applications to the\n  study of interval computation", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the framework for complexity of operators in analysis devised by\nKawamura and Cook (2012) to allow for the treatment of a wider class of\nrepresentations. The main novelty is to endow represented spaces of interest\nwith an additional function on names, called a parameter, which measures the\ncomplexity of a given name. This parameter generalises the size function which\nis usually used in second-order complexity theory and therefore also central to\nthe framework of Kawamura and Cook. The complexity of an algorithm is measured\nin terms of its running time as a second-order function in the parameter, as\nwell as in terms of how much it increases the complexity of a given name, as\nmeasured by the parameters on the input and output side.\n  As an application we develop a rigorous computational complexity theory for\ninterval computation. In the framework of Kawamura and Cook the representation\nof real numbers based on nested interval enclosures does not yield a reasonable\ncomplexity theory. In our new framework this representation is polytime\nequivalent to the usual Cauchy representation based on dyadic rational\napproximation. By contrast, the representation of continuous real functions\nbased on interval enclosures is strictly smaller in the polytime reducibility\nlattice than the usual representation, which encodes a modulus of continuity.\nFurthermore, the function space representation based on interval enclosures is\noptimal in the sense that it contains the minimal amount of information amongst\nthose representations which render evaluation polytime computable.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 19:48:59 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 12:21:36 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Neumann", "Eike", ""], ["Steinberg", "Florian", ""]]}, {"id": "1711.10605", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae, Yuki Takeuchi, Harumichi Nishimura", "title": "Merlin-Arthur with efficient quantum Merlin and quantum supremacy for\n  the second level of the Fourier hierarchy", "comments": "30 pages, 4 figures", "journal-ref": "Quantum 2, 106 (2018)", "doi": "10.22331/q-2018-11-15-106", "report-no": "YITP-18-05", "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a simple sub-universal quantum computing model, which we call\nthe Hadamard-classical circuit with one-qubit (HC1Q) model. It consists of a\nclassical reversible circuit sandwiched by two layers of Hadamard gates, and\ntherefore it is in the second level of the Fourier hierarchy. We show that\noutput probability distributions of the HC1Q model cannot be classically\nefficiently sampled within a multiplicative error unless the polynomial-time\nhierarchy collapses to the second level. The proof technique is different from\nthose used for previous sub-universal models, such as IQP, Boson Sampling, and\nDQC1, and therefore the technique itself might be useful for finding other\nsub-universal models that are hard to classically simulate. We also study the\nclassical verification of quantum computing in the second level of the Fourier\nhierarchy. To this end, we define a promise problem, which we call the\nprobability distribution distinguishability with maximum norm (PDD-Max). It is\na promise problem to decide whether output probability distributions of two\nquantum circuits are far apart or close. We show that PDD-Max is BQP-complete,\nbut if the two circuits are restricted to some types in the second level of the\nFourier hierarchy, such as the HC1Q model or the IQP model, PDD-Max has a\nMerlin-Arthur system with quantum polynomial-time Merlin and classical\nprobabilistic polynomial-time Arthur.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 23:05:52 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 01:27:47 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 11:35:05 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Morimae", "Tomoyuki", ""], ["Takeuchi", "Yuki", ""], ["Nishimura", "Harumichi", ""]]}, {"id": "1711.10661", "submitter": "Alexander A. Sherstov", "authors": "Vladimir V. Podolskii and Alexander A. Sherstov", "title": "Inner Product and Set Disjointness: Beyond Logarithmically Many Parties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic goal in complexity theory is to understand the communication\ncomplexity of number-on-the-forehead problems\n$f\\colon(\\{0,1\\}^n)^{k}\\to\\{0,1\\}$ with $k\\gg\\log n$ parties. We study the\nproblems of inner product and set disjointness and determine their randomized\ncommunication complexity for every $k\\geq\\log n$, showing in both cases that\n$\\Theta(1+\\lceil\\log n\\rceil/\\log\\lceil1+k/\\log n\\rceil)$ bits are necessary\nand sufficient. In particular, these problems admit constant-cost protocols if\nand only if the number of parties is $k\\geq n^{\\epsilon}$ for some constant\n$\\epsilon>0.$\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 03:30:23 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Podolskii", "Vladimir V.", ""], ["Sherstov", "Alexander A.", ""]]}, {"id": "1711.11029", "submitter": "Karthik C. S.", "authors": "Karthik C. S., Bundit Laekhanukit, and Pasin Manurangsi", "title": "On the Parameterized Complexity of Approximating Dominating Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of approximating the $k$-Dominating Set\n(DomSet) problem where an integer $k$ and a graph $G$ on $n$ vertices are given\nas input, and the goal is to find a dominating set of size at most $F(k) \\cdot\nk$ whenever the graph $G$ has a dominating set of size $k$. When such an\nalgorithm runs in time $T(k) \\cdot poly(n)$ (i.e., FPT-time) for some\ncomputable function $T$, it is said to be an $F(k)$-FPT-approximation algorithm\nfor $k$-DomSet. We prove the following for every computable functions $T, F$\nand every constant $\\varepsilon > 0$:\n  $\\bullet$ Assuming $W[1]\\neq FPT$, there is no $F(k)$-FPT-approximation\nalgorithm for $k$-DomSet.\n  $\\bullet$ Assuming the Exponential Time Hypothesis (ETH), there is no\n$F(k)$-approximation algorithm for $k$-DomSet that runs in $T(k) \\cdot\nn^{o(k)}$ time.\n  $\\bullet$ Assuming the Strong Exponential Time Hypothesis (SETH), for every\ninteger $k \\geq 2$, there is no $F(k)$-approximation algorithm for $k$-DomSet\nthat runs in $T(k) \\cdot n^{k - \\varepsilon}$ time.\n  $\\bullet$ Assuming the $k$-Sum Hypothesis, for every integer $k \\geq 3$,\nthere is no $F(k)$-approximation algorithm for $k$-DomSet that runs in $T(k)\n\\cdot n^{\\lceil k/2 \\rceil - \\varepsilon}$ time.\n  Our results are obtained by establishing a connection between communication\ncomplexity and hardness of approximation, generalizing the ideas from a recent\nbreakthrough work of Abboud et al. [FOCS 2017]. Specifically, we show that to\nprove hardness of approximation of a certain parameterized variant of the label\ncover problem, it suffices to devise a specific protocol for a communication\nproblem that depends on which hypothesis we rely on. Each of these\ncommunication problems turns out to be either a well studied problem or a\nvariant of one; this allows us to easily apply known techniques to solve them.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 18:58:47 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 16:53:20 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["S.", "Karthik C.", ""], ["Laekhanukit", "Bundit", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "1711.11158", "submitter": "Hao Wu", "authors": "Hao Wu", "title": "A note on time hierarchies for reasonable semantic classes without\n  advice", "comments": "There is a mistake in the argument,take BPTIME as example, after\n  fixing the advice,the new uniform probablistic machine probably won't satisfy\n  BP promise any more. Pointed out by Professor Fortnow", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show time hierarchies for reasonable semantic classes without advice by\neliminating the constant bits of advice in previous results.The elimination is\ndone by a contrapositive argument that for any reasonable computational\nmodel,let $\\text{CTIME}(f(n))/{g(n)}$ denote the set of all languages decide by\nmachines running in time $O(f(n))$ with advice of $g(n)$ bits in that model, if\n$\\text{CTIME}(t(n))\\subseteq \\text{CTIME}(T(n))/{A(n)}$ then\n$\\text{CTIME}(t(n))/a \\subseteq \\text{CTIME}(T(n))/{a+2^aA(n)}$ where $a$ is a\nconstant integer.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 23:49:59 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 13:14:26 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Wu", "Hao", ""]]}, {"id": "1711.11336", "submitter": "Renato Portugal", "authors": "Renato Portugal", "title": "Element Distinctness Revisited", "comments": "14 pages", "journal-ref": "Quantum Inf. Process. 17, 163, 2018", "doi": "10.1007/s11128-018-1930-x", "report-no": null, "categories": "quant-ph cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The element distinctness problem is the problem of determining whether the\nelements of a list are distinct, that is, if $x=(x_1,...,x_N)$ is a list with\n$N$ elements, we ask whether the elements of $x$ are distinct or not. The\nsolution in a classical computer requires $N$ queries because it uses sorting\nto check whether there are equal elements. In the quantum case, it is possible\nto solve the problem in $O(N^{2/3})$ queries. There is an extension which asks\nwhether there are $k$ colliding elements, known as element $k$-distinctness\nproblem.\n  This work obtains optimal values of two critical parameters of Ambainis'\nseminal quantum algorithm [SIAM J.~Comput., 37, 210-239, 2007]. The first\ncritical parameter is the number of repetitions of the algorithm's main block,\nwhich inverts the phase of the marked elements and calls a subroutine. The\nsecond parameter is the number of quantum walk steps interlaced by oracle\nqueries. We show that, when the optimal values of the parameters are used, the\nalgorithm's success probability is $1-O(N^{1/(k+1)})$, quickly approaching 1.\nThe specification of the exact running time and success probability is\nimportant in practical applications of this algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 12:06:28 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 21:05:37 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 18:54:59 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Portugal", "Renato", ""]]}, {"id": "1711.11469", "submitter": "Aaron Potechin", "authors": "Aaron Potechin", "title": "Sum of squares lower bounds from symmetry and a good story", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop machinery which makes it much easier to prove sum\nof squares lower bounds when the problem is symmetric under permutations of\n$[1,n]$ and the unsatisfiability of our problem comes from integrality\narguments, i.e. arguments that an expression must be an integer. Roughly\nspeaking, to prove SOS lower bounds with our machinery it is sufficient to\nverify that the answer to the following three questions is yes:\n  1. Are there natural pseudo-expectation values for the problem?\n  2. Are these pseudo-expectation values rational functions of the problem\nparameters?\n  3. Are there sufficiently many values of the parameters for which these\npseudo-expectation values correspond to the actual expected values over a\ndistribution of solutions which is the uniform distribution over permutations\nof a single solution?\n  We demonstrate our machinery on three problems, the knapsack problem analyzed\nby Grigoriev, the MOD 2 principle (which says that the complete graph $K_n$ has\nno perfect matching when $n$ is odd), and the following Turan type problem:\nMinimize the number of triangles in a graph $G$ with a given edge density. For\nknapsack, we recover Grigoriev's lower bound exactly. For the MOD 2 principle,\nwe tighten Grigoriev's linear degree sum of squares lower bound, making it\nexact. Finally, for the triangle problem, we prove a sum of squares lower bound\nfor finding the minimum triangle density. This lower bound is completely new\nand gives a simple example where constant degree sum of squares methods have a\nconstant factor error in estimating graph densities.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 15:47:13 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 14:20:45 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2018 00:11:25 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Potechin", "Aaron", ""]]}, {"id": "1711.11497", "submitter": "Nikhil Srivastava", "authors": "Prasad Raghavendra and Nick Ryder and Nikhil Srivastava and Benjamin\n  Weitz", "title": "Exponential lower bounds on spectrahedral representations of\n  hyperbolicity cones", "comments": "Fixed a mistake in the proof of Lemma 6. The statement is unchanged\n  except for constant factors, and the main theorem is unaffected. Wrote a\n  slightly stronger statement for the main theorem, emphasizing approximate\n  representations (the proof is the same). Added one figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generalized Lax Conjecture asks whether every hyperbolicity cone is a\nsection of a semidefinite cone of sufficiently high dimension. We prove that\nthe space of hyperbolicity cones of hyperbolic polynomials of degree $d$ in $n$\nvariables contains $(n/d)^{\\Omega(d)}$ pairwise distant cones in a certain\nmetric, and therefore that any semidefinite representation of such cones must\nhave dimension at least $(n/d)^{\\Omega(d)}$ (even if a small approximation is\nallowed). The proof contains several ingredients of independent interest,\nincluding the identification of a large subspace in which the elementary\nsymmetric polynomials lie in the relative interior of the set of hyperbolic\npolynomials, and quantitative versions of several basic facts about real rooted\npolynomials.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 16:23:12 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 18:55:17 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Raghavendra", "Prasad", ""], ["Ryder", "Nick", ""], ["Srivastava", "Nikhil", ""], ["Weitz", "Benjamin", ""]]}, {"id": "1711.11560", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne, Ilias Diakonikolas, Daniel M. Kane, Alistair\n  Stewart", "title": "Testing Conditional Independence of Discrete Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing \\emph{conditional independence} for discrete\ndistributions. Specifically, given samples from a discrete random variable $(X,\nY, Z)$ on domain $[\\ell_1]\\times[\\ell_2] \\times [n]$, we want to distinguish,\nwith probability at least $2/3$, between the case that $X$ and $Y$ are\nconditionally independent given $Z$ from the case that $(X, Y, Z)$ is\n$\\epsilon$-far, in $\\ell_1$-distance, from every distribution that has this\nproperty. Conditional independence is a concept of central importance in\nprobability and statistics with a range of applications in various scientific\ndomains. As such, the statistical task of testing conditional independence has\nbeen extensively studied in various forms within the statistics and\neconometrics communities for nearly a century. Perhaps surprisingly, this\nproblem has not been previously considered in the framework of distribution\nproperty testing and in particular no tester with sublinear sample complexity\nis known, even for the important special case that the domains of $X$ and $Y$\nare binary.\n  The main algorithmic result of this work is the first conditional\nindependence tester with {\\em sublinear} sample complexity for discrete\ndistributions over $[\\ell_1]\\times[\\ell_2] \\times [n]$. To complement our upper\nbounds, we prove information-theoretic lower bounds establishing that the\nsample complexity of our algorithm is optimal, up to constant factors, for a\nnumber of settings. Specifically, for the prototypical setting when $\\ell_1,\n\\ell_2 = O(1)$, we show that the sample complexity of testing conditional\nindependence (upper bound and matching lower bound) is\n  \\[\n  \\Theta\\left({\\max\\left(n^{1/2}/\\epsilon^2,\\min\\left(n^{7/8}/\\epsilon,n^{6/7}/\\epsilon^{8/7}\\right)\\right)}\\right)\\,.\n  \\]\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 18:30:02 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 19:59:50 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""]]}]