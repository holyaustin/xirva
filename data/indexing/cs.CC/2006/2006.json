[{"id": "2006.00061", "submitter": "Kaustav Bose", "authors": "Ranendu Adhikary, Kaustav Bose, Satwik Mukherjee, Bodhayan Roy", "title": "Complexity of Maximum Cut on Interval Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We resolve the longstanding open problem concerning the computational\ncomplexity of Max Cut on interval graphs by showing that it is NP-complete.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 20:16:29 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 17:32:11 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 07:48:56 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Adhikary", "Ranendu", ""], ["Bose", "Kaustav", ""], ["Mukherjee", "Satwik", ""], ["Roy", "Bodhayan", ""]]}, {"id": "2006.00625", "submitter": "Gal Vardi", "authors": "Gal Vardi and Ohad Shamir", "title": "Neural Networks with Small Weights and Depth-Separation Barriers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In studying the expressiveness of neural networks, an important question is\nwhether there are functions which can only be approximated by sufficiently deep\nnetworks, assuming their size is bounded. However, for constant depths,\nexisting results are limited to depths $2$ and $3$, and achieving results for\nhigher depths has been an important open question. In this paper, we focus on\nfeedforward ReLU networks, and prove fundamental barriers to proving such\nresults beyond depth $4$, by reduction to open problems and natural-proof\nbarriers in circuit complexity. To show this, we study a seemingly unrelated\nproblem of independent interest: Namely, whether there are polynomially-bounded\nfunctions which require super-polynomial weights in order to approximate with\nconstant-depth neural networks. We provide a negative and constructive answer\nto that question, by showing that if a function can be approximated by a\npolynomially-sized, constant depth $k$ network with arbitrarily large weights,\nit can also be approximated by a polynomially-sized, depth $3k+3$ network,\nwhose weights are polynomially bounded.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 21:56:17 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 14:32:52 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 23:15:16 GMT"}, {"version": "v4", "created": "Sun, 27 Dec 2020 20:33:40 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Vardi", "Gal", ""], ["Shamir", "Ohad", ""]]}, {"id": "2006.00743", "submitter": "Li-Yang Tan", "authors": "Guy Blanc and Jane Lange and Li-Yang Tan", "title": "Provable guarantees for decision tree induction: the agnostic setting", "comments": "20 pages, to appear in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give strengthened provable guarantees on the performance of widely\nemployed and empirically successful {\\sl top-down decision tree learning\nheuristics}. While prior works have focused on the realizable setting, we\nconsider the more realistic and challenging {\\sl agnostic} setting. We show\nthat for all monotone functions~$f$ and parameters $s\\in \\mathbb{N}$, these\nheuristics construct a decision tree of size $s^{\\tilde{O}((\\log\ns)/\\varepsilon^2)}$ that achieves error $\\le \\mathsf{opt}_s + \\varepsilon$,\nwhere $\\mathsf{opt}_s$ denotes the error of the optimal size-$s$ decision tree\nfor $f$. Previously, such a guarantee was not known to be achievable by any\nalgorithm, even one that is not based on top-down heuristics. We complement our\nalgorithmic guarantee with a near-matching $s^{\\tilde{\\Omega}(\\log s)}$ lower\nbound.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 06:44:07 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Blanc", "Guy", ""], ["Lange", "Jane", ""], ["Tan", "Li-Yang", ""]]}, {"id": "2006.00917", "submitter": "Peter Hillmann", "authors": "Tobias Uhlig and Peter Hillmann and Oliver Rose", "title": "Evaluation of the general applicability of Dragoon for the k-center\n  problem", "comments": null, "journal-ref": "Winter Simulation Conference 2016", "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CC cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-center problem is a fundamental problem we often face when considering\ncomplex service systems. Typical challenges include the placement of warehouses\nin logistics or positioning of servers for content delivery networks. We\npreviously have proposed Dragoon as an effective algorithm to approach the\nk-center problem. This paper evaluates Dragoon with a focus on potential worst\ncase behavior in comparison to other techniques. We use an evolutionary\nalgorithm to generate instances of the k-center problem that are especially\nchallenging for Dragoon. Ultimately, our experiments confirm the previous good\nresults of Dragoon, however, we also can reliably find scenarios where it is\nclearly outperformed by other approaches.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:54:17 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Uhlig", "Tobias", ""], ["Hillmann", "Peter", ""], ["Rose", "Oliver", ""]]}, {"id": "2006.01256", "submitter": "Jayson Lynch", "authors": "Joshua Ani, Jeffrey Bosboom, Erik D. Demaine, Yevhenii Diomidov, Dylan\n  Hendrickson, Jayson Lynch", "title": "Walking through Doors is Hard, even without Staircases: Proving\n  PSPACE-hardness via Planar Assemblies of Door Gadgets", "comments": "Accepted to FUN2020, 35 pages, 41 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A door gadget has two states and three tunnels that can be traversed by an\nagent (player, robot, etc.): the \"open\" and \"close\" tunnel sets the gadget's\nstate to open and closed, respectively, while the \"traverse\" tunnel can be\ntraversed if and only if the door is in the open state. We prove that it is\nPSPACE-complete to decide whether an agent can move from one location to\nanother through a planar assembly of such door gadgets, removing the\ntraditional need for crossover gadgets and thereby simplifying past\nPSPACE-hardness proofs of Lemmings and Nintendo games Super Mario Bros., Legend\nof Zelda, and Donkey Kong Country. Our result holds in all but one of the\npossible local planar embedding of the open, close, and traverse tunnels within\na door gadget; in the one remaining case, we prove NP-hardness.\n  We also introduce and analyze a simpler type of door gadget, called the\nself-closing door. This gadget has two states and only two tunnels, similar to\nthe \"open\" and \"traverse\" tunnels of doors, except that traversing the traverse\ntunnel also closes the door. In a variant called the symmetric self-closing\ndoor, the \"open\" tunnel can be traversed if and only if the door is closed. We\nprove that it is PSPACE-complete to decide whether an agent can move from one\nlocation to another through a planar assembly of either type of self-closing\ndoor. Then we apply this framework to prove new PSPACE-hardness results for\neight different 3D Mario games and Sokobond.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 20:47:51 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ani", "Joshua", ""], ["Bosboom", "Jeffrey", ""], ["Demaine", "Erik D.", ""], ["Diomidov", "Yevhenii", ""], ["Hendrickson", "Dylan", ""], ["Lynch", "Jayson", ""]]}, {"id": "2006.01491", "submitter": "Andreas Pavlogiannis", "authors": "Anders Alnor Mathiasen and Andreas Pavlogiannis", "title": "The Fine-Grained and Parallel Complexity of Andersen's Pointer Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pointer analysis is one of the fundamental problems in static program\nanalysis. Given a set of pointers, the task is to produce a useful\nover-approximation of the memory locations that each pointer may point-to at\nruntime. The most common formulation is Andersen's Pointer Analysis (APA),\ndefined as an inclusion-based set of $m$ pointer constraints over a set of $n$\npointers. Existing algorithms solve APA in $O(n^2\\cdot m)$ time, while it has\nbeen conjectured that the problem has no truly sub-cubic algorithm, with a\nproof so far having remained elusive.\n  In this work we draw a rich fine-grained and parallel complexity landscape of\nAPA, and present upper and lower bounds. First, we establish an $O(n^3)$\nupper-bound for general APA, improving over $O(n^2\\cdot m)$ as $n=O(m)$.\nSecond, we show that even on-demand APA (\"may a specific pointer $a$ point to a\nspecific location $b$?\") has an $\\Omega(n^3)$ (combinatorial) lower bound under\nstandard complexity-theoretic hypotheses. This formally establishes the\nlong-conjectured \"cubic bottleneck\" of APA, and shows that our $O(n^3)$-time\nalgorithm is optimal. Third, we show that under mild restrictions, APA is\nsolvable in $\\tilde{O}(n^{\\omega})$ time, where $\\omega<2.373$ is the\nmatrix-multiplication exponent. It is believed that $\\omega=2+o(1)$, in which\ncase this bound becomes quadratic. Fourth, we show that even under such\nrestrictions, even the on-demand problem has an $\\Omega(n^2)$ lower bound under\nstandard complexity-theoretic hypotheses, and hence our algorithm is optimal\nwhen $\\omega=2+o(1)$. Fifth, we study the parallelizability of APA and\nestablish lower and upper bounds: (i) in general, the problem is P-complete and\nhence unlikely parallelizable, whereas (ii) under mild restrictions, the\nproblem is parallelizable. Our theoretical treatment formalizes several\ninsights that can lead to practical improvements in the future.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 09:45:31 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 10:34:21 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 10:15:51 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Mathiasen", "Anders Alnor", ""], ["Pavlogiannis", "Andreas", ""]]}, {"id": "2006.01598", "submitter": "Peter Hillmann", "authors": "Peter Hillmann and Tobias Uhlig and Gabi Dreo Rodosek and Oliver Rose", "title": "A Novel Approach to Solve K-Center Problems with Geographical Placement", "comments": "International Conference on Service Operations and Logistics, and\n  Informatics 2015. arXiv admin note: text overlap with arXiv:2005.13905", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The facility location problem is a well-known challenge in logistics that is\nproven to be NP-hard. In this paper we specifically simulate the geographical\nplacement of facilities to provide adequate service to customers. Determining\nreasonable center locations is an important challenge for a management since it\ndirectly effects future service costs. Generally, the objective is to place the\ncentral nodes such that all customers have convenient access to them. We\nanalyze the problem and compare different placement strategies and evaluate the\nnumber of required centers. We use several existing approaches and propose a\nnew heuristic for the problem. For our experiments we consider various\nscenarios and employ simulation to evaluate the performance of the optimization\nalgorithms. Our new optimization approach shows a significant improvement. The\npresented results are generally applicable to many domains, e.g., the placement\nof military bases, the planning of content delivery networks, or the placement\nof warehouses.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:01:05 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Hillmann", "Peter", ""], ["Uhlig", "Tobias", ""], ["Rodosek", "Gabi Dreo", ""], ["Rose", "Oliver", ""]]}, {"id": "2006.01903", "submitter": "Stefan Hoffmann", "authors": "Stefan Hoffmann", "title": "On a Class of Constrained Synchronization Problems in NP", "comments": "arXiv admin note: text overlap with arXiv:2005.05907", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class of known constraint automata for which the constrained\nsynchronization problem is in NP all admit a special form. In this work, we\ntake a closer look at them. We characterize a wider class of constraint\nautomata that give constrained synchronization problems in NP, which\nencompasses all known problems in NP. We call these automata polycyclic\nautomata. The corresponding language class of polycyclic languages is\nintroduced. We show various characterizations and closure properties for this\nnew language class. We then give a criterion for NP-completeness and a\ncriterion for polynomial time solvability for polycyclic constraint languages.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 19:36:48 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Hoffmann", "Stefan", ""]]}, {"id": "2006.02374", "submitter": "Pascal Koiran", "authors": "Pascal Koiran", "title": "On tensor rank and commuting matrices", "comments": "New material in this version: * More extensive presentation of prior\n  work, and in particular of rank methods and barrier results. * Discussion of\n  embedding in commuting matrices versus commuting diagonalizable matrices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining superlinear lower bounds on tensor rank is a major open problem in\ncomplexity theory. In this paper we propose a generalization of the approach\nused by Strassen in the proof of his 3n/2 border rank lower bound. Our approach\nrevolves around a problem on commuting matrices:\n  Given matrices Z_1,...,Z_p of size n and an integer r>n, are there commuting\nmatrices Z'_1,...,Z'_p of size r such that every Z_k is embedded as a submatrix\nin the top-left corner of Z'_k?\n  As one of our main results, we show that this question always has a positive\nanswer for r larger than rank(T)+n, where T denotes the tensor with slices\nZ_1,..,Z_p. Taking the contrapositive, if one can show for some specific\nmatrices Z_1,...,Z_p and a specific integer r that this question has a negative\nanswer, this yields the lower bound rank(T) > r-n. There is a little bit of\nslack in the above rank(T)+n bound, but we also provide a number of exact\ncharacterizations of tensor rank and symmetric rank, for ordinary and symmetric\ntensors, over the fields of real and complex numbers. Each of these\ncharacterizations points to a corresponding variation on the above approach. In\norder to explain how Strassen's theorem fits within this framework we also\nprovide a self-contained proof of his lower bound.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 16:41:40 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 10:06:23 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Koiran", "Pascal", ""]]}, {"id": "2006.03177", "submitter": "Gal Vardi", "authors": "Amit Daniely and Gal Vardi", "title": "Hardness of Learning Neural Networks with Natural Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are nowadays highly successful despite strong hardness\nresults. The existing hardness results focus on the network architecture, and\nassume that the network's weights are arbitrary. A natural approach to settle\nthe discrepancy is to assume that the network's weights are \"well-behaved\" and\nposses some generic properties that may allow efficient learning. This approach\nis supported by the intuition that the weights in real-world networks are not\narbitrary, but exhibit some \"random-like\" properties with respect to some\n\"natural\" distributions. We prove negative results in this regard, and show\nthat for depth-$2$ networks, and many \"natural\" weights distributions such as\nthe normal and the uniform distribution, most networks are hard to learn.\nNamely, there is no efficient learning algorithm that is provably successful\nfor most weights, and every input distribution. It implies that there is no\ngeneric property that holds with high probability in such random networks and\nallows efficient learning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 00:14:20 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 23:18:45 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Daniely", "Amit", ""], ["Vardi", "Gal", ""]]}, {"id": "2006.03399", "submitter": "Morteza Davari", "authors": "Dirk Briskorn, Morteza Davari, Jannik Matuschke", "title": "Single-machine scheduling with an external resource", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the complexity of single-machine scheduling with an\nexternal resource, which is rented for a non-interrupted period. Jobs that need\nthis external resource are executed only when the external resource is\navailable. There is a cost associated with the scheduling of jobs and a cost\nassociated with the duration of the renting period of the external resource. We\nlook at four classes of problems with an external resource: a class of problems\nwhere the renting period is budgeted and the scheduling cost needs to be\nminimized, a class of problems where the scheduling cost is budgeted and the\nrenting period needs to be minimized, a class of two-objective problems where\nboth, the renting period and the scheduling cost, are to be minimized, and a\nclass of problems where a linear combination of the scheduling cost and the\nrenting period is minimized. We provide a thorough complexity analysis\n(NP-hardness proofs and (pseudo-)polynomial algorithms) for different members\nof these four classes.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 12:24:22 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 15:21:43 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Briskorn", "Dirk", ""], ["Davari", "Morteza", ""], ["Matuschke", "Jannik", ""]]}, {"id": "2006.03470", "submitter": "Andrey Nikolaev", "authors": "Andrey Nikolaev and Alexander Ushakov", "title": "On subset sum problem in branch groups", "comments": "v3: final version for journal of Groups, Complexity, Cryptology.\n  arXiv admin note: text overlap with arXiv:1703.07406", "journal-ref": "journal of Groups, Complexity, Cryptology, Volume 12, issue 1\n  (June 24, 2020) gcc:6541", "doi": "10.46298/jgcc.2020.12.1.6541", "report-no": null, "categories": "math.GR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a group-theoretic analogue of the classic subset sum problem. In\nthis brief note, we show that the subset sum problem is NP-complete in the\nfirst Grigorchuk group. More generally, we show NP-hardness of that problem in\nweakly regular branch groups, which implies NP-completeness if the group is, in\naddition, contracting.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 16:04:09 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 17:21:02 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 16:40:03 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Nikolaev", "Andrey", ""], ["Ushakov", "Alexander", ""]]}, {"id": "2006.03530", "submitter": "Zachary Remscrim", "authors": "Bill Fefferman (University of Chicago), Zachary Remscrim (University\n  of Chicago)", "title": "Eliminating Intermediate Measurements in Space-Bounded Quantum\n  Computation", "comments": "Minor tweaks to correspond to published version, to appear in STOC\n  2021", "journal-ref": null, "doi": "10.1145/3406325.3451051", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A foundational result in the theory of quantum computation known as the\n\"principle of safe storage\" shows that it is always possible to take a quantum\ncircuit and produce an equivalent circuit that makes all measurements at the\nend of the computation. While this procedure is time efficient, meaning that it\ndoes not introduce a large overhead in the number of gates, it uses extra\nancillary qubits and so is not generally space efficient. It is quite natural\nto ask whether it is possible to defer measurements to the end of a quantum\ncomputation without increasing the number of ancillary qubits.\n  We give an affirmative answer to this question by exhibiting a procedure to\neliminate all intermediate measurements that is simultaneously space-efficient\nand time-efficient. A key component of our approach, which may be of\nindependent interest, involves showing that the well-conditioned versions of\nmany standard linear-algebraic problems may be solved by a quantum computer in\nless space than seems possible by a classical computer.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 16:05:49 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 21:18:02 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Fefferman", "Bill", "", "University of Chicago"], ["Remscrim", "Zachary", "", "University\n  of Chicago"]]}, {"id": "2006.03578", "submitter": "Konrad Dabrowski", "authors": "Konrad K. Dabrowski, Tom\\'a\\v{s} Masa\\v{r}\\'ik, Jana Novotn\\'a,\n  Dani\\\"el Paulusma, Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Clique-Width: Harnessing the Power of Atoms", "comments": "37 pages, 32 figures, an extended abstract of this paper appeared in\n  the proceedings of WG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many NP-complete graph problems are polynomial-time solvable on graph classes\nof bounded clique-width. Several of these problems are polynomial-time solvable\non a hereditary graph class ${\\cal G}$ if they are so on the atoms (graphs with\nno clique cut-set) of ${\\cal G}$. Hence, we initiate a systematic study into\nboundedness of clique-width of atoms of hereditary graph classes. A graph $G$\nis $H$-free if $H$ is not an induced subgraph of $G$, and it is\n$(H_1,H_2)$-free if it is both $H_1$-free and $H_2$-free. A class of $H$-free\ngraphs has bounded clique-width if and only if its atoms have this property.\nThis is no longer true for $(H_1,H_2)$-free graphs, as evidenced by one known\nexample. We prove the existence of another such pair $(H_1,H_2)$ and classify\nthe boundedness of clique-width on $(H_1,H_2)$-free atoms for all but 18 cases.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:50:21 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 23:19:10 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Dabrowski", "Konrad K.", ""], ["Masa\u0159\u00edk", "Tom\u00e1\u0161", ""], ["Novotn\u00e1", "Jana", ""], ["Paulusma", "Dani\u00ebl", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "2006.03666", "submitter": "Jason Schoeters", "authors": "Arnaud Casteigts, Mathieu Raffinot, Jason Schoeters", "title": "VectorTSP: A Traveling Salesperson Problem with Racetrack-like\n  acceleration constraints", "comments": "12 pages, 22 pages with bibliography and appendices, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a new version of the Euclidean TSP called VectorTSP (VTSP for short)\nwhere a mobile entity is allowed to move according to a set of physical\nconstraints inspired from the pen-and-pencil game Racetrack (also known as\nVector Racer ). In contrast to other versions of TSP accounting for physical\nconstraints, such as Dubins TSP, the spirit of this model is that (1) no speed\nlimitations apply, and (2) inertia depends on the current velocity. As such,\nthis model is closer to typical models considered in path planning problems,\nalthough applied here to the visit of n cities in a non-predetermined order. We\nmotivate and introduce the VectorTSP problem, discussing fundamental\ndifferences with previous versions of TSP. In particular, an optimal visit\norder for ETSP may not be optimal for VTSP. We show that VectorTSP is NP-hard,\nand in the other direction, that VectorTSP reduces to GroupTSP in polynomial\ntime (although with a significant blow-up in size). On the algorithmic side, we\nformulate the search for a solution as an interactive scheme between a\nhigh-level algorithm and a trajectory oracle, the former being responsible for\ncomputing the visit order and the latter for computing the cost (or the\ntrajectory) for a given visit order. We present algorithms for both, and we\ndemonstrate and quantify through experiments that this approach frequently\nfinds a better solution than the optimal trajectory realizing an optimal ETSP\ntour, which legitimates the problem itself and (we hope) motivates further\nalgorithmic developments.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 20:17:06 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 08:45:25 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Casteigts", "Arnaud", ""], ["Raffinot", "Mathieu", ""], ["Schoeters", "Jason", ""]]}, {"id": "2006.03856", "submitter": "Mordechai Shalom", "authors": "Arman Boyac{\\i} and T{\\i}naz Ekim and Mordechai Shalom", "title": "On the Maximum Cardinality Cut Problem in Proper Interval Graphs and\n  Related Graph Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although it has been claimed in two different papers that the maximum\ncardinality cut problem is polynomial-time solvable for proper interval graphs,\nboth of them turned out to be erroneous. In this paper, we give FPT algorithms\nfor the maximum cardinality cut problem in classes of graphs containing proper\ninterval graphs and mixed unit interval graphs when parameterized by some new\nparameters that we introduce. These new parameters are related to a\ngeneralization of the so-called bubble representations of proper interval\ngraphs and mixed unit interval graphs and to clique-width decompositions.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 12:55:59 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Boyac\u0131", "Arman", ""], ["Ekim", "T\u0131naz", ""], ["Shalom", "Mordechai", ""]]}, {"id": "2006.04124", "submitter": "Samarth Tiwari", "authors": "Daniel Dadush and Samarth Tiwari", "title": "On the Complexity of Branching Proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the task of proving integer infeasibility of a bounded convex $K$\nin $\\mathbb{R}^n$ using a general branching proof system. In a general\nbranching proof, one constructs a branching tree by adding an integer\ndisjunction $\\mathbf{a} \\mathbf{x} \\leq b$ or $\\mathbf{a} \\mathbf{x} \\geq b+1$,\n$\\mathbf{a} \\in \\mathbb{Z}^n$, $b \\in \\mathbb{Z}$, at each node, such that the\nleaves of the tree correspond to empty sets (i.e., $K$ together with the\ninequalities picked up from the root to leaf is empty). Recently, Beame et al\n(ITCS 2018), asked whether the bit size of the coefficients in a branching\nproof, which they named stabbing planes (SP) refutations, for the case of\npolytopes derived from SAT formulas, can be assumed to be polynomial in $n$. We\nresolve this question by showing that any branching proof can be recompiled so\nthat the integer disjunctions have coefficients of size at most $(n\nR)^{O(n^2)}$, where $R \\in \\mathbb{N}$ such that $K \\in R \\mathbb{B}_1^n$,\nwhile increasing the number of nodes in the branching tree by at most a factor\n$O(n)$. As our second contribution, we show that Tseitin formulas, an important\nclass of infeasible SAT instances, have quasi-polynomial sized cutting plane\n(CP) refutations, disproving the conjecture that Tseitin formulas are\n(exponentially) hard for CP. As our final contribution, we give a simple family\nof polytopes in $[0,1]^n$ requiring branching proofs of length $2^n/n$.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 11:35:46 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Dadush", "Daniel", ""], ["Tiwari", "Samarth", ""]]}, {"id": "2006.04324", "submitter": "Morgan Chopin", "authors": "Amal Benhamiche and Morgan Chopin", "title": "Toward Scalable Algorithms for the Unsplittable Shortest Path Routing\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the Delay Constrained Unsplittable Shortest Path\nRouting problem which arises in the field of traffic engineering for IP\nnetworks. This problem consists, given a directed graph and a set of\ncommodities, to compute a set of routing paths and the associated\nadministrative weights such that each commodity is routed along the unique\nshortest path between its origin and its destination, according to these\nweights. We present a compact MILP formulation for the problem, extending the\nwork in (A. Bley, 2010) along with some valid inequalities to strengthen its\nlinear relaxation. This formulation is used as the bulding block of an\niterative approach that we develop to tackle large scale instances. We further\npropose a dynamic programming algorithm based on a tree decomposition of the\ngraph. To the best of our knowledge, this is the first exact combinatorial\nalgorithm for the problem. Finally, we assess the efficiency of our approaches\nthrough a set of experiments on state-of-the-art instances.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 02:29:40 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Benhamiche", "Amal", ""], ["Chopin", "Morgan", ""]]}, {"id": "2006.04337", "submitter": "Jayson Lynch", "authors": "Joshua Ani, Sualeh Asif, Erik D. Demaine, Yevhenii Diomidov, Dylan\n  Hendrickson, Jayson Lynch, Sarah Scheffler, Adam Suhl", "title": "PSPACE-completeness of Pulling Blocks to Reach a Goal", "comments": "Full version of JCDCGGG2019 paper, 22 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove PSPACE-completeness of all but one problem in a large space of\npulling-block problems where the goal is for the agent to reach a target\ndestination. The problems are parameterized by whether pulling is optional, the\nnumber of blocks which can be pulled simultaneously, whether there are fixed\nblocks or thin walls, and whether there is gravity. We show NP-hardness for the\nremaining problem, Pull?-1FG (optional pulling, strength 1, fixed blocks, with\ngravity).\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 03:21:45 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ani", "Joshua", ""], ["Asif", "Sualeh", ""], ["Demaine", "Erik D.", ""], ["Diomidov", "Yevhenii", ""], ["Hendrickson", "Dylan", ""], ["Lynch", "Jayson", ""], ["Scheffler", "Sarah", ""], ["Suhl", "Adam", ""]]}, {"id": "2006.04409", "submitter": "Nader Bshouty", "authors": "Nader H. Bshouty", "title": "An Optimal Tester for $k$-Linear", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Boolean function $f:\\{0,1\\}^n\\to \\{0,1\\}$ is $k$-linear if it returns the\nsum (over the binary field $F_2$) of $k$ coordinates of the input. In this\npaper, we study property testing of the classes $k$-Linear, the class of all\n$k$-linear functions, and $k$-Linear$^*$, the class $\\cup_{j=0}^kj$-Linear. We\ngive a non-adaptive distribution-free two-sided $\\epsilon$-tester for\n$k$-Linear that makes $$O\\left(k\\log k+\\frac{1}{\\epsilon}\\right)$$ queries.\nThis matches the lower bound known from the literature.\n  We then give a non-adaptive distribution-free one-sided $\\epsilon$-tester for\n$k$-Linear$^*$ that makes the same number of queries and show that any\nnon-adaptive uniform-distribution one-sided $\\epsilon$-tester for $k$-Linear\nmust make at least $ \\tilde\\Omega(k)\\log n+\\Omega(1/\\epsilon)$ queries. The\nlatter bound, almost matches the upper bound $O(k\\log n+1/\\epsilon)$ known from\nthe literature. We then show that any adaptive uniform-distribution one-sided\n$\\epsilon$-tester for $k$-Linear must make at least $\\tilde\\Omega(\\sqrt{k})\\log\nn+\\Omega(1/\\epsilon)$ queries.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 08:33:05 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Bshouty", "Nader H.", ""]]}, {"id": "2006.04411", "submitter": "Andreas Emil Feldmann", "authors": "Andreas Emil Feldmann, Karthik C. S., Euiwoong Lee, Pasin Manurangsi", "title": "A Survey on Approximation in Parameterized Complexity: Hardness and\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterization and approximation are two popular ways of coping with\nNP-hard problems. More recently, the two have also been combined to derive many\ninteresting results. We survey developments in the area both from the\nalgorithmic and hardness perspectives, with emphasis on new techniques and\npotential future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 08:34:47 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Feldmann", "Andreas Emil", ""], ["S.", "Karthik C.", ""], ["Lee", "Euiwoong", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2006.04823", "submitter": "David Sutter", "authors": "David Sutter, Giacomo Nannicini, Tobias Sutter, Stefan Woerner", "title": "Quantum Legendre-Fenchel Transform", "comments": "28 pages; v3: error in correctness proof of Algorithm 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a quantum algorithm to compute the discrete Legendre-Fenchel\ntransform. Given access to a convex function evaluated at $N$ points, the\nalgorithm outputs a quantum-mechanical representation of its corresponding\ndiscrete Legendre-Fenchel transform evaluated at $K$ points in the transformed\nspace. For a fixed regular discretization of the dual space the expected\nrunning time scales as $O(\\sqrt{\\kappa}\\,\\mathrm{polylog}(N,K))$, where\n$\\kappa$ is the condition number of the function. If the discretization of the\ndual space is chosen adaptively with $K$ equal to $N$, the running time reduces\nto $O(\\mathrm{polylog}(N))$. We explain how to extend the presented algorithm\nto the multivariate setting and prove lower bounds for the query complexity,\nshowing that our quantum algorithm is optimal up to polylogarithmic factors.\nFor multivariate functions with $\\kappa=1$, the quantum algorithm computes a\nquantum-mechanical representation of the Legendre-Fenchel transform at $K$\npoints exponentially faster than any classical algorithm can compute it at a\nsingle point.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 18:00:05 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 07:47:03 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 07:07:52 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Sutter", "David", ""], ["Nannicini", "Giacomo", ""], ["Sutter", "Tobias", ""], ["Woerner", "Stefan", ""]]}, {"id": "2006.04831", "submitter": "Jason Larkin", "authors": "Jason Larkin, Mat\\'ias Jonsson, Daniel Justice, and Gian Giacomo\n  Guerreschi", "title": "Evaluation of QAOA based on the approximation ratio of individual\n  samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quantum Approximate Optimization Algorithm (QAOA) is a hybrid\nquantum-classical algorithm to solve binary-variable optimization problems. Due\nto the short circuit depth and its expected robustness to systematic errors, it\nis one of the promising candidates likely to run on near-term quantum devices.\nWe simulate the performance of QAOA applied to the Max-Cut problem and compare\nit with some of the best classical alternatives, for exact, approximate and\nheuristic solution. When comparing solvers, their performance is characterized\nby the computational time taken to achieve a given quality of solution. Since\nQAOA is based on sampling, we utilize performance metrics based on the\nprobability of observing a sample above a certain quality. In addition, we show\nthat the QAOA performance varies significantly with the graph type. By\nselecting a suitable optimizer for the variational parameters and reducing the\nnumber of function evaluations, QAOA performance improves by up to 2 orders of\nmagnitude compared to previous estimates. Especially for 3-regular random\ngraphs, this setting decreases the performance gap with classical alternatives.\nBecause of the evolving QAOA computational complexity-theoretic guidance, we\nutilize a framework for the search for quantum advantage which incorporates a\nlarge number of problem instances and all three classical solver modalities:\nexact, approximate, and heuristic.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 18:00:18 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 20:03:38 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Larkin", "Jason", ""], ["Jonsson", "Mat\u00edas", ""], ["Justice", "Daniel", ""], ["Guerreschi", "Gian Giacomo", ""]]}, {"id": "2006.04880", "submitter": "Wei Zhan", "authors": "Uma Girish, Ran Raz, Wei Zhan", "title": "Quantum Logspace Algorithm for Powering Matrices with Bounded Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a quantum logspace algorithm for powering contraction matrices, that\nis, matrices with spectral norm at most~1. The algorithm gets as an input an\narbitrary $n\\times n$ contraction matrix $A$, and a parameter $T \\leq\n\\mathrm{poly}(n)$ and outputs the entries of $A^T$, up to (arbitrary)\npolynomially small additive error. The algorithm applies only unitary\noperators, without intermediate measurements. We show various implications and\napplications of this result:\n  First, we use this algorithm to show that the class of quantum logspace\nalgorithms with only quantum memory and with intermediate measurements is\nequivalent to the class of quantum logspace algorithms with only quantum memory\nwithout intermediate measurements. This shows that the deferred-measurement\nprinciple, a fundamental principle of quantum computing, applies also for\nquantum logspace algorithms (without classical memory). More generally, we give\na quantum algorithm with space $O(S + \\log T)$ that takes as an input the\ndescription of a quantum algorithm with quantum space $S$ and time $T$, with\nintermediate measurements (without classical memory), and simulates it\nunitarily with polynomially small error, without intermediate measurements.\n  Since unitary transformations are reversible (while measurements are\nirreversible) an interesting aspect of this result is that it shows that any\nquantum logspace algorithm (without classical memory) can be simulated by a\nreversible quantum logspace algorithm. This proves a quantum analogue of the\nresult of Lange, McKenzie and Tapp that deterministic logspace is equal to\nreversible logspace [LMT00].\n  Finally, we use our results to show non-trivial classical simulations of\nquantum logspace learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 19:01:04 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 15:33:21 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 20:57:50 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Girish", "Uma", ""], ["Raz", "Ran", ""], ["Zhan", "Wei", ""]]}, {"id": "2006.05084", "submitter": "Ibrahim Al-Nahhal Mr", "authors": "Ibrahim Al-Nahhal, Octavia A. Dobre, and Salama Ikki", "title": "Reliable Detection for Spatial Modulation Systems", "comments": "5 pages, 7 figures, to be appeared on IEEE VTC-Fall 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spatial modulation (SM) is a promising multiple-input multiple-output system\nused to increase spectral efficiency. The maximum likelihood (ML) decoder\njointly detects the transmitted SM symbol, which is of high complexity. In this\npaper, a novel reliable sphere decoder (RSD) algorithm based on tree-search is\nproposed for the SM system. The basic idea of the proposed RSD algorithm is to\nreduce the size of the tree-search, and then, a smart searching method inside\nthe reduced tree-search is performed to find the solution. The proposed RSD\nalgorithm provides a significant reduction in decoding complexity compared to\nthe ML decoder and existent decoders as well. Moreover, the RSD algorithm\nprovides a flexible trade-off between the bit error rate (BER) performance and\ndecoding complexity, so as to be reliable for a wide range of practical\nhardware implementations. The BER performance and decoding complexity analysis\nfor the RSD algorithm are studied, and Monte Carlo simulations are then\nprovided to demonstrate the findings.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 07:25:09 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Al-Nahhal", "Ibrahim", ""], ["Dobre", "Octavia A.", ""], ["Ikki", "Salama", ""]]}, {"id": "2006.05310", "submitter": "Alexander Tuisov", "authors": "Alexander Tuisov, Liron Yedidsion", "title": "The Continuous Joint Replenishment Problem is Strongly NP-Hard", "comments": "arXiv admin note: text overlap with arXiv:1511.02454", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Continuous Periodic Joint Replenishment Problem (CPJRP) has been one of\nthe core and most studied problems in supply chain management for the last half\na century. Nonetheless, despite the vast effort put into studying the problem,\nits complexity has eluded researchers for years. Although the CPJRP has one of\nthe tighter constant approximation ratio of 1.02, a polynomial optimal solution\nto it was never found. Recently, the discrete version of this problem was\nfinally proved to be NP-hard. In this paper, we extend this result and finaly\nprove that the CPJRP problem is also strongly NP-hard.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 08:52:54 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Tuisov", "Alexander", ""], ["Yedidsion", "Liron", ""]]}, {"id": "2006.05650", "submitter": "Luowen Qian", "authors": "Kai-Min Chung, Siyao Guo, Qipeng Liu, Luowen Qian", "title": "Tight Quantum Time-Space Tradeoffs for Function Inversion", "comments": "Minor updates from FOCS review comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In function inversion, we are given a function $f: [N] \\mapsto [N]$, and want\nto prepare some advice of size $S$, such that we can efficiently invert any\nimage in time $T$. This is a well studied problem with profound connections to\ncryptography, data structures, communication complexity, and circuit lower\nbounds. Investigation of this problem in the quantum setting was initiated by\nNayebi, Aaronson, Belovs, and Trevisan (2015), who proved a lower bound of\n$ST^2 = \\tilde\\Omega(N)$ for random permutations against classical advice,\nleaving open an intriguing possibility that Grover's search can be sped up to\ntime $\\tilde O(\\sqrt{N/S})$. Recent works by Hhan, Xagawa, and Yamakawa (2019),\nand Chung, Liao, and Qian (2019) extended the argument for random functions and\nquantum advice, but the lower bound remains $ST^2 = \\tilde\\Omega(N)$.\n  In this work, we prove that even with quantum advice, $ST + T^2 =\n\\tilde\\Omega(N)$ is required for an algorithm to invert random functions. This\ndemonstrates that Grover's search is optimal for $S = \\tilde O(\\sqrt{N})$,\nruling out any substantial speed-up for Grover's search even with quantum\nadvice. Further improvements to our bounds would imply new classical circuit\nlower bounds, as shown by Corrigan-Gibbs and Kogan (2019).\n  To prove this result, we develop a general framework for establishing quantum\ntime-space lower bounds. We further demonstrate the power of our framework by\nproving quantum time-space lower bounds for Yao's box problem and salted\ncryptography.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 04:23:26 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 19:44:59 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chung", "Kai-Min", ""], ["Guo", "Siyao", ""], ["Liu", "Qipeng", ""], ["Qian", "Luowen", ""]]}, {"id": "2006.06392", "submitter": "Luka Murn", "authors": "Luka Murn, Saverio Blasi, Alan F. Smeaton, Noel E. O'Connor, Marta\n  Mrak", "title": "Interpreting CNN for Low Complexity Learned Sub-pixel Motion\n  Compensation in Video Coding", "comments": "27th IEEE International Conference on Image Processing, 25-28 Oct\n  2020, Abu Dhabi, United Arab Emirates", "journal-ref": "2020 IEEE International Conference on Image Processing (ICIP),\n  2020, pp. 798-802", "doi": "10.1109/ICIP40778.2020.9191193", "report-no": null, "categories": "eess.IV cs.CC cs.CV cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning has shown great potential in image and video compression tasks.\nHowever, it brings bit savings at the cost of significant increases in coding\ncomplexity, which limits its potential for implementation within practical\napplications. In this paper, a novel neural network-based tool is presented\nwhich improves the interpolation of reference samples needed for fractional\nprecision motion compensation. Contrary to previous efforts, the proposed\napproach focuses on complexity reduction achieved by interpreting the\ninterpolation filters learned by the networks. When the approach is implemented\nin the Versatile Video Coding (VVC) test model, up to 4.5% BD-rate saving for\nindividual sequences is achieved compared with the baseline VVC, while the\ncomplexity of learned interpolation is significantly reduced compared to the\napplication of full neural network.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 13:10:20 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Murn", "Luka", ""], ["Blasi", "Saverio", ""], ["Smeaton", "Alan F.", ""], ["O'Connor", "Noel E.", ""], ["Mrak", "Marta", ""]]}, {"id": "2006.06965", "submitter": "Kamil Khadiev", "authors": "Dmitry Kravchenko, Kamil Khadiev, Danil Serov and Ruslan Kapralov", "title": "Quantum-over-classical Advantage in Solving Multiplayer Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the applicability of quantum algorithms in computational game theory\nand generalize some results related to Subtraction games, which are sometimes\nreferred to as one-heap Nim games.\n  In quantum game theory, a subset of Subtraction games became the first\nexplicitly defined class of zero-sum combinatorial games with provable\nseparation between quantum and classical complexity of solving them. For a\nnarrower subset of Subtraction games, an exact quantum sublinear algorithm is\nknown that surpasses all deterministic algorithms for finding solutions with\nprobability $1$.\n  Typically, both Nim and Subtraction games are defined for only two players.\nWe extend some known results to games for three or more players, while\nmaintaining the same classical and quantum complexities:\n$\\Theta\\left(n^2\\right)$ and $\\tilde{O}\\left(n^{1.5}\\right)$ respectively.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 06:36:07 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Kravchenko", "Dmitry", ""], ["Khadiev", "Kamil", ""], ["Serov", "Danil", ""], ["Kapralov", "Ruslan", ""]]}, {"id": "2006.07432", "submitter": "George Kenison", "authors": "George Kenison, Richard Lipton, Jo\\\"el Ouaknine, James Worrell", "title": "On the Skolem Problem and Prime Powers", "comments": "13 pages, ISSAC 2020", "journal-ref": null, "doi": "10.1145/3373207.3404036", "report-no": null, "categories": "math.NT cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Skolem Problem asks, given a linear recurrence sequence $(u_n)$, whether\nthere exists $n\\in\\mathbb{N}$ such that $u_n=0$. In this paper we consider the\nfollowing specialisation of the problem: given in addition $c\\in\\mathbb{N}$,\ndetermine whether there exists $n\\in\\mathbb{N}$ of the form $n=lp^k$, with\n$k,l\\leq c$ and $p$ any prime number, such that $u_n=0$.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 19:23:03 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kenison", "George", ""], ["Lipton", "Richard", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Worrell", "James", ""]]}, {"id": "2006.07613", "submitter": "Abhibhav Garg", "authors": "Abhibhav Garg, Nitin Saxena", "title": "Special-case Algorithms for Blackbox Radical Membership, Nullstellensatz\n  and Transcendence Degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radical membership testing, and the special case of Hilbert's Nullstellensatz\n(HN), is a fundamental computational algebra problem. It is NP-hard; and has a\nfamous PSPACE algorithm due to effective Nullstellensatz bounds. We identify a\nuseful case of these problems where practical algorithms, and improved bounds,\ncould be given, when the transcendence degree $r$ of the input polynomials is\nsmaller than the number of variables $n$. If $d$ is the degree bound on the\ninput polynomials, then we solve radical membership (even if input polynomials\nare blackboxes) in around $d^r$ time. The prior best was $> d^n$ time (always,\n$d^n\\ge d^r$). Also, we significantly improve effective Nullstellensatz\ndegree-bound, when $r\\ll n$. Structurally, our proof shows that these problems\nreduce to the case of $r+1$ polynomials of transcendence degree $\\ge r$. This\ninput instance (corresponding to none or a unique annihilator) is at the core\nof HN's hardness. Our proof methods invoke basic algebraic-geometry.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 10:50:04 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Garg", "Abhibhav", ""], ["Saxena", "Nitin", ""]]}, {"id": "2006.08181", "submitter": "Xiaopeng Luo Dr.", "authors": "Xiaopeng Luo and Xin Xu and Daoyi Dong", "title": "Derivative-free global minimization for a class of multiple minima\n  problems", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the finite-difference based derivative-free descent (FD-DFD)\nmethods have a capability to find the global minima for a class of multiple\nminima problems. Our main result shows that, for a class of multiple minima\nobjectives that is extended from strongly convex functions with\nLipschitz-continuous gradients, the iterates of FD-DFD converge to the global\nminimizer $x_*$ with the linear convergence $\\|x_{k+1}-x_*\\|_2^2\\leqslant\\rho^k\n\\|x_1-x_*\\|_2^2$ for a fixed $0<\\rho<1$ and any initial iteration\n$x_1\\in\\mathbb{R}^d$ when the parameters are properly selected. Since the\nper-iteration cost, i.e., the number of function evaluations, is fixed and\nalmost independent of the dimension $d$, the FD-DFD algorithm has a complexity\nbound $\\mathcal{O}(\\log\\frac{1}{\\epsilon})$ for finding a point $x$ such that\nthe optimality gap $\\|x-x_*\\|_2^2$ is less than $\\epsilon>0$. Numerical\nexperiments in various dimensions from $5$ to $500$ demonstrate the benefits of\nthe FD-DFD method.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 07:16:42 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 17:35:53 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Luo", "Xiaopeng", ""], ["Xu", "Xin", ""], ["Dong", "Daoyi", ""]]}, {"id": "2006.08263", "submitter": "Shir Peleg", "authors": "Shir Peleg and Amir Shpilka", "title": "Polynomial time deterministic identity testingalgorithm for\n  $\\Sigma^{[3]}\\Pi\\Sigma\\Pi^{[2]}$ circuits via Edelstein-Kelly type theorem\n  for quadratic polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we resolve conjectures of Beecken, Mitmann and Saxena [BMS13]\nand Gupta [Gup14], by proving an analog of a theorem of Edelstein and Kelly for\nquadratic polynomials. As immediate corollary we obtain the first deterministic\npolynomial time black-box algorithm for testing zeroness of\n$\\Sigma^{[3]}\\Pi\\Sigma\\Pi^{[2]}$ circuits.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 09:56:25 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Peleg", "Shir", ""], ["Shpilka", "Amir", ""]]}, {"id": "2006.08266", "submitter": "Vidya Sagar Sharma", "authors": "Vidya Sagar Sharma, Piyush Srivastava", "title": "The PSPACE-hardness of understanding neural circuits", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neuroscience, an important aspect of understanding the function of a\nneural circuit is to determine which, if any, of the neurons in the circuit are\nvital for the biological behavior governed by the neural circuit. A similar\nproblem is to determine whether a given small set of neurons may be enough for\nthe behavior to be displayed, even if all other neurons in the circuit are\ndeactivated. Such a subset of neurons forms what is called a degenerate circuit\nfor the behavior being studied.\n  Recent advances in experimental techniques have provided researchers with\ntools to activate and deactivate subsets of neurons with a very high\nresolution, even in living animals. The data collected from such experiments\nmay be of the following form: when a given subset of neurons is deactivated, is\nthe behavior under study observed? This setting leads to the algorithmic\nquestion of determining the minimal vital or degenerate sets of neurons when\none is given as input a description of the neural circuit. The algorithmic\nproblem entails both figuring out which subsets of neurons should be perturbed\n(activated/deactivated), and then using the data from those perturbations to\ndetermine the minimal vital or degenerate sets. Given the large number of\npossible perturbations, and the recurrent nature of neural circuits, the\npossibility of a combinatorial explosion in such an approach has been\nrecognized in the biology and the neuroscience literature.\n  In this paper, we prove that the problems of finding minimal or minimum-size\ndegenerate sets, and of finding the set of vital neurons, of a neural circuit\ngiven as input, are in fact PSPACE-hard. More importantly, we prove our\nhardness results by showing that a simpler problem, that of simulating such\nneural circuits, is itself PSPACE-hard.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 10:05:51 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 15:14:48 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 01:59:06 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Sharma", "Vidya Sagar", ""], ["Srivastava", "Piyush", ""]]}, {"id": "2006.08272", "submitter": "Vineet Nair", "authors": "Janaky Murthy, Vineet Nair, Chandan Saha", "title": "Randomized polynomial-time equivalence between determinant and trace-IMM\n  equivalence tests", "comments": "36 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equivalence testing for a polynomial family {g_m} over a field F is the\nfollowing problem: Given black-box access to an n-variate polynomial f(x),\nwhere n is the number of variables in g_m, check if there exists an A in\nGL(n,F) such that f(x) = g_m(Ax). If yes, then output such an A. The complexity\nof equivalence testing has been studied for a number of important polynomial\nfamilies, including the determinant (Det) and the two popular variants of the\niterated matrix multiplication polynomial: IMM_{w,d} (the (1,1) entry of the\nproduct of d many w $\\times$ w symbolic matrices) and Tr-IMM_{w,d} (the trace\nof the product of d many w $\\times$ w symbolic matrices). The families Det, IMM\nand Tr-IMM are VBP-complete, and so, in this sense, they have the same\ncomplexity. But, do they have the same equivalence testing complexity? We show\nthat the answer is 'yes' for Det and Tr-IMM (modulo the use of randomness). The\nresult is obtained by connecting the two problems via another well-studied\nproblem called the full matrix algebra isomorphism problem (FMAI). In\nparticular, we prove the following:\n  1. Testing equivalence of polynomials to Tr-IMM_{w,d}, for d$\\geq$ 3 and\nw$\\geq$ 2, is randomized polynomial-time Turing reducible to testing\nequivalence of polynomials to Det_w, the determinant of the w $\\times$ w matrix\nof formal variables. (Here, d need not be a constant.)\n  2. FMAI is randomized polynomial-time Turing reducible to equivalence testing\n(in fact, to tensor isomorphism testing) for the family of matrix\nmultiplication tensors {Tr-IMM_{w,3}}.\n  These in conjunction with the randomized poly-time reduction from determinant\nequivalence testing to FMAI [Garg,Gupta,Kayal,Saha19], imply that FMAI,\nequivalence testing for Tr-IMM and for Det, and the $3$-tensor isomorphism\nproblem for the family of matrix multiplication tensors are randomized\npoly-time equivalent under Turing reductions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 10:25:24 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Murthy", "Janaky", ""], ["Nair", "Vineet", ""], ["Saha", "Chandan", ""]]}, {"id": "2006.08314", "submitter": "Steffan S{\\o}lvsten", "authors": "Kristoffer Arnsfelt Hansen and Steffan Christ S{\\o}lvsten", "title": "Existential Theory of the Reals Completeness of Stationary Nash\n  Equilibria in Perfect Information Stochastic Games", "comments": "19 pages, 9 figures, to be published at the 45th International\n  Symposium on Mathematical Foundations of Computer Science", "journal-ref": "MFCS 2020, LIPIcs 170, 45:1--45:15", "doi": "10.4230/LIPIcs.MFCS.2020.45", "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the problem of deciding whether in a multi-player perfect\ninformation recursive game (i.e. a stochastic game with terminal rewards) there\nexists a stationary Nash equilibrium ensuring each player a certain payoff is\nExistential Theory of the Reals complete. Our result holds for acyclic games,\nwhere a Nash equilibrium may be computed efficiently by backward induction, and\neven for deterministic acyclic games with non-negative terminal rewards. We\nfurther extend our results to the existence of Nash equilibria where a single\nplayer is surely winning. Combining our result with known gadget games without\nany stationary Nash equilibrium, we obtain that for cyclic games, just deciding\nexistence of any stationary Nash equilibrium is Existential Theory of the Reals\ncomplete. This holds for reach-a-set games, stay-in-a-set games, and for\ndeterministic recursive games.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 12:14:12 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 09:12:15 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Hansen", "Kristoffer Arnsfelt", ""], ["S\u00f8lvsten", "Steffan Christ", ""]]}, {"id": "2006.08467", "submitter": "Marie-Laure Mugnier", "authors": "Pierre Bourhis and Michel Lecl\\`ere and Marie-Laure Mugnier and Sophie\n  Tison and Federico Ulliana and Lily Galois", "title": "Oblivious and Semi-Oblivious Boundedness for Existential Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the notion of boundedness in the context of positive existential\nrules, that is, whether there exists an upper bound to the depth of the chase\nprocedure, that is independent from the initial instance. By focussing our\nattention on the oblivious and the semi-oblivious chase variants, we give a\ncharacterization of boundedness in terms of FO-rewritability and chase\ntermination. We show that it is decidable to recognize if a set of rules is\nbounded for several classes and outline the complexity of the problem.\n  This report contains the paper published at IJCAI 2019 and an appendix with\nfull proofs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:18:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Bourhis", "Pierre", ""], ["Lecl\u00e8re", "Michel", ""], ["Mugnier", "Marie-Laure", ""], ["Tison", "Sophie", ""], ["Ulliana", "Federico", ""], ["Galois", "Lily", ""]]}, {"id": "2006.08468", "submitter": "Neil Lutz", "authors": "Jack H. Lutz, Neil Lutz", "title": "Algorithmically Optimal Outer Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the relationship between algorithmic fractal dimensions and\nthe classical local fractal dimensions of outer measures in Euclidean spaces.\nWe introduce global and local optimality conditions for lower semicomputable\nouter measures. We prove that globally optimal outer measures exist. Our main\ntheorem states that the classical local fractal dimensions of any locally\noptimal outer measure coincide exactly with the algorithmic fractal dimensions.\nOur proof uses an especially convenient locally optimal outer measure\n$\\boldsymbol{\\kappa}$ defined in terms of Kolmogorov complexity. We discuss\nimplications for point-to-set principles.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:19:24 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Lutz", "Jack H.", ""], ["Lutz", "Neil", ""]]}, {"id": "2006.08473", "submitter": "Xiaojin Zhang", "authors": "Xiaojin Zhang", "title": "Improved algorithm for permutation testing", "comments": "There were some mistakes for the proposal of a simpler algorithm for\n  testing monotone pattern", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing forbidden patterns. The patterns that are of\nsignificant interest include monotone pattern and $(1,3,2)$-pattern. For the\nproblem of testing monotone patterns, \\cite{newman2019testing} propose a\nnon-adaptive algorithm with query complexity $(\\log n)^{O(k^2)}$.\n\\cite{ben2019finding} then improve the query complexity of non-adaptive\nalgorithm to $\\Omega((\\log n)^{\\lfloor\\log k\\rfloor})$. Further,\n\\cite{ben2019optimal} propose an adaptive algorithm for testing monotone\npattern with optimal query complexity $O(\\log n)$. However, the adaptive\nalgorithm and the analysis are rather complicated. We provide a simple adaptive\nalgorithm with one-sided error for testing monotone permutation. We also\npresent an algorithm with improved query complexity for testing\n$(1,3,2)$-pattern.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:25:40 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 01:03:49 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 10:49:09 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2020 00:55:48 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Zhang", "Xiaojin", ""]]}, {"id": "2006.08731", "submitter": "Johannes Vass", "authors": "Johannes Vass, Marie-Louise Lackner, Nysret Musliu", "title": "Exact and Metaheuristic Approaches for the Production Leveling Problem", "comments": "Instance set is published under\n  https://dbai.tuwien.ac.at/staff/jvass/production-leveling/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new problem in the field of production planning\nwhich we call the Production Leveling Problem. The task is to assign orders to\nproduction periods such that the load in each period and on each production\nresource is balanced, capacity limits are not exceeded and the orders'\npriorities are taken into account. Production Leveling is an important\nintermediate step between long-term planning and the final scheduling of orders\nwithin a production period, as it is responsible for selecting good subsets of\norders to be scheduled within each period.\n  A formal model of the problem is proposed and NP-hardness is shown by\nreduction from Bin Backing. As an exact method for solving moderately sized\ninstances we introduce a MIP formulation. For solving large problem instances,\nmetaheuristic local search is investigated. A greedy heuristic and two\nneighborhood structures for local search are proposed, in order to apply them\nusing Variable Neighborhood Descent and Simulated Annealing. Regarding exact\ntechniques, the main question of research is, up to which size instances are\nsolvable within a fixed amount of time. For the metaheuristic approaches the\naim is to show that they produce near-optimal solutions for smaller instances,\nbut also scale well to very large instances.\n  A set of realistic problem instances from an industrial partner is\ncontributed to the literature, as well as random instance generators. The\nexperimental evaluation conveys that the proposed MIP model works well for\ninstances with up to 250 orders. Out of the investigated metaheuristic\napproaches, Simulated Annealing achieves the best results. It is shown to\nproduce solutions with less than 3% average optimality gap on small instances\nand to scale well up to thousands of orders and dozens of periods and products.\nThe presented metaheuristic methods are already being used in the industry.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 20:04:59 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Vass", "Johannes", ""], ["Lackner", "Marie-Louise", ""], ["Musliu", "Nysret", ""]]}, {"id": "2006.08926", "submitter": "Ashish Dwivedi", "authors": "Ashish Dwivedi and Nitin Saxena", "title": "Computing Igusa's local zeta function of univariates in deterministic\n  polynomial-time", "comments": "15 pages, ANTS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC cs.DS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Igusa's local zeta function $Z_{f,p}(s)$ is the generating function that\ncounts the number of integral roots, $N_{k}(f)$, of $f(\\mathbf x) \\bmod p^k$,\nfor all $k$. It is a famous result, in analytic number theory, that $Z_{f,p}$\nis a rational function in $\\mathbb{Q}(p^s)$. We give an elementary proof of\nthis fact for a univariate polynomial $f$. Our proof is constructive as it\ngives a closed-form expression for the number of roots $N_{k}(f)$.\n  Our proof, when combined with the recent root-counting algorithm of (Dwivedi,\nMittal, Saxena, CCC, 2019), yields the first deterministic poly($|f|, \\log p$)\ntime algorithm to compute $Z_{f,p}(s)$. Previously, an algorithm was known only\nin the case when $f$ completely splits over $\\mathbb{Q}_p$; it required the\nrational roots to use the concept of generating function of a tree\n(Z\\'u\\~niga-Galindo, J.Int.Seq., 2003).\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 04:59:41 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Dwivedi", "Ashish", ""], ["Saxena", "Nitin", ""]]}, {"id": "2006.08958", "submitter": "Eric Hutter", "authors": "Eric Hutter and Mathias Pacher and Uwe Brinkschulte", "title": "On the Hardness of Problems Involving Negator Relationships in an\n  Artificial Hormone System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Artificial Hormone System (AHS) is a self-organizing middleware to\nallocate tasks in a distributed system. We extended it by so-called negator\nhormones to enable conditional task structures. However, this extension\nincreases the computational complexity of seemingly simple decision problems in\nthe system: In [1] and [2], we defined the problems Negator-Path and\nNegator-Sat and proved their NP-completeness. In this supplementary report to\nthese papers, we show examples of Negator-Path and Negator-Sat, introduce the\nnovel problem Negator-Stability and explain why all of these problems involving\nnegators are hard to solve algorithmically.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 07:17:40 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Hutter", "Eric", ""], ["Pacher", "Mathias", ""], ["Brinkschulte", "Uwe", ""]]}, {"id": "2006.09969", "submitter": "Mitali Bafna", "authors": "Mitali Bafna, Boaz Barak, Pravesh Kothari, Tselil Schramm, David\n  Steurer", "title": "Playing Unique Games on Certified Small-Set Expanders", "comments": "To appear in STOC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm for solving unique games (UG) instances whenever\nlow-degree sum-of-squares proofs certify good bounds on the small-set-expansion\nof the underlying constraint graph via a hypercontractive inequality. Our\nalgorithm is in fact more versatile, and succeeds even when the constraint\ngraph is not a small-set expander as long as the structure of non-expanding\nsmall sets is (informally speaking) \"characterized\" by a low-degree\nsum-of-squares proof. Our results are obtained by rounding \\emph{low-entropy}\nsolutions -- measured via a new global potential function -- to sum-of-squares\n(SoS) semidefinite programs. This technique adds to the (currently short) list\nof general tools for analyzing SoS relaxations for \\emph{worst-case}\noptimization problems.\n  As corollaries, we obtain the first polynomial-time algorithms for solving\nany UG instance where the constraint graph is either the \\emph{noisy\nhypercube}, the \\emph{short code} or the \\emph{Johnson} graph. The prior best\nalgorithm for such instances was the eigenvalue enumeration algorithm of Arora,\nBarak, and Steurer (2010) which requires quasi-polynomial time for the noisy\nhypercube and nearly-exponential time for the short code and Johnson graphs.\nAll of our results achieve an approximation of $1-\\epsilon$ vs $\\delta$ for UG\ninstances, where $\\epsilon>0$ and $\\delta > 0$ depend on the expansion\nparameters of the graph but are independent of the alphabet size.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 16:28:08 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 17:58:43 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2021 21:51:46 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Bafna", "Mitali", ""], ["Barak", "Boaz", ""], ["Kothari", "Pravesh", ""], ["Schramm", "Tselil", ""], ["Steurer", "David", ""]]}, {"id": "2006.10207", "submitter": "Lukasz Augustyniak", "authors": "{\\L}ukasz Augustyniak, Krzysztof Rajda, Tomasz Kajdanowicz, Micha{\\l}\n  Bernaczyk", "title": "Political Advertising Dataset: the use case of the Polish 2020\n  Presidential Elections", "comments": "ACL 2020 WiNLP Workshop - accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Political campaigns are full of political ads posted by candidates on social\nmedia. Political advertisements constitute a basic form of campaigning,\nsubjected to various social requirements. We present the first publicly open\ndataset for detecting specific text chunks and categories of political\nadvertising in the Polish language. It contains 1,705 human-annotated tweets\ntagged with nine categories, which constitute campaigning under Polish\nelectoral law. We achieved a 0.65 inter-annotator agreement (Cohen's kappa\nscore). An additional annotator resolved the mismatches between the first two\nannotators improving the consistency and complexity of the annotation process.\nWe used the newly created dataset to train a well established neural tagger\n(achieving a 70% percent points F1 score). We also present a possible direction\nof use cases for such datasets and models with an initial analysis of the\nPolish 2020 Presidential Elections on Twitter.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 23:58:01 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Augustyniak", "\u0141ukasz", ""], ["Rajda", "Krzysztof", ""], ["Kajdanowicz", "Tomasz", ""], ["Bernaczyk", "Micha\u0142", ""]]}, {"id": "2006.10444", "submitter": "Pavel Dvo\\v{r}\\'ak", "authors": "Pavel Dvo\\v{r}\\'ak, Andreas Emil Feldmann, Ashutosh Rai, Pawe{\\l}\n  Rz\\k{a}\\.zewski", "title": "Parameterized Inapproximability of Independent Set in $H$-Free Graphs", "comments": "Preliminary version of the paper in WG 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Independent Set (IS) problem in $H$-free graphs, i.e., graphs\nexcluding some fixed graph $H$ as an induced subgraph. We prove several\ninapproximability results both for polynomial-time and parameterized\nalgorithms.\n  Halld\\'orsson [SODA 1995] showed that for every $\\delta>0$ IS has a\npolynomial-time $(\\frac{d-1}{2}+\\delta)$-approximation in $K_{1,d}$-free\ngraphs. We extend this result by showing that $K_{a,b}$-free graphs admit a\npolynomial-time $O(\\alpha(G)^{1-1/a})$-approximation, where $\\alpha(G)$ is the\nsize of a maximum independent set in $G$. Furthermore, we complement the result\nof Halld\\'orsson by showing that for some $\\gamma=\\Theta(d/\\log d),$ there is\nno polynomial-time $\\gamma$-approximation for these graphs, unless NP = ZPP.\n  Bonnet et al. [IPEC 2018] showed that IS parameterized by the size $k$ of the\nindependent set is W[1]-hard on graphs which do not contain (1) a cycle of\nconstant length at least $4$, (2) the star $K_{1,4}$, and (3) any tree with two\nvertices of degree at least $3$ at constant distance.\n  We strengthen this result by proving three inapproximability results under\ndifferent complexity assumptions for almost the same class of graphs (we weaken\ncondition (2) that $G$ does not contain $K_{1,5}$). First, under the ETH, there\nis no $f(k)\\cdot n^{o(k/\\log k)}$ algorithm for any computable function $f$.\nThen, under the deterministic Gap-ETH, there is a constant $\\delta>0$ such that\nno $\\delta$-approximation can be computed in $f(k) \\cdot n^{O(1)}$ time. Also,\nunder the stronger randomized Gap-ETH there is no such approximation algorithm\nwith runtime $f(k)\\cdot n^{o(k)}$.\n  Finally, we consider the parameterization by the excluded graph $H$, and show\nthat under the ETH, IS has no $n^{o(\\alpha(H))}$ algorithm in $H$-free graphs\nand under Gap-ETH there is no $d/k^{o(1)}$-approximation for $K_{1,d}$-free\ngraphs with runtime $f(d,k) n^{O(1)}$.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 11:48:29 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Dvo\u0159\u00e1k", "Pavel", ""], ["Feldmann", "Andreas Emil", ""], ["Rai", "Ashutosh", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "2006.10592", "submitter": "Nitin Saurabh", "authors": "Balagopal Komarath and Nitin Saurabh", "title": "On the complexity of detecting hazards", "comments": "To appear in Information Processing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and eliminating logic hazards in Boolean circuits is a fundamental\nproblem in logic circuit design. We show that there is no $O(3^{(1-\\epsilon)n}\n\\text{poly}(s))$ time algorithm, for any $\\epsilon > 0$, that detects logic\nhazards in Boolean circuits of size $s$ on $n$ variables under the assumption\nthat the strong exponential time hypothesis is true. This lower bound holds\neven when the input circuits are restricted to be formulas of depth four. We\nalso present a polynomial time algorithm for detecting $1$-hazards in DNF (or,\n$0$-hazards in CNF) formulas. Since $0$-hazards in DNF (or, $1$-hazards in CNF)\nformulas are easy to eliminate, this algorithm can be used to detect whether a\ngiven DNF or CNF formula has a hazard in practice.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 14:55:08 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Komarath", "Balagopal", ""], ["Saurabh", "Nitin", ""]]}, {"id": "2006.10957", "submitter": "Robin Kothari", "authors": "Shalev Ben-David, Mika G\\\"o\\\"os, Robin Kothari, Thomas Watson", "title": "When Is Amplification Necessary for Composition in Randomized Query\n  Complexity?", "comments": "17 pages. Accepted to RANDOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we have randomized decision trees for an outer function $f$ and an\ninner function $g$. The natural approach for obtaining a randomized decision\ntree for the composed function $(f\\circ\ng^n)(x^1,\\ldots,x^n)=f(g(x^1),\\ldots,g(x^n))$ involves amplifying the success\nprobability of the decision tree for $g$, so that a union bound can be used to\nbound the error probability over all the coordinates. The amplification\nintroduces a logarithmic factor cost overhead. We study the question: When is\nthis log factor necessary? We show that when the outer function is parity or\nmajority, the log factor can be necessary, even for models that are more\npowerful than plain randomized decision trees. Our results are related to, but\nqualitatively strengthen in various ways, known results about decision trees\nwith noisy inputs.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 04:59:26 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Ben-David", "Shalev", ""], ["G\u00f6\u00f6s", "Mika", ""], ["Kothari", "Robin", ""], ["Watson", "Thomas", ""]]}, {"id": "2006.11152", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Common equivalence and size after forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forgetting variables from a propositional formula may increase its size.\nIntroducing new variables is a way to shorten it. Both operations can be\nexpressed in terms of common equivalence, a weakened version of equivalence. In\nturn, common equivalence can be expressed in terms of forgetting. An algorithm\nfor forgetting and checking common equivalence in polynomial space is given for\nthe Horn case; it is polynomial-time for the subclass of single-head formulae.\nMinimizing after forgetting is polynomial-time if the formula is also acyclic\nand variables cannot be introduced, NP-hard when they can.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:27:51 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 12:07:40 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "2006.11155", "submitter": "Pawe{\\l} Rz\\k{a}\\.zewski", "authors": "Karolina Okrasa and Marta Piecyk and Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Full complexity classification of the list homomorphism problem for\n  bounded-treewidth graphs", "comments": "The extended abstract of the paper was accepted to ESA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A homomorphism from a graph $G$ to a graph $H$ is an edge-preserving mapping\nfrom $V(G)$ to $V(H)$. Let $H$ be a fixed graph with possible loops. In the\nlist homomorphism problem, denoted by LHom($H$), we are given a graph $G$,\nwhose every vertex $v$ is assigned with a list $L(v)$ of vertices of $H$. We\nask whether there exists a homomorphism $h$ from $G$ to $H$, which respects\nlists $L$, i.e., for every $v \\in V(G)$ it holds that $h(v) \\in L(v)$.\n  The complexity dichotomy for LHom($H$) was proven by Feder, Hell, and Huang\n[JGT 2003]. We are interested in the complexity of the problem, parameterized\nby the treewidth of the input graph. This problem was investigated by Egri,\nMarx, and Rz\\k{a}\\.zewski [STACS 2018], who obtained tight complexity bounds\nfor the special case of reflexive graphs $H$.\n  In this paper we extend and generalize their results for \\emph{all} relevant\ngraphs $H$, i.e., those, for which the LHom{H} problem is NP-hard. For every\nsuch $H$ we find a constant $k = k(H)$, such that LHom($H$) on instances with\n$n$ vertices and treewidth $t$\n  * can be solved in time $k^{t} \\cdot n^{\\mathcal{O}(1)}$, provided that the\ninput graph is given along with a tree decomposition of width $t$,\n  * cannot be solved in time $(k-\\varepsilon)^{t} \\cdot n^{\\mathcal{O}(1)}$,\nfor any $\\varepsilon >0$, unless the SETH fails.\n  For some graphs $H$ the value of $k(H)$ is much smaller than the trivial\nupper bound, i.e., $|V(H)|$.\n  Obtaining matching upper and lower bounds shows that the set of algorithmic\ntools we have discovered cannot be extended in order to obtain faster\nalgorithms for LHom($H$) in bounded-treewidth graphs. Furthermore, neither the\nalgorithm, nor the proof of the lower bound, is very specific to treewidth. We\nbelieve that they can be used for other variants of LHom($H$), e.g. with\ndifferent parameterizations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:32:14 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 09:57:04 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Okrasa", "Karolina", ""], ["Piecyk", "Marta", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "2006.12028", "submitter": "Hannes Leipold", "authors": "Hannes Leipold, Federico M. Spedalieri", "title": "Constructing Driver Hamiltonians for Optimization Problems with Linear\n  Constraints", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the field of adiabatic quantum computing and the closely\nrelated field of quantum annealers has centered around using more advanced and\nnovel Hamiltonian representations to solve optimization problems. One of these\nadvances has centered around the development of driver Hamiltonians that\ncommute with the constraints of an optimization problem - allowing for another\navenue to satisfying those constraints instead of imposing penalty terms for\neach of them. In particular, the approach is able to use sparser connectivity\nto embed several practical problems on quantum devices than other common\npractices. However, designing the driver Hamiltonians that successfully commute\nwith several constraints has largely been based on strong intuition for\nspecific problems and with no simple general algorithm to generate them for\narbitrary constraints. In this work, we develop a simple and intuitive\nalgebraic framework for reasoning about the commutation of Hamiltonians with\nlinear constraints - one that allows us to classify the complexity of finding a\ndriver Hamiltonian for an arbitrary set of constraints as NP-Complete. Because\nunitary operators are exponentials of Hermitian operators, these results can\nalso be applied to the construction of mixers in the Quantum Alternating\nOperator Ansatz (QAOA) framework.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 06:47:50 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 21:54:48 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 07:18:53 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 06:00:10 GMT"}, {"version": "v5", "created": "Thu, 11 Mar 2021 18:59:56 GMT"}, {"version": "v6", "created": "Fri, 18 Jun 2021 17:49:09 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Leipold", "Hannes", ""], ["Spedalieri", "Federico M.", ""]]}, {"id": "2006.12125", "submitter": "Yuki Takeuchi", "authors": "Yuki Takeuchi, Yasuhiro Takahashi, Seiichiro Tani", "title": "Efficiently generating ground states is hard for postselected quantum\n  computation", "comments": "7 pages, 4 figures", "journal-ref": "Phys. Rev. Research 3, 013213 (2021)", "doi": "10.1103/PhysRevResearch.3.013213", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although quantum computing is expected to outperform universal classical\ncomputing, an unconditional proof of this assertion seems to be hard because an\nunconditional separation between ${\\sf BQP}$ and ${\\sf BPP}$ implies ${\\sf\nP}\\neq{\\sf PSPACE}$. Because of this, the quantum-computational-supremacy\napproach has been actively studied; it shows that if the output probability\ndistributions from a family of quantum circuits can be efficiently simulated in\nclassical polynomial time, then the polynomial hierarchy collapses to its\nsecond or third level. Since it is widely believed that the polynomial\nhierarchy does not collapse, this approach shows one kind of quantum advantage\nunder a plausible assumption. On the other hand, the limitations of universal\nquantum computing are also actively studied. For example, it is believed to be\nimpossible to generate ground states of any local Hamiltonians in quantum\npolynomial time. In this paper, we give evidence for this impossibility by\napplying an argument used in the quantum-computational-supremacy approach. More\nprecisely, we show that if ground states of any $3$-local Hamiltonians can be\napproximately generated in quantum polynomial time with postselection, then the\ncounting hierarchy collapses to its first level. Our evidence is superior to\nthe existing findings in the sense that we reduce the impossibility to an\nunlikely relation between classical complexity classes. Furthermore, our\nargument can be used to give evidence that at least one $3$-local Hamiltonian\nexists such that its ground state cannot be represented by a polynomial number\nof bits, which may be related to a gap between ${\\sf QMA}$ and ${\\sf QCMA}$.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:28:51 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Takeuchi", "Yuki", ""], ["Takahashi", "Yasuhiro", ""], ["Tani", "Seiichiro", ""]]}, {"id": "2006.12330", "submitter": "Utkan Gezer", "authors": "M. Utkan Gezer and A. C. Cem Say", "title": "Constant-Space, Constant-Randomness Verifiers with Arbitrarily Small\n  Error", "comments": null, "journal-ref": null, "doi": "10.1016/j.ic.2021.104744", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study the capabilities of probabilistic finite-state machines that act as\nverifiers for certificates of language membership for input strings, in the\nregime where the verifiers are restricted to toss some fixed nonzero number of\ncoins regardless of the input size. Say and Yakary{\\i}lmaz showed that the\nclass of languages that could be verified by these machines within an error\nbound strictly less than $1/2$ is precisely NL, but their construction yields\nverifiers with error bounds that are very close to $1/2$ for most languages in\nthat class when the definition of \"error\" is strengthened to include looping\nforever without giving a response. We characterize a subset of NL for which\nverification with arbitrarily low error is possible by these extremely weak\nmachines. It turns out that, for any $\\varepsilon>0$, one can construct a\nconstant-coin, constant-space verifier operating within error $\\varepsilon$ for\nevery language that is recognizable by a linear-time multi-head\nnondeterministic finite automaton (2nfa($k$)). We discuss why it is difficult\nto generalize this method to all of NL, and give a reasonably tight way to\nrelate the power of linear-time 2nfa($k$)'s to simultaneous time-space\ncomplexity classes defined in terms of Turing machines.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 15:16:42 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 13:15:54 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Gezer", "M. Utkan", ""], ["Say", "A. C. Cem", ""]]}, {"id": "2006.12760", "submitter": "Andrew M. Childs", "authors": "Shalev Ben-David, Andrew M. Childs, Andr\\'as Gily\\'en, William\n  Kretschmer, Supartha Podder, Daochen Wang", "title": "Symmetries, graph properties, and quantum speedups", "comments": "46 pages. Subsumes arXiv:2001.09642 and arXiv:2001.10520; adds a\n  characterization of permutation groups with speedup and an exponential\n  speedup for adjacency-list graph property testing", "journal-ref": "Proceedings of the 61st IEEE Symposium on Foundations of Computer\n  Science (FOCS 2020), pp. 649-660 (2020)", "doi": "10.1109/FOCS46700.2020.00066", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aaronson and Ambainis (2009) and Chailloux (2018) showed that fully symmetric\n(partial) functions do not admit exponential quantum query speedups. This\nraises a natural question: how symmetric must a function be before it cannot\nexhibit a large quantum speedup?\n  In this work, we prove that hypergraph symmetries in the adjacency matrix\nmodel allow at most a polynomial separation between randomized and quantum\nquery complexities. We also show that, remarkably, permutation groups\nconstructed out of these symmetries are essentially the only permutation groups\nthat prevent super-polynomial quantum speedups. We prove this by fully\ncharacterizing the primitive permutation groups that allow super-polynomial\nquantum speedups.\n  In contrast, in the adjacency list model for bounded-degree graphs (where\ngraph symmetry is manifested differently), we exhibit a property testing\nproblem that shows an exponential quantum speedup. These results resolve open\nquestions posed by Ambainis, Childs, and Liu (2010) and Montanaro and de Wolf\n(2013).\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 05:00:15 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Ben-David", "Shalev", ""], ["Childs", "Andrew M.", ""], ["Gily\u00e9n", "Andr\u00e1s", ""], ["Kretschmer", "William", ""], ["Podder", "Supartha", ""], ["Wang", "Daochen", ""]]}, {"id": "2006.13073", "submitter": "Dana Moshkovitz", "authors": "Ronen Eldan, Dana Moshkovitz", "title": "Reduction From Non-Unique Games To Boolean Unique Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reduce the problem of proving a \"Boolean Unique Games Conjecture\" (with\ngap 1-delta vs. 1-C*delta, for any C> 1, and sufficiently small delta>0) to the\nproblem of proving a PCP Theorem for a certain non-unique game. In a previous\nwork, Khot and Moshkovitz suggested an inefficient candidate reduction (i.e.,\nwithout a proof of soundness). The current work is the first to provide an\nefficient reduction along with a proof of soundness. The non-unique game we\nreduce from is similar to non-unique games for which PCP theorems are known.\nOur proof relies on a new concentration theorem for functions in Gaussian space\nthat are restricted to a random hyperplane. We bound the typical Euclidean\ndistance between the low degree part of the restriction of the function to the\nhyperplane and the restriction to the hyperplane of the low degree part of the\nfunction.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 14:50:35 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 15:49:14 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Eldan", "Ronen", ""], ["Moshkovitz", "Dana", ""]]}, {"id": "2006.13449", "submitter": "Diptarka Chakraborty", "authors": "Amey Bhangale, Diptarka Chakraborty, Rajendra Kumar", "title": "Hardness of Approximation of (Multi-)LCS over Small Alphabet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding longest common subsequence (LCS) is one of the\nfundamental problems in computer science, which finds application in fields\nsuch as computational biology, text processing, information retrieval, data\ncompression etc. It is well known that (decision version of) the problem of\nfinding the length of a LCS of an arbitrary number of input sequences (which we\nrefer to as Multi-LCS problem) is NP-complete. Jiang and Li [SICOMP'95] showed\nthat if Max-Clique is hard to approximate within a factor of $s$ then Multi-LCS\nis also hard to approximate within a factor of $\\Theta(s)$. By the NP-hardness\nof the problem of approximating Max-Clique by Zuckerman [ToC'07], for any\nconstant $\\delta>0$, the length of a LCS of arbitrary number of input sequences\nof length $n$ each, cannot be approximated within an $n^{1-\\delta}$-factor in\npolynomial time unless {\\tt{P}}$=${\\NP}. However, the reduction of Jiang and Li\nassumes the alphabet size to be $\\Omega(n)$. So far no hardness result is known\nfor the problem of approximating Multi-LCS over sub-linear sized alphabet. On\nthe other hand, it is easy to get $1/|\\Sigma|$-factor approximation for strings\nof alphabet $\\Sigma$.\n  In this paper, we make a significant progress towards proving hardness of\napproximation over small alphabet by showing a polynomial-time reduction from\nthe well-studied \\emph{densest $k$-subgraph} problem with {\\em perfect\ncompleteness} to approximating Multi-LCS over alphabet of size $poly(n/k)$. As\na consequence, from the known hardness result of densest $k$-subgraph problem\n(e.g. [Manurangsi, STOC'17]) we get that no polynomial-time algorithm can give\nan $n^{-o(1)}$-factor approximation of Multi-LCS over an alphabet of size\n$n^{o(1)}$, unless the Exponential Time Hypothesis is false.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 03:24:20 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Bhangale", "Amey", ""], ["Chakraborty", "Diptarka", ""], ["Kumar", "Rajendra", ""]]}, {"id": "2006.13712", "submitter": "Arijit Ghosh", "authors": "Anup Bhattacharya, Sourav Chakraborty, Arijit Ghosh, Gopinath Mishra,\n  and Manaswi Paraashar", "title": "Disjointness through the Lens of Vapnik-Chervonenkis Dimension: Sparsity\n  and Beyond", "comments": "To appear in RANDOM 2020. Pages: 15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The disjointness problem - where Alice and Bob are given two subsets of $\\{1,\n\\dots, n\\}$ and they have to check if their sets intersect - is a central\nproblem in the world of communication complexity. While both deterministic and\nrandomized communication complexities for this problem are known to be\n$\\Theta(n)$, it is also known that if the sets are assumed to be drawn from\nsome restricted set systems then the communication complexity can be much\nlower. In this work, we explore how communication complexity measures change\nwith respect to the complexity of the underlying set system. The complexity\nmeasure for the set system that we use in this work is the Vapnik-Chervonenkis\n(VC) dimension. More precisely, on any set system with VC dimension bounded by\n$d$, we analyze how large can the deterministic and randomized communication\ncomplexities be, as a function of $d$ and $n$.\n  In this paper, we construct two natural set systems of VC dimension $d$,\nmotivated from geometry. Using these set systems we show that the deterministic\nand randomized communication complexity can be $\\widetilde{\\Theta}\\left(d\\log\n\\left( n/d \\right)\\right)$ for set systems of VC dimension $d$ and this matches\nthe deterministic upper bound for all set systems of VC dimension $d$. We also\nstudy the deterministic and randomized communication complexities of the set\nintersection problem when sets belong to a set system of bounded VC dimension.\nWe show that there exists set systems of VC dimension $d$ such that both\ndeterministic and randomized (one-way and multi-round) complexity for the set\nintersection problem can be as high as $\\Theta\\left( d\\log \\left( n/d \\right)\n\\right)$, and this is tight among all set systems of VC dimension $d$.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 13:19:53 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Bhattacharya", "Anup", ""], ["Chakraborty", "Sourav", ""], ["Ghosh", "Arijit", ""], ["Mishra", "Gopinath", ""], ["Paraashar", "Manaswi", ""]]}, {"id": "2006.14015", "submitter": "Hanlin Zhu", "authors": "Cyrus Rashtchian, David P. Woodruff and Hanlin Zhu", "title": "Vector-Matrix-Vector Queries for Solving Linear Algebra, Statistics, and\n  Graph Problems", "comments": "26 pages, to be published in RANDOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the general problem of learning about a matrix through\nvector-matrix-vector queries. These queries provide the value of\n$\\boldsymbol{u}^{\\mathrm{T}}\\boldsymbol{M}\\boldsymbol{v}$ over a fixed field\n$\\mathbb{F}$ for a specified pair of vectors $\\boldsymbol{u},\\boldsymbol{v} \\in\n\\mathbb{F}^n$. To motivate these queries, we observe that they generalize many\npreviously studied models, such as independent set queries, cut queries, and\nstandard graph queries. They also specialize the recently studied matrix-vector\nquery model. Our work is exploratory and broad, and we provide new upper and\nlower bounds for a wide variety of problems, spanning linear algebra,\nstatistics, and graphs. Many of our results are nearly tight, and we use\ndiverse techniques from linear algebra, randomized algorithms, and\ncommunication complexity.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 19:33:49 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Rashtchian", "Cyrus", ""], ["Woodruff", "David P.", ""], ["Zhu", "Hanlin", ""]]}, {"id": "2006.14733", "submitter": "Debajyoti Mondal", "authors": "Debajyoti Mondal, N. Parthiban, V. Kavitha, Indra Rajasingh", "title": "APX-Hardness and Approximation for the k-Burning Number Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an information diffusion process on a graph $G$ that starts with\n$k>0$ burnt vertices, and at each subsequent step, burns the neighbors of the\ncurrently burnt vertices, as well as $k$ other unburnt vertices. The\n\\emph{$k$-burning number} of $G$ is the minimum number of steps $b_k(G)$ such\nthat all the vertices can be burned within $b_k(G)$ steps. Note that the last\nstep may have smaller than $k$ unburnt vertices available, where all of them\nare burned. The $1$-burning number coincides with the well-known burning number\nproblem, which was proposed to model the spread of social contagion. The\ngeneralization to $k$-burning number allows us to examine different worst-case\ncontagion scenarios by varying the spread factor $k$.\n  In this paper we prove that computing $k$-burning number is APX-hard, for any\nfixed constant $k$. We then give an $O((n+m)\\log n)$-time 3-approximation\nalgorithm for computing $k$-burning number, for any $k\\ge 1$, where $n$ and $m$\nare the number of vertices and edges, respectively. Finally, we show that even\nif the burning sources are given as an input, computing a burning sequence\nitself is an NP-hard problem.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 23:41:13 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 05:07:11 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Mondal", "Debajyoti", ""], ["Parthiban", "N.", ""], ["Kavitha", "V.", ""], ["Rajasingh", "Indra", ""]]}, {"id": "2006.14798", "submitter": "Tolga Ergen", "authors": "Tolga Ergen, Mert Pilanci", "title": "Implicit Convex Regularizers of CNN Architectures: Convex Optimization\n  of Two- and Three-Layer Networks in Polynomial Time", "comments": "Accepted for Spotlight Presentation at ICLR 2021", "journal-ref": "International Conference on Learning Representations (ICLR), 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study training of Convolutional Neural Networks (CNNs) with ReLU\nactivations and introduce exact convex optimization formulations with a\npolynomial complexity with respect to the number of data samples, the number of\nneurons, and data dimension. More specifically, we develop a convex analytic\nframework utilizing semi-infinite duality to obtain equivalent convex\noptimization problems for several two- and three-layer CNN architectures. We\nfirst prove that two-layer CNNs can be globally optimized via an $\\ell_2$ norm\nregularized convex program. We then show that multi-layer circular CNN training\nproblems with a single ReLU layer are equivalent to an $\\ell_1$ regularized\nconvex program that encourages sparsity in the spectral domain. We also extend\nthese results to three-layer CNNs with two ReLU layers. Furthermore, we present\nextensions of our approach to different pooling methods, which elucidates the\nimplicit architectural bias as convex regularizers.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 04:47:20 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:17:31 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 15:30:26 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Ergen", "Tolga", ""], ["Pilanci", "Mert", ""]]}, {"id": "2006.14828", "submitter": "Guus Regts", "authors": "Pjotr Buys, Andreas Galanis, Viresh Patel, Guus Regts", "title": "Lee-Yang zeros and the complexity of the ferromagnetic Ising model on\n  bounded-degree graphs", "comments": "40 pages, 1 figure. We have included a new result for the case $b\\in\n  [1-2/\\Delta,1)$. This essentially gives a complete picture of the complexity\n  of the problem. An extended abstract has been presented at SODA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of approximating the partition function\nof the ferromagnetic Ising model with the external field parameter $\\lambda$ on\nthe unit circle in the complex plane. Complex-valued parameters for the Ising\nmodel are relevant for quantum circuit computations and phase transitions in\nstatistical physics, but have also been key in the recent deterministic\napproximation scheme for all $|\\lambda|\\neq 1$ by Liu, Sinclair, and\nSrivastava. Here, we focus on the unresolved complexity picture on the unit\ncircle, and on the tantalising question of what happens around $\\lambda=1$,\nwhere on one hand the classical algorithm of Jerrum and Sinclair gives a\nrandomised approximation scheme on the real axis suggesting tractability, and\non the other hand the presence of Lee-Yang zeros alludes to computational\nhardness.\n  Our main result establishes a sharp computational transition at the point\n$\\lambda=1$, and more generally on the entire unit circle. For an integer\n$\\Delta\\geq 3$ and edge interaction parameter $b\\in (0,1)$ we show #P-hardness\nfor approximating the partition function on graphs of maximum degree $\\Delta$\non the arc of the unit circle where the Lee-Yang zeros are dense. This result\ncontrasts with known approximation algorithms when $|\\lambda|\\neq 1$ or when\n$\\lambda$ is in the complementary arc around $1$ of the unit circle. Our work\nthus gives a direct connection between the presence/absence of Lee-Yang zeros\nand the tractability of efficiently approximating the partition function on\nbounded-degree graphs.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 07:09:04 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 13:34:10 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 12:57:14 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Buys", "Pjotr", ""], ["Galanis", "Andreas", ""], ["Patel", "Viresh", ""], ["Regts", "Guus", ""]]}, {"id": "2006.14870", "submitter": "Arturo Castellanos Salinas", "authors": "Aleksandrs Belovs, Arturo Castellanos, Fran\\c{c}ois Le Gall, Guillaume\n  Malod and Alexander A. Sherstov", "title": "Quantum Communication Complexity of Distribution Testing", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical communication complexity of testing closeness of discrete\ndistributions has recently been studied by Andoni, Malkin and Nosatzki\n(ICALP'19). In this problem, two players each receive $t$ samples from one\ndistribution over $[n]$, and the goal is to decide whether their two\ndistributions are equal, or are $\\epsilon$-far apart in the $l_1$-distance. In\nthe present paper we show that the quantum communication complexity of this\nproblem is $\\tilde{O}(n/(t\\epsilon^2))$ qubits when the distributions have low\n$l_2$-norm, which gives a quadratic improvement over the classical\ncommunication complexity obtained by Andoni, Malkin and Nosatzki. We also\nobtain a matching lower bound by using the pattern matrix method. Let us stress\nthat the samples received by each of the parties are classical, and it is only\ncommunication between them that is quantum. Our results thus give one setting\nwhere quantum protocols overcome classical protocols for a testing problem with\npurely classical samples.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 09:05:58 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Belovs", "Aleksandrs", ""], ["Castellanos", "Arturo", ""], ["Gall", "Fran\u00e7ois Le", ""], ["Malod", "Guillaume", ""], ["Sherstov", "Alexander A.", ""]]}, {"id": "2006.15349", "submitter": "Marc G\\'orriz Blanch", "authors": "Marc G\\'orriz, Saverio Blasi, Alan F. Smeaton, Noel E. O'Connor, Marta\n  Mrak", "title": "Chroma Intra Prediction with attention-based CNN architectures", "comments": "27th IEEE International Conference on Image Processing, 25-28 Oct\n  2020, Abu Dhabi, United Arab Emirates", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CC cs.CV cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural networks can be used in video coding to improve chroma\nintra-prediction. In particular, usage of fully-connected networks has enabled\nbetter cross-component prediction with respect to traditional linear models.\nNonetheless, state-of-the-art architectures tend to disregard the location of\nindividual reference samples in the prediction process. This paper proposes a\nnew neural network architecture for cross-component intra-prediction. The\nnetwork uses a novel attention module to model spatial relations between\nreference and predicted samples. The proposed approach is integrated into the\nVersatile Video Coding (VVC) prediction pipeline. Experimental results\ndemonstrate compression gains over the latest VVC anchor compared with\nstate-of-the-art chroma intra-prediction methods based on neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 12:11:17 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["G\u00f3rriz", "Marc", ""], ["Blasi", "Saverio", ""], ["Smeaton", "Alan F.", ""], ["O'Connor", "Noel E.", ""], ["Mrak", "Marta", ""]]}, {"id": "2006.15381", "submitter": "Sangram Kishor Jena Mr", "authors": "Sangram K. Jena, Ramesh K. Jallu, Gautam K. Das and Subhas C. Nandy", "title": "The Generalized Independent and Dominating Set Problems on Unit Disk\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study a generalized version of the maximum independent\nset and minimum dominating set problems, namely, the maximum $d$-distance\nindependent set problem and the minimum $d$-distance dominating set problem on\nunit disk graphs for a positive integer $d>0$. We first show that the maximum\n$d$-distance independent set problem and the minimum $d$-distance dominating\nset problem belongs to NP-hard class. Next, we propose a simple polynomial-time\nconstant-factor approximation algorithms and PTAS for both the problems.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 15:18:44 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Jena", "Sangram K.", ""], ["Jallu", "Ramesh K.", ""], ["Das", "Gautam K.", ""], ["Nandy", "Subhas C.", ""]]}, {"id": "2006.16104", "submitter": "Bo Yang", "authors": "Bo Yang, Xuelin Cao, Joshua Bassey, Xiangfang Li, Timothy Kroecker,\n  and Lijun Qian", "title": "Computation Offloading in Multi-Access Edge Computing Networks: A\n  Multi-Task Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-access edge computing (MEC) has already shown the potential in enabling\nmobile devices to bear the computation-intensive applications by offloading\nsome tasks to a nearby access point (AP) integrated with a MEC server (MES).\nHowever, due to the varying network conditions and limited computation\nresources of the MES, the offloading decisions taken by a mobile device and the\ncomputational resources allocated by the MES may not be efficiently achieved\nwith the lowest cost. In this paper, we propose a dynamic offloading framework\nfor the MEC network, in which the uplink non-orthogonal multiple access (NOMA)\nis used to enable multiple devices to upload their tasks via the same frequency\nband. We formulate the offloading decision problem as a multiclass\nclassification problem and formulate the MES computational resource allocation\nproblem as a regression problem. Then a multi-task learning based feedforward\nneural network (MTFNN) model is designed to jointly optimize the offloading\ndecision and computational resource allocation. Numerical results illustrate\nthat the proposed MTFNN outperforms the conventional optimization method in\nterms of inference accuracy and computation complexity.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 15:11:10 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Yang", "Bo", ""], ["Cao", "Xuelin", ""], ["Bassey", "Joshua", ""], ["Li", "Xiangfang", ""], ["Kroecker", "Timothy", ""], ["Qian", "Lijun", ""]]}, {"id": "2006.16422", "submitter": "Arpitha Prasad Bharathi", "authors": "Arpitha P. Bharathi and Monaldo Mastrolilli", "title": "Ideal Membership Problem for Boolean Minority", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.SC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ideal Membership Problem (IMP) tests if an input polynomial $f\\in\n\\mathbb{F}[x_1,\\dots,x_n]$ with coefficients from a field $\\mathbb{F}$ belongs\nto a given ideal $I \\subseteq \\mathbb{F}[x_1,\\dots,x_n]$. It is a well-known\nfundamental problem with many important applications, though notoriously\nintractable in the general case. In this paper we consider the IMP for\npolynomial ideals encoding combinatorial problems and where the input\npolynomial $f$ has degree at most $d=O(1)$ (we call this problem IMP$_d$). A\ndichotomy result between ``hard'' (NP-hard) and ``easy'' (polynomial time) IMPs\nwas recently achieved for Constraint Satisfaction Problems over finite domains\n[Bulatov FOCS'17, Zhuk FOCS'17] (this is equivalent to IMP$_0$) and IMP$_d$ for\nthe Boolean domain [Mastrolilli SODA'19], both based on the classification of\nthe IMP through functions called polymorphisms. The complexity of the IMP$_d$\nfor five polymorphisms has been solved in [Mastrolilli SODA'19] whereas for the\nternary minority polymorphism it was incorrectly declared to have been resolved\nby a previous result. As a matter of fact the complexity of the IMP$_d$ for the\nternary minority polymorphism is open. In this paper we provide the missing\nlink by proving that the IMP$_d$ for Boolean combinatorial ideals whose\nconstraints are closed under the minority polymorphism can be solved in\npolynomial time. This result, along with the results in [Mastrolilli SODA'19],\ncompletes the identification of the precise borderline of tractability for the\nIMP$_d$ for constrained problems over the Boolean domain. This paper is\nmotivated by the pursuit of understanding the issue of bit complexity of\nSum-of-Squares proofs raised by O'Donnell [ITCS'17]. Raghavendra and Weitz\n[ICALP'17] show how the IMP$_d$ tractability for combinatorial ideals implies\nbounded coefficients in Sum-of-Squares proofs.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 22:41:11 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Bharathi", "Arpitha P.", ""], ["Mastrolilli", "Monaldo", ""]]}, {"id": "2006.16632", "submitter": "Jacob Focke", "authors": "Jacob Focke, Leslie Ann Goldberg, Marc Roth and Stanislav \\v{Z}ivn\\'y", "title": "Counting Homomorphisms to $K_4$-minor-free Graphs, modulo 2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of computing the parity of the number of homomorphisms\nfrom an input graph $G$ to a fixed graph $H$. Faben and Jerrum [ToC'15]\nintroduced an explicit criterion on the graph $H$ and conjectured that, if\nsatisfied, the problem is solvable in polynomial time and, otherwise, the\nproblem is complete for the complexity class $\\oplus\\mathrm{P}$ of parity\nproblems. We verify their conjecture for all graphs $H$ that exclude the\ncomplete graph on $4$ vertices as a minor. Further, we rule out the existence\nof a subexponential-time algorithm for the $\\oplus\\mathrm{P}$-complete cases,\nassuming the randomised Exponential Time Hypothesis. Our proofs introduce a\nnovel method of deriving hardness from globally defined substructures of the\nfixed graph $H$. Using this, we subsume all prior progress towards resolving\nthe conjecture (Faben and Jerrum [ToC'15]; G\\\"obel, Goldberg and Richerby\n[ToCT'14,'16]). As special cases, our machinery also yields a proof of the\nconjecture for graphs with maximum degree at most $3$, as well as a full\nclassification for the problem of counting list homomorphisms, modulo $2$.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 09:51:00 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 16:49:53 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 16:46:35 GMT"}, {"version": "v4", "created": "Tue, 27 Jul 2021 16:13:13 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Focke", "Jacob", ""], ["Goldberg", "Leslie Ann", ""], ["Roth", "Marc", ""], ["\u017divn\u00fd", "Stanislav", ""]]}, {"id": "2006.16909", "submitter": "David Schaller", "authors": "David Schaller, Peter F. Stadler and Marc Hellmuth", "title": "Complexity of modification problems for best match graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Best match graphs (BMGs) are vertex-colored directed graphs that were\nintroduced to model the relationships of genes (vertices) from different\nspecies (colors) given an underlying evolutionary tree that is assumed to be\nunknown. In real-life applications, BMGs are estimated from sequence similarity\ndata. Measurement noise and approximation errors usually result in empirically\ndetermined graphs that in general violate characteristic properties of BMGs.\nThe arc modification problems for BMGs aim at correcting such violations and\nthus provide a means to improve the initial estimates of best match data. We\nshow here that the arc deletion, arc completion and arc editing problems for\nBMGs are NP-complete and that they can be formulated and solved as integer\nlinear programs. To this end, we provide a novel characterization of BMGs in\nterms of triples (binary trees on three leaves) and a characterization of BMGs\nwith two colors in terms of forbidden subgraphs.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 15:41:10 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 09:52:55 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 15:04:01 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Schaller", "David", ""], ["Stadler", "Peter F.", ""], ["Hellmuth", "Marc", ""]]}]