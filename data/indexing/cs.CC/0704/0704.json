[{"id": "0704.0108", "submitter": "Sergey Gubin", "authors": "Sergey Gubin", "title": "Reducing SAT to 2-SAT", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  Description of a polynomial time reduction of SAT to 2-SAT of polynomial\nsize.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2007 23:16:27 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Gubin", "Sergey", ""]]}, {"id": "0704.0213", "submitter": "Ketan Mulmuley D", "authors": "Ketan D. Mulmuley Hariharan Narayanan", "title": "Geometric Complexity Theory V: On deciding nonvanishing of a generalized\n  Littlewood-Richardson coefficient", "comments": "This article has been withdrawn because it has been merged with the\n  earlier article (GCT3) in the series, and a new article appears in this GCT5\n  slot now as shown in the abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  This article has been withdrawn because it has been merged with the earlier\narticle GCT3 (arXiv: CS/0501076 [cs.CC]) in the series. The merged article is\nnow available as:\n  Geometric Complexity Theory III: on deciding nonvanishing of a\nLittlewood-Richardson Coefficient, Journal of Algebraic Combinatorics, vol. 36,\nissue 1, 2012, pp. 103-110. (Authors: Ketan Mulmuley, Hari Narayanan and Milind\nSohoni)\n  The new article in this GCT5 slot in the series is:\n  Geometric Complexity Theory V: Equivalence between blackbox derandomization\nof polynomial identity testing and derandomization of Noether's Normalization\nLemma, in the Proceedings of FOCS 2012 (abstract), arXiv:1209.5993 [cs.CC]\n(full version) (Author: Ketan Mulmuley)\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2007 15:13:27 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2012 15:23:39 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Narayanan", "Ketan D. Mulmuley Hariharan", ""]]}, {"id": "0704.0229", "submitter": "Ketan Mulmuley D", "authors": "Ketan D. Mulmuley", "title": "Geometric Complexity Theory VI: the flip via saturated and positive\n  integer programming in representation theory and algebraic geometry", "comments": "139 pages. Corrects error in the conjectural saturation hypothesis\n  (SH) in the earlier version, which was pointed out in a recent paper of\n  Briand et al (arXIv:0810.3163v1 [math.CO])", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article belongs to a series on geometric complexity theory (GCT), an\napproach to the P vs. NP and related problems through algebraic geometry and\nrepresentation theory. The basic principle behind this approach is called the\nflip. In essence, it reduces the negative hypothesis in complexity theory (the\nlower bound problems), such as the P vs. NP problem in characteristic zero, to\nthe positive hypothesis in complexity theory (the upper bound problems):\nspecifically, to showing that the problems of deciding nonvanishing of the\nfundamental structural constants in representation theory and algebraic\ngeometry, such as the well known plethysm constants--or rather certain relaxed\nforms of these decision probelms--belong to the complexity class P. In this\narticle, we suggest a plan for implementing the flip, i.e., for showing that\nthese relaxed decision problems belong to P. This is based on the reduction of\nthe preceding complexity-theoretic positive hypotheses to mathematical\npositivity hypotheses: specifically, to showing that there exist positive\nformulae--i.e. formulae with nonnegative coefficients--for the structural\nconstants under consideration and certain functions associated with them. These\nturn out be intimately related to the similar positivity properties of the\nKazhdan-Lusztig polynomials and the multiplicative structural constants of the\ncanonical (global crystal) bases in the theory of Drinfeld-Jimbo quantum\ngroups. The known proofs of these positivity properties depend on the Riemann\nhypothesis over finite fields and the related results. Thus the reduction here,\nin conjunction with the flip, in essence, says that the validity of the P vs.\nNP conjecture in characteristic zero is intimately linked to the Riemann\nhypothesis over finite fields and related problems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2007 16:41:38 GMT"}, {"version": "v2", "created": "Fri, 18 May 2007 19:55:46 GMT"}, {"version": "v3", "created": "Mon, 28 Apr 2008 19:49:27 GMT"}, {"version": "v4", "created": "Thu, 22 Jan 2009 15:25:24 GMT"}], "update_date": "2009-01-22", "authors_parsed": [["Mulmuley", "Ketan D.", ""]]}, {"id": "0704.0282", "submitter": "Samuele Bandi", "authors": "Samuele Bandi, Luca Stabellini, Andrea Conti and Velio Tralli", "title": "On Punctured Pragmatic Space-Time Codes in Block Fading Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": null, "abstract": "  This paper considers the use of punctured convolutional codes to obtain\npragmatic space-time trellis codes over block-fading channel. We show that good\nperformance can be achieved even when puncturation is adopted and that we can\nstill employ the same Viterbi decoder of the convolutional mother code by using\napproximated metrics without increasing the complexity of the decoding\noperations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2007 22:44:17 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Bandi", "Samuele", ""], ["Stabellini", "Luca", ""], ["Conti", "Andrea", ""], ["Tralli", "Velio", ""]]}, {"id": "0704.0301", "submitter": "Akitoshi Kawamura", "authors": "Akitoshi Kawamura", "title": "Differential Recursion and Differentially Algebraic Functions", "comments": "14 pages, 3 figures", "journal-ref": "Revised and published in ACM Trans. Comput. Logic 10, Article 22,\n  2009, under the title \"Differential Recursion\".", "doi": "10.1145/1507244.1507252", "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  Moore introduced a class of real-valued \"recursive\" functions by analogy with\nKleene's formulation of the standard recursive functions. While his concise\ndefinition inspired a new line of research on analog computation, it contains\nsome technical inaccuracies. Focusing on his \"primitive recursive\" functions,\nwe pin down what is problematic and discuss possible attempts to remove the\nambiguity regarding the behavior of the differential recursion operator on\npartial functions. It turns out that in any case the purported relation to\ndifferentially algebraic functions, and hence to Shannon's model of analog\ncomputation, fails.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2007 19:50:14 GMT"}], "update_date": "2009-04-19", "authors_parsed": [["Kawamura", "Akitoshi", ""]]}, {"id": "0704.0309", "submitter": "Guohun Zhu", "authors": "Guohun Zhu", "title": "The Complexity of HCP in Digraps with Degree Bound Two", "comments": "10 pages, 4 figures, had been submitted to a Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": null, "abstract": "  The Hamiltonian cycle problem (HCP) in digraphs D with degree bound two is\nsolved by two mappings in this paper. The first bijection is between an\nincidence matrix C_{nm} of simple digraph and an incidence matrix F of balanced\nbipartite undirected graph G; The second mapping is from a perfect matching of\nG to a cycle of D. It proves that the complexity of HCP in D is polynomial, and\nfinding a second non-isomorphism Hamiltonian cycle from a given Hamiltonian\ndigraph with degree bound two is also polynomial. Lastly it deduces P=NP base\non the results.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2007 03:50:43 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2007 15:42:14 GMT"}, {"version": "v3", "created": "Fri, 13 Jul 2007 01:38:24 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Zhu", "Guohun", ""]]}, {"id": "0704.0468", "submitter": "Jinsong Tan", "authors": "Jinsong Tan", "title": "Inapproximability of Maximum Weighted Edge Biclique and Its Applications", "comments": null, "journal-ref": "LNCS 4978, TAMC 2008, pp 282-293", "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a bipartite graph $G = (V_1,V_2,E)$ where edges take on {\\it both}\npositive and negative weights from set $\\mathcal{S}$, the {\\it maximum weighted\nedge biclique} problem, or $\\mathcal{S}$-MWEB for short, asks to find a\nbipartite subgraph whose sum of edge weights is maximized. This problem has\nvarious applications in bioinformatics, machine learning and databases and its\n(in)approximability remains open. In this paper, we show that for a wide range\nof choices of $\\mathcal{S}$, specifically when $| \\frac{\\min\\mathcal{S}} {\\max\n\\mathcal{S}} | \\in \\Omega(\\eta^{\\delta-1/2}) \\cap O(\\eta^{1/2-\\delta})$ (where\n$\\eta = \\max\\{|V_1|, |V_2|\\}$, and $\\delta \\in (0,1/2]$), no polynomial time\nalgorithm can approximate $\\mathcal{S}$-MWEB within a factor of $n^{\\epsilon}$\nfor some $\\epsilon > 0$ unless $\\mathsf{RP = NP}$. This hardness result gives\njustification of the heuristic approaches adopted for various applied problems\nin the aforementioned areas, and indicates that good approximation algorithms\nare unlikely to exist. Specifically, we give two applications by showing that:\n1) finding statistically significant biclusters in the SAMBA model, proposed in\n\\cite{Tan02} for the analysis of microarray data, is\n$n^{\\epsilon}$-inapproximable; and 2) no polynomial time algorithm exists for\nthe Minimum Description Length with Holes problem \\cite{Bu05} unless\n$\\mathsf{RP=NP}$.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2007 21:39:11 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2009 02:50:29 GMT"}], "update_date": "2009-03-23", "authors_parsed": [["Tan", "Jinsong", ""]]}, {"id": "0704.1043", "submitter": "Hector Zenil", "authors": "Jean-Paul Delahaye and Hector Zenil", "title": "On the Kolmogorov-Chaitin Complexity for short sequences", "comments": "21 pages. Paper webpage: http://www.mathrix.org/experimentalAIT/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A drawback of Kolmogorov-Chaitin complexity (K) as a function from s to the\nshortest program producing s is its noncomputability which limits its range of\napplicability. Moreover, when strings are short, the dependence of K on a\nparticular universal Turing machine U can be arbitrary. In practice one can\napproximate it by computable compression methods. However, such compression\nmethods do not always provide meaningful approximations--for strings shorter,\nfor example, than typical compiler lengths. In this paper we suggest an\nempirical approach to overcome this difficulty and to obtain a stable\ndefinition of the Kolmogorov-Chaitin complexity for short sequences.\nAdditionally, a correlation in terms of distribution frequencies was found\nacross the output of two models of abstract machines, namely unidimensional\ncellular automata and deterministic Turing machine.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2007 20:01:47 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2007 13:00:55 GMT"}, {"version": "v3", "created": "Wed, 30 May 2007 10:16:36 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2010 20:03:20 GMT"}, {"version": "v5", "created": "Fri, 17 Dec 2010 01:36:26 GMT"}], "update_date": "2010-12-20", "authors_parsed": [["Delahaye", "Jean-Paul", ""], ["Zenil", "Hector", ""]]}, {"id": "0704.1269", "submitter": "Lenka Zdeborova", "authors": "Lenka Zdeborov\\'a, Florent Krzakala", "title": "Phase Transitions in the Coloring of Random Graphs", "comments": "36 pages, 15 figures", "journal-ref": "Phys. Rev. E 76, 031131 (2007)", "doi": "10.1103/PhysRevE.76.031131", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC", "license": null, "abstract": "  We consider the problem of coloring the vertices of a large sparse random\ngraph with a given number of colors so that no adjacent vertices have the same\ncolor. Using the cavity method, we present a detailed and systematic analytical\nstudy of the space of proper colorings (solutions).\n  We show that for a fixed number of colors and as the average vertex degree\n(number of constraints) increases, the set of solutions undergoes several phase\ntransitions similar to those observed in the mean field theory of glasses.\nFirst, at the clustering transition, the entropically dominant part of the\nphase space decomposes into an exponential number of pure states so that beyond\nthis transition a uniform sampling of solutions becomes hard. Afterward, the\nspace of solutions condenses over a finite number of the largest states and\nconsequently the total entropy of solutions becomes smaller than the annealed\none. Another transition takes place when in all the entropically dominant\nstates a finite fraction of nodes freezes so that each of these nodes is\nallowed a single color in all the solutions inside the state. Eventually, above\nthe coloring threshold, no more solutions are available. We compute all the\ncritical connectivities for Erdos-Renyi and regular random graphs and determine\ntheir asymptotic values for large number of colors.\n  Finally, we discuss the algorithmic consequences of our findings. We argue\nthat the onset of computational hardness is not associated with the clustering\ntransition and we suggest instead that the freezing transition might be the\nrelevant phenomenon. We also discuss the performance of a simple local Walk-COL\nalgorithm and of the belief propagation algorithm in the light of our results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2007 16:42:15 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2007 15:26:20 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Zdeborov\u00e1", "Lenka", ""], ["Krzakala", "Florent", ""]]}, {"id": "0704.1678", "submitter": "Shanghua Teng", "authors": "Xi Chen, Xiaotie Deng, Shang-Hua Teng", "title": "Settling the Complexity of Computing Two-Player Nash Equilibria", "comments": "53 pages 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": null, "abstract": "  We settle a long-standing open question in algorithmic game theory. We prove\nthat Bimatrix, the problem of finding a Nash equilibrium in a two-player game,\nis complete for the complexity class PPAD Polynomial Parity Argument, Directed\nversion) introduced by Papadimitriou in 1991.\n  This is the first of a series of results concerning the complexity of Nash\nequilibria. In particular, we prove the following theorems:\n  Bimatrix does not have a fully polynomial-time approximation scheme unless\nevery problem in PPAD is solvable in polynomial time. The smoothed complexity\nof the classic Lemke-Howson algorithm and, in fact, of any algorithm for\nBimatrix is not polynomial unless every problem in PPAD is solvable in\nrandomized polynomial time. Our results demonstrate that, even in the simplest\nform of non-cooperative games, equilibrium computation and approximation are\npolynomial-time equivalent to fixed point computation. Our results also have\ntwo broad complexity implications in mathematical economics and operations\nresearch: Arrow-Debreu market equilibria are PPAD-hard to compute. The P-Matrix\nLinear Complementary Problem is computationally harder than convex programming\nunless every problem in PPAD is solvable in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2007 23:54:30 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Chen", "Xi", ""], ["Deng", "Xiaotie", ""], ["Teng", "Shang-Hua", ""]]}, {"id": "0704.1694", "submitter": "Sergey Yekhanin", "authors": "Kiran S. Kedlaya, Sergey Yekhanin", "title": "Locally Decodable Codes From Nice Subsets of Finite Fields and Prime\n  Factors of Mersenne Numbers", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.NT", "license": null, "abstract": "  A k-query Locally Decodable Code (LDC) encodes an n-bit message x as an N-bit\ncodeword C(x), such that one can probabilistically recover any bit x_i of the\nmessage by querying only k bits of the codeword C(x), even after some constant\nfraction of codeword bits has been corrupted. The major goal of LDC related\nresearch is to establish the optimal trade-off between length and query\ncomplexity of such codes.\n  Recently [Y] introduced a novel technique for constructing locally decodable\ncodes and vastly improved the upper bounds for code length. The technique is\nbased on Mersenne primes. In this paper we extend the work of [Y] and argue\nthat further progress via these methods is tied to progress on an old number\ntheory question regarding the size of the largest prime factors of Mersenne\nnumbers.\n  Specifically, we show that every Mersenne number m=2^t-1 that has a prime\nfactor p>m^\\gamma yields a family of k(\\gamma)-query locally decodable codes of\nlength Exp(n^{1/t}). Conversely, if for some fixed k and all \\epsilon > 0 one\ncan use the technique of [Y] to obtain a family of k-query LDCs of length\nExp(n^\\epsilon); then infinitely many Mersenne numbers have prime factors arger\nthan known currently.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2007 04:18:19 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Kedlaya", "Kiran S.", ""], ["Yekhanin", "Sergey", ""]]}, {"id": "0704.2386", "submitter": "Pilar Albert", "authors": "Pilar Albert, Elvira Mayordomo, and Philippe Moser", "title": "Bounded Pushdown dimension vs Lempel Ziv information density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": null, "abstract": "  In this paper we introduce a variant of pushdown dimension called bounded\npushdown (BPD) dimension, that measures the density of information contained in\na sequence, relative to a BPD automata, i.e. a finite state machine equipped\nwith an extra infinite memory stack, with the additional requirement that every\ninput symbol only allows a bounded number of stack movements. BPD automata are\na natural real-time restriction of pushdown automata. We show that BPD\ndimension is a robust notion by giving an equivalent characterization of BPD\ndimension in terms of BPD compressors. We then study the relationships between\nBPD compression, and the standard Lempel-Ziv (LZ) compression algorithm, and\nshow that in contrast to the finite-state compressor case, LZ is not universal\nfor bounded pushdown compressors in a strong sense: we construct a sequence\nthat LZ fails to compress signicantly, but that is compressed by at least a\nfactor 2 by a BPD compressor. As a corollary we obtain a strong separation\nbetween finite-state and BPD dimension.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2007 16:49:48 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Albert", "Pilar", ""], ["Mayordomo", "Elvira", ""], ["Moser", "Philippe", ""]]}, {"id": "0704.2779", "submitter": "J D", "authors": "Jonas Dieckelmann", "title": "The Complexity of Simple Stochastic Games", "comments": "Hi, while reading through literature i noticed that it has not yet\n  been proved that computing the value vector of simple stochastic games is a\n  Problem in FNP. This is why i came up with a prove in this seminar work of\n  mine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": null, "abstract": "  In this paper we survey the computational time complexity of assorted simple\nstochastic game problems, and we give an overview of the best known algorithms\nassociated with each problem.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2007 19:51:36 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Dieckelmann", "Jonas", ""]]}, {"id": "0704.3177", "submitter": "Andreas Enge", "authors": "Andreas Enge (INRIA Futurs)", "title": "Computing modular polynomials in quasi-linear time", "comments": null, "journal-ref": "Mathematics of Computation 78, 267 (2009) 1809-1824", "doi": null, "report-no": null, "categories": "math.NT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse and compare the complexity of several algorithms for computing\nmodular polynomials. We show that an algorithm relying on floating point\nevaluation of modular functions and on interpolation, which has received little\nattention in the literature, has a complexity that is essentially (up to\nlogarithmic factors) linear in the size of the computed polynomials. In\nparticular, it obtains the classical modular polynomials $\\Phi_\\ell$ of prime\nlevel $\\ell$ in time O (\\ell^3 \\log^4 \\ell \\log \\log \\ell). Besides treating\nmodular polynomials for $\\Gamma^0 (\\ell)$, which are an important ingredient in\nmany algorithms dealing with isogenies of elliptic curves, the algorithm is\neasily adapted to more general situations. Composite levels are handled just as\neasily as prime levels, as well as polynomials between a modular function and\nits transform of prime level, such as the Schl\\\"afli polynomials and their\ngeneralisations. Our distributed implementation of the algorithm confirms the\ntheoretical analysis by computing modular equations of record level around\n10000 in less than two weeks on ten processors.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2007 12:27:39 GMT"}, {"version": "v2", "created": "Wed, 23 Jul 2008 12:33:49 GMT"}], "update_date": "2009-05-08", "authors_parsed": [["Enge", "Andreas", "", "INRIA Futurs"]]}, {"id": "0704.3496", "submitter": "Frank Gurski", "authors": "Frank Gurski", "title": "Polynomial algorithms for protein similarity search for restricted mRNA\n  structures", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  In this paper we consider the problem of computing an mRNA sequence of\nmaximal similarity for a given mRNA of secondary structure constraints,\nintroduced by Backofen et al. in [BNS02] denoted as the MRSO problem. The\nproblem is known to be NP-complete for planar associated implied structure\ngraphs of vertex degree at most 3. In [BFHV05] a first polynomial dynamic\nprogramming algorithms for MRSO on implied structure graphs with maximum vertex\ndegree 3 of bounded cut-width is shown. We give a simple but more general\npolynomial dynamic programming solution for the MRSO problem for associated\nimplied structure graphs of bounded clique-width. Our result implies that MRSO\nis polynomial for graphs of bounded tree-width, co-graphs, $P_4$-sparse graphs,\nand distance hereditary graphs. Further we conclude that the problem of\ncomparing two solutions for MRSO is hard for the class of problems which can be\nsolved in polynomial time with a number of parallel queries to an oracle in NP.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2007 08:30:14 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Gurski", "Frank", ""]]}, {"id": "0704.3683", "submitter": "Mark Jerrum", "authors": "Martin Dyer, Leslie Ann Goldberg and Mark Jerrum", "title": "The Complexity of Weighted Boolean #CSP", "comments": "Minor revision", "journal-ref": "SIAM J. Comput. 38(5), 1970-1986", "doi": "10.1137/070690201", "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a dichotomy theorem for the complexity of computing the\npartition function of an instance of a weighted Boolean constraint satisfaction\nproblem. The problem is parameterised by a finite set F of non-negative\nfunctions that may be used to assign weights to the configurations (feasible\nsolutions) of a problem instance. Classical constraint satisfaction problems\ncorrespond to the special case of 0,1-valued functions. We show that the\npartition function, i.e. the sum of the weights of all configurations, can be\ncomputed in polynomial time if either (1) every function in F is of ``product\ntype'', or (2) every function in F is ``pure affine''. For every other fixed\nset F, computing the partition function is FP^{#P}-complete.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2007 13:19:32 GMT"}, {"version": "v2", "created": "Thu, 19 Jun 2008 08:00:54 GMT"}], "update_date": "2009-02-23", "authors_parsed": [["Dyer", "Martin", ""], ["Goldberg", "Leslie Ann", ""], ["Jerrum", "Mark", ""]]}, {"id": "0704.3835", "submitter": "K. Y. Michael Wong", "authors": "K. Y. Michael Wong and David Saad", "title": "Minimizing Unsatisfaction in Colourful Neighbourhoods", "comments": "28 pages, 12 figures, substantially revised with additional\n  explanation", "journal-ref": "J. Phys. A: Math. Theor. 41, 324023 (2008).", "doi": "10.1088/1751-8113/41/32/324023", "report-no": null, "categories": "cs.DS cond-mat.dis-nn cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colouring sparse graphs under various restrictions is a theoretical problem\nof significant practical relevance. Here we consider the problem of maximizing\nthe number of different colours available at the nodes and their\nneighbourhoods, given a predetermined number of colours. In the analytical\nframework of a tree approximation, carried out at both zero and finite\ntemperatures, solutions obtained by population dynamics give rise to estimates\nof the threshold connectivity for the incomplete to complete transition, which\nare consistent with those of existing algorithms. The nature of the transition\nas well as the validity of the tree approximation are investigated.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2007 10:03:00 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2007 04:18:58 GMT"}, {"version": "v3", "created": "Tue, 1 Jul 2008 17:43:32 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Wong", "K. Y. Michael", ""], ["Saad", "David", ""]]}]