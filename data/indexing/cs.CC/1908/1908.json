[{"id": "1908.00041", "submitter": "Yuguang Wang", "authors": "Quoc T. Le Gia, Ming Li, Yu Guang Wang", "title": "FaVeST: Fast Vector Spherical Harmonic Transforms", "comments": "23 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector spherical harmonics on the unit sphere of $\\mathbb{R}^3$ have broad\napplications in geophysics, quantum mechanics and astrophysics. In the\nrepresentation of a tangent vector field, one needs to evaluate the expansion\nand the Fourier coefficients of vector spherical harmonics. In this paper, we\ndevelop fast algorithms (FaVeST) for vector spherical harmonic transforms on\nthese evaluations. The forward FaVeST evaluates the Fourier coefficients and\nhas a computational cost proportional to $N\\log \\sqrt{N}$ for $N$ number of\nevaluation points. The adjoint FaVeST which evaluates a linear combination of\nvector spherical harmonics with a degree up to $\\sqrt{M}$ for $M$ evaluation\npoints has cost proportional to $M\\log\\sqrt{M}$. Numerical examples of\nsimulated tangent fields illustrate the accuracy, efficiency and stability of\nFaVeST.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 18:31:24 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 06:32:57 GMT"}, {"version": "v3", "created": "Wed, 24 Mar 2021 07:41:11 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Gia", "Quoc T. Le", ""], ["Li", "Ming", ""], ["Wang", "Yu Guang", ""]]}, {"id": "1908.00140", "submitter": "Max Reuter", "authors": "Max Reuter, Gheorghe-Teodor Bercea", "title": "Sublinear Subwindow Search", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient approximation algorithm for subwindow search that\nruns in sublinear time and memory. Applied to object localization, this\nalgorithm significantly reduces running time and memory usage while maintaining\ncompetitive accuracy scores compared to the state-of-the-art. The algorithm's\naccuracy also scales with both the size and the spatial coherence\n(nearby-element similarity) of the matrix. It is thus well-suited for real-time\napplications and against many matrices in general.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 23:21:52 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Reuter", "Max", ""], ["Bercea", "Gheorghe-Teodor", ""]]}, {"id": "1908.00491", "submitter": "Konrad Dabrowski", "authors": "Konrad K. Dabrowski, Carl Feghali, Matthew Johnson, Giacomo Paesani,\n  Dani\\\"el Paulusma, Pawe{\\l} Rz\\k{a}\\.zewski", "title": "On Cycle Transversals and Their Connected Variants in the Absence of a\n  Small Linear Forest", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is $H$-free if it contains no induced subgraph isomorphic to $H$. We\nprove new complexity results for the two classical cycle transversal problems\nFeedback Vertex Set and Odd Cycle Transversal by showing that they can be\nsolved in polynomial time on $(sP_1+P_3)$-free graphs for every integer $s\\geq\n1$. We show the same result for the variants Connected Feedback Vertex Set and\nConnected Odd Cycle Transversal. We also prove that the latter two problems are\npolynomial-time solvable on cographs; this was already known for Feedback\nVertex Set and Odd Cycle Transversal. We complement these results by proving\nthat Odd Cycle Transversal and Connected Odd Cycle Transversal are NP-complete\non $(P_2+P_5,P_6)$-free graphs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 16:36:43 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Dabrowski", "Konrad K.", ""], ["Feghali", "Carl", ""], ["Johnson", "Matthew", ""], ["Paesani", "Giacomo", ""], ["Paulusma", "Dani\u00ebl", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "1908.00887", "submitter": "Donsub Rim", "authors": "Donsub Rim", "title": "Exact and fast inversion of the approximate discrete Radon transform\n  from partial data", "comments": "4 pages, 1 figure", "journal-ref": "Appl. Math. Lett. 102 106159 (2020)", "doi": "10.1016/j.aml.2019.106159", "report-no": null, "categories": "math.NA cs.CC cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an exact inversion formula for the approximate discrete Radon\ntransform introduced in [Brady, SIAM J. Comput., 27(1), 107--119] that is of\ncost $O(N \\log N)$ for a square 2D image with $N$ pixels and requires only\npartial data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:41:35 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 05:45:55 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 05:29:43 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Rim", "Donsub", ""]]}, {"id": "1908.01020", "submitter": "Joshua Brody", "authors": "Eric Blais and Joshua Brody", "title": "Optimal Separation and Strong Direct Sum for Randomized Query Complexity", "comments": "15 pages, 2 figures, CCC 2019", "journal-ref": null, "doi": "10.4230/LIPIcs.CCC.2019.29", "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish two results regarding the query complexity of bounded-error\nrandomized algorithms.\n  * Bounded-error separation theorem. There exists a total function $f :\n\\{0,1\\}^n \\to \\{0,1\\}$ whose $\\epsilon$-error randomized query complexity\nsatisfies $\\overline{\\mathrm{R}}_\\epsilon(f) = \\Omega( \\mathrm{R}(f) \\cdot\n\\log\\frac1\\epsilon)$.\n  * Strong direct sum theorem. For every function $f$ and every $k \\ge 2$, the\nrandomized query complexity of computing $k$ instances of $f$ simultaneously\nsatisfies $\\overline{\\mathrm{R}}_\\epsilon(f^k) = \\Theta(k \\cdot\n\\overline{\\mathrm{R}}_{\\frac\\epsilon k}(f))$.\n  As a consequence of our two main results, we obtain an optimal superlinear\ndirect-sum-type theorem for randomized query complexity: there exists a\nfunction $f$ for which $\\mathrm{R}(f^k) = \\Theta( k \\log k \\cdot\n\\mathrm{R}(f))$. This answers an open question of Drucker (2012). Combining\nthis result with the query-to-communication complexity lifting theorem of\nG\\\"o\\\"os, Pitassi, and Watson (2017), this also shows that there is a total\nfunction whose public-coin randomized communication complexity satisfies\n$\\mathrm{R}^{\\mathrm{cc}} (f^k) = \\Theta( k \\log k \\cdot\n\\mathrm{R}^{\\mathrm{cc}}(f))$, answering a question of Feder, Kushilevitz,\nNaor, and Nisan (1995).\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 19:16:22 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Blais", "Eric", ""], ["Brody", "Joshua", ""]]}, {"id": "1908.02213", "submitter": "Tillmann Miltzow", "authors": "Michael G. Dobbins, Andreas Holmsen, Tillmann Miltzow", "title": "A Universality Theorem for Nested Polytopes", "comments": "20 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a nutshell, we show that polynomials and nested polytopes are topological,\nalgebraic and algorithmically equivalent. Given two polytops $A\\subseteq B$ and\na number $k$, the Nested Polytope Problem (NPP) asks, if there exists a\npolytope $X$ on $k$ vertices such that $A\\subseteq X \\subseteq B$. The polytope\n$A$ is given by a set of vertices and the polytope $B$ is given by the defining\nhyperplanes. We show a universality theorem for NPP. Given an instance $I$ of\nthe NPP, we define the solutions set of $I$ as $$ V'(I) = \\{(x_1,\\ldots,x_k)\\in\n\\mathbb{R}^{k\\cdot n} : A\\subseteq \\text{conv}(x_1,\\ldots,x_k) \\subseteq B\\}.$$\nAs there are many symmetries, induced by permutations of the vertices, we will\nconsider the \\emph{normalized} solution space $V(I)$. Let $F$ be a finite set\nof polynomials, with bounded solution space. Then there is an instance $I$ of\nthe NPP, which has a rationally-equivalent normalized solution space $V(I)$.\nTwo sets $V$ and $W$ are rationally equivalent if there exists a homeomorphism\n$f : V \\rightarrow W$ such that both $f$ and $f^{-1}$ are given by rational\nfunctions. A function $f:V\\rightarrow W$ is a homeomorphism, if it is\ncontinuous, invertible and its inverse is continuous as well. As a corollary,\nwe show that NPP is $\\exists \\mathbb{R}$-complete. This implies that unless\n$\\exists \\mathbb{R} =$ NP, the NPP is not contained in the complexity class NP.\nNote that those results already follow from a recent paper by Shitov. Our proof\nis geometric and arguably easier.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 15:31:43 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Dobbins", "Michael G.", ""], ["Holmsen", "Andreas", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "1908.02499", "submitter": "Gil Kalai", "authors": "Gil Kalai", "title": "The Argument against Quantum Computers", "comments": "To appear in: Hemmo, Meir and Shenker, Orly (eds.) Quantum,\n  Probability, Logic: Itamar Pitowsky's Work and Influence, Springer, Nature\n  (2019), forthcoming", "journal-ref": "in: M. Hemmo, and O. Shenker,(eds.) Quantum, Probability, Logic:\n  Itamar Pitowsky's Work and Influence, Springer(2020),pp. 399-422", "doi": null, "report-no": null, "categories": "quant-ph cs.CC math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a computational complexity argument against the feasibility of\nquantum computers. We identify a very low complexity class of probability\ndistributions described by noisy intermediate-scale quantum computers, and\nexplain why it will allow neither good-quality quantum error-correction nor a\ndemonstration of \"quantum supremacy.\" Some general principles governing the\nbehavior of noisy quantum systems are derived. Our work supports the \"physical\nChurch thesis\" studied by Pitowsky (1990) and follows his vision of using\nabstract ideas about computation to study the performance of actual physical\ncomputers.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 09:37:55 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Kalai", "Gil", ""]]}, {"id": "1908.02525", "submitter": "Aleksandrs Belovs", "authors": "Aleksandrs Belovs, Eric Blais, and Abhinav Bommireddi", "title": "Testing convexity of functions over finite domains", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish new upper and lower bounds on the number of queries required to\ntest convexity of functions over various discrete domains.\n  1. We provide a simplified version of the non-adaptive convexity tester on\nthe line. We re-prove the upper bound $O(\\frac{\\log(\\epsilon n)}{\\epsilon})$ in\nthe usual uniform model, and prove an $O(\\frac{\\log n}{\\epsilon})$ upper bound\nin the distribution-free setting.\n  2. We show a tight lower bound of $\\Omega(\\frac{\\log(\\epsilon n)}{\\epsilon})$\nqueries for testing convexity of functions $f: [n] \\rightarrow \\mathbb{R}$ on\nthe line. This lower bound applies to both adaptive and non-adaptive\nalgorithms, and matches the upper bound from item 1, showing that adaptivity\ndoes not help in this setting.\n  3. Moving to higher dimensions, we consider the case of a stripe $[3] \\times\n[n]$. We construct an \\emph{adaptive} tester for convexity of functions\n$f\\colon [3] \\times [n] \\to \\mathbb R$ with query complexity $O(\\log^2 n)$. We\nalso show that any \\emph{non-adaptive} tester must use $\\Omega(\\sqrt{n})$\nqueries in this setting. Thus, adaptivity yields an exponential improvement for\nthis problem.\n  4. For functions $f\\colon [n]^d \\to \\mathbb R$ over domains of dimension $d\n\\geq 2$, we show a non-adaptive query lower bound\n$\\Omega((\\frac{n}{d})^{\\frac{d}{2}})$.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 10:50:45 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Belovs", "Aleksandrs", ""], ["Blais", "Eric", ""], ["Bommireddi", "Abhinav", ""]]}, {"id": "1908.02530", "submitter": "Patrick Prosser", "authors": "Benjamin Bumpus, Patrick Prosser, James Trimble", "title": "A Constraint Model for the Tree Decomposition of a Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a constraint model for the problem of producing a tree\ndecomposition of a graph. The inputs to the model are a simple graph G, the\nnumber of nodes in the desired tree decomposition and the maximum cardinality\nof each node in that decomposition. Via a sequence of decision problems, the\nmodel allows us to find the tree width of a graph whilst delivering a tree\ndecomposition of that width, i.e. a witness.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 11:18:27 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Bumpus", "Benjamin", ""], ["Prosser", "Patrick", ""], ["Trimble", "James", ""]]}, {"id": "1908.02860", "submitter": "Saulo Queiroz", "authors": "Saulo Queiroz and Wesley Silva and Jo\\~ao P. Vilela and Edmundo\n  Monteiro", "title": "Maximal Spectral Efficiency of OFDM with Index Modulation under\n  Polynomial Space Complexity", "comments": "Copyright (c) 2020 IEEE. Personal use is permitted. For any other\n  purposes, permission must be obtained from the IEEE by emailing\n  pubs-permissions@ieee.org", "journal-ref": "IEEE Wireless Communications Letters, 2020", "doi": "10.1109/LWC.2020.2965533", "report-no": null, "categories": "eess.SP cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we demonstrate a mapper that enables all waveforms of OFDM\nwith Index Modulation (OFDM-IM) while preserving polynomial time and space\ncomputational complexities. Enabling all OFDM-IM waveforms maximizes the\nspectral efficiency (SE) gain over the classic OFDM but, as far as we know, the\ncomputational overhead of the resulting mapper remains conjectured as\nprohibitive across the OFDM-IM literature. We show that the largest number of\nbinomial coefficient calculations performed by the original OFDM-IM mapper is\npolynomial on the number of subcarriers, even under the setup that maximizes\nthe SE gain over OFDM. Also, such coefficients match the entries of the\nso-called Pascal's triangle (PT). Thus, by assisting the OFDM-IM mapper with a\nPT table, we show that the maximum SE gain over OFDM can be achieved under\npolynomial (rather than exponential) time and space complexities.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 22:17:23 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 18:23:06 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 11:42:35 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Queiroz", "Saulo", ""], ["Silva", "Wesley", ""], ["Vilela", "Jo\u00e3o P.", ""], ["Monteiro", "Edmundo", ""]]}, {"id": "1908.02905", "submitter": "Mohammad Amin Sarafrazi", "authors": "Mohammad Amin Sarafrazi, \\\"Ulle Kotta and Zbigniew Bartosiewicz", "title": "Finite determination of accessibility and geometric structure of\n  singular points for nonlinear systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting tools from algebraic geometry, the problem of finiteness of\ndetermination of accessibility/strong accessibility is investigated for\npolynomial systems and also for analytic systems that are immersible into\npolynomial systems. The results are constructive, and algorithms are given to\nfind the maximum depth of Lie brackets necessary for deciding\naccessibility/strong accessibility of the system at any point, called here\naccessibility/strong accessibility index of the system, and is known as the\ndegree of non-holonomy in the literature. Alternatively, upper bounds on the\naccessibility/strong accessibility index are obtained, which can be computed\neasier. In each approach, the entire set of accessibility/strong accessibility\nsingular points are obtained.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 02:10:02 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Sarafrazi", "Mohammad Amin", ""], ["Kotta", "\u00dclle", ""], ["Bartosiewicz", "Zbigniew", ""]]}, {"id": "1908.03363", "submitter": "Ami Paz", "authors": "Pierluigi Crescenzi and Pierre Fraigniaud and Ami Paz", "title": "Trade-offs in Distributed Interactive Proofs", "comments": "To be presented in DISC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of interactive proofs in the context of distributed network\ncomputing is a novel topic, recently introduced by Kol, Oshman, and Saxena\n[PODC 2018]. In the spirit of sequential interactive proofs theory, we study\nthe power of distributed interactive proofs. This is achieved via a series of\nresults establishing trade-offs between various parameters impacting the power\nof interactive proofs, including the number of interactions, the certificate\nsize, the communication complexity, and the form of randomness used. Our\nresults also connect distributed interactive proofs with the established field\nof distributed verification. In general, our results contribute to providing\nstructure to the landscape of distributed interactive proofs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 08:30:36 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Crescenzi", "Pierluigi", ""], ["Fraigniaud", "Pierre", ""], ["Paz", "Ami", ""]]}, {"id": "1908.03501", "submitter": "Peter Hertling", "authors": "Peter Hertling and Gisela Krommes", "title": "EXPSPACE-Completeness of the Logics K4xS5 and S4xS5 and the Logic of\n  Subset Spaces, Part 1: ESPACE-Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the satisfiability problems of the product logics K4xS5 and\nS4xS5 and of the logic SSL of subset spaces are in N2EXPTIME. We improve this\nupper bound for the complexity of these problems by presenting\nESPACE-algorithms for these problems. In another paper we show that these\nproblems are EXPSPACE-hard. This shows that all three problems are\nEXPSPACE-complete.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 15:43:50 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Hertling", "Peter", ""], ["Krommes", "Gisela", ""]]}, {"id": "1908.03509", "submitter": "Peter Hertling", "authors": "Peter Hertling and Gisela Krommes", "title": "EXPSPACE-Completeness of the Logics K4xS5 and S4xS5 and the Logic of\n  Subset Spaces, Part 2: EXPSPACE-Hardness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the satisfiability problems of the product logics K4xS5 and\nS4xS5 are NEXPTIME-hard and that the satisfiability problem of the logic SSL of\nsubset spaces is PSPACE-hard. We improve these lower bounds for the complexity\nof these problems by showing that all three problems are EXPSPACE-hard under\nlogspace reduction. In another paper we show that these problems are in ESPACE.\nThis shows that all three problems are EXPSPACE-complete.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 15:57:36 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Hertling", "Peter", ""], ["Krommes", "Gisela", ""]]}, {"id": "1908.03870", "submitter": "Christian Komusiewicz", "authors": "Guillaume Fertin and Christian Komusiewicz", "title": "Graph Motif Problems Parameterized by Dual", "comments": "A preliminary version of this work appeared in Proceedings of the\n  27th Annual Symposium on Combinatorial Pattern Matching (CPM '16), volume 54\n  of LIPIcs, pages 7:1--7:12. This version contains all missing proofs and\n  several further improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G=(V,E)$ be a vertex-colored graph, where $C$ is the set of colors used\nto color $V$. The Graph Motif (or GM) problem takes as input $G$, a multiset\n$M$ of colors built from $C$, and asks whether there is a subset $S\\subseteq V$\nsuch that (i) $G[S]$ is connected and (ii) the multiset of colors obtained from\n$S$ equals $M$. The Colorful Graph Motif (or CGM) problem is the special case\nof GM in which $M$ is a set, and the List-Colored Graph Motif (or LGM) problem\nis the extension of GM in which each vertex $v$ of $V$ may choose its color\nfrom a list $\\mathcal{L}(v)\\subseteq C$ of colors.\n  We study the three problems GM, CGM, and LGM, parameterized by the dual\nparameter $\\ell:=|V|-|M|$. For general graphs, we show that, assuming the\nstrong exponential time hypothesis, CGM has no $(2-\\epsilon)^\\ell\\cdot\n|V|^{\\mathcal{O}(1)}$-time algorithm, which implies that a previous algorithm,\nrunning in $\\mathcal{O}(2^\\ell\\cdot |E|)$ time is optimal [Betzler et al.,\nIEEE/ACM TCBB 2011]. We also prove that LGM is W[1]-hard with respect to $\\ell$\neven if we restrict ourselves to lists of at most two colors. If we constrain\nthe input graph to be a tree, then we show that GM can be solved in\n$\\mathcal{O}(3^\\ell\\cdot |V|)$ time but admits no polynomial-size problem\nkernel, while CGM can be solved in $\\mathcal{O}(\\sqrt{2}^{\\ell} + |V|)$ time\nand admits a polynomial-size problem kernel.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 08:34:12 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Fertin", "Guillaume", ""], ["Komusiewicz", "Christian", ""]]}, {"id": "1908.03996", "submitter": "Joshua Brakensiek", "authors": "Joshua Brakensiek, Ray Li, Bruce Spang", "title": "Coded trace reconstruction in a constant number of traces", "comments": "34 pages, 2 figures; FOCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DS math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coded trace reconstruction problem asks to construct a code $C\\subset\n\\{0,1\\}^n$ such that any $x\\in C$ is recoverable from independent outputs\n(\"traces\") of $x$ from a binary deletion channel (BDC). We present binary codes\nof rate $1-\\varepsilon$ that are efficiently recoverable from\n${\\exp(O_q(\\log^{1/3}(\\frac{1}{\\varepsilon})))}$ (a constant independent of\n$n$) traces of a $\\operatorname{BDC}_q$ for any constant deletion probability\n$q\\in(0,1)$. We also show that, for rate $1-\\varepsilon$ binary codes, $\\tilde\n\\Omega(\\log^{5/2}(1/\\varepsilon))$ traces are required. The results follow from\na pair of black-box reductions that show that average-case trace reconstruction\nis essentially equivalent to coded trace reconstruction. We also show that\nthere exist codes of rate $1-\\varepsilon$ over an $O_{\\varepsilon}(1)$-sized\nalphabet that are recoverable from $O(\\log(1/\\varepsilon))$ traces, and that\nthis is tight.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 04:27:12 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 18:14:30 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 22:28:29 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Brakensiek", "Joshua", ""], ["Li", "Ray", ""], ["Spang", "Bruce", ""]]}, {"id": "1908.04198", "submitter": "Janosch D\\\"ocker", "authors": "Andreas Darmann and Janosch D\\\"ocker", "title": "On simplified NP-complete variants of Not-All-Equal 3-Sat and 3-Sat", "comments": "34 pages; 1 figure; reference corrected in introduction (the result\n  of Karpinski and Piecuch does not consider monotone formulas); revised\n  notation for formulas and clauses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider simplified, monotone versions of Not-All-Equal 3-Sat and 3-Sat,\nvariants of the famous Satisfiability Problem where each clause is made up of\nexactly three distinct literals. We show that Not-All-Equal 3-Sat remains\nNP-complete even if (1) each variable appears exactly four times, (2) there are\nno negations in the formula, and (3) the formula is linear, i.e., each pair of\ndistinct clauses shares at most one variable.\n  Concerning 3-Sat we prove several hardness results for monotone formulas with\nrespect to a variety of restrictions imposed on the variable appearances.\nMonotone 3-Sat is the restriction of 3-Sat to monotone formulas, i.e. to\nformulas in which each clause contains only unnegated variables or only negated\nvariables, respectively. In particular, we show that, for any $k\\geq 5$,\nMonotone 3-Sat is NP-complete even if each variable appears exactly $k$ times\nunnegated and exactly once negated. In addition, we show that Monotone 3-Sat is\nNP-complete even if each variable appears exactly three times unnegated and\nthree times negated, respectively. In fact, we provide a complete analysis of\nMonotone 3-Sat with exactly six appearances per variable. Further, we prove\nthat the problem remains NP-complete when restricted to instances in which each\nvariable appears either exactly once unnegated and three times negated or the\nother way around. Thereby, we improve on a result by Darmann et al. [DDD18]\nshowing NP-completeness for four appearances per variable. Our stronger result\nalso implies that 3-Sat remains NP-complete even if each variable appears\nexactly three times unnegated and once negated, therewith complementing a\nresult by Berman et al. [BKS03].\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:31:05 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 17:25:57 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Darmann", "Andreas", ""], ["D\u00f6cker", "Janosch", ""]]}, {"id": "1908.04232", "submitter": "Stacey Jeffery", "authors": "Stacey Jeffery", "title": "Span Programs and Quantum Space Complexity", "comments": "Improved approximate monotone span program lower bound from\n  2^{log^{7/6} n} to 2^{log^2 n}", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While quantum computers hold the promise of significant computational\nspeedups, the limited size of early quantum machines motivates the study of\nspace-bounded quantum computation. We relate the quantum space complexity of\ncomputing a function f with one-sided error to the logarithm of its span\nprogram size, a classical quantity that is well-studied in attempts to prove\nformula size lower bounds.\n  In the more natural bounded error model, we show that the amount of space\nneeded for a unitary quantum algorithm to compute f with bounded (two-sided)\nerror is lower bounded by the logarithm of its approximate span program size.\nApproximate span programs were introduced in the field of quantum algorithms\nbut not studied classically. However, the approximate span program size of a\nfunction is a natural generalization of its span program size.\n  While no non-trivial lower bound is known on the span program size (or\napproximate span program size) of any concrete function, a number of lower\nbounds are known on the monotone span program size. We show that the\napproximate monotone span program size of f is a lower bound on the space\nneeded by quantum algorithms of a particular form, called monotone phase\nestimation algorithms, to compute f. We then give the first non-trivial lower\nbound on the approximate span program size of an explicit function.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 16:32:33 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 11:23:23 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Jeffery", "Stacey", ""]]}, {"id": "1908.04409", "submitter": "Hwee Kim", "authors": "Yo-Sub Han and Hwee Kim", "title": "Cyclic Oritatami Systems Cannot Fold Infinite Fractal Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RNA cotranscriptional folding is the phenomenon in which an RNA transcript\nfolds upon itself while being synthesized out of a gene. The oritatami system\n(OS) is a computation model of this phenomenon, which lets its sequence\n(transcript) of beads (abstract molecules) fold cotranscriptionally by the\ninteractions between beads according to the binding ruleset. The OS is an\nuseful computational model for predicting and simulating an RNA folding as well\nas constructing a biological structure. A fractal is an infinite pattern that\nis self-similar across different scales, and is an important structure in\nnature. Therefore, the fractal construction using self-assembly is one of the\nmost important problems. We focus on the problem of generating an infinite\nfractal instead of a partial finite fractal, which is much more challenging. We\nuse a cyclic OS, which has an infinite periodic transcript, to generate an\ninfinite structure. We prove a negative result that it is impossible to make a\nKoch curve or a Minkowski curve, both of which are fractals, using a cyclic OS.\nWe then establish sufficient conditions of infinite aperiodic curves that a\ncyclic OS cannot fold.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 14:47:02 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Han", "Yo-Sub", ""], ["Kim", "Hwee", ""]]}, {"id": "1908.04478", "submitter": "EPTCS", "authors": "Thomas Seiller (CNRS, France), Steffen Jost (LMU Munich, Germany)", "title": "Proceedings Third Joint Workshop on Developments in Implicit\n  Computational complExity and Foundational & Practical Aspects of Resource\n  Analysis", "comments": null, "journal-ref": "EPTCS 298, 2019", "doi": "10.4204/EPTCS.298", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These proceedings present the accepted regular papers and some selected\nextended abstracts from the 3rd joint DICE-FOPARA workshop, which was held in\nPrague, Czech Republic on April 6-7, 2019, as a part of ETAPS. The joint\nworkshop provides synergies by combining two complementary communities:\n  The 10th DICE workshop explores the area of Implicit Computational Complexity\n(ICC), which grew out from several proposals to use logic and formal methods to\nprovide languages for complexity-bounded computation (e.g. Ptime, Logspace\ncomputation). It aims at studying the computational complexity of programs\nwithout referring to external measuring conditions or a particular machine\nmodel, but only by considering language restrictions or logical/computational\nprinciples entailing complexity properties. Several approaches have been\nexplored for that purpose, such as restrictions on primitive recursion and\nramification, rewriting systems, linear logic, types and lambda calculus,\ninterpretations of functional and imperative programs.\n  The 6th FOPARA workshop serves as a forum for presenting original research\nresults that are relevant to the analysis of resource (e.g. time, space,\nenergy) consumption by computer programs. The workshop aims to bring together\nthe researchers that work on foundational issues with the researchers that\nfocus more on practical results. Therefore, both theoretical and practical\ncontributions are encouraged. We also encourage papers that combine theory and\npractice.\n  This third joint DICE-FOPARA workshop at ETAPS 2019 follows the successful\nexperiences of co-location of DICE-FOPARA at ETAPS 2015 in London and ETAPS\n2017 in Uppsala.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 04:09:00 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Seiller", "Thomas", "", "CNRS, France"], ["Jost", "Steffen", "", "LMU Munich, Germany"]]}, {"id": "1908.04921", "submitter": "EPTCS", "authors": "L\\^e Th\\`anh D\\~ung Nguyen (LIPN, Universit\\'e Paris 13)", "title": "On the Elementary Affine Lambda-Calculus with and Without Fixed Points", "comments": "In Proceedings DICE-FOPARA 2019, arXiv:1908.04478", "journal-ref": "EPTCS 298, 2019, pp. 15-29", "doi": "10.4204/EPTCS.298.2", "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The elementary affine lambda-calculus was introduced as a polyvalent setting\nfor implicit computational complexity, allowing for characterizations of\npolynomial time and hyperexponential time predicates. But these results rely on\ntype fixpoints (a.k.a. recursive types), and it was unknown whether this\nfeature of the type system was really necessary. We give a positive answer by\nshowing that without type fixpoints, we get a characterization of regular\nlanguages instead of polynomial time. The proof uses the semantic evaluation\nmethod. We also propose an aesthetic improvement on the characterization of the\nfunction classes FP and k-FEXPTIME in the presence of recursive types.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:57:27 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Nguyen", "L\u00ea Th\u00e0nh D\u0169ng", "", "LIPN, Universit\u00e9 Paris 13"]]}, {"id": "1908.04922", "submitter": "EPTCS", "authors": "Paulin Jacob\\'e de Naurois (CNRS/universit\\'e paris13)", "title": "Pointers in Recursion: Exploring the Tropics", "comments": "In Proceedings DICE-FOPARA 2019, arXiv:1908.04478", "journal-ref": "EPTCS 298, 2019, pp. 31-45", "doi": "10.4204/EPTCS.298.3", "report-no": null, "categories": "cs.CC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We translate the usual class of partial/primitive recursive functions to a\npointer recursion framework, accessing actual input values via a pointer\nreading unit-cost function. These pointer recursive functions classes are\nproven equivalent to the usual partial/primitive recursive functions.\nComplexity-wise, this framework captures in a streamlined way most of the\nrelevant sub-polynomial classes. Pointer recursion with the safe/normal tiering\ndiscipline of Bellantoni and Cook corresponds to polylogtime computation. We\nintroduce a new, non-size increasing tiering discipline, called tropical\ntiering. Tropical tiering and pointer recursion, used with some of the most\ncommon recursion schemes, capture the classes logspace, logspace/polylogtime,\nptime, and NC. Finally, in a fashion reminiscent of the safe recursive\nfunctions, tropical tiering is expressed directly in the syntax of the function\nalgebras, yielding the tropical recursive function algebras.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:57:44 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["de Naurois", "Paulin Jacob\u00e9", "", "CNRS/universit\u00e9 paris13"]]}, {"id": "1908.04923", "submitter": "EPTCS", "authors": "Bruce M. Kapron (University of Victoria), Florian Steinberg (INRIA\n  Saclay)", "title": "Type-two Iteration with Bounded Query Revision", "comments": "In Proceedings DICE-FOPARA 2019, arXiv:1908.04478", "journal-ref": "EPTCS 298, 2019, pp. 61-73", "doi": "10.4204/EPTCS.298.5", "report-no": null, "categories": "cs.CC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent results of Kapron and Steinberg (LICS 2018) we introduce\nnew forms of iteration on length in the setting of applied lambda-calculi for\nhigher-type poly-time computability. In particular, in a type-two setting, we\nconsider functionals which capture iteration on input length which bound\ninteraction with the type-one input parameter, by restricting to a constant\neither the number of times the function parameter may return a value of\nincreasing size, or the number of times the function parameter may be applied\nto an argument of increasing size. We prove that for any constant bound, the\niterators obtained are equivalent, with respect to lambda-definability over\ntype-one poly-time functions, to the recursor of Cook and Urquhart which\ncaptures Cobham's notion of limited recursion on notation in this setting.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:58:18 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Kapron", "Bruce M.", "", "University of Victoria"], ["Steinberg", "Florian", "", "INRIA\n  Saclay"]]}, {"id": "1908.05155", "submitter": "Kun Fang", "authors": "Kun Fang, Hamza Fawzi", "title": "The sum-of-squares hierarchy on the sphere, and applications in quantum\n  information theory", "comments": null, "journal-ref": "Mathematical Programming (2020)", "doi": "10.1007/s10107-020-01537-7", "report-no": null, "categories": "math.OC cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximizing a homogeneous polynomial on the unit\nsphere and its hierarchy of Sum-of-Squares (SOS) relaxations. Exploiting the\npolynomial kernel technique, we obtain a quadratic improvement of the known\nconvergence rate by Reznick and Doherty & Wehner. Specifically, we show that\nthe rate of convergence is no worse than $O(d^2/\\ell^2)$ in the regime $\\ell\n\\geq \\Omega(d)$ where $\\ell$ is the level of the hierarchy and $d$ the\ndimension, solving a problem left open in the recent paper by de Klerk &\nLaurent (arXiv:1904.08828). Importantly, our analysis also works for\nmatrix-valued polynomials on the sphere which has applications in quantum\ninformation for the Best Separable State problem. By exploiting the duality\nrelation between sums of squares and the DPS hierarchy in quantum information\ntheory, we show that our result generalizes to nonquadratic polynomials the\nconvergence rates of Navascu\\'es, Owari & Plenio.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:52:31 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Fang", "Kun", ""], ["Fawzi", "Hamza", ""]]}, {"id": "1908.05361", "submitter": "Janosch D\\\"ocker", "authors": "Janosch D\\\"ocker, Britta Dorn, Simone Linz, Charles Semple", "title": "Placing quantified variants of 3-SAT and Not-All-Equal 3-SAT in the\n  polynomial hierarchy", "comments": "36 pages; reference corrected in introduction (the result of\n  Karpinski and Piecuch establishes NP-completeness of Not-All-Equal 3-SAT if\n  each variable appears *at most* four times)", "journal-ref": "Theoretical Computer Science, 822:72-91, 2020", "doi": "10.1016/j.tcs.2020.04.003", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of variants of 3-SAT and Not-All-Equal 3-SAT is well studied.\nHowever, in contrast, very little is known about the complexity of the\nproblems' quantified counterparts. In the first part of this paper, we show\nthat $\\forall \\exists$ 3-SAT is $\\Pi_2^P$-complete even if (1) each variable\nappears exactly twice unnegated and exactly twice negated, (2) each clause is a\ndisjunction of exactly three distinct variables, and (3) the number of\nuniversal variables is equal to the number of existential variables.\nFurthermore, we show that the problem remains $\\Pi_2^P$-complete if (1a) each\nuniversal variable appears exactly once unnegated and exactly once negated,\n(1b) each existential variable appears exactly twice unnegated and exactly\ntwice negated, and (2) and (3) remain unchanged. On the other hand, the problem\nbecomes NP-complete for certain variants in which each universal variable\nappears exactly once. In the second part of the paper, we establish\n$\\Pi_2^P$-completeness for $\\forall \\exists$ Not-All-Equal 3-SAT even if (1')\nthe Boolean formula is linear and monotone, (2') each universal variable\nappears exactly once and each existential variable appears exactly three times,\nand (3') each clause is a disjunction of exactly three distinct variables that\ncontains at most one universal variable. On the positive side, we uncover\nvariants of $\\forall \\exists$ Not-All-Equal 3-SAT that are co-NP-complete or\nsolvable in polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 22:09:49 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 14:12:01 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["D\u00f6cker", "Janosch", ""], ["Dorn", "Britta", ""], ["Linz", "Simone", ""], ["Semple", "Charles", ""]]}, {"id": "1908.05943", "submitter": "Erich Novak", "authors": "Erich Novak", "title": "Algorithms and Complexity for Functions on General Domains", "comments": "minor revision; to appear in Journal of Complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error bounds and complexity bounds in numerical analysis and\ninformation-based complexity are often proved for functions that are defined on\nvery simple domains, such as a cube, a torus, or a sphere. We study optimal\nerror bounds for the approximation or integration of functions defined on $D_d\n\\subset R^d$ and only assume that $D_d$ is a bounded Lipschitz domain. Some\nresults are even more general. We study three different concepts to measure the\ncomplexity: order of convergence, asymptotic constant, and explicit uniform\nbounds, i.e., bounds that hold for all $n$ (number of pieces of information)\nand all (normalized) domains. It is known for many problems that the order of\nconvergence of optimal algorithms does not depend on the domain $D_d \\subset\nR^d$. We present examples for which the following statements are true:\n  1) Also the asymptotic constant does not depend on the shape of $D_d$ or the\nimposed boundary values, it only depends on the volume of the domain.\n  2) There are explicit and uniform lower (or upper, respectively) bounds for\nthe error that are only slightly smaller (or larger, respectively) than the\nasymptotic error bound.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 12:07:35 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 20:22:26 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Novak", "Erich", ""]]}, {"id": "1908.05966", "submitter": "Petter Restadh", "authors": "Per Alexandersson, Petter Restadh", "title": "LaserTank is NP-complete", "comments": "5 pages", "journal-ref": "Mathematical Aspects of Computer and Information Sciences (2020)", "doi": "10.1007/978-3-030-43120-4_26", "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the classical game LaserTank is $\\mathrm{NP}$-complete, even\nwhen the tank movement is restricted to a single column and the only blocks\nappearing on the board are mirrors and solid blocks. We show this by reducing\n$3$-SAT instances to LaserTank puzzles.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:31:59 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Alexandersson", "Per", ""], ["Restadh", "Petter", ""]]}, {"id": "1908.06130", "submitter": "Matthew Brennan", "authors": "Matthew Brennan, Guy Bresler", "title": "Average-Case Lower Bounds for Learning Sparse Mixtures, Robust\n  Estimation and Semirandom Adversaries", "comments": "Preliminary version (subsumed by expanded version at\n  arXiv:2005.08099), 65 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops several average-case reduction techniques to show new\nhardness results for three central high-dimensional statistics problems,\nimplying a statistical-computational gap induced by robustness, a\ndetection-recovery gap and a universality principle for these gaps. A main\nfeature of our approach is to map to these problems via a common intermediate\nproblem that we introduce, which we call Imbalanced Sparse Gaussian Mixtures.\nWe assume the planted clique conjecture for a version of the planted clique\nproblem where the position of the planted clique is mildly constrained, and\nfrom this obtain the following computational lower bounds: (1) a $k$-to-$k^2$\nstatistical-computational gap for robust sparse mean estimation, providing the\nfirst average-case evidence for a conjecture of Li (2017) and Balakrishnan et\nal. (2017); (2) a tight lower bound for semirandom planted dense subgraph,\nwhich shows that a semirandom adversary shifts the detection threshold in\nplanted dense subgraph to the conjectured recovery threshold; and (3) a\nuniversality principle for $k$-to-$k^2$ gaps in a broad class of sparse mixture\nproblems that includes many natural formulations such as the spiked covariance\nmodel.\n  Our main approach is to introduce several average-case techniques to produce\nstructured and Gaussianized versions of an input graph problem, and then to\nrotate these high-dimensional Gaussians by matrices carefully constructed from\nhyperplanes in $\\mathbb{F}_r^t$. For our universality result, we introduce a\nnew method to perform an algorithmic change of measure tailored to sparse\nmixtures. We also provide evidence that the mild promise in our variant of\nplanted clique does not change the complexity of the problem.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 22:14:09 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 01:20:43 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""]]}, {"id": "1908.06320", "submitter": "Giannis Nikolentzos", "authors": "Giannis Nikolentzos and Michalis Vazirgiannis", "title": "Revisiting the Graph Isomorphism Problem with Semidefinite Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the graph isomorphism problem can be posed as an\nequivalent problem of determining whether an auxiliary graph structure contains\na clique of specific order. However, the algorithms that have been developed so\nfar for this problem are either not efficient or not exact. In this paper, we\npresent a new algorithm which solves this equivalent formulation via\nsemidefinite programming. Specifically, we show that the problem of determining\nwhether the auxiliary graph contains a clique of specific order can be\nformulated as a semidefinite programming problem, and can thus be (almost\nexactly) solved in polynomial time. Furthermore, we show that we can determine\nif the graph contains such a clique by rounding the optimal solution to the\nnearest integer. Our algorithm provides a significant complexity result in\ngraph isomorphism testing, and also represents the first use of semidefinite\nprogramming for solving this problem.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 17:08:57 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 16:23:28 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Nikolentzos", "Giannis", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1908.06322", "submitter": "Yingfei Gu", "authors": "Yingfei Gu and Xiao-Liang Qi", "title": "Majorana fermions and the Sensitivity Conjecture", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cond-mat.str-el cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Hao Huang proved the Sensitivity Conjecture, an important result\nabout complexity measures of Boolean functions. We will discuss how this simple\nand elegant proof turns out to be closely related to physics concepts of the\nJordan-Wigner transformation and Majorana fermions. This note is not intended\nto contain original results. Instead, it is a translation of the math\nliterature in a language that is more familiar to physicists, which helps our\nunderstanding and hopefully may inspire future works along this direction.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 17:15:06 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Gu", "Yingfei", ""], ["Qi", "Xiao-Liang", ""]]}, {"id": "1908.06371", "submitter": "Shenghui Su", "authors": "Xuewei Niu, Shenghui Su, Jianghua Zheng, and Shuwang L\\\"u", "title": "A New Fast Computation of a Permanent", "comments": "Unsuitable", "journal-ref": null, "doi": "10.1088/1757-899X/790/1/012057", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a general algorithm called Store-zechin for quickly\ncomputing the permanent of an arbitrary square matrix. Its key idea is storage,\nmultiplexing, and recursion. That is, in a recursive process, some sub-terms\nwhich have already been calculated are no longer calculated, but are directly\nsubstituted with the previous calculation results. The new algorithm utilizes\nsufficiently computer memories and stored data to speed the computation of a\npermanent. The Analyses show that computating the permanent of an n * n matrix\nby Store-zechin requires (2^(n - 1)- 1)n multiplications and (2^(n-1))(n - 2)+\n1 additions while does (2^n - 1)n + 1 multiplications and (2^n - n)(n + 1)- 2\nadditions by the Ryser algorithm, and does (2^(n - 1))n + (n + 2)\nmultiplications and (2^(n - 1))(n + 1)+ (n^2 - n -1) additions by the R-N-W\nalgorithm. Therefore, Store-zechin is excellent more than the latter two\nalgorithms, and has a better application prospect.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 04:02:26 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 12:30:41 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Niu", "Xuewei", ""], ["Su", "Shenghui", ""], ["Zheng", "Jianghua", ""], ["L\u00fc", "Shuwang", ""]]}, {"id": "1908.06664", "submitter": "Joergen Bang-Jensen", "authors": "Yandong Bai, J{\\o}rgen Bang-Jensen, Shinya Fujita, Anders Yeo", "title": "Safe sets in digraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A non-empty subset $S$ of the vertices of a digraph $D$ is called a {\\it safe\nset} if \\begin{itemize}\n  \\item[(i)] for every strongly connected component $M$ of $D-S$, there exists\na strongly connected component $N$ of $D[S]$ such that there exists an arc from\n$M$ to $N$; and \\item[(ii)] for every strongly connected component $M$ of $D-S$\nand every strongly connected component $N$ of $D[S]$, we have $|M|\\leq |N|$\nwhenever there exists an arc from $M$ to $N$. \\end{itemize} In the case of\nacyclic digraphs a set $X$ of vertices is a safe set precisely when $X$ is an\n{\\it in-dominating set}, that is, every vertex not in $X$ has at least one arc\nto $X$. We prove that, even for acyclic digraphs which are traceable (have a\nhamiltonian path) it is NP-hard to find a minimum cardinality in-dominating\nset. Then we show that the problem is also NP-hard for tournaments and give,\nfor every positive constant $c$, a polynomial algorithm for finding a minimum\ncardinality safe set in a tournament on $n$ vertices in which no strong\ncomponent has size more than $c\\log{}(n)$. Under the so called Exponential Time\nHypothesis (ETH) this is close to best possible in the following sense: If ETH\nholds, then, for every $\\epsilon>0$ there is no polynomial time algorithm for\nfinding a minimum cardinality safe set for the class of tournaments in which\nthe largest strong component has size at most $\\log^{1+\\epsilon}(n)$.\n  We also discuss bounds on the cardinality of safe sets in tournaments.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:33:26 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Bai", "Yandong", ""], ["Bang-Jensen", "J\u00f8rgen", ""], ["Fujita", "Shinya", ""], ["Yeo", "Anders", ""]]}, {"id": "1908.06751", "submitter": "Guillaume Theyssier", "authors": "Nicolas Ollinger (LIFO), Guillaume Theyssier (I2M)", "title": "Freezing, Bounded-Change and Convergent Cellular Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies three classes of cellular automata from a computational\npoint of view: freezing cellular automata where the state of a cell can only\ndecrease according to some order on states, cellular automata where each cell\nonly makes a bounded number of state changes in any orbit, and finally cellular\nautomata where each orbit converges to some fixed point. Many examples studied\nin the literature fit into these definitions, in particular the works on\ncristal growth started by S. Ulam in the 60s. The central question addressed\nhere is how the computational power and computational hardness of basic\nproperties is affected by the constraints of convergence, bounded number of\nchange, or local decreasing of states in each cell. By studying various\nbenchmark problems (short-term prediction, long term reachability, limits) and\nconsidering various complexity measures and scales (LOGSPACE vs. PTIME,\ncommunication complexity, Turing computability and arithmetical hierarchy) we\ngive a rich and nuanced answer: the overall computational complexity of such\ncellular automata depends on the class considered (among the three above), the\ndimension, and the precise problem studied. In particular, we show that all\nsettings can achieve universality in the sense of Blondel-Delvenne-K\\r{u}rka,\nalthough short term predictability varies from NLOGSPACE to P-complete.\nBesides, the computability of limit configurations starting from computable\ninitial configurations separates bounded-change from convergent cellular\nautomata in dimension 1, but also dimension 1 versus higher dimensions for\nfreezing cellular automata. Another surprising dimension-sensitive result\nobtained is that nilpotency becomes decidable in dimension 1 for all the three\nclasses, while it stays undecidable even for freezing cellular automata in\nhigher dimension.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 12:39:10 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 09:05:12 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 07:55:33 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Ollinger", "Nicolas", "", "LIFO"], ["Theyssier", "Guillaume", "", "I2M"]]}, {"id": "1908.06964", "submitter": "Dhananjay Phatak", "authors": "Dhananjay Phatak, Alan T. Sherman, Steven D. Houston, Andrew Henry", "title": "PPT: New Low Complexity Deterministic Primality Tests Leveraging\n  Explicit and Implicit Non-Residues. A Set of Three Companion Manuscripts", "comments": "a set of 3 companion articles.217 (two hundred and seventeen) pages\n  including everything = table of contents, list of figures, list of tables and\n  an acknowledgment at the end. There is no watermark or highlighted text. Only\n  color is in hyper-links and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DS cs.SC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this set of three companion manuscripts/articles, we unveil our new\nresults on primality testing and reveal new primality testing algorithms\nenabled by those results. The results have been classified (and referred to) as\nlemmas/corollaries/claims whenever we have complete analytic proof(s);\notherwise the results are introduced as conjectures.\n  In Part/Article 1, we start with the Baseline Primality Conjecture~(PBPC)\nwhich enables deterministic primality detection with a low complexity = O((log\nN)^2) ; when an explicit value of a Quadratic Non Residue (QNR) modulo-N is\navailable (which happens to be the case for an overwhelming majority = 11/12 =\n91.67% of all odd integers). We then demonstrate Primality Lemma PL-1, which\nreveals close connections between the state-of-the-art Miller-Rabin method and\nthe renowned Euler-Criterion. This Lemma, together with the Baseline Primality\nConjecture enables a synergistic fusion of Miller-Rabin iterations and our\nmethod(s), resulting in hybrid algorithms that are substantially better than\ntheir components. Next, we illustrate how the requirement of an explicit value\nof a QNR can be circumvented by using relations of the form: Polynomial(x) mod\nN = 0 ; whose solutions implicitly specify Non Residues modulo-N. We then\ndevelop a method to derive low-degree canonical polynomials that together\nguarantee implicit Non Residues modulo-N ; which along with the Generalized\nPrimality Conjectures enable algorithms that achieve a worst case deterministic\npolynomial complexity = O( (log N)^3 polylog(log N)) ; unconditionally ; for\nany/all values of N.\n  In Part/Article 2 , we present substantial experimental data that corroborate\nall the conjectures. No counter example has been found.\n  Finally in Part/Article 3, we present analytic proof(s) of the Baseline\nPrimality Conjecture that we have been able to complete for some special cases.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 16:48:15 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Phatak", "Dhananjay", ""], ["Sherman", "Alan T.", ""], ["Houston", "Steven D.", ""], ["Henry", "Andrew", ""]]}, {"id": "1908.07215", "submitter": "Utkarsh Tripathi", "authors": "Srikanth Srinivasan, Utkarsh Tripathi, S. Venkitesh", "title": "Decoding Downset codes over a finite grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, Kim and Kopparty (Theory of Computing, 2017) gave a\ndeterministic algorithm for the unique decoding problem for polynomials of\nbounded total degree over a general grid. We show that their algorithm can be\nadapted to solve the unique decoding problem for the general family of Downset\ncodes. Here, a downset code is specified by a family D of monomials closed\nunder taking factors: the corresponding code is the space of evaluations of all\npolynomials that can be written as linear combinations of monomials from D.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 08:25:14 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Srinivasan", "Srikanth", ""], ["Tripathi", "Utkarsh", ""], ["Venkitesh", "S.", ""]]}, {"id": "1908.07239", "submitter": "Tony Tan", "authors": "Yanger Ma, Tony Tan", "title": "A simple combinatorial proof for small model property of two-variable\n  logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present another proof for the well-known {\\em small model property} of\ntwo-variable logic. As far as we know, existing proofs of this property rely\nheavily on model theoretic concepts. In contrast, ours is purely combinatorial\nand uses only a very simple counting argument, which we find rather intuitive\nand elegant.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 09:31:55 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 03:42:52 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ma", "Yanger", ""], ["Tan", "Tony", ""]]}, {"id": "1908.07282", "submitter": "Alain Finkel", "authors": "Alain Finkel, M. Praveen", "title": "Verification of Flat FIFO Systems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 4 (October\n  14, 2020) lmcs:6839", "doi": "10.23638/LMCS-16(4:4)2020", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The decidability and complexity of reachability problems and model-checking\nfor flat counter machines have been explored in detail. However, only few\nresults are known for flat (lossy) FIFO machines, only in some particular cases\n(a single loop or a single bounded expression). We prove, by establishing\nreductions between properties, and by reducing SAT to a subset of these\nproperties that many verification problems like reachability, non-termination,\nunboundedness are NP-complete for flat FIFO machines, generalizing similar\nexisting results for flat counter machines. We also show that reachability is\nNP-complete for flat lossy FIFO machines and for flat front-lossy FIFO\nmachines. We construct a trace-flattable system of many counter machines\ncommunicating via rendez-vous that is bisimilar to a given flat FIFO machine,\nwhich allows to model-check the original flat FIFO machine. Our results lay the\ntheoretical foundations and open the way to build a verification tool for\n(general) FIFO machines based on analysis of flat sub-machines.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 11:44:36 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 06:03:21 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 18:09:28 GMT"}, {"version": "v4", "created": "Sun, 23 Aug 2020 13:54:03 GMT"}, {"version": "v5", "created": "Mon, 12 Oct 2020 13:04:52 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Finkel", "Alain", ""], ["Praveen", "M.", ""]]}, {"id": "1908.07447", "submitter": "Fatemeh Keshavarz-Kohjerdi", "authors": "Ruo-Wei Hung and Fatemeh Keshavarz-Kohjerdi", "title": "Finding Hamiltonian and Longest (s, t)-paths of C-shaped Supergrid\n  Graphs in Linear Time", "comments": "24 pages and 29 figures. arXiv admin note: substantial text overlap\n  with arXiv:1904.02581", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A supergrid graph is a finite vertex-induced subgraph of the infinite graph\nwhose vertex set consists of all points of the plane with integer coordinates\nand in which two vertices are adjacent if the difference of their x or y\ncoordinates is not larger than 1. The Hamiltonian path (cycle) problem is to\ndetermine whether a graph contains a simple path (cycle) in which each vertex\nof the graph appears exactly once. This problem is NP-complete for general\ngraphs and it is also NP-complete for general supergrid graphs. Despite the\nmany applications of the problem, it is still open for many classes, including\nsolid supergrid graphs and supergrid graphs with some holes. A graph is called\nHamiltonian connected if it contains a Hamiltonian path between any two\ndistinct vertices. In this paper, first we will study the Hamiltonian cycle\nproperty of C-shaped supergrid graphs, which are a special case of rectangular\nsupergrid graphs with a rectangular hole. Next, we will show that C-shaped\nsupergrid graphs are Hamiltonian connected except few conditions. Finally, we\nwill compute a longest path between two distinct vertices in these graphs. The\nHamiltonian connectivity of C-shaped supergrid graphs can be applied to compute\nthe optimal stitching trace of computer embroidery machines, and construct the\nminimum printing trace of 3D printers with a C-like component being printed.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 11:41:39 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Hung", "Ruo-Wei", ""], ["Keshavarz-Kohjerdi", "Fatemeh", ""]]}, {"id": "1908.08347", "submitter": "Abhranil Chatterjee", "authors": "V. Arvind, Abhranil Chatterjee, Rajit Datta and Partha Mukhopadhyay", "title": "On Explicit Branching Programs for the Rectangular Determinant and\n  Permanent Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the arithmetic circuit complexity of some well-known family of\npolynomials through the lens of parameterized complexity. Our main focus is on\nthe construction of explicit algebraic branching programs (ABP) for determinant\nand permanent polynomials of the \\emph{rectangular} symbolic matrix in both\ncommutative and noncommutative settings. The main results are:\n  1. We show an explicit $O^{*}({n\\choose {\\downarrow k/2}})$-size ABP\nconstruction for noncommutative permanent polynomial of $k\\times n$ symbolic\nmatrix. We obtain this via an explicit ABP construction of size\n$O^{*}({n\\choose {\\downarrow k/2}})$ for $S_{n,k}^*$, noncommutative\nsymmetrized version of the elementary symmetric polynomial $S_{n,k}$.\n  2. We obtain an explicit $O^{*}(2^k)$-size ABP construction for the\ncommutative rectangular determinant polynomial of the $k\\times n$ symbolic\nmatrix.\n  3. In contrast, we show that evaluating the rectangular noncommutative\ndeterminant over rational matrices is $W[1]$-hard.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:01:28 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Arvind", "V.", ""], ["Chatterjee", "Abhranil", ""], ["Datta", "Rajit", ""], ["Mukhopadhyay", "Partha", ""]]}, {"id": "1908.08483", "submitter": "Ryan Alweiss", "authors": "Ryan Alweiss, Shachar Lovett, Kewen Wu, Jiapeng Zhang", "title": "Improved bounds for the sunflower lemma", "comments": "Revised preprint, added sections on applications and rainbow\n  sunflowers", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sunflower with $r$ petals is a collection of $r$ sets so that the\nintersection of each pair is equal to the intersection of all. Erd\\H{o}s and\nRado proved the sunflower lemma: for any fixed $r$, any family of sets of size\n$w$, with at least about $w^w$ sets, must contain a sunflower. The famous\nsunflower conjecture is that the bound on the number of sets can be improved to\n$c^w$ for some constant $c$. In this paper, we improve the bound to about\n$(\\log w)^w$. In fact, we prove the result for a robust notion of sunflowers,\nfor which the bound we obtain is tight up to lower order terms.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 16:33:22 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 18:22:14 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Alweiss", "Ryan", ""], ["Lovett", "Shachar", ""], ["Wu", "Kewen", ""], ["Zhang", "Jiapeng", ""]]}, {"id": "1908.08881", "submitter": "Lorenzo Najt", "authors": "Lorenzo Najt, Daryl DeFord, Justin Solomon", "title": "Complexity and Geometry of Sampling Connected Graph Partitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CY cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove intractability results about sampling from the set of\npartitions of a planar graph into connected components. Our proofs are\nmotivated by a technique introduced by Jerrum, Valiant, and Vazirani. Moreover,\nwe use gadgets inspired by their technique to provide families of graphs where\nthe \"flip walk\" Markov chain used in practice for this sampling task exhibits\nexponentially slow mixing. Supporting our theoretical results we present some\nempirical evidence demonstrating the slow mixing of the flip walk on grid\ngraphs and on real data. Inspired by connections to the statistical physics of\nself-avoiding walks, we investigate the sensitivity of certain popular sampling\nalgorithms to the graph topology. Finally, we discuss a few cases where the\nsampling problem is tractable. Applications to political redistricting have\nrecently brought increased attention to this problem, and we articulate open\nquestions about this application that are highlighted by our results.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 15:52:19 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Najt", "Lorenzo", ""], ["DeFord", "Daryl", ""], ["Solomon", "Justin", ""]]}, {"id": "1908.09278", "submitter": "Shmuel Onn", "authors": "Gabriel Deza, Shmuel Onn", "title": "Optimization over Degree Sequences of Graphs", "comments": null, "journal-ref": "Discrete Applied Mathematics, 296:2--8, 2021", "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding a subgraph of a given graph minimizing the\nsum of given functions at vertices evaluated at their subgraph degrees. While\nthe problem is NP-hard already for bipartite graphs when the functions are\nconvex on one side and concave on the other, we show that when all functions\nare convex, the problem can be solved in polynomial time for any graph. We also\nprovide polynomial time solutions for bipartite graphs with one side fixed for\narbitrary functions, and for arbitrary graphs when all but a fixed number of\nfunctions are either nondecreasing or nonincreasing. We note that the general\nfactor problem and the (l,u)-factor problem over a graph are special cases of\nour problem, as well as the intriguing exact matching problem. The complexity\nof the problem remains widely open, particularly for arbitrary functions over\ncomplete graphs.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 08:36:51 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Deza", "Gabriel", ""], ["Onn", "Shmuel", ""]]}, {"id": "1908.09325", "submitter": "Yoichi Iwata", "authors": "\\'Edouard Bonnet, Yoichi Iwata, Bart M. P. Jansen, {\\L}ukasz Kowalik", "title": "Fine-Grained Complexity of k-OPT in Bounded-Degree Graphs for Solving\n  TSP", "comments": "A new running time bound for counting cycles and paths in graphs was\n  added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local search is a widely-employed strategy for finding good solutions to\nTraveling Salesman Problem. We analyze the problem of determining whether the\nweight of a given cycle can be decreased by a popular $k$-opt move. Earlier\nwork has shown that (i) assuming the Exponential Time Hypothesis, there is no\nalgorithm to find an improving $k$-opt move in time $f(k)n^{o(k/\\log k)}$ for\nany function $f$, while (ii) it is possible to improve on the brute-force\nrunning time of $O(n^k)$ and save linear factors in the exponent. Modern TSP\nheuristics show that very good global solutions can already be reached using\nonly the top-$O(1)$ most promising edges incident to each vertex. Motivated by\nthis, we study the problem of finding an improving $k$-move in bounded degree\ngraphs, presenting new algorithms and conditional lower bounds. We show that\nthe aforementioned ETH lower bound also holds for graphs of maximum degree\nthree, but that in bounded-degree graphs the best improving $k$-move can be\nfound in time $O(n^{23k/135+o(k)})$. This improves upon the best-known bounds\nfor general graphs. Due to its practical importance, we devote special\nattention to the range of $k$ in which improving $k$-moves in bounded-degree\ngraphs can be found in quasi-linear time. For $k\\le 7$, we give quasi-linear\ntime algorithms for general weights. For $k=8$ we obtain a quasi-linear time\nalgorithm for polylogarithmic weights. On the other hand, based on established\nfine-grained complexity hypotheses, we prove that the $k=9$ case does not admit\nquasi-linear time algorithms. Hence we fully characterize the values of $k$ for\nwhich quasi-linear time algorithms exist for polylogarithmic weights on\nbounded-degree graphs. As a byproduct, we show a new bound on pathwidth of even\ngraphs which results in improved running time bounds for counting $k$-vertex\npaths and cycles.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 13:28:53 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 07:01:59 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Iwata", "Yoichi", ""], ["Jansen", "Bart M. P.", ""], ["Kowalik", "\u0141ukasz", ""]]}, {"id": "1908.09606", "submitter": "Grzegorz Kwasniewski", "authors": "Grzegorz Kwasniewski (1), Marko Kabi\\'c (2,3), Maciej Besta (1), Joost\n  VandeVondele (2,3), Raffaele Solc\\`a (2,3), Torsten Hoefler (1) ((1)\n  Department of Computer Science, ETH Zurich, (2) ETH Zurich, (3) Swiss\n  National Supercomputing Centre (CSCS))", "title": "Red-blue pebbling revisited: near optimal parallel matrix-matrix\n  multiplication", "comments": "18 pages, 29 figures, short version submitted to the SC'19 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose COSMA: a parallel matrix-matrix multiplication algorithm that is\nnear communication-optimal for all combinations of matrix dimensions, processor\ncounts, and memory sizes. The key idea behind COSMA is to derive an optimal (up\nto a factor of 0.03\\% for 10MB of fast memory) sequential schedule and then\nparallelize it, preserving I/O optimality. To achieve this, we use the red-blue\npebble game to precisely model MMM dependencies and derive a constructive and\ntight sequential and parallel I/O lower bound proofs. Compared to 2D or 3D\nalgorithms, which fix processor decomposition upfront and then map it to the\nmatrix dimensions, it reduces communication volume by up to $\\sqrt{3}$ times.\nCOSMA outperforms the established ScaLAPACK, CARMA, and CTF algorithms in all\nscenarios up to 12.8x (2.2x on average), achieving up to 88\\% of Piz Daint's\npeak performance. Our work does not require any hand tuning and is maintained\nas an open source implementation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 11:40:17 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 00:24:39 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 15:36:04 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Kwasniewski", "Grzegorz", ""], ["Kabi\u0107", "Marko", ""], ["Besta", "Maciej", ""], ["VandeVondele", "Joost", ""], ["Solc\u00e0", "Raffaele", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1908.09648", "submitter": "Nicolas Dupin", "authors": "Nicolas Dupin, Frank Nielsen, El-Ghazali Talbi", "title": "Planar p-center problems are solvable in polynomial time when clustering\n  a Pareto Front", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is motivated by real-life applications of bi-objective\noptimization. Having many non dominated solutions, one wishes to cluster the\nPareto front using Euclidian distances. The p-center problems, both in the\ndiscrete and continuous versions, are proven solvable in polynomial time with a\ncommon dynamic programming algorithm. Having $N$ points to partition in\n$K\\geqslant 3$ clusters, the complexity is proven in $O(KN\\log N)$ (resp\n$O(KN\\log^2 N)$) time and $O(KN)$ memory space for the continuous (resp\ndiscrete) $K$-center problem. $2$-center problems have complexities in $O(N\\log\nN)$. To speed-up the algorithm, parallelization issues are discussed. A\nposteriori, these results allow an application inside multi-objective\nheuristics to archive partial Pareto Fronts.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 22:24:07 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Dupin", "Nicolas", ""], ["Nielsen", "Frank", ""], ["Talbi", "El-Ghazali", ""]]}, {"id": "1908.09942", "submitter": "Adrian De Wynter", "authors": "Adrian de Wynter", "title": "On the Bounds of Function Approximations", "comments": "Accepted as a full paper at ICANN 2019. The final, authenticated\n  publication will be available at https://doi.org/10.1007/978-3-030-30487-4_32", "journal-ref": "In: Tetko, I. V. et al. (eds.) ICANN 2019. LNCS, vol 11727.\n  Springer, Heidelberg, pp. 401-417", "doi": "10.1007/978-3-030-30487-4_32", "report-no": null, "categories": "cs.LG cs.CC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within machine learning, the subfield of Neural Architecture Search (NAS) has\nrecently garnered research attention due to its ability to improve upon\nhuman-designed models. However, the computational requirements for finding an\nexact solution to this problem are often intractable, and the design of the\nsearch space still requires manual intervention. In this paper we attempt to\nestablish a formalized framework from which we can better understand the\ncomputational bounds of NAS in relation to its search space. For this, we first\nreformulate the function approximation problem in terms of sequences of\nfunctions, and we call it the Function Approximation (FA) problem; then we show\nthat it is computationally infeasible to devise a procedure that solves FA for\nall functions to zero error, regardless of the search space. We show also that\nsuch error will be minimal if a specific class of functions is present in the\nsearch space. Subsequently, we show that machine learning as a mathematical\nproblem is a solution strategy for FA, albeit not an effective one, and further\ndescribe a stronger version of this approach: the Approximate Architectural\nSearch Problem (a-ASP), which is the mathematical equivalent of NAS. We\nleverage the framework from this paper and results from the literature to\ndescribe the conditions under which a-ASP can potentially solve FA as well as\nan exhaustive search, but in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:32:33 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["de Wynter", "Adrian", ""]]}, {"id": "1908.09959", "submitter": "Aukosh Jagannath", "authors": "David Gamarnik, Aukosh Jagannath, Subhabrata Sen", "title": "The Overlap Gap Property in Principal Submatrix Recovery", "comments": "42 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study support recovery for a $k \\times k$ principal submatrix with\nelevated mean $\\lambda/N$, hidden in an $N\\times N$ symmetric mean zero\nGaussian matrix. Here $\\lambda>0$ is a universal constant, and we assume $k = N\n\\rho$ for some constant $\\rho \\in (0,1)$. We establish that {there exists a\nconstant $C>0$ such that} the MLE recovers a constant proportion of the hidden\nsubmatrix if $\\lambda {\\geq C} \\sqrt{\\frac{1}{\\rho} \\log \\frac{1}{\\rho}}$,\n{while such recovery is information theoretically impossible if $\\lambda = o(\n\\sqrt{\\frac{1}{\\rho} \\log \\frac{1}{\\rho}} )$}. The MLE is computationally\nintractable in general, and in fact, for $\\rho>0$ sufficiently small, this\nproblem is conjectured to exhibit a \\emph{statistical-computational gap}. To\nprovide rigorous evidence for this, we study the likelihood landscape for this\nproblem, and establish that for some $\\varepsilon>0$ and $\\sqrt{\\frac{1}{\\rho}\n\\log \\frac{1}{\\rho} } \\ll \\lambda \\ll \\frac{1}{\\rho^{1/2 + \\varepsilon}}$, the\nproblem exhibits a variant of the \\emph{Overlap-Gap-Property (OGP)}. As a\ndirect consequence, we establish that a family of local MCMC based algorithms\ndo not achieve optimal recovery. Finally, we establish that for $\\lambda >\n1/\\rho$, a simple spectral method recovers a constant proportion of the hidden\nsubmatrix.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 23:46:07 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 03:09:41 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Gamarnik", "David", ""], ["Jagannath", "Aukosh", ""], ["Sen", "Subhabrata", ""]]}, {"id": "1908.10248", "submitter": "Karthik C. S.", "authors": "Elazar Goldenberg and Karthik C. S.", "title": "Hardness Amplification of Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove a general hardness amplification scheme for\noptimization problems based on the technique of direct products. We say that an\noptimization problem $\\Pi$ is direct product feasible if it is possible to\nefficiently aggregate any $k$ instances of $\\Pi$ and form one large instance of\n$\\Pi$ such that given an optimal feasible solution to the larger instance, we\ncan efficiently find optimal feasible solutions to all the $k$ smaller\ninstances. Given a direct product feasible optimization problem $\\Pi$, our\nhardness amplification theorem may be informally stated as follows: If there is\na distribution $\\mathcal{D}$ over instances of $\\Pi$ of size $n$ such that\nevery randomized algorithm running in time $t(n)$ fails to solve $\\Pi$ on\n$\\frac{1}{\\alpha(n)}$ fraction of inputs sampled from $\\mathcal{D}$, then,\nassuming some relationships on $\\alpha(n)$ and $t(n)$, there is a distribution\n$\\mathcal{D}'$ over instances of $\\Pi$ of size $O(n\\cdot \\alpha(n))$ such that\nevery randomized algorithm running in time $\\frac{t(n)}{poly(\\alpha(n))}$ fails\nto solve $\\Pi$ on $\\frac{99}{100}$ fraction of inputs sampled from\n$\\mathcal{D}'$. As a consequence of the above theorem, we show hardness\namplification of problems in various classes such as NP-hard problems like\nMax-Clique, Knapsack, and Max-SAT, problems in P such as Longest Common\nSubsequence, Edit Distance, Matrix Multiplication, and even problems in TFNP\nsuch as Factoring and computing Nash equilibrium.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:56:12 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Goldenberg", "Elazar", ""], ["S.", "Karthik C.", ""]]}, {"id": "1908.10805", "submitter": "Paul Vitanyi", "authors": "Paul MB Vitanyi", "title": "Logical depth for reversible Turing machines with an application to the\n  rate of decrease in logical depth for general Turing machines", "comments": "Latex 4 pages", "journal-ref": "Theor. Comput. Sci., 778(2019), 78-80", "doi": "10.1016/j.tcs.2019.01.031", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logical depth of a {\\em reversible} Turing machine equals the shortest\nrunning time of a shortest program for it. This is applied to show that the\nresult in L.F. Antunes, A. Souto, and P.M.B. Vit\\'anyi, On the Rate of Decrease\nin Logical Depth, Theor. Comput. Sci., 702(2017), 60--64 is valid\nnotwithstanding the error noted in Corrigendum P.M.B. Vit\\'anyi, Corrigendum to\n\"On the rate of decrease in logical depth\" by L.F. Antunes, A. Souto, and\nP.M.B. Vit\\'anyi [Theoret. Comput. Sci. 702 (2017) 60--64], {\\em Theoret.\nComput. Sci.}, https://doi.org/10.1016/j.tcs.2018.07.009 . /\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 16:14:04 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Vitanyi", "Paul MB", ""]]}, {"id": "1908.10844", "submitter": "Franklin Marquezino", "authors": "Alexandre Abreu, Lu\\'is Cunha, Celina de Figueiredo, Luis Kowada,\n  Franklin Marquezino, Renato Portugal, Daniel Posner", "title": "The Tessellation Cover Number of Good Tessellable Graphs", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tessellation of a graph is a partition of its vertices into vertex disjoint\ncliques. A tessellation cover of a graph is a set of tessellations that covers\nall of its edges, and the tessellation cover number, denoted by $T(G)$, is the\nsize of a smallest tessellation cover. The \\textsc{$t$-tessellability} problem\naims to decide whether a graph $G$ has $T(G)\\leq t$ and is\n$\\mathcal{NP}$-complete for $t\\geq 3$. Since the number of edges of a maximum\ninduced star of $G$, denoted by $is(G)$, is a lower bound on $T(G)$, we define\ngood tessellable graphs as the graphs~$G$ such that $T(G)=is(G)$. The\n\\textsc{good tessellable recognition (gtr)} problem aims to decide whether $G$\nis a good tessellable graph. We show that \\textsc{gtr} is\n$\\mathcal{NP}$-complete not only if $T(G)$ is known or $is(G)$ is fixed, but\nalso when the gap between $T(G)$ and $is(G)$ is large. As a byproduct, we\nobtain graph classes that obey the corresponding computational complexity\nbehaviors.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:30:29 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Abreu", "Alexandre", ""], ["Cunha", "Lu\u00eds", ""], ["de Figueiredo", "Celina", ""], ["Kowada", "Luis", ""], ["Marquezino", "Franklin", ""], ["Portugal", "Renato", ""], ["Posner", "Daniel", ""]]}, {"id": "1908.11518", "submitter": "Yangyang Xu", "authors": "Qihang Lin, Runchao Ma, Yangyang Xu", "title": "Inexact Proximal-Point Penalty Methods for Constrained Non-Convex\n  Optimization", "comments": "submitted to journal; corrected a few ? in references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an inexact proximal-point penalty method is studied for\nconstrained optimization problems, where the objective function is non-convex,\nand the constraint functions can also be non-convex. The proposed method\napproximately solves a sequence of subproblems, each of which is formed by\nadding to the original objective function a proximal term and quadratic penalty\nterms associated to the constraint functions. Under a weak-convexity\nassumption, each subproblem is made strongly convex and can be solved\neffectively to a required accuracy by an optimal gradient-based method. The\ncomputational complexity of the proposed method is analyzed separately for the\ncases of convex constraint and non-convex constraint. For both cases, the\ncomplexity results are established in terms of the number of proximal gradient\nsteps needed to find an $\\varepsilon$-stationary point. When the constraint\nfunctions are convex, we show a complexity result of $\\tilde\nO(\\varepsilon^{-5/2})$ to produce an $\\varepsilon$-stationary point under the\nSlater's condition. When the constraint functions are non-convex, the\ncomplexity becomes $\\tilde O(\\varepsilon^{-3})$ if a non-singularity condition\nholds on constraints and otherwise $\\tilde O(\\varepsilon^{-4})$ if a feasible\ninitial solution is available.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 03:33:53 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 15:24:30 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 03:49:43 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 14:23:29 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Lin", "Qihang", ""], ["Ma", "Runchao", ""], ["Xu", "Yangyang", ""]]}, {"id": "1908.11554", "submitter": "Yasuhide Maei", "authors": "Tesshu Hanaka, Hironori Kiya, Yasuhide Maei, Hirotaka Ono", "title": "Computational Complexity of Hedonic Games on Sparse Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The additively separable hedonic game (ASHG) is a model of coalition\nformation games on graphs. In this paper, we intensively and extensively\ninvestigate the computational complexity of finding several desirable\nsolutions, such as a Nash stable solution, a maximum utilitarian solution, and\na maximum egalitarian solution in ASHGs on sparse graphs including\nbounded-degree graphs, bounded-treewidth graphs, and near-planar graphs. For\nexample, we show that finding a maximum egalitarian solution is weakly NP-hard\neven on graphs of treewidth 2, whereas it can be solvable in polynomial time on\ntrees. Moreover, we give a pseudo fixed parameter algorithm when parameterized\nby treewidth.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 06:26:11 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 12:22:00 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Hanaka", "Tesshu", ""], ["Kiya", "Hironori", ""], ["Maei", "Yasuhide", ""], ["Ono", "Hirotaka", ""]]}, {"id": "1908.11819", "submitter": "Adam Polak", "authors": "Lech Duraj, Krzysztof Kleiner, Adam Polak, Virginia Vassilevska\n  Williams", "title": "Equivalences between triangle and range query problems", "comments": null, "journal-ref": null, "doi": "10.1137/1.9781611975994.3", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a natural class of range query problems, and prove that all\nproblems within this class have the same time complexity (up to polylogarithmic\nfactors). The equivalence is very general, and even applies to online\nalgorithms. This allows us to obtain new improved algorithms for all of the\nproblems in the class.\n  We then focus on the special case of the problems when the queries are\noffline and the number of queries is linear. We show that our range query\nproblems are runtime-equivalent (up to polylogarithmic factors) to counting for\neach edge $e$ in an $m$-edge graph the number of triangles through $e$. This\nnatural triangle problem can be solved using the best known triangle counting\nalgorithm, running in $O(m^{2\\omega/(\\omega+1)}) \\leq O(m^{1.41})$ time.\nMoreover, if $\\omega=2$, the $O(m^{2\\omega/(\\omega+1)})$ running time is known\nto be tight (within $m^{o(1)}$ factors) under the 3SUM Hypothesis. In this\ncase, our equivalence settles the complexity of the range query problems. Our\nproblems constitute the first equivalence class with this peculiar running time\nbound.\n  To better understand the complexity of these problems, we also provide a\ndeeper insight into the family of triangle problems, in particular showing\nblack-box reductions between triangle listing and per-edge triangle detection\nand counting. As a byproduct of our reductions, we obtain a simple triangle\nlisting algorithm matching the state-of-the-art for all regimes of the number\nof triangles. We also give some not necessarily tight, but still surprising\nreductions from variants of matrix products, such as the $(\\min,\\max)$-product.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 16:17:45 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 20:11:11 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Duraj", "Lech", ""], ["Kleiner", "Krzysztof", ""], ["Polak", "Adam", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1908.11825", "submitter": "Dawei Huang", "authors": "Dawei Huang, Seth Pettie, Yixiang Zhang, Zhijun Zhang", "title": "The Communication Complexity of Set Intersection and Multiple Equality\n  Testing", "comments": "44 pages", "journal-ref": "Proceedings of the 2020 ACM-SIAM Symposium on Discrete Algorithms.\n  2020, 1715-1732", "doi": "10.1137/1.9781611975994.105", "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore fundamental problems in randomized communication\ncomplexity such as computing Set Intersection on sets of size $k$ and Equality\nTesting between vectors of length $k$. Sa\\u{g}lam and Tardos and Brody et al.\nshowed that for these types of problems, one can achieve optimal communication\nvolume of $O(k)$ bits, with a randomized protocol that takes $O(\\log^* k)$\nrounds. Aside from rounds and communication volume, there is a \\emph{third}\nparameter of interest, namely the \\emph{error probability} $p_{\\mathrm{err}}$.\nIt is straightforward to show that protocols for Set Intersection or Equality\nTesting need to send $\\Omega(k + \\log p_{\\mathrm{err}}^{-1})$ bits. Is it\npossible to simultaneously achieve optimality in all three parameters, namely\n$O(k + \\log p_{\\mathrm{err}}^{-1})$ communication and $O(\\log^* k)$ rounds? In\nthis paper we prove that there is no universally optimal algorithm, and\ncomplement the existing round-communication tradeoffs with a new tradeoff\nbetween rounds, communication, and probability of error. In particular:\n  1. Any protocol for solving Multiple Equality Testing in $r$ rounds with\nfailure probability $2^{-E}$ has communication volume $\\Omega(Ek^{1/r})$.\n  2. There exists a protocol for solving Multiple Equality Testing in $r +\n\\log^*(k/E)$ rounds with $O(k + rEk^{1/r})$ communication, thereby essentially\nmatching our lower bound and that of Sa\\u{g}lam and Tardos.\n  Our original motivation for considering $p_{\\mathrm{err}}$ as an independent\nparameter came from the problem of enumerating triangles in distributed\n($\\textsf{CONGEST}$) networks having maximum degree $\\Delta$. We prove that\nthis problem can be solved in $O(\\Delta/\\log n + \\log\\log \\Delta)$ time with\nhigh probability $1-1/\\operatorname{poly}(n)$.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 16:31:23 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 15:50:42 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Huang", "Dawei", ""], ["Pettie", "Seth", ""], ["Zhang", "Yixiang", ""], ["Zhang", "Zhijun", ""]]}]