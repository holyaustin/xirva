[{"id": "1204.0543", "submitter": "Daniel Kane", "authors": "Daniel M. Kane", "title": "A Structure Theorem for Poorly Anticoncentrated Gaussian Chaoses and\n  Applications to the Study of Polynomial Threshold Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a structural result for degree-$d$ polynomials. In particular, we\nshow that any degree-$d$ polynomial, $p$ can be approximated by another\npolynomial, $p_0$, which can be decomposed as some function of polynomials\n$q_1,...,q_m$ with $q_i$ normalized and $m=O_d(1)$, so that if $X$ is a\nGaussian random variable, the probability distribution on $(q_1(X),...,q_m(X))$\ndoes not have too much mass in any small box.\n  Using this result, we prove improved versions of a number of results about\npolynomial threshold functions, including producing better pseudorandom\ngenerators, obtaining a better invariance principle, and proving improved\nbounds on noise sensitivity.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2012 21:37:49 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2012 21:08:39 GMT"}], "update_date": "2012-08-17", "authors_parsed": [["Kane", "Daniel M.", ""]]}, {"id": "1204.0660", "submitter": "Sergio Cabello", "authors": "Sergio Cabello", "title": "Hardness of approximation for crossing number", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, if P\\not=NP, there is a constant c > 1 such that there is no\nc-approximation algorithm for the crossing number, even when restricted to\n3-regular graphs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 11:32:13 GMT"}], "update_date": "2012-04-04", "authors_parsed": [["Cabello", "Sergio", ""]]}, {"id": "1204.0775", "submitter": "Christoph Berkholz", "authors": "Christoph Berkholz", "title": "On the Complexity of Finding Narrow Proofs", "comments": "Full version of the FOCS 2012 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of the following \"resolution width problem\": Does a\ngiven 3-CNF have a resolution refutation of width k? We prove that the problem\ncannot be decided in time O(n^((k-3)/12)). This lower bound is unconditional\nand does not rely on any unproven complexity theoretic assumptions. The lower\nbound is matched by a trivial upper bound of n^O(k).\n  We also prove that the resolution width problem is EXPTIME-complete (if k is\npart of the input). This confirms a conjecture by Vardi, who has first raised\nthe question for the complexity of the resolution width problem. Furthermore,\nwe prove that the variant of the resolution width problem for regular\nresolution is PSPACE-complete, confirming a conjecture by Urquhart.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 19:34:19 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2012 07:48:22 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Berkholz", "Christoph", ""]]}, {"id": "1204.0816", "submitter": "Shiva Kintali", "authors": "Shiva Kintali and Asaf Shapira", "title": "A Note on the Balanced ST-Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that every YES instance of Balanced ST-Connectivity has a balanced\npath of polynomial length.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 21:39:39 GMT"}], "update_date": "2012-04-05", "authors_parsed": [["Kintali", "Shiva", ""], ["Shapira", "Asaf", ""]]}, {"id": "1204.0849", "submitter": "C. Seshadhri", "authors": "Deeparnab Chakrabarty and C. Seshadhri", "title": "Optimal bounds for monotonicity and Lipschitz testing over hypercubes\n  and hypergrids", "comments": "Cleaner proof and much better presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of monotonicity testing over the hypergrid and its special case,\nthe hypercube, is a classic, well-studied, yet unsolved question in property\ntesting. We are given query access to $f:[k]^n \\mapsto \\R$ (for some ordered\nrange $\\R$). The hypergrid/cube has a natural partial order given by\ncoordinate-wise ordering, denoted by $\\prec$. A function is \\emph{monotone} if\nfor all pairs $x \\prec y$, $f(x) \\leq f(y)$. The distance to monotonicity,\n$\\eps_f$, is the minimum fraction of values of $f$ that need to be changed to\nmake $f$ monotone.\n  For $k=2$ (the boolean hypercube), the usual tester is the \\emph{edge\ntester}, which checks monotonicity on adjacent pairs of domain points. It is\nknown that the edge tester using $O(\\eps^{-1}n\\log|\\R|)$ samples can\ndistinguish a monotone function from one where $\\eps_f > \\eps$. On the other\nhand, the best lower bound for monotonicity testing over the hypercube is\n$\\min(|\\R|^2,n)$. This leaves a quadratic gap in our knowledge, since $|\\R|$\ncan be $2^n$. We resolve this long standing open problem and prove that\n$O(n/\\eps)$ samples suffice for the edge tester. For hypergrids, known testers\nrequire $O(\\eps^{-1}n\\log k\\log |\\R|)$ samples, while the best known\n(non-adaptive) lower bound is $\\Omega(\\eps^{-1} n\\log k)$. We give a\n(non-adaptive) monotonicity tester for hypergrids running in $O(\\eps^{-1} n\\log\nk)$ time.\n  Our techniques lead to optimal property testers (with the same running time)\nfor the natural \\emph{Lipschitz property} on hypercubes and hypergrids. (A\n$c$-Lipschitz function is one where $|f(x) - f(y)| \\leq c\\|x-y\\|_1$.) In fact,\nwe give a general unified proof for $O(\\eps^{-1}n\\log k)$-query testers for a\nclass of \"bounded-derivative\" properties, a class containing both monotonicity\nand Lipschitz.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2012 02:15:55 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2012 21:55:18 GMT"}, {"version": "v3", "created": "Wed, 2 Apr 2014 21:57:38 GMT"}], "update_date": "2014-04-04", "authors_parsed": [["Chakrabarty", "Deeparnab", ""], ["Seshadhri", "C.", ""]]}, {"id": "1204.0939", "submitter": "Guillaume Aupy", "authors": "Guillaume Aupy, Anne Benoit, Fanny Dufoss\\'e and Yves Robert", "title": "Reclaiming the energy of a schedule: models and algorithms", "comments": "A two-page extended abstract of this work appeared as a short\n  presentation in SPAA'2011, while the long version has been accepted for\n  publication in \"Concurrency and Computation: Practice and Experience\"", "journal-ref": null, "doi": "10.1002/cpe.2889", "report-no": "INRIA Research report 7598", "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a task graph to be executed on a set of processors. We assume\nthat the mapping is given, say by an ordered list of tasks to execute on each\nprocessor, and we aim at optimizing the energy consumption while enforcing a\nprescribed bound on the execution time. While it is not possible to change the\nallocation of a task, it is possible to change its speed. Rather than using a\nlocal approach such as backfilling, we consider the problem as a whole and\nstudy the impact of several speed variation models on its complexity. For\ncontinuous speeds, we give a closed-form formula for trees and series-parallel\ngraphs, and we cast the problem into a geometric programming problem for\ngeneral directed acyclic graphs. We show that the classical dynamic voltage and\nfrequency scaling (DVFS) model with discrete modes leads to a NP-complete\nproblem, even if the modes are regularly distributed (an important particular\ncase in practice, which we analyze as the incremental model). On the contrary,\nthe VDD-hopping model leads to a polynomial solution. Finally, we provide an\napproximation algorithm for the incremental model, which we extend for the\ngeneral DVFS model.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2012 12:53:48 GMT"}], "update_date": "2012-08-03", "authors_parsed": [["Aupy", "Guillaume", ""], ["Benoit", "Anne", ""], ["Dufoss\u00e9", "Fanny", ""], ["Robert", "Yves", ""]]}, {"id": "1204.0944", "submitter": "Tom Gur", "authors": "Tom Gur and Omer Tamuz", "title": "Testing Booleanity and the Uncertainty Principle", "comments": "15 pages", "journal-ref": "Chicago Journal of Theoretical Computer Science 2013, Article 14", "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let f:{-1,1}^n -> R be a real function on the hypercube, given by its\ndiscrete Fourier expansion, or, equivalently, represented as a multilinear\npolynomial. We say that it is Boolean if its image is in {-1,1}.\n  We show that every function on the hypercube with a sparse Fourier expansion\nmust either be Boolean or far from Boolean. In particular, we show that a\nmultilinear polynomial with at most k terms must either be Boolean, or output\nvalues different than -1 or 1 for a fraction of at least 2/(k+2)^2 of its\ndomain.\n  It follows that given oracle access to f, together with the guarantee that\nits representation as a multilinear polynomial has at most k terms, one can\ntest Booleanity using O(k^2) queries. We show an \\Omega(k) queries lower bound\nfor this problem.\n  Our proof crucially uses Hirschman's entropic version of Heisenberg's\nuncertainty principle.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2012 13:09:30 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2013 05:45:40 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Gur", "Tom", ""], ["Tamuz", "Omer", ""]]}, {"id": "1204.0949", "submitter": "Pierre Guillon", "authors": "Pierre Guillon, Charalampos Zinoviadis", "title": "Densities and entropies in cellular automata", "comments": "10 pages + 8 pages appendix, cited in bib; published in CiE 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following work by Hochman and Meyerovitch on multidimensional SFT, we give\ncomputability-theoretic characterizations of the real numbers that can appear\nas the topological entropies of one-dimensional and two-dimensional cellular\nautomata.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2012 13:56:47 GMT"}], "update_date": "2012-04-05", "authors_parsed": [["Guillon", "Pierre", ""], ["Zinoviadis", "Charalampos", ""]]}, {"id": "1204.0957", "submitter": "G\\'abor Braun", "authors": "G\\'abor Braun, Samuel Fiorini, Sebastian Pokutta, and David Steurer", "title": "Approximation Limits of Linear Programs (Beyond Hierarchies)", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for approximation limits of polynomial-size linear\nprograms from lower bounds on the nonnegative ranks of suitably defined\nmatrices. This framework yields unconditional impossibility results that are\napplicable to any linear program as opposed to only programs generated by\nhierarchies. Using our framework, we prove that O(n^{1/2-eps})-approximations\nfor CLIQUE require linear programs of size 2^{n^\\Omega(eps)}. (This lower bound\napplies to linear programs using a certain encoding of CLIQUE as a linear\noptimization problem.) Moreover, we establish a similar result for\napproximations of semidefinite programs by linear programs. Our main ingredient\nis a quantitative improvement of Razborov's rectangle corruption lemma for the\nhigh error regime, which gives strong lower bounds on the nonnegative rank of\ncertain perturbations of the unique disjointness matrix.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2012 14:14:34 GMT"}, {"version": "v2", "created": "Mon, 13 May 2013 20:06:04 GMT"}, {"version": "v3", "created": "Fri, 16 May 2014 20:23:01 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Braun", "G\u00e1bor", ""], ["Fiorini", "Samuel", ""], ["Pokutta", "Sebastian", ""], ["Steurer", "David", ""]]}, {"id": "1204.1079", "submitter": "Johan Thapper", "authors": "Johan Thapper and Stanislav Zivny", "title": "The Power of Linear Programming for Valued CSPs", "comments": "Corrected a few typos", "journal-ref": "Proc. of FOCS'12 669-678 (2012)", "doi": "10.1109/FOCS.2012.25", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A class of valued constraint satisfaction problems (VCSPs) is characterised\nby a valued constraint language, a fixed set of cost functions on a finite\ndomain. An instance of the problem is specified by a sum of cost functions from\nthe language with the goal to minimise the sum. This framework includes and\ngeneralises well-studied constraint satisfaction problems (CSPs) and maximum\nconstraint satisfaction problems (Max-CSPs).\n  Our main result is a precise algebraic characterisation of valued constraint\nlanguages whose instances can be solved exactly by the basic linear programming\nrelaxation. Using this result, we obtain tractability of several novel and\npreviously widely-open classes of VCSPs, including problems over valued\nconstraint languages that are: (1) submodular on arbitrary lattices; (2)\nbisubmodular (also known as k-submodular) on arbitrary finite domains; (3)\nweakly (and hence strongly) tree-submodular on arbitrary trees.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2012 21:12:26 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2012 14:39:54 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Thapper", "Johan", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1204.1111", "submitter": "Francois Le Gall", "authors": "Fran\\c{c}ois Le Gall", "title": "Faster Algorithms for Rectangular Matrix Multiplication", "comments": "37 pages; v2: some additions in the acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let {\\alpha} be the maximal value such that the product of an n x n^{\\alpha}\nmatrix by an n^{\\alpha} x n matrix can be computed with n^{2+o(1)} arithmetic\noperations. In this paper we show that \\alpha>0.30298, which improves the\nprevious record \\alpha>0.29462 by Coppersmith (Journal of Complexity, 1997).\nMore generally, we construct a new algorithm for multiplying an n x n^k matrix\nby an n^k x n matrix, for any value k\\neq 1. The complexity of this algorithm\nis better than all known algorithms for rectangular matrix multiplication. In\nthe case of square matrix multiplication (i.e., for k=1), we recover exactly\nthe complexity of the algorithm by Coppersmith and Winograd (Journal of\nSymbolic Computation, 1990).\n  These new upper bounds can be used to improve the time complexity of several\nknown algorithms that rely on rectangular matrix multiplication. For example,\nwe directly obtain a O(n^{2.5302})-time algorithm for the all-pairs shortest\npaths problem over directed graphs with small integer weights, improving over\nthe O(n^{2.575})-time algorithm by Zwick (JACM 2002), and also improve the time\ncomplexity of sparse square matrix multiplication.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2012 02:14:37 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2012 06:47:16 GMT"}], "update_date": "2012-08-02", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""]]}, {"id": "1204.1113", "submitter": "J. Maurice Rojas", "authors": "Jingguo Bi, Qi Cheng, J. Maurice Rojas", "title": "Sub-Linear Root Detection, and New Hardness Results, for Sparse\n  Polynomials Over Finite Fields", "comments": "15 pages total (cover page, 10 pages, references, and 3 short\n  appendices). This version corrects various minor typos, and improves the\n  statement of the first main theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deterministic 2^O(t)q^{(t-2)(t-1)+o(1)} algorithm to decide\nwhether a univariate polynomial f, with exactly t monomial terms and degree <q,\nhas a root in F_q. A corollary of our method --- the first with complexity\nsub-linear in q when t is fixed --- is that the nonzero roots in F_q can be\npartitioned into at most 2 \\sqrt{t-1} (q-1)^{(t-2)(t-1)} cosets of two\nsubgroups S_1,S_2 of F^*_q, with S_1 in S_2. Another corollary is the first\ndeterministic sub-linear algorithm for detecting common degree one factors of\nk-tuples of t-nomials in F_q[x] when k and t are fixed.\n  When t is not fixed we show that each of the following problems is NP-hard\nwith respect to BPP-reductions, even when p is prime: (1) detecting roots in\nF_p for f, (2) deciding whether the square of a degree one polynomial in F_p[x]\ndivides f, (3) deciding whether the discriminant of f vanishes, (4) deciding\nwhether the gcd of two t-nomials in F_p[x] has positive degree. Finally, we\nprove that if the complexity of root detection is sub-linear (in a refined\nsense), relative to the straight-line program encoding, then NEXP is not in\nP/Poly.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2012 02:54:28 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2012 04:23:56 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Bi", "Jingguo", ""], ["Cheng", "Qi", ""], ["Rojas", "J. Maurice", ""]]}, {"id": "1204.1196", "submitter": "Felix Weiss", "authors": "Stefan G\\\"oller, Arne Meier, Martin Mundhenk, Thomas Schneider,\n  Michael Thomas, Felix Weiss", "title": "The Complexity of Monotone Hybrid Logics over Linear Frames and the\n  Natural Numbers", "comments": "19 pages + 15 pages appendix, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid logic with binders is an expressive specification language. Its\nsatisfiability problem is undecidable in general. If frames are restricted to N\nor general linear orders, then satisfiability is known to be decidable, but of\nnon-elementary complexity. In this paper, we consider monotone hybrid logics\n(i.e., the Boolean connectives are conjunction and disjunction only) over N and\ngeneral linear orders. We show that the satisfiability problem remains\nnon-elementary over linear orders, but its complexity drops to\nPSPACE-completeness over N. We categorize the strict fragments arising from\ndifferent combinations of modal and hybrid operators into NP-complete and\ntractable (i.e. complete for NC1or LOGSPACE). Interestingly, NP-completeness\ndepends only on the fragment and not on the frame. For the cases above NP,\nsatisfiability over linear orders is harder than over N, while below NP it is\nat most as hard. In addition we examine model-theoretic properties of the\nfragments in question.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2012 12:15:24 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2012 09:47:55 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["G\u00f6ller", "Stefan", ""], ["Meier", "Arne", ""], ["Mundhenk", "Martin", ""], ["Schneider", "Thomas", ""], ["Thomas", "Michael", ""], ["Weiss", "Felix", ""]]}, {"id": "1204.1292", "submitter": "Jean-Fran\\c{c}ois Biasse", "authors": "Jean-Fran\\c{c}ois Biasse", "title": "An L(1/3) algorithm for discrete logarithm computation and principality\n  testing in certain number fields", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the complexity of solving the discrete logarithm problem and of\ntesting the principality of ideals in a certain class of number fields. We\nachieve the subexponential complexity in $O(L(1/3,O(1)))$ when both the\ndiscriminant and the degree of the extension tend to infinity by using\ntechniques due to Enge, Gaudry and Thom\\'{e} in the context of algebraic curves\nover finite fields.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2012 18:04:39 GMT"}], "update_date": "2012-04-06", "authors_parsed": [["Biasse", "Jean-Fran\u00e7ois", ""]]}, {"id": "1204.1298", "submitter": "Jean-Fran\\c{c}ois Biasse", "authors": "Jean-Fran\\c{c}ois Biasse and Claus Fieker", "title": "A polynomial time algorithm for computing the HNF of a module over the\n  integers of a number field", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a variation of the modular algorithm for computing the Hermite\nNormal Form of an $\\OK$-module presented by Cohen, where $\\OK$ is the ring of\nintegers of a number field K. The modular strategy was conjectured to run in\npolynomial time by Cohen, but so far, no such proof was available in the\nliterature. In this paper, we provide a new method to prevent the coefficient\nexplosion and we rigorously assess its complexity with respect to the size of\nthe input and the invariants of the field K.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2012 18:25:59 GMT"}], "update_date": "2012-04-06", "authors_parsed": [["Biasse", "Jean-Fran\u00e7ois", ""], ["Fieker", "Claus", ""]]}, {"id": "1204.1367", "submitter": "Shachar Lovett", "authors": "Abhishek Bhowmick and Zeev Dvir and Shachar Lovett", "title": "New Lower Bounds for Matching Vector Codes", "comments": "Fixed typos and small bugs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Matching Vector (MV) family modulo $m$ is a pair of ordered lists\n$U=(u_1,...,u_t)$ and $V=(v_1,...,v_t)$ where $u_i,v_j \\in \\mathbb{Z}_m^n$ with\nthe following inner product pattern: for any $i$, $< u_i,v_i>=0$, and for any\n$i \\ne j$, $< u_i,v_j> \\ne 0$. A MV family is called $q$-restricted if inner\nproducts $< u_i,v_j>$ take at most $q$ different values.\n  Our interest in MV families stems from their recent application in the\nconstruction of sub-exponential locally decodable codes (LDCs). There,\n$q$-restricted MV families are used to construct LDCs with $q$ queries, and\nthere is special interest in the regime where $q$ is constant. When $m$ is a\nprime it is known that such constructions yield codes with exponential block\nlength. However, for composite $m$ the behaviour is dramatically different. A\nrecent work by Efremenko [STOC 2009] (based on an approach initiated by\nYekhanin [JACM 2008]) gives the first sub-exponential LDC with constant\nqueries. It is based on a construction of a MV family of super-polynomial size\nby Grolmusz [Combinatorica 2000] modulo composite $m$.\n  In this work, we prove two lower bounds on the block length of LDCs which are\nbased on black box construction using MV families. When $q$ is constant (or\nsufficiently small), we prove that such LDCs must have a quadratic block\nlength. When the modulus $m$ is constant (as it is in the construction of\nEfremenko) we prove a super-polynomial lower bound on the block-length of the\nLDCs, assuming a well-known conjecture in additive combinatorics, the\npolynomial Freiman-Ruzsa conjecture over $\\mathbb{Z}_m$.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2012 22:16:37 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2013 18:21:48 GMT"}], "update_date": "2013-04-01", "authors_parsed": [["Bhowmick", "Abhishek", ""], ["Dvir", "Zeev", ""], ["Lovett", "Shachar", ""]]}, {"id": "1204.1417", "submitter": "Christophe Paul", "authors": "Eun Jung Kim and Christophe Paul and Geevarghese Philip", "title": "A single-exponential FPT algorithm for the $K_4$-minor cover problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an input graph G and an integer k, the parameterized K_4-minor cover\nproblem asks whether there is a set S of at most k vertices whose deletion\nresults in a K_4-minor-free graph, or equivalently in a graph of treewidth at\nmost 2. This problem is inspired by two well-studied parameterized vertex\ndeletion problems, Vertex Cover and Feedback Vertex Set, which can also be\nexpressed as Treewidth-t Vertex Deletion problems: t=0 for Vertex Cover and t=1\nfor Feedback Vertex Set. While a single-exponential FPT algorithm has been\nknown for a long time for \\textsc{Vertex Cover}, such an algorithm for Feedback\nVertex Set was devised comparatively recently. While it is known to be unlikely\nthat Treewidth-t Vertex Deletion can be solved in time c^{o(k)}.n^{O(1)}, it\nwas open whether the K_4-minor cover problem could be solved in\nsingle-exponential FPT time, i.e. in c^k.n^{O(1)} time. This paper answers this\nquestion in the affirmative.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2012 06:37:59 GMT"}], "update_date": "2012-04-09", "authors_parsed": [["Kim", "Eun Jung", ""], ["Paul", "Christophe", ""], ["Philip", "Geevarghese", ""]]}, {"id": "1204.1505", "submitter": "J\\'er\\'emie Roland", "authors": "Iordanis Kerenidis and Sophie Laplante and Virginie Lerays and\n  J\\'er\\'emie Roland and David Xiao", "title": "Lower bounds on information complexity via zero-communication protocols\n  and applications", "comments": "22 pages", "journal-ref": "In 53rd Annual IEEE Symposium on Foundations of Computer Science\n  (FOCS'12), pages 500-509, 2012", "doi": "10.1109/FOCS.2012.68", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that almost all known lower bound methods for communication\ncomplexity are also lower bounds for the information complexity. In particular,\nwe define a relaxed version of the partition bound of Jain and Klauck and prove\nthat it lower bounds the information complexity of any function. Our relaxed\npartition bound subsumes all norm based methods (e.g. the factorization norm\nmethod) and rectangle-based methods (e.g. the rectangle/corruption bound, the\nsmooth rectangle bound, and the discrepancy bound), except the partition bound.\nOur result uses a new connection between rectangles and zero-communication\nprotocols where the players can either output a value or abort. We prove the\nfollowing compression lemma: given a protocol for a function f with information\ncomplexity I, one can construct a zero-communication protocol that has\nnon-abort probability at least 2^{-O(I)} and that computes f correctly with\nhigh probability conditioned on not aborting. Then, we show how such a\nzero-communication protocol relates to the relaxed partition bound. We use our\nmain theorem to resolve three of the open questions raised by Braverman. First,\nwe show that the information complexity of the Vector in Subspace Problem is\n{\\Omega}(n^{1/3}), which, in turn, implies that there exists an exponential\nseparation between quantum communication complexity and classical information\ncomplexity. Moreover, we provide an {\\Omega}(n) lower bound on the information\ncomplexity of the Gap Hamming Distance Problem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2012 16:01:53 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2013 09:48:10 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["Kerenidis", "Iordanis", ""], ["Laplante", "Sophie", ""], ["Lerays", "Virginie", ""], ["Roland", "J\u00e9r\u00e9mie", ""], ["Xiao", "David", ""]]}, {"id": "1204.1580", "submitter": "Dustin Mixon", "authors": "Afonso S. Bandeira, Edgar Dobriban, Dustin G. Mixon, William F. Sawin", "title": "Certifying the restricted isometry property is hard", "comments": null, "journal-ref": null, "doi": "10.1109/TIT.2013.2248414", "report-no": null, "categories": "math.FA cs.CC cs.IT math.IT", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  This paper is concerned with an important matrix condition in compressed\nsensing known as the restricted isometry property (RIP). We demonstrate that\ntesting whether a matrix satisfies RIP is NP-hard. As a consequence of our\nresult, it is impossible to efficiently test for RIP provided P \\neq NP.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2012 23:58:53 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2012 15:16:57 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Bandeira", "Afonso S.", ""], ["Dobriban", "Edgar", ""], ["Mixon", "Dustin G.", ""], ["Sawin", "William F.", ""]]}, {"id": "1204.1656", "submitter": "Bernd Schuh", "authors": "Bernd R. Schuh", "title": "Phase Transition in Unrestricted Random SAT", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For random CNF formulae with m clauses, n variables and an unrestricted\nnumber of literals per clause the transition from high to low satisfiability\ncan be determined exactly for large n. The critical density m/n turns out to be\nstrongly n-dependent, ccr = ln(2)/(1-p)^^n, where pn is the mean number of\npositive literals per clause.This is in contrast to restricted random SAT\nproblems (random K-SAT), where the critical ratio m/n is a constant. All\ntransition lines are calculated by the second moment method applied to the\nnumber of solutions N of a formula. In contrast to random K-SAT, the method\ndoes not fail for the unrestricted model, because long range interactions\nbetween solutions are not cut off by disorder.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 16:50:46 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Schuh", "Bernd R.", ""]]}, {"id": "1204.1764", "submitter": "Deepak Ponvel Chermakani Mr", "authors": "Deepak Ponvel Chermakani", "title": "A Non-Triviality Certificate for Scalars and its application to Linear\n  Systems", "comments": "6 pages, 10 figures, 1 Theorem on the non-triviality Certificate for\n  Scalars", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach of taking a linear weighted Average of N given\nscalars, such that this Average is zero, if and only if, all N scalars are\nzero. The weights for the scalars in this Average vary asymptotically with\nrespect to a large positive real. We use this approach with a previous result\non Asymptotic Linear Programming, to develop an O(M^4) Algorithm that decides\nwhether or not a system of M Linear Inequalities is feasible, and, whether or\nnot any desired subset of the variables in this system, is permitted to have a\nnon-trivial solution.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2012 20:56:41 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Chermakani", "Deepak Ponvel", ""]]}, {"id": "1204.1990", "submitter": "Martin Grohe", "authors": "Martin Grohe and Martin Otto", "title": "Pebble Games and Linear Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new, simplified and detailed account of the correspondence between\nlevels of the Sherali-Adams relaxation of graph isomorphism and levels of\npebble-game equivalence with counting (higher-dimensional Weisfeiler-Lehman\ncolour refinement). The correspondence between basic colour refinement and\nfractional isomorphism, due to Tinhofer (1986, 1991) and Ramana, Scheinerman\nand Ullman (1994), is re-interpreted as the base level of Sherali-Adams and\ngeneralised to higher levels in this sense by Atserias and Maneva (2012) and\nMalkin (2014), who prove that the two resulting hierarchies interleave.\n  In carrying this analysis further, we here give\n  (a) a precise characterisation of the level-k Sherali-Adams relaxation in\nterms of a modified counting pebble game;\n  (b) a variant of the Sherali-Adams levels that precisely match the k-pebble\ncounting game;\n  (c) a proof that the interleaving between these two hierarchies is strict.\n  We also investigate the variation based on boolean arithmetic instead of\nreal/rational arithmetic and obtain analogous correspondences and separations\nfor plain k-pebble equivalence (without counting). Our results are driven by\nconsiderably simplified accounts of the underlying combinatorics and linear\nalgebra.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2012 21:00:07 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2012 22:06:55 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2015 13:23:31 GMT"}], "update_date": "2015-03-25", "authors_parsed": [["Grohe", "Martin", ""], ["Otto", "Martin", ""]]}, {"id": "1204.2026", "submitter": "Peng Cui", "authors": "Peng Cui", "title": "Strengthened Hardness for Approximating Minimum Unique Game and Small\n  Set Expansion", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the author puts forward a variation of Feige's Hypothesis,\nwhich claims that it is hard on average refuting Unbalanced Max 3-XOR under\nbiased assignments on a natural distribution. Under this hypothesis, the author\nstrengthens the previous known hardness for approximating Minimum Unique Game,\n$5/4-\\epsilon$, by proving that Min 2-Lin-2 is hard to within $3/2-\\epsilon$\nand strengthens the previous known hardness for approximating Small Set\nExpansion, $4/3-\\epsilon$, by proving that Min Bisection is hard to approximate\nwithin $3-\\epsilon$. In addition, the author discusses the limitation of this\nmethod to show that it can strengthen the hardness for approximating Minimum\nUnique Game to $2-\\kappa$ where $\\kappa$ is a small absolute positive, but is\nshort of proving $\\omega_k(1)$ hardness for Minimum Unique Game (or Small Set\nExpansion), by assuming a generalization of this hypothesis on Unbalanced Max\nk-CSP with Samorodnitsky-Trevisan hypergraph predicate.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 02:11:49 GMT"}, {"version": "v2", "created": "Mon, 7 May 2012 03:31:51 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2013 10:34:31 GMT"}, {"version": "v4", "created": "Tue, 23 Apr 2013 07:02:25 GMT"}, {"version": "v5", "created": "Wed, 19 Feb 2014 04:01:50 GMT"}, {"version": "v6", "created": "Mon, 15 Dec 2014 02:03:54 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Cui", "Peng", ""]]}, {"id": "1204.2040", "submitter": "Yanbin Pan", "authors": "Gengran Hu and Yanbin Pan", "title": "A New Reduction from Search SVP to Optimization SVP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  It is well known that search SVP is equivalent to optimization SVP. However,\nthe former reduction from search SVP to optimization SVP by Kannan needs\npolynomial times calls to the oracle that solves the optimization SVP. In this\npaper, a new rank-preserving reduction is presented with only one call to the\noptimization SVP oracle. It is obvious that the new reduction needs the least\ncalls, and improves Kannan's classical result. What's more, the idea also leads\na similar direct reduction from search CVP to optimization CVP with only one\ncall to the oracle.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 04:23:24 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Hu", "Gengran", ""], ["Pan", "Yanbin", ""]]}, {"id": "1204.2124", "submitter": "Bernard Lidick\\'y", "authors": "Petr A. Golovach, Bernard Lidick\\'y, Barnaby Martin, Dani\\\"el Paulusma", "title": "Finding vertex-surjective graph homomorphisms", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": "10.1007/s00236-012-0164-0\"", "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Surjective Homomorphism problem is to test whether a given graph G called\nthe guest graph allows a vertex-surjective homomorphism to some other given\ngraph H called the host graph. The bijective and injective homomorphism\nproblems can be formulated in terms of spanning subgraphs and subgraphs, and as\nsuch their computational complexity has been extensively studied. What about\nthe surjective variant? Because this problem is NP-complete in general, we\nrestrict the guest and the host graph to belong to graph classes G and H,\nrespectively. We determine to what extent a certain choice of G and H\ninfluences its computational complexity. We observe that the problem is\npolynomial-time solvable if H is the class of paths, whereas it is NP-complete\nif G is the class of paths. Moreover, we show that the problem is even\nNP-complete on many other elementary graph classes, namely linear forests,\nunions of complete graphs, cographs, proper interval graphs, split graphs and\ntrees of pathwidth at most 2. In contrast, we prove that the problem is\nfixed-parameter tractable in k if G is the class of trees and H is the class of\ntrees with at most k leaves, or if G and H are equal to the class of graphs\nwith vertex cover number at most k.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 12:31:27 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Golovach", "Petr A.", ""], ["Lidick\u00fd", "Bernard", ""], ["Martin", "Barnaby", ""], ["Paulusma", "Dani\u00ebl", ""]]}, {"id": "1204.2201", "submitter": "Chris Thachuk", "authors": "Anne Condon, J\\'an Ma\\v{n}uch and Chris Thachuk", "title": "The complexity of string partitioning", "comments": "14 pages main text + 13 pages appendix. Full version with proofs of\n  an article appearing in the Proceedings of the 23rd Annual Symposium on\n  Combinatorial Pattern Matching (CPM 2012), Helsinki, Finland, July 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a string $w$ over a finite alphabet $\\Sigma$ and an integer $K$, can\n$w$ be partitioned into strings of length at most $K$, such that there are no\n\\emph{collisions}? We refer to this question as the \\emph{string partition}\nproblem and show it is \\NP-complete for various definitions of collision and\nfor a number of interesting restrictions including $|\\Sigma|=2$. This\nestablishes the hardness of an important problem in contemporary synthetic\nbiology, namely, oligo design for gene synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 16:00:02 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Condon", "Anne", ""], ["Ma\u0148uch", "J\u00e1n", ""], ["Thachuk", "Chris", ""]]}, {"id": "1204.2202", "submitter": "Minghui Jiang", "authors": "Minghui Jiang", "title": "Clique in 3-track interval graphs is APX-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Butman, Hermelin, Lewenstein, and Rawitz proved that Clique in t-interval\ngraphs is NP-hard for t >= 3. We strengthen this result to show that Clique in\n3-track interval graphs is APX-hard.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 16:00:48 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Jiang", "Minghui", ""]]}, {"id": "1204.2652", "submitter": "Vladimir V. Podolskii", "authors": "Vladimir V. Podolskii (Steklov Mathematical Institute)", "title": "Lower Bound on Weights of Large Degree Threshold Functions", "comments": "17 pages, to appear in LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 2 (June 28,\n  2013) lmcs:722", "doi": "10.2168/LMCS-9(2:13)2013", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An integer polynomial $p$ of $n$ variables is called a \\emph{threshold gate}\nfor a Boolean function $f$ of $n$ variables if for all $x \\in \\zoon$ $f(x)=1$\nif and only if $p(x)\\geq 0$. The \\emph{weight} of a threshold gate is the sum\nof its absolute values.\n  In this paper we study how large a weight might be needed if we fix some\nfunction and some threshold degree. We prove $2^{\\Omega(2^{2n/5})}$ lower bound\non this value. The best previous bound was $2^{\\Omega(2^{n/8})}$ (Podolskii,\n2009).\n  In addition we present substantially simpler proof of the weaker\n$2^{\\Omega(2^{n/4})}$ lower bound. This proof is conceptually similar to other\nproofs of the bounds on weights of nonlinear threshold gates, but avoids a lot\nof technical details arising in other proofs. We hope that this proof will help\nto show the ideas behind the construction used to prove these lower bounds.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 08:23:35 GMT"}, {"version": "v2", "created": "Sun, 19 May 2013 09:26:23 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2013 14:48:23 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Podolskii", "Vladimir V.", "", "Steklov Mathematical Institute"]]}, {"id": "1204.3022", "submitter": "Bjarki Holm", "authors": "Anuj Dawar (University of Cambridge), Eryk Kopczynski (Warsaw\n  University), Bjarki Holm (University of Cambridge), Erich Gr\\\"adel (RWTH\n  Aachen University), Wied Pakusa (RWTH Aachen University)", "title": "Definability of linear equation systems over groups and rings", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 4 (November\n  14, 2013) lmcs:725", "doi": "10.2168/LMCS-9(4:12)2013", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the quest for a logic for PTIME and recent insights that the\ndescriptive complexity of problems from linear algebra is a crucial aspect of\nthis problem, we study the solvability of linear equation systems over finite\ngroups and rings from the viewpoint of logical (inter-)definability. All\nproblems that we consider are decidable in polynomial time, but not expressible\nin fixed-point logic with counting. They also provide natural candidates for a\nseparation of polynomial time from rank logics, which extend fixed-point logics\nby operators for determining the rank of definable matrices and which are\nsufficient for solvability problems over fields. Based on the structure theory\nof finite rings, we establish logical reductions among various solvability\nproblems. Our results indicate that all solvability problems for linear\nequation systems that separate fixed-point logic with counting from PTIME can\nbe reduced to solvability over commutative rings. Moreover, we prove closure\nproperties for classes of queries that reduce to solvability over rings, which\nprovides normal forms for logics extended with solvability operators. We\nconclude by studying the extent to which fixed-point logic with counting can\nexpress problems in linear algebra over finite commutative rings, generalising\nknown results on the logical definability of linear-algebraic problems over\nfinite fields.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2012 15:06:01 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2013 17:21:09 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2013 23:03:38 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Dawar", "Anuj", "", "University of Cambridge"], ["Kopczynski", "Eryk", "", "Warsaw\n  University"], ["Holm", "Bjarki", "", "University of Cambridge"], ["Gr\u00e4del", "Erich", "", "RWTH\n  Aachen University"], ["Pakusa", "Wied", "", "RWTH Aachen University"]]}, {"id": "1204.3040", "submitter": "Stefan R\\\"ummele", "authors": "Reinhard Pichler, Stefan R\\\"ummele, Stefan Szeider, Stefan Woltran", "title": "Tractable Answer-Set Programming with Weight Constraints: Bounded\n  Treewidth is not Enough", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 141-164", "doi": "10.1017/S1471068412000099", "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardinality constraints or, more generally, weight constraints are well\nrecognized as an important extension of answer-set programming. Clearly, all\ncommon algorithmic tasks related to programs with cardinality or weight\nconstraints - like checking the consistency of a program - are intractable.\nMany intractable problems in the area of knowledge representation and reasoning\nhave been shown to become linear time tractable if the treewidth of the\nprograms or formulas under consideration is bounded by some constant. The goal\nof this paper is to apply the notion of treewidth to programs with cardinality\nor weight constraints and to identify tractable fragments. It will turn out\nthat the straightforward application of treewidth to such class of programs\ndoes not suffice to obtain tractability. However, by imposing further\nrestrictions, tractability can be achieved.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2012 16:25:30 GMT"}, {"version": "v2", "created": "Tue, 29 May 2012 13:28:54 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Pichler", "Reinhard", ""], ["R\u00fcmmele", "Stefan", ""], ["Szeider", "Stefan", ""], ["Woltran", "Stefan", ""]]}, {"id": "1204.3348", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Symmetry Breaking Constraints: Recent Results", "comments": "To appear in Proceedings of Twenty-Sixth Conference on Artificial\n  Intelligence (AAAI-12)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetry is an important problem in many combinatorial problems. One way of\ndealing with symmetry is to add constraints that eliminate symmetric solutions.\nWe survey recent results in this area, focusing especially on two common and\nuseful cases: symmetry breaking constraints for row and column symmetry, and\nsymmetry breaking constraints for eliminating value symmetry\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 02:56:16 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "1204.3413", "submitter": "Yonatan Goldhirsh", "authors": "Eldar Fischer, Yonatan Goldhirsh and Oded Lachish", "title": "Testing Formula Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the query complexity of testing for properties defined by read once\nformulas, as instances of {\\em massively parametrized properties}, and prove\nseveral testability and non-testability results. First we prove the testability\nof any property accepted by a Boolean read-once formula involving any bounded\narity gates, with a number of queries exponential in $\\epsilon$, doubly\nexponential in the arity, and independent of all other parameters. When the\ngates are limited to being monotone, we prove that there is an {\\em estimation}\nalgorithm, that outputs an approximation of the distance of the input from\nsatisfying the property. For formulas only involving And/Or gates, we provide a\nmore efficient test whose query complexity is only quasipolynomial in\n$\\epsilon$. On the other hand, we show that such testability results do not\nhold in general for formulas over non-Boolean alphabets; specifically we\nconstruct a property defined by a read-once arity $2$ (non-Boolean) formula\nover an alphabet of size $4$, such that any $1/4$-test for it requires a number\nof queries depending on the formula size. We also present such a formula over\nan alphabet of size $5$ that additionally satisfies a strong monotonicity\ncondition.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 09:14:54 GMT"}, {"version": "v2", "created": "Thu, 27 Mar 2014 06:39:05 GMT"}], "update_date": "2014-03-28", "authors_parsed": [["Fischer", "Eldar", ""], ["Goldhirsh", "Yonatan", ""], ["Lachish", "Oded", ""]]}, {"id": "1204.3529", "submitter": "Aritanan Gruber", "authors": "Endre Boros, Aritanan Gruber", "title": "Hardness Results for Approximate Pure Horn CNF Formulae Minimization", "comments": "39 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the hardness of approximation of clause minimum and literal minimum\nrepresentations of pure Horn functions in $n$ Boolean variables. We show that\nunless P=NP, it is not possible to approximate in polynomial time the minimum\nnumber of clauses and the minimum number of literals of pure Horn CNF\nrepresentations to within a factor of $2^{\\log^{1-o(1)} n}$. This is the case\neven when the inputs are restricted to pure Horn 3-CNFs with\n$O(n^{1+\\varepsilon})$ clauses, for some small positive constant $\\varepsilon$.\nFurthermore, we show that even allowing sub-exponential time computation, it is\nstill not possible to obtain constant factor approximations for such problems\nunless the Exponential Time Hypothesis turns out to be false.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 15:41:43 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 21:49:23 GMT"}, {"version": "v3", "created": "Tue, 11 Mar 2014 18:21:16 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Boros", "Endre", ""], ["Gruber", "Aritanan", ""]]}, {"id": "1204.3752", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "GPS Information and Rate Tolerance - Clarifying Relationship between\n  Rate Distortion and Complexity Distortion", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I proposed rate tolerance and discussed its relation to rate distortion in my\nbook \"A Generalized Information Theory\" published in 1993. Recently, I examined\nthe structure function and the complexity distortion based on Kolmogorov's\ncomplexity theory. It is my understanding now that complexity-distortion is\nonly a special case of rate tolerance while constraint sets change from fuzzy\nsets into clear sets that look like balls with the same radius. It is not true\nthat the complexity distortion is generally equivalent to rate distortion as\nclaimed by the researchers of complexity theory. I conclude that a rate\ndistortion function can only be equivalent to a rate tolerance function and\nboth of them can be described by a generalized mutual information formula where\nP(Y|X) is equal to P(Y|Tolerance). The paper uses GPS as an example to derive\ngeneralized information formulae and proves the above conclusions using\nmathematical analyses and a coding example. The similarity between the formula\nfor measuring GPS information and the formula for rate distortion function can\ndeepen our understanding the generalized information measure.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 10:48:14 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "1204.3860", "submitter": "Andr\\'as Salamon", "authors": "Subramanian Ramamoorthy and Andr\\'as Z. Salamon and Rahul Santhanam", "title": "Macroscopes: models for collective decision making", "comments": "Presented at Collective Intelligence conference, 2012\n  (arXiv:1204.2991), 8 pages", "journal-ref": null, "doi": null, "report-no": "CollectiveIntelligence/2012/44", "categories": "cs.SI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model of collective decision making, when a global\ndecision needs to be made but the parties only possess partial information, and\nare unwilling (or unable) to first create a globalcomposite of their local\nviews. Our macroscope model captures two key features of many real-world\nproblems: allotment structure (how access to local information is apportioned\nbetween parties, including overlaps between the parties) and the possible\npresence of meta-information (what each party knows about the allotment\nstructure of the overall problem). Using the framework of communication\ncomplexity, we formalize the efficient solution of a macroscope. We present\ngeneral results about the macroscope model, and also results that abstract the\nessential computational operations underpinning practical applications,\nincluding in financial markets and decentralized sensor networks. We illustrate\nthe computational problem inherent in real-world collective decision making\nprocesses using results for specific functions, involving detecting a change in\nstate (constant and step functions), and computing statistical properties (the\nmean).\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 17:57:58 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Ramamoorthy", "Subramanian", ""], ["Salamon", "Andr\u00e1s Z.", ""], ["Santhanam", "Rahul", ""]]}, {"id": "1204.3918", "submitter": "Toby Walsh", "authors": "Jessica Davies and Nina Narodytska and Toby Walsh", "title": "Eliminating the Weakest Link: Making Manipulation Intractable?", "comments": "To appear in Proceedings of Twenty-Sixth Conference on Artificial\n  Intelligence (AAAI-12)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successive elimination of candidates is often a route to making manipulation\nintractable to compute. We prove that eliminating candidates does not\nnecessarily increase the computational complexity of manipulation. However, for\nmany voting rules used in practice, the computational complexity increases. For\nexample, it is already known that it is NP-hard to compute how a single voter\ncan manipulate the result of single transferable voting (the elimination\nversion of plurality voting). We show here that it is NP-hard to compute how a\nsingle voter can manipulate the result of the elimination version of veto\nvoting, of the closely related Coombs' rule, and of the elimination versions of\na general class of scoring rules.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 21:08:39 GMT"}], "update_date": "2012-04-19", "authors_parsed": [["Davies", "Jessica", ""], ["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1204.3986", "submitter": "Grygoriy Zholtkevych", "authors": "Mizal Alobaidi (1), Andriy Batyiv (2), Grygoriy Zholtkevych (2) ((1)\n  Tikrit University, Faculty of Computer Sciences and Mathematics, (2) V.N.\n  Karazin Kharkiv National University, School of Mathematics)", "title": "Towards the Notion of an Abstract Quantum Automaton", "comments": "15 pages, 3 figures", "journal-ref": "Proc. ICTERI 2012 CEUR-WS 848(2012) 17-32", "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this paper is to give a rigorous mathematical description of\nsystems for processing quantum information. To do it authors consider abstract\nstate machines as models of classical computational systems. This class of\nmachines is refined by introducing constrains on a state structure, namely, it\nis assumed that state of computational process has two components: a control\nunit state and a memory state. Then authors modify the class of models by\nsubstituting the deterministic evolutionary mechanism for a stochastic\nevolutionary mechanism. This approach can be generalized to the quantum case:\none can replace transformations of a classical memory with quantum operations\non a quantum memory. Hence the authors come to the need to construct a\nmathematical model of an operation on the quantum memory. It leads them to the\nnotion of an abstract quantum automaton. Further the authors demonstrate that a\nquantum teleportation process is described as evolutionary process for some\nabstract quantum automaton.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 05:58:56 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Alobaidi", "Mizal", ""], ["Batyiv", "Andriy", ""], ["Zholtkevych", "Grygoriy", ""]]}, {"id": "1204.4176", "submitter": "David Doty", "authors": "Ho-Lin Chen, David Doty, David Soloveichik", "title": "Deterministic Function Computation with Chemical Reaction Networks", "comments": "fixed errors in previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical reaction networks (CRNs) formally model chemistry in a well-mixed\nsolution. CRNs are widely used to describe information processing occurring in\nnatural cellular regulatory networks, and with upcoming advances in synthetic\nbiology, CRNs are a promising language for the design of artificial molecular\ncontrol circuitry. Nonetheless, despite the widespread use of CRNs in the\nnatural sciences, the range of computational behaviors exhibited by CRNs is not\nwell understood.\n  CRNs have been shown to be efficiently Turing-universal when allowing for a\nsmall probability of error. CRNs that are guaranteed to converge on a correct\nanswer, on the other hand, have been shown to decide only the semilinear\npredicates. We introduce the notion of function, rather than predicate,\ncomputation by representing the output of a function f:N^k --> N^l by a count\nof some molecular species, i.e., if the CRN starts with n_1,...,n_k molecules\nof some \"input\" species X1,...,Xk, the CRN is guaranteed to converge to having\nf(n_1,...,n_k) molecules of the \"output\" species Y1,...,Yl. We show that a\nfunction f:N^k --> N^l is deterministically computed by a CRN if and only if\nits graph {(x,y) | f(x) = y} is a semilinear set. Furthermore, each semilinear\nfunction f can be computed on input x in expected time O(polylog(|x|)).\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 19:57:14 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2012 21:25:31 GMT"}, {"version": "v3", "created": "Thu, 10 Jan 2013 08:18:05 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Chen", "Ho-Lin", ""], ["Doty", "David", ""], ["Soloveichik", "David", ""]]}, {"id": "1204.4368", "submitter": "Gregory Gutin", "authors": "G. Gutin, G. Muciaccia and A. Yeo", "title": "(Non-)existence of Polynomial Kernels for the Test Cover Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The input of the Test Cover problem consists of a set $V$ of vertices, and a\ncollection ${\\cal E}=\\{E_1,..., E_m\\}$ of distinct subsets of $V$, called\ntests. A test $E_q$ separates a pair $v_i,v_j$ of vertices if $|\\{v_i,v_j\\}\\cap\nE_q|=1.$ A subcollection ${\\cal T}\\subseteq {\\cal E}$ is a test cover if each\npair $v_i,v_j$ of distinct vertices is separated by a test in ${\\cal T}$. The\nobjective is to find a test cover of minimum cardinality, if one exists. This\nproblem is NP-hard.\n  We consider two parameterizations the Test Cover problem with parameter $k$:\n(a) decide whether there is a test cover with at most $k$ tests, (b) decide\nwhether there is a test cover with at most $|V|-k$ tests. Both\nparameterizations are known to be fixed-parameter tractable. We prove that none\nhave a polynomial size kernel unless $NP\\subseteq coNP/poly$. Our proofs use\nthe cross-composition method recently introduced by Bodlaender et al. (2011)\nand parametric duality introduced by Chen et al. (2005). The result for the\nparameterization (a) was an open problem (private communications with Henning\nFernau and Jiong Guo, Jan.-Feb. 2012). We also show that the parameterization\n(a) admits a polynomial size kernel if the size of each test is upper-bounded\nby a constant.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 15:05:32 GMT"}], "update_date": "2012-04-20", "authors_parsed": [["Gutin", "G.", ""], ["Muciaccia", "G.", ""], ["Yeo", "A.", ""]]}, {"id": "1204.4379", "submitter": "Michael Walter", "authors": "Matthias Christandl and Brent Doran and Michael Walter", "title": "Computing Multiplicities of Lie Group Representations", "comments": "10 pages", "journal-ref": "Proceedings of 2012 IEEE 53rd Annual Symposium on Foundations of\n  Computer Science (FOCS'12), p. 639-648", "doi": "10.1109/FOCS.2012.43", "report-no": null, "categories": "cs.CC math.RT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For fixed compact connected Lie groups H \\subseteq G, we provide a polynomial\ntime algorithm to compute the multiplicity of a given irreducible\nrepresentation of H in the restriction of an irreducible representation of G.\nOur algorithm is based on a finite difference formula which makes the\nmultiplicities amenable to Barvinok's algorithm for counting integral points in\npolytopes.\n  The Kronecker coefficients of the symmetric group, which can be seen to be a\nspecial case of such multiplicities, play an important role in the geometric\ncomplexity theory approach to the P vs. NP problem. Whereas their computation\nis known to be #P-hard for Young diagrams with an arbitrary number of rows, our\nalgorithm computes them in polynomial time if the number of rows is bounded. We\ncomplement our work by showing that information on the asymptotic growth rates\nof multiplicities in the coordinate rings of orbit closures does not directly\nlead to new complexity-theoretic obstructions beyond what can be obtained from\nthe moment polytopes of the orbit closures. Non-asymptotic information on the\nmultiplicities, such as provided by our algorithm, may therefore be essential\nin order to find obstructions in geometric complexity theory.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 15:33:03 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2012 11:49:01 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["Christandl", "Matthias", ""], ["Doran", "Brent", ""], ["Walter", "Michael", ""]]}, {"id": "1204.4564", "submitter": "Simon Perdrix", "authors": "J\\'er\\^ome Javelle, Mehdi Mhalla, Simon Perdrix", "title": "On the Minimum Degree up to Local Complementation: Bounds and Complexity", "comments": "11 pages", "journal-ref": null, "doi": "10.1007/978-3-642-34611-8_16", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The local minimum degree of a graph is the minimum degree reached by means of\na series of local complementations. In this paper, we investigate on this\nquantity which plays an important role in quantum computation and quantum error\ncorrecting codes. First, we show that the local minimum degree of the Paley\ngraph of order p is greater than sqrt{p} - 3/2, which is, up to our knowledge,\nthe highest known bound on an explicit family of graphs. Probabilistic methods\nallows us to derive the existence of an infinite number of graphs whose local\nminimum degree is linear in their order with constant 0.189 for graphs in\ngeneral and 0.110 for bipartite graphs. As regards the computational complexity\nof the decision problem associated with the local minimum degree, we show that\nit is NP-complete and that there exists no k-approximation algorithm for this\nproblem for any constant k unless P = NP.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 08:58:46 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Javelle", "J\u00e9r\u00f4me", ""], ["Mhalla", "Mehdi", ""], ["Perdrix", "Simon", ""]]}, {"id": "1204.4578", "submitter": "Vladimir Podolskii", "authors": "Dima Grigoriev and Vladimir V. Podolskii", "title": "Complexity of tropical and min-plus linear prevarieties", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tropical (or min-plus) semiring is a set $\\mathbb{Z}$ (or $\\mathbb{Z \\cup\n\\{\\infty\\}}$) endowed with two operations: $\\oplus$, which is just usual\nminimum, and $\\odot$, which is usual addition. In tropical algebra the vector\n$x$ is a solution to a polynomial $g_1(x) \\oplus g_2(x) \\oplus...\\oplus\ng_k(x)$, where $g_i(x)$'s are tropical monomials, if the minimum in\n$\\min_i(g_{i}(x))$ is attained at least twice. In min-plus algebra solutions of\nsystems of equations of the form $g_1(x)\\oplus...\\oplus g_k(x) =\nh_1(x)\\oplus...\\oplus h_l(x)$ are studied.\n  In this paper we consider computational problems related to tropical linear\nsystem. We show that the solvability problem (both over $\\mathbb{Z}$ and\n$\\mathbb{Z} \\cup \\{\\infty\\}$) and the problem of deciding the equivalence of\ntwo linear systems (both over $\\mathbb{Z}$ and $\\mathbb{Z} \\cup \\{\\infty\\}$)\nare equivalent under polynomial-time reduction to mean payoff games and are\nalso equivalent to analogous problems in min-plus algebra. In particular, all\nthese problems belong to $\\mathsf{NP} \\cap \\mathsf{coNP}$. Thus we provide a\ntight connection of computational aspects of tropical linear algebra with mean\npayoff games and min-plus linear algebra. On the other hand we show that\ncomputing the dimension of the solution space of a tropical linear system and\nof a min-plus linear system are $\\mathsf{NP}$-complete.\n  We also extend some of our results to the systems of min-plus linear\ninequalities.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 10:33:02 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["Grigoriev", "Dima", ""], ["Podolskii", "Vladimir V.", ""]]}, {"id": "1204.4596", "submitter": "Ronald de Wolf", "authors": "Gabor Ivanyos, Hartmut Klauck, Troy Lee, Miklos Santha, Ronald de Wolf", "title": "New bounds on the classical and quantum communication complexity of some\n  graph properties", "comments": "12 pages LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the communication complexity of a number of graph properties where\nthe edges of the graph $G$ are distributed between Alice and Bob (i.e., each\nreceives some of the edges as input). Our main results are:\n  * An Omega(n) lower bound on the quantum communication complexity of deciding\nwhether an n-vertex graph G is connected, nearly matching the trivial classical\nupper bound of O(n log n) bits of communication.\n  * A deterministic upper bound of O(n^{3/2}log n) bits for deciding if a\nbipartite graph contains a perfect matching, and a quantum lower bound of\nOmega(n) for this problem.\n  * A Theta(n^2) bound for the randomized communication complexity of deciding\nif a graph has an Eulerian tour, and a Theta(n^{3/2}) bound for the quantum\ncommunication complexity of this problem.\n  The first two quantum lower bounds are obtained by exhibiting a reduction\nfrom the n-bit Inner Product problem to these graph problems, which solves an\nopen question of Babai, Frankl and Simon. The third quantum lower bound comes\nfrom recent results about the quantum communication complexity of composed\nfunctions. We also obtain essentially tight bounds for the quantum\ncommunication complexity of a few other problems, such as deciding if G is\ntriangle-free, or if G is bipartite, as well as computing the determinant of a\ndistributed matrix.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 12:14:18 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["Ivanyos", "Gabor", ""], ["Klauck", "Hartmut", ""], ["Lee", "Troy", ""], ["Santha", "Miklos", ""], ["de Wolf", "Ronald", ""]]}, {"id": "1204.4619", "submitter": "Ronald de Wolf", "authors": "Hartmut Klauck, Ronald de Wolf", "title": "Fooling One-Sided Quantum Protocols", "comments": "10 pages LaTeX. Version: corrected an error in Section 2, slightly\n  weakening the result", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the venerable \"fooling set\" method to prove new lower bounds on the\nquantum communication complexity of various functions. Let f:X x Y-->{0,1} be a\nBoolean function, fool^1(f) its maximal fooling set size among 1-inputs,\nQ_1^*(f) its one-sided error quantum communication complexity with prior\nentanglement, and NQ(f) its nondeterministic quantum communication complexity\n(without prior entanglement; this model is trivial with shared randomness or\nentanglement). Our main results are the following, where logs are to base 2:\n  * If the maximal fooling set is \"upper triangular\" (which is for instance the\ncase for the equality, disjointness, and greater-than functions), then we have\nQ_1^*(f)>=(1/2)log fool^1(f) - 1/2, which is essentially optimal by superdense\ncoding. No super-constant lower bound for equality seems to follow from earlier\ntechniques.\n  * For all f we have Q_1^*(f)>=(1/4)log fool^1(f) - 1/2, which is optimal up\nto a factor of 2.\n  * NQ(f)>=log \\fool^1(f)/2 + 1. We do not know if the factor 1/2 is needed in\nthis result, but it cannot be replaced by 1: we give an example where\nNQ(f)~0.613 log fool^1(f).\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 13:16:00 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2012 09:48:25 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Klauck", "Hartmut", ""], ["de Wolf", "Ronald", ""]]}, {"id": "1204.4659", "submitter": "Michiel de Bondt", "authors": "Michiel de Bondt", "title": "The computational complexity of Minesweeper", "comments": "14 pages, LaTeX => DVI => PS => PDF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Minesweeper game is PP-hard, when the object is to locate\nall mines with the highest probability. When the probability of locating all\nmines may be infinitesimal, the Minesweeper game is even PSPACE-complete. In\nour construction, the player can reveal a boolean circuit in polynomial time,\nafter guessing an initial square with no surrounding mines, a guess that has 99\npercent probability of success. Subsequently, the mines must be located with a\nmaximum probability of success.\n  Furthermore, we show that determining the solvability of a partially\nuncovered Minesweeper board is NP-complete with hexagonal and triangular grids\nas well as a square grid, extending a similar result for square grids only by\nR. Kaye. Actually finding the mines with a maximum probability of success is\nagain PP-hard or PSPACE-complete respectively.\n  Our constructions are in such a way that the number of mines can be computed\nin polynomial time and hence a possible mine counter does not provide\nadditional information. The results are obtained by replacing the dyadic gates\nin [3] by two primitives which makes life more easy in this context.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 15:57:40 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["de Bondt", "Michiel", ""]]}, {"id": "1204.4691", "submitter": "Junichi Teruyama", "authors": "Richard Cleve, Kazuo Iwama, Fran\\c{c}ois Le Gall, Harumichi Nishimura,\n  Seiichiro Tani, Junichi Teruyama, Shigeru Yamashita", "title": "Reconstructing Strings from Substrings with Quantum Queries", "comments": "13 pages", "journal-ref": "Proceedings of 13th Scandinavian Symposium and Workshops\n  (SWAT2012), Lecture Notes in Computer Science 7357, pp. 388-397, 2012", "doi": "10.1007/978-3-642-31155-0_34", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the number of quantum queries made to solve the\nproblem of reconstructing an unknown string from its substrings in a certain\nquery model. More concretely, the goal of the problem is to identify an unknown\nstring $S$ by making queries of the following form: \"Is $s$ a substring of\n$S$?\", where $s$ is a query string over the given alphabet. The number of\nqueries required to identify the string $S$ is the query complexity of this\nproblem.\n  First we show a quantum algorithm that exactly identifies the string $S$ with\nat most $3/4N + o(N)$ queries, where $N$ is the length of $S$. This contrasts\nsharply with the classical query complexity $N$. Our algorithm uses Skiena and\nSundaram's classical algorithm and the Grover search as subroutines. To make\nthem effectively work, we develop another subroutine that finds a string\nappearing only once in $S$, which may have an independent interest. We also\nprove two lower bounds. The first one is a general lower bound of\n$\\Omega(\\frac{N}{\\log^2{N}})$, which means we cannot achieve a query complexity\nof $O(N^{1-\\epsilon})$ for any constant $\\epsilon$. The other one claims that\nif we cannot use queries of length roughly between $\\log N$ and $3 \\log N$,\nthen we cannot achieve a query complexity of any sublinear function in $N$.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 18:13:34 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Cleve", "Richard", ""], ["Iwama", "Kazuo", ""], ["Gall", "Fran\u00e7ois Le", ""], ["Nishimura", "Harumichi", ""], ["Tani", "Seiichiro", ""], ["Teruyama", "Junichi", ""], ["Yamashita", "Shigeru", ""]]}, {"id": "1204.4693", "submitter": "J. M. Landsberg", "authors": "Harlan Kadish and J.M. Landsberg", "title": "Padded polynomials, their cousins, and geometric complexity theory", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish basic facts about the varieties of homogeneous polynomials\ndivisible by powers of linear forms, and explain consequences for geometric\ncomplexity theory. This includes quadratic set-theoretic equations, a\ndescription of the ideal in terms of the kernel of a linear map that\ngeneralizes the Foulkes-Howe map, and an explicit description of the coordinate\nring of the normalization. We also prove asymptotic injectivity of the\nFoulkes-Howe map.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 18:30:50 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["Kadish", "Harlan", ""], ["Landsberg", "J. M.", ""]]}, {"id": "1204.5074", "submitter": "Aleksandrs Belovs", "authors": "Aleksandrs Belovs", "title": "Adversary Lower Bound for Element Distinctness", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we construct an explicit optimal (negative-weight) adversary\nmatrix for the element distinctness problem, given that the size of the\nalphabet is sufficiently large.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2012 14:18:18 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Belovs", "Aleksandrs", ""]]}, {"id": "1204.5224", "submitter": "Martin Lackner", "authors": "Marie-Louise Bruner, Martin Lackner", "title": "A Fast Algorithm for Permutation Pattern Matching Based on Alternating\n  Runs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NP-complete Permutation Pattern Matching problem asks whether a\n$k$-permutation $P$ is contained in a $n$-permutation $T$ as a pattern. This is\nthe case if there exists an order-preserving embedding of $P$ into $T$. In this\npaper, we present a fixed-parameter algorithm solving this problem with a\nworst-case runtime of $\\mathcal{O}(1.79^{\\mathsf{run}(T)}\\cdot n\\cdot k)$,\nwhere $\\mathsf{run}(T)$ denotes the number of alternating runs of $T$. This\nalgorithm is particularly well-suited for instances where $T$ has few runs,\ni.e., few ups and downs. Moreover, since $\\mathsf{run}(T)<n$, this can be seen\nas a $\\mathcal{O}(1.79^{n}\\cdot n\\cdot k)$ algorithm which is the first to beat\nthe exponential $2^n$ runtime of brute-force search. Furthermore, we prove that\nunder standard complexity theoretic assumptions such a fixed-parameter\ntractability result is not possible for $\\mathsf{run}(P)$.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2012 22:46:21 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2015 16:47:42 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Bruner", "Marie-Louise", ""], ["Lackner", "Martin", ""]]}, {"id": "1204.5447", "submitter": "Dara Shayda", "authors": "Dara O. Shayda", "title": "Kolmogorov Complexity, Causality And Spin", "comments": "Higher resolution images available, plus the Mathematica code that\n  generated them", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel topological and computational method for 'motion' is described.\nMotion is constrained by inequalities in terms of Kolmogorov Complexity.\nCausality is obtained as the output of a high-pass filter, passing through only\nhigh values of Kolmogorov Complexity. Motion under the electromagnetic field\ndescribed with immediate relationship with Subscript[G, 2] Holonomy group and\nits corresponding dense free 2-subgroup. Similar to Causality, Spin emerges as\nan immediate and inevitable consequence of high values of Kolmogorov\nComplexity. Consequently, the physical laws are nothing but a low-pass filter\nfor small values of Kolmogorov Complexity.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 17:50:58 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2012 04:13:52 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["Shayda", "Dara O.", ""]]}, {"id": "1204.5508", "submitter": "Stephen Cook", "authors": "Klaus Aehlig, Stephen Cook, Phuong Nguyen", "title": "Relativizing Small Complexity Classes and their Theories", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing definitions of the relativizations of \\NCOne, \\L\\ and \\NL\\ do not\npreserve the inclusions $\\NCOne \\subseteq \\L$, $\\NL\\subseteq \\ACOne$. We start\nby giving the first definitions that preserve them. Here for \\L\\ and \\NL\\ we\ndefine their relativizations using Wilson's stack oracle model, but limit the\nheight of the stack to a constant (instead of $\\log(n)$). We show that the\ncollapse of any two classes in $\\{\\ACZm, \\TCZ, \\NCOne, \\L, \\NL\\}$ implies the\ncollapse of their relativizations. Next we exhibit an oracle $\\alpha$ that\nmakes $\\ACk(\\alpha)$ a proper hierarchy. This strengthens and clarifies the\nseparations of the relativized theories in [Takeuti, 1995]. The idea is that a\ncircuit whose nested depth of oracle gates is bounded by $k$ cannot compute\ncorrectly the $(k+1)$ compositions of every oracle function. Finally we develop\ntheories that characterize the relativizations of subclasses of \\Ptime\\ by\nmodifying theories previously defined by the second two authors. A function is\nprovably total in a theory iff it is in the corresponding relativized class,\nand hence the oracle separations imply separations for the relativized\ntheories.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 22:44:53 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["Aehlig", "Klaus", ""], ["Cook", "Stephen", ""], ["Nguyen", "Phuong", ""]]}, {"id": "1204.5576", "submitter": "YuQian Zhou", "authors": "YuQian Zhou", "title": "Efficient programs of NPC problems should be length upper-bounded, and a\n  thought experiment to search for them by machine enumeration", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a thought experiment to search for efficient bounded\nalgorithms of NPC problems by machine enumeration. The key contributions are:\n  -- On Universal Turing Machines, a program's time complexity should be\ncharacterized as: execution time(n) = loading time(n) + running time(n).\n  -- Introduces the concept of bounded algorithms; proposes a comparison based\ncriterion to decide if a bounded algorithm is inefficient; and establishes the\nlength upper bound of efficient bounded programs.\n  -- Introduces the growth rate characteristic function to evaluate program\ncomplexity, which is more easily machine checkable based on observations.\n  -- Raises the theoretical question: if there exists any bounded algorithm\nwith polynomial execution time for NPC problems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2012 07:20:41 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2012 19:40:09 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Zhou", "YuQian", ""]]}, {"id": "1204.5662", "submitter": "Per Austrin", "authors": "Per Austrin and Johan H{\\aa}stad", "title": "On the Usefulness of Predicates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the pervasiveness of strong inapproximability results for\nMax-CSPs, we introduce a relaxed notion of an approximate solution of a\nMax-CSP. In this relaxed version, loosely speaking, the algorithm is allowed to\nreplace the constraints of an instance by some other (possibly real-valued)\nconstraints, and then only needs to satisfy as many of the new constraints as\npossible.\n  To be more precise, we introduce the following notion of a predicate $P$\nbeing \\emph{useful} for a (real-valued) objective $Q$: given an almost\nsatisfiable Max-$P$ instance, there is an algorithm that beats a random\nassignment on the corresponding Max-$Q$ instance applied to the same sets of\nliterals. The standard notion of a nontrivial approximation algorithm for a\nMax-CSP with predicate $P$ is exactly the same as saying that $P$ is useful for\n$P$ itself.\n  We say that $P$ is useless if it is not useful for any $Q$. This turns out to\nbe equivalent to the following pseudo-randomness property: given an almost\nsatisfiable instance of Max-$P$ it is hard to find an assignment such that the\ninduced distribution on $k$-bit strings defined by the instance is not\nessentially uniform.\n  Under the Unique Games Conjecture, we give a complete and simple\ncharacterization of useful Max-CSPs defined by a predicate: such a Max-CSP is\nuseless if and only if there is a pairwise independent distribution supported\non the satisfying assignments of the predicate. It is natural to also consider\nthe case when no negations are allowed in the CSP instance, and we derive a\nsimilar complete characterization (under the UGC) there as well.\n  Finally, we also include some results and examples shedding additional light\non the approximability of certain Max-CSPs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2012 14:12:06 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["Austrin", "Per", ""], ["H\u00e5stad", "Johan", ""]]}, {"id": "1204.5666", "submitter": "Per Austrin", "authors": "Per Austrin and Ryan O'Donnell and John Wright", "title": "A new point of NP-hardness for 2-to-1 Label Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that given a satisfiable instance of the 2-to-1 Label Cover problem,\nit is NP-hard to find a $(23/24 + \\eps)$-satisfying assignment.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2012 14:20:23 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["Austrin", "Per", ""], ["O'Donnell", "Ryan", ""], ["Wright", "John", ""]]}, {"id": "1204.5714", "submitter": "Colin McQuillan", "authors": "Colin McQuillan", "title": "Degree two approximate Boolean #CSPs with variable weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A counting constraint satisfaction problem (#CSP) asks for the number of ways\nto satisfy a given list of constraints, drawn from a fixed constraint language\n\\Gamma. We study how hard it is to evaluate this number approximately. There is\nan interesting partial classification, due to Dyer, Goldberg, Jalsenius and\nRicherby, of Boolean constraint languages when the degree of instances is\nbounded by d>=3 - every variable appears in at most d constraints - under the\nassumption that \"pinning\" is allowed as part of the instance. We study the d=2\ncase under the stronger assumption that \"variable weights\" are allowed as part\nof the instance. We give a dichotomy: in each case, either the #CSP is\ntractable, or one of two important open problems, #BIS or #PM, reduces to the\n#CSP.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2012 17:40:10 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["McQuillan", "Colin", ""]]}, {"id": "1204.6233", "submitter": "Serge Gaspers", "authors": "Serge Gaspers and Stefan Szeider", "title": "Strong Backdoors to Bounded Treewidth SAT", "comments": "arXiv admin note: substantial text overlap with arXiv:1202.4331", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are various approaches to exploiting \"hidden structure\" in instances of\nhard combinatorial problems to allow faster algorithms than for general\nunstructured or random instances. For SAT and its counting version #SAT, hidden\nstructure has been exploited in terms of decomposability and strong backdoor\nsets. Decomposability can be considered in terms of the treewidth of a graph\nthat is associated with the given CNF formula, for instance by considering\nclauses and variables as vertices of the graph, and making a variable adjacent\nwith all the clauses it appears in. On the other hand, a strong backdoor set of\na CNF formula is a set of variables such that each possible partial assignment\nto this set moves the formula into a fixed class for which (#)SAT can be solved\nin polynomial time.\n  In this paper we combine the two above approaches. In particular, we study\nthe algorithmic question of finding a small strong backdoor set into the class\nW_t of CNF formulas whose associated graphs have treewidth at most t. The main\nresults are positive:\n  (1) There is a cubic-time algorithm that, given a CNF formula F and two\nconstants k,t\\ge 0, either finds a strong W_t-backdoor set of size at most 2^k,\nor concludes that F has no strong W_t-backdoor set of size at most k.\n  (2) There is a cubic-time algorithm that, given a CNF formula F, computes the\nnumber of satisfying assignments of F or concludes that sb_t(F)>k, for any pair\nof constants k,t\\ge 0. Here, sb_t(F) denotes the size of a smallest strong\nW_t-backdoor set of F.\n  The significance of our results lies in the fact that they allow us to\nexploit algorithmically a hidden structure in formulas that is not accessible\nby any one of the two approaches (decomposability, backdoors) alone. Already a\nbackdoor size 1 on top of treewidth 1 (i.e., sb_1(F)=1) entails formulas of\narbitrarily large treewidth and arbitrarily large cycle cutsets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2012 14:51:23 GMT"}], "update_date": "2012-04-30", "authors_parsed": [["Gaspers", "Serge", ""], ["Szeider", "Stefan", ""]]}, {"id": "1204.6291", "submitter": "Michael Elberfeld", "authors": "Michael Elberfeld, Martin Grohe, Till Tantau", "title": "Where First-Order and Monadic Second-Order Logic Coincide", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study on which classes of graphs first-order logic (FO) and monadic\nsecond-order logic (MSO) have the same expressive power. We show that for all\nclasses C of graphs that are closed under taking subgraphs, FO and MSO have the\nsame expressive power on C if, and only if, C has bounded tree depth. Tree\ndepth is a graph invariant that measures the similarity of a graph to a star in\na similar way that tree width measures the similarity of a graph to a tree. For\nclasses just closed under taking induced subgraphs, we show an analogous result\nfor guarded second-order logic (GSO), the variant of MSO that not only allows\nquantification over vertex sets but also over edge sets. A key tool in our\nproof is a Feferman-Vaught-type theorem that is constructive and still works\nfor unbounded partitions.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2012 18:52:15 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Elberfeld", "Michael", ""], ["Grohe", "Martin", ""], ["Tantau", "Till", ""]]}, {"id": "1204.6445", "submitter": "Heng Guo", "authors": "Jin-Yi Cai, Heng Guo and Tyson Williams", "title": "A Complete Dichotomy Rises from the Capture of Vanishing Signatures", "comments": "Author accepted manuscript", "journal-ref": "SIAM J. Comput. 45(5), 1671-1728, 2016", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a complexity dichotomy theorem for Holant problems over an arbitrary\nset of complex-valued symmetric constraint functions F on Boolean variables.\nThis extends and unifies all previous dichotomies for Holant problems on\nsymmetric constraint functions (taking values without a finite modulus). We\ndefine and characterize all symmetric vanishing signatures. They turned out to\nbe essential to the complete classification of Holant problems. The dichotomy\ntheorem has an explicit tractability criterion expressible in terms of\nholographic transformations. A Holant problem defined by a set of constraint\nfunctions F is solvable in polynomial time if it satisfies this tractability\ncriterion, and is #P-hard otherwise. The tractability criterion can be\nintuitively stated as follows: A set F is tractable if (1) every function in F\nhas arity at most two, or (2) F is transformable to an affine type, or (3) F is\ntransformable to a product type, or (4) F is vanishing, combined with the right\ntype of binary functions, or (5) F belongs to a special category of vanishing\ntype Fibonacci gates. The proof of this theorem utilizes many previous\ndichotomy theorems on Holant problems and Boolean #CSP. Holographic\ntransformations play an indispensable role as both a proof technique and in the\nstatement of the tractability criterion.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2012 00:22:39 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2013 13:42:13 GMT"}, {"version": "v3", "created": "Wed, 10 Jan 2018 13:53:53 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Guo", "Heng", ""], ["Williams", "Tyson", ""]]}, {"id": "1204.6484", "submitter": "Shlomo Jozeph", "authors": "Uriel Feige and Shlomo Jozeph", "title": "Universal Factor Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The factor graph of an instance of a symmetric constraint satisfaction\nproblem on n Boolean variables and m constraints (CSPs such as k-SAT, k-AND,\nk-LIN) is a bipartite graph describing which variables appear in which\nconstraints. The factor graph describes the instance up to the polarity of the\nvariables, and hence there are up to 2km instances of the CSP that share the\nsame factor graph. It is well known that factor graphs with certain structural\nproperties make the underlying CSP easier to either solve exactly (e.g., for\ntree structures) or approximately (e.g., for planar structures). We are\ninterested in the following question: is there a factor graph for which if one\ncan solve every instance of the CSP with this particular factor graph, then one\ncan solve every instance of the CSP regardless of the factor graph (and\nsimilarly, for approximation)? We call such a factor graph universal. As one\nneeds different factor graphs for different values of n and m, this gives rise\nto the notion of a family of universal factor graphs. We initiate a systematic\nstudy of universal factor graphs, and present some results for max-kSAT. Our\nwork has connections with the notion of preprocessing as previously studied for\nclosest codeword and closest lattice-vector problems, with proofs for the PCP\ntheorem, and with tests for the long code. Many questions remain open.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2012 15:05:40 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Feige", "Uriel", ""], ["Jozeph", "Shlomo", ""]]}, {"id": "1204.6588", "submitter": "Nir Ailon", "authors": "Nir Ailon and Zohar Karnin", "title": "A note on: No need to choose: How to get both a PTAS and Sublinear Query\n  Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit various PTAS's (Polynomial Time Approximation Schemes) for\nminimization versions of dense problems, and show that they can be performed\nwith sublinear query complexity. This means that not only do we obtain a\n(1+eps)-approximation to the NP-Hard problems in polynomial time, but also\navoid reading the entire input. This setting is particularly advantageous when\nthe price of reading parts of the input is high, as is the case, for examples,\nwhere humans provide the input. Trading off query complexity with approximation\nis the raison d'etre of the field of learning theory, and of the ERM (Empirical\nRisk Minimization) setting in particular. A typical ERM result, however, does\nnot deal with computational complexity. We discuss two particular problems for\nwhich (a) it has already been shown that sublinear querying is sufficient for\nobtaining a (1 + eps)-approximation using unlimited computational power (an ERM\nresult), and (b) with full access to input, we could get a\n(1+eps)-approximation in polynomial time (a PTAS). Here we show that neither\nbenefit need be sacrificed. We get a PTAS with efficient query complexity.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2012 10:34:58 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Ailon", "Nir", ""], ["Karnin", "Zohar", ""]]}, {"id": "1204.6696", "submitter": "Marius Zimand", "authors": "Marius Zimand", "title": "Nonuniform Kolmogorov extractors", "comments": "This is a part of the conference paper from CCC 2011. It corrects an\n  erroneus result from there, namely Theorem 4.8 (the new version has weaker\n  parameters)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish tight bounds on the amount on nonuniformity that is necessary\nfor extracting a string with randomness rate 1 from a single source of\nrandomness with lower randomness rate. More precisely, as instantiations of\nmore general results, we show that while O(1) amount of advice regarding the\nsource is not enough for extracting a string with randomness rate 1 from a\nsource string with constant subunitary random rate, \\omega(1) amount of advice\nis.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2012 16:42:34 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Zimand", "Marius", ""]]}]