[{"id": "0901.0373", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM, Lip)", "title": "Highly Undecidable Problems For Infinite Computations", "comments": "to appear in RAIRO-Theoretical Informatics and Applications", "journal-ref": "RAIRO - Theoretical Informatics and Applications 43, 2 (2009)\n  339-364", "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that many classical decision problems about 1-counter\nomega-languages, context free omega-languages, or infinitary rational\nrelations, are $\\Pi_2^1$-complete, hence located at the second level of the\nanalytical hierarchy, and \"highly undecidable\". In particular, the universality\nproblem, the inclusion problem, the equivalence problem, the determinizability\nproblem, the complementability problem, and the unambiguity problem are all\n$\\Pi_2^1$-complete for context-free omega-languages or for infinitary rational\nrelations. Topological and arithmetical properties of 1-counter\nomega-languages, context free omega-languages, or infinitary rational\nrelations, are also highly undecidable. These very surprising results provide\nthe first examples of highly undecidable problems about the behaviour of very\nsimple finite machines like 1-counter automata or 2-tape automata.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jan 2009 13:13:32 GMT"}], "update_date": "2009-08-04", "authors_parsed": [["Finkel", "Olivier", "", "ELM, Lip"]]}, {"id": "0901.0858", "submitter": "Vadim E. Levit", "authors": "Vadim E. Levit and David Tankus", "title": "Weighted Well-Covered Graphs without Cycles of Length 4, 5, 6 and 7", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is well-covered if every maximal independent set has the same\ncardinality. The recognition problem of well-covered graphs is known to be\nco-NP-complete. Let w be a weight function defined on the vertices of G. Then G\nis w-well-covered if all maximal independent sets of G are of the same weight.\nThe set of weight functions w for which a graph is w-well-covered is a vector\nspace. We prove that finding the vector space of weight functions under which\nan input graph is w-well-covered can be done in polynomial time, if the input\ngraph does not contain cycles of length 4, 5, 6 and 7.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2009 16:09:49 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2009 12:46:08 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2009 13:34:05 GMT"}, {"version": "v4", "created": "Thu, 16 Sep 2010 14:44:12 GMT"}], "update_date": "2010-09-17", "authors_parsed": [["Levit", "Vadim E.", ""], ["Tankus", "David", ""]]}, {"id": "0901.1230", "submitter": "Leslie De Koninck", "authors": "Leslie De Koninck", "title": "Logical Algorithms meets CHR: A meta-complexity result for Constraint\n  Handling Rules with rule priorities", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the relationship between the Logical Algorithms\nlanguage (LA) of Ganzinger and McAllester and Constraint Handling Rules (CHR).\nWe present a translation schema from LA to CHR-rp: CHR with rule priorities,\nand show that the meta-complexity theorem for LA can be applied to a subset of\nCHR-rp via inverse translation. Inspired by the high-level implementation\nproposal for Logical Algorithm by Ganzinger and McAllester and based on a new\nscheduling algorithm, we propose an alternative implementation for CHR-rp that\ngives strong complexity guarantees and results in a new and accurate\nmeta-complexity theorem for CHR-rp. It is furthermore shown that the\ntranslation from Logical Algorithms to CHR-rp combined with the new CHR-rp\nimplementation, satisfies the required complexity for the Logical Algorithms\nmeta-complexity result to hold.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2009 12:37:32 GMT"}], "update_date": "2009-01-12", "authors_parsed": [["De Koninck", "Leslie", ""]]}, {"id": "0901.1427", "submitter": "Sourav Chakraborty", "authors": "Sourav Chakraborty, Nikhil Devanur", "title": "An Online Multi-unit Auction with Improved Competitive Ratio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the best known competitive ratio (from 1/4 to 1/2), for the online\nmulti-unit allocation problem, where the objective is to maximize the\nsingle-price revenue. Moreover, the competitive ratio of our algorithm tends to\n1, as the bid-profile tends to ``smoothen''. This algorithm is used as a\nsubroutine in designing truthful auctions for the same setting: the allocation\nhas to be done online, while the payments can be decided at the end of the day.\nEarlier, a reduction from the auction design problem to the allocation problem\nwas known only for the unit-demand case. We give a reduction for the general\ncase when the bidders have decreasing marginal utilities. The problem is\ninspired by sponsored search auctions.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jan 2009 10:00:38 GMT"}], "update_date": "2009-01-13", "authors_parsed": [["Chakraborty", "Sourav", ""], ["Devanur", "Nikhil", ""]]}, {"id": "0901.1849", "submitter": "David Doty", "authors": "David Doty", "title": "Randomized Self-Assembly for Exact Shapes", "comments": "Conference version accepted to FOCS 2009. Present version accepted to\n  SIAM Journal on Computing, which adds new sections on arbitrary scaled\n  shapes, smooth trade-off between specifying bits of n through concentrations\n  versus hardcoded tile types, and construction that uses concentrations\n  arbitrarily close to uniform to fix potential thermodynamic problems with\n  model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working in Winfree's abstract tile assembly model, we show that a\nconstant-size tile assembly system can be programmed through relative tile\nconcentrations to build an n x n square with high probability, for any\nsufficiently large n. This answers an open question of Kao and Schweller\n(Randomized Self-Assembly for Approximate Shapes, ICALP 2008), who showed how\nto build an approximately n x n square using tile concentration programming,\nand asked whether the approximation could be made exact with high probability.\nWe show how this technique can be modified to answer another question of Kao\nand Schweller, by showing that a constant-size tile assembly system can be\nprogrammed through tile concentrations to assemble arbitrary finite *scaled\nshapes*, which are shapes modified by replacing each point with a c x c block\nof points, for some integer c. Furthermore, we exhibit a smooth tradeoff\nbetween specifying bits of n via tile concentrations versus specifying them via\nhard-coded tile types, which allows tile concentration programming to be\nemployed for specifying a fraction of the bits of \"input\" to a tile assembly\nsystem, under the constraint that concentrations can only be specified to a\nlimited precision. Finally, to account for some unrealistic aspects of the tile\nconcentration programming model, we show how to modify the construction to use\nonly concentrations that are arbitrarily close to uniform.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2009 20:55:01 GMT"}, {"version": "v2", "created": "Wed, 14 Jan 2009 20:06:49 GMT"}, {"version": "v3", "created": "Fri, 27 Feb 2009 05:57:06 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2009 18:10:14 GMT"}, {"version": "v5", "created": "Mon, 5 Oct 2009 20:16:03 GMT"}, {"version": "v6", "created": "Fri, 16 Jul 2010 18:24:31 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Doty", "David", ""]]}, {"id": "0901.2068", "submitter": "Ji\\v{r}\\'i Srba", "authors": "Ji\\v{r}\\'i Srba", "title": "Beyond Language Equivalence on Visibly Pushdown Automata", "comments": "Final version of paper, accepted by LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 1 (January\n  26, 2009) lmcs:756", "doi": "10.2168/LMCS-5(1:2)2009", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study (bi)simulation-like preorder/equivalence checking on the class of\nvisibly pushdown automata and its natural subclasses visibly BPA (Basic Process\nAlgebra) and visibly one-counter automata. We describe generic methods for\nproving complexity upper and lower bounds for a number of studied preorders and\nequivalences like simulation, completed simulation, ready simulation, 2-nested\nsimulation preorders/equivalences and bisimulation equivalence. Our main\nresults are that all the mentioned equivalences and preorders are\nEXPTIME-complete on visibly pushdown automata, PSPACE-complete on visibly\none-counter automata and P-complete on visibly BPA. Our PSPACE lower bound for\nvisibly one-counter automata improves also the previously known DP-hardness\nresults for ordinary one-counter automata and one-counter nets. Finally, we\nstudy regularity checking problems for visibly pushdown automata and show that\nthey can be decided in polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2009 17:28:17 GMT"}, {"version": "v2", "created": "Mon, 26 Jan 2009 10:16:05 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Srba", "Ji\u0159\u00ed", ""]]}, {"id": "0901.2130", "submitter": "Lenka Zdeborova", "authors": "Florent Krzakala and Lenka Zdeborov\\'a", "title": "Hiding Quiet Solutions in Random Constraint Satisfaction Problems", "comments": "4 pages, 3 figures", "journal-ref": "Phys. Rev. Lett. 102, 238701 (2009)", "doi": "10.1103/PhysRevLett.102.238701", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study constraint satisfaction problems on the so-called 'planted' random\nensemble. We show that for a certain class of problems, e.g. graph coloring,\nmany of the properties of the usual random ensemble are quantitatively\nidentical in the planted random ensemble. We study the structural phase\ntransitions, and the easy/hard/easy pattern in the average computational\ncomplexity. We also discuss the finite temperature phase diagram, finding a\nclose connection with the liquid/glass/solid phenomenology.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2009 21:47:05 GMT"}, {"version": "v2", "created": "Wed, 27 May 2009 18:32:00 GMT"}], "update_date": "2009-06-13", "authors_parsed": [["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "0901.2703", "submitter": "Abuzer Yakaryilmaz", "authors": "Abuzer Yakaryilmaz and A. C. Cem Say", "title": "Language recognition by generalized quantum finite automata with\n  unbounded error (abstract & poster)", "comments": "2 pages, poster presented at the 4th Workshop on Theory of Quantum\n  Computation, Communication, and Cryptography (TQC2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we generalize the results of arXiv:0901.2703v1 We show that all\none-way quantum finite automaton (QFA) models that are at least as general as\nKondacs-Watrous QFA's are equivalent in power to classical probabilistic finite\nautomata in this setting. Unlike their probabilistic counterparts, allowing the\ntape head to stay put for some steps during its traversal of the input does\nenlarge the class of languages recognized by such QFA's with unbounded error.\n(Note that, the proof of Theorem 1 in the abstract was presented in the\nprevious version (arXiv:0901.2703v1).)\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2009 13:33:21 GMT"}, {"version": "v2", "created": "Fri, 17 Sep 2010 09:50:03 GMT"}], "update_date": "2010-09-20", "authors_parsed": [["Yakaryilmaz", "Abuzer", ""], ["Say", "A. C. Cem", ""]]}, {"id": "0901.2903", "submitter": "Andre Souto", "authors": "Andreia Teixeira, Andre Souto, Armando Matos, Luis Antunes", "title": "Entropy Measures vs. Algorithmic Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic entropy and Shannon entropy are two conceptually different\ninformation measures, as the former is based on size of programs and the later\nin probability distributions. However, it is known that, for any recursive\nprobability distribution, the expected value of algorithmic entropy equals its\nShannon entropy, up to a constant that depends only on the distribution. We\nstudy if a similar relationship holds for R\\'{e}nyi and Tsallis entropies of\norder $\\alpha$, showing that it only holds for R\\'{e}nyi and Tsallis entropies\nof order 1 (i.e., for Shannon entropy). Regarding a time bounded analogue\nrelationship, we show that, for distributions such that the cumulative\nprobability distribution is computable in time $t(n)$, the expected value of\ntime-bounded algorithmic entropy (where the alloted time is $nt(n)\\log\n(nt(n))$) is in the same range as the unbounded version. So, for these\ndistributions, Shannon entropy captures the notion of computationally\naccessible information. We prove that, for universal time-bounded distribution\n$\\m^t(x)$, Tsallis and R\\'{e}nyi entropies converge if and only if $\\alpha$ is\ngreater than 1.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2009 17:45:39 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2010 15:25:33 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Teixeira", "Andreia", ""], ["Souto", "Andre", ""], ["Matos", "Armando", ""], ["Antunes", "Luis", ""]]}, {"id": "0901.2906", "submitter": "Andre Souto", "authors": "Armando Matos, Andreia Teixeira, Andre Souto", "title": "Measuring communication complexity using instance complexity with\n  oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a connection between non-deterministic communication complexity\nand instance complexity, a measure of information based on algorithmic entropy.\nLet $\\overline{x}$, $\\overline{y}$ and $Y_1(\\overline{x})$ be respectively the\ninput known by Alice, the input known by Bob, and the set of all values of $y$\nsuch that $f(\\overline{x},y)=1$; a string is a witness of the non-deterministic\ncommunication protocol iff it is a program $p$ that \"corresponds exactly\" to\nthe instance complexity $\\ic^{f,t}(\\overline{y}:Y_1(\\overline{x}))$.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2009 18:00:37 GMT"}], "update_date": "2009-01-20", "authors_parsed": [["Matos", "Armando", ""], ["Teixeira", "Andreia", ""], ["Souto", "Andre", ""]]}, {"id": "0901.2954", "submitter": "Kenichi Horie", "authors": "Kenichi Horie", "title": "An Upper Limit of AC Huffman Code Length in JPEG Compression", "comments": "US patent application 11/947936", "journal-ref": null, "doi": null, "report-no": "OIMC07P03556", "categories": "cs.IT cs.CC cs.CE cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A strategy for computing upper code-length limits of AC Huffman codes for an\n8x8 block in JPEG Baseline coding is developed. The method is based on a\ngeometric interpretation of the DCT, and the calculated limits are as close as\n14% to the maximum code-lengths. The proposed strategy can be adapted to other\ntransform coding methods, e.g., MPEG 2 and 4 video compressions, to calculate\nclose upper code length limits for the respective processing blocks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2009 23:19:00 GMT"}], "update_date": "2009-01-21", "authors_parsed": [["Horie", "Kenichi", ""]]}, {"id": "0901.3615", "submitter": "Xiaofei Huang", "authors": "Xiaofei Huang", "title": "A Constructive Generalization of Nash Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a society of multiple individuals, if everybody is only interested in\nmaximizing his own payoff, will there exist any equilibrium for the society?\nJohn Nash proved more than 50 years ago that an equilibrium always exists such\nthat nobody would benefit from unilaterally changing his strategy. Nash\nEquilibrium is a central concept in game theory, which offers the mathematical\nfoundation for social science and economy. However, the original definition is\ndeclarative without including a solution to find them. It has been found later\nthat it is computationally difficult to find a Nash equilibrium. Furthermore, a\nNash equilibrium may be unstable, sensitive to the smallest variation of payoff\nfunctions. Making the situation worse, a society with selfish individuals can\nhave an enormous number of equilibria, making it extremely hard to find out the\nglobal optimal one. This paper offers a constructive generalization of Nash\nequilibrium to cover the case when the selfishness of individuals are reduced\nto lower levels in a controllable way. It shows that the society has one and\nonly one equilibrium when the selfishness is reduced to a certain level. When\nevery individual follows the iterative, soft-decision optimization process\npresented in this paper, the society converges to the unique equilibrium with\nan exponential rate under any initial conditions. When it is a consensus\nequilibrium at the same time, it must be the global optimum. The study of this\npaper suggests that, to build a good, stable society (including the financial\nmarket) for the benefit everyone in it, the pursuing of maximal payoff by each\nindividual should be controlled at some level either by voluntary good\ncitizenship or some proper regulations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 07:40:36 GMT"}], "update_date": "2009-01-26", "authors_parsed": [["Huang", "Xiaofei", ""]]}, {"id": "0901.3692", "submitter": "Dorothea Baumeister", "authors": "Dorothea Baumeister, Felix Brandt, Felix Fischer, Jan Hoffmann, Joerg\n  Rothe", "title": "The Complexity of Computing Minimal Unidirectional Covering Sets", "comments": "27 pages, 7 figures", "journal-ref": "Theory of Computing Systems 53(3), 2012", "doi": "10.1007/s00224-012-9437-9", "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a binary dominance relation on a set of alternatives, a common thread\nin the social sciences is to identify subsets of alternatives that satisfy\ncertain notions of stability. Examples can be found in areas as diverse as\nvoting theory, game theory, and argumentation theory. Brandt and Fischer [BF08]\nproved that it is NP-hard to decide whether an alternative is contained in some\ninclusion-minimal upward or downward covering set. For both problems, we raise\nthis lower bound to the Theta_{2}^{p} level of the polynomial hierarchy and\nprovide a Sigma_{2}^{p} upper bound. Relatedly, we show that a variety of other\nnatural problems regarding minimal or minimum-size covering sets are hard or\ncomplete for either of NP, coNP, and Theta_{2}^{p}. An important consequence of\nour results is that neither minimal upward nor minimal downward covering sets\n(even when guaranteed to exist) can be computed in polynomial time unless P=NP.\nThis sharply contrasts with Brandt and Fischer's result that minimal\nbidirectional covering sets (i.e., sets that are both minimal upward and\nminimal downward covering sets) are polynomial-time computable.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 14:29:21 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2009 09:21:45 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2009 19:43:20 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Baumeister", "Dorothea", ""], ["Brandt", "Felix", ""], ["Fischer", "Felix", ""], ["Hoffmann", "Jan", ""], ["Rothe", "Joerg", ""]]}, {"id": "0901.3761", "submitter": "Jeffrey Shallit", "authors": "J. Brzozowski, E. Grant, J. Shallit", "title": "Closures in Formal Languages and Kuratowski's Theorem", "comments": "submitted to DLT 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A famous theorem of Kuratowski states that in a topological space, at most 14\ndistinct sets can be produced by repeatedly applying the operations of closure\nand complement to a given set. We re-examine this theorem in the setting of\nformal languages, where closure is either Kleene closure or positive closure.\nWe classify languages according to the structure of the algebra they generate\nunder iterations of complement and closure. We show that there are precisely 9\nsuch algebras in the case of positive closure, and 12 in the case of Kleene\nclosure.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 19:45:01 GMT"}], "update_date": "2009-04-15", "authors_parsed": [["Brzozowski", "J.", ""], ["Grant", "E.", ""], ["Shallit", "J.", ""]]}, {"id": "0901.3763", "submitter": "Jeffrey Shallit", "authors": "J. Brzozowski, E. Grant, J. Shallit", "title": "Closures in Formal Languages: Concatenation, Separation, and Algorithms", "comments": "submitted to DLT 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue our study of open and closed languages. We investigate how the\nproperties of being open and closed are preserved under concatenation. We\ninvestigate analogues, in formal languages, of the separation axioms in\ntopological spaces; one of our main results is that there is a clopen partition\nseparating two words if and only if the words commute. We show that we can\ndecide in quadratic time if the language specified by a DFA is closed, but if\nthe language is specified by an NFA, the problem is PSPACE-complete.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 19:51:41 GMT"}], "update_date": "2009-04-12", "authors_parsed": [["Brzozowski", "J.", ""], ["Grant", "E.", ""], ["Shallit", "J.", ""]]}, {"id": "0901.3828", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM)", "title": "On Recognizable Languages of Infinite Pictures", "comments": "An erratum is added at the end of the paper: The supremum of the set\n  of Borel ranks of B\\\"uchi recognizable languages of infinite pictures is not\n  the first non recursive ordinal $\\omega_1^{CK}$ but an ordinal $\\gamma^1_2$\n  which is strictly greater than the ordinal $\\omega_1^{CK}$. This follows from\n  a result proved by Kechris, Marker and Sami (JSL 1989)", "journal-ref": "International Journal of Foundations of Computer Science 15, 6\n  (2004) 823-840", "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, Altenbernd, Thomas and W\\\"ohrle have considered acceptance\nof languages of infinite two-dimensional words (infinite pictures) by finite\ntiling systems, with the usual acceptance conditions, such as the B\\\"uchi and\nMuller ones, firstly used for infinite words. The authors asked for comparing\nthe tiling system acceptance with an acceptance of pictures row by row using an\nautomaton model over ordinal words of length $\\omega^2$. We give in this paper\na solution to this problem, showing that all languages of infinite pictures\nwhich are accepted row by row by B\\\"uchi or Choueka automata reading words of\nlength $\\omega^2$ are B\\\"uchi recognized by a finite tiling system, but the\nconverse is not true. We give also the answer to two other questions which were\nraised by Altenbernd, Thomas and W\\\"ohrle, showing that it is undecidable\nwhether a B\\\"uchi recognizable language of infinite pictures is E-recognizable\n(respectively, A-recognizable).\n", "versions": [{"version": "v1", "created": "Sat, 24 Jan 2009 12:09:35 GMT"}], "update_date": "2009-01-27", "authors_parsed": [["Finkel", "Olivier", "", "ELM"]]}, {"id": "0901.4023", "submitter": "Boris Ryabko", "authors": "Boris Ryabko, Daniil Ryabko", "title": "Using Kolmogorov Complexity for Understanding Some Limitations on\n  Steganography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently perfectly secure steganographic systems have been described for a\nwide class of sources of covertexts. The speed of transmission of secret\ninformation for these stegosystems is proportional to the length of the\ncovertext. In this work we show that there are sources of covertexts for which\nsuch stegosystems do not exist. The key observation is that if the set of\npossible covertexts has a maximal Kolmogorov complexity, then a high-speed\nperfect stegosystem has to have complexity of the same order.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2009 15:28:02 GMT"}], "update_date": "2009-01-27", "authors_parsed": [["Ryabko", "Boris", ""], ["Ryabko", "Daniil", ""]]}, {"id": "0901.4400", "submitter": "J. Maurice Rojas", "authors": "Frederic Bihan, J. Maurice Rojas, Casey Stella", "title": "Faster Real Feasibility via Circuit Discriminants", "comments": "12 pages in double column ACM format. Submitted to a conference.\n  Significantly improves and simplifies the algorithms and complexity lower\n  bounds of arXiv:math/0411107 . Also presents a new complexity lower bound for\n  A-discriminants. This version fixes many annoying typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that detecting real roots for honestly n-variate (n+2)-nomials (with\ninteger exponents and coefficients) can be done in time polynomial in the\nsparse encoding for any fixed n. The best previous complexity bounds were\nexponential in the sparse encoding, even for n fixed. We then give a\ncharacterization of those functions k(n) such that the complexity of detecting\nreal roots for n-variate (n+k(n))-nomials transitions from P to NP-hardness as\nn tends to infinity. Our proofs follow in large part from a new complexity\nthreshold for deciding the vanishing of A-discriminants of n-variate\n(n+k(n))-nomials. Diophantine approximation, through linear forms in\nlogarithms, also arises as a key tool.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2009 05:15:07 GMT"}, {"version": "v2", "created": "Thu, 29 Jan 2009 03:26:58 GMT"}], "update_date": "2013-09-09", "authors_parsed": [["Bihan", "Frederic", ""], ["Rojas", "J. Maurice", ""], ["Stella", "Casey", ""]]}]