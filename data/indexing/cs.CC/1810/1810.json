[{"id": "1810.00029", "submitter": "Eduardo Laber", "authors": "Eduardo Sany Laber and Lucas Murtinho", "title": "Minimization of Gini impurity via connections with the k-means problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gini impurity is one of the measures used to select attribute in Decision\nTrees/Random Forest construction. In this note we discuss connections between\nthe problem of computing the partition with minimum Weighted Gini impurity and\nthe $k$-means clustering problem. Based on these connections we show that the\ncomputation of the partition with minimum Weighted Gini is a NP-Complete\nproblem and we also discuss how to obtain new algorithms with provable\napproximation for the Gini Minimization problem.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:26:43 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Laber", "Eduardo Sany", ""], ["Murtinho", "Lucas", ""]]}, {"id": "1810.00481", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam, Sourav Chakraborty, Troy Lee, Manaswi\n  Paraashar and Ronald de Wolf", "title": "Two new results about quantum exact learning", "comments": "v3: 21 pages. Small corrections and clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two new results about exact learning by quantum computers. First,\nwe show how to exactly learn a $k$-Fourier-sparse $n$-bit Boolean function from\n$O(k^{1.5}(\\log k)^2)$ uniform quantum examples for that function. This\nimproves over the bound of $\\widetilde{\\Theta}(kn)$ uniformly random classical\nexamples (Haviv and Regev, CCC'15). Our main tool is an improvement of Chang's\nlemma for the special case of sparse functions. Second, we show that if a\nconcept class $\\mathcal{C}$ can be exactly learned using $Q$ quantum membership\nqueries, then it can also be learned using $O\\left(\\frac{Q^2}{\\log\nQ}\\log|\\mathcal{C}|\\right)$ classical membership queries. This improves the\nprevious-best simulation result (Servedio and Gortler, SICOMP'04) by a $\\log\nQ$-factor.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 22:54:58 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 14:24:59 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 15:09:26 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Chakraborty", "Sourav", ""], ["Lee", "Troy", ""], ["Paraashar", "Manaswi", ""], ["de Wolf", "Ronald", ""]]}, {"id": "1810.00529", "submitter": "Bhadrachalam Chitturi", "authors": "Bhadrachalam Chitturi and Jayakumar Pai", "title": "Minimum-Link Rectilinear Covering Tour is NP-hard in $R^{4}$", "comments": "8 pages. 1 Table 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $P$ of $n$ points in $R^{d}$, a tour is a closed simple path that\ncovers all the given points, i.e. a Hamiltonian cycle. % In $P$ if no three\npoints are collinear then the points are said to be in general position. A\n\\textit{link} is a line segment connecting two points and a rectilinear link is\nparallel to one of the axes. The problems of defining a path and a tour with\nminimum number of links, also known as Minimum-Link Covering Path and\nMinimum-Link Covering Tour respectively are proven to be NP-hard in $R^2$. The\ncorresponding rectilinear versions are also NP-hard in $R^2$.\n  A set of points is said to be in \\textit{general position} for rectilinear\nversions of the problems if no two points share any coordinate. We call a set\nof points in $R^{d}$ to be in \\textit{relaxed general position} if no three\npoints share any coordinate and any two points can share at most one\ncoordinate. That is, if the points are either in general position or in relaxed\ngeneral position then an axis parallel line can contain at most one point. If\npoints are in relaxed general position then these problems are NP-hard in\n$R^{10}$. We prove that these two problems are in fact NP-hard in $R^{4}$. If\npoints in $R^{d},~d>1$ are in general position then the time complexities of\nthese problems, both basic and rectilinear versions, are unknown.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 04:54:57 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Chitturi", "Bhadrachalam", ""], ["Pai", "Jayakumar", ""]]}, {"id": "1810.00875", "submitter": "Matthew Delacorte", "authors": "M. Delacorte", "title": "Solving 3SAT By Reduction To Testing For Odd Hole", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm is given for finding the solutions to 3SAT problems. The\nalgorithm uses Bienstock's reduction from 3SAT to existence of induced odd\ncycle of length greater than three, passing through a prescribed node in the\nconstructed graph. The algorithm proceeds to find what will be called the hole\ncomplexes of the graph. The set of the boundary nodes of the hole complex\ncontaining the prescribed node is then searched for the subsets of 8 nodes\ncorresponding to the 3SAT's literals. If a complete set of literals is\ncontained in the boundary then the 3SAT is solvable.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:43:27 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Delacorte", "M.", ""]]}, {"id": "1810.00876", "submitter": "Matthew Delacorte", "authors": "M. Delacorte", "title": "Graph Isomorphism by Conversion to Chordal (6, 3) Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Babel has shown that for an extended class of chordal (6, 3) graphs the\ncoarsest regular simplicial partition is equivalent to the graph's automorphism\npartition. We give a reversible transformation for any graph to one of these\ngraph by using Booth's reduction of a graph to a chordal graph and elimination\nof Babel's forbidden subgraphs for these graphs by adding edges to them.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:43:38 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Delacorte", "M.", ""]]}, {"id": "1810.01111", "submitter": "Jonathan Noel", "authors": "Jae-Baek Lee and Jonathan A. Noel and Mark Siggers", "title": "Reconfiguring Graph Homomorphisms on the Sphere", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a loop-free graph $H$, the reconfiguration problem for homomorphisms to\n$H$ (also called $H$-colourings) asks: given two $H$-colourings $f$ of $g$ of a\ngraph $G$, is it possible to transform $f$ into $g$ by a sequence of\nsingle-vertex colour changes such that every intermediate mapping is an\n$H$-colouring? This problem is known to be polynomial-time solvable for a wide\nvariety of graphs $H$ (e.g. all $C_4$-free graphs) but only a handful of hard\ncases are known. We prove that this problem is PSPACE-complete whenever $H$ is\na $K_{2,3}$-free quadrangulation of the $2$-sphere (equivalently, the plane)\nwhich is not a $4$-cycle. From this result, we deduce an analogous statement\nfor non-bipartite $K_{2,3}$-free quadrangulations of the projective plane. This\ninclude several interesting classes of graphs, such as odd wheels, for which\nthe complexity was known, and $4$-chromatic generalized Mycielski graphs, for\nwhich it was not.\n  If we instead consider graphs $G$ and $H$ with loops on every vertex (i.e.\nreflexive graphs), then the reconfiguration problem is defined in a similar way\nexcept that a vertex can only change its colour to a neighbour of its current\ncolour. In this setting, we use similar ideas to show that the reconfiguration\nproblem for $H$-colourings is PSPACE-complete whenever $H$ is a reflexive\n$K_{4}$-free triangulation of the $2$-sphere which is not a reflexive triangle.\nThis proof applies more generally to reflexive graphs which, roughly speaking,\nresemble a triangulation locally around a particular vertex. This provides the\nfirst graphs for which $H$-Recolouring is known to be PSPACE-complete for\nreflexive instances.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:28:44 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 23:26:32 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Lee", "Jae-Baek", ""], ["Noel", "Jonathan A.", ""], ["Siggers", "Mark", ""]]}, {"id": "1810.01166", "submitter": "Li Yu", "authors": "Li Yu", "title": "A quantum homomorphic encryption scheme for polynomial-sized circuits", "comments": "29 pages, 2 figures. Revised Section VIII, among other minor fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum homomorphic encryption (QHE) is an encryption method that allows\nquantum computation to be performed on one party's private data with the\nprogram provided by another party, without revealing much information about the\ndata nor about the program to the opposite party. It is known that\ninformation-theoretically-secure QHE for circuits of unrestricted size would\nrequire exponential resources, and efficient computationally-secure QHE schemes\nfor polynomial-sized quantum circuits have been constructed. In this paper we\nfirst propose a QHE scheme for a type of circuits of polynomial depth, based on\nthe rebit quantum computation formalism. The scheme keeps the restricted type\nof data perfectly secure. We then propose a QHE scheme for a larger class of\npolynomial-depth quantum circuits, which has partial data privacy. Both schemes\nhave good circuit privacy. We also propose an interactive QHE scheme with\nasymptotic data privacy, however, the circuit privacy is not good, in the sense\nthat the party who provides the data could cheat and learn about the circuit.\nWe show that such cheating would generally affect the correctness of the\nevaluation or cause deviation from the protocol. Hence the cheating can be\ncaught by the opposite party in an interactive scheme with embedded\nverifications. Such scheme with verification has a minor drawback in data\nprivacy. Finally, we show some methods which achieve some nontrivial level of\ndata privacy and circuit privacy without resorting to allowing early\nterminations, in both the QHE problem and in secure evaluation of classical\nfunctions. The entanglement and classical communication costs in these schemes\nare polynomial in the circuit size and the security parameter (if any).\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 10:38:32 GMT"}, {"version": "v10", "created": "Mon, 26 Nov 2018 10:44:40 GMT"}, {"version": "v11", "created": "Tue, 11 Dec 2018 15:11:28 GMT"}, {"version": "v12", "created": "Thu, 13 Dec 2018 18:44:45 GMT"}, {"version": "v13", "created": "Wed, 26 Dec 2018 12:10:55 GMT"}, {"version": "v14", "created": "Tue, 5 Feb 2019 15:54:01 GMT"}, {"version": "v15", "created": "Mon, 4 Mar 2019 02:43:27 GMT"}, {"version": "v16", "created": "Thu, 4 Apr 2019 16:21:48 GMT"}, {"version": "v17", "created": "Sun, 5 May 2019 16:20:57 GMT"}, {"version": "v18", "created": "Mon, 3 Jun 2019 14:44:46 GMT"}, {"version": "v19", "created": "Tue, 9 Jul 2019 14:09:19 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 17:48:37 GMT"}, {"version": "v20", "created": "Thu, 1 Aug 2019 17:55:11 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 16:09:20 GMT"}, {"version": "v4", "created": "Wed, 17 Oct 2018 16:44:17 GMT"}, {"version": "v5", "created": "Mon, 29 Oct 2018 16:23:18 GMT"}, {"version": "v6", "created": "Thu, 1 Nov 2018 11:46:07 GMT"}, {"version": "v7", "created": "Mon, 5 Nov 2018 15:45:04 GMT"}, {"version": "v8", "created": "Mon, 12 Nov 2018 16:40:08 GMT"}, {"version": "v9", "created": "Mon, 19 Nov 2018 17:57:19 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Yu", "Li", ""]]}, {"id": "1810.01223", "submitter": "Max A. Deppert", "authors": "Max A. Deppert, Klaus Jansen", "title": "Near-Linear Approximation Algorithms for Scheduling Problems with Batch\n  Setup Times", "comments": null, "journal-ref": null, "doi": "10.1145/3323165.3323200", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the scheduling of $n$ jobs divided into $c$ classes on $m$\nidentical parallel machines. For every class there is a setup time which is\nrequired whenever a machine switches from the processing of one class to\nanother class. The objective is to find a schedule that minimizes the makespan.\nWe give near-linear approximation algorithms for the following problem\nvariants: the non-preemptive context where jobs may not be preempted, the\npreemptive context where jobs may be preempted but not parallelized, as well as\nthe splittable context where jobs may be preempted and parallelized.\n  We present the first algorithm improving the previously best approximation\nratio of $2$ to a better ratio of $3/2$ in the preemptive case. In more detail,\nfor all three flavors we present an approximation ratio $2$ with running time\n$\\mathcal{O}(n)$, ratio $3/2+\\varepsilon$ in time $\\mathcal{O}(n\\log\n1/\\varepsilon)$ as well as a ratio of $3/2$. The $(3/2)$-approximate algorithms\nhave different running times. In the non-preemptive case we get time\n$\\mathcal{O}(n\\log (n+\\Delta))$ where $\\Delta$ is the largest value of the\ninput. The splittable approximation runs in time $\\mathcal{O}(n+c\\log(c+m))$\nwhereas the preemptive algorithm has a running time $\\mathcal{O}(n \\log (c+m))\n\\leq \\mathcal{O}(n \\log n)$. So far, no PTAS is known for the preemptive\nproblem without restrictions, so we make progress towards that question.\nRecently Jansen et al. found an EPTAS for the splittable and non-preemptive\ncase but with impractical running times exponential in $1/\\varepsilon$.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 13:14:46 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 17:01:08 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Deppert", "Max A.", ""], ["Jansen", "Klaus", ""]]}, {"id": "1810.01393", "submitter": "Themistoklis Melissourgos", "authors": "Argyrios Deligkas, John Fearnley, Themistoklis Melissourgos, and Paul\n  G. Spirakis", "title": "Approximating the Existential Theory of the Reals", "comments": "In the proceedings of the 14th Conference on Web and Internet\n  Economics (WINE 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.GT math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Existential Theory of the Reals (ETR) consists of existentially\nquantified Boolean formulas over equalities and inequalities of polynomial\nfunctions of variables in $\\mathbb{R}$. In this paper we propose and study the\napproximate existential theory of the reals ($\\epsilon$-ETR), in which the\nconstraints only need to be satisfied approximately. We first show that when\nthe domain of the variables is $\\mathbb{R}$ then $\\epsilon$-ETR = ETR under\npolynomial time reductions, and then study the constrained $\\epsilon$-ETR\nproblem when the variables are constrained to lie in a given bounded convex\nset. Our main theorem is a sampling theorem, similar to those that have been\nproved for approximate equilibria in normal form games. It discretizes the\ndomain in a grid-like manner whose density depends on various properties of the\nformula. A consequence of our theorem is that we obtain a quasi-polynomial time\napproximation scheme (QPTAS) for a fragment of constrained $\\epsilon$-ETR. We\nuse our theorem to create several new PTAS and QPTAS algorithms for problems\nfrom a variety of fields.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:33:46 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 11:23:45 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 18:16:20 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Deligkas", "Argyrios", ""], ["Fearnley", "John", ""], ["Melissourgos", "Themistoklis", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1810.01407", "submitter": "Mohammad Mahmoody", "authors": "Saeed Mahloujifar and Mohammad Mahmoody", "title": "Can Adversarially Robust Learning Leverage Computational Hardness?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making learners robust to adversarial perturbation at test time (i.e.,\nevasion attacks) or training time (i.e., poisoning attacks) has emerged as a\nchallenging task. It is known that for some natural settings, sublinear\nperturbations in the training phase or the testing phase can drastically\ndecrease the quality of the predictions. These negative results, however, are\ninformation theoretic and only prove the existence of such successful\nadversarial perturbations. A natural question for these settings is whether or\nnot we can make classifiers computationally robust to polynomial-time attacks.\n  In this work, we prove strong barriers against achieving such envisioned\ncomputational robustness both for evasion and poisoning attacks. In particular,\nwe show that if the test instances come from a product distribution (e.g.,\nuniform over $\\{0,1\\}^n$ or $[0,1]^n$, or isotropic $n$-variate Gaussian) and\nthat there is an initial constant error, then there exists a polynomial-time\nattack that finds adversarial examples of Hamming distance $O(\\sqrt n)$. For\npoisoning attacks, we prove that for any learning algorithm with sample\ncomplexity $m$ and any efficiently computable \"predicate\" defining some \"bad\"\nproperty $B$ for the produced hypothesis (e.g., failing on a particular test)\nthat happens with an initial constant probability, there exist polynomial-time\nonline poisoning attacks that tamper with $O (\\sqrt m)$ many examples, replace\nthem with other correctly labeled examples, and increases the probability of\nthe bad event $B$ to $\\approx 1$.\n  Both of our poisoning and evasion attacks are black-box in how they access\ntheir corresponding components of the system (i.e., the hypothesis, the\nconcept, and the learning algorithm) and make no further assumptions about the\nclassifier or the learning algorithm producing the classifier.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:58:23 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 04:53:12 GMT"}, {"version": "v3", "created": "Tue, 6 Nov 2018 04:19:41 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1810.01542", "submitter": "Daniel Paulusma", "authors": "Walter Kern and Daniel Paulusma", "title": "Contracting to a Longest Path in H-Free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove two dichotomy results for detecting long paths as patterns in a\ngiven graph. The NP-hard problem Longest Induced Path is to determine the\nlongest induced path in a graph. The NP-hard problem Longest Path\nContractibility is to determine the longest path to which a graph can be\ncontracted to. By combining known results with new results we completely\nclassify the computational complexity of both problems for $H$-free graphs. Our\nmain focus is on the second problem, for which we design a general\ncontractibility technique that enables us to reduce the problem to a matching\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 23:45:12 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Kern", "Walter", ""], ["Paulusma", "Daniel", ""]]}, {"id": "1810.01634", "submitter": "M. J\\'anos Uray", "authors": "M. J. Uray", "title": "Algebraic number fields and the LLL algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the computational costs of various operations and\nalgorithms in algebraic number fields using exact arithmetic. Let $K$ be an\nalgebraic number field. In the first half of the paper, we calculate the\nrunning time and the size of the output of many operations in $K$ in terms of\nthe size of the input and the parameters of $K$. We include some earlier\nresults about these, but we go further than them, e.g. we also analyze some\n$\\mathbb{R}$-specific operations in $K$ like less-than comparison. In the\nsecond half of the paper, we analyze two algorithms: the Bareiss algorithm,\nwhich is an integer-preserving version of the Gaussian elimination, and the LLL\nalgorithm, which is for lattice basis reduction. In both cases, we extend the\nalgorithm from $\\mathbb{Z}^n$ to $K^n$, and give a polynomial upper bound on\nthe running time when the computations in $K$ are performed exactly (as opposed\nto floating-point approximations).\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 08:39:35 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 14:32:46 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Uray", "M. J.", ""]]}, {"id": "1810.01969", "submitter": "Preetum Nakkiran", "authors": "Venkatesan Guruswami, Preetum Nakkiran, Madhu Sudan", "title": "Algorithmic Polarization for Hidden Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a mild variant of polar codes we design linear compression schemes\ncompressing Hidden Markov sources (where the source is a Markov chain, but\nwhose state is not necessarily observable from its output), and to decode from\nHidden Markov channels (where the channel has a state and the error introduced\ndepends on the state). We give the first polynomial time algorithms that manage\nto compress and decompress (or encode and decode) at input lengths that are\npolynomial $\\it{both}$ in the gap to capacity and the mixing time of the Markov\nchain. Prior work achieved capacity only asymptotically in the limit of large\nlengths, and polynomial bounds were not available with respect to either the\ngap to capacity or mixing time. Our results operate in the setting where the\nsource (or the channel) is $\\it{known}$. If the source is $\\it{unknown}$ then\ncompression at such short lengths would lead to effective algorithms for\nlearning parity with noise -- thus our results are the first to suggest a\nseparation between the complexity of the problem when the source is known\nversus when it is unknown.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 20:56:03 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Nakkiran", "Preetum", ""], ["Sudan", "Madhu", ""]]}, {"id": "1810.02241", "submitter": "Olivier Bournez", "authors": "Olivier Bournez and Arnaud Durand and Sabrina Ouazzani", "title": "Recursion schemes, discrete differential equations and characterization\n  of polynomial time computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This papers studies the expressive and computational power of discrete\nOrdinary Differential Equations (ODEs). It presents a new framework using\ndiscrete ODEs as a central tool for computation and provides several implicit\ncharacterizations of complexity and computability classes.\n  The proposed framework presents an original point of view on complexity and\ncomputability classes. It also unifies in an elegant settings various\nconstructions that have been proposed for characterizing these classes. This\nincludes Cobham's and, Bellantoni and Cook's definition of polynomial time and\nlater extensions on the approach, as well as recent characterizations of\ncomputability and complexity by classes of ordinary differential equations. It\nalso helps understanding the relationships between analog computations and\nclassical discrete models of computation theory.\n  At a more technical point of view, this paper points out the fundamental role\nof linear (discrete) ordinary differential equations and classical ODE tools\nsuch as changes of variables to capture computability and complexity measures,\nor as a tool for programming various algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:27:25 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 20:36:16 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Bournez", "Olivier", ""], ["Durand", "Arnaud", ""], ["Ouazzani", "Sabrina", ""]]}, {"id": "1810.02304", "submitter": "Guillaume Ducoffe", "authors": "Guillaume Ducoffe", "title": "Polynomial-time Recognition of 4-Steiner Powers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k^{th}$-power of a given graph $G=(V,E)$ is obtained from $G$ by adding\nan edge between every two distinct vertices at a distance at most $k$ in $G$.\nWe call $G$ a $k$-Steiner power if it is an induced subgraph of the\n$k^{th}$-power of some tree. Our main contribution is a polynomial-time\nrecognition algorithm of $4$-Steiner powers, thereby extending the\ndecade-year-old results of (Lin, Kearney and Jiang, ISAAC'00) for $k=1,2$ and\n(Chang and Ko, WG'07) for $k=3$.\n  A graph $G$ is termed $k$-leaf power if there is some tree $T$ such that: all\nvertices in $V(G)$ are leaf-nodes of $T$, and $G$ is an induced subgraph of the\n$k^{th}$-power of $T$. As a byproduct of our main result, we give the first\nknown polynomial-time recognition algorithm for $6$-leaf powers.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 16:36:53 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 15:25:17 GMT"}, {"version": "v3", "created": "Sun, 3 Feb 2019 16:53:50 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Ducoffe", "Guillaume", ""]]}, {"id": "1810.02393", "submitter": "Jevg\\=enijs Vihrovs", "authors": "Andris Ambainis, Kri\\v{s}j\\=anis Pr\\=usis, Jevg\\=enijs Vihrovs", "title": "On Block Sensitivity and Fractional Block Sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the relation between the block sensitivity $\\text{bs}(f)$ and\nfractional block sensitivity $\\text{fbs}(f)$ complexity measures of Boolean\nfunctions. While it is known that $\\text{fbs}(f) = O(\\text{bs}(f)^2)$, the best\nknown separation achieves $\\text{fbs}(f) = \\left(\\frac{1}{3\\sqrt2} +o(1)\\right)\n\\text{bs(f)}^{3/2}$. We improve the constant factor and show a family of\nfunctions that give $\\text{fbs}(f) = \\left(\\frac{1}{\\sqrt6}-o(1)\\right)\n\\text{bs}(f)^{3/2}.$\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 18:51:04 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Ambainis", "Andris", ""], ["Pr\u016bsis", "Kri\u0161j\u0101nis", ""], ["Vihrovs", "Jevg\u0113nijs", ""]]}, {"id": "1810.02396", "submitter": "Jevg\\=enijs Vihrovs", "authors": "Balthazar Bauer, Jevg\\=enijs Vihrovs, Hoeteck Wee", "title": "On the Inner Product Predicate and a Generalization of Matching Vector\n  Families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by cryptographic applications such as predicate encryption, we\nconsider the problem of representing an arbitrary predicate as the inner\nproduct predicate on two vectors. Concretely, fix a Boolean function $P$ and\nsome modulus $q$. We are interested in encoding $x$ to $\\vec x$ and $y$ to\n$\\vec y$ so that $$P(x,y) = 1 \\Longleftrightarrow \\langle\\vec x,\\vec y\\rangle=\n0 \\bmod q,$$ where the vectors should be as short as possible. This problem can\nalso be viewed as a generalization of matching vector families, which\ncorresponds to the equality predicate. Matching vector families have been used\nin the constructions of Ramsey graphs, private information retrieval (PIR)\nprotocols, and more recently, secret sharing.\n  Our main result is a simple lower bound that allows us to show that known\nencodings for many predicates considered in the cryptographic literature such\nas greater than and threshold are essentially optimal for prime modulus $q$.\nUsing this approach, we also prove lower bounds on encodings for composite $q$,\nand then show tight upper bounds for such predicates as greater than, index and\ndisjointness.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 19:14:37 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Bauer", "Balthazar", ""], ["Vihrovs", "Jevg\u0113nijs", ""], ["Wee", "Hoeteck", ""]]}, {"id": "1810.02494", "submitter": "Yuzhou Gu", "authors": "Yuzhou Gu", "title": "A note on spanoid rank", "comments": "Merged into arXiv:1809.10372", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a spanoid $\\mathcal{S}$ on $n$ elements with\n$\\textsf{rank}(\\mathcal{S}) \\ge n^c \\textsf{f-rank}(\\mathcal{S})$ where $c =\n\\log_5 3 - \\log_5 2.5 \\approx 0.113283$. This answers a question of\nDvir-Gopi-Wigderson [DGW18].\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 02:36:23 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 05:44:23 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Gu", "Yuzhou", ""]]}, {"id": "1810.02684", "submitter": "Vahid Moosavi", "authors": "Joao P. Leitao, Mohamed Zaghloul and Vahid Moosavi", "title": "Modeling overland flow from local inflows in almost no-time, using Self\n  Organizing Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physically-based overland flow models are computationally demanding,\nhindering their use for real-time applications. Therefore, the development of\nfast (and reasonably accurate) overland flow models is needed if they are to be\nused to support flood mitigation decision making. In this study, we investigate\nthe potential of Self-Organizing Maps to rapidly generate water depth and flood\nextent results. To conduct the study, we developed a flood-simulation specific\nSOM, using cellular automata flood model results and a synthetic DEM and inflow\nhydrograph. The preliminary results showed that water depth and flood extent\nresults produced by the SOM are reasonably accurate and obtained in a very\nshort period of time. Based on this, it seems that SOMs have the potential to\nprovide critical flood information to support real-time flood mitigation\ndecisions. The findings presented would however require further investigations\nto obtain general conclusions; these further investigations may include the\nconsideration of real terrain representations, real water supply networks and\nrealistic inflows from pipe bursts.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 18:54:29 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Leitao", "Joao P.", ""], ["Zaghloul", "Mohamed", ""], ["Moosavi", "Vahid", ""]]}, {"id": "1810.02757", "submitter": "Alberto Del Pia", "authors": "Alberto Del Pia, Santanu S. Dey, Robert Weismantel", "title": "Subset selection in sparse matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In subset selection we search for the best linear predictor that involves a\nsmall subset of variables. From a computational complexity viewpoint, subset\nselection is NP-hard and few classes are known to be solvable in polynomial\ntime. Using mainly tools from discrete geometry, we show that some sparsity\nconditions on the original data matrix allow us to solve the problem in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 15:42:38 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 17:25:01 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Del Pia", "Alberto", ""], ["Dey", "Santanu S.", ""], ["Weismantel", "Robert", ""]]}, {"id": "1810.02763", "submitter": "Alberto Del Pia", "authors": "Alberto Del Pia", "title": "Subdeterminants and Concave Integer Quadratic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the NP-hard problem of minimizing a separable concave quadratic\nfunction over the integral points in a polyhedron, and we denote by D the\nlargest absolute value of the subdeterminants of the constraint matrix. In this\npaper we give an algorithm that finds an epsilon-approximate solution for this\nproblem by solving a number of integer linear programs whose constraint\nmatrices have subdeterminants bounded by D in absolute value. The number of\nthese integer linear programs is polynomial in the dimension n, in D and in\n1/epsilon, provided that the number k of variables that appear nonlinearly in\nthe objective is fixed. As a corollary, we obtain the first polynomial-time\napproximation algorithm for separable concave integer quadratic programming\nwith D at most two and k fixed. In the totally unimodular case D=1, we give an\nimproved algorithm that only needs to solve a number of linear programs that is\npolynomial in 1/epsilon and is independent on n, provided that k is fixed.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 15:49:30 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 18:29:48 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Del Pia", "Alberto", ""]]}, {"id": "1810.02784", "submitter": "Aditya Potukuchi", "authors": "Per Austrin, Amey Bhangale, Aditya Potukuchi", "title": "Improved Inapproximability of Rainbow Coloring", "comments": "26 pages, 4 figures, bugs fixed and small discussion regarding\n  Sarkaria's theorem added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rainbow $q$-coloring of a $k$-uniform hypergraph is a $q$-coloring of the\nvertex set such that every hyperedge contains all $q$ colors.\n  We prove that given a rainbow $(k - 2\\lfloor \\sqrt{k}\\rfloor)$-colorable\n$k$-uniform hypergraph, it is NP-hard to find a normal $2$-coloring.\nPreviously, this was only known for rainbow $\\lfloor k/2 \\rfloor$-colorable\nhypergraphs (Guruswami and Lee, SODA 2015).\n  We also study a generalization which we call rainbow $(q, p)$-coloring,\ndefined as a coloring using $q$ colors such that every hyperedge contains at\nleast $p$ colors. We prove that given a rainbow $(k - \\lfloor \\sqrt{kc}\n\\rfloor, k- \\lfloor3\\sqrt{kc} \\rfloor)$-colorable $k$ uniform hypergraph, it is\nNP-hard to find a normal $c$-coloring for any $c = o(k)$.\n  The proof of our second result relies on two combinatorial theorems. One of\nthe theorems was proved by Sarkaria (J. Comb. Theory. 1990) using topological\nmethods and the other theorem we prove using a generalized Borsuk-Ulam theorem.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 16:39:43 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 15:27:49 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 21:13:46 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Austrin", "Per", ""], ["Bhangale", "Amey", ""], ["Potukuchi", "Aditya", ""]]}, {"id": "1810.02854", "submitter": "Andr\\'es Ortiz-Mu\\~noz", "authors": "Daniele Cappelletti, Andr\\'es Ortiz-Mu\\~noz, David Anderson, Erik\n  Winfree", "title": "Stochastic Chemical Reaction Networks for Robustly Approximating\n  Arbitrary Probability Distributions", "comments": null, "journal-ref": "Theoretical Computer Science, 2019", "doi": "10.1016/j.tcs.2019.08.013", "report-no": null, "categories": "cs.CC math.PR q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that discrete distributions on the $d$-dimensional non-negative\ninteger lattice can be approximated arbitrarily well via the marginals of\nstationary distributions for various classes of stochastic chemical reaction\nnetworks. We begin by providing a class of detailed balanced networks and prove\nthat they can approximate any discrete distribution to any desired accuracy.\nHowever, these detailed balanced constructions rely on the ability to\ninitialize a system precisely, and are therefore susceptible to perturbations\nin the initial conditions. We therefore provide another construction based on\nthe ability to approximate point mass distributions and prove that this\nconstruction is capable of approximating arbitrary discrete distributions for\nany choice of initial condition. In particular, the developed models are\nergodic, so their limit distributions are robust to a finite number of\nperturbations over time in the counts of molecules.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 02:52:11 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Cappelletti", "Daniele", ""], ["Ortiz-Mu\u00f1oz", "Andr\u00e9s", ""], ["Anderson", "David", ""], ["Winfree", "Erik", ""]]}, {"id": "1810.03087", "submitter": "Andrei Bulatov", "authors": "Amineh Dadsetan and Andrei A. Bulatov", "title": "Counting homomorphisms in plain exponential time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the counting Graph Homomorphism problem (#GraphHom) the question is: Given\ngraphs G,H, find the number of homomorphisms from G to H. This problem is\ngenerally #P-complete, moreover, Cygan et al. proved that unless the ETH is\nfalse there is no algorithm that solves this problem in time\nO(|V(H)|^{o(|V(G)|)}. This, however, does not rule out the possibility that\nfaster algorithms exist for restricted problems of this kind. Wahlstrom proved\nthat #GraphHom can be solved in plain exponential time, that is, in time\nk^{|V(G)|+V(H)|}\\poly(|V(H)|,|V(G)|) provided H has clique width k. We\ngeneralize this result to a larger class of graphs, and also identify several\nother graph classes that admit a plain exponential algorithm for #GraphHom.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 05:42:30 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Dadsetan", "Amineh", ""], ["Bulatov", "Andrei A.", ""]]}, {"id": "1810.03386", "submitter": "Jef Wijsen", "authors": "Paraschos Koutris and Jef Wijsen", "title": "Consistent Query Answering for Primary Keys in Logspace", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of consistent query answering on databases that may\nviolate primary key constraints. A repair of such a database is any consistent\ndatabase that can be obtained by deleting a minimal set of tuples. For every\nBoolean query q, CERTAINTY(q) is the problem that takes a database as input and\nasks whether q evaluates to true on every repair. In [KW17], the authors show\nthat for every self-join-free Boolean conjunctive query q, the problem\nCERTAINTY(q) is either in P or coNP-complete, and it is decidable which of the\ntwo cases applies. In this paper, we sharpen this result by showing that for\nevery self-join-free Boolean conjunctive query q, the problem CERTAINTY(q) is\neither expressible in symmetric stratified Datalog or coNP-complete. Since\nsymmetric stratified Datalog is in L, we thus obtain a complexity-theoretic\ndichotomy between L and coNP-complete. Another new finding of practical\nimportance is that CERTAINTY(q) is on the logspace side of the dichotomy for\nqueries q where all join conditions express foreign-to-primary key matches,\nwhich is undoubtedly the most common type of join condition.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 11:50:20 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Koutris", "Paraschos", ""], ["Wijsen", "Jef", ""]]}, {"id": "1810.03390", "submitter": "Kunal Das Dr", "authors": "Kunal Das, Arindam Sadhu", "title": "Constant Time Quantum search Algorithm Over A Datasets: An Experimental\n  Study Using IBM Q Experience", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a constant time Quantum searching algorithm over a datasets is\nproposed and subsequently the algorithm is executed in real chip quantum\ncomputer developed by IBM Quantum experience (IBMQ). QISKit, the software\nplatform developed by IBM is used for this algorithm implementation. Quantum\ninterference, Quantum superposition and {\\pi} phase shift of quantum state\napplied for this constant time search algorithm. The proposed quantum algorithm\nis executed in QISKit SDK local backend 'local_qasm_simulator', real chip\n'ibmq_16_melbourne' and 'ibmqx4' IBMQ. Result also suggest that real chip\nibmq_16_melbourne is more quantum error or noise prone than ibmqx4.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 12:08:46 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Das", "Kunal", ""], ["Sadhu", "Arindam", ""]]}, {"id": "1810.03742", "submitter": "Marcelo Prates", "authors": "Marcelo Prates, Luis Lamb", "title": "Problem Solving at the Edge of Chaos: Entropy, Puzzles and the Sudoku\n  Freezing Transition", "comments": "8 pages & 14 figures. Accepted at ICTAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sudoku is a widely popular $\\mathcal{NP}$-Complete combinatorial puzzle whose\nprospects for studying human computation have recently received attention, but\nthe algorithmic hardness of Sudoku solving is yet largely unexplored. In this\npaper, we study the statistical mechanical properties of random Sudoku grids,\nshowing that puzzles of varying sizes attain a hardness peak associated with a\ncritical behavior in the constrainedness of random instances. In doing so, we\nprovide the first description of a Sudoku \\emph{freezing} transition, showing\nthat the fraction of backbone variables undergoes a phase transition as the\ndensity of pre-filled cells is calibrated. We also uncover a variety of\ncritical phenomena in the applicability of Sudoku elimination strategies,\nproviding explanations as to why puzzles become boring outside the typical\nrange of clue densities adopted by Sudoku publishers. We further show that the\nconstrainedness of Sudoku puzzles can be understood in terms of the\ninformational (Shannon) entropy of their solutions, which only increases up to\nthe critical point where variables become frozen. Our findings shed light on\nthe nature of the $k$-coloring transition when the graph topology is fixed, and\nare an invitation to the study of phase transition phenomena in problems\ndefined over \\emph{alldifferent} constraints. They also suggest advantages to\nstudying the statistical mechanics of popular $\\mathcal{NP}$-Hard puzzles,\nwhich can both aid the design of hard instances and help understand the\ndifficulty of human problem solving.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 23:19:23 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Prates", "Marcelo", ""], ["Lamb", "Luis", ""]]}, {"id": "1810.03811", "submitter": "Kewen Wu", "authors": "Xiaoming Sun, Yuan Sun, Kewen Wu, Zhiyu Xia", "title": "On the Relationship between Energy Complexity and other Boolean Function\n  Measures", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate into energy complexity, a Boolean function\nmeasure related to circuit complexity. Given a circuit $\\mathcal{C}$ over the\nstandard basis $\\{\\vee_2,\\wedge_2,\\neg\\}$, the energy complexity of\n$\\mathcal{C}$, denoted by $\\mathrm{EC}(\\mathcal{C})$, is the maximum number of\nits activated inner gates over all inputs. The energy complexity of a Boolean\nfunction $f$, denoted by $\\mathrm{EC}(f)$, is the minimum of\n$\\mathrm{EC}(\\mathcal{C})$ over all circuits $\\mathcal{C}$ computing $f$. This\nconcept has attracted lots of attention in literature. Recently, Dinesh, Otiv,\nand Sarma [COCOON'18] gave $\\mathrm{EC}(f)$ an upper bound in terms of the\ndecision tree complexity, $\\mathrm{EC}(f)=O(\\mathrm{D}(f)^3)$. They also showed\nthat $\\mathrm{EC}(f)\\leq 3n-1$, where $n$ is the input size. Recall that the\nminimum size of circuit to compute $f$ could be as large as $2^n/n$. We improve\ntheir upper bounds by showing that\n$\\mathrm{EC}(f)\\leq\\min\\{\\frac12\\mathrm{D}(f)^2+O(\\mathrm{D}(f)),n+2\\mathrm{D}(f)-2\\}$.\nFor the lower bound, Dinesh, Otiv, and Sarma defined positive sensitivity, a\ncomplexity measure denoted by $\\mathrm{psens}(f)$, and showed that\n$\\mathrm{EC}(f)\\ge\\frac{1}{3}\\mathrm{psens}(f)$. They asked whether\n$\\mathrm{EC}(f)$ can also be lower bounded by a polynomial of $\\mathrm{D}(f)$.\nIn this paper we affirm it by proving\n$\\mathrm{EC}(f)=\\Omega(\\sqrt{\\mathrm{D}(f)})$. For non-degenerated functions\nwith input size $n$, we give another lower bound\n$\\mathrm{EC}(f)=\\Omega(\\log{n})$. All these three lower bounds are incomparable\nto each other. Besides, we also examine the energy complexity of $\\mathtt{OR}$\nfunctions and $\\mathtt{ADDRESS}$ functions, which implies the tightness of our\ntwo lower bounds respectively. In addition, the former one answers another open\nquestion asking for a non-trivial lower bounds for the energy complexity of\n$\\mathtt{OR}$ functions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 04:33:41 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 02:20:53 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Sun", "Xiaoming", ""], ["Sun", "Yuan", ""], ["Wu", "Kewen", ""], ["Xia", "Zhiyu", ""]]}, {"id": "1810.03868", "submitter": "Jocelyn Thiebaut", "authors": "Florian Barbero, Lucas Isenmann, Jocelyn Thiebaut", "title": "On the Distance Identifying Set meta-problem and applications to the\n  complexity of identifying problems on graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous problems consisting in identifying vertices in graphs using\ndistances are useful in domains such as network verification and graph\nisomorphism. Unifying them into a meta-problem may be of main interest. We\nintroduce here a promising solution named Distance Identifying Set. The model\ncontains Identifying Code (IC), Locating Dominating Set (LD) and their\ngeneralizations $r$-IC and $r$-LD where the closed neighborhood is considered\nup to distance $r$. It also contains Metric Dimension (MD) and its refinement\n$r$-MD in which the distance between two vertices is considered as infinite if\nthe real distance exceeds $r$. Note that while IC = 1-IC and LD = 1-LD, we have\nMD = $\\infty$-MD; we say that MD is not local\n  In this article, we prove computational lower bounds for several problems\nincluded in Distance Identifying Set by providing generic reductions from\n(Planar) Hitting Set to the meta-problem. We mainly focus on two families of\nproblem from the meta-problem: the first one, called bipartite gifted local,\ncontains $r$-IC, $r$-LD and $r$-MD for each positive integer $r$ while the\nsecond one, called 1-layered, contains LD, MD and $r$-MD for each positive\ninteger $r$. We have:\n  - the 1-layered problems are NP-hard even in bipartite apex graphs,\n  - the bipartite gifted local problems are NP-hard even in bipartite planar\ngraphs,\n  - assuming ETH, all these problems cannot be solved in $2^{o(\\sqrt{n})}$ when\nrestricted to bipartite planar or apex graph, respectively, and they cannot be\nsolved in $2^{o(n)}$ on bipartite graphs,\n  - even restricted to bipartite graphs, they do not admit parameterized\nalgorithms in $2^{O(k)}.n^{O(1)}$ except if W[0] = W[2]. Here $k$ is the\nsolution size of a relevant identifying set.\n  In particular, Metric Dimension cannot be solved in $2^{o(n)}$ under ETH,\nanswering a question of Hartung in 2013.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 09:14:15 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Barbero", "Florian", ""], ["Isenmann", "Lucas", ""], ["Thiebaut", "Jocelyn", ""]]}, {"id": "1810.03980", "submitter": "Hiram H. L\\'opez", "authors": "Allison Beemer, Ryan Coatney, Venkatesan Guruswami, Hiram H. L\\'opez\n  and Fernando Pi\\~nero", "title": "Explicit optimal-length locally repairable codes of distance 5", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.AC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally repairable codes (LRCs) have received significant recent attention as\na method of designing data storage systems robust to server failure. Optimal\nLRCs offer the ideal trade-off between minimum distance and locality, a measure\nof the cost of repairing a single codeword symbol. For optimal LRCs with\nminimum distance greater than or equal to 5, block length is bounded by a\npolynomial function of alphabet size. In this paper, we give explicit\nconstructions of optimal-length (in terms of alphabet size), optimal LRCs with\nminimum distance equal to 5.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 13:47:03 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 01:46:03 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Beemer", "Allison", ""], ["Coatney", "Ryan", ""], ["Guruswami", "Venkatesan", ""], ["L\u00f3pez", "Hiram H.", ""], ["Pi\u00f1ero", "Fernando", ""]]}, {"id": "1810.04006", "submitter": "Florent Capelli", "authors": "Florent Capelli, Yann Strozecki", "title": "Enumerating models of DNF faster: breaking the dependency on the formula\n  size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study the problem of enumerating the models of DNF\nformulas. The aim is to provide enumeration algorithms with a delay that\ndepends polynomially on the size of each model and not on the size of the\nformula, which can be exponentially larger. We succeed for two subclasses of\nDNF formulas: we provide a constant delay algorithm for $k$-DNF with fixed $k$\nby an appropriate amortization method and we give a quadratic delay algorithm\nfor monotone formulas. We then focus on the \\emph{average delay} of enumeration\nalgorithms and show how to obtain a sublinear delay in the formula size.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 14:06:57 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 06:30:36 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Capelli", "Florent", ""], ["Strozecki", "Yann", ""]]}, {"id": "1810.04063", "submitter": "Vajira Thambawita", "authors": "Vajira Thambawita, Roshan G. Ragel, Dhammike Elkaduwe", "title": "To Use or Not to Use: CPUs' Cache Optimization Techniques on GPGPUs", "comments": "6 pages, 15 Figures", "journal-ref": "ICIAfS 2016- IEEE International Conference on Information and\n  Automation for Sustainability", "doi": "10.1109/ICIAFS.2016.7946534", "report-no": null, "categories": "cs.DC cs.CC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General Purpose Graphic Processing Unit(GPGPU) is used widely for achieving\nhigh performance or high throughput in parallel programming. This capability of\nGPGPUs is very famous in the new era and mostly used for scientific computing\nwhich requires more processing power than normal personal computers. Therefore,\nmost of the programmers, researchers and industry use this new concept for\ntheir work. However, achieving high-performance or high-throughput using GPGPUs\nare not an easy task compared with conventional programming concepts in the CPU\nside. In this research, the CPU's cache memory optimization techniques have\nbeen adopted to the GPGPU's cache memory to identify rare performance\nimprovement techniques compared to GPGPU's best practices. The cache\noptimization techniques of blocking, loop fusion, array merging and array\ntranspose were tested on GPGPUs for finding suitability of these techniques.\nFinally, we identified that some of the CPU cache optimization techniques go\nwell with the cache memory system of the GPGPU and shows performance\nimprovements while some others show the opposite effect on the GPGPUs compared\nwith the CPUs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 15:10:33 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Thambawita", "Vajira", ""], ["Ragel", "Roshan G.", ""], ["Elkaduwe", "Dhammike", ""]]}, {"id": "1810.04190", "submitter": "Ruhollah Majdoddin", "authors": "Ruhollah Majdoddin", "title": "Uniform CSP Parameterized by Solution Size is in W[1]", "comments": "A rewrite of the proof, an error introduced in version 3 is dealt\n  with. An earlier version of this paper is accepted to CSR 2019, Novosibirsk,\n  Russia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the uniform Constraint Satisfaction Problem (CSP) parameterized\nby the size of the solution is in W[1] (the problem is W[1]-hard and it is easy\nto place it in W[3]). Given a single \"free\" element of the domain, denoted by\n$0$, we define the size of an assignment as the number of variables that are\nmapped to a value other than $0$. Named by Kolaitis and Vardi (2000), uniform\nCSP means that the input contains the domain and the list of tuples of each\nrelation in the instance. Uniform CSP is polynomial time equivalent to\nhomomorphism problem and also to evaluation of conjunctive queries on\nrelational databases. It also has applications in artificial intelligence.\n  We do not restrict the problem to any (finite or infinite) family of\nrelations. Marx and Bulatov (2014) showed that Uniform CSP restricted to some\nfinite family of relations (thus with a bound on the arity of relations) and\nover any finite domain is either W[1]-complete or fixed parameter tractable.\n  We then prove that parameterized Subset Sum with weights bounded by $n^k$ is\nin W[1]. Abboud et al. (2014) have already proved it, but our proof is much\nshorter and arguably more intuitive.\n  Lastly, we study the weighted CSP over the Boolean Domain, where each\nvariable is assigned a weight, and given a target value, it should be decided\nif there is a satisfying assignment of size $k$ (the parameter) such that the\nweight of its $1$-variables adds up to the target value. We prove that if the\nweights are bounded by $n^k$, then the problem is in W[1]. Our proofs give a\nnondeterministic RAM program with special properties deciding the problem.\nFirst defined by Chen et al. (2005), such programs characterize W[1].\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 18:04:01 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 15:20:07 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 11:24:24 GMT"}, {"version": "v4", "created": "Tue, 30 Apr 2019 14:13:04 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Majdoddin", "Ruhollah", ""]]}, {"id": "1810.04207", "submitter": "Daniel Reichman", "authors": "Pasin Manurangsi, Daniel Reichman", "title": "The Computational Complexity of Training ReLU(s)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the computational complexity of training depth-2 neural networks\ncomposed of rectified linear units (ReLUs). We show that, even for the case of\na single ReLU, finding a set of weights that minimizes the squared error (even\napproximately) for a given training set is NP-hard. We also show that for a\nsimple network consisting of two ReLUs, the error minimization problem is\nNP-hard, even in the realizable case. We complement these hardness results by\nshowing that, when the weights and samples belong to the unit ball, one can\n(agnostically) properly and reliably learn depth-2 ReLUs with $k$ units and\nerror at most $\\epsilon$ in time $2^{(k/\\epsilon)^{O(1)}}n^{O(1)}$; this\nextends upon a previous work of Goel, Kanade, Klivans and Thaler (2017) which\nprovided efficient improper learning algorithms for ReLUs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 18:42:22 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 16:33:50 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Manurangsi", "Pasin", ""], ["Reichman", "Daniel", ""]]}, {"id": "1810.04254", "submitter": "Tharun Kumar Reddy Medini", "authors": "Qixuan Huang, Yiqiu Wang, Tharun Medini, Anshumali Shrivastava", "title": "Extreme Classification in Log Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Merged-Averaged Classifiers via Hashing (MACH) for\nK-classification with ultra-large values of K. Compared to traditional\none-vs-all classifiers that require O(Kd) memory and inference cost, MACH only\nneed O(d log K) (d is dimensionality )memory while only requiring O(K log K + d\nlog K) operation for inference. MACH is a generic K-classification algorithm,\nwith provably theoretical guarantees, which requires O(log K) memory without\nany assumption on the relationship between classes. MACH uses universal hashing\nto reduce classification with a large number of classes to few independent\nclassification tasks with small (constant) number of classes. We provide\ntheoretical quantification of discriminability-memory tradeoff. With MACH we\ncan train ODP dataset with 100,000 classes and 400,000 features on a single\nTitan X GPU, with the classification accuracy of 19.28%, which is the\nbest-reported accuracy on this dataset. Before this work, the best performing\nbaseline is a one-vs-all classifier that requires 40 billion parameters (160 GB\nmodel size) and achieves 9% accuracy. In contrast, MACH can achieve 9% accuracy\nwith 480x reduction in the model size (of mere 0.3GB). With MACH, we also\ndemonstrate complete training of fine-grained imagenet dataset (compressed size\n104GB), with 21,000 classes, on a single GPU. To the best of our knowledge,\nthis is the first work to demonstrate complete training of these extreme-class\ndatasets on a single Titan X.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:43:57 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Huang", "Qixuan", ""], ["Wang", "Yiqiu", ""], ["Medini", "Tharun", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1810.04379", "submitter": "Daniel Paulusma", "authors": "Esther Galby, Paloma T. Lima, Daniel Paulusma, Bernard Ries", "title": "Classifying k-Edge Colouring for H-free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is $H$-free if it does not contain an induced subgraph isomorphic to\n$H$. For every integer $k$ and every graph $H$, we determine the computational\ncomplexity of $k$-Edge Colouring for $H$-free graphs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 06:03:12 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Galby", "Esther", ""], ["Lima", "Paloma T.", ""], ["Paulusma", "Daniel", ""], ["Ries", "Bernard", ""]]}, {"id": "1810.04553", "submitter": "Mehdi Khosravian Ghadikoalei", "authors": "Katrin Casel, Henning Fernau, Mehdi Khosravian Ghadikolaei, J\\'er\\^ome\n  Monnot and Florian Sikora", "title": "On the Complexity of Solution Extension of Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question if a given partial solution to a problem can be extended\nreasonably occurs in many algorithmic approaches for optimization problems. For\ninstance, when enumerating minimal dominating sets of a graph $G=(V,E)$, one\nusually arrives at the problem to decide for a vertex set $U \\subseteq V$, if\nthere exists a \\textit{minimal} dominating set $S$ with $U\\subseteq S$. We\npropose a general, partial-order based formulation of such extension problems\nand study a number of specific problems which can be expressed in this\nframework. Possibly contradicting intuition, these problems tend to be NP-hard,\neven for problems where the underlying optimisation problem can be solved in\npolynomial time. This raises the question of how fixing a partial solution\ncauses this increase in difficulty. In this regard, we study the parameterised\ncomplexity of extension problems with respect to parameters related to the\npartial solution, as well as the optimality of simple exact algorithms under\nthe Exponential-Time Hypothesis. All complexity considerations are also carried\nout in very restricted scenarios, be it degree restrictions or topological\nrestrictions (planarity) for graph problems or the size of the given partition\nfor the considered extension variant of Bin Packing.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 14:48:33 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Casel", "Katrin", ""], ["Fernau", "Henning", ""], ["Ghadikolaei", "Mehdi Khosravian", ""], ["Monnot", "J\u00e9r\u00f4me", ""], ["Sikora", "Florian", ""]]}, {"id": "1810.04620", "submitter": "R\\'emi Watrigant", "authors": "\\'Edouard Bonnet, Nicolas Bousquet, Pierre Charbit, St\\'ephan\n  Thomass\\'e, R\\'emi Watrigant", "title": "Parameterized Complexity of Independent Set in H-Free Graphs", "comments": "An extended abstract appeared in the proceedings of IPEC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate the complexity of Maximum Independent Set (MIS)\nin the class of $H$-free graphs, that is, graphs excluding a fixed graph as an\ninduced subgraph. Given that the problem remains $NP$-hard for most graphs $H$,\nwe study its fixed-parameter tractability and make progress towards a dichotomy\nbetween $FPT$ and $W[1]$-hard cases. We first show that MIS remains $W[1]$-hard\nin graphs forbidding simultaneously $K_{1, 4}$, any finite set of cycles of\nlength at least $4$, and any finite set of trees with at least two branching\nvertices. In particular, this answers an open question of Dabrowski et al.\nconcerning $C_4$-free graphs. Then we extend the polynomial algorithm of\nAlekseev when $H$ is a disjoint union of edges to an $FPT$ algorithm when $H$\nis a disjoint union of cliques. We also provide a framework for solving several\nother cases, which is a generalization of the concept of \\emph{iterative\nexpansion} accompanied by the extraction of a particular structure using\nRamsey's theorem. Iterative expansion is a maximization version of the\nso-called \\emph{iterative compression}. We believe that our framework can be of\nindependent interest for solving other similar graph problems. Finally, we\npresent positive and negative results on the existence of polynomial (Turing)\nkernels for several graphs $H$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:24:29 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 15:34:23 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Bousquet", "Nicolas", ""], ["Charbit", "Pierre", ""], ["Thomass\u00e9", "St\u00e9phan", ""], ["Watrigant", "R\u00e9mi", ""]]}, {"id": "1810.04629", "submitter": "Mehdi Khosravian Ghadikolaei", "authors": "Katrin Casel, Henning Fernau, Mehdi Khosravian Ghadikolaei, J\\'er\\^ome\n  Monnot and Florian Sikora", "title": "Extension of vertex cover and independent set in some classes of graphs\n  and generalizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider extension variants of the classical graph problems Vertex Cover\nand Independent Set. Given a graph $G=(V,E)$ and a vertex set $U \\subseteq V$,\nit is asked if there exists a minimal vertex cover (resp.\\ maximal independent\nset) $S$ with $U\\subseteq S$ (resp.\\ $U \\supseteq S$). Possibly contradicting\nintuition, these problems tend to be NP-hard, even in graph classes where the\nclassical problem can be solved in polynomial time. Yet, we exhibit some graph\nclasses where the extension variant remains polynomial-time solvable. We also\nstudy the parameterized complexity of these problems, with parameter $|U|$, as\nwell as the optimality of simple exact algorithms under the Exponential-Time\nHypothesis. All these complexity considerations are also carried out in very\nrestricted scenarios, be it degree or topological restrictions (bipartite,\nplanar or chordal graphs). This also motivates presenting some explicit\nbranching algorithms for degree-bounded instances.\n  We further discuss the price of extension, measuring the distance of $U$ to\nthe closest set that can be extended, which results in natural optimization\nproblems related to extension problems for which we discuss polynomial-time\napproximability.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:40:26 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 15:19:14 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Casel", "Katrin", ""], ["Fernau", "Henning", ""], ["Ghadikolaei", "Mehdi Khosravian", ""], ["Monnot", "J\u00e9r\u00f4me", ""], ["Sikora", "Florian", ""]]}, {"id": "1810.04670", "submitter": "Ranveer Singh", "authors": "Ranveer Singh, Vivek Vijay, RB Bapat", "title": "Algorithm for $\\mathcal{B}$-partitions, parameterized complexity of the\n  matrix determinant and permanent", "comments": "arXiv admin note: text overlap with arXiv:1701.04420", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every square matrix $A=(a_{uv})\\in \\mathcal{C}^{n\\times n}$ can be\nrepresented as a digraph having $n$ vertices. In the digraph, a block (or\n2-connected component) is a maximally connected subdigraph that has no\ncut-vertex. The determinant and the permanent of a matrix can be calculated in\nterms of the determinant and the permanent of some specific induced subdigraphs\nof the blocks in the digraph. Interestingly, these induced subdigraphs are\nvertex-disjoint and they partition the digraph. Such partitions of the digraph\nare called the $\\mathcal{B}$-partitions. In this paper, first, we develop an\nalgorithm to find the $\\mathcal{B}$-partitions. Next, we analyze the\nparameterized complexity of matrix determinant and permanent, where, the\nparameters are the sizes of blocks and the number of cut-vertices of the\ndigraph. We give a class of combinations of cut-vertices and block sizes for\nwhich the parametrized complexities beat the state of art complexities of the\ndeterminant and the permanent.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 08:03:34 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Singh", "Ranveer", ""], ["Vijay", "Vivek", ""], ["Bapat", "RB", ""]]}, {"id": "1810.05129", "submitter": "Pascal Maillard", "authors": "Louigi Addario-Berry, Pascal Maillard", "title": "The algorithmic hardness threshold for continuous random energy models", "comments": "22 pages, 2 figures. Minor additions and modifications in v2, minor\n  corrections in v3 to v5, to appear in Mathematical Statistics and Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cond-mat.dis-nn cond-mat.stat-mech cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an algorithmic hardness result for finding low-energy states in the\nso-called \\emph{continuous random energy model (CREM)}, introduced by Bovier\nand Kurkova in 2004 as an extension of Derrida's \\emph{generalized random\nenergy model}. The CREM is a model of a random energy landscape $(X_v)_{v \\in\n\\{0,1\\}^N}$ on the discrete hypercube with built-in hierarchical structure, and\ncan be regarded as a toy model for strongly correlated random energy landscapes\nsuch as the family of $p$-spin models including the Sherrington--Kirkpatrick\nmodel. The CREM is parameterized by an increasing function $A:[0,1]\\to[0,1]$,\nwhich encodes the correlations between states.\n  We exhibit an \\emph{algorithmic hardness threshold} $x_*$, which is explicit\nin terms of $A$. More precisely, we obtain two results: First, we show that a\nrenormalization procedure combined with a greedy search yields for any\n$\\varepsilon > 0$ a linear-time algorithm which finds states $v \\in \\{0,1\\}^N$\nwith $X_v \\ge (x_*-\\varepsilon) N$. Second, we show that the value $x_*$ is\nessentially best-possible: for any $\\varepsilon > 0$, any algorithm which finds\nstates $v$ with $X_v \\ge (x_*+\\varepsilon)N$ requires exponentially many\nqueries in expectation and with high probability. We further discuss what\ninsights this study yields for understanding algorithmic hardness thresholds\nfor random instances of combinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:21:55 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 11:54:35 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 20:53:42 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Addario-Berry", "Louigi", ""], ["Maillard", "Pascal", ""]]}, {"id": "1810.05603", "submitter": "Daniel Saunders", "authors": "Daniel J. Saunders", "title": "Investigating the Power of Circuits with $MOD_6$ Gates", "comments": "23 pages, 1 figure, unpublished undergraduate independent study work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the power of Boolean circuits with MOD$_{6}$ gates. First, we\nintroduce a few basic notions of computational complexity, and describe the\nstandard models with which we study the complexity of problems. We then define\nthe model of Boolean circuits, equate a restricted class of circuits with an\nalgebraic model, and present some results from working with this algebra.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:46:33 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Saunders", "Daniel J.", ""]]}, {"id": "1810.05830", "submitter": "Leslie Ann Goldberg", "authors": "Leslie Ann Goldberg and Mark Jerrum", "title": "Approximating Pairwise Correlations in the Ising Model", "comments": "To Appear in ACM ToCT", "journal-ref": "ACM Trans. Comput. Theory 11 (2019), no. 4, Art. 23", "doi": "10.1145/3337785", "report-no": null, "categories": "cs.DS cs.CC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Ising model, we consider the problem of estimating the covariance of\nthe spins at two specified vertices. In the ferromagnetic case, it is easy to\nobtain an additive approximation to this covariance by repeatedly sampling from\nthe relevant Gibbs distribution. However, we desire a multiplicative\napproximation, and it is not clear how to achieve this by sampling, given that\nthe covariance can be exponentially small. Our main contribution is a fully\npolynomial time randomised approximation scheme (FPRAS) for the covariance. We\nalso show that that the restriction to the ferromagnetic case is essential ---\nthere is no FPRAS for multiplicatively estimating the covariance of an\nantiferromagnetic Ising model unless RP = #P. In fact, we show that even\ndetermining the sign of the covariance is #P-hard in the antiferromagnetic\ncase.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 09:20:08 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 09:14:33 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Goldberg", "Leslie Ann", ""], ["Jerrum", "Mark", ""]]}, {"id": "1810.05907", "submitter": "David Gamarnik", "authors": "David Gamarnik and Eren Kizildag", "title": "Computing the partition function of the Sherrington-Kirkpatrick model is\n  hard on average", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish the average-case hardness of the algorithmic problem of exact\ncomputation of the partition function associated with the\nSherrington-Kirkpatrick model of spin glasses with Gaussian couplings and\nrandom external field. In particular, we establish that unless $P= \\#P$, there\ndoes not exist a polynomial-time algorithm to exactly compute the partition\nfunction on average. This is done by showing that if there exists a polynomial\ntime algorithm, which exactly computes the partition function for inverse\npolynomial fraction ($1/n^{O(1)}$) of all inputs, then there is a polynomial\ntime algorithm, which exactly computes the partition function for all inputs,\nwith high probability, yielding $P=\\#P$. The computational model that we adopt\nis {\\em finite-precision arithmetic}, where the algorithmic inputs are\ntruncated first to a certain level $N$ of digital precision. The ingredients of\nour proof include the random and downward self-reducibility of the partition\nfunction with random external field; an argument of Cai et al.\n\\cite{cai1999hardness} for establishing the average-case hardness of computing\nthe permanent of a matrix; a list-decoding algorithm of Sudan\n\\cite{sudan1996maximum}, for reconstructing polynomials intersecting a given\nlist of numbers at sufficiently many points; and near-uniformity of the\nlog-normal distribution, modulo a large prime $p$. To the best of our\nknowledge, our result is the first one establishing a provable hardness of a\nmodel arising in the field of spin glasses.\n  Furthermore, we extend our result to the same problem under a different {\\em\nreal-valued} computational model, e.g. using a Blum-Shub-Smale machine\n\\cite{blum1988theory} operating over real-valued inputs.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 18:13:22 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 20:18:11 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 02:14:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Gamarnik", "David", ""], ["Kizildag", "Eren", ""]]}, {"id": "1810.06081", "submitter": "Nikhil Vyas", "authors": "Nikhil Vyas", "title": "Super Strong ETH is False for Random $k$-SAT", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been hypothesized that $k$-SAT is hard to solve for randomly chosen\ninstances near the \"critical threshold\", where the clause-to-variable ratio is\n$2^k \\ln 2-\\theta(1)$. Feige's hypothesis for $k$-SAT says that for all\nsufficiently large clause-to-variable ratios, random $k$-SAT cannot be refuted\nin polynomial time. It has also been hypothesized that the worst-case $k$-SAT\nproblem cannot be solved in $2^{n(1-\\omega_k(1)/k)}$ time, as multiple known\nalgorithmic paradigms (backtracking, local search and the polynomial method)\nonly yield an $2^{n(1-1/O(k))}$ time algorithm. This hypothesis has been called\nthe \"Super-Strong ETH\", modeled after the ETH and the Strong ETH.\n  Our main result is a randomized algorithm which refutes the Super-Strong ETH\nfor the case of random $k$-SAT, for any clause-to-variable ratio. Given any\nrandom $k$-SAT instance $F$ with $n$ variables and $m$ clauses, our algorithm\ndecides satisfiability for $F$ in $2^{n(1-\\Omega(\\log k)/k)}$ time, with high\nprobability. It turns out that a well-known algorithm from the literature on\nSAT algorithms does the job: the PPZ algorithm of Paturi, Pudlak, and Zane\n(1998).\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 19:12:39 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Vyas", "Nikhil", ""]]}, {"id": "1810.06213", "submitter": "Fran\\c{c}ois Schwarzentruber", "authors": "Tristan Charrier, Fran\\c{c}ois Schwarzentruber, Eva Soulier", "title": "Dynamic Connected Cooperative Coverage Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the so-called dynamic coverage problem by agents located in some\ntopological graph. The agents must visit all regions of interest but they also\nshould stay connected to the base via multi-hop. We prove that the algorithmic\ncomplexity of this planning problem is PSPACE-complete. Furthermore we prove\nthat the problem becomes NP-complete for bounded plans. We also prove the same\ncomplexities for the reachability problem of some positions. We also prove that\ncomplexities are maintained for a subclass of topological graphs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 08:00:34 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Charrier", "Tristan", ""], ["Schwarzentruber", "Fran\u00e7ois", ""], ["Soulier", "Eva", ""]]}, {"id": "1810.06839", "submitter": "Alex Nowak-Vila", "authors": "Alex Nowak-Vila (SIERRA, PSL), Francis Bach (SIERRA, PSL), Alessandro\n  Rudi (SIERRA, PSL)", "title": "Sharp Analysis of Learning with Discrete Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of devising learning strategies for discrete losses (e.g.,\nmultilabeling, ranking) is currently addressed with methods and theoretical\nanalyses ad-hoc for each loss. In this paper we study a least-squares framework\nto systematically design learning algorithms for discrete losses, with\nquantitative characterizations in terms of statistical and computational\ncomplexity. In particular we improve existing results by providing explicit\ndependence on the number of labels for a wide class of losses and faster\nlearning rates in conditions of low-noise. Theoretical results are complemented\nwith experiments on real datasets, showing the effectiveness of the proposed\ngeneral approach.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 06:44:42 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Nowak-Vila", "Alex", "", "SIERRA, PSL"], ["Bach", "Francis", "", "SIERRA, PSL"], ["Rudi", "Alessandro", "", "SIERRA, PSL"]]}, {"id": "1810.06872", "submitter": "Esther Galby", "authors": "Esther Galby, Andrea Munaro, Bernard Ries", "title": "Semitotal Domination: New hardness results and a polynomial-time\n  algorithm for graphs of bounded mim-width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semitotal dominating set of a graph $G$ with no isolated vertex is a\ndominating set $D$ of $G$ such that every vertex in $D$ is within distance two\nof another vertex in $D$. The minimum size $\\gamma_{t2}(G)$ of a semitotal\ndominating set of $G$ is squeezed between the domination number $\\gamma(G)$ and\nthe total domination number $\\gamma_{t}(G)$.\n  \\textsc{Semitotal Dominating Set} is the problem of finding, given a graph\n$G$, a semitotal dominating set of $G$ of size $\\gamma_{t2}(G)$. In this paper,\nwe continue the systematic study on the computational complexity of this\nproblem when restricted to special graph classes. In particular, we show that\nit is solvable in polynomial time for the class of graphs with bounded\nmim-width by a reduction to \\textsc{Total Dominating Set} and we provide\nseveral approximation lower bounds for subclasses of subcubic graphs. Moreover,\nwe obtain complexity dichotomies in monogenic classes for the decision versions\nof \\textsc{Semitotal Dominating Set} and \\textsc{Total Dominating Set}.\n  Finally, we show that it is $\\mathsf{NP}$-complete to recognise the graphs\nsuch that $\\gamma_{t2}(G) = \\gamma_{t}(G)$ and those such that $\\gamma(G) =\n\\gamma_{t2}(G)$, even if restricted to be planar and with maximum degree at\nmost $4$, and we provide forbidden induced subgraph characterisations for the\ngraphs heriditarily satisfying either of these two equalities.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 08:26:17 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Galby", "Esther", ""], ["Munaro", "Andrea", ""], ["Ries", "Bernard", ""]]}, {"id": "1810.07358", "submitter": "Tian An Wong", "authors": "Tanuj Mathur and Tian An Wong", "title": "On the computational complexity of MSTD sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline a general algorithm for verifying whether a subset of the integers\nis a more sum than differences (MSTD) set, also known as sum dominated sets,\nand give estimates on its computational complexity. We conclude with some\nnumerical results on large MSTD sets and MSTD subsets of $[1,N]\\cap \\mathbb Z$\nfor $N$ up to 160.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 02:30:45 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Mathur", "Tanuj", ""], ["Wong", "Tian An", ""]]}, {"id": "1810.08004", "submitter": "Hossein Vahidi", "authors": "Saeed Akhoondian Amiri, Alexandru Popa, Mohammad Roghani, Golnoosh\n  Shahkarami, Reza Soltani, Hossein Vahidi", "title": "Complexity of Computing the Anti-Ramsey Numbers for Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The anti-Ramsey numbers are a fundamental notion in graph theory, introduced\nin 1978, by Erd\\\" os, Simonovits and S\\' os. For given graphs $G$ and $H$ the\n\\emph{anti-Ramsey number} $\\textrm{ar}(G,H)$ is defined to be the maximum\nnumber $k$ such that there exists an assignment of $k$ colors to the edges of\n$G$ in which every copy of $H$ in $G$ has at least two edges with the same\ncolor.\n  There are works on the computational complexity of the problem when $H$ is a\nstar. Along this line of research, we study the complexity of computing the\nanti-Ramsey number $\\textrm{ar}(G,P_k)$, where $P_k$ is a path of length $k$.\nFirst, we observe that when $k = \\Omega(n)$, the problem is hard; hence, the\nchallenging part is the computational complexity of the problem when $k$ is a\nfixed constant.\n  We provide a characterization of the problem for paths of constant length.\nOur first main contribution is to prove that computing $\\textrm{ar}(G,P_k)$ for\nevery integer $k>2$ is NP-hard. We obtain this by providing several structural\nproperties of such coloring in graphs. We investigate further and show that\napproximating $\\textrm{ar}(G,P_3)$ to a factor of $n^{-1/2 - \\epsilon}$ is hard\nalready in $3$-partite graphs, unless P=NP. We also study the exact complexity\nof the precolored version and show that there is no subexponential algorithm\nfor the problem unless ETH fails for any fixed constant $k$.\n  Given the hardness of approximation and parametrization of the problem, it is\nnatural to study the problem on restricted graph families. We introduce the\nnotion of color connected coloring and employing this structural property. We\nobtain a linear time algorithm to compute $\\textrm{ar}(G,P_k)$, for every\ninteger $k$, when the host graph, $G$, is a tree.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 11:59:02 GMT"}, {"version": "v2", "created": "Sat, 9 Mar 2019 12:47:48 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 20:40:36 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 20:36:42 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Amiri", "Saeed Akhoondian", ""], ["Popa", "Alexandru", ""], ["Roghani", "Mohammad", ""], ["Shahkarami", "Golnoosh", ""], ["Soltani", "Reza", ""], ["Vahidi", "Hossein", ""]]}, {"id": "1810.08345", "submitter": "Zhao Song", "authors": "Rasmus Kyng, Zhao Song", "title": "A Matrix Chernoff Bound for Strongly Rayleigh Distributions and Spectral\n  Sparsifiers from a few Random Spanning Trees", "comments": "FOCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Strongly Rayleigh distributions are a class of negatively dependent\ndistributions of binary-valued random variables [Borcea, Branden, Liggett JAMS\n09]. Recently, these distributions have played a crucial role in the analysis\nof algorithms for fundamental graph problems, e.g. Traveling Salesman Problem\n[Gharan, Saberi, Singh FOCS 11]. We prove a new matrix Chernoff bound for\nStrongly Rayleigh distributions.\n  As an immediate application, we show that adding together the Laplacians of\n$\\epsilon^{-2} \\log^2 n$ random spanning trees gives an $(1\\pm \\epsilon)$\nspectral sparsifiers of graph Laplacians with high probability. Thus, we\npositively answer an open question posed in [Baston, Spielman, Srivastava, Teng\nJACM 13]. Our number of spanning trees for spectral sparsifier matches the\nnumber of spanning trees required to obtain a cut sparsifier in [Fung,\nHariharan, Harvey, Panigraphi STOC 11]. The previous best result was by naively\napplying a classical matrix Chernoff bound which requires $\\epsilon^{-2} n \\log\nn$ spanning trees. For the tree averaging procedure to agree with the original\ngraph Laplacian in expectation, each edge of the tree should be reweighted by\nthe inverse of the edge leverage score in the original graph. We also show that\nwhen using this reweighting of the edges, the Laplacian of single random tree\nis bounded above in the PSD order by the original graph Laplacian times a\nfactor $\\log n$ with high probability, i.e. $L_T \\preceq O(\\log n) L_G$.\n  We show a lower bound that almost matches our last result, namely that in\nsome graphs, with high probability, the random spanning tree is $\\it{not}$\nbounded above in the spectral order by $\\frac{\\log n}{\\log\\log n}$ times the\noriginal graph Laplacian. We also show a lower bound that in $\\epsilon^{-2}\n\\log n$ spanning trees are necessary to get a $(1\\pm \\epsilon)$ spectral\nsparsifier.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 03:27:28 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Kyng", "Rasmus", ""], ["Song", "Zhao", ""]]}, {"id": "1810.08484", "submitter": "Roland Molontay", "authors": "Roland Molontay and Kitti Varga", "title": "On the complexity of color-avoiding site and bond percolation", "comments": "14 pages", "journal-ref": null, "doi": "10.1007/978-3-030-10801-4_28", "report-no": null, "categories": "cs.DM cs.CC cs.SI math.CO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mathematical analysis of robustness and error-tolerance of complex\nnetworks has been in the center of research interest. On the other hand, little\nwork has been done when the attack-tolerance of the vertices or edges are not\nindependent but certain classes of vertices or edges share a mutual\nvulnerability. In this study, we consider a graph and we assign colors to the\nvertices or edges, where the color-classes correspond to the shared\nvulnerabilities. An important problem is to find robustly connected vertex\nsets: nodes that remain connected to each other by paths providing any type of\nerror (i.e. erasing any vertices or edges of the given color). This is also\nknown as color-avoiding percolation. In this paper, we study various possible\nmodeling approaches of shared vulnerabilities, we analyze the computational\ncomplexity of finding the robustly (color-avoiding) connected components. We\nfind that the presented approaches differ significantly regarding their\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 13:19:09 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Molontay", "Roland", ""], ["Varga", "Kitti", ""]]}, {"id": "1810.08668", "submitter": "Vladimir Podolskii", "authors": "Anastasiya Chistopolskaya and Vladimir V. Podolskii", "title": "Parity Decision Tree Complexity is Greater Than Granularity", "comments": "Compared to the previous version we added a comparison of the\n  complexity measures discussed to the degree of Boolean functions over\n  $\\mathbb{F}_2$. We removed the section on $MOD^3$ as a non-instructive\n  example. We added the connection to multiplicative complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a new lower bound on the parity decision tree complexity\n$\\mathsf{D}_{\\oplus}(f)$ of a Boolean function $f$. Namely, granularity of the\nBoolean function $f$ is the smallest $k$ such that all Fourier coefficients of\n$f$ are integer multiples of $1/2^k$. We show that $\\mathsf{D}_{\\oplus}(f)\\geq\nk+1$.\n  This lower bound is an improvement of lower bounds through the sparsity of\n$f$ and through the degree of $f$ over $\\mathbb{F}_2$. Using our lower bound we\ndetermine the exact parity decision tree complexity of several important\nBoolean functions including majority and recursive majority. For majority the\ncomplexity is $n - \\mathsf{B}(n)+1$, where $\\mathsf{B}(n)$ is the number of\nones in the binary representation of $n$. For recursive majority the complexity\nis $\\frac{n+1}{2}$. Finally, we provide an example of a function for which our\nlower bound is not tight.\n  Our results imply new lower bound of $n - \\mathsf{B}(n)$ on the\nmultiplicative complexity of majority.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 19:58:59 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 17:22:34 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Chistopolskaya", "Anastasiya", ""], ["Podolskii", "Vladimir V.", ""]]}, {"id": "1810.08671", "submitter": "Josh Alman", "authors": "Josh Alman and Virginia Vassilevska Williams", "title": "Limits on All Known (and Some Unknown) Approaches to Matrix\n  Multiplication", "comments": "32 pages. A preliminary version appeared in the 59th Annual IEEE\n  Symposium on Foundations of Computer Science (FOCS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the known techniques for designing Matrix Multiplication algorithms.\nThe two main approaches are the Laser method of Strassen, and the Group\ntheoretic approach of Cohn and Umans. We define a generalization based on\nzeroing outs which subsumes these two approaches, which we call the Solar\nmethod, and an even more general method based on monomial degenerations, which\nwe call the Galactic method.\n  We then design a suite of techniques for proving lower bounds on the value of\n$\\omega$, the exponent of matrix multiplication, which can be achieved by\nalgorithms using many tensors $T$ and the Galactic method. Some of our\ntechniques exploit `local' properties of $T$, like finding a sub-tensor of $T$\nwhich is so `weak' that $T$ itself couldn't be used to achieve a good bound on\n$\\omega$, while others exploit `global' properties, like $T$ being a monomial\ndegeneration of the structural tensor of a group algebra.\n  Our main result is that there is a universal constant $\\ell>2$ such that a\nlarge class of tensors generalizing the Coppersmith-Winograd tensor $CW_q$\ncannot be used within the Galactic method to show a bound on $\\omega$ better\nthan $\\ell$, for any $q$. We give evidence that previous lower-bounding\ntechniques were not strong enough to show this. We also prove a number of\ncomplementary results along the way, including that for any group $G$, the\nstructural tensor of $\\mathbb{C}[G]$ can be used to recover the best bound on\n$\\omega$ which the Coppersmith-Winograd approach gets using $CW_{|G|-2}$ as\nlong as the asymptotic rank of the structural tensor is not too large.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:07:08 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Alman", "Josh", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1810.08873", "submitter": "Yaqiao Li", "authors": "Yaqiao Li", "title": "Conflict complexity is lower bounded by block sensitivity", "comments": "a discussion section added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show conflict complexity of every total Boolean function, recently\nintroduced in [Swagato Sanyal. A composition theorem via conict complexity.\narXiv preprint arXiv:1801.03285, 2018.] to prove a composition theorem of\nrandomized decision tree complexity, is at least a half of its block\nsensitivity. We propose to compare conflict complexity with certificate\ncomplexity, and explain why it could be interesting.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 00:37:24 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 13:44:34 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Li", "Yaqiao", ""]]}, {"id": "1810.10361", "submitter": "Colleen Robichaux", "authors": "Anshul Adve, Colleen Robichaux, Alexander Yong", "title": "Computational complexity, Newton polytopes, and Schubert polynomials", "comments": "12 pages. v2 is the conference proceedings version. The remaining\n  material of v1 (proofs, the theorem on #P-completeness) is split off into a\n  subsequent arXiv post. That post has a different title (\"An efficient\n  algorithm for deciding vanishing of Schubert polynomial coefficients\"),\n  abstract, and discussion of the general \"nonvanishing problem\" removed", "journal-ref": "Proceedings of the 31st Conference on Formal Power Series and\n  Algebraic Combinatorics (Ljubljana), Sem. Lothar. Combin. 82B (2020), Art.\n  52, 12 pp", "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nonvanishing problem asks if a coefficient of a polynomial is nonzero.\nMany families of polynomials in algebraic combinatorics admit combinatorial\ncounting rules and simultaneously enjoy having saturated Newton polytopes\n(SNP). Thereby, in amenable cases, nonvanishing is in the complexity class\n$NP\\cap coNP$ of problems with \"good characterizations\". This suggests a new\nalgebraic combinatorics viewpoint on complexity theory.\n  This report discusses the case of Schubert polynomials. These form a basis of\nall polynomials and appear in the study of cohomology rings of flag manifolds.\nWe give a tableau criterion for nonvanishing, from which we deduce the first\npolynomial time algorithm. These results are obtained from new\ncharacterizations of the Schubitope, a generalization of the permutahedron\ndefined for any subset of the n x n grid, together with a theorem of A. Fink,\nK. M\\'{e}sz\\'{a}ros, and A. St. Dizier, which proved a conjecture of C.\nMonical, N. Tokcan, and the third author.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 12:44:06 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 20:04:28 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Adve", "Anshul", ""], ["Robichaux", "Colleen", ""], ["Yong", "Alexander", ""]]}, {"id": "1810.10838", "submitter": "Francois Le Gall", "authors": "Fran\\c{c}ois Le Gall, Harumichi Nishimura and Ansis Rosmanis", "title": "Quantum Advantage for the LOCAL Model in Distributed Computing", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two central models considered in (fault-free synchronous)\ndistributed computing: the CONGEST model, in which communication channels have\nlimited bandwidth, and the LOCAL model, in which communication channels have\nunlimited bandwidth. Very recently, Le Gall and Magniez (PODC 2018) showed the\nsuperiority of quantum distributed computing over classical distributed\ncomputing in the CONGEST model. In this work we show the superiority of quantum\ndistributed computing in the LOCAL model: we exhibit a computational task that\ncan be solved in a constant number of rounds in the quantum setting but\nrequires $\\Omega(n)$ rounds in the classical setting, where $n$ denotes the\nsize of the network.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 12:03:35 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""], ["Nishimura", "Harumichi", ""], ["Rosmanis", "Ansis", ""]]}, {"id": "1810.10938", "submitter": "Han-Hsuan Lin", "authors": "Kai-Min Chung and Han-Hsuan Lin", "title": "Sample Efficient Algorithms for Learning Quantum Channels in PAC Model\n  and the Approximate State Discrimination Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the PAC (probably approximately correct) learning model to the\nquantum world by generalizing the concepts from classical functions to quantum\nprocesses, defining the problem of \\emph{PAC learning quantum process}, and\nstudy its sample complexity. In the problem of PAC learning quantum process, we\nwant to learn an $\\epsilon$-approximate of an unknown quantum process $c^*$\nfrom a known finite concept class $C$ with probability $1-\\delta$ using samples\n$\\{(x_1,c^*(x_1)),(x_2,c^*(x_2)),\\dots\\}$, where $\\{x_1,x_2, \\dots\\}$ are\ncomputational basis states sampled from an unknown distribution $D$ and\n$\\{c^*(x_1),c^*(x_2),\\dots\\}$ are the (possibly mixed) quantum states outputted\nby $c^*$. The special case of PAC-learning quantum process under constant input\nreduces to a natural problem which we named as approximate state\ndiscrimination, where we are given copies of an unknown quantum state $c^*$\nfrom an known finite set $C$, and we want to learn with probability $1-\\delta$\nan $\\epsilon$-approximate of $c^*$ with as few copies of $c^*$ as possible. We\nshow that the problem of PAC learning quantum process can be solved with\n$$O\\left(\\frac{\\log|C| + \\log(1/ \\delta)} { \\epsilon^2}\\right)$$ samples when\nthe outputs are pure states and $$O\\left(\\frac{\\log^3 |C|(\\log |C|+\\log(1/\n\\delta))} { \\epsilon^2}\\right)$$ samples if the outputs can be mixed. Some\nimplications of our results are that we can PAC-learn a polynomial sized\nquantum circuit in polynomial samples and approximate state discrimination can\nbe solved in polynomial samples even when concept class size $|C|$ is\nexponential in the number of qubits, an exponentially improvement over a full\nstate tomography.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:50:57 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 16:42:35 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 02:40:11 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Chung", "Kai-Min", ""], ["Lin", "Han-Hsuan", ""]]}, {"id": "1810.10944", "submitter": "JaeSung Choi", "authors": "Jaesung Choi and Pilwon Kim", "title": "Critical Neuromorphic Computing based on Explosive Synchronization", "comments": "14pages, 8figures", "journal-ref": null, "doi": "10.1063/1.5086902", "report-no": null, "categories": "cs.NE cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronous oscillations in neuronal ensembles have been proposed to provide\na neural basis for the information processes in the brain. In this work, we\npresent a neuromorphic computing algorithm based on oscillator synchronization\nin a critical regime. The algorithm uses the high dimensional transient\ndynamics perturbed by an input and translates it into proper output stream. One\nof the benefits of adopting coupled phase oscillators as neuromorphic elements\nis that the synchrony among oscillators can be finely tuned at a critical\nstate. Especially near a critical state, the marginally synchronized\noscillators operate with high efficiency and maintain better computing\nperformances. We also show that explosive synchronization which is induced from\nspecific neuronal connectivity produces more improved and stable outputs. This\nwork provides a systematic way to encode computing in a large size coupled\noscillators, which may be useful in designing neuromorphic devices.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 12:57:06 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Choi", "Jaesung", ""], ["Kim", "Pilwon", ""]]}, {"id": "1810.10961", "submitter": "\\'E. Rold\\'an", "authors": "Hannah Alpert and \\'Erika Rold\\'an", "title": "Art gallery problem with rook and queen vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many chess rooks or queens does it take to guard all the squares of a\ngiven polyomino, the union of square tiles from a square grid? This question is\na version of the art gallery problem in which the guards can \"see\" whichever\nsquares the rook or queen attacks. We show that floor(n/2) rooks or floor(n/3)\nqueens are sufficient and sometimes necessary to guard a polyomino with n\ntiles. We also prove that finding the minimum number of rooks or the minimum\nnumber of queens needed to guard a polyomino is NP-hard. These results also\napply to d-dimensional rooks and queens on d-dimensional polycubes. We also use\nbipartite matching theorems to describe sets of non-attacking rooks on\npolyominoes.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:31:09 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 17:16:20 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Alpert", "Hannah", ""], ["Rold\u00e1n", "\u00c9rika", ""]]}, {"id": "1810.11391", "submitter": "Johan Kwisthout", "authors": "Johan Kwisthout", "title": "Finding dissimilar explanations in Bayesian networks: Complexity results", "comments": "Presented at the Benelux AI Conference (BNAIC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the most probable explanation for observed variables in a Bayesian\nnetwork is a notoriously intractable problem, particularly if there are hidden\nvariables in the network. In this paper we examine the complexity of a related\nproblem, that is, the problem of finding a set of sufficiently dissimilar, yet\nall plausible, explanations. Applications of this problem are, e.g., in search\nquery results (you won't want 10 results that all link to the same website) or\nin decision support systems. We show that the problem of finding a 'good\nenough' explanation that differs in structure from the best explanation is at\nleast as hard as finding the best explanation itself.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 15:37:24 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 10:33:54 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Kwisthout", "Johan", ""]]}, {"id": "1810.11700", "submitter": "Dimitrios Thilikos", "authors": "Julien Baste and Didem G\\\"oz\\\"upek and Mordechai Shalom and Dimitrios\n  M. Thilikos", "title": "Minimum Reload Cost Graph Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of Reload cost in a graph refers to the cost that occurs while\ntraversing a vertex via two of its incident edges. This cost is uniquely\ndetermined by the colors of the two edges. This concept has various\napplications in transportation networks, communication networks, and energy\ndistribution networks. Various problems using this model are defined and\nstudied in the literature. The problem of finding a spanning tree whose\ndiameter with respect to the reload costs is the smallest possible, the\nproblems of finding a path, trail or walk with minimum total reload cost\nbetween two given vertices, problems about finding a proper edge coloring of a\ngraph such that the total reload cost is minimized, the problem of finding a\nspanning tree such that the sum of the reload costs of all paths between all\npairs of vertices is minimized, and the problem of finding a set of cycles of\nminimum reload cost, that cover all the vertices of a graph, are examples of\nsuch problems. % In this work we focus on the last problem. Noting that a cycle\ncover of a graph is a 2-factor of it, we generalize the problem to that of\nfinding an $r$-factor of minimum reload cost of an edge colored graph. We prove\nseveral NP-hardness results for special cases of the problem. Namely, bounded\ndegree graphs, planar graphs, bounded total cost, and bounded number of\ndistinct costs. For the special case of $r=2$, our results imply an improved\nNP-hardness result. On the positive side, we present a polynomial-time solvable\nspecial case which provides a tight boundary between the polynomial and hard\ncases in terms of $r$ and the maximum degree of the graph. We then investigate\nthe parameterized complexity of the problem, prove W[1]-hardness results and\npresent an FPT algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 20:37:42 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 14:49:14 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Baste", "Julien", ""], ["G\u00f6z\u00fcpek", "Didem", ""], ["Shalom", "Mordechai", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "1810.12030", "submitter": "Joran van Apeldoorn", "authors": "Joran van Apeldoorn and Sander Gribling", "title": "Simon's problem for linear functions", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simon's problem asks the following: determine if a function $f: \\{0,1\\}^n\n\\rightarrow \\{0,1\\}^n$ is one-to-one or if there exists a unique $s \\in\n\\{0,1\\}^n$ such that $f(x) = f(x \\oplus s)$ for all $x \\in \\{0,1\\}^n$, given\nthe promise that exactly one of the two holds. A classical algorithm that can\nsolve this problem for every $f$ requires $2^{\\Omega(n)}$ queries to $f$. Simon\nshowed that there is a quantum algorithm that can solve this promise problem\nfor every $f$ using only $\\mathcal O(n)$ quantum queries to $f$. A matching\nlower bound on the number of quantum queries was given by Koiran et al., even\nfor functions $f: {\\mathbb{F}_p^n} \\to {\\mathbb{F}_p^n}$. We give a short proof\nthat $\\mathcal O(n)$ quantum queries is optimal even when we are additionally\npromised that $f$ is linear. This is somewhat surprising because for linear\nfunctions there even exists a classical $n$-query algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 09:47:30 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 12:55:50 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["van Apeldoorn", "Joran", ""], ["Gribling", "Sander", ""]]}, {"id": "1810.12095", "submitter": "Amandeep Bhatia", "authors": "Amandeep Singh Bhatia and Ajay Kumar", "title": "On the Power of Quantum Queue Automata in Real-time", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposed a quantum analogue of classical queue automata by using\nthe definition of the quantum Turing machine and quantum finite-state automata.\nHowever, quantum automata equipped with storage medium of a stack has been\nconsidered, but the concept of quantum queue automata has not been introduced\nso far. The classical Turing machines can be simulated by classical queue\nautomata. Motivated by the efficiency of the quantum Turing machine and nature\nof classical queue automata, we have introduced the notion of quantum queue\nautomata using unitary criteria. Our contributions are as follows. We have also\nintroduced a generalization of real-time deterministic queue automata, the\nreal-time quantum queue automata which work in real-time i.e. the input head\ncan move towards the right direction only and takes exactly one step per input\nsymbol. We have shown that real-time quantum queue automata is more superior\nthan its real-time classical variants by using quantum transitions. We have\nproved the existence of the language that can be recognized by real-time\nquantum queue automata and cannot be recognized by real-time deterministic\n(reversible) queue automata. Further, we have shown that there is a language\nthat can be recognized by real-time quantum queue automata but not by real-time\nnon-deterministic queue automata.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 13:22:28 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Bhatia", "Amandeep Singh", ""], ["Kumar", "Ajay", ""]]}, {"id": "1810.12272", "submitter": "Dimitrios Diochnos", "authors": "Dimitrios I. Diochnos, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Adversarial Risk and Robustness: General Definitions and Implications\n  for the Uniform Distribution", "comments": "Full version of a work with the same title that will appear in NIPS\n  2018, 31 pages containing 5 figures, 1 table, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversarial perturbations when the instances are uniformly\ndistributed over $\\{0,1\\}^n$. We study both \"inherent\" bounds that apply to any\nproblem and any classifier for such a problem as well as bounds that apply to\nspecific problems and specific hypothesis classes.\n  As the current literature contains multiple definitions of adversarial risk\nand robustness, we start by giving a taxonomy for these definitions based on\ntheir goals, we identify one of them as the one guaranteeing misclassification\nby pushing the instances to the error region. We then study some classic\nalgorithms for learning monotone conjunctions and compare their adversarial\nrisk and robustness under different definitions by attacking the hypotheses\nusing instances drawn from the uniform distribution. We observe that sometimes\nthese definitions lead to significantly different bounds. Thus, this study\nadvocates for the use of the error-region definition, even though other\ndefinitions, in other contexts, may coincide with the error-region definition.\n  Using the error-region definition of adversarial perturbations, we then study\ninherent bounds on risk and robustness of any classifier for any classification\nproblem whose instances are uniformly distributed over $\\{0,1\\}^n$. Using the\nisoperimetric inequality for the Boolean hypercube, we show that for initial\nerror $0.01$, there always exists an adversarial perturbation that changes\n$O(\\sqrt{n})$ bits of the instances to increase the risk to $0.5$, making\nclassifier's decisions meaningless. Furthermore, by also using the central\nlimit theorem we show that when $n\\to \\infty$, at most $c \\cdot \\sqrt{n}$ bits\nof perturbations, for a universal constant $c< 1.17$, suffice for increasing\nthe risk to $0.5$, and the same $c \\cdot \\sqrt{n} $ bits of perturbations on\naverage suffice to increase the risk to $1$, hence bounding the robustness by\n$c \\cdot \\sqrt{n}$.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:41:29 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Diochnos", "Dimitrios I.", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1810.12792", "submitter": "Francois Le Gall", "authors": "Fran\\c{c}ois Le Gall", "title": "Average-Case Quantum Advantage with Shallow Circuits", "comments": "18 pages; accepted to CCC'19; v2: added references, soundness\n  improved (from constant to exponentially small) in the main result; v3:\n  discussion added about the relation with Ref. [BGK18]; v4: corrected typos,\n  footnote 3 removed", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Bravyi, Gosset and K\\\"onig (Science 2018) proved an unconditional\nseparation between the computational powers of small-depth quantum and\nclassical circuits for a relation. In this paper we show a similar separation\nin the average-case setting that gives stronger evidence of the superiority of\nsmall-depth quantum computation: we construct a computational task that can be\nsolved on all inputs by a quantum circuit of constant depth with bounded-fanin\ngates (a \"shallow\" quantum circuit) and show that any classical circuit with\nbounded-fanin gates solving this problem on a non-negligible fraction of the\ninputs must have logarithmic depth. Our results are obtained by introducing a\ntechnique to create quantum states exhibiting global quantum correlations from\nany graph, via a construction that we call the \\emph{extended graph}.\n  Similar results have been very recently (and independently) obtained by\nCoudron, Stark and Vidick (arXiv:1810.04233), and Bene Watts, Kothari,\nSchaeffer and Tal (STOC 2019).\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:00:47 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 00:32:10 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 13:29:23 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 03:44:22 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""]]}, {"id": "1810.13246", "submitter": "Lei Yu", "authors": "Lei Yu and Vincent Y. F. Tan", "title": "Exact Channel Synthesis", "comments": "This is the final version. To appear in IEEE Transactions on\n  Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exact channel synthesis problem. This problem concerns the\ndetermination of the minimum amount of information required to create exact\ncorrelation remotely when there is a certain rate of randomness shared by two\nterminals. This problem generalizes an existing approximate version, in which\nthe generated joint distribution is required to be close to a target\ndistribution under the total variation (TV) distance measure (instead being\nexactly equal to the target distribution). We provide single-letter inner and\nouter bounds on the admissible region of the shared randomness rate and the\ncommunication rate for the exact channel synthesis problem. These two bounds\ncoincide for doubly symmetric binary sources. We observe that for such sources,\nthe admissible rate region for exact channel synthesis is strictly included in\nthat for the TV-approximate version. We also extend the exact and\nTV-approximate channel synthesis problems to sources with countably infinite\nalphabets and continuous sources; the latter includes Gaussian sources. As\nby-products, lemmas concerning soft-covering under R\\'enyi divergence measures\nare derived.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:23:41 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 09:22:40 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Yu", "Lei", ""], ["Tan", "Vincent Y. F.", ""]]}]